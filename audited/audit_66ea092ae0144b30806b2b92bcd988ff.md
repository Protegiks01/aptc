# Audit Report

## Title
Validator Node Crash Due to Unhandled Lazy gRPC Connection Failures in Remote Sharded Block Execution

## Summary
The remote sharded block executor uses `connect_lazy()` for gRPC connections, which defers connection establishment until the first RPC call. When this first call fails due to network issues, the error handler invokes `panic!()`, causing the validator node to crash during consensus-critical block execution. This vulnerability can cause total loss of validator liveness when remote sharded execution is configured.

## Finding Description

The vulnerability exists in the gRPC network service implementation used by the remote sharded block executor. The attack surface spans multiple components: [1](#0-0) 

The `get_channel` function uses `connect_lazy()`, which defers actual connection establishment until the first RPC call is made. This is a performance optimization to avoid blocking during initialization. [2](#0-1) 

When `send_message()` is called and the RPC fails (which would happen on the first call if the connection cannot be established), the error is handled by calling `panic!()` instead of gracefully propagating the error or implementing retry logic. Note the TODO comment at line 150 explicitly acknowledges this needs to be fixed.

This gRPC client is used in the remote executor client for distributed block execution: [3](#0-2) 

The `execute_block` method sends execution commands to remote shards and blocks waiting for results. When a network issue prevents connection to any shard, the panic propagates up through the call stack.

The remote executor is integrated into the consensus execution path: [4](#0-3) 

When remote addresses are configured, the `execute_block_sharded` function uses `REMOTE_SHARDED_BLOCK_EXECUTOR`, which delegates to the remote executor client. [5](#0-4) 

This is called from `BlockExecutor::execute_and_update_state`, which is the consensus-critical block execution path.

**Exploitation Path:**
1. Validator is configured with remote sharded execution (via `set_remote_addresses()`)
2. During consensus block execution, `execute_and_update_state` is called
3. This triggers `DoGetExecutionOutput::by_transaction_execution`
4. Which calls `execute_block_sharded` on the remote executor
5. The remote executor sends messages to shards via gRPC
6. On first RPC, `connect_lazy()` attempts to establish connection
7. If connection fails (network partition, DNS failure, shard down), the error is caught in `send_message`
8. Instead of retry or graceful degradation, `panic!()` is called
9. Validator node crashes during block execution

## Impact Explanation

**Severity: CRITICAL** - Total loss of liveness/network availability

This vulnerability qualifies as Critical severity under the Aptos Bug Bounty program because:

1. **Validator Node Crash**: The panic causes the entire validator process to terminate during consensus-critical block execution
2. **Consensus Availability Impact**: If multiple validators using remote sharded execution experience network issues simultaneously, consensus can stall as nodes crash
3. **Deterministic Crash**: This is not a race condition or edge case - any network connectivity issue deterministically triggers the crash
4. **Production Code Path**: While remote sharded execution is optional, it is production code designed for distributed execution scaling

The crash violates multiple critical invariants:
- **Deterministic Execution**: Validators crash non-deterministically based on network conditions
- **Consensus Safety**: Validator crashes during block execution can prevent consensus progress
- **State Consistency**: Crash during execution may leave inconsistent state requiring recovery

## Likelihood Explanation

**Likelihood: HIGH** when remote sharded execution is configured

The vulnerability is highly likely to be triggered because:

1. **Common Network Issues**: Transient network partitions, DNS resolution failures, shard process restarts, or network congestion are common in distributed systems
2. **First-Call Failure**: The lazy connection makes the first RPC call the critical failure point, which could occur at any time during block execution
3. **No Retry Logic**: The TODO comment and test acknowledgment confirm retry logic is missing
4. **Wide Attack Surface**: Any connectivity issue to ANY of the configured shards triggers the crash [6](#0-5) 

The test at lines 198-201 explicitly includes a sleep to avoid hitting this issue, acknowledging the timing problem.

## Recommendation

Replace the panic with proper error handling and retry logic:

```rust
pub async fn send_message(
    &mut self,
    sender_addr: SocketAddr,
    message: Message,
    mt: &MessageType,
) -> Result<(), NetworkError> {
    let request = tonic::Request::new(NetworkMessage {
        message: message.data,
        message_type: mt.get_type(),
    });
    
    const MAX_RETRIES: u32 = 3;
    const INITIAL_BACKOFF_MS: u64 = 100;
    
    for attempt in 0..MAX_RETRIES {
        match self.remote_channel.simple_msg_exchange(request.clone()).await {
            Ok(_) => return Ok(()),
            Err(e) => {
                if attempt < MAX_RETRIES - 1 {
                    let backoff = INITIAL_BACKOFF_MS * (2u64.pow(attempt));
                    warn!(
                        "Retry {}/{} after {}ms for message to {} on node {:?}: {}",
                        attempt + 1, MAX_RETRIES, backoff, self.remote_addr, sender_addr, e
                    );
                    tokio::time::sleep(Duration::from_millis(backoff)).await;
                } else {
                    error!(
                        "Failed to send message to {} on node {:?} after {} retries: {}",
                        self.remote_addr, sender_addr, MAX_RETRIES, e
                    );
                    return Err(NetworkError::SendFailed(e));
                }
            },
        }
    }
    unreachable!()
}
```

Additionally, update callers to handle the error result and implement circuit breaker patterns for repeated failures.

## Proof of Concept

```rust
#[test]
fn test_lazy_connection_failure() {
    use aptos_config::utils;
    use std::{
        net::{IpAddr, Ipv4Addr, SocketAddr},
    };

    // Create client pointing to non-existent server
    let invalid_addr = SocketAddr::new(
        IpAddr::V4(Ipv4Addr::new(192, 0, 2, 1)), // TEST-NET-1, unreachable
        utils::get_available_port()
    );
    
    let rt = Runtime::new().unwrap();
    let mut client = GRPCNetworkMessageServiceClientWrapper::new(&rt, invalid_addr);
    
    let sender_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), utils::get_available_port());
    let test_message = Message::new("test".as_bytes().to_vec());
    
    // This will panic due to connect_lazy() failing on first RPC
    // In production, this happens during block execution causing validator crash
    rt.block_on(async {
        client.send_message(
            sender_addr,
            test_message,
            &MessageType::new("test".to_string()),
        ).await;
        // Execution never reaches here - validator has crashed
    });
}
```

## Notes

The vulnerability is explicitly acknowledged in the codebase:
- Line 150 TODO comment: "Retry with exponential backoff on failures"
- Test lines 198-201: Comment acknowledging the need for retry on send_message failures

While remote sharded execution is an optional feature controlled by configuration, it is production code intended for performance scaling. Any deployment using this feature is vulnerable to validator crashes from routine network issues.

### Citations

**File:** secure/net/src/grpc_network_service/mod.rs (L132-138)
```rust
    async fn get_channel(remote_addr: String) -> NetworkMessageServiceClient<Channel> {
        info!("Trying to connect to remote server at {:?}", remote_addr);
        let conn = tonic::transport::Endpoint::new(remote_addr)
            .unwrap()
            .connect_lazy();
        NetworkMessageServiceClient::new(conn).max_decoding_message_size(MAX_MESSAGE_SIZE)
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L140-160)
```rust
    pub async fn send_message(
        &mut self,
        sender_addr: SocketAddr,
        message: Message,
        mt: &MessageType,
    ) {
        let request = tonic::Request::new(NetworkMessage {
            message: message.data,
            message_type: mt.get_type(),
        });
        // TODO: Retry with exponential backoff on failures
        match self.remote_channel.simple_msg_exchange(request).await {
            Ok(_) => {},
            Err(e) => {
                panic!(
                    "Error '{}' sending message to {} on node {:?}",
                    e, self.remote_addr, sender_addr
                );
            },
        }
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L163-220)
```rust
#[test]
fn basic_test() {
    use aptos_config::utils;
    use std::{
        net::{IpAddr, Ipv4Addr},
        thread,
    };

    let server_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), utils::get_available_port());
    let message_type = "test_type".to_string();
    let server_handlers: Arc<Mutex<HashMap<MessageType, Sender<Message>>>> =
        Arc::new(Mutex::new(HashMap::new()));

    let (msg_tx, msg_rx) = crossbeam_channel::unbounded();
    server_handlers
        .lock()
        .unwrap()
        .insert(MessageType::new(message_type.clone()), msg_tx);
    let server = GRPCNetworkMessageServiceServerWrapper::new(server_handlers, server_addr);

    let rt = Runtime::new().unwrap();
    let (server_shutdown_tx, server_shutdown_rx) = oneshot::channel();
    server.start(
        &rt,
        "unit tester".to_string(),
        server_addr,
        1000,
        server_shutdown_rx,
    );

    let mut grpc_client = GRPCNetworkMessageServiceClientWrapper::new(&rt, server_addr);

    let client_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), utils::get_available_port());
    let test_message_content = "test1".as_bytes().to_vec();

    // wait for the server to be ready before sending messages
    // TODO: We need to implement retry on send_message failures such that we can pass this test
    //       without this sleep
    thread::sleep(std::time::Duration::from_millis(10));

    for _ in 0..2 {
        rt.block_on(async {
            grpc_client
                .send_message(
                    client_addr,
                    Message::new(test_message_content.clone()),
                    &MessageType::new(message_type.clone()),
                )
                .await;
        });
    }

    for _ in 0..2 {
        let received_msg = msg_rx.recv().unwrap();
        assert_eq!(received_msg.data, test_message_content);
    }
    server_shutdown_tx.send(()).unwrap();
}
```

**File:** execution/executor-service/src/remote_executor_client.rs (L180-212)
```rust
    fn execute_block(
        &self,
        state_view: Arc<S>,
        transactions: PartitionedTransactions,
        concurrency_level_per_shard: usize,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<ShardedExecutionOutput, VMStatus> {
        trace!("RemoteExecutorClient Sending block to shards");
        self.state_view_service.set_state_view(state_view);
        let (sub_blocks, global_txns) = transactions.into();
        if !global_txns.is_empty() {
            panic!("Global transactions are not supported yet");
        }
        for (shard_id, sub_blocks) in sub_blocks.into_iter().enumerate() {
            let senders = self.command_txs.clone();
            let execution_request = RemoteExecutionRequest::ExecuteBlock(ExecuteBlockCommand {
                sub_blocks,
                concurrency_level: concurrency_level_per_shard,
                onchain_config: onchain_config.clone(),
            });

            senders[shard_id]
                .lock()
                .unwrap()
                .send(Message::new(bcs::to_bytes(&execution_request).unwrap()))
                .unwrap();
        }

        let execution_results = self.get_output_from_shards()?;

        self.state_view_service.drop_state_view();
        Ok(ShardedExecutionOutput::new(execution_results, vec![]))
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L256-276)
```rust
    fn execute_block_sharded<V: VMBlockExecutor>(
        partitioned_txns: PartitionedTransactions,
        state_view: Arc<CachedStateView>,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>> {
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        } else {
            Ok(V::execute_block_sharded(
                &SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        }
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L235-257)
```rust
                let _timer = GET_BLOCK_EXECUTION_OUTPUT_BY_EXECUTING.start_timer();
                fail_point!("executor::block_executor_execute_block", |_| {
                    Err(ExecutorError::from(anyhow::anyhow!(
                        "Injected error in block_executor_execute_block"
                    )))
                });

                DoGetExecutionOutput::by_transaction_execution(
                    &self.block_executor,
                    transactions,
                    auxiliary_info,
                    parent_output.result_state(),
                    state_view,
                    onchain_config.clone(),
                    TransactionSliceMetadata::block(parent_block_id, block_id),
                )?
            };

        let output = PartialStateComputeResult::new(execution_output);
        let _ = self
            .block_tree
            .add_block(parent_block_id, block_id, output)?;
        Ok(())
```
