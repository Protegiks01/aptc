# Audit Report

## Title
Orphaned Transaction Summaries Due to Inconsistent Pruning Logic

## Summary
The `prune_transaction_summaries_by_account()` function fails to properly clean up transaction summaries when the corresponding transaction is missing from the main transaction store. This creates permanently orphaned summaries that waste storage space and cause data inconsistencies.

## Finding Description

The pruning logic in `TransactionPruner` has a fundamental architectural flaw that can leave orphaned transaction summaries in the database. This breaks the **State Consistency** invariant.

The vulnerability lies in the mismatch between how transactions and their summaries are pruned: [1](#0-0) 

The pruning process works as follows:

1. `get_pruning_candidate_transactions(current_progress, target_version)` reads transactions from `TransactionSchema` to build a candidate list by iterating through the database: [2](#0-1) 

2. `prune_transactions(current_progress, target_version)` deletes transactions by **version range**: [3](#0-2) 

3. `prune_transaction_summaries_by_account(&candidate_transactions)` deletes summaries **only for transactions found** in the candidate list: [4](#0-3) 

**The Critical Flaw:**

If a transaction at version V is missing from `TransactionSchema` (due to corruption, selective deletion, or any database inconsistency), but its summary still exists in `TransactionSummariesByAccountSchema`:

- The iterator in `get_pruning_candidate_transactions()` will skip over the missing entry (it simply won't return it)
- `prune_transactions()` will attempt to delete version V from `TransactionSchema` (no-op since it's already gone)
- `prune_transaction_summaries_by_account()` will **NOT** delete the summary for version V because it wasn't in the candidate list
- Result: **Permanently orphaned summary** at version V

Once a version range is pruned, subsequent pruning operations will not revisit that range, so the orphaned summary remains forever.

While the write path is atomic (both schemas are written in the same batch), database corruption, hardware failures, or bugs in other code paths could create this inconsistency: [5](#0-4) 

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty program criteria: "State inconsistencies requiring intervention."

**Specific impacts:**

1. **Storage Space Waste**: Orphaned summaries accumulate over time, consuming disk space without serving any purpose
2. **Data Inconsistency**: The `TransactionSummariesByAccountSchema` indexes transactions by `(AccountAddress, Version)` for efficient account history queries. Orphaned summaries reference non-existent transactions: [6](#0-5) 

3. **API Confusion**: Client applications querying account transaction history may receive references to transactions that don't exist, causing errors or incorrect behavior
4. **Potential DoS**: If the inconsistency can be reliably triggered, an attacker could fill storage with orphaned entries
5. **No Self-Healing**: The system has no mechanism to detect or correct this inconsistency. There is no validation that checks `TransactionSummariesByAccountSchema` against `TransactionSchema`: [7](#0-6) 

Note that the validation only checks `OrderedTransactionByAccountSchema`, not `TransactionSummariesByAccountSchema`.

## Likelihood Explanation

**Likelihood: Low to Medium**

Under normal operation with a healthy database, the write path is atomic and both schemas stay synchronized. However, this vulnerability can be triggered by:

1. **Database Corruption**: RocksDB corruption affecting `TransactionSchema` but not `TransactionSummariesByAccountSchema` (or vice versa due to different column families)
2. **Hardware Failures**: Disk failures or power loss causing partial writes
3. **Backup/Restore Issues**: Inconsistent restoration of different column families
4. **Bugs in Other Code Paths**: Any code that modifies these schemas outside the normal flow could introduce inconsistency
5. **Manual Database Operations**: Administrator actions that affect one schema but not the other

Once the inconsistency exists, it becomes **permanent** because the pruning logic cannot correct it.

## Recommendation

**Fix the pruning logic to use version ranges consistently for both schemas:**

```rust
pub fn prune_transaction_summaries_by_account(
    &self,
    start_version: Version,
    end_version: Version,
    db_batch: &mut SchemaBatch,
) -> Result<()> {
    // Iterate through all transaction summaries in the version range
    let mut iter = self
        .ledger_db
        .transaction_db_raw()
        .iter::<TransactionSummariesByAccountSchema>()?;
    
    // Seek to start of range
    iter.seek(&(AccountAddress::ZERO, start_version))?;
    
    for item in iter {
        let ((address, version), _summary) = item?;
        // Stop if we've reached the end of the range
        if version >= end_version {
            break;
        }
        // Delete the summary entry
        db_batch.delete::<TransactionSummariesByAccountSchema>(&(address, version))?;
    }
    
    Ok(())
}
```

Then update the caller to pass version ranges instead of transaction lists:

```rust
// In TransactionPruner::prune()
self.transaction_store
    .prune_transaction_summaries_by_account(current_progress, target_version, &mut batch)?;
```

This ensures that **all** summaries in the version range are deleted, regardless of whether the corresponding transaction exists in `TransactionSchema`.

**Additionally, add validation:**

Add a consistency check in the `db_debugger` validation module to detect orphaned summaries and alert operators.

## Proof of Concept

```rust
#[cfg(test)]
mod test_orphaned_summaries {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_types::transaction::Transaction;
    use aptos_schemadb::SchemaBatch;
    
    #[test]
    fn test_orphaned_summary_not_cleaned() {
        // Setup: Create a database with transactions 0-99
        let tmp_dir = TempPath::new();
        let db = AptosDB::new_for_test(&tmp_dir);
        
        // Commit transactions 0-99 (both TransactionSchema and TransactionSummariesByAccountSchema)
        // ... initialization code ...
        
        // Simulate corruption: manually delete transaction 50 from TransactionSchema
        // but leave its summary in TransactionSummariesByAccountSchema
        let mut batch = SchemaBatch::new();
        batch.delete::<TransactionSchema>(&50).unwrap();
        db.ledger_db.transaction_db().write_schemas(batch).unwrap();
        
        // Now verify transaction 50 is missing from TransactionSchema
        assert!(db.ledger_db.transaction_db().get_transaction(50).unwrap().is_none());
        
        // But summary for version 50 still exists in TransactionSummariesByAccountSchema
        let summary = db.transaction_store.get_account_transaction_summaries_iter(
            test_account_address,
            Some(50),
            Some(51),
            1,
            100
        ).unwrap().next();
        assert!(summary.is_some()); // Summary still exists!
        
        // Now run pruning for versions 0-60
        let pruner = TransactionPruner::new(
            Arc::clone(&db.transaction_store),
            Arc::clone(&db.ledger_db),
            0,
            None
        ).unwrap();
        
        pruner.prune(0, 60).unwrap();
        
        // Verify: Transaction 50 is pruned from TransactionSchema (was already gone)
        assert!(db.ledger_db.transaction_db().get_transaction(50).unwrap().is_none());
        
        // BUG: Summary for version 50 is NOT pruned - it's orphaned!
        let summary = db.transaction_store.get_account_transaction_summaries_iter(
            test_account_address,
            Some(50),
            Some(51),
            1,
            100
        ).unwrap().next();
        
        // This assertion SHOULD pass (summary should be deleted) but WILL FAIL (summary still exists)
        assert!(summary.is_none(), "Orphaned summary was not cleaned up!");
    }
}
```

## Notes

The vulnerability demonstrates a fundamental design issue: using **transaction-based deletion** for summaries while using **range-based deletion** for transactions creates an unavoidable consistency gap when the database is already inconsistent. The fix must ensure both schemas use the same deletion strategy (range-based) to maintain consistency even in the presence of pre-existing corruption.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-74)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
        self.ledger_db.transaction_db().prune_transactions(
            current_progress,
            target_version,
            &mut batch,
        )?;
        self.transaction_store
            .prune_transaction_summaries_by_account(&candidate_transactions, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L106-131)
```rust
    fn get_pruning_candidate_transactions(
        &self,
        start: Version,
        end: Version,
    ) -> Result<Vec<(Version, Transaction)>> {
        ensure!(end >= start, "{} must be >= {}", end, start);

        let mut iter = self
            .ledger_db
            .transaction_db_raw()
            .iter::<TransactionSchema>()?;
        iter.seek(&start)?;

        // The capacity is capped by the max number of txns we prune in a single batch. It's a
        // relatively small number set in the config, so it won't cause high memory usage here.
        let mut txns = Vec::with_capacity((end - start) as usize);
        for item in iter {
            let (version, txn) = item?;
            if version >= end {
                break;
            }
            txns.push((version, txn));
        }

        Ok(txns)
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L150-166)
```rust
        if let Some(signed_txn) = transaction.try_as_signed_user_txn() {
            let txn_summary = IndexedTransactionSummary::V1 {
                sender: signed_txn.sender(),
                replay_protector: signed_txn.replay_protector(),
                version,
                transaction_hash,
            };
            batch.put::<TransactionSummariesByAccountSchema>(
                &(signed_txn.sender(), version),
                &txn_summary,
            )?;
        }
        batch.put::<TransactionByHashSchema>(&transaction_hash, &version)?;
        batch.put::<TransactionSchema>(&version, transaction)?;

        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L168-179)
```rust
    /// Deletes transaction data given version range [begin, end).
    pub(crate) fn prune_transactions(
        &self,
        begin: Version,
        end: Version,
        db_batch: &mut SchemaBatch,
    ) -> Result<()> {
        for version in begin..end {
            db_batch.delete::<TransactionSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/transaction_store/mod.rs (L159-171)
```rust
    pub fn prune_transaction_summaries_by_account(
        &self,
        transactions: &[(Version, Transaction)],
        db_batch: &mut SchemaBatch,
    ) -> Result<()> {
        for (version, transaction) in transactions {
            if let Some(txn) = transaction.try_as_signed_user_txn() {
                db_batch
                    .delete::<TransactionSummariesByAccountSchema>(&(txn.sender(), *version))?;
            }
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/schema/transaction_summaries_by_account/mod.rs (L1-33)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! This module defines physical storage schema for a transaction index via which the version of a
//! transaction sent by `account_address` with `sequence_number` can be found. With the version one
//! can resort to `TransactionSchema` for the transaction content.
//!
//! ```text
//! |<-------key------->|<---value--->|
//! | address | version | txn_summary |
//! ```

use crate::schema::{ensure_slice_len_eq, TRANSACTION_SUMMARIES_BY_ACCOUNT_CF_NAME};
use anyhow::Result;
use aptos_schemadb::{
    define_pub_schema,
    schema::{KeyCodec, ValueCodec},
};
use aptos_types::{
    account_address::AccountAddress,
    transaction::{IndexedTransactionSummary, Version},
};
use byteorder::{BigEndian, ReadBytesExt, WriteBytesExt};
use std::{convert::TryFrom, mem::size_of};

define_pub_schema!(
    TransactionSummariesByAccountSchema,
    Key,
    IndexedTransactionSummary,
    TRANSACTION_SUMMARIES_BY_ACCOUNT_CF_NAME
);

type Key = (AccountAddress, Version);
```

**File:** storage/aptosdb/src/db_debugger/validation.rs (L193-226)
```rust
fn verify_transactions(
    transaction_list: &TransactionListWithProofV2,
    internal_indexer_db: &DB,
    start_version: u64,
) -> Result<()> {
    for (idx, txn) in transaction_list
        .get_transaction_list_with_proof()
        .transactions
        .iter()
        .enumerate()
    {
        match txn {
            UserTransaction(signed_transaction) => {
                let key = (
                    signed_transaction.sender(),
                    signed_transaction.sequence_number(),
                );
                match internal_indexer_db.get::<OrderedTransactionByAccountSchema>(&key)? {
                    Some(version) => {
                        assert_eq!(version, start_version + idx as u64);
                        if idx + start_version as usize % SAMPLE_RATE == 0 {
                            println!("Processed {} at {:?}", idx + start_version as usize, key);
                        }
                    },
                    None => {
                        panic!("Transaction not found in internal indexer db: {:?}", key);
                    },
                }
            },
            _ => continue,
        }
    }
    Ok(())
}
```
