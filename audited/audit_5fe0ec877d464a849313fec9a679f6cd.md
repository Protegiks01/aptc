# Audit Report

## Title
Storage Service Request Replay Causes Resource Exhaustion via Missing In-Flight Request Deduplication

## Summary
The storage service server lacks in-flight request deduplication, allowing identical `StorageServiceRequest` messages to be processed concurrently. This enables an attacker to exhaust node resources by sending multiple copies of expensive requests before the first completes, bypassing the LRU cache and causing redundant database operations.

## Finding Description

The storage service server processes incoming requests without tracking in-flight operations. When a `StorageServiceRequest` arrives, the server immediately spawns a blocking task to handle it, regardless of whether identical requests are already being processed. [1](#0-0) 

Each request creates a new `Handler` and calls `process_request_and_respond()`, which validates the request and fetches data from storage. [2](#0-1) 

The LRU cache in `process_cachable_request()` only helps if a response is already cached. If multiple identical requests arrive before the first completes, all will miss the cache and hit the database concurrently. [3](#0-2) 

The `StorageServiceRequest` structure contains no unique request ID or nonce for deduplication: [4](#0-3) 

The `RequestModerator` only tracks invalid requests per peer, not concurrent valid requests: [5](#0-4) 

In contrast, other components implement proper in-flight deduplication. For example, `BatchReaderImpl` uses a HashMap to track in-flight batch fetches: [6](#0-5) 

**Attack Scenario:**
1. Attacker identifies an expensive request (e.g., `GetTransactionsWithProof` for 3000 transactions)
2. Attacker sends 50+ identical requests concurrently from one or multiple peers
3. All requests spawn blocking tasks before the first completes
4. All tasks miss the LRU cache (since first hasn't finished)
5. All tasks concurrently query the database, causing resource exhaustion
6. Node experiences CPU/memory/database connection saturation

## Impact Explanation

This vulnerability enables **validator node slowdowns** (High Severity per Aptos bug bounty). An attacker can:

- Exhaust CPU resources through redundant blocking task execution
- Saturate database connections with duplicate queries
- Consume memory storing duplicate intermediate results
- Degrade node responsiveness to legitimate requests

While tokio's `max_blocking_threads` limit (64) provides some protection, an attacker can still queue unlimited requests, and 64 concurrent expensive database operations can significantly degrade node performance.

The impact is **Medium Severity** as it causes resource waste requiring operator intervention but does not directly compromise consensus safety or cause fund loss. However, sustained attacks could impact validator availability and sync performance.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is easily exploitable:
- No special privileges required (any network peer can send requests)
- No cryptographic operations needed
- Attack can be automated with simple network client
- Expensive requests are well-defined (large transaction ranges)
- No rate limiting on valid concurrent requests per peer

The only mitigations are:
- Network-level peer management (which may not detect identical requests from different peers)
- Eventual cache population (but attacker can vary requests slightly to bypass)

## Recommendation

Implement in-flight request deduplication similar to `BatchReaderImpl`. Add a `DashMap<StorageServiceRequest, Shared<Future>>` to track active requests:

```rust
// In StorageServiceServer
inflight_requests: Arc<DashMap<StorageServiceRequest, Shared<Pin<Box<dyn Future<Output = StorageServiceResponse> + Send>>>>>,

// In request handling
fn get_or_process_request(&self, request: StorageServiceRequest) -> Shared<Future<StorageServiceResponse>> {
    self.inflight_requests
        .entry(request.clone())
        .or_insert_with(|| {
            let inflight_clone = self.inflight_requests.clone();
            let request_clone = request.clone();
            
            let fut = async move {
                defer!({
                    inflight_clone.remove(&request_clone);
                });
                // Process request...
            };
            fut.boxed().shared()
        })
        .value()
        .clone()
}
```

Additional hardening:
1. Add per-peer concurrent request limit in `StorageServiceConfig`
2. Track request processing metrics to detect replay attacks
3. Consider request nonces for subscription streams

## Proof of Concept

```rust
#[tokio::test]
async fn test_concurrent_duplicate_requests_cause_resource_waste() {
    use aptos_storage_service_types::requests::*;
    use std::sync::atomic::{AtomicU64, Ordering};
    
    // Setup storage service server
    let (mut mock_client, mut service, _) = MockClient::new(None);
    tokio::spawn(service.start());
    
    // Create expensive request
    let request = StorageServiceRequest::new(
        DataRequest::GetTransactionsWithProof(TransactionsWithProofRequest {
            proof_version: 5000,
            start_version: 1,
            end_version: 3000,  // Large range
            include_events: true,
        }),
        false,
    );
    
    // Track database calls
    let db_call_count = Arc::new(AtomicU64::new(0));
    let db_count_clone = db_call_count.clone();
    
    // Mock storage to count concurrent calls
    mock_db.expect_get_transactions_with_proof()
        .returning(move |_, _, _, _| {
            db_count_clone.fetch_add(1, Ordering::SeqCst);
            std::thread::sleep(Duration::from_millis(100)); // Simulate expensive operation
            Ok(/* ... */)
        });
    
    // Send 50 identical requests concurrently
    let mut handles = vec![];
    for _ in 0..50 {
        let request_clone = request.clone();
        let client_clone = mock_client.clone();
        handles.push(tokio::spawn(async move {
            client_clone.process_request(request_clone).await
        }));
    }
    
    // Wait for all
    for handle in handles {
        handle.await.unwrap();
    }
    
    // Verify: Without deduplication, database is called 50 times
    // With proper deduplication, it should be called only once
    let final_count = db_call_count.load(Ordering::SeqCst);
    assert!(final_count > 1, "Expected multiple DB calls due to missing deduplication, got {}", final_count);
    // In a fixed implementation: assert_eq!(final_count, 1);
}
```

**Notes**

This vulnerability breaks the **Resource Limits** invariant (invariant #9) by allowing unbounded concurrent processing of identical requests. The attack is amplified because storage operations are expensive (database I/O, proof generation, serialization). While individual requests may be valid, the lack of deduplication transforms legitimate functionality into a resource exhaustion vector.

### Citations

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/server/src/handler.rs (L82-139)
```rust
    pub fn process_request_and_respond(
        &self,
        storage_service_config: StorageServiceConfig,
        peer_network_id: PeerNetworkId,
        protocol_id: ProtocolId,
        request: StorageServiceRequest,
        response_sender: ResponseSender,
    ) {
        // Log the request
        trace!(LogSchema::new(LogEntry::ReceivedStorageRequest)
            .request(&request)
            .message(&format!(
                "Received storage request. Peer: {:?}, protocol: {:?}.",
                peer_network_id, protocol_id,
            )));

        // Update the request count
        increment_counter(
            &metrics::STORAGE_REQUESTS_RECEIVED,
            peer_network_id.network_id(),
            request.get_label(),
        );

        // If the request is for transaction v2 data, only process it
        // if the server supports it. Otherwise, drop the request.
        if request.data_request.is_transaction_data_v2_request()
            && !storage_service_config.enable_transaction_data_v2
        {
            warn!(LogSchema::new(LogEntry::StorageServiceError)
                .error(&Error::InvalidRequest(format!(
                    "Received a v2 data request ({}), which is not supported!",
                    request.get_label()
                )))
                .peer_network_id(&peer_network_id));
            return;
        }

        // Handle any optimistic fetch requests
        if request.data_request.is_optimistic_fetch() {
            self.handle_optimistic_fetch_request(peer_network_id, request, response_sender);
            return;
        }

        // Handle any subscription requests
        if request.data_request.is_subscription_request() {
            self.handle_subscription_request(
                storage_service_config,
                peer_network_id,
                request,
                response_sender,
            );
            return;
        }

        // Process the request and return the response to the client
        let response = self.process_request(&peer_network_id, request.clone(), false);
        self.send_response(request, response, response_sender);
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L384-461)
```rust
    fn process_cachable_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> aptos_storage_service_types::Result<StorageServiceResponse, Error> {
        // Increment the LRU cache probe counter
        increment_counter(
            &metrics::LRU_CACHE_EVENT,
            peer_network_id.network_id(),
            LRU_CACHE_PROBE.into(),
        );

        // Check if the response is already in the cache
        if let Some(response) = self.lru_response_cache.get(request) {
            increment_counter(
                &metrics::LRU_CACHE_EVENT,
                peer_network_id.network_id(),
                LRU_CACHE_HIT.into(),
            );
            return Ok(response.clone());
        }

        // Otherwise, fetch the data from storage and time the operation
        let fetch_data_response = || match &request.data_request {
            DataRequest::GetStateValuesWithProof(request) => {
                self.get_state_value_chunk_with_proof(request)
            },
            DataRequest::GetEpochEndingLedgerInfos(request) => {
                self.get_epoch_ending_ledger_infos(request)
            },
            DataRequest::GetNumberOfStatesAtVersion(version) => {
                self.get_number_of_states_at_version(*version)
            },
            DataRequest::GetTransactionOutputsWithProof(request) => {
                self.get_transaction_outputs_with_proof(request)
            },
            DataRequest::GetTransactionsWithProof(request) => {
                self.get_transactions_with_proof(request)
            },
            DataRequest::GetTransactionsOrOutputsWithProof(request) => {
                self.get_transactions_or_outputs_with_proof(request)
            },
            DataRequest::GetTransactionDataWithProof(request) => {
                self.get_transaction_data_with_proof(request)
            },
            _ => Err(Error::UnexpectedErrorEncountered(format!(
                "Received an unexpected request: {:?}",
                request
            ))),
        };
        let data_response = utils::execute_and_time_duration(
            &metrics::STORAGE_FETCH_PROCESSING_LATENCY,
            Some((peer_network_id, request)),
            None,
            fetch_data_response,
            None,
        )?;

        // Create the storage response and time the operation
        let create_storage_response = || {
            StorageServiceResponse::new(data_response, request.use_compression)
                .map_err(|error| error.into())
        };
        let storage_response = utils::execute_and_time_duration(
            &metrics::STORAGE_RESPONSE_CREATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            create_storage_response,
            None,
        )?;

        // Create and cache the storage response
        self.lru_response_cache
            .insert(request.clone(), storage_response.clone());

        // Return the storage response
        Ok(storage_response)
    }
```

**File:** state-sync/storage-service/types/src/requests.rs (L8-31)
```rust
/// A storage service request.
#[derive(Clone, Debug, Deserialize, Eq, Hash, PartialEq, Serialize)]
pub struct StorageServiceRequest {
    pub data_request: DataRequest, // The data to fetch from the storage service
    pub use_compression: bool,     // Whether or not the client wishes data to be compressed
}

impl StorageServiceRequest {
    pub fn new(data_request: DataRequest, use_compression: bool) -> Self {
        Self {
            data_request,
            use_compression,
        }
    }

    /// Returns a summary label for the request
    pub fn get_label(&self) -> String {
        let mut label = self.data_request.get_label().to_string();
        if self.use_compression {
            label += COMPRESSION_SUFFIX_LABEL;
        }
        label
    }
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L132-196)
```rust
    /// Validates the given request and verifies that the peer is behaving
    /// correctly. If the request fails validation, an error is returned.
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L648-688)
```rust
pub struct BatchReaderImpl<T> {
    batch_store: Arc<BatchStore>,
    batch_requester: Arc<BatchRequester<T>>,
    inflight_fetch_requests: Arc<Mutex<HashMap<HashValue, BatchFetchUnit>>>,
}

impl<T: QuorumStoreSender + Clone + Send + Sync + 'static> BatchReaderImpl<T> {
    pub(crate) fn new(batch_store: Arc<BatchStore>, batch_requester: BatchRequester<T>) -> Self {
        Self {
            batch_store,
            batch_requester: Arc::new(batch_requester),
            inflight_fetch_requests: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    fn get_or_fetch_batch(
        &self,
        batch_info: BatchInfo,
        responders: Vec<PeerId>,
    ) -> Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>> {
        let mut responders = responders.into_iter().collect();

        self.inflight_fetch_requests
            .lock()
            .entry(*batch_info.digest())
            .and_modify(|fetch_unit| {
                fetch_unit.responders.lock().append(&mut responders);
            })
            .or_insert_with(|| {
                let responders = Arc::new(Mutex::new(responders));
                let responders_clone = responders.clone();

                let inflight_requests_clone = self.inflight_fetch_requests.clone();
                let batch_store = self.batch_store.clone();
                let requester = self.batch_requester.clone();

                let fut = async move {
                    let batch_digest = *batch_info.digest();
                    defer!({
                        inflight_requests_clone.lock().remove(&batch_digest);
                    });
```
