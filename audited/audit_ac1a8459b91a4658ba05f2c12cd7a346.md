# Audit Report

## Title
Unbounded Block Storage During Fast-Forward Sync Leading to Disk Exhaustion

## Summary
The `save_blocks_and_quorum_certificates()` function in ConsensusDB has no upper limit on the number of blocks/QCs it accepts. When combined with fast-forward sync in configurations with `window_size = None` (the default), a validator node can fetch and store an unbounded number of blocks based solely on round differences, potentially causing disk exhaustion before pruning occurs.

## Finding Description

The vulnerability exists in the consensus synchronization mechanism when a validator node needs to catch up after being offline. The critical flaw is in the `fast_forward_sync()` function where the number of blocks to fetch is calculated without any upper bound: [1](#0-0) 

When `window_size = None` (which is the default production configuration), the calculation becomes: [2](#0-1) 

This means `num_blocks = highest_quorum_cert.certified_block().round() - highest_commit_cert.ledger_info().ledger_info().round() + 1`, which could be millions if the node has been offline for an extended period.

All fetched blocks are then saved to persistent storage without any limit validation: [3](#0-2) 

The underlying `save_blocks_and_quorum_certificates()` function imposes no restrictions on the vector sizes: [4](#0-3) 

While blocks are eventually pruned during recovery, the pruning happens AFTER all blocks have been written to disk, creating a critical window where disk exhaustion can occur.

**Breaking Invariant #9 (Resource Limits)**: The system fails to enforce storage limits on consensus database operations, allowing unbounded disk writes.

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria:
- **Validator node slowdowns/crashes**: A validator that has been offline during high network activity (millions of rounds) will experience severe disk I/O saturation or complete disk exhaustion when attempting to sync
- **Denial of Service**: The node becomes unavailable during the sync period or crashes if disk space is exhausted
- **Network Liveness Impact**: Multiple validators experiencing this issue simultaneously could affect consensus liveness

The impact is amplified because:
1. Disk exhaustion occurs before pruning can clean up unnecessary blocks
2. The only assertion is that `num_blocks < usize::MAX`, which provides no practical protection on 64-bit systems
3. No rate limiting or chunked cleanup exists during the sync process

## Likelihood Explanation

**High Likelihood** in production scenarios:
1. Aptos mainnet runs continuously with high throughput (thousands of rounds per hour)
2. A validator offline for just 24 hours during peak activity could face millions of rounds difference
3. Network partitions, hardware failures, or maintenance windows commonly cause extended offline periods
4. The default `window_size = None` configuration means this affects all nodes not explicitly configured otherwise

The attack surface doesn't require malicious actors—it's triggered by legitimate operational scenarios.

## Recommendation

Implement strict upper bounds on block fetching and use chunked sync-and-prune:

```rust
pub async fn fast_forward_sync<'a>(
    highest_quorum_cert: &'a QuorumCert,
    highest_commit_cert: &'a WrappedLedgerInfo,
    // ... other params
) -> anyhow::Result<RecoveryData> {
    const MAX_BLOCKS_PER_SYNC_BATCH: u64 = 10_000; // Reasonable upper limit
    const MAX_TOTAL_SYNC_BLOCKS: u64 = 100_000;    // Safety limit
    
    let (target_block_retrieval_payload, num_blocks) =
        Self::generate_target_block_retrieval_payload_and_num_blocks(
            highest_quorum_cert,
            highest_commit_cert,
            window_size,
        );
    
    // Enforce upper bound
    ensure!(
        num_blocks <= MAX_TOTAL_SYNC_BLOCKS,
        "Sync gap too large: {} blocks exceeds maximum {}. Consider state sync instead.",
        num_blocks,
        MAX_TOTAL_SYNC_BLOCKS
    );
    
    // Fetch and prune in chunks to prevent disk exhaustion
    let mut current_round = highest_commit_cert.ledger_info().ledger_info().round();
    while current_round < highest_quorum_cert.certified_block().round() {
        let batch_size = min(MAX_BLOCKS_PER_SYNC_BATCH, 
                            highest_quorum_cert.certified_block().round() - current_round);
        
        // Fetch batch
        let blocks = retriever.retrieve_blocks_in_range(/* ... */).await?;
        
        // Save batch
        storage.save_tree(blocks.clone(), quorum_certs.clone())?;
        
        // Immediately prune old blocks from this batch
        let recovery_data = storage.start(order_vote_enabled, window_size);
        storage.prune_tree(recovery_data.take_blocks_to_prune())?;
        
        current_round += batch_size;
    }
    // ... rest of sync logic
}
```

Additionally, add validation in `save_blocks_and_quorum_certificates()`:

```rust
pub fn save_blocks_and_quorum_certificates(
    &self,
    block_data: Vec<Block>,
    qc_data: Vec<QuorumCert>,
) -> Result<(), DbError> {
    const MAX_BLOCKS_PER_SAVE: usize = 10_000;
    
    ensure!(
        block_data.len() <= MAX_BLOCKS_PER_SAVE,
        "Attempting to save {} blocks exceeds limit of {}",
        block_data.len(),
        MAX_BLOCKS_PER_SAVE
    );
    
    if block_data.is_empty() && qc_data.is_empty() {
        return Err(anyhow::anyhow!("Consensus block and qc data is empty!").into());
    }
    // ... rest of function
}
```

## Proof of Concept

```rust
// Scenario: Validator offline during 1M rounds of network operation
// Network parameters:
// - Rounds per second: ~3 (typical Aptos throughput)
// - Offline duration: ~4 days (1,000,000 rounds ÷ 3 ÷ 86,400)
// - Block size: ~50KB average
// - Total disk usage spike: 50KB × 1,000,000 = ~50GB before pruning

#[tokio::test]
async fn test_unbounded_sync_disk_exhaustion() {
    // Setup: Create QCs with large round gap
    let committed_round = 0;
    let current_round = 1_000_000;
    
    let highest_commit_cert = create_mock_ledger_info(committed_round);
    let highest_quorum_cert = create_mock_quorum_cert(current_round);
    
    // Calculate blocks to fetch (current implementation)
    let num_blocks = current_round - committed_round + 1;
    assert_eq!(num_blocks, 1_000_001); // No upper limit!
    
    // This would attempt to save 1M+ blocks at once
    // Expected: Disk exhaustion before pruning completes
    // Actual: No validation or limit enforced
}
```

**Notes**

The vulnerability is exacerbated by the silent failure handling in pruning operations: [5](#0-4) 

If disk space is exhausted during the initial save, the pruning operation will fail, and the error is only logged as a warning. The node then relies on restart cleanup, but if disk is full, restart will also fail, creating a recovery deadlock.

### Citations

**File:** consensus/src/block_storage/sync_manager.rs (L334-347)
```rust
        match window_size {
            None => {
                let num_blocks = highest_quorum_cert.certified_block().round()
                    - highest_commit_cert.ledger_info().ledger_info().round()
                    + 1;
                let target_block_id = highest_commit_cert.commit_info().id();
                info!(
                    "[FastForwardSync] with window_size: None, target_block_id: {}, num_blocks: {}",
                    target_block_id, num_blocks
                );
                (
                    TargetBlockRetrieval::TargetBlockId(target_block_id),
                    num_blocks,
                )
```

**File:** consensus/src/block_storage/sync_manager.rs (L503-503)
```rust
        storage.save_tree(blocks.clone(), quorum_certs.clone())?;
```

**File:** types/src/on_chain_config/consensus_config.rs (L10-13)
```rust
/// Default Window Size for Execution Pool.
/// This describes the number of blocks in the Execution Pool Window
pub const DEFAULT_WINDOW_SIZE: Option<u64> = None;
pub const DEFAULT_ENABLED_WINDOW_SIZE: Option<u64> = Some(1);
```

**File:** consensus/src/consensusdb/mod.rs (L121-137)
```rust
    pub fn save_blocks_and_quorum_certificates(
        &self,
        block_data: Vec<Block>,
        qc_data: Vec<QuorumCert>,
    ) -> Result<(), DbError> {
        if block_data.is_empty() && qc_data.is_empty() {
            return Err(anyhow::anyhow!("Consensus block and qc data is empty!").into());
        }
        let mut batch = SchemaBatch::new();
        block_data
            .iter()
            .try_for_each(|block| batch.put::<BlockSchema>(&block.id(), block))?;
        qc_data
            .iter()
            .try_for_each(|qc| batch.put::<QCSchema>(&qc.certified_block().id(), qc))?;
        self.commit(batch)
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L591-596)
```rust
        if let Err(e) = storage.prune_tree(ids_to_remove.clone().into_iter().collect()) {
            // it's fine to fail here, as long as the commit succeeds, the next restart will clean
            // up dangling blocks, and we need to prune the tree to keep the root consistent with
            // executor.
            warn!(error = ?e, "fail to delete block");
        }
```
