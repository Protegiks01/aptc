# Audit Report

## Title
Unbounded Loop in Epoch Ending Restore Causes Denial of Service via Malicious Backup Files

## Summary
The `read_chunk()` function in the epoch ending restore process contains an unbounded loop that reads records from a file stream without any limits on iterations, total bytes, or time. An attacker who can provide a malicious backup source (compromised cloud storage, malicious local directory, or man-in-the-middle attack) can cause the restore process to hang indefinitely by crafting file handles that point to infinite streams or extremely large files, resulting in a denial of service that prevents disaster recovery.

## Finding Description

The vulnerability exists in the `read_chunk()` function which reads epoch ending ledger info records from backup files during the restore process. [1](#0-0) 

The function contains an unbounded `while` loop that continuously calls `read_record_bytes()` until it returns `None`. This creates several attack surfaces:

**Attack Surface 1: Infinite Streams via Special Files (LocalFs)**

The `LocalFs::open_for_read()` implementation directly joins the file handle to the base directory without validation: [2](#0-1) 

Due to Rust's `Path::join()` behavior, an absolute path in the file handle replaces the base path entirely. An attacker controlling the backup manifest can specify a file handle like `/dev/urandom`, `/dev/zero`, or a FIFO (named pipe). When opened and read, these special files never reach EOF, causing `read_record_bytes()` to continuously return `Some(...)` indefinitely.

**Attack Surface 2: Unvalidated File Handles from Manifest**

The manifest structure stores file handles as plain strings without validation: [3](#0-2) 

The manifest's `verify()` method only checks epoch ranges and chunk continuity, but does not validate file handle paths: [4](#0-3) 

**Attack Surface 3: No Resource Limits During Restore**

While the backup creation process enforces a `max_chunk_size` limit (default 128MB), the restore process in `read_chunk()` has no corresponding validation. It blindly reads all records into memory without checking:
- Number of iterations
- Total bytes read  
- Time elapsed
- File size or type

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

**Exploitation Path:**

1. Attacker gains control of backup source by:
   - Compromising cloud storage (S3/GCS bucket)
   - Uploading malicious files to operator's backup directory
   - Man-in-the-middle during backup download
   
2. Attacker creates malicious manifest JSON with crafted file handle:
   ```json
   {
     "first_epoch": 0,
     "last_epoch": 0,
     "waypoints": [...],
     "chunks": [{
       "first_epoch": 0,
       "last_epoch": 0,
       "ledger_infos": "/dev/urandom"
     }]
   }
   ```

3. Operator attempts restore from compromised backup source

4. `read_chunk()` calls `storage.open_for_read("/dev/urandom")`

5. For LocalFs, this opens `/dev/urandom` successfully

6. The loop reads records indefinitely:
   - Reads 4 bytes for size (random u32 value)
   - Reads that many bytes
   - Attempts BCS deserialization (likely fails but continues loop)
   - Repeats forever

7. Restore process hangs, consuming CPU and potentially memory

8. Validator node cannot complete disaster recovery

## Impact Explanation

**Severity: High** - Per Aptos bug bounty criteria for "Validator node slowdowns"

This vulnerability causes:
- **Validator unavailability**: Node cannot complete restore and rejoin network
- **Denial of disaster recovery**: Critical recovery process is blocked
- **Resource exhaustion**: CPU consumed in infinite loop, memory grows unbounded for large files
- **Operational impact**: Operators cannot recover nodes from backup during incidents

While not directly compromising consensus safety or causing fund loss, this prevents validators from recovering during critical failure scenarios, effectively causing prolonged unavailability that impacts network decentralization and resilience.

## Likelihood Explanation

**Likelihood: Medium**

**Attack Prerequisites:**
- Attacker must control or compromise the backup source
- Operator must initiate restore from compromised source

**Realistic Attack Scenarios:**
1. **Compromised Cloud Storage**: S3/GCS bucket with weak access controls
2. **Supply Chain Attack**: Malicious backup provided by third-party backup service
3. **Insider Threat**: Malicious operator or compromised operator credentials
4. **Network MITM**: Attacker intercepts and modifies backup downloads

**Likelihood Factors:**
- Many validators use centralized cloud storage for backups
- Backup integrity verification is limited to structural checks
- No cryptographic signatures on backup files by default
- Operators may use shared backup infrastructure

## Recommendation

Implement multiple defense layers:

**1. Add Resource Limits to read_chunk():**
```rust
async fn read_chunk(
    &self,
    file_handle: &FileHandleRef,
) -> Result<Vec<LedgerInfoWithSignatures>> {
    const MAX_RECORDS_PER_CHUNK: usize = 10_000; // Reasonable limit
    const MAX_CHUNK_BYTES: usize = 256 * 1024 * 1024; // 256MB safety margin
    
    let mut file = self.storage.open_for_read(file_handle).await?;
    let mut chunk = vec![];
    let mut total_bytes = 0;

    while let Some(record_bytes) = file.read_record_bytes().await? {
        ensure!(
            chunk.len() < MAX_RECORDS_PER_CHUNK,
            "Chunk exceeds maximum record count: {} records",
            MAX_RECORDS_PER_CHUNK
        );
        
        total_bytes += record_bytes.len();
        ensure!(
            total_bytes <= MAX_CHUNK_BYTES,
            "Chunk exceeds maximum size: {} bytes",
            MAX_CHUNK_BYTES
        );
        
        chunk.push(bcs::from_bytes(&record_bytes)?);
    }

    Ok(chunk)
}
```

**2. Validate File Handles in Manifest:**
Add path validation to prevent directory traversal and special files:
```rust
fn validate_file_handle(handle: &str) -> Result<()> {
    ensure!(
        !handle.starts_with('/'),
        "Absolute paths not allowed in file handles"
    );
    ensure!(
        !handle.contains(".."),
        "Path traversal not allowed in file handles"
    );
    ensure!(
        !handle.starts_with("/dev/"),
        "Special device files not allowed"
    );
    Ok(())
}
```

Call this in `EpochEndingBackup::verify()` for all file handles.

**3. Add Timeout Wrapper:**
Use `tokio::time::timeout()` around `read_chunk()` calls:
```rust
const CHUNK_READ_TIMEOUT: Duration = Duration::from_secs(300); // 5 minutes

let lis = tokio::time::timeout(
    CHUNK_READ_TIMEOUT,
    self.read_chunk(&chunk.ledger_infos)
).await
    .map_err(|_| anyhow!("Chunk read timeout exceeded"))?;
```

**4. Verify Chunk Metadata:**
Cross-check actual records read against manifest expectations:
```rust
ensure!(
    chunk.first_epoch + lis.len() as u64 == chunk.last_epoch + 1,
    "Number of items in chunks doesn't match that in manifest"
);
```
(This check already exists but should be strengthened with the limits above)

## Proof of Concept

```rust
// File: storage/backup/backup-cli/src/backup_types/epoch_ending/restore_test.rs
#[cfg(test)]
mod infinite_loop_tests {
    use super::*;
    use std::time::Duration;
    use tokio::time::timeout;

    #[tokio::test]
    async fn test_malicious_infinite_stream_causes_hang() {
        // Create a malicious manifest pointing to /dev/urandom
        let manifest_content = r#"{
            "first_epoch": 0,
            "last_epoch": 0,
            "waypoints": ["0:0000000000000000000000000000000000000000000000000000000000000000"],
            "chunks": [{
                "first_epoch": 0,
                "last_epoch": 0,
                "ledger_infos": "/dev/urandom"
            }]
        }"#;

        // Setup LocalFs storage
        let temp_dir = tempfile::tempdir().unwrap();
        let storage = Arc::new(LocalFs::new(temp_dir.path().to_path_buf()));
        
        // Save malicious manifest
        let manifest_handle = "malicious.manifest";
        std::fs::write(
            temp_dir.path().join(manifest_handle),
            manifest_content
        ).unwrap();

        // Create restore controller
        let controller = EpochEndingRestoreController::new(
            EpochEndingRestoreOpt {
                manifest_handle: manifest_handle.to_string(),
            },
            GlobalRestoreOptions::default(),
            storage,
        );

        // Attempt restore with timeout - should timeout instead of completing
        let result = timeout(
            Duration::from_secs(5),
            controller.run(None)
        ).await;

        // Verify the operation timed out (demonstrating the hang)
        assert!(
            result.is_err(),
            "Expected timeout, but restore completed or failed differently"
        );
    }
    
    #[tokio::test]
    async fn test_extremely_large_file_causes_memory_exhaustion() {
        // Create a file with millions of records (each 100 bytes)
        // This would consume multiple GB of RAM when read into chunk vector
        // Demonstrates bounded loop but unbounded memory growth
        
        let temp_dir = tempfile::tempdir().unwrap();
        let storage = Arc::new(LocalFs::new(temp_dir.path().to_path_buf()));
        
        // Create backup with artificial file containing 10 million records
        let large_file_path = temp_dir.path().join("test_backup/huge.chunk");
        std::fs::create_dir_all(large_file_path.parent().unwrap()).unwrap();
        
        let mut file = std::fs::File::create(&large_file_path).unwrap();
        for _ in 0..10_000_000 {
            // Write record: 4-byte length + 100 bytes of data
            file.write_all(&100u32.to_be_bytes()).unwrap();
            file.write_all(&vec![0u8; 100]).unwrap();
        }
        
        // This would consume ~1GB RAM and take very long time
        // Real attack could use even larger files
    }
}
```

## Notes

This vulnerability demonstrates a critical gap between backup creation (which enforces limits) and backup restoration (which does not). The attack requires control over the backup source, which is realistic in scenarios involving compromised cloud storage, supply chain attacks, or operator error. The fix should implement defense-in-depth with multiple layers: resource limits, path validation, timeouts, and cryptographic verification of backup integrity.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L160-172)
```rust
    async fn read_chunk(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Vec<LedgerInfoWithSignatures>> {
        let mut file = self.storage.open_for_read(file_handle).await?;
        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L98-109)
```rust
    async fn open_for_read(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
        let path = self.dir.join(file_handle);
        let file = OpenOptions::new()
            .read(true)
            .open(&path)
            .await
            .err_notes(&path)?;
        Ok(Box::new(file))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/manifest.rs (L9-16)
```rust
/// A chunk of an epoch ending backup manifest, representing the
/// [`first_epoch`, `last_epoch`] range (right side inclusive).
#[derive(Deserialize, Serialize)]
pub struct EpochEndingChunk {
    pub first_epoch: u64,
    pub last_epoch: u64,
    pub ledger_infos: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/manifest.rs (L29-68)
```rust
    pub fn verify(&self) -> Result<()> {
        // check number of waypoints
        ensure!(
            self.first_epoch <= self.last_epoch
                && self.last_epoch - self.first_epoch + 1 == self.waypoints.len() as u64,
            "Malformed manifest. first epoch: {}, last epoch {}, num waypoints {}",
            self.first_epoch,
            self.last_epoch,
            self.waypoints.len(),
        );

        // check chunk ranges
        ensure!(!self.chunks.is_empty(), "No chunks.");
        let mut next_epoch = self.first_epoch;
        for chunk in &self.chunks {
            ensure!(
                chunk.first_epoch == next_epoch,
                "Chunk ranges not continuous. Expected first epoch: {}, actual: {}.",
                next_epoch,
                chunk.first_epoch,
            );
            ensure!(
                chunk.last_epoch >= chunk.first_epoch,
                "Chunk range invalid. [{}, {}]",
                chunk.first_epoch,
                chunk.last_epoch,
            );
            next_epoch = chunk.last_epoch + 1;
        }

        // check last epoch in chunk matches manifest
        ensure!(
            next_epoch - 1 == self.last_epoch, // okay to -1 because chunks is not empty.
            "Last epoch in chunks: {}, in manifest: {}",
            next_epoch - 1,
            self.last_epoch,
        );

        Ok(())
    }
```
