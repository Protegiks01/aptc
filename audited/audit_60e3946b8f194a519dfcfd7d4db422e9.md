# Audit Report

## Title
State Sync Stream Corruption via Premature Flag Reset in Epoch Ending Response Handling

## Summary
A malicious peer can cause state synchronization denial-of-service by sending invalid epoch ending ledger info responses (zero or multiple ledger infos instead of exactly one). The stream engine prematurely resets the `end_of_epoch_requested` flag before validating the response, and fails to notify the data client about the bad peer, allowing repeated exploitation that blocks nodes from syncing across epoch boundaries.

## Finding Description

The vulnerability exists in the epoch ending response handling logic within the `ContinuousTransactionStreamEngine`. When a node needs to sync across an epoch boundary, it requests an epoch ending ledger info and sets `end_of_epoch_requested = true`. [1](#0-0) 

When the response arrives, the code processes it in `transform_client_response_into_notification`: [2](#0-1) 

**Critical Flaw #1 - Premature State Reset**: At line 1340, the code resets `end_of_epoch_requested = false` BEFORE validating the response payload. This violates the invariant that the flag should only be cleared after successful processing.

**Critical Flaw #2 - Missing Peer Notification**: In `handle_epoch_ending_response`, when an invalid number of ledger infos is detected, the code returns an error but does NOT call `notify_bad_response` to inform the data client: [3](#0-2) 

The TODO comment at line 844 acknowledges this missing functionality. The `notify_bad_response` mechanism exists and is used elsewhere: [4](#0-3) 

**Critical Flaw #3 - No Failure Tracking**: When the error propagates up through the call chain, it's caught and logged but doesn't increment `request_failure_count`: [5](#0-4) 

This means the stream won't terminate even after repeated failures, unlike other error cases that properly increment the failure count: [6](#0-5) 

**Exploitation Path**:

1. Victim node detects epoch change and requests epoch ending ledger info
2. Malicious peer responds with 0 or multiple ledger infos
3. `end_of_epoch_requested` reset to `false` (line 1340)
4. `handle_epoch_ending_response` returns error (line 845-848)  
5. Error logged but peer NOT blacklisted, stream NOT terminated
6. Next iteration: stream has `end_of_epoch_requested = false` and `current_target_ledger_info = None`
7. Stream requests another epoch ending ledger info (line 1204-1209)
8. Malicious peer selected again (wasn't blacklisted), repeats attack
9. **Result**: Infinite loop blocking epoch boundary synchronization

## Impact Explanation

**Severity: Medium** (per Aptos Bug Bounty criteria: "State inconsistencies requiring intervention")

**Impact Breakdown**:
- **State Sync Denial of Service**: Affected nodes cannot sync past epoch boundaries, preventing them from receiving new transactions and state updates
- **Validator Impact**: Validator nodes stuck at epoch boundaries cannot participate in consensus for the new epoch, affecting network liveness
- **Scope**: Any node syncing during epoch transitions that connects to a malicious peer
- **Duration**: Attack can persist indefinitely as the malicious peer is never blacklisted
- **Mitigation Available**: Node operators can manually restart with different peers or blacklist the malicious peer externally

This doesn't reach **High** severity because:
- No funds are at risk
- No consensus safety violation (nodes don't diverge in state, they just get stuck)
- Manual intervention can recover the node
- Not all nodes are affected simultaneously (only those syncing at epoch boundaries)

This qualifies as **Medium** severity because:
- State synchronization is blocked, requiring manual intervention
- Validator participation can be disrupted during critical epoch transitions
- The attack is repeatable and can affect multiple nodes

## Likelihood Explanation

**Likelihood: Medium-High**

**Favorable Conditions for Attack**:
- Epoch transitions occur regularly (every ~2 hours on mainnet)
- Many nodes will be syncing during these transitions
- Malicious peer only needs to serve invalid responses
- No authentication required beyond being a network peer
- Attack is low-cost (minimal bandwidth/computation)

**Attack Requirements**:
- Malicious peer must be selected by victim's data client
- Victim must be syncing across an epoch boundary
- Relatively simple to execute (just send wrong number of ledger infos)

**Mitigation Factors**:
- Aptos data client uses weighted peer selection by latency/distance
- Multiple peers available in healthy network
- Nodes may naturally rotate to different peers over time (though not guaranteed for this specific request type)

**Overall Assessment**: Medium-High likelihood because epoch transitions are frequent events and the attack is trivial to execute once a malicious peer is selected.

## Recommendation

**Fix Strategy**: Implement proper error handling with three key changes:

1. **Delay Flag Reset**: Only reset `end_of_epoch_requested` after successful validation
2. **Add Peer Notification**: Call `notify_bad_response` when invalid responses are detected  
3. **Track Failures**: Ensure errors increment `request_failure_count` so streams terminate after max retries

**Proposed Code Fix**:

```rust
fn transform_client_response_into_notification(
    &mut self,
    client_request: &DataClientRequest,
    client_response_payload: ResponsePayload,
    notification_id_generator: Arc<U64IdGenerator>,
) -> Result<Option<DataNotification>, Error> {
    // DON'T reset flags here - move after successful processing
    
    // Update the metrics for the number of received items
    update_response_chunk_size_metrics(client_request, &client_response_payload);

    // Handle and transform the response
    match client_request {
        EpochEndingLedgerInfos(_) => {
            self.handle_epoch_ending_response(client_response_payload)?;
            // Only reset flag after successful processing
            self.end_of_epoch_requested = false;
            Ok(None)
        },
        // ... rest of matches
        _ => {
            // Reset optimistic fetch flag only for non-epoch requests
            if self.optimistic_fetch_requested {
                self.optimistic_fetch_requested = false;
            }
            // ... rest of processing
        }
    }
}
```

And modify `handle_epoch_ending_response` to return the response context for bad response notification:

```rust
fn handle_epoch_ending_response(
    &mut self,
    response_payload: ResponsePayload,
) -> Result<(), Error> {
    if let ResponsePayload::EpochEndingLedgerInfos(epoch_ending_ledger_infos) = response_payload {
        match &epoch_ending_ledger_infos[..] {
            [target_ledger_info] => {
                // ... success case
                self.current_target_ledger_info = Some(target_ledger_info.clone());
                Ok(())
            },
            _ => {
                // Return specific error type that caller can use to notify bad peer
                Err(Error::AptosDataClientResponseIsInvalid(format!(
                    "Received an incorrect number of epoch ending ledger infos. Expected 1, got: {}",
                    epoch_ending_ledger_infos.len()
                )))
            },
        }
    } else {
        Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Expected an epoch ending ledger response but got: {:?}",
            response_payload
        )))
    }
}
```

Then in `send_data_notification_to_client`, catch epoch ending errors and notify the bad peer before propagating the error.

## Proof of Concept

**Reproduction Steps**:

1. Set up Aptos fullnode configured to sync from network peers
2. Deploy malicious peer that responds to `EpochEndingLedgerInfos` requests with empty array or multiple ledger infos
3. Trigger epoch transition in network
4. Monitor victim node logs for repeated error messages: "Received an incorrect number of epoch ending ledger infos"
5. Observe that victim node remains stuck at epoch boundary, repeatedly requesting from same malicious peer
6. Verify `end_of_epoch_requested` flag cycles between true/false but `current_target_ledger_info` remains None
7. Confirm that malicious peer's score is not decreased (peer not blacklisted)

**Expected Behavior**: Node should blacklist malicious peer after first invalid response and try different peers, eventually syncing successfully.

**Actual Behavior**: Node repeatedly requests from same malicious peer indefinitely, never syncing past the epoch boundary.

**Rust Test Skeleton**:

```rust
#[tokio::test]
async fn test_epoch_ending_invalid_response_corruption() {
    // Setup: Create continuous transaction stream engine
    // Mock data client that returns invalid epoch ending response
    // Send epoch ending request
    // Verify end_of_epoch_requested = true
    
    // Malicious peer responds with empty array
    // Call transform_client_response_into_notification
    
    // Assert: end_of_epoch_requested = false (reset)
    // Assert: current_target_ledger_info = None (not set)
    // Assert: Error returned
    
    // Next iteration: create_data_client_requests called again
    // Assert: New epoch ending request created (loop detected)
    // Assert: request_failure_count still 0 (not incremented)
}
```

## Notes

This vulnerability breaks the **State Consistency** invariant by allowing stream state to become corrupted (flags reset without corresponding state updates). It also impacts the **Resource Limits** invariant by potentially creating infinite retry loops consuming network bandwidth.

The developers are aware of the missing peer notification (TODO comment at line 844) but the premature flag reset issue may not be recognized as a separate vulnerability amplifying the impact.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L822-858)
```rust
    fn handle_epoch_ending_response(
        &mut self,
        response_payload: ResponsePayload,
    ) -> Result<(), Error> {
        if let ResponsePayload::EpochEndingLedgerInfos(epoch_ending_ledger_infos) = response_payload
        {
            match &epoch_ending_ledger_infos[..] {
                [target_ledger_info] => {
                    info!(
                        (LogSchema::new(LogEntry::ReceivedDataResponse)
                            .event(LogEvent::Success)
                            .message(&format!(
                                "Received an epoch ending ledger info for epoch: {:?}. \
                                        Setting new target version: {:?}",
                                target_ledger_info.ledger_info().epoch(),
                                target_ledger_info.ledger_info().version()
                            )))
                    );
                    self.current_target_ledger_info = Some(target_ledger_info.clone());
                    Ok(())
                },
                response_payload => {
                    // TODO(joshlind): eventually we want to notify the data client of the bad response
                    Err(Error::AptosDataClientResponseIsInvalid(format!(
                        "Received an incorrect number of epoch ending ledger infos. Response: {:?}",
                        response_payload
                    )))
                },
            }
        } else {
            // TODO(joshlind): eventually we want to notify the data client of the bad response
            Err(Error::AptosDataClientResponseIsInvalid(format!(
                "Expected an epoch ending ledger response but got: {:?}",
                response_payload
            )))
        }
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1193-1209)
```rust
                if target_ledger_info.ledger_info().epoch() > next_request_epoch {
                    // There was an epoch change. Request an epoch ending ledger info.
                    info!(
                        (LogSchema::new(LogEntry::AptosDataClient)
                            .event(LogEvent::Pending)
                            .message(&format!(
                                "Requested an epoch ending ledger info for epoch: {:?}",
                                next_request_epoch
                            )))
                    );
                    self.end_of_epoch_requested = true;
                    return Ok(vec![DataClientRequest::EpochEndingLedgerInfos(
                        EpochEndingLedgerInfosRequest {
                            start_epoch: next_request_epoch,
                            end_epoch: next_request_epoch,
                        },
                    )]);
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1336-1353)
```rust
        // Reset the pending requests to prevent malicious responses from
        // blocking the streams. Note: these request types are mutually
        // exclusive and only a single request will exist at any given time.
        if self.end_of_epoch_requested {
            self.end_of_epoch_requested = false;
        } else if self.optimistic_fetch_requested {
            self.optimistic_fetch_requested = false;
        }

        // Update the metrics for the number of received items
        update_response_chunk_size_metrics(client_request, &client_response_payload);

        // Handle and transform the response
        match client_request {
            EpochEndingLedgerInfos(_) => {
                self.handle_epoch_ending_response(client_response_payload)?;
                Ok(None)
            },
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L729-744)
```rust
    fn resend_data_client_request(
        &mut self,
        data_client_request: &DataClientRequest,
    ) -> Result<(), Error> {
        // Increment the number of client failures for this request
        self.request_failure_count += 1;

        // Resend the client request
        let pending_client_response = self.send_client_request(true, data_client_request.clone());

        // Push the pending response to the head of the sent requests queue
        self.get_sent_data_requests()?
            .push_front(pending_client_response);

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L746-764)
```rust
    /// Notifies the Aptos data client of a bad client response
    fn notify_bad_response(
        &self,
        response_context: &ResponseContext,
        response_error: ResponseError,
    ) {
        let response_id = response_context.id;
        info!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .message(&format!(
                "Notifying the data client of a bad response. Response id: {:?}, error: {:?}",
                response_id, response_error
            )));

        response_context
            .response_callback
            .notify_bad_response(response_error);
    }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L313-332)
```rust
            if let Err(error) = self.update_progress_of_data_stream(data_stream_id).await {
                if matches!(error, Error::NoDataToFetch(_)) {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(NO_DATA_TO_FETCH_LOG_FREQ_SECS)),
                        info!(LogSchema::new(LogEntry::CheckStreamProgress)
                            .stream_id(*data_stream_id)
                            .event(LogEvent::Pending)
                            .error(&error))
                    );
                } else {
                    metrics::increment_counter(
                        &metrics::CHECK_STREAM_PROGRESS_ERROR,
                        error.get_label(),
                    );
                    warn!(LogSchema::new(LogEntry::CheckStreamProgress)
                        .stream_id(*data_stream_id)
                        .event(LogEvent::Error)
                        .error(&error));
                }
            }
```
