# Audit Report

## Title
Race Condition Allows Message Processing from Disconnecting Peers in Consensus Observer

## Summary
A race condition exists between connection state updates and subscription termination in the consensus observer system. When a peer's connection state changes to `Disconnecting`, the peer is immediately removed from `connected_peers_and_metadata`, but its subscription remains active for up to 5 seconds. During this window, the disconnecting peer can still send and have consensus observer messages processed, violating the assumption that disconnecting peers cannot send messages.

## Finding Description

The vulnerability stems from an asynchronous mismatch between connection state management and subscription lifecycle management in the consensus observer.

**The Flow:**

1. The `is_connected()` function only returns `true` for `ConnectionState::Connected`: [1](#0-0) 

2. When the health checker detects excessive ping failures, it calls `disconnect_peer()`, which first updates the connection state to `Disconnecting`: [2](#0-1) 

3. The `update_connection_state()` call immediately updates the peer's state, making `is_connected()` return `false`: [3](#0-2) 

4. When `get_connected_peers_and_metadata()` is called, it filters out peers where `is_connected()` returns `false`: [4](#0-3) 

5. However, incoming messages are still processed by `handle_inbound_network_message()` with no connection state check: [5](#0-4) 

6. The consensus observer's `verify_message_for_subscription()` only checks if the sender exists in `active_observer_subscriptions`, not the connection state: [6](#0-5) 

7. Subscriptions are only terminated when `check_and_manage_subscriptions()` is called, which checks if peers are in `connected_peers_and_metadata`: [7](#0-6) 

8. This check happens periodically at `progress_check_interval_ms` (default 5 seconds): [8](#0-7) 

**Attack Scenario:**
- A malicious peer establishes a subscription with the consensus observer
- The peer sends invalid data causing health check failures  
- Health checker sets state to `Disconnecting` (peer removed from `connected_peers_and_metadata`)
- Socket remains open, subscription remains active
- For up to 5 seconds, the malicious peer floods consensus observer messages
- These messages pass `verify_message_for_subscription()` and are processed
- Messages from an "unhealthy/disconnecting" peer are processed as if from a healthy peer

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria: "State inconsistencies requiring intervention."

The vulnerability allows:
- Processing consensus observer messages (OrderedBlock, CommitDecision, BlockPayload) from peers marked as disconnecting
- Bypassing health check protections that should prevent unhealthy peers from influencing consensus
- Potential for malicious peers to send invalid consensus data during the race window
- DoS attacks via message flooding from disconnecting peers before subscription termination

While the window is time-limited (maximum 5 seconds), it's predictable and reliably exploitable. The consensus observer could process malicious data that would normally be rejected from unhealthy peers.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability requires:
- A malicious peer establishing a consensus observer subscription (easily achievable)
- Triggering health check failures (can be done by sending invalid pings or timing out)
- Exploiting the 5-second race window (predictable and reliable)

No privileged access or validator insider status is required. Any network peer can establish subscriptions and exploit this race condition. The window is guaranteed to exist for up to 5 seconds on every health-check-triggered disconnection.

## Recommendation

**Fix Option 1: Check connection state in message verification**

Modify `verify_message_for_subscription()` to also verify the sender is in `connected_peers_and_metadata`:

```rust
pub fn verify_message_for_subscription(
    &mut self,
    message_sender: PeerNetworkId,
) -> Result<(), Error> {
    // First verify the peer is still connected
    let connected_peers = self.consensus_observer_client
        .get_peers_and_metadata()
        .get_connected_peers_and_metadata()?;
    
    if !connected_peers.contains_key(&message_sender) {
        self.unsubscribe_from_peer(message_sender);
        return Err(Error::InvalidMessageError(format!(
            "Received message from disconnected peer: {}!",
            message_sender
        )));
    }
    
    // Then check if message is from active subscription
    if let Some(active_subscription) = self
        .active_observer_subscriptions
        .lock()
        .get_mut(&message_sender)
    {
        active_subscription.update_last_message_receive_time();
        return Ok(());
    }

    self.unsubscribe_from_peer(message_sender);
    Err(Error::InvalidMessageError(format!(
        "Received message from unexpected peer: {}!",
        message_sender
    )))
}
```

**Fix Option 2: Terminate subscriptions synchronously on connection state change**

Subscribe to connection state change notifications and immediately terminate subscriptions when peers enter `Disconnecting` state, rather than waiting for periodic `check_and_manage_subscriptions()`.

## Proof of Concept

```rust
// Integration test demonstrating the race condition
#[tokio::test]
async fn test_disconnecting_peer_message_race_condition() {
    // Setup: Create consensus observer with active subscription to peer A
    let (mut observer, peer_a_network_id) = setup_observer_with_subscription().await;
    
    // Step 1: Peer A's health checker detects failures
    // This sets connection state to Disconnecting
    observer.peers_and_metadata
        .update_connection_state(peer_a_network_id, ConnectionState::Disconnecting)
        .unwrap();
    
    // Step 2: Verify peer A is no longer in connected_peers_and_metadata
    let connected_peers = observer.peers_and_metadata
        .get_connected_peers_and_metadata()
        .unwrap();
    assert!(!connected_peers.contains_key(&peer_a_network_id));
    
    // Step 3: But subscription is still active!
    let active_subscriptions = observer.subscription_manager
        .active_observer_subscriptions
        .lock();
    assert!(active_subscriptions.contains_key(&peer_a_network_id));
    
    // Step 4: Peer A sends OrderedBlock message
    let malicious_block = create_malicious_ordered_block();
    let network_message = ConsensusObserverDirectSend::OrderedBlock(malicious_block);
    
    // Step 5: Message passes verification and is processed!
    let result = observer.subscription_manager
        .verify_message_for_subscription(peer_a_network_id);
    assert!(result.is_ok()); // Race condition: message from disconnecting peer accepted!
    
    // Step 6: Only after check_and_manage_subscriptions is called
    // (up to 5 seconds later) will the subscription be terminated
    observer.subscription_manager
        .check_and_manage_subscriptions()
        .await
        .unwrap();
    
    // Now the subscription is finally terminated
    let active_subscriptions = observer.subscription_manager
        .active_observer_subscriptions
        .lock();
    assert!(!active_subscriptions.contains_key(&peer_a_network_id));
}
```

## Notes

This race condition exists because:
1. Connection state management is synchronous and immediate
2. Subscription lifecycle management is asynchronous and periodic
3. Message verification only checks subscription presence, not connection state
4. The peer socket remains open during the `Disconnecting` state

The vulnerability affects all consensus observer nodes and could be exploited by any malicious peer without requiring validator privileges or collusion.

### Citations

**File:** network/framework/src/application/metadata.rs (L51-53)
```rust
    pub fn is_connected(&self) -> bool {
        self.connection_state == ConnectionState::Connected
    }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L65-81)
```rust
    pub async fn disconnect_peer(
        &mut self,
        peer_network_id: PeerNetworkId,
        disconnect_reason: DisconnectReason,
    ) -> Result<(), Error> {
        // Possibly already disconnected, but try anyways
        let _ = self.update_connection_state(peer_network_id, ConnectionState::Disconnecting);
        let result = self
            .network_client
            .disconnect_from_peer(peer_network_id, disconnect_reason)
            .await;
        let peer_id = peer_network_id.peer_id();
        if result.is_ok() {
            self.health_check_data.write().remove(&peer_id);
        }
        result
    }
```

**File:** network/framework/src/application/storage.rs (L108-125)
```rust
    pub fn get_connected_peers_and_metadata(
        &self,
    ) -> Result<HashMap<PeerNetworkId, PeerMetadata>, Error> {
        // Get the cached peers and metadata
        let cached_peers_and_metadata = self.cached_peers_and_metadata.load();

        // Collect all connected peers
        let mut connected_peers_and_metadata = HashMap::new();
        for (network_id, peers_and_metadata) in cached_peers_and_metadata.iter() {
            for (peer_id, peer_metadata) in peers_and_metadata.iter() {
                if peer_metadata.is_connected() {
                    let peer_network_id = PeerNetworkId::new(*network_id, *peer_id);
                    connected_peers_and_metadata.insert(peer_network_id, peer_metadata.clone());
                }
            }
        }
        Ok(connected_peers_and_metadata)
    }
```

**File:** network/framework/src/application/storage.rs (L266-290)
```rust
    pub fn update_connection_state(
        &self,
        peer_network_id: PeerNetworkId,
        connection_state: ConnectionState,
    ) -> Result<(), Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Update the connection state for the peer
        if let Some(peer_metadata) = peer_metadata_for_network.get_mut(&peer_network_id.peer_id()) {
            peer_metadata.connection_state = connection_state;
        } else {
            // Unable to find the peer metadata for the given peer
            return Err(missing_peer_metadata_error(&peer_network_id));
        }

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        Ok(())
    }
```

**File:** network/framework/src/peer/mod.rs (L447-541)
```rust
    fn handle_inbound_network_message(
        &mut self,
        message: NetworkMessage,
    ) -> Result<(), PeerManagerError> {
        match &message {
            NetworkMessage::DirectSendMsg(direct) => {
                let data_len = direct.raw_msg.len();
                network_application_inbound_traffic(
                    self.network_context,
                    direct.protocol_id,
                    data_len as u64,
                );
                match self.upstream_handlers.get(&direct.protocol_id) {
                    None => {
                        counters::direct_send_messages(&self.network_context, UNKNOWN_LABEL).inc();
                        counters::direct_send_bytes(&self.network_context, UNKNOWN_LABEL)
                            .inc_by(data_len as u64);
                    },
                    Some(handler) => {
                        let key = (self.connection_metadata.remote_peer_id, direct.protocol_id);
                        let sender = self.connection_metadata.remote_peer_id;
                        let network_id = self.network_context.network_id();
                        let sender = PeerNetworkId::new(network_id, sender);
                        match handler.push(key, ReceivedMessage::new(message, sender)) {
                            Err(_err) => {
                                // NOTE: aptos_channel never returns other than Ok(()), but we might switch to tokio::sync::mpsc and then this would work
                                counters::direct_send_messages(
                                    &self.network_context,
                                    DECLINED_LABEL,
                                )
                                .inc();
                                counters::direct_send_bytes(&self.network_context, DECLINED_LABEL)
                                    .inc_by(data_len as u64);
                            },
                            Ok(_) => {
                                counters::direct_send_messages(
                                    &self.network_context,
                                    RECEIVED_LABEL,
                                )
                                .inc();
                                counters::direct_send_bytes(&self.network_context, RECEIVED_LABEL)
                                    .inc_by(data_len as u64);
                            },
                        }
                    },
                }
            },
            NetworkMessage::Error(error_msg) => {
                warn!(
                    NetworkSchema::new(&self.network_context)
                        .connection_metadata(&self.connection_metadata),
                    error_msg = ?error_msg,
                    "{} Peer {} sent an error message: {:?}",
                    self.network_context,
                    self.remote_peer_id().short_str(),
                    error_msg,
                );
            },
            NetworkMessage::RpcRequest(request) => {
                match self.upstream_handlers.get(&request.protocol_id) {
                    None => {
                        counters::direct_send_messages(&self.network_context, UNKNOWN_LABEL).inc();
                        counters::direct_send_bytes(&self.network_context, UNKNOWN_LABEL)
                            .inc_by(request.raw_request.len() as u64);
                    },
                    Some(handler) => {
                        let sender = self.connection_metadata.remote_peer_id;
                        let network_id = self.network_context.network_id();
                        let sender = PeerNetworkId::new(network_id, sender);
                        if let Err(err) = self
                            .inbound_rpcs
                            .handle_inbound_request(handler, ReceivedMessage::new(message, sender))
                        {
                            warn!(
                                NetworkSchema::new(&self.network_context)
                                    .connection_metadata(&self.connection_metadata),
                                error = %err,
                                "{} Error handling inbound rpc request: {}",
                                self.network_context,
                                err
                            );
                        }
                    },
                }
            },
            NetworkMessage::RpcResponse(_) => {
                // non-reference cast identical to this match case
                let NetworkMessage::RpcResponse(response) = message else {
                    unreachable!("NetworkMessage type changed between match and let")
                };
                self.outbound_rpcs.handle_inbound_response(response)
            },
        };
        Ok(())
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L363-385)
```rust
    pub fn verify_message_for_subscription(
        &mut self,
        message_sender: PeerNetworkId,
    ) -> Result<(), Error> {
        // Check if the message is from an active subscription
        if let Some(active_subscription) = self
            .active_observer_subscriptions
            .lock()
            .get_mut(&message_sender)
        {
            // Update the last message receive time and return early
            active_subscription.update_last_message_receive_time();
            return Ok(());
        }

        // Otherwise, the message is not from an active subscription.
        // Send another unsubscribe request, and return an error.
        self.unsubscribe_from_peer(message_sender);
        Err(Error::InvalidMessageError(format!(
            "Received message from unexpected peer, and not an active subscription: {}!",
            message_sender
        )))
    }
```

**File:** consensus/src/consensus_observer/observer/subscription.rs (L63-91)
```rust
    pub fn check_subscription_health(
        &mut self,
        connected_peers_and_metadata: &HashMap<PeerNetworkId, PeerMetadata>,
        skip_peer_optimality_check: bool,
    ) -> Result<(), Error> {
        // Verify the subscription peer is still connected
        let peer_network_id = self.get_peer_network_id();
        if !connected_peers_and_metadata.contains_key(&peer_network_id) {
            return Err(Error::SubscriptionDisconnected(format!(
                "The peer: {:?} is no longer connected!",
                peer_network_id
            )));
        }

        // Verify the subscription has not timed out
        self.check_subscription_timeout()?;

        // Verify that the DB is continuing to sync and commit new data
        self.check_syncing_progress()?;

        // Verify that the subscription peer is still optimal
        self.check_subscription_peer_optimality(
            connected_peers_and_metadata,
            skip_peer_optimality_check,
        )?;

        // The subscription seems healthy
        Ok(())
    }
```

**File:** config/src/config/consensus_observer_config.rs (L73-73)
```rust
            progress_check_interval_ms: 5_000, // 5 seconds
```
