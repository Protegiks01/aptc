# Audit Report

## Title
Token V2 Burn Events Missing from Indexer After MODULE_EVENT_MIGRATION Feature Activation

## Summary
The Aptos indexer fails to capture Token V2 burn events after the `MODULE_EVENT_MIGRATION` feature flag (flag 57) is enabled, causing `current_supply` in `FixedSupply` to decrease in the indexer database without corresponding burn event records. This breaks supply tracking integrity for Token V2 collections.

## Finding Description

The vulnerability exists in the indexer's event parsing logic for Token V2 burn operations. When the `module_event_migration_enabled()` feature flag is enabled, the on-chain Move framework emits new `Burn` events (type `0x4::collection::Burn`) instead of legacy `BurnEvent` events (type `0x4::collection::BurnEvent`). [1](#0-0) 

The on-chain `decrement_supply` function checks the feature flag and conditionally emits either the new `Burn` event format or the old `BurnEvent` format. Both are atomic with the `current_supply -= 1` state change.

However, the indexer only parses the old `BurnEvent` format: [2](#0-1) 

The `V2TokenEvent::from_event` function only matches `"0x4::collection::BurnEvent"` (line 526-528) and returns `Ok(None)` for any other event type, including the new `"0x4::collection::Burn"` events.

The indexer's token processor processes both WriteResources and Events separately: [3](#0-2) 

The `FixedSupply` resource with decremented `current_supply` is extracted and stored in the database. [4](#0-3) 

But the burn event parsing at line 1169 fails to capture new `Burn` events, only detecting old `BurnEvent` events. This results in the indexer database showing reduced `current_supply` without corresponding burn event records in the `token_activities_v2` table.

The new `Burn` event type is defined as: [5](#0-4) 

This type (`0x4::collection::Burn`) is never handled by the indexer's event parsing logic, despite being the active event type after feature flag migration.

## Impact Explanation

This is a **Medium Severity** issue under the category "State inconsistencies requiring intervention."

The indexer is critical infrastructure that provides queryable token data for:
- NFT marketplaces calculating collection supply and rarity
- Analytics platforms tracking token burns and supply changes  
- Wallet applications displaying token ownership and collection statistics
- Blockchain explorers showing transaction history

With missing burn events, the indexer data shows:
- `current_supply` decreasing in `current_collections_v2` table
- No corresponding burn activity records in `token_activities_v2` table
- Inconsistent supply tracking that cannot be reconciled from events alone

This breaks the data integrity guarantee that all supply changes are traceable through event records, potentially causing:
- Incorrect rarity calculations for NFT collections
- Failed audits of token supply changes
- Misleading analytics about token burn rates
- Broken integrations that rely on complete event history

## Likelihood Explanation

**Likelihood: HIGH** - This issue will occur automatically once the `MODULE_EVENT_MIGRATION` feature flag is enabled network-wide. [6](#0-5) 

The feature flag controls event format globally. Once enabled, **all** Token V2 burn operations will emit the new event format that the indexer cannot parse. This affects:
- Every Token V2 collection using `FixedSupply` or `UnlimitedSupply`
- All token burn transactions after feature activation
- Historical event queries that span the migration boundary

The issue is not exploitable by attackers but occurs as a natural consequence of feature flag activation without corresponding indexer updates.

## Recommendation

Update the indexer to handle both old and new burn event formats. Modify `V2TokenEvent::from_event` to parse both event types:

```rust
match data_type {
    "0x4::collection::MintEvent" => {
        serde_json::from_value(data.clone()).map(|inner| Some(Self::MintEvent(inner)))
    },
    "0x4::token::MutationEvent" => serde_json::from_value(data.clone())
        .map(|inner| Some(Self::TokenMutationEvent(inner))),
    "0x4::collection::BurnEvent" => {
        serde_json::from_value(data.clone()).map(|inner| Some(Self::BurnEvent(inner)))
    },
    // ADD: Handle new Burn event format
    "0x4::collection::Burn" => {
        // Parse new Burn event and convert to BurnEvent format for backward compatibility
        let burn: Burn = serde_json::from_value(data.clone())?;
        let burn_event = BurnEvent {
            index: burn.index.into(),
            token: burn.token.to_string(),
        };
        Ok(Some(Self::BurnEvent(burn_event)))
    },
    "0x1::object::TransferEvent" => {
        serde_json::from_value(data.clone()).map(|inner| Some(Self::TransferEvent(inner)))
    },
    _ => Ok(None),
}
```

Additionally, add similar handling for `Mint` events (`0x4::collection::Mint`) to maintain consistency.

## Proof of Concept

**Prerequisites:**
1. Deploy a Token V2 collection with `FixedSupply`
2. Enable `MODULE_EVENT_MIGRATION` feature flag (flag 57)
3. Run the indexer against a node with the feature enabled

**Steps to Reproduce:**

1. **Create a collection with FixedSupply:**
```move
use aptos_token_objects::collection;
let constructor_ref = collection::create_fixed_collection(
    creator,
    string::utf8(b"Test Collection"),
    100, // max_supply
    string::utf8(b"Test"),
    option::none(),
    string::utf8(b"https://example.com")
);
```

2. **Mint and burn a token:**
```move
use aptos_token_objects::token;
let token_constructor = token::create(...);
// ... later ...
token::burn(burn_ref); // This will emit 0x4::collection::Burn event
```

3. **Query indexer database:**
```sql
    -- Check current_supply decreased
SELECT current_supply FROM current_collections_v2 WHERE collection_id = '0x...';

-- Check for burn events (will be empty)
SELECT * FROM token_activities_v2 
WHERE token_data_id = '0x...' 
AND type_ LIKE '%Burn%';
```

**Expected Result:** Burn event should be present in `token_activities_v2`.

**Actual Result:** No burn event record exists, only the decremented `current_supply` value, creating an inconsistency between state and event history.

---

## Notes

While this issue does not affect on-chain consensus or security, it represents a critical data integrity failure in the indexer that many applications depend on. The severity is mitigated by the fact that the on-chain state remains correct and queryable directly, but the indexer's value proposition is providing efficient access to historical data, which is compromised by this bug.

### Citations

**File:** aptos-move/framework/aptos-token-objects/sources/collection.move (L486-506)
```text
        } else if (exists<FixedSupply>(collection_addr)) {
            let supply = &mut FixedSupply[collection_addr];
            supply.current_supply -= 1;
            if (std::features::module_event_migration_enabled()) {
                event::emit(
                    Burn {
                        collection: collection_addr,
                        index: *index.borrow(),
                        token,
                        previous_owner,
                    },
                );
            } else {
                event::emit_event(
                    &mut supply.burn_events,
                    BurnEvent {
                        index: *index.borrow(),
                        token,
                    },
                );
            };
```

**File:** crates/indexer/src/models/token_models/v2_token_utils.rs (L514-539)
```rust
impl V2TokenEvent {
    pub fn from_event(
        data_type: &str,
        data: &serde_json::Value,
        txn_version: i64,
    ) -> Result<Option<Self>> {
        match data_type {
            "0x4::collection::MintEvent" => {
                serde_json::from_value(data.clone()).map(|inner| Some(Self::MintEvent(inner)))
            },
            "0x4::token::MutationEvent" => serde_json::from_value(data.clone())
                .map(|inner| Some(Self::TokenMutationEvent(inner))),
            "0x4::collection::BurnEvent" => {
                serde_json::from_value(data.clone()).map(|inner| Some(Self::BurnEvent(inner)))
            },
            "0x1::object::TransferEvent" => {
                serde_json::from_value(data.clone()).map(|inner| Some(Self::TransferEvent(inner)))
            },
            _ => Ok(None),
        }
        .context(format!(
            "version {} failed! failed to parse type {}, data {:?}",
            txn_version, data_type, data
        ))
    }
}
```

**File:** crates/indexer/src/processors/token_processor.rs (L1118-1126)
```rust
            for wsc in user_txn.info.changes.iter() {
                if let WriteSetChange::WriteResource(wr) = wsc {
                    let address = standardize_address(&wr.address.to_string());
                    if let Some(aggregated_data) = token_v2_metadata_helper.get_mut(&address) {
                        if let Some(fixed_supply) =
                            FixedSupply::from_write_resource(wr, txn_version).unwrap()
                        {
                            aggregated_data.fixed_supply = Some(fixed_supply);
                        }
```

**File:** crates/indexer/src/processors/token_processor.rs (L1168-1171)
```rust
            for (index, event) in user_txn.events.iter().enumerate() {
                if let Some(burn_event) = BurnEvent::from_event(event, txn_version).unwrap() {
                    tokens_burned.insert(burn_event.get_token_address());
                }
```

**File:** types/src/account_config/events/burn.rs (L59-64)
```rust
impl MoveStructType for Burn {
    const MODULE_NAME: &'static IdentStr = ident_str!("collection");
    const STRUCT_NAME: &'static IdentStr = ident_str!("Burn");
}

impl MoveEventV2Type for Burn {}
```

**File:** aptos-move/framework/move-stdlib/sources/configs/features.move (L57-57)
```text
    /// This is needed because of the introduction of new native functions.
```
