# Audit Report

## Title
OptQuorumStore Payload Batch Duplication Vulnerability Enabling Transaction Re-execution

## Summary
A malicious block proposer can include the same `BatchInfo` in both `opt_batches` and `inline_batches` fields of an `OptQuorumStorePayload`, causing the same transactions to be executed twice. This occurs because payload verification does not check for duplicate `BatchInfo` entries across these collections, and transaction extraction concatenates transactions from both sources without deduplication.

## Finding Description
The `OptQuorumStorePayload` structure contains three collections of batches: `proof_batches` (certified batches), `opt_batches` (optimistic batches with metadata only), and `inline_batches` (batches with transactions included). When a block proposer creates a payload, they can maliciously include the same `BatchInfo` in both `opt_batches` and `inline_batches`.

During payload verification, the system validates: [1](#0-0) 

This verification checks proof signatures, inline batch digests, and opt batch authors, but **does not verify that opt_batches and inline_batches are disjoint sets**.

When transactions are extracted for execution: [2](#0-1) 

The code fetches transactions from `opt_batches` via the batch reader, retrieves transactions directly from `inline_batches`, and concatenates them. If the same `BatchInfo` appears in both collections, its transactions will appear twice in the final transaction list, leading to duplicate execution.

The honest payload construction path properly excludes duplicates: [3](#0-2) 

However, this deduplication only occurs during honest payload creation. A malicious proposer can bypass this by manually constructing a payload with duplicates.

The consensus observer verification also fails to detect duplicates: [4](#0-3) 

This function only verifies that the received batches match expected batches but doesn't check for duplicates within the combined list.

## Impact Explanation
**Critical Severity** - This vulnerability breaks fundamental consensus invariants:

1. **Deterministic Execution Violation**: If validators have different batch store states, some may fetch transactions for opt_batches while others cannot, leading to different transaction orderings and divergent state roots.

2. **Transaction Duplication**: The same transactions execute twice, which could:
   - Cause double-spending if sequence number checks fail
   - Create state inconsistencies across validators
   - Lead to incorrect balance updates or resource modifications

3. **Consensus Safety Risk**: Different validators may reject or accept the block differently based on their local batch availability, potentially causing chain splits or liveness failures.

This meets the Critical severity criteria: "Consensus/Safety violations" potentially affecting all nodes in the network.

## Likelihood Explanation
**High Likelihood** if exploited:

- **Attacker Requirements**: Requires being a validator and selected as block proposer for a round (probability proportional to stake)
- **Complexity**: Low - simply construct a payload with duplicate `BatchInfo` entries
- **Detection**: No validation prevents this; the malicious payload passes all verification checks
- **Impact**: Guaranteed transaction duplication if batch is available in batch store

Once a malicious validator attempts this attack as proposer, the vulnerability will trigger with high probability unless other validators fail to fetch the batches.

## Recommendation
Add validation to ensure `opt_batches` and `inline_batches` are disjoint sets during payload verification:

```rust
// In consensus/consensus-types/src/common.rs, in the verify() method for OptQuorumStore:
pub fn verify_no_duplicate_batches<T: TBatchInfo>(
    opt_batches: &OptBatches<T>,
    inline_batches: &InlineBatches<T>,
) -> anyhow::Result<()> {
    let mut seen_digests = HashSet::new();
    
    // Check opt_batches
    for batch in &opt_batches.batch_summary {
        ensure!(
            seen_digests.insert(batch.digest()),
            "Duplicate batch digest {} found in opt_batches",
            batch.digest()
        );
    }
    
    // Check inline_batches don't duplicate opt_batches
    for batch in inline_batches.iter() {
        ensure!(
            seen_digests.insert(batch.info().digest()),
            "Duplicate batch digest {} found between opt_batches and inline_batches",
            batch.info().digest()
        );
    }
    
    Ok(())
}

// Then call in verify():
(true, Payload::OptQuorumStore(OptQuorumStorePayload::V1(p))) => {
    let proof_with_data = p.proof_with_data();
    Self::verify_with_cache(&proof_with_data.batch_summary, verifier, proof_cache)?;
    Self::verify_inline_batches(
        p.inline_batches()
            .iter()
            .map(|batch| (batch.info(), batch.transactions())),
    )?;
    Self::verify_opt_batches(verifier, p.opt_batches())?;
    Self::verify_no_duplicate_batches(p.opt_batches(), p.inline_batches())?; // NEW
    Ok(())
},
```

## Proof of Concept
```rust
#[test]
fn test_duplicate_batch_in_opt_and_inline() {
    use aptos_consensus_types::{
        payload::{OptQuorumStorePayload, InlineBatch, InlineBatches, PayloadExecutionLimit},
        proof_of_store::BatchInfo,
        common::Payload,
    };
    use aptos_crypto::HashValue;
    use aptos_types::transaction::SignedTransaction;
    
    // Create a BatchInfo
    let batch_info = BatchInfo::new(
        PeerId::random(),
        BatchId::new_for_test(1),
        0, // epoch
        1000, // expiration
        HashValue::random(),
        10, // num_txns
        1000, // num_bytes
        HashValue::random(),
    );
    
    // Create dummy transactions
    let transactions = vec![create_dummy_transaction(); 10];
    
    // Create payload with SAME batch_info in both opt_batches and inline_batches
    let inline_batch = InlineBatch::new(batch_info.clone(), transactions.clone());
    let inline_batches = InlineBatches::from(vec![inline_batch]);
    let opt_batches = vec![batch_info.clone()].into();
    let proof_batches = vec![].into();
    
    let payload = Payload::OptQuorumStore(OptQuorumStorePayload::new(
        inline_batches,
        opt_batches,
        proof_batches,
        PayloadExecutionLimit::None,
    ));
    
    // Verify payload - THIS SHOULD FAIL but currently PASSES
    let verifier = create_test_validator_verifier();
    let proof_cache = ProofCache::new(100);
    let result = payload.verify(&verifier, &proof_cache, true);
    
    // Current behavior: verification passes (BUG!)
    assert!(result.is_ok()); // This demonstrates the vulnerability
    
    // When transactions are extracted, batch_info's transactions
    // will appear twice: once from opt_batches fetch, once from inline_batches
}
```

## Notes
This vulnerability requires a malicious validator to be selected as block proposer, which falls within the Byzantine Fault Tolerance threat model (up to 1/3 malicious validators). The system should protect against such proposers by rejecting invalid blocks during verification, which it currently fails to do for duplicate batches across `opt_batches` and `inline_batches`.

### Citations

**File:** consensus/consensus-types/src/common.rs (L598-607)
```rust
            (true, Payload::OptQuorumStore(OptQuorumStorePayload::V1(p))) => {
                let proof_with_data = p.proof_with_data();
                Self::verify_with_cache(&proof_with_data.batch_summary, verifier, proof_cache)?;
                Self::verify_inline_batches(
                    p.inline_batches()
                        .iter()
                        .map(|batch| (batch.info(), batch.transactions())),
                )?;
                Self::verify_opt_batches(verifier, p.opt_batches())?;
                Ok(())
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L511-541)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(opt_qs_payload)) => {
                let opt_batch_txns = process_optqs_payload(
                    opt_qs_payload.opt_batches(),
                    self.batch_reader.clone(),
                    block,
                    &self.ordered_authors,
                    block_signers.as_ref(),
                )
                .await?;
                let proof_batch_txns = process_optqs_payload(
                    opt_qs_payload.proof_with_data(),
                    self.batch_reader.clone(),
                    block,
                    &self.ordered_authors,
                    None,
                )
                .await?;
                let inline_batch_txns = opt_qs_payload.inline_batches().transactions();
                let all_txns = [proof_batch_txns, opt_batch_txns, inline_batch_txns].concat();
                BlockTransactionPayload::new_opt_quorum_store(
                    all_txns,
                    opt_qs_payload.proof_with_data().deref().clone(),
                    opt_qs_payload.max_txns_to_execute(),
                    opt_qs_payload.block_gas_limit(),
                    [
                        opt_qs_payload.opt_batches().deref().clone(),
                        opt_qs_payload.inline_batches().batch_infos(),
                    ]
                    .concat(),
                )
            },
```

**File:** consensus/src/quorum_store/proof_manager.rs (L155-184)
```rust
        let (inline_block, inline_block_size) =
            if self.allow_batches_without_pos_in_proposal && proof_queue_fully_utilized {
                let mut max_inline_txns_to_pull = request
                    .max_txns
                    .saturating_sub(cur_txns)
                    .minimum(request.max_inline_txns);
                max_inline_txns_to_pull.set_count(min(
                    max_inline_txns_to_pull.count(),
                    request
                        .max_txns_after_filtering
                        .saturating_sub(cur_unique_txns),
                ));
                let (inline_batches, inline_payload_size, _) =
                    self.batch_proof_queue.pull_batches_with_transactions(
                        &excluded_batches
                            .iter()
                            .cloned()
                            .chain(proof_block.iter().map(|proof| proof.info().clone()))
                            .chain(opt_batches.clone())
                            .collect(),
                        max_inline_txns_to_pull,
                        request.max_txns_after_filtering,
                        request.soft_max_txns_after_filtering,
                        request.return_non_full,
                        request.block_timestamp,
                    );
                (inline_batches, inline_payload_size)
            } else {
                (Vec::new(), PayloadTxnsSize::zero())
            };
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L774-803)
```rust
    fn verify_optqs_and_inline_batches(
        &self,
        expected_opt_batches: &Vec<BatchInfo>,
        expected_inline_batches: &InlineBatches<BatchInfo>,
    ) -> Result<(), Error> {
        let optqs_and_inline_batches: &Vec<BatchInfo> = match self {
            BlockTransactionPayload::OptQuorumStore(_, optqs_and_inline_batches) => {
                optqs_and_inline_batches
            },
            _ => {
                return Err(Error::InvalidMessageError(
                    "Transaction payload is not an OptQS Payload".to_string(),
                ))
            },
        };

        let expected_opt_and_inline_batches = expected_opt_batches.iter().chain(
            expected_inline_batches
                .iter()
                .map(|inline_batch| inline_batch.info()),
        );

        if !expected_opt_and_inline_batches.eq(optqs_and_inline_batches.iter()) {
            return Err(Error::InvalidMessageError(format!(
                "Transaction payload failed batch verification! Expected optimistic batches {:?}, inline batches {:?} but found {:?}",
                expected_opt_batches, expected_inline_batches, optqs_and_inline_batches
            )));
        }
        Ok(())
    }
```
