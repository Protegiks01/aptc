# Audit Report

## Title
Module Verification Race Condition Causing Redundant CPU Usage in Parallel Execution

## Summary
A race condition exists in the module verification caching mechanism where multiple concurrent threads can verify the same module simultaneously, wasting CPU resources. The `VERIFIED_MODULES_CACHE` uses a check-then-act pattern without atomic synchronization, allowing parallel execution threads to redundantly verify identical modules.

## Finding Description

The vulnerability exists in the module verification flow used by both eager and lazy loading paths. The critical race condition occurs in the `build_locally_verified_module()` function: [1](#0-0) 

The verification cache check and insertion are separate operations with locks released between them: [2](#0-1) 

During parallel block execution, when multiple transactions require the same unverified module, all threads check the cache, find it absent, and proceed with expensive verification work:

**Eager Loading Path:** [3](#0-2) 

**Lazy Loading Path:** [4](#0-3) 

**Attack Scenario:**
1. Attacker publishes or identifies a module M that hasn't been verified yet
2. Attacker submits N transactions in a block that all invoke functions from module M  
3. The parallel block executor spawns concurrent threads (up to `concurrency_level`): [5](#0-4) 

4. All N threads call `build_locally_verified_module()` for the same module
5. All threads execute: `VERIFIED_MODULES_CACHE.contains(hash)` â†’ `false`
6. All threads perform expensive bytecode verification (parsing, type checking, etc.)
7. All threads execute: `VERIFIED_MODULES_CACHE.put(hash)`
8. Result: Verification performed N times instead of once

The `SyncModuleCache` provides thread-safe insertion but doesn't prevent the race between cache checking and verification work: [6](#0-5) 

## Impact Explanation

**Severity: Low** (as indicated in the original security question)

This issue causes wasteful CPU resource consumption but does not compromise:
- **Consensus correctness**: All threads produce identical verified modules (deterministic verification)
- **State integrity**: No state corruption occurs
- **Funds security**: No loss or theft of assets possible

The impact is limited to performance degradation through redundant computation. While this could theoretically contribute to validator slowdowns under heavy load, it does not meet the threshold for High severity "Validator node slowdowns" because:
1. The redundant work is bounded by block transaction count
2. Modern validators have sufficient CPU capacity to handle moderate duplication
3. The condition requires specific timing (all threads hitting same unverified module simultaneously)

## Likelihood Explanation

**Likelihood: Medium in parallel execution scenarios**

The race condition triggers when:
- Parallel execution is enabled (production default)
- Multiple transactions in a block use the same previously-unverified module
- Threads check cache before any completes verification

This is realistic but not guaranteed every block, as most modules are pre-verified in the cache from previous blocks.

## Recommendation

Implement atomic "test-and-set" semantics for module verification using a concurrent set to track modules currently being verified:

```rust
// In verified_module_cache.rs
pub(crate) struct VerifiedModuleCache {
    cache: Mutex<lru::LruCache<[u8; 32], ()>>,
    in_progress: DashSet<[u8; 32]>,  // Track ongoing verifications
}

pub(crate) fn verify_or_wait(&self, module_hash: [u8; 32]) -> VerificationStatus {
    if self.cache.lock().contains(&module_hash) {
        return VerificationStatus::AlreadyVerified;
    }
    
    // Atomically insert into in-progress set
    if self.in_progress.insert(module_hash) {
        // This thread won the race, should verify
        VerificationStatus::ShouldVerify
    } else {
        // Another thread is verifying, wait or retry
        VerificationStatus::InProgress
    }
}

pub(crate) fn mark_verified(&self, module_hash: [u8; 32]) {
    self.cache.lock().put(module_hash, ());
    self.in_progress.remove(&module_hash);
}
```

Then modify `build_locally_verified_module()` to use this atomic operation.

## Proof of Concept

```rust
// Rust test demonstrating the race condition
#[test]
fn test_concurrent_module_verification_race() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let runtime_env = Arc::new(RuntimeEnvironment::new(/*...*/));
    let module_bytes = Arc::new(/* compiled module bytes */);
    let barrier = Arc::new(Barrier::new(10)); // 10 threads
    let verification_counter = Arc::new(AtomicUsize::new(0));
    
    let handles: Vec<_> = (0..10).map(|_| {
        let env = runtime_env.clone();
        let bytes = module_bytes.clone();
        let barrier = barrier.clone();
        let counter = verification_counter.clone();
        
        thread::spawn(move || {
            barrier.wait(); // Synchronize start
            
            // This should ideally only verify once across all threads
            let result = env.build_locally_verified_module(
                bytes.clone(),
                bytes.len(),
                &compute_hash(&bytes),
            );
            
            if result.is_ok() {
                counter.fetch_add(1, Ordering::SeqCst);
            }
        })
    }).collect();
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    // Without fix: counter == 10 (all threads verified)
    // With fix: counter == 1 (only one thread verified)
    println!("Verifications performed: {}", verification_counter.load(Ordering::SeqCst));
    assert!(verification_counter.load(Ordering::SeqCst) > 1, "Race condition demonstrated");
}
```

---

## Notes

While this vulnerability is confirmed to exist in the codebase, it does **not meet the validation checklist requirement** for reportable severity (Critical/High/Medium). The issue is classified as **Low severity** per the original security question, causing only resource wastage without compromising consensus, state integrity, or fund security. According to strict bug bounty criteria, this would not qualify for a significant reward but represents a valid optimization opportunity.

### Citations

**File:** third_party/move/move-vm/runtime/src/storage/environment.rs (L184-198)
```rust
        if !VERIFIED_MODULES_CACHE.contains(module_hash) {
            let _timer =
                VM_TIMER.timer_with_label("move_bytecode_verifier::verify_module_with_config");

            // For regular execution, we cache already verified modules. Note that this even caches
            // verification for the published modules. This should be ok because as long as the
            // hash is the same, the deployed bytecode and any dependencies are the same, and so
            // the cached verification result can be used.
            move_bytecode_verifier::verify_module_with_config(
                &self.vm_config().verifier_config,
                compiled_module.as_ref(),
            )?;
            check_natives(compiled_module.as_ref())?;
            VERIFIED_MODULES_CACHE.put(*module_hash);
        }
```

**File:** third_party/move/move-vm/runtime/src/storage/verified_module_cache.rs (L26-38)
```rust
    pub(crate) fn contains(&self, module_hash: &[u8; 32]) -> bool {
        // Note: need to use get to update LRU queue.
        verifier_cache_enabled() && self.0.lock().get(module_hash).is_some()
    }

    /// Inserts the hash into the cache, marking the corresponding as locally verified. For tests,
    /// entries are not added to the cache.
    pub(crate) fn put(&self, module_hash: [u8; 32]) {
        if verifier_cache_enabled() {
            let mut cache = self.0.lock();
            cache.put(module_hash, ());
        }
    }
```

**File:** third_party/move/move-vm/runtime/src/storage/module_storage.rs (L315-319)
```rust
        let locally_verified_code = runtime_environment.build_locally_verified_module(
            module.code().deserialized().clone(),
            module.extension().size_in_bytes(),
            module.extension().hash(),
        )?;
```

**File:** third_party/move/move-vm/runtime/src/storage/module_storage.rs (L377-381)
```rust
    let locally_verified_code = runtime_environment.build_locally_verified_module(
        module.code().deserialized().clone(),
        module.extension().size_in_bytes(),
        module.extension().hash(),
    )?;
```

**File:** aptos-move/block-executor/src/executor.rs (L119-133)
```rust
    /// The caller needs to ensure that concurrency_level > 1 (0 is illegal and 1 should
    /// be handled by sequential execution) and that concurrency_level <= num_cpus.
    pub fn new(
        config: BlockExecutorConfig,
        executor_thread_pool: Arc<ThreadPool>,
        transaction_commit_hook: Option<L>,
    ) -> Self {
        let num_cpus = num_cpus::get();
        assert!(
            config.local.concurrency_level > 0 && config.local.concurrency_level <= num_cpus,
            "Parallel execution concurrency level {} should be between 1 and number of CPUs ({})",
            config.local.concurrency_level,
            num_cpus,
        );
        Self {
```

**File:** third_party/move/move-vm/types/src/code/cache/module_cache.rs (L444-467)
```rust
    fn insert_verified_module(
        &self,
        key: Self::Key,
        verified_code: Self::Verified,
        extension: Arc<Self::Extension>,
        version: Self::Version,
    ) -> VMResult<Arc<ModuleCode<Self::Deserialized, Self::Verified, Self::Extension>>> {
        use dashmap::mapref::entry::Entry::*;

        match self.module_cache.entry(key) {
            Occupied(mut entry) => match version.cmp(&entry.get().version()) {
                Ordering::Less => Err(version_too_small_error!()),
                Ordering::Equal => {
                    if entry.get().module_code().code().is_verified() {
                        Ok(entry.get().module_code().clone())
                    } else {
                        let versioned_module = VersionedModuleCode::new(
                            ModuleCode::from_verified(verified_code, extension),
                            version,
                        );
                        let module = versioned_module.module_code().clone();
                        entry.insert(CachePadded::new(versioned_module));
                        Ok(module)
                    }
```
