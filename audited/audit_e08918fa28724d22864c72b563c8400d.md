# Audit Report

## Title
Byzantine Nodes Can Advertise False Historical Transaction Ranges to Disrupt New Node Bootstrapping

## Summary
Byzantine nodes can advertise transaction ranges starting from version 0 (genesis) even when they have pruned early history. When new nodes attempt to bootstrap from genesis, they will repeatedly select these Byzantine peers based on the false advertisements, fail to fetch the data, and be unable to make sync progress. This creates a denial-of-service vector against node bootstrapping and historical data queries.

## Finding Description

The Aptos state sync system aggregates storage summaries from all connected peers to build a global data summary that guides data requests. The vulnerability exists in how transaction ranges are advertised and trusted without cryptographic verification.

**Attack Flow:**

1. **False Advertisement Creation**: A Byzantine peer running modified code creates a `StorageServerSummary` with `data_summary.transactions` claiming to hold transactions from version 0, despite having pruned this data. [1](#0-0) 

2. **Unchecked Aggregation**: The data client aggregates these advertisements without verification into the global summary: [2](#0-1) 

The transaction ranges are simply collected at lines 379-380 with no validation that peers actually possess the advertised data.

3. **Misleading Peer Selection**: The `lowest_transaction_version()` function returns the minimum across all advertised ranges: [3](#0-2) 

4. **Trust-Based Selection**: When selecting peers to service requests, the system only checks if the advertised range contains the requested data: [4](#0-3) 

The `can_service_transactions()` method uses `superset_of()` which only compares advertised ranges, not actual data availability.

5. **Request Failure**: When the Byzantine peer receives the actual request, it tries to fetch from its pruned database and fails, causing the requesting node to receive an error: [5](#0-4) 

**Critical Gap**: Storage summaries are **not cryptographically signed or proven**. Only the `synced_ledger_info` within the summary contains signatures, but the transaction/output ranges themselves have no proof of actual data availability: [6](#0-5) 

**Inadequate Mitigation**: While the peer scoring system reduces scores for failed requests, it is insufficient because: [7](#0-6) 

- Starting score is 50.0, ignore threshold is 25.0
- "NotUseful" errors multiply by 0.95, requiring ~13 failures to ignore
- Multiple Byzantine peers can coordinate to maintain a majority in the serviceable peer pool
- New Byzantine peers can join and reset the attack

## Impact Explanation

This is a **High Severity** vulnerability according to Aptos bug bounty criteria:

- **Validator node slowdowns**: New validator nodes attempting to bootstrap cannot sync efficiently
- **Significant protocol violations**: Violates the expected behavior that advertised data availability should be accurate and that state sync should make progress when sufficient peers are available

The vulnerability enables:
- **Denial of Service** against new node bootstrapping
- **Historical data censorship** by preventing access to genesis/early transactions
- **Network fragmentation** if coordinated Byzantine peers control genesis data access

It does not reach Critical severity because:
- No loss or theft of funds
- Does not break consensus safety for already-synced nodes  
- Existing operational nodes continue functioning normally
- Does not enable remote code execution

## Likelihood Explanation

**High Likelihood** of occurrence:

**Attacker Requirements**:
- Ability to run modified Aptos node software (Byzantine peer)
- Network connectivity to target nodes
- No stake or validator status required
- Multiple coordinating peers increases effectiveness

**Attack Simplicity**:
- Trivial code modification to advertise false ranges
- No cryptographic operations to forge
- No complex timing or race conditions needed

**Target Vulnerability**:
- Affects all new nodes attempting to bootstrap from genesis
- Affects any node querying early historical data
- Particularly effective in mature networks where most nodes have pruned genesis data

**Coordination Benefit**:
- Single Byzantine peer causes delays and retries
- Multiple Byzantine peers make the attack highly effective
- If Byzantine peers dominate the "has genesis" pool, attack succeeds reliably

## Recommendation

Implement cryptographic proof of data availability for advertised ranges:

**Solution 1: Range Commitments**
- Peers must provide Merkle proofs that they can access the first and last transaction in advertised ranges
- Verify these proofs before adding ranges to the global summary
- Periodically re-verify to detect pruning

**Solution 2: Optimistic Verification with Fast Banning**
- On first request failure for genesis data, immediately mark peer as "unreliable for historical data"
- Implement separate scoring for historical vs. recent data
- Fast-track peer banning for repeated failures on low-version requests

**Solution 3: Trusted Archive Node Registry**
- Maintain a registry of known-good archive nodes (similar to seed nodes)
- Prioritize these peers for historical data requests
- Fallback to untrusted peers only when necessary

**Code Fix Example** (Solution 2 - Fast Banning for Historical Data):

```rust
// In peer_states.rs, add separate tracking for historical data failures
pub struct PeerState {
    // ... existing fields ...
    historical_data_failures: Arc<AtomicU64>,
}

const MAX_HISTORICAL_FAILURES: u64 = 3;

impl PeerState {
    fn update_score_error(&mut self, error: ErrorType, is_historical_data: bool) {
        // Existing score update
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
        
        // Fast ban for repeated historical data failures
        if is_historical_data && error == ErrorType::NotUseful {
            let failures = self.historical_data_failures.fetch_add(1, Ordering::Relaxed);
            if failures >= MAX_HISTORICAL_FAILURES {
                self.score = MIN_SCORE; // Immediately ban
            }
        }
    }
    
    fn is_ignored(&self) -> bool {
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }
        
        // Check historical data ban
        if self.historical_data_failures.load(Ordering::Relaxed) >= MAX_HISTORICAL_FAILURES {
            return true;
        }
        
        self.score <= IGNORE_PEER_THRESHOLD
    }
}
```

## Proof of Concept

```rust
// Proof of Concept: Byzantine peer advertising false genesis data
// This demonstrates the attack scenario

#[cfg(test)]
mod byzantine_genesis_attack {
    use aptos_storage_service_types::responses::{
        DataSummary, CompleteDataRange, StorageServerSummary, ProtocolMetadata
    };
    use aptos_types::transaction::Version;

    #[test]
    fn test_byzantine_peer_false_genesis_advertisement() {
        // Byzantine peer creates false storage summary claiming to have genesis
        let byzantine_summary = StorageServerSummary {
            protocol_metadata: ProtocolMetadata::default(),
            data_summary: DataSummary {
                synced_ledger_info: None,
                epoch_ending_ledger_infos: None,
                states: None,
                // FALSE CLAIM: Advertising transactions from version 0
                // when the peer actually pruned everything below version 1_000_000
                transactions: Some(CompleteDataRange::new(0, 5_000_000).unwrap()),
                transaction_outputs: None,
            },
        };

        // This false advertisement will be accepted and aggregated
        // into the global data summary without any verification
        
        // When a bootstrapping node requests transactions starting from
        // version 0, it will select this Byzantine peer based on the
        // advertised range, but the peer cannot actually serve the data
        
        // Demonstrate the range check passes (peer appears serviceable)
        let requested_range = CompleteDataRange::new(0, 100).unwrap();
        let advertised_range = byzantine_summary
            .data_summary
            .transactions
            .unwrap();
        
        // This check passes, making the Byzantine peer appear serviceable
        assert!(advertised_range.superset_of(&requested_range));
        
        // But the peer doesn't actually have this data - it will fail when
        // the requesting node tries to fetch, causing bootstrap failure
        
        println!("Byzantine peer falsely claims to have genesis transactions!");
        println!("Advertised range: {:?}", advertised_range);
        println!("Peer will be selected for genesis requests but will fail to serve data");
    }
}
```

## Notes

This vulnerability is particularly concerning because:

1. **No Stake Required**: Unlike consensus attacks that require significant stake, any peer can advertise false data availability

2. **Archive Node Scarcity**: In mature networks, few nodes maintain full history from genesis, making Byzantine peers advertising genesis data especially attractive to bootstrapping nodes

3. **Bootstrapping Critical Path**: New validators and full nodes must bootstrap successfully to join the network, making this a critical attack surface

4. **Peer Selection Bias**: The system preferentially selects peers advertising the lowest transaction versions for historical queries, exactly where Byzantine peers can cause maximum disruption

The fix should balance security (verifying data availability) with performance (not requiring expensive proofs for every advertisement) and practicality (allowing efficient state sync).

### Citations

**File:** state-sync/storage-service/server/src/storage.rs (L179-192)
```rust
    fn fetch_transaction_range(
        &self,
        latest_version: Version,
    ) -> aptos_storage_service_types::Result<Option<CompleteDataRange<Version>>, Error> {
        let first_transaction_version = self.storage.get_first_txn_version()?;
        if let Some(first_transaction_version) = first_transaction_version {
            let transaction_range =
                CompleteDataRange::new(first_transaction_version, latest_version)
                    .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
            Ok(Some(transaction_range))
        } else {
            Ok(None)
        }
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L339-408)
```rust
    pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
        // Gather all storage summaries, but exclude peers that are ignored
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();

        // If we have no peers, return an empty global summary
        if storage_summaries.is_empty() {
            return GlobalDataSummary::empty();
        }

        // Calculate the global data summary using the advertised peer data
        let mut advertised_data = AdvertisedData::empty();
        let mut max_epoch_chunk_sizes = vec![];
        let mut max_state_chunk_sizes = vec![];
        let mut max_transaction_chunk_sizes = vec![];
        let mut max_transaction_output_chunk_sizes = vec![];
        for summary in storage_summaries {
            // Collect aggregate data advertisements
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
            if let Some(transactions) = summary.data_summary.transactions {
                advertised_data.transactions.push(transactions);
            }
            if let Some(transaction_outputs) = summary.data_summary.transaction_outputs {
                advertised_data
                    .transaction_outputs
                    .push(transaction_outputs);
            }

            // Collect preferred max chunk sizes
            max_epoch_chunk_sizes.push(summary.protocol_metadata.max_epoch_chunk_size);
            max_state_chunk_sizes.push(summary.protocol_metadata.max_state_chunk_size);
            max_transaction_chunk_sizes.push(summary.protocol_metadata.max_transaction_chunk_size);
            max_transaction_output_chunk_sizes
                .push(summary.protocol_metadata.max_transaction_output_chunk_size);
        }

        // Calculate optimal chunk sizes based on the advertised data
        let optimal_chunk_sizes = calculate_optimal_chunk_sizes(
            &self.data_client_config,
            max_epoch_chunk_sizes,
            max_state_chunk_sizes,
            max_transaction_chunk_sizes,
            max_transaction_output_chunk_sizes,
        );
        GlobalDataSummary {
            advertised_data,
            optimal_chunk_sizes,
        }
    }
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L211-224)
```rust
    pub fn lowest_transaction_version(&self) -> Option<Version> {
        get_lowest_version_from_range_set(&self.transactions)
    }
}

/// Returns the lowest version from the given set of data ranges
fn get_lowest_version_from_range_set(
    data_ranges: &[CompleteDataRange<Version>],
) -> Option<Version> {
    data_ranges
        .iter()
        .map(|data_range| data_range.lowest())
        .min()
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L665-686)
```rust
/// A summary of the data actually held by the storage service instance.
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct DataSummary {
    /// The ledger info corresponding to the highest synced version in storage.
    /// This indicates the highest version and epoch that storage can prove.
    pub synced_ledger_info: Option<LedgerInfoWithSignatures>,
    /// The range of epoch ending ledger infos in storage, e.g., if the range
    /// is [(X,Y)], it means all epoch ending ledger infos for epochs X->Y
    /// (inclusive) are held.
    pub epoch_ending_ledger_infos: Option<CompleteDataRange<Epoch>>,
    /// The range of states held in storage, e.g., if the range is
    /// [(X,Y)], it means all states are held for every version X->Y
    /// (inclusive).
    pub states: Option<CompleteDataRange<Version>>,
    /// The range of transactions held in storage, e.g., if the range is
    /// [(X,Y)], it means all transactions for versions X->Y (inclusive) are held.
    pub transactions: Option<CompleteDataRange<Version>>,
    /// The range of transaction outputs held in storage, e.g., if the range
    /// is [(X,Y)], it means all transaction outputs for versions X->Y
    /// (inclusive) are held.
    pub transaction_outputs: Option<CompleteDataRange<Version>>,
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L826-830)
```rust
    fn can_service_transactions(&self, desired_range: &CompleteDataRange<u64>) -> bool {
        self.transactions
            .map(|range| range.superset_of(desired_range))
            .unwrap_or(false)
    }
```

**File:** state-sync/aptos-data-client/src/client.rs (L675-701)
```rust
        // Wait for the first successful response and abort all other tasks.
        // If all requests fail, gather the errors and return them.
        let num_sent_requests = sent_requests.len();
        let mut sent_request_errors = vec![];
        for _ in 0..num_sent_requests {
            if let Ok(response_result) = sent_requests.select_next_some().await {
                match response_result {
                    Ok(response) => {
                        // We received a valid response. Abort all pending tasks.
                        for abort_handle in abort_handles {
                            abort_handle.abort();
                        }
                        return Ok(response); // Return the response
                    },
                    Err(error) => {
                        // Gather the error and continue waiting for a response
                        sent_request_errors.push(error)
                    },
                }
            }
        }

        // Otherwise, all requests failed and we should return an error
        Err(Error::DataIsUnavailable(format!(
            "All {} attempts failed for the given request: {:?}. Errors: {:?}",
            num_sent_requests, request, sent_request_errors
        )))
```
