# Audit Report

## Title
Indexer Concurrent Write Vulnerability: Missing Advisory Locks Allow Silent Data Overwrites and Non-Deterministic State

## Summary
The Aptos indexer lacks database-level locking mechanisms to prevent multiple instances from processing and writing the same MoveResource data simultaneously. This allows race conditions that result in non-deterministic `inserted_at` timestamps and potential silent data corruption through last-writer-wins semantics without validation.

## Finding Description

The MoveResource indexer uses an unconditional upsert strategy that overwrites existing records without data validation or advisory locks to prevent concurrent instance execution. [1](#0-0) 

The database insertion logic employs an upsert pattern that unconditionally updates conflicting records: [2](#0-1) 

The PRIMARY KEY constraint in the database schema only covers `(transaction_version, write_set_change_index)`: [3](#0-2) 

**Critical Issues:**

1. **No Advisory Locks**: The codebase contains no PostgreSQL advisory locks (`pg_advisory_lock`) or any mechanism to prevent multiple indexer instances from running concurrently against the same database and processor name.

2. **Unconditional Upsert**: Unlike other tables such as `current_table_items` which include WHERE clauses to validate updates, the `move_resources` upsert unconditionally overwrites `inserted_at` and `state_key_hash` on every conflict without checking if the data has actually changed. [4](#0-3) 

3. **Race Condition in Version Management**: The processor status update uses optimistic concurrency control but only after data has been written: [5](#0-4) 

4. **Read-Committed Isolation**: The system uses "read-committed" isolation level, not serializable, allowing phantom reads between the status check and data write operations.

**Attack Scenario:**
1. Operator deploys two indexer instances (e.g., during Kubernetes rolling update or for redundancy)
2. Both instances read `last_success_version = 1000` from processor_status
3. Both decide to process versions 1001-1500
4. Both fetch and process the same transactions
5. Instance A writes MoveResource at version 1001 with `inserted_at = T1`, `state_key_hash = H1`
6. Instance B writes the same MoveResource with `inserted_at = T2`, `state_key_hash = H2`
7. Result: Last writer wins, `inserted_at` reflects T2 (non-deterministic), and if there's any processing bug causing different `state_key_hash` values, corruption occurs silently

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty program: "State inconsistencies requiring intervention."

**Specific Impacts:**

1. **Non-Deterministic Timestamps**: The `inserted_at` field reflects whichever indexer instance wrote last, making forensics and debugging impossible. You cannot determine when data was originally indexed.

2. **Silent Data Corruption**: If any non-determinism exists in data processing (time-dependent logic, floating-point operations, concurrency bugs), the last writer silently overwrites correct data with potentially incorrect data, with no error or warning.

3. **Operational Blindness**: Database metrics and monitoring cannot detect when this race condition occurs, as upserts return success for both instances.

4. **State Consistency Violation**: Breaks the "State Consistency: State transitions must be atomic and verifiable" invariant, as the indexer state becomes non-reproducible.

While blockchain consensus is not directly affected (indexer is read-only), the indexer provides critical infrastructure for dApps, wallets, and explorers. Data corruption could lead to incorrect balance displays, missed transactions, or application failures.

## Likelihood Explanation

**High Likelihood** in production environments:

1. **Kubernetes Deployments**: Rolling updates create temporary periods where old and new pods both run, each believing it should process the next batch.

2. **Horizontal Scaling Attempts**: Operators trying to scale indexer for performance may accidentally run multiple instances with the same processor name.

3. **Deployment Race Conditions**: CI/CD pipelines deploying to multiple regions simultaneously.

4. **Manual Interventions**: Restarting an indexer while the previous instance is still committing its transaction.

5. **No Warning or Prevention**: The system provides no warnings, locks, or safeguards against this configuration error.

The configuration system shows no protection mechanism: [6](#0-5) 

## Recommendation

Implement PostgreSQL advisory locks to ensure only one indexer instance per processor name can run at a time:

```rust
// In tailer.rs, add at startup:
pub fn acquire_advisory_lock(&self, processor_name: &str) -> Result<()> {
    let mut conn = self.connection_pool.get()?;
    let lock_id = compute_lock_id(processor_name);
    
    let acquired: bool = diesel::sql_query(
        "SELECT pg_try_advisory_lock($1) as acquired"
    )
    .bind::<BigInt, _>(lock_id)
    .get_result(&mut conn)?;
    
    ensure!(acquired, "Another indexer instance is already running for processor '{}'", processor_name);
    Ok(())
}

fn compute_lock_id(processor_name: &str) -> i64 {
    use std::hash::{Hash, Hasher};
    let mut hasher = std::collections::hash_map::DefaultHasher::new();
    processor_name.hash(&mut hasher);
    hasher.finish() as i64
}
```

Additionally, add a WHERE clause to the move_resources upsert to prevent unnecessary updates:

```rust
fn insert_move_resources(
    conn: &mut PgConnection,
    items_to_insert: &[MoveResource],
) -> Result<(), diesel::result::Error> {
    use schema::move_resources::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), MoveResource::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::move_resources::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((transaction_version, write_set_change_index))
                .do_update()
                .set((
                    inserted_at.eq(excluded(inserted_at)),
                    state_key_hash.eq(excluded(state_key_hash)),
                )),
            Some(" WHERE move_resources.state_key_hash != excluded.state_key_hash "),
        )?;
    }
    Ok(())
}
```

## Proof of Concept

```bash
# Terminal 1: Start first indexer instance
export PROCESSOR_NAME="default_processor"
export INDEXER_DATABASE_URL="postgresql://user:pass@localhost/indexer"
cargo run --bin aptos-node -- --config config.yaml

# Terminal 2: While first is running, start second instance with same processor name
export PROCESSOR_NAME="default_processor"  # Same processor name!
export INDEXER_DATABASE_URL="postgresql://user:pass@localhost/indexer"
cargo run --bin aptos-node -- --config config.yaml

# Both instances will:
# 1. Read the same last_success_version from processor_status
# 2. Process the same transaction versions
# 3. Write to move_resources table concurrently
# 4. Last writer wins for inserted_at timestamp
# 5. No error occurs, but data is non-deterministic

# Verify the race condition:
psql $INDEXER_DATABASE_URL -c "
SELECT transaction_version, write_set_change_index, inserted_at, state_key_hash 
FROM move_resources 
WHERE transaction_version BETWEEN 1000 AND 1500 
ORDER BY inserted_at DESC 
LIMIT 10;
"
# inserted_at timestamps will reflect whichever instance wrote last
```

## Notes

The vulnerability is confined to the indexer component and does not affect blockchain consensus or validator operations. However, it represents a significant operational risk and data integrity issue. The lack of advisory locks means that production deployments using standard cloud orchestration patterns (Kubernetes, auto-scaling, rolling updates) are vulnerable to silent data corruption without any error indication.

### Citations

**File:** crates/indexer/src/models/move_resources.rs (L15-27)
```rust
pub struct MoveResource {
    pub transaction_version: i64,
    pub write_set_change_index: i64,
    pub transaction_block_height: i64,
    pub name: String,
    pub type_: String,
    pub address: String,
    pub module: String,
    pub generic_type_params: Option<serde_json::Value>,
    pub data: Option<serde_json::Value>,
    pub is_deleted: bool,
    pub state_key_hash: String,
}
```

**File:** crates/indexer/src/processors/default_processor.rs (L337-358)
```rust
fn insert_move_resources(
    conn: &mut PgConnection,
    items_to_insert: &[MoveResource],
) -> Result<(), diesel::result::Error> {
    use schema::move_resources::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), MoveResource::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::move_resources::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((transaction_version, write_set_change_index))
                .do_update()
                .set((
                    inserted_at.eq(excluded(inserted_at)),
                    state_key_hash.eq(excluded(state_key_hash)),
                )),
            None,
        )?;
    }
    Ok(())
}
```

**File:** crates/indexer/src/processors/default_processor.rs (L379-403)
```rust
fn insert_current_table_items(
    conn: &mut PgConnection,
    items_to_insert: &[CurrentTableItem],
) -> Result<(), diesel::result::Error> {
    use schema::current_table_items::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), CurrentTableItem::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::current_table_items::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((table_handle, key_hash))
                .do_update()
                .set((
                    key.eq(excluded(key)),
                    decoded_key.eq(excluded(decoded_key)),
                    decoded_value.eq(excluded(decoded_value)),
                    is_deleted.eq(excluded(is_deleted)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
                Some(" WHERE current_table_items.last_transaction_version <= excluded.last_transaction_version "),
        )?;
    }
    Ok(())
```

**File:** crates/indexer/migrations/2022-08-08-043603_core_tables/up.sql (L262-279)
```sql
CREATE TABLE move_resources (
  transaction_version BIGINT NOT NULL,
  write_set_change_index BIGINT NOT NULL,
  transaction_block_height BIGINT NOT NULL,
  name TEXT NOT NULL,
  address VARCHAR(66) NOT NULL,
  type TEXT NOT NULL,
  module TEXT NOT NULL,
  generic_type_params jsonb,
  data jsonb,
  is_deleted BOOLEAN NOT NULL,
  inserted_at TIMESTAMP NOT NULL DEFAULT NOW(),
  -- Constraints
  PRIMARY KEY (transaction_version, write_set_change_index),
  CONSTRAINT fk_transaction_versions FOREIGN KEY (transaction_version) REFERENCES transactions (version)
);
CREATE INDEX mr_addr_mod_name_ver_index ON move_resources (address, module, name, transaction_version);
CREATE INDEX mr_insat_index ON move_resources (inserted_at);
```

**File:** crates/indexer/src/indexer/tailer.rs (L170-191)
```rust
    pub fn update_last_processed_version(&self, processor_name: &str, version: u64) -> Result<()> {
        let mut conn = self.connection_pool.get()?;

        let status = ProcessorStatusV2 {
            processor: processor_name.to_owned(),
            last_success_version: version as i64,
        };
        execute_with_better_error(
            &mut conn,
            diesel::insert_into(processor_status::table)
                .values(&status)
                .on_conflict(processor_status::processor)
                .do_update()
                .set((
                    processor_status::last_success_version
                        .eq(excluded(processor_status::last_success_version)),
                    processor_status::last_updated.eq(excluded(processor_status::last_updated)),
                )),
            Some(" WHERE processor_status.last_success_version <= EXCLUDED.last_success_version "),
        )?;
        Ok(())
    }
```

**File:** config/src/config/indexer_config.rs (L25-90)
```rust
#[derive(Clone, Default, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct IndexerConfig {
    /// Whether the indexer is enabled or not
    /// Alternatively can set the `INDEXER_ENABLED` env var
    #[serde(default)]
    pub enabled: bool,

    /// Postgres database uri, ex: "postgresql://user:pass@localhost/postgres"
    /// Alternatively can set the `INDEXER_DATABASE_URL` env var
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub postgres_uri: Option<String>,

    /// The specific processor that it will run, ex: "token_processor"
    /// Alternatively can set the `PROCESSOR_NAME` env var
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub processor: Option<String>,

    /// If set, will ignore database contents and start processing from the specified version.
    /// This will not delete any database contents, just transactions as it reprocesses them.
    /// Alternatively can set the `STARTING_VERSION` env var
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub starting_version: Option<u64>,

    ///////////////////
    ///////////////////
    ///////////////////
    /// If set, don't run any migrations
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub skip_migrations: Option<bool>,

    /// If set, will make sure that we're indexing the right chain
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub check_chain_id: Option<bool>,

    /// How many versions to fetch and process from a node in parallel
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub batch_size: Option<u16>,

    /// How many tasks to run for fetching the transactions
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub fetch_tasks: Option<u8>,

    /// How many tasks to run for processing the transactions
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub processor_tasks: Option<u8>,

    /// How many versions to process before logging a "processed X versions" message.
    /// This will only be checked every `batch_size` number of versions.
    /// Set to 0 to disable.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub emit_every: Option<u64>,

    /// Indicates how many versions we should look back for gaps (default 1.5M versions, meaning
    /// we will only find gaps within MAX - 1.5M versions)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub gap_lookback_versions: Option<u64>,

    /// Which address does the ans contract live at. Only available for token_processor. If null, disable ANS indexing
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ans_contract_address: Option<String>,

    /// Custom NFT points contract
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub nft_points_contract: Option<String>,
}
```
