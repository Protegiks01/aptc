# Audit Report

## Title
Missing Reverse Range Validation in DBSubPruner Implementations Causes State Corruption

## Summary
Multiple `DBSubPruner` implementations fail to validate that `current_progress <= target_version` before pruning, allowing reverse ranges to silently corrupt pruner state by moving the progress metadata backward. This violates the state consistency invariant and can cause operational failures requiring manual intervention.

## Finding Description

The `DBSubPruner` trait defines a `prune()` method that accepts `current_progress` and `target_version` parameters without specifying validation requirements: [1](#0-0) 

Most implementations assume `current_progress < target_version` but fail to validate this invariant. When this assumption is violated during initialization (e.g., due to database inconsistency where sub-pruner progress exceeds metadata progress), the following vulnerable implementations silently process empty ranges and corrupt state:

**Vulnerable implementations:**

1. **WriteSetPruner**: Uses range iteration that produces empty range when `begin > end`: [2](#0-1) 

2. **TransactionInfoPruner**: Same pattern: [3](#0-2) 

3. **TransactionAuxiliaryDataPruner**: Same pattern: [4](#0-3) 

4. **PersistedAuxiliaryInfoPruner**: Same pattern: [5](#0-4) 

5. **TransactionAccumulatorPruner**: Same pattern: [6](#0-5) 

**Attack vector:**

During sub-pruner initialization, if `get_or_initialize_subpruner_progress()` returns a stored progress value higher than the current `metadata_progress`: [7](#0-6) 

The sub-pruner calls `prune(progress, metadata_progress)` where `progress > metadata_progress`: [8](#0-7) 

In Rust, `for version in begin..end` creates an **empty range** when `begin > end`, causing the loop to execute zero iterations. The method returns `Ok(())` without error, and the metadata gets updated to `target_version` (the **lower** value): [9](#0-8) 

**State corruption outcome:**
- Pruner progress moves backward from higher version to lower version
- Future pruning attempts reference incorrect progress baseline
- Can cause missing data errors when trying to re-prune already pruned ranges
- Requires manual database intervention to restore correct state

**Triggering scenarios:**
1. Database corruption causing metadata inconsistency
2. Partial database restore where `LedgerPrunerProgress` is rolled back but sub-pruner progress remains at higher version
3. Manual database manipulation errors
4. Software bugs that incorrectly update progress metadata

**Only safe implementation:** `TransactionPruner` explicitly validates the range: [10](#0-9) 

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Corrupted pruner metadata requires manual database fixes or node restart with corrected metadata
- **Operational disruption**: Affected nodes may experience pruning failures or data access errors
- **No direct fund loss**: Does not directly cause theft or minting of tokens
- **No consensus break**: Does not violate consensus safety, though repeated failures could affect liveness

The vulnerability breaks the **State Consistency** critical invariant: "State transitions must be atomic and verifiable via Merkle proofs." Corrupted pruner state creates metadata inconsistency that violates the assumption that pruning progress monotonically increases.

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires specific preconditions:
- Database state inconsistency where sub-pruner progress exceeds main pruner progress
- Node restart/initialization triggering the catch-up logic

While database corruption is rare in properly maintained systems, it can occur through:
- Hardware failures during write operations
- Software bugs in metadata management
- Operational errors during backup/restore procedures
- Race conditions in concurrent metadata updates (if present)

The impact is deterministic once the condition is met - every affected sub-pruner will corrupt its state during initialization.

## Recommendation

Add explicit range validation to all `DBSubPruner::prune()` implementations. The fix should mirror `TransactionPruner`'s approach:

```rust
// In WriteSetDb::prune()
pub(crate) fn prune(begin: Version, end: Version, db_batch: &mut SchemaBatch) -> Result<()> {
    ensure!(
        end >= begin,
        "Invalid pruning range: end ({}) must be >= begin ({})",
        end,
        begin
    );
    
    for version in begin..end {
        db_batch.delete::<WriteSetSchema>(&version)?;
    }
    Ok(())
}
```

Apply the same validation to:
- `TransactionInfoDb::prune()`
- `TransactionAuxiliaryDataDb::prune()`
- `PersistedAuxiliaryInfoDb::prune()`
- `TransactionAccumulatorDb::prune()`
- `EventDb::prune_event_indices()` and `prune_events()`

Additionally, consider adding validation at the trait level or in the sub-pruner `new()` constructors to detect and log (or fail fast) when metadata inconsistency is detected.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_schemadb::{SchemaBatch, DB};
    use aptos_temppath::TempPath;
    
    #[test]
    fn test_reverse_range_corruption() {
        // Setup test database
        let tmpdir = TempPath::new();
        let db = DB::open(tmpdir.path(), "test", &[]).unwrap();
        
        // Simulate reverse range scenario
        let current_progress: Version = 100;
        let target_version: Version = 50;
        let mut batch = SchemaBatch::new();
        
        // This should fail but currently succeeds with empty iteration
        let result = WriteSetDb::prune(current_progress, target_version, &mut batch);
        
        // Current behavior: returns Ok(()) with no pruning
        assert!(result.is_ok());
        
        // Metadata would be updated to 50 (backward movement)
        // This corrupts the pruner state
        
        // Expected behavior: should return error
        // assert!(result.is_err());
        // assert!(result.unwrap_err().to_string().contains("Invalid pruning range"));
    }
}
```

**Notes:**
The vulnerability is present in the current codebase and represents a defensive programming gap. While the normal pruning flow through `LedgerPruner::prune()` prevents reverse ranges via its while-loop condition, the catch-up logic during initialization lacks this protection. Adding explicit validation provides defense-in-depth against database corruption scenarios and makes the code more robust against future refactoring that might bypass the normal flow.

### Citations

**File:** storage/aptosdb/src/pruner/db_sub_pruner.rs (L6-14)
```rust
/// Defines the trait for sub-pruner of a parent DB pruner
pub trait DBSubPruner {
    /// Returns the name of the sub pruner.
    fn name(&self) -> &str;

    /// Performs the actual pruning, a target version is passed, which is the target the pruner
    /// tries to prune.
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()>;
}
```

**File:** storage/aptosdb/src/ledger_db/write_set_db.rs (L158-163)
```rust
    pub(crate) fn prune(begin: Version, end: Version, db_batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            db_batch.delete::<WriteSetSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_info_db.rs (L95-100)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<TransactionInfoSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_auxiliary_data_db.rs (L74-79)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<TransactionAuxiliaryDataSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/persisted_auxiliary_info_db.rs (L121-126)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<PersistedAuxiliaryInfoSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_accumulator_db.rs (L149-164)
```rust
    pub(crate) fn prune(begin: Version, end: Version, db_batch: &mut SchemaBatch) -> Result<()> {
        for version_to_delete in begin..end {
            db_batch.delete::<TransactionAccumulatorRootHashSchema>(&version_to_delete)?;
            // The even version will be pruned in the iteration of version + 1.
            if version_to_delete % 2 == 0 {
                continue;
            }

            let first_ancestor_that_is_a_left_child =
                Self::find_first_ancestor_that_is_a_left_child(version_to_delete);

            // This assertion is true because we skip the leaf nodes with address which is a
            // a multiple of 2.
            assert!(!first_ancestor_that_is_a_left_child.is_leaf());

            let mut current = first_ancestor_that_is_a_left_child;
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/write_set_pruner.rs (L25-33)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        WriteSetDb::prune(current_progress, target_version, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::WriteSetPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        self.ledger_db.write_set_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/write_set_pruner.rs (L36-58)
```rust
impl WriteSetPruner {
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.write_set_db_raw(),
            &DbMetadataKey::WriteSetPrunerProgress,
            metadata_progress,
        )?;

        let myself = WriteSetPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up WriteSetPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L106-131)
```rust
    fn get_pruning_candidate_transactions(
        &self,
        start: Version,
        end: Version,
    ) -> Result<Vec<(Version, Transaction)>> {
        ensure!(end >= start, "{} must be >= {}", end, start);

        let mut iter = self
            .ledger_db
            .transaction_db_raw()
            .iter::<TransactionSchema>()?;
        iter.seek(&start)?;

        // The capacity is capped by the max number of txns we prune in a single batch. It's a
        // relatively small number set in the config, so it won't cause high memory usage here.
        let mut txns = Vec::with_capacity((end - start) as usize);
        for item in iter {
            let (version, txn) = item?;
            if version >= end {
                break;
            }
            txns.push((version, txn));
        }

        Ok(txns)
    }
```
