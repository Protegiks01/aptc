# Audit Report

## Title
Connection State Desynchronization Vulnerability in Peer Metadata Management During Rapid Disconnect-Reconnect Cycles

## Summary
The `insert_connection_metadata()` function in `PeersAndMetadata` fails to reset the `connection_state` field when updating existing peer metadata, allowing peers to remain in stale states (e.g., `Disconnecting` or `Disconnected`) despite having active connections. This creates a race condition exploitable during rapid disconnect-reconnect cycles, causing connected peers to be invisible to critical network protocols including consensus observers.

## Finding Description

The vulnerability exists in the production peer metadata management system and is **masked** by the inadequate test utility's `disconnect()` implementation. The issue manifests through two interconnected flaws:

**Flaw 1: Test Utility Inadequacy**

The test utility's `disconnect()` function only updates `ConnectionState` without performing the full cleanup that production code requires. [1](#0-0) 

Production disconnect handling, by contrast, completely removes peer metadata: [2](#0-1) [3](#0-2) 

**Flaw 2: Connection State Not Reset on Reconnection (Production Bug)**

The production `insert_connection_metadata()` function uses `and_modify` which **only** updates the `connection_metadata` field when a peer entry already exists, but does **NOT** reset the `connection_state`: [4](#0-3) 

Note that `or_insert_with` creates a new `PeerMetadata` with `ConnectionState::Connected`, but `and_modify` leaves the state unchanged: [5](#0-4) 

**Attack Scenario:**

1. A peer is connected with `connection_id: 1`, `state: Connected`
2. Health checker detects failure and sets `state: Disconnecting` for this peer: [6](#0-5) 

3. Before disconnect completes, the **same peer** reconnects with `connection_id: 2`
4. `PeerManager::add_peer` handles simultaneous dial by removing old connection from `active_peers` but **not** from `peers_and_metadata`: [7](#0-6) 

5. `insert_connection_metadata` is called for the new connection (line 684-687), but the peer entry still exists with old state `Disconnecting`
6. `and_modify` closure executes, updating `connection_metadata` (including new `connection_id: 2`) but **leaving** `connection_state: Disconnecting`
7. The peer is now **actually connected** but appears disconnected to all applications

**Impact on Consensus Observer:**

The consensus observer relies on `get_connected_peers_and_metadata()` which filters by `is_connected()`: [8](#0-7) 

Peers stuck in `Disconnecting` state return `false` from `is_connected()`: [9](#0-8) 

This causes the consensus observer to:
- Not create subscriptions to affected peers
- Potentially fail to maintain minimum subscription count
- Risk consensus liveness issues

## Impact Explanation

**Severity: Medium** (per Aptos bug bounty criteria: "State inconsistencies requiring intervention")

This vulnerability causes:

1. **State Consistency Violation**: Peer metadata becomes desynchronized from actual connection state
2. **Protocol Invisibility**: Connected peers become invisible to critical protocols (consensus observer, peer monitoring, state sync)
3. **Resource Accumulation**: Repeated disconnect-reconnect cycles can accumulate stale metadata entries
4. **Consensus Liveness Risk**: If enough validator peers enter this state, consensus observer subscriptions fail, potentially affecting block propagation

The impact is **not** Critical because it doesn't directly cause fund loss or total network failure, but requires manual intervention to recover affected nodes.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is **highly likely** to occur because:

1. **Natural Network Conditions**: Network instability, health check failures, and reconnections are common in production
2. **No Special Access Required**: Any peer can trigger this by normal disconnect-reconnect behavior
3. **Race Window**: The race condition window exists between health checker setting `Disconnecting` and the actual disconnect completing
4. **Amplification**: Malicious peers can intentionally trigger rapid disconnect-reconnect cycles to accumulate affected peers
5. **Test Coverage Gap**: The inadequate test utility means this bug is **never tested** in integration tests

## Recommendation

**Fix 1: Correct `insert_connection_metadata` to reset connection state**

Modify the `and_modify` closure to reset `connection_state` when updating existing peer metadata:

```rust
// In network/framework/src/application/storage.rs, line 199-204
peer_metadata_for_network
    .entry(peer_network_id.peer_id())
    .and_modify(|peer_metadata| {
        peer_metadata.connection_metadata = connection_metadata.clone();
        peer_metadata.connection_state = ConnectionState::Connected;  // ADD THIS LINE
    })
    .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));
```

**Fix 2: Improve test utility to match production behavior**

Modify the test utility's `disconnect()` to properly remove peer metadata:

```rust
// In network/framework/src/testutils/test_node.rs
pub fn disconnect(
    &self,
    self_peer_network_id: PeerNetworkId,
    conn_metadata: ConnectionMetadata,
) {
    let network_id = self_peer_network_id.network_id();
    let peer_network_id = PeerNetworkId::new(network_id, conn_metadata.remote_peer_id);
    
    // Remove peer metadata entirely (matching production behavior)
    let _ = self.peers_and_metadata
        .remove_peer_metadata(peer_network_id, conn_metadata.connection_id);
}
```

**Fix 3: Add explicit connection_id validation**

In `insert_connection_metadata`, verify connection_ids don't conflict to prevent races:

```rust
.and_modify(|peer_metadata| {
    // Only update if this is actually a new connection
    if peer_metadata.connection_metadata.connection_id != connection_metadata.connection_id {
        peer_metadata.connection_metadata = connection_metadata.clone();
        peer_metadata.connection_state = ConnectionState::Connected;
    }
})
```

## Proof of Concept

```rust
// Add this test to network/framework/src/application/tests.rs

#[tokio::test]
async fn test_reconnect_during_disconnect_resets_state() {
    use crate::application::metadata::ConnectionState;
    use crate::transport::ConnectionOrigin;
    
    let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Validator]);
    let peer_id = PeerId::random();
    let peer_network_id = PeerNetworkId::new(NetworkId::Validator, peer_id);
    
    // Step 1: Connect peer with connection_id 1
    let conn_meta_1 = ConnectionMetadata::mock_with_role_and_origin(
        peer_id,
        PeerRole::Validator,
        ConnectionOrigin::Outbound,
    );
    let connection_id_1 = conn_meta_1.connection_id;
    
    peers_and_metadata
        .insert_connection_metadata(peer_network_id, conn_meta_1.clone())
        .unwrap();
    
    // Step 2: Set state to Disconnecting (simulating health check)
    peers_and_metadata
        .update_connection_state(peer_network_id, ConnectionState::Disconnecting)
        .unwrap();
    
    // Step 3: Reconnect with new connection_id BEFORE disconnect completes
    let conn_meta_2 = ConnectionMetadata::mock_with_role_and_origin(
        peer_id,
        PeerRole::Validator,
        ConnectionOrigin::Outbound,
    );
    let connection_id_2 = conn_meta_2.connection_id;
    assert_ne!(connection_id_1, connection_id_2);
    
    peers_and_metadata
        .insert_connection_metadata(peer_network_id, conn_meta_2.clone())
        .unwrap();
    
    // Step 4: Verify the bug - peer should be Connected, but is still Disconnecting
    let metadata = peers_and_metadata
        .get_metadata_for_peer(peer_network_id)
        .unwrap();
    
    // BUG: connection_state is still Disconnecting even though peer reconnected!
    assert_eq!(metadata.connection_state, ConnectionState::Disconnecting);
    assert_eq!(metadata.connection_metadata.connection_id, connection_id_2);
    
    // This causes is_connected() to return false for a connected peer
    assert!(!metadata.is_connected()); // BUG: Should be true!
    
    // Connected peers with stale Disconnecting state are invisible to protocols
    let connected_peers = peers_and_metadata
        .get_connected_peers_and_metadata()
        .unwrap();
    assert!(!connected_peers.contains_key(&peer_network_id)); // BUG: Peer is missing!
}
```

## Notes

This vulnerability demonstrates how inadequate test utilities can mask critical production bugs. The test utility's `disconnect()` never triggers the production cleanup path, meaning tests never validate that `connection_state` is properly reset during reconnection. The bug exists in **production code** (`storage.rs`), affects **critical protocols** (consensus observer), and is **exploitable** through natural network conditions or malicious behavior.

The `ConnectionState::Disconnected` state even has a comment indicating it's "Currently unused" [10](#0-9) , further evidence that the disconnect cleanup path is not properly tested.

### Citations

**File:** network/framework/src/testutils/test_node.rs (L62-74)
```rust
    pub fn disconnect(
        &self,
        self_peer_network_id: PeerNetworkId,
        conn_metadata: ConnectionMetadata,
    ) {
        let network_id = self_peer_network_id.network_id();

        // Set the state of the peer as disconnected
        let peer_network_id = PeerNetworkId::new(network_id, conn_metadata.remote_peer_id);
        self.peers_and_metadata
            .update_connection_state(peer_network_id, ConnectionState::Disconnected)
            .unwrap();
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L275-296)
```rust
            TransportNotification::Disconnected(lost_conn_metadata, reason) => {
                // See: https://github.com/aptos-labs/aptos-core/issues/3128#issuecomment-605351504 for
                // detailed reasoning on `Disconnected` events should be handled correctly.
                info!(
                    NetworkSchema::new(&self.network_context)
                        .connection_metadata_with_address(&lost_conn_metadata),
                    disconnection_reason = reason,
                    "{} Connection {} closed due to {}",
                    self.network_context,
                    lost_conn_metadata,
                    reason
                );
                let peer_id = lost_conn_metadata.remote_peer_id;
                // If the active connection with the peer is lost, remove it from `active_peers`.
                if let Entry::Occupied(entry) = self.active_peers.entry(peer_id) {
                    let (conn_metadata, _) = entry.get();
                    let connection_id = conn_metadata.connection_id;
                    if connection_id == lost_conn_metadata.connection_id {
                        // We lost an active connection.
                        entry.remove();
                        self.remove_peer_from_metadata(peer_id, connection_id);
                    }
```

**File:** network/framework/src/peer_manager/mod.rs (L407-420)
```rust
    fn remove_peer_from_metadata(&mut self, peer_id: AccountAddress, connection_id: ConnectionId) {
        let peer_network_id = PeerNetworkId::new(self.network_context.network_id(), peer_id);
        if let Err(error) = self
            .peers_and_metadata
            .remove_peer_metadata(peer_network_id, connection_id)
        {
            warn!(
                NetworkSchema::new(&self.network_context),
                "Failed to remove peer from peers and metadata. Peer: {:?}, error: {:?}",
                peer_network_id,
                error
            );
        }
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L626-655)
```rust
        if let Entry::Occupied(active_entry) = self.active_peers.entry(peer_id) {
            let (curr_conn_metadata, _) = active_entry.get();
            if Self::simultaneous_dial_tie_breaking(
                self.network_context.peer_id(),
                peer_id,
                curr_conn_metadata.origin,
                conn_meta.origin,
            ) {
                let (_, peer_handle) = active_entry.remove();
                // Drop the existing connection and replace it with the new connection
                drop(peer_handle);
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing existing connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                send_new_peer_notification = false;
            } else {
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing incoming connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                // Drop the new connection and keep the one already stored in active_peers
                self.disconnect(connection);
                return Ok(());
            }
        }
```

**File:** network/framework/src/application/storage.rs (L199-204)
```rust
        peer_metadata_for_network
            .entry(peer_network_id.peer_id())
            .and_modify(|peer_metadata| {
                peer_metadata.connection_metadata = connection_metadata.clone()
            })
            .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));
```

**File:** network/framework/src/application/metadata.rs (L17-17)
```rust
    Disconnected, // Currently unused (TODO: fix this!)
```

**File:** network/framework/src/application/metadata.rs (L29-35)
```rust
    pub fn new(connection_metadata: ConnectionMetadata) -> Self {
        PeerMetadata {
            connection_state: ConnectionState::Connected,
            connection_metadata,
            peer_monitoring_metadata: PeerMonitoringMetadata::default(),
        }
    }
```

**File:** network/framework/src/application/metadata.rs (L50-53)
```rust
    /// Returns true iff the peer is still connected
    pub fn is_connected(&self) -> bool {
        self.connection_state == ConnectionState::Connected
    }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L65-81)
```rust
    pub async fn disconnect_peer(
        &mut self,
        peer_network_id: PeerNetworkId,
        disconnect_reason: DisconnectReason,
    ) -> Result<(), Error> {
        // Possibly already disconnected, but try anyways
        let _ = self.update_connection_state(peer_network_id, ConnectionState::Disconnecting);
        let result = self
            .network_client
            .disconnect_from_peer(peer_network_id, disconnect_reason)
            .await;
        let peer_id = peer_network_id.peer_id();
        if result.is_ok() {
            self.health_check_data.write().remove(&peer_id);
        }
        result
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L105-175)
```rust
    /// Checks the health of the active subscriptions. If any subscription is
    /// unhealthy, it will be terminated and new subscriptions will be created.
    /// This returns an error iff all subscriptions were unhealthy and terminated.
    pub async fn check_and_manage_subscriptions(&mut self) -> Result<(), Error> {
        // Get the subscription and connected peers
        let initial_subscription_peers = self.get_active_subscription_peers();
        let connected_peers_and_metadata = self.get_connected_peers_and_metadata();

        // Terminate any unhealthy subscriptions
        let terminated_subscriptions =
            self.terminate_unhealthy_subscriptions(&connected_peers_and_metadata);

        // Check if all subscriptions were terminated
        let num_terminated_subscriptions = terminated_subscriptions.len();
        let all_subscriptions_terminated = num_terminated_subscriptions > 0
            && num_terminated_subscriptions == initial_subscription_peers.len();

        // Calculate the number of new subscriptions to create
        let remaining_subscription_peers = self.get_active_subscription_peers();
        let max_concurrent_subscriptions =
            self.consensus_observer_config.max_concurrent_subscriptions as usize;
        let num_subscriptions_to_create =
            max_concurrent_subscriptions.saturating_sub(remaining_subscription_peers.len());

        // Update the total subscription metrics
        update_total_subscription_metrics(&remaining_subscription_peers);

        // Spawn a task to create the new subscriptions (asynchronously)
        self.spawn_subscription_creation_task(
            num_subscriptions_to_create,
            remaining_subscription_peers,
            terminated_subscriptions,
            connected_peers_and_metadata,
        )
        .await;

        // Return an error if all subscriptions were terminated
        if all_subscriptions_terminated {
            Err(Error::SubscriptionsReset(format!(
                "All {:?} subscriptions were unhealthy and terminated!",
                num_terminated_subscriptions,
            )))
        } else {
            Ok(())
        }
    }

    /// Returns the currently active subscription peers
    fn get_active_subscription_peers(&self) -> Vec<PeerNetworkId> {
        let active_observer_subscriptions = self.active_observer_subscriptions.lock();
        active_observer_subscriptions.keys().cloned().collect()
    }

    /// Gets the connected peers and metadata. If an error
    /// occurred, it is logged and an empty map is returned.
    fn get_connected_peers_and_metadata(&self) -> HashMap<PeerNetworkId, PeerMetadata> {
        self.consensus_observer_client
            .get_peers_and_metadata()
            .get_connected_peers_and_metadata()
            .unwrap_or_else(|error| {
                // Log the error
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to get connected peers and metadata! Error: {:?}",
                        error
                    ))
                );

                // Return an empty map
                HashMap::new()
            })
```
