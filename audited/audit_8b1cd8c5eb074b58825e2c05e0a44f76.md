# Audit Report

## Title
Configuration Validation Failure Leads to Infinite Loop and Resource Exhaustion in State KV Pruner

## Summary
The `StateKvPrunerManager::new()` function does not validate that `LedgerPrunerConfig.batch_size` is non-zero when `enable=true`. This allows a misconfigured pruner to enter an infinite loop, causing 100% CPU consumption and eventual node failure due to storage exhaustion.

## Finding Description

The `LedgerPrunerConfig` structure lacks validation to ensure that contradictory settings are rejected during initialization. Specifically, when a node operator configures the state KV pruner with `enable=true` but `batch_size=0`, the system accepts this invalid configuration and proceeds to initialize the pruner. [1](#0-0) 

The configuration sanitizer validates prune windows and offset values but does not check `batch_size`: [2](#0-1) 

When the pruner is initialized with `batch_size=0`, it creates a `PrunerWorker` that passes this zero value to the pruner: [3](#0-2) 

The `PrunerWorker` thread repeatedly calls `self.pruner.prune(self.batch_size)` with the zero batch_size: [4](#0-3) 

In `StateKvPruner::prune()`, when `max_versions` (batch_size) is 0, the pruning loop calculates `current_batch_target_version = min(progress + 0, target_version) = progress`, causing progress to never advance: [5](#0-4) 

This creates an infinite loop where:
1. `progress < target_version` remains true
2. `current_batch_target_version` equals `progress` (line 57)
3. Pruning work is performed with identical start and end versions
4. `progress` is set to `current_batch_target_version` (line 80), which equals the old `progress`
5. Loop repeats indefinitely

The same vulnerability exists in `LedgerPruner`: [6](#0-5) 

## Impact Explanation

**Medium Severity** - This issue meets the criteria for Medium severity:

1. **Resource Exhaustion**: The pruner thread consumes 100% CPU in a tight infinite loop, degrading node performance
2. **Storage Exhaustion**: Since pruning never completes, old versions accumulate indefinitely until storage is exhausted
3. **Node Availability Loss**: The affected node eventually becomes non-functional and may crash
4. **State Inconsistencies**: The node's state diverges from the network as it fails to prune properly

This maps to "State inconsistencies requiring intervention" (Medium) and potentially "Validator node slowdowns" (High), but is classified as Medium because it requires operator configuration access rather than being exploitable by external attackers.

## Likelihood Explanation

**Low to Medium Likelihood**:

- **Requires operator access**: An attacker would need access to node configuration files or the ability to influence operator configuration decisions
- **Not the default**: The default `batch_size` is 5,000, so this requires explicit misconfiguration
- **Realistic operator error**: Node operators may set `batch_size=0` thinking it disables batching or optimizes performance
- **No runtime detection**: The node starts successfully and only fails when pruning is triggered
- **Silent failure mode**: The issue manifests gradually as CPU usage increases and storage fills

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Recommendation

Add validation in the `ConfigSanitizer` implementation to reject invalid `batch_size` values when pruning is enabled:

```rust
// In config/src/config/storage_config.rs, in the sanitize() function
// Add after line 728:

if config.storage_pruner_config.ledger_pruner_config.enable
    && config.storage_pruner_config.ledger_pruner_config.batch_size == 0
{
    return Err(Error::ConfigSanitizerFailed(
        sanitizer_name,
        "ledger_pruner_config.batch_size must be greater than 0 when pruning is enabled.".to_string(),
    ));
}

if config.storage_pruner_config.state_merkle_pruner_config.enable
    && config.storage_pruner_config.state_merkle_pruner_config.batch_size == 0
{
    return Err(Error::ConfigSanitizerFailed(
        sanitizer_name,
        "state_merkle_pruner_config.batch_size must be greater than 0 when pruning is enabled.".to_string(),
    ));
}

if config.storage_pruner_config.epoch_snapshot_pruner_config.enable
    && config.storage_pruner_config.epoch_snapshot_pruner_config.batch_size == 0
{
    return Err(Error::ConfigSanitizerFailed(
        sanitizer_name,
        "epoch_snapshot_pruner_config.batch_size must be greater than 0 when pruning is enabled.".to_string(),
    ));
}
```

Alternatively, add defensive checks in the pruner initialization to panic early with a clear error message if `batch_size` is 0 when the pruner is enabled.

## Proof of Concept

Create a test configuration file that triggers the vulnerability:

```rust
#[test]
fn test_invalid_batch_size_rejected() {
    use crate::config::{ConfigSanitizer, NodeConfig, StorageConfig};
    
    let mut node_config = NodeConfig::default();
    
    // Configure pruner with enable=true and batch_size=0
    node_config.storage.storage_pruner_config.ledger_pruner_config.enable = true;
    node_config.storage.storage_pruner_config.ledger_pruner_config.batch_size = 0;
    
    // This should fail validation
    let result = StorageConfig::sanitize(&node_config, NodeType::Validator, None);
    
    assert!(result.is_err(), "Configuration with enable=true and batch_size=0 should be rejected");
}
```

To reproduce the infinite loop behavior, create a minimal test that initializes a pruner with zero batch_size and sets a target version, then observe the CPU usage spike as the pruner thread enters an infinite loop.

## Notes

This vulnerability affects all three pruner types that share the same configuration pattern:
1. **StateKvPruner** (in state_kv_pruner/mod.rs)
2. **LedgerPruner** (in ledger_pruner/mod.rs)  
3. Potentially **StateMerklePruner** (uses different logic but should be audited)

The `NO_OP_STORAGE_PRUNER_CONFIG` constant correctly sets `batch_size=0` when `enable=false`, which is safe because the pruner worker is never created in that case. The vulnerability only manifests when both `enable=true` AND `batch_size=0`.

### Citations

**File:** config/src/config/storage_config.rs (L325-341)
```rust
#[derive(Clone, Copy, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct LedgerPrunerConfig {
    /// Boolean to enable/disable the ledger pruner. The ledger pruner is responsible for pruning
    /// everything else except for states (e.g. transactions, events etc.)
    pub enable: bool,
    /// This is the default pruning window for any other store except for state store. State store
    /// being big in size, we might want to configure a smaller window for state store vs other
    /// store.
    pub prune_window: u64,
    /// Batch size of the versions to be sent to the ledger pruner - this is to avoid slowdown due to
    /// issuing too many DB calls and batch prune instead. For ledger pruner, this means the number
    /// of versions to prune a time.
    pub batch_size: usize,
    /// The offset for user pruning window to adjust
    pub user_pruning_window_offset: u64,
}
```

**File:** config/src/config/storage_config.rs (L682-728)
```rust
impl ConfigSanitizer for StorageConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let config = &node_config.storage;

        let ledger_prune_window = config
            .storage_pruner_config
            .ledger_pruner_config
            .prune_window;
        let state_merkle_prune_window = config
            .storage_pruner_config
            .state_merkle_pruner_config
            .prune_window;
        let epoch_snapshot_prune_window = config
            .storage_pruner_config
            .epoch_snapshot_pruner_config
            .prune_window;
        let user_pruning_window_offset = config
            .storage_pruner_config
            .ledger_pruner_config
            .user_pruning_window_offset;

        if ledger_prune_window < 50_000_000 {
            warn!("Ledger prune_window is too small, harming network data availability.");
        }
        if state_merkle_prune_window < 100_000 {
            warn!("State Merkle prune_window is too small, node might stop functioning.");
        }
        if epoch_snapshot_prune_window < 50_000_000 {
            warn!("Epoch snapshot prune_window is too small, harming network data availability.");
        }
        if user_pruning_window_offset > 1_000_000 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "user_pruning_window_offset too large, so big a buffer is unlikely necessary. Set something < 1 million.".to_string(),
            ));
        }
        if user_pruning_window_offset > ledger_prune_window {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "user_pruning_window_offset is larger than the ledger prune window, the API will refuse to return any data.".to_string(),
            ));
        }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_pruner_manager.rs (L84-108)
```rust
    pub fn new(state_kv_db: Arc<StateKvDb>, state_kv_pruner_config: LedgerPrunerConfig) -> Self {
        let pruner_worker = if state_kv_pruner_config.enable {
            Some(Self::init_pruner(
                Arc::clone(&state_kv_db),
                state_kv_pruner_config,
            ))
        } else {
            None
        };

        let min_readable_version =
            pruner_utils::get_state_kv_pruner_progress(&state_kv_db).expect("Must succeed.");

        PRUNER_VERSIONS
            .with_label_values(&["state_kv_pruner", "min_readable"])
            .set(min_readable_version as i64);

        Self {
            state_kv_db,
            prune_window: state_kv_pruner_config.prune_window,
            pruner_worker,
            pruning_batch_size: state_kv_pruner_config.batch_size,
            min_readable_version: AtomicVersion::new(min_readable_version),
        }
    }
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L52-69)
```rust
    // Loop that does the real pruning job.
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L49-86)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_pruner__prune"]);

        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning state kv data."
            );
            self.metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.shard_pruners.par_iter().try_for_each(|shard_pruner| {
                    shard_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| {
                            anyhow!(
                                "Failed to prune state kv shard {}: {err}",
                                shard_pruner.shard_id(),
                            )
                        })
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning state kv data is done.");
        }

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L62-89)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning ledger data."
            );
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning ledger data is done.");
        }
```
