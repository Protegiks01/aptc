# Audit Report

## Title
Missing Batch Metadata Validation in SignedBatchInfo Verification Enables DoS Attack

## Summary
The quorum store protocol lacks validation that `num_txns` and `num_bytes` in received `SignedBatchInfo` messages match the actual stored batch. A malicious validator can create a `SignedBatchInfo` with falsified transaction counts for an existing batch, obtain signatures from honest validators, and generate a `ProofOfStore` that passes proposal validation but fails during execution, causing network disruption.

## Finding Description

The vulnerability exists in the quorum store's batch proof aggregation flow. When validators receive `SignedBatchInfo` messages to aggregate signatures for proof-of-store creation, they only verify that a batch with the specified digest exists locally, without validating that the claimed `num_txns` and `num_bytes` match the actual batch. [1](#0-0) 

The `init_proof()` function checks:
1. The batch author matches the local peer ID
2. A batch with the digest exists in the batch reader
3. The batch author matches

**Missing validation**: It never verifies that `batch_info.num_txns()` or `batch_info.num_bytes()` match the actual stored batch's transaction count and size.

**Attack Flow:**

1. **Batch Creation**: Malicious validator creates and broadcasts a legitimate batch with 10 transactions (digest D, actual num_txns=10)

2. **Batch Storage**: Honest validators receive the batch via `BatchMsg`, which correctly verifies the payload matches metadata: [2](#0-1) 

3. **Falsified SignedBatchInfo**: Malicious validator creates a NEW `BatchInfo` with:
   - Same digest D (hash of the actual 10-transaction payload)
   - Falsified `num_txns = 10000` (100x inflation)
   - Falsified `num_bytes` to match the claimed transaction count
   - Valid signature over this falsified `BatchInfo`

4. **Signature Collection**: Malicious validator sends this falsified `SignedBatchInfo` to honest validators. They verify it passes `init_proof()` checks (batch with digest D exists) and sign it, not realizing the metadata is false.

5. **ProofOfStore Creation**: With enough signatures, a `ProofOfStore` is created with `num_txns=10000`

6. **Proposal Validation**: When included in a proposal, validators check: [3](#0-2) 

   If `10000 <= max_receiving_block_txns`, validation passes.

7. **Execution Failure**: During block execution, when transactions are fetched: [4](#0-3) 

   The `verify_with_digest()` call checks that actual payload matches claimed metadata. The verification fails because 10 â‰  10000, causing execution to fail.

This breaks **Deterministic Execution** (invariant #1) and **Consensus Safety** (invariant #2) by allowing proposals that different validators cannot execute consistently.

## Impact Explanation

**Severity: High**

This vulnerability enables a **Denial of Service attack** against the consensus protocol:

1. **Validator Node Slowdowns**: Failed batch fetches delay block execution
2. **Significant Protocol Violation**: Proposals pass validation but fail execution, violating the expectation that validated proposals can be executed
3. **Network Disruption**: Repeated attacks can cause sustained execution failures

The attack can also cause:
- **Resource Exhaustion**: Inflated `num_txns` values affect batch selection logic in proposal generation: [5](#0-4) 

  Using falsified counts, attackers can prevent legitimate batches from being included by artificially inflating the transaction count calculation.

- **Consensus Liveness Impact**: If the malicious validator is frequently selected as proposer, they can systematically create failing proposals.

This qualifies for **High Severity ($50,000)** under the bug bounty program's criteria for "Validator node slowdowns" and "Significant protocol violations."

## Likelihood Explanation

**Likelihood: High**

The attack is highly feasible:

1. **Single Malicious Validator**: Only requires ONE Byzantine validator, well within the < 1/3 Byzantine fault tolerance assumption
2. **No Special Resources**: Uses standard quorum store protocol operations
3. **Easy to Execute**: Attacker just needs to:
   - Create normal batches (already part of validator duties)
   - Manually construct `BatchInfo` with false metadata
   - Use existing signing and broadcast mechanisms
4. **Hard to Detect**: The falsified `BatchInfo` has a valid signature and passes all validation checks until execution time
5. **Repeatable**: Attack can be repeated indefinitely for sustained disruption

## Recommendation

Add metadata validation in `ProofCoordinator::init_proof()` to verify the claimed `num_txns` and `num_bytes` match the actual stored batch:

```rust
fn init_proof(
    &mut self,
    signed_batch_info: &SignedBatchInfo<BatchInfoExt>,
) -> Result<(), SignedBatchInfoError> {
    // Existing checks
    if signed_batch_info.author() != self.peer_id {
        return Err(SignedBatchInfoError::WrongAuthor);
    }
    
    // Get the stored batch to validate metadata
    let stored_batch = self
        .batch_reader
        .get_batch_from_local(signed_batch_info.digest())
        .map_err(|_| SignedBatchInfoError::NotFound)?;
    
    // NEW: Validate num_txns and num_bytes match
    if stored_batch.num_txns() != signed_batch_info.num_txns() {
        return Err(SignedBatchInfoError::WrongInfo((
            stored_batch.num_txns(),
            signed_batch_info.num_txns(),
        )));
    }
    
    if stored_batch.num_bytes() != signed_batch_info.num_bytes() {
        return Err(SignedBatchInfoError::WrongInfo((
            stored_batch.num_bytes(),
            signed_batch_info.num_bytes(),
        )));
    }
    
    let batch_author = stored_batch.author();
    if batch_author != signed_batch_info.author() {
        return Err(SignedBatchInfoError::WrongAuthor);
    }
    
    // Rest of existing logic...
}
```

## Proof of Concept

**Rust reproduction steps:**

1. Set up a test network with multiple validators
2. Have validator A create a batch with 10 transactions
3. Broadcast and store the batch normally (digest D)
4. Validator A manually constructs a `BatchInfo` with:
   - Same digest D
   - `num_txns = 10000`
   - `num_bytes = 10000000`
5. Validator A signs this to create `SignedBatchInfo`
6. Send to validator B, which calls `init_proof()`
7. Observe that init_proof() succeeds (no metadata check)
8. Validator B signs the falsified `BatchInfo`
9. Aggregate into `ProofOfStore` with `num_txns=10000`
10. Include in a proposal, observe it passes validation
11. Attempt execution, observe `verify_with_digest()` fails
12. Block execution fails, demonstrating DoS

**Expected result**: Without the fix, `init_proof()` accepts the falsified metadata. With the fix, it rejects it at step 7 with `SignedBatchInfoError::WrongInfo`.

**Notes**

This vulnerability demonstrates a critical gap in the quorum store's trust assumptions. While the protocol correctly validates batch content when received as `BatchMsg`, it fails to re-validate metadata when aggregating signatures. The fix is straightforward and adds minimal overhead since the batch must be retrieved from local storage anyway.

### Citations

**File:** consensus/src/quorum_store/proof_coordinator.rs (L269-311)
```rust
    fn init_proof(
        &mut self,
        signed_batch_info: &SignedBatchInfo<BatchInfoExt>,
    ) -> Result<(), SignedBatchInfoError> {
        // Check if the signed digest corresponding to our batch
        if signed_batch_info.author() != self.peer_id {
            return Err(SignedBatchInfoError::WrongAuthor);
        }
        let batch_author = self
            .batch_reader
            .exists(signed_batch_info.digest())
            .ok_or(SignedBatchInfoError::NotFound)?;
        if batch_author != signed_batch_info.author() {
            return Err(SignedBatchInfoError::WrongAuthor);
        }

        self.timeouts.add(
            signed_batch_info.batch_info().clone(),
            self.proof_timeout_ms,
        );
        if signed_batch_info.batch_info().is_v2() {
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info_ext(signed_batch_info.batch_info().clone()),
            );
        } else {
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info(
                    signed_batch_info.batch_info().info().clone(),
                ),
            );
        }
        self.batch_info_to_time
            .entry(signed_batch_info.batch_info().clone())
            .or_insert(Instant::now());
        debug!(
            LogSchema::new(LogEvent::ProofOfStoreInit),
            digest = signed_batch_info.digest(),
            batch_id = signed_batch_info.batch_id().id,
        );
        Ok(())
    }
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```

**File:** consensus/src/round_manager.rs (L1178-1185)
```rust
        let payload_len = proposal.payload().map_or(0, |payload| payload.len());
        let payload_size = proposal.payload().map_or(0, |payload| payload.size());
        ensure!(
            num_validator_txns + payload_len as u64 <= self.local_config.max_receiving_block_txns,
            "Payload len {} exceeds the limit {}",
            payload_len,
            self.local_config.max_receiving_block_txns,
        );
```

**File:** consensus/src/network.rs (L574-579)
```rust
                batch.verify_with_digest(request_digest)?;
                Ok(BatchResponse::Batch(*batch))
            },
            ConsensusMsg::BatchResponseV2(maybe_batch) => {
                if let BatchResponse::Batch(batch) = maybe_batch.as_ref() {
                    batch.verify_with_digest(request_digest)?;
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L648-673)
```rust
                        } else {
                            cur_unique_txns + batch.num_txns()
                        };
                        if cur_all_txns + batch.size() > max_txns
                            || unique_txns > max_txns_after_filtering
                        {
                            // Exceeded the limit for requested bytes or number of transactions.
                            full = true;
                            return false;
                        }
                        cur_all_txns += batch.size();
                        // Add this batch to filtered_txns and calculate the number of
                        // unique transactions added in the result so far.
                        cur_unique_txns +=
                            item.txn_summaries
                                .as_ref()
                                .map_or(batch.num_txns(), |summaries| {
                                    summaries
                                        .iter()
                                        .filter(|summary| {
                                            filtered_txns.insert(**summary)
                                                && block_timestamp.as_secs()
                                                    < summary.expiration_timestamp_secs
                                        })
                                        .count() as u64
                                });
```
