# Audit Report

## Title
Infinite Loop Vulnerability in Indexer GRPC Data Service Due to Missing Error Handling and Timeout

## Summary
The indexer-grpc-data-service-v2's `fetch_transactions` method contains an infinite loop with no timeout or error handling, which can cause service-wide resource exhaustion and denial of service when upstream connections fail or requested data is unavailable.

## Finding Description

The vulnerability exists in the data fetching pipeline of the live data service, specifically in how it handles missing cache data and upstream fetch failures.

**Primary Vulnerability Location:** [1](#0-0) 

The `fetch_transactions` function contains an infinite loop that retries gRPC calls indefinitely without any timeout, backoff mechanism, or error handling. When the upstream gRPC server is unavailable or returns errors, the loop continues spinning without delay, creating a tight CPU-burning infinite loop.

**Attack Flow:**

1. Client sends a `GetTransactionsRequest` to the LiveDataService [2](#0-1) 

2. A new async task is spawned that calls `in_memory_cache.get_data()` [3](#0-2) 

3. If the requested version is not in cache, `get_data()` enters a loop that calls `fetch_past_data()` [4](#0-3) 

4. `fetch_past_data()` calls `fetch_and_update_cache()` which invokes `fetch_transactions()` [5](#0-4) 

5. In `fetch_transactions()`, if the gRPC call fails (connection refused, timeout, server down), the error is silently ignored and the loop continues without any delay

**Vulnerability Scenarios:**

**Scenario A - Upstream Server Failure (Critical):** When the upstream gRPC manager is unavailable, `client.get_transactions()` returns an error. The `if let Ok(response) = response` check fails, and the loop continues immediately with no delay, creating a tight infinite loop that burns CPU cycles continuously.

**Scenario B - Missing/Pruned Data:** When the requested version doesn't exist (pruned or gap in data), `fetch_transactions()` may return an empty vector. The `fetch_and_update_cache()` function doesn't update the cache when receiving empty data, so the outer loop in `get_data()` retries indefinitely. [6](#0-5) 

**Scenario C - Version Mismatch:** If upstream returns transactions but with the wrong starting version, the inner loop continues indefinitely until the correct version appears, which may never happen.

**Invariant Violation:**

This vulnerability breaks **Invariant #9 (Resource Limits)**: "All operations must respect gas, storage, and computational limits." The infinite loops allow unbounded CPU consumption and task accumulation without any resource limits or timeouts.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria for the following reasons:

1. **API Crashes/Unavailability** - The indexer-grpc-data-service becomes unresponsive when multiple client requests trigger the infinite loop condition. Each affected request spawns an async task that never completes, leading to:
   - CPU exhaustion from tight spinning loops
   - Memory accumulation from hung client connections
   - Complete service unavailability for legitimate users

2. **Resource Exhaustion DoS** - An attacker can intentionally trigger this condition by:
   - Requesting pruned/unavailable transaction versions
   - Timing requests during known upstream maintenance windows
   - Sending concurrent requests to amplify the resource exhaustion

3. **Cascading Service Degradation** - While the indexer service is not consensus-critical, its failure affects:
   - Blockchain explorers and analytics platforms
   - Wallets and dApps that rely on indexer APIs for transaction history
   - Monitoring and alerting systems

The vulnerability does NOT reach Critical severity because:
- It doesn't affect consensus validators or the core blockchain
- No funds are at risk
- Service can be recovered through restart (though data may be lost during downtime)

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to occur in production environments:

1. **Natural Triggers**: Upstream gRPC server failures are common operational events (network partitions, server restarts, maintenance windows)

2. **Zero Attack Complexity**: Any client can send requests without authentication or special privileges. The indexer API is publicly accessible.

3. **Existing Evidence**: The code contains a `TODO` comment acknowledging missing error handling, indicating the developers are aware this is incomplete. [7](#0-6) 

4. **No Protective Mechanisms**: Investigation confirms there are no timeout wrappers, circuit breakers, or retry limits anywhere in the call chain. [8](#0-7) 

The gRPC client is created with `connect_lazy()` and no timeout configuration, relying on potentially infinite default timeouts.

## Recommendation

Implement comprehensive error handling, timeouts, and retry limits:

```rust
// In data_client.rs, replace the infinite loop with proper error handling:

pub(super) async fn fetch_transactions(&self, starting_version: u64) -> Vec<Transaction> {
    const MAX_RETRIES: usize = 3;
    const RETRY_DELAY: Duration = Duration::from_millis(100);
    const REQUEST_TIMEOUT: Duration = Duration::from_secs(30);
    
    let request = GetTransactionsRequest {
        starting_version: Some(starting_version),
        transactions_count: None,
        batch_size: None,
        transaction_filter: None,
    };
    
    for attempt in 0..MAX_RETRIES {
        let mut client = self
            .connection_manager
            .get_grpc_manager_client_for_request();
            
        match tokio::time::timeout(REQUEST_TIMEOUT, client.get_transactions(request.clone())).await {
            Ok(Ok(response)) => {
                let transactions = response.into_inner().transactions;
                if transactions.is_empty() {
                    warn!("Received empty transactions for version {}", starting_version);
                    return vec![];
                }
                if transactions.first().unwrap().version == starting_version {
                    return transactions;
                }
                warn!("Version mismatch: expected {}, got {}", 
                      starting_version, transactions.first().unwrap().version);
            }
            Ok(Err(e)) => {
                warn!("gRPC error on attempt {}/{}: {:?}", attempt + 1, MAX_RETRIES, e);
            }
            Err(_) => {
                warn!("Request timeout on attempt {}/{}", attempt + 1, MAX_RETRIES);
            }
        }
        
        if attempt < MAX_RETRIES - 1 {
            tokio::time::sleep(RETRY_DELAY * (attempt as u32 + 1)).await; // Exponential backoff
        }
    }
    
    error!("Failed to fetch transactions for version {} after {} attempts", 
           starting_version, MAX_RETRIES);
    vec![] // Return empty to signal failure
}
```

Additionally, in `in_memory_cache.rs`, add a maximum retry limit:

```rust
// Add a retry counter to prevent infinite outer loop
const MAX_FETCH_ATTEMPTS: usize = 5;
let mut fetch_attempts = 0;

loop {
    // ... existing code ...
    
    if data_manager.get_data(starting_version).is_none() {
        fetch_attempts += 1;
        if fetch_attempts > MAX_FETCH_ATTEMPTS {
            warn!("Max fetch attempts reached for version {}", starting_version);
            return None;
        }
        drop(data_manager);
        self.fetch_manager.fetch_past_data(starting_version).await;
        continue;
    }
    
    // ... rest of the function ...
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use tokio::time::Duration;
    
    #[tokio::test(flavor = "multi_thread")]
    async fn test_infinite_loop_on_upstream_failure() {
        // Setup: Create a ConnectionManager pointing to a non-existent server
        let bad_addresses = vec!["http://127.0.0.1:99999".to_string()];
        let connection_manager = Arc::new(
            ConnectionManager::new(
                1, // chain_id
                bad_addresses,
                "test-service".to_string(),
                true,
            ).await
        );
        
        let data_client = DataClient::new(connection_manager);
        
        // Attempt to fetch transactions - this will loop infinitely in vulnerable code
        let fetch_task = tokio::spawn(async move {
            data_client.fetch_transactions(1000).await
        });
        
        // In vulnerable code, this timeout will trigger because fetch never completes
        let result = tokio::time::timeout(Duration::from_secs(5), fetch_task).await;
        
        assert!(result.is_err(), "fetch_transactions should timeout when upstream is unavailable");
        // In fixed code, this should return within timeout with proper error handling
    }
    
    #[tokio::test(flavor = "multi_thread")]
    async fn test_infinite_loop_on_missing_data() {
        // Setup live data service with mock upstream
        // Request a version that doesn't exist (e.g., pruned data)
        // Verify that the request eventually returns an error instead of hanging
        
        // This test would demonstrate the outer loop infinite retry issue
        // when fetch_past_data repeatedly returns empty results
    }
}
```

## Notes

This vulnerability is particularly concerning because:

1. **Silent Failure**: The TODO comment indicates developers are aware of missing error handling but haven't prioritized the fix
2. **Amplification Effect**: Each client request spawns a separate async task, so concurrent requests multiply the resource consumption
3. **Production Impact**: This affects real user-facing services (explorers, wallets) that depend on the indexer API
4. **No Monitoring**: Without timeout metrics, operators may not detect the issue until complete service failure occurs

The fix should include proper observability (metrics for retry counts, timeout events) to enable proactive monitoring and alerting.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_client.rs (L27-42)
```rust
        loop {
            let mut client = self
                .connection_manager
                .get_grpc_manager_client_for_request();
            let response = client.get_transactions(request.clone()).await;
            if let Ok(response) = response {
                let transactions = response.into_inner().transactions;
                if transactions.is_empty() {
                    return vec![];
                }
                if transactions.first().unwrap().version == starting_version {
                    return transactions;
                }
            }
            // TODO(grao): Error handling.
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L127-139)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        MAX_BYTES_PER_BATCH,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L185-194)
```rust
            if let Some((transactions, batch_size_bytes, last_processed_version)) = self
                .in_memory_cache
                .get_data(
                    next_version,
                    ending_version,
                    max_num_transactions_per_batch,
                    max_bytes_per_batch,
                    &filter,
                )
                .await
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L73-76)
```rust
            if data_manager.get_data(starting_version).is_none() {
                drop(data_manager);
                self.fetch_manager.fetch_past_data(starting_version).await;
                continue;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L34-38)
```rust
    pub(super) async fn fetch_past_data(&self, version: u64) -> usize {
        let _timer = TIMER.with_label_values(&["fetch_past_data"]).start_timer();
        Self::fetch_and_update_cache(self.data_client.clone(), self.data_manager.clone(), version)
            .await
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L56-61)
```rust
        if len > 0 {
            data_manager
                .write()
                .await
                .update_data(version, transactions);
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/connection_manager.rs (L303-313)
```rust
    fn create_client_from_address(address: &str) -> GrpcManagerClient<Channel> {
        info!("Creating GrpcManagerClient for {address}.");
        let channel = Channel::from_shared(address.to_string())
            .expect("Bad address.")
            .connect_lazy();
        GrpcManagerClient::new(channel)
            .send_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Zstd)
            .max_decoding_message_size(MAX_MESSAGE_SIZE)
            .max_encoding_message_size(MAX_MESSAGE_SIZE)
    }
```
