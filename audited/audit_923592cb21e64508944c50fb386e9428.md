# Audit Report

## Title
Unverified WriteSet Corruption in Transaction Backup Restore Process

## Summary
The `LoadedChunk::load()` function in the transaction restore process fails to verify that WriteSet data matches the cryptographic commitment in TransactionInfo structures. This allows malicious backup files to inject arbitrary WriteSet data that will corrupt the blockchain state database while passing all verification checks.

## Finding Description

The vulnerability exists in the backup restoration flow where WriteSet integrity is not validated against the `state_change_hash` field in TransactionInfo objects.

**Vulnerable Code Path:** [1](#0-0) 

The `LoadedChunk::load()` function reads transactions, transaction_infos, events, and write_sets from a backup file, then creates a `TransactionListWithProof` structure for verification. However, the write_sets are excluded from this verification structure.

**Missing Verification:** [2](#0-1) 

The verification uses `TransactionListWithProof::verify()` which only validates: [3](#0-2) 

This method checks transaction hashes and events, but **does not verify write_sets** against the `state_change_hash` field in TransactionInfo.

**Correct Verification Exists But Is Not Used:** [4](#0-3) 

The `TransactionOutputListWithProof::verify()` method properly validates write_sets, but the backup restore code uses `TransactionListWithProof` instead.

**TransactionInfo Contains State Change Hash:** [5](#0-4) 

The `state_change_hash` field is defined as "the hash value summarizing all changes caused to the world state by this transaction, i.e. hash of the output write set."

**Unverified WriteSets Are Used for State Reconstruction:** [6](#0-5) [7](#0-6) 

The unverified write_sets are persisted to WriteSetDb and used to calculate state updates, directly corrupting the state database.

**Attack Scenario:**

1. Attacker creates a malicious backup file with:
   - Valid transactions (correct hashes matching transaction_infos)
   - Valid transaction_infos (cryptographically proven by ledger)
   - Valid events (matching event root hashes)
   - **Malicious write_sets** (arbitrary data not matching state_change_hash)

2. Victim node performs backup restoration using this file

3. All verification passes because write_sets are never checked

4. Malicious write_sets are saved to WriteSetDb and used for state KV reconstruction

5. Blockchain state is corrupted with attacker-controlled data

## Impact Explanation

**Severity: Critical** (up to $1,000,000 per Aptos Bug Bounty)

This vulnerability breaks multiple critical invariants:

1. **State Consistency Violation**: State transitions are no longer verifiable via Merkle proofs when arbitrary write_sets corrupt the state database

2. **Deterministic Execution Violation**: Nodes restoring from different malicious backups will have divergent state, breaking consensus

3. **Consensus Safety Violation**: If validators restore from malicious backups, they will have inconsistent state views, potentially causing chain splits or double-spending

4. **Potential Loss of Funds**: Attacker can manipulate account balances, resource ownership, or other critical state by crafting write_sets that modify arbitrary storage locations

This meets the "Consensus/Safety violations" critical severity criterion and potentially "Loss of Funds" depending on how the malicious write_sets are constructed.

## Likelihood Explanation

**Likelihood: Medium-to-High**

Attack prerequisites:
- Attacker must be able to provide a malicious backup file to the victim (through compromised backup storage, supply chain attack, or social engineering)
- Victim must perform a restore operation using the malicious backup

While this requires specific conditions, backup restoration is a common operational procedure for:
- Spinning up new validator nodes
- Recovering from hardware failures
- Setting up archive nodes or read replicas

The attack complexity is low once backup file access is achieved, as constructing the malicious file only requires:
1. Copying legitimate transaction and transaction_info data
2. Replacing write_sets with attacker-chosen data
3. Maintaining proper serialization format

## Recommendation

Add write_set verification to the `LoadedChunk::load()` function by checking that each write_set's hash matches the corresponding transaction_info's `state_change_hash`:

```rust
// After line 167 in restore.rs, add write_set verification:
for (write_set, txn_info) in write_sets.iter().zip(txn_infos.iter()) {
    let write_set_hash = CryptoHash::hash(write_set);
    ensure!(
        txn_info.state_change_hash() == write_set_hash,
        "WriteSet hash mismatch at version {}. Expected: {:x}, Got: {:x}",
        manifest.first_version,
        txn_info.state_change_hash(),
        write_set_hash
    );
}
```

Alternatively, refactor to use `TransactionOutputListWithProof` which includes proper write_set verification, or extract the write_set verification logic into a reusable function.

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[tokio::test]
async fn test_malicious_writeset_bypass() {
    // 1. Create legitimate backup data
    let txn = /* valid transaction */;
    let txn_info = /* valid transaction info with state_change_hash */;
    let events = /* valid events */;
    let legitimate_write_set = /* write set matching state_change_hash */;
    
    // 2. Create malicious write_set that does NOT match state_change_hash
    let malicious_write_set = WriteSet::new(vec![
        (StateKey::raw(b"attacker_account"), WriteOp::Value(b"unlimited_funds".to_vec())),
    ]);
    
    // 3. Serialize backup chunk with mismatched write_set
    let chunk_data = bcs::to_bytes(&(
        txn,
        PersistedAuxiliaryInfo::None,
        txn_info,
        events,
        malicious_write_set,  // Malicious data here
    )).unwrap();
    
    // 4. Create backup manifest and proof
    let manifest = TransactionChunk { /* valid manifest */ };
    let proof = /* valid cryptographic proof */;
    
    // 5. Load chunk - this will SUCCEED despite malicious write_set
    let loaded_chunk = LoadedChunk::load(manifest, &storage, None).await.unwrap();
    
    // 6. Verify the malicious write_set was loaded
    assert_eq!(loaded_chunk.write_sets[0], malicious_write_set);
    
    // 7. When saved to DB, state will be corrupted
    restore_handler.save_transactions(
        first_version,
        &loaded_chunk.txns,
        &loaded_chunk.persisted_aux_info,
        &loaded_chunk.txn_infos,
        &loaded_chunk.event_vecs,
        loaded_chunk.write_sets,  // Malicious data persisted
    ).unwrap();
    
    // State database is now corrupted with attacker-controlled data
}
```

## Notes

This vulnerability specifically affects the backup restore code path and does not impact normal transaction execution or state sync, which use different verification mechanisms. The issue only manifests when nodes perform restoration from backup files, making it a supply chain / operational security concern rather than a runtime protocol vulnerability.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L100-186)
```rust
    async fn load(
        manifest: TransactionChunk,
        storage: &Arc<dyn BackupStorage>,
        epoch_history: Option<&Arc<EpochHistory>>,
    ) -> Result<Self> {
        let mut file = BufReader::new(storage.open_for_read(&manifest.transactions).await?);
        let mut txns = Vec::new();
        let mut persisted_aux_info = Vec::new();
        let mut txn_infos = Vec::new();
        let mut event_vecs = Vec::new();
        let mut write_sets = Vec::new();

        while let Some(record_bytes) = file.read_record_bytes().await? {
            let (txn, aux_info, txn_info, events, write_set): (
                _,
                PersistedAuxiliaryInfo,
                _,
                _,
                WriteSet,
            ) = match manifest.format {
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
                    (
                        txn,
                        PersistedAuxiliaryInfo::None,
                        txn_info,
                        events,
                        write_set,
                    )
                },
                TransactionChunkFormat::V1 => bcs::from_bytes(&record_bytes)?,
            };
            txns.push(txn);
            persisted_aux_info.push(aux_info);
            txn_infos.push(txn_info);
            event_vecs.push(events);
            write_sets.push(write_set);
        }

        ensure!(
            manifest.first_version + (txns.len() as Version) == manifest.last_version + 1,
            "Number of items in chunks doesn't match that in manifest. first_version: {}, last_version: {}, items in chunk: {}",
            manifest.first_version,
            manifest.last_version,
            txns.len(),
        );

        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }

        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
        // and disassemble it to get things back.
        let (txn_list_with_proof, persisted_aux_info) = txn_list_with_proof.into_parts();
        let txns = txn_list_with_proof.transactions;
        let range_proof = txn_list_with_proof
            .proof
            .ledger_info_to_transaction_infos_proof;
        let txn_infos = txn_list_with_proof.proof.transaction_infos;
        let event_vecs = txn_list_with_proof.events.expect("unknown to be Some.");

        Ok(Self {
            manifest,
            txns,
            persisted_aux_info,
            txn_infos,
            event_vecs,
            range_proof,
            write_sets,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L593-600)
```rust
                        handler.save_transactions_and_replay_kv(
                            base_version,
                            &txns,
                            &persisted_aux_info,
                            &txn_infos,
                            &events,
                            write_sets,
                        )?;
```

**File:** types/src/transaction/mod.rs (L2040-2042)
```rust
    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,
```

**File:** types/src/transaction/mod.rs (L2295-2354)
```rust
    pub fn verify(
        &self,
        ledger_info: &LedgerInfo,
        first_transaction_version: Option<Version>,
    ) -> Result<()> {
        // Verify the first transaction versions match
        ensure!(
            self.get_first_transaction_version() == first_transaction_version,
            "First transaction version ({:?}) doesn't match given version ({:?}).",
            self.get_first_transaction_version(),
            first_transaction_version,
        );

        // Verify the lengths of the transactions and transaction infos match
        ensure!(
            self.proof.transaction_infos.len() == self.get_num_transactions(),
            "The number of TransactionInfo objects ({}) does not match the number of \
             transactions ({}).",
            self.proof.transaction_infos.len(),
            self.get_num_transactions(),
        );

        // Verify the transaction hashes match those of the transaction infos
        self.transactions
            .par_iter()
            .zip_eq(self.proof.transaction_infos.par_iter())
            .map(|(txn, txn_info)| {
                let txn_hash = CryptoHash::hash(txn);
                ensure!(
                    txn_hash == txn_info.transaction_hash(),
                    "The hash of transaction does not match the transaction info in proof. \
                     Transaction hash: {:x}. Transaction hash in txn_info: {:x}.",
                    txn_hash,
                    txn_info.transaction_hash(),
                );
                Ok(())
            })
            .collect::<Result<Vec<_>>>()?;

        // Verify the transaction infos are proven by the ledger info.
        self.proof
            .verify(ledger_info, self.get_first_transaction_version())?;

        // Verify the events if they exist.
        if let Some(event_lists) = &self.events {
            ensure!(
                event_lists.len() == self.get_num_transactions(),
                "The length of event_lists ({}) does not match the number of transactions ({}).",
                event_lists.len(),
                self.get_num_transactions(),
            );
            event_lists
                .into_par_iter()
                .zip_eq(self.proof.transaction_infos.par_iter())
                .map(|(events, txn_info)| verify_events_against_root_hash(events, txn_info))
                .collect::<Result<Vec<_>>>()?;
        }

        Ok(())
    }
```

**File:** types/src/transaction/mod.rs (L2578-2586)
```rust
            // Verify the write set matches for both the transaction info and output
            let write_set_hash = CryptoHash::hash(&txn_output.write_set);
            ensure!(
                txn_info.state_change_hash() == write_set_hash,
                "The write set in transaction output does not match the transaction info \
                     in proof. Hash of write set in transaction output: {}. Write set hash in txn_info: {}.",
                write_set_hash,
                txn_info.state_change_hash(),
            );
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L261-277)
```rust
    for (idx, ws) in write_sets.iter().enumerate() {
        WriteSetDb::put_write_set(
            first_version + idx as Version,
            ws,
            &mut ledger_db_batch.write_set_db_batches,
        )?;
    }

    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```
