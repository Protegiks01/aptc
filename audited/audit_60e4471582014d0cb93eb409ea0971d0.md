# Audit Report

## Title
Incorrect `more` Flag in Epoch Change Proof Causes Synchronization Failure Beyond 100 Epochs

## Summary
When size-and-time-aware chunking is enabled, the storage service incorrectly hardcodes `more = false` in epoch change proofs even when the database iterator is capped at 100 epochs. This causes clients more than 100 epochs behind to fail synchronization with "Inconsistent epoch change proof and latest ledger info" errors, creating a liveness failure.

## Finding Description

The TODO comment in `common.rs` highlights the need for an iteration API or recent waypoint to handle synchronization beyond 100 epochs: [1](#0-0) 

The constant `MAX_NUM_EPOCH_ENDING_LEDGER_INFO = 100` limits epoch ending ledger info retrieval. The database layer correctly enforces this cap: [2](#0-1) 

However, when `enable_size_and_time_aware_chunking` is enabled, the storage service uses an iterator-based approach that doesn't track whether truncation occurred: [3](#0-2) 

The service then incorrectly hardcodes `more = false` when constructing the `EpochChangeProof`: [4](#0-3) 

This is in contrast to the legacy implementation which correctly propagates the `more` flag from the database: [5](#0-4) 

When a client receives an epoch change proof with `more = false` but the proof doesn't reach the latest ledger info's epoch, verification fails: [6](#0-5) 

The test suite confirms this behavior - when `more = false` with an epoch gap, verification must fail: [7](#0-6) 

**Attack Scenario:**
1. A node is offline for >100 epochs (e.g., epoch 0 to epoch 150)
2. When it comes back online, it requests epoch ending ledger infos
3. The storage service's iterator is capped at 100 epochs due to `MAX_NUM_EPOCH_ENDING_LEDGER_INFO`
4. The service returns an `EpochChangeProof` with epochs 0-99 but incorrectly sets `more = false`
5. The client receives a latest ledger info at epoch 150
6. Verification fails because `latest_li.epoch() (150) > new_epoch (99) && more (false)`
7. The client cannot sync and remains stuck

## Impact Explanation

This issue represents a **High Severity** vulnerability per Aptos bug bounty criteria:
- **Significant protocol violation**: Breaks the state synchronization protocol guarantees
- **Validator node impact**: Nodes that have been offline cannot rejoin the network
- **Network availability**: While not total network failure, it prevents a subset of nodes from synchronizing

The vulnerability doesn't cause consensus safety violations or fund loss, but creates a liveness failure for nodes attempting to catch up after extended offline periods. With typical epoch durations, being 100 epochs behind is realistic for nodes offline for several days or weeks.

## Likelihood Explanation

**Likelihood: High**

This issue occurs naturally without any malicious action:
- Any node offline for >100 epochs will encounter this when trying to sync
- The buggy code path is active when `enable_size_and_time_aware_chunking = true`
- While the config default is `false`, the `ConfigOptimizer` enables it for non-mainnet networks

The configuration shows the app-level limit exceeds the DB limit: [8](#0-7) 

This makes the bug triggerable in common scenarios where clients request large epoch ranges.

## Recommendation

The storage service must detect when the iterator was truncated by the DB layer and correctly set the `more` flag. Fix for `get_epoch_ending_ledger_infos_by_size`:

```rust
// Track the requested end epoch
let requested_end_epoch = start_epoch
    .checked_add(num_ledger_infos_to_fetch)
    .ok_or_else(|| Error::UnexpectedErrorEncountered("End epoch has overflown!".into()))?;

// Get the epoch ending ledger info iterator (may be capped by DB)
let mut epoch_ending_ledger_info_iterator = self
    .storage
    .get_epoch_ending_ledger_info_iterator(start_epoch, requested_end_epoch)?;

// ... fetch ledger infos into epoch_ending_ledger_infos ...

// Determine if there are more epochs beyond what we fetched
let fetched_epochs = epoch_ending_ledger_infos.len() as u64;
let last_fetched_epoch = if !epoch_ending_ledger_infos.is_empty() {
    epoch_ending_ledger_infos.last().unwrap().ledger_info().next_block_epoch()
} else {
    start_epoch
};

// Set more = true if we didn't reach the expected end epoch
let more = last_fetched_epoch < expected_end_epoch;

// Create the epoch change proof with correct more flag
let epoch_change_proof = EpochChangeProof::new(epoch_ending_ledger_infos, more);
```

Alternatively, propagate the truncation information from the DB layer through the iterator interface.

## Proof of Concept

```rust
#[tokio::test]
async fn test_epoch_sync_beyond_100_epochs_fails() {
    use aptos_storage_service_server::StorageReader;
    use aptos_storage_service_types::requests::*;
    use aptos_types::epoch_change::EpochChangeProof;
    
    // Setup: Create a network at epoch 150
    let mut mock_db = MockDatabaseReader::new();
    let current_epoch = 150;
    
    // Mock will cap iterator at 100 epochs (simulating MAX_NUM_EPOCH_ENDING_LEDGER_INFO)
    mock_db
        .expect_get_epoch_ending_ledger_info_iterator()
        .returning(|start, _end| {
            // DB caps at 100, so only returns epochs 0-99
            let capped_end = std::cmp::min(start + 100, start + 100);
            let ledger_infos = create_epoch_ending_ledger_infos(start, capped_end - 1);
            Ok(Box::new(ledger_infos.into_iter().map(Ok)))
        });
    
    // Create storage service with size-aware chunking ENABLED
    let config = StorageServiceConfig {
        enable_size_and_time_aware_chunking: true,
        ..Default::default()
    };
    let storage = StorageReaderServiceImpl::new(config, Arc::new(mock_db));
    
    // Client at epoch 0 requests to sync to epoch 150
    let proof = storage
        .get_epoch_ending_ledger_infos(0, 150)
        .unwrap();
    
    // BUG: proof.more is false even though it only contains epochs 0-99
    assert_eq!(proof.more, false); // This should be true!
    assert_eq!(proof.ledger_info_with_sigs.len(), 100);
    
    // Create a latest ledger info at epoch 150
    let latest_li = create_ledger_info_at_epoch(150);
    
    // Client tries to verify
    let trusted_state = TrustedState::from_epoch_waypoint(waypoint_at_epoch_0);
    let result = trusted_state.verify_and_ratchet_inner(&latest_li, &proof);
    
    // FAILURE: Client cannot sync because more=false but there's an epoch gap
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Inconsistent"));
}
```

## Notes

The TODO comment in `common.rs` identified this issue as technical debt, but the implementation bug has not been addressed. The legacy code path (when `enable_size_and_time_aware_chunking = false`) correctly handles the `more` flag by directly calling the DB method that returns the flag. The new implementation needs similar tracking to determine if truncation occurred.

This vulnerability demonstrates how a hardcoded constant (`MAX_NUM_EPOCH_ENDING_LEDGER_INFO = 100`) in one layer can create security issues when upper layers don't properly account for it. The fix requires either propagating truncation information through the iterator API or tracking the expected vs actual epoch range at the storage service level.

### Citations

**File:** storage/aptosdb/src/common.rs (L7-9)
```rust
// TODO: Either implement an iteration API to allow a very old client to loop through a long history
// or guarantee that there is always a recent enough waypoint and client knows to boot from there.
pub(crate) const MAX_NUM_EPOCH_ENDING_LEDGER_INFO: usize = 100;
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L579-583)
```rust
            let limit = std::cmp::min(
                end_epoch.saturating_sub(start_epoch),
                MAX_NUM_EPOCH_ENDING_LEDGER_INFO as u64,
            );
            let end_epoch = start_epoch.saturating_add(limit);
```

**File:** state-sync/storage-service/server/src/storage.rs (L240-242)
```rust
        let mut epoch_ending_ledger_info_iterator = self
            .storage
            .get_epoch_ending_ledger_info_iterator(start_epoch, end_epoch)?;
```

**File:** state-sync/storage-service/server/src/storage.rs (L289-289)
```rust
        let epoch_change_proof = EpochChangeProof::new(epoch_ending_ledger_infos, false);
```

**File:** state-sync/storage-service/server/src/storage.rs (L315-317)
```rust
            let epoch_change_proof = self
                .storage
                .get_epoch_ending_ledger_infos(start_epoch, end_epoch)?;
```

**File:** types/src/trusted_state.rs (L183-187)
```rust
            } else if latest_li.ledger_info().epoch() > new_epoch && epoch_change_proof.more {
                epoch_change_li
            } else {
                bail!("Inconsistent epoch change proof and latest ledger info");
            };
```

**File:** types/src/unit_tests/trusted_state_test.rs (L387-393)
```rust
        // ratcheting with more = false should fail, since the state proof claims
        // we're done syncing epoch changes but doesn't get us all the way to the
        // latest ledger info
        let mut change_proof = EpochChangeProof::new(lis_with_sigs, false /* more */);
        trusted_state
            .verify_and_ratchet_inner(&latest_li, &change_proof)
            .expect_err("Should return Err when more is false and there's a gap");
```

**File:** config/src/config/state_sync_config.rs (L24-24)
```rust
const MAX_EPOCH_CHUNK_SIZE: u64 = 200;
```
