# Audit Report

## Title
Memory Exhaustion via Unbounded State Sync RPC Request Queue

## Summary
An attacker can cause validator node crashes through memory exhaustion by flooding the state sync storage service with large RPC requests. While the `SERVER_MAX_MESSAGE_SIZE` constant limits response sizes to 10 MiB, there is no corresponding limit on incoming request message sizes, allowing attackers to queue up to 4000 messages of 64 MiB each per peer connection, potentially exhausting node memory.

## Finding Description
The vulnerability stems from a critical asymmetry in message size enforcement between incoming requests and outgoing responses in the state sync storage service: [1](#0-0) 

This 10 MiB limit is only applied to **outgoing responses**, not incoming requests: [2](#0-1) 

Meanwhile, the network layer allows messages up to `MAX_MESSAGE_SIZE` (64 MiB): [3](#0-2) 

Messages are queued in an aptos_channel with a per-peer capacity of 4000: [4](#0-3) [5](#0-4) 

Critically, the queue capacity is **per-peer**, not global: [6](#0-5) 

Large messages are assembled via streaming, with fragments appended to the raw_request Vec: [7](#0-6) 

The complete `NetworkMessage` with fully allocated raw bytes is then wrapped in `ReceivedMessage` and pushed to the queue before any storage service validation occurs.

**Attack Path:**
1. Attacker connects to a validator node as a peer (e.g., as a public fullnode connecting to a VFN)
2. Attacker sends 4000 large RPC requests to `StorageServiceRpc`, each utilizing the full 64 MiB message size limit
3. Messages are streamed in fragments, assembled, and queued in the per-peer aptos_channel
4. Each `NetworkMessage::RpcRequest` contains a `raw_request: Vec<u8>` of up to 64 MiB
5. Total memory allocation per malicious peer: 4000 Ã— 64 MiB = **256 GB**
6. Node memory exhausts, causing OOM crash or severe performance degradation

The request moderator validates whether requests can be satisfied but does **not** validate incoming request payload sizes: [8](#0-7) 

## Impact Explanation
This is a **High Severity** vulnerability under the Aptos bug bounty criteria:
- **Validator node slowdowns**: Memory pressure causes severe performance degradation
- **API crashes**: OOM conditions lead to node crashes requiring restart

While a single attacker with one peer connection can queue 256 GB (exceeding typical validator RAM of 32-64 GB), multiple malicious peers could amplify the impact. This affects consensus availability as crashed validators cannot participate in block production.

## Likelihood Explanation
**Likelihood: HIGH**

The attack is straightforward to execute:
- No authentication barriers for peer connections to VFNs
- No privileged access required
- Standard network RPC calls using existing protocol
- No rate limiting on incoming request sizes
- The `max_network_channel_size` of 4000 is generous enough to cause significant memory exhaustion

The only barrier is establishing peer connections, which is part of normal fullnode operation.

## Recommendation

Implement size validation for incoming storage service requests before queueing. Add a maximum request payload size check at the network layer or in the storage service handler:

**Option 1: Network layer validation** - Add max request size to `NetworkConfig` and validate in `MultiplexMessageStream` before queueing.

**Option 2: Storage service validation** - Add early request size validation in the handler before processing:

```rust
// In handler.rs process_request_and_respond()
pub fn process_request_and_respond(
    &self,
    storage_service_config: StorageServiceConfig,
    peer_network_id: PeerNetworkId,
    protocol_id: ProtocolId,
    request: StorageServiceRequest,
    response_sender: ResponseSender,
) {
    // Add size validation for the serialized request
    let request_size = bcs::to_bytes(&request).map(|b| b.len()).unwrap_or(0);
    if request_size > MAX_REQUEST_SIZE {
        warn!("Request from {:?} exceeds max size: {} bytes", peer_network_id, request_size);
        return; // Drop oversized requests
    }
    // ... existing code
}
```

**Option 3: Reduce queue capacity** - Lower `max_network_channel_size` to a more conservative value (e.g., 100-500) to limit memory exposure per peer.

**Recommended approach:** Implement both Options 1 and 3 - add explicit request size limits at the network layer and reduce the per-peer queue capacity to provide defense in depth.

## Proof of Concept

```rust
// Rust integration test demonstrating the vulnerability
#[tokio::test]
async fn test_storage_service_memory_exhaustion() {
    // Setup: Create a test validator node with storage service
    let (node, mut peer_handle) = setup_test_validator_with_storage_service().await;
    
    // Attack: Send 4000 large RPC requests
    let large_payload = vec![0u8; 64 * 1024 * 1024]; // 64 MiB
    
    for i in 0..4000 {
        let request = NetworkMessage::RpcRequest(RpcRequest {
            protocol_id: ProtocolId::StorageServiceRpc,
            request_id: i,
            priority: 0,
            raw_request: large_payload.clone(),
        });
        
        // Send without waiting for response
        peer_handle.send_message(request).await.unwrap();
    }
    
    // Verify: Check memory usage
    let memory_usage = node.get_memory_usage();
    assert!(memory_usage > 200 * 1024 * 1024 * 1024, // > 200 GB
            "Expected significant memory allocation, got {} bytes", memory_usage);
    
    // Node should experience memory pressure or crash
}
```

## Notes

The vulnerability is exacerbated by the fact that:
1. The `SERVER_MAX_MESSAGE_SIZE` constant creates a false sense of security - it only applies to responses
2. The per-peer queue model means each malicious peer can independently exhaust memory
3. There is no global memory budget across all peer connections
4. Deserialization happens in parallel (`max_parallel_deserialization_tasks`) but messages are already fully allocated before deserialization attempts
5. Failed deserialization still leaves the allocated memory in the queue temporarily

This represents a fundamental resource limit violation where the configured "max message size" for state sync (10 MiB) is not enforced for the critical memory allocation path.

### Citations

**File:** config/src/config/state_sync_config.rs (L16-17)
```rust
// The maximum message size per state sync message
const SERVER_MAX_MESSAGE_SIZE: usize = 10 * 1024 * 1024; // 10 MiB
```

**File:** config/src/config/state_sync_config.rs (L203-204)
```rust
            max_network_channel_size: 4000,
            max_network_chunk_bytes: SERVER_MAX_MESSAGE_SIZE as u64,
```

**File:** state-sync/storage-service/server/src/storage.rs (L1080-1090)
```rust
        include_events: bool,
    ) -> aptos_storage_service_types::Result<TransactionDataWithProofResponse, Error> {
        self.get_transactions_with_proof_by_size(
            proof_version,
            start_version,
            end_version,
            include_events,
            self.config.max_network_chunk_bytes,
            self.config.enable_size_and_time_aware_chunking,
        )
    }
```

**File:** config/src/config/network_config.rs (L50-50)
```rust
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** aptos-node/src/network.rs (L147-166)
```rust
pub fn storage_service_network_configuration(node_config: &NodeConfig) -> NetworkApplicationConfig {
    let direct_send_protocols = vec![]; // The storage service does not use direct send
    let rpc_protocols = vec![ProtocolId::StorageServiceRpc];
    let max_network_channel_size = node_config
        .state_sync
        .storage_service
        .max_network_channel_size as usize;

    let network_client_config =
        NetworkClientConfig::new(direct_send_protocols.clone(), rpc_protocols.clone());
    let network_service_config = NetworkServiceConfig::new(
        direct_send_protocols,
        rpc_protocols,
        aptos_channel::Config::new(max_network_channel_size)
            .queue_style(QueueStyle::FIFO)
            .counters(
                &aptos_storage_service_server::metrics::PENDING_STORAGE_SERVER_NETWORK_EVENTS,
            ),
    );
    NetworkApplicationConfig::new(network_client_config, network_service_config)
```

**File:** crates/channel/src/aptos_channel.rs (L203-207)
```rust
impl Config {
    /// The aptos_channel has a "sub-queue" per key. The `max_capacity` controls
    /// the capacity of each "sub-queue"; when the queues exceed the max
    /// capacity the messages will be dropped according to the queue style/eviction
    /// policy.
```

**File:** network/framework/src/protocols/stream/mod.rs (L200-209)
```rust
        // Append the fragment data to the message
        let raw_data = &mut fragment.raw_data;
        match &mut self.message {
            NetworkMessage::Error(_) => {
                panic!("StreamHeader for NetworkMessage::Error(_) should be rejected!")
            },
            NetworkMessage::RpcRequest(request) => request.raw_request.append(raw_data),
            NetworkMessage::RpcResponse(response) => response.raw_response.append(raw_data),
            NetworkMessage::DirectSendMsg(message) => message.raw_msg.append(raw_data),
        }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-186)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

```
