# Audit Report

## Title
Pruner Infinite Retry Loop on Stale Node Index Decode Failures Causes Unbounded Storage Accumulation

## Summary
When `decode_key()` in the `StaleNodeIndexSchema` encounters decoding errors due to corrupted database entries, the pruner worker enters an infinite retry loop without advancing its progress marker. This prevents all subsequent stale node indices from being pruned, leading to unbounded accumulation of unprunable entries and eventual disk space exhaustion.

## Finding Description

The vulnerability exists in the error handling path of the state merkle pruner. The critical code flow is:

1. **Decode Implementation**: The `decode_key()` function can fail with multiple error conditions when deserializing corrupted data: [1](#0-0) 

2. **Iterator Error Propagation**: When the pruner iterates over stale node indices, decode errors are propagated through the iterator chain: [2](#0-1) 

The `transpose()?` pattern propagates decode errors up the call stack to the metadata pruner: [3](#0-2) 

And to the shard pruner: [4](#0-3) 

3. **Critical Flaw - Infinite Retry Without Progress**: When the pruner worker receives an error, it logs the failure and retries indefinitely WITHOUT updating the progress marker: [5](#0-4) 

The progress is only updated on successful pruning: [6](#0-5) 

**Attack Propagation:**
1. Database corruption occurs (hardware failure, software bug, cosmic ray, memory corruption)
2. A single stale node index entry becomes undecodable
3. Pruner attempts to iterate over entries starting from current progress
4. Iterator hits the corrupt entry and `decode_key()` fails
5. Error propagates to pruner worker, which logs and retries
6. Progress marker is never updated past the corrupt entry
7. Every retry attempts the same operation, hitting the same corrupt entry
8. All subsequent stale node indices accumulate indefinitely
9. Disk space grows unbounded until exhaustion
10. Node eventually fails due to disk space issues

## Impact Explanation

**Medium Severity** - This qualifies as "State inconsistencies requiring intervention" per the Aptos bug bounty program.

**Operational Impact:**
- Unbounded accumulation of unprunable stale node indices consuming disk space
- Eventual disk space exhaustion leading to node failure
- Requires manual intervention to identify and remove corrupt entries
- No automatic recovery mechanism exists
- Affects node availability and operational reliability

**Why Not Higher Severity:**
- Does not directly affect consensus safety or funds
- Requires database corruption as precondition (not directly attacker-controlled)
- Impact is limited to individual nodes experiencing corruption
- Does not compromise network-wide security

**Why Not Lower Severity:**
- Has real operational impact requiring human intervention
- Can lead to node failure and loss of availability
- No defensive mechanisms or circuit breakers exist
- Affects critical storage subsystem

## Likelihood Explanation

**Likelihood: Low to Medium**

**Factors Increasing Likelihood:**
- Database corruption can occur through multiple vectors: hardware failures, cosmic rays affecting memory, software bugs in RocksDB or serialization layers, memory corruption bugs elsewhere in the codebase
- Long-running validator nodes have higher probability of encountering bit flips or hardware issues over time
- No validation or checksums exist at the schema decode level to detect corruption early

**Factors Decreasing Likelihood:**
- Modern hardware has ECC memory and error detection mechanisms
- RocksDB provides internal checksums and corruption detection
- The specific corruption must affect the stale node index column family
- Quality hardware and software practices reduce corruption probability

**Real-World Scenarios:**
- Validator nodes running on degraded hardware
- Cosmic ray bit flips in memory or storage (documented occurrences)
- Software bugs in dependencies causing occasional write corruption
- Improper shutdown causing database inconsistencies

## Recommendation

Implement graceful error handling with skip-and-log functionality for undecodable entries:

```rust
// In storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs
pub(in crate::pruner::state_merkle_pruner) fn get_stale_node_indices(
    state_merkle_db_shard: &DB,
    start_version: Version,
    target_version: Version,
    limit: usize,
) -> Result<(Vec<StaleNodeIndex>, Option<Version>)> {
    let mut indices = Vec::new();
    let mut iter = state_merkle_db_shard.iter::<S>()?;
    iter.seek(&StaleNodeIndex {
        stale_since_version: start_version,
        node_key: NodeKey::new_empty_path(0),
    })?;

    let mut next_version = None;
    let mut decode_errors = 0;
    const MAX_DECODE_ERRORS: usize = 100; // Circuit breaker
    
    while indices.len() < limit {
        match iter.next() {
            Some(Ok((index, _))) => {
                next_version = Some(index.stale_since_version);
                if index.stale_since_version <= target_version {
                    indices.push(index);
                    continue;
                }
            }
            Some(Err(e)) => {
                // Log corruption and skip this entry to make progress
                error!(
                    error = ?e,
                    "Failed to decode stale node index entry, skipping corrupted entry"
                );
                decode_errors += 1;
                
                // Circuit breaker: if too many errors, fail to prevent infinite skipping
                if decode_errors > MAX_DECODE_ERRORS {
                    return Err(anyhow!(
                        "Too many decode errors ({}) encountered during pruning, possible widespread corruption",
                        decode_errors
                    ));
                }
                continue; // Skip this entry and try next
            }
            None => {}
        }
        break;
    }

    Ok((indices, next_version))
}
```

**Additional Recommendations:**
1. Add metrics for decode failures to monitor corruption rates
2. Implement periodic integrity checks on stale node index column family
3. Add circuit breaker to prevent infinite retry loops
4. Consider adding checksums or validation at schema encode/decode level
5. Document recovery procedures for operators encountering this issue

## Proof of Concept

```rust
// Reproduction test demonstrating the issue
// File: storage/aptosdb/src/pruner/state_merkle_pruner/test.rs

#[test]
fn test_pruner_stuck_on_corrupt_entry() {
    use crate::schema::stale_node_index::StaleNodeIndexSchema;
    use aptos_jellyfish_merkle::StaleNodeIndex;
    use aptos_schemadb::schema::KeyCodec;
    
    // Setup test database
    let tmpdir = aptos_temppath::TempPath::new();
    let db = DB::open(&tmpdir, "test", &[], &[]).unwrap();
    
    // Write valid stale node indices at versions 1-5
    let mut batch = SchemaBatch::new();
    for version in 1..=5 {
        let index = StaleNodeIndex {
            stale_since_version: version,
            node_key: NodeKey::new_empty_path(version),
        };
        batch.put::<StaleNodeIndexSchema>(&index, &()).unwrap();
    }
    db.write_schemas(batch).unwrap();
    
    // Inject corrupt data at version 3 by directly writing invalid bytes
    let corrupt_key = {
        let mut key = vec![];
        key.write_u64::<BigEndian>(3u64).unwrap(); // version 3
        key.write_u8(255).unwrap(); // invalid nibble count > ROOT_NIBBLE_HEIGHT
        key
    };
    db.put::<StaleNodeIndexSchema>(&corrupt_key, &vec![]).unwrap();
    
    // Attempt to prune - this will fail when hitting the corrupt entry
    let result = StateMerklePruner::get_stale_node_indices(
        &db,
        0,
        10,
        usize::MAX,
    );
    
    // Verify that decode error is returned
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Invalid number of nibbles"));
    
    // In production, the pruner worker would retry indefinitely from version 0,
    // never advancing past version 3, causing versions 4 and 5 to accumulate forever
}
```

**Notes:**
- This vulnerability requires database corruption to trigger, which is not directly controllable by external attackers
- The impact is operational (availability/reliability) rather than direct security compromise
- The issue represents a defensive programming failure in error handling
- Manual intervention is required to recover from this condition

### Citations

**File:** storage/aptosdb/src/schema/stale_node_index/mod.rs (L47-58)
```rust
    fn decode_key(data: &[u8]) -> Result<Self> {
        const VERSION_SIZE: usize = size_of::<Version>();

        ensure_slice_len_gt(data, VERSION_SIZE)?;
        let stale_since_version = (&data[..VERSION_SIZE]).read_u64::<BigEndian>()?;
        let node_key = NodeKey::decode(&data[VERSION_SIZE..])?;

        Ok(Self {
            stale_since_version,
            node_key,
        })
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L84-84)
```rust
                self.record_progress(target_version_for_this_round);
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L206-206)
```rust
            if let Some((index, _)) = iter.next().transpose()? {
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_metadata_pruner.rs (L53-58)
```rust
        let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
            &self.metadata_db,
            current_progress,
            target_version_for_this_round,
            usize::MAX,
        )?;
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L66-71)
```rust
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L53-68)
```rust
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
```
