# Audit Report

## Title
Premature Stream Termination via Malicious last_index Manipulation in State Sync

## Summary
A malicious peer can cause state sync streams to terminate prematurely by manipulating the `last_index` field in `StateValueChunkWithProof` responses. The data streaming service trusts the peer-provided `last_index` to determine stream completion without validating it matches the actual data received, causing nodes to accept incomplete state and repeatedly fail synchronization.

## Finding Description

The vulnerability exists in the state sync data streaming service where the stream completion logic operates on untrusted peer data before validation can occur.

**Vulnerable Stream Completion Logic:**

The `StateStreamEngine::transform_client_response_into_notification()` function directly extracts `last_index` from peer responses and uses it to mark stream completion: [1](#0-0) 

At line 330, `last_index` is extracted from the untrusted peer response without validating that `last_index - first_index + 1` equals `raw_values.len()`. The function only checks that `raw_values` is not empty. At lines 347-348, when `last_received_index >= last_stream_index`, the stream is immediately marked complete based solely on this unvalidated field.

**Missing Data Detection Mechanism:**

The system does attempt to detect incomplete responses by comparing received versus requested counts: [2](#0-1) 

At line 1124, the check correctly uses `raw_values.len()` to determine if data is missing. When `num_received_state_values < num_requested_state_values`, a missing data request is created and sent.

**The Race Condition:**

The vulnerability is exploited through the ordering in the response processing loop: [3](#0-2) 

At line 473, `request_missing_data()` detects incomplete data and creates a missing data request. At line 502, `send_data_notification_to_client()` calls `transform_client_response_into_notification()` which marks `stream_is_complete = true` based on the manipulated `last_index`. At line 514, the loop breaks due to head-of-line blocking.

**Stream Completion Prevents Recovery:**

On the next iteration, the early completion check prevents processing pending responses: [4](#0-3) 

At line 446, `is_stream_complete()` returns true due to the manipulated flag. The function returns early at line 453, and the missing data request that was queued is never processed.

**Bootstrapper Validation Is Too Late:**

The `StateValueChunkWithProof` struct has a TODO comment indicating proof verification is not implemented: [5](#0-4) 

The validation that would catch the manipulation exists in the bootstrapper: [6](#0-5) 

At lines 938-946, the check verifies `last_index - first_index + 1 == raw_values.len()`. However, by this point the data stream has already terminated, making recovery impossible. The bootstrapper can only reset the stream and retry: [7](#0-6) 

**Attack Execution:**

1. Syncing node requests state values for indices 50-99 (50 values expected)
2. Malicious peer responds with:
   - `first_index = 50`
   - `last_index = 99` (manipulated to equal `last_stream_index`)
   - `raw_values` containing only 10 items (indices 50-59)
3. `create_missing_state_values_request()` detects missing data (10 < 50) and creates request for indices 60-99
4. `transform_client_response_into_notification()` marks stream complete (99 >= 99)
5. Next iteration: `process_data_responses()` returns early, missing data request never processed
6. Bootstrapper receives incomplete data, validation fails, stream reset
7. State sync retries from beginning, potentially selecting another malicious peer

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria for **Validator Node Slowdowns**:

**Operational Impact**: Nodes attempting to sync will repeatedly fail and restart state synchronization. Each failed attempt consumes network bandwidth, CPU cycles, and storage I/O before failing validation. With multiple malicious peers in the network, nodes may experience prolonged synchronization failures requiring operator intervention.

**Affected Operations**:
- New validators joining the network and performing initial state sync
- Existing validators recovering from downtime or corruption
- Full nodes bootstrapping from snapshots
- Archival nodes performing historical state reconstruction

**Not a Consensus Violation**: This vulnerability does not break consensus safety or liveness. Validators that are already synced continue operating normally. The bootstrapper's validation layer prevents acceptance of corrupted state. However, it creates significant operational barriers to node synchronization.

**Resource Exhaustion**: Repeated sync failures consume resources without progress, effectively creating a denial-of-service condition for syncing nodes without being a network-level DoS attack (which is out of scope).

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements**:
- Ability to participate as a peer in the Aptos P2P network (publicly accessible)
- Ability to respond to state sync data requests (standard peer functionality)
- No special privileges, validator status, or stake required

**Attack Complexity: LOW**
- Single malicious response per sync attempt
- No precise timing required beyond normal request-response flow
- Deterministic outcome once the malicious response is processed
- Attack is undetectable until stream termination

**Frequency**:
This vulnerability triggers on EVERY state sync attempt where a malicious peer is selected to serve data. Given that:
- Peer selection includes any connected peer in the network
- State synchronization is a critical operation for node bootstrapping and recovery
- Multiple peers may respond to data requests
- The attack leaves no traces until validation failure

In networks with any malicious peers, this vulnerability will manifest frequently and cause repeated operational failures.

## Recommendation

Implement early validation of `last_index` consistency in `transform_client_response_into_notification()` before using it for stream completion:

```rust
// In transform_client_response_into_notification(), after extracting last_index:
ResponsePayload::StateValuesWithProof(state_values_with_proof) => {
    // Verify that we received at least one state value
    if state_values_with_proof.raw_values.is_empty() {
        return Err(Error::AptosDataClientResponseIsInvalid(...));
    }

    // NEW: Verify last_index matches actual data received
    let expected_last_index = state_values_with_proof.first_index
        .checked_add(state_values_with_proof.raw_values.len() as u64)
        .and_then(|v| v.checked_sub(1))
        .ok_or_else(|| Error::IntegerOverflow(...))?;
    
    if state_values_with_proof.last_index != expected_last_index {
        return Err(Error::AptosDataClientResponseIsInvalid(format!(
            "last_index mismatch: claimed {}, expected {} based on {} values",
            state_values_with_proof.last_index,
            expected_last_index,
            state_values_with_proof.raw_values.len()
        )));
    }

    // Get the last received state index
    state_values_with_proof.last_index
}
```

This ensures the stream completion logic operates on validated data, preventing premature termination from manipulated responses.

## Proof of Concept

The vulnerability can be demonstrated by constructing a malicious `StateValueChunkWithProof` response:

```rust
// Create a state values chunk with manipulated last_index
let malicious_chunk = StateValueChunkWithProof {
    first_index: 50,
    last_index: 99,  // Manipulated: claims 50 values
    first_key: HashValue::zero(),
    last_key: HashValue::zero(),
    raw_values: vec![
        (StateKey::raw(&[0]), StateValue::new_legacy(vec![].into())),
        // Only 10 items instead of 50
        (StateKey::raw(&[9]), StateValue::new_legacy(vec![].into())),
    ], // len() = 10, but last_index claims 50 values
    proof: SparseMerkleRangeProof::new(vec![]),
    root_hash: HashValue::zero(),
};

// This response will cause:
// 1. create_missing_state_values_request() to detect 40 missing values
// 2. transform_client_response_into_notification() to mark stream complete
// 3. Missing data request to never be processed
// 4. Bootstrapper validation to fail on index mismatch
```

The existing test infrastructure in `state-sync/data-streaming-service/src/tests/missing_data.rs` can be extended to reproduce this scenario by creating a chunk where `last_index - first_index + 1 > raw_values.len()`.

---

**Notes**: This vulnerability represents a logic flaw in the layered validation approach where stream completion decisions are made before data integrity validation. The bootstrapper's validation is sound but occurs too late to prevent resource waste from incomplete sync attempts. The fix should move index consistency validation earlier in the pipeline to the data streaming layer.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L318-350)
```rust
                // Identify the last received state index and bound it appropriately
                let last_received_index = match &client_response_payload {
                    ResponsePayload::StateValuesWithProof(state_values_with_proof) => {
                        // Verify that we received at least one state value
                        if state_values_with_proof.raw_values.is_empty() {
                            return Err(Error::AptosDataClientResponseIsInvalid(format!(
                                "Received an empty state values response! Request: {:?}",
                                client_request
                            )));
                        }

                        // Get the last received state index
                        state_values_with_proof.last_index
                    },
                    _ => invalid_response_type!(client_response_payload),
                };
                let last_received_index =
                    bound_by_range(last_received_index, request.start_index, request.end_index);

                // Update the next stream index
                self.next_stream_index = last_received_index.checked_add(1).ok_or_else(|| {
                    Error::IntegerOverflow("Next stream index has overflown!".into())
                })?;

                // Check if the stream is complete
                let last_stream_index = self
                    .get_number_of_states()?
                    .checked_sub(1)
                    .ok_or_else(|| Error::IntegerOverflow("End index has overflown!".into()))?;
                if last_received_index >= last_stream_index {
                    self.stream_is_complete = true;
                }

```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L442-520)
```rust
    pub async fn process_data_responses(
        &mut self,
        global_data_summary: GlobalDataSummary,
    ) -> Result<(), Error> {
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
        }

        // Continuously process any ready data responses
        while let Some(pending_response) = self.pop_pending_response_queue()? {
            // Get the client request and response information
            let maybe_client_response = pending_response.lock().client_response.take();
            let client_response = maybe_client_response.ok_or_else(|| {
                Error::UnexpectedErrorEncountered("The client response should be ready!".into())
            })?;
            let client_request = &pending_response.lock().client_request.clone();

            // Process the client response
            match client_response {
                Ok(client_response) => {
                    // Sanity check and process the response
                    if sanity_check_client_response_type(client_request, &client_response) {
                        // If the response wasn't enough to satisfy the original request (e.g.,
                        // it was truncated), missing data should be requested.
                        let mut head_of_line_blocked = false;
                        match self.request_missing_data(client_request, &client_response.payload) {
                            Ok(missing_data_requested) => {
                                if missing_data_requested {
                                    head_of_line_blocked = true; // We're now head of line blocked on the missing data
                                }
                            },
                            Err(error) => {
                                warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
                                    .stream_id(self.data_stream_id)
                                    .event(LogEvent::Error)
                                    .error(&error)
                                    .message("Failed to determine if missing data was requested!"));
                            },
                        }

                        // If the request was a subscription request and the subscription
                        // stream is lagging behind the data advertisements, the stream
                        // engine should be notified (e.g., so that it can catch up).
                        if client_request.is_subscription_request() {
                            if let Err(error) = self.check_subscription_stream_lag(
                                &global_data_summary,
                                &client_response.payload,
                            ) {
                                self.notify_new_data_request_error(client_request, error)?;
                                head_of_line_blocked = true; // We're now head of line blocked on the failed stream
                            }
                        }

                        // The response is valid, send the data notification to the client
                        self.send_data_notification_to_client(client_request, client_response)
                            .await?;

                        // If the request is for specific data, increase the prefetching limit.
                        // Note: we don't increase the limit for new data requests because
                        // those don't invoke the prefetcher (as we're already up-to-date).
                        if !client_request.is_new_data_request() {
                            self.dynamic_prefetching_state
                                .increase_max_concurrent_requests();
                        }

                        // If we're head of line blocked, we should return early
                        if head_of_line_blocked {
                            break;
                        }
                    } else {
                        // The sanity check failed
                        self.handle_sanity_check_failure(client_request, &client_response.context)?;
                        break; // We're now head of line blocked on the failed request
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L1107-1146)
```rust
fn create_missing_state_values_request(
    request: &StateValuesWithProofRequest,
    response_payload: &ResponsePayload,
) -> Result<Option<DataClientRequest>, Error> {
    // Determine the number of requested state values
    let num_requested_state_values = request
        .end_index
        .checked_sub(request.start_index)
        .and_then(|v| v.checked_add(1))
        .ok_or_else(|| {
            Error::IntegerOverflow("Number of requested state values has overflown!".into())
        })?;

    // Identify the missing data if the request was not satisfied
    match response_payload {
        ResponsePayload::StateValuesWithProof(state_values_with_proof) => {
            // Check if the request was satisfied
            let num_received_state_values = state_values_with_proof.raw_values.len() as u64;
            if num_received_state_values < num_requested_state_values {
                let start_index = request
                    .start_index
                    .checked_add(num_received_state_values)
                    .ok_or_else(|| Error::IntegerOverflow("Start index has overflown!".into()))?;
                Ok(Some(DataClientRequest::StateValuesWithProof(
                    StateValuesWithProofRequest {
                        version: request.version,
                        start_index,
                        end_index: request.end_index,
                    },
                )))
            } else {
                Ok(None) // The request was satisfied!
            }
        },
        payload => Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Invalid response payload found for state values request: {:?}",
            payload
        ))),
    }
}
```

**File:** types/src/state_store/state_value.rs (L337-353)
```rust
/// TODO(joshlind): add a proof implementation (e.g., verify()) and unit tests
/// for these once we start supporting them.
///
/// A single chunk of all state values at a specific version.
/// Note: this is similar to `StateSnapshotChunk` but all data is included
/// in the struct itself and not behind pointers/handles to file locations.
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub struct StateValueChunkWithProof {
    pub first_index: u64,     // The first hashed state index in chunk
    pub last_index: u64,      // The last hashed state index in chunk
    pub first_key: HashValue, // The first hashed state key in chunk
    pub last_key: HashValue,  // The last hashed state key in chunk
    pub raw_values: Vec<(StateKey, StateValue)>, // The hashed state key and and raw state value.
    pub proof: SparseMerkleRangeProof, // The proof to ensure the chunk is in the hashed states
    pub root_hash: HashValue, // The root hash of the sparse merkle tree for this chunk
}
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L938-956)
```rust
        let expected_num_state_values = state_value_chunk_with_proof
            .last_index
            .checked_sub(state_value_chunk_with_proof.first_index)
            .and_then(|version| version.checked_add(1)) // expected_num_state_values = last_index - first_index + 1
            .ok_or_else(|| {
                Error::IntegerOverflow("The expected number of state values has overflown!".into())
            })?;
        let num_state_values = state_value_chunk_with_proof.raw_values.len() as u64;
        if expected_num_state_values != num_state_values {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::VerificationError(format!(
                "The expected number of state values was invalid! Expected: {:?}, received: {:?}",
                expected_num_state_values, num_state_values,
            )));
        }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1539-1556)
```rust
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```
