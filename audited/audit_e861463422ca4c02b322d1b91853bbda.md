# Audit Report

## Title
Transaction Hash Index Inconsistency Due to Unsafe Pruning Logic

## Summary
The transaction pruning system contains a critical flaw where `prune_transaction_by_hash_indices` unconditionally deletes transaction hash mappings without verifying which version the hash currently references. If the same transaction hash appears at multiple versions, pruning can orphan later versions by deleting their hash index, causing `get_transaction_by_hash()` to return `None` even though the transaction exists in storage.

## Finding Description

The vulnerability exists in the transaction pruning workflow: [1](#0-0) 

The `prune_transaction_by_hash_indices` method unconditionally deletes transaction hashes without checking which version they currently map to: [2](#0-1) 

When storing transactions, the hash-to-version mapping uses a simple key-value put operation that overwrites any existing mapping: [3](#0-2) 

**Attack Scenario:**
1. Transaction T1 with hash H stored at version V1 → `TransactionByHashSchema[H] = V1`
2. Through state sync or restore, transaction T2 with same hash H stored at version V2 → `TransactionByHashSchema[H] = V2` (overwrites V1)
3. Pruning versions [V1, V2) executes:
   - Reads transaction at V1, computes hash H
   - Deletes H from TransactionByHashSchema
   - Deletes V1 from TransactionSchema
4. **Result**: Version V2 still contains transaction with hash H, but hash index is deleted
5. `get_transaction_by_hash(H)` returns None despite transaction existing at V2 [4](#0-3) 

The lookup logic depends entirely on TransactionByHashSchema, so a missing entry causes incorrect results.

**Exploitation Paths:**
- State sync processing duplicate transactions during network synchronization
- Backup/restore operations that replay transactions at different versions
- Database corruption or crash recovery scenarios
- Theoretically possible (though cryptographically unlikely) SHA3-256 hash collisions

State sync and restore operations use the same `put_transaction` method, making duplicate hash storage possible: [5](#0-4) 

## Impact Explanation

**Severity: Medium to High**

This violates the **State Consistency** critical invariant (#4) by creating divergence between TransactionByHashSchema and TransactionSchema. 

**Impact:**
- API queries using `get_transaction_by_hash()` return incorrect results (None instead of actual transaction)
- External services, indexers, and wallets relying on hash-based lookups receive wrong data
- Different nodes with different pruning histories may have inconsistent hash indices
- State sync and restore operations could be disrupted
- Violates the fundamental assumption that transaction lookups by hash are reliable

While this doesn't directly cause fund loss or consensus violations, it creates **state inconsistencies requiring intervention** (Medium severity per bug bounty) and potentially **significant protocol violations** (High severity).

## Likelihood Explanation

**Likelihood: Low to Medium**

While user transactions are protected by replay protection (sequence numbers/nonces), several scenarios make this exploitable:

1. **State Sync Edge Cases**: Network synchronization could process the same transaction data at different version ranges during catch-up or reorgs
2. **Restore Operations**: Backup restoration from overlapping snapshots might store identical transactions at different versions
3. **System Transactions**: BlockMetadata, StateCheckpoint, and ValidatorTransaction variants might have implementation bugs allowing duplicate hashes
4. **Database Corruption**: Partial writes or crash recovery could create inconsistent states

The lack of validation in the storage layer makes this a defensive programming failure - the code assumes hash uniqueness but doesn't enforce it.

## Recommendation

Add version verification before deleting hash indices. The pruner should only delete a hash if it currently points to a version being pruned:

```rust
pub(crate) fn prune_transaction_by_hash_indices(
    &self,
    transaction_hashes_with_versions: impl Iterator<Item = (HashValue, Version)>,
    db_batch: &mut SchemaBatch,
) -> Result<()> {
    for (hash, pruning_version) in transaction_hashes_with_versions {
        // Only delete if the hash currently maps to the version being pruned
        if let Some(current_version) = self.db.get::<TransactionByHashSchema>(&hash)? {
            if current_version == pruning_version {
                db_batch.delete::<TransactionByHashSchema>(&hash)?;
            }
        }
    }
    Ok(())
}
```

Update the caller to pass version information:

```rust
self.ledger_db
    .transaction_db()
    .prune_transaction_by_hash_indices(
        candidate_transactions.iter().map(|(version, txn)| (txn.hash(), *version)),
        &mut batch,
    )?;
```

## Proof of Concept

```rust
#[test]
fn test_prune_with_duplicate_hash_at_different_versions() {
    use aptos_crypto::hash::CryptoHash;
    use aptos_temppath::TempPath;
    use crate::AptosDB;
    
    let tmp_dir = TempPath::new();
    let db = AptosDB::new_for_test(&tmp_dir);
    let transaction_db = db.ledger_db.transaction_db();
    
    // Create two transactions - in practice, these would need the same hash
    // This PoC demonstrates the logic flaw assuming duplicate hashes exist
    let txn1 = create_test_transaction(/* params */);
    let txn2 = create_test_transaction(/* params */);
    
    // Store transaction at V1
    transaction_db.commit_transactions(1, &[txn1.clone()], false).unwrap();
    let hash = txn1.hash();
    
    // Verify hash lookup works
    assert_eq!(
        transaction_db.get_transaction_version_by_hash(&hash, 100).unwrap(),
        Some(1)
    );
    
    // Store transaction with same hash at V2 (overwrites hash index)
    transaction_db.commit_transactions(2, &[txn2.clone()], false).unwrap();
    assert_eq!(
        transaction_db.get_transaction_version_by_hash(&hash, 100).unwrap(),
        Some(2)
    );
    
    // Prune V1 (which deletes hash unconditionally)
    let mut batch = SchemaBatch::new();
    transaction_db.prune_transaction_by_hash_indices(
        std::iter::once(hash),
        &mut batch
    ).unwrap();
    transaction_db.prune_transactions(1, 2, &mut batch).unwrap();
    transaction_db.write_schemas(batch).unwrap();
    
    // BUG: Hash lookup now returns None even though V2 exists
    assert_eq!(
        transaction_db.get_transaction_version_by_hash(&hash, 100).unwrap(),
        None  // Should be Some(2)!
    );
    
    // But transaction still exists at V2
    assert!(transaction_db.get_transaction(2).is_ok());
}
```

**Note**: This PoC requires a method to create transactions with identical hashes, which is currently not possible through normal means due to replay protection. However, it demonstrates the logic flaw in the pruning system that would manifest if duplicate hashes ever occur through state sync, restore, or other edge cases.

---

## Notes

The vulnerability depends on the ability to store transactions with duplicate hashes at different versions. While user transactions are protected by replay protection mechanisms, the storage layer itself provides no validation against duplicate hash storage. This represents a gap in defensive programming where the pruning logic assumes an invariant (hash uniqueness across versions) without enforcing it. State sync, backup/restore operations, and potential bugs in transaction processing could violate this assumption, leading to storage inconsistencies.

### Citations

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L74-83)
```rust
    pub(crate) fn get_transaction_version_by_hash(
        &self,
        hash: &HashValue,
        ledger_version: Version,
    ) -> Result<Option<Version>> {
        Ok(match self.db.get::<TransactionByHashSchema>(hash)? {
            Some(version) if version <= ledger_version => Some(version),
            _ => None,
        })
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L148-163)
```rust
        let transaction_hash = transaction.hash();

        if let Some(signed_txn) = transaction.try_as_signed_user_txn() {
            let txn_summary = IndexedTransactionSummary::V1 {
                sender: signed_txn.sender(),
                replay_protector: signed_txn.replay_protector(),
                version,
                transaction_hash,
            };
            batch.put::<TransactionSummariesByAccountSchema>(
                &(signed_txn.sender(), version),
                &txn_summary,
            )?;
        }
        batch.put::<TransactionByHashSchema>(&transaction_hash, &version)?;
        batch.put::<TransactionSchema>(&version, transaction)?;
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L182-191)
```rust
    pub(crate) fn prune_transaction_by_hash_indices(
        &self,
        transaction_hashes: impl Iterator<Item = HashValue>,
        db_batch: &mut SchemaBatch,
    ) -> Result<()> {
        for hash in transaction_hashes {
            db_batch.delete::<TransactionByHashSchema>(&hash)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-46)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L206-213)
```rust
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }
```
