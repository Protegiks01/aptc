# Audit Report

## Title
Unvalidated Compression Flag Enables Resource Exhaustion Attack on Validator Storage Service

## Summary
The `use_compression` flag in `StorageServiceRequest` lacks validation, allowing any Public fullnode to force validators to perform expensive compression operations on all responses. This can exhaust the limited blocking thread pool (64 threads), causing validator slowdowns and affecting consensus operations.

## Finding Description
The storage service accepts requests from Public fullnodes with a client-controlled `use_compression` boolean flag. When set to `true`, the server performs CPU-intensive LZ4 compression on response data without any validation or rate limiting specific to compression requests. [1](#0-0) 

The request flow processes compression unconditionally:

1. **No Validation on Compression Flag**: The `RequestModerator` validates whether the request can be serviced (data availability) but never checks the compression flag. [2](#0-1) 

2. **Blocking Task Per Request**: Each storage service request spawns a blocking task on a shared thread pool limited to 64 threads. [3](#0-2) 

3. **Compression Performed Unconditionally**: When `use_compression` is true, the server serializes and compresses the response using LZ4. [4](#0-3) 

4. **LRU Cache Ineffective**: The cache key includes the `use_compression` flag, so identical requests with different compression settings create separate cache entries. [5](#0-4) 

**Attack Scenario:**
A malicious Public fullnode sends 100+ concurrent valid storage requests (e.g., `GetTransactionsWithProof` with different version ranges) all with `use_compression=true`. Each request:
- Passes validation (data exists)
- Spawns a blocking task
- Fetches data from storage
- Serializes response (~600KB per chunk)
- Compresses using LZ4 (CPU-intensive)

With only 64 blocking threads available, requests 65+ queue up. Since consensus, execution, and other critical services share this thread pool, they experience delays. The `RequestModerator` doesn't block these requests because they are valid (data is serviceable), only invalid requests trigger peer penalties. [6](#0-5) 

## Impact Explanation
This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria because it enables "Validator node slowdowns." By exhausting the blocking thread pool shared across consensus, execution, and storage operations, an attacker can:

- Delay block execution and commitment
- Slow down state synchronization
- Impact consensus message processing (which uses `spawn_blocking` for cryptographic operations)
- Degrade overall validator performance

The blocking thread pool configuration is limited to 64 threads across all node operations. [7](#0-6) 

## Likelihood Explanation
**High likelihood** - The attack requires:
- Running a Public fullnode (no special privileges)
- Sending valid RPC requests (standard network protocol)
- Basic knowledge of storage service API

The storage service is designed to accept requests from Public networks, making this attack surface readily accessible. [8](#0-7) 

No authentication beyond network-level peer validation is required. The `max_network_channel_size` (4000) limits queued requests but doesn't prevent the attackâ€”it just means 4000 compression requests can queue concurrently. [9](#0-8) 

## Recommendation
Implement one or more of the following mitigations:

**Option 1: Server-Controlled Compression**
Remove client control over compression. The server decides when to compress based on response size and peer reputation:

```rust
impl StorageServiceRequest {
    pub fn new(data_request: DataRequest) -> Self {
        Self {
            data_request,
            // Remove use_compression from client control
        }
    }
}

// In handler.rs, server decides compression:
fn should_compress_response(
    &self,
    peer_network_id: &PeerNetworkId,
    response_size: usize,
) -> bool {
    // Only compress for trusted networks or large responses
    if peer_network_id.network_id().is_validator_network() {
        return response_size > COMPRESSION_THRESHOLD;
    }
    // Rate limit compression for public networks
    false
}
```

**Option 2: Per-Peer Compression Rate Limiting**
Track compression requests per peer in `RequestModerator`:

```rust
pub struct UnhealthyPeerState {
    compression_request_count: u64,
    last_compression_window_start: Instant,
    max_compression_requests_per_window: u64,
    // ... existing fields
}

pub fn validate_compression_request(
    &mut self,
    peer_network_id: &PeerNetworkId,
    use_compression: bool,
) -> Result<(), Error> {
    if use_compression && peer_network_id.network_id().is_public_network() {
        // Allow max 10 compression requests per 10 seconds
        if self.compression_request_count >= self.max_compression_requests_per_window {
            return Err(Error::TooManyCompressionRequests(
                "Peer exceeded compression request rate limit".into()
            ));
        }
        self.compression_request_count += 1;
    }
    Ok(())
}
```

**Option 3: Separate Compression Thread Pool**
Isolate compression operations from critical consensus/execution threads using a dedicated bounded executor.

## Proof of Concept

```rust
// Malicious client PoC (pseudo-code demonstrating attack)
use aptos_storage_service_types::{
    requests::{StorageServiceRequest, DataRequest, TransactionsWithProofRequest},
};
use tokio::task::JoinSet;

#[tokio::main]
async fn main() {
    let mut tasks = JoinSet::new();
    
    // Get current ledger version
    let latest_version = get_latest_version().await;
    
    // Spawn 100 concurrent requests with compression enabled
    for i in 0..100 {
        let start_version = i * 100;
        let end_version = start_version + 99;
        
        tasks.spawn(async move {
            let request = StorageServiceRequest::new(
                DataRequest::GetTransactionsWithProof(
                    TransactionsWithProofRequest {
                        proof_version: latest_version,
                        start_version,
                        end_version,
                        include_events: false,
                    }
                ),
                true, // Force expensive compression
            );
            
            // Send request to validator storage service
            send_storage_service_request(request).await
        });
    }
    
    // All 100 requests execute concurrently, exhausting blocking threads
    // Requests 65+ queue up, causing validator slowdown
    while let Some(result) = tasks.join_next().await {
        println!("Request completed: {:?}", result);
    }
}
```

**Expected Impact**: Validator blocking thread pool saturates at 64 threads. Additional compression requests queue, delaying consensus and execution operations that depend on `spawn_blocking`.

**Notes**
- The vulnerability exists because compression is expensive but client-controlled
- The LRU cache provides no protection since cache keys include the compression flag
- Valid requests with compression bypass `RequestModerator` peer penalties
- The shared blocking thread pool creates a single point of resource contention across all validator operations

### Citations

**File:** state-sync/storage-service/types/src/requests.rs (L10-13)
```rust
pub struct StorageServiceRequest {
    pub data_request: DataRequest, // The data to fetch from the storage service
    pub use_compression: bool,     // Whether or not the client wishes data to be compressed
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-189)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
```

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/types/src/responses.rs (L74-94)
```rust
    pub fn new(data_response: DataResponse, perform_compression: bool) -> Result<Self, Error> {
        if perform_compression {
            // Serialize and compress the raw data
            let raw_data = bcs::to_bytes(&data_response)
                .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
            let compressed_data = aptos_compression::compress(
                raw_data,
                CompressionClient::StateSync,
                MAX_APPLICATION_MESSAGE_SIZE,
            )?;

            // Create the compressed response
            let label = data_response.get_label().to_string() + COMPRESSION_SUFFIX_LABEL;
            Ok(StorageServiceResponse::CompressedResponse(
                label,
                compressed_data,
            ))
        } else {
            Ok(StorageServiceResponse::RawResponse(data_response))
        }
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L396-404)
```rust
        // Check if the response is already in the cache
        if let Some(response) = self.lru_response_cache.get(request) {
            increment_counter(
                &metrics::LRU_CACHE_EVENT,
                peer_network_id.network_id(),
                LRU_CACHE_HIT.into(),
            );
            return Ok(response.clone());
        }
```

**File:** crates/aptos-runtimes/src/lib.rs (L1-1)
```rust
// Copyright (c) Aptos Foundation
```

**File:** aptos-node/src/network.rs (L147-167)
```rust
pub fn storage_service_network_configuration(node_config: &NodeConfig) -> NetworkApplicationConfig {
    let direct_send_protocols = vec![]; // The storage service does not use direct send
    let rpc_protocols = vec![ProtocolId::StorageServiceRpc];
    let max_network_channel_size = node_config
        .state_sync
        .storage_service
        .max_network_channel_size as usize;

    let network_client_config =
        NetworkClientConfig::new(direct_send_protocols.clone(), rpc_protocols.clone());
    let network_service_config = NetworkServiceConfig::new(
        direct_send_protocols,
        rpc_protocols,
        aptos_channel::Config::new(max_network_channel_size)
            .queue_style(QueueStyle::FIFO)
            .counters(
                &aptos_storage_service_server::metrics::PENDING_STORAGE_SERVER_NETWORK_EVENTS,
            ),
    );
    NetworkApplicationConfig::new(network_client_config, network_service_config)
}
```

**File:** config/src/config/state_sync_config.rs (L196-217)
```rust
    fn default() -> Self {
        Self {
            enable_size_and_time_aware_chunking: false,
            enable_transaction_data_v2: true,
            max_epoch_chunk_size: MAX_EPOCH_CHUNK_SIZE,
            max_invalid_requests_per_peer: 500,
            max_lru_cache_size: 500, // At ~0.6MiB per chunk, this should take no more than 0.5GiB
            max_network_channel_size: 4000,
            max_network_chunk_bytes: SERVER_MAX_MESSAGE_SIZE as u64,
            max_network_chunk_bytes_v2: SERVER_MAX_MESSAGE_SIZE_V2 as u64,
            max_num_active_subscriptions: 30,
            max_optimistic_fetch_period_ms: 5000, // 5 seconds
            max_state_chunk_size: MAX_STATE_CHUNK_SIZE,
            max_storage_read_wait_time_ms: 10_000, // 10 seconds
            max_subscription_period_ms: 30_000,    // 30 seconds
            max_transaction_chunk_size: MAX_TRANSACTION_CHUNK_SIZE,
            max_transaction_output_chunk_size: MAX_TRANSACTION_OUTPUT_CHUNK_SIZE,
            min_time_to_ignore_peers_secs: 300, // 5 minutes
            request_moderator_refresh_interval_ms: 1000, // 1 second
            storage_summary_refresh_interval_ms: 100, // Optimal for <= 10 blocks per second
        }
    }
```
