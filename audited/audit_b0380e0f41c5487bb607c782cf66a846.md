# Audit Report

## Title
Epoch Transition Liveness Failure Due to Single-Point Self-Message Dependency

## Summary
The `send_epoch_change()` function sends epoch change notifications exclusively to `self.author`, creating a single point of failure. If the self-message delivery fails (e.g., due to channel closure during concurrent shutdown), the node will not initiate epoch transition and will remain stuck in the old epoch until it reactively receives a message from a peer in the new epoch.

## Finding Description

The Aptos consensus system uses `send_epoch_change()` to trigger epoch transitions in two critical paths:

**Path 1: DAG State Sync** [1](#0-0) 

**Path 2: Persisting Phase** [2](#0-1) 

The `send_epoch_change()` implementation only sends to self: [3](#0-2) 

This invokes the `send()` function, which attempts self-delivery through an unbounded channel: [4](#0-3) 

**Critical Issue:** If the self-message send fails (line 418), only a warning is logged (line 419), and execution continues. The node never receives the `EpochChangeProof`, so `initiate_new_epoch()` is never triggered: [5](#0-4) 

**When Self-Messages Can Fail:**
1. During `shutdown_current_processor()` if the receiver is dropped before the self-message is processed [6](#0-5) 

2. Concurrent epoch transitions where the NetworkTask receiver is closed/dropped while a self-message is being sent

3. System resource exhaustion causing receiver task failure

**Recovery Mechanism:** A reactive recovery exists through `process_different_epoch()`: [7](#0-6) 

However, this requires receiving a message from a peer already in the new epoch, making recovery dependent on network activity and peer behavior.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program due to:

1. **Validator node slowdowns**: Affected nodes cannot participate in consensus during the epoch transition period
2. **Significant protocol violations**: Breaks the liveness guarantee that all honest nodes should transition epochs together

**Impact scenarios:**
- Single node: Temporary loss of consensus participation until peer message triggers recovery
- Multiple nodes: If systemically triggered (e.g., during network-wide upgrades with concurrent shutdowns), could delay or prevent epoch transitions
- Reduced network capacity: During epoch transitions, affected nodes cannot vote or propose blocks

This does NOT constitute Critical severity because:
- No permanent network partition (recovery mechanism exists)
- No loss of funds
- No consensus safety violation (only liveness/availability)

## Likelihood Explanation

**Likelihood: Medium**

The issue can occur in realistic scenarios:

1. **Concurrent shutdown during epoch change**: If a node's components are shutting down (e.g., during restart or upgrade) at the exact moment an epoch ends, the self_sender channel's receiver may be dropped before the self-message is delivered

2. **Race condition**: The `shutdown_current_processor()` drops various receivers. If `send_epoch_change()` is called during or immediately after shutdown initiation, the message will fail

3. **System instability**: Under resource pressure or during crashes, receiver tasks may terminate unexpectedly

**Mitigation factors reducing likelihood:**
- Unbounded channels reduce buffer overflow risk
- Recovery mechanism provides eventual consistency
- Most epoch transitions occur during planned periods with lower concurrent activity

## Recommendation

Replace self-only messaging with a more robust approach:

**Option 1: Use RPC with guaranteed delivery**
```rust
pub async fn send_epoch_change(&self, proof: EpochChangeProof) {
    fail_point!("consensus::send::epoch_change", |_| ());
    let msg = ConsensusMsg::EpochChangeProof(Box::new(proof));
    // Use RPC to self with retry logic
    match self.send_rpc(self.author, msg, Duration::from_millis(1000)).await {
        Ok(_) => {},
        Err(e) => {
            error!("Failed to send epoch change to self: {:?}, broadcasting to all peers", e);
            // Fallback: broadcast to all validators
            self.broadcast_epoch_change(proof).await;
        }
    }
}
```

**Option 2: Always broadcast epoch changes**
```rust
pub async fn send_epoch_change(&self, proof: EpochChangeProof) {
    fail_point!("consensus::send::epoch_change", |_| ());
    // Broadcast to all validators for redundancy
    self.broadcast_epoch_change(proof).await
}
```

**Option 3: Direct invocation**
```rust
// In dag_state_sync.rs and persisting_phase.rs, directly call initiate_new_epoch
// instead of relying on message passing
```

Option 2 is recommended as it provides maximum redundancy by leveraging the existing `broadcast_epoch_change()` implementation used in the sync manager: [8](#0-7) 

## Proof of Concept

```rust
#[tokio::test]
async fn test_epoch_change_self_message_failure() {
    use aptos_channels;
    use consensus::network::{NetworkSender, NetworkTask};
    use aptos_types::epoch_change::EpochChangeProof;
    
    // Setup: Create NetworkSender with self_sender
    let (self_sender, self_receiver) = aptos_channels::new_unbounded_test();
    let network_sender = Arc::new(NetworkSender::new(
        author,
        consensus_network_client,
        self_sender,
        validators,
    ));
    
    // Start NetworkTask that consumes self_receiver
    let (network_task, receivers) = NetworkTask::new(
        network_service_events,
        self_receiver,
    );
    let task_handle = tokio::spawn(network_task.start());
    
    // Simulate epoch ending in persisting phase
    let epoch_change_proof = create_test_epoch_change_proof();
    
    // Step 1: Drop the NetworkTask (simulating shutdown/crash)
    drop(task_handle);
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Step 2: Try to send epoch change - this will fail silently
    network_sender.send_epoch_change(epoch_change_proof.clone()).await;
    
    // Step 3: Verify that epoch_manager never receives the proof
    // and remains stuck in old epoch
    
    // Expected: Node stuck in old epoch until peer message triggers recovery
    // Actual: Warning logged but no retry, no broadcast, no direct invocation
}
```

**Notes:**
- The vulnerability stems from architectural design rather than implementation bugs
- Recovery mechanism provides eventual consistency but introduces latency
- The issue is exacerbated during concurrent operations (shutdown + epoch change)
- Broadcast approach used in sync_manager (line 193) demonstrates the preferred pattern for critical messages

### Citations

**File:** consensus/src/dag/dag_state_sync.rs (L95-102)
```rust
        if ledger_info_with_sigs.ledger_info().ends_epoch() {
            self.proof_notifier
                .send_epoch_change(EpochChangeProof::new(
                    vec![ledger_info_with_sigs.clone()],
                    /* more = */ false,
                ))
                .await;
            return Ok(SyncOutcome::EpochEnds);
```

**File:** consensus/src/pipeline/persisting_phase.rs (L75-79)
```rust
        if commit_ledger_info.ledger_info().ends_epoch() {
            self.commit_msg_tx
                .send_epoch_change(EpochChangeProof::new(vec![commit_ledger_info], false))
                .await;
        }
```

**File:** consensus/src/network.rs (L416-421)
```rust
            if self.author == peer {
                let self_msg = Event::Message(self.author, msg.clone());
                if let Err(err) = self_sender.send(self_msg).await {
                    warn!(error = ?err, "Error delivering a self msg");
                }
                continue;
```

**File:** consensus/src/network.rs (L533-537)
```rust
    pub async fn send_epoch_change(&self, proof: EpochChangeProof) {
        fail_point!("consensus::send::epoch_change", |_| ());
        let msg = ConsensusMsg::EpochChangeProof(Box::new(proof));
        self.send(msg, vec![self.author]).await
    }
```

**File:** consensus/src/epoch_manager.rs (L520-536)
```rust
            Ordering::Greater => {
                let request = EpochRetrievalRequest {
                    start_epoch: self.epoch(),
                    end_epoch: different_epoch,
                };
                let msg = ConsensusMsg::EpochRetrievalRequest(Box::new(request));
                if let Err(err) = self.network_sender.send_to(peer_id, msg) {
                    warn!(
                        "[EpochManager] Failed to send epoch retrieval to {}, {:?}",
                        peer_id, err
                    );
                    counters::EPOCH_MANAGER_ISSUES_DETAILS
                        .with_label_values(&["failed_to_send_epoch_retrieval"])
                        .inc();
                }

                Ok(())
```

**File:** consensus/src/epoch_manager.rs (L637-683)
```rust
    async fn shutdown_current_processor(&mut self) {
        if let Some(close_tx) = self.round_manager_close_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop round manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop round manager");
        }
        self.round_manager_tx = None;

        if let Some(close_tx) = self.dag_shutdown_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
        }
        self.dag_shutdown_tx = None;

        // Shutdown the previous rand manager
        self.rand_manager_msg_tx = None;

        // Shutdown the previous secret share manager
        self.secret_share_manager_tx = None;

        // Shutdown the previous buffer manager, to release the SafetyRule client
        self.execution_client.end_epoch().await;

        // Shutdown the block retrieval task by dropping the sender
        self.block_retrieval_tx = None;
        self.batch_retrieval_tx = None;

        if let Some(mut quorum_store_coordinator_tx) = self.quorum_store_coordinator_tx.take() {
            let (ack_tx, ack_rx) = oneshot::channel();
            quorum_store_coordinator_tx
                .send(CoordinatorCommand::Shutdown(ack_tx))
                .await
                .expect("Could not send shutdown indicator to QuorumStore");
            ack_rx.await.expect("Failed to stop QuorumStore");
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L1655-1675)
```rust
            ConsensusMsg::EpochChangeProof(proof) => {
                let msg_epoch = proof.epoch()?;
                debug!(
                    LogSchema::new(LogEvent::ReceiveEpochChangeProof)
                        .remote_peer(peer_id)
                        .epoch(self.epoch()),
                    "Proof from epoch {}", msg_epoch,
                );
                if msg_epoch == self.epoch() {
                    monitor!("process_epoch_proof", self.initiate_new_epoch(*proof).await)?;
                } else {
                    info!(
                        remote_peer = peer_id,
                        "[EpochManager] Unexpected epoch proof from epoch {}, local epoch {}",
                        msg_epoch,
                        self.epoch()
                    );
                    counters::EPOCH_MANAGER_ISSUES_DETAILS
                        .with_label_values(&["epoch_proof_wrong_epoch"])
                        .inc();
                }
```

**File:** consensus/src/block_storage/sync_manager.rs (L190-198)
```rust
            if qc.ends_epoch() {
                retriever
                    .network
                    .broadcast_epoch_change(EpochChangeProof::new(
                        vec![qc.ledger_info().clone()],
                        /* more = */ false,
                    ))
                    .await;
            }
```
