# Audit Report

## Title
Consensus Divergence Risk from Silent Transaction Discarding During Critical Error Recovery in BCS Fallback Path

## Summary
When resource group serialization failures occur during the BCS fallback execution path, the block executor logs a critical error but continues processing by discarding the failing transaction. If the serialization failure condition is non-deterministic or results from validator state differences, this creates a consensus divergence risk where validators produce different block outputs. [1](#0-0) 

## Finding Description

The `CRITICAL_ERRORS` counter is incremented via the `alert!` macro when critical invariant violations are detected. The security question asks whether incrementing this counter implies safe continuation. Analysis reveals a critical violation of this assumption in the block executor's BCS fallback path. [2](#0-1) 

When sequential block execution encounters resource group serialization errors, the system may enter a BCS fallback mode: [3](#0-2) 

During this fallback execution with `resource_group_bcs_fallback=true`, serialization errors are handled differently than in normal execution: [4](#0-3) 

The critical issue is that when a serialization error is detected, the transaction is discarded and execution **continues to the next transaction**. The error detection logic checks whether the serialized resource group size matches the expected size: [5](#0-4) 

In normal sequential execution (without BCS fallback), the same serialization check returns an error that propagates up: [6](#0-5) 

The resource group size calculation is based on BCS serialization format: [7](#0-6) 

The serialization size mismatch is detected and logged as a critical error: [8](#0-7) 

**Breaking the Deterministic Execution Invariant**: The vulnerability breaks Invariant #1 ("All validators must produce identical state roots for identical blocks"). If the resource group size calculation or serialization check produces different results across validators due to:
- Bugs in size calculation logic
- Non-flushed cache state differences
- Race conditions from prior parallel execution
- Non-deterministic behavior in resource group operations

Then different validators will discard different transactions, producing different `TransactionInfo` hashes that are included in consensus: [9](#0-8) 

## Impact Explanation

This vulnerability represents a **Critical Severity** consensus safety violation per Aptos bug bounty criteria. If triggered, it causes:

1. **Consensus Divergence**: Different validators produce blocks with different transaction sets, leading to different state roots and TransactionInfo accumulator hashes
2. **Non-recoverable Network Partition**: Validators that discarded different transactions cannot reach consensus, potentially requiring a hardfork to resolve
3. **Chain Safety Violation**: Breaks the fundamental BFT safety guarantee that honest validators agree on committed blocks

The `TransactionInfo` structure (which includes the `ExecutionStatus`) is hashed using BCS serialization for inclusion in the transaction accumulator, making any difference in transaction inclusion/exclusion visible in consensus.

## Likelihood Explanation

The likelihood depends on whether the resource group size calculation can produce non-deterministic results or has undiscovered bugs. The comment at line 2400-2401 acknowledges this is a workaround: "The corresponding error / alert must already be triggered, the goal in sequential fallback is to just skip any transactions that would cause such serialization errors."

This admission that errors are being "skipped" rather than properly handled indicates the developers recognized this as a temporary measure. However, the code does not programmatically verify that the error "must already be triggered" - if a new error appears during fallback that wasn't seen before, it's silently discarded without validation that other validators will do the same.

**Triggering Conditions**:
- Resource group operations with complex size calculations
- Transactions involving multiple resource group modifications
- Edge cases in BCS serialization size estimation
- State differences from cache inconsistencies (despite cache flushes at line 2593-2594)

## Recommendation

Critical errors indicating code invariant violations should trigger immediate execution halt rather than silent transaction discarding. Specifically:

1. **Remove Silent Discarding**: When resource group serialization fails in BCS fallback, return a fatal error instead of continuing:

```rust
if serialization_error {
    return Err(SequentialBlockExecutionError::ErrorToReturn(
        BlockExecutionError::FatalBlockExecutorError(code_invariant_error(
            "Resource group serialization failed in BCS fallback - this indicates a critical bug"
        ))
    ));
}
```

2. **Make Fallback Configuration Consensus-Critical**: Move `allow_fallback` from `BlockExecutorLocalConfig` to `BlockExecutorConfigFromOnchain` to ensure all validators use the same fallback behavior: [10](#0-9) 

3. **Add Determinism Verification**: Before discarding any transaction due to critical errors, add assertions that the error condition is deterministic and will be seen by all validators.

4. **Halt on Unrecoverable Errors**: Update the error recovery philosophy to treat resource group serialization mismatches as unrecoverable errors requiring node shutdown for investigation.

## Proof of Concept

While a complete PoC requires identifying specific bugs in resource group size calculation, the vulnerability can be demonstrated conceptually:

```rust
// Hypothetical test showing consensus divergence scenario
#[test]
fn test_consensus_divergence_on_serialization_error() {
    // Setup: Two validators with identical initial state
    let validator_a = setup_validator();
    let validator_b = setup_validator();
    
    // Execute block with resource group transaction
    let block = create_block_with_resource_group_txn();
    
    // If resource group size calculation has any non-determinism:
    // Validator A: size_a = 100, serialized_size = 105 → mismatch → discard txn
    // Validator B: size_b = 105, serialized_size = 105 → match → include txn
    
    let output_a = validator_a.execute_block(block.clone());
    let output_b = validator_b.execute_block(block.clone());
    
    // Result: Different block outputs
    assert_ne!(output_a.state_root(), output_b.state_root());
    // This breaks consensus - validators cannot agree on committed state
}
```

The actual exploitation requires finding a specific trigger for non-deterministic resource group size calculation, which would require deeper investigation into the resource group implementation and size tracking mechanisms.

**Notes**

This vulnerability represents a fundamental design flaw in error recovery: critical errors that indicate code invariant violations should never allow execution to continue, as they may signal non-deterministic behavior that breaks consensus. The BCS fallback path's approach of silently discarding transactions on critical errors violates the principle that validators must produce identical outputs for identical inputs.

The `allow_fallback` configuration being local rather than consensus-critical (lines 51-64 in config.rs) also creates operational inconsistencies where some validators panic while others continue with fallback, though this is a secondary concern compared to the silent transaction discarding issue.

### Citations

**File:** aptos-move/aptos-vm-logging/src/counters.rs (L9-11)
```rust
pub static CRITICAL_ERRORS: Lazy<IntCounter> = Lazy::new(|| {
    register_int_counter!("aptos_vm_critical_errors", "Number of critical errors").unwrap()
});
```

**File:** aptos-move/aptos-vm-logging/src/lib.rs (L164-168)
```rust
macro_rules! alert {
    ($($args:tt)+) => {
	error!($($args)+);
	CRITICAL_ERRORS.inc();
    };
```

**File:** aptos-move/block-executor/src/executor.rs (L2349-2397)
```rust
                        let serialization_error = output_before_guard
                            .group_reads_needing_delayed_field_exchange()
                            .iter()
                            .any(|(group_key, _)| {
                                fail_point!("fail-point-resource-group-serialization", |_| {
                                    true
                                });

                                let (finalized_group, group_size) = finalize(group_key.clone());
                                match bcs::to_bytes(&finalized_group) {
                                    Ok(group) => {
                                        (!finalized_group.is_empty() || group_size.get() != 0)
                                            && group.len() as u64 != group_size.get()
                                    },
                                    Err(_) => true,
                                }
                            })
                            || output_before_guard
                                .resource_group_write_set()
                                .into_iter()
                                .any(|(group_key, (_, output_group_size, group_ops))| {
                                    fail_point!("fail-point-resource-group-serialization", |_| {
                                        true
                                    });

                                    let (mut finalized_group, group_size) = finalize(group_key);
                                    if output_group_size.get() != group_size.get() {
                                        return false;
                                    }
                                    for (value_tag, (group_op, _)) in group_ops {
                                        if group_op.is_deletion() {
                                            finalized_group.remove(&value_tag);
                                        } else {
                                            finalized_group.insert(
                                                value_tag,
                                                group_op
                                                    .extract_raw_bytes()
                                                    .expect("Not a deletion"),
                                            );
                                        }
                                    }
                                    match bcs::to_bytes(&finalized_group) {
                                        Ok(group) => {
                                            (!finalized_group.is_empty() || group_size.get() != 0)
                                                && group.len() as u64 != group_size.get()
                                        },
                                        Err(_) => true,
                                    }
                                });
```

**File:** aptos-move/block-executor/src/executor.rs (L2399-2408)
```rust
                        if serialization_error {
                            // The corresponding error / alert must already be triggered, the goal in sequential
                            // fallback is to just skip any transactions that would cause such serialization errors.
                            alert!("Discarding transaction because serialization failed in bcs fallback");
                            ret.push(E::Output::discard_output(
                                StatusCode::DELAYED_FIELD_OR_BLOCKSTM_CODE_INVARIANT_ERROR,
                            ));
                            idx += 1;
                            continue;
                        }
```

**File:** aptos-move/block-executor/src/executor.rs (L2439-2442)
```rust
                        let serialized_groups =
                            serialize_groups::<T>(materialized_finalized_groups).map_err(|_| {
                                SequentialBlockExecutionError::ResourceGroupSerializationError
                            })?;
```

**File:** aptos-move/block-executor/src/executor.rs (L2613-2630)
```rust
            Err(SequentialBlockExecutionError::ResourceGroupSerializationError) => {
                if !self.config.local.allow_fallback {
                    panic!("Parallel execution failed and fallback is not allowed");
                }

                // TODO[agg_v2](cleanup): check if sequential execution logs anything in the speculative logs,
                // and whether clearing them below is needed at all.
                // All logs from the first pass of sequential execution should be cleared and not reported.
                // Clear by re-initializing the speculative logs.
                init_speculative_logs(signature_verified_block.num_txns());

                let sequential_result = self.execute_transactions_sequential(
                    signature_verified_block,
                    base_view,
                    transaction_slice_metadata,
                    module_cache_manager_guard,
                    true,
                );
```

**File:** aptos-move/aptos-vm-types/src/resolver.rs (L282-324)
```rust
pub enum ResourceGroupSize {
    Concrete(u64),
    /// Combined represents what would the size be if we know individual
    /// parts that contribute to it. This is useful when individual parts
    /// are changing, and we want to know what the size of the group would be.
    ///
    /// Formula is based on how bcs serializes the BTreeMap:
    ///   varint encoding len(num_tagged_resources) + all_tagged_resources_size
    /// Also, if num_tagged_resources is 0, then the size is 0, because we will not store
    /// empty resource group in storage.
    Combined {
        num_tagged_resources: usize,
        all_tagged_resources_size: u64,
    },
}

impl ResourceGroupSize {
    pub fn zero_combined() -> Self {
        Self::Combined {
            num_tagged_resources: 0,
            all_tagged_resources_size: 0,
        }
    }

    pub fn zero_concrete() -> Self {
        Self::Concrete(0)
    }

    pub fn get(&self) -> u64 {
        match self {
            Self::Concrete(size) => *size,
            Self::Combined {
                num_tagged_resources,
                all_tagged_resources_size,
            } => {
                if *num_tagged_resources == 0 {
                    0
                } else {
                    size_u32_as_uleb128(*num_tagged_resources) as u64 + *all_tagged_resources_size
                }
            },
        }
    }
```

**File:** aptos-move/block-executor/src/executor_utilities.rs (L150-164)
```rust
                match bcs::to_bytes(&btree) {
                    Ok(group_bytes) => {
                        if (!btree.is_empty() || group_size.get() != 0)
                            && group_bytes.len() as u64 != group_size.get()
                        {
                            alert!(
                                "Serialized resource group size mismatch key = {:?} num items {}, \
				 len {} recorded size {}, op {:?}",
                                group_key,
                                btree.len(),
                                group_bytes.len(),
                                group_size.get(),
                                metadata_op,
                            );
                            Err(ResourceGroupSerializationError)
```

**File:** types/src/transaction/mod.rs (L2023-2072)
```rust
#[derive(Clone, CryptoHasher, BCSCryptoHash, Debug, Eq, PartialEq, Serialize, Deserialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct TransactionInfoV0 {
    /// The amount of gas used.
    gas_used: u64,

    /// The vm status. If it is not `Executed`, this will provide the general error class. Execution
    /// failures and Move abort's receive more detailed information. But other errors are generally
    /// categorized with no status code or other information
    status: ExecutionStatus,

    /// The hash of this transaction.
    transaction_hash: HashValue,

    /// The root hash of Merkle Accumulator storing all events emitted during this transaction.
    event_root_hash: HashValue,

    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,

    /// The root hash of the Sparse Merkle Tree describing the world state at the end of this
    /// transaction. Depending on the protocol configuration, this can be generated periodical
    /// only, like per block.
    state_checkpoint_hash: Option<HashValue>,

    /// The hash value summarizing PersistedAuxiliaryInfo.
    auxiliary_info_hash: Option<HashValue>,
}

impl TransactionInfoV0 {
    pub fn new(
        transaction_hash: HashValue,
        state_change_hash: HashValue,
        event_root_hash: HashValue,
        state_checkpoint_hash: Option<HashValue>,
        gas_used: u64,
        status: ExecutionStatus,
        auxiliary_info_hash: Option<HashValue>,
    ) -> Self {
        Self {
            gas_used,
            status,
            transaction_hash,
            event_root_hash,
            state_change_hash,
            state_checkpoint_hash,
            auxiliary_info_hash,
        }
    }
```

**File:** types/src/block_executor/config.rs (L51-64)
```rust
/// Local, per-node configuration.
#[derive(Clone, Debug)]
pub struct BlockExecutorLocalConfig {
    // If enabled, uses BlockSTMv2 algorithm / scheduler for parallel execution.
    pub blockstm_v2: bool,
    pub concurrency_level: usize,
    // If specified, parallel execution fallbacks to sequential, if issue occurs.
    // Otherwise, if there is an error in either of the execution, we will panic.
    pub allow_fallback: bool,
    // If true, we will discard the failed blocks and continue with the next block.
    // (allow_fallback needs to be set)
    pub discard_failed_blocks: bool,
    pub module_cache_config: BlockExecutorModuleCacheLocalConfig,
}
```
