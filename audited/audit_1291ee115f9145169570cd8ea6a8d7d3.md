# Audit Report

## Title
Orphaned Event Indices After Database Truncation Leading to API Query Failures and State Inconsistency

## Summary
The `delete_event_data()` function in the truncation helper fails to delete event indices (`EventByKeySchema` and `EventByVersionSchema`) when pruning event data during database recovery operations. This leaves orphaned index entries pointing to non-existent event data, causing API query failures and violating database consistency invariants.

## Finding Description

During database recovery after a crash or partial commit, the `sync_commit_progress()` function triggers ledger database truncation to bring all database components back to a consistent state. [1](#0-0) 

The truncation process calls `delete_event_data()` which is responsible for removing events from versions that exceed the target truncation point. [2](#0-1) 

The critical vulnerability occurs at line 538 where `prune_event_indices()` is called with `None` as the `indices_batch` parameter, explicitly skipping index deletion with a TODO comment acknowledging this is unimplemented. [3](#0-2) 

When `indices_batch` is `None`, the `prune_event_indices()` function iterates through events to count them but skips the critical index deletion logic that removes entries from `EventByKeySchema` and `EventByVersionSchema`. [4](#0-3) 

However, the actual event data IS deleted by the subsequent `prune_events()` call, which removes entries from `EventSchema` and prunes event accumulators. [5](#0-4) 

**This creates orphaned indices**: The index entries remain in the database pointing to deleted event data, violating the fundamental invariant that indices must reference valid data.

In contrast, regular event pruning operations properly handle indices by passing a batch reference to `prune_event_indices()`, ensuring indices are deleted atomically with the data. [6](#0-5) 

**Attack Scenario:**
1. Node is operating normally with events stored at versions 1-1000
2. A crash occurs leaving the ledger database ahead of other databases
3. On restart, `sync_commit_progress()` detects the inconsistency
4. Truncation is triggered to roll back ledger database from version 1000 to version 900
5. `delete_event_data()` is called with `start_version=901`
6. Event indices for versions 901-1000 remain in `EventByKeySchema` and `EventByVersionSchema`
7. Actual event data for versions 901-1000 is deleted from `EventSchema`
8. Result: Orphaned index entries pointing to non-existent data

**Impact on API Queries:**
When clients query events through the REST API endpoints (`/accounts/{address}/events/{creation_number}`), the system uses these indices to locate events. [7](#0-6) 

The query path follows: `Context::get_events()` → `get_events_by_event_key()` → `lookup_events_by_key()` which queries `EventByKeySchema` to get `(version, index)` tuples. [8](#0-7) 

The code then attempts to fetch the actual events using `get_event_by_version_and_index()`. [9](#0-8) 

If the index points to deleted data, this query fails with `AptosDbError::NotFound`, causing the entire API request to fail. [10](#0-9) 

Additionally, `get_latest_sequence_number()` uses `EventByVersionSchema` to determine the latest event sequence number, which could return values from deleted versions, producing incorrect results. [11](#0-10) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program category "State inconsistencies requiring intervention":

1. **API Availability Impact**: Event query endpoints fail for any event streams that had data in the truncated version range, disrupting client applications and indexers that depend on event data.

2. **Database Integrity Violation**: Orphaned indices violate the core database invariant that index entries must point to valid data. This represents a corruption of the database's referential integrity.

3. **Operational Disruption**: The inconsistency persists until manual intervention (database repair or rebuild), requiring operational overhead and potentially extended downtime.

4. **No Direct Fund Loss**: While this breaks availability and consistency, it does not directly enable theft of funds or consensus violations, preventing Critical severity classification.

5. **Limited to Event Queries**: The impact is scoped to event-related APIs and does not affect transaction processing, state queries, or consensus operations, preventing High severity classification.

## Likelihood Explanation

The likelihood of this vulnerability manifesting is **Medium to High**:

**Triggering Conditions:**
- Occurs automatically during any database recovery scenario after crashes or unclean shutdowns
- The `sync_commit_progress()` function is called on every node restart when database components are out of sync
- No attacker action required - this is an operational bug in the recovery path

**Frequency:**
- Database inconsistencies requiring truncation occur during node crashes, out-of-memory conditions, disk failures, or deployment errors
- Production blockchain networks experience these conditions regularly across their validator sets
- Every truncation that removes event data triggers this vulnerability

**Detection:**
- Operators may not immediately notice the issue since transaction processing continues normally
- Event query failures may be attributed to network issues or client errors
- The TODO comment indicates this is known technical debt but remains unpatched

**Scope:**
- Affects all nodes that undergo truncation recovery with event data in the truncated range
- Both validator and fullnodes are susceptible
- Internal indexer configurations may be affected differently but the core issue persists

## Recommendation

**Fix the `delete_event_data()` function to properly delete event indices during truncation:**

The fix should mirror the approach used in `EventStorePruner::prune()` by providing a proper batch reference to `prune_event_indices()`:

```rust
fn delete_event_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    if let Some(latest_version) = ledger_db.event_db().latest_version()? {
        if latest_version >= start_version {
            info!(
                start_version = start_version,
                latest_version = latest_version,
                "Truncate event data."
            );
            
            // FIX: Pass the batch to properly delete indices
            let num_events_per_version = ledger_db.event_db().prune_event_indices(
                start_version,
                latest_version + 1,
                Some(batch),  // Changed from None to Some(batch)
            )?;
            
            ledger_db.event_db().prune_events(
                num_events_per_version,
                start_version,
                latest_version + 1,
                batch,
            )?;
        }
    }
    Ok(())
}
```

**Alternative Approach for Internal Indexer Support:**

If internal indexer separation is required, follow the pattern from `EventStorePruner`:

```rust
fn delete_event_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut SchemaBatch,
    internal_indexer_db: Option<&InternalIndexerDB>,
) -> Result<()> {
    if let Some(latest_version) = ledger_db.event_db().latest_version()? {
        if latest_version >= start_version {
            let mut indexer_batch = None;
            
            let indices_batch = if let Some(indexer_db) = internal_indexer_db {
                if indexer_db.event_enabled() {
                    indexer_batch = Some(SchemaBatch::new());
                }
                indexer_batch.as_mut()
            } else {
                Some(batch)
            };
            
            let num_events_per_version = ledger_db.event_db().prune_event_indices(
                start_version,
                latest_version + 1,
                indices_batch,
            )?;
            
            ledger_db.event_db().prune_events(
                num_events_per_version,
                start_version,
                latest_version + 1,
                batch,
            )?;
            
            if let Some(indexer_batch) = indexer_batch {
                internal_indexer_db.unwrap().get_inner_db_ref().write_schemas(indexer_batch)?;
            }
        }
    }
    Ok(())
}
```

**Additional Steps:**
1. Remove the misleading TODO comment after implementing the fix
2. Add integration tests verifying indices are properly cleaned during truncation
3. Consider adding validation checks to detect orphaned indices during startup
4. Update documentation about the truncation recovery process

## Proof of Concept

The following Rust integration test demonstrates the vulnerability:

```rust
#[cfg(test)]
mod truncation_index_bug_test {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_types::{
        contract_event::ContractEvent,
        event::EventKey,
        transaction::Version,
    };
    
    #[test]
    fn test_orphaned_event_indices_after_truncation() {
        // Setup: Create a test database
        let tmpdir = TempPath::new();
        let db = AptosDB::new_for_test(&tmpdir);
        
        // Step 1: Commit events at versions 0-10
        let event_key = EventKey::random();
        for version in 0..=10 {
            let events = vec![ContractEvent::new_v1(
                event_key,
                version, // sequence number
                bcs::to_bytes(&"test_event").unwrap(),
            )];
            
            // Commit the events with indices
            db.save_transactions(
                &transactions_for_version(version),
                version,
                &ledger_info_for_version(version),
                false, // skip_index = false
            ).unwrap();
        }
        
        // Step 2: Verify events and indices exist at version 10
        let (version, _event) = db.event_store
            .get_event_by_key(&event_key, 10, 10)
            .expect("Event at version 10 should exist");
        assert_eq!(version, 10);
        
        // Step 3: Simulate crash and truncation to version 5
        // This calls delete_event_data which has the bug
        truncate_ledger_db(db.ledger_db.clone(), 5).unwrap();
        
        // Step 4: BUG - Indices still exist but data is gone
        // Query EventByKeySchema directly
        let index_entry = db.ledger_db.event_db().db()
            .get::<EventByKeySchema>(&(event_key, 10))
            .unwrap();
        
        // Index entry STILL EXISTS pointing to version 10
        assert!(index_entry.is_some(), 
            "BUG: Index entry should have been deleted but still exists!");
        
        let (indexed_version, indexed_idx) = index_entry.unwrap();
        assert_eq!(indexed_version, 10);
        
        // Step 5: But actual event data is GONE
        let event_result = db.event_store
            .get_event_by_version_and_index(indexed_version, indexed_idx);
        
        // This FAILS because the event data was deleted
        assert!(event_result.is_err(), 
            "BUG: Event data was deleted but index still points to it!");
        
        // Step 6: API query fails due to orphaned index
        let api_query_result = db.event_store
            .get_event_by_key(&event_key, 10, 15);
        
        assert!(api_query_result.is_err(),
            "BUG: API query fails because index points to deleted data!");
        
        // Expected behavior: Both index and data should be deleted
        // After truncation to version 5, querying sequence 10 should return NotFound
        // because both the index AND the data should be gone
    }
}
```

**Expected vs Actual Behavior:**
- **Expected**: After truncation to version 5, both event indices and event data for versions 6-10 are deleted. Queries for these events return NotFound cleanly.
- **Actual**: Event data for versions 6-10 is deleted, but indices remain. Queries find the index entries, attempt to fetch the data, and fail with unexpected errors.

**Notes**

The vulnerability exists because truncation operations prioritize speed and simplicity by assuming "same data will be overwritten into indices" (as stated in the comment). However, this assumption is invalid because:

1. Truncation typically occurs during error recovery, not normal operation
2. There's no guarantee the same transactions will be re-executed
3. Even if similar transactions occur, they may emit different events
4. The time window between truncation and new data being written leaves indices inconsistent

The fix is straightforward and follows the established pattern already used in regular pruning operations. The main challenge is ensuring proper batch management for scenarios with and without internal indexers.

### Citations

**File:** storage/aptosdb/src/state_store/mod.rs (L440-449)
```rust
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L520-549)
```rust
fn delete_event_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    if let Some(latest_version) = ledger_db.event_db().latest_version()? {
        if latest_version >= start_version {
            info!(
                start_version = start_version,
                latest_version = latest_version,
                "Truncate event data."
            );
            let num_events_per_version = ledger_db.event_db().prune_event_indices(
                start_version,
                latest_version + 1,
                // Assuming same data will be overwritten into indices, we don't bother to deal
                // with the existence or placement of indices
                // TODO: prune data from internal indices
                None,
            )?;
            ledger_db.event_db().prune_events(
                num_events_per_version,
                start_version,
                latest_version + 1,
                batch,
            )?;
        }
    }
    Ok(())
}
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L192-222)
```rust
    pub(crate) fn prune_event_indices(
        &self,
        start: Version,
        end: Version,
        mut indices_batch: Option<&mut SchemaBatch>,
    ) -> Result<Vec<usize>> {
        let mut ret = Vec::new();

        let mut current_version = start;

        for events in self.get_events_by_version_iter(start, (end - start) as usize)? {
            let events = events?;
            ret.push(events.len());

            if let Some(ref mut batch) = indices_batch {
                for event in events {
                    if let ContractEvent::V1(v1) = event {
                        batch.delete::<EventByKeySchema>(&(*v1.key(), v1.sequence_number()))?;
                        batch.delete::<EventByVersionSchema>(&(
                            *v1.key(),
                            current_version,
                            v1.sequence_number(),
                        ))?;
                    }
                }
            }
            current_version += 1;
        }

        Ok(ret)
    }
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L224-243)
```rust
    /// Deletes a set of events in the range of version in [begin, end), and all related indices.
    pub(crate) fn prune_events(
        &self,
        num_events_per_version: Vec<usize>,
        start: Version,
        end: Version,
        db_batch: &mut SchemaBatch,
    ) -> Result<()> {
        let mut current_version = start;

        for num_events in num_events_per_version {
            for idx in 0..num_events {
                db_batch.delete::<EventSchema>(&(current_version, idx as u64))?;
            }
            current_version += 1;
        }
        self.event_store
            .prune_event_accumulator(start, end, db_batch)?;
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L43-59)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let mut indexer_batch = None;

        let indices_batch = if let Some(indexer_db) = self.indexer_db() {
            if indexer_db.event_enabled() {
                indexer_batch = Some(SchemaBatch::new());
            }
            indexer_batch.as_mut()
        } else {
            Some(&mut batch)
        };
        let num_events_per_version = self.ledger_db.event_db().prune_event_indices(
            current_progress,
            target_version,
            indices_batch,
        )?;
```

**File:** api/src/events.rs (L47-88)
```rust
    async fn get_events_by_creation_number(
        &self,
        accept_type: AcceptType,
        /// Hex-encoded 32 byte Aptos account, with or without a `0x` prefix, for
        /// which events are queried. This refers to the account that events were
        /// emitted to, not the account hosting the move module that emits that
        /// event type.
        address: Path<Address>,
        /// Creation number corresponding to the event stream originating
        /// from the given account.
        creation_number: Path<U64>,
        /// Starting sequence number of events.
        ///
        /// If unspecified, by default will retrieve the most recent events
        start: Query<Option<U64>>,
        /// Max number of events to retrieve.
        ///
        /// If unspecified, defaults to default page size
        limit: Query<Option<u16>>,
    ) -> BasicResultWith404<Vec<VersionedEvent>> {
        fail_point_poem("endpoint_get_events_by_event_key")?;
        self.context
            .check_api_output_enabled("Get events by event key", &accept_type)?;
        let page = Page::new(
            start.0.map(|v| v.0),
            limit.0,
            self.context.max_events_page_size(),
        );

        // Ensure that account exists
        let api = self.clone();
        api_spawn_blocking(move || {
            let account = Account::new(api.context.clone(), address.0, None, None, None)?;
            api.list(
                account.latest_ledger_info,
                accept_type,
                page,
                EventKey::new(creation_number.0 .0, address.0.into()),
            )
        })
        .await
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1132-1137)
```rust
        let mut event_indices = self.event_store.lookup_events_by_key(
            event_key,
            first_seq,
            real_limit,
            ledger_version,
        )?;
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1153-1169)
```rust
        let mut events_with_version = event_indices
            .into_iter()
            .map(|(seq, ver, idx)| {
                let event = self.event_store.get_event_by_version_and_index(ver, idx)?;
                let v0 = match &event {
                    ContractEvent::V1(event) => event,
                    ContractEvent::V2(_) => bail!("Unexpected module event"),
                };
                ensure!(
                    seq == v0.sequence_number(),
                    "Index broken, expected seq:{}, actual:{}",
                    seq,
                    v0.sequence_number()
                );
                Ok(EventWithVersion::new(ver, event))
            })
            .collect::<Result<Vec<_>>>()?;
```

**File:** storage/aptosdb/src/event_store/mod.rs (L42-50)
```rust
    pub fn get_event_by_version_and_index(
        &self,
        version: Version,
        index: u64,
    ) -> Result<ContractEvent> {
        self.event_db
            .get::<EventSchema>(&(version, index))?
            .ok_or_else(|| AptosDbError::NotFound(format!("Event {} of Txn {}", index, version)))
    }
```

**File:** storage/aptosdb/src/event_store/mod.rs (L76-88)
```rust
    /// no greater than `ledger_version`.
    pub fn get_latest_sequence_number(
        &self,
        ledger_version: Version,
        event_key: &EventKey,
    ) -> Result<Option<u64>> {
        let mut iter = self.event_db.iter::<EventByVersionSchema>()?;
        iter.seek_for_prev(&(*event_key, ledger_version, u64::MAX));

        Ok(iter.next().transpose()?.and_then(
            |((key, _version, seq), _idx)| if &key == event_key { Some(seq) } else { None },
        ))
    }
```
