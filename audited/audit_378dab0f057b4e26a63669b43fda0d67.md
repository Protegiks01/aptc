# Audit Report

## Title
Backup Restore Allows Permanent State Corruption via Unvalidated WriteSet Persistence

## Summary
The backup restore flow in Aptos Core fails to validate that WriteSets match their corresponding `state_change_hash` values in TransactionInfo before persisting them to AptosDB. This allows an attacker to craft a malicious backup file containing valid transactions and events but corrupted WriteSets, which will pass verification and be permanently persisted, causing irreversible state corruption.

## Finding Description

The vulnerability exists in the backup restore code path where transactions are loaded from backup files and saved to the database without replay verification.

**The Critical Flaw:**

When `LoadedChunk::load()` processes a backup chunk, it performs the following steps: [1](#0-0) 

The function loads transactions, transaction_infos, events, and write_sets separately from the backup file. However, when creating the verification structure, WriteSets are **excluded**: [2](#0-1) 

The `TransactionListWithProofV2` structure does **not** contain WriteSets - it only contains transactions, events, transaction_infos, and auxiliary info. The verification at line 167 calls `verify()` which checks: [3](#0-2) 

This verification validates transaction hashes and event root hashes, but **never validates WriteSets** because they are not part of the `TransactionListWithProof` structure: [4](#0-3) 

After verification passes, the WriteSets are directly persisted without any hash validation: [5](#0-4) 

The `save_transactions` function persists all components to separate database tables without cross-validation: [6](#0-5) 

**Why This Breaks Security:**

In normal execution, `TransactionInfo` is created by hashing the `TransactionOutput`: [7](#0-6) 

This ensures `state_change_hash` (line 76) matches the WriteSet hash by construction. However, in backup restore, no such validation exists.

**Attack Scenario:**

1. Attacker creates a malicious backup file with:
   - Valid Transaction T with correct hash
   - Valid TransactionInfo TI with `state_change_hash = H1`
   - Valid events matching `event_root_hash`
   - **Malicious WriteSet WS** where `hash(WS) = H2 â‰  H1`

2. When restored without replay (`replay_from_version = None` or transactions before replay threshold), the verification passes because WriteSet hash is never checked

3. Database permanently stores inconsistent state:
   - TransactionInfo claims `state_change_hash = H1`
   - Actual WriteSet has `hash(WS) = H2`

4. Different state transitions occur than what TransactionInfo declares, breaking the **Deterministic Execution** invariant

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under the Aptos bug bounty program for the following reasons:

1. **Permanent State Corruption**: Once persisted, the corrupted WriteSets cannot be detected or corrected without database wiping and full resync. This meets the "Non-recoverable network partition (requires hardfork)" criterion.

2. **Consensus Safety Violation**: Different validators restoring from different backup sources could have different state roots for the same transactions, breaking consensus safety and potentially causing chain splits.

3. **Deterministic Execution Violation**: The stored WriteSet doesn't match the declared `state_change_hash`, meaning validators cannot verify state transitions are deterministic. This is a fundamental blockchain invariant violation.

4. **Potential Fund Theft**: Malicious WriteSets could transfer assets, mint tokens, or modify balances arbitrarily while maintaining valid transaction and event hashes.

5. **Database Integrity Compromise**: The Jellyfish Merkle Tree and state storage will contain inconsistent data that doesn't match cryptographic commitments in TransactionInfo.

## Likelihood Explanation

**Medium-to-High Likelihood:**

1. **Common Operation**: Backup restore is a standard disaster recovery procedure for validators, especially when:
   - Bootstrapping new validator nodes
   - Recovering from hardware failures
   - Migrating to new infrastructure
   - Syncing archival nodes

2. **Attack Prerequisites**:
   - Attacker needs to provide a malicious backup file
   - Victim must restore from this backup
   - Transactions must not be replayed (either `replay_from_version = None` or malicious txns are before replay threshold)

3. **Exploitation Vectors**:
   - Compromised backup storage (S3, GCS, etc.)
   - Man-in-the-middle during backup download
   - Social engineering to distribute "official" malicious backups
   - Supply chain attack on backup providers

4. **Detection Difficulty**: The corruption is silent - no errors are raised, and the database appears consistent until state root mismatches are discovered during execution.

## Recommendation

**Immediate Fix:** Add WriteSet hash validation during backup restore before persisting to database.

**Implementation in `storage/backup/backup-cli/src/backup_types/transaction/restore.rs`:**

Add validation in `LoadedChunk::load()` after line 167:

```rust
// Verify WriteSets match state_change_hash in TransactionInfo
for (write_set, txn_info) in write_sets.iter().zip(txn_infos.iter()) {
    let write_set_hash = CryptoHash::hash(write_set);
    ensure!(
        write_set_hash == txn_info.state_change_hash(),
        "WriteSet hash mismatch! Computed: {:?}, Expected: {:?}",
        write_set_hash,
        txn_info.state_change_hash()
    );
}
```

**Alternative Fix:** Modify `TransactionListWithProof` to include WriteSets and extend the `verify()` method to validate them. However, this is a larger architectural change.

**Additional Safety Measures:**
1. Add checksum validation to backup files
2. Implement cryptographic signing of backup manifests
3. Add post-restore verification that compares state roots
4. Log warnings when restoring without replay verification

## Proof of Concept

**Step 1: Create Malicious Backup File**

```rust
use aptos_types::{
    transaction::{Transaction, TransactionInfo, WriteSet},
    contract_event::ContractEvent,
};
use aptos_crypto::{hash::CryptoHash, HashValue};

// Create valid transaction and events
let transaction = Transaction::UserTransaction(/* valid user transaction */);
let events = vec![/* valid events */];

// Create malicious WriteSet that transfers funds
let malicious_write_set = WriteSet::new(vec![
    (state_key_for_account_balance, WriteOp::Modification(malicious_balance_bytes)),
    // ... other malicious state changes
]);

// Create TransactionInfo with DIFFERENT WriteSet hash
let legitimate_write_set = WriteSet::new(vec![/* legitimate changes */]);
let legitimate_hash = CryptoHash::hash(&legitimate_write_set);

let txn_info = TransactionInfo::new(
    transaction.hash(),
    legitimate_hash,  // Points to legitimate WriteSet hash
    event_root_hash,
    state_checkpoint_hash,
    gas_used,
    status,
    aux_hash,
);

// Serialize to backup file with malicious_write_set instead of legitimate_write_set
let backup_record = (transaction, txn_info, events, malicious_write_set);
// Write to backup file...
```

**Step 2: Restore Backup**

```bash
# Restore backup without replay
aptos-db-tool restore \
  --target-db-dir /var/aptos/db \
  --transaction-manifest backup://malicious-backup/transaction.manifest \
  # Note: No --replay-transactions-from-version specified
```

**Step 3: Verify Corruption**

```rust
// After restore, query the database
let stored_write_set = db.get_write_set(version)?;
let stored_txn_info = db.get_transaction_info(version)?;

// These will NOT match!
let actual_hash = CryptoHash::hash(&stored_write_set);
assert_ne!(actual_hash, stored_txn_info.state_change_hash());
// Database is now permanently corrupted
```

**Expected Result:** The malicious WriteSet is persisted despite not matching the `state_change_hash`, causing permanent state corruption that can enable fund theft and consensus violations.

## Notes

**Contrast with Safe Paths:**

1. **State Sync Path (SAFE)**: Uses `TransactionOutputListWithProofV2` which includes WriteSets and validates them: [8](#0-7) 

2. **Normal Execution Path (SAFE)**: Creates TransactionInfo from TransactionOutput, ensuring consistency by construction: [9](#0-8) 

3. **Backup Restore with Replay (SAFE)**: Re-executes transactions and validates outputs: [10](#0-9) 

**The vulnerability exists ONLY in backup restore without replay**, which is a commonly used configuration for fast node bootstrapping and disaster recovery.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L112-136)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
            let (txn, aux_info, txn_info, events, write_set): (
                _,
                PersistedAuxiliaryInfo,
                _,
                _,
                WriteSet,
            ) = match manifest.format {
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
                    (
                        txn,
                        PersistedAuxiliaryInfo::None,
                        txn_info,
                        events,
                        write_set,
                    )
                },
                TransactionChunkFormat::V1 => bcs::from_bytes(&record_bytes)?,
            };
            txns.push(txn);
            persisted_aux_info.push(aux_info);
            txn_infos.push(txn_info);
            event_vecs.push(events);
            write_sets.push(write_set);
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L156-167)
```rust
        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L498-527)
```rust
                    if first_version < first_to_replay {
                        let num_to_save =
                            (min(first_to_replay, last_version + 1) - first_version) as usize;
                        let txns_to_save: Vec<_> = txns.drain(..num_to_save).collect();
                        let persisted_aux_info_to_save: Vec<_> =
                            persisted_aux_info.drain(..num_to_save).collect();
                        let txn_infos_to_save: Vec<_> = txn_infos.drain(..num_to_save).collect();
                        let event_vecs_to_save: Vec<_> = event_vecs.drain(..num_to_save).collect();
                        let write_sets_to_save = write_sets.drain(..num_to_save).collect();
                        tokio::task::spawn_blocking(move || {
                            restore_handler.save_transactions(
                                first_version,
                                &txns_to_save,
                                &persisted_aux_info_to_save,
                                &txn_infos_to_save,
                                &event_vecs_to_save,
                                write_sets_to_save,
                            )
                        })
                        .await??;
                        let last_saved = first_version + num_to_save as u64 - 1;
                        TRANSACTION_SAVE_VERSION.set(last_saved as i64);
                        info!(
                            version = last_saved,
                            accumulative_tps = ((last_saved - global_first_version + 1) as f64
                                / start.elapsed().as_secs_f64())
                                as u64,
                            "Transactions saved."
                        );
                    }
```

**File:** types/src/transaction/mod.rs (L2245-2250)
```rust
pub struct TransactionListWithProof {
    pub transactions: Vec<Transaction>,
    pub events: Option<Vec<Vec<ContractEvent>>>,
    pub first_transaction_version: Option<Version>,
    pub proof: TransactionInfoListWithProof,
}
```

**File:** types/src/transaction/mod.rs (L2317-2354)
```rust
        // Verify the transaction hashes match those of the transaction infos
        self.transactions
            .par_iter()
            .zip_eq(self.proof.transaction_infos.par_iter())
            .map(|(txn, txn_info)| {
                let txn_hash = CryptoHash::hash(txn);
                ensure!(
                    txn_hash == txn_info.transaction_hash(),
                    "The hash of transaction does not match the transaction info in proof. \
                     Transaction hash: {:x}. Transaction hash in txn_info: {:x}.",
                    txn_hash,
                    txn_info.transaction_hash(),
                );
                Ok(())
            })
            .collect::<Result<Vec<_>>>()?;

        // Verify the transaction infos are proven by the ledger info.
        self.proof
            .verify(ledger_info, self.get_first_transaction_version())?;

        // Verify the events if they exist.
        if let Some(event_lists) = &self.events {
            ensure!(
                event_lists.len() == self.get_num_transactions(),
                "The length of event_lists ({}) does not match the number of transactions ({}).",
                event_lists.len(),
                self.get_num_transactions(),
            );
            event_lists
                .into_par_iter()
                .zip_eq(self.proof.transaction_infos.par_iter())
                .map(|(events, txn_info)| verify_events_against_root_hash(events, txn_info))
                .collect::<Result<Vec<_>>>()?;
        }

        Ok(())
    }
```

**File:** types/src/transaction/mod.rs (L2573-2586)
```rust
        self.transactions_and_outputs.par_iter().zip_eq(self.proof.transaction_infos.par_iter())
        .map(|((txn, txn_output), txn_info)| {
            // Check the events against the expected events root hash
            verify_events_against_root_hash(&txn_output.events, txn_info)?;

            // Verify the write set matches for both the transaction info and output
            let write_set_hash = CryptoHash::hash(&txn_output.write_set);
            ensure!(
                txn_info.state_change_hash() == write_set_hash,
                "The write set in transaction output does not match the transaction info \
                     in proof. Hash of write set in transaction output: {}. Write set hash in txn_info: {}.",
                write_set_hash,
                txn_info.state_change_hash(),
            );
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L261-267)
```rust
    for (idx, ws) in write_sets.iter().enumerate() {
        WriteSetDb::put_write_set(
            first_version + idx as Version,
            ws,
            &mut ledger_db_batch.write_set_db_batches,
        )?;
    }
```

**File:** execution/executor/src/workflow/do_ledger_update.rs (L69-88)
```rust
                let event_hashes = txn_output
                    .events()
                    .iter()
                    .map(CryptoHash::hash)
                    .collect::<Vec<_>>();
                let event_root_hash =
                    InMemoryEventAccumulator::from_leaves(&event_hashes).root_hash();
                let write_set_hash = CryptoHash::hash(txn_output.write_set());
                let txn_info = TransactionInfo::new(
                    txn.hash(),
                    write_set_hash,
                    event_root_hash,
                    state_checkpoint_hash,
                    txn_output.gas_used(),
                    txn_output
                        .status()
                        .as_kept_status()
                        .expect("Already sorted."),
                    auxiliary_info_hash,
                );
```

**File:** execution/executor/src/chunk_executor/mod.rs (L636-641)
```rust
            if let Err(err) = txn_out.ensure_match_transaction_info(
                version,
                txn_info,
                Some(write_set),
                Some(events),
            ) {
```
