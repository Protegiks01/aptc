# Audit Report

## Title
Database Corruption Silently Accepted During Replay Verification Due to Panic Suppression

## Summary
The replay verification tool in `replay_on_archive.rs` uses `catch_unwind` to suppress panics during write-mode database opening, then falls back to read-only mode. If the initial panic was caused by database corruption, the read-only open may succeed with corrupted data, causing the verifier to validate against corrupted state and produce false verification success. [1](#0-0) 

## Finding Description

The `Verifier::new()` function attempts to open AptosDB in write mode to "create any new DBs necessary", but wraps this operation in `panic::catch_unwind()`. If the write-mode open panics, the error is merely logged as a warning, and execution continues to open the database in read-only mode. [2](#0-1) 

**The vulnerability arises from the behavioral difference between write and read-only database opening:**

1. **Write-mode open** (`readonly=false`) performs full initialization including:
   - RocksDB WAL recovery
   - Pruner target version initialization
   - Indexer opening
   - Additional consistency checks

2. **Read-only open** (`readonly=true`) uses a more permissive mode:
   - Uses `DB::open_cf_readonly` with `error_if_log_file_exist=false`
   - Filters out missing column families instead of failing
   - Skips pruner and indexer initialization [3](#0-2) 

**Critical flaw:** The verifier uses this potentially corrupted database as the source of truth for both:

1. **Expected transaction outputs** - read via `backup_handler.get_transaction_iter()` which directly queries the ledger database: [4](#0-3) 

2. **State for re-execution** - via `arc_db.state_view_at_version()`: [5](#0-4) 

**Attack scenario:**
If database corruption causes the write-mode open to panic (e.g., during WAL recovery or consistency checks), but the read-only open succeeds by bypassing those checks, the verifier will:
- Read corrupted "expected" transaction outputs from the database
- Execute transactions against corrupted state
- Compare corrupted execution results against corrupted expected values
- Report verification success even though the database is corrupted

This violates the **State Consistency** invariant - the verification tool designed to detect corruption instead silently accepts it.

## Impact Explanation

**High Severity** according to Aptos bug bounty criteria ("Significant protocol violations"):

1. **Verification bypass**: A tool specifically designed to verify database integrity fails to detect corruption
2. **Silent failure**: No error or warning indicates that verification was performed against corrupted state
3. **Operational risk**: Operators may deploy nodes with corrupted databases based on false verification success
4. **Consensus risk**: If multiple nodes independently verify corrupted backups as valid and sync from them, they could diverge from the correct chain state
5. **State inconsistency**: Violates the fundamental guarantee that state can be verified through re-execution

The impact is significant because:
- The tool is used in production for state restore verification after backup restoration
- False verification success could lead to corrupted nodes joining the network
- No additional integrity checks exist to catch this failure mode

## Likelihood Explanation

**Medium to High likelihood:**

1. **Database corruption scenarios**:
   - Hardware failures (disk errors, memory corruption)
   - Crashes during database writes
   - Software bugs in RocksDB or AptosDB
   - Incomplete backup restoration
   - Filesystem-level corruption

2. **Write-mode panic triggers**:
   - RocksDB WAL recovery encountering corrupted log files
   - Pruner initialization with inconsistent version metadata
   - Indexer opening with corrupted index state
   - Column family validation failures

3. **Read-only mode success**: The permissive nature of read-only opening (`error_if_log_file_exist=false`, missing CF filtering) makes it more likely to succeed despite underlying corruption

4. **Real-world occurrence**: Database corruption is a known operational issue in distributed systems, and this code path would be triggered whenever corruption affects write-mode specific operations but not basic data reading.

## Recommendation

Implement integrity validation before using the database for verification:

```rust
impl Verifier {
    pub fn new(config: &Opt) -> Result<Self> {
        // Open in write mode to create any new DBs necessary.
        {
            if let Err(e) = panic::catch_unwind(|| {
                AptosDB::open(
                    StorageDirPaths::from_path(config.db_dir.as_path()),
                    false,
                    NO_OP_STORAGE_PRUNER_CONFIG,
                    config.rocksdb_opt.clone().into(),
                    false,
                    BUFFERED_STATE_TARGET_ITEMS,
                    DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
                    None,
                    HotStateConfig::default(),
                )
            }) {
                // FIXED: Return error instead of just warning
                bail!("Failed to open AptosDB in write mode (possible corruption): {:?}", e);
            };
        }

        // Rest of the function remains the same...
```

**Alternative comprehensive fix:**

1. Remove the `catch_unwind` wrapper entirely - let panics propagate as errors
2. Add explicit database integrity checks before verification:
   - Verify transaction accumulator consistency
   - Check state checkpoint version metadata
   - Validate that synced_version is accessible
3. Add a `--force-readonly` flag for intentional read-only verification with explicit warnings

## Proof of Concept

```rust
// PoC: Demonstrate corruption acceptance
// File: storage/db-tool/tests/replay_corruption_test.rs

#[test]
fn test_replay_accepts_corrupted_db() {
    use std::fs;
    use tempfile::TempDir;
    
    // Setup: Create a database with some transactions
    let temp_dir = TempDir::new().unwrap();
    let db_path = temp_dir.path();
    
    // Initialize database with valid data
    let mut aptos_db = AptosDB::open(
        StorageDirPaths::from_path(db_path),
        false, // write mode
        NO_OP_STORAGE_PRUNER_CONFIG,
        RocksdbConfigs::default(),
        false,
        BUFFERED_STATE_TARGET_ITEMS,
        DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
        None,
        HotStateConfig::default(),
    ).unwrap();
    
    // Commit some transactions
    // ... (commit code omitted for brevity)
    
    drop(aptos_db);
    
    // Simulate corruption: Corrupt a WAL file or SST file
    let wal_dir = db_path.join("ledger_db");
    let wal_files: Vec<_> = fs::read_dir(&wal_dir)
        .unwrap()
        .filter_map(|e| e.ok())
        .filter(|e| e.path().extension().map(|s| s == "log").unwrap_or(false))
        .collect();
    
    if let Some(wal_file) = wal_files.first() {
        // Corrupt the WAL file by truncating or modifying it
        let mut file = fs::OpenOptions::new()
            .write(true)
            .open(wal_file.path())
            .unwrap();
        file.set_len(file.metadata().unwrap().len() / 2).unwrap(); // Truncate
    }
    
    // Attempt replay verification - this should FAIL but may succeed
    let opt = Opt {
        start_version: 0,
        end_version: 10,
        db_dir: db_path.to_path_buf(),
        chunk_size: 500,
        concurrent_replay: 1,
        timeout_secs: None,
        paranoid_type_checks: false,
        replay_concurrency_level: ReplayConcurrencyLevelOpt::default(),
        rocksdb_opt: RocksdbOpt::default(),
    };
    
    // BUG: This may return Ok despite corruption
    let result = Verifier::new(&opt);
    
    // Expected: Error indicating corruption
    // Actual: May succeed with corrupted database
    assert!(result.is_err(), "Verifier should detect database corruption");
}
```

## Notes

This vulnerability represents a **defensive failure** rather than an active attack vector. The tool is specifically designed to verify database integrity after state synchronization or backup restoration, but the panic suppression pattern allows corrupted databases to pass verification.

The core issue is the asymmetry between write-mode and read-only mode opening behavior in RocksDB. Write mode performs stricter validation that can detect corruption, while read-only mode prioritizes availability over consistency checks.

**Additional context from code review:**
- The comment at line 281 in `ledger_db/mod.rs` says "TODO(grao): Handle data inconsistency" - suggesting known concerns about data consistency handling
- There is a separate validation module (`db_debugger/validation.rs`) that performs comprehensive integrity checks, but it is not invoked by the replay verification tool
- The backup handler directly reads from database column families without any integrity verification

The fix should either remove panic suppression entirely or add explicit integrity validation before proceeding with verification.

### Citations

**File:** storage/db-tool/src/replay_on_archive.rs (L153-167)
```rust
            if let Err(e) = panic::catch_unwind(|| {
                AptosDB::open(
                    StorageDirPaths::from_path(config.db_dir.as_path()),
                    false,
                    NO_OP_STORAGE_PRUNER_CONFIG,
                    config.rocksdb_opt.clone().into(),
                    false,
                    BUFFERED_STATE_TARGET_ITEMS,
                    DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
                    None,
                    HotStateConfig::default(),
                )
            }) {
                warn!("Unable to open AptosDB in write mode: {:?}", e);
            };
```

**File:** storage/db-tool/src/replay_on_archive.rs (L170-183)
```rust
        let aptos_db = AptosDB::open(
            StorageDirPaths::from_path(config.db_dir.as_path()),
            true,
            NO_OP_STORAGE_PRUNER_CONFIG,
            config.rocksdb_opt.clone().into(),
            false,
            BUFFERED_STATE_TARGET_ITEMS,
            DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
            None,
            HotStateConfig {
                delete_on_restart: false,
                ..Default::default()
            },
        )?;
```

**File:** storage/db-tool/src/replay_on_archive.rs (L378-380)
```rust
                &self
                    .arc_db
                    .state_view_at_version(current_version.checked_sub(1))?,
```

**File:** storage/schemadb/src/lib.rs (L174-180)
```rust
                ReadOnly => {
                    DB::open_cf_descriptors_read_only(
                        db_opts,
                        path.de_unc(),
                        all_cfds.filter(|cfd| !missing_cfs.contains(cfd.name())),
                        false, /* error_if_log_file_exist */
                    )
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L56-75)
```rust
        let txn_iter = self
            .ledger_db
            .transaction_db()
            .get_transaction_iter(start_version, num_transactions)?;
        let mut txn_info_iter = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_iter(start_version, num_transactions)?;
        let mut event_vec_iter = self
            .ledger_db
            .event_db()
            .get_events_by_version_iter(start_version, num_transactions)?;
        let mut write_set_iter = self
            .ledger_db
            .write_set_db()
            .get_write_set_iter(start_version, num_transactions)?;
        let mut persisted_aux_info_iter = self
            .ledger_db
            .persisted_auxiliary_info_db()
            .get_persisted_auxiliary_info_iter(start_version, num_transactions)?;
```
