# Audit Report

## Title
Integer Overflow DoS in Epoch Ending Stream Request Creation via Malicious Peer Advertisement

## Summary
A malicious peer can advertise an epoch ending ledger info with `highest_epoch = u64::MAX`, causing permanent denial of service in the epoch ending stream engine. The vulnerability occurs in the request batch creation logic, not in `update_request_tracking()` as specified in the question, but achieves the same blocking effect.

## Finding Description

The security question asks about overflow at lines 1528-1531 in `update_request_tracking()`, but the actual vulnerability occurs earlier in the request creation pipeline at [1](#0-0) 

**Attack Flow:**

1. **Malicious Advertisement**: A malicious peer sends a `StorageServerSummary` advertising `epoch_ending_ledger_infos` with `highest_epoch = u64::MAX`. The storage service computes this from blockchain data at [2](#0-1) , but malicious peers can construct arbitrary summaries.

2. **Unvalidated Aggregation**: The advertised epoch is aggregated into `AdvertisedData` via [3](#0-2)  without bounds validation.

3. **Stream Engine Initialization**: `EpochEndingStreamEngine::new()` accepts this value at [4](#0-3)  with only a lower bound check at [5](#0-4) . No upper bound validation exists.

4. **Request Creation Failure**: When `create_data_client_requests()` is called at [6](#0-5) , it invokes `create_data_client_request_batch()` which fails with integer overflow:
   - **Scenario A** (start_epoch = 0): Overflow at [7](#0-6)  when computing `total_items_to_fetch = u64::MAX - 0 + 1`
   - **Scenario B** (start_epoch > 0): Overflow at [8](#0-7)  when computing `next_index_to_request = u64::MAX + 1` after creating the final request chunk

5. **Permanent Blocking**: The error propagates to [9](#0-8) , then to the driver at [10](#0-9)  where it's logged but the stream state remains unchanged. On the next iteration, the same error recurs indefinitely.

**Note**: The question mentions lines 1528-1531 in `update_request_tracking()`, but that code is unreachable when `end_epoch = u64::MAX` because the overflow occurs before any requests are created. However, the vulnerability still exists and produces the same blocking effect.

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos Bug Bounty)

This vulnerability enables a **Denial of Service** attack:

- **Node Impact**: A targeted node cannot sync epoch ending ledger infos, blocking critical epoch transition data required for validator set updates and bootstrapping
- **Persistence**: The DoS is permanent until the malicious peer is disconnected or the node is restarted
- **Attack Surface**: Any network peer can launch this attack by advertising malicious data
- **Resource Exhaustion**: Causes repeated error logging and metric updates in an infinite loop at [10](#0-9) 

While the node continues operating for other data types, inability to sync epoch ending ledger infos violates the **Resource Limits** invariant (operations must respect computational limits) and constitutes a "Validator node slowdown" qualifying as High severity.

## Likelihood Explanation

**Likelihood: Medium to High**

- **Attacker Requirements**: Only requires peer network access; no validator privileges needed
- **Complexity**: Low - attacker simply advertises a crafted `StorageServerSummary` with epoch = u64::MAX
- **Detection Probability**: Low - the overflow appears as a legitimate error in logs, not immediately distinguishable from transient network issues
- **Mitigation Bypass**: The peer scoring system at [11](#0-10)  only penalizes peers for bad response data, not invalid advertisements, so the malicious peer maintains high scores

**Realistic Scenario**: Epoch u64::MAX is impossible via legitimate blockchain progression, but nothing prevents a malicious peer from advertising it. The lack of validation makes this easily exploitable.

## Recommendation

Implement defense-in-depth protections:

**1. Add bounds validation in `EpochEndingStreamEngine::new()`:**

```rust
fn new(
    request: &GetAllEpochEndingLedgerInfosRequest,
    advertised_data: &AdvertisedData,
) -> Result<Self, Error> {
    let end_epoch = advertised_data
        .highest_epoch_ending_ledger_info()
        .ok_or_else(|| {
            Error::DataIsUnavailable(format!(
                "Unable to find any epoch ending ledger info in the network: {:?}",
                advertised_data
            ))
        })?;

    // Add upper bound check to prevent overflow in request creation
    const MAX_REASONABLE_EPOCH: u64 = u64::MAX - 1000; // Reserve headroom
    if end_epoch > MAX_REASONABLE_EPOCH {
        return Err(Error::DataIsUnavailable(format!(
            "Advertised epoch {} exceeds maximum reasonable value {}",
            end_epoch, MAX_REASONABLE_EPOCH
        )));
    }

    if end_epoch < request.start_epoch {
        return Err(Error::DataIsUnavailable(format!(
            "The epoch to start syncing from is higher than the highest epoch ending ledger info! Highest: {:?}, start: {:?}",
            end_epoch, request.start_epoch
        )));
    }
    // ... rest of function
}
```

**2. Fix loop logic in `create_data_client_request_batch()` to avoid unnecessary overflow:**

```rust
// Update the local loop state
total_items_to_fetch = total_items_to_fetch
    .checked_sub(num_items_to_fetch)
    .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;
num_requests_made = num_requests_made.checked_add(1).ok_or_else(|| {
    Error::IntegerOverflow("Number of payload requests has overflown!".into())
})?;

// Only calculate next_index_to_request if we're continuing the loop
if total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
    next_index_to_request = request_end_index
        .checked_add(1)
        .ok_or_else(|| Error::IntegerOverflow("Next index to request has overflown!".into()))?;
}
```

**3. Add validation when receiving peer advertisements** in the data client poller to filter out unreasonable epoch values before aggregation.

## Proof of Concept

```rust
#[cfg(test)]
mod epoch_overflow_attack {
    use super::*;
    use aptos_data_client::global_summary::{AdvertisedData, GlobalDataSummary, OptimalChunkSizes};
    use aptos_storage_service_types::responses::CompleteDataRange;
    use crate::streaming_client::GetAllEpochEndingLedgerInfosRequest;

    #[test]
    #[should_panic(expected = "IntegerOverflow")]
    fn test_malicious_peer_epoch_max_dos() {
        // Simulate malicious peer advertising epoch u64::MAX
        let malicious_advertised_data = AdvertisedData {
            epoch_ending_ledger_infos: vec![
                CompleteDataRange::new(0, u64::MAX).unwrap()
            ],
            states: vec![],
            synced_ledger_infos: vec![],
            transactions: vec![],
            transaction_outputs: vec![],
        };

        // Attempt to create stream engine with malicious advertised data
        let request = GetAllEpochEndingLedgerInfosRequest {
            start_epoch: 0,
            expected_end_epoch: u64::MAX,
        };

        let stream_engine = EpochEndingStreamEngine::new(
            &request,
            &malicious_advertised_data
        ).expect("Stream engine creation should succeed");

        // Attempt to create requests - this should panic with IntegerOverflow
        let config = DataStreamingServiceConfig::default();
        let global_data_summary = GlobalDataSummary {
            advertised_data: malicious_advertised_data,
            optimal_chunk_sizes: OptimalChunkSizes {
                epoch_chunk_size: 100,
                state_chunk_size: 1000,
                transaction_chunk_size: 1000,
                transaction_output_chunk_size: 1000,
            },
        };

        let id_generator = Arc::new(U64IdGenerator::new());
        
        // This call will panic with IntegerOverflow, demonstrating the DoS
        let _ = stream_engine.create_data_client_requests(
            10,
            10,
            0,
            &global_data_summary,
            id_generator
        );
    }
}
```

## Notes

- The vulnerability exists at a different location than specified in the security question (in `create_data_client_request_batch` rather than `update_request_tracking`), but achieves the same blocking effect
- The issue demonstrates inadequate input validation on peer-provided data, violating defense-in-depth principles
- While epoch u64::MAX is unreachable via legitimate blockchain operation, the absence of validation creates an exploitable attack surface
- The fix requires both immediate bounds checking and improved loop logic to prevent similar issues at other edge values

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1487-1494)
```rust
        let end_epoch = advertised_data
            .highest_epoch_ending_ledger_info()
            .ok_or_else(|| {
                Error::DataIsUnavailable(format!(
                    "Unable to find any epoch ending ledger info in the network: {:?}",
                    advertised_data
                ))
            })?;
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1496-1501)
```rust
        if end_epoch < request.start_epoch {
            return Err(Error::DataIsUnavailable(format!(
                "The epoch to start syncing from is higher than the highest epoch ending ledger info! Highest: {:?}, start: {:?}",
                end_epoch, request.start_epoch
            )));
        }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1541-1567)
```rust
    fn create_data_client_requests(
        &mut self,
        max_number_of_requests: u64,
        max_in_flight_requests: u64,
        num_in_flight_requests: u64,
        global_data_summary: &GlobalDataSummary,
        _unique_id_generator: Arc<U64IdGenerator>,
    ) -> Result<Vec<DataClientRequest>, Error> {
        // Calculate the number of requests to send
        let num_requests_to_send = calculate_num_requests_to_send(
            max_number_of_requests,
            max_in_flight_requests,
            num_in_flight_requests,
        );

        // Create the client requests
        let client_requests = create_data_client_request_batch(
            self.next_request_epoch,
            self.end_epoch,
            num_requests_to_send,
            global_data_summary.optimal_chunk_sizes.epoch_chunk_size,
            self.clone().into(),
        )?;

        // Return the requests
        self.update_request_tracking(&client_requests)?;
        Ok(client_requests)
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2049-2099)
```rust
fn create_data_client_request_batch(
    start_index: u64,
    end_index: u64,
    max_number_of_requests: u64,
    optimal_chunk_size: u64,
    stream_engine: StreamEngine,
) -> Result<Vec<DataClientRequest>, Error> {
    if start_index > end_index {
        return Ok(vec![]);
    }

    // Calculate the total number of items left to satisfy the stream
    let mut total_items_to_fetch = end_index
        .checked_sub(start_index)
        .and_then(|e| e.checked_add(1)) // = end_index - start_index + 1
        .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;

    // Iterate until we've requested all transactions or hit the maximum number of requests
    let mut data_client_requests = vec![];
    let mut num_requests_made = 0;
    let mut next_index_to_request = start_index;
    while total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
        // Calculate the number of items to fetch in this request
        let num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size);

        // Calculate the start and end indices for the request
        let request_start_index = next_index_to_request;
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;

        // Create the data client requests
        let data_client_request =
            create_data_client_request(request_start_index, request_end_index, &stream_engine)?;
        data_client_requests.push(data_client_request);

        // Update the local loop state
        next_index_to_request = request_end_index
            .checked_add(1)
            .ok_or_else(|| Error::IntegerOverflow("Next index to request has overflown!".into()))?;
        total_items_to_fetch = total_items_to_fetch
            .checked_sub(num_items_to_fetch)
            .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;
        num_requests_made = num_requests_made.checked_add(1).ok_or_else(|| {
            Error::IntegerOverflow("Number of payload requests has overflown!".into())
        })?;
    }

    Ok(data_client_requests)
}
```

**File:** state-sync/storage-service/server/src/storage.rs (L1040-1053)
```rust
        // Fetch the epoch ending ledger info range
        let latest_ledger_info = latest_ledger_info_with_sigs.ledger_info();
        let epoch_ending_ledger_infos = if latest_ledger_info.ends_epoch() {
            let highest_ending_epoch = latest_ledger_info.epoch();
            Some(CompleteDataRange::from_genesis(highest_ending_epoch))
        } else if latest_ledger_info.epoch() > 0 {
            let highest_ending_epoch =
                latest_ledger_info.epoch().checked_sub(1).ok_or_else(|| {
                    Error::UnexpectedErrorEncountered("Highest ending epoch overflowed!".into())
                })?;
            Some(CompleteDataRange::from_genesis(highest_ending_epoch))
        } else {
            None // We haven't seen an epoch change yet
        };
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L176-181)
```rust
    pub fn highest_epoch_ending_ledger_info(&self) -> Option<Epoch> {
        self.epoch_ending_ledger_infos
            .iter()
            .map(|epoch_range| epoch_range.highest())
            .max()
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L288-294)
```rust
            let client_requests = self.stream_engine.create_data_client_requests(
                max_num_requests_to_send,
                max_in_flight_requests,
                num_in_flight_requests,
                global_data_summary,
                self.notification_id_generator.clone(),
            )?;
```

**File:** state-sync/state-sync-driver/src/driver.rs (L711-718)
```rust
        } else if let Err(error) = self.bootstrapper.drive_progress(&global_data_summary).await {
            sample!(
                    SampleRate::Duration(Duration::from_secs(DRIVER_ERROR_LOG_FREQ_SECS)),
                    warn!(LogSchema::new(LogEntry::Driver)
                        .error(&error)
                        .message("Error found when checking the bootstrapper progress!"));
            );
            metrics::increment_counter(&metrics::BOOTSTRAPPER_ERRORS, error.get_label());
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L162-174)
```rust
    /// Updates the score of the peer according to a successful operation
    fn update_score_success(&mut self) {
        self.score = f64::min(self.score + SUCCESSFUL_RESPONSE_DELTA, MAX_SCORE);
    }

    /// Updates the score of the peer according to an error
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```
