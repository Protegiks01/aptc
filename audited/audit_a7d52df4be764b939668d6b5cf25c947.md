# Audit Report

## Title
Weak Validation in Multi-Version Data Structure Allows Non-Deterministic Execution from Malicious StateView

## Summary
The `set_base_value` function in the multi-version data structure only validates byte length equality instead of full content equality when concurrent threads fetch the same state key from storage. This allows a malicious or buggy StateView implementation to cause non-deterministic block execution and consensus failures.

## Finding Description
The vulnerability exists in the parallel block execution path where multiple threads can concurrently read the same state key from the underlying StateView for the first time. [1](#0-0) 

When a transaction reads a state key that hasn't been cached yet, it calls `get_raw_base_value` which directly invokes the StateView's `get_state_value` method. [2](#0-1) 

If multiple threads concurrently read the same uninitialized key, they both call `get_raw_base_value` and then attempt to cache the result via `set_base_value`. The critical flaw is in how `set_base_value` validates concurrent fetches: [3](#0-2) 

The assertion only checks that byte lengths are equal, not that the actual content is identical. The comment explicitly states this is "for efficiency (instead of full equality)". This means a StateView that returns different values V1 and V2 for the same key K, where `len(V1) == len(V2)` but `V1 â‰  V2`, will pass validation.

While both threads subsequently re-read from the cache and converge on whichever value won the race, this creates **timing-dependent non-determinism**. More critically, if the same block is executed multiple times (during replay, validation, or block synchronization), different executions could produce different state root hashes depending on thread scheduling.

This breaks the fundamental **Deterministic Execution** invariant that all validators must produce identical state roots for identical blocks. [4](#0-3) 

The parallel executor creates multiple threads that share the same `base_view` (StateView), allowing concurrent calls to `get_state_value` for the same key.

## Impact Explanation
**Severity: Critical** (up to $1,000,000)

This vulnerability enables **Consensus/Safety violations**:
1. A single validator with a buggy StateView could produce different state roots on different executions of the same block
2. This leads to self-inconsistency where the validator cannot validate its own block replays
3. In a multi-validator setting with even a single buggy node, consensus cannot be achieved as validators produce different state roots
4. This breaks the deterministic execution guarantee required for Byzantine Fault Tolerant consensus

The impact qualifies as Critical because it causes **non-recoverable consensus failures** that could require a hardfork to resolve.

## Likelihood Explanation
**Likelihood: Low to Medium**

While the vulnerability exists in the code, exploitation requires one of these scenarios:

1. **Buggy StateView Implementation**: A validator operator deploys a StateView that inadvertently returns non-deterministic values (e.g., reading from a concurrently modified data structure, using timestamps, or having race conditions in the implementation)

2. **Storage Layer Issues**: The underlying database or storage system has consistency issues that cause `DbStateView` to return different values for the same key at the same version

3. **Intentional Malicious Validator**: A validator operator deliberately implements a non-deterministic StateView (though this would be easily detected)

The likelihood is not "High" because standard StateView implementations (DbStateView, CachedStateView) are deterministic under normal operation. However, the weakness in validation means bugs in StateView implementations or storage layers would not be caught, leading to subtle consensus failures.

## Recommendation
Replace the weak length-only assertion with full content equality validation:

```rust
(RawFromStorage(existing_value), RawFromStorage(base_value)) => {
    // Base value from storage MUST be identical across concurrent fetches
    // Validate full content equality to detect non-deterministic StateView implementations
    let existing_bytes = existing_value.bytes();
    let base_bytes = base_value.bytes();
    
    assert_eq!(
        existing_bytes, 
        base_bytes,
        "StateView returned different values for the same state key - this indicates \
         a non-deterministic StateView implementation or storage corruption"
    );
},
```

Additionally, add runtime validation in production:
1. Log a critical alert when this assertion fails
2. Consider adding metrics to track StateView consistency
3. Add defensive checks in StateView implementations to ensure determinism

## Proof of Concept

```rust
// This PoC demonstrates the vulnerability by creating a non-deterministic StateView

use aptos_types::state_store::{StateKey, StateValue, StateViewId, StateStorageUsage, TStateView};
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;

/// A malicious StateView that returns different values on each call
struct NonDeterministicStateView {
    counter: Arc<AtomicU64>,
}

impl TStateView for NonDeterministicStateView {
    type Key = StateKey;
    
    fn get_state_value(&self, _state_key: &StateKey) -> Result<Option<StateValue>, Error> {
        // Return different values with same length on each call
        let value = self.counter.fetch_add(1, Ordering::SeqCst);
        let bytes = value.to_le_bytes(); // 8 bytes, always same length
        Ok(Some(StateValue::new_legacy(bytes.to_vec().into())))
    }
    
    fn get_usage(&self) -> Result<StateStorageUsage, Error> {
        Ok(StateStorageUsage::zero())
    }
    
    fn id(&self) -> StateViewId {
        StateViewId::Miscellaneous
    }
}

// When multiple threads call get_raw_base_value with this StateView:
// Thread 1: gets StateValue with bytes [0,0,0,0,0,0,0,0]
// Thread 2: gets StateValue with bytes [1,0,0,0,0,0,0,0]
// Both have length 8, so the assertion passes
// But they represent different values, causing non-deterministic execution
```

**Notes:**
- This vulnerability requires control over the StateView implementation, which is typically only possible for validator operators
- However, the weak validation represents a defense-in-depth failure that should be corrected regardless of attack surface
- The issue is particularly dangerous because it would manifest as subtle, hard-to-debug consensus failures rather than obvious crashes

### Citations

**File:** aptos-move/block-executor/src/view.rs (L1140-1163)
```rust
    pub(crate) fn get_raw_base_value(
        &self,
        state_key: &T::Key,
    ) -> PartialVMResult<Option<StateValue>> {
        let ret = self.base_view.get_state_value(state_key).map_err(|e| {
            PartialVMError::new(StatusCode::STORAGE_ERROR).with_message(format!(
                "Unexpected storage error for {:?}: {:?}",
                state_key, e
            ))
        });

        if ret.is_err() {
            // Even speculatively, reading from base view should not return an error.
            // Thus, this critical error log and count does not need to be buffered.
            let log_context = AdapterLogSchema::new(self.base_view.id(), self.txn_idx as usize);
            alert!(
                log_context,
                "[VM, StateView] Error getting data from storage for {:?}",
                state_key
            );
        }

        ret
    }
```

**File:** aptos-move/block-executor/src/view.rs (L1524-1562)
```rust
    fn get_resource_state_value_impl(
        &self,
        state_key: &T::Key,
        layout: UnknownOrLayout,
        kind: ReadKind,
    ) -> PartialVMResult<ReadResult> {
        debug_assert!(
            !state_key.is_module_path(),
            "Reading a module {:?} using ResourceView",
            state_key,
        );

        let state = self.latest_view.get_resource_state();

        let mut ret = state.read_cached_data_by_kind(
            self.txn_idx,
            state_key,
            kind,
            layout.clone(),
            &|value, layout| self.patch_base_value(value, layout),
        )?;
        if matches!(ret, ReadResult::Uninitialized) {
            let from_storage =
                TransactionWrite::from_state_value(self.get_raw_base_value(state_key)?);
            state.set_base_value(
                state_key.clone(),
                ValueWithLayout::RawFromStorage(TriompheArc::new(from_storage)),
            );

            // In case of concurrent storage fetches, we cannot use our value,
            // but need to fetch it from versioned_map again.
            ret = state.read_cached_data_by_kind(
                self.txn_idx,
                state_key,
                kind,
                layout.clone(),
                &|value, layout| self.patch_base_value(value, layout),
            )?;
        }
```

**File:** aptos-move/mvhashmap/src/versioned_data.rs (L578-584)
```rust
                        (RawFromStorage(existing_value), RawFromStorage(base_value)) => {
                            // Base value from storage needs to be identical
                            // Assert the length of bytes for efficiency (instead of full equality)
                            assert!(
                                base_value.bytes().map(|b| b.len())
                                    == existing_value.bytes().map(|b| b.len())
                            );
```

**File:** aptos-move/block-executor/src/executor.rs (L82-99)
```rust
struct SharedSyncParams<'a, T, E, S>
where
    T: BlockExecutableTransaction,
    E: ExecutorTask<Txn = T>,
    S: TStateView<Key = T::Key> + Sync,
{
    // TODO: should not need to pass base view.
    base_view: &'a S,
    versioned_cache: &'a MVHashMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
    global_module_cache:
        &'a GlobalModuleCache<ModuleId, CompiledModule, Module, AptosModuleExtension>,
    last_input_output: &'a TxnLastInputOutput<T, E::Output>,
    start_shared_counter: u32,
    delayed_field_id_counter: &'a AtomicU32,
    block_limit_processor: &'a ExplicitSyncWrapper<BlockGasLimitProcessor<T>>,
    final_results: &'a ExplicitSyncWrapper<Vec<E::Output>>,
    maybe_block_epilogue_txn_idx: &'a ExplicitSyncWrapper<Option<TxnIndex>>,
}
```
