# Audit Report

## Title
Silent Failure of commit_ledger Operations Causes State Inconsistency and Consensus Safety Violations

## Summary
ExecutorError failures from `commit_ledger()` operations are silently discarded in the consensus pipeline, causing validators to believe blocks are committed when they are not. This creates state divergence between validators, violates consensus safety invariants, and can lead to permanent data loss after node restarts.

## Finding Description

Aptos uses a two-phase commit protocol for block persistence:
1. **Pre-commit phase**: `pre_commit_block()` writes transaction data to disk and advances the buffered state
2. **Commit phase**: `commit_ledger()` updates commit progress markers to make data visible to clients

The vulnerability occurs when `commit_ledger()` fails but the error is silently discarded. [1](#0-0) 

The `wait_for_commit_ledger()` method discards the result of `commit_ledger_fut` using `let _`, completely ignoring any ExecutorError that occurred. [2](#0-1) 

The PersistingPhase then unconditionally returns `Ok(round)` at line 74, making consensus believe the commit succeeded regardless of actual outcome.

**Attack Scenario:**

1. Validator receives block B covering versions 100-109
2. `pre_commit_block(B)` succeeds, calling `pre_commit_ledger()` which:
   - Writes transactions, events, state updates to disk
   - Updates buffered state: `next_version` advances from 100 â†’ 110 [3](#0-2) 

3. `commit_ledger(B)` fails with ExecutorError (disk error, validation failure, concurrent access detected) [4](#0-3) 

4. Error is silently discarded, consensus advances `highest_committed_round`
5. Result: Buffered state shows version 110, but database `synced_version` remains at 99
6. On node restart, `sync_commit_progress()` truncates uncommitted data [5](#0-4) 

7. Block B's transactions (versions 100-109) are permanently lost

**Invariant Violations:**

- **State Consistency**: Buffered state diverges from persisted state
- **Consensus Safety**: Different validators may have different committed states if only some experience commit failures
- **Deterministic Execution**: Validators produce different state roots due to inconsistent commit status

If a retry occurs, the validation check will fail: [6](#0-5) 

The `pre_commit_validation()` ensures `chunk.first_version == next_version`, which will fail since `next_version` already advanced to 110 but we're trying to pre-commit version 100 again.

## Impact Explanation

**Critical Severity** - This vulnerability causes:

1. **Consensus Safety Violations**: Validators can diverge on committed state. If validator A's commit succeeds but validator B's commit fails silently, they will have different views of the chain but consensus continues believing both committed the block.

2. **Permanent Data Loss**: Transactions in blocks where `commit_ledger()` failed are lost after node restart when `sync_commit_progress()` truncates the uncommitted data.

3. **State Divergence**: Buffered state becomes inconsistent with persisted state, breaking the atomic state transition invariant. This can cause subsequent blocks to be built on incorrect state.

4. **Non-Recoverable Inconsistency**: Once multiple validators have diverged, manual intervention or a hard fork may be required to restore consensus agreement.

This meets the **Critical Severity** criteria per Aptos bug bounty: "Consensus/Safety violations" and potentially "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Medium-High Likelihood:**

- **Trigger conditions are realistic**: Disk I/O errors, database lock contention, validation failures, out-of-space conditions can all cause `commit_ledger()` to fail
- **No attacker action required**: This is a protocol-level bug that can be triggered by infrastructure issues
- **Affects all validators**: Any validator experiencing transient errors during commit will silently drop blocks
- **No detection mechanism**: Since errors are discarded, operators have no visibility into commit failures unless they monitor detailed logs

The failpoint injection shows this scenario is considered possible: [7](#0-6) 

## Recommendation

**Immediate Fix**: Propagate commit_ledger errors to the PersistingPhase and fail the persisting request if commit fails.

Modify `wait_for_commit_ledger()` to return and check the result:

```rust
// In consensus/consensus-types/src/pipelined_block.rs
pub async fn wait_for_commit_ledger(&self) -> ExecutorResult<()> {
    if let Some(fut) = self.pipeline_futs() {
        fut.commit_ledger_fut
            .await
            .map(|_| ())
            .map_err(|e| ExecutorError::InternalError {
                error: e.to_string(),
            })
    } else {
        Ok(())
    }
}
```

Modify PersistingPhase to check and propagate errors:

```rust
// In consensus/src/pipeline/persisting_phase.rs
async fn process(&self, req: PersistingRequest) -> PersistingResponse {
    let PersistingRequest { blocks, commit_ledger_info } = req;
    
    for b in &blocks {
        if let Some(tx) = b.pipeline_tx().lock().as_mut() {
            tx.commit_proof_tx
                .take()
                .map(|tx| tx.send(commit_ledger_info.clone()));
        }
        // Propagate errors instead of discarding them
        b.wait_for_commit_ledger().await?;
    }
    
    let response = Ok(blocks.last().expect("Blocks can't be empty").round());
    if commit_ledger_info.ledger_info().ends_epoch() {
        self.commit_msg_tx
            .send_epoch_change(EpochChangeProof::new(vec![commit_ledger_info], false))
            .await;
    }
    response
}
```

**Additional safeguards**:
- Add retry logic with exponential backoff for transient commit failures
- Add monitoring/alerting for commit failures
- Implement idempotency checks in `commit_ledger()` to safely handle retries

## Proof of Concept

Create a test that injects a commit failure and verifies the error is not silently discarded:

```rust
#[tokio::test]
async fn test_commit_ledger_failure_detection() {
    // Enable the failpoint to inject commit error
    fail::cfg("executor::commit_blocks", "return").unwrap();
    
    // Set up test environment with executor and pipeline
    let executor = create_test_executor();
    let pipeline = create_test_pipeline(executor);
    
    // Create a test block
    let block = create_test_block(/* ... */);
    let commit_proof = create_test_commit_proof(/* ... */);
    
    // Execute the block (should succeed)
    pipeline.execute_block(block.clone()).await.unwrap();
    
    // Pre-commit should succeed
    pipeline.pre_commit_block(block.id()).await.unwrap();
    
    // Attempt commit with failpoint active - should return error
    let result = pipeline.persisting_phase.process(PersistingRequest {
        blocks: vec![block.clone()],
        commit_ledger_info: commit_proof,
    }).await;
    
    // EXPECTED: Error is returned
    // ACTUAL (BUG): Returns Ok() even though commit failed
    assert!(result.is_err(), "Commit failure must be detected and propagated");
    
    fail::remove("executor::commit_blocks");
}
```

This PoC demonstrates that commit failures are currently ignored, violating the expectation that critical commit errors should halt consensus progression until resolved.

---

**Notes**: This vulnerability affects the core consensus safety guarantee. The silent error handling in `wait_for_commit_ledger()` combined with unconditional success return in `PersistingPhase::process()` creates a systemic failure mode where validators can silently diverge on committed state. The issue is exacerbated by the lack of idempotency protection in the commit path, making retries unsafe after partial commit failures.

### Citations

**File:** consensus/consensus-types/src/pipelined_block.rs (L562-568)
```rust
    pub async fn wait_for_commit_ledger(&self) {
        // may be aborted (e.g. by reset)
        if let Some(fut) = self.pipeline_futs() {
            // this may be cancelled
            let _ = fut.commit_ledger_fut.await;
        }
    }
```

**File:** consensus/src/pipeline/persisting_phase.rs (L59-82)
```rust
    async fn process(&self, req: PersistingRequest) -> PersistingResponse {
        let PersistingRequest {
            blocks,
            commit_ledger_info,
        } = req;

        for b in &blocks {
            if let Some(tx) = b.pipeline_tx().lock().as_mut() {
                tx.commit_proof_tx
                    .take()
                    .map(|tx| tx.send(commit_ledger_info.clone()));
            }
            b.wait_for_commit_ledger().await;
        }

        let response = Ok(blocks.last().expect("Blocks can't be empty").round());
        if commit_ledger_info.ledger_info().ends_epoch() {
            self.commit_msg_tx
                .send_epoch_change(EpochChangeProof::new(vec![commit_ledger_info], false))
                .await;
        }
        response
    }
}
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L44-76)
```rust
    fn pre_commit_ledger(&self, chunk: ChunkToCommit, sync_commit: bool) -> Result<()> {
        gauged_api("pre_commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .pre_commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["pre_commit_ledger"]);

            chunk
                .state_summary
                .latest()
                .global_state_summary
                .log_generation("db_save");

            self.pre_commit_validation(&chunk)?;
            let _new_root_hash =
                self.calculate_and_commit_ledger_and_state_kv(&chunk, self.skip_index_and_usage)?;

            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions__others"]);

            self.state_store.buffered_state().lock().update(
                chunk.result_ledger_state_with_summary(),
                chunk.estimated_total_state_updates(),
                sync_commit || chunk.is_reconfig,
            )?;

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L245-261)
```rust
    fn pre_commit_validation(&self, chunk: &ChunkToCommit) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions_validation"]);

        ensure!(!chunk.is_empty(), "chunk is empty, nothing to save.");

        let next_version = self.state_store.current_state_locked().next_version();
        // Ensure the incoming committing requests are always consecutive and the version in
        // buffered state is consistent with that in db.
        ensure!(
            chunk.first_version == next_version,
            "The first version passed in ({}), and the next version expected by db ({}) are inconsistent.",
            chunk.first_version,
            next_version,
        );

        Ok(())
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L383-385)
```rust
        fail_point!("executor::commit_blocks", |_| {
            Err(anyhow::anyhow!("Injected error in commit_blocks.").into())
        });
```
