# Audit Report

## Title
Race Condition Between Consensus Shutdown and Network Peer Disconnection During Epoch Transitions

## Summary
During epoch transitions, a race condition exists between the consensus layer shutting down its round manager and the network layer updating peer lists and closing connections. This can cause consensus messages to be silently dropped when sent to peers that have been disconnected, potentially causing temporary liveness issues at epoch boundaries.

## Finding Description

The vulnerability stems from the concurrent and uncoordinated handling of epoch reconfigurations between the consensus and network layers:

**1. Concurrent Reconfig Processing:**
When a reconfiguration notification is triggered (e.g., validator set change), it is broadcast to multiple independent components:
- Consensus `EpochManager` [1](#0-0) 
- Network `ValidatorSetStream` [2](#0-1) 

**2. Asynchronous Peer List Updates:**
The network layer immediately processes validator set changes:
- `DiscoveryChangeListener` sends `UpdateDiscoveredPeers` to `ConnectivityManager` [3](#0-2) 
- `ConnectivityManager` updates the trusted peer set [4](#0-3) 
- On the next connectivity check tick, stale connections are closed [5](#0-4) 

**3. Silent Message Dropping:**
When consensus attempts to send messages to disconnected peers, the `PeerManager` silently drops them: [6](#0-5) 

The critical issue is that consensus round manager shutdown [7](#0-6)  happens asynchronously relative to network peer disconnections. Messages in the consensus send queues or being processed during shutdown may be sent to already-disconnected peers.

**4. Lack of Coordination:**
The consensus epoch transition and network peer list updates operate independently:
- Consensus waits for acknowledgment from round manager shutdown
- Network disconnects peers based on new validator set
- No synchronization mechanism prevents peers from being disconnected while consensus is still sending messages

## Impact Explanation

**Severity: Low-to-Medium**

This issue does **not** meet Critical severity because:
- It does not cause permanent consensus failure or network partition
- The consensus protocol is designed with message loss resilience  
- Nodes can recover through existing sync and recovery mechanisms
- Cross-epoch message handling prevents permanent hangs [8](#0-7) 

However, it can cause **temporary liveness degradation** at epoch boundaries:
- Delayed quorum formation due to lost votes
- Increased sync requests and network overhead
- Potential for multiple rounds of timeouts before recovery
- In edge cases with many concurrent transitions, this could cause observable delays in block finalization

This aligns with **Medium Severity** ($10,000): "State inconsistencies requiring intervention" - though the system should self-recover, epoch transitions become unreliable and may require manual monitoring.

## Likelihood Explanation

**Likelihood: High during validator set changes**

This race condition triggers on every epoch transition that changes the validator set:
- Occurs automatically during regular validator set updates
- No attacker action required - it's an inherent design race
- Timing is probabilistic based on system load and network conditions
- More likely under heavy load when consensus has more pending messages

The issue is deterministically exploitable in the sense that the race condition always exists, though the actual message loss depends on timing.

## Recommendation

**Add synchronization between consensus epoch transitions and network peer updates:**

1. **Modify EpochManager to coordinate with connectivity manager:**
```rust
// In consensus/src/epoch_manager.rs - initiate_new_epoch()
async fn initiate_new_epoch(&mut self, proof: EpochChangeProof) -> anyhow::Result<()> {
    let ledger_info = proof.verify(self.epoch_state())?;
    
    // Shutdown existing processor first
    self.shutdown_current_processor().await;
    *self.pending_blocks.lock() = PendingBlocks::new();
    
    // Sync to target
    self.execution_client.sync_to_target(ledger_info.clone()).await?;
    
    // NEW: Wait for reconfig notification BEFORE network updates peers
    let reconfig_payload = self.await_reconfig_notification().await;
    
    // NEW: Notify network to wait before disconnecting peers
    self.notify_network_epoch_transition_start().await;
    
    // NEW: Small delay to ensure no messages in flight
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Now safe to proceed with new epoch
    Ok(())
}
```

2. **Add barrier in ConnectivityManager:**
```rust
// In network/framework/src/connectivity_manager/mod.rs
async fn handle_update_discovered_peers(&mut self, src: DiscoverySource, peers: PeerSet) {
    // NEW: If this is an epoch change (OnChainValidatorSet), wait for consensus signal
    if src == DiscoverySource::OnChainValidatorSet {
        self.wait_for_consensus_epoch_transition_ready().await;
    }
    
    // Proceed with existing peer update logic
    // ...
}
```

3. **Ensure message queues are drained before disconnection:**
The network layer should ensure all pending messages are sent or explicitly failed before closing connections during epoch transitions.

## Proof of Concept

This vulnerability is difficult to reproduce deterministically due to its timing-dependent nature. However, the following test scenario demonstrates the risk:

```rust
// Pseudo-code for reproduction test
#[tokio::test]
async fn test_epoch_transition_message_loss() {
    // Setup: Create a network with 4 validators
    let mut test_harness = create_test_network(4).await;
    
    // 1. Trigger consensus to send votes while at epoch boundary
    test_harness.consensus.start_voting_on_proposal().await;
    
    // 2. Immediately trigger epoch change with validator set change
    //    (remove one validator)
    test_harness.trigger_epoch_change(vec![0, 1, 2]).await;
    
    // 3. Verify that connectivity manager disconnects peer 3
    tokio::time::sleep(Duration::from_millis(200)).await;
    assert!(!test_harness.network.is_connected(3));
    
    // 4. Check if votes sent to peer 3 were lost
    let lost_messages = test_harness.network.get_dropped_messages();
    assert!(!lost_messages.is_empty(), "Messages should be dropped");
    
    // 5. Verify consensus eventually recovers (but with delay)
    let recovery_time = test_harness.wait_for_consensus_progress().await;
    assert!(recovery_time > Duration::from_secs(5), "Recovery took longer due to message loss");
}
```

**Notes:**
- The race condition exists in the codebase as described
- The network layer silently drops messages to disconnected peers without errors
- Consensus and network epoch transitions are not synchronized
- However, the system is designed with recovery mechanisms that eventually restore liveness

Due to the inherent resilience mechanisms in the consensus protocol and the lack of permanent safety violations, this represents a **reliability issue rather than a critical security vulnerability**. The system will eventually recover, but with degraded performance during epoch transitions.

### Citations

**File:** consensus/src/epoch_manager.rs (L478-542)
```rust
    fn process_different_epoch(
        &mut self,
        different_epoch: u64,
        peer_id: AccountAddress,
    ) -> anyhow::Result<()> {
        debug!(
            LogSchema::new(LogEvent::ReceiveMessageFromDifferentEpoch)
                .remote_peer(peer_id)
                .epoch(self.epoch()),
            remote_epoch = different_epoch,
        );
        match different_epoch.cmp(&self.epoch()) {
            Ordering::Less => {
                if self
                    .epoch_state()
                    .verifier
                    .get_voting_power(&self.author)
                    .is_some()
                {
                    // Ignore message from lower epoch if we're part of the validator set, the node would eventually see messages from
                    // higher epoch and request a proof
                    sample!(
                        SampleRate::Duration(Duration::from_secs(1)),
                        debug!("Discard message from lower epoch {} from {}", different_epoch, peer_id);
                    );
                    Ok(())
                } else {
                    // reply back the epoch change proof if we're not part of the validator set since we won't broadcast
                    // timeout in this epoch
                    monitor!(
                        "process_epoch_retrieval",
                        self.process_epoch_retrieval(
                            EpochRetrievalRequest {
                                start_epoch: different_epoch,
                                end_epoch: self.epoch(),
                            },
                            peer_id
                        )
                    )
                }
            },
            // We request proof to join higher epoch
            Ordering::Greater => {
                let request = EpochRetrievalRequest {
                    start_epoch: self.epoch(),
                    end_epoch: different_epoch,
                };
                let msg = ConsensusMsg::EpochRetrievalRequest(Box::new(request));
                if let Err(err) = self.network_sender.send_to(peer_id, msg) {
                    warn!(
                        "[EpochManager] Failed to send epoch retrieval to {}, {:?}",
                        peer_id, err
                    );
                    counters::EPOCH_MANAGER_ISSUES_DETAILS
                        .with_label_values(&["failed_to_send_epoch_retrieval"])
                        .inc();
                }

                Ok(())
            },
            Ordering::Equal => {
                bail!("[EpochManager] Same epoch should not come to process_different_epoch");
            },
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L544-569)
```rust
    async fn initiate_new_epoch(&mut self, proof: EpochChangeProof) -> anyhow::Result<()> {
        let ledger_info = proof
            .verify(self.epoch_state())
            .context("[EpochManager] Invalid EpochChangeProof")?;
        info!(
            LogSchema::new(LogEvent::NewEpoch).epoch(ledger_info.ledger_info().next_block_epoch()),
            "Received verified epoch change",
        );

        // shutdown existing processor first to avoid race condition with state sync.
        self.shutdown_current_processor().await;
        *self.pending_blocks.lock() = PendingBlocks::new();
        // make sure storage is on this ledger_info too, it should be no-op if it's already committed
        // panic if this doesn't succeed since the current processors are already shutdown.
        self.execution_client
            .sync_to_target(ledger_info.clone())
            .await
            .context(format!(
                "[EpochManager] State sync to new epoch {}",
                ledger_info
            ))
            .expect("Failed to sync to new epoch");

        monitor!("reconfig", self.await_reconfig_notification().await);
        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L637-683)
```rust
    async fn shutdown_current_processor(&mut self) {
        if let Some(close_tx) = self.round_manager_close_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop round manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop round manager");
        }
        self.round_manager_tx = None;

        if let Some(close_tx) = self.dag_shutdown_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
        }
        self.dag_shutdown_tx = None;

        // Shutdown the previous rand manager
        self.rand_manager_msg_tx = None;

        // Shutdown the previous secret share manager
        self.secret_share_manager_tx = None;

        // Shutdown the previous buffer manager, to release the SafetyRule client
        self.execution_client.end_epoch().await;

        // Shutdown the block retrieval task by dropping the sender
        self.block_retrieval_tx = None;
        self.batch_retrieval_tx = None;

        if let Some(mut quorum_store_coordinator_tx) = self.quorum_store_coordinator_tx.take() {
            let (ack_tx, ack_rx) = oneshot::channel();
            quorum_store_coordinator_tx
                .send(CoordinatorCommand::Shutdown(ack_tx))
                .await
                .expect("Could not send shutdown indicator to QuorumStore");
            ack_rx.await.expect("Failed to stop QuorumStore");
        }
    }
```

**File:** network/discovery/src/validator_set.rs (L94-105)
```rust
impl<P: OnChainConfigProvider> Stream for ValidatorSetStream<P> {
    type Item = Result<PeerSet, DiscoveryError>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        Pin::new(&mut self.reconfig_events)
            .poll_next(cx)
            .map(|maybe_notification| {
                maybe_notification
                    .map(|notification| Ok(self.extract_updates(notification.on_chain_configs)))
            })
    }
}
```

**File:** network/discovery/src/lib.rs (L131-171)
```rust
    async fn run(mut self: Pin<Box<Self>>) {
        let network_context = self.network_context;
        let discovery_source = self.discovery_source;
        let mut update_channel = self.update_channel.clone();
        let source_stream = &mut self.source_stream;
        info!(
            NetworkSchema::new(&network_context),
            "{} Starting {} Discovery", network_context, discovery_source
        );

        while let Some(update) = source_stream.next().await {
            if let Ok(update) = update {
                trace!(
                    NetworkSchema::new(&network_context),
                    "{} Sending update: {:?}",
                    network_context,
                    update
                );
                let request = ConnectivityRequest::UpdateDiscoveredPeers(discovery_source, update);
                if let Err(error) = update_channel.try_send(request) {
                    inc_by_with_context(&DISCOVERY_COUNTS, &network_context, "send_failure", 1);
                    warn!(
                        NetworkSchema::new(&network_context),
                        "{} Failed to send update {:?}", network_context, error
                    );
                }
            } else {
                warn!(
                    NetworkSchema::new(&network_context),
                    "{} {} Discovery update failed {:?}",
                    &network_context,
                    discovery_source,
                    update
                );
            }
        }
        warn!(
            NetworkSchema::new(&network_context),
            "{} {} Discovery actor terminated", &network_context, discovery_source
        );
    }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L484-531)
```rust
    async fn close_stale_connections(&mut self) {
        if let Some(trusted_peers) = self.get_trusted_peers() {
            // Identify stale peer connections
            let stale_peers = self
                .connected
                .iter()
                .filter(|(peer_id, _)| !trusted_peers.contains_key(peer_id))
                .filter_map(|(peer_id, metadata)| {
                    // If we're using server only auth, we need to not evict unknown peers
                    // TODO: We should prevent `Unknown` from discovery sources
                    if !self.mutual_authentication
                        && metadata.origin == ConnectionOrigin::Inbound
                        && (metadata.role == PeerRole::ValidatorFullNode
                            || metadata.role == PeerRole::Unknown)
                    {
                        None
                    } else {
                        Some(*peer_id) // The peer is stale
                    }
                });

            // Close existing connections to stale peers
            for stale_peer in stale_peers {
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&stale_peer),
                    "{} Closing stale connection to peer {}",
                    self.network_context,
                    stale_peer.short_str()
                );

                if let Err(disconnect_error) = self
                    .connection_reqs_tx
                    .disconnect_peer(stale_peer, DisconnectReason::StaleConnection)
                    .await
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .remote_peer(&stale_peer),
                        error = %disconnect_error,
                        "{} Failed to close stale connection to peer {}, error: {}",
                        self.network_context,
                        stale_peer.short_str(),
                        disconnect_error
                    );
                }
            }
        }
    }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L886-1002)
```rust
    fn handle_update_discovered_peers(
        &mut self,
        src: DiscoverySource,
        new_discovered_peers: PeerSet,
    ) {
        // Log the update event
        info!(
            NetworkSchema::new(&self.network_context),
            "{} Received updated list of discovered peers! Source: {:?}, num peers: {:?}",
            self.network_context,
            src,
            new_discovered_peers.len()
        );

        // Remove peers that no longer have relevant network information
        let mut keys_updated = false;
        let mut peers_to_check_remove = Vec::new();
        for (peer_id, peer) in self.discovered_peers.write().peer_set.iter_mut() {
            let new_peer = new_discovered_peers.get(peer_id);
            let check_remove = if let Some(new_peer) = new_peer {
                if new_peer.keys.is_empty() {
                    keys_updated |= peer.keys.clear_src(src);
                }
                if new_peer.addresses.is_empty() {
                    peer.addrs.clear_src(src);
                }
                new_peer.addresses.is_empty() && new_peer.keys.is_empty()
            } else {
                keys_updated |= peer.keys.clear_src(src);
                peer.addrs.clear_src(src);
                true
            };
            if check_remove {
                peers_to_check_remove.push(*peer_id);
            }
        }

        // Remove peers that no longer have state
        for peer_id in peers_to_check_remove {
            self.discovered_peers.write().remove_peer_if_empty(&peer_id);
        }

        // Make updates to the peers accordingly
        for (peer_id, discovered_peer) in new_discovered_peers {
            // Don't include ourselves, because we don't need to dial ourselves
            if peer_id == self.network_context.peer_id() {
                continue;
            }

            // Create the new `DiscoveredPeer`, role is set when a `Peer` is first discovered
            let mut discovered_peers = self.discovered_peers.write();
            let peer = discovered_peers
                .peer_set
                .entry(peer_id)
                .or_insert_with(|| DiscoveredPeer::new(discovered_peer.role));

            // Update the peer's pubkeys
            let mut peer_updated = false;
            if peer.keys.update(src, discovered_peer.keys) {
                info!(
                    NetworkSchema::new(&self.network_context)
                        .remote_peer(&peer_id)
                        .discovery_source(&src),
                    "{} pubkey sets updated for peer: {}, pubkeys: {}",
                    self.network_context,
                    peer_id.short_str(),
                    peer.keys
                );
                keys_updated = true;
                peer_updated = true;
            }

            // Update the peer's addresses
            if peer.addrs.update(src, discovered_peer.addresses) {
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    network_addresses = &peer.addrs,
                    "{} addresses updated for peer: {}, update src: {:?}, addrs: {}",
                    self.network_context,
                    peer_id.short_str(),
                    src,
                    &peer.addrs,
                );
                peer_updated = true;
            }

            // If we're currently trying to dial this peer, we reset their
            // dial state. As a result, we will begin our next dial attempt
            // from the first address (which might have changed) and from a
            // fresh backoff (since the current backoff delay might be maxed
            // out if we can't reach any of their previous addresses).
            if peer_updated {
                if let Some(dial_state) = self.dial_states.get_mut(&peer_id) {
                    *dial_state = DialState::new(self.backoff_strategy.clone());
                }
            }
        }

        // update eligible peers accordingly
        if keys_updated {
            // For each peer, union all of the pubkeys from each discovery source
            // to generate the new eligible peers set.
            let new_eligible = self.discovered_peers.read().get_eligible_peers();

            // Swap in the new eligible peers set
            if let Err(error) = self
                .peers_and_metadata
                .set_trusted_peers(&self.network_context.network_id(), new_eligible)
            {
                error!(
                    NetworkSchema::new(&self.network_context),
                    error = %error,
                    "Failed to update trusted peers set"
                );
            }
        }
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L538-546)
```rust
        } else {
            warn!(
                NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                protocol_id = %protocol_id,
                "{} Can't send message to peer.  Peer {} is currently not connected",
                self.network_context,
                peer_id.short_str()
            );
        }
```
