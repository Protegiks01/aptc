# Audit Report

## Title
JWK Consensus State Race Condition Allows Quorum-Certified Updates to be Silently Discarded

## Summary
In `KeyLevelConsensusManager::maybe_start_consensus()`, the unconditional `states_by_key.insert()` at line 216 can overwrite an in-progress consensus state when a new JWK update is observed for the same (issuer, kid) pair. This creates a race condition where a quorum-certified update may be accepted but later discarded from the validator transaction pool, causing state inconsistency and potential consensus divergence among validators. [1](#0-0) 

## Finding Description

The vulnerability stems from three interacting flaws:

**Flaw 1: Insufficient Guard Against State Overwriting**

The check at lines 180-190 only prevents starting a new consensus if the `to_upsert` values match. When a different JWK version is observed for the same (issuer, kid), the function proceeds to overwrite the existing state: [2](#0-1) 

**Flaw 2: Abort Handle Drops Background Consensus Task**

When the old state is overwritten at line 216, the `QuorumCertProcessGuard` is dropped, which calls `abort()` on the consensus task: [3](#0-2) 

However, if the consensus task for update A completes just before abort is called, the quorum-certified update is already in the `qc_update_tx` channel.

**Flaw 3: No Validation in process_quorum_certified_update**

When a QC arrives, `process_quorum_certified_update()` accepts it if the state is `InProgress`, but **never validates that the QC matches the current proposal**: [4](#0-3) 

This creates an inconsistent state where `my_proposal` references update B but `quorum_certified` contains the QC for update A.

**Exploitation Scenario:**

1. At t=0: Validator observes JWK version A, starts consensus for (issuer, kid) → version A
   - State: `InProgress{proposal: A, abort_handle: H_A}`
   
2. At t=5: JWK provider updates to version B (e.g., key rotation)

3. At t=8: Consensus for A completes, quorum-certified update sent to channel (but not yet processed)

4. At t=9: Validator fetches again, observes version B
   - Calls `maybe_start_consensus(B)`
   - Check fails (A.to_upsert ≠ B.to_upsert)
   - Overwrites state at line 216
   - State: `InProgress{proposal: B, abort_handle: H_B}`
   - H_A.abort() called, but consensus for A already completed

5. At t=10: QC for A processed via `process_quorum_certified_update()`
   - State is `InProgress{proposal: B}` ✓
   - No validation that QC matches proposal
   - Accepts QC for A, puts validator txn in pool
   - State: `Finished{my_proposal: B, quorum_certified: A, vtxn_guard_A}`

6. At t=12: Consensus for B completes, QC arrives
   - State is `Finished`, not `InProgress`
   - Rejected with error "qc update not expected"
   
7. At t=15: Observer fetches again, sees version A (network caching/glitch)
   - Calls `maybe_start_consensus(A)`
   - State is `Finished{my_proposal: B}`, B ≠ A
   - Starts new consensus for A
   - Overwrites `Finished` state at line 216
   - **vtxn_guard_A is dropped**
   
8. When `TxnGuard` drops, it removes transaction A from pool: [5](#0-4) 

**Result:** A quorum-certified JWK update is silently removed from the validator transaction pool.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria:

**Validator Protocol Violations:**
- Quorum-certified validator transactions can be discarded without being included in blocks
- Different validators may have different transactions in their pools depending on timing
- Breaks the expectation that quorum-certified updates will be proposed

**State Consistency Violations:**
The system maintains inconsistent state where:
- `my_proposal` references one update
- `quorum_certified` contains a QC for a different update
- The validator transaction pool may not contain the QC that was certified

**Potential Consensus Divergence:**
If different validators observe JWK updates at different times (due to network conditions or cache behavior), they may:
- Have different validator transactions in their pools
- Propose different JWK updates in blocks
- Disagree on which JWK updates should be applied

This violates the critical invariant: **"State transitions must be atomic and verifiable"** and can cause **"Significant protocol violations"** (High severity per bug bounty).

## Likelihood Explanation

**High Likelihood** due to:

1. **Legitimate Trigger Conditions:**
   - JWK providers frequently rotate keys for security
   - OAuth/OIDC providers may update JWKs every few hours
   - The JWK observer fetches every 10 seconds (configurable) [6](#0-5) 

2. **Network Timing Variations:**
   - Different validators may fetch JWKs at slightly different times
   - HTTP caching, CDN behavior, or DNS can cause validators to see different versions
   - The race window is realistic (consensus takes time to gather quorum)

3. **No External Attack Required:**
   - Occurs naturally during normal JWK rotation
   - No malicious actor needed, though a malicious JWK provider could amplify the issue

## Recommendation

**Add validation in `process_quorum_certified_update()` to ensure the QC matches the current proposal:**

```rust
pub fn process_quorum_certified_update(
    &mut self,
    issuer_level_repr: QuorumCertifiedUpdate,
) -> Result<()> {
    let key_level_update =
        KeyLevelUpdate::try_from_issuer_level_repr(&issuer_level_repr.update)
            .context("process_quorum_certified_update failed with repr err")?;
    let issuer = &key_level_update.issuer;
    let kid = &key_level_update.kid;
    
    let state = self
        .states_by_key
        .entry((issuer.clone(), kid.clone()))
        .or_default();
    match state {
        ConsensusState::InProgress { my_proposal, .. } => {
            // ADDED: Validate that QC matches current proposal
            if my_proposal.observed.to_upsert != key_level_update.to_upsert {
                return Err(anyhow!(
                    "QC update mismatch: expected {:?}, got {:?}",
                    my_proposal.observed.to_upsert,
                    key_level_update.to_upsert
                ));
            }
            
            let topic = Topic::JWK_CONSENSUS_PER_KEY_MODE {
                issuer: issuer.clone(),
                kid: kid.clone(),
            };
            let txn = ValidatorTransaction::ObservedJWKUpdate(issuer_level_repr.clone());
            let vtxn_guard = self.vtxn_pool.put(topic, Arc::new(txn), None);
            *state = ConsensusState::Finished {
                vtxn_guard,
                my_proposal: my_proposal.clone(),
                quorum_certified: issuer_level_repr,
            };
            Ok(())
        },
        _ => Err(anyhow!(
            "qc update not expected for issuer {:?} in state {}",
            String::from_utf8(issuer.clone()),
            state.name()
        )),
    }
}
```

**Additionally, consider improving `maybe_start_consensus()` to handle the race more gracefully:**
- Check if a QC is already being processed before aborting
- Use a more explicit state machine to track consensus lifecycle
- Add logging when aborting an in-progress consensus

## Proof of Concept

```rust
#[tokio::test]
async fn test_race_condition_qc_discard() {
    // Setup: 4 validators, simulating validator 0
    let private_keys: Vec<Arc<PrivateKey>> = (0..4)
        .map(|_| Arc::new(PrivateKey::generate_for_testing()))
        .collect();
    let addrs: Vec<AccountAddress> = (0..4).map(|_| AccountAddress::random()).collect();
    let epoch_state = Arc::new(create_test_epoch_state(&private_keys, &addrs));
    
    let vtxn_pool = VTxnPoolState::default();
    let mut manager = KeyLevelConsensusManager::new(
        private_keys[0].clone(),
        addrs[0],
        epoch_state.clone(),
        // Mock reliable broadcast that completes quickly
        create_test_rb(),
        vtxn_pool.clone(),
    );
    
    // Initialize with empty on-chain state
    manager.reset_with_on_chain_state(AllProvidersJWKs::empty()).unwrap();
    
    let issuer = b"https://accounts.google.com".to_vec();
    let kid = b"key_v1".to_vec();
    let jwk_v1 = JWK::Unsupported(UnsupportedJWK::new_for_testing("key_v1", "payload_v1"));
    let jwk_v2 = JWK::Unsupported(UnsupportedJWK::new_for_testing("key_v1", "payload_v2"));
    
    // Step 1: Observe version 1, start consensus
    manager.process_new_observation(issuer.clone(), vec![jwk_v1.clone()]).unwrap();
    
    // Verify state is InProgress for v1
    let state = manager.states_by_key.get(&(issuer.clone(), kid.clone())).unwrap();
    assert!(matches!(state, ConsensusState::InProgress { .. }));
    
    // Step 2: Simulate consensus completing for v1 (manually create QC)
    let qc_v1 = create_mock_qc(&epoch_state, &private_keys, issuer.clone(), kid.clone(), Some(jwk_v1.clone()));
    
    // Step 3: Before processing QC, observe version 2
    manager.process_new_observation(issuer.clone(), vec![jwk_v2.clone()]).unwrap();
    
    // Verify state is now InProgress for v2 (v1 was overwritten)
    let state = manager.states_by_key.get(&(issuer.clone(), kid.clone())).unwrap();
    if let ConsensusState::InProgress { my_proposal, .. } = state {
        assert_eq!(my_proposal.observed.to_upsert, Some(jwk_v2.clone()));
    } else {
        panic!("Expected InProgress state");
    }
    
    // Step 4: Process the QC for v1 (arrives late from channel)
    manager.process_quorum_certified_update(qc_v1).unwrap();
    
    // BUG: State is now Finished with inconsistent proposal
    let state = manager.states_by_key.get(&(issuer.clone(), kid.clone())).unwrap();
    if let ConsensusState::Finished { my_proposal, quorum_certified, .. } = state {
        // my_proposal says v2, but quorum_certified is for v1!
        assert_eq!(my_proposal.observed.to_upsert, Some(jwk_v2.clone()));
        let qc_update = KeyLevelUpdate::try_from_issuer_level_repr(&quorum_certified.update).unwrap();
        assert_eq!(qc_update.to_upsert, Some(jwk_v1.clone()));
        
        println!("BUG CONFIRMED: State inconsistency detected!");
        println!("  my_proposal: {:?}", my_proposal.observed.to_upsert);
        println!("  quorum_certified: {:?}", qc_update.to_upsert);
    }
    
    // Step 5: Observe v1 again (cache/network glitch)
    manager.process_new_observation(issuer.clone(), vec![jwk_v1.clone()]).unwrap();
    
    // BUG: The Finished state is overwritten, vtxn_guard dropped, txn removed from pool
    // Even though we have a valid QC for v1!
    let pool_txns = vtxn_pool.pull(Instant::now() + Duration::from_secs(1), 100, 1000000, TransactionFilter::no_op());
    
    // Transaction should be in pool, but it was removed
    assert_eq!(pool_txns.len(), 0, "BUG: Quorum-certified transaction was discarded!");
}
```

## Notes

This vulnerability specifically affects the **per-key JWK consensus mode** (`KeyLevelConsensusManager`). The per-issuer mode (`IssuerLevelConsensusManager`) may have similar issues but was not analyzed in detail. The root cause is the lack of validation when accepting quorum-certified updates combined with the ability to overwrite consensus state mid-flight.

### Citations

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L180-194)
```rust
        let consensus_already_started = match self
            .states_by_key
            .get(&(update.issuer.clone(), update.kid.clone()))
            .cloned()
        {
            Some(ConsensusState::InProgress { my_proposal, .. })
            | Some(ConsensusState::Finished { my_proposal, .. }) => {
                my_proposal.observed.to_upsert == update.to_upsert
            },
            _ => false,
        };

        if consensus_already_started {
            return Ok(());
        }
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L216-228)
```rust
        self.states_by_key.insert(
            (update.issuer.clone(), update.kid.clone()),
            ConsensusState::InProgress {
                my_proposal: ObservedKeyLevelUpdate {
                    author: self.my_addr,
                    observed: update,
                    signature,
                },
                abort_handle_wrapper: QuorumCertProcessGuard {
                    handle: abort_handle,
                },
            },
        );
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L335-346)
```rust
            ConsensusState::InProgress { my_proposal, .. } => {
                let topic = Topic::JWK_CONSENSUS_PER_KEY_MODE {
                    issuer: issuer.clone(),
                    kid: kid.clone(),
                };
                let txn = ValidatorTransaction::ObservedJWKUpdate(issuer_level_repr.clone());
                let vtxn_guard = self.vtxn_pool.put(topic, Arc::new(txn), None);
                *state = ConsensusState::Finished {
                    vtxn_guard,
                    my_proposal: my_proposal.clone(),
                    quorum_certified: issuer_level_repr,
                };
```

**File:** crates/aptos-jwk-consensus/src/types.rs (L96-101)
```rust
impl Drop for QuorumCertProcessGuard {
    fn drop(&mut self) {
        let QuorumCertProcessGuard { handle } = self;
        handle.abort();
    }
}
```

**File:** crates/validator-transaction-pool/src/lib.rs (L202-206)
```rust
impl Drop for TxnGuard {
    fn drop(&mut self) {
        self.pool.lock().try_delete(self.seq_num);
    }
}
```

**File:** crates/aptos-jwk-consensus/src/jwk_observer.rs (L59-72)
```rust
        let mut interval = tokio::time::interval(fetch_interval);
        interval.set_missed_tick_behavior(MissedTickBehavior::Delay);
        let mut close_rx = close_rx.into_stream();
        let my_addr = if cfg!(feature = "smoke-test") {
            // Include self validator address in JWK request,
            // so dummy OIDC providers in smoke tests can do things like "key A for validator 1, key B for validator 2".
            Some(my_addr)
        } else {
            None
        };

        loop {
            tokio::select! {
                _ = interval.tick().fuse() => {
```
