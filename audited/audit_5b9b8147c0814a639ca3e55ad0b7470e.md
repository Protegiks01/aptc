# Audit Report

## Title
State KV Shard Pruner Skips Historical Entries After Progress Initialization, Causing Unbounded Database Growth

## Summary
The `StateKvShardPruner::prune()` function uses RocksDB's `seek()` operation with a partial key encoding that positions the iterator at entries with `stale_since_version >= current_progress`. When a shard's pruner progress is lost due to crashes and gets reinitialized to the metadata pruner's progress, the catch-up prune operation permanently skips all stale entries with `stale_since_version < current_progress`, causing unbounded database growth and eventual storage exhaustion.

## Finding Description

The vulnerability exists in the interaction between pruner initialization and the seek-based iteration logic.

When `StateKvShardPruner::new()` is called, it retrieves the shard's pruning progress using `get_or_initialize_subpruner_progress()`. If no progress exists (due to crashes or data loss), this function initializes the progress to `metadata_progress` and persists it: [1](#0-0) 

The shard pruner then performs a catch-up prune by calling `prune(progress, metadata_progress)`: [2](#0-1) 

**Critical Issue:** The `prune()` function uses `seek()` with just the `current_progress` Version value: [3](#0-2) 

The schema key structure is `| stale_since_version | version | state_key_hash |` with `stale_since_version` as the primary sort component: [4](#0-3) 

The `SeekKeyCodec` implementation for `Version` encodes only 8 bytes (the version value), creating a partial key: [5](#0-4) 

RocksDB's `seek()` operation positions the iterator at the first key **≥** the seek key. When seeking with version 100, the iterator positions at the first entry where `stale_since_version ≥ 100`, permanently skipping all entries with `stale_since_version < 100`.

**Attack Scenario:**
1. Node runs with sharding enabled (mandatory for mainnet/testnet): [6](#0-5) 
2. Metadata pruner completes and updates progress to version 100
3. Node crashes before shard pruner persists its progress (non-atomic update): [7](#0-6) 
4. On restart: shard has no progress, gets initialized to metadata_progress=100
5. Catch-up prune calls `prune(100, 100)`, seeks to version 100
6. All entries with `stale_since_version < 100` are skipped and never pruned
7. Repeated crashes accumulate orphaned entries, causing unbounded database growth

The same vulnerability pattern exists in `StateMerkleShardPruner` which uses similar initialization logic: [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program:

1. **Validator Node Slowdowns (High Severity)**: As unpruned data accumulates, database operations become progressively slower, degrading node performance and potentially affecting consensus participation. This aligns with bug bounty criterion #8: "Validator Node Slowdowns - Significant performance degradation affecting consensus."

2. **Storage Exhaustion**: Unbounded database growth eventually leads to disk space exhaustion, causing node crashes and loss of availability. This affects network health as validators become unable to participate in consensus.

3. **State Inconsistencies**: Different nodes accumulate different amounts of orphaned data based on their crash history, leading to inconsistent database sizes and performance characteristics across the network.

4. **Production Impact**: This affects all mainnet/testnet deployments where `enable_storage_sharding=true` is mandatory, making it a widespread production issue.

## Likelihood Explanation

**Likelihood: High**

This vulnerability will occur in production under realistic operational conditions:

1. **Node Crashes During Pruning**: Common causes include power failures, OOM kills during heavy pruning operations, manual restarts/updates during active pruning, and hardware issues. These are routine operational events.

2. **Non-Atomic Progress Updates**: The metadata pruner and shard pruners write to separate database instances sequentially, creating a vulnerability window during which crashes can occur.

3. **Accumulation Over Time**: Each crash during pruning potentially leaves more orphaned entries. Over months of operation, the cumulative effect becomes significant.

4. **No Self-Healing**: Once entries are skipped, there is no mechanism to detect or recover them. They remain permanently until manual intervention.

This is a **logic vulnerability** in the pruner's catch-up design that manifests through normal operational events, not requiring any malicious actor.

## Recommendation

Modify the catch-up prune logic in `StateKvShardPruner::new()` to always start seeking from version 0 when catching up, ensuring no entries are skipped:

```rust
pub(in crate::pruner) fn new(
    shard_id: usize,
    db_shard: Arc<DB>,
    metadata_progress: Version,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        &db_shard,
        &DbMetadataKey::StateKvShardPrunerProgress(shard_id),
        metadata_progress,
    )?;
    let myself = Self { shard_id, db_shard };

    info!(
        progress = progress,
        metadata_progress = metadata_progress,
        "Catching up state kv shard {shard_id}."
    );
    // Always start from version 0 to ensure no entries are skipped
    myself.prune(0, metadata_progress)?;

    Ok(myself)
}
```

Alternatively, implement backward seeking from `current_progress` to version 0, or maintain a separate index of unpruned entry ranges.

## Proof of Concept

A complete Rust test demonstrating this vulnerability would require:
1. Creating a state KV database with sharding enabled
2. Inserting stale entries across multiple versions (e.g., versions 50, 75, 100, 120)
3. Advancing metadata pruner progress to version 100
4. Simulating shard progress loss (deleting `StateKvShardPrunerProgress` metadata)
5. Reinitializing the shard pruner
6. Verifying that entries with `stale_since_version < 100` remain in the database

The technical analysis above, validated through code inspection at multiple levels (initialization, schema structure, seek implementation, and RocksDB iterator behavior), demonstrates the vulnerability's existence and exploitability through routine operational events.

### Citations

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-59)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L30-44)
```rust
        let progress = get_or_initialize_subpruner_progress(
            &db_shard,
            &DbMetadataKey::StateKvShardPrunerProgress(shard_id),
            metadata_progress,
        )?;
        let myself = Self { shard_id, db_shard };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up state kv shard {shard_id}."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L54-62)
```rust
        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
```

**File:** storage/aptosdb/src/schema/stale_state_value_index_by_key_hash/mod.rs (L13-19)
```rust
//! ```text
//! |<-------------------key------------------------>|
//! | stale_since_version | version | state_key_hash |
//! ```
//!
//! `stale_since_version` is serialized in big endian so that records in RocksDB will be in order of
//! its numeric value.
```

**File:** storage/aptosdb/src/schema/stale_state_value_index_by_key_hash/mod.rs (L76-80)
```rust
impl SeekKeyCodec<StaleStateValueIndexByKeyHashSchema> for Version {
    fn encode_seek_key(&self) -> Result<Vec<u8>> {
        Ok(self.to_be_bytes().to_vec())
    }
}
```

**File:** config/src/config/storage_config.rs (L664-668)
```rust
            if (chain_id.is_testnet() || chain_id.is_mainnet())
                && config_yaml["rocksdb_configs"]["enable_storage_sharding"].as_bool() != Some(true)
            {
                panic!("Storage sharding (AIP-97) is not enabled in node config. Please follow the guide to migration your node, and set storage.rocksdb_configs.enable_storage_sharding to true explicitly in your node config. https://aptoslabs.notion.site/DB-Sharding-Migration-Public-Full-Nodes-1978b846eb7280b29f17ceee7d480730");
            }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L64-78)
```rust
            self.metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.shard_pruners.par_iter().try_for_each(|shard_pruner| {
                    shard_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| {
                            anyhow!(
                                "Failed to prune state kv shard {}: {err}",
                                shard_pruner.shard_id(),
                            )
                        })
                })
            })?;
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L36-53)
```rust
        let progress = get_or_initialize_subpruner_progress(
            &db_shard,
            &S::progress_metadata_key(Some(shard_id)),
            metadata_progress,
        )?;
        let myself = Self {
            shard_id,
            db_shard,
            _phantom: PhantomData,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up {} shard {shard_id}.",
            S::name(),
        );
        myself.prune(progress, metadata_progress, usize::MAX)?;
```
