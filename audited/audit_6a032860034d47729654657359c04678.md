# Audit Report

## Title
Consensus Private Key Exposure via Persistent Temporary File After fs::rename() Failure

## Summary
When `OnDiskStorage::write()` fails during the `fs::rename()` operation, the temporary file containing sensitive consensus private keys remains on disk until either the next successful write or the `OnDiskStorage` instance is dropped. If the validator process crashes between the failed write and cleanup, the consensus private key persists on the filesystem indefinitely, creating an information disclosure vulnerability.

## Finding Description

The vulnerability exists in the `write()` function of `OnDiskStorage`, which is used by validators to persist consensus private keys through `PersistentSafetyStorage`. [1](#0-0) 

The critical flow is:
1. Consensus private keys are stored via `internal_store.set(CONSENSUS_KEY, consensus_private_key)` [2](#0-1) 
2. This calls `OnDiskStorage::write()` which serializes the entire key-value store (including the BLS private key) to JSON
3. The serialized data is written to a temporary file at `self.temp_path.path()`
4. `fs::rename()` attempts to atomically move the temp file to the final location
5. If `fs::rename()` fails (permission denied, cross-device link, disk full, etc.), the function returns an error but the temp file remains on disk

The `temp_path` field is a `TempPath` instance with automatic cleanup via its `Drop` implementation: [3](#0-2) 

However, since `temp_path` is a **field** of the `OnDiskStorage` struct [4](#0-3) , it only gets dropped when the entire `OnDiskStorage` instance is dropped. 

**Attack Scenario:**
1. Validator attempts to persist updated consensus safety data (last_voted_round, etc.)
2. `fs::rename()` fails due to transient filesystem issue (permission denied, disk I/O error, target file locked)
3. Validator process crashes or is killed before next successful write
4. Temp file containing consensus private key remains on disk with potentially permissive permissions
5. Attacker with filesystem access (via separate vulnerability, container escape, or compromised co-tenant) reads the temp file
6. Attacker extracts the BLS consensus private key and can sign consensus messages on behalf of the validator

**Broken Invariant:** 
This violates the "Cryptographic Correctness" invariant - sensitive cryptographic keys must be properly protected and cleaned up. The implementation creates an unintended data persistence window where consensus keys remain exposed on disk.

## Impact Explanation

**Severity: HIGH**

Per Aptos bug bounty criteria, this qualifies as **High Severity** due to:
- **Significant protocol violations**: Exposure of consensus private keys enables Byzantine behavior
- **Validator node security compromise**: Attacker can impersonate the validator in consensus
- Potential for **consensus safety violations** if the compromised key is used for double-signing or equivocation

While the vulnerability requires filesystem access as a prerequisite (which limits direct exploitation), it represents a **defense-in-depth failure** that compounds the impact of other vulnerabilities. Additionally, in containerized/multi-tenant environments, filesystem isolation failures could allow cross-container access to these temp files.

The comment in the code itself acknowledges security concerns: [5](#0-4) 

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability requires two conditions:
1. **fs::rename() failure**: Realistic in production environments due to:
   - Filesystem permission issues (common in containerized deployments)
   - Disk I/O errors or disk full conditions  
   - File locking on some operating systems
   - SELinux/AppArmor policy violations
   
2. **Process crash before cleanup**: Realistic scenarios include:
   - OOM killer terminating the validator process
   - Forced shutdown (SIGKILL) during maintenance
   - Crash due to separate bug
   - Container orchestration (Kubernetes) pod eviction

The combination is moderately likely in production deployments, especially in cloud environments with aggressive resource management.

## Recommendation

Implement explicit cleanup in the error path to ensure temp files are removed even when `fs::rename()` fails:

```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    let mut file = File::create(self.temp_path.path())?;
    file.write_all(&contents)?;
    
    // Attempt rename and cleanup temp file on failure
    match fs::rename(&self.temp_path, &self.file_path) {
        Ok(()) => Ok(()),
        Err(e) => {
            // Explicitly remove temp file on rename failure
            let _ = fs::remove_file(self.temp_path.path());
            Err(e.into())
        }
    }
}
```

Alternatively, use a scoped temporary file that gets cleaned up immediately after successful rename:

```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    
    // Create a new scoped temp file for this operation
    let scoped_temp = TempPath::new_with_temp_dir(
        self.file_path.parent()
            .map_or_else(PathBuf::new, |p| p.to_path_buf())
    );
    
    let mut file = File::create(scoped_temp.path())?;
    file.write_all(&contents)?;
    drop(file);
    
    fs::rename(&scoped_temp, &self.file_path)?;
    // scoped_temp is dropped here, cleaning up on success
    Ok(())
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_temp_file_leak {
    use super::*;
    use std::fs;
    use std::path::PathBuf;
    
    #[test]
    fn test_temp_file_persists_after_rename_failure() {
        // Create OnDiskStorage with a test file
        let test_dir = std::env::temp_dir().join("aptos_test_ondisk");
        fs::create_dir_all(&test_dir).unwrap();
        
        let storage_path = test_dir.join("test_storage.json");
        let mut storage = OnDiskStorage::new(storage_path.clone());
        
        // Store a sensitive value (simulating consensus key)
        let sensitive_data = "SENSITIVE_CONSENSUS_PRIVATE_KEY_DATA";
        storage.set("consensus", sensitive_data).unwrap();
        
        // Record the temp file path before it's moved
        let temp_file_path = storage.temp_path.path().to_path_buf();
        
        // Make target file read-only to force rename failure
        let target_file = fs::File::create(&storage_path).unwrap();
        let metadata = target_file.metadata().unwrap();
        let mut permissions = metadata.permissions();
        permissions.set_readonly(true);
        fs::set_permissions(&storage_path, permissions).unwrap();
        
        // Attempt to write again - this will fail at rename
        let result = storage.set("consensus", "NEW_VALUE");
        assert!(result.is_err());
        
        // VULNERABILITY: Temp file still exists with sensitive data
        assert!(temp_file_path.exists(), "Temp file should still exist after rename failure");
        
        let leaked_content = fs::read_to_string(&temp_file_path).unwrap();
        assert!(leaked_content.contains("SENSITIVE"), "Sensitive data leaked in temp file");
        
        // Cleanup
        drop(storage);
        fs::remove_dir_all(&test_dir).unwrap();
    }
}
```

## Notes

While the code contains a warning that `OnDiskStorage` "should not be used in production" [6](#0-5) , it is still used in validator configurations [7](#0-6)  and test networks. The vulnerability is particularly concerning because:

1. Defense-in-depth principle: Even if an attacker gains partial filesystem access, they shouldn't be able to extract long-lived secrets
2. Container environments: In Kubernetes/Docker deployments, volume mounts and shared storage increase the risk of cross-boundary access
3. Forensic concerns: Temp files may persist in backups, snapshots, or crash dumps

The fix should be implemented regardless of the "testing only" disclaimer, as the component is demonstrably used in deployed configurations.

### Citations

**File:** secure/storage/src/on_disk.rs (L16-22)
```rust
/// OnDiskStorage represents a key value store that is persisted to the local filesystem and is
/// intended for single threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission
/// checks and simply offers a proof of concept to unblock building of applications without more
/// complex data stores. Internally, it reads and writes all data to a file, which means that it
/// must make copies of all key material which violates the code base. It violates it because
/// the anticipation is that data stores would securely handle key material. This should not be used
/// in production.
```

**File:** secure/storage/src/on_disk.rs (L23-27)
```rust
pub struct OnDiskStorage {
    file_path: PathBuf,
    temp_path: TempPath,
    time_service: TimeService,
}
```

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L68-68)
```rust
        let result = internal_store.set(CONSENSUS_KEY, consensus_private_key);
```

**File:** crates/aptos-temppath/src/lib.rs (L20-28)
```rust
impl Drop for TempPath {
    fn drop(&mut self) {
        if !self.persist {
            fs::remove_dir_all(&self.path_buf)
                .or_else(|_| fs::remove_file(&self.path_buf))
                .unwrap_or(());
        }
    }
}
```

**File:** docker/compose/aptos-node/validator.yaml (L1-1)
```yaml
base:
```
