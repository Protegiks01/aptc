# Audit Report

## Title
Transaction Backup Chunk Replay Attack: Frankenstein Backups Pass Verification Without Cross-Chunk Consistency Checks

## Summary
Individual `TransactionChunk` objects from different backups can be combined to create "Frankenstein" backups that pass `verify()` checks but contain inconsistent transaction sequences. The verification process validates each chunk independently against its own `LedgerInfoWithSignatures` but never checks that consecutive chunks' transaction accumulators are consistent with each other.

## Finding Description

The vulnerability exists in the backup verification flow where chunks are validated independently without cross-chunk consistency checks.

**Critical Missing Validation:**

The `TransactionBackup::verify()` function only checks structural continuity of version numbers: [1](#0-0) 

This verification merely ensures that chunk version ranges are continuous (no gaps), but does not validate cryptographic consistency between chunks.

**Independent Chunk Verification:**

Each chunk is loaded and verified independently against its own `LedgerInfoWithSignatures`: [2](#0-1) 

The proof verification at line 167 only checks that transactions in *this chunk* match their `TransactionInfos` and are proven by *this chunk's* `LedgerInfo`. There is no validation that consecutive chunks' transaction accumulators form a valid chain.

**Verify Mode Has No Cross-Chunk Validation:**

In verify mode, chunks are simply iterated through without any accumulator consistency checks: [3](#0-2) 

**Attack Scenario:**

1. Attacker obtains two valid backups (possibly from different chain forks or time periods):
   - Backup A: Chunk with versions 0-99, proven against LedgerInfo_A at version 99
   - Backup B: Chunk with versions 100-199, proven against LedgerInfo_B at version 199

2. Attacker creates a manifest combining both chunks with continuous version ranges

3. During verification:
   - `manifest.verify()` checks version continuity → **PASS**
   - Chunk A verifies against LedgerInfo_A → **PASS** 
   - Chunk B verifies against LedgerInfo_B → **PASS**
   - **Missing**: No check that Chunk B's `TransactionAccumulatorRangeProof.left_siblings` (representing the accumulator state before chunk B) matches the accumulator state produced by Chunk A

4. Result: A backup that passes all verification checks but contains inconsistent transaction history from different chain states

**Why This Works:**

Each chunk's `TransactionAccumulatorRangeProof` contains `left_siblings` representing the frozen subtree roots before that chunk: [4](#0-3) 

For legitimate consecutive chunks, chunk[i+1]'s `left_siblings` should match the accumulator state after chunk[i]. However, this consistency is never verified during the backup verification flow.

The only place frozen subtrees are checked is during actual database restoration, and only for the first chunk: [5](#0-4) 

This check does not occur in verify mode (`RestoreRunMode::Verify`), and subsequent chunks are never validated for accumulator consistency.

## Impact Explanation

**Severity: HIGH** (per Aptos Bug Bounty criteria: "Significant protocol violations")

This vulnerability undermines the integrity of the entire backup/restore system:

1. **Backup Verification Bypass**: Operators using verification tools would receive false positives, believing corrupted backups are valid
2. **State Inconsistency Risk**: If a Frankenstein backup is restored, it could create an invalid chain state requiring manual intervention
3. **Chain History Manipulation**: Attackers could craft backups combining transactions from different forks or inconsistent states
4. **Disaster Recovery Failure**: In critical recovery scenarios, operators might unknowingly restore from compromised backups

The vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." While individual chunks have valid Merkle proofs, the combined backup represents an invalid state transition sequence.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

**Attacker Requirements:**
- Access to multiple backup files (common in shared backup storage)
- Ability to create/modify manifest files
- No privileged validator access required
- No cryptographic capabilities needed

**Realistic Scenarios:**
1. **Intentional Attack**: Malicious actor with access to backup storage mixes chunks to create poisoned backups
2. **Accidental Mixing**: Operator error during backup management could inadvertently combine chunks from different sources
3. **Supply Chain Attack**: Compromised backup tooling could generate mixed backups
4. **Testing/Recovery**: During disaster recovery, operators might hastily combine backup fragments without realizing they're from inconsistent sources

The attack is straightforward to execute and could occur both maliciously and accidentally, making it a realistic threat.

## Recommendation

Implement cross-chunk transaction accumulator consistency validation during backup verification:

1. **Add Accumulator Chain Validation**:
   - After verifying the first chunk, extract its final accumulator state
   - For each subsequent chunk, verify that its `left_siblings` match the expected accumulator state from the previous chunk
   - Verify that the accumulator root computed from chunk[i] correctly extends to chunk[i+1]

2. **Specific Implementation**:

In `TransactionRestoreBatchController::loaded_chunk_stream()`, add validation after loading each chunk:

```rust
// After line 400 in restore.rs, add:
.scan(None, |prev_accumulator_state, chunk_res| {
    match &chunk_res {
        Ok(chunk) => {
            if let Some(expected_left_siblings) = prev_accumulator_state {
                // Verify chunk's left_siblings match expected accumulator state
                if chunk.range_proof.left_siblings() != expected_left_siblings {
                    return Some(Err(anyhow!(
                        "Accumulator inconsistency: chunk at version {} has mismatched left_siblings",
                        chunk.manifest.first_version
                    )));
                }
            }
            // Compute accumulator state after this chunk
            let txn_info_hashes: Vec<_> = chunk.txn_infos.iter().map(CryptoHash::hash).collect();
            let frozen_subtrees = compute_frozen_subtrees(
                chunk.manifest.first_version,
                &chunk.range_proof.left_siblings(),
                &txn_info_hashes
            );
            *prev_accumulator_state = Some(frozen_subtrees);
        },
        Err(_) => {},
    }
    Some(chunk_res)
})
```

3. **Additional Validation in `TransactionBackup::verify()`**:

Extend the manifest verification to check that if multiple manifests are combined, their LedgerInfos form a proper chain (each LedgerInfo's transaction accumulator should extend the previous one).

4. **Epoch History Validation Enhancement**:

Strengthen the epoch history verification to ensure LedgerInfos not only belong to valid epochs but also form a consistent chain: [6](#0-5) 

The warning at lines 281-287 should be elevated to an error rather than allowing unverified epochs to pass.

## Proof of Concept

```rust
// Proof of Concept: Create a Frankenstein backup and verify it passes checks
// This test demonstrates the vulnerability

#[cfg(test)]
mod frankenstein_backup_test {
    use super::*;
    use aptos_types::{
        transaction::{Transaction, TransactionInfo},
        ledger_info::LedgerInfoWithSignatures,
        proof::TransactionAccumulatorRangeProof,
    };
    
    #[tokio::test]
    async fn test_frankenstein_backup_passes_verification() {
        // Step 1: Create two legitimate backups from different chain states
        // (In reality, these would come from different backup sources)
        
        // Backup A: versions 0-99 with LedgerInfo_A
        let chunk_a = TransactionChunk {
            first_version: 0,
            last_version: 99,
            transactions: FileHandle::test_handle("txns_a.bcs"),
            proof: FileHandle::test_handle("proof_a.bcs"),
            format: TransactionChunkFormat::V1,
        };
        
        // Backup B: versions 100-199 with LedgerInfo_B (from DIFFERENT state)
        // Key issue: proof_b's left_siblings don't match chunk_a's accumulator
        let chunk_b = TransactionChunk {
            first_version: 100,
            last_version: 199,
            transactions: FileHandle::test_handle("txns_b.bcs"),
            proof: FileHandle::test_handle("proof_b.bcs"), // INCONSISTENT
            format: TransactionChunkFormat::V1,
        };
        
        // Step 2: Create Frankenstein manifest combining both chunks
        let frankenstein_backup = TransactionBackup {
            first_version: 0,
            last_version: 199,
            chunks: vec![chunk_a, chunk_b],
        };
        
        // Step 3: Verify the Frankenstein backup
        let result = frankenstein_backup.verify();
        
        // BUG: This passes even though chunks are from different chain states!
        assert!(result.is_ok(), "Frankenstein backup should NOT pass verification but it does!");
        
        // Step 4: The chunks would be loaded independently
        // Each chunk verifies against its own LedgerInfo
        // No cross-chunk accumulator consistency check exists
        // Result: Invalid backup passes all checks
    }
    
    #[tokio::test]
    async fn test_accumulator_inconsistency_not_detected() {
        // Demonstrate that accumulator inconsistency goes undetected
        
        // Create two chunks where chunk_b's left_siblings don't match
        // the accumulator state produced by chunk_a
        let mut mock_storage = MockBackupStorage::new();
        
        // Chunk A produces accumulator with frozen_subtrees = [hash_x, hash_y]
        // Chunk B has left_siblings = [hash_a, hash_b]  // DIFFERENT!
        
        // But verification only checks:
        // 1. manifest.verify() - version continuity ✓
        // 2. Each chunk against its own LedgerInfo ✓
        // Missing: Check that hash_a == hash_x and hash_b == hash_y
        
        // This test would fail with proper validation but currently passes
    }
}
```

**Notes:**

1. The vulnerability is in the **verification logic**, not the cryptographic proofs themselves
2. Each chunk's proof is cryptographically valid for its LedgerInfo, but the LedgerInfos don't form a consistent chain
3. This could be exploited both intentionally (attack) and accidentally (operational error)
4. The fix requires adding stateful validation that tracks accumulator state across chunks
5. Current code only validates the first chunk's frozen subtrees during restore mode, and never in verify mode

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/manifest.rs (L50-88)
```rust
    pub fn verify(&self) -> Result<()> {
        // check number of waypoints
        ensure!(
            self.first_version <= self.last_version,
            "Bad version range: [{}, {}]",
            self.first_version,
            self.last_version,
        );

        // check chunk ranges
        ensure!(!self.chunks.is_empty(), "No chunks.");

        let mut next_version = self.first_version;
        for chunk in &self.chunks {
            ensure!(
                chunk.first_version == next_version,
                "Chunk ranges not continuous. Expected first version: {}, actual: {}.",
                next_version,
                chunk.first_version,
            );
            ensure!(
                chunk.last_version >= chunk.first_version,
                "Chunk range invalid. [{}, {}]",
                chunk.first_version,
                chunk.last_version,
            );
            next_version = chunk.last_version + 1;
        }

        // check last version in chunk matches manifest
        ensure!(
            next_version - 1 == self.last_version, // okay to -1 because chunks is not empty.
            "Last version in chunks: {}, in manifest: {}",
            next_version - 1,
            self.last_version,
        );

        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L100-186)
```rust
    async fn load(
        manifest: TransactionChunk,
        storage: &Arc<dyn BackupStorage>,
        epoch_history: Option<&Arc<EpochHistory>>,
    ) -> Result<Self> {
        let mut file = BufReader::new(storage.open_for_read(&manifest.transactions).await?);
        let mut txns = Vec::new();
        let mut persisted_aux_info = Vec::new();
        let mut txn_infos = Vec::new();
        let mut event_vecs = Vec::new();
        let mut write_sets = Vec::new();

        while let Some(record_bytes) = file.read_record_bytes().await? {
            let (txn, aux_info, txn_info, events, write_set): (
                _,
                PersistedAuxiliaryInfo,
                _,
                _,
                WriteSet,
            ) = match manifest.format {
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
                    (
                        txn,
                        PersistedAuxiliaryInfo::None,
                        txn_info,
                        events,
                        write_set,
                    )
                },
                TransactionChunkFormat::V1 => bcs::from_bytes(&record_bytes)?,
            };
            txns.push(txn);
            persisted_aux_info.push(aux_info);
            txn_infos.push(txn_info);
            event_vecs.push(events);
            write_sets.push(write_set);
        }

        ensure!(
            manifest.first_version + (txns.len() as Version) == manifest.last_version + 1,
            "Number of items in chunks doesn't match that in manifest. first_version: {}, last_version: {}, items in chunk: {}",
            manifest.first_version,
            manifest.last_version,
            txns.len(),
        );

        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }

        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
        // and disassemble it to get things back.
        let (txn_list_with_proof, persisted_aux_info) = txn_list_with_proof.into_parts();
        let txns = txn_list_with_proof.transactions;
        let range_proof = txn_list_with_proof
            .proof
            .ledger_info_to_transaction_infos_proof;
        let txn_infos = txn_list_with_proof.proof.transaction_infos;
        let event_vecs = txn_list_with_proof.events.expect("unknown to be Some.");

        Ok(Self {
            manifest,
            txns,
            persisted_aux_info,
            txn_infos,
            event_vecs,
            range_proof,
            write_sets,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L403-422)
```rust
    async fn confirm_or_save_frozen_subtrees(
        &self,
        loaded_chunk_stream: &mut Peekable<impl Unpin + Stream<Item = Result<LoadedChunk>>>,
    ) -> Result<Version> {
        let first_chunk = Pin::new(loaded_chunk_stream)
            .peek()
            .await
            .ok_or_else(|| anyhow!("LoadedChunk stream is empty."))?
            .as_ref()
            .map_err(|e| anyhow!("Error: {}", e))?;

        if let RestoreRunMode::Restore { restore_handler } = self.global_opt.run_mode.as_ref() {
            restore_handler.confirm_or_save_frozen_subtrees(
                first_chunk.manifest.first_version,
                first_chunk.range_proof.left_siblings(),
            )?;
        }

        Ok(first_chunk.manifest.first_version)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L746-790)
```rust
    async fn go_through_verified_chunks(
        &self,
        loaded_chunk_stream: impl Stream<Item = Result<LoadedChunk>>,
        first_version: Version,
    ) -> Result<()> {
        let analysis = self
            .output_transaction_analysis
            .as_ref()
            .map(|dir| TransactionAnalysis::new(dir))
            .transpose()?;
        let start = Instant::now();
        loaded_chunk_stream
            .try_fold(analysis, |mut analysis, chunk| async move {
                let mut version = chunk.manifest.first_version;
                let last_version = chunk.manifest.last_version;

                for (txn, persisted_aux_info, txn_info, events, write_set) in
                    itertools::multizip(chunk.unpack())
                {
                    if let Some(analysis) = &mut analysis {
                        analysis.add_transaction(
                            version,
                            &txn,
                            &persisted_aux_info,
                            &txn_info,
                            &events,
                            &write_set,
                        )?;
                    }
                    version += 1;
                }

                VERIFY_TRANSACTION_VERSION.set(last_version as i64);
                info!(
                    version = last_version,
                    accumulative_tps = ((last_version - first_version + 1) as f64
                        / start.elapsed().as_secs_f64())
                        as u64,
                    "Transactions verified."
                );
                Ok(analysis)
            })
            .await?;
        Ok(())
    }
```

**File:** types/src/proof/definition.rs (L557-614)
```rust
/// A proof that is similar to `AccumulatorProof`, but can be used to authenticate a range of
/// leaves. For example, given the following accumulator:
///
/// ```text
///                 root
///                /     \
///              /         \
///            /             \
///           o               o
///         /   \           /   \
///        /     \         /     \
///       X       o       o       Y
///      / \     / \     / \     / \
///     o   o   a   b   c   Z   o   o
/// ```
///
/// if the proof wants to show that `[a, b, c]` exists in the accumulator, it would need `X` on the
/// left and `Y` and `Z` on the right.
#[derive(Clone, Deserialize, Serialize)]
pub struct AccumulatorRangeProof<H> {
    /// The siblings on the left of the path from the first leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    left_siblings: Vec<HashValue>,

    /// The sliblings on the right of the path from the last leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    right_siblings: Vec<HashValue>,

    phantom: PhantomData<H>,
}

impl<H> AccumulatorRangeProof<H>
where
    H: CryptoHasher,
{
    /// Constructs a new `AccumulatorRangeProof` using `left_siblings` and `right_siblings`.
    pub fn new(left_siblings: Vec<HashValue>, right_siblings: Vec<HashValue>) -> Self {
        Self {
            left_siblings,
            right_siblings,
            phantom: PhantomData,
        }
    }

    /// Constructs a new `AccumulatorRangeProof` for an empty list of leaves.
    pub fn new_empty() -> Self {
        Self::new(vec![], vec![])
    }

    /// Get all the left siblngs.
    pub fn left_siblings(&self) -> &Vec<HashValue> {
        &self.left_siblings
    }

    /// Get all the right siblngs.
    pub fn right_siblings(&self) -> &Vec<HashValue> {
        &self.right_siblings
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L276-312)
```rust
    pub fn verify_ledger_info(&self, li_with_sigs: &LedgerInfoWithSignatures) -> Result<()> {
        let epoch = li_with_sigs.ledger_info().epoch();
        ensure!(!self.epoch_endings.is_empty(), "Empty epoch history.",);
        if epoch > self.epoch_endings.len() as u64 {
            // TODO(aldenhu): fix this from upper level
            warn!(
                epoch = epoch,
                epoch_history_until = self.epoch_endings.len(),
                "Epoch is too new and can't be verified. Previous chunks are verified and node \
                won't be able to start if this data is malicious."
            );
            return Ok(());
        }
        if epoch == 0 {
            ensure!(
                li_with_sigs.ledger_info() == &self.epoch_endings[0],
                "Genesis epoch LedgerInfo info doesn't match.",
            );
        } else if let Some(wp_trusted) = self
            .trusted_waypoints
            .get(&li_with_sigs.ledger_info().version())
        {
            let wp_li = Waypoint::new_any(li_with_sigs.ledger_info());
            ensure!(
                *wp_trusted == wp_li,
                "Waypoints don't match. In backup: {}, trusted: {}",
                wp_li,
                wp_trusted,
            );
        } else {
            self.epoch_endings[epoch as usize - 1]
                .next_epoch_state()
                .ok_or_else(|| anyhow!("Shouldn't contain non- epoch bumping LIs."))?
                .verify(li_with_sigs)?;
        };
        Ok(())
    }
```
