# Audit Report

## Title
Critical Use-After-Free in QuorumStore Batch Cleanup Leading to Consensus Halt on Crash Recovery

## Summary
The QuorumStore consensus implementation has a critical flaw where batch cleanup occurs based solely on time-based expiration without checking if uncommitted blocks in ConsensusDB still reference those batches. During crash recovery, the materialize phase enters an infinite retry loop when attempting to fetch already-cleaned batches, preventing the node from rejoining consensus and potentially causing network-wide liveness loss.

## Finding Description

The vulnerability stems from the architectural separation between block metadata storage and transaction data storage in the QuorumStore system.

**Architecture Context:**

ConsensusDB persists Block objects containing only payload metadata (batch digests and proofs), not actual transaction data. [1](#0-0) 

The actual transaction batches are stored separately in QuorumStoreDB and referenced by digest. When blocks are committed, `notify_commit()` triggers batch cleanup by calling `update_certified_timestamp()`. [2](#0-1) 

The cleanup process removes batches where `expiration <= certified_time - expiration_buffer_usecs` (60 second buffer). [3](#0-2) 

**The Critical Flaw:**

During crash recovery, `BlockStore::new()` calls `build()` which inserts uncommitted blocks via `insert_block()`. [4](#0-3) 

For each uncommitted block, `insert_block_inner()` invokes `pipeline_builder.build_for_consensus()` to construct the execution pipeline. [5](#0-4) 

The pipeline's materialize phase spawns an asynchronous task that calls `get_transactions()` to fetch batch data. [6](#0-5) [7](#0-6) 

When batches are not found locally, `BatchRequester` attempts to fetch from remote peers. [8](#0-7) 

If all peers have also cleaned up the expired batch, the request returns `ExecutorError::CouldNotGetData`. [9](#0-8) 

**The Fatal Loop:**

The materialize phase implements an infinite retry loop with no timeout mechanism. [10](#0-9) 

When `get_transactions()` fails, the loop retries every 100ms indefinitely, permanently blocking block execution and preventing the node from committing any blocks that depend on the stuck block.

**Vulnerability Scenario:**

1. Validator has uncommitted blocks B1, B2 in ConsensusDB referencing batch X with expiration T
2. Network commits other blocks, advancing `certified_time` past T + 60 seconds  
3. Batch X is cleaned up globally across all validators
4. Validator crashes
5. On restart, recovery loads B1, B2 and spawns materialize phases
6. Materialize phases attempt to fetch batch X via `get_transactions()`
7. Batch X not found locally or remotely â†’ `ExecutorError::CouldNotGetData`
8. Materialize phases enter infinite retry loop
9. Blocks B1, B2 cannot complete execution
10. `try_send_for_execution()` cannot commit these blocks
11. Node's commit_root is frozen, cannot advance ledger state
12. Validator is effectively offline and cannot participate in consensus

## Impact Explanation

This vulnerability meets the **Critical Severity** criterion of "Total loss of liveness/network availability" from the Aptos bug bounty program:

**1. Validator-Level Liveness Loss:**
- Affected validators cannot recover from crashes without manual intervention
- The infinite retry loop has no timeout or fallback mechanism
- The node's commit_root remains frozen at the round before the stuck blocks
- The validator cannot advance its ledger state or commit new blocks

**2. Network-Level Impact:**
- If multiple validators crash simultaneously (datacenter outage, software bug, network partition), all would be unable to recover
- Multiple stuck validators could bring the network below the 2f+1 threshold required for BFT consensus
- This would halt the entire network until manual intervention (deleting ConsensusDB or state sync from snapshot)

**3. Breaks Critical Invariants:**
- Violates the liveness guarantee that a correct node can always recover after a crash
- Violates the assumption that blocks persisted in ConsensusDB can be re-executed
- The `TPayloadManager` trait provides no ordering guarantees preventing this scenario [11](#0-10) 

**4. Non-Recoverable Without Manual Intervention:**
- Automatic recovery via state sync is not triggered because the node successfully starts but blocks are stuck in materialization
- Requires manual deletion of ConsensusDB or forced state sync to recover

## Likelihood Explanation

**High Likelihood** - This vulnerability WILL occur deterministically under specific but common conditions:

**1. Natural Occurrence:**
- No attacker action required
- Happens through normal operational issues (crashes, restarts, deployments)
- Any validator crash lasting longer than batch expiration window + buffer time is at risk

**2. Time Window:**
- Default `expiration_buffer_usecs` is 60 seconds as documented in the code [12](#0-11) 
- Batches expire and are cleaned up when `certified_time > batch.expiration + 60 seconds`
- Common operational scenarios (rolling updates, network issues, hardware failures) can easily exceed this window

**3. Shared Batch Architecture:**
- QuorumStore intentionally shares batches across multiple blocks for bandwidth optimization
- Multiple uncommitted blocks commonly reference the same batches
- Increases the probability that some blocks remain uncommitted when batches expire

**4. No Protection Mechanism:**
- No check exists to prevent cleanup of batches referenced by uncommitted blocks in ConsensusDB
- No mechanism to extend batch expiration for uncommitted blocks
- No fallback or timeout in the materialize retry loop

**5. Production Scenarios:**
- Datacenter maintenance requiring validator restarts
- Software updates with extended downtime
- Network partitions followed by recovery
- Hardware failures requiring node rebuilds

## Recommendation

Implement a multi-layered protection strategy:

**1. Immediate Fix - Add Uncommitted Block Check:**
Before cleaning up batches in `clear_expired_payload()`, check if any uncommitted blocks in ConsensusDB reference those batches. Extend expiration for referenced batches.

**2. Add Materialize Phase Timeout:**
In the materialize retry loop, add a timeout (e.g., 5 minutes) after which the task should abort and trigger state sync as a fallback recovery mechanism.

**3. Preserve Batches for Uncommitted Blocks:**
When persisting blocks to ConsensusDB, also persist their batch data or extend batch expiration to match the longest uncommitted block chain.

**4. Add Recovery Validation:**
During `BlockStore::new()`, validate that all batches referenced by uncommitted blocks are available before building pipelines. If not, trigger state sync immediately.

**5. Improve Monitoring:**
Add metrics to detect stuck materialize phases and alert operators before the issue impacts consensus participation.

## Proof of Concept

The vulnerability can be demonstrated with the following test scenario:

1. Create a validator node with QuorumStore enabled
2. Propose and persist several blocks to ConsensusDB (but don't commit them)
3. Wait for `certified_time` to advance past batch expiration + 60 seconds
4. Trigger batch cleanup via `update_certified_timestamp()`
5. Verify batches are deleted from all validators
6. Restart the validator node
7. Observe that `BlockStore::new()` completes but blocks are stuck in materialize phase
8. Monitor logs showing infinite retry attempts: "failed to prepare block {}, retrying: {}"
9. Verify that `try_send_for_execution()` cannot commit the affected blocks
10. Confirm the node's commit_root remains frozen

The infinite retry can be observed in the logs from the materialize phase retry loop, which will continuously log warnings every 100ms without progressing.

## Notes

This is a deterministic vulnerability that affects the core liveness guarantee of the consensus system. While it requires specific timing conditions (crash + batch expiration), these conditions naturally occur in production environments. The lack of any timeout or fallback mechanism in the materialize retry loop makes this particularly severe, as affected nodes cannot self-recover and require manual operator intervention to restore functionality.

### Citations

**File:** consensus/consensus-types/src/common.rs (L207-224)
```rust
/// The payload in block.
#[derive(Deserialize, Serialize, Clone, Debug, PartialEq, Eq)]
pub enum Payload {
    DirectMempool(Vec<SignedTransaction>),
    InQuorumStore(ProofWithData),
    InQuorumStoreWithLimit(ProofWithDataWithTxnLimit),
    QuorumStoreInlineHybrid(
        Vec<(BatchInfo, Vec<SignedTransaction>)>,
        ProofWithData,
        Option<u64>,
    ),
    OptQuorumStore(OptQuorumStorePayload),
    QuorumStoreInlineHybridV2(
        Vec<(BatchInfo, Vec<SignedTransaction>)>,
        ProofWithData,
        PayloadExecutionLimit,
    ),
}
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L168-170)
```rust
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>) {
        self.batch_reader
            .update_certified_timestamp(block_timestamp);
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-472)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
        let mut ret = Vec::new();
        for h in expired_digests {
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
            // No longer holding the lock on db_cache entry.
            if let Some(value) = removed_value {
                self.free_quota(value);
                ret.push(h);
            }
        }
        ret
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L663-723)
```rust
    fn get_or_fetch_batch(
        &self,
        batch_info: BatchInfo,
        responders: Vec<PeerId>,
    ) -> Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>> {
        let mut responders = responders.into_iter().collect();

        self.inflight_fetch_requests
            .lock()
            .entry(*batch_info.digest())
            .and_modify(|fetch_unit| {
                fetch_unit.responders.lock().append(&mut responders);
            })
            .or_insert_with(|| {
                let responders = Arc::new(Mutex::new(responders));
                let responders_clone = responders.clone();

                let inflight_requests_clone = self.inflight_fetch_requests.clone();
                let batch_store = self.batch_store.clone();
                let requester = self.batch_requester.clone();

                let fut = async move {
                    let batch_digest = *batch_info.digest();
                    defer!({
                        inflight_requests_clone.lock().remove(&batch_digest);
                    });
                    // TODO(ibalajiarun): Support V2 batch
                    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
                        Ok(value.take_payload().expect("Must have payload"))
                    } else {
                        // Quorum store metrics
                        counters::MISSED_BATCHES_COUNT.inc();
                        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
                        Ok(payload)
                    }
                }
                .boxed()
                .shared();

                tokio::spawn(fut.clone());

                BatchFetchUnit {
                    responders: responders_clone,
                    fut,
                }
            })
            .fut
            .clone()
    }
```

**File:** consensus/src/block_storage/block_store.rs (L282-297)
```rust
        for block in blocks {
            if block.round() <= root_block_round {
                block_store
                    .insert_committed_block(block)
                    .await
                    .unwrap_or_else(|e| {
                        panic!(
                            "[BlockStore] failed to insert committed block during build {:?}",
                            e
                        )
                    });
            } else {
                block_store.insert_block(block).await.unwrap_or_else(|e| {
                    panic!("[BlockStore] failed to insert block during build {:?}", e)
                });
            }
```

**File:** consensus/src/block_storage/block_store.rs (L464-496)
```rust
        if let Some(pipeline_builder) = &self.pipeline_builder {
            let parent_block = self
                .get_block(pipelined_block.parent_id())
                .ok_or_else(|| anyhow::anyhow!("Parent block not found"))?;

            // need weak pointer to break the cycle between block tree -> pipeline block -> callback
            let block_tree = Arc::downgrade(&self.inner);
            let storage = self.storage.clone();
            let id = pipelined_block.id();
            let round = pipelined_block.round();
            let window_size = self.window_size;
            let callback = Box::new(
                move |finality_proof: WrappedLedgerInfo,
                      commit_decision: LedgerInfoWithSignatures| {
                    if let Some(tree) = block_tree.upgrade() {
                        tree.write().commit_callback(
                            storage,
                            id,
                            round,
                            finality_proof,
                            commit_decision,
                            window_size,
                        );
                    }
                },
            );
            pipeline_builder.build_for_consensus(
                &pipelined_block,
                parent_block.pipeline_futs().ok_or_else(|| {
                    anyhow::anyhow!("Parent future doesn't exist, potentially epoch ended")
                })?,
                callback,
            );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L457-460)
```rust
        let materialize_fut = spawn_shared_fut(
            Self::materialize(self.block_preparer.clone(), block.clone(), qc_rx),
            Some(&mut abort_handles),
        );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```

**File:** consensus/src/block_preparer.rs (L42-63)
```rust
    pub async fn materialize_block(
        &self,
        block: &Block,
        block_qc_fut: Shared<impl Future<Output = Option<Arc<QuorumCert>>>>,
    ) -> ExecutorResult<(Vec<SignedTransaction>, Option<u64>, Option<u64>)> {
        fail_point!("consensus::prepare_block", |_| {
            use aptos_executor_types::ExecutorError;
            use std::{thread, time::Duration};
            thread::sleep(Duration::from_millis(10));
            Err(ExecutorError::CouldNotGetData)
        });
        //TODO(ibalajiarun): measure latency
        let (txns, max_txns_from_block_to_execute, block_gas_limit) = tokio::select! {
                // Poll the block qc future until a QC is received. Ignore None outcomes.
                Some(qc) = block_qc_fut => {
                    let block_voters = Some(qc.ledger_info().get_voters_bitvec().clone());
                    self.payload_manager.get_transactions(block, block_voters).await
                },
                result = self.payload_manager.get_transactions(block, None) => {
                   result
                }
        }?;
```

**File:** consensus/src/quorum_store/batch_requester.rs (L142-151)
```rust
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
```

**File:** consensus/src/payload_manager/mod.rs (L27-56)
```rust
pub trait TPayloadManager: Send + Sync {
    /// Notify the payload manager that a block has been committed. This indicates that the
    /// transactions in the block's payload are no longer required for consensus.
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>);

    /// Prefetch the data for a payload. This is used to ensure that the data for a payload is
    /// available when block is executed.
    fn prefetch_payload_data(&self, payload: &Payload, author: Author, timestamp: u64);

    /// Check if the block contains any inline transactions that need
    /// to be denied (e.g., due to block transaction filtering).
    /// This is only used when processing block proposals.
    fn check_denied_inline_transactions(
        &self,
        block: &Block,
        block_txn_filter_config: &BlockTransactionFilterConfig,
    ) -> anyhow::Result<()>;

    /// Check if the transactions corresponding are available. This is specific to payload
    /// manager implementations. For optimistic quorum store, we only check if optimistic
    /// batches are available locally.
    fn check_payload_availability(&self, block: &Block) -> Result<(), BitVec>;

    /// Get the transactions in a block's payload. This function returns a vector of transactions.
    async fn get_transactions(
        &self,
        block: &Block,
        block_voters: Option<BitVec>,
    ) -> ExecutorResult<(Vec<SignedTransaction>, Option<u64>, Option<u64>)>;
}
```
