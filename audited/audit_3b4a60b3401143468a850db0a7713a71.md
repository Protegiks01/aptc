# Audit Report

## Title
Panic-Based Denial of Service in Indexer Transaction Filtering Due to Unvalidated Transaction Type Enum Values

## Summary
The `TransactionRootFilter::matches()` function in the indexer-grpc transaction filtering system contains an unsafe `.expect()` call that panics when encountering transaction type values outside the defined enum range (0-4, 20-21). While this vulnerability cannot be exploited through normal blockchain operations, a malicious validator operating a modified indexer-grpc fullnode service could serve protobuf messages with invalid transaction type values, causing repeated crashes of indexer nodes and data services that apply transaction filters.

## Finding Description

The vulnerability exists in the transaction filtering logic used by the indexer-grpc infrastructure: [1](#0-0) 

The protobuf `TransactionType` enum defines only specific values: [2](#0-1) 

When protobuf messages are deserialized, the `type` field is stored as an `i32` and protobuf allows ANY integer value during deserialization: [3](#0-2) 

**Attack Path:**

1. A malicious validator modifies their indexer-grpc fullnode service to bypass the normal `convert_transaction` function and directly construct protobuf `Transaction` messages with invalid `type` field values (e.g., 5, 10, 100)

2. An indexer's cache worker connects to this malicious validator's fullnode-data-service and receives the malformed transactions: [4](#0-3) 

3. The cache worker stores these transactions in Redis without validation

4. Either:
   - The data service applies a `txns_to_strip_filter` containing a `TransactionRootFilter` with `txn_type` set, causing a panic: [5](#0-4) 
   
   OR
   
   - The fullnode stream coordinator applies a filter when serving transactions: [6](#0-5) 

5. The `.expect("Invalid transaction type")` call panics, crashing the indexer node or data service

**Important Caveats:**
- This vulnerability does NOT affect core blockchain consensus, state, or validator operations
- The core blockchain stores transactions as native Rust types, not protobuf, and always has valid type values
- The vulnerability is limited to the indexer-grpc infrastructure layer
- Exploitation requires a malicious validator to run modified indexer-grpc software

## Impact Explanation

This meets **High Severity** criteria per the Aptos bug bounty program: "API crashes" - specifically, the indexer data service API can be repeatedly crashed, denying service to all indexers relying on that infrastructure.

The impact includes:
- Repeated crashes of indexer data services when processing transactions with invalid type values
- Potential cascade effect where one malicious validator affects all indexers using shared data service infrastructure
- Denial of service for downstream applications relying on indexer data (DEXs, wallets, explorers)
- Service disruption until the malicious data is identified and removed from cache/storage

However, the core blockchain remains unaffected - validators continue producing blocks normally, and the blockchain state is not corrupted.

## Likelihood Explanation

**Likelihood: Low to Medium**

While technically exploitable, this requires specific conditions:

**Requirements:**
- A validator operator must intentionally modify their indexer-grpc fullnode code to serve malformed protobuf messages
- Indexers must configure their cache workers to connect to the malicious validator's fullnode service
- The indexer or data service must use transaction filtering with `txn_type` checks

**Realistic Scenarios:**
- Indexer operators commonly connect to multiple validators for redundancy - one malicious validator in the set could cause crashes
- Shared data service infrastructure means one compromised cache worker affects all downstream indexers
- Transaction type filtering is a common use case for selective indexing

**Mitigating Factors:**
- Validator operators are generally trusted entities with reputation at stake
- Indexers typically operate their own trusted fullnodes rather than relying on external validators
- The issue can be detected and mitigated by removing the malicious data source

## Recommendation

Replace the unsafe `.expect()` call with graceful error handling that logs invalid values and skips the transaction or returns a default matching behavior:

```rust
#[inline]
fn matches(&self, item: &Transaction) -> bool {
    if !self
        .success
        .matches_opt(&item.info.as_ref().map(|i| i.success))
    {
        return false;
    }

    if let Some(txn_type) = &self.txn_type {
        match TransactionType::try_from(item.r#type) {
            Ok(item_txn_type) => {
                if txn_type != &item_txn_type {
                    return false;
                }
            }
            Err(_) => {
                // Log invalid transaction type but don't panic
                warn!(
                    "Invalid transaction type value {} at version {}", 
                    item.r#type, 
                    item.version
                );
                // Return false to filter out invalid transactions
                return false;
            }
        }
    }

    true
}
```

Additionally, consider validating transaction type values when deserializing from cache/file store, before they reach the filtering stage.

## Proof of Concept

**Setup:**
1. Run a modified fullnode with altered indexer-grpc service that constructs transactions with invalid type values
2. Configure a cache worker to connect to this fullnode
3. Set up a data service with transaction filtering enabled

**Exploitation:**

```rust
// Modified fullnode code (attacker's modification):
// In convert_transaction or stream coordinator, replace valid type with invalid:

let malicious_txn = transaction::Transaction {
    timestamp: Some(timestamp),
    version: 12345,
    info: Some(txn_info),
    epoch: 1,
    block_height: 100,
    r#type: 100, // INVALID: not in enum range (0-4, 20-21)
    txn_data: Some(txn_data),
    size_info: Some(size_info),
};

// When indexer data service applies filter:
let filter = TransactionRootFilterBuilder::default()
    .txn_type(Some(TransactionType::User))
    .build()
    .unwrap();

// This will panic:
// thread 'main' panicked at 'Invalid transaction type': 
// ecosystem/indexer-grpc/transaction-filter/src/filters/transaction_root.rs:69
filter.matches(&malicious_txn);
```

**Testing:**
To test without a malicious validator, inject a corrupted protobuf message directly into Redis with an invalid type value, then query the data service with filtering enabled.

---

## Notes

**Critical Limitation:** This vulnerability requires insider access - either a malicious validator running modified software, or an attacker with access to the Redis/file store infrastructure. The question explicitly mentions "malicious validators" which suggests this threat model is in scope, but it does not meet the general criterion of being "exploitable by unprivileged attacker without privileged validator access."

The core Aptos blockchain and consensus mechanism are **not affected** by this issue. This is purely an indexer infrastructure vulnerability that affects data availability for off-chain applications, not on-chain security or state integrity.

### Citations

**File:** ecosystem/indexer-grpc/transaction-filter/src/filters/transaction_root.rs (L59-76)
```rust
    fn matches(&self, item: &Transaction) -> bool {
        if !self
            .success
            .matches_opt(&item.info.as_ref().map(|i| i.success))
        {
            return false;
        }

        if let Some(txn_type) = &self.txn_type {
            if txn_type
                != &TransactionType::try_from(item.r#type).expect("Invalid transaction type")
            {
                return false;
            }
        }

        true
    }
```

**File:** protos/proto/aptos/transaction/v1/transaction.proto (L47-56)
```text
  enum TransactionType {
    TRANSACTION_TYPE_UNSPECIFIED = 0;
    TRANSACTION_TYPE_GENESIS = 1;
    TRANSACTION_TYPE_BLOCK_METADATA = 2;
    TRANSACTION_TYPE_STATE_CHECKPOINT = 3;
    TRANSACTION_TYPE_USER = 4;
    // values 5-19 skipped for no reason
    TRANSACTION_TYPE_VALIDATOR = 20;
    TRANSACTION_TYPE_BLOCK_EPILOGUE = 21;
  }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L142-156)
```rust
    pub fn into_transaction(self) -> Transaction {
        match self {
            CacheEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
            },
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
            },
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L209-247)
```rust
        Response::Data(data) => {
            let transaction_len = data.transactions.len();
            let data_download_duration_in_secs = download_start_time.elapsed().as_secs_f64();
            let mut cache_operator_clone = cache_operator.clone();
            let task: JoinHandle<anyhow::Result<()>> = tokio::spawn({
                let first_transaction = data
                    .transactions
                    .first()
                    .context("There were unexpectedly no transactions in the response")?;
                let first_transaction_version = first_transaction.version;
                let last_transaction = data
                    .transactions
                    .last()
                    .context("There were unexpectedly no transactions in the response")?;
                let last_transaction_version = last_transaction.version;
                let start_version = first_transaction.version;
                let first_transaction_pb_timestamp = first_transaction.timestamp;
                let last_transaction_pb_timestamp = last_transaction.timestamp;

                log_grpc_step(
                    SERVICE_TYPE,
                    IndexerGrpcStep::CacheWorkerReceivedTxns,
                    Some(start_version as i64),
                    Some(last_transaction_version as i64),
                    first_transaction_pb_timestamp.as_ref(),
                    last_transaction_pb_timestamp.as_ref(),
                    Some(data_download_duration_in_secs),
                    Some(size_in_bytes),
                    Some((last_transaction_version + 1 - first_transaction_version) as i64),
                    None,
                );

                let cache_update_start_time = std::time::Instant::now();

                async move {
                    // Push to cache.
                    match cache_operator_clone
                        .update_cache_transactions(data.transactions)
                        .await
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L930-950)
```rust
    let stripped_transactions: Vec<Transaction> = transactions
        .into_iter()
        .map(|mut txn| {
            // Note: `is_allowed` means the txn matches the filter, in which case
            // we strip it.
            if txns_to_strip_filter.matches(&txn) {
                stripped_count += 1;
                if let Some(info) = txn.info.as_mut() {
                    info.changes = vec![];
                }
                if let Some(TxnData::User(user_transaction)) = txn.txn_data.as_mut() {
                    user_transaction.events = vec![];
                    if let Some(utr) = user_transaction.request.as_mut() {
                        // Wipe the payload and signature.
                        utr.payload = None;
                        utr.signature = None;
                    }
                }
            }
            txn
        })
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L174-182)
```rust
                // Apply filter if present.
                let pb_txns = if let Some(ref filter) = filter {
                    pb_txns
                        .into_iter()
                        .filter(|txn| filter.matches(txn))
                        .collect::<Vec<_>>()
                } else {
                    pb_txns
                };
```
