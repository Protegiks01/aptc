# Audit Report

## Title
Round Number Type Truncation in Batch Encryption Digest Operations

## Summary
The batch encryption scheme uses `u64` for consensus round numbers but casts them to `usize` in digest operations. On 32-bit systems, this causes silent truncation when round numbers exceed `u32::MAX` (4,294,967,295), leading to consensus divergence between validators on different architectures.

## Finding Description

The vulnerability exists in the digest computation flow for encrypted transaction decryption: [1](#0-0) [2](#0-1) 

The consensus layer uses `Round = u64` for block round numbers, which are passed to the batch encryption digest function: [3](#0-2) 

Inside the digest computation, the u64 round is explicitly cast to usize: [4](#0-3) 

This truncated round value is then:
1. Used to index into `tau_powers_g1[round]` array (selecting cryptographic parameters)
2. Stored in the `Digest` struct as `usize`
3. Serialized and transmitted over the network [5](#0-4) 

The Digest is embedded in network messages via SecretShareMetadata: [6](#0-5) 

**Attack Scenario:**
If the network reaches round 4,294,967,296 (u32::MAX + 1) and a validator runs on a 32-bit system:
- 64-bit validators: round = 4,294,967,296 → indexes `tau_powers_g1[4294967296]`
- 32-bit validators: round = 4,294,967,296 → truncates to 0 → indexes `tau_powers_g1[0]`

The validators compute different digests using different cryptographic randomness, breaking consensus determinism. When validators exchange decryption key shares, verification fails because shares are derived from incompatible digests.

## Impact Explanation

This breaks the **Deterministic Execution** invariant - validators must produce identical state for identical blocks. When digests diverge:
- Secret share verification fails across validators
- Encrypted transactions cannot be decrypted
- Block execution stalls, requiring manual intervention

However, this qualifies as **Medium severity** rather than Critical because:
1. **Limited Scope**: Only affects encrypted transaction processing, not the core consensus protocol
2. **Requires Intervention**: Would cause a network halt requiring coordinator intervention, but doesn't allow theft or permanent damage
3. **State Inconsistency**: Falls under "State inconsistencies requiring intervention" per Medium severity criteria

The vulnerability also creates a **cross-platform serialization incompatibility** - `usize` serializes as 32 or 64 bits depending on architecture, violating protocol portability requirements.

## Likelihood Explanation

**Current Likelihood: Very Low**

Aptos validators only support 64-bit architectures: [7](#0-6) 

To trigger this vulnerability requires BOTH:
1. A 32-bit validator joining the network (currently architecturally impossible)
2. Round numbers exceeding 4.3 billion

At Aptos's target throughput (multiple rounds per second during failures), this could theoretically occur after years of operation, but remains a latent risk rather than immediate threat.

**Future Likelihood: Low but Non-Zero**
- Network could run for extended periods (years)
- Architecture requirements could change
- Testing/development environments might use different architectures

## Recommendation

Change the `Digest` struct to store round as `u64` instead of `usize`:

```rust
#[derive(Clone, Serialize, Deserialize, Debug, Default, PartialEq, Eq, Hash)]
pub struct Digest {
    #[serde(serialize_with = "ark_se", deserialize_with = "ark_de")]
    digest_g1: G1Affine,
    round: u64,  // Changed from usize
}
```

Update the digest function to avoid the cast:

```rust
pub fn digest(
    &self,
    ids: &mut IdSet<UncomputedCoeffs>,
    round: u64,
) -> Result<(Digest, EvalProofsPromise)> {
    let round_index: usize = round.try_into()
        .map_err(|_| anyhow!("Round number too large for array indexing"))?;
    
    if round_index >= self.tau_powers_g1.len() {
        return Err(anyhow!("Round exceeds setup capacity"));
    }
    // ... rest of function using round_index for array access
    // but storing original round (u64) in Digest
}
```

Update downstream code that uses `digest.round` to handle `u64`: [8](#0-7) 

Update FKDomain methods to accept u64 and convert internally with bounds checking: [9](#0-8) 

## Proof of Concept

```rust
#[test]
fn test_round_truncation_on_32bit() {
    use aptos_batch_encryption::shared::digest::DigestKey;
    
    // Simulate 32-bit environment behavior
    let round_u64: u64 = (u32::MAX as u64) + 1; // 4,294,967,296
    let round_32bit_usize = round_u64 as u32 as usize; // Truncates to 0
    let round_64bit_usize = round_u64 as usize; // Remains 4,294,967,296
    
    assert_eq!(round_32bit_usize, 0);
    assert_eq!(round_64bit_usize, 4_294_967_296);
    
    // This demonstrates the digest would differ:
    // - 32-bit system would use tau_powers_g1[0]
    // - 64-bit system would use tau_powers_g1[4294967296]
    // Result: Different digests for same input on different architectures
}
```

**Notes**

While current Aptos validators only run on 64-bit architectures making this vulnerability unlikely to manifest in production, it represents a **protocol design flaw** that violates architecture independence principles. The use of `usize` in serialized network messages creates a latent time bomb that could surface years in the future when round numbers grow large or if architecture requirements change. The fix is straightforward and should be implemented as a hardening measure even though immediate exploitation risk is negligible.

### Citations

**File:** consensus/consensus-types/src/common.rs (L33-33)
```rust
pub type Round = u64;
```

**File:** crates/aptos-batch-encryption/src/schemes/fptx_succinct.rs (L41-41)
```rust
    type Round = u64;
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L91-93)
```rust
        let encryption_round = block.round();
        let (digest, proofs_promise) =
            FPTXWeighted::digest(&digest_key, &txn_ciphertexts, encryption_round)?;
```

**File:** crates/aptos-batch-encryption/src/shared/digest.rs (L37-42)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, Default, PartialEq, Eq, Hash)]
pub struct Digest {
    #[serde(serialize_with = "ark_se", deserialize_with = "ark_de")]
    digest_g1: G1Affine,
    round: usize,
}
```

**File:** crates/aptos-batch-encryption/src/shared/digest.rs (L106-136)
```rust
    pub fn digest(
        &self,
        ids: &mut IdSet<UncomputedCoeffs>,
        round: u64,
    ) -> Result<(Digest, EvalProofsPromise)> {
        let round: usize = round as usize;
        if round >= self.tau_powers_g1.len() {
            Err(anyhow!(
                "Tried to compute digest with round greater than setup length."
            ))
        } else if ids.capacity() > self.tau_powers_g1[round].len() - 1 {
            Err(anyhow!(
                "Tried to compute a batch digest with size {}, where setup supports up to size {}",
                ids.capacity(),
                self.tau_powers_g1[round].len() - 1
            ))?
        } else {
            let ids = ids.compute_poly_coeffs();
            let mut coeffs = ids.poly_coeffs();
            coeffs.resize(self.tau_powers_g1[round].len(), Fr::zero());

            let digest = Digest {
                digest_g1: G1Projective::msm(&self.tau_powers_g1[round], &coeffs)
                    .unwrap()
                    .into(),
                round,
            };

            Ok((digest.clone(), EvalProofsPromise::new(digest, ids)))
        }
    }
```

**File:** types/src/secret_sharing.rs (L32-39)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, Default, PartialEq, Eq, Hash)]
pub struct SecretShareMetadata {
    pub epoch: u64,
    pub round: Round,
    pub timestamp: u64,
    pub block_id: HashValue,
    pub digest: Digest,
}
```

**File:** crates/aptos/src/update/update_helper.rs (L13-26)
```rust
#[cfg(target_arch = "x86_64")]
pub fn get_arch() -> &'static str {
    "x86_64"
}

#[cfg(target_arch = "aarch64")]
pub fn get_arch() -> &'static str {
    "aarch64"
}

#[cfg(not(any(target_arch = "x86_64", target_arch = "aarch64")))]
pub fn get_arch() -> &'static str {
    unimplemented!("Self-updating is not supported on your CPU architecture right now, please download the binary manually")
}
```

**File:** crates/aptos-batch-encryption/src/shared/ids/mod.rs (L124-146)
```rust
    pub fn compute_all_eval_proofs_with_setup(
        &self,
        setup: &crate::shared::digest::DigestKey,
        round: usize,
    ) -> HashMap<Id, G1Affine> {
        let pfs: Vec<G1Affine> = setup
            .fk_domain
            .eval_proofs_at_x_coords_naive_multi_point_eval(
                &self.poly_coeffs(),
                &self.poly_roots,
                round,
            )
            .iter()
            .map(|g| G1Affine::from(*g))
            .collect();

        HashMap::from_iter(
            self.as_vec()
                .into_iter()
                .zip(pfs)
                .collect::<Vec<(Id, G1Affine)>>(),
        )
    }
```

**File:** crates/aptos-batch-encryption/src/shared/algebra/fk_algorithm.rs (L336-352)
```rust
    fn compute_h_term_commitments(&self, f: &[F], round: usize) -> Vec<T> {
        let mut f = Vec::from(f);
        f.extend(std::iter::repeat_n(
            F::zero(),
            self.toeplitz_domain.dimension() + 1 - f.len(),
        ));
        // f.len() = (degree of f) + 1. Degree of f should be equal to the toeplitz domain
        // dimension.
        debug_assert_eq!(self.toeplitz_domain.dimension(), f.len() - 1);

        self.toeplitz_domain.eval_prepared(
            &self.toeplitz_for_poly(&f),
            // The Toeplitz matrix is only evaluated on the powers up to max_poly_degree - 1,
            // since the H_j(X) polynomials have degree at most that
            &self.prepared_toeplitz_inputs[round],
        )
    }
```
