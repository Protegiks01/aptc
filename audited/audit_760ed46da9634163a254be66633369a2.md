# Audit Report

## Title
Race Condition in State Merkle Pruner Progress Metadata Allows Inconsistent State Where Pruned Nodes Are Marked as Available

## Summary
A critical race condition exists between the background pruner worker and state snapshot finalization that can cause the pruner progress metadata to be inconsistent with actual deleted Merkle tree nodes. This allows the system to claim data is available when it has already been pruned, violating state consistency guarantees.

## Finding Description

The vulnerability stems from two independent code paths that write to the same database metadata key (`StateMerklePrunerProgress`) without synchronization:

**Path 1: Background Pruner Worker** (runs continuously in separate thread) [1](#0-0) 

The pruner creates an atomic batch that includes both node deletions AND progress metadata updates, then writes this batch to the database.

**Path 2: State Snapshot Finalization** (called during state sync/restore) [2](#0-1) 

This calls `save_min_readable_version()` which performs a **separate, independent write** to the same progress metadata key: [3](#0-2) 

Which directly writes to the database: [4](#0-3) 

**The Race Condition:**

1. **T1**: Pruner worker executes `maybe_prune_single_version(1000, 1500)`
   - Creates batch with deletions for stale nodes at versions 1001-1500
   - Adds to batch: `PUT StateMerklePrunerProgress = 1500`
   - Writes batch atomically → **Nodes for versions < 1500 are now DELETED**

2. **T2**: State snapshot finalization executes `finalize_state_snapshot(version=1200)`
   - Calls `save_min_readable_version(1200)`
   - Writes: `PUT StateMerklePrunerProgress = 1200` (separate write, not in any batch)
   - **This overwrites the progress from 1500 back to 1200**

3. **Result**: Database state is now inconsistent:
   - Progress metadata = 1200 (claims versions ≥1200 are available)
   - Actual Merkle nodes for versions 1200-1499 are **DELETED**

4. **Exploitation**: When attempting to read state at version 1300: [5](#0-4) 
   
   The check passes (1300 ≥ 1200), but reading the nodes fails because they were already pruned.

There is **no locking mechanism** to prevent this race: [6](#0-5) 

The `finalize_state_snapshot` method does not acquire `commit_lock` or `pre_commit_lock`, and the pruner worker runs independently without coordination.

## Impact Explanation

This vulnerability meets **Critical Severity** criteria:

1. **State Consistency Violation**: Breaks Invariant #4 - the fundamental guarantee that state data is consistent and verifiable. The system claims data exists when it doesn't.

2. **Failed State Operations**: Any attempt to:
   - Generate state proofs for "available" versions
   - Read state at those versions
   - Perform state sync from those versions
   
   Will fail with node-not-found errors, causing operational failures.

3. **Potential Consensus Divergence**: Different nodes may have different views of what data is available:
   - Node A: Experiences the race, thinks version 1200+ is available but nodes are deleted
   - Node B: No race, has correct progress metadata
   - This can lead to divergent behavior during state sync or proof verification

4. **Non-Recoverable Without Intervention**: Once the inconsistency is created, it persists until either:
   - Manual database repair
   - Complete re-sync from genesis or snapshot
   - The pruner happens to prune past that point again (may not happen if already "past" it)

## Likelihood Explanation

**Likelihood: Medium to High**

This race condition will occur whenever:
- State snapshot restoration (via `finalize_state_snapshot`) happens concurrently with active pruning
- Common scenarios include:
  - Node performing state sync while pruner is running
  - Backup restoration on a running node
  - Fast sync bootstrap operations

The pruner runs continuously in the background on all validator and fullnodes. State snapshot operations occur during:
- Initial node bootstrap
- Catching up after downtime
- State sync between epochs
- Backup restoration procedures

The window for the race is narrow (milliseconds) but given the frequency of these operations across the network, it's likely to occur naturally without malicious intent.

## Recommendation

Add synchronization to ensure `save_min_readable_version()` only updates progress if the new version is greater than the current persisted value. Implement atomic compare-and-set semantics:

```rust
fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
    // Read current progress from DB
    let current_progress = get_progress(
        self.state_merkle_db.metadata_db(),
        &S::progress_metadata_key(None),
    )?
    .unwrap_or(0);
    
    // Only write if new version is greater (never regress)
    if min_readable_version <= current_progress {
        // Already at or past this version, just update in-memory state
        self.min_readable_version.store(
            current_progress, 
            Ordering::SeqCst
        );
        return Ok(());
    }
    
    self.min_readable_version
        .store(min_readable_version, Ordering::SeqCst);

    PRUNER_VERSIONS
        .with_label_values(&[S::name(), "min_readable"])
        .set(min_readable_version as i64);

    self.state_merkle_db
        .write_pruner_progress(&S::progress_metadata_key(None), min_readable_version)
}
```

**Alternative Solution**: Include progress metadata updates in a lock-protected section or use proper database transactions with conflict detection.

## Proof of Concept

```rust
// Rust test demonstrating the race condition
#[test]
fn test_pruner_progress_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    // Setup: Initialize AptosDB with pruner enabled
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    
    // Commit state up to version 2000
    for v in 0..2000 {
        // Commit transactions to build state
    }
    
    // Set initial pruner progress to 1000
    db.state_store.state_merkle_pruner.save_min_readable_version(1000).unwrap();
    
    // Barrier to synchronize threads for maximum race likelihood
    let barrier = Arc::new(Barrier::new(2));
    let barrier1 = Arc::clone(&barrier);
    let barrier2 = Arc::clone(&barrier);
    
    let db1 = Arc::clone(&db);
    let db2 = Arc::clone(&db);
    
    // Thread 1: Pruner worker prunes to version 1500
    let handle1 = thread::spawn(move || {
        barrier1.wait();
        // Simulate pruner operation that deletes nodes and sets progress=1500
        db1.state_store.state_merkle_pruner.prune_impl(1500).unwrap();
    });
    
    // Thread 2: Finalize state snapshot at version 1200
    let handle2 = thread::spawn(move || {
        barrier2.wait();
        // This writes progress=1200, potentially after pruner deleted nodes
        db2.state_store.state_merkle_pruner
            .save_min_readable_version(1200).unwrap();
    });
    
    handle1.join().unwrap();
    handle2.join().unwrap();
    
    // Verify inconsistency
    let progress = db.state_store.state_merkle_pruner.get_min_readable_version();
    
    // If progress < 1500, race occurred and nodes are inconsistent
    if progress < 1500 {
        // Try to read state at version 1300
        // Should pass min_readable check but fail to find nodes
        let result = db.get_state_proof_by_version(
            &test_key_hash, 
            1300
        );
        
        // This should fail with node-not-found if race occurred
        assert!(result.is_err(), "Race condition: data marked available but pruned");
    }
}
```

The test demonstrates that after the race condition, attempting to read state at an "available" version (according to progress metadata) fails because the actual nodes were deleted.

### Citations

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_metadata_pruner.rs (L60-71)
```rust
        let mut batch = SchemaBatch::new();
        indices.into_iter().try_for_each(|index| {
            batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
            batch.delete::<S>(&index)
        })?;

        batch.put::<DbMetadataSchema>(
            &S::progress_metadata_key(None),
            &DbMetadataValue::Version(target_version_for_this_round),
        )?;

        self.metadata_db.write_schemas(batch)?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-135)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L225-234)
```rust
            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_pruner_manager.rs (L74-84)
```rust
    fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&[S::name(), "min_readable"])
            .set(min_readable_version as i64);

        self.state_merkle_db
            .write_pruner_progress(&S::progress_metadata_key(None), min_readable_version)
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L568-575)
```rust
    pub(crate) fn write_pruner_progress(
        &self,
        progress_key: &DbMetadataKey,
        version: Version,
    ) -> Result<()> {
        self.state_merkle_metadata_db
            .put::<DbMetadataSchema>(progress_key, &DbMetadataValue::Version(version))
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L273-303)
```rust
    pub(super) fn error_if_state_merkle_pruned(
        &self,
        data_type: &str,
        version: Version,
    ) -> Result<()> {
        let min_readable_version = self
            .state_store
            .state_db
            .state_merkle_pruner
            .get_min_readable_version();
        if version >= min_readable_version {
            return Ok(());
        }

        let min_readable_epoch_snapshot_version = self
            .state_store
            .state_db
            .epoch_snapshot_pruner
            .get_min_readable_version();
        if version >= min_readable_epoch_snapshot_version {
            self.ledger_db.metadata_db().ensure_epoch_ending(version)
        } else {
            bail!(
                "{} at version {} is pruned. snapshots are available at >= {}, epoch snapshots are available at >= {}",
                data_type,
                version,
                min_readable_version,
                min_readable_epoch_snapshot_version,
            )
        }
    }
```
