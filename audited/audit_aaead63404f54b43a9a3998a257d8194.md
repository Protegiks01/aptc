# Audit Report

## Title
Unbounded Disk Writes via `/malloc/dump_profile` Endpoint Leading to Storage Exhaustion

## Summary
The `/malloc/dump_profile` admin service endpoint does not respect the configured `malloc_stats_max_len` limit and writes unbounded heap profile data directly to disk without any size constraints, cleanup mechanisms, or disk space validation. Repeated invocations create accumulating files in `/tmp/` that can exhaust available disk space, causing validator node failure.

## Finding Description

The admin service configuration defines a `malloc_stats_max_len` parameter intended to limit memory statistics output. [1](#0-0) 

However, while the `/malloc/stats` endpoint correctly respects this limit by passing it as a parameter [2](#0-1) , the `/malloc/dump_profile` endpoint completely ignores it. [3](#0-2) 

The `handle_dump_profile_request()` function accepts no parameters and calls `dump_heap_profile()` directly. [4](#0-3) 

The `dump_heap_profile()` function uses jemalloc's `prof.dump` control to write heap profiling data to timestamped files in `/tmp/`. [5](#0-4)  Each invocation creates a new file with no size limits, no disk space validation, and no cleanup of previous dumps.

**Attack Path:**
1. Attacker obtains authentication credentials (or exploits configurations where authentication is disabled on non-mainnet networks) [6](#0-5) 
2. Attacker repeatedly calls `GET /malloc/dump_profile`
3. Each call creates a new timestamped file: `/tmp/heap-profile.{timestamp}`
4. File sizes are proportional to application memory usage (potentially hundreds of MB to GB for validator nodes with jemalloc profiling enabled) [7](#0-6) 
5. No rate limiting exists on admin service endpoints to prevent rapid requests
6. No cleanup mechanism removes old heap profile files
7. Files accumulate until disk partition is exhausted
8. Node becomes unable to write logs, database commits, or perform other disk operations
9. Node becomes unavailable, requiring manual intervention

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos Bug Bounty criteria:
- **"State inconsistencies requiring intervention"**: Disk exhaustion prevents proper node operation, requiring manual cleanup and service restoration
- **"Validator node slowdowns"**: As disk space depletes, performance degrades before complete failure

While this does not directly compromise consensus safety or cause fund loss (Critical severity), it can render validator nodes unavailable, impacting network liveness and requiring operator intervention. The issue is exacerbated because:
- Multiple validator operators could independently trigger this issue
- The configuration parameter `malloc_stats_max_len` creates a false expectation that limits are enforced
- No automatic cleanup or rotation prevents indefinite accumulation

## Likelihood Explanation

**Likelihood: Medium to High**

**Factors increasing likelihood:**
1. **Authentication may be disabled**: On non-mainnet networks, authentication is not required [8](#0-7) 
2. **Legitimate operator usage**: Even authorized operators using this endpoint for debugging can accidentally exhaust disk space through repeated profiling sessions
3. **No rate limiting**: No protection exists against rapid repeated requests
4. **Large file sizes**: With jemalloc profiling enabled by default, heap dumps from memory-intensive validator nodes can be very large
5. **No cleanup**: Files persist indefinitely until manual removal

**Factors decreasing likelihood:**
1. **Mainnet requires authentication**: The configuration sanitizer enforces authentication on mainnet [6](#0-5) 
2. **Admin service disabled by default on mainnet**: The optimizer disables the admin service on mainnet unless explicitly enabled [8](#0-7) 

However, even with authentication, the lack of any size limits or cleanup remains a security risk for accidental or malicious exhaustion.

## Recommendation

**Immediate fixes:**

1. **Enforce `malloc_stats_max_len` limit**: Modify `handle_dump_profile_request()` to accept and respect the configured size limit, either by:
   - Checking available disk space before writing
   - Limiting the heap profile data size
   - Rejecting requests if disk space is below a threshold

2. **Implement file rotation**: Add automatic cleanup of old heap profile files, keeping only N most recent dumps

3. **Add rate limiting**: Implement request throttling on the admin service to prevent rapid repeated calls

4. **Pre-flight disk space check**: Before writing heap dumps, verify sufficient disk space is available

**Recommended code changes:**

```rust
// In malloc.rs
pub fn handle_dump_profile_request(max_files: usize, min_disk_space_mb: u64) -> hyper::Result<Response<Body>> {
    // Check disk space before dumping
    if let Ok(available_space) = check_available_disk_space("/tmp") {
        if available_space < min_disk_space_mb * 1024 * 1024 {
            return Ok(reply_with_status(
                StatusCode::INSUFFICIENT_STORAGE,
                format!("Insufficient disk space: {} MB available", available_space / (1024 * 1024)),
            ));
        }
    }
    
    // Clean up old files, keeping only max_files most recent
    cleanup_old_heap_profiles(max_files)?;
    
    match dump_heap_profile() {
        Ok(path) => Ok(reply_with(
            Vec::new(),
            Body::from(format!("Successfully dumped heap profile to {path}")),
        )),
        Err(e) => Ok(reply_with_status(
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("Failed to dump heap profile: {e}"),
        )),
    }
}
```

Add configuration parameters:
```rust
// In admin_service_config.rs
pub struct AdminServiceConfig {
    // ... existing fields ...
    pub malloc_stats_max_len: usize,
    pub heap_profile_max_files: usize,  // New: max number of heap profiles to keep
    pub heap_profile_min_disk_space_mb: u64,  // New: minimum disk space required
}
```

## Proof of Concept

```bash
#!/bin/bash
# PoC: Disk Exhaustion via Repeated Heap Profile Dumps

ADMIN_SERVICE_URL="http://localhost:9102"
PASSCODE="your_passcode_here"  # If authentication is enabled

echo "Starting disk exhaustion attack simulation..."
echo "Initial /tmp disk usage:"
df -h /tmp

# Make 100 requests to dump heap profiles
for i in {1..100}; do
    echo "Request $i: Dumping heap profile..."
    curl -s "$ADMIN_SERVICE_URL/malloc/dump_profile?passcode=$PASSCODE"
    sleep 0.1  # Small delay to allow file write
done

echo "Final /tmp disk usage:"
df -h /tmp

echo "Heap profile files created:"
ls -lh /tmp/heap-profile.* | tail -10

echo "Total size of heap profiles:"
du -sh /tmp/heap-profile.* | awk '{sum+=$1} END {print sum}'
```

**Rust Integration Test:**
```rust
#[tokio::test]
async fn test_dump_profile_disk_exhaustion() {
    // Setup admin service with authentication disabled for test
    let config = AdminServiceConfig {
        enabled: Some(true),
        authentication_configs: vec![],
        ..Default::default()
    };
    
    let admin_service = AdminService::new_with_config(config);
    
    // Make repeated requests to dump profile
    for i in 0..50 {
        let response = admin_service
            .handle_request("/malloc/dump_profile")
            .await
            .unwrap();
        assert_eq!(response.status(), StatusCode::OK);
    }
    
    // Check that multiple files were created in /tmp/
    let profile_files: Vec<_> = std::fs::read_dir("/tmp")
        .unwrap()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_name().to_string_lossy().starts_with("heap-profile."))
        .collect();
    
    // Verify files accumulate without cleanup
    assert!(profile_files.len() >= 50, "Expected at least 50 heap profile files");
    
    // Calculate total size
    let total_size: u64 = profile_files
        .iter()
        .map(|f| f.metadata().unwrap().len())
        .sum();
    
    println!("Total heap profile disk usage: {} MB", total_size / (1024 * 1024));
}
```

## Notes

This vulnerability is particularly concerning because:

1. **Configuration creates false security expectations**: The presence of `malloc_stats_max_len` in the configuration suggests that size limits are enforced, but they are only applied to the `/malloc/stats` endpoint, not `/malloc/dump_profile`.

2. **No cleanup mechanism**: Unlike other temporary file systems in the codebase, there is no rotation or cleanup for heap profile dumps, allowing indefinite accumulation.

3. **Legitimate use can trigger the issue**: Even non-malicious operators performing debugging could accidentally exhaust disk space through repeated profiling sessions during incident response.

4. **Silent failure mode**: Disk exhaustion manifests as gradual node degradation rather than immediate failure, making the root cause harder to diagnose.

The fix should align the `/malloc/dump_profile` endpoint behavior with the security expectations set by the configuration parameter and implement proper resource management for temporary debugging files.

### Citations

**File:** config/src/config/admin_service_config.rs (L23-23)
```rust
    pub malloc_stats_max_len: usize,
```

**File:** config/src/config/admin_service_config.rs (L67-77)
```rust
        if node_config.admin_service.enabled == Some(true) {
            if let Some(chain_id) = chain_id {
                if chain_id.is_mainnet()
                    && node_config.admin_service.authentication_configs.is_empty()
                {
                    return Err(Error::ConfigSanitizerFailed(
                        sanitizer_name,
                        "Must enable authentication for AdminService on mainnet.".into(),
                    ));
                }
            }
```

**File:** config/src/config/admin_service_config.rs (L94-100)
```rust
            // Only enable the admin service if the chain is not mainnet
            let admin_service_enabled = if let Some(chain_id) = chain_id {
                !chain_id.is_mainnet()
            } else {
                false // We cannot determine the chain ID, so we disable the admin service
            };
            node_config.admin_service.enabled = Some(admin_service_enabled);
```

**File:** crates/aptos-admin-service/src/server/mod.rs (L189-191)
```rust
            (hyper::Method::GET, "/malloc/stats") => {
                malloc::handle_malloc_stats_request(context.config.malloc_stats_max_len)
            },
```

**File:** crates/aptos-admin-service/src/server/mod.rs (L193-193)
```rust
            (hyper::Method::GET, "/malloc/dump_profile") => malloc::handle_dump_profile_request(),
```

**File:** crates/aptos-admin-service/src/server/malloc.rs (L46-63)
```rust
fn dump_heap_profile() -> anyhow::Result<String> {
    let _ = jemalloc_ctl::epoch::advance();

    let key = b"prof.dump\0";
    let path = format!(
        "{}.{}",
        PROFILE_PATH_PREFIX,
        SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)?
            .as_millis()
    );
    let value = CString::new(path.clone())?;
    unsafe {
        jemalloc_ctl::raw::write(key, value.as_ptr())
            .map_err(|e| anyhow::anyhow!("prof.dump error: {e}"))?;
    }
    Ok(path)
}
```

**File:** crates/aptos-admin-service/src/server/malloc.rs (L65-76)
```rust
pub fn handle_dump_profile_request() -> hyper::Result<Response<Body>> {
    match dump_heap_profile() {
        Ok(path) => Ok(reply_with(
            Vec::new(),
            Body::from(format!("Successfully dumped heap profile to {path}")),
        )),
        Err(e) => Ok(reply_with_status(
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("Failed to dump heap profile: {e}"),
        )),
    }
}
```

**File:** aptos-node/src/main.rs (L19-19)
```rust
pub static mut malloc_conf: *const c_char = c"prof:true,lg_prof_sample:23".as_ptr().cast();
```
