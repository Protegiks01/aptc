# Audit Report

## Title
Timestamp Parsing Panic Causing Cascading Indexer-GRPC Service Failures

## Summary
The `parse_timestamp` function in the indexer-grpc-utils library contains an unwrap that panics when processing invalid timestamp values from deserialized protobuf data. Since protobuf deserialization doesn't validate timestamp field constraints, corrupted data from cache or file storage can trigger thread crashes that cascade through downstream indexer components, causing persistent service disruption.

## Finding Description

The indexer-grpc system lacks defensive validation when processing timestamp data, creating a cascading failure vulnerability through the following chain:

**Vulnerable Function:** [1](#0-0) 

This function panics if `chrono::NaiveDateTime::from_timestamp_opt` returns `None`, which occurs when:
- The `seconds` value is outside the valid range for `NaiveDateTime`
- The `nanos` value is >= 1,000,000,000 or negative

**Protobuf Deserialization Lacks Validation:** [2](#0-1) 

The protobuf specification defines constraints (seconds from year 0001-9999, nanos 0-999,999,999), but protobuf deserialization doesn't enforce these - it accepts any i64/i32 values.

**Cache Deserialization Path:** [3](#0-2) 

The `Transaction::decode()` call deserializes protobuf data without validating timestamp constraints.

**Panic Trigger Point:** [4](#0-3) 

After deserializing cached transactions, timestamps are extracted and passed to `log_grpc_step`, which calls `timestamp_to_iso`: [5](#0-4) 

**Additional Panic Points:** [6](#0-5) [7](#0-6) 

**Exploitation Scenario:**
1. Data corruption occurs in Redis cache or GCS file store (bit flips, storage errors, partial writes, concurrent access bugs)
2. Corrupted protobuf bytes contain invalid timestamp values (e.g., `nanos = 2,000,000,000`)
3. `CacheEntry::into_transaction()` successfully deserializes the corrupted data
4. Data service calls `log_grpc_step` with the invalid timestamp
5. `timestamp_to_iso` â†’ `parse_timestamp` panics, crashing the service thread
6. Downstream indexer processors waiting for this data receive errors
7. Retry attempts hit the same corrupted data, causing repeated failures
8. The persistent corrupted data blocks all indexers at that version range

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria - "State inconsistencies requiring intervention"

**Impact Details:**
- **Service Availability**: Indexer-grpc data service threads crash when encountering corrupted timestamps
- **Cascading Failures**: All downstream indexer processors dependent on this data range cannot proceed
- **Persistent Disruption**: Corrupted data in cache/storage causes repeated failures until manually resolved
- **Multi-Component Failure**: Affects data service, cache workers, file store operators, and all connected indexer processors
- **No Automatic Recovery**: Requires manual intervention to identify and remediate corrupted data

**Does Not Qualify as Critical/High:**
- Does not affect consensus, validator nodes, or blockchain state
- Does not cause fund loss or theft
- Does not compromise validator security
- Indexer-grpc is an off-chain indexing service, not core consensus infrastructure

## Likelihood Explanation

**Moderate-to-Low Likelihood:**

**Realistic Triggers:**
- Storage system bit flips or corruption in Redis/GCS
- Network interruptions during cache writes causing partial data
- Race conditions in concurrent cache updates
- Bugs in protobuf serialization/compression libraries
- File system errors in local storage mode

**Mitigating Factors:**
- Redis and GCS are highly reliable systems with error detection
- Corruption would need to affect specific timestamp bytes
- Most data corruption is detected by checksums at lower layers

**Aggravating Factors:**
- No validation layer between deserialization and usage
- Panic propagates rather than being caught and handled
- Single corrupted transaction blocks entire version range

## Recommendation

**Implement Defensive Validation:**

Replace panic-prone functions with graceful error handling:

```rust
pub fn parse_timestamp(ts: &Timestamp, version: i64) -> Result<chrono::NaiveDateTime, String> {
    // Validate nanos is in valid range
    if ts.nanos < 0 || ts.nanos >= 1_000_000_000 {
        return Err(format!(
            "Invalid nanos value {} for timestamp at version {}. Must be 0-999,999,999",
            ts.nanos, version
        ));
    }
    
    #[allow(deprecated)]
    chrono::NaiveDateTime::from_timestamp_opt(ts.seconds, ts.nanos as u32)
        .ok_or_else(|| {
            format!(
                "Could not parse timestamp (seconds={}, nanos={}) for version {}. Seconds out of valid range",
                ts.seconds, ts.nanos, version
            )
        })
}

pub fn timestamp_to_iso(timestamp: &Timestamp) -> Result<String, String> {
    let dt = parse_timestamp(timestamp, 0)?;
    Ok(dt.format("%Y-%m-%dT%H:%M:%S%.9fZ").to_string())
}
```

**Add Validation at Deserialization:**

```rust
impl Transaction {
    pub fn validate_timestamp(&self) -> Result<(), String> {
        if let Some(ts) = &self.timestamp {
            if ts.nanos < 0 || ts.nanos >= 1_000_000_000 {
                return Err(format!("Invalid nanos: {}", ts.nanos));
            }
            // Validate seconds is within chrono's valid range
            parse_timestamp(ts, self.version as i64)?;
        }
        Ok(())
    }
}
```

**Handle Errors in Logging:**

Modify `log_grpc_step` to handle timestamp conversion errors gracefully:

```rust
let start_txn_timestamp_iso = start_version_timestamp
    .and_then(|ts| timestamp_to_iso(ts).ok())
    .unwrap_or_else(|| "INVALID_TIMESTAMP".to_string());
```

## Proof of Concept

**Rust Test to Demonstrate Panic:**

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_protos::util::timestamp::Timestamp;

    #[test]
    #[should_panic(expected = "Could not parse timestamp")]
    fn test_parse_timestamp_invalid_nanos_panics() {
        let invalid_ts = Timestamp {
            seconds: 1700000000,
            nanos: 2_000_000_000, // Invalid: >= 1 billion
        };
        parse_timestamp(&invalid_ts, 12345);
    }

    #[test]
    #[should_panic(expected = "Could not parse timestamp")]
    fn test_parse_timestamp_invalid_seconds_panics() {
        let invalid_ts = Timestamp {
            seconds: -62135596801, // Before valid range
            nanos: 0,
        };
        parse_timestamp(&invalid_ts, 12345);
    }

    #[test]
    fn test_timestamp_to_iso_with_invalid_data_panics() {
        let invalid_ts = Timestamp {
            seconds: 1700000000,
            nanos: 1_500_000_000, // Invalid
        };
        // This will panic in timestamp_to_iso -> parse_timestamp
        let _ = timestamp_to_iso(&invalid_ts);
    }
}
```

**Reproduction Steps:**
1. Inject corrupted protobuf data into Redis cache with invalid timestamp
2. Configure indexer-grpc data service to read from cache
3. Request transactions containing the corrupted timestamp
4. Observe thread panic and service failure
5. Verify downstream processors cannot proceed
6. Confirm repeated requests fail consistently

## Notes

This vulnerability demonstrates a lack of defensive programming when handling external data from potentially unreliable storage systems. While direct attacker exploitation is difficult (requires compromising Redis/GCS), the failure mode from legitimate data corruption is severe and persistent. The recommendation implements defense-in-depth by validating timestamps at multiple layers and gracefully degrading rather than crashing when encountering invalid data.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L107-113)
```rust
pub fn system_time_to_proto(system_time: SystemTime) -> Timestamp {
    let ts = system_time.duration_since(UNIX_EPOCH).unwrap();
    Timestamp {
        seconds: ts.as_secs() as i64,
        nanos: ts.subsec_nanos() as i32,
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L115-122)
```rust
pub fn time_diff_since_pb_timestamp_in_secs(timestamp: &Timestamp) -> f64 {
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("SystemTime before UNIX EPOCH!")
        .as_secs_f64();
    let transaction_time = timestamp.seconds as f64 + timestamp.nanos as f64 * 1e-9;
    current_timestamp - transaction_time
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L125-128)
```rust
pub fn timestamp_to_iso(timestamp: &Timestamp) -> String {
    let dt = parse_timestamp(timestamp, 0);
    dt.format("%Y-%m-%dT%H:%M:%S%.9fZ").to_string()
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L135-139)
```rust
pub fn parse_timestamp(ts: &Timestamp, version: i64) -> chrono::NaiveDateTime {
    #[allow(deprecated)]
    chrono::NaiveDateTime::from_timestamp_opt(ts.seconds, ts.nanos as u32)
        .unwrap_or_else(|| panic!("Could not parse timestamp {:?} for version {}", ts, version))
}
```

**File:** protos/proto/aptos/util/timestamp/timestamp.proto (L8-19)
```text
message Timestamp {
  // Represents seconds of UTC time since Unix epoch
  // 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to
  // 9999-12-31T23:59:59Z inclusive.
  int64 seconds = 1;

  // Non-negative fractions of a second at nanosecond resolution. Negative
  // second values with fractions must still have non-negative nanos values
  // that count forward in time. Must be from 0 to 999,999,999
  // inclusive.
  int32 nanos = 2;
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L142-157)
```rust
    pub fn into_transaction(self) -> Transaction {
        match self {
            CacheEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
            },
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L737-753)
```rust
            let transactions =
                deserialize_cached_transactions(transactions, storage_format).await?;
            let start_version_timestamp = transactions.first().unwrap().timestamp.as_ref();
            let end_version_timestamp = transactions.last().unwrap().timestamp.as_ref();

            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::DataServiceDataFetchedCache,
                Some(starting_version as i64),
                Some(starting_version as i64 + num_of_transactions as i64 - 1),
                start_version_timestamp,
                end_version_timestamp,
                Some(duration_in_secs),
                Some(size_in_bytes),
                Some(num_of_transactions as i64),
                Some(&request_metadata),
            );
```
