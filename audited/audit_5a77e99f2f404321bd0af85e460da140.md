# Audit Report

## Title
Byzantine Publishers Can Exhaust Observer Memory Through Unverified Pending Block Flooding

## Summary
Byzantine publishers can flood consensus observers with up to `max_num_pending_blocks` (150 blocks default, 300 on test networks) blocks that bypass cryptographic signature verification, causing memory exhaustion. Blocks are stored in pending state without proof validation if their payloads are missing, allowing attackers to craft structurally valid but cryptographically invalid blocks that consume observer resources indefinitely.

## Finding Description

The consensus observer processes ordered block messages through a two-stage validation approach that creates a critical vulnerability. When an observer receives an `OrderedBlock` message in `process_ordered_block_message`, it performs only lightweight structural validation before making storage decisions. [1](#0-0) 

The `verify_ordered_blocks()` method only validates block structure (non-empty, proper chaining, ID consistency), NOT cryptographic signatures: [2](#0-1) 

After this lightweight validation, blocks are immediately stored as pending if their payloads don't exist: [3](#0-2) 

The critical issue: **cryptographic signature verification via `verify_ordered_proof()` only occurs in `process_ordered_block()`**, which is only called when all payloads exist: [4](#0-3) [5](#0-4) 

A Byzantine publisher (compromised validator or VFN that the observer has subscribed to) can exploit this by:

1. Crafting blocks that pass `verify_ordered_blocks()` (trivial - just chain blocks properly)
2. Referencing payloads that will never be sent
3. Flooding the observer with up to `max_num_pending_blocks` such blocks
4. These blocks get stored without signature verification and consume memory indefinitely

The pending block store's garbage collection only removes oldest blocks when the limit is exceeded: [6](#0-5) 

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**High Severity** - This qualifies as "Validator node slowdowns" per the bug bounty criteria:

1. **Memory Exhaustion**: Each pending block (containing multiple pipelined blocks) consumes heap memory. An attacker can maintain 150-300 unverified blocks in memory continuously.

2. **Observer Performance Degradation**: Memory pressure can cause:
   - Increased garbage collection overhead
   - Reduced cache effectiveness
   - Slower block processing
   - Potential out-of-memory conditions under sustained attack

3. **Network-Wide Impact**: If multiple observers subscribe to the same Byzantine publisher, all affected observers experience degradation simultaneously, potentially impacting network liveness.

4. **No Natural Recovery**: Unlike temporary network issues, these invalid blocks remain in memory indefinitely (until garbage collected by newer invalid blocks), causing sustained resource consumption.

The configuration shows test networks have higher limits (300 blocks): [7](#0-6) [8](#0-7) 

## Likelihood Explanation

**High Likelihood** under the following realistic conditions:

1. **Attack Prerequisites**: 
   - Attacker controls a validator or VFN node (Byzantine publisher scenario)
   - Observer has subscribed to the malicious publisher
   - Both conditions are explicitly within the security question's threat model

2. **Ease of Exploitation**:
   - Crafting structurally valid blocks is computationally cheap (no signature generation needed)
   - No special timing or race conditions required
   - Attack can be sustained indefinitely
   - No detection mechanism exists since blocks appear valid structurally

3. **Observable in Production**: Validators and VFNs run consensus observers, making them targets. A compromised validator node immediately becomes an attack vector for all its subscribers.

## Recommendation

Implement early signature verification for all ordered blocks before storing them as pending:

```rust
async fn process_ordered_block_message(
    &mut self,
    peer_network_id: PeerNetworkId,
    message_received_time: Instant,
    ordered_block: OrderedBlock,
) {
    // ... existing execution pool check ...
    
    // Verify the ordered blocks structure
    if let Err(error) = ordered_block.verify_ordered_blocks() { 
        // ... existing error handling ...
    }
    
    // **NEW: Verify signatures BEFORE storage decision**
    let epoch_state = self.get_epoch_state();
    if ordered_block.proof_block_info().epoch() == epoch_state.epoch {
        if let Err(error) = ordered_block.verify_ordered_proof(&epoch_state) {
            error!(LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Failed to verify ordered proof early! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                ordered_block.proof_block_info(), peer_network_id, error
            )));
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        }
    }
    
    // ... rest of existing code (staleness checks, pending block creation) ...
}
```

This ensures:
- All blocks undergo cryptographic validation before memory allocation
- Invalid blocks from Byzantine publishers are rejected immediately
- Memory consumption is limited to legitimately ordered blocks
- No change to legitimate operation flow (verified blocks still stored as pending if payloads missing)

## Proof of Concept

```rust
// Test demonstrating unverified block storage
#[tokio::test]
async fn test_byzantine_publisher_pending_block_flood() {
    use aptos_consensus_types::{block::Block, block_data::BlockData, quorum_cert::QuorumCert};
    use aptos_types::{aggregate_signature::AggregateSignature, ledger_info::LedgerInfo};
    
    // Setup observer with max 10 pending blocks
    let config = ConsensusObserverConfig {
        max_num_pending_blocks: 10,
        ..Default::default()
    };
    
    // Create 10 structurally valid blocks with invalid signatures
    // and non-existent payload references
    for i in 0..10 {
        let block = create_block_with_fake_signature(epoch, round + i);
        let ordered_block = OrderedBlock::new(
            vec![Arc::new(block)],
            create_invalid_ledger_info_with_signatures(), // Invalid BLS signatures
        );
        
        // Send to observer - will pass verify_ordered_blocks() 
        // but fail verify_ordered_proof() if it were called
        observer.process_ordered_block_message(
            peer_id,
            Instant::now(),
            ordered_block,
        ).await;
    }
    
    // Verify all 10 blocks stored WITHOUT signature verification
    let pending_count = observer.observer_block_data.lock()
        .pending_block_store.blocks_without_payloads.len();
    assert_eq!(pending_count, 10); // All stored without proof verification
    
    // Blocks remain in memory indefinitely (payloads never arrive)
    // Memory exhaustion achieved
}
```

**Notes**

The vulnerability exists because signature verification (`verify_ordered_proof`) is deferred until payload availability, creating a window where Byzantine publishers can flood memory with unverified blocks. The fix requires moving cryptographic validation earlier in the pipeline, before any storage allocation decisions, ensuring the "Resource Limits" invariant is maintained even under Byzantine publisher scenarios.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L659-671)
```rust
        if let Err(error) = ordered_block.verify_ordered_blocks() {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify ordered blocks! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                    ordered_block.proof_block_info(),
                    peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        };
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L704-713)
```rust
        // If all payloads exist, process the block. Otherwise, store it
        // in the pending block store and wait for the payloads to arrive.
        if self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        } else {
            self.observer_block_data
                .lock()
                .insert_pending_block(pending_block_with_metadata);
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L728-743)
```rust
        let epoch_state = self.get_epoch_state();
        if ordered_block.proof_block_info().epoch() == epoch_state.epoch {
            if let Err(error) = ordered_block.verify_ordered_proof(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify ordered proof! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                        ordered_block.proof_block_info(),
                        peer_network_id,
                        error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
                return;
            }
        } else {
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L225-266)
```rust
    /// Verifies the ordered blocks and returns an error if the data is invalid.
    /// Note: this does not check the ordered proof.
    pub fn verify_ordered_blocks(&self) -> Result<(), Error> {
        // Verify that we have at least one ordered block
        if self.blocks.is_empty() {
            return Err(Error::InvalidMessageError(
                "Received empty ordered block!".to_string(),
            ));
        }

        // Verify the last block ID matches the ordered proof block ID
        if self.last_block().id() != self.proof_block_info().id() {
            return Err(Error::InvalidMessageError(
                format!(
                    "Last ordered block ID does not match the ordered proof ID! Number of blocks: {:?}, Last ordered block ID: {:?}, Ordered proof ID: {:?}",
                    self.blocks.len(),
                    self.last_block().id(),
                    self.proof_block_info().id()
                )
            ));
        }

        // Verify the blocks are correctly chained together (from the last block to the first)
        let mut expected_parent_id = None;
        for block in self.blocks.iter().rev() {
            if let Some(expected_parent_id) = expected_parent_id {
                if block.id() != expected_parent_id {
                    return Err(Error::InvalidMessageError(
                        format!(
                            "Block parent ID does not match the expected parent ID! Block ID: {:?}, Expected parent ID: {:?}",
                            block.id(),
                            expected_parent_id
                        )
                    ));
                }
            }

            expected_parent_id = Some(block.parent_id());
        }

        Ok(())
    }
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L268-277)
```rust
    /// Verifies the ordered proof and returns an error if the proof is invalid
    pub fn verify_ordered_proof(&self, epoch_state: &EpochState) -> Result<(), Error> {
        epoch_state.verify(&self.ordered_proof).map_err(|error| {
            Error::InvalidMessageError(format!(
                "Failed to verify ordered proof ledger info: {:?}, Error: {:?}",
                self.proof_block_info(),
                error
            ))
        })
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L156-195)
```rust
    /// Garbage collects the pending blocks store by removing
    /// the oldest blocks if the store is too large.
    fn garbage_collect_pending_blocks(&mut self) {
        // Verify that both stores have the same number of entries.
        // If not, log an error as this should never happen.
        let num_pending_blocks = self.blocks_without_payloads.len() as u64;
        let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
        if num_pending_blocks != num_pending_blocks_by_hash {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "The pending block stores have different numbers of entries: {} and {} (by hash)",
                    num_pending_blocks, num_pending_blocks_by_hash
                ))
            );
        }

        // Calculate the number of blocks to remove
        let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
        let num_blocks_to_remove = num_pending_blocks.saturating_sub(max_pending_blocks);

        // Remove the oldest blocks if the store is too large
        for _ in 0..num_blocks_to_remove {
            if let Some((oldest_epoch_round, pending_block)) =
                self.blocks_without_payloads.pop_first()
            {
                // Log a warning message for the removed block
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "The pending block store is too large: {:?} blocks. Removing the block for the oldest epoch and round: {:?}",
                        num_pending_blocks, oldest_epoch_round
                    ))
                );

                // Remove the block from the hash store
                let first_block = pending_block.ordered_block().first_block();
                self.blocks_without_payloads_by_hash
                    .remove(&first_block.id());
            }
        }
    }
```

**File:** config/src/config/consensus_observer_config.rs (L16-17)
```rust
// Maximum number of pending blocks for test networks (e.g., devnet)
const MAX_NUM_PENDING_BLOCKS_FOR_TEST_NETWORKS: u64 = 300;
```

**File:** config/src/config/consensus_observer_config.rs (L140-151)
```rust
        // Optimize the max number of pending blocks to accommodate increased block rates.
        // Note: we currently only do this for test networks (e.g., devnet).
        if let Some(chain_id) = chain_id {
            if local_observer_config_yaml["max_num_pending_blocks"].is_null()
                && !chain_id.is_testnet()
                && !chain_id.is_mainnet()
            {
                consensus_observer_config.max_num_pending_blocks =
                    MAX_NUM_PENDING_BLOCKS_FOR_TEST_NETWORKS;
                modified_config = true;
            }
        }
```
