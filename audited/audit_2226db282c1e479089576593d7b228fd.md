# Audit Report

## Title
Epoch Transition Race Condition Causes Validator Transaction Execution Failures

## Summary
During epoch transitions, the validator transaction pool's `pull()` method can return validator transactions (DKG or JWK) with stale epoch numbers. When a block's prologue triggers an epoch transition via `reconfigure()`, any validator transactions in that same block become invalid and fail execution with `EpochNotCurrent`, wasting network resources and violating protocol guarantees.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Validator Transaction Pool** - The `pull()` method returns transactions without validating their epoch numbers against the current on-chain epoch. [1](#0-0) 

2. **DKG Transaction Creation** - When DKG completes, it creates a validator transaction stamped with the current epoch number. [2](#0-1) 

3. **Block Prologue Epoch Change** - The block prologue can increment the epoch mid-block when the epoch interval expires. [3](#0-2) [4](#0-3) 

4. **VM Epoch Validation** - During validator transaction execution, the VM strictly validates that the transaction's epoch matches the current on-chain epoch. [5](#0-4) 

**Attack Scenario:**

1. Epoch N is active, DKG completes and adds transaction `T` with `epoch=N` to the pool
2. Consensus proposes Block B including transaction T
3. Block B's prologue executes and detects `timestamp - last_reconfiguration_time >= epoch_interval`
4. The prologue calls `reconfigure()`, incrementing the epoch from N to N+1
5. Transaction T executes, but the VM checks `T.epoch (N) != current_epoch (N+1)` and returns `EpochNotCurrent` error
6. Transaction T is discarded with `TransactionStatus::Discard(StatusCode::ABORTED)` [6](#0-5) 

The reconfiguration rule that prevents proposing validator transactions after reconfiguration only applies to *subsequent* blocks, not the block that triggers the transition itself. [7](#0-6) 

## Impact Explanation

**Severity: High** (up to $50,000)

This vulnerability causes significant protocol violations:

1. **Validator Transaction Execution Failures** - Critical system transactions (DKG for randomness, JWK for keyless accounts) fail to execute despite being included in committed blocks
2. **Resource Waste** - Network bandwidth and block space are consumed by transactions guaranteed to fail
3. **Validator Node Issues** - Validators expend computation resources processing invalid transactions
4. **Protocol Degradation** - DKG/JWK updates are delayed until the next epoch when they must be regenerated

While not causing consensus splits (execution is deterministic across all validators), this represents a significant protocol violation affecting validator operations and system functionality.

## Likelihood Explanation

**Likelihood: High**

This vulnerability triggers naturally whenever:
1. A DKG or JWK transaction is ready in the pool
2. The epoch interval is about to expire (within the current block's timestamp)
3. A block is proposed that includes both conditions

Given that epochs transition regularly (controlled by `epoch_interval`), and DKG transactions are generated for each epoch, this race condition occurs frequently in normal operation. No attacker action is required - it's a timing bug in the protocol itself.

## Recommendation

Add epoch validation to the validator transaction pull path. The proposal generator should check if validator transactions have matching epochs before including them in blocks, especially when approaching epoch boundaries.

**Proposed Fix:**

1. Add current epoch parameter to `pull()` method
2. Filter transactions where `transaction.epoch != current_epoch`
3. Alternatively, check if epoch transition is imminent (within block timestamp) and skip validator transactions if so

Implementation location: Add epoch filtering in the proposal generator before pulling validator transactions: [8](#0-7) 

The proposal generator should query the current epoch from the block store and pass it to the pull method, or check if `current_timestamp - last_reconfiguration_time >= epoch_interval` and skip validator transactions if true.

## Proof of Concept

**Scenario Setup:**
1. Configure short epoch interval (e.g., 60 seconds) for testing
2. Start network with DKG enabled
3. Advance time to `last_reconfiguration_time + epoch_interval - 1` second
4. Complete DKG, adding transaction with current epoch to pool
5. Propose block with timestamp that crosses epoch boundary
6. Observe block prologue triggers `reconfigure()`, incrementing epoch
7. Observe DKG transaction fails with `EpochNotCurrent` abort code
8. Verify transaction is discarded despite being in committed block

**Expected Result:** DKG transaction with epoch N fails when executed in the block that transitions to epoch N+1.

**Verification:** Check block execution logs for `TransactionStatus::Discard(StatusCode::ABORTED)` with abort code `0x10001` (EpochNotCurrent) for the DKG validator transaction.

## Notes

This vulnerability specifically affects validator transactions (DKG and JWK updates) because they embed epoch numbers in their metadata. The issue does not affect regular user transactions. The reconfiguration rule provides protection for blocks *after* an epoch transition but not for the transition block itself.

### Citations

**File:** crates/validator-transaction-pool/src/lib.rs (L152-199)
```rust
    pub fn pull(
        &mut self,
        deadline: Instant,
        mut max_items: u64,
        mut max_bytes: u64,
        filter: TransactionFilter,
    ) -> Vec<ValidatorTransaction> {
        let mut ret = vec![];
        let mut seq_num_lower_bound = 0;

        // Check deadline at the end of every iteration to ensure validator txns get a chance no matter what current proposal delay is.
        while max_items >= 1 && max_bytes >= 1 {
            // Find the seq_num of the first txn that satisfies the quota.
            if let Some(seq_num) = self
                .txn_queue
                .range(seq_num_lower_bound..)
                .filter(|(_, item)| {
                    item.txn.size_in_bytes() as u64 <= max_bytes
                        && !filter.should_exclude(&item.txn)
                })
                .map(|(seq_num, _)| *seq_num)
                .next()
            {
                // Update the quota usage.
                // Send the pull notification if requested.
                let PoolItem {
                    txn,
                    pull_notification_tx,
                    ..
                } = self.txn_queue.get(&seq_num).unwrap();
                if let Some(tx) = pull_notification_tx {
                    let _ = tx.push((), txn.clone());
                }
                max_items -= 1;
                max_bytes -= txn.size_in_bytes() as u64;
                seq_num_lower_bound = seq_num + 1;
                ret.push(txn.as_ref().clone());

                if Instant::now() >= deadline {
                    break;
                }
            } else {
                break;
            }
        }

        ret
    }
```

**File:** dkg/src/dkg_manager/mod.rs (L397-404)
```rust
                let txn = ValidatorTransaction::DKGResult(DKGTranscript {
                    metadata: DKGTranscriptMetadata {
                        epoch: self.epoch_state.epoch,
                        author: self.my_addr,
                    },
                    transcript_bytes: bcs::to_bytes(&agg_trx)
                        .map_err(|e| anyhow!("transcript serialization error: {e}"))?,
                });
```

**File:** aptos-move/framework/aptos-framework/sources/block.move (L215-217)
```text
        if (timestamp - reconfiguration::last_reconfiguration_time() >= epoch_interval) {
            reconfiguration::reconfigure();
        };
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration.move (L142-142)
```text
        config_ref.epoch = config_ref.epoch + 1;
```

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L68-77)
```rust
            Err(Expected(failure)) => {
                // Pretend we are inside Move, and expected failures are like Move aborts.
                Ok((
                    VMStatus::MoveAbort {
                        location: AbortLocation::Script,
                        code: failure as u64,
                        message: None,
                    },
                    VMOutput::empty_with_status(TransactionStatus::Discard(StatusCode::ABORTED)),
                ))
```

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L100-102)
```rust
        if dkg_node.metadata.epoch != config_resource.epoch() {
            return Err(Expected(EpochNotCurrent));
        }
```

**File:** consensus/src/liveness/proposal_generator.rs (L505-515)
```rust
        let (validator_txns, payload, timestamp) = if hqc.certified_block().has_reconfiguration() {
            // Reconfiguration rule - we propose empty blocks with parents' timestamp
            // after reconfiguration until it's committed
            (
                vec![],
                Payload::empty(
                    self.quorum_store_enabled,
                    self.allow_batches_without_pos_in_proposal,
                ),
                hqc.certified_block().timestamp_usecs(),
            )
```

**File:** consensus/src/liveness/proposal_generator.rs (L643-672)
```rust
        let pending_validator_txn_hashes: HashSet<HashValue> = pending_blocks
            .iter()
            .filter_map(|block| block.validator_txns())
            .flatten()
            .map(ValidatorTransaction::hash)
            .collect();
        let validator_txn_filter =
            vtxn_pool::TransactionFilter::PendingTxnHashSet(pending_validator_txn_hashes);

        let (validator_txns, mut payload) = self
            .payload_client
            .pull_payload(
                PayloadPullParameters {
                    max_poll_time: self.quorum_store_poll_time.saturating_sub(proposal_delay),
                    max_txns: max_block_txns,
                    max_txns_after_filtering: max_block_txns_after_filtering,
                    soft_max_txns_after_filtering: max_txns_from_block_to_execute
                        .unwrap_or(max_block_txns_after_filtering),
                    max_inline_txns: self.max_inline_txns,
                    maybe_optqs_payload_pull_params,
                    user_txn_filter: payload_filter,
                    pending_ordering,
                    pending_uncommitted_blocks: pending_blocks.len(),
                    recent_max_fill_fraction: max_fill_fraction,
                    block_timestamp: timestamp,
                },
                validator_txn_filter,
            )
            .await
            .context("Fail to retrieve payload")?;
```
