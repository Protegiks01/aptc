# Audit Report

## Title
Missing Configuration Validation Causes Indexer Data Service to Crash on First Request

## Summary
The indexer-grpc-data-service-v2 lacks startup validation to ensure at least one data service (live or historical) is enabled. When both services are disabled via configuration, the service successfully starts and binds to its network port but crashes with a panic when clients make their first `get_transactions` request, resulting in a denial of service.

## Finding Description

The indexer-grpc-data-service-v2 service allows operators to enable/disable the live data service and historical data service independently through configuration flags. [1](#0-0) [2](#0-1) 

When both `live_data_service_config.enabled` and `historical_data_service_config.enabled` are set to `false`, the service initialization proceeds without validation. The `create_live_data_service` and `create_historical_data_service` methods return `None` when their respective services are disabled: [3](#0-2) [4](#0-3) 

The service creates a `DataServiceWrapperWrapper` with both services as `None` and successfully starts the gRPC server: [5](#0-4) 

However, when a client calls `get_transactions`, the code reaches an `unreachable!()` macro that panics: [6](#0-5) 

The panic handler configured in the server framework causes the entire process to exit: [7](#0-6) 

## Impact Explanation

This issue is categorized as **Medium severity** per the following considerations:

1. **Service Availability**: The indexer data service crashes on first client request, creating a denial of service for data consumers
2. **Operational Impact**: The service appears healthy (passes health checks, binds to port) but is non-functional, causing operational confusion
3. **Resource Waste**: System resources are consumed by a service that cannot fulfill its purpose
4. **Limited Scope**: This affects only the indexer query infrastructure, not core blockchain consensus, execution, or validator operations

**Important Note**: This vulnerability does NOT affect:
- Blockchain consensus or safety
- Validator node operations
- Transaction execution or state management
- On-chain funds or assets
- Core protocol functionality

The indexer-grpc service is auxiliary query infrastructure. Its failure does not compromise the blockchain itself.

## Likelihood Explanation

**Likelihood: Low to Medium**

This issue occurs when an operator misconfigures the service by disabling both data services. While this is an operator error rather than an external attack, it represents a realistic failure mode because:

1. Configuration files may be deployed with incorrect settings during maintenance
2. Operators may intentionally disable both services temporarily, not realizing it causes crashes
3. The lack of startup validation makes the misconfiguration easy to miss
4. The service appears to start successfully, delaying detection until runtime

## Recommendation

Add configuration validation in the `RunnableConfig` implementation to fail fast at startup if both services are disabled: [8](#0-7) 

Add the following validation method to `IndexerGrpcDataServiceConfig`:

```rust
#[async_trait::async_trait]
impl RunnableConfig for IndexerGrpcDataServiceConfig {
    fn validate(&self) -> Result<()> {
        if !self.live_data_service_config.enabled 
            && !self.historical_data_service_config.enabled {
            anyhow::bail!(
                "At least one of live_data_service or historical_data_service must be enabled"
            );
        }
        Ok(())
    }
    
    // ... rest of implementation
}
```

This ensures the service fails immediately during startup with a clear error message rather than crashing on first use.

## Proof of Concept

**Configuration file that triggers the issue** (`config.yaml`):

```yaml
health_check_port: 8081
server_config:
  chain_id: 1
  service_config:
    listen_address: "0.0.0.0:50051"
    tls_config: null
  live_data_service_config:
    enabled: false  # Both services disabled
  historical_data_service_config:
    enabled: false  # Both services disabled
  grpc_manager_addresses: []
  self_advertised_address: "localhost:50051"
```

**Steps to reproduce:**

1. Deploy the indexer-grpc-data-service-v2 with the above configuration
2. Service starts successfully and binds to port 50051
3. Make a gRPC call to `GetTransactions` endpoint
4. Service crashes with panic: "Must have at least one of the data services enabled."
5. Process exits with code 12

The service will repeatedly crash if auto-restarted until the configuration is corrected.

## Notes

While this is a genuine implementation flaw requiring a fix, it falls outside the primary security concerns of the Aptos blockchain. The indexer infrastructure provides query capabilities but is not part of the critical consensus, execution, or state management layers. This issue represents poor defensive programming and configuration validation rather than a security vulnerability that threatens blockchain integrity, validator operations, or user funds.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L58-64)
```rust
pub struct LiveDataServiceConfig {
    pub enabled: bool,
    #[serde(default = "LiveDataServiceConfig::default_num_slots")]
    pub num_slots: usize,
    #[serde(default = "LiveDataServiceConfig::default_size_limit_bytes")]
    pub size_limit_bytes: usize,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L78-81)
```rust
pub struct HistoricalDataServiceConfig {
    pub enabled: bool,
    pub file_store_config: IndexerGrpcFileStoreConfig,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L111-113)
```rust
        if !self.live_data_service_config.enabled {
            return None;
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L161-163)
```rust
        if !self.historical_data_service_config.enabled {
            return None;
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L208-292)
```rust
#[async_trait::async_trait]
impl RunnableConfig for IndexerGrpcDataServiceConfig {
    async fn run(&self) -> Result<()> {
        let reflection_service = tonic_reflection::server::Builder::configure()
            // Note: It is critical that the file descriptor set is registered for every
            // file that the top level API proto depends on recursively. If you don't,
            // compilation will still succeed but reflection will fail at runtime.
            //
            // TODO: Add a test for this / something in build.rs, this is a big footgun.
            .register_encoded_file_descriptor_set(INDEXER_V1_FILE_DESCRIPTOR_SET)
            .register_encoded_file_descriptor_set(TRANSACTION_V1_TESTING_FILE_DESCRIPTOR_SET)
            .register_encoded_file_descriptor_set(UTIL_TIMESTAMP_FILE_DESCRIPTOR_SET)
            .build_v1alpha()
            .map_err(|e| anyhow::anyhow!("Failed to build reflection service: {}", e))?
            .send_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Gzip);

        let mut tasks = vec![];

        let live_data_service = self.create_live_data_service(&mut tasks).await;
        let historical_data_service = self.create_historical_data_service(&mut tasks).await;

        let wrapper = Arc::new(DataServiceWrapperWrapper::new(
            live_data_service,
            historical_data_service,
        ));
        let wrapper_service_raw =
            aptos_protos::indexer::v1::raw_data_server::RawDataServer::from_arc(wrapper.clone())
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
        let wrapper_service =
            aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);

        let listen_address = self.service_config.listen_address;
        let mut server_builder = Server::builder()
            .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
            .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION));
        if let Some(config) = &self.service_config.tls_config {
            let cert = tokio::fs::read(config.cert_path.clone()).await?;
            let key = tokio::fs::read(config.key_path.clone()).await?;
            let identity = tonic::transport::Identity::from_pem(cert, key);
            server_builder = server_builder
                .tls_config(tonic::transport::ServerTlsConfig::new().identity(identity))?;
            info!(
                grpc_address = listen_address.to_string().as_str(),
                "[Data Service] Starting gRPC server with TLS."
            );
        } else {
            info!(
                grpc_address = listen_address.to_string().as_str(),
                "[data service] starting gRPC server with non-TLS."
            );
        }

        tasks.push(tokio::spawn(async move {
            server_builder
                .add_service(wrapper_service)
                .add_service(wrapper_service_raw)
                .add_service(reflection_service)
                .serve(listen_address)
                .await
                .map_err(|e| anyhow::anyhow!(e))
        }));

        futures::future::try_join_all(tasks).await?;
        Ok(())
    }

    fn get_server_name(&self) -> String {
        "indexer_grpc_data_service_v2".to_string()
    }

    async fn status_page(&self) -> Result<Response, Rejection> {
        crate::status_page::status_page()
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L67-71)
```rust
        } else if let Some(historical_data_service) = self.historical_data_service.as_ref() {
            historical_data_service.get_transactions(req).await
        } else {
            unreachable!("Must have at least one of the data services enabled.");
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L149-168)
```rust
pub fn setup_panic_handler() {
    std::panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());
    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);
    // Kill the process
    process::exit(12);
}
```
