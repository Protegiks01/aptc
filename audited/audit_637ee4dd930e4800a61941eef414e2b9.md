# Audit Report

## Title
State Restore Mode Change Attack: Hybrid KV-Tree State Corruption

## Summary
The state restore mechanism lacks validation to ensure that the `restore_mode` parameter remains consistent across resume operations. An operator can start a state snapshot restore with one mode (e.g., `KvOnly`), allow it to partially complete, then resume with a different mode (e.g., `TreeOnly`), resulting in a hybrid state where some chunks contain only KV data while others contain only tree data. This violates the critical state consistency invariant and can cause consensus splits.

## Finding Description

The vulnerability exists in the state restore progress tracking mechanism. When a state snapshot restore operation is interrupted and later resumed, the system only tracks the last processed key hash and storage usage, but **not** the restore mode used. [1](#0-0) 

The `StateSnapshotProgress` struct persists only `key_hash` and `usage`, with no field for `restore_mode`. This progress is stored in the database to enable resume functionality: [2](#0-1) 

When resuming a restore operation, the system retrieves this progress and skips already-processed chunks based solely on the key hash: [3](#0-2) 

The `restore_mode` parameter controls which data gets written for each chunk: [4](#0-3) 

In `KvOnly` mode, only key-value data is written to the state KV database. In `TreeOnly` mode, only Merkle tree nodes are written. In `Default` mode, both are written.

The critical flaw is that the restore mode is accepted as a user-specified parameter without validation against any previously stored mode: [5](#0-4) [6](#0-5) 

The db-tool CLI exposes this parameter, allowing operators to manually specify the restore mode: [7](#0-6) 

**Attack Scenario:**

1. Operator runs: `db-tool restore oneoff state-snapshot --restore-mode=kv_only --state-manifest=<handle> --state-into-version=1000000`
2. Restore processes chunks 1-500 with `KvOnly` mode (writes only KV data, no tree nodes)
3. Progress saved: `StateSnapshotKvRestoreProgress(1000000) = StateSnapshotProgress{key_hash: <chunk_500_last_key>, usage: ...}`
4. Process crashes or operator manually stops it
5. Operator runs: `db-tool restore oneoff state-snapshot --restore-mode=tree_only --state-manifest=<handle> --state-into-version=1000000`
6. System loads progress from step 3, skips chunks 1-500
7. Restore processes chunks 501-1000 with `TreeOnly` mode (writes only tree nodes, no KV data)
8. **Result:** Database contains KV data for chunks 1-500 but no corresponding tree nodes, and tree nodes for chunks 501-1000 but no corresponding KV data

This creates a fundamentally inconsistent state where:
- State reads will fail for keys in chunks 501-1000 (no KV data exists)
- Merkle proofs cannot be generated for keys in chunks 1-500 (no tree nodes exist)
- The state root hash becomes invalid or unprovable
- Different nodes restoring with different mode sequences will have different states, breaking consensus

## Impact Explanation

This vulnerability has **Critical Severity** impact:

**Consensus Safety Violation:** The fundamental guarantee of blockchain consensus is that all honest validators produce identical state roots for identical blocks. This vulnerability allows different nodes to have structurally different databases for the same version, violating Invariant #1 (Deterministic Execution) and Invariant #4 (State Consistency).

If different validator nodes restore state snapshots with different mode combinations:
- Node A: Restores chunks 1-500 with KvOnly, then chunks 501-1000 with Default → has complete data for chunks 501-1000, incomplete for 1-500
- Node B: Restores chunks 1-500 with Default, then chunks 501-1000 with TreeOnly → has complete data for chunks 1-500, incomplete for 501-1000

Both nodes will compute different state roots and produce different commitment hashes, causing a **non-recoverable consensus split** requiring manual intervention or a hard fork to resolve.

**State Corruption:** The hybrid state prevents normal blockchain operations:
- State queries for affected keys will fail
- Transaction execution touching affected state will panic or produce incorrect results
- State synchronization from the corrupted node will propagate corruption to other nodes
- Merkle proof generation and verification becomes impossible for affected ranges

This meets the **Critical Severity** criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability requires operator access to the restore tooling, but the scenarios where it can occur are realistic:

1. **Operational Errors:** During disaster recovery or node bootstrap, operators may:
   - Start a restore with wrong parameters
   - Interrupt and retry with corrected parameters without clearing the database
   - Follow incomplete or incorrect runbooks

2. **Configuration Changes:** Organizations may change their restore procedures (e.g., switching from Default to TreeOnly for performance) without realizing the impact on partial restores.

3. **Automated Systems:** Orchestration tools that retry failed operations with different parameters could inadvertently trigger this vulnerability.

4. **Multiple Operators:** In team environments, different operators may unknowingly continue a restore started by someone else with different parameters.

The vulnerability is NOT immediately obvious because:
- No error is thrown when resuming with a different mode
- The restore completes successfully
- The corruption is silent and only manifests later during normal operations

While this requires privileged access to the restore tooling, it does NOT require Byzantine behavior or malicious intent—simple operational mistakes can trigger it. Given the critical nature of state restore operations and the lack of safeguards, this is highly likely to occur in real-world deployments.

## Recommendation

**Immediate Fix:** Store and validate the restore mode in progress metadata.

**Implementation:**

1. Extend `StateSnapshotProgress` to include the restore mode:

```rust
// In storage/indexer_schemas/src/metadata.rs
#[derive(Clone, Copy, Debug, Deserialize, Eq, PartialEq, Serialize)]
pub struct StateSnapshotProgress {
    pub key_hash: HashValue,
    pub usage: StateStorageUsage,
    pub restore_mode: Option<StateSnapshotRestoreMode>,  // NEW FIELD
}
```

2. Store the mode when saving progress:

```rust
// In storage/aptosdb/src/state_restore/mod.rs, StateValueRestore::add_chunk
self.db.write_kv_batch(
    self.version,
    &kv_batch,
    StateSnapshotProgress::new_with_mode(last_key_hash, usage, self.restore_mode),  // Pass mode
)
```

3. Validate mode consistency when resuming:

```rust
// In storage/aptosdb/src/state_restore/mod.rs, StateSnapshotRestore::new
pub fn new<T: 'static + TreeReader<K> + TreeWriter<K>, S: 'static + StateValueWriter<K, V>>(
    tree_store: &Arc<T>,
    value_store: &Arc<S>,
    version: Version,
    expected_root_hash: HashValue,
    async_commit: bool,
    restore_mode: StateSnapshotRestoreMode,
) -> Result<Self> {
    // Check for existing progress
    if let Some(existing_progress) = value_store.get_progress(version)? {
        if let Some(existing_mode) = existing_progress.restore_mode {
            if existing_mode != restore_mode {
                return Err(anyhow!(
                    "Restore mode mismatch: attempted to resume with {:?} but previous restore used {:?}. \
                    Clear the database or use the same restore mode.",
                    restore_mode, existing_mode
                ));
            }
        }
    }
    
    Ok(Self {
        tree_restore: Arc::new(Mutex::new(Some(JellyfishMerkleRestore::new(
            Arc::clone(tree_store),
            version,
            expected_root_hash,
            async_commit,
        )?))),
        kv_restore: Arc::new(Mutex::new(Some(StateValueRestore::new(
            Arc::clone(value_store),
            version,
        )))),
        restore_mode,
    })
}
```

4. Add a CLI flag to force override (with clear warning):

```rust
#[clap(long, help = "Force restore with new mode, ignoring previous progress (DANGEROUS: may corrupt state)")]
pub force_mode_override: bool,
```

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// File: storage/aptosdb/src/state_restore/restore_test.rs

#[test]
fn test_restore_mode_change_creates_hybrid_state() {
    use crate::state_restore::{StateSnapshotRestore, StateSnapshotRestoreMode};
    use aptos_crypto::HashValue;
    use aptos_storage_interface::StateSnapshotReceiver;
    use aptos_types::state_store::{state_key::StateKey, state_value::StateValue};
    
    // Setup test database
    let tmpdir = tempfile::tempdir().unwrap();
    let db = AptosDB::new_for_test(&tmpdir);
    let version = 100;
    let expected_root = HashValue::random();
    
    // Phase 1: Start restore with KvOnly mode
    let mut receiver1 = db.get_restore_handler()
        .get_state_restore_receiver(version, expected_root, StateSnapshotRestoreMode::KvOnly)
        .unwrap();
    
    // Add first chunk with KvOnly mode (only KV data written)
    let chunk1 = vec![
        (StateKey::raw(b"key1"), StateValue::from(b"value1")),
        (StateKey::raw(b"key2"), StateValue::from(b"value2")),
    ];
    let proof1 = create_test_proof(&chunk1);
    receiver1.add_chunk(chunk1.clone(), proof1).unwrap();
    
    // Simulate crash - drop receiver without calling finish
    drop(receiver1);
    
    // Phase 2: Resume with TreeOnly mode (ATTACK)
    let mut receiver2 = db.get_restore_handler()
        .get_state_restore_receiver(version, expected_root, StateSnapshotRestoreMode::TreeOnly)
        .unwrap();
    
    // Add second chunk with TreeOnly mode (only tree data written)
    let chunk2 = vec![
        (StateKey::raw(b"key3"), StateValue::from(b"value3")),
        (StateKey::raw(b"key4"), StateValue::from(b"value4")),
    ];
    let proof2 = create_test_proof(&chunk2);
    receiver2.add_chunk(chunk2.clone(), proof2).unwrap();
    receiver2.finish().unwrap();
    
    // VERIFY CORRUPTION:
    // chunk1 keys should have KV data but NO tree nodes
    let kv1 = db.state_store.get_state_value_by_version(&StateKey::raw(b"key1"), version).unwrap();
    assert!(kv1.is_some()); // KV data exists
    
    let tree_node1 = db.state_merkle_db.get_node(&chunk1[0].0.hash(), version);
    assert!(tree_node1.is_err()); // Tree node MISSING - CORRUPTION!
    
    // chunk2 keys should have tree nodes but NO KV data  
    let kv2 = db.state_store.get_state_value_by_version(&StateKey::raw(b"key3"), version).unwrap();
    assert!(kv2.is_none()); // KV data MISSING - CORRUPTION!
    
    let tree_node2 = db.state_merkle_db.get_node(&chunk2[0].0.hash(), version);
    assert!(tree_node2.is_ok()); // Tree node exists
    
    // This proves hybrid state: some keys have KV only, others have tree only
    // This breaks state consistency and would cause consensus splits
}
```

## Notes

This vulnerability is particularly insidious because:

1. **Silent Corruption:** No errors are thrown during the restore process—the corruption only manifests during normal operations
2. **Difficult to Detect:** Operators may not realize the database is corrupted until nodes start diverging during consensus
3. **Hard to Recover:** Once corrupted, the only fix is to wipe the database and restart the full restore from scratch
4. **Amplification Risk:** If one corrupted node is used as the source for state sync, it can propagate the corruption to other nodes

The fix should be applied urgently as this affects core state management functionality critical to blockchain safety.

### Citations

**File:** storage/indexer_schemas/src/metadata.rs (L46-49)
```rust
pub struct StateSnapshotProgress {
    pub key_hash: HashValue,
    pub usage: StateStorageUsage,
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1254-1257)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
            &DbMetadataValue::StateSnapshotProgress(progress),
        )?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L57-58)
```rust
    #[clap(long)]
    pub restore_mode: StateSnapshotRestoreMode,
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L165-174)
```rust
        let resume_point_opt = receiver.lock().as_mut().unwrap().previous_key_hash()?;
        let chunks = if let Some(resume_point) = resume_point_opt {
            manifest
                .chunks
                .into_iter()
                .skip_while(|chunk| chunk.last_key <= resume_point)
                .collect()
        } else {
            manifest.chunks
        };
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L246-255)
```rust
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => kv_fn()?,
            StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
        }
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L216-227)
```rust
    pub fn get_state_restore_receiver(
        &self,
        version: Version,
        expected_root_hash: HashValue,
        restore_mode: StateSnapshotRestoreMode,
    ) -> Result<StateSnapshotRestore<StateKey, StateValue>> {
        match self {
            Self::Restore { restore_handler } => restore_handler.get_state_restore_receiver(
                version,
                expected_root_hash,
                restore_mode,
            ),
```

**File:** storage/db-tool/src/restore.rs (L47-54)
```rust
    StateSnapshot {
        #[clap(flatten)]
        storage: DBToolStorageOpt,
        #[clap(flatten)]
        opt: StateSnapshotRestoreOpt,
        #[clap(flatten)]
        global: GlobalRestoreOpt,
    },
```
