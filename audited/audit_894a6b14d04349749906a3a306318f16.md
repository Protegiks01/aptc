# Audit Report

## Title
Missing Recipient Validation in Quorum Store Signed Batch Info Messaging Allows Potential Consensus Data Leakage

## Summary
The `send_signed_batch_info_msg()` and `send_signed_batch_info_msg_v2()` functions in the consensus network layer do not validate that recipients are valid validators before sending signed batch information. This lack of validation creates a potential information leakage vector during epoch transitions, where consensus metadata could be sent to nodes that are no longer part of the validator set.

## Finding Description

The `send_signed_batch_info_msg()` function calls the internal `send()` method without validating recipients against the current validator set. [1](#0-0) [2](#0-1) 

The underlying `send()` function iterates through recipients and sends messages without any validator verification: [3](#0-2) 

In contrast, the `broadcast_without_self()` function explicitly uses the validator set to determine recipients: [4](#0-3) 

While the current production code path in `BatchCoordinator::persist_and_send_digests()` validates recipients when batches are initially received, there is a temporal gap between validation and sending due to asynchronous task execution: [5](#0-4) 

The validation occurs when `BatchMsg::verify()` checks that the batch author is a current validator: [6](#0-5) 

**Epoch Transition Race Condition:**

1. Validator A sends a batch to Validator B during epoch N
2. Validator B receives and validates the batch (A is confirmed as a validator in epoch N)
3. Validator B spawns an async task via `tokio::spawn()` to persist and send signed batch info
4. Before the async task completes, an epoch transition occurs (epoch N â†’ N+1)
5. Validator A is not part of the validator set in epoch N+1
6. The async task completes and sends signed batch info to A (now a non-validator)
7. A receives consensus metadata (batch digests, validator signatures, transaction counts) despite no longer being a validator

The signed batch info contains sensitive consensus metadata: [7](#0-6) [8](#0-7) 

## Impact Explanation

This issue qualifies as **Medium Severity** based on the Aptos bug bounty criteria:
- **Minor information leak**: Consensus metadata (batch digests, signatures, transaction counts, epoch information) may be disclosed to non-validators
- **State inconsistencies**: Violates the invariant that consensus data should only be shared among active validators
- Does not result in loss of funds, consensus safety violations, or network liveness issues

The leaked information includes batch metadata that could provide insights into validator behavior, transaction patterns, and consensus timing, though it does not directly expose transaction contents or enable fund theft.

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires specific timing conditions:
- An epoch transition must occur during the async delay between batch validation and signed batch info transmission
- The batch author must be removed from the validator set in the new epoch
- Epoch transitions are infrequent (typically hours apart)
- The async task execution is typically fast (milliseconds to seconds)

However, the issue represents a **defensive programming failure**:
- No validation safeguard exists even though the NetworkSender has access to the validator set
- Future code changes could introduce new call paths without proper validation
- The function's API does not enforce caller-side validation

## Recommendation

Add recipient validation to the `send()` function to verify all recipients are valid validators:

```rust
async fn send(&self, msg: ConsensusMsg, recipients: Vec<Author>) {
    fail_point!("consensus::send::any", |_| ());
    let network_sender = self.consensus_network_client.clone();
    let mut self_sender = self.self_sender.clone();
    
    // Get current validator addresses
    let valid_validators: std::collections::HashSet<_> = self
        .validators
        .get_ordered_account_addresses_iter()
        .collect();
    
    for peer in recipients {
        // Validate recipient is a current validator (excluding self)
        if peer != self.author && !valid_validators.contains(&peer) {
            warn!(
                remote_peer = peer,
                "Attempted to send consensus message to non-validator, skipping"
            );
            continue;
        }
        
        if self.author == peer {
            let self_msg = Event::Message(self.author, msg.clone());
            if let Err(err) = self_sender.send(self_msg).await {
                warn!(error = ?err, "Error delivering a self msg");
            }
            continue;
        }
        counters::CONSENSUS_SENT_MSGS
            .with_label_values(&[msg.name()])
            .inc();
        if let Err(e) = network_sender.send_to(peer, msg.clone()) {
            warn!(
                remote_peer = peer,
                error = ?e, "Failed to send a msg {:?} to peer", msg
            );
        }
    }
}
```

Alternatively, add validation specifically in `send_signed_batch_info_msg()` functions before calling `send()`.

## Proof of Concept

This vulnerability is challenging to reproduce deterministically due to the race condition nature. A PoC would require:

1. Setting up a multi-validator test environment
2. Triggering batch processing near epoch boundaries
3. Forcing an epoch transition during the async task execution
4. Monitoring network messages to confirm signed batch info delivery to non-validators

A simplified reproduction approach:

```rust
// Conceptual PoC - would need to be integrated into consensus tests
#[tokio::test]
async fn test_signed_batch_info_sent_to_non_validator() {
    // Setup: Create validator set for epoch N with validators A and B
    let epoch_n_validators = vec![validator_a, validator_b];
    let network_sender_n = NetworkSender::new(
        validator_b,
        network_client.clone(),
        self_sender.clone(),
        Arc::new(ValidatorVerifier::new(epoch_n_validators)),
    );
    
    // Validator A sends batch to B
    let batch = create_test_batch(validator_a, epoch_n);
    
    // B validates and spawns async task
    let persist_task = tokio::spawn(async move {
        tokio::time::sleep(Duration::from_millis(100)).await; // Simulate persist delay
        network_sender_n.send_signed_batch_info_msg_v2(
            signed_batch_infos,
            vec![validator_a]
        ).await;
    });
    
    // Simulate epoch transition: A is removed from validator set
    let epoch_n1_validators = vec![validator_b, validator_c]; // A removed
    // Network sender still has old epoch validator set
    
    // Task completes and sends to A (now non-validator)
    persist_task.await.unwrap();
    
    // Assert: Signed batch info was sent to non-validator A
    // This violates the invariant that consensus data should only go to validators
}
```

**Notes**

The core issue is a **violation of defensive programming principles** rather than an immediately exploitable attack. While the current code path validates recipients earlier in the flow, the lack of validation at the send layer creates fragility:

1. The `NetworkSender` struct contains a `validators` field specifically for validator verification, yet `send()` does not use it
2. The `broadcast_without_self()` function demonstrates the correct pattern of filtering recipients through the validator set
3. The async execution delay in `BatchCoordinator::persist_and_send_digests()` creates a temporal window for epoch changes
4. Future code modifications could introduce additional call paths that bypass the current validation

This represents a **defense-in-depth failure** where the networking layer should provide an additional validation barrier, even if upstream code performs checks.

### Citations

**File:** consensus/src/network.rs (L387-408)
```rust
    pub fn broadcast_without_self(&self, msg: ConsensusMsg) {
        fail_point!("consensus::send::any", |_| ());

        let self_author = self.author;
        let mut other_validators: Vec<_> = self
            .validators
            .get_ordered_account_addresses_iter()
            .filter(|author| author != &self_author)
            .collect();
        self.sort_peers_by_latency(&mut other_validators);

        counters::CONSENSUS_SENT_MSGS
            .with_label_values(&[msg.name()])
            .inc_by(other_validators.len() as u64);
        // Broadcast message over direct-send to all other validators.
        if let Err(err) = self
            .consensus_network_client
            .send_to_many(other_validators, msg)
        {
            warn!(error = ?err, "Error broadcasting message");
        }
    }
```

**File:** consensus/src/network.rs (L411-433)
```rust
    async fn send(&self, msg: ConsensusMsg, recipients: Vec<Author>) {
        fail_point!("consensus::send::any", |_| ());
        let network_sender = self.consensus_network_client.clone();
        let mut self_sender = self.self_sender.clone();
        for peer in recipients {
            if self.author == peer {
                let self_msg = Event::Message(self.author, msg.clone());
                if let Err(err) = self_sender.send(self_msg).await {
                    warn!(error = ?err, "Error delivering a self msg");
                }
                continue;
            }
            counters::CONSENSUS_SENT_MSGS
                .with_label_values(&[msg.name()])
                .inc();
            if let Err(e) = network_sender.send_to(peer, msg.clone()) {
                warn!(
                    remote_peer = peer,
                    error = ?e, "Failed to send a msg {:?} to peer", msg
                );
            }
        }
    }
```

**File:** consensus/src/network.rs (L588-597)
```rust
    async fn send_signed_batch_info_msg(
        &self,
        signed_batch_infos: Vec<SignedBatchInfo<BatchInfo>>,
        recipients: Vec<Author>,
    ) {
        fail_point!("consensus::send::signed_batch_info", |_| ());
        let msg =
            ConsensusMsg::SignedBatchInfo(Box::new(SignedBatchInfoMsg::new(signed_batch_infos)));
        self.send(msg, recipients).await
    }
```

**File:** consensus/src/network.rs (L599-609)
```rust
    async fn send_signed_batch_info_msg_v2(
        &self,
        signed_batch_infos: Vec<SignedBatchInfo<BatchInfoExt>>,
        recipients: Vec<Author>,
    ) {
        fail_point!("consensus::send::signed_batch_info", |_| ());
        let msg = ConsensusMsg::SignedBatchInfoMsgV2(Box::new(SignedBatchInfoMsg::new(
            signed_batch_infos,
        )));
        self.send(msg, recipients).await
    }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L78-135)
```rust
    fn persist_and_send_digests(
        &self,
        persist_requests: Vec<PersistedValue<BatchInfoExt>>,
        approx_created_ts_usecs: u64,
    ) {
        if persist_requests.is_empty() {
            return;
        }

        let batch_store = self.batch_store.clone();
        let network_sender = self.network_sender.clone();
        let sender_to_proof_manager = self.sender_to_proof_manager.clone();
        tokio::spawn(async move {
            let peer_id = persist_requests[0].author();
            let batches = persist_requests
                .iter()
                .map(|persisted_value| {
                    (
                        persisted_value.batch_info().clone(),
                        persisted_value.summary(),
                    )
                })
                .collect();

            if persist_requests[0].batch_info().is_v2() {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    network_sender
                        .send_signed_batch_info_msg_v2(signed_batch_infos, vec![peer_id])
                        .await;
                }
            } else {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    assert!(!signed_batch_infos
                        .first()
                        .expect("must not be empty")
                        .is_v2());
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    let signed_batch_infos = signed_batch_infos
                        .into_iter()
                        .map(|sbi| sbi.try_into().expect("Batch must be V1 batch"))
                        .collect();
                    network_sender
                        .send_signed_batch_info_msg(signed_batch_infos, vec![peer_id])
                        .await;
                }
            }
            let _ = sender_to_proof_manager
                .send(ProofManagerCommand::ReceiveBatches(batches))
                .await;
        });
    }
```

**File:** consensus/src/quorum_store/types.rs (L433-461)
```rust
    pub fn verify(
        &self,
        peer_id: PeerId,
        max_num_batches: usize,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        ensure!(!self.batches.is_empty(), "Empty message");
        ensure!(
            self.batches.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.batches.len(),
            max_num_batches
        );
        let epoch_authors = verifier.address_to_validator_index();
        for batch in self.batches.iter() {
            ensure!(
                epoch_authors.contains_key(&batch.author()),
                "Invalid author {} for batch {} in current epoch",
                batch.author(),
                batch.digest()
            );
            ensure!(
                batch.author() == peer_id,
                "Batch author doesn't match sender"
            );
            batch.verify()?
        }
        Ok(())
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L49-58)
```rust
pub struct BatchInfo {
    author: PeerId,
    batch_id: BatchId,
    epoch: u64,
    expiration: u64,
    digest: HashValue,
    num_txns: u64,
    num_bytes: u64,
    gas_bucket_start: u64,
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L414-419)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct SignedBatchInfo<T> {
    info: T,
    signer: PeerId,
    signature: SignatureWithStatus,
}
```
