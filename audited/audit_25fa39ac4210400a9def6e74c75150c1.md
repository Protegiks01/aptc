# Audit Report

## Title
Oneshot Channel Panic During Epoch Transition Shutdown

## Summary
The `shutdown_current_processor()` function in the EpochManager uses `.expect()` on oneshot channel sends without handling the case where the receiver has been dropped. If the RoundManager or DAG bootstrapper tasks terminate abnormally before shutdown is initiated, attempting to send the shutdown acknowledgment request will panic, preventing graceful epoch transitions. [1](#0-0) [2](#0-1) 

## Finding Description

The vulnerability exists in the shutdown mechanism for consensus components. When initiating a new epoch, the `initiate_new_epoch()` function calls `shutdown_current_processor()` to gracefully stop the current RoundManager and DAG bootstrapper tasks. [3](#0-2) 

The shutdown protocol works as follows:
1. A oneshot channel pair `(close_tx, close_rx)` is created when spawning the RoundManager
2. The receiver `close_rx` is passed to the RoundManager's event loop
3. On shutdown, `close_tx.send(ack_tx)` sends an acknowledgment channel to the task
4. The task receives it, sends back confirmation, and terminates gracefully [4](#0-3) [5](#0-4) 

However, if the RoundManager or DAG task terminates abnormally (due to a panic, task cancellation, or unhandled error) before `shutdown_current_processor()` is called, the `close_rx` receiver is dropped. When `close_tx.send(ack_tx)` is subsequently called, it returns an error because the receiver no longer exists. The `.expect()` then causes the EpochManager to panic with the message "Fail to drop round manager" or "Fail to drop DAG bootstrapper".

This creates a **cascading failure** where:
1. An initial bug/panic in RoundManager causes abnormal termination
2. The dropped receiver prevents graceful shutdown
3. The EpochManager panics during epoch transition
4. The validator node cannot join the new epoch

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria for the following reasons:

1. **Validator Node Crashes**: When triggered, the EpochManager panics during critical epoch transitions, causing the entire consensus component to crash. This prevents the validator from participating in the new epoch.

2. **Liveness Impact**: Epoch transitions occur during validator set changes, stake updates, and governance reconfigurationsâ€”critical moments for network operation. If multiple validators encounter this issue simultaneously, it could impact network liveness.

3. **Amplification of Bugs**: This vulnerability transforms any bug that causes RoundManager to panic into a more severe issue by preventing recovery during epoch transitions. It violates defense-in-depth principles by making error conditions worse rather than containing them.

4. **Recovery Requires Intervention**: A node affected by this issue cannot automatically recover and requires manual restart, potentially during a time-sensitive epoch transition.

## Likelihood Explanation

The likelihood is **Medium** and depends on whether the RoundManager or DAG tasks can be made to panic:

**Triggering Conditions:**
- Any unhandled panic in RoundManager's processing code
- Task cancellation by the runtime
- Assertion failures or invariant violations in consensus logic

**Observable Panic Points:**
The RoundManager contains several `unwrap()` and `unreachable!()` calls that could panic if invariants are violated: [6](#0-5) 

While the code generally handles errors gracefully, the presence of `.expect()` in the shutdown path itself demonstrates that developers did not anticipate the receiver being dropped scenario.

## Recommendation

Replace the `.expect()` calls with proper error handling that logs the failure but does not panic:

```rust
async fn shutdown_current_processor(&mut self) {
    if let Some(close_tx) = self.round_manager_close_tx.take() {
        let (ack_tx, ack_rx) = oneshot::channel();
        match close_tx.send(ack_tx) {
            Ok(_) => {
                if let Err(e) = ack_rx.await {
                    warn!("[EpochManager] Round manager did not acknowledge shutdown: {:?}", e);
                }
            }
            Err(_) => {
                warn!("[EpochManager] Round manager receiver already dropped, task may have terminated abnormally");
            }
        }
    }
    self.round_manager_tx = None;

    if let Some(close_tx) = self.dag_shutdown_tx.take() {
        let (ack_tx, ack_rx) = oneshot::channel();
        match close_tx.send(ack_tx) {
            Ok(_) => {
                if let Err(e) = ack_rx.await {
                    warn!("[EpochManager] DAG bootstrapper did not acknowledge shutdown: {:?}", e);
                }
            }
            Err(_) => {
                warn!("[EpochManager] DAG bootstrapper receiver already dropped, task may have terminated abnormally");
            }
        }
    }
    self.dag_shutdown_tx = None;
    
    // ... rest of shutdown logic
}
```

This ensures that even if tasks terminate abnormally, the epoch transition can proceed, allowing the validator to potentially recover by starting fresh consensus components for the new epoch.

## Proof of Concept

```rust
#[tokio::test]
async fn test_shutdown_with_dropped_receiver() {
    use futures::channel::oneshot;
    
    // Simulate the scenario
    let (close_tx, close_rx) = oneshot::channel::<oneshot::Sender<()>>();
    
    // Drop the receiver (simulating abnormal RoundManager termination)
    drop(close_rx);
    
    // Now attempt to send (this is what shutdown_current_processor does)
    let (ack_tx, _ack_rx) = oneshot::channel();
    let result = close_tx.send(ack_tx);
    
    // This will be Err because receiver was dropped
    assert!(result.is_err());
    
    // The actual code does .expect() which would panic here:
    // result.expect("[EpochManager] Fail to drop round manager"); // <- This panics
}
```

To trigger this in the actual system, one would need to:
1. Cause the RoundManager task to panic or terminate abnormally
2. Wait for or trigger an epoch transition
3. Observe the EpochManager panic in `shutdown_current_processor()`

**Notes:**

This is a **defensive programming failure** rather than a directly exploitable vulnerability. The issue is real and the code does panic when the receiver is dropped, as stated in the security question. However, triggering this requires an abnormal termination of the RoundManager task, which would typically indicate another underlying bug. The severity comes from the fact that it prevents recovery during critical epoch transitions and amplifies the impact of any RoundManager bugs.

### Citations

**File:** consensus/src/epoch_manager.rs (L544-569)
```rust
    async fn initiate_new_epoch(&mut self, proof: EpochChangeProof) -> anyhow::Result<()> {
        let ledger_info = proof
            .verify(self.epoch_state())
            .context("[EpochManager] Invalid EpochChangeProof")?;
        info!(
            LogSchema::new(LogEvent::NewEpoch).epoch(ledger_info.ledger_info().next_block_epoch()),
            "Received verified epoch change",
        );

        // shutdown existing processor first to avoid race condition with state sync.
        self.shutdown_current_processor().await;
        *self.pending_blocks.lock() = PendingBlocks::new();
        // make sure storage is on this ledger_info too, it should be no-op if it's already committed
        // panic if this doesn't succeed since the current processors are already shutdown.
        self.execution_client
            .sync_to_target(ledger_info.clone())
            .await
            .context(format!(
                "[EpochManager] State sync to new epoch {}",
                ledger_info
            ))
            .expect("Failed to sync to new epoch");

        monitor!("reconfig", self.await_reconfig_notification().await);
        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L638-647)
```rust
        if let Some(close_tx) = self.round_manager_close_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop round manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop round manager");
        }
```

**File:** consensus/src/epoch_manager.rs (L650-659)
```rust
        if let Some(close_tx) = self.dag_shutdown_tx.take() {
            // Release the previous RoundManager, especially the SafetyRule client
            let (ack_tx, ack_rx) = oneshot::channel();
            close_tx
                .send(ack_tx)
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop DAG bootstrapper");
        }
```

**File:** consensus/src/epoch_manager.rs (L993-1000)
```rust
        let (close_tx, close_rx) = oneshot::channel();
        self.round_manager_close_tx = Some(close_tx);
        tokio::spawn(round_manager.start(
            round_manager_rx,
            buffered_proposal_rx,
            opt_proposal_loopback_rx,
            close_rx,
        ));
```

**File:** consensus/src/round_manager.rs (L2072-2080)
```rust
        let mut close_rx = close_rx.into_stream();
        loop {
            tokio::select! {
                biased;
                close_req = close_rx.select_next_some() => {
                    if let Ok(ack_sender) = close_req {
                        ack_sender.send(()).expect("[RoundManager] Fail to ack shutdown");
                    }
                    break;
```

**File:** consensus/src/round_manager.rs (L2104-2111)
```rust
                            unexpected_event => unreachable!("Unexpected event {:?}", unexpected_event),
                        }
                    };
                    proposals.sort_by_key(get_round);
                    // If the first proposal is not for the next round, we only process the last proposal.
                    // to avoid going through block retrieval of many garbage collected rounds.
                    if self.round_state.current_round() + 1 < get_round(&proposals[0]) {
                        proposals = vec![proposals.pop().unwrap()];
```
