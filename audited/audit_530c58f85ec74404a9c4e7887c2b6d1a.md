# Audit Report

## Title
Protocol Encoding Mismatch in Reliable Broadcast Causing Consensus Degradation During Upgrades

## Summary
The reliable broadcast implementation creates a protocol negotiation mismatch by serializing messages using DirectSend protocol preferences but sending them via RPC protocol preferences. During rolling upgrades when validators support different protocol combinations, this causes messages serialized with plain BCS encoding to be tagged and transmitted with compressed BCS protocol identifiers, resulting in decompression failures and consensus slowdowns.

## Finding Description

The vulnerability exists in the interaction between serialization and transmission in the reliable broadcast mechanism used by consensus modules.

**Core Issue:**

`NetworkClient::to_bytes_by_protocol()` serializes messages by selecting protocols from `direct_send_protocols_and_preferences` [1](#0-0) , while `NetworkClient::send_to_peer_rpc_raw()` transmits messages by selecting protocols from `rpc_protocols_and_preferences` [2](#0-1) .

The reliable broadcast library exploits this by pre-serializing messages for all recipients using `to_bytes_by_protocol()` [3](#0-2) , then sending those pre-serialized bytes via `send_rb_rpc_raw()` [4](#0-3) .

**Protocol Configuration:**

JWK Consensus (and similar modules) maintain separate protocol preference lists [5](#0-4) :
- DirectSend: `[JWKConsensusDirectSendCompressed, JWKConsensusDirectSendBcs, JWKConsensusDirectSendJson]`
- RPC: `[JWKConsensusRpcCompressed, JWKConsensusRpcBcs, JWKConsensusRpcJson]`

**Encoding Differences:**

Protocol encodings are fundamentally different [6](#0-5) :
- `DirectSendBcs` → plain BCS encoding
- `RpcCompressed` → compressed BCS with LZ4

**Attack Scenario During Rolling Upgrade:**

1. Old validator supports: `[DirectSendBcs, RpcCompressed, RpcBcs]` (compression added to RPC first historically, as evidenced by protocol IDs 11 vs 12)
2. New validator has full protocol support with preferences ordering compressed first
3. When new validator multicasts to old validator:
   - `to_bytes_by_protocol()` checks DirectSend preferences, finds old validator supports `DirectSendBcs` → serializes plain BCS
   - `send_rpc_raw()` checks RPC preferences, finds old validator supports `RpcCompressed` → tags as compressed BCS
4. Old validator receives plain BCS bytes with `RpcCompressed` protocol tag
5. Deserialization attempts to decompress [7](#0-6) 
6. Decompression reads first 4 bytes as LZ4 size header [8](#0-7) , but plain BCS data has no such header
7. Decompression fails with error [9](#0-8) 

**Affected Modules:**

This pattern affects all reliable broadcast users:
- Consensus commit votes/decisions [10](#0-9) 
- JWK consensus updates [11](#0-10) 
- DKG transcript aggregation
- DAG consensus messages

## Impact Explanation

**HIGH Severity - Validator Node Slowdowns**

This vulnerability causes significant performance degradation affecting consensus during rolling upgrades:

1. **RPC Failures**: Decompression errors cause RPC calls to fail repeatedly
2. **Exponential Backoff**: Reliable broadcast retries failed RPCs with exponential backoff, accumulating delays
3. **Consensus Slowdowns**: Multiple validators with mismatched configurations create systemic delays in consensus message delivery
4. **Cascading Effects**: Affects critical paths including commit votes, JWK updates, and DAG messages

This aligns with the Aptos bug bounty HIGH severity category of "Validator node slowdowns" causing "significant performance degradation affecting consensus."

While the report mentions a theoretical Critical scenario (garbage data from valid size prefix), this is extremely unlikely as BCS-serialized data rarely has valid LZ4 headers in the first 4 bytes. The primary impact is HIGH severity performance degradation.

## Likelihood Explanation

**HIGH Likelihood During Protocol Upgrades**

This vulnerability triggers naturally during rolling upgrades without requiring any malicious behavior:

1. **Historical Protocol Evolution**: The protocol ID numbering (ConsensusRpcCompressed=11, ConsensusDirectSendCompressed=12) indicates compression was added to RPC protocols before DirectSend protocols
2. **Upgrade Scenarios**: When upgrading from versions with RpcCompressed but not DirectSendCompressed to versions with both, the mismatch triggers
3. **Multiple Validators**: During rolling upgrades, validators run different software versions simultaneously for hours or days
4. **Widespread Impact**: Affects multiple consensus subsystems (JWK, DKG, pipeline consensus, DAG)

This is not a theoretical vulnerability—it's a design flaw that manifests during normal operational upgrades.

## Recommendation

**Fix Option 1: Use Consistent Protocol Lists**

Modify reliable broadcast to use the same protocol preference list for both serialization and transmission:

```rust
// In ReliableBroadcast::multicast, use RPC protocols for serialization
let protocols = Arc::new(
    tokio::task::spawn_blocking(move || {
        // Change to use RPC-specific serialization
        sender.to_bytes_by_rpc_protocol(peers, message_clone)
    })
    .await??,
);
```

Add a new method to `RBNetworkSender`:
```rust
fn to_bytes_by_rpc_protocol(
    &self,
    peers: Vec<Author>,
    message: Req,
) -> anyhow::Result<HashMap<Author, Bytes>>;
```

**Fix Option 2: Tag Pre-Serialized Bytes with Protocol**

Store the protocol ID with each pre-serialized byte array and use it during transmission:

```rust
HashMap<Author, (ProtocolId, Bytes)>
```

Then in `send_rb_rpc_raw`, use the stored protocol ID instead of re-negotiating.

**Fix Option 3: Disable Pre-Serialization Optimization**

Remove the optimization and serialize separately for each RPC call, accepting the performance cost for correctness.

## Proof of Concept

Due to the complexity of setting up a multi-validator network with protocol version mismatches, a complete PoC would require:

1. Two validator nodes with different protocol support configurations
2. Triggering reliable broadcast from the newer validator to the older one
3. Observing decompression failures in logs

A simpler unit test demonstrating the mismatch:

```rust
#[test]
fn test_protocol_mismatch() {
    // Simulate old validator supporting DirectSendBcs + RpcCompressed
    let old_protocols = ProtocolIdSet::from([
        ProtocolId::JWKConsensusDirectSendBcs,
        ProtocolId::JWKConsensusRpcCompressed,
    ]);
    
    // New validator preferences
    let direct_send_prefs = vec![
        ProtocolId::JWKConsensusDirectSendCompressed,
        ProtocolId::JWKConsensusDirectSendBcs,
    ];
    let rpc_prefs = vec![
        ProtocolId::JWKConsensusRpcCompressed,
        ProtocolId::JWKConsensusRpcBcs,
    ];
    
    // Serialization selects DirectSendBcs (plain BCS)
    let serialize_protocol = select_protocol(&old_protocols, &direct_send_prefs);
    assert_eq!(serialize_protocol, ProtocolId::JWKConsensusDirectSendBcs);
    
    // Transmission selects RpcCompressed
    let send_protocol = select_protocol(&old_protocols, &rpc_prefs);
    assert_eq!(send_protocol, ProtocolId::JWKConsensusRpcCompressed);
    
    // This mismatch causes decompression to fail
    let msg = create_test_message();
    let serialized = serialize_protocol.to_bytes(&msg).unwrap(); // Plain BCS
    let result = send_protocol.from_bytes(&serialized); // Try to decompress
    assert!(result.is_err()); // Decompression fails!
}
```

**Notes**

This vulnerability demonstrates a subtle but critical design flaw where performance optimization (pre-serialization) conflicts with protocol negotiation logic. The separation of DirectSend and RPC protocol preferences, combined with reliable broadcast's optimization strategy, creates a protocol mismatch during the common operational scenario of rolling upgrades. While not a direct security exploit, it significantly impacts network availability and consensus performance during upgrades, meeting the HIGH severity threshold for validator node slowdowns.

### Citations

**File:** network/framework/src/application/interface.rs (L169-169)
```rust
                .get_preferred_protocol_for_peer(&peer, &self.direct_send_protocols_and_preferences)
```

**File:** network/framework/src/application/interface.rs (L282-282)
```rust
            self.get_preferred_protocol_for_peer(&peer, &self.rpc_protocols_and_preferences)?;
```

**File:** crates/reliable-broadcast/src/lib.rs (L131-135)
```rust
                tokio::task::spawn_blocking(move || {
                    sender.to_bytes_by_protocol(peers, message_clone)
                })
                .await??,
            );
```

**File:** crates/reliable-broadcast/src/lib.rs (L148-149)
```rust
                    } else if let Some(raw_message) = protocols.get(&receiver).cloned() {
                        network_sender.send_rb_rpc_raw(receiver, raw_message, rpc_timeout_duration)
```

**File:** crates/aptos-jwk-consensus/src/network_interface.rs (L15-26)
```rust
pub const DIRECT_SEND: &[ProtocolId] = &[
    ProtocolId::JWKConsensusDirectSendCompressed,
    ProtocolId::JWKConsensusDirectSendBcs,
    ProtocolId::JWKConsensusDirectSendJson,
];

/// Supported protocols in preferred order (from highest priority to lowest).
pub const RPC: &[ProtocolId] = &[
    ProtocolId::JWKConsensusRpcCompressed,
    ProtocolId::JWKConsensusRpcBcs,
    ProtocolId::JWKConsensusRpcJson,
];
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L156-172)
```rust
    fn encoding(self) -> Encoding {
        match self {
            ProtocolId::ConsensusDirectSendJson | ProtocolId::ConsensusRpcJson => Encoding::Json,
            ProtocolId::ConsensusDirectSendCompressed | ProtocolId::ConsensusRpcCompressed => {
                Encoding::CompressedBcs(RECURSION_LIMIT)
            },
            ProtocolId::ConsensusObserver => Encoding::CompressedBcs(RECURSION_LIMIT),
            ProtocolId::DKGDirectSendCompressed | ProtocolId::DKGRpcCompressed => {
                Encoding::CompressedBcs(RECURSION_LIMIT)
            },
            ProtocolId::JWKConsensusDirectSendCompressed
            | ProtocolId::JWKConsensusRpcCompressed => Encoding::CompressedBcs(RECURSION_LIMIT),
            ProtocolId::MempoolDirectSend => Encoding::CompressedBcs(USER_INPUT_RECURSION_LIMIT),
            ProtocolId::MempoolRpc => Encoding::Bcs(USER_INPUT_RECURSION_LIMIT),
            _ => Encoding::Bcs(RECURSION_LIMIT),
        }
    }
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L231-242)
```rust
        let result = match self.encoding() {
            Encoding::Bcs(limit) => self.bcs_decode(bytes, limit),
            Encoding::CompressedBcs(limit) => {
                let compression_client = self.get_compression_client();
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
                self.bcs_decode(&raw_bytes, limit)
            },
```

**File:** crates/aptos-compression/src/lib.rs (L156-180)
```rust
        return Err(DecompressionError(format!(
            "Compressed data must be at least 4 bytes long! Got: {}",
            compressed_data.len()
        )));
    }

    // Parse the size prefix
    let size = (compressed_data[0] as i32)
        | ((compressed_data[1] as i32) << 8)
        | ((compressed_data[2] as i32) << 16)
        | ((compressed_data[3] as i32) << 24);
    if size < 0 {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer must not be negative! Got: {}",
            size
        )));
    }

    // Ensure that the size is not greater than the max size limit
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
```

**File:** consensus/src/pipeline/commit_reliable_broadcast.rs (L153-161)
```rust
    fn to_bytes_by_protocol(
        &self,
        peers: Vec<Author>,
        message: CommitMessage,
    ) -> Result<HashMap<Author, bytes::Bytes>, anyhow::Error> {
        let msg = ConsensusMsg::CommitMessage(Box::new(message));
        self.consensus_network_client
            .to_bytes_by_protocol(peers, msg)
    }
```

**File:** crates/aptos-jwk-consensus/src/update_certifier.rs (L37-68)
```rust
    reliable_broadcast: Arc<ReliableBroadcast<JWKConsensusMsg, ExponentialBackoff>>,
}

impl UpdateCertifier {
    pub fn new(reliable_broadcast: ReliableBroadcast<JWKConsensusMsg, ExponentialBackoff>) -> Self {
        Self {
            reliable_broadcast: Arc::new(reliable_broadcast),
        }
    }
}

impl<ConsensusMode: TConsensusMode> TUpdateCertifier<ConsensusMode> for UpdateCertifier {
    fn start_produce(
        &self,
        epoch_state: Arc<EpochState>,
        payload: ProviderJWKs,
        qc_update_tx: aptos_channel::Sender<
            ConsensusMode::ConsensusSessionKey,
            QuorumCertifiedUpdate,
        >,
    ) -> anyhow::Result<AbortHandle> {
        ConsensusMode::log_certify_start(epoch_state.epoch, &payload);
        let rb = self.reliable_broadcast.clone();
        let epoch = epoch_state.epoch;
        let req = ConsensusMode::new_rb_request(epoch, &payload)
            .context("UpdateCertifier::start_produce failed at rb request construction")?;
        let agg_state = Arc::new(ObservationAggregationState::<ConsensusMode>::new(
            epoch_state,
            payload,
        ));
        let task = async move {
            let qc_update = rb.broadcast(req, agg_state).await.expect("cannot fail");
```
