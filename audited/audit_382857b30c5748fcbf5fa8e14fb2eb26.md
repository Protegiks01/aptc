Audit Report

## Title
StateMerklePruner Initialization Unbounded Batch Memory Exhaustion

## Summary
When a new `StateMerkleShardPruner` is initialized, it calls its `prune` method with `max_nodes_to_prune` set to `usize::MAX`. This causes it to accumulate and batch a potentially unbounded number of stale state nodes, potentially resulting in extreme memory usage or out-of-memory (OOM) crashes for a node with a large gap between its shard's progress and metadata progress.

## Finding Description
The constructor `StateMerkleShardPruner::new()` immediately calls `prune()` with `max_nodes_to_prune = usize::MAX` to "catch up" the shard. This causes a single batch to accumulate deletes for every prunable stale node between the shard's progress and the metadata progress. If the difference covers millions of versions, and each version creates many stale nodes, the batch may contain millions (or more) entries, using unbounded RAM. This violates resource limits and can crash the node through OOM during initialization (or, on large reorg/recovery, restart), breaking node liveness and availability invariants.

## Impact Explanation
**High Severity**: Repeated or targeted node resets, especially for slow or recovering nodes, can result in validator node crashes. Multiple crashing nodes can result in loss of network availability and possibly failed epoch transitions if quorum can't be maintained. All this occurs without needing privileged access or attacker intervention, and could affect both full nodes and validators with large storage or under heavy load.

## Likelihood Explanation
This issue is likely to occur whenever a pruner needs to catch up a large gap, which is common after restarts, backups, or historical replay, or in any scenario where shard progress lags behind metadata progress significantly.

## Recommendation
Replace the use of `usize::MAX` during initial catch-up with the configured, safe `batch_size` as used in normal pruning operations. Iteratively prune with bounded batches instead of attempting all deletions in a single batch.

## Proof of Concept
- Launch a node with pruning enabled, then "stall" a shard by simulating a replay, and accumulate millions of unpruned nodes (e.g., by manual DB modification).
- Restart the node. Observe memory usage spikes massively during initialization and the process is OOM-killed before startup is complete.

---

Citations: [1](#0-0) [2](#0-1) [3](#0-2) [4](#0-3) 

Notes:
- The critical call site is in the `StateMerkleShardPruner::new()` function, where `prune()` is called with `usize::MAX`.
- Normal operation uses a small, configurable batch size (default 1,000) for pruning to avoid memory issues.
- No protections exist on batch size during initialization catch-up, so risk is directly proportional to data accumulated and stale state delta.
- This is not an out-of-scope performance concern; it directly impacts validator and node availability.

### Citations

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L31-56)
```rust
    pub(in crate::pruner) fn new(
        shard_id: usize,
        db_shard: Arc<DB>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            &db_shard,
            &S::progress_metadata_key(Some(shard_id)),
            metadata_progress,
        )?;
        let myself = Self {
            shard_id,
            db_shard,
            _phantom: PhantomData,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up {} shard {shard_id}.",
            S::name(),
        );
        myself.prune(progress, metadata_progress, usize::MAX)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L58-100)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
        max_nodes_to_prune: usize,
    ) -> Result<()> {
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }

        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L191-218)
```rust
    pub(in crate::pruner::state_merkle_pruner) fn get_stale_node_indices(
        state_merkle_db_shard: &DB,
        start_version: Version,
        target_version: Version,
        limit: usize,
    ) -> Result<(Vec<StaleNodeIndex>, Option<Version>)> {
        let mut indices = Vec::new();
        let mut iter = state_merkle_db_shard.iter::<S>()?;
        iter.seek(&StaleNodeIndex {
            stale_since_version: start_version,
            node_key: NodeKey::new_empty_path(0),
        })?;

        let mut next_version = None;
        while indices.len() < limit {
            if let Some((index, _)) = iter.next().transpose()? {
                next_version = Some(index.stale_since_version);
                if index.stale_since_version <= target_version {
                    indices.push(index);
                    continue;
                }
            }
            break;
        }

        Ok((indices, next_version))
    }
}
```

**File:** config/src/config/storage_config.rs (L399-413)
```rust
    fn default() -> Self {
        StateMerklePrunerConfig {
            enable: true,
            // This allows a block / chunk being executed to have access to a non-latest state tree.
            // It needs to be greater than the number of versions the state committing thread is
            // able to commit during the execution of the block / chunk. If the bad case indeed
            // happens due to this being too small, a node restart should recover it.
            // Still, defaulting to 1M to be super safe.
            prune_window: 1_000_000,
            // A 10k transaction block (touching 60k state values, in the case of the account
            // creation benchmark) on a 4B items DB (or 1.33B accounts) yields 300k JMT nodes
            batch_size: 1_000,
        }
    }
}
```
