Based on my comprehensive investigation of the Aptos Core codebase, I need to make a final determination about this security claim.
> Searching codebase... [1](#0-0) [2](#0-1) [3](#0-2) [4](#0-3) [5](#0-4) [6](#0-5) [7](#0-6) [8](#0-7) [9](#0-8) 

---

**Notes:**

- The cited code confirms the vulnerability: when receiving state snapshot chunks in state sync, there is no input validation limiting the number of state entries per chunk. The only enforced limit is on the *sent* chunk size (4000 entries), not on the *received* chunksâ€”an attacker can send up to 1M entries if they fit within the 40MiB message size.
- The impact is Medium (state inconsistency / OOM crash requiring intervention), and the issue stems from *protocol-level resource validation*, not from a network-layer DoS (which would be out of scope).
- Affected nodes are those performing state sync. This is realistically exploitable by any connected peer.
- This breaks the resource invariant and is a valid Aptos Core security flaw needing remediation.

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L117-120)
```rust
        let kv_batch: StateValueBatch<K, Option<V>> = chunk
            .into_iter()
            .map(|(k, v)| ((k, self.version), Some(v)))
            .collect();
```

**File:** types/src/state_store/state_value.rs (L345-353)
```rust
pub struct StateValueChunkWithProof {
    pub first_index: u64,     // The first hashed state index in chunk
    pub last_index: u64,      // The last hashed state index in chunk
    pub first_key: HashValue, // The first hashed state key in chunk
    pub last_key: HashValue,  // The last hashed state key in chunk
    pub raw_values: Vec<(StateKey, StateValue)>, // The hashed state key and and raw state value.
    pub proof: SparseMerkleRangeProof, // The proof to ensure the chunk is in the hashed states
    pub root_hash: HashValue, // The root hash of the sparse merkle tree for this chunk
}
```

**File:** config/src/config/state_sync_config.rs (L21-21)
```rust
const SERVER_MAX_MESSAGE_SIZE_V2: usize = 40 * 1024 * 1024; // 40 MiB (used for v2 data requests)
```

**File:** config/src/config/state_sync_config.rs (L25-25)
```rust
const MAX_STATE_CHUNK_SIZE: u64 = 4000;
```

**File:** state-sync/storage-service/server/src/storage.rs (L909-911)
```rust
        let expected_num_state_values = inclusive_range_len(start_index, end_index)?;
        let max_num_state_values = self.config.max_state_chunk_size;
        let num_state_values_to_fetch = min(expected_num_state_values, max_num_state_values);
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L938-956)
```rust
        let expected_num_state_values = state_value_chunk_with_proof
            .last_index
            .checked_sub(state_value_chunk_with_proof.first_index)
            .and_then(|version| version.checked_add(1)) // expected_num_state_values = last_index - first_index + 1
            .ok_or_else(|| {
                Error::IntegerOverflow("The expected number of state values has overflown!".into())
            })?;
        let num_state_values = state_value_chunk_with_proof.raw_values.len() as u64;
        if expected_num_state_values != num_state_values {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::VerificationError(format!(
                "The expected number of state values was invalid! Expected: {:?}, received: {:?}",
                expected_num_state_values, num_state_values,
            )));
        }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L961-1060)
```rust
    /// Process a single state value chunk with proof payload
    async fn process_state_values_payload(
        &mut self,
        notification_id: NotificationId,
        state_value_chunk_with_proof: StateValueChunkWithProof,
    ) -> Result<(), Error> {
        // Verify that we're expecting state value payloads
        let bootstrapping_mode = self.get_bootstrapping_mode();
        if self.should_fetch_epoch_ending_ledger_infos() || !bootstrapping_mode.is_fast_sync() {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::InvalidPayload(
                "Received an unexpected state values payload!".into(),
            ));
        }

        // Fetch the target ledger info and transaction info for bootstrapping
        let ledger_info_to_sync = self.get_ledger_info_to_sync()?;
        let transaction_output_to_sync = self.get_transaction_output_to_sync()?;

        // Initialize the state value synchronizer (if not already done)
        if !self.state_value_syncer.initialized_state_snapshot_receiver {
            // Fetch all verified epoch change proofs
            let version_to_sync = ledger_info_to_sync.ledger_info().version();
            let epoch_change_proofs = if version_to_sync == GENESIS_TRANSACTION_VERSION {
                vec![ledger_info_to_sync.clone()] // Sync to genesis
            } else {
                self.verified_epoch_states.all_epoch_ending_ledger_infos() // Sync beyond genesis
            };

            // Initialize the state value synchronizer
            let _join_handle = self.storage_synchronizer.initialize_state_synchronizer(
                epoch_change_proofs,
                ledger_info_to_sync,
                transaction_output_to_sync.clone(),
            )?;
            self.state_value_syncer.initialized_state_snapshot_receiver = true;
        }

        // Verify the state values payload start and end indices
        self.verify_states_values_indices(notification_id, &state_value_chunk_with_proof)
            .await?;

        // Verify the chunk root hash matches the expected root hash
        let first_transaction_info = transaction_output_to_sync
            .get_output_list_with_proof()
            .proof
            .transaction_infos
            .first()
            .ok_or_else(|| {
                Error::UnexpectedError("Target transaction info does not exist!".into())
            })?;
        let expected_root_hash = first_transaction_info
            .ensure_state_checkpoint_hash()
            .map_err(|error| {
                Error::UnexpectedError(format!("State checkpoint must exist! Error: {:?}", error))
            })?;
        if state_value_chunk_with_proof.root_hash != expected_root_hash {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::VerificationError(format!(
                "The states chunk with proof root hash: {:?} didn't match the expected hash: {:?}!",
                state_value_chunk_with_proof.root_hash, expected_root_hash,
            )));
        }

        // Process the state values chunk and proof
        let last_state_value_index = state_value_chunk_with_proof.last_index;
        if let Err(error) = self
            .storage_synchronizer
            .save_state_values(notification_id, state_value_chunk_with_proof)
            .await
        {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::InvalidPayload(format!(
                "The states chunk with proof was invalid! Error: {:?}",
                error,
            )));
        }

        // Update the next state value index to process
        self.state_value_syncer.next_state_index_to_process =
            last_state_value_index.checked_add(1).ok_or_else(|| {
                Error::IntegerOverflow(
                    "The next state value index to process has overflown!".into(),
                )
            })?;

        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L412-440)
```rust
    async fn save_state_values(
        &mut self,
        notification_id: NotificationId,
        state_value_chunk_with_proof: StateValueChunkWithProof,
    ) -> Result<(), Error> {
        // Get the snapshot notifier and create the storage data chunk
        let state_snapshot_notifier = self.state_snapshot_notifier.as_mut().ok_or_else(|| {
            Error::UnexpectedError("The state snapshot receiver has not been initialized!".into())
        })?;
        let storage_data_chunk =
            StorageDataChunk::States(notification_id, state_value_chunk_with_proof);

        // Notify the snapshot receiver of the storage data chunk
        if let Err(error) = send_and_monitor_backpressure(
            state_snapshot_notifier,
            metrics::STORAGE_SYNCHRONIZER_STATE_SNAPSHOT_RECEIVER,
            storage_data_chunk,
        )
        .await
        {
            Err(Error::UnexpectedError(format!(
                "Failed to send storage data chunk to state snapshot listener: {:?}",
                error
            )))
        } else {
            increment_pending_data_chunks(self.pending_data_chunks.clone());
            Ok(())
        }
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L827-882)
```rust
fn spawn_state_snapshot_receiver<
    ChunkExecutor: ChunkExecutorTrait + 'static,
    MetadataStorage: MetadataStorageInterface + Clone + Send + Sync + 'static,
>(
    chunk_executor: Arc<ChunkExecutor>,
    mut state_snapshot_listener: mpsc::Receiver<StorageDataChunk>,
    mut commit_notification_sender: mpsc::UnboundedSender<CommitNotification>,
    error_notification_sender: mpsc::UnboundedSender<ErrorNotification>,
    pending_data_chunks: Arc<AtomicU64>,
    metadata_storage: MetadataStorage,
    storage: DbReaderWriter,
    epoch_change_proofs: Vec<LedgerInfoWithSignatures>,
    target_ledger_info: LedgerInfoWithSignatures,
    target_output_with_proof: TransactionOutputListWithProofV2,
    runtime: Option<Handle>,
) -> JoinHandle<()> {
    // Create a state snapshot receiver
    let receiver = async move {
        // Get the target version and expected root hash
        let version = target_ledger_info.ledger_info().version();
        let expected_root_hash = target_output_with_proof
            .get_output_list_with_proof()
            .proof
            .transaction_infos
            .first()
            .expect("Target transaction info should exist!")
            .ensure_state_checkpoint_hash()
            .expect("Must be at state checkpoint.");

        // Create the snapshot receiver
        let mut state_snapshot_receiver = storage
            .writer
            .get_state_snapshot_receiver(version, expected_root_hash)
            .expect("Failed to initialize the state snapshot receiver!");

        // Handle state value chunks
        while let Some(storage_data_chunk) = state_snapshot_listener.next().await {
            // Start the snapshot timer for the state value chunk
            let _timer = metrics::start_timer(
                &metrics::STORAGE_SYNCHRONIZER_LATENCIES,
                metrics::STORAGE_SYNCHRONIZER_STATE_VALUE_CHUNK,
            );

            // Commit the state value chunk
            match storage_data_chunk {
                StorageDataChunk::States(notification_id, states_with_proof) => {
                    // Commit the state value chunk
                    let all_states_synced = states_with_proof.is_last_chunk();
                    let last_committed_state_index = states_with_proof.last_index;
                    let num_state_values = states_with_proof.raw_values.len();

                    let result = state_snapshot_receiver.add_chunk(
                        states_with_proof.raw_values,
                        states_with_proof.proof.clone(),
                    );

```
