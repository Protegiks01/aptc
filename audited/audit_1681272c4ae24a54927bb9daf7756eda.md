# Audit Report

## Title
Memory Ordering Race Condition in Stall Mechanism Allowing Non-Deterministic Validator Behavior

## Summary
The `is_stalled()` function uses `Ordering::Relaxed` to read `num_stalls`, while `add_stall()` and `remove_stall()` use `Ordering::SeqCst` for atomic operations. This memory ordering mismatch creates a race condition where `is_stalled()` can observe stale values, causing the stall mechanism to make incorrect scheduling decisions and potentially leading to performance divergence between validators.

## Finding Description

The BlockSTMv2 scheduler implements a stall mechanism to reduce cascading transaction aborts during parallel execution. The mechanism tracks stall count via an `AtomicU32` called `num_stalls`, with the invariant that transactions with `num_stalls > 0` should not be scheduled for execution. [1](#0-0) 

The `is_stalled()` function reads this counter using `Ordering::Relaxed`, which provides no synchronization guarantees. However, the operations that modify `num_stalls` use `Ordering::SeqCst`: [2](#0-1) [3](#0-2) 

**The Race Condition:**

In Rust's memory model, `Relaxed` loads do not synchronize with `SeqCst` stores. This creates a race where:

1. Thread A calls `remove_stall()`: `fetch_sub(1, SeqCst)` decrements `num_stalls` from 1 to 0
2. Thread B calls `add_stall()`: `fetch_add(1, SeqCst)` increments `num_stalls` from 0 to 1
3. Thread A acquires the status lock
4. Thread A calls `is_stalled()` which performs `load(Relaxed)`
5. **Due to memory reordering, the Relaxed load observes the stale value (0) instead of the current value (1)**
6. Thread A incorrectly concludes the transaction is not stalled and proceeds with unstalling logic

This race manifests in three critical code paths:

**Path 1 - Incorrect Scheduling in `remove_stall()`:** [4](#0-3) 

If `is_stalled()` returns false due to the race, a stalled transaction gets added to the execution queue when it should remain deferred.

**Path 2 - Incorrect Dependency Status in `finish_execution()`:** [5](#0-4) 

The dependency status is set to `IsSafe` instead of `ShouldDefer`, signaling to other transactions that it's safe to read when the transaction is actually stalled.

**Path 3 - Incorrect Scheduling in `to_pending_scheduling()`:** [6](#0-5) 

Stalled transactions are added to the schedule instead of being deferred.

## Impact Explanation

**Severity: Medium**

This vulnerability falls under the **Medium** severity category: "State inconsistencies requiring intervention" from the Aptos bug bounty program.

**Why Not Critical/High:**
- Does NOT break consensus safety - the validation mechanism ensures all validators produce the same final state
- Does NOT cause fund loss or theft
- Does NOT allow direct attacker exploitation

**Why Medium:**
1. **Non-Deterministic Validator Behavior**: Different validators may observe different memory orderings, causing them to make different scheduling decisions for the same block
2. **Performance Divergence**: Some validators may waste significant computation re-executing stalled transactions while others correctly defer them
3. **Stall Mechanism Invariant Violation**: Breaks the documented invariant that stalled transactions should not be scheduled
4. **Cascading Effects**: The stall mechanism is designed to prevent cascading aborts; when it fails, expensive re-execution chains occur

While the stall mechanism is documented as "best-effort" [7](#0-6) , this doesn't justify race conditions in its implementation. The mechanism's internal state (stall counts) must still be maintained correctly.

## Likelihood Explanation

**Likelihood: Medium to High**

This race condition:
- Occurs naturally during normal block execution with concurrent transactions
- Has a narrow but real race window between atomic operations and subsequent checks
- Becomes more likely under high transaction volume where many threads execute concurrently
- Requires no attacker intervention - it's a non-deterministic bug that happens during regular operation
- Can affect any validator processing blocks with dependent transactions

The race is not exploitable by an attacker (memory ordering cannot be controlled externally), but it will occur probabilistically during normal validator operation, especially on machines with weaker memory ordering guarantees (ARM, POWER architectures).

## Recommendation

**Fix: Use Acquire Ordering in `is_stalled()`**

Change the memory ordering from `Relaxed` to `Acquire` to synchronize with the `SeqCst` stores in `add_stall()` and `remove_stall()`:

```rust
pub(crate) fn is_stalled(&self) -> bool {
    self.num_stalls.load(Ordering::Acquire) > 0
}
```

**Why Acquire is sufficient:**
- `Acquire` loads synchronize with `Release` and `SeqCst` stores
- Establishes a happens-before relationship ensuring visibility of prior writes
- Prevents the observed race condition while maintaining performance
- Minimal performance impact compared to Relaxed (typically same cost on x86-64)

**Alternative (more conservative):**
If stronger guarantees are desired, use `SeqCst` for the load as well, though `Acquire` is sufficient for correctness.

## Proof of Concept

The following Rust unit test demonstrates the race condition using mocked atomics (this is a conceptual PoC as true race conditions are timing-dependent):

```rust
#[cfg(test)]
mod race_condition_test {
    use super::*;
    use std::sync::Arc;
    use std::thread;
    use std::sync::atomic::{AtomicU32, Ordering};

    #[test]
    fn test_stall_race_condition() {
        // Simulate the race by showing how Relaxed load can see stale values
        let num_stalls = Arc::new(AtomicU32::new(1));
        
        // Thread 1: remove_stall equivalent
        let num_stalls_t1 = num_stalls.clone();
        let t1 = thread::spawn(move || {
            // fetch_sub returns previous value
            let prev = num_stalls_t1.fetch_sub(1, Ordering::SeqCst);
            assert_eq!(prev, 1); // num_stalls is now 0
            
            // Simulate acquiring lock and checking is_stalled
            // With Relaxed, this might see 0 even after Thread 2's add
            thread::sleep(std::time::Duration::from_micros(1));
            
            // This load with Relaxed can observe stale value
            let stalled = num_stalls_t1.load(Ordering::Relaxed) > 0;
            stalled
        });
        
        // Thread 2: add_stall equivalent
        let num_stalls_t2 = num_stalls.clone();
        let t2 = thread::spawn(move || {
            let prev = num_stalls_t2.fetch_add(1, Ordering::SeqCst);
            assert_eq!(prev, 0); // num_stalls is now 1
        });
        
        t2.join().unwrap();
        let stalled = t1.join().unwrap();
        
        // Final value should be 1 (stalled)
        assert_eq!(num_stalls.load(Ordering::SeqCst), 1);
        
        // But Thread 1's Relaxed load might have seen 0 (not stalled)
        // This demonstrates the race condition
        println!("Thread 1 saw stalled={}, actual value={}", 
                 stalled, num_stalls.load(Ordering::SeqCst));
    }
}
```

**Note**: This race is timing-dependent and may not manifest consistently. On architectures with stronger memory ordering (x86-64), it may be harder to observe than on ARM/POWER. The fix should be applied regardless of observability in tests.

### Citations

**File:** aptos-move/block-executor/src/scheduler_status.rs (L109-111)
```rust
   - Best-effort approach that allows flexibility in concurrency scenarios, but such that
     high-priority transactions may still be re-executed even in stalled state

```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L363-365)
```rust
    pub(crate) fn add_stall(&self, txn_idx: TxnIndex) -> Result<bool, PanicError> {
        let status = &self.statuses[txn_idx as usize];
        if status.num_stalls.fetch_add(1, Ordering::SeqCst) == 0 {
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L417-419)
```rust
    pub(crate) fn remove_stall(&self, txn_idx: TxnIndex) -> Result<bool, PanicError> {
        let status = &self.statuses[txn_idx as usize];
        let prev_num_stalls = status.num_stalls.fetch_sub(1, Ordering::SeqCst);
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L427-445)
```rust
        if prev_num_stalls == 1 {
            // Acquire write lock for (non-monitor) shortcut modifications.
            let status_guard = status.status_with_incarnation.lock();

            // num_stalls updates are not under the lock, so need to re-check (otherwise
            // a different add_stall might have already incremented the count).
            if status.is_stalled() {
                return Ok(false);
            }

            if let Some(incarnation) = status_guard.pending_scheduling() {
                if incarnation == 0 {
                    // Invariant due to scheduler logic: for a successful remove_stall there
                    // must have been an add_stall for incarnation 0, which is impossible.
                    return Err(code_invariant_error("0-th incarnation in remove_stall"));
                }
                self.execution_queue_manager
                    .add_to_schedule(incarnation == 1, txn_idx);
            } else if status_guard.is_executed() {
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L601-610)
```rust
                let new_status_flag = if status.is_stalled() {
                    DependencyStatus::ShouldDefer
                } else {
                    DependencyStatus::IsSafe
                };
                status.swap_dependency_status_any(
                    &[DependencyStatus::WaitForExecution],
                    new_status_flag,
                    "finish_execution",
                )?;
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L885-890)
```rust
        if add_to_schedule && !status.is_stalled() {
            // Need to schedule the transaction for re-execution. If stalled, then
            // scheduling is deferred to the remove_stall.
            self.execution_queue_manager
                .add_to_schedule(new_incarnation == 1, txn_idx);
        }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L959-961)
```rust
    pub(crate) fn is_stalled(&self) -> bool {
        self.num_stalls.load(Ordering::Relaxed) > 0
    }
```
