# Audit Report

## Title
Missing Client-Side Timeout in gRPC Network Service Causes Indefinite Validator Hang During Remote Execution

## Summary
The `send_message()` function in the gRPC network service client lacks timeout configuration, allowing unresponsive remote executor shards to cause the validator's outbound message handler to hang indefinitely. This blocks consensus block execution and prevents validator participation in the consensus protocol.

## Finding Description

The `GRPCNetworkMessageServiceClientWrapper` used for remote executor communication does not configure client-side RPC timeouts. When a validator is configured with remote executor shards for distributed block execution, an unresponsive remote executor can cause the sending validator to hang indefinitely.

**Vulnerable Code Path:** [1](#0-0) 

The gRPC channel is created without any timeout configuration on the `Endpoint`. [2](#0-1) 

The `send_message()` function awaits the RPC call without any timeout wrapper. If the remote server accepts the TCP connection but never responds to the gRPC request, this call hangs indefinitely.

**Execution Flow to Consensus Impact:**

1. During consensus block execution, if remote executor addresses are configured, the system uses `REMOTE_SHARDED_BLOCK_EXECUTOR`: [3](#0-2) 

2. The remote executor client sends execution commands via the `NetworkController`: [4](#0-3) 

3. The outbound handler processes messages sequentially in a loop: [5](#0-4) 

When `send_message()` hangs, the entire outbound handler loop is blocked, preventing any further messages from being sent. This blocks block execution, which prevents the validator from participating in consensus.

**Contrast with Consensus Network Layer:**

The Aptos consensus network layer properly implements mandatory timeouts for all RPC operations: [6](#0-5) 

However, the remote executor gRPC service does not use this framework and lacks equivalent timeout protection.

**Server-Side Timeout is Insufficient:**

While the server has a timeout configured: [7](#0-6) 

This only protects the server from slow clients, not the client from unresponsive servers. The client can hang indefinitely waiting for a response that never arrives.

## Impact Explanation

**Severity: High** - "Validator node slowdowns"

This vulnerability causes validator nodes to completely stop processing blocks when a remote executor shard becomes unresponsive. The impact includes:

1. **Loss of Consensus Participation**: The affected validator cannot execute blocks, vote on proposals, or participate in consensus rounds
2. **Validator Downtime**: The node remains hung until manually restarted
3. **No Automatic Recovery**: Unlike transient network errors that trigger reconnection, an indefinitely hanging RPC call provides no error signal to trigger recovery logic
4. **Cascading Effect**: If multiple validators use the same unresponsive remote executor, multiple validators could be affected simultaneously

The vulnerability meets the High severity criteria per Aptos bug bounty: "Validator node slowdowns" and "Significant protocol violations" (inability to participate in consensus).

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability can be triggered by:

1. **Operational Failures**: Remote executor shard crashes after accepting connection but before sending response
2. **Network Partitions**: Network issues that allow TCP connection but block RPC responses
3. **Resource Exhaustion**: Remote executor overloaded and unable to respond within reasonable time
4. **Malicious Remote Executors**: If remote executor infrastructure is compromised or malicious

The likelihood depends on deployment configuration:
- **Not exploitable** if validators use local execution only (default configuration)
- **Exploitable** if validators are configured with remote executor shards (which the codebase explicitly supports)

Given that the code path exists and is integrated into the main execution flow, deployments using this feature are vulnerable to both accidental failures and targeted attacks.

## Recommendation

Configure client-side timeouts for all gRPC operations. Modify the `get_channel()` function to add timeout configuration:

```rust
async fn get_channel(remote_addr: String) -> NetworkMessageServiceClient<Channel> {
    info!("Trying to connect to remote server at {:?}", remote_addr);
    let conn = tonic::transport::Endpoint::new(remote_addr)
        .unwrap()
        .timeout(std::time::Duration::from_millis(5000)) // Add timeout
        .connect_lazy();
    NetworkMessageServiceClient::new(conn).max_decoding_message_size(MAX_MESSAGE_SIZE)
}
```

Additionally, wrap the RPC call in `send_message()` with an explicit timeout:

```rust
pub async fn send_message(
    &mut self,
    sender_addr: SocketAddr,
    message: Message,
    mt: &MessageType,
) {
    let request = tonic::Request::new(NetworkMessage {
        message: message.data,
        message_type: mt.get_type(),
    });
    
    let timeout = tokio::time::Duration::from_millis(5000);
    match tokio::time::timeout(timeout, self.remote_channel.simple_msg_exchange(request)).await {
        Ok(Ok(_)) => {},
        Ok(Err(e)) => {
            panic!(
                "Error '{}' sending message to {} on node {:?}",
                e, self.remote_addr, sender_addr
            );
        },
        Err(_) => {
            panic!(
                "Timeout sending message to {} on node {:?}",
                self.remote_addr, sender_addr
            );
        },
    }
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_send_message_timeout_vulnerability() {
    use std::net::{IpAddr, Ipv4Addr, SocketAddr};
    use tokio::net::TcpListener;
    use std::time::Duration;
    
    // Start a malicious server that accepts connections but never responds
    let malicious_server_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), 0);
    let listener = TcpListener::bind(malicious_server_addr).await.unwrap();
    let server_addr = listener.local_addr().unwrap();
    
    tokio::spawn(async move {
        loop {
            // Accept connections but never send responses
            let (mut socket, _) = listener.accept().await.unwrap();
            tokio::spawn(async move {
                let mut buf = vec![0u8; 1024];
                // Read data but never respond - simulating hang
                let _ = socket.readable().await;
                let _ = socket.try_read(&mut buf);
                // Hang forever
                tokio::time::sleep(Duration::from_secs(3600)).await;
            });
        }
    });
    
    // Create client and attempt to send message
    let rt = tokio::runtime::Runtime::new().unwrap();
    let mut client = GRPCNetworkMessageServiceClientWrapper::new(&rt, server_addr);
    
    let client_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), 0);
    let message = Message::new(vec![1, 2, 3, 4]);
    let message_type = MessageType::new("test".to_string());
    
    // This call will hang indefinitely without timeout
    // In production, this blocks the entire outbound handler loop
    let start = std::time::Instant::now();
    tokio::select! {
        _ = client.send_message(client_addr, message, &message_type) => {
            panic!("Should not complete");
        }
        _ = tokio::time::sleep(Duration::from_secs(10)) => {
            let elapsed = start.elapsed();
            assert!(elapsed >= Duration::from_secs(10), 
                "Client hung for {} seconds, demonstrating indefinite hang vulnerability", 
                elapsed.as_secs());
        }
    }
}
```

## Notes

This vulnerability only affects validators configured to use remote executor shards for distributed block execution. Validators using the default local execution configuration are not affected. However, the existence of this code path in production and its integration into the consensus execution flow indicates it is a supported deployment option that requires proper timeout protection to ensure validator reliability and consensus participation.

### Citations

**File:** secure/net/src/grpc_network_service/mod.rs (L75-76)
```rust
        Server::builder()
            .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
```

**File:** secure/net/src/grpc_network_service/mod.rs (L132-138)
```rust
    async fn get_channel(remote_addr: String) -> NetworkMessageServiceClient<Channel> {
        info!("Trying to connect to remote server at {:?}", remote_addr);
        let conn = tonic::transport::Endpoint::new(remote_addr)
            .unwrap()
            .connect_lazy();
        NetworkMessageServiceClient::new(conn).max_decoding_message_size(MAX_MESSAGE_SIZE)
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L140-160)
```rust
    pub async fn send_message(
        &mut self,
        sender_addr: SocketAddr,
        message: Message,
        mt: &MessageType,
    ) {
        let request = tonic::Request::new(NetworkMessage {
            message: message.data,
            message_type: mt.get_type(),
        });
        // TODO: Retry with exponential backoff on failures
        match self.remote_channel.simple_msg_exchange(request).await {
            Ok(_) => {},
            Err(e) => {
                panic!(
                    "Error '{}' sending message to {} on node {:?}",
                    e, self.remote_addr, sender_addr
                );
            },
        }
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L261-267)
```rust
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
```

**File:** execution/executor-service/src/remote_executor_client.rs (L201-205)
```rust
            senders[shard_id]
                .lock()
                .unwrap()
                .send(Message::new(bcs::to_bytes(&execution_request).unwrap()))
                .unwrap();
```

**File:** secure/net/src/network_controller/outbound_handler.rs (L155-160)
```rust
                grpc_clients
                    .get_mut(remote_addr)
                    .unwrap()
                    .send_message(*socket_addr, msg, message_type)
                    .await;
            }
```

**File:** network/framework/src/protocols/rpc/mod.rs (L31-36)
```rust
//! ## Timeouts:
//!
//! Both inbound and outbound requests have mandatory timeouts. The tasks in the
//! async completion queues are each wrapped in a `timeout` future, which causes
//! the task to complete with an error if the task isn't fulfilled before the
//! deadline.
```
