# Audit Report

## Title
Configuration Mismatch Causes Out-of-Bounds Panic in Cross-Shard Messaging Leading to Total Node Liveness Loss

## Summary
A missing validation in the sharded execution system allows a configuration mismatch between `num_shards` (used for partitioning) and `remote_shard_addresses.len()` (used for network channels) to cause an out-of-bounds panic in `send_cross_shard_msg()`, resulting in immediate executor service crash and total loss of node liveness. [1](#0-0) 

## Finding Description

The vulnerability exists in the remote sharded execution architecture where two independent configuration parameters are not validated to match:

1. **Partitioning Configuration** (`num_shards`): Used by the block partitioner to determine how many shards to create, resulting in cross-shard dependencies with `shard_id` values from 0 to `num_shards-1`. [2](#0-1) 

2. **Network Configuration** (`remote_executor_addresses`): Used to create communication channels between shards in `RemoteCrossShardClient`, creating a `message_txs` vector with length equal to `remote_executor_addresses.len()`. [3](#0-2) 

**Attack Path:**

When `num_shards > remote_executor_addresses.len()` (e.g., num_shards=5, addresses.len()=3):

1. Block partitioner creates cross-shard dependencies with `shard_id` values 0-4 [4](#0-3) 

2. Dependencies are encoded in `ShardedTxnIndex` structures stored in transaction metadata [5](#0-4) 

3. During execution, `CrossShardCommitSender` sends remote updates to dependent shards [6](#0-5) 

4. When `dependent_shard_id` â‰¥ 3, the call to `send_cross_shard_msg(dependent_shard_id, ...)` accesses `message_txs[dependent_shard_id]` where the index exceeds the vector bounds

5. Rust's bounds checking triggers an immediate panic: `index out of bounds: the len is 3 but the index is 3`

6. The panic propagates unhandled, crashing the entire executor service process

**Broken Invariants:**
- **Deterministic Execution**: Nodes with different configurations produce different results (crash vs. execute)
- **Total Loss of Liveness**: Executor service cannot continue processing blocks
- **Missing Input Validation**: Critical configuration mismatch is not detected at startup

## Impact Explanation

**Critical Severity** - Total Loss of Liveness/Network Availability ($1,000,000 bounty category)

When triggered, this vulnerability causes:

1. **Immediate Node Crash**: The executor service panics and terminates, unable to process any further blocks
2. **Unrecoverable Without Restart**: Requires operator intervention to fix configuration and restart the process
3. **Shard-Wide Impact**: If multiple shards have the misconfiguration, all affected shards become unavailable
4. **Block Execution Failure**: Since sharded execution requires all shards to complete, a single shard crash prevents entire block execution

The impact qualifies as Critical because it results in **total loss of liveness** for affected nodes, matching the Aptos bug bounty criteria: "Total loss of liveness/network availability."

## Likelihood Explanation

**Likelihood: Medium to High** depending on deployment practices

The vulnerability can be triggered through:

1. **Operator Misconfiguration**: During initial setup or reconfiguration, operators may mistakenly provide mismatched parameters via command-line arguments [7](#0-6) 

2. **Configuration File Compromise**: If an attacker gains access to configuration files or deployment scripts, they could introduce the mismatch

3. **Deployment Script Errors**: Automated deployment tools that independently calculate `num_shards` and `remote_executor_addresses` could produce inconsistent values

The vulnerability is particularly dangerous because:
- No validation occurs at startup to detect the mismatch
- The error only manifests during block execution with cross-shard dependencies
- The panic message doesn't clearly indicate the root cause (configuration mismatch)

While it requires configuration access (limiting direct attacker exploitation), the lack of defensive validation makes this a critical robustness issue that can easily occur through operational errors.

## Recommendation

**Add Configuration Validation at Startup**

Add validation in `ExecutorService::new()` to ensure configuration consistency:

```rust
pub fn new(
    shard_id: ShardId,
    num_shards: usize,
    num_threads: usize,
    self_address: SocketAddr,
    coordinator_address: SocketAddr,
    remote_shard_addresses: Vec<SocketAddr>,
) -> Self {
    // VALIDATION: Ensure num_shards matches network configuration
    assert_eq!(
        num_shards, 
        remote_shard_addresses.len(),
        "Configuration mismatch: num_shards ({}) must equal remote_shard_addresses.len() ({})",
        num_shards,
        remote_shard_addresses.len()
    );
    
    assert!(
        shard_id < num_shards,
        "Configuration error: shard_id ({}) must be less than num_shards ({})",
        shard_id,
        num_shards
    );
    
    // ... rest of initialization
}
```

**Additional Defensive Measure**

Add bounds checking in `send_cross_shard_msg()` as a defense-in-depth measure:

```rust
fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
    assert!(
        shard_id < self.message_txs.len(),
        "Invalid shard_id: {} exceeds available channels ({})",
        shard_id,
        self.message_txs.len()
    );
    assert!(
        round < self.message_txs[shard_id].len(),
        "Invalid round: {} exceeds available rounds ({})",
        round,
        MAX_ALLOWED_PARTITIONING_ROUNDS
    );
    
    let input_message = bcs::to_bytes(&msg).unwrap();
    let tx = self.message_txs[shard_id][round].lock().unwrap();
    tx.send(Message::new(input_message)).unwrap();
}
```

## Proof of Concept

**Reproduction Steps:**

1. Start executor service with mismatched configuration:
```bash
# Terminal 1: Start shard 0 with num_shards=5 but only 3 addresses
./executor-service \
  --shard-id 0 \
  --num-shards 5 \
  --remote-executor-addresses 127.0.0.1:5000 127.0.0.1:5001 127.0.0.1:5002 \
  --coordinator-address 127.0.0.1:6000

# Terminal 2: Start shard 1
./executor-service \
  --shard-id 1 \
  --num-shards 5 \
  --remote-executor-addresses 127.0.0.1:5000 127.0.0.1:5001 127.0.0.1:5002 \
  --coordinator-address 127.0.0.1:6000
```

2. Submit a block for execution that creates cross-shard dependencies

3. When partitioner assigns transactions to shards 3 or 4, cross-shard dependencies are created with `shard_id=3` or `shard_id=4`

4. When shard 0, 1, or 2 executes and calls `send_cross_shard_msg(3, ...)` or `send_cross_shard_msg(4, ...)`:

**Expected Panic:**
```
thread 'sharded-executor-shard-0-1' panicked at 'index out of bounds: the len is 3 but the index is 3'
execution/executor-service/src/remote_cross_shard_client.rs:57:36
```

5. Executor service crashes, node becomes unavailable

**Alternative Rust Test:**
```rust
#[test]
#[should_panic(expected = "index out of bounds")]
fn test_cross_shard_msg_out_of_bounds() {
    let mut controller = NetworkController::new("test".to_string(), 
        "127.0.0.1:5000".parse().unwrap(), 1000);
    
    // Create client with only 3 shard addresses
    let shard_addresses = vec![
        "127.0.0.1:5001".parse().unwrap(),
        "127.0.0.1:5002".parse().unwrap(),
        "127.0.0.1:5003".parse().unwrap(),
    ];
    
    let client = RemoteCrossShardClient::new(&mut controller, shard_addresses);
    
    // Try to send message to shard 3 (out of bounds)
    client.send_cross_shard_msg(3, 0, CrossShardMsg::StopMsg); // PANIC!
}
```

## Notes

This vulnerability highlights a systemic issue in distributed system configuration management. While the immediate trigger requires configuration access (not directly exploitable by transaction senders), the lack of validation makes the system fragile and prone to operational errors. The severity is justified by the total loss of liveness impact, which aligns with Critical severity criteria in the Aptos bug bounty program.

### Citations

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L22-34)
```rust
    pub fn new(controller: &mut NetworkController, shard_addresses: Vec<SocketAddr>) -> Self {
        let mut message_txs = vec![];
        let mut message_rxs = vec![];
        // Create outbound channels for each shard per round.
        for remote_address in shard_addresses.iter() {
            let mut txs = vec![];
            for round in 0..MAX_ALLOWED_PARTITIONING_ROUNDS {
                let message_type = format!("cross_shard_{}", round);
                let tx = controller.create_outbound_channel(*remote_address, message_type);
                txs.push(Mutex::new(tx));
            }
            message_txs.push(txs);
        }
```

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L55-59)
```rust
    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
        let input_message = bcs::to_bytes(&msg).unwrap();
        let tx = self.message_txs[shard_id][round].lock().unwrap();
        tx.send(Message::new(input_message)).unwrap();
    }
```

**File:** execution/executor-service/src/main.rs (L17-21)
```rust
    #[clap(long)]
    pub num_shards: usize,

    #[clap(long, num_args = 1..)]
    pub remote_executor_addresses: Vec<SocketAddr>,
```

**File:** execution/block-partitioner/src/v2/build_edge.rs (L38-46)
```rust
                    (0..state.num_executor_shards)
                        .into_par_iter()
                        .for_each(|shard_id| {
                            let twds = state.finalized_txn_matrix[round_id][shard_id]
                                .par_iter()
                                .map(|&txn_idx1| {
                                    state.take_txn_with_dep(round_id, shard_id, txn_idx1)
                                })
                                .collect();
```

**File:** execution/block-partitioner/src/v2/state.rs (L337-344)
```rust
                    let dst_txn_idx = ShardedTxnIndex {
                        txn_index: *self.final_idxs_by_pre_partitioned
                            [follower_txn_idx.pre_partitioned_txn_idx]
                            .read()
                            .unwrap(),
                        shard_id: final_sub_blk_idx.shard_id,
                        round_id: final_sub_blk_idx.round_id,
                    };
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L115-130)
```rust
            if let Some(dependent_shard_ids) = edges.get(state_key) {
                for (dependent_shard_id, round_id) in dependent_shard_ids.iter() {
                    trace!("Sending remote update for success for shard id {:?} and txn_idx: {:?}, state_key: {:?}, dependent shard id: {:?}", self.shard_id, txn_idx, state_key, dependent_shard_id);
                    let message = RemoteTxnWriteMsg(RemoteTxnWrite::new(
                        state_key.clone(),
                        Some(write_op.clone()),
                    ));
                    if *round_id == GLOBAL_ROUND_ID {
                        self.cross_shard_client.send_global_msg(message);
                    } else {
                        self.cross_shard_client.send_cross_shard_msg(
                            *dependent_shard_id,
                            *round_id,
                            message,
                        );
                    }
```

**File:** execution/executor-service/src/process_executor_service.rs (L17-23)
```rust
    pub fn new(
        shard_id: ShardId,
        num_shards: usize,
        num_threads: usize,
        coordinator_address: SocketAddr,
        remote_shard_addresses: Vec<SocketAddr>,
    ) -> Self {
```
