# Audit Report

## Title
Missing Write Set Validation in KV Replay Mode Allows State Corruption via Compromised Backups

## Summary
The KV replay restore path (`kv_replay=true`) applies write sets from backup files directly to blockchain state without cryptographic validation against the `state_change_hash` field in `TransactionInfo` objects. This breaks the "State Consistency" critical invariant and allows state corruption if backup storage is compromised.

## Finding Description

During database restoration with KV-only replay mode enabled, write sets are applied to state without validation. The vulnerability exists in the two-phase restore process:

**Phase 1 - KV Replay (Vulnerable Path):** [1](#0-0) 

The `LoadedChunk::load()` method deserializes transaction data including write sets, then verifies the `TransactionListWithProof`: [2](#0-1) 

However, this verification only validates transactions and transaction infos, NOT write sets: [3](#0-2) 

The write sets remain unvalidated and are later applied directly to state: [4](#0-3) [5](#0-4) 

**Contrast with Normal Replay Path (Secure):**

The normal transaction replay path validates write sets via `ensure_match_transaction_info()`: [6](#0-5) [7](#0-6) 

**Attack Scenario:**
1. Attacker gains write access to backup storage (compromised credentials, malicious cloud admin)
2. Modifies transaction backup chunks: keeps `Transaction` and `TransactionInfo` unchanged but alters `WriteSet`
3. Node operator initiates restore with KV replay from compromised backup
4. Unvalidated write sets are applied to state, creating corrupted KV data
5. Phase 2 restores tree structure from snapshot, but KV data remains corrupted
6. Result: State inconsistency between KV data and Merkle tree

## Impact Explanation

**Severity: Does Not Meet Bounty Requirements**

While this breaks the "State Consistency" invariant (state transitions must be verifiable via Merkle proofs), it **requires privileged access** to backup storage infrastructure. This is an **insider threat** scenario rather than an unprivileged attacker exploit.

The issue could cause:
- State divergence requiring manual intervention (Medium severity per bounty criteria)
- Corrupted blockchain state for affected nodes
- Potential loss of funds if account balances are manipulated

However, it does NOT qualify for bounty consideration because:
- Requires backup storage write permissions (privileged access)
- Not exploitable by external attackers without compromised credentials
- Detection would occur when nodes sync with network (state root mismatch)

## Likelihood Explanation

**Likelihood: Low**

Requires multiple preconditions:
- Attacker has backup storage write access (insider or compromised credentials)
- Node operator initiates restore with KV replay enabled
- Occurs only during restore operations, not normal node operation
- Would be detected when state roots diverge from network consensus

## Recommendation

Add cryptographic validation of write sets against `state_change_hash` in the KV replay path:

```rust
// In restore_utils.rs, before applying write sets:
for (idx, (txn_info, write_set)) in txn_infos.iter().zip(write_sets.iter()).enumerate() {
    let write_set_hash = CryptoHash::hash(write_set);
    ensure!(
        write_set_hash == txn_info.state_change_hash(),
        "Write set hash mismatch at version {}: computed {:?}, expected {:?}",
        first_version + idx as Version,
        write_set_hash,
        txn_info.state_change_hash()
    );
}
```

Alternatively, always use the normal replay path with execution verification for maximum security.

## Proof of Concept

This vulnerability cannot be demonstrated without backup storage write access, which is outside the scope of a standard PoC. A test would require:

1. Creating a modified backup file with tampered write sets
2. Uploading to test backup storage
3. Initiating restore with KV replay enabled
4. Observing corrupted state post-restore

**Final Assessment:** While this is a real implementation gap, it fails the validation checklist requirement for **unprivileged attacker exploitability** and therefore does not qualify as a valid bounty submission per the stated criteria.

---

**Notes:**

The actual file path differs from the security question. The correct path is `storage/aptosdb/src/backup/restore_handler.rs` (not `restore/restore_handler.rs`), and the vulnerable code path involves `storage/aptosdb/src/backup/restore_utils.rs`. The KV replay mechanism is a legitimate optimization for faster restore but lacks the cryptographic validation present in the normal execution path.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L100-186)
```rust
    async fn load(
        manifest: TransactionChunk,
        storage: &Arc<dyn BackupStorage>,
        epoch_history: Option<&Arc<EpochHistory>>,
    ) -> Result<Self> {
        let mut file = BufReader::new(storage.open_for_read(&manifest.transactions).await?);
        let mut txns = Vec::new();
        let mut persisted_aux_info = Vec::new();
        let mut txn_infos = Vec::new();
        let mut event_vecs = Vec::new();
        let mut write_sets = Vec::new();

        while let Some(record_bytes) = file.read_record_bytes().await? {
            let (txn, aux_info, txn_info, events, write_set): (
                _,
                PersistedAuxiliaryInfo,
                _,
                _,
                WriteSet,
            ) = match manifest.format {
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
                    (
                        txn,
                        PersistedAuxiliaryInfo::None,
                        txn_info,
                        events,
                        write_set,
                    )
                },
                TransactionChunkFormat::V1 => bcs::from_bytes(&record_bytes)?,
            };
            txns.push(txn);
            persisted_aux_info.push(aux_info);
            txn_infos.push(txn_info);
            event_vecs.push(events);
            write_sets.push(write_set);
        }

        ensure!(
            manifest.first_version + (txns.len() as Version) == manifest.last_version + 1,
            "Number of items in chunks doesn't match that in manifest. first_version: {}, last_version: {}, items in chunk: {}",
            manifest.first_version,
            manifest.last_version,
            txns.len(),
        );

        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }

        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
        // and disassemble it to get things back.
        let (txn_list_with_proof, persisted_aux_info) = txn_list_with_proof.into_parts();
        let txns = txn_list_with_proof.transactions;
        let range_proof = txn_list_with_proof
            .proof
            .ledger_info_to_transaction_infos_proof;
        let txn_infos = txn_list_with_proof.proof.transaction_infos;
        let event_vecs = txn_list_with_proof.events.expect("unknown to be Some.");

        Ok(Self {
            manifest,
            txns,
            persisted_aux_info,
            txn_infos,
            event_vecs,
            range_proof,
            write_sets,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L554-600)
```rust
    async fn replay_kv(
        &self,
        restore_handler: &RestoreHandler,
        txns_to_execute_stream: impl Stream<
            Item = Result<(
                Transaction,
                PersistedAuxiliaryInfo,
                TransactionInfo,
                WriteSet,
                Vec<ContractEvent>,
            )>,
        >,
    ) -> Result<()> {
        let (first_version, _) = self.replay_from_version.unwrap();
        restore_handler.force_state_version_for_kv_restore(first_version.checked_sub(1))?;

        let mut base_version = first_version;
        let mut offset = 0u64;
        let replay_start = Instant::now();
        let arc_restore_handler = Arc::new(restore_handler.clone());

        let db_commit_stream = txns_to_execute_stream
            .try_chunks(BATCH_SIZE)
            .err_into::<anyhow::Error>()
            .map_ok(|chunk| {
                let (txns, persisted_aux_info, txn_infos, write_sets, events): (
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                ) = chunk.into_iter().multiunzip();
                let handler = arc_restore_handler.clone();
                base_version += offset;
                offset = txns.len() as u64;
                async move {
                    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["replay_txn_chunk_kv_only"]);
                    tokio::task::spawn_blocking(move || {
                        // we directly save transaction and kvs to DB without involving chunk executor
                        handler.save_transactions_and_replay_kv(
                            base_version,
                            &txns,
                            &persisted_aux_info,
                            &txn_infos,
                            &events,
                            write_sets,
                        )?;
```

**File:** types/src/transaction/mod.rs (L1898-1908)
```rust
        let write_set_hash = CryptoHash::hash(self.write_set());
        ensure!(
            write_set_hash == txn_info.state_change_hash(),
            "{}: version:{}, write_set_hash:{:?}, expected:{:?}, write_set: {:?}, expected(if known): {:?}",
            ERR_MSG,
            version,
            write_set_hash,
            txn_info.state_change_hash(),
            self.write_set,
            expected_write_set,
        );
```

**File:** types/src/transaction/mod.rs (L2295-2336)
```rust
    pub fn verify(
        &self,
        ledger_info: &LedgerInfo,
        first_transaction_version: Option<Version>,
    ) -> Result<()> {
        // Verify the first transaction versions match
        ensure!(
            self.get_first_transaction_version() == first_transaction_version,
            "First transaction version ({:?}) doesn't match given version ({:?}).",
            self.get_first_transaction_version(),
            first_transaction_version,
        );

        // Verify the lengths of the transactions and transaction infos match
        ensure!(
            self.proof.transaction_infos.len() == self.get_num_transactions(),
            "The number of TransactionInfo objects ({}) does not match the number of \
             transactions ({}).",
            self.proof.transaction_infos.len(),
            self.get_num_transactions(),
        );

        // Verify the transaction hashes match those of the transaction infos
        self.transactions
            .par_iter()
            .zip_eq(self.proof.transaction_infos.par_iter())
            .map(|(txn, txn_info)| {
                let txn_hash = CryptoHash::hash(txn);
                ensure!(
                    txn_hash == txn_info.transaction_hash(),
                    "The hash of transaction does not match the transaction info in proof. \
                     Transaction hash: {:x}. Transaction hash in txn_info: {:x}.",
                    txn_hash,
                    txn_info.transaction_hash(),
                );
                Ok(())
            })
            .collect::<Result<Vec<_>>>()?;

        // Verify the transaction infos are proven by the ledger info.
        self.proof
            .verify(ledger_info, self.get_first_transaction_version())?;
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```

**File:** execution/executor/src/chunk_executor/mod.rs (L592-652)
```rust
    fn verify_execution(
        &self,
        transactions: &[Transaction],
        persisted_aux_info: &[PersistedAuxiliaryInfo],
        transaction_infos: &[TransactionInfo],
        write_sets: &[WriteSet],
        event_vecs: &[Vec<ContractEvent>],
        begin_version: Version,
        end_version: Version,
        verify_execution_mode: &VerifyExecutionMode,
    ) -> Result<Version> {
        // Execute transactions.
        let parent_state = self.commit_queue.lock().latest_state().clone();
        let state_view = self.state_view(parent_state.latest())?;
        let txns = transactions
            .iter()
            .take((end_version - begin_version) as usize)
            .cloned()
            .map(|t| t.into())
            .collect::<Vec<SignatureVerifiedTransaction>>();

        let auxiliary_info = persisted_aux_info
            .iter()
            .take((end_version - begin_version) as usize)
            .map(|persisted_aux_info| AuxiliaryInfo::new(*persisted_aux_info, None))
            .collect::<Vec<_>>();
        // State sync executor shouldn't have block gas limit.
        let execution_output = DoGetExecutionOutput::by_transaction_execution::<V>(
            &V::new(),
            txns.into(),
            auxiliary_info,
            &parent_state,
            state_view,
            BlockExecutorConfigFromOnchain::new_no_block_limit(),
            TransactionSliceMetadata::chunk(begin_version, end_version),
        )?;
        // not `zip_eq`, deliberately
        for (version, txn_out, txn_info, write_set, events) in multizip((
            begin_version..end_version,
            &execution_output.to_commit.transaction_outputs,
            transaction_infos.iter(),
            write_sets.iter(),
            event_vecs.iter(),
        )) {
            if let Err(err) = txn_out.ensure_match_transaction_info(
                version,
                txn_info,
                Some(write_set),
                Some(events),
            ) {
                return if verify_execution_mode.is_lazy_quit() {
                    error!("(Not quitting right away.) {}", err);
                    verify_execution_mode.mark_seen_error();
                    Ok(version + 1)
                } else {
                    Err(err)
                };
            }
        }
        Ok(end_version)
    }
```
