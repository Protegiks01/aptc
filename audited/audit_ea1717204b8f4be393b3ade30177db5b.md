# Audit Report

## Title
Insufficient Version Continuity Validation in Cache Worker Batch Processing

## Summary
The indexer-grpc cache worker's version mismatch detection at lines 433-443 only validates the sum of transaction counts but fails to verify version continuity within chunks, allowing data gaps and overlaps to pass undetected if the fullnode sends malformed batches.

## Finding Description
The cache worker processes streaming transaction data from fullnodes in chunks. Each chunk increments `current_version` by the number of transactions in the array (`data.transactions.len()`), not by the actual version range covered. [1](#0-0) 

At batch completion, the only validation performed is: [2](#0-1) 

This check validates that `current_version == start_version + num_of_transactions`, which only verifies the **sum** of transaction counts, not whether the actual transaction versions are continuous, unique, or complete.

**Attack Scenario:** If a fullnode (due to bug, corruption, or compromise) sends:
- Chunk 1: versions 100-124 (25 transactions)
- Chunk 2: versions 110-134 (25 transactions, overlapping 110-124)
- Chunk 3: versions 135-159 (25 transactions)
- Chunk 4: versions 160-184 (25 transactions)
- BatchEnd: start_version=100, num_of_transactions=100

The validation would pass (current_version = 200 = 100 + 100), but the cache would contain:
- Duplicate data for versions 110-124
- Missing data for versions 125-134 and 185-199

**Contrast with Correct Implementation:** The data service has proper validation: [3](#0-2) 

The `ensure_sequential_transactions()` function properly detects gaps and panics, whereas the cache worker lacks equivalent checks.

## Impact Explanation
**Severity: Medium** - This is an indexer infrastructure data consistency issue, not a core blockchain vulnerability.

The impact is limited to the indexer cache layer:
- Downstream consumers (explorers, wallets, APIs) may query incomplete transaction data from cache
- Applications relying on indexer data could make incorrect decisions based on gaps
- However, the underlying blockchain state remains unaffected
- Data can be recovered from file store or direct blockchain queries

This does not qualify as Critical or High severity because:
- No consensus violation
- No validator operations affected  
- No blockchain state corruption
- No direct fund loss at protocol layer

## Likelihood Explanation
**Likelihood: Low to Medium**

The vulnerability requires:
1. Fullnode sending malformed batch data (bug, network corruption, or compromise)
2. Chunks containing overlapping or non-continuous versions
3. Sum of chunk lengths matching expected total

Under normal operation, fullnodes send correctly sorted, continuous transactions: [4](#0-3) 

However, bugs or network issues could trigger this condition.

## Recommendation
Implement version continuity validation similar to the data service's `ensure_sequential_transactions()`:

```rust
// After line 432 in worker.rs, add validation:
fn validate_chunk_continuity(
    chunks_received: &[(u64, u64)], // (first_version, last_version) pairs
    expected_start: u64,
    expected_count: u64,
) -> Result<()> {
    let mut sorted_chunks = chunks_received.to_vec();
    sorted_chunks.sort_by_key(|(first, _)| *first);
    
    let mut expected_next = expected_start;
    for (first, last) in sorted_chunks {
        if first != expected_next {
            bail!("Gap detected: expected version {}, got {}", expected_next, first);
        }
        expected_next = last + 1;
    }
    
    if expected_next != expected_start + expected_count {
        bail!("Version range mismatch");
    }
    Ok(())
}
```

Track chunk version ranges during processing and validate before accepting the batch.

## Proof of Concept
While a full PoC would require modifying fullnode behavior to send malformed batches, the vulnerability can be demonstrated by examining the code paths:

1. The worker accepts any chunks where array lengths sum correctly
2. No validation exists for version continuity
3. Redis updates would accept duplicate versions (last write wins)
4. The `update_cache_latest_version` Lua script detects gaps only AFTER the sum check passes

**Notes**

This finding represents a data consistency vulnerability in the **indexer infrastructure**, not the core Aptos blockchain protocol. While the validation logic is genuinely insufficient compared to best practices demonstrated elsewhere in the codebase (data service), the impact is limited to off-chain indexing services. The underlying blockchain consensus, execution, and state management remain unaffected.

The vulnerability meets the technical criteria (insufficient validation, potential for data inconsistency) but falls into the **Medium severity** category as it affects indexer data quality rather than blockchain security fundamentals. Applications should implement defense-in-depth by validating transaction continuity at their own layer and maintaining fallback data sources beyond the cache.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L395-404)
```rust
                GrpcDataStatus::ChunkDataOk {
                    num_of_transactions,
                    task,
                } => {
                    current_version += num_of_transactions;
                    transaction_count += num_of_transactions;
                    tps_calculator.tick_now(num_of_transactions);

                    tasks_to_run.push(task);
                },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L433-443)
```rust
                    if current_version != start_version + num_of_transactions {
                        error!(
                            current_version = current_version,
                            actual_current_version = start_version + num_of_transactions,
                            "[Indexer Cache] End signal received with wrong version."
                        );
                        ERROR_COUNT
                            .with_label_values(&["data_end_wrong_version"])
                            .inc();
                        break;
                    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L592-668)
```rust
fn ensure_sequential_transactions(mut batches: Vec<Vec<Transaction>>) -> Vec<Transaction> {
    // If there's only one, no sorting required
    if batches.len() == 1 {
        return batches.pop().unwrap();
    }

    // Sort by the first version per batch, ascending
    batches.sort_by(|a, b| a.first().unwrap().version.cmp(&b.first().unwrap().version));
    let first_version = batches.first().unwrap().first().unwrap().version;
    let last_version = batches.last().unwrap().last().unwrap().version;
    let mut transactions: Vec<Transaction> = vec![];

    let mut prev_start = None;
    let mut prev_end = None;
    for mut batch in batches {
        let mut start_version = batch.first().unwrap().version;
        let end_version = batch.last().unwrap().version;
        if let Some(prev_start) = prev_start {
            let prev_end = prev_end.unwrap();
            // If this batch is fully contained within the previous batch, skip it
            if prev_start <= start_version && prev_end >= end_version {
                NUM_MULTI_FETCH_OVERLAPPED_VERSIONS
                    .with_label_values(&[SERVICE_TYPE, "full"])
                    .inc_by(end_version - start_version);
                continue;
            }
            // If this batch overlaps with the previous batch, combine them
            if prev_end >= start_version {
                NUM_MULTI_FETCH_OVERLAPPED_VERSIONS
                    .with_label_values(&[SERVICE_TYPE, "partial"])
                    .inc_by(prev_end - start_version + 1);
                tracing::debug!(
                    batch_first_version = first_version,
                    batch_last_version = last_version,
                    start_version = start_version,
                    end_version = end_version,
                    prev_start = ?prev_start,
                    prev_end = prev_end,
                    "[Filestore] Overlapping version data"
                );
                batch.drain(0..(prev_end - start_version + 1) as usize);
                start_version = batch.first().unwrap().version;
            }

            // Otherwise there is a gap
            if prev_end + 1 != start_version {
                NUM_MULTI_FETCH_OVERLAPPED_VERSIONS
                    .with_label_values(&[SERVICE_TYPE, "gap"])
                    .inc_by(prev_end - start_version + 1);

                tracing::error!(
                    batch_first_version = first_version,
                    batch_last_version = last_version,
                    start_version = start_version,
                    end_version = end_version,
                    prev_start = ?prev_start,
                    prev_end = prev_end,
                    "[Filestore] Gaps or dupes in processing version data"
                );
                panic!("[Filestore] Gaps in processing data batch_first_version: {}, batch_last_version: {}, start_version: {}, end_version: {}, prev_start: {:?}, prev_end: {:?}",
                       first_version,
                       last_version,
                       start_version,
                       end_version,
                       prev_start,
                       prev_end,
                );
            }
        }

        prev_start = Some(start_version);
        prev_end = Some(end_version);
        transactions.extend(batch);
    }

    transactions
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L263-271)
```rust
        transactions_from_storage
            .into_iter()
            .flatten()
            .sorted_by(|a, b| a.version.cmp(&b.version))
            .map(|txn| {
                let size = bcs::serialized_size(&txn).expect("Unable to serialize txn");
                (txn, size)
            })
            .collect::<Vec<_>>()
```
