# Audit Report

## Title
State Snapshot Backup Creates Unverified Manifests Leading to Silent Backup Corruption

## Summary
The `StateSnapshotBackupController::write_manifest()` function obtains state root proofs from the backup service via `get_state_root_proof()` but writes them to the backup manifest without any cryptographic verification against the actual chunk data. This allows compromised or buggy backup services to produce invalid backups that will fail during restoration, breaking disaster recovery capabilities.

## Finding Description

The backup system violates the critical "trust but verify" security principle. During state snapshot backup, the system collects state data chunks and their corresponding Merkle proofs, then creates a manifest with a root hash. However, no verification occurs during backup creation. [1](#0-0) 

In the `write_manifest()` function, the code:
1. Obtains a state root proof from the backup service (line 454)
2. Deserializes it to extract the root hash (lines 455-456, 468)
3. Writes the manifest with this root hash without verification (lines 465-491)

The system performs NO verification that:
- The state root proof is valid
- The root hash matches what the chunks would compute to
- The chunk proofs obtained earlier match the manifest's root hash

This contrasts sharply with the restore process, which performs rigorous verification: [2](#0-1) 

During restoration, the proof IS verified against the ledger info and the root hash is checked for consistency (lines 127, 131-136).

The chunk proofs themselves should be verified using the `SparseMerkleRangeProof::verify()` method: [3](#0-2) 

But searching the entire backup code reveals zero verification calls: [4](#0-3) 

The `write_chunk()` function obtains chunk proofs (line 432) but never verifies them against the actual chunk data before writing.

**Attack Scenario:**

If a backup service is compromised (via vulnerability, misconfiguration, or malicious operator), it can:
1. Return correct state chunk data from version V1
2. Return incorrect proofs or root hash from version V2  
3. The backup CLI blindly writes this inconsistent data
4. The backup appears successful
5. When restoration is attempted, verification fails catastrophically

This breaks **Invariant #4: State Consistency** - "State transitions must be atomic and verifiable via Merkle proofs." While this doesn't affect live consensus, it undermines the disaster recovery system's integrity guarantees.

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty program:
- **State inconsistencies requiring intervention**: Invalid backups may not be detected until disaster recovery is needed, at which point restoration fails
- Does NOT meet Critical severity because:
  - Doesn't affect live consensus or validator operations
  - Doesn't enable fund theft or creation
  - Requires compromise of backup infrastructure (not unprivileged attack)
  - Doesn't cause network partition or liveness failure

The impact is primarily **operational availability** - if backups are needed after a catastrophic failure, corrupted backups could extend downtime significantly or require manual state reconstruction.

## Likelihood Explanation

**Likelihood: LOW to MEDIUM**

Requirements for exploitation:
1. Attacker compromises the backup service (requires validator infrastructure access)
2. OR attacker performs MITM attack on HTTP connection between backup CLI and service
3. Backup service returns tampered proofs without detection
4. Invalid backup is stored and potentially replicated across backup storage

This is more likely to occur through:
- Backup service software bugs (returning stale/incorrect proofs)
- Configuration errors causing service to return proofs from wrong versions
- Sophisticated targeted attacks on validator backup infrastructure

The likelihood is NOT high because the backup service typically runs on trusted validator infrastructure. However, defense-in-depth principles mandate verification even of "trusted" components.

## Recommendation

Implement cryptographic verification during backup creation. The manifest should only be written after verifying all proofs:

```rust
async fn write_manifest(
    &self,
    backup_handle: &BackupHandleRef,
    chunks: Vec<StateSnapshotChunk>,
) -> Result<FileHandle> {
    let proof_bytes = self.client.get_state_root_proof(self.version()).await?;
    let (txn_info, ledger_info): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
        bcs::from_bytes(&proof_bytes)?;
    
    // VERIFY the transaction info proof
    txn_info.verify(ledger_info.ledger_info(), self.version())?;
    
    let expected_root_hash = txn_info.transaction_info().ensure_state_checkpoint_hash()?;
    
    // VERIFY each chunk proof against expected root hash
    for chunk in &chunks {
        let chunk_proof: SparseMerkleRangeProof = 
            self.storage.load_bcs_file(&chunk.proof).await?;
        let chunk_data: Vec<(StateKey, StateValue)> = 
            self.load_chunk_data(&chunk.blobs).await?;
        
        // Verify the chunk proof produces the expected root hash
        self.verify_chunk_against_root(
            &chunk_data, 
            &chunk_proof, 
            expected_root_hash
        )?;
    }
    
    // Only write manifest if all verifications passed
    // ... rest of manifest writing code
}
```

The verification should construct the Merkle tree from chunk data and ensure it matches the root hash in the manifest.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    
    #[tokio::test]
    async fn test_backup_accepts_invalid_proof() {
        // Setup: Create a backup controller
        let (client, storage) = setup_test_backup_environment().await;
        let controller = StateSnapshotBackupController::new(
            test_opt(),
            test_global_opt(),
            Arc::new(client),
            Arc::new(storage),
        );
        
        // Attack: Mock backup service returns correct chunks but wrong proof
        let correct_chunks = generate_test_state_chunks();
        let wrong_proof = generate_proof_for_different_state();
        mock_backup_service_response(correct_chunks.clone(), wrong_proof);
        
        // Execute backup - should fail but currently succeeds
        let result = controller.run().await;
        
        // BUG: Backup succeeds with invalid proof
        assert!(result.is_ok(), "Backup should fail with invalid proof but succeeds");
        
        // Verification: Try to restore - this WILL fail
        let restore_result = attempt_restore_from_backup(result.unwrap()).await;
        assert!(restore_result.is_err(), "Restore fails due to invalid proof");
        
        // Expected: Backup should have failed during creation with verification error
    }
}
```

## Notes

While this vulnerability requires compromise of backup infrastructure (making it lower severity than pure protocol bugs), it represents a significant defense-in-depth failure. Cryptographic verification should occur at **every** trust boundary, including between the backup CLI and backup service, even when both run on trusted infrastructure.

The verification logic already exists in the restoration code path but is conspicuously absent from the backup code path, suggesting this was an oversight rather than a deliberate design decision.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L404-447)
```rust
    async fn write_chunk(
        &self,
        backup_handle: &BackupHandleRef,
        chunk: Chunk,
    ) -> Result<StateSnapshotChunk> {
        let _timer = BACKUP_TIMER.timer_with(&["state_snapshot_write_chunk"]);

        let Chunk {
            bytes,
            first_idx,
            last_idx,
            first_key,
            last_key,
        } = chunk;

        let (chunk_handle, mut chunk_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_name(first_idx))
            .await?;
        chunk_file.write_all(&bytes).await?;
        chunk_file.shutdown().await?;
        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_proof_name(first_idx, last_idx))
            .await?;
        tokio::io::copy(
            &mut self
                .client
                .get_account_range_proof(last_key, self.version())
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;

        Ok(StateSnapshotChunk {
            first_idx,
            last_idx,
            first_key,
            last_key,
            blobs: chunk_handle,
            proof: proof_handle,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L449-492)
```rust
    async fn write_manifest(
        &self,
        backup_handle: &BackupHandleRef,
        chunks: Vec<StateSnapshotChunk>,
    ) -> Result<FileHandle> {
        let proof_bytes = self.client.get_state_root_proof(self.version()).await?;
        let (txn_info, _): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            bcs::from_bytes(&proof_bytes)?;

        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(backup_handle, Self::proof_name())
            .await?;
        proof_file.write_all(&proof_bytes).await?;
        proof_file.shutdown().await?;

        let manifest = StateSnapshotBackup {
            epoch: self.epoch,
            version: self.version(),
            root_hash: txn_info.transaction_info().ensure_state_checkpoint_hash()?,
            chunks,
            proof: proof_handle,
        };

        let (manifest_handle, mut manifest_file) = self
            .storage
            .create_for_write(backup_handle, Self::manifest_name())
            .await?;
        manifest_file
            .write_all(&serde_json::to_vec(&manifest)?)
            .await?;
        manifest_file.shutdown().await?;

        let metadata = Metadata::new_state_snapshot_backup(
            self.epoch,
            self.version(),
            manifest_handle.clone(),
        );
        self.storage
            .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
            .await?;

        Ok(manifest_handle)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-139)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
        if let Some(epoch_history) = self.epoch_history.as_ref() {
            epoch_history.verify_ledger_info(&li)?;
        }
```

**File:** types/src/proof/definition.rs (L782-826)
```rust
    pub fn verify(
        &self,
        expected_root_hash: HashValue,
        rightmost_known_leaf: SparseMerkleLeafNode,
        left_siblings: Vec<HashValue>,
    ) -> Result<()> {
        let num_siblings = left_siblings.len() + self.right_siblings.len();
        let mut left_sibling_iter = left_siblings.iter();
        let mut right_sibling_iter = self.right_siblings().iter();

        let mut current_hash = rightmost_known_leaf.hash();
        for bit in rightmost_known_leaf
            .key()
            .iter_bits()
            .rev()
            .skip(HashValue::LENGTH_IN_BITS - num_siblings)
        {
            let (left_hash, right_hash) = if bit {
                (
                    *left_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing left sibling."))?,
                    current_hash,
                )
            } else {
                (
                    current_hash,
                    *right_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing right sibling."))?,
                )
            };
            current_hash = SparseMerkleInternalNode::new(left_hash, right_hash).hash();
        }

        ensure!(
            current_hash == expected_root_hash,
            "{}: Root hashes do not match. Actual root hash: {:x}. Expected root hash: {:x}.",
            type_name::<Self>(),
            current_hash,
            expected_root_hash,
        );

        Ok(())
    }
```
