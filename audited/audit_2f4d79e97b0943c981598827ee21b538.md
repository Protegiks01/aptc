# Audit Report

## Title
Indexer gRPC Service: Retry Amplification DoS via Deeply Nested Transaction Filters Without Rate Limiting

## Summary
The indexer gRPC services lack rate limiting for failed transaction filter parsing requests, allowing clients to repeatedly send deeply nested filters that trigger expensive recursive parsing and validation operations, causing service degradation through computational resource exhaustion.

## Finding Description

The `parse_transaction_filter()` function in the indexer gRPC services validates transaction filters but lacks protection against retry amplification attacks. [1](#0-0) 

The vulnerability exists because:

1. **No Rate Limiting**: When filter parsing fails in the live data service, the code simply logs the error, increments a counter, and continues accepting new requests without any backoff or rate limiting. [2](#0-1) 

2. **Recursive Parsing Without Individual Limits**: The filter parsing uses a top-level size check, but nested filter conversions recursively call `new_from_proto()` with `None` for the size limit, allowing arbitrary recursion depth within the overall size budget. [3](#0-2) 

3. **Expensive Validation**: Each filter validation recursively traverses the entire tree and performs JSON serialization at every level for error tracing. [4](#0-3) 

4. **Protobuf Schema Allows Deep Nesting**: The `BooleanTransactionFilter` message allows self-referential nesting via the `logical_not` field, enabling filters with thousands of nesting levels within the default 10KB size limit. [5](#0-4) 

5. **Default Size Limit Insufficient**: The default limit is 10,000 bytes, which allows approximately 3,000+ levels of nesting when using minimal `LogicalNot` wrappers. [6](#0-5) 

**Attack Path:**
1. Attacker crafts a deeply nested filter: `NOT(NOT(NOT(...NOT(simple_filter)...)))` with ~3000 levels
2. Filter passes the 10KB size check but triggers expensive recursive parsing
3. Attacker sends this filter repeatedly (e.g., 100 requests/second)
4. Server CPU is consumed by recursive parsing, validation, and JSON serialization
5. Legitimate clients experience degraded service or timeouts

The same vulnerability exists in the historical data service [7](#0-6)  and localnet service [8](#0-7) .

## Impact Explanation

This is a **Medium Severity** issue per the Aptos bug bounty criteria because it causes service degradation of critical indexer infrastructure without affecting core blockchain operations. While the indexer services are auxiliary components that don't directly impact consensus or state integrity, they are essential for:
- Block explorers querying transaction data
- Wallets tracking user transactions
- Analytics platforms monitoring network activity
- Dapp backends accessing blockchain state

The computational cost amplification means a single attacker can degrade service for all legitimate users. However, this does not affect validator operations, consensus safety, or blockchain state consistency.

## Likelihood Explanation

**High Likelihood** - This attack is trivial to execute:
- No authentication bypass required
- Any client can send gRPC requests to public indexer endpoints
- Crafting deeply nested filters requires minimal effort
- No special tools or infrastructure needed
- Attack can be automated and sustained
- No existing protections prevent repeated malicious requests

The absence of rate limiting makes this immediately exploitable against any deployed indexer gRPC service.

## Recommendation

Implement multi-layered defense:

1. **Add Per-Client Rate Limiting**: Implement token bucket rate limiting at the gRPC handler level, tracking failed parse attempts per client IP/identifier. Reject requests from clients exceeding thresholds (e.g., 10 failed parses per minute).

2. **Add Recursion Depth Limit**: Enforce a maximum nesting depth (e.g., 50 levels) during filter parsing:
   ```rust
   pub fn new_from_proto(
       proto_filter: aptos_protos::indexer::v1::BooleanTransactionFilter,
       max_filter_size: Option<usize>,
       max_depth: usize,  // Add depth parameter
   ) -> Result<Self> {
       if max_depth == 0 {
           return Err(anyhow!("Maximum filter nesting depth exceeded"));
       }
       // ... existing size check ...
       // Pass max_depth - 1 to recursive calls
   }
   ```

3. **Optimize Validation**: Remove or optimize JSON serialization in the validation path, as it's expensive and only used for error messages.

4. **Add Request Metrics**: Track and alert on high rates of filter parse failures, indicating potential attacks.

5. **Consider gRPC Interceptors**: Implement tonic interceptors for centralized rate limiting before request handlers execute.

## Proof of Concept

```rust
// Rust test demonstrating expensive parsing of deeply nested filters
#[test]
fn test_deeply_nested_filter_dos() {
    use aptos_protos::indexer::v1::{BooleanTransactionFilter as ProtoFilter, TransactionRootFilter};
    use aptos_transaction_filter::BooleanTransactionFilter;
    use std::time::Instant;
    
    // Create a base filter
    let mut filter = ProtoFilter {
        filter: Some(aptos_protos::indexer::v1::boolean_transaction_filter::Filter::ApiFilter(
            aptos_protos::indexer::v1::ApiFilter {
                filter: Some(aptos_protos::indexer::v1::api_filter::Filter::TransactionRootFilter(
                    TransactionRootFilter { success: Some(true), transaction_type: None }
                ))
            }
        ))
    };
    
    // Wrap in 1000 levels of LogicalNot
    for _ in 0..1000 {
        filter = ProtoFilter {
            filter: Some(aptos_protos::indexer::v1::boolean_transaction_filter::Filter::LogicalNot(
                Box::new(filter)
            ))
        };
    }
    
    // Measure parsing time
    let start = Instant::now();
    let result = BooleanTransactionFilter::new_from_proto(filter.clone(), Some(10_000));
    let duration = start.elapsed();
    
    println!("Parsing took: {:?}", duration);
    println!("Filter size: {} bytes", filter.encoded_len());
    
    // Now measure validation time if parsing succeeded
    if let Ok(parsed_filter) = result {
        let start = Instant::now();
        let _ = parsed_filter.is_valid();
        let duration = start.elapsed();
        println!("Validation took: {:?}", duration);
    }
    
    // Simulate repeated requests
    let start = Instant::now();
    for _ in 0..100 {
        let _ = BooleanTransactionFilter::new_from_proto(filter.clone(), Some(10_000));
    }
    let duration = start.elapsed();
    println!("100 parse attempts took: {:?}", duration);
}
```

## Notes

This vulnerability specifically affects the indexer gRPC services, which are auxiliary data access services rather than core consensus or execution components. While the issue doesn't directly impact blockchain security invariants (consensus safety, state integrity, etc.), it can degrade the availability of critical infrastructure that applications depend on for accessing blockchain data.

The attack exploits the combination of: (1) recursive filter parsing without depth limits, (2) expensive validation with JSON serialization, and (3) absence of rate limiting on failed requests. Any one of the recommended mitigations would significantly reduce the attack surface.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/filter_utils.rs (L9-15)
```rust
pub fn parse_transaction_filter(
    proto_filter: aptos_protos::indexer::v1::BooleanTransactionFilter,
    max_filter_size_bytes: usize,
) -> Result<BooleanTransactionFilter, Status> {
    BooleanTransactionFilter::new_from_proto(proto_filter, Some(max_filter_size_bytes))
        .map_err(|e| Status::invalid_argument(format!("Invalid transaction_filter: {e:?}.")))
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L98-115)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["live_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
                    }
                } else {
                    None
                };
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L265-276)
```rust
impl TryFrom<aptos_protos::indexer::v1::LogicalAndFilters> for LogicalAnd {
    type Error = anyhow::Error;

    fn try_from(proto_filter: aptos_protos::indexer::v1::LogicalAndFilters) -> Result<Self> {
        Ok(Self {
            and: proto_filter
                .filters
                .into_iter()
                .map(|f| BooleanTransactionFilter::new_from_proto(f, None))
                .collect::<Result<_>>()?,
        })
    }
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/traits.rs (L29-39)
```rust
    #[inline]
    fn is_valid(&self) -> Result<(), FilterError> {
        // T
        self.validate_state().map_err(|mut e| {
            e.add_trace(
                serde_json::to_string(self).unwrap(),
                std::any::type_name::<Self>().to_string(),
            );
            e
        })
    }
```

**File:** protos/proto/aptos/indexer/v1/filter.proto (L58-65)
```text
message BooleanTransactionFilter {
  oneof filter {
      APIFilter api_filter = 1;
      LogicalAndFilters logical_and = 2;
      LogicalOrFilters logical_or = 3;
      BooleanTransactionFilter logical_not = 4;
  }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L20-21)
```rust
// Default maximum size in bytes for transaction filters.
pub const DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES: usize = 10_000;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L83-96)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["historical_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/localnet_data_service.rs (L64-68)
```rust
        let filter = if let Some(proto_filter) = r.transaction_filter {
            Some(parse_transaction_filter(
                proto_filter,
                self.service_context.max_transaction_filter_size_bytes,
            )?)
```
