# Audit Report

## Title
Out-of-Bounds Array Access in DKG Transcript Verification Causing Validator Node DoS

## Summary
A missing chunk size validation in the DKG transcript verification code allows malicious validators to craft transcripts with oversized chunk vectors, causing out-of-bounds array access that crashes validator nodes during epoch transitions.

## Finding Description
The DKG (Distributed Key Generation) protocol uses chunked secret sharing where scalars are split into multiple chunks. During transcript verification in `weighted_transcript.rs`, the code iterates through chunk vectors and accesses a pre-computed array `pp.powers_of_radix` without validating that chunk vectors don't exceed the expected size. [1](#0-0) 

The `powers_of_radix` array is initialized with exactly `num_chunks_per_scalar(pp.ell)` elements: [2](#0-1) 

However, during deserialization, there is no validation that chunk vectors in `Cs` have the correct size: [3](#0-2) 

The existing validation only checks outer array dimensions (number of players), not individual chunk vector sizes: [4](#0-3) 

The range proof verification checks the total chunk count but not per-vector sizes: [5](#0-4) 

**Attack Path:**
1. Malicious validator creates a DKG transcript where some chunk vectors contain more than `num_chunks_per_scalar(pp.ell)` elements (e.g., 20 chunks instead of 16 for BLS12-381 with ell=16)
2. To pass the range proof total count check, attacker balances by making other chunk vectors shorter
3. Other validators receive and deserialize the transcript successfully
4. During verification, the pairing equation computation attempts to access `pp.powers_of_radix[j]` where `j >= powers_of_radix.len()`
5. Validator node panics with out-of-bounds error, crashing the verification process

This breaks the **Consensus Safety** invariant by preventing validators from completing DKG, blocking epoch transitions and causing liveness failures.

## Impact Explanation
**Severity: High** (Validator node crashes, liveness impact)

While this doesn't directly cause consensus safety violations or fund loss, it creates a severe liveness attack during DKG:
- Any malicious validator can broadcast invalid transcripts
- All honest validators crash when verifying these transcripts
- DKG cannot complete, preventing epoch transitions
- Network availability is compromised until the issue is patched

This meets **High Severity** criteria: "Validator node slowdowns/crashes" and "Significant protocol violations."

## Likelihood Explanation
**Likelihood: High**

- Exploitable by any validator participating in DKG (no special privileges required beyond being a validator)
- Attack is trivial to execute (just create oversized chunk vectors)
- No rate limiting or detection mechanisms exist
- Attack surface is exposed during every epoch transition
- Deterministic crash makes it highly effective

## Recommendation
Add explicit chunk size validation during transcript deserialization or early in verification:

```rust
// In weighted_transcript.rs verify() function, after line 153:
let expected_chunks_per_scalar = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;
for (i, Cs_player) in self.subtrs.Cs.iter().enumerate() {
    for (j, chunk_vec) in Cs_player.iter().enumerate() {
        if chunk_vec.len() != expected_chunks_per_scalar {
            bail!(
                "Player {} share {} has {} chunks, expected {}",
                i,
                j,
                chunk_vec.len(),
                expected_chunks_per_scalar
            );
        }
    }
}
```

Additionally, validate Rs vectors have consistent sizes:

```rust
for (i, R_vec) in self.subtrs.Rs.iter().enumerate() {
    if R_vec.len() != expected_chunks_per_scalar {
        bail!(
            "Randomness vector {} has {} chunks, expected {}",
            i,
            R_vec.len(),
            expected_chunks_per_scalar
        );
    }
}
```

## Proof of Concept

```rust
// This PoC demonstrates how a malicious transcript triggers the crash
#[test]
#[should_panic(expected = "index out of bounds")]
fn test_oversized_chunks_cause_panic() {
    use crate::pvss::chunky::{weighted_transcript::*, public_parameters::*, keys::*};
    use aptos_crypto::weighted_config::WeightedConfigArkworks;
    use ark_bls12_381::{Bls12_381, Fr};
    
    // Setup normal parameters
    let mut rng = rand::thread_rng();
    let ell = 16u8;
    let max_aggregation = 100;
    let num_players = 4;
    
    // Create config and public parameters
    let sc = WeightedConfigArkworks::<Fr>::new(/* ... */);
    let pp = PublicParameters::<Bls12_381>::new(ell, max_aggregation, &mut rng);
    
    // Create malicious transcript with oversized chunk vectors
    let expected_chunks = num_chunks_per_scalar::<Fr>(ell) as usize; // e.g., 16
    let malicious_chunks = expected_chunks + 4; // 20 chunks instead of 16
    
    let mut transcript = Transcript::<Bls12_381>::generate(&sc, &pp, &mut rng);
    
    // Modify first player's first share to have oversized chunk vector
    transcript.subtrs.Cs[0][0] = vec![G1Projective::rand(&mut rng); malicious_chunks];
    
    // Compensate in total count to pass range proof (make other vectors shorter)
    transcript.subtrs.Cs[1][0] = vec![G1Projective::rand(&mut rng); expected_chunks - 4];
    
    // Generate encryption keys
    let eks: Vec<EncryptPubKey<Bls12_381>> = (0..num_players)
        .map(|_| EncryptPubKey::generate(&mut rng))
        .collect();
    
    // This will panic at line 258 when j=16 but powers_of_radix.len()=16
    let _ = transcript.verify(&sc, &pp, &[], &eks, &"test_session");
    // Panic: index out of bounds: the len is 16 but the index is 16
}
```

## Notes
While the security question specifically mentioned the projection closure in `hkzg_chunked_elgamal_commit.rs`, the actual vulnerability exists in the related verification code in `weighted_transcript.rs`. The projection closure itself does not directly cause out-of-bounds reads, but the lack of chunk size validation throughout the DKG verification pipeline creates this critical DoS vulnerability. The `weighted_transcriptv2.rs` implementation does not have this specific bug as it uses a different verification approach without the problematic pairing equation computation.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L102-109)
```rust
impl<E: Pairing> TryFrom<&[u8]> for Subtranscript<E> {
    type Error = CryptoMaterialError;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        bcs::from_bytes::<Subtranscript<E>>(bytes)
            .map_err(|_| CryptoMaterialError::DeserializationError)
    }
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L140-153)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L193-200)
```rust
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L255-262)
```rust
        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/public_parameters.rs (L35-40)
```rust
fn compute_powers_of_radix<E: Pairing>(ell: u8) -> Vec<E::ScalarField> {
    utils::powers(
        E::ScalarField::from(1u64 << ell),
        num_chunks_per_scalar::<E::ScalarField>(ell) as usize,
    )
}
```
