# Audit Report

## Title
State Corruption in sync_for_duration() Error Handling Leads to Consensus Inconsistency

## Summary
When `sync_for_duration()` returns a `StateSyncError`, the validator's state is NOT rolled back to a consistent state. Instead, partially committed data remains in storage while consensus metadata (logical time, rand/buffer managers) reflects the pre-sync state, creating a dangerous inconsistency that violates consensus safety invariants.

## Finding Description

The vulnerability exists in the error handling path of `sync_for_duration()` across multiple components. Unlike `sync_to_target()` which explicitly guarantees "In case of failure the LI of storage remains unchanged", `sync_for_duration()` has no such atomicity guarantee. [1](#0-0) 

The attack sequence:

1. **Incremental Chunk Commits**: State sync processes chunks incrementally, committing each to storage as it arrives. The committer processes chunks one-by-one through the pipeline: [2](#0-1) 

2. **Error After Partial Commits**: If chunks 1-3 are successfully committed to storage but chunk 4 triggers an error (invalid proof, network timeout, malformed data), state sync returns `StateSyncError`. [3](#0-2) 

3. **Unconditional Executor Reset**: In `ExecutionProxy::sync_for_duration()`, the executor cache is ALWAYS reset via `executor.reset()` regardless of success or failure, loading whatever data exists in storage (including the partially committed chunks): [4](#0-3) 

4. **Incomplete State Updates**: The logical time is only updated on success (line 159-163), and rand/buffer managers are only reset on success in the calling layer: [5](#0-4) 

**Result**: The validator enters an inconsistent state where:
- Storage contains partially synced data (version 100 â†’ 103)
- Executor cache reflects version 103
- Logical time still at version 100
- Rand/buffer managers at version 100

When consensus resumes, it believes it's at version 100 but attempts to execute using an executor positioned at version 103, causing:
- Attempts to re-execute already-committed transactions
- Version mismatch assertions
- Divergent validator states (different validators fail at different chunks)
- **Consensus safety violations** when validators have different committed states

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

1. **Consensus Safety Violation**: Different validators experiencing errors at different points will have divergent states, potentially leading to chain splits or double-spending if validators disagree on what transactions have been committed.

2. **State Inconsistency Requiring Intervention**: Affected validators cannot recover automatically - their storage is ahead of their consensus state, requiring manual intervention or node restart with state wipe.

3. **Validator Node Dysfunction**: Subsequent block execution will fail due to version mismatches, causing validators to fall out of consensus and potentially lose rewards.

This breaks the critical invariant: "State transitions must be atomic and verifiable" and "All validators must produce identical state roots for identical blocks."

## Likelihood Explanation

**High Likelihood**:

1. **Natural Network Conditions**: Transient network errors, peer disconnections, or timeouts during long sync operations naturally trigger this path.

2. **Malicious Peer Attack**: An attacker can deliberately send valid chunks followed by invalid data to trigger errors, forcing validators into inconsistent states without requiring validator compromise.

3. **No Special Privileges Required**: Any network peer providing state sync data can trigger this, making it accessible to external attackers.

4. **Common Operation**: Consensus observer fallback mode and validator catch-up both use `sync_for_duration()`, making this a frequently-executed code path. [6](#0-5) 

## Recommendation

Implement atomic commit semantics for `sync_for_duration()` similar to `sync_to_target()`:

1. **Add Transaction-Level Atomicity**: Buffer all chunks until the sync duration completes or a ledger info boundary is reached, then commit atomically.

2. **Add Rollback on Error**: If an error occurs mid-sync, rollback any uncommitted chunks and ensure storage remains at the pre-sync version.

3. **Fix Reset Logic**: Only call `executor.reset()` if the sync succeeds:

```rust
async fn sync_for_duration(
    &self,
    duration: Duration,
) -> Result<LedgerInfoWithSignatures, StateSyncError> {
    let mut latest_logical_time = self.write_mutex.lock().await;
    
    self.executor.finish();
    
    let result = self.state_sync_notifier.sync_for_duration(duration).await;
    
    // Only reset and update if successful
    if let Ok(latest_synced_ledger_info) = &result {
        let ledger_info = latest_synced_ledger_info.ledger_info();
        let synced_logical_time = LogicalTime::new(ledger_info.epoch(), ledger_info.round());
        *latest_logical_time = synced_logical_time;
        
        // Reset executor to reflect new committed state
        self.executor.reset()?;
    }
    // On error, DON'T reset - executor remains in pre-sync state
    
    result.map_err(|error| {
        let anyhow_error: anyhow::Error = error.into();
        anyhow_error.into()
    })
}
```

4. **Document Guarantee**: Add explicit documentation matching `sync_to_target()`: "In case of failure, storage remains unchanged and the validator can assume no modifications were made."

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_sync_for_duration_partial_commit_corruption() {
    // Setup: Initialize validator at version 100
    let (executor, storage, state_sync_notifier) = setup_test_components().await;
    let execution_proxy = ExecutionProxy::new(
        executor.clone(),
        txn_notifier,
        state_sync_notifier.clone(),
        txn_filter_config,
        false,
        None,
    );
    
    // Attacker: Provide valid chunks 1-3, then invalid chunk 4
    let mut state_sync_mock = state_sync_notifier.clone();
    state_sync_mock.set_chunks(vec![
        valid_chunk(101, 102),  // Commits successfully
        valid_chunk(102, 103),  // Commits successfully  
        valid_chunk(103, 104),  // Commits successfully
        invalid_chunk(104),     // Triggers error
    ]);
    
    // Trigger sync_for_duration
    let result = execution_proxy.sync_for_duration(Duration::from_secs(30)).await;
    
    // Verify: Error is returned
    assert!(result.is_err());
    
    // BUG: Storage is at version 103 (partial commits succeeded)
    let storage_version = storage.get_latest_version().unwrap();
    assert_eq!(storage_version, 103);
    
    // BUG: Executor cache reflects version 103 (reset was called)
    let executor_committed_block = executor.committed_block_id();
    assert_eq!(get_version_for_block(executor_committed_block), 103);
    
    // BUG: Logical time still at version 100 (not updated on error)
    // Consensus will attempt to execute from version 100, but storage is at 103
    // This causes: version mismatch errors, potential double-execution, 
    // and consensus divergence across validators
    
    // Expected: All components should be at version 100 after error
}
```

## Notes

This vulnerability is particularly dangerous because:

1. **Silent Corruption**: No error is logged about the inconsistent state - the error is returned but the corruption remains.

2. **Cascading Failures**: Once in this state, the validator cannot recover through normal operations and may experience repeated failures.

3. **Network-Wide Impact**: If multiple validators hit this during the same sync window, they may end up with different partial states, leading to consensus divergence.

4. **Differs from sync_to_target**: The codebase explicitly documents atomicity for `sync_to_target()` but `sync_for_duration()` lacks this guarantee, suggesting this may be an oversight rather than intentional design.

### Citations

**File:** consensus/src/state_replication.rs (L28-37)
```rust
    async fn sync_for_duration(
        &self,
        duration: Duration,
    ) -> Result<LedgerInfoWithSignatures, StateSyncError>;

    /// Best effort state synchronization to the given target LedgerInfo.
    /// In case of success (`Result::Ok`) the LI of storage is at the given target.
    /// In case of failure (`Result::Error`) the LI of storage remains unchanged, and the validator
    /// can assume there were no modifications to the storage made.
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError>;
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L691-780)
```rust
fn spawn_committer<ChunkExecutor: ChunkExecutorTrait + 'static>(
    chunk_executor: Arc<ChunkExecutor>,
    error_notification_sender: mpsc::UnboundedSender<ErrorNotification>,
    mut committer_listener: mpsc::Receiver<NotificationMetadata>,
    mut commit_post_processor_notifier: mpsc::Sender<ChunkCommitNotification>,
    pending_data_chunks: Arc<AtomicU64>,
    runtime: Option<Handle>,
    storage: Arc<dyn DbReader>,
) -> JoinHandle<()> {
    // Create a committer
    let committer = async move {
        while let Some(notification_metadata) = committer_listener.next().await {
            // Start the commit timer
            let _timer = metrics::start_timer(
                &metrics::STORAGE_SYNCHRONIZER_LATENCIES,
                metrics::STORAGE_SYNCHRONIZER_COMMIT_CHUNK,
            );

            // Commit the executed chunk
            let result = commit_chunk(chunk_executor.clone()).await;

            // Notify the commit post-processor of the committed chunk
            match result {
                Ok(notification) => {
                    // Log the successful commit
                    info!(
                        LogSchema::new(LogEntry::StorageSynchronizer).message(&format!(
                            "Committed a new transaction chunk! \
                                    Transaction total: {:?}, event total: {:?}",
                            notification.committed_transactions.len(),
                            notification.subscribable_events.len()
                        ))
                    );

                    // Update the synced version metrics
                    utils::update_new_synced_metrics(
                        storage.clone(),
                        notification.committed_transactions.len(),
                    );

                    // Update the synced epoch metrics
                    let reconfiguration_occurred = notification.reconfiguration_occurred;
                    utils::update_new_epoch_metrics(storage.clone(), reconfiguration_occurred);

                    // Update the metrics for the data notification commit post-process latency
                    metrics::observe_duration(
                        &metrics::DATA_NOTIFICATION_LATENCIES,
                        metrics::NOTIFICATION_CREATE_TO_COMMIT_POST_PROCESS,
                        notification_metadata.creation_time,
                    );

                    // Notify the commit post-processor of the committed chunk
                    if let Err(error) = send_and_monitor_backpressure(
                        &mut commit_post_processor_notifier,
                        metrics::STORAGE_SYNCHRONIZER_COMMIT_POST_PROCESSOR,
                        notification,
                    )
                    .await
                    {
                        // Send an error notification to the driver (we failed to notify the commit post-processor)
                        let error = format!(
                            "Failed to notify the commit post-processor! Error: {:?}",
                            error
                        );
                        handle_storage_synchronizer_error(
                            notification_metadata,
                            error,
                            &error_notification_sender,
                            &pending_data_chunks,
                        )
                        .await;
                    }
                },
                Err(error) => {
                    // Send an error notification to the driver (we failed to commit the chunk)
                    let error = format!("Failed to commit executed chunk! Error: {:?}", error);
                    handle_storage_synchronizer_error(
                        notification_metadata,
                        error,
                        &error_notification_sender,
                        &pending_data_chunks,
                    )
                    .await;
                },
            };
        }
    };

    // Spawn the committer
    spawn(runtime, committer)
```

**File:** execution/executor/src/chunk_executor/mod.rs (L261-288)
```rust
    fn commit_chunk_impl(&self) -> Result<ExecutedChunk> {
        let _timer = CHUNK_OTHER_TIMERS.timer_with(&["commit_chunk_impl__total"]);
        let chunk = {
            let _timer =
                CHUNK_OTHER_TIMERS.timer_with(&["commit_chunk_impl__next_chunk_to_commit"]);
            self.commit_queue.lock().next_chunk_to_commit()?
        };

        let output = chunk.output.expect_complete_result();
        let num_txns = output.num_transactions_to_commit();
        if chunk.ledger_info_opt.is_some() || num_txns != 0 {
            let _timer = CHUNK_OTHER_TIMERS.timer_with(&["commit_chunk_impl__save_txns"]);
            // TODO(aldenhu): remove since there's no practical strategy to recover from this error.
            fail_point!("executor::commit_chunk", |_| {
                Err(anyhow::anyhow!("Injected error in commit_chunk"))
            });
            self.db.writer.save_transactions(
                output.as_chunk_to_commit(),
                chunk.ledger_info_opt.as_ref(),
                false, // sync_commit
            )?;
        }

        let _timer = CHUNK_OTHER_TIMERS.timer_with(&["commit_chunk_impl__dequeue_and_return"]);
        self.commit_queue.lock().dequeue_committed()?;

        Ok(chunk)
    }
```

**File:** consensus/src/state_computer.rs (L132-174)
```rust
    async fn sync_for_duration(
        &self,
        duration: Duration,
    ) -> Result<LedgerInfoWithSignatures, StateSyncError> {
        // Grab the logical time lock
        let mut latest_logical_time = self.write_mutex.lock().await;

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by the BlockExecutor to prevent a memory leak.
        self.executor.finish();

        // Inject an error for fail point testing
        fail_point!("consensus::sync_for_duration", |_| {
            Err(anyhow::anyhow!("Injected error in sync_for_duration").into())
        });

        // Invoke state sync to synchronize for the specified duration. Here, the
        // ChunkExecutor will process chunks and commit to storage. However, after
        // block execution and commits, the internal state of the ChunkExecutor may
        // not be up to date. So, it is required to reset the cache of the
        // ChunkExecutor in state sync when requested to sync.
        let result = monitor!(
            "sync_for_duration",
            self.state_sync_notifier.sync_for_duration(duration).await
        );

        // Update the latest logical time
        if let Ok(latest_synced_ledger_info) = &result {
            let ledger_info = latest_synced_ledger_info.ledger_info();
            let synced_logical_time = LogicalTime::new(ledger_info.epoch(), ledger_info.round());
            *latest_logical_time = synced_logical_time;
        }

        // Similarly, after state synchronization, we have to reset the cache of
        // the BlockExecutor to guarantee the latest committed state is up to date.
        self.executor.reset()?;

        // Return the result
        result.map_err(|error| {
            let anyhow_error: anyhow::Error = error.into();
            anyhow_error.into()
        })
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L642-659)
```rust
    async fn sync_for_duration(
        &self,
        duration: Duration,
    ) -> Result<LedgerInfoWithSignatures, StateSyncError> {
        fail_point!("consensus::sync_for_duration", |_| {
            Err(anyhow::anyhow!("Injected error in sync_for_duration").into())
        });

        // Sync for the specified duration
        let result = self.execution_proxy.sync_for_duration(duration).await;

        // Reset the rand and buffer managers to the new synced round
        if let Ok(latest_synced_ledger_info) = &result {
            self.reset(latest_synced_ledger_info).await?;
        }

        result
    }
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L117-187)
```rust
    pub fn sync_for_fallback(&mut self) {
        // Log that we're starting to sync in fallback mode
        info!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Started syncing in fallback mode! Syncing duration: {:?} ms!",
                self.consensus_observer_config.observer_fallback_duration_ms
            ))
        );

        // Update the state sync fallback counter
        metrics::increment_counter_without_labels(&metrics::OBSERVER_STATE_SYNC_FALLBACK_COUNTER);

        // Clone the required components for the state sync task
        let consensus_observer_config = self.consensus_observer_config;
        let execution_client = self.execution_client.clone();
        let sync_notification_sender = self.state_sync_notification_sender.clone();

        // Spawn a task to sync for the fallback
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(
            async move {
                // Update the state sync metrics now that we're syncing for the fallback
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    1, // We're syncing for the fallback
                );

                // Get the fallback duration
                let fallback_duration =
                    Duration::from_millis(consensus_observer_config.observer_fallback_duration_ms);

                // Sync for the fallback duration
                let latest_synced_ledger_info = match execution_client
                    .clone()
                    .sync_for_duration(fallback_duration)
                    .await
                {
                    Ok(latest_synced_ledger_info) => latest_synced_ledger_info,
                    Err(error) => {
                        error!(LogSchema::new(LogEntry::ConsensusObserver)
                            .message(&format!("Failed to sync for fallback! Error: {:?}", error)));
                        return;
                    },
                };

                // Notify consensus observer that we've synced for the fallback
                let state_sync_notification =
                    StateSyncNotification::fallback_sync_completed(latest_synced_ledger_info);
                if let Err(error) = sync_notification_sender.send(state_sync_notification) {
                    error!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to send state sync notification for fallback! Error: {:?}",
                            error
                        ))
                    );
                }

                // Clear the state sync metrics now that we're done syncing
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    0, // We're no longer syncing for the fallback
                );
            },
            abort_registration,
        ));

        // Save the sync task handle
        self.fallback_sync_handle = Some(DropGuard::new(abort_handle));
    }
```
