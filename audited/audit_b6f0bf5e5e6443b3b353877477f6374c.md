# Audit Report

## Title
Database Shard Inconsistency: Missing Recovery for persisted_auxiliary_info_db Leads to Permanent Cross-Shard State Corruption

## Summary
The parallel database commit mechanism in `calculate_and_commit_ledger_and_state_kv()` writes to seven separate databases without cross-database atomicity guarantees. A power loss or crash during these operations can leave `persisted_auxiliary_info_db` with orphaned data that is never cleaned up during recovery, causing permanent database inconsistency that persists across restarts and can lead to consensus disagreements between validators. [1](#0-0) 

## Finding Description

### The Parallel Write Problem

When committing transactions, `calculate_and_commit_ledger_and_state_kv()` spawns seven parallel threads that write to separate RocksDB instances (when sharding is enabled):

1. `event_db` - stores contract events
2. `write_set_db` - stores state changes  
3. `transaction_db` - stores raw transactions
4. `persisted_auxiliary_info_db` - stores transaction replay information
5. `state_kv` + `ledger_metadata` - stores state key-values and metadata
6. `transaction_info_db` - stores transaction metadata
7. `transaction_accumulator_db` - stores accumulator data [2](#0-1) 

Each individual database write is atomic within its own RocksDB instance, but there is **no cross-database transaction** spanning all seven databases. The code explicitly acknowledges this limitation with a TODO comment: [3](#0-2) 

### The Recovery Gap

When a node restarts after a crash, `sync_commit_progress()` is called to detect and repair database inconsistencies. It reads the authoritative `overall_commit_progress` and truncates databases back to that version: [4](#0-3) 

The recovery mechanism calls `truncate_ledger_db()`, which in turn calls `truncate_ledger_db_single_batch()` to clean up the ledger databases: [5](#0-4) 

### Critical Missing Truncation

The `delete_per_version_data()` function explicitly handles truncation for:
- `TransactionAccumulatorRootHashSchema`
- `TransactionInfoSchema` 
- `TransactionSchema` (transaction_db)
- `VersionDataSchema`
- `WriteSetSchema` (write_set_db) [6](#0-5) 

Event data is handled separately: [7](#0-6) 

**However, `PersistedAuxiliaryInfoSchema` is completely missing from the truncation logic.** The `persisted_auxiliary_info_db` database uses version-keyed storage: [8](#0-7) 

Yet it is never truncated during recovery, despite being written in parallel with other databases: [9](#0-8) 

### Exploitation Scenario

1. **Normal Commit**: Node is committing transactions 101-110
2. **Crash During Parallel Writes**: Power loss occurs after `persisted_auxiliary_info_db` has been updated to version 110, but before `overall_commit_progress` is updated. Other databases only reached version 105.
3. **Restart and Recovery**: 
   - `overall_commit_progress` = 105
   - Recovery truncates all databases to version 105
   - **Except `persisted_auxiliary_info_db` still has data for versions 106-110**
4. **Permanent Inconsistency**: The database is now permanently inconsistent with orphaned auxiliary info data that has no corresponding transactions in other databases.
5. **Consensus Impact**: Different validators experiencing crashes at different times will have different sets of orphaned data, leading to non-deterministic behavior when reading transaction data.

## Impact Explanation

**Critical Severity** - This vulnerability meets multiple Critical severity criteria:

1. **Consensus Safety Violation**: Different validators will have different database states after experiencing crashes, violating the fundamental invariant that "all validators must produce identical state roots for identical blocks." When validators query transaction auxiliary info, they may get different results depending on what orphaned data exists.

2. **Non-Recoverable State Inconsistency**: The orphaned data persists permanently across restarts. There is no automatic recovery mechanism, and manual intervention would be required to detect and fix the inconsistency.

3. **Deterministic Execution Broken**: The presence of orphaned auxiliary info can cause non-deterministic behavior during transaction replay or state synchronization, as nodes may interpret historical data differently.

The developers themselves acknowledge this as a critical issue with TODO comments indicating awareness of the problem: [10](#0-9) 

## Likelihood Explanation

**High Likelihood** of occurrence:

1. **Natural Occurrence**: Power failures, kernel panics, OOM kills, and hardware failures are common in distributed systems running 24/7. Every validator node will eventually experience crashes.

2. **Wide Time Window**: The vulnerability window exists during every transaction commit (thousands per second), spanning the duration of parallel writes across multiple databases.

3. **No Special Conditions Required**: No attacker action needed - this is a natural consequence of system crashes during normal operation.

4. **Affects All Deployment Modes**: When storage sharding is enabled (the recommended configuration for performance), all seven databases are separate RocksDB instances, maximizing the window for inconsistency. [11](#0-10) 

## Recommendation

**Immediate Fix**: Add `PersistedAuxiliaryInfoSchema` truncation to the recovery mechanism.

In `storage/aptosdb/src/utils/truncation_helper.rs`, modify `delete_per_version_data()` to include:

```rust
fn delete_per_version_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut LedgerDbSchemaBatches,
) -> Result<()> {
    // ... existing code ...
    
    // ADD THIS: Truncate persisted_auxiliary_info_db
    delete_per_version_data_impl::<PersistedAuxiliaryInfoSchema>(
        ledger_db.persisted_auxiliary_info_db_raw(),
        start_version,
        &mut batch.persisted_auxiliary_info_db_batches,
    )?;
    
    Ok(())
}
```

This requires exposing a `persisted_auxiliary_info_db_raw()` method on `LedgerDb` similar to the existing `transaction_info_db_raw()` and `write_set_db_raw()` methods.

**Long-term Solution**: Implement the TODO items to write per-database progress markers and perform comprehensive consistency checks at startup, as indicated in the code comments.

## Proof of Concept

While a full PoC would require a Rust integration test that simulates crashes, the vulnerability can be demonstrated by:

1. **Setup**: Start a validator node with storage sharding enabled
2. **Generate Load**: Submit continuous transactions to create database commits
3. **Simulate Crash**: Send SIGKILL to the process during a commit operation
4. **Verify Inconsistency**: On restart, query `persisted_auxiliary_info_db` for versions beyond `overall_commit_progress` and observe orphaned data
5. **Demonstrate Persistence**: Restart multiple times - the orphaned data persists

**Database Query to Detect Inconsistency**:
```rust
let overall_progress = ledger_db.metadata_db().get_synced_version()?;
let mut iter = persisted_auxiliary_info_db.db().iter::<PersistedAuxiliaryInfoSchema>()?;
iter.seek(&(overall_progress + 1))?;
if iter.next().is_some() {
    // Orphaned data detected - database is inconsistent!
}
```

The vulnerability is confirmed by:
- Explicit TODO comments acknowledging the issue
- Missing truncation code for `persisted_auxiliary_info_db` 
- Parallel writes without atomicity guarantees
- Recovery mechanism that handles all other databases except this one

## Notes

This vulnerability is particularly dangerous because:

1. **Silent Corruption**: The inconsistency is not immediately visible and may only manifest during specific read patterns or state synchronization operations.

2. **Cumulative Effect**: Each crash adds more orphaned data, potentially causing the inconsistency to grow over time.

3. **Cross-Validator Divergence**: Different validators will have different sets of orphaned data based on their crash history, creating subtle consensus disagreements that are difficult to debug.

4. **Production Impact**: This affects all production validators running with storage sharding enabled (the recommended configuration for mainnet).

The same recovery gap may exist for `transaction_auxiliary_data_db` as well, which should be verified and fixed using the same approach.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L271-322)
```rust
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            // TODO(grao): Write progress for each of the following databases, and handle the
            // inconsistency at the startup time.
            //
            // TODO(grao): Consider propagating the error instead of panic, if necessary.
            s.spawn(|_| {
                self.commit_events(
                    chunk.first_version,
                    chunk.transaction_outputs,
                    skip_index_and_usage,
                )
                .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .write_set_db()
                    .commit_write_sets(chunk.first_version, chunk.transaction_outputs)
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .transaction_db()
                    .commit_transactions(
                        chunk.first_version,
                        chunk.transactions,
                        skip_index_and_usage,
                    )
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .persisted_auxiliary_info_db()
                    .commit_auxiliary_info(chunk.first_version, chunk.persisted_auxiliary_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_state_kv_and_ledger_metadata(chunk, skip_index_and_usage)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_transaction_infos(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                new_root_hash = self
                    .commit_transaction_accumulator(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
        });

        Ok(new_root_hash)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-450)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L325-361)
```rust
fn truncate_ledger_db_single_batch(
    ledger_db: &LedgerDb,
    transaction_store: &TransactionStore,
    start_version: Version,
) -> Result<()> {
    let mut batch = LedgerDbSchemaBatches::new();

    delete_transaction_index_data(
        ledger_db,
        transaction_store,
        start_version,
        &mut batch.transaction_db_batches,
    )?;
    delete_per_epoch_data(
        &ledger_db.metadata_db_arc(),
        start_version,
        &mut batch.ledger_metadata_db_batches,
    )?;
    delete_per_version_data(ledger_db, start_version, &mut batch)?;

    delete_event_data(ledger_db, start_version, &mut batch.event_db_batches)?;

    truncate_transaction_accumulator(
        ledger_db.transaction_accumulator_db_raw(),
        start_version,
        &mut batch.transaction_accumulator_db_batches,
    )?;

    let mut progress_batch = SchemaBatch::new();
    progress_batch.put::<DbMetadataSchema>(
        &DbMetadataKey::LedgerCommitProgress,
        &DbMetadataValue::Version(start_version - 1),
    )?;
    ledger_db.metadata_db().write_schemas(progress_batch)?;

    ledger_db.write_schemas(batch)
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L430-462)
```rust
fn delete_per_version_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut LedgerDbSchemaBatches,
) -> Result<()> {
    delete_per_version_data_impl::<TransactionAccumulatorRootHashSchema>(
        ledger_db.transaction_accumulator_db_raw(),
        start_version,
        &mut batch.transaction_accumulator_db_batches,
    )?;
    delete_per_version_data_impl::<TransactionInfoSchema>(
        ledger_db.transaction_info_db_raw(),
        start_version,
        &mut batch.transaction_info_db_batches,
    )?;
    delete_transactions_and_transaction_summary_data(
        ledger_db.transaction_db(),
        start_version,
        &mut batch.transaction_db_batches,
    )?;
    delete_per_version_data_impl::<VersionDataSchema>(
        &ledger_db.metadata_db_arc(),
        start_version,
        &mut batch.ledger_metadata_db_batches,
    )?;
    delete_per_version_data_impl::<WriteSetSchema>(
        ledger_db.write_set_db_raw(),
        start_version,
        &mut batch.write_set_db_batches,
    )?;

    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L520-548)
```rust
fn delete_event_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    if let Some(latest_version) = ledger_db.event_db().latest_version()? {
        if latest_version >= start_version {
            info!(
                start_version = start_version,
                latest_version = latest_version,
                "Truncate event data."
            );
            let num_events_per_version = ledger_db.event_db().prune_event_indices(
                start_version,
                latest_version + 1,
                // Assuming same data will be overwritten into indices, we don't bother to deal
                // with the existence or placement of indices
                // TODO: prune data from internal indices
                None,
            )?;
            ledger_db.event_db().prune_events(
                num_events_per_version,
                start_version,
                latest_version + 1,
                batch,
            )?;
        }
    }
    Ok(())
```

**File:** storage/aptosdb/src/schema/persisted_auxiliary_info/mod.rs (L25-30)
```rust
define_schema!(
    PersistedAuxiliaryInfoSchema,
    Version,
    PersistedAuxiliaryInfo,
    PERSISTED_AUXILIARY_INFO_CF_NAME
);
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L122-293)
```rust
    pub(crate) fn new<P: AsRef<Path>>(
        db_root_path: P,
        rocksdb_configs: RocksdbConfigs,
        env: Option<&Env>,
        block_cache: Option<&Cache>,
        readonly: bool,
    ) -> Result<Self> {
        let sharding = rocksdb_configs.enable_storage_sharding;
        let ledger_metadata_db_path = Self::metadata_db_path(db_root_path.as_ref(), sharding);
        let ledger_metadata_db = Arc::new(Self::open_rocksdb(
            ledger_metadata_db_path.clone(),
            if sharding {
                LEDGER_METADATA_DB_NAME
            } else {
                LEDGER_DB_NAME
            },
            &rocksdb_configs.ledger_db_config,
            env,
            block_cache,
            readonly,
        )?);

        info!(
            ledger_metadata_db_path = ledger_metadata_db_path,
            sharding = sharding,
            "Opened ledger metadata db!"
        );

        if !sharding {
            info!("Individual ledger dbs are not enabled!");
            return Ok(Self {
                ledger_metadata_db: LedgerMetadataDb::new(Arc::clone(&ledger_metadata_db)),
                event_db: EventDb::new(
                    Arc::clone(&ledger_metadata_db),
                    EventStore::new(Arc::clone(&ledger_metadata_db)),
                ),
                persisted_auxiliary_info_db: PersistedAuxiliaryInfoDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_accumulator_db: TransactionAccumulatorDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_auxiliary_data_db: TransactionAuxiliaryDataDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_db: TransactionDb::new(Arc::clone(&ledger_metadata_db)),
                transaction_info_db: TransactionInfoDb::new(Arc::clone(&ledger_metadata_db)),
                write_set_db: WriteSetDb::new(Arc::clone(&ledger_metadata_db)),
                enable_storage_sharding: false,
            });
        }

        let ledger_db_folder = db_root_path.as_ref().join(LEDGER_DB_FOLDER_NAME);

        let mut event_db = None;
        let mut persisted_auxiliary_info_db = None;
        let mut transaction_accumulator_db = None;
        let mut transaction_auxiliary_data_db = None;
        let mut transaction_db = None;
        let mut transaction_info_db = None;
        let mut write_set_db = None;
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            s.spawn(|_| {
                let event_db_raw = Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(EVENT_DB_NAME),
                        EVENT_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                );
                event_db = Some(EventDb::new(
                    event_db_raw.clone(),
                    EventStore::new(event_db_raw),
                ));
            });
            s.spawn(|_| {
                persisted_auxiliary_info_db = Some(PersistedAuxiliaryInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(PERSISTED_AUXILIARY_INFO_DB_NAME),
                        PERSISTED_AUXILIARY_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_accumulator_db = Some(TransactionAccumulatorDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_ACCUMULATOR_DB_NAME),
                        TRANSACTION_ACCUMULATOR_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_auxiliary_data_db = Some(TransactionAuxiliaryDataDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_AUXILIARY_DATA_DB_NAME),
                        TRANSACTION_AUXILIARY_DATA_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )))
            });
            s.spawn(|_| {
                transaction_db = Some(TransactionDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_DB_NAME),
                        TRANSACTION_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_info_db = Some(TransactionInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_INFO_DB_NAME),
                        TRANSACTION_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                write_set_db = Some(WriteSetDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(WRITE_SET_DB_NAME),
                        WRITE_SET_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
        });

        // TODO(grao): Handle data inconsistency.

        Ok(Self {
            ledger_metadata_db: LedgerMetadataDb::new(ledger_metadata_db),
            event_db: event_db.unwrap(),
            persisted_auxiliary_info_db: persisted_auxiliary_info_db.unwrap(),
            transaction_accumulator_db: transaction_accumulator_db.unwrap(),
            transaction_auxiliary_data_db: transaction_auxiliary_data_db.unwrap(),
            transaction_db: transaction_db.unwrap(),
            transaction_info_db: transaction_info_db.unwrap(),
            write_set_db: write_set_db.unwrap(),
            enable_storage_sharding: true,
        })
```
