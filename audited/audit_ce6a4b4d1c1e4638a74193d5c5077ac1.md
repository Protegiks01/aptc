# Audit Report

## Title
Unverified Synced Ledger Info Allows Malicious Peers to Manipulate State Sync Peer Selection

## Summary
Malicious peers can provide fake `synced_ledger_info` with invalid signatures that pass `can_service()` checks in the state sync data client, causing validator node slowdowns during bootstrapping and continuous syncing through resource exhaustion and peer selection manipulation.

## Finding Description

The `DataSummary` struct's `synced_ledger_info` field is used for peer selection decisions without signature verification, violating the security principle that cryptographically signed data must be verified before trust. [1](#0-0) 

When a peer sends a `StorageServerSummary`, the data client's poller receives and stores it without any validation of the `synced_ledger_info` signatures: [2](#0-1) [3](#0-2) 

The stored summary is then used for peer selection via `can_service()` checks, which only validate version numbers and timestamps, NOT signatures: [4](#0-3) [5](#0-4) [6](#0-5) 

The peer selection logic filters peers based on these unverified checks: [7](#0-6) 

**Attack Path:**
1. Malicious peer crafts `LedgerInfoWithSignatures` with arbitrarily high version (e.g., 999,999,999) and recent timestamp, but with invalid/empty BLS signatures
2. Honest node polls peer and stores the fake summary without verification
3. Fake `synced_ledger_info` passes `can_service()` checks (only version and timestamp are checked)
4. Malicious peer gets selected for data requests
5. When actual data is requested, proof verification fails, but only after wasting resources
6. Peer score degrades by 0.8x per failure, reaching ignore threshold after ~4 requests
7. Malicious peer disconnects and reconnects to reset score to starting value (50.0), repeating the attack

The peer scoring system attempts mitigation but is undermined by score reset on reconnection: [8](#0-7) [9](#0-8) [10](#0-9) [11](#0-10) 

While proof verification eventually catches invalid data, this occurs AFTER peer selection and network communication: [12](#0-11) [13](#0-12) 

## Impact Explanation

This qualifies as **High Severity** under "Validator node slowdowns" per the Aptos bug bounty criteria.

During bootstrapping or continuous syncing, validators are particularly vulnerable. An attacker controlling multiple peer identities (Sybil attack) can:
- Cause significant resource exhaustion through repeated failed verification attempts
- Manipulate peer selection to crowd out legitimate peers
- Force continuous stream resets and retry cycles
- Each malicious peer wastes ~4 request/response cycles before being ignored (starting score 50.0, malicious multiplier 0.8x, ignore threshold 25.0)
- With 10+ malicious peers cycling through disconnect/reconnect, a validator can be severely slowed

The impact is amplified during:
- Initial bootstrapping when the node has no prior peer reputation information
- Network partitions when few legitimate peers are available
- Epoch transitions when peers need to re-synchronize

This is an application-level protocol vulnerability exploiting peer selection logic, distinct from network-layer DoS attacks. The resource waste occurs at the protocol level through invalid proof verification after peer selection has already occurred based on unverified metadata.

## Likelihood Explanation

**Likelihood: High**

The attack is trivially easy to execute:
- No special privileges required - any network peer can participate
- Crafting fake `LedgerInfoWithSignatures` requires only setting arbitrary version/timestamp values
- No cryptographic work needed (invalid signatures are not checked at selection time)
- Sybil attacks are feasible in permissionless P2P networks
- The disconnect/reconnect pattern to reset scores is simple to automate

The peer scoring mitigation is insufficient because:
- Score resets on disconnect/reconnect enable persistent attacks
- Multiple malicious identities can sustain the attack indefinitely
- The ignore threshold (25.0) is reached only after ~4 failed attempts per peer

## Recommendation

Implement signature verification for `synced_ledger_info` before trusting it for peer selection decisions. The verification should occur when the `StorageServerSummary` is received, not just when actual data is requested.

Recommended fix in `state-sync/aptos-data-client/src/poller.rs`:

```rust
// After receiving storage_summary, verify synced_ledger_info if present
if let Some(synced_ledger_info) = &storage_summary.data_summary.synced_ledger_info {
    // Verify signatures against known epoch state before storing
    if let Err(error) = verify_ledger_info_signatures(synced_ledger_info) {
        warn!("Peer advertised invalid synced_ledger_info with bad signatures");
        // Update peer score for malicious behavior
        data_summary_poller.data_client.update_peer_score_error(
            peer,
            ErrorType::Malicious
        );
        return;
    }
}
```

Additionally, consider making peer scores persistent across disconnect/reconnect cycles to prevent score reset attacks.

## Proof of Concept

A malicious peer can be constructed that:
1. Responds to `GetStorageServerSummary` requests with a `StorageServerSummary` containing a `synced_ledger_info` with arbitrarily high version and recent timestamp but invalid signatures
2. The fake metadata passes `can_service()` checks and causes the peer to be selected for data requests
3. When actual data is requested, proof verification fails after resource waste
4. After ~4 failures, the malicious peer disconnects and reconnects with a fresh score of 50.0
5. The attack pattern repeats indefinitely with multiple peer identities

The vulnerability can be demonstrated by instrumenting the state sync data client to log peer selection decisions and observing that peers with unverified `synced_ledger_info` are selected for requests, leading to subsequent proof verification failures and resource waste.

## Notes

This vulnerability demonstrates a violation of the security principle that cryptographically signed data must be verified before making trust decisions. While the peer scoring system provides defense-in-depth, the score reset on reconnection fundamentally undermines this mitigation, enabling sustained resource exhaustion attacks during critical synchronization operations.

### Citations

**File:** state-sync/storage-service/types/src/responses.rs (L621-631)
```rust
    pub fn can_service(
        &self,
        aptos_data_client_config: &AptosDataClientConfig,
        time_service: TimeService,
        request: &StorageServiceRequest,
    ) -> bool {
        self.protocol_metadata.can_service(request)
            && self
                .data_summary
                .can_service(aptos_data_client_config, time_service, request)
    }
```

**File:** state-sync/storage-service/types/src/responses.rs (L666-686)
```rust
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct DataSummary {
    /// The ledger info corresponding to the highest synced version in storage.
    /// This indicates the highest version and epoch that storage can prove.
    pub synced_ledger_info: Option<LedgerInfoWithSignatures>,
    /// The range of epoch ending ledger infos in storage, e.g., if the range
    /// is [(X,Y)], it means all epoch ending ledger infos for epochs X->Y
    /// (inclusive) are held.
    pub epoch_ending_ledger_infos: Option<CompleteDataRange<Epoch>>,
    /// The range of states held in storage, e.g., if the range is
    /// [(X,Y)], it means all states are held for every version X->Y
    /// (inclusive).
    pub states: Option<CompleteDataRange<Version>>,
    /// The range of transactions held in storage, e.g., if the range is
    /// [(X,Y)], it means all transactions for versions X->Y (inclusive) are held.
    pub transactions: Option<CompleteDataRange<Version>>,
    /// The range of transaction outputs held in storage, e.g., if the range
    /// is [(X,Y)], it means all transaction outputs for versions X->Y
    /// (inclusive) are held.
    pub transaction_outputs: Option<CompleteDataRange<Version>>,
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L892-912)
```rust
/// Returns true iff an optimistic data request can be serviced
/// by the peer with the given synced ledger info.
fn can_service_optimistic_request(
    aptos_data_client_config: &AptosDataClientConfig,
    time_service: TimeService,
    synced_ledger_info: Option<&LedgerInfoWithSignatures>,
) -> bool {
    let max_lag_secs = aptos_data_client_config.max_optimistic_fetch_lag_secs;
    check_synced_ledger_lag(synced_ledger_info, time_service, max_lag_secs)
}

/// Returns true iff a subscription data request can be serviced
/// by the peer with the given synced ledger info.
fn can_service_subscription_request(
    aptos_data_client_config: &AptosDataClientConfig,
    time_service: TimeService,
    synced_ledger_info: Option<&LedgerInfoWithSignatures>,
) -> bool {
    let max_lag_secs = aptos_data_client_config.max_subscription_lag_secs;
    check_synced_ledger_lag(synced_ledger_info, time_service, max_lag_secs)
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L916-934)
```rust
fn check_synced_ledger_lag(
    synced_ledger_info: Option<&LedgerInfoWithSignatures>,
    time_service: TimeService,
    max_lag_secs: u64,
) -> bool {
    if let Some(synced_ledger_info) = synced_ledger_info {
        // Get the ledger info timestamp (in microseconds)
        let ledger_info_timestamp_usecs = synced_ledger_info.ledger_info().timestamp_usecs();

        // Get the current timestamp and max version lag (in microseconds)
        let current_timestamp_usecs = time_service.now_unix_time().as_micros() as u64;
        let max_version_lag_usecs = max_lag_secs * NUM_MICROSECONDS_IN_SECOND;

        // Return true iff the synced ledger info timestamp is within the max version lag
        ledger_info_timestamp_usecs + max_version_lag_usecs > current_timestamp_usecs
    } else {
        false // No synced ledger info was found!
    }
}
```

**File:** state-sync/aptos-data-client/src/poller.rs (L436-439)
```rust
        // Update the summary for the peer
        data_summary_poller
            .data_client
            .update_peer_storage_summary(peer, storage_summary);
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L35-43)
```rust
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L54-62)
```rust
impl From<ResponseError> for ErrorType {
    fn from(error: ResponseError) -> Self {
        match error {
            ResponseError::InvalidData | ResponseError::InvalidPayloadDataType => {
                ErrorType::NotUseful
            },
            ResponseError::ProofVerificationError => ErrorType::Malicious,
        }
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L168-174)
```rust
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L200-227)
```rust
    pub fn can_service_request(
        &self,
        peer: &PeerNetworkId,
        time_service: TimeService,
        request: &StorageServiceRequest,
    ) -> bool {
        // Storage services can always respond to data advertisement requests.
        // We need this outer check, since we need to be able to send data summary
        // requests to new peers (who don't have a peer state yet).
        if request.data_request.is_storage_summary_request()
            || request.data_request.is_protocol_version_request()
        {
            return true;
        }

        // Check if the peer can service the request
        if let Some(peer_state) = self.peer_to_state.get(peer) {
            return match peer_state.get_storage_summary_if_not_ignored() {
                Some(storage_summary) => {
                    storage_summary.can_service(&self.data_client_config, time_service, request)
                },
                None => false, // The peer is temporarily ignored
            };
        }

        // Otherwise, the request cannot be serviced
        false
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L325-330)
```rust
    pub fn update_summary(&self, peer: PeerNetworkId, storage_summary: StorageServerSummary) {
        self.peer_to_state
            .entry(peer)
            .or_insert(PeerState::new(self.data_client_config.clone()))
            .update_storage_summary(storage_summary);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L333-336)
```rust
    pub fn garbage_collect_peer_states(&self, connected_peers: HashSet<PeerNetworkId>) {
        self.peer_to_state
            .retain(|peer_network_id, _| connected_peers.contains(peer_network_id));
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L452-465)
```rust
        // Verify the ledger info state and signatures
        if let Err(error) = self
            .get_speculative_stream_state()?
            .verify_ledger_info_with_signatures(ledger_info_with_signatures)
        {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::PayloadProofFailed,
            )))
            .await?;
            Err(error)
        } else {
            Ok(())
        }
```

**File:** state-sync/state-sync-driver/src/utils.rs (L100-110)
```rust
    /// Verifies the given ledger info with signatures against the current epoch state
    pub fn verify_ledger_info_with_signatures(
        &mut self,
        ledger_info_with_signatures: &LedgerInfoWithSignatures,
    ) -> Result<(), Error> {
        self.epoch_state
            .verify(ledger_info_with_signatures)
            .map_err(|error| {
                Error::VerificationError(format!("Ledger info failed verification: {:?}", error))
            })
    }
```
