# Audit Report

## Title
Integer Overflow in Quorum Store Back Pressure AIMD Algorithm Allows Throughput Degradation via Misconfiguration

## Summary
The Quorum Store batch generator's additive increase multiplicative decrease (AIMD) back pressure algorithm performs unchecked addition when increasing `dynamic_pull_txn_per_s`, allowing integer overflow if `additive_increase_when_no_backpressure` is set to a value near `u64::MAX`. This causes the throughput rate to wrap around to near-zero instead of increasing during normal operation, severely degrading validator performance.

## Finding Description
The Quorum Store implements an AIMD congestion control algorithm to dynamically adjust transaction pull rates from mempool. During normal operation (no backpressure), the system should additively increase `dynamic_pull_txn_per_s` every `increase_duration_ms` by the configured `additive_increase_when_no_backpressure` value. [1](#0-0) 

The default configuration sets this to 2000, which is safe: [2](#0-1) 

However, the configuration struct is deserializable via Serde with no validation on this field's maximum value. The batch generator's main loop performs unchecked addition: [3](#0-2) 

The vulnerability occurs at line 452 where `dynamic_pull_txn_per_s + self.config.back_pressure.additive_increase_when_no_backpressure` is computed without checked arithmetic. In Rust release mode (used in production), integer overflow wraps around silently.

**Exploitation Path:**
1. Validator operator sets `additive_increase_when_no_backpressure = u64::MAX` in node configuration (either accidentally or via configuration generation bug)
2. Node starts with `dynamic_pull_txn_per_s = (160 + 12000) / 2 = 6080` [4](#0-3) 
3. During normal operation (no backpressure), every 1 second the system attempts to increase the rate
4. The addition `6080 + u64::MAX` overflows, wrapping to `(6080 + 18446744073709551615) % 2^64 = 6079`
5. `std::cmp::min(6079, 12000) = 6079`, which is LESS than the current rate
6. This repeats every second: `6079 → 6078 → 6077 → ...` until reaching near-zero
7. The low `dynamic_pull_txn_per_s` severely limits transaction pulling from mempool [5](#0-4) 

The system exhibits behavior opposite to its design: instead of additively increasing throughput during normal operation, it decreases to near-zero, breaking the invariant that resource limits should be respected appropriately.

## Impact Explanation
This qualifies as **High Severity** under Aptos bug bounty criteria for "Validator node slowdowns". While it doesn't affect consensus safety, it causes:

- **Liveness Degradation**: Affected validator processes minimal transactions per second
- **Missed Consensus Participation**: Validator may fall behind and miss voting deadlines
- **Network Throughput Reduction**: If multiple validators are affected by configuration templates or automation bugs

The impact is amplified because:
1. Configuration files are often generated programmatically or from templates
2. Large values might be set thinking "bigger is better" for performance
3. No validation exists to prevent unrealistic values

## Likelihood Explanation
**Likelihood: Medium**

While this requires operator-level configuration access, several realistic scenarios exist:

1. **Configuration Generation Bug**: Automated deployment scripts or Terraform/Ansible playbooks with template errors could set extreme values
2. **Copy-Paste Errors**: Operators copying configurations might accidentally paste `u64::MAX` (18446744073709551615) 
3. **Misunderstanding**: Operators unfamiliar with overflow semantics might set very large values expecting faster recovery
4. **Default Override Mistakes**: When overriding defaults, typos or unit confusion could introduce extreme values

The vulnerability exists in production code with no validation, making exploitation dependent only on configuration rather than complex attack sequences.

## Recommendation
Implement validation in the `ConfigSanitizer` for `QuorumStoreBackPressureConfig` to enforce reasonable bounds:

```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let bp = &node_config.consensus.quorum_store.back_pressure;
        
        // Validate back pressure config values
        if bp.additive_increase_when_no_backpressure > bp.dynamic_max_txn_per_s * 10 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("additive_increase_when_no_backpressure ({}) exceeds safe threshold (10x dynamic_max_txn_per_s)", 
                    bp.additive_increase_when_no_backpressure),
            ));
        }
        
        if bp.dynamic_min_txn_per_s > bp.dynamic_max_txn_per_s {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "dynamic_min_txn_per_s must not exceed dynamic_max_txn_per_s".to_string(),
            ));
        }

        // Existing validations...
        Self::sanitize_send_recv_batch_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;
        
        Ok(())
    }
}
```

Additionally, use checked arithmetic in the batch generator:

```rust
dynamic_pull_txn_per_s = dynamic_pull_txn_per_s
    .saturating_add(self.config.back_pressure.additive_increase_when_no_backpressure)
    .min(self.config.back_pressure.dynamic_max_txn_per_s);
```

## Proof of Concept

```rust
#[test]
fn test_additive_increase_overflow() {
    // Simulate the overflow scenario
    let mut dynamic_pull_txn_per_s: u64 = 6080;
    let additive_increase = u64::MAX;
    let dynamic_max = 12000u64;
    
    println!("Initial rate: {}", dynamic_pull_txn_per_s);
    
    // Simulate 10 seconds of increases
    for i in 1..=10 {
        let new_rate = dynamic_pull_txn_per_s + additive_increase;
        dynamic_pull_txn_per_s = std::cmp::min(new_rate, dynamic_max);
        println!("After {} seconds: {} (overflowed: {})", 
            i, dynamic_pull_txn_per_s, new_rate);
    }
    
    // The rate should have decreased to near-zero instead of increasing
    assert!(dynamic_pull_txn_per_s < 6080, 
        "Rate decreased instead of increasing due to overflow");
}
```

**Expected Output:**
```
Initial rate: 6080
After 1 seconds: 6079 (overflowed: 6079)
After 2 seconds: 6078 (overflowed: 6078)
After 3 seconds: 6077 (overflowed: 6077)
...
```

The test demonstrates that with `additive_increase_when_no_backpressure = u64::MAX`, the rate decreases by 1 each iteration rather than increasing, violating the AIMD algorithm's design.

## Notes
This vulnerability exists due to missing input validation on configuration values combined with unchecked arithmetic in a critical control loop. While it requires configuration access, the realistic scenarios (template bugs, automation errors) and lack of safeguards make this a valid security concern warranting immediate validation implementation.

### Citations

**File:** config/src/config/quorum_store_config.rs (L26-27)
```rust
    pub additive_increase_when_no_backpressure: u64,
}
```

**File:** config/src/config/quorum_store_config.rs (L44-44)
```rust
            additive_increase_when_no_backpressure: 2000,
```

**File:** consensus/src/quorum_store/batch_generator.rs (L419-421)
```rust
        let mut dynamic_pull_txn_per_s = (self.config.back_pressure.dynamic_min_txn_per_s
            + self.config.back_pressure.dynamic_max_txn_per_s)
            / 2;
```

**File:** consensus/src/quorum_store/batch_generator.rs (L448-456)
```rust
                        // additive increase, every second
                        if back_pressure_increase_latest.elapsed() >= back_pressure_increase_duration {
                            back_pressure_increase_latest = tick_start;
                            dynamic_pull_txn_per_s = std::cmp::min(
                                dynamic_pull_txn_per_s + self.config.back_pressure.additive_increase_when_no_backpressure,
                                self.config.back_pressure.dynamic_max_txn_per_s,
                            );
                            trace!("QS: dynamic_max_pull_txn_per_s: {}", dynamic_pull_txn_per_s);
                        }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L476-481)
```rust
                        let dynamic_pull_max_txn = std::cmp::max(
                            (since_last_non_empty_pull_ms as f64 / 1000.0 * dynamic_pull_txn_per_s as f64) as u64, 1);
                        let pull_max_txn = std::cmp::min(
                            dynamic_pull_max_txn,
                            self.config.sender_max_total_txns as u64,
                        );
```
