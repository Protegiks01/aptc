# Audit Report

## Title
JWK Consensus Liveness Failure Due to Protocol Version Mismatch During Validator Upgrades

## Summary
The JWK consensus protocol can permanently stall if validators upgrade to incompatible protocol versions where the RPC protocol arrays have insufficient overlap. When >1/3 of validators (by voting power) cannot establish RPC communication due to protocol mismatches, the ReliableBroadcast mechanism cannot achieve quorum (>2/3 voting power), causing indefinite retry loops and complete consensus failure.

## Finding Description
The JWK consensus system uses a hardcoded protocol preference array to establish RPC communication between validators: [1](#0-0) 

During RPC transmission, the network layer selects a protocol by finding the intersection between the sender's preferences and the receiver's supported protocols: [2](#0-1) 

If no common protocol exists, the RPC fails with an error. The JWK consensus uses ReliableBroadcast to achieve quorum certification: [3](#0-2) [4](#0-3) 

The ReliableBroadcast retries failed RPCs indefinitely with exponential backoff (line 198-199) until quorum is achieved. However, the quorum requirement is >2/3 voting power: [5](#0-4) 

**Attack Scenario:**
1. Validators V1 run version A supporting protocols: `[JWKConsensusRpcBcs, JWKConsensusRpcJson]` (hypothetical old version before Compressed was added)
2. Validators V2 upgrade to version B supporting: `[JWKConsensusRpcCompressed]` (hypothetical future version with old protocols removed)
3. If V1 represents >1/3 voting power, then V2 cannot achieve quorum because:
   - RPCs from V2 to V1 fail (no common protocol)
   - Retries continue indefinitely
   - `check_voting_power()` never reaches the quorum threshold
   - JWK consensus permanently stalls

This breaks the **Consensus Liveness** invariant - the system must make progress even with <1/3 Byzantine validators, but protocol mismatches can create artificial unavailability.

## Impact Explanation
This qualifies as **High Severity** per the Aptos bug bounty criteria:
- **Significant protocol violations**: JWK consensus completely fails to produce QuorumCertifiedUpdates
- **Validator node slowdowns**: The retry loop consumes resources indefinitely
- **Operational impact**: OIDC authentication infrastructure breaks without JWK updates

While not directly causing fund loss, JWK consensus stalling prevents critical authentication updates, potentially locking users out of the network if OIDC provider keys rotate.

## Likelihood Explanation
**Likelihood: Medium to High during validator upgrades**

This issue can realistically occur when:
1. **Future protocol cleanup**: Developers remove old protocols (Bcs, Json) to simplify the codebase, keeping only Compressed
2. **Staggered validator upgrades**: During rolling upgrades, validators temporarily run mixed versions
3. **Version skipping**: Validators directly upgrade from very old versions (without Compressed) to very new versions (without Bcs/Json), bypassing intermediate versions

The current code has all three protocols, but there's no safeguard preventing future protocol removal or ensuring backward compatibility during migrations.

## Recommendation

**Solution 1: Enforce Minimum Protocol Set**
Require that at least one "baseline" protocol (e.g., `JWKConsensusRpcBcs`) must always be supported for backward compatibility:

```rust
// In network_interface.rs
pub const RPC: &[ProtocolId] = &[
    ProtocolId::JWKConsensusRpcCompressed,
    ProtocolId::JWKConsensusRpcBcs, // REQUIRED: Never remove for backward compat
    ProtocolId::JWKConsensusRpcJson,
];

// Add compile-time assertion
const _: () = {
    assert!(
        RPC.contains(&ProtocolId::JWKConsensusRpcBcs),
        "JWKConsensusRpcBcs must be supported for backward compatibility"
    );
};
```

**Solution 2: Graceful Degradation**
Modify `get_preferred_protocol_for_peer` to fall back to alternative communication methods or log warnings when validators are unreachable:

```rust
fn get_preferred_protocol_for_peer(
    &self,
    peer: &PeerNetworkId,
    preferred_protocols: &[ProtocolId],
) -> Result<ProtocolId, Error> {
    let protocols_supported_by_peer = self.get_supported_protocols(peer)?;
    for protocol in preferred_protocols {
        if protocols_supported_by_peer.contains(*protocol) {
            return Ok(*protocol);
        }
    }
    
    // New: Log critical warning before failing
    warn!(
        "CRITICAL: No common JWK consensus protocol with peer {:?}. \
         Validator may be running incompatible version. \
         Supported by peer: {:?}, Preferred: {:?}",
        peer, protocols_supported_by_peer, preferred_protocols
    );
    
    Err(Error::NetworkError(format!(
        "No common protocols with peer {:?}. This may indicate version skew during upgrade.",
        peer
    )))
}
```

**Solution 3: Protocol Migration Guards**
Add on-chain feature flags or version checks to coordinate protocol transitions across all validators before removing old protocols.

## Proof of Concept

```rust
// Conceptual PoC showing how protocol mismatch causes stall
// (Cannot run without full validator setup)

use aptos_types::validator_verifier::ValidatorVerifier;

#[test]
fn test_jwk_consensus_stall_on_protocol_mismatch() {
    // Setup: 4 validators with 25% voting power each
    // V1, V2 run old version: [RpcBcs, RpcJson]
    // V3, V4 run new version: [RpcCompressed]
    
    // Scenario: V3 tries to broadcast JWK observation
    // Expected: Can reach V4 (50% power) but not V1, V2
    // Result: 50% < 67% quorum → Broadcast retries forever
    
    // When V3 calls send_rpc to V1:
    let v3_protocols = vec![ProtocolId::JWKConsensusRpcCompressed];
    let v1_protocols = vec![ProtocolId::JWKConsensusRpcBcs, 
                           ProtocolId::JWKConsensusRpcJson];
    
    // get_preferred_protocol_for_peer(V1, v3_protocols)
    // → Returns Error (no intersection)
    
    // ReliableBroadcast.broadcast() at line 198:
    // → Retries V1, V2 indefinitely with backoff
    // → Never reaches 67% quorum
    // → Task never completes
    
    // JWK consensus is permanently stalled
    assert!(false, "JWK consensus cannot make progress");
}
```

## Notes

**Current Risk Assessment:**
The current codebase includes all three protocol variants (`Compressed`, `Bcs`, `Json`), so validators running the current version can communicate. However, this vulnerability becomes active if:

1. Future releases remove protocol variants without coordination
2. Validators run significantly divergent versions during upgrades
3. There's no operational procedure to ensure minimum protocol overlap

**Mitigation Priority:**
This should be addressed before any protocol cleanup efforts. The lack of backward compatibility enforcement or migration safeguards creates operational risk during validator upgrades.

**Related Systems:**
The same pattern exists in Consensus and DKG network configurations. Any protocol array changes in those systems could have similar impacts on their respective consensus mechanisms.

### Citations

**File:** crates/aptos-jwk-consensus/src/network_interface.rs (L22-26)
```rust
pub const RPC: &[ProtocolId] = &[
    ProtocolId::JWKConsensusRpcCompressed,
    ProtocolId::JWKConsensusRpcBcs,
    ProtocolId::JWKConsensusRpcJson,
];
```

**File:** network/framework/src/application/interface.rs (L142-158)
```rust
    fn get_preferred_protocol_for_peer(
        &self,
        peer: &PeerNetworkId,
        preferred_protocols: &[ProtocolId],
    ) -> Result<ProtocolId, Error> {
        let protocols_supported_by_peer = self.get_supported_protocols(peer)?;
        for protocol in preferred_protocols {
            if protocols_supported_by_peer.contains(*protocol) {
                return Ok(*protocol);
            }
        }
        Err(Error::NetworkError(format!(
            "None of the preferred protocols are supported by this peer! \
            Peer: {:?}, supported protocols: {:?}",
            peer, protocols_supported_by_peer
        )))
    }
```

**File:** crates/aptos-jwk-consensus/src/update_certifier.rs (L67-79)
```rust
        let task = async move {
            let qc_update = rb.broadcast(req, agg_state).await.expect("cannot fail");
            ConsensusMode::log_certify_done(epoch, &qc_update);
            let session_key = ConsensusMode::session_key_from_qc(&qc_update);
            match session_key {
                Ok(key) => {
                    let _ = qc_update_tx.push(key, qc_update);
                },
                Err(e) => {
                    error!("JWK update QCed but could not identify the session key: {e}");
                },
            }
        };
```

**File:** crates/reliable-broadcast/src/lib.rs (L167-205)
```rust
            loop {
                tokio::select! {
                    Some((receiver, result)) = rpc_futures.next() => {
                        let aggregating = aggregating.clone();
                        let future = executor.spawn(async move {
                            (
                                    receiver,
                                    result
                                        .and_then(|msg| {
                                            msg.try_into().map_err(|e| anyhow::anyhow!("{:?}", e))
                                        })
                                        .and_then(|ack| aggregating.add(receiver, ack)),
                            )
                        }).await;
                        aggregate_futures.push(future);
                    },
                    Some(result) = aggregate_futures.next() => {
                        let (receiver, result) = result.expect("spawned task must succeed");
                        match result {
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
                                }
                            },
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
                        }
                    },
                    else => unreachable!("Should aggregate with all responses")
                }
            }
```

**File:** crates/aptos-jwk-consensus/src/observation_aggregation/mod.rs (L94-117)
```rust
        let power_check_result = self
            .epoch_state
            .verifier
            .check_voting_power(voters.iter(), true);
        let new_total_power = match &power_check_result {
            Ok(x) => Some(*x),
            Err(VerifyError::TooLittleVotingPower { voting_power, .. }) => Some(*voting_power),
            _ => None,
        };

        info!(
            epoch = self.epoch_state.epoch,
            peer = sender,
            issuer = String::from_utf8(self.local_view.issuer.clone()).ok(),
            peer_power = peer_power,
            new_total_power = new_total_power,
            threshold = self.epoch_state.verifier.quorum_voting_power(),
            threshold_exceeded = power_check_result.is_ok(),
            "Peer vote aggregated."
        );

        if power_check_result.is_err() {
            return Ok(None);
        }
```
