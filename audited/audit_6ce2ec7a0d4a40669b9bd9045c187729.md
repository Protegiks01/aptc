# Audit Report

## Title
Crash Recovery Truncation Creates Orphaned Merkle Nodes Due to Stale Index Desynchronization

## Summary
During database crash recovery, the truncation logic in `truncate_state_merkle_db` incorrectly deletes stale node indices while leaving their referenced old nodes in the database. This creates orphaned JellyfishMerkleNode entries that will never be pruned, leading to unbounded storage growth and eventual resource exhaustion.

## Finding Description

The vulnerability exists in the coordination between stale node index deletion and actual node deletion during crash recovery truncation in the Aptos storage layer.

**StaleNodeIndex Structure:**

A `StaleNodeIndex` records when a node becomes obsolete. It contains two fields defined in the codebase:
- `stale_since_version`: The version at which the node was replaced
- `node_key`: The key identifying the **OLD node that became stale** (not the new node) [1](#0-0) 

**NodeKey Structure:**

Each node is uniquely identified by a `NodeKey` containing:
- `version`: The version at which the node was **created**
- `nibble_path`: The tree path [2](#0-1) 

**Stale Index Creation:**

When a node is replaced during tree updates, the system marks the OLD node as stale by calling `put_stale_node` with the old node's key and the NEW version when replacement happens: [3](#0-2) 

This creates a `StaleNodeIndex` where `stale_since_version` is the NEW version and `node_key` contains the OLD node's version.

**The Vulnerability:**

During crash recovery, `sync_commit_progress` calls truncation functions to roll back inconsistent state: [4](#0-3) 

The truncation uses `delete_nodes_and_stale_indices_at_or_after_version` which implements this logic: [5](#0-4) 

The function deletes:
1. All stale indices where `stale_since_version >= version` (lines 609-612)
2. All nodes where `node.version() >= version` (lines 614-619)

**The Critical Flaw:**

Since stale indices point to OLD nodes (created before `stale_since_version`), but the deletion checks `stale_since_version >= version` to delete the index, a desynchronization occurs:

**Concrete Scenario:**

1. **Version 100**: Node A created at `NodeKey{version: 100, path: P}`
2. **Version 200**: Node A replaced by Node B
   - Stale index: `{stale_since_version: 200, node_key: NodeKey{version: 100, path: P}}`
   - Node B: `NodeKey{version: 200, path: P}`
3. **Crash at version 250, recover to version 150**:
   - Deletes stale index: `200 >= 150` ✓
   - Deletes Node B: `200 >= 150` ✓
   - **Keeps Node A**: `100 < 150` ✗ **ORPHANED!**

**Pruner Dependency on Stale Indices:**

The pruner exclusively relies on stale indices to identify which nodes to delete: [6](#0-5) 

Without a stale index, Node A at version 100 will never be pruned.

## Impact Explanation

This is a **HIGH severity** vulnerability per Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: As orphaned nodes accumulate over multiple crash-recovery cycles, disk I/O operations degrade, database query performance suffers, and overall validator performance decreases. This directly matches the HIGH severity criterion #8 "Validator Node Slowdowns" in the Aptos bug bounty program.

2. **Resource Exhaustion Path**: Each crash-recovery cycle where nodes were replaced before the crash point adds orphaned nodes. Over time, this leads to unbounded storage growth that can eventually exhaust disk space and cause node failure.

3. **Operational Impact**: There is no automatic mechanism to detect or clean up these orphaned nodes. Recovery requires either manual database intervention or full state synchronization from peers.

4. **State Database Integrity**: The state merkle database maintains internally inconsistent data with unprunable orphaned nodes, violating storage layer invariants.

While not immediately catastrophic on a single crash, the cumulative effect over multiple crashes makes this a significant operational concern for production validator nodes.

## Likelihood Explanation

**HIGH likelihood** of occurrence:

1. **Common Trigger**: Validator nodes experience crashes due to hardware failures, out-of-memory conditions, power loss, or software bugs. These are normal operational events in production environments.

2. **Automatic Activation**: The vulnerability triggers automatically during normal crash recovery whenever the truncation point falls between a node's creation version and its replacement version. No attacker action is required.

3. **Cumulative Effect**: Each crash-recovery cycle potentially adds more orphaned nodes. The problem compounds over time rather than being a one-time issue.

4. **No Self-Healing**: The system has no mechanism to detect orphaned nodes or reconstruct missing stale indices. Once orphaned, nodes remain permanently unprunable.

5. **Production Reality**: Mainnet validators experience periodic crashes, making this a real operational concern rather than a theoretical vulnerability.

## Recommendation

The truncation logic should be modified to maintain consistency between stale indices and node deletions. Two potential approaches:

**Approach 1: Delete nodes referenced by deleted indices**

When deleting stale indices, also delete the nodes they reference:

```rust
fn delete_nodes_and_stale_indices_at_or_after_version(
    db: &DB,
    version: Version,
    shard_id: Option<usize>,
    batch: &mut SchemaBatch,
) -> Result<()> {
    // Collect indices and delete the nodes they reference
    let mut iter = db.iter::<StaleNodeIndexSchema>()?;
    iter.seek(&version)?;
    for item in iter {
        let (index, _) = item?;
        if index.stale_since_version >= version {
            batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
            batch.delete::<StaleNodeIndexSchema>(&index)?;
        }
    }
    
    // Same for cross-epoch indices
    let mut iter = db.iter::<StaleNodeIndexCrossEpochSchema>()?;
    iter.seek(&version)?;
    for item in iter {
        let (index, _) = item?;
        if index.stale_since_version >= version {
            batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
            batch.delete::<StaleNodeIndexCrossEpochSchema>(&index)?;
        }
    }
    
    // Then delete remaining nodes at or after version
    let mut iter = db.iter::<JellyfishMerkleNodeSchema>()?;
    iter.seek(&NodeKey::new_empty_path(version))?;
    for item in iter {
        let (key, _) = item?;
        batch.delete::<JellyfishMerkleNodeSchema>(&key)?;
    }

    StateMerkleDb::put_progress(version.checked_sub(1), shard_id, batch)
}
```

**Approach 2: Keep stale indices for nodes below truncation point**

Only delete stale indices that point to nodes at or after the truncation version:

```rust
fn delete_stale_node_index_at_or_after_version<S>(
    db: &DB,
    version: Version,
    batch: &mut SchemaBatch,
) -> Result<()>
where
    S: Schema<Key = StaleNodeIndex>,
    Version: SeekKeyCodec<S>,
{
    let mut iter = db.iter::<S>()?;
    iter.seek(&version)?;
    for item in iter {
        let (index, _) = item?;
        // Only delete index if it points to a node that will be deleted
        if index.node_key.version() >= version {
            batch.delete::<S>(&index)?;
        }
    }
    Ok(())
}
```

## Proof of Concept

While a full end-to-end test would require simulating crashes and recovery, the vulnerability can be demonstrated by examining the code flow:

1. Create Node A at version 100
2. Replace with Node B at version 200 (creates stale index pointing to Node A)
3. Simulate crash recovery truncating to version 150
4. Verify stale index deleted but Node A remains
5. Confirm pruner cannot find Node A without its stale index

The logical flow is evident from the cited code sections where the version comparisons create the orphaning condition.

### Citations

**File:** storage/jellyfish-merkle/src/lib.rs (L195-201)
```rust
pub struct StaleNodeIndex {
    /// The version since when the node is overwritten and becomes stale.
    pub stale_since_version: Version,
    /// The [`NodeKey`](node_type/struct.NodeKey.html) identifying the node associated with this
    /// record.
    pub node_key: NodeKey,
}
```

**File:** storage/jellyfish-merkle/src/lib.rs (L497-501)
```rust
        let node_opt = self.reader.get_node_option(node_key, "commit")?;

        if node_opt.is_some() {
            batch.put_stale_node(node_key.clone(), version);
        }
```

**File:** storage/jellyfish-merkle/src/node_type/mod.rs (L49-54)
```rust
pub struct NodeKey {
    // The version at which the node is created.
    version: Version,
    // The nibble path this node represents in the tree.
    nibble_path: NibblePath,
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L490-497)
```rust
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L603-622)
```rust
fn delete_nodes_and_stale_indices_at_or_after_version(
    db: &DB,
    version: Version,
    shard_id: Option<usize>,
    batch: &mut SchemaBatch,
) -> Result<()> {
    delete_stale_node_index_at_or_after_version::<StaleNodeIndexSchema>(db, version, batch)?;
    delete_stale_node_index_at_or_after_version::<StaleNodeIndexCrossEpochSchema>(
        db, version, batch,
    )?;

    let mut iter = db.iter::<JellyfishMerkleNodeSchema>()?;
    iter.seek(&NodeKey::new_empty_path(version))?;
    for item in iter {
        let (key, _) = item?;
        batch.delete::<JellyfishMerkleNodeSchema>(&key)?;
    }

    StateMerkleDb::put_progress(version.checked_sub(1), shard_id, batch)
}
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L66-76)
```rust
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;
```
