# Audit Report

## Title
AsyncConcurrentDropper Thread Pool Exhaustion Causes Validator Liveness Failures

## Summary

The `DEFAULT_DROPPER` thread pool (8 threads, 32 max tasks) used by `DropHelper` can be exhausted by long-running drop operations of large state objects, causing critical consensus and execution threads to block indefinitely when attempting to drop `ExecutionOutput`, `StateCheckpointOutput`, and `LedgerUpdateOutput` objects. This leads to validator slowdowns and potential loss of liveness.

## Finding Description

The `AsyncConcurrentDropper` implements a bounded concurrent drop queue to avoid blocking on expensive drop operations. However, the implementation contains a critical flaw: when the queue is full (â‰¥32 tasks), calls to `schedule_drop` block the calling thread indefinitely until a slot becomes available. [1](#0-0) 

Critical execution objects are wrapped in `DropHelper`, which automatically schedules drops to the `DEFAULT_DROPPER`: [2](#0-1) [3](#0-2) 

The `StateComputeResult` stored in consensus `PipelinedBlock` contains three `DropHelper`-wrapped objects: [4](#0-3) 

Each of these objects can contain large state structures. Specifically, `ExecutionOutput::Inner` contains a `LedgerState`: [5](#0-4) 

`LedgerState` contains two `State` objects, each with 16 `MapLayer` instances: [6](#0-5) [7](#0-6) 

When `MapLayer` objects are dropped, they trigger recursive tree cleanup operations that, due to the `IN_ANY_DROP_POOL` guard, execute synchronously within drop pool threads: [8](#0-7) [9](#0-8) 

**Attack Scenario:**

1. Attacker submits transactions that touch many state keys, creating large `ShardedStateCache` instances and causing `State` objects with deep `MapLayer` trees
2. As blocks execute, `ExecutionOutput` objects accumulate these large state structures
3. When consensus advances and old `PipelinedBlock` objects are dropped, they schedule drops of large `StateComputeResult` objects
4. The 8 `DEFAULT_DROPPER` threads become occupied with long-running synchronous drops of nested structures
5. The queue fills with 32 pending tasks
6. New drops from critical consensus/execution paths call `schedule_drop`, which blocks at the `inc()` function waiting for available slots
7. **Critical consensus threads block**, preventing new block processing
8. Validator experiences liveness failure and cannot participate in consensus

This breaks the **Resource Limits** invariant (#9) and affects validator **liveness**, a critical system property.

## Impact Explanation

This vulnerability qualifies as **High Severity** ($50,000) per Aptos bug bounty criteria:

- **Validator node slowdowns**: When the drop queue fills, critical threads block waiting for drop slots, severely degrading validator performance
- **Potential liveness failure**: If consensus threads block during critical operations (advancing rounds, voting), the validator cannot participate in consensus
- **Cascading failures**: Multiple validators experiencing this issue simultaneously could impact network liveness

The impact is not **Critical** because:
- It does not cause permanent state corruption or fund loss
- Recovery is possible by restarting the validator
- It does not violate consensus safety (only liveness)

However, the impact is clearly **High** as it causes significant operational disruption and could affect network health if multiple validators are impacted.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to occur in production because:

1. **Normal operation triggers it**: Large state changes from legitimate transactions (e.g., NFT mints, DeFi operations touching many accounts) naturally create large drop workloads
2. **Bounded resources**: With only 8 threads and 32 max tasks, the queue can fill during high-throughput periods
3. **Compounding effect**: The `IN_ANY_DROP_POOL` guard causes synchronous drops, making each drop operation potentially very long
4. **No backpressure mechanism**: There's no limit on the size of objects being dropped or circuit breaker to prevent queue exhaustion
5. **Critical path exposure**: Consensus directly drops these objects, putting the most critical code path at risk

Attackers can intentionally trigger this by:
- Submitting transactions that maximize state reads/writes
- Timing attacks during high network load
- Creating large on-chain data structures that require extensive cleanup

## Recommendation

Implement multiple mitigation strategies:

**1. Increase Thread Pool Capacity:**
```rust
pub static DEFAULT_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("default", 128, 32)); // Increase both limits
```

**2. Add Non-Blocking Fallback:**
Modify `schedule_drop_impl` to drop synchronously if the queue is nearly full when called from critical paths:
```rust
fn schedule_drop_impl<V: Send + 'static>(&self, v: V, notif_sender_opt: Option<Sender<()>>) {
    if IN_ANY_DROP_POOL.get() {
        Self::do_drop(v, notif_sender_opt);
        return;
    }

    // Try to schedule, but fallback to sync drop if queue is >80% full
    let num_tasks = self.num_tasks_tracker.lock.lock();
    if *num_tasks >= (self.num_tasks_tracker.max_tasks * 4 / 5) {
        drop(num_tasks);
        Self::do_drop(v, notif_sender_opt);
        return;
    }
    drop(num_tasks);

    // Proceed with normal async drop
    let _timer = TIMER.timer_with(&[self.name, "enqueue_drop"]);
    self.num_tasks_tracker.inc();
    // ... rest of existing code
}
```

**3. Use Dedicated Dropper for Critical Objects:**
Create separate droppers for consensus-critical vs. non-critical objects:
```rust
pub static CRITICAL_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("critical", 64, 16));
    
pub static BULK_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("bulk", 256, 8));
```

**4. Add Monitoring:**
Implement alerts when the drop queue exceeds critical thresholds (e.g., >70% full) to detect issues before they cause failures.

## Proof of Concept

```rust
// Integration test demonstrating thread pool exhaustion
#[test]
fn test_drop_pool_exhaustion_blocks_critical_threads() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    use std::time::Duration;
    use aptos_drop_helper::{DEFAULT_DROPPER, DropHelper};
    
    // Create objects that take a long time to drop
    struct SlowDrop {
        data: Vec<Vec<u8>>,
    }
    
    impl Drop for SlowDrop {
        fn drop(&mut self) {
            // Simulate expensive cleanup
            thread::sleep(Duration::from_millis(500));
        }
    }
    
    // Fill the drop queue beyond capacity
    let items: Vec<DropHelper<SlowDrop>> = (0..50)
        .map(|_| DropHelper::new(SlowDrop {
            data: vec![vec![0u8; 1024]; 1000],
        }))
        .collect();
    
    let barrier = Arc::new(Barrier::new(2));
    let barrier_clone = barrier.clone();
    
    // Spawn a "critical thread" that tries to drop an object
    let critical_thread = thread::spawn(move || {
        barrier_clone.wait();
        let start = std::time::Instant::now();
        
        // This represents a consensus thread dropping StateComputeResult
        let critical_obj = DropHelper::new(SlowDrop {
            data: vec![vec![0u8; 1024]; 100],
        });
        drop(critical_obj);
        
        start.elapsed()
    });
    
    // Trigger drops by dropping the vector
    thread::spawn(move || {
        barrier.wait();
        drop(items); // This fills the queue
    });
    
    // Check if critical thread was blocked
    let elapsed = critical_thread.join().unwrap();
    
    // If the critical thread had to wait for the drop queue,
    // it will take significantly longer than expected
    assert!(
        elapsed < Duration::from_millis(100),
        "Critical thread was blocked for {:?}, indicating drop queue exhaustion",
        elapsed
    );
}
```

**Notes:**

This vulnerability is particularly dangerous because:
1. The developers are aware of drop performance issues (evidenced by explicit `schedule_drop` calls in `executor.rs`) but the mitigation is insufficient
2. The `IN_ANY_DROP_POOL` guard prevents deadlock but exacerbates the problem by making drops arbitrarily long
3. There are actually TWO separate drop pools (DEFAULT_DROPPER and layered-map DROPPER) that can interact poorly
4. No monitoring or alerting exists to detect drop queue saturation before it causes failures

The vulnerability affects validator **availability** (liveness), which while not consensus-breaking, is critical for network operation and validator rewards.

### Citations

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L62-65)
```rust
        if IN_ANY_DROP_POOL.get() {
            Self::do_drop(v, notif_sender_opt);
            return;
        }
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L112-119)
```rust
    fn inc(&self) {
        let mut num_tasks = self.lock.lock();
        while *num_tasks >= self.max_tasks {
            num_tasks = self.cvar.wait(num_tasks).expect("lock poisoned.");
        }
        *num_tasks += 1;
        GAUGE.set_with(&[self.name, "num_tasks"], *num_tasks as i64);
    }
```

**File:** crates/aptos-drop-helper/src/lib.rs (L19-20)
```rust
pub static DEFAULT_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("default", 32, 8));
```

**File:** crates/aptos-drop-helper/src/lib.rs (L51-55)
```rust
impl<T: Send + 'static> Drop for DropHelper<T> {
    fn drop(&mut self) {
        DEFAULT_DROPPER.schedule_drop(self.inner.take());
    }
}
```

**File:** execution/executor-types/src/state_compute_result.rs (L30-34)
```rust
pub struct StateComputeResult {
    pub execution_output: ExecutionOutput,
    pub state_checkpoint_output: StateCheckpointOutput,
    pub ledger_update_output: LedgerUpdateOutput,
}
```

**File:** execution/executor-types/src/execution_output.rs (L25-29)
```rust
#[derive(Clone, Debug, Deref)]
pub struct ExecutionOutput {
    #[deref]
    inner: Arc<DropHelper<Inner>>,
}
```

**File:** storage/storage-interface/src/state_store/state.rs (L62-74)
```rust
pub struct State {
    /// The next version. If this is 0, the state is the "pre-genesis" empty state.
    next_version: Version,
    /// The updates made to the state at the current version.
    ///  N.b. this is not directly iterable, one needs to make a `StateDelta`
    ///       between this and a `base_version` to list the updates or create a
    ///       new `State` at a descendant version.
    shards: Arc<[MapLayer<StateKey, StateSlot>; NUM_STATE_SHARDS]>,
    hot_state_metadata: [HotStateMetadata; NUM_STATE_SHARDS],
    /// The total usage of the state at the current version.
    usage: StateStorageUsage,
    hot_state_config: HotStateConfig,
}
```

**File:** storage/storage-interface/src/state_store/state.rs (L390-394)
```rust
pub struct LedgerState {
    last_checkpoint: State,
    #[deref]
    latest: State,
}
```

**File:** experimental/storage/layered-map/src/layer.rs (L32-49)
```rust
impl<K: ArcAsyncDrop, V: ArcAsyncDrop> Drop for LayerInner<K, V> {
    fn drop(&mut self) {
        // Drop the tree nodes in a different thread, because that's the slowest part.
        DROPPER.schedule_drop(self.peak.take_for_drop());

        let mut stack = self.drain_children_for_drop();
        while let Some(descendant) = stack.pop() {
            if Arc::strong_count(&descendant) == 1 {
                // The only ref is the one we are now holding, so the
                // descendant will be dropped after we free the `Arc`, which results in a chain
                // of such structures being dropped recursively and that might trigger a stack
                // overflow. To prevent that we follow the chain further to disconnect things
                // beforehand.
                stack.extend(descendant.drain_children_for_drop());
            }
        }
        self.log_layer("dropped");
    }
```
