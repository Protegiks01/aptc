# Audit Report

## Title
Mempool Snapshot Generation Causes Validator Node Slowdowns via Prolonged Lock Holding

## Summary
The `gen_snapshot()` function unconditionally creates a `TxnsLog` with unlimited capacity and iterates through all mempool transactions while holding the mempool lock. When trace logging is enabled and the mempool contains millions of transactions, this causes prolonged lock holding every 3 minutes, blocking critical mempool operations including consensus transaction retrieval via `get_batch()`, leading to validator node slowdowns and potential missed consensus rounds.

## Finding Description

The vulnerability exists in the interaction between three components:

**1. TxnsLog unlimited capacity**: The `TxnsLog::new()` constructor sets `max_displayed` to `usize::MAX`, allowing unbounded growth. [1](#0-0) 

**2. gen_snapshot() iteration without limits**: The `gen_snapshot()` function creates a `TxnsLog` and iterates through ALL transactions in the mempool, adding each transaction's full metadata to the log without any capacity checks. [2](#0-1) 

**3. Lock holding during snapshot generation**: The `snapshot_job()` acquires the mempool lock via `mempool.lock()` and holds it for the entire duration of `gen_snapshot()` execution. [3](#0-2) 

**Attack Scenario:**
1. Operator enables trace logging for debugging purposes. The `snapshot_job()` is only spawned when trace logging is enabled. [4](#0-3) 

2. Attacker fills mempool with transactions up to the default capacity of 2,000,000 transactions [5](#0-4)  by submitting transactions across multiple accounts (limited to 100 sequence number transactions per account). [6](#0-5) 

3. Every 180 seconds (default snapshot interval) [7](#0-6) , `snapshot_job()` locks the mempool and calls `gen_snapshot()`.

4. During this operation, the mempool remains locked, blocking consensus transaction pulls. When consensus calls `get_batch()` to retrieve transactions, it must acquire the same mempool lock [8](#0-7) , causing it to block until the snapshot completes.

5. The lock implementation is `std::sync::Mutex`, a blocking mutex. [9](#0-8) 

6. Result: Validator cannot provide transactions to consensus during the snapshot generation, potentially causing empty blocks or degraded consensus participation.

**Code Inconsistency**: Other logging code in the same file checks the trace logging level and uses `TxnsLog::new_with_max(10)` when trace is disabled to limit memory allocation. [10](#0-9)  This pattern is repeated elsewhere [11](#0-10)  but is not applied to `gen_snapshot()`, suggesting this is an oversight.

## Impact Explanation

This qualifies as **High Severity** per the Aptos bug bounty program under "Validator node slowdowns". The specific impacts are:

1. **Consensus Participation Degradation**: While the mempool lock is held during snapshot generation, consensus cannot retrieve transactions via `get_batch()`. This blocks the consensus component from obtaining transactions to include in proposed blocks, potentially causing validators to propose empty blocks or experience degraded consensus participation.

2. **Transaction Processing Delays**: New transactions cannot be added to the mempool during the lock period, causing user-visible delays and potential transaction timeouts.

3. **Memory Pressure**: Allocating storage for potentially millions of transaction entries (up to ~250 MB for 2M transactions) every 3 minutes can contribute to memory pressure on validator nodes.

While this vulnerability requires trace logging to be enabled (not typical for production), trace logging is a legitimate debugging tool that operators enable when investigating issues. The disproportionate performance impact—blocking critical consensus operations—makes this a security issue rather than expected debugging overhead.

## Likelihood Explanation

**Likelihood: Medium to Low** (but impact is High when triggered)

The vulnerability requires:
- Trace logging enabled at node startup (operator decision for debugging)
- Mempool filled to high capacity (attacker action OR natural high load)

Mitigating factors:
- Trace logging is not typically enabled in production environments
- Operators control logging configuration

Aggravating factors:
- Operators legitimately enable trace logging when debugging network issues
- During debugging sessions, the network often experiences high load, making full mempools more likely
- An attacker who observes trace logging is enabled can deliberately fill the mempool to maximize impact

The inconsistency with other logging code that uses capacity limits when trace is disabled suggests this is an unintentional oversight rather than intentional design.

## Recommendation

Apply the same pattern used elsewhere in the codebase: check the trace logging level in `gen_snapshot()` and use a limited capacity `TxnsLog` when generating snapshots:

```rust
pub(crate) fn gen_snapshot(&self) -> TxnsLog {
    let mut txns_log = match aptos_logger::enabled!(Level::Trace) {
        true => TxnsLog::new(),
        false => TxnsLog::new_with_max(10),
    };
    for (account, txns) in self.transactions.iter() {
        for txn in txns.values() {
            let status = match txn.get_replay_protector() {
                // ... existing logic ...
            };
            txns_log.add_full_metadata(
                *account,
                txn.get_replay_protector(),
                status,
                txn.insertion_info.insertion_time,
            );
        }
    }
    txns_log
}
```

Alternatively, since `snapshot_job()` is only spawned when trace logging is enabled, consider adding an explicit limit (e.g., `TxnsLog::new_with_max(10000)`) to prevent unbounded iteration even when trace is enabled.

## Proof of Concept

No executable PoC is provided, but the vulnerability can be demonstrated through code analysis as shown above. To reproduce:

1. Start a validator node with trace logging enabled (`RUST_LOG=trace`)
2. Fill mempool to high capacity (approaching 2M transactions) by submitting transactions from multiple accounts
3. Monitor the mempool lock acquisition metrics during snapshot generation every 180 seconds
4. Observe that consensus `get_batch()` calls are blocked during snapshot generation
5. Monitor for empty blocks or reduced transaction throughput during snapshot intervals

**Notes**

The vulnerability is valid based on code analysis and meets the High Severity criteria for "Validator node slowdowns" in the Aptos bug bounty program. The key security concern is that a debugging feature (trace logging + snapshot generation) can inadvertently block critical consensus operations by holding the mempool lock for extended periods when processing large transaction sets. The inconsistency with other logging code patterns in the same file strongly suggests this is an oversight that should be corrected to maintain validator performance even when trace logging is enabled for debugging purposes.

### Citations

**File:** mempool/src/logging.rs (L26-28)
```rust
    pub fn new() -> Self {
        Self::new_with_max(usize::MAX)
    }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L650-652)
```rust
            let mut rm_txns = match aptos_logger::enabled!(Level::Trace) {
                true => TxnsLog::new(),
                false => TxnsLog::new_with_max(10),
```

**File:** mempool/src/core_mempool/transaction_store.rs (L936-938)
```rust
        let mut gc_txns_log = match aptos_logger::enabled!(Level::Trace) {
            true => TxnsLog::new(),
            false => TxnsLog::new_with_max(10),
```

**File:** mempool/src/core_mempool/transaction_store.rs (L1012-1038)
```rust
    pub(crate) fn gen_snapshot(&self) -> TxnsLog {
        let mut txns_log = TxnsLog::new();
        for (account, txns) in self.transactions.iter() {
            for txn in txns.values() {
                let status = match txn.get_replay_protector() {
                    ReplayProtector::SequenceNumber(_) => {
                        if self.parking_lot_index.contains(
                            account,
                            txn.get_replay_protector(),
                            txn.get_committed_hash(),
                        ) {
                            "parked"
                        } else {
                            "ready"
                        }
                    },
                    ReplayProtector::Nonce(_) => "ready",
                };
                txns_log.add_full_metadata(
                    *account,
                    txn.get_replay_protector(),
                    status,
                    txn.insertion_info.insertion_time,
                );
            }
        }
        txns_log
```

**File:** mempool/src/shared_mempool/coordinator.rs (L465-470)
```rust
pub(crate) async fn snapshot_job(mempool: Arc<Mutex<CoreMempool>>, snapshot_interval_secs: u64) {
    let mut interval = IntervalStream::new(interval(Duration::from_secs(snapshot_interval_secs)));
    while let Some(_interval) = interval.next().await {
        let snapshot = mempool.lock().gen_snapshot();
        trace!(LogSchema::new(LogEntry::MempoolSnapshot).txns(snapshot));
    }
```

**File:** mempool/src/shared_mempool/runtime.rs (L83-88)
```rust
    if aptos_logger::enabled!(Level::Trace) {
        executor.spawn(snapshot_job(
            mempool,
            config.mempool.mempool_snapshot_interval_secs,
        ));
    }
```

**File:** config/src/config/mempool_config.rs (L120-120)
```rust
            mempool_snapshot_interval_secs: 180,
```

**File:** config/src/config/mempool_config.rs (L121-121)
```rust
            capacity: 2_000_000,
```

**File:** config/src/config/mempool_config.rs (L123-123)
```rust
            capacity_per_user: 100,
```

**File:** mempool/src/shared_mempool/tasks.rs (L654-674)
```rust
                let mut mempool = smp.mempool.lock();
                lock_timer.observe_duration();

                {
                    let _gc_timer = counters::mempool_service_start_latency_timer(
                        counters::GET_BLOCK_GC_LABEL,
                        counters::REQUEST_SUCCESS_LABEL,
                    );
                    // gc before pulling block as extra protection against txns that may expire in consensus
                    // Note: this gc operation relies on the fact that consensus uses the system time to determine block timestamp
                    let curr_time = aptos_infallible::duration_since_epoch();
                    mempool.gc_by_expiration_time(curr_time);
                }

                let max_txns = cmp::max(max_txns, 1);
                let _get_batch_timer = counters::mempool_service_start_latency_timer(
                    counters::GET_BLOCK_GET_BATCH_LABEL,
                    counters::REQUEST_SUCCESS_LABEL,
                );
                txns =
                    mempool.get_batch(max_txns, max_bytes, return_non_full, exclude_transactions);
```

**File:** crates/aptos-infallible/src/mutex.rs (L4-23)
```rust
use std::sync::Mutex as StdMutex;
pub use std::sync::MutexGuard;

/// A simple wrapper around the lock() function of a std::sync::Mutex
/// The only difference is that you don't need to call unwrap() on it.
#[derive(Debug)]
pub struct Mutex<T>(StdMutex<T>);

impl<T> Mutex<T> {
    /// creates mutex
    pub fn new(t: T) -> Self {
        Self(StdMutex::new(t))
    }

    /// lock the mutex
    pub fn lock(&self) -> MutexGuard<'_, T> {
        self.0
            .lock()
            .expect("Cannot currently handle a poisoned lock")
    }
```
