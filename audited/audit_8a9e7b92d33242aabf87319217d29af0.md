# Audit Report

## Title
Unbounded Memory Consumption in StateKvShardPruner Leading to Potential Node Availability Issues

## Summary
The `StateKvShardPruner::prune()` function processes entire version ranges without internal batching, accumulating all delete operations in an unbounded `SchemaBatch`. In high-throughput scenarios with many state updates per version, this can lead to excessive memory consumption, write stalls, and potential node crashes.

## Finding Description

The `StateKvShardPruner::prune()` function is responsible for pruning stale state values from database shards when sharding is enabled. The function has a critical design flaw: it processes the entire version range from `current_progress` to `target_version` without internal batching. [1](#0-0) 

The function iterates through all stale state value indices in the version range and adds ALL delete operations to a single `SchemaBatch` in memory. There is no size limit on `SchemaBatch`: [2](#0-1) 

The parent `StateKvPruner` does batch at the top level using `max_versions` (default 5,000): [3](#0-2) 

However, each call to `StateKvShardPruner::prune()` still processes the entire batch range without further subdivision. The default batch size comes from `LedgerPrunerConfig`: [4](#0-3) 

**The Core Issue:**
- Each version can contain many state updates (touching different keys)
- Each state update creates a stale state value entry when the key is updated again
- Over 5,000 versions with high throughput, there could be hundreds of thousands or millions of stale entries
- All are loaded into a single `SchemaBatch` in memory

**Why RocksDB Doesn't Block But Still Causes Issues:**

While RocksDB uses MVCC and doesn't hold exclusive locks during iteration, the issues are:

1. **Memory Exhaustion**: The `SchemaBatch` grows unbounded in memory, potentially causing OOM errors and node crashes

2. **Write Stalls**: When the large batch is committed via `write_schemas()`, RocksDB can experience write stalls that affect the entire node's database operations [5](#0-4) 

3. **Snapshot Retention**: The iterator holds an implicit RocksDB snapshot throughout the iteration, preventing compaction and disk space reclamation

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty criteria for the following reasons:

**Validator Node Slowdowns**: The write stalls caused by committing large batches can significantly slow down all database operations on the node, affecting block processing, state commitment, and API responses.

**API Crashes**: If memory exhaustion causes an OOM error, the entire validator node process crashes, requiring restart. During downtime, the validator cannot participate in consensus.

**Availability Impact**: While a single node crash doesn't cause network partition, if multiple validators experience this simultaneously during high-throughput periods, it could impact network liveness.

The issue breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits" - the pruner does not respect memory limits.

## Likelihood Explanation

**Likelihood: Medium to High**

The issue is likely to occur in the following scenarios:

1. **High-Throughput Mainnet Operation**: On mainnet with sustained high TPS (thousands of transactions per second), each version contains hundreds of state updates. Over a 5,000 version range, this easily results in millions of stale entries.

2. **Natural Occurrence**: This doesn't require attacker action - normal high-throughput blockchain operation will trigger it.

3. **Exacerbation by Attackers**: Transaction senders could deliberately submit transactions that update many different state keys, maximizing stale entry creation. While this costs gas, it could amplify the natural issue.

4. **Default Configuration**: Sharding is enabled by default on mainnet/testnet: [6](#0-5) 

The likelihood is high enough that this represents a real operational risk for validator nodes.

## Recommendation

Implement internal batching within `StateKvShardPruner::prune()` to limit the size of each `SchemaBatch`. The fix should:

1. Add a maximum batch size constant (e.g., 10,000 entries per batch)
2. Subdivide the iteration into smaller chunks
3. Commit each chunk separately
4. Update progress incrementally

**Suggested Fix:**

```rust
pub(in crate::pruner) fn prune(
    &self,
    current_progress: Version,
    target_version: Version,
) -> Result<()> {
    const MAX_ENTRIES_PER_BATCH: usize = 10_000;
    
    let mut progress = current_progress;
    let mut iter = self
        .db_shard
        .iter::<StaleStateValueIndexByKeyHashSchema>()?;
    iter.seek(&progress)?;
    
    while progress < target_version {
        let mut batch = SchemaBatch::new();
        let mut count = 0;
        
        for item in &mut iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
            
            count += 1;
            progress = index.stale_since_version;
            
            if count >= MAX_ENTRIES_PER_BATCH {
                break;
            }
        }
        
        if count > 0 {
            batch.put::<DbMetadataSchema>(
                &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
                &DbMetadataValue::Version(progress),
            )?;
            self.db_shard.write_schemas(batch)?;
        } else {
            break; // No more entries
        }
    }
    
    // Final progress update
    let mut batch = SchemaBatch::new();
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
        &DbMetadataValue::Version(target_version),
    )?;
    self.db_shard.write_schemas(batch)
}
```

## Proof of Concept

Due to the nature of this vulnerability, a full PoC requires setting up a high-throughput test environment. However, the vulnerability can be demonstrated by:

1. Creating a test that simulates many stale state values
2. Monitoring memory usage during pruning
3. Observing unbounded growth

**Simplified demonstration steps:**

```rust
#[test]
fn test_unbounded_batch_growth() {
    // 1. Create a test database with sharding enabled
    // 2. Insert 100,000 state updates across 5,000 versions
    // 3. Mark them all as stale
    // 4. Call StateKvShardPruner::prune() with range 0..5000
    // 5. Monitor memory usage - should see unbounded growth
    // 6. Compare with a batched version that limits entries per batch
    
    // Expected: Without batching, memory usage proportional to total entries
    // With batching: Memory usage bounded by MAX_ENTRIES_PER_BATCH
}
```

The vulnerability is evident from code inspection: the single `SchemaBatch` created at line 52 accumulates all deletes from lines 63-64 without any size checks or intermediate commits. [7](#0-6) 

## Notes

This vulnerability is specific to the sharded state KV pruner implementation. The non-sharded path in `StateKvMetadataPruner` has similar issues but is not used on mainnet/testnet where sharding is enabled. The issue represents a gap between the designed batch size at the `StateKvPruner` level and the actual implementation at the `StateKvShardPruner` level, where internal batching is missing.

### Citations

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L47-72)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
            &DbMetadataValue::Version(target_version),
        )?;

        self.db_shard.write_schemas(batch)
    }
```

**File:** storage/schemadb/src/batch.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::{
    metrics::{APTOS_SCHEMADB_DELETES_SAMPLED, APTOS_SCHEMADB_PUT_BYTES_SAMPLED, TIMER},
    schema::{KeyCodec, Schema, ValueCodec},
    ColumnFamilyName, DB,
};
use aptos_drop_helper::DropHelper;
use aptos_metrics_core::{IntCounterVecHelper, TimerHelper};
use aptos_storage_interface::Result as DbResult;
use std::{
    collections::HashMap,
    fmt::{Debug, Formatter},
};

#[derive(Debug, Default)]
pub struct BatchStats {
    put_sizes: HashMap<ColumnFamilyName, Vec<usize>>,
    num_deletes: HashMap<ColumnFamilyName, usize>,
}

impl BatchStats {
    fn put(&mut self, cf_name: ColumnFamilyName, size: usize) {
        self.put_sizes.entry(cf_name).or_default().push(size);
    }

    fn delete(&mut self, cf_name: ColumnFamilyName) {
        *self.num_deletes.entry(cf_name).or_default() += 1
    }

    fn commit(&self) {
        for (cf_name, put_sizes) in &self.put_sizes {
            for put_size in put_sizes {
                APTOS_SCHEMADB_PUT_BYTES_SAMPLED.observe_with(&[cf_name], *put_size as f64);
            }
        }
        for (cf_name, num_deletes) in &self.num_deletes {
            APTOS_SCHEMADB_DELETES_SAMPLED.inc_with_by(&[cf_name], *num_deletes as u64);
        }
    }
}

#[derive(Debug)]
pub struct SampledBatchStats {
    inner: Option<BatchStats>,
}

impl SampledBatchStats {
    pub fn put(&mut self, cf_name: ColumnFamilyName, size: usize) {
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L49-86)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_pruner__prune"]);

        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning state kv data."
            );
            self.metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.shard_pruners.par_iter().try_for_each(|shard_pruner| {
                    shard_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| {
                            anyhow!(
                                "Failed to prune state kv shard {}: {err}",
                                shard_pruner.shard_id(),
                            )
                        })
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning state kv data is done.");
        }

        Ok(target_version)
    }
```

**File:** config/src/config/storage_config.rs (L219-239)
```rust
impl Default for RocksdbConfigs {
    fn default() -> Self {
        Self {
            ledger_db_config: RocksdbConfig::default(),
            state_merkle_db_config: RocksdbConfig::default(),
            state_kv_db_config: RocksdbConfig {
                bloom_filter_bits: Some(10.0),
                bloom_before_level: Some(2),
                ..Default::default()
            },
            index_db_config: RocksdbConfig {
                max_open_files: 1000,
                ..Default::default()
            },
            enable_storage_sharding: true,
            high_priority_background_threads: 4,
            low_priority_background_threads: 2,
            shared_block_cache_size: Self::DEFAULT_BLOCK_CACHE_SIZE,
        }
    }
}
```

**File:** config/src/config/storage_config.rs (L387-396)
```rust
impl Default for LedgerPrunerConfig {
    fn default() -> Self {
        LedgerPrunerConfig {
            enable: true,
            prune_window: 90_000_000,
            batch_size: 5_000,
            user_pruning_window_offset: 200_000,
        }
    }
}
```

**File:** storage/schemadb/src/lib.rs (L289-310)
```rust
    fn write_schemas_inner(&self, batch: impl IntoRawBatch, option: &WriteOptions) -> DbResult<()> {
        let labels = [self.name.as_str()];
        let _timer = APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS.timer_with(&labels);

        let raw_batch = batch.into_raw_batch(self)?;

        let serialized_size = raw_batch.inner.size_in_bytes();
        self.inner
            .write_opt(raw_batch.inner, option)
            .into_db_res()?;

        raw_batch.stats.commit();
        APTOS_SCHEMADB_BATCH_COMMIT_BYTES.observe_with(&[&self.name], serialized_size as f64);

        Ok(())
    }

    /// Writes a group of records wrapped in a [`SchemaBatch`].
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }

```
