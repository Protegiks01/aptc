# Audit Report

## Title
SafetyData Deserialization Allows Equivocation Through Storage Corruption Leading to Consensus Safety Violation

## Summary
The `SafetyData` struct is deserialized from storage without any validation of field consistency. A corrupted or malicious storage backend can inject `SafetyData` with semantically inconsistent fields (e.g., `last_voted_round` lowered from 100 to 50, `last_vote` set to None) that passes serde JSON validation but allows the validator to double-vote in the same round, violating AptosBFT consensus safety guarantees. [1](#0-0) 

## Finding Description

The `SafetyData` struct stores critical consensus safety state including `epoch`, `last_voted_round`, `preferred_round`, `one_chain_round`, and `last_vote`. These fields have semantic relationships that must be maintained to prevent equivocation (double-voting). [2](#0-1) 

When `SafetyData` is loaded from storage, it undergoes pure serde JSON deserialization with no semantic validation of field consistency: [3](#0-2) 

The voting logic in SafetyRules relies on two critical checks to prevent double-voting:

1. **Round check**: Ensures `round > safety_data.last_voted_round` [4](#0-3) 

2. **Last vote check**: Returns previous vote if already voted in this round [5](#0-4) 

**Attack Scenario:**

1. Validator legitimately votes in epoch 1, round 100, creating vote V1
2. Storage backend (on-disk, Vault, or in-memory) becomes corrupted or is maliciously modified to contain:
   ```json
   {
     "epoch": 1,
     "last_voted_round": 50,  // Lowered from 100
     "preferred_round": 49,
     "one_chain_round": 49,
     "last_vote": null,        // Cleared
     "highest_timeout_round": 0
   }
   ```
3. Validator restarts or re-queries storage
4. Network re-proposes round 100 (due to network delays, state sync, or Byzantine behavior)
5. In `guarded_construct_and_sign_vote_two_chain`:
   - Line 70-74: `last_vote` is None, so duplicate check doesn't trigger
   - Line 77-80: `verify_and_update_last_vote_round(100, ...)` checks `100 <= 50` â†’ FALSE, passes!
   - Validator creates NEW vote V2 for round 100 with different signature

6. Network now has two conflicting votes (V1 and V2) from the same validator for round 100
7. Different validators may observe different votes, potentially forming conflicting quorum certificates
8. **Consensus safety violation**: Chain split becomes possible even with < 1/3 Byzantine validators [6](#0-5) 

While equivocation detection exists in `PendingVotes`, it only protects against receiving two different votes at the same node in the same session: [7](#0-6) 

This detection **does not** protect against the scenario where:
- Vote V1 is created and broadcast before corruption
- Storage is corrupted
- Validator restarts and creates vote V2
- Different network nodes observe different votes (some saw V1 before, some see V2 now)

## Impact Explanation

**Critical Severity** - This vulnerability directly violates AptosBFT consensus safety guarantees:

1. **Equivocation**: Validator creates multiple votes for the same round, breaking the fundamental BFT assumption that honest validators vote once per round
2. **Chain Split Risk**: Different validators may form conflicting quorum certificates based on which vote they observed
3. **Safety Violation**: Even with < 1/3 Byzantine validators, consensus safety can be broken if storage corruption affects multiple validators
4. **Non-recoverable**: Once conflicting QCs are formed and blocks committed, the chain split may require a hard fork to resolve

This meets the **Critical Severity** category: "Consensus/Safety violations" with potential for "Non-recoverable network partition (requires hardfork)."

## Likelihood Explanation

**Medium to High Likelihood:**

1. **Storage corruption sources:**
   - File system corruption on validator nodes
   - Bugs in storage backend implementations (Vault, on-disk, in-memory)
   - Backup/restore operations that restore stale SafetyData
   - State synchronization bugs during validator recovery
   - Malicious operators with file system access

2. **No defense-in-depth:** Critical consensus safety depends entirely on storage integrity with zero validation

3. **Attack surface:** Any of OnDiskStorage, VaultStorage, or InMemoryStorage implementations could experience corruption

4. **Real-world precedent:** Storage corruption is a known issue in distributed systems, and blockchain consensus is particularly sensitive to state inconsistencies

## Recommendation

Implement comprehensive validation of `SafetyData` after deserialization to ensure field consistency:

```rust
impl SafetyData {
    /// Validates internal consistency of SafetyData fields
    pub fn validate(&self) -> Result<(), String> {
        // Validate last_vote consistency
        if let Some(ref vote) = self.last_vote {
            let vote_round = vote.vote_data().proposed().round();
            let vote_epoch = vote.vote_data().proposed().epoch();
            
            if vote_epoch != self.epoch {
                return Err(format!(
                    "last_vote epoch {} doesn't match SafetyData epoch {}",
                    vote_epoch, self.epoch
                ));
            }
            
            if vote_round != self.last_voted_round {
                return Err(format!(
                    "last_vote round {} doesn't match last_voted_round {}",
                    vote_round, self.last_voted_round
                ));
            }
        }
        
        // Validate round relationships
        // In 2-chain, we expect: one_chain_round >= preferred_round (usually)
        // and last_voted_round should be >= 0 (always)
        
        // Validate highest_timeout_round relationship
        if self.highest_timeout_round > self.last_voted_round {
            // This is suspicious but not necessarily invalid
            // Could log a warning
        }
        
        Ok(())
    }
}
```

Then call validation in `PersistentSafetyStorage::safety_data()`:

```rust
pub fn safety_data(&mut self) -> Result<SafetyData, Error> {
    let safety_data = if !self.enable_cached_safety_data {
        self.internal_store.get(SAFETY_DATA).map(|v| v.value)?
    } else {
        // ... existing caching logic
    };
    
    // Validate consistency after deserialization
    safety_data.validate()
        .map_err(|e| Error::InternalError(format!("SafetyData validation failed: {}", e)))?;
    
    Ok(safety_data)
}
```

Additionally, consider:
1. Adding cryptographic signatures/HMACs to SafetyData to detect tampering
2. Implementing storage integrity checks (checksums, merkle proofs)
3. Maintaining write-ahead logs for SafetyData changes
4. Adding telemetry to detect suspicious SafetyData inconsistencies

## Proof of Concept

```rust
#[cfg(test)]
mod vulnerability_poc {
    use super::*;
    use aptos_consensus_types::{safety_data::SafetyData, vote::Vote};
    use aptos_crypto::HashValue;
    use aptos_secure_storage::{InMemoryStorage, Storage, KVStorage};
    use aptos_global_constants::SAFETY_DATA;
    
    #[test]
    fn test_corrupted_safety_data_allows_equivocation() {
        // Step 1: Validator votes in round 100
        let legitimate_safety_data = SafetyData::new(
            1,      // epoch
            100,    // last_voted_round - voted in round 100
            99,     // preferred_round
            99,     // one_chain_round
            Some(create_test_vote(100)), // last_vote for round 100
            0,      // highest_timeout_round
        );
        
        // Step 2: Store in storage
        let mut storage = Storage::from(InMemoryStorage::new());
        storage.set(SAFETY_DATA, legitimate_safety_data.clone()).unwrap();
        
        // Step 3: Simulate storage corruption - lower last_voted_round and clear last_vote
        let corrupted_safety_data = SafetyData::new(
            1,      // epoch (same)
            50,     // last_voted_round - CORRUPTED (lowered from 100)
            49,     // preferred_round
            49,     // one_chain_round
            None,   // last_vote - CORRUPTED (cleared)
            0,      // highest_timeout_round
        );
        storage.set(SAFETY_DATA, corrupted_safety_data).unwrap();
        
        // Step 4: Load from storage - passes serde validation!
        let loaded_data: SafetyData = storage.get(SAFETY_DATA).unwrap().value;
        assert_eq!(loaded_data.epoch, 1);
        assert_eq!(loaded_data.last_voted_round, 50); // Corrupted value
        assert!(loaded_data.last_vote.is_none()); // Corrupted value
        
        // Step 5: Validator can now vote in round 100 again!
        // In real code, verify_and_update_last_vote_round would check:
        // if round <= safety_data.last_voted_round  => if 100 <= 50 => FALSE
        // So the check PASSES when it should FAIL!
        
        let can_vote_again = 100 > loaded_data.last_voted_round; // TRUE!
        assert!(can_vote_again, "VULNERABILITY: Can vote in round 100 again despite having already voted!");
        
        // This allows creating a second vote for the same round
        // Leading to equivocation and potential consensus safety violation
    }
    
    fn create_test_vote(round: u64) -> Vote {
        // Simplified test vote creation
        // In real test would use proper VoteProposal construction
        unimplemented!("Use proper test utilities from safety_rules tests")
    }
}
```

**Notes:**
- Storage corruption can occur through multiple vectors: file system errors, backup restoration, state sync bugs, or malicious modification
- The lack of validation creates a single point of failure where storage integrity directly determines consensus safety
- Defense-in-depth principles require validating critical security state after deserialization, especially for consensus-critical data structures
- The fix is straightforward and adds minimal performance overhead while providing strong safety guarantees

### Citations

**File:** consensus/consensus-types/src/safety_data.rs (L9-21)
```rust
#[derive(Debug, Deserialize, Eq, PartialEq, Serialize, Clone, Default)]
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L134-148)
```rust
    pub fn safety_data(&mut self) -> Result<SafetyData, Error> {
        if !self.enable_cached_safety_data {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            return self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
        }

        if let Some(cached_safety_data) = self.cached_safety_data.clone() {
            Ok(cached_safety_data)
        } else {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            let safety_data: SafetyData = self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
            self.cached_safety_data = Some(safety_data.clone());
            Ok(safety_data)
        }
    }
```

**File:** secure/storage/src/on_disk.rs (L78-83)
```rust
    fn get<V: DeserializeOwned>(&self, key: &str) -> Result<GetResponse<V>, Error> {
        let mut data = self.read()?;
        data.remove(key)
            .ok_or_else(|| Error::KeyNotSet(key.to_string()))
            .and_then(|value| serde_json::from_value(value).map_err(|e| e.into()))
    }
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L53-95)
```rust
    pub(crate) fn guarded_construct_and_sign_vote_two_chain(
        &mut self,
        vote_proposal: &VoteProposal,
        timeout_cert: Option<&TwoChainTimeoutCertificate>,
    ) -> Result<Vote, Error> {
        // Exit early if we cannot sign
        self.signer()?;

        let vote_data = self.verify_proposal(vote_proposal)?;
        if let Some(tc) = timeout_cert {
            self.verify_tc(tc)?;
        }
        let proposed_block = vote_proposal.block();
        let mut safety_data = self.persistent_storage.safety_data()?;

        // if already voted on this round, send back the previous vote
        // note: this needs to happen after verifying the epoch as we just check the round here
        if let Some(vote) = safety_data.last_vote.clone() {
            if vote.vote_data().proposed().round() == proposed_block.round() {
                return Ok(vote);
            }
        }

        // Two voting rules
        self.verify_and_update_last_vote_round(
            proposed_block.block_data().round(),
            &mut safety_data,
        )?;
        self.safe_to_vote(proposed_block, timeout_cert)?;

        // Record 1-chain data
        self.observe_qc(proposed_block.quorum_cert(), &mut safety_data);
        // Construct and sign vote
        let author = self.signer()?.author();
        let ledger_info = self.construct_ledger_info_2chain(proposed_block, vote_data.hash())?;
        let signature = self.sign(&ledger_info)?;
        let vote = Vote::new_with_signature(vote_data, author, ledger_info, signature);

        safety_data.last_vote = Some(vote.clone());
        self.persistent_storage.set_safety_data(safety_data)?;

        Ok(vote)
    }
```

**File:** consensus/src/pending_votes.rs (L287-308)
```rust
        if let Some((previously_seen_vote, previous_li_digest)) =
            self.author_to_vote.get(&vote.author())
        {
            // is it the same vote?
            if &li_digest == previous_li_digest {
                // we've already seen an equivalent vote before
                let new_timeout_vote = vote.is_timeout() && !previously_seen_vote.is_timeout();
                if !new_timeout_vote {
                    // it's not a new timeout vote
                    return VoteReceptionResult::DuplicateVote;
                }
            } else {
                // we have seen a different vote for the same round
                error!(
                    SecurityEvent::ConsensusEquivocatingVote,
                    remote_peer = vote.author(),
                    vote = vote,
                    previous_vote = previously_seen_vote
                );

                return VoteReceptionResult::EquivocateVote;
            }
```
