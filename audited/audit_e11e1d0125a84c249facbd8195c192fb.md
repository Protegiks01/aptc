# Audit Report

## Title
State Synchronization Premature Finalization via Empty SparseMerkleRangeProof Bypass

## Summary
A vulnerability in the state synchronization process allows malicious peers to force syncing nodes to prematurely finalize state restoration with incomplete data. The issue arises from `is_last_chunk()` returning `true` for empty proofs combined with empty chunks bypassing proof verification, enabling attackers to corrupt individual syncing nodes' state merkle trees.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Empty Proof Generation**: The `StateValueChunkWithProof` struct derives `proptest_derive::Arbitrary`, allowing generation of instances with empty `raw_values` and empty `SparseMerkleRangeProof`. [1](#0-0) 

2. **is_last_chunk() Vacuous Truth**: The method returns `true` when all right siblings are placeholder hashes. For an empty vector, `iter().all(predicate)` returns `true` vacuously due to Rust's iterator semantics. [2](#0-1) 

3. **Empty Chunk Verification Bypass**: When a chunk is empty, `add_chunk_impl()` returns early at line 369-371 **before** calling `verify()` at line 391, accepting any proof without cryptographic verification. [3](#0-2) 

**Attack Flow:**

1. Syncing node requests state chunks from network peers
2. Malicious peer sends legitimate chunks with valid proofs (e.g., first 100 accounts)
3. Attacker sends an **empty chunk** (`raw_values = vec![]`) with an **empty proof** (`right_siblings = vec![]`)
4. State synchronizer checks `is_last_chunk()` â†’ returns `true` [4](#0-3) 
5. `add_chunk()` is called, which returns early without verification [5](#0-4) 
6. Because `all_states_synced = true`, finalization is triggered [6](#0-5) 
7. `finish_impl()` freezes partial nodes and writes an **incorrect root hash** to storage without verification against `expected_root_hash` [7](#0-6) 

The vulnerability violates the critical invariant that the finalized tree's root hash must match `expected_root_hash`, but this check is absent in `finish_impl()`.

## Impact Explanation

**Medium Severity** - This vulnerability causes state corruption in individual syncing nodes:

1. **State Inconsistency for Syncing Nodes**: Affected nodes end up with incomplete state trees that don't match the expected root hash. This prevents the node from properly serving the network.

2. **Detection on Restart**: The incorrect root hash is detected when `JellyfishMerkleRestore::new()` checks the stored root against `expected_root_hash` during node restart, causing startup failure. [8](#0-7) 

3. **Manual Intervention Required**: The affected node must resync from scratch or from a different, honest peer to recover.

This qualifies as **Medium Severity** under the bug bounty program because:
- It affects syncing nodes individually, not the consensus network
- It causes state inconsistencies requiring manual intervention
- It does NOT enable fund theft, consensus violations, or network-wide impact
- It does NOT affect active validators participating in consensus
- The corruption is detected (fail-safe behavior) rather than silently persisting

## Likelihood Explanation

**High Likelihood** - The attack is easily exploitable:

1. **Low Complexity**: Attacker only needs to serve malicious state chunks during sync, requiring no validator access or special privileges
2. **Common Scenario**: State synchronization occurs frequently (new nodes joining, nodes catching up after downtime)
3. **Protocol Relies on Proofs**: The peer scoring system exists, but the protocol's security depends on cryptographic proof verification, which is bypassed
4. **Silent Failure**: The attack succeeds without immediate detection, only failing on node restart

The attack requires the victim node to be in state sync mode and requesting chunks from a malicious peer, which is a realistic scenario in a P2P network where peer selection occurs.

## Recommendation

Add verification of the root hash in `finish_impl()` before writing to storage:

```rust
pub fn finish_impl(mut self) -> Result<()> {
    self.wait_for_async_commit()?;
    
    // Deal with special cases...
    if self.partial_nodes.len() == 1 {
        // ... existing special case handling ...
    }
    
    self.freeze(0);
    
    // ADDED: Verify the root hash matches expected before writing
    if let Some(root_node) = self.frozen_nodes.get(&NodeKey::new_empty_path(self.version)) {
        ensure!(
            root_node.hash() == self.expected_root_hash,
            "Root hash mismatch: computed {:x}, expected {:x}",
            root_node.hash(),
            self.expected_root_hash
        );
    }
    
    self.store.write_node_batch(&self.frozen_nodes)?;
    Ok(())
}
```

Additionally, consider rejecting empty chunks early in the validation flow or ensuring `verify()` is always called regardless of chunk size.

## Proof of Concept

A PoC would involve:
1. Setting up a state sync scenario with a mock peer
2. Sending legitimate chunks followed by an empty chunk with empty proof
3. Demonstrating that `is_last_chunk()` returns true
4. Verifying that finalization occurs prematurely
5. Confirming the incorrect root hash is written to storage
6. Showing detection failure occurs on restart

The vulnerability is confirmed through code analysis tracing the execution path from empty chunk reception through premature finalization without root hash verification.

## Notes

While the technical vulnerability is valid, the actual security impact is limited to individual syncing nodes rather than consensus-level effects. The fail-safe behavior (detection on restart) prevents silent corruption from persisting indefinitely, reducing the overall risk compared to undetected state corruption scenarios.

### Citations

**File:** types/src/state_store/state_value.rs (L343-353)
```rust
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub struct StateValueChunkWithProof {
    pub first_index: u64,     // The first hashed state index in chunk
    pub last_index: u64,      // The last hashed state index in chunk
    pub first_key: HashValue, // The first hashed state key in chunk
    pub last_key: HashValue,  // The last hashed state key in chunk
    pub raw_values: Vec<(StateKey, StateValue)>, // The hashed state key and and raw state value.
    pub proof: SparseMerkleRangeProof, // The proof to ensure the chunk is in the hashed states
    pub root_hash: HashValue, // The root hash of the sparse merkle tree for this chunk
}
```

**File:** types/src/state_store/state_value.rs (L355-363)
```rust
impl StateValueChunkWithProof {
    /// Returns true iff this chunk is the last chunk (i.e., there are no
    /// more state values to write to storage after this chunk).
    pub fn is_last_chunk(&self) -> bool {
        let right_siblings = self.proof.right_siblings();
        right_siblings
            .iter()
            .all(|sibling| *sibling == *SPARSE_MERKLE_PLACEHOLDER_HASH)
    }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L196-206)
```rust
        let (finished, partial_nodes, previous_leaf) = if let Some(root_node) =
            tree_reader.get_node_option(&NodeKey::new_empty_path(version), "restore")?
        {
            info!("Previous restore is complete, checking root hash.");
            ensure!(
                root_node.hash() == expected_root_hash,
                "Previous completed restore has root hash {}, expecting {}",
                root_node.hash(),
                expected_root_hash,
            );
            (true, vec![], None)
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L369-391)
```rust
        if chunk.is_empty() {
            return Ok(());
        }

        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L750-789)
```rust
    pub fn finish_impl(mut self) -> Result<()> {
        self.wait_for_async_commit()?;
        // Deal with the special case when the entire tree has a single leaf or null node.
        if self.partial_nodes.len() == 1 {
            let mut num_children = 0;
            let mut leaf = None;
            for i in 0..16 {
                if let Some(ref child_info) = self.partial_nodes[0].children[i] {
                    num_children += 1;
                    if let ChildInfo::Leaf(node) = child_info {
                        leaf = Some(node.clone());
                    }
                }
            }

            match num_children {
                0 => {
                    let node_key = NodeKey::new_empty_path(self.version);
                    assert!(self.frozen_nodes.is_empty());
                    self.frozen_nodes.insert(node_key, Node::Null);
                    self.store.write_node_batch(&self.frozen_nodes)?;
                    return Ok(());
                },
                1 => {
                    if let Some(node) = leaf {
                        let node_key = NodeKey::new_empty_path(self.version);
                        assert!(self.frozen_nodes.is_empty());
                        self.frozen_nodes.insert(node_key, node.into());
                        self.store.write_node_batch(&self.frozen_nodes)?;
                        return Ok(());
                    }
                },
                _ => (),
            }
        }

        self.freeze(0);
        self.store.write_node_batch(&self.frozen_nodes)?;
        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L872-876)
```rust
                StorageDataChunk::States(notification_id, states_with_proof) => {
                    // Commit the state value chunk
                    let all_states_synced = states_with_proof.is_last_chunk();
                    let last_committed_state_index = states_with_proof.last_index;
                    let num_state_values = states_with_proof.raw_values.len();
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L909-929)
```rust
                            if !all_states_synced {
                                // Update the metadata storage with the last committed state index
                                if let Err(error) = metadata_storage
                                    .clone()
                                    .update_last_persisted_state_value_index(
                                        &target_ledger_info,
                                        last_committed_state_index,
                                        all_states_synced,
                                    )
                                {
                                    let error = format!("Failed to update the last persisted state index at version: {:?}! Error: {:?}", version, error);
                                    send_storage_synchronizer_error(
                                        error_notification_sender.clone(),
                                        notification_id,
                                        error,
                                    )
                                    .await;
                                }
                                decrement_pending_data_chunks(pending_data_chunks.clone());
                                continue; // Wait for the next chunk
                            }
```
