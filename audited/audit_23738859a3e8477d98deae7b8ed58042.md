# Audit Report

## Title
Metric Update Lock Contention in DEFAULT_DROPPER Can Delay Consensus-Critical Operations

## Summary
The `DEFAULT_DROPPER` used by `DropHelper` performs Prometheus metric updates while holding a mutex lock in the critical path between transaction execution completion and consensus voting. Under high load conditions, this lock contention can delay execution responses, potentially impacting validator performance and consensus timing.

## Finding Description
The `DEFAULT_DROPPER` is a globally shared `AsyncConcurrentDropper` initialized with 32 max concurrent tasks and 8 worker threads. [1](#0-0) 

When `DropHelper` objects are dropped (used extensively for `ExecutionOutput`, `LedgerUpdateOutput`, and `SchemaBatch`), they schedule asynchronous drops via `DEFAULT_DROPPER.schedule_drop()`. [2](#0-1) 

The critical issue occurs in `NumTasksTracker::inc()`, which is called synchronously during `schedule_drop()`. This function acquires a mutex lock and performs a Prometheus metric update **while holding that lock**: [3](#0-2) 

Similarly, `dec()` updates metrics while holding the lock: [4](#0-3) 

The metric update calls `GAUGE.set_with()` which internally calls `with_label_values()` on the Prometheus registry. [5](#0-4)  This involves HashMap lookups with internal synchronization, which can be contended under concurrent access.

**Critical Path Impact:**

The block executor explicitly calls `DEFAULT_DROPPER.schedule_drop()` immediately after parallel execution completes, before returning results: [6](#0-5) 

This occurs in the consensus execution pipeline where multiple blocks can be processed concurrently in different stages. The execution completion triggers drops of large data structures that must go through the shared `DEFAULT_DROPPER`.

Additionally, `ExecutionOutput` structures (core to consensus voting decisions) are wrapped in `DropHelper`: [7](#0-6) 

## Impact Explanation
This qualifies as **High Severity** under the Aptos bug bounty criteria: "Validator node slowdowns" (up to $50,000).

Under sustained high transaction load:
1. Multiple blocks in the consensus pipeline trigger concurrent `schedule_drop()` calls
2. Each call contends on the `NumTasksTracker` mutex
3. While holding the mutex, Prometheus metric updates introduce additional latency
4. If 32 drops are queued, subsequent drops **block waiting** (lines 114-116 of async_concurrent_dropper.rs)
5. This blocking occurs in the executor thread before execution results are returned to consensus
6. Delayed execution responses slow consensus voting and block production

The cascading effect: Block A's execution completes → tries to schedule drop → blocks on metric contention → delays execution response → delays consensus vote → slows block production → Block B completion also blocked → performance degradation compounds.

## Likelihood Explanation
**Likelihood: Medium to High under normal operation**

The Aptos consensus uses a pipelined execution model where multiple blocks are processed concurrently across different stages. With validators processing high transaction throughput (thousands of TPS), the following conditions make this likely:

1. **High concurrent drop activity**: Multiple blocks completing execution, old block tree roots being replaced, and various `ExecutionOutput`/`LedgerUpdateOutput`/`SchemaBatch` objects being dropped
2. **Shared global dropper**: All components use the same `DEFAULT_DROPPER` (32 task limit, 8 threads)
3. **Synchronous metric updates**: Every `inc()` and `dec()` updates metrics while holding the lock
4. **Prometheus contention**: With numerous metrics being updated across the system, `with_label_values()` can experience contention

The 32-task limit can be reached when:
- Multiple blocks in execution pipeline (4-8 concurrent blocks typical)
- Each block's large data structures (MVHashMap, scheduler, etc.) take time to drop
- Additional drops from ExecutionOutput/LedgerUpdateOutput/SchemaBatch lifecycle

## Recommendation
**Move metric updates outside the critical section:**

```rust
fn inc(&self) {
    let mut num_tasks = self.lock.lock();
    while *num_tasks >= self.max_tasks {
        num_tasks = self.cvar.wait(num_tasks).expect("lock poisoned.");
    }
    let new_count = *num_tasks + 1;
    *num_tasks = new_count;
    drop(num_tasks); // Release lock BEFORE metric update
    
    // Update metrics outside lock
    GAUGE.set_with(&[self.name, "num_tasks"], new_count as i64);
}

fn dec(&self) {
    let new_count = {
        let mut num_tasks = self.lock.lock();
        *num_tasks -= 1;
        let count = *num_tasks;
        drop(num_tasks); // Release lock BEFORE metric update
        count
    };
    
    // Update metrics outside lock
    GAUGE.set_with(&[self.name, "num_tasks"], new_count as i64);
    self.cvar.notify_all();
}
```

**Additional recommendations:**
1. Consider using atomic counters for metrics instead of mutex-protected updates
2. Increase `DEFAULT_DROPPER` capacity from 32 to 128 or make it configurable
3. Add monitoring for drop queue saturation metrics
4. Consider separate drop pools for different priority levels (consensus-critical vs. background)

## Proof of Concept

```rust
// Add to aptos-move/block-executor/src/executor.rs tests
#[test]
fn test_concurrent_drop_contention() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    use aptos_drop_helper::{DEFAULT_DROPPER, DropHelper};
    
    // Simulate high concurrent load
    const NUM_CONCURRENT_DROPS: usize = 40; // Exceeds DEFAULT_DROPPER's 32 limit
    let barrier = Arc::new(Barrier::new(NUM_CONCURRENT_DROPS));
    
    let start = std::time::Instant::now();
    let handles: Vec<_> = (0..NUM_CONCURRENT_DROPS)
        .map(|_| {
            let barrier = barrier.clone();
            thread::spawn(move || {
                // Create large data structure wrapped in DropHelper
                let large_vec = vec![0u8; 10_000_000]; // 10MB
                let helper = DropHelper::new(large_vec);
                
                // Synchronize all threads to drop concurrently
                barrier.wait();
                
                // Drop happens here - measures time until schedule_drop completes
                let drop_start = std::time::Instant::now();
                drop(helper);
                drop_start.elapsed()
            })
        })
        .collect();
    
    let mut drop_times: Vec<_> = handles.into_iter()
        .map(|h| h.join().unwrap())
        .collect();
    
    drop_times.sort();
    let median = drop_times[drop_times.len() / 2];
    let p95 = drop_times[drop_times.len() * 95 / 100];
    let total = start.elapsed();
    
    println!("Total time: {:?}", total);
    println!("Median drop time: {:?}", median);
    println!("P95 drop time: {:?}", p95);
    
    // The P95 drop time should show significant blocking
    // when exceeding the 32 task limit
    assert!(p95 > Duration::from_millis(100), 
            "Expected blocking due to queue saturation");
}
```

**Expected behavior:** When 40 threads concurrently try to schedule drops, the first 32 succeed quickly, but threads 33-40 block waiting for slots. The P95 latency will show significant delays (potentially 100ms+) compared to median, demonstrating the blocking behavior in a consensus-critical operation.

## Notes
The vulnerability is exacerbated by the fact that `schedule_drop()` is called **synchronously** in the block executor's critical path before returning execution results to consensus. While the actual drop happens asynchronously in worker threads, the enqueue operation itself blocks, which is sufficient to delay consensus operations.

The test in the existing codebase (`test_concurrency_limit_hit`) demonstrates this blocking behavior is intentional design, but it was not anticipated that this would be in consensus-critical paths with shared global state.

### Citations

**File:** crates/aptos-drop-helper/src/lib.rs (L19-20)
```rust
pub static DEFAULT_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("default", 32, 8));
```

**File:** crates/aptos-drop-helper/src/lib.rs (L51-54)
```rust
impl<T: Send + 'static> Drop for DropHelper<T> {
    fn drop(&mut self) {
        DEFAULT_DROPPER.schedule_drop(self.inner.take());
    }
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L112-119)
```rust
    fn inc(&self) {
        let mut num_tasks = self.lock.lock();
        while *num_tasks >= self.max_tasks {
            num_tasks = self.cvar.wait(num_tasks).expect("lock poisoned.");
        }
        *num_tasks += 1;
        GAUGE.set_with(&[self.name, "num_tasks"], *num_tasks as i64);
    }
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L121-126)
```rust
    fn dec(&self) {
        let mut num_tasks = self.lock.lock();
        *num_tasks -= 1;
        GAUGE.set_with(&[self.name, "num_tasks"], *num_tasks as i64);
        self.cvar.notify_all();
    }
```

**File:** crates/aptos-metrics-core/src/lib.rs (L67-70)
```rust
impl IntGaugeVecHelper for IntGaugeVec {
    fn set_with(&self, labels: &[&str], val: i64) {
        self.with_label_values(labels).set(val)
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1836-1841)
```rust
        // Explicit async drops even when there is an error.
        DEFAULT_DROPPER.schedule_drop((last_input_output, scheduler, versioned_cache));

        if has_error {
            return Err(());
        }
```

**File:** execution/executor-types/src/execution_output.rs (L130-133)
```rust
    fn new_impl(inner: Inner) -> Self {
        Self {
            inner: Arc::new(DropHelper::new(inner)),
        }
```
