# Audit Report

## Title
Cache Worker Fails to Finalize Pending Transactions on Stream Termination

## Summary
The `process_streaming_response()` function in the indexer-grpc cache worker does not properly finalize pending transaction batches when the gRPC stream ends naturally after 5 minutes. This results in transaction data loss and cache state inconsistency, where transactions may be written to Redis but the cache version tracker is never updated, leaving the data unreachable to consumers.

## Finding Description

The cache worker streams transaction data from a fullnode via gRPC and maintains a Redis cache with version tracking. The streaming protocol works as follows:

1. Receive `StreamInit` signal with starting version
2. Receive transaction data chunks (`ChunkDataOk`) which spawn async tasks to write to Redis
3. Receive `BatchEnd` signal which triggers awaiting all pending tasks and updating the cache version [1](#0-0) 

When a stream ends naturally (after 5 minutes as noted in the comment), the loop breaks immediately without awaiting pending tasks: [2](#0-1) 

The critical issue is that transaction data tasks are added to the `tasks_to_run` vector but only awaited when a `BatchEnd` signal arrives: [3](#0-2) [4](#0-3) 

If the stream terminates between receiving transaction chunks and their corresponding `BatchEnd`, two problems occur:

1. **Pending tasks are dropped**: Tasks in `tasks_to_run` are never awaited, potentially losing transaction data that was being written to Redis.

2. **Cache version not updated**: Even if tasks complete before being dropped, the cache version tracker (`latest_version` key) is never updated since that only happens on `BatchEnd`: [5](#0-4) 

This creates cache inconsistency because consumers check the `latest_version` to determine data availability: [6](#0-5) 

Transaction data may exist in Redis but remain unreachable because `latest_version` indicates the data is "not ready."

## Impact Explanation

This qualifies as **Medium severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

The impact includes:
- **Data loss**: Partial transaction batches are lost from the cache when streams timeout
- **Cache inconsistency**: Transaction keys may exist in Redis without corresponding version tracking updates
- **Consumer disruption**: External indexers and applications relying on the cache receive incomplete data or experience delays
- **Re-processing overhead**: The worker must re-request already-processed transactions on restart

While this does not affect blockchain consensus, validator operations, or fund security, it creates a persistent state inconsistency in the indexer infrastructure that requires manual intervention to resolve.

## Likelihood Explanation

This issue occurs with **high likelihood**:
- The stream naturally terminates every 5 minutes by design (load balancer or server timeout)
- If transaction processing is ongoing when the timeout occurs, the bug triggers deterministically
- Given typical transaction throughput, there's a high probability that a batch is in progress during any 5-minute window
- No attacker action requiredâ€”this is a reliability bug in normal operation

## Recommendation

Before returning from `process_streaming_response()`, await any pending tasks and handle the incomplete batch appropriately:

```rust
async fn process_streaming_response(...) -> Result<()> {
    // ... existing code ...
    
    loop {
        // ... existing processing ...
    }
    
    // NEW: Handle pending tasks before returning
    if !tasks_to_run.is_empty() {
        tracing::warn!(
            num_pending_tasks = tasks_to_run.len(),
            current_version = current_version,
            "[Indexer Cache] Stream ended with pending tasks. Awaiting completion..."
        );
        
        // Await all pending tasks
        let results = join_all(tasks_to_run).await;
        if results.iter().any(|r| r.is_err() || r.as_ref().unwrap().is_err()) {
            return Err(anyhow::anyhow!(
                "Failed to finalize pending tasks before stream termination"
            ));
        }
        
        // DO NOT update cache version for incomplete batch
        // The worker will restart from file_store version
        tracing::warn!(
            "[Indexer Cache] Pending tasks completed but batch was incomplete. \
             Data written to cache but version not advanced."
        );
    }
    
    Ok(())
}
```

Alternatively, implement a more robust solution that either:
1. Requests a final `BatchEnd` signal before disconnection
2. Maintains batch boundaries within the worker to update versions for completed sub-batches
3. Implements a checkpoint mechanism for partial batch recovery

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use futures::stream;
    use tokio::sync::mpsc;
    
    #[tokio::test]
    async fn test_stream_timeout_loses_transactions() {
        // Setup: Create mock Redis connection and stream
        let (tx, rx) = mpsc::channel(100);
        let mut mock_stream = ReceiverStream::new(rx);
        
        // Simulate Init signal
        tx.send(Ok(create_init_response(0))).await.unwrap();
        
        // Simulate transaction data chunks WITHOUT BatchEnd
        for i in 0..10 {
            tx.send(Ok(create_transaction_response(i * 100, 100))).await.unwrap();
        }
        
        // Simulate stream end (timeout) - no BatchEnd sent
        drop(tx);
        
        // Process stream
        let result = process_streaming_response(
            mock_redis_conn,
            StorageFormat::Base64UncompressedProto,
            mock_file_store_metadata,
            mock_stream,
        ).await;
        
        // Verify: Function returns Ok but pending tasks were dropped
        assert!(result.is_ok());
        
        // Verify: Cache version was NOT updated
        let cache_version = redis_conn.get::<_, u64>("latest_version").await.unwrap();
        assert_eq!(cache_version, 0); // Still at initial version
        
        // Verify: Some transaction keys may exist in Redis but are unreachable
        // because latest_version wasn't updated
    }
}
```

## Notes

This vulnerability affects the indexer-grpc cache worker, which is auxiliary infrastructure for querying blockchain data. While it does not impact core blockchain consensus, execution, or storage, it creates persistent data inconsistency in the cache layer that degrades service reliability for external applications and indexers relying on this data source. The issue manifests in normal operation without requiring attacker action, making it a high-probability reliability and data integrity bug warranting Medium severity classification.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L356-367)
```rust
    loop {
        let download_start_time = std::time::Instant::now();
        let received = match resp_stream.next().await {
            Some(r) => r,
            _ => {
                error!(
                    service_type = SERVICE_TYPE,
                    "[Indexer Cache] Streaming error: no response."
                );
                ERROR_COUNT.with_label_values(&["streaming_error"]).inc();
                break;
            },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L395-404)
```rust
                GrpcDataStatus::ChunkDataOk {
                    num_of_transactions,
                    task,
                } => {
                    current_version += num_of_transactions;
                    transaction_count += num_of_transactions;
                    tps_calculator.tick_now(num_of_transactions);

                    tasks_to_run.push(task);
                },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L413-448)
```rust
                GrpcDataStatus::BatchEnd {
                    start_version,
                    num_of_transactions,
                } => {
                    // Handle the data multithreading.
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
                    if current_version != start_version + num_of_transactions {
                        error!(
                            current_version = current_version,
                            actual_current_version = start_version + num_of_transactions,
                            "[Indexer Cache] End signal received with wrong version."
                        );
                        ERROR_COUNT
                            .with_label_values(&["data_end_wrong_version"])
                            .inc();
                        break;
                    }
                    cache_operator
                        .update_cache_latest_version(transaction_count, current_version)
                        .await
                        .context("Failed to update the latest version in the cache")?;
                    transaction_count = 0;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L502-504)
```rust
    // It is expected that we get to this point, the upstream server disconnects
    // clients after 5 minutes.
    Ok(())
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L193-219)
```rust
    pub async fn check_cache_coverage_status(
        &mut self,
        requested_version: u64,
    ) -> anyhow::Result<CacheCoverageStatus> {
        let latest_version: u64 = match self
            .conn
            .get::<&str, String>(CACHE_KEY_LATEST_VERSION)
            .await
        {
            Ok(v) => v
                .parse::<u64>()
                .expect("Redis latest_version is not a number."),
            Err(err) => return Err(err.into()),
        };

        if requested_version >= latest_version {
            Ok(CacheCoverageStatus::DataNotReady)
        } else if requested_version + CACHE_SIZE_ESTIMATION < latest_version {
            Ok(CacheCoverageStatus::CacheEvicted)
        } else {
            // TODO: rewrite this logic to surface this max fetch size better
            Ok(CacheCoverageStatus::CacheHit(std::cmp::min(
                latest_version - requested_version,
                FILE_ENTRY_TRANSACTION_COUNT,
            )))
        }
    }
```
