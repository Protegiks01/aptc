# Audit Report

## Title
Uniform Decompression Limits Across All CompressionClient Types Enable Resource Exhaustion DoS Attacks

## Summary
The compression library uses a single `MAX_APPLICATION_MESSAGE_SIZE` (~62 MiB) decompression limit for all client types (Consensus, StateSync, Mempool), despite these protocols having vastly different logical message size limits (6 MB for consensus, 10-40 MB for state sync). This mismatch allows attackers to trigger excessive memory allocations that bypass protocol-specific validation, enabling memory exhaustion DoS attacks against validator nodes.

## Finding Description
The vulnerability exists in how the decompression layer handles size limits across different protocol types. All `CompressionClient` types share the same `max_size` parameter when decompressing data: [1](#0-0) 

The `MAX_APPLICATION_MESSAGE_SIZE` constant is approximately 62 MiB: [2](#0-1) 

However, protocol-specific logical limits are much smaller:
- **Consensus**: 6 MB max receiving block size [3](#0-2) 

- **StateSync v1**: 10 MB max message size
- **StateSync v2**: 40 MB max message size [4](#0-3) 

The decompression function allocates memory based on the size prefix in compressed data before validation: [5](#0-4) 

**Attack Flow:**
1. Attacker sends a compressed consensus message with a size prefix claiming 60 MB decompressed size
2. `get_decompressed_size()` validates: 60 MB ≤ 62 MB ✓
3. Memory allocated: `vec![0u8; 60_000_000]` 
4. Decompression executes into the 60 MB buffer
5. Consensus validation rejects the message (60 MB > 6 MB limit) [6](#0-5) 

6. Memory is freed, but the allocation already consumed resources

An attacker can send hundreds of such messages concurrently to exhaust node memory, causing crashes or severe performance degradation.

## Impact Explanation
This is a **Medium Severity** DoS vulnerability (potentially escalating to **High Severity**):

- **Validator node slowdowns**: Repeated memory allocations cause GC pressure and CPU overhead
- **Memory exhaustion**: Concurrent malicious messages can consume gigabytes of RAM
- **Node crashes**: Memory exhaustion can trigger OOM kills on validators
- **Network degradation**: Affects validator availability and consensus participation

The attack bypasses application-layer size limits by exploiting the uniform decompression limit. It violates the **Resource Limits** invariant requiring "all operations must respect computational limits."

## Likelihood Explanation
**Likelihood: High**

- **Low barrier to entry**: Any network peer can send consensus protocol messages
- **No authentication required**: Attack works at the network deserialization layer
- **Simple exploitation**: Attacker only needs to craft compressed data with large size prefixes
- **High amplification**: Small compressed payloads (1-5 MB) trigger large allocations (60+ MB)
- **Concurrent attacks possible**: Multiple connections multiply the impact

The `CompressionClient` enum is only used for metrics labeling, not access control: [7](#0-6) 

## Recommendation
Implement client-specific `max_size` limits that match protocol-level expectations:

```rust
impl CompressionClient {
    /// Returns the maximum decompressed size for this client type
    pub fn max_decompressed_size(&self) -> usize {
        match self {
            Self::Consensus | Self::ConsensusObserver => 10 * 1024 * 1024, // 10 MB (with buffer above 6 MB)
            Self::StateSync => 50 * 1024 * 1024, // 50 MB (with buffer above 40 MB)
            Self::Mempool => MAX_APPLICATION_MESSAGE_SIZE, // 62 MB
            Self::DKG | Self::JWKConsensus => 20 * 1024 * 1024, // 20 MB
        }
    }
}
```

Modify the `from_bytes` method to use client-specific limits:

```rust
Encoding::CompressedBcs(limit) => {
    let compression_client = self.get_compression_client();
    let max_size = compression_client.max_decompressed_size(); // Use client-specific limit
    let raw_bytes = aptos_compression::decompress(
        &bytes.to_vec(),
        compression_client,
        max_size,
    )
    .map_err(|e| anyhow! {"{:?}", e})?;
    self.bcs_decode(&raw_bytes, limit)
}
```

## Proof of Concept
```rust
// Malicious network peer sends crafted consensus message
use aptos_compression::{compress, decompress, client::CompressionClient};

fn exploit_consensus_decompression() {
    // Create a large payload that consensus would reject (60 MB)
    let malicious_payload = vec![0u8; 60_000_000];
    
    // Compress it (compression ratio may reduce to ~5-10 MB compressed)
    let compressed = compress(
        malicious_payload.clone(),
        CompressionClient::Consensus,
        70_000_000, // Bypass compression size check
    ).unwrap();
    
    // Victim node receives and decompresses
    // This allocates 60 MB despite consensus only accepting 6 MB blocks
    let decompressed = decompress(
        &compressed,
        CompressionClient::Consensus,
        62_000_000, // MAX_APPLICATION_MESSAGE_SIZE allows this
    ).unwrap();
    
    // After deserialization, consensus validation would reject:
    // "Payload size 60000000 exceeds the limit 6000000"
    // But memory was already allocated and consumed
    
    // Attacker repeats this 100 times concurrently = 6 GB memory exhaustion
}
```

**Notes:**
- The vulnerability stems from using a uniform `MAX_APPLICATION_MESSAGE_SIZE` limit across all protocol types
- The `CompressionClient` enum is designed for metrics but could enforce client-specific security boundaries  
- StateSync responses also use `MAX_APPLICATION_MESSAGE_SIZE` for decompression despite having 10-40 MB limits: [8](#0-7) 
- Mempool appropriately uses the full 62 MB limit as its batch size matches: [9](#0-8)

### Citations

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L233-241)
```rust
            Encoding::CompressedBcs(limit) => {
                let compression_client = self.get_compression_client();
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
                self.bcs_decode(&raw_bytes, limit)
```

**File:** config/src/config/network_config.rs (L47-48)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
```

**File:** config/src/config/consensus_config.rs (L227-231)
```rust
            max_sending_block_bytes: 3 * 1024 * 1024, // 3MB
            max_receiving_block_txns: *MAX_RECEIVING_BLOCK_TXNS,
            max_sending_inline_txns: 100,
            max_sending_inline_bytes: 200 * 1024,       // 200 KB
            max_receiving_block_bytes: 6 * 1024 * 1024, // 6MB
```

**File:** config/src/config/state_sync_config.rs (L16-21)
```rust
// The maximum message size per state sync message
const SERVER_MAX_MESSAGE_SIZE: usize = 10 * 1024 * 1024; // 10 MiB

// The maximum message size per state sync message (for v2 data requests)
const CLIENT_MAX_MESSAGE_SIZE_V2: usize = 20 * 1024 * 1024; // 20 MiB (used for v2 data requests)
const SERVER_MAX_MESSAGE_SIZE_V2: usize = 40 * 1024 * 1024; // 40 MiB (used for v2 data requests)
```

**File:** crates/aptos-compression/src/lib.rs (L100-108)
```rust
    // Check size of the data and initialize raw_data
    let decompressed_size = match get_decompressed_size(compressed_data, max_size) {
        Ok(size) => size,
        Err(error) => {
            let error_string = format!("Failed to get decompressed size: {}", error);
            return create_decompression_error(&client, error_string);
        },
    };
    let mut raw_data = vec![0u8; decompressed_size];
```

**File:** consensus/src/round_manager.rs (L1187-1193)
```rust
        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );
```

**File:** crates/aptos-compression/src/client.rs (L7-15)
```rust
#[derive(Clone, Copy, Debug)]
pub enum CompressionClient {
    Consensus,
    ConsensusObserver,
    DKG,
    JWKConsensus,
    Mempool,
    StateSync,
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L100-104)
```rust
                let raw_data = aptos_compression::decompress(
                    compressed_data,
                    CompressionClient::StateSync,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )?;
```

**File:** config/src/config/mempool_config.rs (L114-114)
```rust
            shared_mempool_max_batch_bytes: MAX_APPLICATION_MESSAGE_SIZE as u64,
```
