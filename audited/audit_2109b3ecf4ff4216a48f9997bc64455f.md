# Audit Report

## Title
Unbounded Memory Growth in BatchStore persist_subscribers Leading to Validator Node Memory Exhaustion

## Summary
The `persist_subscribers` DashMap in `BatchStore` grows unboundedly when batches are subscribed to but fail to persist, causing memory exhaustion on validator nodes. This occurs because subscription entries are only removed on successful persistence or when batches exist in the cache during expiration, leaving orphaned entries for failed fetch attempts.

## Finding Description

The vulnerability exists in the subscription and cleanup mechanisms of the `BatchStore` structure. The issue manifests through the following execution flow:

**Subscription Addition:**
When a batch is not available locally, `get_or_fetch_batch()` calls `subscribe()` which unconditionally adds an entry to the `persist_subscribers` DashMap. [1](#0-0) 

**Failed Persistence Path:**
The `request_batch()` method can fail in two scenarios:
1. **Batch Expiration**: When peers respond with `BatchResponse::NotFound` indicating the batch has expired [2](#0-1) 

2. **Request Timeout**: When all retry attempts are exhausted without receiving the batch [3](#0-2) 

When either failure occurs, `get_or_fetch_batch()` propagates the error without calling `persist()`, meaning `notify_subscribers()` is never invoked. [4](#0-3) 

**Incomplete Cleanup Mechanisms:**

1. `notify_subscribers()` only removes entries when successfully called after persistence [5](#0-4) 

2. `clear_expired_payload()` only removes `persist_subscribers` entries for batches that exist in `db_cache` [6](#0-5) 

Since failed fetches never add entries to `db_cache`, their corresponding `persist_subscribers` entries are never cleaned up.

**Attack Scenario:**
An attacker can repeatedly trigger batch fetch requests for:
- Already expired batches (by referencing old batch digests)
- Non-existent batches (by crafting invalid batch references)
- Batches from unresponsive peers (causing timeouts)

Each failed fetch leaves an orphaned entry in `persist_subscribers` containing a `Vec<oneshot::Sender<PersistedValue<BatchInfoExt>>>`. Over time, this causes unbounded memory growth.

**Invariant Violation:**
This breaks the **Resource Limits** invariant (#9): "All operations must respect gas, storage, and computational limits." The memory allocated to `persist_subscribers` can grow without bounds within an epoch.

## Impact Explanation

**High Severity** (per Aptos Bug Bounty criteria):

1. **Validator Node Slowdowns**: As memory consumption increases, nodes experience performance degradation due to:
   - Increased garbage collection pressure
   - Memory swapping to disk
   - Reduced available memory for other consensus operations

2. **Potential Node Crashes**: If memory exhaustion reaches critical levels, the validator process may be terminated by the OS, causing:
   - Loss of consensus participation
   - Reduced network safety margin (approaching the 1/3 Byzantine threshold)
   - Service disruption requiring manual intervention

3. **Consensus Liveness Impact**: If multiple validators are simultaneously affected, the network may experience:
   - Slower block production
   - Increased round timeouts
   - Potential liveness failures if enough validators become unresponsive

The issue qualifies as High Severity because it enables **validator node slowdowns** and can escalate to availability impacts affecting consensus operations.

## Likelihood Explanation

**High Likelihood** of exploitation:

1. **Natural Occurrence**: The vulnerability can be triggered naturally through normal network conditions:
   - Network partitions causing request timeouts
   - Clock skew leading to expired batch references
   - Peers going offline during batch retrieval

2. **Malicious Exploitation**: An attacker can deliberately trigger the vulnerability by:
   - Sending proof-of-store certificates for expired batches
   - Creating network delays to cause timeouts
   - Referencing non-existent batch digests in consensus messages

3. **Epoch Duration**: On mainnet, epochs last approximately 2 hours, providing a substantial window for memory accumulation before automatic cleanup occurs at epoch transition.

4. **No Rate Limiting**: There are no explicit rate limits on batch subscription attempts, allowing rapid memory growth.

The combination of natural network conditions and deliberate attack vectors makes this vulnerability highly likely to manifest in production environments.

## Recommendation

Implement cleanup of `persist_subscribers` entries when batch fetches fail. Add a cleanup call in the error path of `get_or_fetch_batch()`:

```rust
async move {
    let batch_digest = *batch_info.digest();
    defer!({
        inflight_requests_clone.lock().remove(&batch_digest);
    });
    
    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
        Ok(value.take_payload().expect("Must have payload"))
    } else {
        counters::MISSED_BATCHES_COUNT.inc();
        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
        
        match requester
            .request_batch(
                batch_digest,
                batch_info.expiration(),
                responders,
                subscriber_rx,
            )
            .await 
        {
            Ok(payload) => {
                batch_store.persist(vec![PersistedValue::new(
                    batch_info.into(),
                    Some(payload.clone()),
                )]);
                Ok(payload)
            },
            Err(e) => {
                // Clean up the orphaned subscription entry
                batch_store.persist_subscribers.remove(&batch_digest);
                Err(e)
            }
        }
    }
}
```

Alternatively, implement a timeout-based cleanup mechanism in `BatchStore` that periodically removes stale subscription entries.

## Proof of Concept

```rust
#[tokio::test]
async fn test_persist_subscribers_memory_leak() {
    use std::sync::Arc;
    use aptos_crypto::HashValue;
    use crate::quorum_store::batch_store::{BatchStore, BatchReaderImpl};
    use crate::quorum_store::batch_requester::BatchRequester;
    use aptos_consensus_types::proof_of_store::BatchInfo;
    
    // Setup: Create a BatchStore instance
    let batch_store = Arc::new(create_test_batch_store());
    let batch_requester = create_test_batch_requester();
    let batch_reader = BatchReaderImpl::new(
        batch_store.clone(),
        batch_requester,
    );
    
    let initial_size = batch_store.persist_subscribers.len();
    
    // Trigger 1000 batch fetches for non-existent batches
    for i in 0..1000 {
        let fake_digest = HashValue::sha3_256_of(&i.to_le_bytes());
        let batch_info = create_expired_batch_info(fake_digest);
        
        // This will call subscribe() but fail in request_batch()
        let _ = batch_reader.get_batch(batch_info, vec![]).await;
    }
    
    // Verify memory leak: persist_subscribers should have 1000 orphaned entries
    let final_size = batch_store.persist_subscribers.len();
    assert_eq!(final_size - initial_size, 1000, 
        "persist_subscribers grew by {} entries, demonstrating memory leak", 
        final_size - initial_size);
    
    // Verify entries are never cleaned up by clear_expired_payload
    batch_store.update_certified_timestamp(u64::MAX);
    assert_eq!(batch_store.persist_subscribers.len(), final_size,
        "Expired payload cleanup did not remove orphaned subscriptions");
}
```

## Notes

The vulnerability is partially mitigated by epoch transitions (every ~2 hours on mainnet), which create a new `BatchStore` instance and eventually drop the old one. However, this does not prevent memory exhaustion within an epoch, and the attack can be repeated across epochs. A proper fix requires explicit cleanup of failed subscription attempts.

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L457-457)
```rust
                        self.persist_subscribers.remove(entry.get().digest());
```

**File:** consensus/src/quorum_store/batch_store.rs (L591-602)
```rust
    fn subscribe(&self, digest: HashValue) -> oneshot::Receiver<PersistedValue<BatchInfoExt>> {
        let (tx, rx) = oneshot::channel();
        self.persist_subscribers.entry(digest).or_default().push(tx);

        // This is to account for the race where this subscribe call happens after the
        // persist call.
        if let Ok(value) = self.get_batch_from_local(&digest) {
            self.notify_subscribers(value)
        }

        rx
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L604-610)
```rust
    fn notify_subscribers(&self, value: PersistedValue<BatchInfoExt>) {
        if let Some((_, subscribers)) = self.persist_subscribers.remove(value.digest()) {
            for subscriber in subscribers {
                subscriber.send(value.clone()).ok();
            }
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L695-709)
```rust
                        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
                        Ok(payload)
                    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L142-151)
```rust
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-179)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
        })
```
