# Audit Report

## Title
Async Runtime Starvation via Blocking RwLock in DAG Consensus Leading to Consensus Timeouts

## Summary
The `aptos-infallible::RwLock` uses `std::sync::RwLock` (a blocking, non-async-aware lock) extensively in async contexts throughout the DAG consensus implementation. When multiple concurrent async tasks acquire these locks, they block Tokio worker threads without yielding, potentially exhausting the thread pool and preventing consensus-critical operations from executing within their time bounds, causing validators to miss votes and fall behind.

## Finding Description

The vulnerability stems from a fundamental mismatch between blocking synchronous primitives and async execution contexts: [1](#0-0) 

The `write()` method is a thin wrapper around `std::sync::RwLock::write()`, which blocks the calling thread until the lock is acquired. This lock is used pervasively in DAG consensus to protect the in-memory DAG state: [2](#0-1) 

**Critical async contexts calling blocking locks:**

1. **Async RPC handler for certified nodes** acquires blocking read lock: [3](#0-2) 

2. **Async RPC handler for node broadcasts** acquires blocking write lock: [4](#0-3) [5](#0-4) 

3. **Async round progression** acquires blocking read lock: [6](#0-5) 

**The Attack Vector:**

An attacker can send up to 100 concurrent inbound RPC requests (the network-level limit): [7](#0-6) 

However, the Tokio runtime typically has far fewer worker threads (number of CPU cores, usually 4-16): [8](#0-7) 

**Exploitation Flow:**

1. Attacker sends 100 concurrent certified node or node broadcast RPC messages to a target validator
2. Each spawns an async task that attempts to acquire a lock on `DagStore`
3. When async tasks call blocking lock operations (`.read()` or `.write()`), they block the entire Tokio worker thread
4. Write locks are exclusive, so only one can proceed while others block their threads waiting
5. With sufficient concurrent requests, all Tokio worker threads become blocked waiting for locks
6. Consensus-critical async operations (voting, proposal processing, timeout handling) cannot execute
7. Validator misses consensus deadlines, causing timeouts and falling behind

**Why existing mitigations are insufficient:**

- No `spawn_blocking()` is used to offload blocking operations to a separate thread pool
- The network's 100-concurrent-RPC limit far exceeds the typical 4-16 Tokio worker threads
- Operations like `update_votes()` iterate over parent nodes while holding locks, creating non-trivial hold times: [9](#0-8) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria: **"Validator node slowdowns"**.

**Specific Impacts:**

1. **Liveness Degradation**: Validators experiencing thread starvation miss voting deadlines, reducing network throughput and potentially stalling consensus
2. **Validator Performance Penalty**: Affected validators consistently miss proposal opportunities and votes, appearing unhealthy to the network
3. **Cascading Effects**: If multiple validators are targeted simultaneously, the network's ability to form quorums is impaired
4. **No Safety Violation**: While this affects liveness, it does not break consensus safety (no double-signing or equivocation)

The impact is amplified during high network activity when legitimate load increases lock contention, making the attack more effective.

## Likelihood Explanation

**Likelihood: High**

- **Ease of Exploitation**: Attacker only needs to send standard protocol messages at high concurrency - no special crafting required
- **No Authentication Barrier**: Any network peer can send RPC requests to validators
- **Triggering Conditions**: Occurs naturally during high network activity, but attacker can amplify
- **Detection Difficulty**: Thread starvation manifests as general slowdowns, making it hard to distinguish from legitimate load
- **Cost to Attacker**: Low - sending concurrent RPCs requires minimal resources

## Recommendation

**Replace blocking locks with async-aware alternatives in consensus hot paths:**

```rust
// In crates/aptos-infallible/src/rwlock.rs
// Add async-aware RwLock variant
use tokio::sync::RwLock as TokioRwLock;

pub struct AsyncRwLock<T>(TokioRwLock<T>);

impl<T> AsyncRwLock<T> {
    pub fn new(t: T) -> Self {
        Self(TokioRwLock::new(t))
    }

    pub async fn read(&self) -> tokio::sync::RwLockReadGuard<'_, T> {
        self.0.read().await
    }

    pub async fn write(&self) -> tokio::sync::RwLockWriteGuard<'_, T> {
        self.0.write().await
    }
}
```

**Then update DagStore:**

```rust
// In consensus/src/dag/dag_store.rs
pub struct DagStore {
    dag: AsyncRwLock<InMemDag>,  // Changed from RwLock to AsyncRwLock
    storage: Arc<dyn DAGStorage>,
    payload_manager: Arc<dyn TPayloadManager>,
}
```

**Alternative mitigation (if full async conversion is impractical):**

Use `tokio::task::spawn_blocking()` to offload lock acquisitions:

```rust
pub async fn process(&self, certified_node: Self::Request) -> anyhow::Result<Self::Response> {
    let dag = self.dag.clone();
    let node_metadata = certified_node.metadata().clone();
    
    let exists = tokio::task::spawn_blocking(move || {
        dag.read().exists(&node_metadata)
    }).await??;
    
    if exists {
        return Ok(CertifiedAck::new(epoch));
    }
    // ... rest of handler
}
```

## Proof of Concept

```rust
// consensus/src/dag/tests/thread_starvation_test.rs
#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
async fn test_blocking_lock_causes_thread_starvation() {
    use std::sync::Arc;
    use std::time::Duration;
    use aptos_infallible::RwLock;
    
    // Simulate DagStore with blocking lock
    let shared_state = Arc::new(RwLock::new(vec![0u64; 1000]));
    
    // Spawn 100 concurrent tasks (like 100 concurrent RPCs)
    let mut handles = vec![];
    for i in 0..100 {
        let state = shared_state.clone();
        let handle = tokio::spawn(async move {
            // Simulate RPC handler acquiring write lock
            let mut data = state.write();
            // Simulate some work while holding lock
            for j in 0..data.len() {
                data[j] += i;
            }
            std::thread::sleep(Duration::from_millis(10)); // Simulate update_votes work
        });
        handles.push(handle);
    }
    
    // Spawn a time-sensitive "consensus" task
    let consensus_task = tokio::spawn(async {
        tokio::time::sleep(Duration::from_millis(50)).await;
        println!("Consensus deadline met");
    });
    
    // With only 4 worker threads and 100 tasks blocking on locks,
    // the consensus task will miss its deadline
    let start = std::time::Instant::now();
    let _ = consensus_task.await;
    let elapsed = start.elapsed();
    
    // Clean up
    for handle in handles {
        let _ = handle.await;
    }
    
    // The consensus task should complete in ~50ms, but with thread starvation
    // it will take much longer as it can't get scheduled
    assert!(elapsed > Duration::from_millis(100), 
            "Thread starvation detected: consensus task took {:?}", elapsed);
}
```

**To demonstrate in real validator environment:**

1. Deploy modified validator with instrumentation on lock acquisition times
2. Send 100 concurrent `CertifiedNode` RPCs using the network framework
3. Monitor consensus round progression and vote latencies
4. Observe increased latency in consensus operations correlating with RPC bursts

## Notes

The vulnerability affects the DAG consensus implementation specifically. Traditional consensus paths may use different locking strategies. The fix should be applied consistently across all async contexts using `aptos-infallible::RwLock`, with particular priority on consensus-critical paths.

### Citations

**File:** crates/aptos-infallible/src/rwlock.rs (L26-30)
```rust
    pub fn write(&self) -> RwLockWriteGuard<'_, T> {
        self.0
            .write()
            .expect("Cannot currently handle a poisoned lock")
    }
```

**File:** consensus/src/dag/dag_store.rs (L166-197)
```rust
    pub fn update_votes(&mut self, node: &Node, update_link_power: bool) {
        if node.round() <= self.lowest_round() {
            return;
        }

        let voting_power = self
            .epoch_state
            .verifier
            .get_voting_power(node.author())
            .expect("must exist");

        for parent in node.parents_metadata() {
            let node_status = self
                .get_node_ref_mut(parent.round(), parent.author())
                .expect("must exist");
            match node_status {
                Some(NodeStatus::Unordered {
                    aggregated_weak_voting_power,
                    aggregated_strong_voting_power,
                    ..
                }) => {
                    if update_link_power {
                        *aggregated_strong_voting_power += voting_power as u128;
                    } else {
                        *aggregated_weak_voting_power += voting_power as u128;
                    }
                },
                Some(NodeStatus::Ordered(_)) => {},
                None => unreachable!("parents must exist before voting for a node"),
            }
        }
    }
```

**File:** consensus/src/dag/dag_store.rs (L447-451)
```rust
pub struct DagStore {
    dag: RwLock<InMemDag>,
    storage: Arc<dyn DAGStorage>,
    payload_manager: Arc<dyn TPayloadManager>,
}
```

**File:** consensus/src/dag/dag_driver.rs (L191-198)
```rust
    pub async fn enter_new_round(&self, new_round: Round) {
        if let Err(e) = self.round_state.set_current_round(new_round) {
            debug!(error=?e, "cannot enter round");
            return;
        }

        let (strong_links, sys_payload_filter, payload_filter) = {
            let dag_reader = self.dag.read();
```

**File:** consensus/src/dag/dag_driver.rs (L394-401)
```rust
    async fn process(&self, certified_node: Self::Request) -> anyhow::Result<Self::Response> {
        let epoch = certified_node.metadata().epoch();
        debug!(LogSchema::new(LogEvent::ReceiveCertifiedNode)
            .remote_peer(*certified_node.author())
            .round(certified_node.round()));
        if self.dag.read().exists(certified_node.metadata()) {
            return Ok(CertifiedAck::new(epoch));
        }
```

**File:** consensus/src/dag/rb_handler.rs (L218-228)
```rust
    async fn process(&self, node: Self::Request) -> anyhow::Result<Self::Response> {
        ensure!(
            !self.health_backoff.stop_voting(),
            NodeBroadcastHandleError::VoteRefused
        );

        let key = (node.round(), *node.author());
        ensure!(
            self.votes_fine_grained_lock.insert(key),
            "concurrent insertion"
        );
```

**File:** consensus/src/dag/rb_handler.rs (L258-259)
```rust
        self.dag.write().update_votes(&node, false);
        self.order_rule.process_new_node(node.metadata());
```

**File:** network/framework/src/constants.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

/// A collection of constants and default values for configuring various network components.

// NB: Almost all of these values are educated guesses, and not determined using any empirical
// data. If you run into a limit and believe that it is unreasonably tight, please submit a PR
// with your use-case. If you do change a value, please add a comment linking to the PR which
// advocated the change.
/// The timeout for any inbound RPC call before it's cut off
pub const INBOUND_RPC_TIMEOUT_MS: u64 = 10_000;
/// Limit on concurrent Outbound RPC requests before backpressure is applied
pub const MAX_CONCURRENT_OUTBOUND_RPCS: u32 = 100;
/// Limit on concurrent Inbound RPC requests before backpressure is applied
pub const MAX_CONCURRENT_INBOUND_RPCS: u32 = 100;

// These are only used in tests
// TODO: Fix this so the tests and the defaults in config are the same
pub const NETWORK_CHANNEL_SIZE: usize = 1024;
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
pub const MAX_CONCURRENT_NETWORK_NOTIFS: usize = 100;


```

**File:** crates/aptos-runtimes/src/lib.rs (L40-54)
```rust
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
    if let Some(num_worker_threads) = num_worker_threads {
        builder.worker_threads(num_worker_threads);
    }
```
