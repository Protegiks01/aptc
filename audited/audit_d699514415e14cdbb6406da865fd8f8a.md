# Audit Report

## Title
State Merkle Proof Unavailability Window Due to Asynchronous State Persistence

## Summary
The `commit_chunk_impl()` function calls `save_transactions()` with `sync_commit=false`, causing state merkle tree nodes to be persisted asynchronously while transaction metadata is immediately marked as committed. This creates a window where committed transactions are advertised as queryable, but state merkle proof requests fail with `MissingRootError`. [1](#0-0) 

## Finding Description

When `save_transactions()` is invoked with `sync_commit=false`, the execution flow persists transaction data and state key-value pairs synchronously, but only **enqueues** state merkle tree updates for asynchronous processing: [2](#0-1) 

Within `pre_commit_ledger()`, the buffered state update is enqueued but not awaited when `sync_commit=false`: [3](#0-2) 

The `buffered_state().update()` method with `sync_commit=false` only enqueues the state checkpoint without waiting: [4](#0-3) 

After `save_transactions()` returns, `commit_ledger()` updates `OverallCommitProgress`, marking the transaction as "synced": [5](#0-4) 

At this point, the in-memory latest ledger info is updated, making the new version visible to clients: [6](#0-5) 

However, the state merkle tree nodes are still in the async pipeline (StateSnapshotCommitter â†’ StateMerkleBatchCommitter). If clients request state proofs during this window, they receive `MissingRootError`: [7](#0-6) 

**Crash Recovery Analysis:**

The system includes recovery mechanisms that handle crashes correctly. On restart, `sync_commit_progress()` truncates any data beyond `OverallCommitProgress`: [8](#0-7) 

Then `create_buffered_state_from_latest_snapshot()` replays write sets from the last persisted snapshot to reconstruct the state merkle tree: [9](#0-8) 

**However**, this violates the critical invariant: **"State transitions must be atomic and verifiable via Merkle proofs"**. During the asynchronous write window, state values are queryable but proofs are not, breaking atomicity.

## Impact Explanation

This issue represents a **Medium Severity** vulnerability per Aptos bug bounty criteria:

1. **State inconsistency**: Transaction data and state values are immediately readable, but merkle proofs are temporarily unavailable, creating an inconsistent view of committed state.

2. **Light client impact**: Light clients and applications relying on state proofs for verification will encounter errors when querying recently committed versions, potentially causing synchronization failures or requiring retry logic.

3. **API reliability**: The API layer exposes committed versions via `get_latest_ledger_info()` before all corresponding data (proofs) is available, violating client expectations.

4. **Not Critical** because:
   - No data loss occurs (recovery mechanism is sound)
   - No consensus safety violation (all nodes behave identically)
   - No fund theft or permanent damage
   - Window is transient (milliseconds to seconds typically)

## Likelihood Explanation

**High likelihood** of occurrence during normal operation:
- Every transaction commit with `sync_commit=false` creates this window
- The async pipeline has limited buffering (channel size = 1), meaning proof requests immediately after commit have high probability of hitting this window
- Under high transaction throughput, the async threads may lag further, extending the unavailability window

**Low likelihood** of severe impact:
- Most applications don't request proofs immediately after commit
- The async threads typically catch up quickly
- Recovery from crashes is automatic and correct

## Recommendation

**Option 1 (Conservative)**: Force synchronous commits for all transactions:

```rust
self.db.writer.save_transactions(
    output.as_chunk_to_commit(),
    chunk.ledger_info_opt.as_ref(),
    true, // sync_commit - CHANGED
)?;
```

**Option 2 (Performance-preserving)**: Implement a "proof-ready" version separate from "committed" version:

1. Maintain two version markers:
   - `synced_version`: Current behavior (transaction data committed)
   - `proof_ready_version`: Only advanced after state merkle tree persists

2. API layer should use `proof_ready_version` for queries requiring proofs

3. Add monitoring to alert if the gap exceeds thresholds

**Option 3 (Hybrid)**: Use synchronous commits for epoch boundaries and critical operations while keeping async for normal transactions, with proper API documentation about proof availability.

## Proof of Concept

```rust
// Test demonstrating the proof unavailability window
#[tokio::test]
async fn test_proof_unavailable_after_commit() {
    // Setup: Initialize ChunkExecutor with real storage
    let (db, executor) = setup_executor();
    
    // Step 1: Commit a chunk with sync_commit=false
    let chunk = create_test_chunk();
    executor.enqueue_chunk_by_execution(chunk, &target_li, None).unwrap();
    executor.update_ledger().unwrap();
    let notification = executor.commit_chunk().unwrap();
    
    // Step 2: Immediately query the latest version
    let latest_version = db.reader.get_latest_ledger_info_version().unwrap();
    
    // Step 3: Try to get state proof at this version
    // Expected: MissingRootError due to async state merkle persistence
    let state_key = StateKey::access_path(test_account());
    let result = db.reader.get_state_value_with_proof_by_version(
        &state_key,
        latest_version,
    );
    
    // This should fail with MissingRootError
    assert!(matches!(result, Err(AptosDbError::MissingRootError(_))));
    
    // Step 4: Wait for async persistence
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Step 5: Retry proof request - now should succeed
    let result = db.reader.get_state_value_with_proof_by_version(
        &state_key,
        latest_version,
    );
    assert!(result.is_ok());
}
```

**Notes**

The vulnerability is mitigated by robust crash recovery mechanisms that ensure no data loss or permanent state divergence. The primary concern is the temporary inconsistency during normal operation where committed transactions cannot be proven immediately, potentially affecting light clients and applications requiring immediate proof verification.

### Citations

**File:** execution/executor/src/chunk_executor/mod.rs (L277-282)
```rust
            self.db.writer.save_transactions(
                output.as_chunk_to_commit(),
                chunk.ledger_info_opt.as_ref(),
                false, // sync_commit
            )?;
        }
```

**File:** storage/storage-interface/src/lib.rs (L608-628)
```rust
    fn save_transactions(
        &self,
        chunk: ChunkToCommit,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        sync_commit: bool,
    ) -> Result<()> {
        // For reconfig suffix.
        if ledger_info_with_sigs.is_none() && chunk.is_empty() {
            return Ok(());
        }

        if !chunk.is_empty() {
            self.pre_commit_ledger(chunk.clone(), sync_commit)?;
        }
        let version_to_commit = if let Some(ledger_info_with_sigs) = ledger_info_with_sigs {
            ledger_info_with_sigs.ledger_info().version()
        } else {
            chunk.expect_last_version()
        };
        self.commit_ledger(version_to_commit, ledger_info_with_sigs, Some(chunk))
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L68-72)
```rust
            self.state_store.buffered_state().lock().update(
                chunk.result_ledger_state_with_summary(),
                chunk.estimated_total_state_updates(),
                sync_commit || chunk.is_reconfig,
            )?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L103-107)
```rust
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L662-669)
```rust
        if let Some(x) = ledger_info_with_sigs {
            self.ledger_db
                .metadata_db()
                .set_latest_ledger_info(x.clone());

            LEDGER_VERSION.set(x.ledger_info().version() as i64);
            NEXT_BLOCK_EPOCH.set(x.ledger_info().next_block_epoch() as i64);
        }
```

**File:** storage/aptosdb/src/state_store/buffered_state.rs (L99-113)
```rust
    fn maybe_commit(&mut self, checkpoint: Option<StateWithSummary>, sync_commit: bool) {
        if let Some(checkpoint) = checkpoint {
            if !checkpoint.is_the_same(&self.last_snapshot)
                && (sync_commit
                    || self.estimated_items >= self.target_items
                    || self.buffered_versions() >= TARGET_SNAPSHOT_INTERVAL_IN_VERSION)
            {
                self.enqueue_commit(checkpoint);
            }
        }

        if sync_commit {
            self.drain_commits();
        }
    }
```

**File:** storage/jellyfish-merkle/src/lib.rs (L736-741)
```rust
                    if nibble_depth == 0 {
                        AptosDbError::MissingRootError(version)
                    } else {
                        err
                    }
                })?;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L640-691)
```rust
        if snapshot_next_version < num_transactions {
            if check_max_versions_after_snapshot {
                ensure!(
                    num_transactions - snapshot_next_version <= MAX_WRITE_SETS_AFTER_SNAPSHOT,
                    "Too many versions after state snapshot. snapshot_next_version: {}, num_transactions: {}",
                    snapshot_next_version,
                    num_transactions,
                );
            }
            info!("Replaying writesets from {snapshot_next_version} to {num_transactions} to let state Merkle DB catch up.");

            let write_sets = state_db
                .ledger_db
                .write_set_db()
                .get_write_sets(snapshot_next_version, num_transactions)?;
            let txn_info_iter = state_db
                .ledger_db
                .transaction_info_db()
                .get_transaction_info_iter(snapshot_next_version, write_sets.len())?;
            let all_checkpoint_indices = txn_info_iter
                .into_iter()
                .collect::<Result<Vec<_>>>()?
                .into_iter()
                .positions(|txn_info| txn_info.has_state_checkpoint_hash())
                .collect();

            let state_update_refs = StateUpdateRefs::index_write_sets(
                state.next_version(),
                &write_sets,
                write_sets.len(),
                all_checkpoint_indices,
            );
            let current_state = out_current_state.lock().clone();
            let (hot_state, state) = out_persisted_state.get_state();
            let (new_state, _state_reads, hot_state_updates) = current_state
                .ledger_state()
                .update_with_db_reader(&state, hot_state, &state_update_refs, state_db.clone())?;
            let state_summary = out_persisted_state.get_state_summary();
            let new_state_summary = current_state.ledger_state_summary().update(
                &ProvableStateSummary::new(state_summary, state_db.as_ref()),
                &hot_state_updates,
                &state_update_refs,
            )?;
            let updated =
                LedgerStateWithSummary::from_state_and_summary(new_state, new_state_summary);

            // synchronously commit the snapshot at the last checkpoint here if not committed to disk yet.
            buffered_state.update(
                updated, 0,    /* estimated_items, doesn't matter since we sync-commit */
                true, /* sync_commit */
            )?;
        }
```
