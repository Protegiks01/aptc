# Audit Report

## Title
Batch Verification Soundness Failure When Random Challenge Equals Zero in DKG Sigma Protocols

## Summary
The DKG sigma protocol batch verification uses random challenges that can theoretically be zero, causing only the first proof to be verified while all subsequent proofs are ignored. This breaks the soundness guarantee of batch verification with probability ~1/2^255 per verification.

## Finding Description

The security question asks whether `E::G1::msm()` handles edge cases with zero scalars or points at infinity. The arkworks MSM implementation itself handles these cases correctly (mathematically, 0 * P = O and k * O = O). However, there is a critical logic vulnerability in the **batch verification** that uses MSM.

The vulnerability exists in two locations:

**Location 1: Schnorr PoK Batch Verification** [1](#0-0) 

The function computes powers of gamma: `[1, gamma, gamma^2, ..., gamma^{n-1}]`. If gamma = 0, this becomes `[1, 0, 0, 0, ...]`. [2](#0-1) 

Each PoK's contribution is multiplied by `gammas[i]`. When gamma = 0, only the first PoK (with coefficient 1) is verified; all others have coefficient 0 and are ignored.

**Location 2: Random Challenge Generation** [3](#0-2) 

The random scalars (including gamma/tau) are generated using `random_scalars()`: [4](#0-3) 

This function does NOT guarantee non-zero values. There's even a TODO comment acknowledging this issue: [5](#0-4) 

The codebase provides `random_nonzero_scalar()` but doesn't use it for batch verification challenges: [6](#0-5) 

**Attack Path:**
1. Malicious validator creates DKG transcript with 1 valid PoK and multiple invalid PoKs
2. During verification in `batch_verify_soks` → `pok_batch_verify`, gamma is randomly generated
3. If gamma = 0 (probability ~1/2^255), powers become [1, 0, 0, 0, ...]
4. Only first PoK is verified; invalid PoKs are ignored
5. Invalid transcript passes verification and enters consensus

**Similar Issue:** [7](#0-6) 

The sigma protocol verification uses the same pattern with beta, computing powers that become [1, 0, 0, 0, ...] if beta = 0.

## Impact Explanation

**Severity: HIGH** (but with extremely low likelihood)

If exploited, this breaks the **Cryptographic Correctness** invariant and could lead to:
- Invalid DKG transcripts accepted into consensus
- Compromised randomness beacon affecting consensus security
- Potential validator set manipulation
- Violation of the soundness property of zero-knowledge proofs

This meets the **High Severity** criteria: "Significant protocol violations" affecting consensus integrity.

## Likelihood Explanation

**Likelihood: NEGLIGIBLE** (~1/2^255 per verification)

The probability of gamma or beta being zero is approximately 1 / (order of scalar field), which for BLS12-381 is about 1/2^255. This is astronomically unlikely - comparable to:
- Finding a SHA-256 collision
- Guessing a 256-bit private key

Even with millions of DKG verifications over years, the expected number of occurrences approaches zero. The attacker cannot control or predict when gamma = 0, making this a theoretical rather than practical vulnerability.

However, the existence of the TODO comment indicates the developers recognize this as technical debt that should be fixed.

## Recommendation

Replace `random_scalars()` with `random_nonzero_scalar()` for all batch verification challenges:

**File: `crates/aptos-dkg/src/pvss/das/weighted_protocol.rs`**
```rust
// BEFORE (line 297):
let extra = random_scalars(2 + W * 3, &mut rng);

// AFTER:
let extra: Vec<Scalar> = (0..2 + W * 3)
    .map(|_| random_nonzero_scalar(&mut rng))
    .collect();
```

**File: `crates/aptos-dkg/src/sigma_protocol/traits.rs`**
```rust
// BEFORE (line 96):
let beta = C::ScalarField::rand(&mut rng);

// AFTER:
let beta = loop {
    let b = C::ScalarField::rand(&mut rng);
    if !b.is_zero() { break b; }
};
```

## Proof of Concept

Due to the negligible probability (~1/2^255), a direct PoC demonstrating gamma = 0 is infeasible. However, the vulnerability can be demonstrated conceptually:

```rust
// Conceptual PoC showing the logic flaw
#[test]
fn test_batch_verification_with_zero_challenge() {
    let gamma = Scalar::ZERO; // Force zero for demonstration
    
    // Compute powers: [1, 0, 0, 0, ...]
    let mut gammas = vec![Scalar::ONE];
    for _ in 0..3 {
        gammas.push(gammas.last().unwrap() * gamma);
    }
    assert_eq!(gammas, vec![Scalar::ONE, Scalar::ZERO, Scalar::ZERO, Scalar::ZERO]);
    
    // Create 1 valid PoK + 3 invalid PoKs
    let valid_pok = create_valid_pok();
    let invalid_poks = vec![create_invalid_pok(); 3];
    let all_poks = vec![valid_pok].into_iter().chain(invalid_poks).collect();
    
    // Batch verification with gamma=0 would PASS (only checks first)
    // but should FAIL (has invalid PoKs)
}
```

**Notes**

While this constitutes a theoretical soundness violation with extremely low probability, it does not meet the threshold for a **practically exploitable vulnerability** because:

1. The attacker cannot control or trigger gamma = 0
2. Probability is negligible (1/2^255)
3. The codebase has a TODO acknowledging this technical debt
4. Arkworks MSM itself handles zero scalars correctly

This is best classified as **defense-in-depth hardening** rather than a critical security bug. However, given the high-security requirements of consensus protocols, eliminating even negligible-probability edge cases is recommended.

### Citations

**File:** crates/aptos-dkg/src/pvss/schnorr.rs (L81-86)
```rust
    // Compute \gamma_i = \gamma^i, for all i \in [0, n]
    let mut gammas = Vec::with_capacity(n);
    gammas.push(Scalar::ONE);
    for _ in 0..(n - 1) {
        gammas.push(gammas.last().unwrap().mul(gamma));
    }
```

**File:** crates/aptos-dkg/src/pvss/schnorr.rs (L88-103)
```rust
    let mut last_exp = Scalar::ZERO;
    for i in 0..n {
        let (pk, (R, s)) = poks[i];

        bases.push(R);
        exps.push(gammas[i]);

        bases.push(pk);
        exps.push(schnorr_hash(Challenge::<Gr> { R, pk, g: *g }) * gammas[i]);

        last_exp += s * gammas[i];
    }

    bases.push(*g);
    exps.push(last_exp.neg());

```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L295-297)
```rust
        // Deriving challenges by flipping coins: less complex to implement & less likely to get wrong. Creates bad RNG risks but we deem that acceptable.
        let mut rng = rand::thread_rng();
        let extra = random_scalars(2 + W * 3, &mut rng);
```

**File:** crates/aptos-dkg/src/utils/random.rs (L7-19)
```rust
/// TODO(Security): This file is a workaround for the `rand_core_hell` issue, briefly described below.
///
/// Ideally, we would write the following sane code:
///
/// ```ignore
/// let mut dk = Scalar::random(rng);
/// while dk.is_zero() {
///     dk = Scalar::random(rng);
/// }
/// ```
///
/// But we can't due to `aptos-crypto`'s dependency on an older version of `rand` and `rand_core`
/// compared to `blstrs`'s dependency.
```

**File:** crates/aptos-dkg/src/utils/random.rs (L29-34)
```rust
pub fn random_nonzero_scalar<R>(rng: &mut R) -> Scalar
where
    R: rand_core::RngCore + rand::Rng + rand_core::CryptoRng + rand::CryptoRng,
{
    aptos_crypto::blstrs::random_scalar_internal(rng, true)
}
```

**File:** crates/aptos-dkg/src/utils/random.rs (L102-115)
```rust
pub fn random_scalars<R>(n: usize, rng: &mut R) -> Vec<Scalar>
where
    R: rand_core::RngCore + rand::Rng + rand_core::CryptoRng + rand::CryptoRng,
{
    let mut v = Vec::with_capacity(n);

    for _ in 0..n {
        v.push(aptos_crypto::blstrs::random_scalar(rng));
    }

    debug_assert_eq!(v.len(), n);

    v
}
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L94-97)
```rust
        // --- Random verifier challenge β ---
        let mut rng = ark_std::rand::thread_rng(); // TODO: move this to trait!!
        let beta = C::ScalarField::rand(&mut rng);
        let powers_of_beta = utils::powers(beta, number_of_beta_powers);
```
