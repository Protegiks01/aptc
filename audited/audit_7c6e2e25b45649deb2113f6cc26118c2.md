# Audit Report

## Title
Silent Iterator Error Suppression in Randomness Storage Causes Consensus Divergence

## Summary
The `get_all()` function in the consensus randomness storage layer silently discards database iterator errors using `filter_map`, returning incomplete datasets without indication of failure. This causes validators to have inconsistent views of certified augmented data, breaking consensus safety guarantees during randomness generation.

## Finding Description

The vulnerability exists in the `get_all()` private method in the randomness database storage implementation. The function creates a database iterator and uses `filter_map` to process results, but critically converts all `Err(_)` variants to `None`, silently dropping errors: [1](#0-0) 

The SchemaDB iterator returns `Result<(Key, Value)>` for each item, where errors can occur from RocksDB status checks, BCS deserialization failures, or incomplete result errors: [2](#0-1) 

This function is invoked during critical initialization when loading certified augmented data: [3](#0-2) 

When `get_all_certified_aug_data()` encounters iterator errors, it returns an incomplete set without indication of failure. The calling code uses `unwrap_or_default()`, which only catches the outer `Result`, not the silent filtering inside. This causes `AugDataStore` to initialize with missing validator data.

**Consensus Impact Chain:**

The augmented data contains Delta values used to construct augmented public keys (APKs) for the weighted VUF randomness protocol. Missing certified deltas are processed via the `augment()` function which adds them to the RandConfig: [4](#0-3) 

Missing certified deltas prevent APK reconstruction. When randomness shares arrive from validators whose data was silently dropped, share verification fails because the APK is unavailable: [5](#0-4) 

During share aggregation, missing APKs cause failures or prevent proper aggregation: [6](#0-5) 

The weighted VUF `derive_eval` function requires APKs for all participating players. If APKs are missing, it returns an error: [7](#0-6) 

This breaks **Consensus Safety** because:
1. Different validators experiencing different iterator errors have different views of which validators possess valid APKs
2. Each validator will accept/reject different sets of randomness shares based on APK availability
3. Validators with different APK sets aggregate different share subsets
4. The `derive_eval` computation uses player-specific APKs, potentially producing different randomness values
5. The randomness is embedded in block metadata transactions during execution: [8](#0-7) 

Different randomness values in block metadata lead to different state roots, causing consensus divergence.

## Impact Explanation

**Severity: CRITICAL** (per Aptos Bug Bounty criteria for "Consensus/Safety Violations")

This vulnerability causes **consensus-level protocol violations** by breaking deterministic execution guarantees. When validators have inconsistent views of certified augmented data:

- **Consensus Divergence**: Different nodes compute different randomness values for identical blocks at identical rounds, leading to different state commitments
- **Liveness Failures**: Nodes missing critical validator APK data cannot properly verify or aggregate randomness shares, potentially failing to generate randomness
- **Protocol Safety Violation**: The weighted VUF protocol requires all honest validators to have consistent views of certified public key shares; this assumption is violated
- **Non-deterministic Execution**: Identical blocks produce different execution results on different nodes based on which database entries encountered errors

This directly matches the CRITICAL severity category: "Different validators commit different blocks" due to the randomness being embedded in the deterministically-executed block metadata transaction. While not immediate fund loss, this breaks fundamental blockchain correctness invariants and can cascade into broader consensus failures, chain halts, or require emergency intervention.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

This vulnerability can manifest through natural operational failures:

**Natural Occurrence (HIGH likelihood):**
- Database corruption from hardware failures, power loss, or disk errors
- Schema migration issues causing BCS deserialization failures during iterator processing
- RocksDB hitting internal operational limits
- Filesystem I/O errors during database reads
- These are common operational issues in long-running distributed validator nodes

The vulnerability is particularly dangerous because:
1. Silent failures provide no error logs or diagnostics for operators
2. Inconsistent state across validators is difficult to detect until consensus failures manifest
3. Partial data loss (some validators affected, others not) creates non-deterministic failure patterns
4. The error occurs during initialization, so affected validators run with incomplete state throughout the epoch

The RandKeys structure stores APKs in OnceCell slots that are populated once and never updated: [9](#0-8) 

Once initialized with missing APKs due to silent database errors, the validator cannot recover without restarting and successfully loading the data.

## Recommendation

Replace the silent `filter_map` error suppression with explicit error propagation:

```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    
    let mut results = Vec::new();
    for item in iter {
        let (k, v) = item?; // Propagate errors instead of silently dropping
        results.push((k, v));
    }
    Ok(results)
}
```

This ensures that database errors are properly surfaced to calling code, allowing `AugDataStore::new()` to handle failures appropriately (e.g., retry, log critical errors, or fail initialization cleanly rather than silently starting with incomplete data).

Additionally, add validation in `AugDataStore::new()` to verify that expected certified augmented data was loaded for all validators in the epoch, failing initialization if critical data is missing.

## Proof of Concept

While a complete PoC would require setting up a multi-validator testnet with induced database corruption, the vulnerability can be demonstrated through code analysis:

1. Initialize validator A with corrupted database entries for certain validators' certified augmented data
2. During epoch start, `RandDb::get_all()` encounters deserialization errors for corrupted entries
3. These errors are silently dropped (line 79: `Err(_) => None`)
4. `AugDataStore::new()` initializes with incomplete certified data
5. When randomness generation begins, validator A cannot verify shares from validators with missing APKs
6. Validator A aggregates a different subset of shares than validator B (which has complete data)
7. The WVUF `derive_eval` computation produces different results due to different APK sets
8. Block execution embeds different randomness values, causing state divergence

The consensus impact is deterministic once database inconsistency occurs, as the APK mismatch will persist throughout the epoch.

---

**Notes:**

This vulnerability represents a critical flaw in error handling at the storage layer that propagates to consensus-critical randomness generation. The silent failure mode makes detection extremely difficult, and the impact on consensus safety is severe. The fix is straightforward (proper error propagation), but the potential for production incidents is significant given the realistic likelihood of database errors in distributed systems.

### Citations

**File:** consensus/src/rand/rand_gen/storage/db.rs (L73-82)
```rust
    fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter
            .filter_map(|e| match e {
                Ok((k, v)) => Some((k, v)),
                Err(_) => None,
            })
            .collect::<Vec<(S::Key, S::Value)>>())
    }
```

**File:** storage/schemadb/src/iterator.rs (L92-122)
```rust
    fn next_impl(&mut self) -> aptos_storage_interface::Result<Option<(S::Key, S::Value)>> {
        let _timer = APTOS_SCHEMADB_ITER_LATENCY_SECONDS.timer_with(&[S::COLUMN_FAMILY_NAME]);

        if let Status::Advancing = self.status {
            match self.direction {
                ScanDirection::Forward => self.db_iter.next(),
                ScanDirection::Backward => self.db_iter.prev(),
            }
        } else {
            self.status = Status::Advancing;
        }

        if !self.db_iter.valid() {
            self.db_iter.status().into_db_res()?;
            // advancing an invalid raw iter results in seg fault
            self.status = Status::Invalid;
            return Ok(None);
        }

        let raw_key = self.db_iter.key().expect("db_iter.key() failed.");
        let raw_value = self.db_iter.value().expect("db_iter.value(0 failed.");
        APTOS_SCHEMADB_ITER_BYTES.observe_with(
            &[S::COLUMN_FAMILY_NAME],
            (raw_key.len() + raw_value.len()) as f64,
        );

        let key = <S::Key as KeyCodec<S>>::decode_key(raw_key);
        let value = <S::Value as ValueCodec<S>>::decode_value(raw_value);

        Ok(Some((key?, value?)))
    }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L51-65)
```rust
        let all_data = db.get_all_aug_data().unwrap_or_default();
        let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
        if let Err(e) = db.remove_aug_data(to_remove) {
            error!("[AugDataStore] failed to remove aug data: {:?}", e);
        }

        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }
```

**File:** consensus/src/rand/rand_gen/types.rs (L51-81)
```rust
impl TShare for Share {
    fn verify(
        &self,
        rand_config: &RandConfig,
        rand_metadata: &RandMetadata,
        author: &Author,
    ) -> anyhow::Result<()> {
        let index = *rand_config
            .validator
            .address_to_validator_index()
            .get(author)
            .ok_or_else(|| anyhow!("Share::verify failed with unknown author"))?;
        let maybe_apk = &rand_config.keys.certified_apks[index];
        if let Some(apk) = maybe_apk.get() {
            WVUF::verify_share(
                &rand_config.vuf_pp,
                apk,
                bcs::to_bytes(&rand_metadata)
                    .map_err(|e| anyhow!("Serialization failed: {}", e))?
                    .as_slice(),
                &self.share,
            )?;
        } else {
            bail!(
                "[RandShare] No augmented public key for validator id {}, {}",
                index,
                author
            );
        }
        Ok(())
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L119-127)
```rust
            let apk = rand_config
                .get_certified_apk(share.author())
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with missing apk for share from {}",
                        share.author
                    )
                })?;
            apks_and_proofs.push((Player { id }, apk.clone(), share.share().share));
```

**File:** consensus/src/rand/rand_gen/types.rs (L178-194)
```rust
    fn augment(
        &self,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        author: &Author,
    ) {
        let AugmentedData { delta, fast_delta } = self;
        rand_config
            .add_certified_delta(author, delta.clone())
            .expect("Add delta should succeed");

        if let (Some(config), Some(fast_delta)) = (fast_rand_config, fast_delta) {
            config
                .add_certified_delta(author, fast_delta.clone())
                .expect("Add delta for fast path should succeed");
        }
    }
```

**File:** crates/aptos-dkg/src/weighted_vuf/pinkas/mod.rs (L298-302)
```rust
            let apk = apks[player.id]
                .as_ref()
                .ok_or_else(|| anyhow!("Missing APK for player {}", player.get_id()))?;

            rks.push(&apk.0.rks);
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L807-811)
```rust
        let metadata_txn = if let Some(maybe_rand) = rand_result {
            block.new_metadata_with_randomness(&validator, maybe_rand)
        } else {
            block.new_block_metadata(&validator).into()
        };
```

**File:** types/src/randomness.rs (L117-135)
```rust
    pub fn new(ask: ASK, apk: APK, pk_shares: Vec<PKShare>, num_validators: usize) -> Self {
        let certified_apks = vec![OnceCell::new(); num_validators];

        Self {
            ask,
            apk,
            certified_apks,
            pk_shares,
        }
    }

    pub fn add_certified_apk(&self, index: usize, apk: APK) -> anyhow::Result<()> {
        assert!(index < self.certified_apks.len());
        if self.certified_apks[index].get().is_some() {
            return Ok(());
        }
        self.certified_apks[index].set(apk).unwrap();
        Ok(())
    }
```
