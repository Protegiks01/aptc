# Audit Report

## Title
TPS Checker Allows Malicious Nodes to Inflate Transaction Processing Metrics Without Executing Transactions

## Summary
The node-checker's TPS (Transactions Per Second) evaluation can be trivially bypassed by a malicious node operator who manipulates their local database to report inflated transaction processing rates without actually executing any transactions. This allows underpowered nodes to fraudulently pass validator health checks and join the validator set.

## Finding Description

The TPS checker validates a node's transaction processing capacity by submitting transactions and measuring committed throughput. However, it relies entirely on untrusted API responses from the target node without any cryptographic verification.

**Attack Flow:**

1. **Transaction Submission** - The checker calls `emit_transactions_with_cluster()` which submits transactions via `client.submit_batch_bcs(txns)`. This increments the `stats.submitted` counter when the HTTP POST succeeds. [1](#0-0) 

2. **Fake Commitment Verification** - The checker waits for transactions to be "committed" by polling `get_account_bcs(address)` to check if account sequence numbers increased. [2](#0-1) 

3. **No Cryptographic Verification** - The `get_account_bcs()` method makes a plain HTTP GET request without verifying state proofs or merkle tree consistency. [3](#0-2) 

4. **No Baseline Cross-Validation** - The TPS checker only queries the target node, never comparing against a trusted baseline node. [4](#0-3) 

5. **Stats Calculation** - "Committed" transactions are counted based solely on sequence number increases, which are under the malicious node's control. [5](#0-4) 

**Exploitation:**
A malicious node operator modifies their REST API handlers to:
- Accept transactions via POST `/transactions/batch` (return HTTP 202)
- Immediately increment account sequence numbers in AptosDB
- Skip transaction execution entirely (saves computation)
- Return fake sequence numbers via GET `/accounts/{address}`
- Pass TPS check with score 100/100

**Broken Invariant:**
Violates **State Consistency**: "State transitions must be atomic and verifiable via Merkle proofs" - the checker accepts state changes without cryptographic verification.

## Impact Explanation

**Severity: HIGH** (up to $50,000 per Aptos bug bounty)

This vulnerability enables:

1. **Validator Node Slowdowns** - Underpowered nodes join the validator set, causing consensus delays and missed proposals during actual block production
2. **Network Performance Degradation** - Validators that cannot sustain required TPS slow down block confirmations network-wide
3. **Health Check Bypass** - Completely undermines the node-checker's purpose of ensuring validator quality

This meets the **"Validator node slowdowns"** category from the HIGH severity tier. While not directly causing consensus safety violations, it allows nodes to fraudulently pass capacity checks, leading to operational issues when they participate in consensus.

## Likelihood Explanation

**Likelihood: HIGH**

Attack requirements:
- Node operator access (necessary to run a validator)
- Ability to modify REST API handlers or database state
- No cryptographic keys needed
- No collusion required
- Trivial implementation (simple database manipulation)

This is highly likely because:
- Operators have full control over their node software
- The attack is undetectable without external verification
- No technical sophistication required
- Strong financial incentive (validator rewards without hardware costs)

## Recommendation

Implement multi-layered verification:

**1. Add State Proof Verification**
Modify `get_account_bcs()` to request and verify state proofs against signed ledger info:
- Query account state with merkle proof
- Verify proof against accumulator root hash
- Validate ledger info signatures from validator set

**2. Cross-Validate Against Baseline Node**
Update TPS checker to compare transaction results between target and trusted baseline:
- Submit same transactions to both nodes
- Verify identical accumulator root hashes
- Detect discrepancies in committed transactions

**3. Verify Consensus Participation**
Check that submitted transactions appear in committed blocks:
- Query block contents from multiple validators
- Verify transaction inclusion via merkle proofs
- Ensure consensus signatures from quorum

**4. Add Transaction Execution Verification**
Verify actual state changes occurred:
- Check expected balance changes from transfers
- Validate event emissions match transaction types
- Compare state roots with baseline node

## Proof of Concept

**Conceptual PoC** (requires node operator access):

```rust
// Malicious REST API Handler Modification
// In api/src/accounts.rs - modify get_account handler

async fn get_account_fake_tps(
    accept_type: AcceptType,
    address: Address,
    ledger_version: Option<U64>,
    context: Arc<Context>,
) -> BasicResult<AccountResponse> {
    // Normal retrieval
    let mut account = context.db.get_account_bcs(&address.into(), ledger_version)?;
    
    // MALICIOUS: Artificially inflate sequence number
    // without executing transactions
    if is_being_tps_checked() {
        account.sequence_number += PENDING_FAKE_TXNS_COUNT;
    }
    
    Ok(AccountResponse::new(account))
}
```

**Attack Steps:**
1. Run modified node with fake sequence number logic
2. Node-checker submits 1000 transactions via `emit_transactions_with_cluster()`
3. Malicious node accepts all transactions (increments `submitted`)
4. Malicious node increments sequence numbers without execution
5. Node-checker polls `get_account_bcs()` and sees numbers increased
6. Checker calculates high TPS, awards score 100/100
7. Underpowered node passes validation

**Detection Test:**
Compare state roots between target and trusted baseline after TPS test - they will diverge because the malicious node didn't actually execute transactions, only faked sequence numbers.

## Notes

The vulnerability exists because the node-checker was designed for cooperative health monitoring, not adversarial validation. While the separate `TransactionCorrectnessChecker` does verify accumulator root hashes against a baseline, the TPS checker operates independently without such verification.

This attack requires node operator access (insider threat), but is explicitly in scope since the question asks about "malicious target node" behavior. The purpose of node-checker is to prevent such nodes from joining the validator set.

### Citations

**File:** crates/transaction-emitter-lib/src/emitter/submission_worker.rs (L353-356)
```rust
        if num_committed > 0 {
            loop_stats
                .committed
                .fetch_add(num_committed as u64, Ordering::Relaxed);
```

**File:** crates/transaction-emitter-lib/src/emitter/submission_worker.rs (L486-501)
```rust
pub async fn submit_transactions(
    client: &RestClient,
    txns: &[SignedTransaction],
    loop_start_time: Instant,
    txn_offset_time: Arc<AtomicU64>,
    stats: &StatsAccumulator,
) {
    let cur_time = Instant::now();
    let offset = cur_time - loop_start_time;
    txn_offset_time.fetch_add(
        txns.len() as u64 * offset.as_millis() as u64,
        Ordering::Relaxed,
    );
    stats
        .submitted
        .fetch_add(txns.len() as u64, Ordering::Relaxed);
```

**File:** crates/transaction-emitter-lib/src/emitter/mod.rs (L1104-1189)
```rust
async fn wait_for_accounts_sequence(
    start_time: Instant,
    client: &RestClient,
    account_seqs: &HashMap<AccountAddress, (u64, u64)>,
    txn_expiration_ts_secs: u64,
    sleep_between_cycles: Duration,
) -> (HashMap<AccountAddress, u64>, u128) {
    let mut pending_addresses: HashSet<_> = account_seqs.keys().copied().collect();
    let mut latest_fetched_counts = HashMap::new();

    let mut sum_of_completion_timestamps_millis = 0u128;

    if pending_addresses.is_empty() {
        return (HashMap::new(), sum_of_completion_timestamps_millis);
    }

    loop {
        match query_sequence_numbers(client, pending_addresses.iter()).await {
            Ok((sequence_numbers, ledger_timestamp_secs)) => {
                let millis_elapsed = start_time.elapsed().as_millis();
                for (address, sequence_number) in sequence_numbers {
                    let (start_seq_num, end_seq_num) = account_seqs.get(&address).unwrap();

                    let prev_sequence_number = latest_fetched_counts
                        .insert(address, sequence_number)
                        .unwrap_or(*start_seq_num);
                    // fetched sequence number that is older than one we already fetched.
                    // client connection probably moved to a different server.
                    if prev_sequence_number <= sequence_number {
                        sum_of_completion_timestamps_millis +=
                            millis_elapsed * (sequence_number - prev_sequence_number) as u128;

                        if *end_seq_num == sequence_number {
                            pending_addresses.remove(&address);
                        }
                    }
                }

                if pending_addresses.is_empty() {
                    break;
                }

                if ledger_timestamp_secs > txn_expiration_ts_secs {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(60)),
                        warn!(
                            "[{}] Ledger timestamp {} exceeded txn expiration timestamp {} for {:?}",
                            client.path_prefix_string(),
                            ledger_timestamp_secs,
                            txn_expiration_ts_secs,
                            pending_addresses,
                        )
                    );
                    break;
                }
            },
            Err(e) => {
                sample!(
                    SampleRate::Duration(Duration::from_secs(60)),
                    warn!(
                        "[{}] Failed to query ledger info on accounts {:?}: {:?}",
                        client.path_prefix_string(),
                        pending_addresses,
                        e
                    )
                );
            },
        }

        if aptos_infallible::duration_since_epoch().as_secs() >= txn_expiration_ts_secs + 240 {
            sample!(
                SampleRate::Duration(Duration::from_secs(15)),
                error!(
                    "[{}] Client cannot catch up to needed timestamp ({}), after additional 240s, aborting",
                    client.path_prefix_string(),
                    txn_expiration_ts_secs,
                )
            );
            break;
        }

        time::sleep(sleep_between_cycles).await;
    }

    (latest_fetched_counts, sum_of_completion_timestamps_millis)
}
```

**File:** crates/aptos-rest-client/src/lib.rs (L1581-1588)
```rust
    pub async fn get_account_bcs(
        &self,
        address: AccountAddress,
    ) -> AptosResult<Response<AccountResource>> {
        let url = self.build_path(&format!("accounts/{}", address.to_hex()))?;
        let response = self.get_bcs(url).await?;
        Ok(response.and_then(|inner| bcs::from_bytes(&inner))?)
    }
```

**File:** ecosystem/node-checker/src/checker/tps.rs (L108-191)
```rust
    async fn check(
        &self,
        providers: &ProviderCollection,
    ) -> Result<Vec<CheckResult>, CheckerError> {
        let target_api_index_provider = get_provider!(
            providers.target_api_index_provider,
            self.config.common.required,
            ApiIndexProvider
        );

        let target_url = target_api_index_provider.client.build_path("/").unwrap();
        let chain_id = match target_api_index_provider.provide().await {
            Ok(response) => ChainId::new(response.chain_id),
            Err(err) => {
                return Ok(vec![Self::build_result(
                    "Failed to get chain ID of your node".to_string(),
                    0,
                    format!("There was an error querying your node's API: {:#}", err),
                )]);
            },
        };

        let cluster_config = ClusterArgs {
            targets: Some(vec![target_url; self.config.repeat_target_count]),
            targets_file: None,
            coin_source_args: self.config.coin_source_args.clone(),
            chain_id: Some(chain_id),
            node_api_key: None,
        };
        let cluster = Cluster::try_from_cluster_args(&cluster_config)
            .await
            .map_err(TpsCheckerError::BuildClusterError)?;

        let stats = emit_transactions_with_cluster(
            &cluster,
            &self.config.emit_config,
            self.config
                .emit_workload_configs
                .args_to_transaction_mix_per_phase(),
        )
        .await
        .map_err(TpsCheckerError::TransactionEmitterError)?;

        // AKA stats per second.
        let rate = stats.rate();

        if rate.submitted < (self.config.minimum_tps as f64) {
            return Err(TpsCheckerError::InsufficientSubmittedTransactionsError(
                rate.submitted as u64,
                self.config.minimum_tps,
            )
            .into());
        }

        let mut description = format!("The minimum TPS (transactions per second) \
            required of nodes is {}, your node hit: {} (out of {} transactions submitted per second).", self.config.minimum_tps, rate.committed, rate.submitted);
        let evaluation_result = if rate.committed >= (self.config.minimum_tps as f64) {
            if stats.committed == stats.submitted {
                description.push_str(
                    " Your node could theoretically hit \
                even higher TPS, the evaluation suite only tests to check \
                your node meets the minimum requirements.",
                );
            }
            Self::build_result(
                "Transaction processing speed is sufficient".to_string(),
                100,
                description,
            )
        } else {
            description.push_str(
                " This implies that the hardware you're \
            using to run your node isn't powerful enough, please see the attached link",
            );
            Self::build_result(
                "Transaction processing speed is too low".to_string(),
                0,
                description,
            )
            .links(vec![NODE_REQUIREMENTS_LINK.to_string()])
        };

        Ok(vec![evaluation_result])
    }
```
