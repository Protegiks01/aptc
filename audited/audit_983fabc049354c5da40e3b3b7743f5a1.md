# Audit Report

## Title
Silent Permanent Failure of Storage Service on Network Stream Termination

## Summary
The storage service's main request processing loop exits permanently when the underlying network event stream returns `Poll::Ready(None)`, with no recovery mechanism, error logging, or restart capability. This causes complete loss of storage service availability, preventing other nodes from syncing state and potentially causing network-wide state synchronization failures.

## Finding Description

The vulnerability exists in the stream consumption pattern of `StorageServiceServer::start()`. When `network_requests.next().await` returns `None`, the main processing loop exits silently and permanently. [1](#0-0) 

The `network_requests` field is of type `StorageServiceNetworkEvents`, which implements the `Stream` trait by delegating to an underlying `network_request_stream`: [2](#0-1) 

This stream is constructed by combining multiple `NetworkEvents` streams (one per NetworkId) using `select_all()`: [3](#0-2) 

Each `NetworkEvents` stream terminates when its underlying `aptos_channel::Receiver` returns `None`, which occurs when all senders are dropped AND the queue is drained: [4](#0-3) 

The senders are held in `PeerManager.upstream_handlers` (an `Arc<HashMap>`). When `PeerManager::start()` terminates (its event loop exits via the `complete` branch when all input channels close), the PeerManager is dropped: [5](#0-4) 

When the PeerManager drops, it drops the `upstream_handlers`, which drops all senders, causing the receiver streams to terminate. This propagates through `select_all()` to `StorageServiceNetworkEvents`, causing the storage service's main loop to exit.

**Critical Issue**: Once the loop exits, there is no recovery mechanism. The storage service is started once via: [6](#0-5) 

The spawned task simply completes when `start()` returns, with no restart logic, no error logging, and no recovery attempt.

## Impact Explanation

This vulnerability meets **Critical Severity** criteria per the Aptos bug bounty program:

1. **Total loss of liveness/network availability**: Once the storage service stops processing requests, other nodes cannot sync state from this validator. The storage service is a critical component for state synchronization across the network.

2. **Non-recoverable without node restart**: There is no automatic recovery mechanism. The only way to restore service is to restart the entire node, which requires manual intervention and causes extended downtime.

3. **Silent failure**: The service stops processing requests without any error logging or alerting. Other spawned tasks (summary refresher, optimistic fetch handler, subscription handler) continue running, creating a "zombie" state where the service appears alive but is non-functional.

4. **Network-wide cascading failures**: If multiple nodes are affected (e.g., during network partitions or infrastructure issues), it can cause widespread state sync failures across the Aptos network.

## Likelihood Explanation

**High Likelihood** - This vulnerability can be triggered by multiple realistic scenarios:

1. **Network Partitions**: Temporary network issues can cause PeerManager to shut down when all its input channels close, immediately triggering this bug.

2. **Channel Overflow**: If the `aptos_channel` reaches capacity and starts dropping messages, senders may be dropped, leading to stream termination.

3. **Component Failures**: Any failure in the network stack or related components that causes channel closure will trigger this vulnerability.

4. **Runtime Shutdown Signals**: Graceful shutdown attempts that close channels will cause stream termination, but the storage service has no graceful restart mechanism.

5. **Resource Exhaustion**: Memory pressure or resource limits can cause components to fail and channels to close.

The vulnerability does not require any privileged access, malicious validators, or complex attack setup. It can occur naturally during normal network operations or infrastructure issues.

## Recommendation

Implement a recovery mechanism with automatic restart capability and proper error logging. Here's the recommended fix:

**Option 1: Loop-based restart with exponential backoff**
```rust
pub async fn start(mut self) {
    let mut restart_count = 0;
    let max_restarts = 10;
    
    loop {
        // Spawn the continuously running tasks (only on first start)
        if restart_count == 0 {
            self.spawn_continuous_storage_summary_tasks().await;
        }

        // Handle the storage requests as they arrive
        while let Some(network_request) = self.network_requests.next().await {
            // ... existing request handling code ...
        }

        // Stream terminated - log and attempt recovery
        error!(
            LogSchema::new(LogEntry::StorageServiceStreamTerminated),
            restart_count = restart_count,
            "Storage service network stream terminated. Attempting recovery..."
        );

        restart_count += 1;
        if restart_count >= max_restarts {
            error!("Storage service exceeded maximum restart attempts. Shutting down.");
            panic!("Storage service network stream permanently terminated");
        }

        // Exponential backoff before restart
        let backoff_ms = 1000 * (2_u64.pow(restart_count.min(5)));
        tokio::time::sleep(Duration::from_millis(backoff_ms)).await;

        // Attempt to recreate network stream
        // Note: This requires changes to allow stream recreation
    }
}
```

**Option 2: Panic on stream termination (fail-fast)**
```rust
pub async fn start(mut self) {
    self.spawn_continuous_storage_summary_tasks().await;

    while let Some(network_request) = self.network_requests.next().await {
        // ... existing request handling code ...
    }

    // Stream terminated unexpectedly - panic to force node restart
    panic!(
        "Storage service network stream terminated unexpectedly. \
         This indicates a critical network component failure. \
         Node restart required."
    );
}
```

**Option 3: Health check and monitoring**
Add a health check mechanism that monitors stream liveness and triggers alerts/restarts:

```rust
impl<T: StorageReaderInterface + Send + Sync> StorageServiceServer<T> {
    pub fn is_healthy(&self) -> bool {
        !self.network_requests.is_terminated()
    }
}
```

The recommended approach is **Option 2** (fail-fast with panic) combined with monitoring, as it ensures the node operator is immediately aware of the failure and can take corrective action. This is safer than attempting automatic recovery which might mask underlying network infrastructure issues.

## Proof of Concept

```rust
// Reproduction steps (conceptual - requires test infrastructure):

#[tokio::test]
async fn test_storage_service_stream_termination() {
    // 1. Set up storage service with network events
    let (network_sender, network_receiver) = aptos_channel::new(
        QueueStyle::FIFO,
        10,
        None,
    );
    
    let network_events = NetworkEvents::new(network_receiver, None, false);
    let mut network_service_events = HashMap::new();
    network_service_events.insert(NetworkId::Validator, network_events);
    
    let storage_network_events = StorageServiceNetworkEvents::new(
        NetworkServiceEvents::new(network_service_events)
    );
    
    let storage_service = StorageServiceServer::new(
        config,
        runtime.handle().clone(),
        storage_reader,
        time_service,
        peers_and_metadata,
        storage_network_events,
        storage_service_listener,
    );
    
    // 2. Start the storage service in a background task
    let service_handle = tokio::spawn(storage_service.start());
    
    // 3. Send some requests to verify service is running
    network_sender.push(
        (peer_id, protocol_id),
        create_test_request()
    ).unwrap();
    
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // 4. Drop all senders to trigger stream termination
    drop(network_sender);
    
    // 5. Wait for service task to complete
    let result = tokio::time::timeout(
        Duration::from_secs(5),
        service_handle
    ).await;
    
    // 6. Verify that service terminated (this is the bug)
    assert!(result.is_ok(), "Storage service should have terminated");
    
    // 7. Attempt to send new request - will fail because service is dead
    // This demonstrates the permanent failure with no recovery
    
    // Expected: Service should either:
    // - Panic with clear error message (fail-fast)
    // - Implement recovery mechanism
    // - Log critical error before terminating
    //
    // Actual: Service silently terminates with no error or recovery
}
```

## Notes

This vulnerability is particularly dangerous because:

1. **Silent failure mode**: No errors are logged when the stream terminates, making diagnosis difficult
2. **Partial service continuation**: Background tasks continue running, giving false impression of service health
3. **No observability**: Standard health checks might not detect this issue if they only check process liveness
4. **Cascading impact**: Affects all nodes attempting to sync state from the failed validator

The issue should be addressed by implementing proper error handling, health monitoring, and either fail-fast semantics (panic on stream termination) or automatic recovery with backoff.

### Citations

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/server/src/network.rs (L40-59)
```rust
    pub fn new(network_service_events: NetworkServiceEvents<StorageServiceMessage>) -> Self {
        // Transform the event streams to also include the network ID
        let network_events: Vec<_> = network_service_events
            .into_network_and_events()
            .into_iter()
            .map(|(network_id, events)| events.map(move |event| (network_id, event)))
            .collect();
        let network_events = select_all(network_events).fuse();

        // Transform each event to a network request
        let network_request_stream = network_events
            .filter_map(|(network_id, event)| {
                future::ready(Self::event_to_request(network_id, event))
            })
            .boxed();

        Self {
            network_request_stream,
        }
    }
```

**File:** state-sync/storage-service/server/src/network.rs (L87-93)
```rust
impl Stream for StorageServiceNetworkEvents {
    type Item = NetworkRequest;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        Pin::new(&mut self.network_request_stream).poll_next(cx)
    }
}
```

**File:** crates/channel/src/aptos_channel.rs (L165-186)
```rust
impl<K: Eq + Hash + Clone, M> Stream for Receiver<K, M> {
    type Item = M;

    /// poll_next checks whether there is something ready for consumption from the internal
    /// queue. If there is, then it returns immediately. If the internal_queue is empty,
    /// it sets the waker passed to it by the scheduler/executor and returns Pending
    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        let mut shared_state = self.shared_state.lock();
        if let Some((val, status_ch)) = shared_state.internal_queue.pop() {
            if let Some(status_ch) = status_ch {
                let _err = status_ch.send(ElementStatus::Dequeued);
            }
            Poll::Ready(Some(val))
        // all senders have been dropped (and so the stream is terminated)
        } else if shared_state.num_senders == 0 {
            shared_state.stream_terminated = true;
            Poll::Ready(None)
        } else {
            shared_state.waker = Some(cx.waker().clone());
            Poll::Pending
        }
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L232-260)
```rust
    pub async fn start(mut self) {
        // Start listening for connections.
        info!(
            NetworkSchema::new(&self.network_context),
            "Start listening for incoming connections on {}", self.listen_addr
        );
        self.start_connection_listener();
        loop {
            ::futures::select! {
                connection_event = self.transport_notifs_rx.select_next_some() => {
                    self.handle_connection_event(connection_event);
                }
                connection_request = self.connection_reqs_rx.select_next_some() => {
                    self.handle_outbound_connection_request(connection_request).await;
                }
                request = self.requests_rx.select_next_some() => {
                    self.handle_outbound_request(request).await;
                }
                complete => {
                    break;
                }
            }
        }

        warn!(
            NetworkSchema::new(&self.network_context),
            "PeerManager actor terminated"
        );
    }
```

**File:** aptos-node/src/state_sync.rs (L266-293)
```rust
fn setup_state_sync_storage_service(
    config: StateSyncConfig,
    peers_and_metadata: Arc<PeersAndMetadata>,
    network_service_events: NetworkServiceEvents<StorageServiceMessage>,
    db_rw: &DbReaderWriter,
    storage_service_listener: StorageServiceNotificationListener,
) -> anyhow::Result<Runtime> {
    // Create a new state sync storage service runtime
    let storage_service_runtime = aptos_runtimes::spawn_named_runtime("stor-server".into(), None);

    // Spawn the state sync storage service servers on the runtime
    let storage_reader = StorageReader::new(
        config.storage_service,
        Arc::clone(&db_rw.reader),
        TimeService::real(),
    );
    let service = StorageServiceServer::new(
        config,
        storage_service_runtime.handle().clone(),
        storage_reader,
        TimeService::real(),
        peers_and_metadata,
        StorageServiceNetworkEvents::new(network_service_events),
        storage_service_listener,
    );
    storage_service_runtime.spawn(service.start());

    Ok(storage_service_runtime)
```
