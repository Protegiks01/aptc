# Audit Report

## Title
Silent Backup Corruption via Unvalidated Stream Truncation in Transaction Proof Backup

## Summary
The `write_chunk()` function in the transaction backup system uses `tokio::io::copy()` to stream cryptographic proofs from the backup service without validating the number of bytes received. If the HTTP stream terminates prematurely due to network failure, server crash, or malicious truncation, partial BCS-serialized proofs are silently written to backup storage. These corrupted backups appear successful but fail during restoration, potentially causing permanent data loss during disaster recovery scenarios.

## Finding Description

The vulnerability exists in the transaction backup flow where cryptographic proofs are copied from an HTTP stream to backup storage: [1](#0-0) 

At lines 163-171, `tokio::io::copy()` streams proof data without validating completeness. The backup service returns BCS-serialized `(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)` tuples: [2](#0-1) 

The HTTP client converts responses to byte streams without preserving Content-Length validation: [3](#0-2) 

At line 69, `.bytes_stream()` discards the Content-Length header, making size validation impossible. When the connection closes cleanly (TCP FIN), `tokio::io::copy()` returns `Ok(bytes_copied)` without error, even if fewer bytes than expected were received.

**Attack Path:**

1. **Backup Initiation**: Operator runs transaction backup via `TransactionBackupController`
2. **Proof Request**: Client requests proof via `get_transaction_range_proof()`
3. **Stream Interruption**: HTTP connection closes prematurely due to:
   - Backup service crash/restart during proof generation
   - Network proxy timeout
   - Load balancer connection limit
   - Malicious insider truncating responses
   - Resource exhaustion on backup server
4. **Silent Truncation**: `tokio::io::copy()` writes partial BCS data and returns success
5. **False Success**: Backup completes with exit code 0, operator believes backup is valid
6. **Delayed Failure**: During restore, `load_bcs_file()` attempts deserialization: [4](#0-3) 

At line 148, `load_bcs_file()` calls `bcs::from_bytes()` on the truncated data: [5](#0-4) 

BCS deserialization fails with "unexpected EOF" error, causing restore failure when the backup is critically needed.

**Invariant Violations:**

1. **State Consistency**: Backups are fundamental to state recovery; corrupted backups violate the guarantee that historical state can be reconstructed
2. **Backup Integrity**: The system assumes backup operations either fully succeed or explicitly fail, never silently produce corrupted outputs
3. **Disaster Recovery**: The inability to restore from backups during disasters violates availability guarantees

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos Bug Bounty)

This vulnerability qualifies as **High severity** because:

1. **Significant Protocol Violation**: Backup integrity is a critical operational requirement. Silent corruption violates the fundamental assumption that successful backup operations produce valid data.

2. **Availability Impact**: While not immediate, discovering corrupted backups during disaster recovery could result in:
   - Extended network downtime if no valid backups exist
   - Data loss if all recent backups are corrupted
   - Requires manual intervention to identify last valid backup

3. **Silent Failure Mode**: The most dangerous aspect is that operators receive success confirmation for failed operations. Traditional monitoring (exit codes, logs) won't detect the corruption until restore is attempted.

4. **Cascading Risk**: In production environments where automated backup systems run continuously, this bug could corrupt multiple consecutive backups before detection, leaving no valid recovery point.

While this doesn't reach Critical severity (no immediate funds loss or consensus violation), it represents a significant operational security risk that could escalate to Critical impact if it leads to unrecoverable data loss during an actual disaster.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to manifest in real-world deployments because:

1. **Common Triggers**:
   - Network instability is common in distributed systems
   - Backup services are often restarted for maintenance
   - Load balancers and proxies routinely timeout long-running connections
   - Resource limits (memory, disk) can cause premature termination

2. **No Defensive Mechanisms**: The code has zero validation layers:
   - No Content-Length checking
   - No byte count validation
   - No checksum verification
   - No post-write validation

3. **Long Backup Windows**: Transaction backups can transfer large amounts of data over extended periods, increasing exposure to network failures

4. **Detection Delay**: Corruption won't be detected until restore attempts, which could be months after backup creation

5. **Malicious Exploitation**: An insider with network access could intentionally corrupt backups by manipulating the backup service or intercepting connections, creating a denial-of-service against future recovery operations.

## Recommendation

**Immediate Fix: Validate Bytes Copied**

Capture and validate the return value from `tokio::io::copy()`:

```rust
async fn write_chunk(
    &self,
    backup_handle: &BackupHandleRef,
    chunk_bytes: &[u8],
    first_version: u64,
    last_version: u64,
) -> Result<TransactionChunk> {
    let (proof_handle, mut proof_file) = self
        .storage
        .create_for_write(
            backup_handle,
            &Self::chunk_proof_name(first_version, last_version),
        )
        .await?;
    
    // Get expected proof size from server
    let mut proof_stream = self
        .client
        .get_transaction_range_proof(first_version, last_version)
        .await?;
    
    // Read all bytes to validate completeness
    let mut proof_bytes = Vec::new();
    proof_stream.read_to_end(&mut proof_bytes).await?;
    
    // Validate BCS deserialization succeeds before writing
    let _validated: (TransactionAccumulatorRangeProof, LedgerInfoWithSignatures) = 
        bcs::from_bytes(&proof_bytes)
            .map_err(|e| anyhow!("Proof deserialization failed during backup: {}", e))?;
    
    // Write validated proof
    proof_file.write_all(&proof_bytes).await?;
    proof_file.shutdown().await?;
    
    // ... rest of function
}
```

**Better Fix: Add Checksum Verification**

Modify the backup service to include SHA-256 checksums in response headers, and validate them client-side. This protects against both truncation and corruption.

**Complete Fix: Implement Content-Addressed Storage**

Use content hashing for all backup artifacts with verification during both backup and restore operations.

## Proof of Concept

```rust
// Mock test demonstrating the vulnerability
#[tokio::test]
async fn test_truncated_proof_silent_corruption() {
    // Setup: Create a mock backup service that returns truncated proof
    let mock_server = MockBackupService::new();
    
    // Server will serialize full proof but truncate response mid-stream
    let full_proof = (
        TransactionAccumulatorRangeProof::new(vec![]),
        LedgerInfoWithSignatures::new(
            LedgerInfo::new(BlockInfo::empty(), HashValue::zero()),
            AggregateSignature::empty(),
        ),
    );
    let full_bytes = bcs::to_bytes(&full_proof).unwrap();
    let truncated_bytes = &full_bytes[..full_bytes.len() / 2]; // Send only half
    
    mock_server.set_response(truncated_bytes.to_vec());
    
    // Action: Perform backup operation
    let backup_controller = TransactionBackupController::new(
        TransactionBackupOpt {
            start_version: 0,
            num_transactions: 100,
        },
        global_opt,
        Arc::new(mock_server.client()),
        storage.clone(),
    );
    
    // Assertion 1: Backup completes successfully (BUG!)
    let result = backup_controller.run().await;
    assert!(result.is_ok(), "Backup should succeed even with truncated proof");
    
    // Assertion 2: Restore fails with deserialization error
    let restore_controller = TransactionRestoreController::new(
        restore_opt,
        global_restore_opt,
        storage.clone(),
        None,
        VerifyExecutionMode::NoVerify,
    );
    
    let restore_result = restore_controller.run().await;
    assert!(restore_result.is_err(), "Restore must fail");
    assert!(
        restore_result.unwrap_err().to_string().contains("unexpected eof") 
        || restore_result.unwrap_err().to_string().contains("deserialization"),
        "Error should indicate truncated/corrupted proof"
    );
}
```

This PoC demonstrates that:
1. Backup operations succeed despite receiving truncated proofs
2. Corruption is only detected during restore via BCS deserialization errors
3. The window between backup and restore allows silent corruption to persist undetected

**Notes**

The same vulnerability pattern exists in state snapshot backups [6](#0-5) , suggesting this is a systemic issue in the backup infrastructure requiring a comprehensive fix across all backup types.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L149-187)
```rust
    async fn write_chunk(
        &self,
        backup_handle: &BackupHandleRef,
        chunk_bytes: &[u8],
        first_version: u64,
        last_version: u64,
    ) -> Result<TransactionChunk> {
        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(
                backup_handle,
                &Self::chunk_proof_name(first_version, last_version),
            )
            .await?;
        tokio::io::copy(
            &mut self
                .client
                .get_transaction_range_proof(first_version, last_version)
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;

        let (chunk_handle, mut chunk_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_name(first_version))
            .await?;
        chunk_file.write_all(chunk_bytes).await?;
        chunk_file.shutdown().await?;

        Ok(TransactionChunk {
            first_version,
            last_version,
            transactions: chunk_handle,
            proof: proof_handle,
            format: TransactionChunkFormat::V1,
        })
    }
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L112-122)
```rust
    // GET transaction_range_proof/<first_version>/<last_version>
    let bh = backup_handler;
    let transaction_range_proof = warp::path!(Version / Version)
        .map(move |first_version, last_version| {
            reply_with_bcs_bytes(
                TRANSACTION_RANGE_PROOF,
                &bh.get_transaction_range_proof(first_version, last_version)?,
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);
```

**File:** storage/backup/backup-cli/src/utils/backup_service_client.rs (L55-84)
```rust
    async fn get(&self, endpoint: &'static str, params: &str) -> Result<impl AsyncRead + use<>> {
        let _timer = BACKUP_TIMER.timer_with(&[&format!("backup_service_client_get_{endpoint}")]);

        let url = if params.is_empty() {
            format!("{}/{}", self.address, endpoint)
        } else {
            format!("{}/{}/{}", self.address, endpoint, params)
        };
        let timeout = Duration::from_secs(Self::TIMEOUT_SECS);
        let reader = tokio::time::timeout(timeout, self.client.get(&url).send())
            .await?
            .err_notes(&url)?
            .error_for_status()
            .err_notes(&url)?
            .bytes_stream()
            .map_ok(|bytes| {
                THROUGHPUT_COUNTER.inc_with_by(&[endpoint], bytes.len() as u64);
                bytes
            })
            .map_err(futures::io::Error::other)
            .into_async_read()
            .compat();

        // Adding the timeout here instead of on the response because we do use long living
        // connections. For example, we stream the entire state snapshot in one request.
        let mut reader_with_read_timeout = TimeoutReader::new(reader);
        reader_with_read_timeout.set_timeout(Some(timeout));

        Ok(Box::pin(reader_with_read_timeout))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L147-154)
```rust
        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }
```

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L31-33)
```rust
    async fn load_bcs_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
        Ok(bcs::from_bytes(&self.read_all(file_handle).await?)?)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L429-437)
```rust
        tokio::io::copy(
            &mut self
                .client
                .get_account_range_proof(last_key, self.version())
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;
```
