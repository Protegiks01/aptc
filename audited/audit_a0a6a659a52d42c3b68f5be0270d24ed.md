# Audit Report

## Title
Indexer gRPC Gateway Lacks Response Integrity Verification Against Compromised Upstream Services

## Summary
The indexer-grpc-gateway blindly forwards responses from upstream data services without any cryptographic integrity checks. A compromised upstream service can return arbitrarily tampered transaction data, and the gateway has no mechanism to detect or prevent this attack, exposing all downstream clients to potentially falsified blockchain data.

## Finding Description

The indexer-grpc-gateway acts as a reverse proxy that routes client requests to appropriate data services based on routing logic provided by a gRPC manager. The core vulnerability exists in the `proxy` function which forwards responses without any integrity verification. [1](#0-0) 

The gateway's request flow is:
1. Client sends `GetTransactionsRequest` to gateway
2. Gateway queries the gRPC manager for an upstream data service address
3. Gateway receives a data service URL from the manager
4. Gateway forwards the request to that upstream service
5. Gateway receives the response and **directly forwards it to the client without any validation** [2](#0-1) 

The security issue is that while transaction data includes integrity fields like `accumulator_root_hash`, `state_change_hash`, `event_root_hash`, and transaction `hash`: [3](#0-2) 

The protocol does **not** include accumulator proofs or LedgerInfo signatures that would allow cryptographic verification of this data. The Aptos blockchain has built-in mechanisms for cryptographic verification through `AccumulatorProof::verify()`: [4](#0-3) 

However, these proofs are not included in the indexer-grpc protocol: [5](#0-4) 

**Attack Scenario:**
1. Attacker compromises one of the upstream data services (through software vulnerability, supply chain attack, or insider threat)
2. Compromised service returns fabricated `TransactionsResponse` with:
   - Modified transaction data
   - Fake but plausible hashes (accumulator_root_hash, state_change_hash, etc.)
   - Altered amounts, addresses, or smart contract execution results
3. Gateway forwards this tampered data to clients without verification
4. Clients (indexers, explorers, dApps) consume the falsified data and make incorrect decisions

This breaks the **State Consistency** invariant - data served through the indexer should be verifiable against the canonical blockchain state, but there's no mechanism to ensure this.

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos bug bounty program criteria:
- **Significant protocol violation**: The indexer gateway fails to maintain data integrity guarantees
- **API integrity compromise**: Applications relying on the indexer API receive potentially falsified data
- **Cascading impact**: Downstream systems (block explorers, analytics platforms, dApps) may display incorrect information or execute incorrect logic

While this doesn't directly compromise consensus or validator operations, it affects the entire ecosystem of applications that rely on indexer data for:
- Transaction history queries
- Account balance tracking
- Smart contract event monitoring
- Analytics and reporting

The impact is amplified because the gateway serves as a trust anchor for many downstream consumers who assume data from official Aptos infrastructure is authentic.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attack Prerequisites:**
- Compromise of at least one data service in the pool
- Data services are not validators, so they have lower security requirements than consensus nodes
- Multiple attack vectors exist: software vulnerabilities, supply chain attacks, compromised credentials, insider threats

**Factors Increasing Likelihood:**
- Data services are separate processes that could be compromised independently
- No cryptographic binding between responses and blockchain state
- Gateway automatically trusts any response from registered services
- Silent failures - no alerts when serving potentially tampered data

**Factors Decreasing Likelihood:**
- Data services are operated by trusted entities (Aptos Foundation/ecosystem)
- Services are monitored via heartbeat mechanisms
- Requires sustained compromise to avoid detection through cross-validation

However, defense-in-depth principles dictate that even trusted components should have integrity verification, especially for blockchain data where cryptographic proofs are standard practice.

## Recommendation

**Immediate Mitigation:**
Implement response integrity verification in the gateway using one of these approaches:

**Option 1: Add Accumulator Proofs to Protocol (Preferred)**
1. Extend the protocol to include `AccumulatorProof` with each transaction batch
2. Gateway verifies proofs against a trusted `LedgerInfo` root hash
3. Reject responses that fail verification

Protocol changes needed:
```protobuf
message TransactionsResponse {
  repeated aptos.transaction.v1.Transaction transactions = 1;
  optional uint64 chain_id = 2 [jstype = JS_STRING];
  optional ProcessedRange processed_range = 3;
  
  // NEW: Add accumulator proof for verification
  repeated bytes accumulator_proof_siblings = 4;
  bytes ledger_info_hash = 5;
}
```

Gateway verification logic:
```rust
async fn proxy(
    data_service_url: Extension<Url>,
    mut request: Request,
) -> Result<Response, (StatusCode, String)> {
    // ... existing code ...
    
    let response = Client::builder(TokioExecutor::new())
        .http2_only(true)
        .build_http()
        .request(request)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;
    
    // NEW: Verify response integrity before forwarding
    verify_response_integrity(&response)?;
    
    Ok(Response::from_parts(parts, axum::body::Body::new(body)))
}

fn verify_response_integrity(response: &Response) -> Result<(), (StatusCode, String)> {
    // Parse response, extract transactions and proof
    // Verify accumulator proof against trusted root
    // Return error if verification fails
}
```

**Option 2: Cross-Validation Against Full Node**
Gateway periodically queries a trusted full node API to validate accumulator root hashes received from data services, rejecting responses that don't match.

**Option 3: Client-Side Verification**
Document that clients MUST verify data integrity themselves by:
- Querying multiple independent data sources
- Verifying transaction hashes against a trusted full node
- Using the REST API to cross-validate critical data

This is less secure as it shifts responsibility to clients, but is a short-term mitigation.

**Long-term Solution:**
Redesign the indexer architecture to include cryptographic proofs at every layer, similar to light client protocols. This ensures end-to-end verifiability from blockchain to client.

## Proof of Concept

```rust
// Mock compromised data service that returns tampered data
use aptos_protos::indexer::v1::{TransactionsResponse, raw_data_server::RawData};
use aptos_protos::transaction::v1::Transaction;
use tonic::{Request, Response, Status};
use futures::Stream;
use std::pin::Pin;

pub struct MaliciousDataService;

#[tonic::async_trait]
impl RawData for MaliciousDataService {
    type GetTransactionsStream = Pin<Box<dyn Stream<Item = Result<TransactionsResponse, Status>> + Send>>;
    
    async fn get_transactions(
        &self,
        request: Request<GetTransactionsRequest>,
    ) -> Result<Response<Self::GetTransactionsStream>, Status> {
        // Return fabricated transactions with fake hashes
        let tampered_response = TransactionsResponse {
            transactions: vec![create_fake_transaction()],
            chain_id: Some(1), // Mainnet chain ID
            processed_range: Some(ProcessedRange {
                first_version: 1000000,
                last_version: 1000000,
            }),
        };
        
        // Gateway will forward this without any verification!
        let stream = futures::stream::once(async { Ok(tampered_response) });
        Ok(Response::new(Box::pin(stream)))
    }
}

fn create_fake_transaction() -> Transaction {
    // Fabricate transaction with plausible but fake hashes
    Transaction {
        version: 1000000,
        info: Some(TransactionInfo {
            hash: vec![0xDE, 0xAD, 0xBE, 0xEF; 32], // Fake hash
            accumulator_root_hash: vec![0xFA, 0xKE; 32], // Fake root
            // ... other fake fields
        }),
        // ... rest of fake transaction data
    }
}

// Test demonstrating the vulnerability
#[tokio::test]
async fn test_gateway_accepts_tampered_response() {
    // 1. Start malicious data service
    let malicious_service = MaliciousDataService;
    
    // 2. Configure gateway to use this service
    // (In real scenario, this would be after compromising a legitimate service)
    
    // 3. Send request through gateway
    let client = create_gateway_client();
    let response = client.get_transactions(GetTransactionsRequest {
        starting_version: Some(1000000),
        transactions_count: Some(1),
        batch_size: None,
        transaction_filter: None,
    }).await.unwrap();
    
    // 4. Gateway forwards tampered data without detection
    let transactions = response.into_inner().transactions;
    assert_eq!(transactions[0].info.unwrap().hash, vec![0xDE, 0xAD, 0xBE, 0xEF; 32]);
    
    // âœ— No integrity check prevented this tampered data from reaching clients!
}
```

## Notes

This vulnerability is particularly concerning because:

1. **Trust Assumption Violation**: The gateway acts as a trusted proxy but doesn't validate that trust cryptographically

2. **Missing Defense Layer**: Even if upstream services are generally trusted, defense-in-depth requires verification, especially for blockchain data where cryptographic proofs are the standard

3. **Silent Failures**: There's no alerting or detection mechanism when potentially tampered data passes through

4. **Ecosystem Impact**: Many downstream applications (explorers, analytics platforms, dApps) depend on indexer data and assume its authenticity

The fix requires protocol changes to include accumulator proofs or LedgerInfo signatures, similar to how Aptos full nodes verify state through Merkle proofs and quorum certificates. Without this, the indexer gateway represents a centralized point of failure in an otherwise trustless system.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-gateway/src/gateway.rs (L92-153)
```rust
async fn get_data_service_url(
    State(config): State<Arc<IndexerGrpcGatewayConfig>>,
    req: Request,
    next: Next,
) -> Result<Response, (StatusCode, String)> {
    let request_compression_encoding: Option<CompressionEncoding> = req
        .headers()
        .get(ENCODING_HEADER)
        .and_then(|encoding_header| {
            encoding_header
                .to_str()
                .ok()
                .map(|encoding_str| match encoding_str {
                    "gzip" => Some(CompressionEncoding::Gzip),
                    "zstd" => Some(CompressionEncoding::Zstd),
                    _ => None,
                })
        })
        .flatten();

    let (head, mut body) = req.into_parts();

    let mut user_request = None;
    if head.uri.path() == "/aptos.indexer.v1.RawData/GetTransactions" {
        let body_bytes = body
            .collect()
            .await
            .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?
            .to_bytes();
        body = body_bytes.clone().into();
        let stream = Streaming::<GetTransactionsRequest>::new_request(
            <ProstCodec<GetTransactionsRequest, GetTransactionsRequest> as Codec>::decoder(
                &mut tonic::codec::ProstCodec::<GetTransactionsRequest, GetTransactionsRequest>::default(),
            ),
            Full::new(body_bytes),
            request_compression_encoding,
            None,
        );

        tokio::pin!(stream);

        if let Ok(Some(request)) = stream.try_next().await {
            user_request = Some(request);
        }
    }

    let mut client = GrpcManagerClient::connect(config.grpc_manager_address.to_string())
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;
    let grpc_manager_request =
        tonic::Request::new(GetDataServiceForRequestRequest { user_request });
    let response: GetDataServiceForRequestResponse = client
        .get_data_service_for_request(grpc_manager_request)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?
        .into_inner();

    let url = Url::from_str(&response.data_service_address).unwrap();
    let mut req = Request::from_parts(head, body);
    req.extensions_mut().insert(url);
    Ok(next.run(req).await)
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-gateway/src/gateway.rs (L155-176)
```rust
async fn proxy(
    data_service_url: Extension<Url>,
    mut request: Request,
) -> Result<Response, (StatusCode, String)> {
    info!(
        data_service_url = data_service_url.as_str(),
        "Proxying request to data service: {}",
        data_service_url.as_str()
    );
    *request.uri_mut() = override_uri_with_upstream_url(request.uri(), &data_service_url)?;

    Client::builder(TokioExecutor::new())
        .http2_only(true)
        .build_http()
        .request(request)
        .await
        .map(|res| {
            let (parts, body) = res.into_parts();
            Response::from_parts(parts, axum::body::Body::new(body))
        })
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/convert.rs (L570-586)
```rust
pub fn convert_transaction_info(
    transaction_info: &TransactionInfo,
) -> transaction::TransactionInfo {
    transaction::TransactionInfo {
        hash: transaction_info.hash.0.to_vec(),
        state_checkpoint_hash: transaction_info
            .state_checkpoint_hash
            .map(|hash| hash.0.to_vec()),
        state_change_hash: transaction_info.state_change_hash.0.to_vec(),
        event_root_hash: transaction_info.event_root_hash.0.to_vec(),
        gas_used: transaction_info.gas_used.0,
        success: transaction_info.success,
        vm_status: transaction_info.vm_status.to_string(),
        accumulator_root_hash: transaction_info.accumulator_root_hash.0.to_vec(),
        changes: convert_write_set_changes(&transaction_info.changes),
    }
}
```

**File:** types/src/proof/definition.rs (L68-100)
```rust
    pub fn verify(
        &self,
        expected_root_hash: HashValue,
        element_hash: HashValue,
        element_index: u64,
    ) -> Result<()> {
        ensure!(
            self.siblings.len() <= MAX_ACCUMULATOR_PROOF_DEPTH,
            "Accumulator proof has more than {} ({}) siblings.",
            MAX_ACCUMULATOR_PROOF_DEPTH,
            self.siblings.len()
        );

        let actual_root_hash = self
            .siblings
            .iter()
            .fold(
                (element_hash, element_index),
                // `index` denotes the index of the ancestor of the element at the current level.
                |(hash, index), sibling_hash| {
                    (
                        if index % 2 == 0 {
                            // the current node is a left child.
                            MerkleTreeInternalNode::<H>::new(hash, *sibling_hash).hash()
                        } else {
                            // the current node is a right child.
                            MerkleTreeInternalNode::<H>::new(*sibling_hash, hash).hash()
                        },
                        // The index of the parent at its level.
                        index / 2,
                    )
                },
            )
```

**File:** protos/proto/aptos/indexer/v1/raw_data.proto (L40-49)
```text
// TransactionsResponse is a batch of transactions.
message TransactionsResponse {
  // Required; transactions data.
  repeated aptos.transaction.v1.Transaction transactions = 1;

  // Required; chain id.
  optional uint64 chain_id = 2 [jstype = JS_STRING];

  optional ProcessedRange processed_range = 3;
}
```
