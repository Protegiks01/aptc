# Audit Report

## Title
Silent Gap Handling in Indexer Allows Permanent Transaction Data Loss

## Summary
The Aptos indexer's parallel batch processing system can silently skip transaction versions when updating the database checkpoint, leading to permanent data loss. The system tracks only the maximum processed version without validating that all intermediate versions were successfully processed, and the existing gap detection function is never invoked during normal operation.

## Finding Description

The indexer processes transactions in parallel batches but fails to validate version continuity before updating the database checkpoint. This breaks the fundamental indexer invariant that all transactions must be indexed without gaps.

**The Critical Flow:**

In the main indexing loop, multiple parallel tasks fetch and process transaction batches: [1](#0-0) 

These tasks independently call `process_next_batch()`, which fetches transactions from a shared channel without coordination: [2](#0-1) 

After all tasks complete, the runtime only tracks the minimum and maximum versions processed: [3](#0-2) 

Then it updates the database with only the maximum version: [4](#0-3) 

The `update_last_processed_version` function blindly updates the checkpoint: [5](#0-4) 

**The False Security Assumption:**

The code contains a misleading comment claiming gaps would cause panics: [6](#0-5) 

However, there is NO validation code that enforces this assumption.

**Unused Gap Detection:**

A gap detection function exists but is never called: [7](#0-6) 

The configuration even provides a `gap_lookback_versions` parameter: [8](#0-7) 

But the runtime only calls the simpler `get_start_version` which returns `last_success_version + 1` without gap checking: [9](#0-8) [10](#0-9) 

**Attack Scenario:**

1. Fetcher sends batch A [versions 100-109] to channel
2. Fetcher encounters error/delay for batch B [versions 110-119]
3. Fetcher sends batch C [versions 120-129] to channel
4. Task 1 processes batch A successfully
5. Task 2 gets empty result (channel temporarily empty)
6. Task 3 processes batch C successfully
7. Runtime computes: `batch_start_version = 100`, `batch_end_version = 129`
8. Database updated: `last_success_version = 129`
9. **Versions 110-119 permanently skipped** - indexer will never reprocess them

## Impact Explanation

**Severity: Medium to High**

This vulnerability causes **permanent data loss** in the indexer, which serves as the primary data source for:
- Block explorers showing transaction history
- dApps querying historical on-chain events
- Analytics platforms tracking chain statistics
- Audit systems verifying transaction execution

Once a gap occurs, the affected transactions are permanently invisible to all indexer consumers. The indexer continues from the checkpoint thinking all prior versions were processed, making this a silent failure with no recovery mechanism in normal operation.

This meets **Medium Severity** criteria: "State inconsistencies requiring intervention" - the only recovery would require manual database intervention and re-indexing from before the gap.

If this impacts critical transactions (governance proposals, validator rewards, token transfers), the impact escalates toward **High Severity**.

## Likelihood Explanation

**Likelihood: Medium**

This vulnerability can be triggered by:

1. **Fetcher bugs**: Any bug in the transaction fetcher that causes non-contiguous batches
2. **Network issues**: Temporary connection losses causing missing transaction batches  
3. **Race conditions**: The parallel processing architecture creates timing windows for gaps
4. **Node synchronization issues**: If the backing node provides inconsistent data
5. **Database connection issues**: Partial write failures during batch processing

The parallel processing design (3-5 concurrent tasks by default) increases the probability of timing-related gaps. The fact that gap detection infrastructure exists but is unused suggests this was a known risk that wasn't properly mitigated.

## Recommendation

**Implement mandatory gap validation before checkpoint updates:**

```rust
// In runtime.rs, after collecting batch results (around line 249):

// Validate no gaps exist in processed versions
if batch_start_version != u64::MAX && batch_end_version != 0 {
    let expected_txn_count = batch_end_version - batch_start_version + 1;
    if num_res != expected_txn_count {
        panic!(
            "Gap detected! Expected {} transactions from {} to {}, but only processed {}",
            expected_txn_count, batch_start_version, batch_end_version, num_res
        );
    }
}
```

**Additionally, use the gap detection on startup:**

```rust
// In runtime.rs, replace get_start_version with get_start_version_long (around line 163):

let starting_version_from_db = tailer
    .get_start_version_long(&processor_name, lookback_versions)
    .unwrap_or_else(|| {
        info!(
            processor_name = processor_name,
            "No starting version from db so starting from version 0"
        );
        0
    }) as u64;
```

This ensures any existing gaps are detected and filled during indexer restart.

## Proof of Concept

```rust
// Create a test demonstrating the gap vulnerability
// File: crates/indexer/src/runtime_test.rs

#[tokio::test]
async fn test_gap_in_parallel_processing() {
    // Setup: Create mock fetcher that returns non-contiguous batches
    // Batch 1: versions [100-109]
    // Batch 2: empty (simulating fetch failure)  
    // Batch 3: versions [120-129]
    
    // Execute: Run parallel processing with 3 tasks
    // Each task fetches from the channel
    
    // Verify: 
    // 1. batch_start_version = 100
    // 2. batch_end_version = 129
    // 3. Database last_success_version = 129
    // 4. Query for version 115 returns None (gap exists!)
    
    // Expected: Should panic/error, but currently succeeds
    // Actual: Silently skips versions 110-119
}
```

## Notes

The existence of unused gap detection infrastructure (`get_start_version_long` and `gap_lookback_versions` config) indicates this was a recognized risk during development. However, the mitigation was never properly integrated into the runtime, leaving the indexer vulnerable to permanent data loss through silent gap introduction.

The vulnerability is particularly concerning because:
1. It's a **silent failure** - no errors logged when gaps occur
2. Recovery requires **manual intervention** - re-indexing from before the gap
3. The **false security comment** misleads developers into assuming gaps are handled
4. The **parallel architecture** makes gaps more likely during network/system issues

This should be treated as a high-priority fix given the indexer's critical role in the Aptos ecosystem.

### Citations

**File:** crates/indexer/src/runtime.rs (L163-172)
```rust
    let starting_version_from_db_short = tailer
        .get_start_version(&processor_name)
        .unwrap_or_else(|e| panic!("Failed to get starting version: {:?}", e))
        .unwrap_or_else(|| {
            info!(
                processor_name = processor_name,
                "No starting version from db so starting from version 0"
            );
            0
        }) as u64;
```

**File:** crates/indexer/src/runtime.rs (L210-219)
```rust
        let mut tasks = vec![];
        for _ in 0..processor_tasks {
            let other_tailer = tailer.clone();
            let task = tokio::spawn(async move { other_tailer.process_next_batch().await });
            tasks.push(task);
        }
        let batches = match futures::future::try_join_all(tasks).await {
            Ok(res) => res,
            Err(err) => panic!("Error processing transaction batches: {:?}", err),
        };
```

**File:** crates/indexer/src/runtime.rs (L245-248)
```rust
            batch_start_version =
                std::cmp::min(batch_start_version, processed_result.start_version);
            batch_end_version = std::cmp::max(batch_end_version, processed_result.end_version);
            num_res += num_txn;
```

**File:** crates/indexer/src/runtime.rs (L251-261)
```rust
        tailer
            .update_last_processed_version(&processor_name, batch_end_version)
            .unwrap_or_else(|e| {
                error!(
                    processor_name = processor_name,
                    end_version = batch_end_version,
                    error = format!("{:?}", e),
                    "Failed to update last processed version!"
                );
                panic!("Failed to update last processed version: {:?}", e);
            });
```

**File:** crates/indexer/src/indexer/tailer.rs (L120-166)
```rust
    pub async fn process_next_batch(
        &self,
    ) -> (
        u64,
        Option<Result<ProcessingResult, TransactionProcessingError>>,
    ) {
        let transactions = self
            .transaction_fetcher
            .lock()
            .await
            .fetch_next_batch()
            .await;

        let num_txns = transactions.len() as u64;
        // When the batch is empty b/c we're caught up
        if num_txns == 0 {
            return (0, None);
        }
        let start_version = transactions.first().unwrap().version();
        let end_version = transactions.last().unwrap().version();

        debug!(
            num_txns = num_txns,
            start_version = start_version,
            end_version = end_version,
            "Starting processing of transaction batch"
        );

        let batch_start = chrono::Utc::now().naive_utc();

        let results = self
            .processor
            .process_transactions_with_status(transactions)
            .await;

        let batch_millis = (chrono::Utc::now().naive_utc() - batch_start).num_milliseconds();

        info!(
            num_txns = num_txns,
            time_millis = batch_millis,
            start_version = start_version,
            end_version = end_version,
            "Finished processing of transaction batch"
        );

        (num_txns, Some(results))
    }
```

**File:** crates/indexer/src/indexer/tailer.rs (L168-169)
```rust
    /// Store last processed version from database. We can assume that all previously processed
    /// versions are successful because any gap would cause the processor to panic
```

**File:** crates/indexer/src/indexer/tailer.rs (L170-191)
```rust
    pub fn update_last_processed_version(&self, processor_name: &str, version: u64) -> Result<()> {
        let mut conn = self.connection_pool.get()?;

        let status = ProcessorStatusV2 {
            processor: processor_name.to_owned(),
            last_success_version: version as i64,
        };
        execute_with_better_error(
            &mut conn,
            diesel::insert_into(processor_status::table)
                .values(&status)
                .on_conflict(processor_status::processor)
                .do_update()
                .set((
                    processor_status::last_success_version
                        .eq(excluded(processor_status::last_success_version)),
                    processor_status::last_updated.eq(excluded(processor_status::last_updated)),
                )),
            Some(" WHERE processor_status.last_success_version <= EXCLUDED.last_success_version "),
        )?;
        Ok(())
    }
```

**File:** crates/indexer/src/indexer/tailer.rs (L194-201)
```rust
    pub fn get_start_version(&self, processor_name: &String) -> Result<Option<i64>> {
        let mut conn = self.connection_pool.get()?;

        match ProcessorStatusV2Query::get_by_processor(processor_name, &mut conn)? {
            Some(status) => Ok(Some(status.last_success_version + 1)),
            None => Ok(None),
        }
    }
```

**File:** crates/indexer/src/indexer/tailer.rs (L205-288)
```rust
    pub fn get_start_version_long(
        &self,
        processor_name: &String,
        lookback_versions: i64,
    ) -> Option<i64> {
        let mut conn = self
            .connection_pool
            .get()
            .expect("DB connection should be available to get starting version");

        // This query gets the first version that isn't equal to the next version (versions would be sorted of course).
        // There's also special handling if the gap happens in the beginning.
        let sql = "
        WITH raw_boundaries AS
        (
            SELECT
                MAX(version) AS MAX_V,
                MIN(version) AS MIN_V
            FROM
                processor_statuses
            WHERE
                name = $1
                AND success = TRUE
        ),
        boundaries AS
        (
            SELECT
                MAX(version) AS MAX_V,
                MIN(version) AS MIN_V
            FROM
                processor_statuses, raw_boundaries
            WHERE
                name = $1
                AND success = true
                and version >= GREATEST(MAX_V - $2, 0)
        ),
        gap AS
        (
            SELECT
                MIN(version) + 1 AS maybe_gap
            FROM
                (
                    SELECT
                        version,
                        LEAD(version) OVER (
                    ORDER BY
                        version ASC) AS next_version
                    FROM
                        processor_statuses,
                        boundaries
                    WHERE
                        name = $1
                        AND success = TRUE
                        AND version >= GREATEST(MAX_V - $2, 0)
                ) a
            WHERE
                version + 1 <> next_version
        )
        SELECT
            CASE
                WHEN
                    MIN_V <> GREATEST(MAX_V - $2, 0)
                THEN
                    GREATEST(MAX_V - $2, 0)
                ELSE
                    COALESCE(maybe_gap, MAX_V + 1)
            END
            AS version
        FROM
            gap, boundaries
        ";
        #[derive(Debug, QueryableByName)]
        pub struct Gap {
            #[diesel(sql_type = BigInt)]
            pub version: i64,
        }
        let mut res: Vec<Option<Gap>> = sql_query(sql)
            .bind::<Text, _>(processor_name)
            // This is the number used to determine how far we look back for gaps. Increasing it may result in slower startup
            .bind::<BigInt, _>(lookback_versions)
            .get_results(&mut conn)
            .unwrap();
        res.pop().unwrap().map(|g| g.version)
    }
```

**File:** config/src/config/indexer_config.rs (L78-81)
```rust
    /// Indicates how many versions we should look back for gaps (default 1.5M versions, meaning
    /// we will only find gaps within MAX - 1.5M versions)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub gap_lookback_versions: Option<u64>,
```
