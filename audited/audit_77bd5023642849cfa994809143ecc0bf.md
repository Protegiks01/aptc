# Audit Report

## Title
Resource Leak in Secret Share Manager: QueueItems Accumulate Indefinitely When Secret Share Aggregation Fails

## Summary
The `SecretShareManager` maintains an unbounded queue of `QueueItem` structures that are never removed when secret share aggregation fails or cannot reach threshold. This causes unbounded memory growth and resource exhaustion on validator nodes during network stress or Byzantine behavior.

## Finding Description

The secret sharing consensus component maintains a `BlockQueue` that stores blocks pending secret share aggregation. Each `QueueItem` contains ordered blocks, associated `DropGuard` abort handles for spawned share requester tasks, and tracking for pending secret keys. [1](#0-0) 

When blocks arrive, the manager spawns background tasks to request shares from validators and stores these tasks' abort handles in the queue: [2](#0-1) 

These spawned tasks use `ReliableBroadcast.multicast()` which retries failed validators indefinitely with exponential backoff capped at a maximum delay: [3](#0-2) 

The consensus configuration sets the maximum retry delay to 10 seconds for randomness-related reliable broadcast: [4](#0-3) 

**Critical Issue**: Queue items are ONLY removed when blocks become "fully secret shared": [5](#0-4) 

A block is considered fully secret shared only when all its pending secret key rounds are cleared: [6](#0-5) 

**Failure Scenarios Where Blocks Never Become Ready:**

1. **Insufficient shares**: When fewer than threshold validators respond (network partitions, offline validators, Byzantine withholding), aggregation never completes and tasks retry indefinitely.

2. **Aggregation errors**: Even with sufficient shares, cryptographic aggregation can fail. When this occurs, the error is logged but no `SecretSharedKey` is sent, leaving the block marked as pending: [7](#0-6) 

3. **Byzantine behavior**: Malicious validators (< 1/3) can deliberately withhold shares to prevent threshold from being reached.

**The Only Cleanup Mechanism** is `process_reset()` which replaces the entire queue, but only occurs during epoch transitions: [8](#0-7) 

**Resource Accumulation:**
- Each failed block adds a `QueueItem` to the unbounded queue
- Queue items hold references to `Arc<PipelinedBlock>` preventing block deallocation
- Queue items hold `DropGuard` objects that maintain abort handles
- Tasks in the insufficient shares scenario continue network retries indefinitely (capped at 10s intervals)
- Memory grows linearly with the number of failed blocks between epoch transitions
- No maximum queue size limit exists

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria under "Validator Node Slowdowns (High): DoS through resource exhaustion."

1. **Memory Exhaustion**: The unbounded queue grows with each failed aggregation, consuming validator node memory. Each `QueueItem` holds multiple `Arc<PipelinedBlock>` references along with metadata and abort handles.

2. **Validator Performance Degradation**: As memory consumption increases, validators experience:
   - Reduced responsiveness to consensus messages
   - Slower block processing due to memory pressure
   - Potential garbage collection overhead in the runtime

3. **Consensus Impact**: Degraded validator performance affects overall network health:
   - Increased block proposal latency
   - Reduced voting participation
   - Potential liveness issues if multiple validators are affected

4. **Attack Surface**: Byzantine validators (< 1/3 tolerated by the protocol) can deliberately trigger this by withholding shares, weaponizing the leak against honest validators.

5. **Cascading Effect**: As validators slow down from resource exhaustion, they may fail to respond to share requests from other validators, propagating the problem across the network.

The vulnerability violates resource management invariants by allowing unbounded accumulation of protocol state during normal consensus operation.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability is likely to manifest in production because:

1. **Natural Occurrence**: Network partitions, validator downtime, or high latency are expected conditions that prevent reaching aggregation threshold.

2. **Byzantine Tolerance Design**: The protocol is designed to tolerate up to 1/3 Byzantine validators, meaning share aggregation failures are operational scenarios the system must handle.

3. **No Timeout Protection**: Tasks retry indefinitely without any cleanup timeout. Even transient failures cause permanent queue growth until the next epoch transition.

4. **Cumulative Effect**: Each failed batch compounds the problem, and the impact grows over time during periods of network stress.

5. **Implementation Reality**: The cryptographic aggregation can legitimately fail (as evidenced by error handling code), and when it does, the block permanently occupies queue space.

6. **Low Attacker Barrier**: Byzantine validators within the tolerated threshold can trigger this deliberately with no additional capabilities required.

## Recommendation

Implement bounded queue management with timeout-based cleanup:

1. **Add Queue Size Limits**: Implement a maximum queue size and drop oldest items when exceeded.

2. **Task Timeout**: Add a maximum retry duration for share requester tasks. After timeout, mark the block as permanently failed and remove from queue.

3. **Periodic Cleanup**: Implement background cleanup that removes items stuck in the queue beyond a reasonable time threshold (e.g., 5 minutes).

4. **Aggregation Failure Handling**: When aggregation fails after receiving threshold shares, immediately mark the block as permanently failed and remove from queue rather than leaving it pending.

5. **Metrics and Monitoring**: Add queue size metrics to detect accumulation early.

Example conceptual fix for timeout-based cleanup:
```rust
// Add timeout tracking to QueueItem
struct QueueItem {
    ordered_blocks: OrderedBlocks,
    offsets_by_round: HashMap<Round, usize>,
    pending_secret_key_rounds: HashSet<Round>,
    share_requester_handles: Option<Vec<DropGuard>>,
    insertion_time: Instant, // NEW
}

// In main event loop, add periodic cleanup
_ = cleanup_interval.tick() => {
    let timeout_threshold = Duration::from_secs(300); // 5 minutes
    self.block_queue.remove_expired_items(timeout_threshold);
}
```

## Proof of Concept

Trigger scenario via network simulation:

1. Configure a local testnet with secret sharing enabled
2. Start validators but configure < threshold validators to respond to share requests
3. Propose blocks through consensus
4. Monitor `DEC_QUEUE_SIZE` metric over time - observe unbounded growth
5. Check validator memory consumption - observe steady increase
6. Blocks never dequeue until epoch transition despite multicast tasks retrying

The vulnerability is demonstrable through load testing where validators experience controlled network partitions or deliberately misconfigured share responses. Memory profiling will show `BlockQueue` growth proportional to failed blocks, with no cleanup between epoch transitions.

## Notes

This is a protocol-level resource management vulnerability, not a network DoS attack. It qualifies as HIGH severity under the "Validator Node Slowdowns" category via "DoS through resource exhaustion" - similar to the gas calculation bug example provided in the bounty criteria. The issue can be triggered by legitimate network conditions and exploited by Byzantine actors within the tolerated threshold, making it both naturally occurring and attackable.

### Citations

**File:** consensus/src/rand/secret_sharing/block_queue.rs (L16-22)
```rust
/// Maintain the ordered blocks received from consensus and corresponding secret shares
pub struct QueueItem {
    ordered_blocks: OrderedBlocks,
    offsets_by_round: HashMap<Round, usize>,
    pending_secret_key_rounds: HashSet<Round>,
    share_requester_handles: Option<Vec<DropGuard>>,
}
```

**File:** consensus/src/rand/secret_sharing/block_queue.rs (L60-77)
```rust
    pub fn is_fully_secret_shared(&self) -> bool {
        self.pending_secret_key_rounds.is_empty()
    }

    pub fn set_secret_shared_key(&mut self, round: Round, key: SecretSharedKey) {
        let offset = self.offset(round);
        if self.pending_secret_key_rounds.contains(&round) {
            observe_block(
                self.blocks()[offset].timestamp_usecs(),
                BlockStage::SECRET_SHARING_ADD_DECISION,
            );
            let block = &self.blocks_mut()[offset];
            if let Some(tx) = block.pipeline_tx().lock().as_mut() {
                tx.secret_shared_key_tx.take().map(|tx| tx.send(Some(key)));
            }
            self.pending_secret_key_rounds.remove(&round);
        }
    }
```

**File:** consensus/src/rand/secret_sharing/block_queue.rs (L112-127)
```rust
    pub fn dequeue_ready_prefix(&mut self) -> Vec<OrderedBlocks> {
        let mut ready_prefix = vec![];
        while let Some((_starting_round, item)) = self.queue.first_key_value() {
            if item.is_fully_secret_shared() {
                let (_, item) = self.queue.pop_first().expect("First key must exist");
                for block in item.blocks() {
                    observe_block(block.timestamp_usecs(), BlockStage::SECRET_SHARING_READY);
                }
                let QueueItem { ordered_blocks, .. } = item;
                ready_prefix.push(ordered_blocks);
            } else {
                break;
            }
        }
        ready_prefix
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L112-130)
```rust
    async fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
        let rounds: Vec<u64> = blocks.ordered_blocks.iter().map(|b| b.round()).collect();
        info!(rounds = rounds, "Processing incoming blocks.");

        let mut share_requester_handles = Vec::new();
        let mut pending_secret_key_rounds = HashSet::new();
        for block in blocks.ordered_blocks.iter() {
            let handle = self.process_incoming_block(block).await;
            share_requester_handles.push(handle);
            pending_secret_key_rounds.insert(block.round());
        }

        let queue_item = QueueItem::new(
            blocks,
            Some(share_requester_handles),
            pending_secret_key_rounds,
        );
        self.block_queue.push_back(queue_item);
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L172-184)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.secret_share_store
            .lock()
            .update_highest_known_round(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L167-205)
```rust
            loop {
                tokio::select! {
                    Some((receiver, result)) = rpc_futures.next() => {
                        let aggregating = aggregating.clone();
                        let future = executor.spawn(async move {
                            (
                                    receiver,
                                    result
                                        .and_then(|msg| {
                                            msg.try_into().map_err(|e| anyhow::anyhow!("{:?}", e))
                                        })
                                        .and_then(|ack| aggregating.add(receiver, ack)),
                            )
                        }).await;
                        aggregate_futures.push(future);
                    },
                    Some(result) = aggregate_futures.next() => {
                        let (receiver, result) = result.expect("spawned task must succeed");
                        match result {
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
                                }
                            },
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
                        }
                    },
                    else => unreachable!("Should aggregate with all responses")
                }
            }
```

**File:** config/src/config/consensus_config.rs (L373-378)
```rust
            rand_rb_config: ReliableBroadcastConfig {
                backoff_policy_base_ms: 2,
                backoff_policy_factor: 100,
                backoff_policy_max_delay_ms: 10000,
                rpc_timeout_ms: 10000,
            },
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L55-70)
```rust
        tokio::task::spawn_blocking(move || {
            let maybe_key = SecretShare::aggregate(self.shares.values(), &dec_config);
            match maybe_key {
                Ok(key) => {
                    let dec_key = SecretSharedKey::new(metadata, key);
                    let _ = decision_tx.unbounded_send(dec_key);
                },
                Err(e) => {
                    warn!(
                        epoch = metadata.epoch,
                        round = metadata.round,
                        "Aggregation error: {e}"
                    );
                },
            }
        });
```
