# Audit Report

## Title
Database Resource Leak: V2 Batches Never Deleted from Disk in Quorum Store

## Summary
The quorum store batch cleanup mechanism fails to delete V2 batches from the database, causing unbounded disk growth on validators running with `enable_batch_v2: true`. Two critical code paths incorrectly use V1 deletion methods (`delete_batches()`) when cleaning up V2 batches that should use `delete_batches_v2()`.

## Finding Description

The Aptos quorum store maintains two separate database column families for batch storage:
- `"batch"` (V1 format) using `BatchSchema`
- `"batch_v2"` (V2 format) using `BatchV2Schema`

When `enable_batch_v2: true` is configured, batches are saved to the V2 column family via `save_batch_v2()`. [1](#0-0) 

However, the cleanup mechanisms contain two critical bugs:

**Bug 1: Epoch Cleanup (Line 241)**

The function `gc_previous_epoch_batches_from_db_v2()` reads batches from the V2 column family but attempts to delete them using the V1 deletion method. [2](#0-1) 

This is a copy-paste error from the V1 cleanup function. [3](#0-2) 

**Bug 2: Expiration Cleanup (Line 536)**

The function `update_certified_timestamp()` cleans up expired batches from the cache and attempts to delete them from disk, but only calls the V1 deletion method regardless of batch version. [4](#0-3) 

**Backward Compatibility Analysis**

Regarding the original security question: There IS a backward compatibility mechanism at the network level. Both V1 and V2 batch messages are properly handled and converted to a unified format after verification. [5](#0-4) 

The network layer supports both message types through separate enum variants. [6](#0-5) 

During initialization, both V1 and V2 batches are loaded from their respective column families. [7](#0-6) 

**However**, the backward compatibility mechanism is INCOMPLETE because it fails at the cleanup stage, causing V2 batches to accumulate indefinitely.

## Impact Explanation

**Severity: Medium** (per Aptos bug bounty criteria: "State inconsistencies requiring intervention")

**Impact:**
- Unbounded database growth on validators with `enable_batch_v2: true`
- Progressive disk space exhaustion over time
- Eventually causes validator node failure when disk is full
- Requires manual intervention (database cleanup or node replacement)
- Does not immediately affect consensus safety but degrades network health

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The database grows without bound, violating storage limits.

**Affected Nodes:**
- Any validator running with `enable_batch_v2: true` in their quorum store configuration [8](#0-7) 
- Default configuration has this flag set to `false`, limiting immediate impact [9](#0-8) 

## Likelihood Explanation

**Likelihood: High** (for nodes with `enable_batch_v2: true`)

The vulnerability triggers automatically without attacker intervention:
1. Validator sets `enable_batch_v2: true` in configuration
2. Batches are created and saved via the V2 path during normal operation [10](#0-9) 
3. When batches expire or epochs change, cleanup functions execute
4. V2 batches remain in database indefinitely
5. Database grows continuously during consensus operation

The attack requires no special privileges - just a configuration change that may be deployed during protocol upgrades when the V2 format becomes standard.

## Recommendation

**Fix for Bug 1** - Change line 241 to use V2 deletion:
```rust
db.delete_batches_v2(expired_keys)
    .expect("Deletion of expired keys should not fail");
```

**Fix for Bug 2** - Modify `update_certified_timestamp()` to track and delete V2 batches separately. The function should:
1. Track which expired batches are V1 vs V2 during `clear_expired_payload()`
2. Call `delete_batches()` for V1 batches
3. Call `delete_batches_v2()` for V2 batches

Alternative: Store batch version information in the cache or use a unified deletion method that checks both column families.

## Proof of Concept

```rust
// Integration test demonstrating the resource leak
#[tokio::test]
async fn test_v2_batch_deletion_leak() {
    // Setup: Create QuorumStoreDB with both column families
    let db_path = TempPath::new();
    let db = QuorumStoreDB::new(&db_path);
    
    // Step 1: Save a V2 batch
    let batch_info_ext = BatchInfoExt::new_v2(
        PeerId::random(),
        BatchId::new_for_test(1),
        1, // epoch
        100000, // expiration
        HashValue::random(),
        10, // num_txns
        1000, // num_bytes
        0, // gas_bucket_start
        BatchKind::Normal,
    );
    let persisted = PersistedValue::new(batch_info_ext.clone(), None);
    db.save_batch_v2(persisted).expect("Save should succeed");
    
    // Step 2: Verify batch exists in V2 column family
    let all_v2 = db.get_all_batches_v2().unwrap();
    assert_eq!(all_v2.len(), 1);
    
    // Step 3: Simulate epoch cleanup (calls buggy function)
    let current_epoch = 2;
    BatchStore::gc_previous_epoch_batches_from_db_v2(Arc::new(db), current_epoch);
    
    // Step 4: Verify batch still exists (BUG - should be deleted!)
    let all_v2_after = db.get_all_batches_v2().unwrap();
    assert_eq!(all_v2_after.len(), 1, "V2 batch was not deleted due to bug!");
    
    // Expected: all_v2_after.len() should be 0
    // Actual: all_v2_after.len() is 1 (batch leaked)
}
```

## Notes

The database schema correctly defines separate storage paths for V1 and V2 batches. [11](#0-10) 

The trait interface provides both V1 and V2 deletion methods. [12](#0-11) 

The root cause is incomplete migration: the save/read paths were updated for V2, but cleanup paths were not. This is a common pattern in version migration bugs where new code paths are added but old cleanup logic is not updated to handle both versions.

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L156-176)
```rust
        if is_new_epoch {
            tokio::task::spawn_blocking(move || {
                Self::gc_previous_epoch_batches_from_db_v1(db_clone.clone(), epoch);
                Self::gc_previous_epoch_batches_from_db_v2(db_clone, epoch);
            });
        } else {
            Self::populate_cache_and_gc_expired_batches_v1(
                db_clone.clone(),
                epoch,
                last_certified_time,
                expiration_buffer_usecs,
                &batch_store,
            );
            Self::populate_cache_and_gc_expired_batches_v2(
                db_clone,
                epoch,
                last_certified_time,
                expiration_buffer_usecs,
                &batch_store,
            );
        }
```

**File:** consensus/src/quorum_store/batch_store.rs (L181-209)
```rust
    fn gc_previous_epoch_batches_from_db_v1(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db.get_all_batches().expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
```

**File:** consensus/src/quorum_store/batch_store.rs (L212-242)
```rust
    fn gc_previous_epoch_batches_from_db_v2(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
```

**File:** consensus/src/quorum_store/batch_store.rs (L509-512)
```rust
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-538)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
```

**File:** consensus/src/round_manager.rs (L166-183)
```rust
            UnverifiedEvent::BatchMsg(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(Box::new((*b).into()))
            },
            UnverifiedEvent::BatchMsgV2(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(b)
            },
```

**File:** consensus/src/network_interface.rs (L69-102)
```rust
    BatchMsg(Box<BatchMsg<BatchInfo>>),
    /// Quorum Store: Request the payloads of a completed batch.
    BatchRequestMsg(Box<BatchRequest>),
    /// Quorum Store: Response to the batch request.
    BatchResponse(Box<Batch<BatchInfo>>),
    /// Quorum Store: Send a signed batch digest. This is a vote for the batch and a promise that
    /// the batch of transactions was received and will be persisted until batch expiration.
    SignedBatchInfo(Box<SignedBatchInfoMsg<BatchInfo>>),
    /// Quorum Store: Broadcast a certified proof of store (a digest that received 2f+1 votes).
    ProofOfStoreMsg(Box<ProofOfStoreMsg<BatchInfo>>),
    /// DAG protocol message
    DAGMessage(DAGNetworkMessage),
    /// Commit message
    CommitMessage(Box<CommitMessage>),
    /// Randomness generation message
    RandGenMessage(RandGenMessage),
    /// Quorum Store: Response to the batch request.
    BatchResponseV2(Box<BatchResponse>),
    /// OrderVoteMsg is the struct that is broadcasted by a validator on receiving quorum certificate
    /// on a block.
    OrderVoteMsg(Box<OrderVoteMsg>),
    /// RoundTimeoutMsg is broadcasted by a validator once it decides to timeout the current round.
    RoundTimeoutMsg(Box<RoundTimeoutMsg>),
    /// RPC to get a chain of block of the given length starting from the given block id, using epoch and round.
    BlockRetrievalRequest(Box<BlockRetrievalRequest>),
    /// OptProposalMsg contains the optimistic proposal and sync info.
    OptProposalMsg(Box<OptProposalMsg>),
    /// Quorum Store: Send a Batch of transactions.
    BatchMsgV2(Box<BatchMsg<BatchInfoExt>>),
    /// Quorum Store: Send a signed batch digest with BatchInfoExt. This is a vote for the batch and a promise that
    /// the batch of transactions was received and will be persisted until batch expiration.
    SignedBatchInfoMsgV2(Box<SignedBatchInfoMsg<BatchInfoExt>>),
    /// Quorum Store: Broadcast a certified proof of store (a digest that received 2f+1 votes) with BatchInfoExt.
    ProofOfStoreMsgV2(Box<ProofOfStoreMsg<BatchInfoExt>>),
```

**File:** config/src/config/quorum_store_config.rs (L102-102)
```rust
    pub enable_batch_v2: bool,
```

**File:** config/src/config/quorum_store_config.rs (L144-144)
```rust
            enable_batch_v2: false,
```

**File:** consensus/src/quorum_store/batch_generator.rs (L190-211)
```rust
        if self.config.enable_batch_v2 {
            // TODO(ibalajiarun): Specify accurate batch kind
            let batch_kind = BatchKind::Normal;
            Batch::new_v2(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
                batch_kind,
            )
        } else {
            Batch::new_v1(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
            )
        }
```

**File:** consensus/src/quorum_store/schema.rs (L14-76)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";

#[derive(Debug)]
pub(crate) struct BatchSchema;

impl Schema for BatchSchema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfo>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_CF_NAME;
}

impl KeyCodec<BatchSchema> for HashValue {
    fn encode_key(&self) -> Result<Vec<u8>> {
        Ok(self.to_vec())
    }

    fn decode_key(data: &[u8]) -> Result<Self> {
        Ok(HashValue::from_slice(data)?)
    }
}

impl ValueCodec<BatchSchema> for PersistedValue<BatchInfo> {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

#[derive(Debug)]
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}

impl KeyCodec<BatchV2Schema> for HashValue {
    fn encode_key(&self) -> Result<Vec<u8>> {
        Ok(self.to_vec())
    }

    fn decode_key(data: &[u8]) -> Result<Self> {
        Ok(HashValue::from_slice(data)?)
    }
}

impl ValueCodec<BatchV2Schema> for PersistedValue<BatchInfoExt> {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L26-44)
```rust
pub trait QuorumStoreStorage: Sync + Send {
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError>;

    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>>;

    fn save_batch(&self, batch: PersistedValue<BatchInfo>) -> Result<(), DbError>;

    fn get_batch(&self, digest: &HashValue) -> Result<Option<PersistedValue<BatchInfo>>, DbError>;

    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError>;

    fn get_all_batches_v2(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfoExt>>>;

    fn save_batch_v2(&self, batch: PersistedValue<BatchInfoExt>) -> Result<(), DbError>;

    fn get_batch_v2(
        &self,
        digest: &HashValue,
    ) -> Result<Option<PersistedValue<BatchInfoExt>>, DbError>;
```
