# Audit Report

## Title
Critical Security Monitoring Gap: Execution Layer Security Events Missing from SecurityEvent Enum Prevents Detection of VM-Level Attacks

## Summary
The `SecurityEvent` enum in the logging system lacks coverage for execution layer security events, creating a critical blind spot in security monitoring. VM-level attacks including gas metering bypasses, parallel execution conflicts, resource safety violations, and bytecode verification failures are logged only as regular errors, not as `SecurityEvent` entries, preventing security monitoring systems from detecting Move VM exploits.

## Finding Description

The `SecurityEvent` enum [1](#0-0)  currently defines events only for:
- Mempool (invalid transactions, invalid network events)
- Consensus (invalid messages, equivocating votes, invalid proposals)
- State-Sync (invalid chunks)
- Health Checker (invalid network events/messages)
- Network (invalid messages, noise handshake failures)

**Critical execution layer security events are completely absent**, including:

1. **Gas Meter Invariant Violations**: When gas meter internal consistency checks fail during transaction cleanup, the code only uses `println!` to log the error [2](#0-1) , with no `SecurityEvent` entry. This allows gas metering bypass attempts to evade security monitoring.

2. **Parallel Execution Conflicts**: When excessive incarnation numbers indicate execution-invalidation cycles (potential livelock attacks), the system logs with `error!` but not as `SecurityEvent` [3](#0-2)  and [4](#0-3) . Attackers could exploit parallel execution vulnerabilities without triggering security alerts.

3. **Reference Safety Violations**: Runtime reference safety failures use `EREFERENCE_SAFETY_FAILURE` status codes [5](#0-4)  but are never logged as `SecurityEvent`, allowing resource safety exploits to bypass monitoring.

4. **UnmeteredGasMeter Misuse**: System transactions use `UnmeteredGasMeter` to bypass gas charging [6](#0-5) . If attackers find ways to trigger unmetered execution in non-system contexts, no `SecurityEvent` would detect it.

**Attack Scenario**: 
An attacker crafts a malicious Move transaction that:
- Triggers gas meter consistency violations to get free computation
- Causes excessive parallel execution conflicts to degrade performance
- Exploits reference safety bugs to corrupt memory

All these critical VM failures are logged only with `error!()` or `println!()` - security monitoring systems filtering for `SecurityEvent` entries would miss them entirely. The monitoring infrastructure [7](#0-6)  has no alerts for execution layer security events because they're not properly categorized.

## Impact Explanation

This is **Critical Severity** per Aptos bug bounty criteria because it enables:

1. **Consensus/Safety Violations**: Gas metering bypasses could allow attackers to execute expensive operations for free, causing validators to produce different state roots (breaking deterministic execution invariant), leading to consensus splits.

2. **Non-recoverable Network Partition**: If attackers exploit VM bugs that cause different validators to fail in different ways (some detecting violations, others not), it could create irreconcilable state divergence requiring hard fork.

3. **Loss of Detection Capability**: Security teams rely on `SecurityEvent` logs to detect attacks. Missing VM-level events means attacks on the execution layer go undetected until after damage occurs.

The vulnerability prevents detection of VM exploits that could lead to the highest severity outcomes: consensus violations, state divergence, and network partition.

## Likelihood Explanation

**Likelihood: High**

1. **Attacker Surface**: Any transaction sender can attempt to trigger VM-level security events. No special privileges required.

2. **Monitoring Dependency**: Security monitoring systems are specifically designed to filter and alert on `SecurityEvent` entries. The absence of execution layer events creates an operational blind spot that is currently exploitable.

3. **Complexity**: Attackers don't need to find new VM bugs - they can exploit the monitoring gap itself. Even failed attacks (detected by VM but not security monitoring) provide reconnaissance value.

4. **Detection Window**: Since these events aren't logged as `SecurityEvent`, there's no automated detection. Manual log analysis would be required to identify attacks, significantly delaying response time.

## Recommendation

Extend the `SecurityEvent` enum to include execution layer security events:

```rust
// In crates/aptos-logger/src/security.rs
#[derive(Clone, Copy, Debug, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum SecurityEvent {
    // ... existing events ...
    
    // Execution Layer
    /// Gas meter internal consistency check failed
    GasMeterInvariantViolation,
    
    /// Parallel execution conflict with excessive incarnations
    ExcessiveParallelExecutionConflicts,
    
    /// Runtime reference safety violation detected
    ReferenceSafetyViolation,
    
    /// Resource safety violation during bytecode verification
    ResourceSafetyViolation,
    
    /// Bytecode verification failure during module loading
    BytecodeVerificationFailure,
    
    /// Unexpected unmetered gas meter usage outside system context
    UnmeteredGasMeterMisuse,
    
    /// Native function execution error
    NativeFunctionError,
    
    /// Module loading or linking error
    ModuleLoadingError,
}
```

Then update relevant code locations to use `SecurityEvent`:

In `aptos-move/aptos-vm/src/aptos_vm.rs` (gas meter check):
```rust
if let Err(err) = gas_meter.algebra().check_consistency() {
    error!(
        SecurityEvent::GasMeterInvariantViolation,
        "[aptos-vm][gas-meter][success-epilogue] {}",
        err.message().unwrap_or("No message found")
    );
    return Err(err.finish(Location::Undefined).into());
}
```

In `aptos-move/block-executor/src/executor.rs` (parallel execution):
```rust
if incarnation > num_workers.pow(2) + num_txns + 30 {
    error!(
        SecurityEvent::ExcessiveParallelExecutionConflicts,
        "Observed incarnation {} of txn {}", incarnation, txn_idx
    );
    return Err(PanicOr::Or(ParallelBlockExecutionError::IncarnationTooHigh));
}
```

Add corresponding alert rules in the monitoring configuration to detect these events.

## Proof of Concept

**Scenario 1: Gas Meter Invariant Violation Goes Undetected**

1. Deploy a Move module with carefully crafted bytecode that causes gas accounting inconsistencies
2. Execute a transaction that triggers the gas meter consistency check failure
3. Observer: The error is logged with `println!` but NO `SecurityEvent::GasMeterInvariantViolation` is emitted
4. Security monitoring system filtering for `SecurityEvent` entries misses the attack
5. Attacker can repeatedly attempt gas metering exploits without triggering security alerts

**Scenario 2: Parallel Execution Attack Without Detection**

1. Submit a batch of transactions designed to create maximum read/write conflicts
2. Force excessive validation failures and re-executions (high incarnation numbers)
3. Observer: The system logs `error!("Observed incarnation...")` but no `SecurityEvent`
4. Performance degradation attack goes undetected by security monitoring
5. Attacker can continue DoS attack on parallel execution without triggering alerts

**Verification Steps**:
```bash
# Check SecurityEvent usage - should show NO matches in execution layer
grep -r "SecurityEvent::" aptos-move/aptos-vm/src/ aptos-move/block-executor/src/

# Check critical error logging - shows errors logged but not as SecurityEvent  
grep -r "error!.*gas.*meter\|error!.*incarnation" aptos-move/

# Verify monitoring has no execution layer security event alerts
grep -r "security_event.*gas\|security_event.*vm" terraform/helm/monitoring/
```

The complete absence of `SecurityEvent` usage in execution layer code, combined with critical error conditions being logged only as regular errors, confirms this vulnerability creates a security monitoring blind spot that attackers can exploit.

---

**Notes**:
This vulnerability is a design gap in the security logging architecture rather than a traditional code bug. The execution layer components (`aptos-vm`, `block-executor`) have robust error handling and detect security violations correctly - but they don't integrate with the `SecurityEvent` logging system. This creates a critical blind spot where VM-level attacks evade security monitoring systems that rely on `SecurityEvent` entries for alerting and incident response.

### Citations

**File:** crates/aptos-logger/src/security.rs (L23-82)
```rust
#[derive(Clone, Copy, Debug, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum SecurityEvent {
    //
    // Mempool
    //
    /// Mempool received a transaction from another peer with an invalid signature
    InvalidTransactionMempool,

    /// Mempool received an invalid network event
    InvalidNetworkEventMempool,

    // Consensus
    // ---------
    /// Consensus received an invalid message (not well-formed, invalid vote data or incorrect signature)
    ConsensusInvalidMessage,

    /// Consensus received an equivocating vote
    ConsensusEquivocatingVote,

    /// Consensus received an equivocating order vote
    ConsensusEquivocatingOrderVote,

    /// Consensus received an invalid proposal
    InvalidConsensusProposal,

    /// Consensus received an invalid new round message
    InvalidConsensusRound,

    /// Consensus received an invalid sync info message
    InvalidSyncInfoMsg,

    /// A received block is invalid
    InvalidRetrievedBlock,

    /// A block being committed or executed is invalid
    InvalidBlock,

    // State-Sync
    // ----------
    /// Invalid chunk of transactions received
    StateSyncInvalidChunk,

    // Health Checker
    // --------------
    /// HealthChecker received an invalid network event
    InvalidNetworkEventHC,

    /// HealthChecker received an invalid message
    InvalidHealthCheckerMsg,

    // Network
    // -------
    /// Network received an invalid message from a remote peer
    InvalidNetworkEvent,

    /// A failed noise handshake that's either a clear bug or indicates some
    /// security issue.
    NoiseHandshake,
}
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L835-847)
```rust
        if self.gas_feature_version() >= 12 {
            // Check if the gas meter's internal counters are consistent.
            //
            // It's better to fail the transaction due to invariant violation than to allow
            // potentially bogus states to be committed.
            if let Err(err) = gas_meter.algebra().check_consistency() {
                println!(
                    "[aptos-vm][gas-meter][success-epilogue] {}",
                    err.message()
                        .unwrap_or("No message found -- this should not happen.")
                );
                return Err(err.finish(Location::Undefined).into());
            }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2311-2311)
```rust
                    &mut UnmeteredGasMeter,
```

**File:** aptos-move/block-executor/src/executor.rs (L1324-1332)
```rust
        loop {
            if let SchedulerTask::ValidationTask(txn_idx, incarnation, _) = &scheduler_task {
                if *incarnation as usize > num_workers.pow(2) + num_txns + 30 {
                    // Something is wrong if we observe high incarnations (e.g. a bug
                    // might manifest as an execution-invalidation cycle). Break out
                    // to fallback to sequential execution.
                    error!("Observed incarnation {} of txn {txn_idx}", *incarnation);
                    return Err(PanicOr::Or(ParallelBlockExecutionError::IncarnationTooHigh));
                }
```

**File:** aptos-move/block-executor/src/executor.rs (L1476-1482)
```rust
                    if incarnation > num_workers.pow(2) + num_txns + 30 {
                        // Something is wrong if we observe high incarnations (e.g. a bug
                        // might manifest as an execution-invalidation cycle). Break out
                        // to fallback to sequential execution.
                        error!("Observed incarnation {} of txn {txn_idx}", incarnation);
                        return Err(PanicOr::Or(ParallelBlockExecutionError::IncarnationTooHigh));
                    }
```

**File:** third_party/move/move-vm/runtime/src/runtime_ref_checks.rs (L100-120)
```rust
    vm_status::{sub_status::unknown_invariant_violation::EREFERENCE_SAFETY_FAILURE, StatusCode},
};
use move_vm_types::{instr::Instruction, loaded_data::runtime_types::Type};
use std::{collections::BTreeSet, slice};

/// A deterministic hash map (used in the Rust compiler), expected to perform well.
/// Not resistant to hash collision attacks, nor is it cryptographically secure.
/// Should not be used for iterating over keys without sorting first.
type UnorderedMap<K, V> = HashMap<K, V, FxBuildHasher>;

/// `ref_check_failure!(msg)` will return a `PartialVMError` with the given message
/// and a sub-status code indicating a reference safety failure.
macro_rules! ref_check_failure {
    ($msg:ident) => {
        Err(
            PartialVMError::new(StatusCode::UNKNOWN_INVARIANT_VIOLATION_ERROR)
                .with_message($msg)
                .with_sub_status(EREFERENCE_SAFETY_FAILURE),
        )
    };
}
```

**File:** terraform/helm/monitoring/files/rules/alerts.yml (L1-100)
```yaml
groups:
- name: "Aptos alerts"
  rules:
{{- if .Values.validator.name }}
  # consensus
  - alert: Zero Block Commit Rate
    expr: rate(aptos_consensus_last_committed_round{role="validator"}[1m]) == 0 OR absent(aptos_consensus_last_committed_round{role="validator"})
    for: 20m
    labels:
      severity: error
      summary: "The block commit rate is low"
    annotations:
  - alert: High local timeout rate
    expr: rate(aptos_consensus_timeout_count{role="validator"}[1m]) > 0.5
    for: 20m
    labels:
      severity: warning
      summary: "Consensus timeout rate is high"
    annotations:
  - alert: High consensus error rate
    expr: rate(aptos_consensus_error_count{role="validator"}[1m]) / on (role) rate(consensus_duration_count{op='main_loop', role="validator"}[1m]) > 0.25
    for: 20m
    labels:
      severity: warning
      summary: "Consensus error rate is high"
    annotations:
{{- end }}
    # State sync alerts
  - alert: State sync is not making progress
    expr: rate(aptos_state_sync_version{type="synced"}[5m]) == 0 OR absent(aptos_state_sync_version{type="synced"})
    for: 5m
    labels:
      severity: error
      summary: "State sync is not making progress (i.e., the synced version is not increasing!)"
    annotations:
  - alert: State sync is lagging significantly
    expr: (aptos_data_client_highest_advertised_data{data_type="transactions"} - on(kubernetes_pod_name, role) aptos_state_sync_version{type="synced"}) > 1000000
    for: 5m
    labels:
      severity: error
      summary: "State sync is lagging significantly (i.e., the lag is greater than 1 million versions)"
    annotations:

    # Mempool alerts
  - alert: Mempool has no active upstream peers
    expr: (sum by (kubernetes_pod_name) (aptos_mempool_active_upstream_peers_count)) == 0
    for: 3m
    labels:
      severity: error
      summary: "Mempool has no active upstream peers (unable to forward transactions to anyone!)"
    annotations:
  - alert: Mempool is at >80% capacity (count)
    expr: aptos_core_mempool_index_size{index="system_ttl"} > 1600000 # assumes default mempool size 2_000_000
    for: 5m
    labels:
      severity: warning
      summary: "Mempool count is at >80% capacity (it may soon become full!)"
    annotations:
  - alert: Mempool is at >80% capacity (bytes)
    expr: aptos_core_mempool_index_size{index="size_bytes"} > 1717986918 # assumes default mempool size 2 * 1024 * 1024 * 1024
    for: 5m
    labels:
      severity: warning
      summary: "Mempool bytes is at >80% capacity (it may soon become full!)"
    annotations:
  - alert: Mempool is growing at a significant rate (count)
    expr: rate(aptos_core_mempool_index_size{index="system_ttl"}[1m]) > 60000 # 3% growth per minute - assumes default mempool size 2_000_000
    for: 10m
    labels:
      severity: warning
      summary: "Mempool count is growing at a significant rate (it may soon become full!)"
    annotations:
  - alert: Mempool is growing at a significant rate (bytes)
    expr: rate(aptos_core_mempool_index_size{index="size_bytes"}[1m]) > 64424509 # 3% growth per minute - assumes default mempool size 2 * 1024 * 1024 * 1024
    for: 10m
    labels:
      severity: warning
      summary: "Mempool bytes is growing at a significant rate (it may soon become full!)"
    annotations:

  # Networking alerts
  - alert: Validator Connected Peers
    expr: 0 == min(aptos_network_peers{state="connected", role_type="validator", role="validator"})
    for: 15m
    labels:
      severity: error
      summary: "Validator node has zero connected peers"
    annotations:

  # Storage core metrics
  - alert: Validator Low Disk Space (warning)
    expr: (kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~".*(validator|fullnode)-e.*"} - kubelet_volume_stats_used_bytes) / 1024 / 1024 / 1024 < 200
    for: 1h
    labels:
      severity: warning
      summary: "Less than 200 GB of free space on Aptos Node."
    annotations:
      description: "(This is a warning, deal with it in working hours.) A validator or fullnode pod has less than 200 GB of disk space. Take these steps:
        1. If only a few nodes have this issue, it might be that they are not typically spec'd or customized differently, \
          it's most likely a expansion of the volume is needed soon. Talk to the PE team. Otherwise, it's a bigger issue.
```
