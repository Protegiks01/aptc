# Audit Report

## Title
Cache Poisoning Vulnerability in Proof-of-Store Verification Enables Performance DoS Attack

## Summary
The proof_cache in the QuorumStore consensus component uses `BatchInfoExt` as the cache key but stores different `AggregateSignature` values. A Byzantine validator can exploit this to create multiple cryptographically valid proofs for the same batch with different signature sets, causing cache thrashing and forcing all validators to perform expensive BLS signature re-verification repeatedly.

## Finding Description

The vulnerability exists in how the `ProofCache` handles proof verification across the consensus network. The cache is defined as `Cache<BatchInfoExt, AggregateSignature>` where `BatchInfoExt` uniquely identifies a batch by its content (author, batch_id, digest, etc.), and `AggregateSignature` contains the validator bitmask and BLS signature. [1](#0-0) 

The core issue occurs in the proof verification logic: [2](#0-1) 

When a `ProofOfStore` is verified:
1. The cache is checked for the `BatchInfoExt` key
2. If found, the cached signature is compared with the proof's signature
3. If they don't match, the code falls through to full cryptographic verification
4. If verification succeeds, the cache is **overwritten** with the new signature

Since BLS aggregate signatures are deterministic based on the validator set, two different quorum subsets (both with >2/3 voting power) will produce **different but equally valid** aggregate signatures for the same batch. [3](#0-2) 

The validator verifier aggregates public keys based on the validator bitmask. Different validator sets produce different aggregate public keys and therefore different valid signatures. [4](#0-3) 

**Attack Scenario:**

1. Byzantine validator authors a batch B
2. Collects signatures from validator set V1 = {A, B, C} (>2/3 voting power)
3. Creates proof P1 with aggregate signature S1, broadcasts to nodes N1, N2, N3
4. Collects signatures from validator set V2 = {A, B, D} (>2/3 voting power, different from V1)
5. Creates proof P2 with aggregate signature S2 ≠ S1, broadcasts to nodes N4, N5, N6
6. Both proofs are cryptographically valid for the same `BatchInfoExt`

When nodes exchange these proofs or receive them in blocks:
- Node receives P1: `cache[B] = S1` (after verification)
- Node receives P2: Cache hit for B returns S1, but P2 has S2, `S1 ≠ S2`, full BLS verification required, `cache[B] = S2` (overwrite)
- Node receives P1 again: Cache hit for B returns S2, but P1 has S1, `S2 ≠ S1`, full BLS verification required, `cache[B] = S1` (overwrite back)

The cache provides no benefit and all proofs require expensive cryptographic verification. [5](#0-4) 

While duplicate proofs are rejected at the insertion stage, the cache pollution occurs during the **verification stage** before insertion, affecting all nodes that verify these proofs.

## Impact Explanation

This vulnerability enables a **Performance Denial-of-Service attack** against all validators in the network:

**High Severity - Validator Node Slowdowns** (per Aptos Bug Bounty):
- BLS signature verification involves expensive pairing operations on elliptic curves
- Each forced re-verification consumes significant CPU resources
- A single Byzantine validator can create multiple valid proofs per batch they author
- With high batch creation rate, this compounds across all validators
- Network-wide performance degradation as all nodes waste resources on redundant verification
- Cache mechanism is completely defeated, eliminating its performance benefit

The attack affects **all validators** in the network, not just the attacker's node, making it a network-wide availability issue. While it doesn't break consensus safety (both signatures are valid), it violates the availability and performance guarantees expected of the consensus protocol.

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is feasible because:
1. **Low barrier**: Any single Byzantine validator can execute this attack (requires <1/3 Byzantine assumption)
2. **Normal validator operations**: The attacker uses standard batch authoring capabilities without requiring special access
3. **Automatic propagation**: Once proofs are created, they propagate through the network naturally via P2P gossiping
4. **Difficult to detect**: Both proofs are cryptographically valid, making it hard to distinguish from legitimate behavior
5. **Sustainable**: The attacker can repeat this for every batch they author

The only limiting factor is that the attacker must be a validator in the active set, which requires staking tokens. However, this is within the protocol's threat model of tolerating <1/3 Byzantine validators.

## Recommendation

**Option 1: Include signature in cache key (Preferred)**
Modify the `ProofCache` to use both `BatchInfoExt` AND `AggregateSignature` as the composite cache key:

```rust
pub type ProofCache = Cache<(BatchInfoExt, AggregateSignature), ()>;
```

Update verification logic:
```rust
pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
    let batch_info_ext: BatchInfoExt = self.info.clone().into();
    let cache_key = (batch_info_ext.clone(), self.multi_signature.clone());
    
    if cache.get(&cache_key).is_some() {
        return Ok(());
    }
    
    let result = validator
        .verify_multi_signatures(&self.info, &self.multi_signature)
        .context(format!("Failed to verify ProofOfStore for batch: {:?}", self.info));
    
    if result.is_ok() {
        cache.insert(cache_key, ());
    }
    result
}
```

**Option 2: Reject proofs with different signatures for same batch**
In `insert_proof()`, check if a different valid signature exists and reject the new proof:

```rust
if let Some(existing_item) = self.items.get(&batch_key) {
    if let Some(existing_proof) = &existing_item.proof {
        if existing_proof.multi_signature() != proof.multi_signature() {
            counters::inc_rejected_pos_count(counters::POS_SIGNATURE_MISMATCH_LABEL);
            warn!("Rejecting proof with different signature for same batch: {:?}", batch_key);
            return;
        }
    }
}
```

**Option 3: First-signature-wins policy in cache**
Modify `ProofOfStore::verify()` to never overwrite cached signatures:

```rust
if let Some(signature) = cache.get(&batch_info_ext) {
    if signature == self.multi_signature {
        return Ok(());
    } else {
        // Different signature - verify but don't update cache
        return validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!("Failed to verify ProofOfStore for batch: {:?}", self.info));
    }
}
```

**Option 1 is preferred** as it maintains cache effectiveness for all valid proofs without rejecting legitimate ones.

## Proof of Concept

**Rust Reproduction Steps:**

```rust
#[test]
fn test_cache_collision_with_different_signatures() {
    use aptos_consensus_types::proof_of_store::{BatchInfoExt, ProofCache, ProofOfStore};
    use aptos_types::aggregate_signature::AggregateSignature;
    
    // Setup validator verifier with multiple validators
    let (validators, verifier) = create_test_validators(10);
    let proof_cache = ProofCache::new(100);
    
    // Create a test batch
    let batch_info = create_test_batch_info();
    
    // Create first proof with validator set {0, 1, 2, 3, 4, 5, 6} (>2/3 of 10)
    let proof1 = create_proof_with_validators(
        batch_info.clone(), 
        &validators[0..7], 
        &verifier
    );
    
    // Verify first proof - should cache the signature
    assert!(proof1.verify(&verifier, &proof_cache).is_ok());
    
    // Create second proof with different validator set {0, 1, 2, 3, 4, 7, 8} (>2/3 of 10)
    let proof2 = create_proof_with_validators(
        batch_info.clone(), 
        &[&validators[0..5], &validators[7..9]].concat(), 
        &verifier
    );
    
    // Both proofs have same BatchInfoExt but different signatures
    assert_eq!(proof1.info(), proof2.info());
    assert_ne!(proof1.multi_signature(), proof2.multi_signature());
    
    // Verify second proof - should require full verification despite cache hit
    // and overwrite the cache
    assert!(proof2.verify(&verifier, &proof_cache).is_ok());
    
    // Verify first proof again - cache now has proof2's signature
    // so this requires full verification again (cache thrashing)
    assert!(proof1.verify(&verifier, &proof_cache).is_ok());
    
    // Demonstrate that this causes repeated expensive verification
    // by measuring verification time with and without cache benefit
    let start = Instant::now();
    for _ in 0..100 {
        proof1.verify(&verifier, &proof_cache).unwrap();
        proof2.verify(&verifier, &proof_cache).unwrap();
    }
    let thrashing_time = start.elapsed();
    
    println!("Cache thrashing verification time: {:?}", thrashing_time);
    // This should be significantly slower than cached verification
}
```

This test demonstrates that two valid proofs with different signatures for the same batch cause cache thrashing, forcing repeated expensive BLS signature verification operations.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L616-616)
```rust
pub type ProofCache = Cache<BatchInfoExt, AggregateSignature>;
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L635-652)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
        let batch_info_ext: BatchInfoExt = self.info.clone().into();
        if let Some(signature) = cache.get(&batch_info_ext) {
            if signature == self.multi_signature {
                return Ok(());
            }
        }
        let result = validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!(
                "Failed to verify ProofOfStore for batch: {:?}",
                self.info
            ));
        if result.is_ok() {
            cache.insert(batch_info_ext, self.multi_signature.clone());
        }
        result
    }
```

**File:** types/src/validator_verifier.rs (L345-386)
```rust
    pub fn verify_multi_signatures<T: CryptoHash + Serialize>(
        &self,
        message: &T,
        multi_signature: &AggregateSignature,
    ) -> std::result::Result<(), VerifyError> {
        // Verify the number of signature is not greater than expected.
        Self::check_num_of_voters(self.len() as u16, multi_signature.get_signers_bitvec())?;
        let mut pub_keys = vec![];
        let mut authors = vec![];
        for index in multi_signature.get_signers_bitvec().iter_ones() {
            let validator = self
                .validator_infos
                .get(index)
                .ok_or(VerifyError::UnknownAuthor)?;
            authors.push(validator.address);
            pub_keys.push(validator.public_key());
        }
        // Verify the quorum voting power of the authors
        self.check_voting_power(authors.iter(), true)?;
        #[cfg(any(test, feature = "fuzzing"))]
        {
            if self.quorum_voting_power == 0 {
                // This should happen only in case of tests.
                // TODO(skedia): Clean up the test behaviors to not rely on empty signature
                // verification
                return Ok(());
            }
        }
        // Verify empty multi signature
        let multi_sig = multi_signature
            .sig()
            .as_ref()
            .ok_or(VerifyError::EmptySignature)?;
        // Verify the optimistically aggregated signature.
        let aggregated_key =
            PublicKey::aggregate(pub_keys).map_err(|_| VerifyError::FailedToAggregatePubKey)?;

        multi_sig
            .verify(message, &aggregated_key)
            .map_err(|_| VerifyError::InvalidMultiSignature)?;
        Ok(())
    }
```

**File:** types/src/aggregate_signature.rs (L11-19)
```rust
/// This struct represents a BLS multi-signature or aggregated signature:
/// it stores a bit mask representing the set of validators participating in the signing process
/// and the multi-signature/aggregated signature itself,
/// which was aggregated from these validators' partial BLS signatures.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, CryptoHasher, BCSCryptoHash)]
pub struct AggregateSignature {
    validator_bitmask: BitVec,
    sig: Option<bls12381::Signature>,
}
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L175-188)
```rust
    pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
        if proof.expiration() <= self.latest_block_timestamp {
            counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
            return;
        }
        let batch_key = BatchKey::from_info(proof.info());
        if self
            .items
            .get(&batch_key)
            .is_some_and(|item| item.proof.is_some() || item.is_committed())
        {
            counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
            return;
        }
```
