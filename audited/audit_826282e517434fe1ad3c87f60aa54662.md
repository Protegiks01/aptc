# Audit Report

## Title
Byzantine Fault Tolerance Violation: Global Data Summary Can Be Poisoned by Single Malicious Peer Without Quorum Verification

## Summary
The `calculate_global_data_summary()` function collects advertised data from all non-ignored peers without requiring Byzantine consensus or quorum validation. A single malicious peer can poison the global summary by advertising fake `synced_ledger_info` with arbitrarily high versions, causing denial of service through resource exhaustion and stalled synchronization progress.

## Finding Description

The vulnerability exists in the state sync data client's peer aggregation logic. [1](#0-0) 

This code collects storage summaries from ALL non-ignored peers without any validation. It then aggregates all advertised data including `synced_ledger_info`: [2](#0-1) 

The critical flaw is that advertised `LedgerInfoWithSignatures` are never validated when received from peers. [3](#0-2) 

The storage summary is directly stored without signature verification: [4](#0-3) 

The global summary then naively selects the highest version without consensus checking: [5](#0-4) 

This highest ledger info is used as a sync target by the streaming engine: [6](#0-5) 

**Attack Scenario:**
1. Malicious peer advertises `StorageServerSummary` with fake `synced_ledger_info` containing version 999,999,999
2. This gets collected into `advertised_data.synced_ledger_infos` without validation
3. `highest_synced_ledger_info()` returns the fake ledger info (highest version)
4. Stream engine selects it as sync target
5. Nodes waste resources attempting to fetch non-existent data
6. Requests fail repeatedly, causing resource exhaustion
7. If attacker controls multiple peer identities, attack persists despite peer scoring

**Contrast with Chunk Size Handling:**
The code correctly uses median for chunk sizes with explicit comment about honest majority: [7](#0-6) 

However, this Byzantine-tolerant approach is NOT applied to the actual advertised data (ledger infos, states, transactions), creating the vulnerability.

## Impact Explanation

**Severity: High**

This qualifies as **High Severity** under Aptos bug bounty criteria:
- **Validator node slowdowns**: Nodes waste CPU/network resources on futile sync attempts
- **Significant protocol violations**: Violates Byzantine fault tolerance guarantee requiring 2/3 honest peers

The vulnerability does NOT cause:
- State corruption (actual data is verified with cryptographic proofs when received)
- Consensus safety breaks (BFT consensus itself remains intact)
- Fund loss (state transitions are still validated)

However, it causes:
- Denial of service through resource exhaustion
- Stalled synchronization progress affecting liveness
- Network-wide disruption if multiple nodes are affected
- Violation of the fundamental BFT assumption that <1/3 Byzantine nodes cannot disrupt the system

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly exploitable:

1. **Low attacker requirements**: Any network peer can advertise storage summaries - no validator privileges needed
2. **Simple attack**: Just send malformed `StorageServerSummary` with inflated version
3. **Persistent impact**: Peer scoring is reactive, allowing initial attack window
4. **Sybil amplification**: Attacker can rotate through multiple peer identities
5. **No cost**: Advertising fake data requires minimal computational resources

The peer scoring system provides limited mitigation: [8](#0-7) 

Malicious peers start with score 50.0 and are only ignored below 25.0, allowing significant attack window before penalties take effect.

## Recommendation

Implement Byzantine-tolerant aggregation for advertised data using quorum verification:

```rust
pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
    let storage_summaries: Vec<StorageServerSummary> = /* ... existing collection ... */;
    
    if storage_summaries.is_empty() {
        return GlobalDataSummary::empty();
    }

    // NEW: Require quorum consensus for synced_ledger_infos
    let synced_ledger_infos = aggregate_with_quorum(
        storage_summaries.iter()
            .filter_map(|s| s.data_summary.synced_ledger_info.as_ref())
            .cloned()
            .collect(),
        self.data_client_config.minimum_peer_quorum_percentage // e.g., 67%
    );

    // Continue with existing aggregation for other data types...
}

// Helper function to enforce quorum
fn aggregate_with_quorum(
    mut ledger_infos: Vec<LedgerInfoWithSignatures>,
    quorum_percentage: u64
) -> Vec<LedgerInfoWithSignatures> {
    // Group by version
    let mut version_counts: HashMap<Version, (usize, LedgerInfoWithSignatures)> = HashMap::new();
    
    for li in ledger_infos {
        let version = li.ledger_info().version();
        version_counts.entry(version)
            .and_modify(|(count, _)| *count += 1)
            .or_insert((1, li.clone()));
    }
    
    let total_peers = version_counts.values().map(|(c, _)| c).sum::<usize>();
    let quorum_threshold = (total_peers * quorum_percentage as usize) / 100;
    
    // Only include versions that meet quorum
    version_counts.into_iter()
        .filter(|(_, (count, _))| *count >= quorum_threshold)
        .map(|(_, (_, li))| li)
        .collect()
}
```

**Alternative**: Verify signatures at advertisement time:
- Validate `LedgerInfoWithSignatures.verify_signatures()` when storage summary is received
- Requires access to current epoch's `ValidatorVerifier`
- Reject summaries with invalid signatures immediately

## Proof of Concept

```rust
// Exploitation demonstration in Rust test

#[tokio::test]
async fn test_malicious_peer_poisons_global_summary() {
    // Setup: Create data client with multiple honest peers
    let (client, peers_and_metadata) = setup_data_client();
    
    // Honest peers advertise version 1000
    for peer in &honest_peers {
        let honest_summary = create_storage_summary(1000, valid_signatures);
        client.update_peer_storage_summary(*peer, honest_summary);
    }
    
    // Attack: Malicious peer advertises version 999,999,999 with fake signatures
    let malicious_peer = PeerNetworkId::random();
    let malicious_summary = StorageServerSummary {
        protocol_metadata: ProtocolMetadata::default(),
        data_summary: DataSummary {
            synced_ledger_info: Some(LedgerInfoWithSignatures::new(
                LedgerInfo::new(
                    BlockInfo::new(999999999, 0, HashValue::zero(), HashValue::zero(), 0, 0, None),
                    HashValue::zero()
                ),
                AggregateSignature::empty() // Fake signature!
            )),
            // ... other fields
        }
    };
    
    client.update_peer_storage_summary(malicious_peer, malicious_summary);
    
    // Verify: Global summary is poisoned
    let global_summary = client.get_global_data_summary();
    let highest = global_summary.advertised_data.highest_synced_ledger_info().unwrap();
    
    assert_eq!(highest.ledger_info().version(), 999999999); // Poisoned!
    
    // Impact: Nodes waste resources trying to sync to fake target
    // Streaming engine will select this as target and fail repeatedly
}
```

## Notes

This vulnerability demonstrates a fundamental misalignment between Byzantine fault tolerance principles and the implementation. While the Aptos consensus layer correctly implements BFT with 2f+1 quorum requirements, the state sync layer naively trusts peer advertisements without quorum validation.

The comment in the code acknowledges the need for honest majority for chunk sizes but fails to apply the same principle to the more critical advertised ledger information. This creates an exploitable asymmetry where a single malicious peer can disrupt synchronization for the entire network.

The actual state transitions remain safe due to cryptographic proof verification at execution time, preventing state corruption. However, the liveness and availability guarantees are violated, qualifying this as a High Severity protocol violation under the Aptos bug bounty program.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L341-350)
```rust
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L365-386)
```rust
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
            if let Some(transactions) = summary.data_summary.transactions {
                advertised_data.transactions.push(transactions);
            }
            if let Some(transaction_outputs) = summary.data_summary.transaction_outputs {
                advertised_data
                    .transaction_outputs
                    .push(transaction_outputs);
            }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L416-418)
```rust
/// To calculate the optimal chunk size, we take the median for each
/// chunk size parameter. This works well when we have an honest
/// majority that mostly agrees on the same chunk sizes.
```

**File:** state-sync/aptos-data-client/src/poller.rs (L436-439)
```rust
        // Update the summary for the peer
        data_summary_poller
            .data_client
            .update_peer_storage_summary(peer, storage_summary);
```

**File:** state-sync/aptos-data-client/src/client.rs (L213-214)
```rust
    pub fn update_peer_storage_summary(&self, peer: PeerNetworkId, summary: StorageServerSummary) {
        self.peer_states.update_summary(peer, summary)
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L184-197)
```rust
    pub fn highest_synced_ledger_info(&self) -> Option<LedgerInfoWithSignatures> {
        let highest_synced_position = self
            .synced_ledger_infos
            .iter()
            .map(|ledger_info_with_sigs| ledger_info_with_sigs.ledger_info().version())
            .position_max();

        if let Some(highest_synced_position) = highest_synced_position {
            self.synced_ledger_infos
                .get(highest_synced_position)
                .cloned()
        } else {
            None
        }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L522-529)
```rust
        // We don't have a final target, select the highest to make progress
        if let Some(highest_synced_ledger_info) = advertised_data.highest_synced_ledger_info() {
            let (next_request_version, _) = self.next_request_version_and_epoch;
            if next_request_version > highest_synced_ledger_info.ledger_info().version() {
                Ok(None) // We're already at the highest synced ledger info. There's no known target.
            } else {
                Ok(Some(highest_synced_ledger_info))
            }
```
