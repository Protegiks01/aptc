# Audit Report

## Title
Unbounded Channel Memory Exhaustion in Internal Indexer Committer Thread

## Summary
The `DBCommitter::run()` function uses an unbounded channel to receive batches from the indexer processing thread. When the disk I/O-bound committer falls behind the producer during catch-up or heavy load scenarios, batches accumulate indefinitely in memory, potentially exhausting available RAM and causing node crashes.

## Finding Description

The internal indexer system suffers from a resource exhaustion vulnerability due to the use of an unbounded channel without backpressure control.

**Root Cause:**

The channel is created as unbounded in `DBIndexer::new()`: [1](#0-0) 

This creates a standard `mpsc::channel()` with no capacity limit, allowing unlimited batches to queue in memory.

**Producer Side - No Backpressure:**

The `DBIndexer::process()` method loops calling `process_a_batch()` with no rate limiting: [2](#0-1) 

Each batch is sent immediately via the channel: [3](#0-2) 

Since the channel is unbounded, `send()` never blocks, allowing the producer to queue batches faster than they can be consumed.

**Consumer Side - Disk I/O Bottleneck:**

The `DBCommitter::run()` receives batches and writes them to disk: [4](#0-3) 

The disk write operation at lines 69-71 can be slow, especially under heavy I/O load. While the committer blocks on disk writes, the producer continues sending batches to the channel.

**Memory Impact:**

Each batch contains up to 10,000 transactions (default batch size): [5](#0-4) 

With events and state keys, each transaction averages 5-10KB. During a catch-up scenario with 1,000,000 versions to process:
- Number of batches: 1,000,000 / 10,000 = 100 batches
- Memory per batch: 10,000 txns × 5KB = 50MB minimum
- Total memory if all queued: 100 × 50MB = 5GB+

**Invariant Violation:**

This breaks the "Resource Limits" invariant: "All operations must respect gas, storage, and computational limits" - specifically memory constraints that should prevent unbounded resource consumption.

**Comparison with Correct Implementation:**

Other committer threads in the codebase use bounded channels. For example, the state snapshot committer uses a sync_channel with explicit backpressure: [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty criteria:

**Node Crashes / Availability Loss:**
- When memory is exhausted, the operating system will kill the node process
- This affects node availability and can cascade to network liveness issues
- Multiple nodes experiencing this simultaneously could impact network consensus participation

**State Inconsistencies:**
- If the node crashes mid-batch, the indexer may have inconsistent state requiring manual intervention
- This aligns with "State inconsistencies requiring intervention" (Medium severity)

**Production Impact:**
- Any node with internal indexer enabled (common configuration for validators and fullnodes providing query services)
- Particularly affects nodes that restart frequently or experience network partitions requiring catch-up

The severity does not reach High/Critical because:
- No consensus safety violation (indexer is auxiliary, not consensus-critical)
- No funds loss or theft
- Nodes can recover after restart
- Not a protocol-level vulnerability

## Likelihood Explanation

**High Likelihood** - This will occur naturally under common operational conditions:

**Trigger Conditions:**
1. Node restart after downtime (planned maintenance, crashes, updates)
2. Network partition recovery requiring catch-up
3. State sync or fast sync operations processing large version ranges
4. Heavy disk I/O load from other processes slowing commits

**Production Scenario:**

The `InternalIndexerDBService::run()` continuously processes versions: [7](#0-6) 

During catch-up, `target_version - start_version` can be millions of versions. The loop processes batches as fast as the main DB can read them (fast), but the committer must write to disk (slow). This mismatch inevitably causes queue buildup.

**No Attack Required:**
- No malicious transaction or validator behavior needed
- Happens through normal node operations
- More likely during network stress or hardware constraints

## Recommendation

**Replace the unbounded channel with a bounded sync_channel to provide backpressure:**

```rust
// In DBIndexer::new() at line 328, change from:
let (sender, reciver) = mpsc::channel();

// To:
const INDEXER_CHANNEL_SIZE: usize = 3; // Allow small buffer for pipelining
let (sender, reciver) = mpsc::sync_channel(INDEXER_CHANNEL_SIZE);
```

**Rationale:**
- `sync_channel(3)` allows up to 3 batches to be buffered, enabling some pipelining
- When the buffer is full, the producer blocks on `send()`, naturally slowing down to match the consumer's pace
- This prevents unbounded memory growth while maintaining good throughput
- Follows the pattern used successfully in `StateSnapshotCommitter`

**Additional Monitoring:**
Add metrics to track channel utilization:
- Gauge for current queue depth
- Counter for producer blocks
- Timer for commit latency

This would provide early warning of performance issues before they cause crashes.

## Proof of Concept

**Reproduction Steps:**

1. **Setup**: Configure a node with internal indexer enabled and a large version gap to process

2. **Simulate Slow Disk**: Use disk throttling or introduce artificial delays in the RocksDB write path

3. **Trigger Catch-up**: Start the indexer service with `start_version = 0` and `target_version = 1000000`

4. **Observe Memory Growth**: Monitor process memory usage

**Rust Test Sketch:**

```rust
#[test]
fn test_indexer_memory_exhaustion() {
    // Create DBIndexer with large backlog
    let (sender, receiver) = mpsc::channel();
    
    // Producer thread - sends batches rapidly
    thread::spawn(move || {
        for i in 0..1000 {
            let mut batch = SchemaBatch::new();
            // Fill batch with 10,000 dummy entries
            for j in 0..10000 {
                batch.put::<StateKeysSchema>(&dummy_state_key(), &()).unwrap();
            }
            sender.send(Some(batch)).unwrap();
            println!("Sent batch {}", i);
        }
    });
    
    // Consumer thread - processes slowly (simulating disk I/O)
    let handle = thread::spawn(move || {
        let mut count = 0;
        while let Ok(Some(batch)) = receiver.recv() {
            // Simulate slow disk write
            thread::sleep(Duration::from_millis(100));
            count += 1;
            
            // Check memory usage - would grow unbounded
            if count % 10 == 0 {
                println!("Processed {} batches", count);
            }
        }
    });
    
    // Producer completes quickly, but receiver is still processing
    // Memory contains ~990 queued batches × ~50MB = ~50GB
    thread::sleep(Duration::from_secs(5));
    
    // This test would OOM without bounded channel
    handle.join().unwrap();
}
```

**Expected Behavior:**
- With unbounded channel: Memory grows to gigabytes, potentially causing OOM
- With bounded `sync_channel(3)`: Memory stays bounded at ~150MB (3 batches), producer blocks when needed

## Notes

This vulnerability demonstrates a classic producer-consumer mismatch where the producer (CPU-bound indexer processing) outpaces the consumer (disk-bound committer) without backpressure control. While the internal indexer is not consensus-critical, node crashes affect network availability and user-facing services. The fix is straightforward and follows established patterns elsewhere in the Aptos codebase.

### Citations

**File:** storage/indexer/src/db_indexer.rs (L62-76)
```rust
    pub fn run(&self) {
        loop {
            let batch_opt = self
                .receiver
                .recv()
                .expect("Failed to receive batch from DB Indexer");
            if let Some(batch) = batch_opt {
                self.db
                    .write_schemas(batch)
                    .expect("Failed to write batch to indexer db");
            } else {
                break;
            }
        }
    }
```

**File:** storage/indexer/src/db_indexer.rs (L328-328)
```rust
        let (sender, reciver) = mpsc::channel();
```

**File:** storage/indexer/src/db_indexer.rs (L397-407)
```rust
    pub fn process(&self, start_version: Version, end_version: Version) -> Result<Version> {
        let mut version = start_version;
        while version < end_version {
            let next_version = self.process_a_batch(version, end_version)?;
            if next_version == version {
                break;
            }
            version = next_version;
        }
        Ok(version)
    }
```

**File:** storage/indexer/src/db_indexer.rs (L546-548)
```rust
        self.sender
            .send(Some(batch))
            .map_err(|e| AptosDbError::Other(e.to_string()))?;
```

**File:** config/src/config/internal_indexer_db_config.rs (L77-78)
```rust
            batch_size: 10_000,
        }
```

**File:** storage/aptosdb/src/state_store/state_snapshot_committer.rs (L64-65)
```rust
        let (state_merkle_batch_commit_sender, state_merkle_batch_commit_receiver) =
            mpsc::sync_channel(Self::CHANNEL_SIZE);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L183-183)
```rust
            let next_version = self.db_indexer.process(start_version, target_version)?;
```
