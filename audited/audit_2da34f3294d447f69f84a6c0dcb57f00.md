# Audit Report

## Title
Configuration Validation Bypass Allows Zero Retry Limit Causing Consensus Liveness Failure

## Summary
The `batch_request_retry_limit` configuration parameter lacks validation to ensure it is greater than zero. Setting this value to 0 causes the batch requester to immediately fail all batch requests without attempting network communication, resulting in complete consensus liveness failure for the affected node.

## Finding Description

The Aptos QuorumStore consensus mechanism uses a batch requester component to fetch transaction batches from peer validators. The `batch_request_retry_limit` configuration controls how many retry attempts are made before giving up on a batch request.

**Vulnerability Location:** [1](#0-0) [2](#0-1) 

The configuration field is defined as `usize` with no lower bound validation. The default value is 10, but operators can set any value including 0.

**Sanitization Gap:** [3](#0-2) 

The `ConfigSanitizer` implementation validates send/recv limits and batch/total limits, but does NOT validate that `batch_request_retry_limit` is non-zero.

**Exploitation Path:**

When `retry_limit` is set to 0: [4](#0-3) [5](#0-4) 

The `next_request_peers()` function checks `if self.num_retries < self.retry_limit`. With `retry_limit = 0`, this evaluates to `if 0 < 0` which is false, causing immediate return of `None` without sending any network requests. [6](#0-5) 

The request loop exits immediately, returning `ExecutorError::CouldNotGetData`. [7](#0-6) 

This error propagates through the payload manager, preventing block execution and halting consensus progress. [8](#0-7) 

## Impact Explanation

**Severity: High** - While this requires configuration file access (not a remote exploit), it represents a critical validation bypass that breaks the fundamental invariant that batch requests must be attempted at least once before failing.

Impact classification:
- **Validator node slowdowns**: Not applicable - the node completely stops making progress
- **Total loss of liveness**: YES - The affected node cannot fetch batches, cannot execute blocks, and consensus halts entirely for that validator
- **Significant protocol violation**: YES - Violates the consensus liveness invariant

This meets **High Severity** criteria per the Aptos bug bounty program, though it falls short of Critical because:
1. It only affects the misconfigured node, not the entire network
2. It requires privileged configuration access (not remotely exploitable)
3. It's recoverable by fixing the configuration and restarting

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires:
- Access to the node's configuration file (privileged operation)
- Explicit setting of `batch_request_retry_limit: 0` (not the default)
- No validation catches this during node startup

However, it could occur through:
1. **Operator error**: Misunderstanding the parameter and setting it to 0 thinking it means "no limit"
2. **Configuration management bugs**: Automated deployment systems setting invalid values
3. **Testing configurations**: Development/test configs with 0 accidentally used in production

The lack of validation means this error is not caught until runtime, when it causes catastrophic failure.

## Recommendation

Add validation to the `QuorumStoreConfig::sanitize()` method to enforce a minimum value: [3](#0-2) 

Add this validation:

```rust
fn sanitize_retry_limit(
    sanitizer_name: &str,
    config: &QuorumStoreConfig,
) -> Result<(), Error> {
    if config.batch_request_retry_limit == 0 {
        return Err(Error::ConfigSanitizerFailed(
            sanitizer_name.to_owned(),
            "batch_request_retry_limit must be at least 1".to_string(),
        ));
    }
    Ok(())
}
```

Then call it in the sanitize method:

```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        
        Self::sanitize_retry_limit(&sanitizer_name, &node_config.consensus.quorum_store)?;
        Self::sanitize_send_recv_batch_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;
        
        Ok(())
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use crate::config::ConsensusConfig;

    #[test]
    fn test_zero_retry_limit_rejected() {
        let node_config = NodeConfig {
            consensus: ConsensusConfig {
                quorum_store: QuorumStoreConfig {
                    batch_request_retry_limit: 0,
                    ..Default::default()
                },
                ..Default::default()
            },
            ..Default::default()
        };

        let error = QuorumStoreConfig::sanitize(
            &node_config,
            NodeType::Validator,
            Some(ChainId::testnet()),
        )
        .unwrap_err();
        
        assert!(matches!(error, Error::ConfigSanitizerFailed(_, msg) if msg.contains("retry_limit")));
    }
}
```

**Notes:**

This vulnerability represents a **configuration validation bypass** rather than a remotely exploitable security flaw. While the technical analysis confirms that `retry_limit: 0` causes the described liveness failure, this issue requires privileged access to modify node configuration files, which places it outside the scope of typical remote security vulnerabilities. It is primarily a **defensive programming issue** that should be fixed to prevent operational failures from misconfiguration, but it does not meet the strict criteria for unprivileged attacker exploitation as defined in the trust model.

### Citations

**File:** config/src/config/quorum_store_config.rs (L85-85)
```rust
    pub batch_request_retry_limit: usize,
```

**File:** config/src/config/quorum_store_config.rs (L128-128)
```rust
            batch_request_retry_limit: 10,
```

**File:** config/src/config/quorum_store_config.rs (L253-271)
```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Sanitize the send/recv batch limits
        Self::sanitize_send_recv_batch_limits(
            &sanitizer_name,
            &node_config.consensus.quorum_store,
        )?;

        // Sanitize the batch total limits
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L30-38)
```rust
impl BatchRequesterState {
    fn new(signers: Arc<Mutex<BTreeSet<PeerId>>>, retry_limit: usize) -> Self {
        Self {
            signers,
            next_index: 0,
            num_retries: 0,
            retry_limit,
        }
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L40-64)
```rust
    fn next_request_peers(&mut self, num_peers: usize) -> Option<Vec<PeerId>> {
        let signers = self.signers.lock();
        if self.num_retries == 0 {
            let mut rng = rand::thread_rng();
            // make sure nodes request from the different set of nodes
            self.next_index = rng.r#gen::<usize>() % signers.len();
            counters::SENT_BATCH_REQUEST_COUNT.inc_by(num_peers as u64);
        } else {
            counters::SENT_BATCH_REQUEST_RETRY_COUNT.inc_by(num_peers as u64);
        }
        if self.num_retries < self.retry_limit {
            self.num_retries += 1;
            let ret = signers
                .iter()
                .cycle()
                .skip(self.next_index)
                .take(num_peers)
                .cloned()
                .collect();
            self.next_index = (self.next_index + num_peers) % signers.len();
            Some(ret)
        } else {
            None
        }
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L122-132)
```rust
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L111-122)
```rust
    async fn request_and_wait_transactions(
        batches: Vec<(BatchInfo, Vec<PeerId>)>,
        block_timestamp: u64,
        batch_reader: Arc<dyn BatchReader>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let futures = Self::request_transactions(batches, block_timestamp, batch_reader);
        let mut all_txns = Vec::new();
        for result in futures::future::join_all(futures).await {
            all_txns.append(&mut result?);
        }
        Ok(all_txns)
    }
```
