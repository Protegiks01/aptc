# Audit Report

## Title
Malicious Peers Can Indefinitely Prevent State Sync Progress via Deliberate Response Delays Without Peer Score Penalties

## Summary
Malicious peers can deliberately delay data responses to trigger `CriticalDataStreamTimeout` errors in state sync, forcing validators to repeatedly restart synchronization streams without any peer reputation penalty. This allows attackers to indefinitely prevent validators from bootstrapping or catching up with the blockchain state, causing a denial-of-service condition.

## Finding Description

The state sync driver tracks consecutive stream timeouts and triggers a `CriticalDataStreamTimeout` error when the threshold is exceeded. [1](#0-0) 

When this critical timeout occurs, the driver resets the active stream **without providing any feedback** about the problematic peer. [2](#0-1) 

The stream termination with `None` feedback means no peer score update occurs. [3](#0-2) 

**The Attack Mechanism:**

1. A malicious peer receives RPC requests for state sync data (transactions, outputs, or state values)
2. The peer deliberately delays responses to arrive **just under** the RPC timeout (e.g., 14.5 seconds for a 15-second subscription timeout)
3. Since the RPC doesn't timeout, no `ErrorType::NotUseful` penalty is applied to the peer's score
4. However, the response arrives much later than `max_stream_wait_time_ms` (default: 5 seconds)
5. The stream times out 12 consecutive times (`max_num_stream_timeouts`)
6. `CriticalDataStreamTimeout` is triggered, but the stream is reset with **no feedback**
7. A new stream is created, and peer selection may choose the same or another malicious peer
8. The cycle repeats indefinitely, preventing the validator from making any sync progress

**Why Existing Safeguards Fail:**

The peer scoring system correctly penalizes individual RPC timeouts with a 0.95 multiplier. [4](#0-3) 

When RPC errors occur, peers are penalized with `ErrorType::NotUseful`. [5](#0-4) 

However, if responses arrive just under the RPC timeout threshold, there is **no RPC timeout error** and therefore no peer score penalty. The stream-level timeout mechanism (waiting for notifications) operates independently from the RPC timeout mechanism and does not provide feedback to the peer scoring system when `CriticalDataStreamTimeout` occurs.

**Configuration Values Exploited:**
- `max_stream_wait_time_ms`: 5000ms (5 seconds) - stream waits for notifications
- `max_num_stream_timeouts`: 12 - consecutive timeouts before critical error
- `subscription_response_timeout_ms`: 15000ms (15 seconds) - RPC timeout for subscriptions
- `response_timeout_ms`: 10000ms (10 seconds) - RPC timeout for regular requests [6](#0-5) [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria for the following reasons:

1. **Validator Node Slowdowns**: Affected validators cannot complete state synchronization and remain perpetually behind the network, unable to participate in consensus effectively

2. **Significant Protocol Violations**: The attack violates the protocol's liveness guarantee that validators should be able to sync state from honest peers

3. **Network Availability Impact**: If multiple validators are targeted simultaneously during network upgrades or after downtime, the network's consensus participation can be significantly degraded

4. **Low Complexity Attack**: The attack requires only standard peer participation without any cryptographic breaking, validator key compromise, or sophisticated exploitation

The impact stops short of Critical severity because:
- No funds are directly stolen or minted
- The network doesn't completely halt if â‰¥2/3 of validators remain operational
- Existing validators that are already synced can continue operating
- The issue is recoverable by network operators identifying and banning malicious peers

## Likelihood Explanation

**Likelihood: High**

This attack is highly likely to occur because:

1. **Low Attacker Requirements**: Any peer can join the network and become a potential data source for state sync. The attacker only needs to:
   - Run a node that responds to storage service requests
   - Time responses to arrive between 5-15 seconds (for subscriptions) or 5-10 seconds (for regular requests)
   - No validator keys, stake, or cryptographic capabilities required

2. **Easy Exploitation**: The attack is trivial to implement - simply add a deliberate delay before responding to RPC requests

3. **No Detection**: The malicious peer appears as a "slow but functional" peer rather than a completely unresponsive one, making detection difficult

4. **Persistent Effect**: Once triggered, the attack can continue indefinitely as each stream reset may select the same or another malicious peer

5. **Motivated Attackers**: Adversaries may target validators during:
   - Network upgrades when validators need to sync new state
   - After validator downtime or crashes
   - When new validators join the network
   - To reduce consensus participation and facilitate other attacks

## Recommendation

**Immediate Fix**: Provide feedback when `CriticalDataStreamTimeout` occurs to ensure peer scores are appropriately penalized.

Modify the error handling in `fetch_next_data_notification` to provide feedback about the timeout: [2](#0-1) 

**Proposed Code Fix** (conceptual - would apply to both `bootstrapper.rs` and `continuous_syncer.rs`):

```rust
async fn fetch_next_data_notification(&mut self) -> Result<DataNotification, Error> {
    let max_stream_wait_time_ms = self.driver_configuration.config.max_stream_wait_time_ms;
    let max_num_stream_timeouts = self.driver_configuration.config.max_num_stream_timeouts;
    let result = utils::get_data_notification(
        max_stream_wait_time_ms,
        max_num_stream_timeouts,
        self.active_data_stream.as_mut(),
    )
    .await;
    
    if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
        warn!("Resetting the currently active data stream due to too many timeouts!");
        
        // Get the last notification ID if available to provide feedback
        let notification_and_feedback = if let Some(stream) = &self.active_data_stream {
            // Get the last notification ID sent by this stream
            stream.get_last_notification_id().map(|notification_id| {
                NotificationAndFeedback::new(
                    notification_id,
                    NotificationFeedback::InvalidPayloadData, // Or create a new "StreamTimeout" variant
                )
            })
        } else {
            None
        };
        
        self.reset_active_stream(notification_and_feedback).await?;
    }
    result
}
```

**Additional Safeguards:**

1. **Add Stream Timeout Feedback Variant**: Create a new `NotificationFeedback::StreamTimeout` variant to specifically track stream-level timeouts separately from payload errors

2. **Exponential Backoff**: After a `CriticalDataStreamTimeout`, implement exponential backoff before creating a new stream to avoid rapid cycling

3. **Peer Blacklisting**: Track which peer was serving the stream when critical timeout occurred and temporarily exclude them from future stream peer selection

4. **Monitoring**: Add metrics and alerts for `CriticalDataStreamTimeout` occurrences to enable operators to detect and respond to attacks

## Proof of Concept

The following outlines a reproduction scenario:

**Setup:**
1. Deploy a malicious peer node that responds to storage service requests
2. Configure the malicious peer to delay all responses by 7 seconds (between the 5-second stream timeout and 10-second RPC timeout)
3. Start a validator node that needs to bootstrap or sync state

**Expected Behavior (Current):**
```
1. Validator creates state sync stream
2. Stream selects malicious peer for data
3. Malicious peer delays response by 7 seconds
4. Stream timeout occurs (no data received within 5 seconds)
5. Step 4 repeats 11 more times (total: 12 consecutive timeouts)
6. CriticalDataStreamTimeout triggered after 60 seconds
7. Stream reset with NO peer score penalty
8. New stream created, may select same malicious peer
9. Cycle repeats - validator makes no progress
```

**Rust Reproduction (Pseudocode):**

```rust
// In a test environment, simulate malicious peer behavior:

#[tokio::test]
async fn test_critical_timeout_no_peer_penalty() {
    // Setup: Create streaming service with mock malicious peer
    let mut malicious_peer = create_mock_peer_with_delay(Duration::from_secs(7));
    let validator = create_test_validator();
    
    // Track initial peer score
    let initial_score = validator.get_peer_score(malicious_peer.id);
    
    // Attempt to sync state
    let sync_result = timeout(
        Duration::from_secs(100),
        validator.bootstrap_state_sync()
    ).await;
    
    // Verify: CriticalDataStreamTimeout occurred
    assert!(matches!(sync_result, Err(_))); // Timeout occurred
    
    // Verify: Peer score was NOT penalized (this is the bug)
    let final_score = validator.get_peer_score(malicious_peer.id);
    assert_eq!(initial_score, final_score); // Score unchanged!
    
    // Expected: Score should have been reduced significantly
    // assert!(final_score < IGNORE_PEER_THRESHOLD); // Should be below 25.0
}
```

**Detection in Production:**
Operators can detect this attack by monitoring:
- High frequency of `CriticalDataStreamTimeout` errors in logs
- Validators repeatedly restarting state sync streams without progress
- Specific peers consistently associated with slow responses
- Gap between validator sync version and network latest version remaining constant

---

**Notes:**

The vulnerability exploits the gap between two timeout mechanisms: the RPC-level timeout (which triggers peer scoring) and the stream-level notification timeout (which does not). By carefully timing responses to avoid the former while triggering the latter, malicious peers can cause indefinite sync failures without reputation consequences.

### Citations

**File:** state-sync/state-sync-driver/src/utils.rs (L200-238)
```rust
pub async fn get_data_notification(
    max_stream_wait_time_ms: u64,
    max_num_stream_timeouts: u64,
    active_data_stream: Option<&mut DataStreamListener>,
) -> Result<DataNotification, Error> {
    let active_data_stream = active_data_stream
        .ok_or_else(|| Error::UnexpectedError("The active data stream does not exist!".into()))?;

    let timeout_ms = Duration::from_millis(max_stream_wait_time_ms);
    if let Ok(data_notification) = timeout(timeout_ms, active_data_stream.select_next_some()).await
    {
        // Update the metrics for the data notification receive latency
        metrics::observe_duration(
            &metrics::DATA_NOTIFICATION_LATENCIES,
            metrics::NOTIFICATION_CREATE_TO_RECEIVE,
            data_notification.creation_time,
        );

        // Reset the number of consecutive timeouts for the data stream
        active_data_stream.num_consecutive_timeouts = 0;
        Ok(data_notification)
    } else {
        // Increase the number of consecutive timeouts for the data stream
        active_data_stream.num_consecutive_timeouts += 1;

        // Check if we've timed out too many times
        if active_data_stream.num_consecutive_timeouts >= max_num_stream_timeouts {
            Err(Error::CriticalDataStreamTimeout(format!(
                "{:?}",
                max_num_stream_timeouts
            )))
        } else {
            Err(Error::DataStreamNotificationTimeout(format!(
                "{:?}",
                timeout_ms
            )))
        }
    }
}
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L583-598)
```rust
    async fn fetch_next_data_notification(&mut self) -> Result<DataNotification, Error> {
        let max_stream_wait_time_ms = self.driver_configuration.config.max_stream_wait_time_ms;
        let max_num_stream_timeouts = self.driver_configuration.config.max_num_stream_timeouts;
        let result = utils::get_data_notification(
            max_stream_wait_time_ms,
            max_num_stream_timeouts,
            self.active_data_stream.as_mut(),
        )
        .await;
        if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
            // If the stream has timed out too many times, we need to reset it
            warn!("Resetting the currently active data stream due to too many timeouts!");
            self.reset_active_stream(None).await?;
        }
        result
    }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L202-250)
```rust
    fn process_terminate_stream_request(
        &mut self,
        terminate_request: &TerminateStreamRequest,
    ) -> Result<(), Error> {
        // Grab the stream id and feedback
        let data_stream_id = &terminate_request.data_stream_id;
        let notification_and_feedback = &terminate_request.notification_and_feedback;

        // Increment the stream termination counter
        let feedback_label = match notification_and_feedback {
            Some(notification_and_feedback) => {
                notification_and_feedback.notification_feedback.get_label()
            },
            None => TERMINATE_NO_FEEDBACK,
        };
        metrics::increment_counter(&metrics::TERMINATE_DATA_STREAM, feedback_label);

        // Remove the data stream
        if let Some(data_stream) = self.data_streams.remove(data_stream_id) {
            info!(LogSchema::new(LogEntry::HandleTerminateRequest)
                .stream_id(*data_stream_id)
                .event(LogEvent::Success)
                .message(&format!(
                    "Terminating the data stream with ID: {:?}. Notification and feedback: {:?}",
                    data_stream_id, notification_and_feedback,
                )));

            // Handle any notification feedback
            if let Some(notification_and_feedback) = notification_and_feedback {
                let notification_id = &notification_and_feedback.notification_id;
                let feedback = &notification_and_feedback.notification_feedback;
                if data_stream.sent_notification(notification_id) {
                    data_stream.handle_notification_feedback(notification_id, feedback)?;
                    Ok(())
                } else {
                    Err(Error::UnexpectedErrorEncountered(format!(
                        "Data stream ID: {:?} did not appear to send notification ID: {:?}",
                        data_stream_id, notification_id,
                    )))
                }
            } else {
                Ok(())
            }
        } else {
            Err(Error::UnexpectedErrorEncountered(format!(
                "Unable to find data stream with ID: {:?}. Notification and feedback: {:?}",
                data_stream_id, notification_and_feedback,
            )))
        }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/client.rs (L872-880)
```rust
    fn notify_bad_response(
        &self,
        _id: ResponseId,
        peer: PeerNetworkId,
        _request: &StorageServiceRequest,
        error_type: ErrorType,
    ) {
        self.peer_states.update_score_error(peer, error_type);
    }
```

**File:** config/src/config/state_sync_config.rs (L134-152)
```rust
impl Default for StateSyncDriverConfig {
    fn default() -> Self {
        Self {
            bootstrapping_mode: BootstrappingMode::ExecuteOrApplyFromGenesis,
            commit_notification_timeout_ms: 5000,
            continuous_syncing_mode: ContinuousSyncingMode::ExecuteTransactionsOrApplyOutputs,
            enable_auto_bootstrapping: false,
            fallback_to_output_syncing_secs: 180, // 3 minutes
            progress_check_interval_ms: 100,
            max_connection_deadline_secs: 10,
            max_consecutive_stream_notifications: 10,
            max_num_stream_timeouts: 12,
            max_pending_data_chunks: 50,
            max_pending_mempool_notifications: 100,
            max_stream_wait_time_ms: 5000,
            num_versions_to_skip_snapshot_sync: 400_000_000, // At 5k TPS, this allows a node to fail for about 24 hours.
        }
    }
}
```

**File:** config/src/config/state_sync_config.rs (L460-484)
```rust
impl Default for AptosDataClientConfig {
    fn default() -> Self {
        Self {
            enable_transaction_data_v2: true,
            data_poller_config: AptosDataPollerConfig::default(),
            data_multi_fetch_config: AptosDataMultiFetchConfig::default(),
            ignore_low_score_peers: true,
            latency_filtering_config: AptosLatencyFilteringConfig::default(),
            latency_monitor_loop_interval_ms: 100,
            max_epoch_chunk_size: MAX_EPOCH_CHUNK_SIZE,
            max_num_output_reductions: 0,
            max_optimistic_fetch_lag_secs: 20, // 20 seconds
            max_response_bytes: CLIENT_MAX_MESSAGE_SIZE_V2 as u64,
            max_response_timeout_ms: 60_000, // 60 seconds
            max_state_chunk_size: MAX_STATE_CHUNK_SIZE,
            max_subscription_lag_secs: 20, // 20 seconds
            max_transaction_chunk_size: MAX_TRANSACTION_CHUNK_SIZE,
            max_transaction_output_chunk_size: MAX_TRANSACTION_OUTPUT_CHUNK_SIZE,
            optimistic_fetch_timeout_ms: 5000,         // 5 seconds
            progress_check_max_stall_time_secs: 86400, // 24 hours (long enough to debug any issues at runtime)
            response_timeout_ms: 10_000,               // 10 seconds
            subscription_response_timeout_ms: 15_000, // 15 seconds (longer than a regular timeout because of prefetching)
            use_compression: true,
        }
    }
```
