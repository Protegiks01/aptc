# Audit Report

## Title
Lack of Size Validation on Persistent Consensus Objects Enables Potential DoS via Resource Exhaustion

## Summary
The persistent liveness storage implementation does not enforce maximum size limits when serializing and saving `Vote` or `TwoChainTimeoutCertificate` objects to disk. While network-level protections exist (64 MiB message limit) and BitVec deserialization enforces a maximum bucket limit, there are no explicit size checks during BCS serialization to persistent storage, creating a potential resource exhaustion vector if malformed objects are created through implementation bugs or fault injection.

## Finding Description
The `PersistentLivenessStorage` implementation in the consensus layer saves votes and timeout certificates to disk without validating their serialized size: [1](#0-0) [2](#0-1) 

Both methods call `bcs::to_bytes()` directly without checking the resulting byte array size. While `TwoChainTimeoutCertificate` contains a `Vec<Round>` that should match the number of voters in the aggregate signature: [3](#0-2) 

This invariant is only enforced during construction via the `assert_eq!` in the constructor, not during BCS deserialization. When loading from disk: [4](#0-3) 

BCS deserialization does not validate that `rounds.len()` matches `sig.get_num_voters()`, meaning a corrupted or malformed object could be loaded without immediate detection.

The `BitVec` component has deserialization protection: [5](#0-4) 

However, this only limits the BitVec to 8192 bytes. The `Vec<Round>` component could theoretically be arbitrarily large if deserialized from corrupted data, as each `Round` is 8 bytes and with 65536 maximum validators: [6](#0-5) 

This creates a maximum theoretical size of ~524 KB for the rounds vector alone, but without explicit validation, corrupted data could exceed this.

## Impact Explanation
This qualifies as **Medium Severity** per the Aptos bug bounty criteria for the following reasons:

1. **Resource Exhaustion**: If a malformed object with an oversized `Vec<Round>` is persisted (through a bug in aggregation logic or fault injection), it could cause:
   - Disk space exhaustion
   - Slow deserialization on node restart
   - Memory exhaustion during recovery
   
2. **State Inconsistencies**: A node that successfully saves but fails to load a malformed object would experience recovery failures, requiring manual intervention to restore consensus state.

3. **DoS Vector**: While not directly exploitable without a separate bug, the lack of size validation violates the **Resource Limits** invariant (#9) that "all operations must respect gas, storage, and computational limits."

The impact is limited to availability (DoS) rather than consensus safety or fund theft, placing it in the Medium severity category.

## Likelihood Explanation
The likelihood is **LOW to MEDIUM** due to the following factors:

**Mitigating factors:**
- Normal code paths properly construct TCs via `aggregate_signatures()` with correct sizes
- Network messages are limited to 64 MiB
- BitVec deserialization enforces size limits
- Individual timeout votes are verified before aggregation [7](#0-6) 

**Risk factors:**
- No defense-in-depth size validation before disk persistence
- BCS deserialization doesn't validate structural invariants
- A bug in the aggregation or vote creation logic could create oversized objects
- Fault injection during testing could trigger the issue

The attack requires either a software bug or ability to corrupt database files, making direct exploitation difficult but not impossible.

## Recommendation
Implement explicit size validation before serialization and after deserialization:

```rust
// In persistent_liveness_storage.rs
const MAX_VOTE_SIZE: usize = 100_000; // 100 KB reasonable limit
const MAX_TC_SIZE: usize = 1_000_000; // 1 MB reasonable limit

fn save_vote(&self, vote: &Vote) -> Result<()> {
    let bytes = bcs::to_bytes(vote)?;
    ensure!(
        bytes.len() <= MAX_VOTE_SIZE,
        "Vote serialized size {} exceeds maximum {}",
        bytes.len(),
        MAX_VOTE_SIZE
    );
    Ok(self.db.save_vote(bytes)?)
}

fn save_highest_2chain_timeout_cert(
    &self,
    highest_timeout_cert: &TwoChainTimeoutCertificate,
) -> Result<()> {
    let bytes = bcs::to_bytes(highest_timeout_cert)?;
    ensure!(
        bytes.len() <= MAX_TC_SIZE,
        "TC serialized size {} exceeds maximum {}",
        bytes.len(),
        MAX_TC_SIZE
    );
    Ok(self.db.save_highest_2chain_timeout_certificate(bytes)?)
}
```

Additionally, validate deserialized objects:

```rust
let highest_2chain_timeout_cert = raw_data.1.map(|b| {
    ensure!(b.len() <= MAX_TC_SIZE, "TC too large");
    let tc: TwoChainTimeoutCertificate = bcs::from_bytes(&b)?;
    // Validate invariant
    ensure!(
        tc.signatures_with_rounds().rounds().len() 
            == tc.signatures_with_rounds().sig().get_num_voters(),
        "TC rounds length mismatch"
    );
    Ok(tc)
}).transpose()?;
```

## Proof of Concept
This vulnerability requires triggering a bug in the TC creation logic. A theoretical PoC would involve:

1. **Fault injection** during TC aggregation to create a malformed object:
```rust
#[cfg(test)]
fn test_oversized_tc_dos() {
    // Create a malformed TC with oversized Vec<Round>
    let mut tc = create_valid_tc();
    
    // Use unsafe or reflection to inject oversized rounds vector
    // (In practice, this would come from a bug in aggregate_signatures)
    let malformed_rounds = vec![0u64; 1_000_000]; // 8 MB of rounds
    
    // Attempt to serialize - should fail with size limit
    let result = persistent_storage.save_highest_2chain_timeout_cert(&tc);
    assert!(result.is_err(), "Should reject oversized TC");
}
```

2. **Recovery DoS**: On node restart, loading the malformed TC would:
```rust
// During start() recovery
let highest_2chain_timeout_cert = raw_data.1.map(|b| {
    bcs::from_bytes(&b).expect("unable to deserialize") // Panics or consumes excessive memory
});
```

Without access to modify the aggregation logic or inject faults, a complete end-to-end PoC cannot be demonstrated, which limits the practical exploitability of this issue.

## Notes
While the lack of size limits is a legitimate defense-in-depth concern, the practical exploitability is limited by:
- Proper construction in normal code paths
- Network-level size limits  
- BitVec deserialization validation

This represents a code quality issue that could become critical if combined with a separate bug in the TC creation or vote generation logic. The recommendation adds important defense-in-depth protection against potential future vulnerabilities.

### Citations

**File:** consensus/src/persistent_liveness_storage.rs (L507-509)
```rust
    fn save_vote(&self, vote: &Vote) -> Result<()> {
        Ok(self.db.save_vote(bcs::to_bytes(vote)?)?)
    }
```

**File:** consensus/src/persistent_liveness_storage.rs (L526-532)
```rust
        let last_vote = raw_data
            .0
            .map(|bytes| bcs::from_bytes(&bytes[..]).expect("unable to deserialize last vote"));

        let highest_2chain_timeout_cert = raw_data.1.map(|b| {
            bcs::from_bytes(&b).expect("unable to deserialize highest 2-chain timeout cert")
        });
```

**File:** consensus/src/persistent_liveness_storage.rs (L598-604)
```rust
    fn save_highest_2chain_timeout_cert(
        &self,
        highest_timeout_cert: &TwoChainTimeoutCertificate,
    ) -> Result<()> {
        Ok(self
            .db
            .save_highest_2chain_timeout_certificate(bcs::to_bytes(highest_timeout_cert)?)?)
```

**File:** consensus/consensus-types/src/timeout_2chain.rs (L354-363)
```rust
pub struct AggregateSignatureWithRounds {
    sig: AggregateSignature,
    rounds: Vec<Round>,
}

impl AggregateSignatureWithRounds {
    pub fn new(sig: AggregateSignature, rounds: Vec<Round>) -> Self {
        assert_eq!(sig.get_num_voters(), rounds.len());
        Self { sig, rounds }
    }
```

**File:** crates/aptos-bitvec/src/lib.rs (L247-249)
```rust
        if v.len() > MAX_BUCKETS {
            return Err(D::Error::custom(format!("BitVec too long: {}", v.len())));
        }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L100-100)
```text
    const MAX_VALIDATOR_SET_SIZE: u64 = 65536;
```

**File:** consensus/src/round_manager.rs (L147-154)
```rust
            UnverifiedEvent::RoundTimeoutMsg(v) => {
                if !self_message {
                    v.verify(validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["timeout"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::RoundTimeoutMsg(v)
```
