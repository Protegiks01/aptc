# Audit Report

## Title
Unbounded Concurrent Batch Fetches Enable Validator DoS via Resource Exhaustion

## Summary
A malicious proposer can craft a block containing hundreds or thousands of small unique batches, causing other validators to spawn unbounded concurrent tokio tasks and network connections when fetching missing batches. This can exhaust file descriptors, saturate network bandwidth, and overwhelm the tokio runtime, resulting in validator node slowdowns or failures.

## Finding Description

The vulnerability exists in the batch fetching mechanism when validators receive block proposals containing many batches they don't have locally.

**Attack Flow:**

1. A malicious proposer creates many small batches (e.g., 1-5 transactions each) and gets them certified through the normal quorum store protocol.

2. When elected as proposer, they include all these batches in their block proposal (e.g., 500-1000 unique batch digests).

3. Other validators receive the block proposal and call `get_transactions()` to fetch the transaction data.

4. In `request_transactions()`, a future is created for EACH batch without any concurrency limit: [1](#0-0) 

5. All futures are awaited concurrently via `join_all()`: [2](#0-1) 

6. For each unique batch digest, `get_or_fetch_batch()` spawns a tokio task: [3](#0-2) 

7. Each spawned task calls `request_batch()` which creates network requests to multiple peers (default 5 per `batch_request_num_peers`): [4](#0-3) 

**Resource Exhaustion:**

With 1000 unique batches in a block:
- 1000 concurrent tokio tasks spawned
- Up to 5000 concurrent network connections (1000 batches Ã— 5 peers)
- Each connection consumes a file descriptor
- High CPU usage from task scheduling
- Network bandwidth saturation from parallel fetch requests

**Missing Safeguards:**

The `pull_proofs()` function limits blocks by total transaction count and byte size but NOT by the number of proofs: [5](#0-4) 

There is no limit on concurrent batch fetches or spawned tasks in the payload manager or batch store implementation.

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty program because it enables "Validator node slowdowns."

**Direct Impacts:**
- **File Descriptor Exhaustion**: Systems have finite file descriptor limits (often 1024-65535). Thousands of concurrent connections can exhaust this limit, causing all new connections (including consensus messages) to fail.
- **Network Bandwidth Saturation**: Fetching hundreds of batches simultaneously can consume all available bandwidth, delaying critical consensus messages.
- **CPU Overload**: Spawning and scheduling thousands of tokio tasks creates significant CPU overhead.
- **Memory Pressure**: Each task and connection has memory overhead that accumulates.

**Consensus Impact:**
- Affected validators may fail to process proposals or votes in time
- Could cause validators to miss rounds, reducing liveness
- If enough validators are affected, could temporarily halt block production

**Network-Wide Effect:**
- Attack affects ALL validators except the malicious proposer
- Can be repeated every time the attacker is elected proposer
- Difficult to rate-limit since batch requests are legitimate protocol operations

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements:**
- Must be a validator (requires stake but network is permissionless)
- Must wait to be elected proposer (happens naturally via VRF rotation)
- Can create batches with normal validator operations (no special privileges needed)

**Attack Feasibility:**
- Creating many small batches is straightforward - simply batch 1-2 transactions each
- Getting batches certified happens through normal protocol (honest validators will sign valid batches)
- No complex timing or race conditions required
- Attack is repeatable whenever attacker is elected proposer

**Detection Difficulty:**
- Batches appear legitimate (contain valid transactions)
- Block passes all validation checks (transaction limits, byte size limits, signature verification)
- Resource exhaustion is the only symptom, which could be mistaken for network issues

**Configuration Enables Attack:**
The default configuration facilitates this attack:
- `batch_request_num_peers: 5` (each fetch hits 5 peers)
- No limit on proofs per block beyond transaction/byte constraints
- No semaphore or rate limiting on concurrent fetches [6](#0-5) 

## Recommendation

**Immediate Mitigations:**

1. **Limit Maximum Proofs Per Block** - Add explicit limit on number of proofs/batches:
```rust
// In batch_proof_queue.rs pull_internal()
const MAX_PROOFS_PER_BLOCK: usize = 100;

// Add check before adding batch to result:
if result.len() >= MAX_PROOFS_PER_BLOCK {
    full = true;
    return false;
}
```

2. **Bounded Concurrency for Fetches** - Use a semaphore to limit concurrent batch fetches:
```rust
// In quorum_store_payload_manager.rs
use tokio::sync::Semaphore;

// Add to QuorumStorePayloadManager:
fetch_semaphore: Arc<Semaphore>,  // e.g., new(50) for max 50 concurrent fetches

// In request_and_wait_transactions():
for future in futures {
    let permit = batch_reader.acquire_fetch_permit().await;
    let result = future.await?;
    drop(permit);
    all_txns.append(&mut result);
}
```

3. **Per-Peer Connection Limits** - Limit concurrent connections per remote peer.

4. **Block Proposal Validation** - Reject blocks with excessive proof counts during validation:
```rust
// In block.rs verify_well_formed():
if let Some(payload) = self.payload() {
    payload.verify_epoch(self.epoch())?;
    
    // Add proof count validation
    let (num_proofs, _, _) = self.proof_stats();
    ensure!(
        num_proofs <= MAX_PROOFS_PER_BLOCK,
        "Block contains too many proofs: {}", num_proofs
    );
}
```

**Configuration Changes:**
Add to `QuorumStoreConfig`:
```rust
pub max_proofs_per_block: usize,  // default: 100
pub max_concurrent_batch_fetches: usize,  // default: 50
```

## Proof of Concept

```rust
// Rust PoC outline - demonstrates resource exhaustion potential

#[tokio::test]
async fn test_concurrent_fetch_dos() {
    // Setup: Create validator with QuorumStore
    let (validator, batch_store, batch_requester) = setup_validator();
    
    // Attacker: Create block with many small batches
    let mut proofs = Vec::new();
    for i in 0..1000 {
        // Create batch with 1 transaction
        let batch = create_batch_with_n_txns(1);
        let proof = certify_batch(batch).await;
        proofs.push(proof);
    }
    
    let block = create_block_with_proofs(proofs);
    
    // Victim: Receive block and trigger fetches
    let start = Instant::now();
    let fetch_tasks = validator.get_transactions(&block).await;
    
    // Measure resource usage
    assert!(fetch_tasks.len() == 1000, "Should spawn 1000 tasks");
    
    // Monitor file descriptors
    let fd_count = count_open_file_descriptors();
    assert!(fd_count > 5000, "Should open many connections");
    
    // Verify slowdown
    let elapsed = start.elapsed();
    assert!(elapsed > Duration::from_secs(10), "Should cause significant delay");
}

// Demonstrate mitigation effectiveness
#[tokio::test]
async fn test_bounded_fetch_prevents_dos() {
    let validator = setup_validator_with_fetch_limit(50);
    
    let block = create_block_with_n_proofs(1000);
    
    let start = Instant::now();
    validator.get_transactions(&block).await;
    
    // With semaphore limiting to 50 concurrent fetches
    let active_tasks = validator.active_fetch_tasks();
    assert!(active_tasks <= 50, "Should respect concurrency limit");
    
    let fd_count = count_open_file_descriptors();
    assert!(fd_count < 500, "Should have reasonable connection count");
}
```

**Notes:**
- The vulnerability breaks the **Resource Limits** invariant (operations must respect computational limits)
- Attack works because proof count limits are absent while transaction/byte limits alone are insufficient
- Mitigation requires both proposal-time validation and fetch-time concurrency controls
- The deduplication mechanism helps but doesn't prevent the initial resource spike for unique batches

### Citations

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L89-109)
```rust
    fn request_transactions(
        batches: Vec<(BatchInfo, Vec<PeerId>)>,
        block_timestamp: u64,
        batch_reader: Arc<dyn BatchReader>,
    ) -> Vec<Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>>>
    {
        let mut futures = Vec::new();
        for (batch_info, responders) in batches {
            trace!(
                "QSE: requesting batch {:?}, time = {}",
                batch_info,
                block_timestamp
            );
            if block_timestamp <= batch_info.expiration() {
                futures.push(batch_reader.get_batch(batch_info, responders.clone()));
            } else {
                debug!("QSE: skipped expired batch {}", batch_info.digest());
            }
        }
        futures
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L111-122)
```rust
    async fn request_and_wait_transactions(
        batches: Vec<(BatchInfo, Vec<PeerId>)>,
        block_timestamp: u64,
        batch_reader: Arc<dyn BatchReader>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let futures = Self::request_transactions(batches, block_timestamp, batch_reader);
        let mut all_txns = Vec::new();
        for result in futures::future::join_all(futures).await {
            all_txns.append(&mut result?);
        }
        Ok(all_txns)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L714-714)
```rust
                tokio::spawn(fut.clone());
```

**File:** consensus/src/quorum_store/batch_requester.rs (L127-127)
```rust
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L651-657)
```rust
                        if cur_all_txns + batch.size() > max_txns
                            || unique_txns > max_txns_after_filtering
                        {
                            // Exceeded the limit for requested bytes or number of transactions.
                            full = true;
                            return false;
                        }
```

**File:** config/src/config/quorum_store_config.rs (L127-127)
```rust
            batch_request_num_peers: 5,
```
