# Audit Report

## Title
Computational DoS via SyncInfo Verification Amplification in Vote Message Processing

## Summary
The consensus layer's optimization to avoid O(n^2) signature verifications during vote aggregation creates an attack vector where a malicious validator can send votes with crafted SyncInfo containing invalid certificates with high round numbers, forcing victim validators to perform expensive signature verification operations (O(n*m) complexity) before detecting invalidity, causing computational denial-of-service.

## Finding Description

The vulnerability exists in the vote message processing flow where `VoteMsg.verify()` intentionally skips SyncInfo verification to avoid O(n^2) complexity during vote aggregation, deferring validation to `sync_up()`. [1](#0-0) 

However, the deferred verification in `sync_up()` only occurs when `has_newer_certificates()` returns true, which merely checks round numbers without validating certificate authenticity: [2](#0-1) [3](#0-2) 

The `has_newer_certificates()` function only compares round numbers and does not validate signatures. A Byzantine validator can craft malicious VoteMsg messages containing:
1. A valid Vote (properly signed by their validator key)
2. A SyncInfo with fabricated certificates containing fake high round numbers and invalid aggregate signatures

When processed, each malicious vote triggers expensive verification of all certificates in the SyncInfo: [4](#0-3) 

Each SyncInfo can contain up to 4 certificates (highest_quorum_cert, highest_ordered_cert, highest_commit_cert, highest_2chain_timeout_cert), and each certificate can contain aggregate signatures from the entire validator set. The verification calls expensive cryptographic operations: [5](#0-4) [6](#0-5) [7](#0-6) 

**Attack Flow:**
1. Byzantine validator crafts k VoteMsg messages per second, each with unique SyncInfo containing fabricated certificates with high round numbers but invalid signatures
2. Victim validator receives votes and calls `VoteMsg.verify()` which validates vote signatures but skips SyncInfo
3. Each vote reaches `sync_up()` where `has_newer_certificates()` returns true (due to fake high rounds)
4. `sync_info.verify()` is invoked, performing expensive aggregate signature verification on all 4 certificates
5. Verification fails after computational cost is incurred
6. Error is logged but no automatic rate limiting or validator banning occurs [8](#0-7) 

**Computational Amplification:**
- Attacker work: O(k) - sign k votes
- Victim work: O(k * m) - verify k SyncInfos each with m signatures (m â‰¤ 4 * validator_set_size)
- For validator_set_size=100 and k=10 votes/sec: attacker performs 10 sig/sec, victim performs ~4000 verifications/sec

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria:
- **Validator node slowdowns**: Excessive CPU consumption on signature verification prevents timely consensus participation, degrading network performance
- **Resource Limits Violation**: Breaks invariant #9 requiring all operations to respect computational limits - a single Byzantine validator can force unbounded computation on honest validators
- **Liveness Impact**: If multiple validators are targeted simultaneously, consensus rounds may timeout due to validators being CPU-bound, reducing network throughput or causing temporary liveness failures

The attack does not cause permanent network partition or loss of funds (Critical), but significantly impacts validator performance and consensus efficiency (High).

## Likelihood Explanation

**Likelihood: Medium-High**

**Requirements:**
- Attacker must control a validator (or compromise validator keys)
- In Aptos' Byzantine fault tolerance model, up to 1/3 of validators can be malicious
- Validator sets contain 100+ validators, making compromise of at least one realistic

**Attack Complexity: Low**
- Simple to execute: craft votes with valid signatures but invalid SyncInfo
- No coordination with other validators required
- No exploitation of race conditions or timing dependencies
- Sustained attack possible as long as validator keys are held

**Mitigations Present: Minimal**
- No per-peer rate limiting on vote messages from validators
- No SyncInfo verification result caching
- Security events logged but no automatic banning mechanism [9](#0-8) 

## Recommendation

Implement early validation and rate limiting for SyncInfo in VoteMsg processing:

**1. Add SyncInfo round sanity checking before expensive verification:**
```rust
// In sync_up() before verify()
if sync_info.has_newer_certificates(&local_sync_info) {
    // Add sanity check: reject SyncInfo with rounds too far ahead
    let local_highest = local_sync_info.highest_round();
    let remote_highest = sync_info.highest_round();
    const MAX_ACCEPTABLE_ROUND_GAP: u64 = 1000; // Configurable threshold
    
    ensure!(
        remote_highest <= local_highest + MAX_ACCEPTABLE_ROUND_GAP,
        "SyncInfo round {} too far ahead of local round {}",
        remote_highest,
        local_highest
    );
    
    sync_info.verify(&self.epoch_state.verifier)?;
    // ... rest of processing
}
```

**2. Implement per-validator rate limiting for invalid SyncInfo:**
```rust
// Track failed SyncInfo verifications per peer
struct PeerTracker {
    failed_sync_info_count: HashMap<Author, (u64, Instant)>,
}

// Before expensive verification
if let Some((count, last_time)) = self.peer_tracker.failed_sync_info_count.get(&author) {
    if last_time.elapsed() < Duration::from_secs(60) && *count > 5 {
        bail!("Too many invalid SyncInfo from peer {} in recent window", author);
    }
}

// After verification failure
self.peer_tracker.record_invalid_sync_info(author);
```

**3. Add SyncInfo hash-based deduplication cache:**
```rust
// Cache recently verified SyncInfo by hash to avoid re-verification
let sync_info_hash = sync_info.hash();
if self.verified_sync_info_cache.contains(&sync_info_hash) {
    return Ok(()); // Already verified
}
sync_info.verify(&self.epoch_state.verifier)?;
self.verified_sync_info_cache.insert(sync_info_hash);
```

## Proof of Concept

```rust
// Rust PoC demonstrating the attack
#[test]
fn test_syncinfo_dos_attack() {
    use consensus_types::{vote_msg::VoteMsg, vote::Vote, sync_info::SyncInfo};
    use aptos_types::validator_verifier::ValidatorVerifier;
    
    // Setup validator set
    let validator_set_size = 100;
    let (validator_signer, validator_verifier) = 
        ValidatorVerifier::new_with_fake_signers(validator_set_size);
    
    // Attacker is a valid validator
    let attacker_signer = &validator_signer[0];
    
    // Craft malicious votes with fake SyncInfo
    let num_malicious_votes = 1000;
    let mut malicious_votes = vec![];
    
    for i in 0..num_malicious_votes {
        // Create valid vote (attacker signs it)
        let vote_data = VoteData::new(/* valid block at round 100 */);
        let ledger_info = LedgerInfo::new(/* ... */);
        let vote = Vote::new(vote_data, attacker_signer.author(), ledger_info, attacker_signer)?;
        
        // Create fake SyncInfo with high round numbers and invalid signatures
        let fake_qc = QuorumCert::new(
            VoteData::new(/* fake block at round 10000 + i */),
            LedgerInfoWithSignatures::new(
                LedgerInfo::dummy(),
                AggregateSignature::dummy(), // Invalid signature
            )
        );
        
        let fake_sync_info = SyncInfo::new(
            fake_qc,
            /* fake ordered cert with invalid sig */,
            /* fake timeout cert with invalid sig */,
        );
        
        let malicious_vote_msg = VoteMsg::new(vote, fake_sync_info);
        malicious_votes.push(malicious_vote_msg);
    }
    
    // Measure victim processing time
    let start = Instant::now();
    let mut round_manager = RoundManager::new(/* ... */);
    
    for vote_msg in malicious_votes {
        // This will verify the vote (passes) but then verify SyncInfo (expensive, fails)
        let _ = round_manager.process_vote_msg(vote_msg).await;
    }
    
    let elapsed = start.elapsed();
    
    // With 1000 votes, each with ~400 signatures to verify (4 certs * 100 validators)
    // Expected: ~400,000 signature verifications performed before all fail
    // This would take several seconds and consume significant CPU
    assert!(elapsed.as_secs() > 5, "Attack should cause significant delay");
}
```

## Notes

The vulnerability exploits the legitimate optimization to avoid O(n^2) complexity during vote aggregation. The fix must balance DoS protection with preserving the performance benefit of deferred SyncInfo verification. The recommended mitigations (round gap limits, rate limiting, caching) maintain the optimization for legitimate traffic while blocking abuse without requiring changes to the core consensus protocol.

### Citations

**File:** consensus/consensus-types/src/vote_msg.rs (L77-80)
```rust
        // We're not verifying SyncInfo here yet: we are going to verify it only in case we need
        // it. This way we avoid verifying O(n) SyncInfo messages while aggregating the votes
        // (O(n^2) signature verifications).
        self.vote().verify(validator)
```

**File:** consensus/src/round_manager.rs (L878-906)
```rust
    async fn sync_up(&mut self, sync_info: &SyncInfo, author: Author) -> anyhow::Result<()> {
        let local_sync_info = self.block_store.sync_info();
        if sync_info.has_newer_certificates(&local_sync_info) {
            info!(
                self.new_log(LogEvent::ReceiveNewCertificate)
                    .remote_peer(author),
                "Local state {},\n remote state {}", local_sync_info, sync_info
            );
            // Some information in SyncInfo is ahead of what we have locally.
            // First verify the SyncInfo (didn't verify it in the yet).
            sync_info.verify(&self.epoch_state.verifier).map_err(|e| {
                error!(
                    SecurityEvent::InvalidSyncInfoMsg,
                    sync_info = sync_info,
                    remote_peer = author,
                    error = ?e,
                );
                VerifyError::from(e)
            })?;
            SYNC_INFO_RECEIVED_WITH_NEWER_CERT.inc();
            let result = self
                .block_store
                .add_certs(sync_info, self.create_block_retriever(author))
                .await;
            self.process_certificates().await?;
            result
        } else {
            Ok(())
        }
```

**File:** consensus/consensus-types/src/sync_info.rs (L138-211)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let epoch = self.highest_quorum_cert.certified_block().epoch();
        ensure!(
            epoch == self.highest_ordered_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HQC"
        );
        ensure!(
            epoch == self.highest_commit_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HCC"
        );
        if let Some(tc) = &self.highest_2chain_timeout_cert {
            ensure!(epoch == tc.epoch(), "Multi epoch in SyncInfo - TC and HQC");
        }

        ensure!(
            self.highest_quorum_cert.certified_block().round()
                >= self.highest_ordered_cert().commit_info().round(),
            "HQC has lower round than HOC"
        );

        ensure!(
            self.highest_ordered_round() >= self.highest_commit_round(),
            format!(
                "HOC {} has lower round than HLI {}",
                self.highest_ordered_cert(),
                self.highest_commit_cert()
            )
        );

        ensure!(
            *self.highest_ordered_cert().commit_info() != BlockInfo::empty(),
            "HOC has no committed block"
        );

        ensure!(
            *self.highest_commit_cert().commit_info() != BlockInfo::empty(),
            "HLI has empty commit info"
        );

        // we don't have execution in unit tests, so this check would fail
        #[cfg(not(any(test, feature = "fuzzing")))]
        {
            ensure!(
                !self.highest_commit_cert().commit_info().is_ordered_only(),
                "HLI {} has ordered only commit info",
                self.highest_commit_cert().commit_info()
            );
        }

        self.highest_quorum_cert
            .verify(validator)
            .and_then(|_| {
                self.highest_ordered_cert
                    .as_ref()
                    .map_or(Ok(()), |cert| cert.verify(validator))
                    .context("Fail to verify ordered certificate")
            })
            .and_then(|_| {
                // we do not verify genesis ledger info
                if self.highest_commit_cert.commit_info().round() > 0 {
                    self.highest_commit_cert
                        .verify(validator)
                        .context("Fail to verify commit certificate")?
                }
                Ok(())
            })
            .and_then(|_| {
                if let Some(tc) = &self.highest_2chain_timeout_cert {
                    tc.verify(validator)?;
                }
                Ok(())
            })
            .context("Fail to verify SyncInfo")?;
        Ok(())
```

**File:** consensus/consensus-types/src/sync_info.rs (L218-223)
```rust
    pub fn has_newer_certificates(&self, other: &SyncInfo) -> bool {
        self.highest_certified_round() > other.highest_certified_round()
            || self.highest_timeout_round() > other.highest_timeout_round()
            || self.highest_ordered_round() > other.highest_ordered_round()
            || self.highest_commit_round() > other.highest_commit_round()
    }
```

**File:** consensus/consensus-types/src/quorum_cert.rs (L119-148)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let vote_hash = self.vote_data.hash();
        ensure!(
            self.ledger_info().ledger_info().consensus_data_hash() == vote_hash,
            "Quorum Cert's hash mismatch LedgerInfo"
        );
        // Genesis's QC is implicitly agreed upon, it doesn't have real signatures.
        // If someone sends us a QC on a fake genesis, it'll fail to insert into BlockStore
        // because of the round constraint.
        if self.certified_block().round() == 0 {
            ensure!(
                self.parent_block() == self.certified_block(),
                "Genesis QC has inconsistent parent block with certified block"
            );
            ensure!(
                self.certified_block() == self.ledger_info().ledger_info().commit_info(),
                "Genesis QC has inconsistent commit block with certified block"
            );
            ensure!(
                self.ledger_info().get_num_voters() == 0,
                "Genesis QC should not carry signatures"
            );
            return Ok(());
        }
        self.ledger_info()
            .verify_signatures(validator)
            .context("Fail to verify QuorumCert")?;
        self.vote_data.verify()?;
        Ok(())
    }
```

**File:** consensus/consensus-types/src/wrapped_ledger_info.rs (L90-108)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        // Genesis's QC is implicitly agreed upon, it doesn't have real signatures.
        // If someone sends us a QC on a fake genesis, it'll fail to insert into BlockStore
        // because of the round constraint.

        // TODO: Earlier, we were comparing self.certified_block().round() to 0. Now, we are
        // comparing self.ledger_info().ledger_info().round() to 0. Is this okay?
        if self.ledger_info().ledger_info().round() == 0 {
            ensure!(
                self.ledger_info().get_num_voters() == 0,
                "Genesis QC should not carry signatures"
            );
            return Ok(());
        }
        self.ledger_info()
            .verify_signatures(validator)
            .context("Fail to verify WrappedLedgerInfo")?;
        Ok(())
    }
```

**File:** consensus/consensus-types/src/timeout_2chain.rs (L141-175)
```rust
    pub fn verify(&self, validators: &ValidatorVerifier) -> anyhow::Result<()> {
        let hqc_round = self.timeout.hqc_round();
        // Verify the highest timeout validity.
        let (timeout_result, sig_result) = rayon::join(
            || self.timeout.verify(validators),
            || {
                let timeout_messages: Vec<_> = self
                    .signatures_with_rounds
                    .get_voters_and_rounds(
                        &validators
                            .get_ordered_account_addresses_iter()
                            .collect_vec(),
                    )
                    .into_iter()
                    .map(|(_, round)| TimeoutSigningRepr {
                        epoch: self.timeout.epoch(),
                        round: self.timeout.round(),
                        hqc_round: round,
                    })
                    .collect();
                let timeout_messages_ref: Vec<_> = timeout_messages.iter().collect();
                validators.verify_aggregate_signatures(
                    &timeout_messages_ref,
                    self.signatures_with_rounds.sig(),
                )
            },
        );
        timeout_result?;
        sig_result?;
        let signed_hqc = self
            .signatures_with_rounds
            .rounds()
            .iter()
            .max()
            .ok_or_else(|| anyhow::anyhow!("Empty rounds"))?;
```

**File:** crates/aptos-logger/src/security.rs (L52-53)
```rust
    /// Consensus received an invalid sync info message
    InvalidSyncInfoMsg,
```
