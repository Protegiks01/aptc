# Audit Report

## Title
V2 Event Primary Key Collision Causes Indexer Data Loss for Claim Events

## Summary
The indexer uses a composite primary key `(account_address, creation_number, sequence_number)` for storing events. V2 events (including Claim) are assigned dummy values (0x0, 0, 0) for these fields, causing all V2 Claim events to map to the same primary key. The `ON CONFLICT DO UPDATE` strategy only updates metadata fields (`inserted_at`, `event_index`) while silently discarding the actual event data from subsequent events, resulting in permanent data loss.

## Finding Description

The vulnerability stems from a schema design flaw in how V2 events are indexed. When V2 events were introduced via the `module_event_migration_enabled()` feature flag, the API layer assigns dummy GUID and sequence numbers to V2 events for backward compatibility: [1](#0-0) [2](#0-1) 

The Claim event is emitted as a V2 event when the migration flag is enabled: [3](#0-2) 

The indexer's Event model uses these dummy values as part of its primary key: [4](#0-3) 

The database schema enforces this as a composite primary key: [5](#0-4) 

When inserting events, the conflict resolution strategy only updates metadata: [6](#0-5) 

**Attack Propagation:**
1. User A creates a token offer and User B claims it, emitting a Claim V2 event with data (accountA, addressB, token1, amount1)
2. Indexer inserts this event with primary key (0x0, 0, 0) successfully
3. User C creates another offer and User D claims it, emitting a Claim V2 event with data (accountC, addressD, token2, amount2)
4. Indexer attempts to insert with the same primary key (0x0, 0, 0)
5. The `ON CONFLICT DO UPDATE` triggers, updating only `inserted_at` and `event_index`
6. The actual claim data (account, to_address, token_id, amount) from the second event is discarded
7. The database now contains a hybrid entry: the first event's data with the second event's metadata

This violates the **State Consistency** invariant, as the indexed state does not accurately reflect the blockchain's actual event history. Applications querying the indexer will only see the first Claim event, missing all subsequent claims.

## Impact Explanation

**Severity: Medium to High**

This issue causes:

1. **Data Loss**: All Claim events after the first one are not properly recorded in the indexer database. Only their `event_index` and `inserted_at` timestamps are updated, while the actual claim information (who claimed, which token, how much) is lost.

2. **State Inconsistencies**: The indexer state diverges from the actual blockchain state. Applications relying on the indexer (wallets, explorers, analytics platforms) will have incomplete and incorrect data.

3. **User Impact**: Users who successfully claimed tokens on-chain will not see their claims reflected in applications that query the indexer. This affects NFT platforms, token tracking tools, and any application displaying claim history.

4. **Application Failures**: dApps that depend on accurate claim event data for business logic (e.g., verifying ownership transfers, tracking token distribution) will malfunction.

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention" and "Limited funds loss or manipulation" (users' claim records are lost, though funds are not stolen on-chain).

Could be elevated to **High Severity** if this causes significant protocol violations affecting multiple applications ecosystem-wide.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability will manifest whenever:
- The `module_event_migration_enabled()` feature flag is enabled (production configuration)
- Multiple users execute claim transactions (normal network activity)
- The indexer processes these transactions

Given that:
1. Token claims are a common operation in NFT ecosystems
2. The feature flag migration to V2 events is actively being deployed
3. The vulnerability affects ALL V2 events, not just Claim events (including coin deposits/withdrawals, transfers, etc.)
4. No attacker action is required - normal user operations trigger the bug

This is a **100% reproducible** issue in production environments once multiple V2 events of the same type are emitted.

## Recommendation

**Immediate Fix**: Include `transaction_version` and `event_index` in the composite primary key to ensure uniqueness: [7](#0-6) 

Change the primary key annotation to:
```rust
#[diesel(primary_key(transaction_version, event_index))]
```

Or maintain backward compatibility by using a conditional primary key:
```rust
#[diesel(primary_key(account_address, creation_number, sequence_number, transaction_version, event_index))]
```

The schema migration should be:
```sql
ALTER TABLE events DROP CONSTRAINT events_pkey;
ALTER TABLE events ADD PRIMARY KEY (transaction_version, event_index);
-- Or for backward compatibility:
ALTER TABLE events ADD PRIMARY KEY (account_address, creation_number, sequence_number, transaction_version, event_index);
```

Update the insert logic to use the new primary key: [8](#0-7) 

Change to:
```rust
.on_conflict((transaction_version, event_index))
.do_nothing()  // Events should be immutable once inserted
```

**Alternative Solution**: For V2 events, generate synthetic but unique GUID values based on transaction_version and event_index during API conversion, instead of using dummy values.

## Proof of Concept

**Move Test Scenario:**

```move
#[test(creator = @0x1, user1 = @0x2, user2 = @0x3)]
public fun test_multiple_claim_events_indexer_collision(
    creator: signer,
    user1: signer,
    user2: signer,
) acquires PendingClaims {
    // Enable V2 events
    features::change_feature_flags(&framework_signer, vector[57], vector[]);
    
    // Setup accounts
    let creator_addr = signer::address_of(&creator);
    let user1_addr = signer::address_of(&user1);
    let user2_addr = signer::address_of(&user2);
    account::create_account_for_test(creator_addr);
    account::create_account_for_test(user1_addr);
    account::create_account_for_test(user2_addr);
    
    // Create two different tokens
    let token_id1 = create_token(&creator, 1);
    let token_id2 = create_token_with_name(&creator, b"Token2", 1);
    
    // First claim: creator offers to user1, user1 claims
    offer(&creator, user1_addr, token_id1, 1);
    claim(&user1, creator_addr, token_id1);  // Emits first Claim V2 event
    
    // Second claim: creator offers to user2, user2 claims
    offer(&creator, user2_addr, token_id2, 1);
    claim(&user2, creator_addr, token_id2);  // Emits second Claim V2 event
    
    // Both events emitted with (0x0, 0, 0) primary key
    // Indexer will only record the first claim, losing the second
}
```

**Rust Reproduction (Indexer):**

```rust
// Simulate indexer processing two Claim V2 events
let claim1 = Event {
    sequence_number: 0,  // DUMMY
    creation_number: 0,  // DUMMY
    account_address: "0x0000000000000000000000000000000000000000000000000000000000000000".to_string(),  // DUMMY
    transaction_version: 100,
    transaction_block_height: 50,
    type_: "0x3::token_transfers::Claim".to_string(),
    data: json!({"account": "0x1", "to_address": "0x2", "token_id": {...}, "amount": 1}),
    event_index: Some(0),
};

let claim2 = Event {
    sequence_number: 0,  // DUMMY (same as claim1)
    creation_number: 0,  // DUMMY (same as claim1)
    account_address: "0x0000000000000000000000000000000000000000000000000000000000000000".to_string(),  // DUMMY (same as claim1)
    transaction_version: 200,  // Different transaction
    transaction_block_height: 100,
    type_: "0x3::token_transfers::Claim".to_string(),
    data: json!({"account": "0x3", "to_address": "0x4", "token_id": {...}, "amount": 2}),
    event_index: Some(0),
};

// Insert both - the second will trigger ON CONFLICT
// Only claim1.data will be in the database, claim2.data is lost
```

## Notes

This vulnerability affects ALL V2 event types, not just Claim events. The issue impacts: CoinDeposit, CoinWithdraw, Transfer, TokenDeposit, TokenWithdraw, and all other V2 events introduced through the module event migration.

The question's framing as a "replay attack" is misleading - this is not about replaying events or transactions. Events cannot be independently replayed as they are deterministically produced during transaction execution. The actual vulnerability is a schema design flaw causing data loss through primary key collisions in the indexer database.

### Citations

**File:** api/types/src/transaction.rs (L48-52)
```rust
static DUMMY_GUID: Lazy<EventGuid> = Lazy::new(|| EventGuid {
    creation_number: U64::from(0u64),
    account_address: Address::from(AccountAddress::ZERO),
});
static DUMMY_SEQUENCE_NUMBER: Lazy<U64> = Lazy::new(|| U64::from(0));
```

**File:** api/types/src/transaction.rs (L886-891)
```rust
            ContractEvent::V2(v2) => Self {
                guid: *DUMMY_GUID,
                sequence_number: *DUMMY_SEQUENCE_NUMBER,
                typ: v2.type_tag().into(),
                data,
            },
```

**File:** aptos-move/framework/aptos-token/sources/token_transfers.move (L177-185)
```text
        if (std::features::module_event_migration_enabled()) {
            event::emit(
                Claim {
                    account: sender,
                    to_address: signer::address_of(receiver),
                    token_id,
                    amount,
                }
            )
```

**File:** crates/indexer/src/models/events.rs (L10-23)
```rust
#[derive(Associations, Debug, Deserialize, FieldCount, Identifiable, Insertable, Serialize)]
#[diesel(belongs_to(Transaction, foreign_key = transaction_version))]
#[diesel(primary_key(account_address, creation_number, sequence_number))]
#[diesel(table_name = events)]
pub struct Event {
    pub sequence_number: i64,
    pub creation_number: i64,
    pub account_address: String,
    pub transaction_version: i64,
    pub transaction_block_height: i64,
    pub type_: String,
    pub data: serde_json::Value,
    pub event_index: Option<i64>,
}
```

**File:** crates/indexer/src/schema.rs (L508-522)
```rust
diesel::table! {
    events (account_address, creation_number, sequence_number) {
        sequence_number -> Int8,
        creation_number -> Int8,
        #[max_length = 66]
        account_address -> Varchar,
        transaction_version -> Int8,
        transaction_block_height -> Int8,
        #[sql_name = "type"]
        type_ -> Text,
        data -> Jsonb,
        inserted_at -> Timestamp,
        event_index -> Nullable<Int8>,
    }
}
```

**File:** crates/indexer/src/processors/default_processor.rs (L276-296)
```rust
fn insert_events(
    conn: &mut PgConnection,
    items_to_insert: &[EventModel],
) -> Result<(), diesel::result::Error> {
    use schema::events::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), EventModel::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::events::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((account_address, creation_number, sequence_number))
                .do_update()
                .set((
                    inserted_at.eq(excluded(inserted_at)),
                    event_index.eq(excluded(event_index)),
                )),
            None,
        )?;
    }
    Ok(())
```
