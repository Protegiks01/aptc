# Audit Report

## Title
Panic in Database Restore Coordinator Due to Missing State Snapshot Validation

## Summary
The `RestoreCoordinator::run_impl()` function contains two `expect()` calls that panic when required state snapshots are not found in backup storage, causing the Tokio async runtime to crash during database restoration operations. This affects validator availability during disaster recovery scenarios. [1](#0-0) [2](#0-1) 

## Finding Description
The database restore process, invoked through the `aptos-debugger aptos-db restore` command, uses `RestoreCoordinator` to orchestrate restoration from backup storage. Within the async execution flow, the coordinator attempts to locate appropriate state snapshots by calling `select_state_snapshot()` on the metadata view.

The `select_state_snapshot()` method returns `Result<Option<StateSnapshotBackupMeta>>`, where `Ok(None)` indicates no snapshot exists at or before the requested version. [3](#0-2) 

However, the restore coordinator uses `.expect()` on these `Option` values without proper validation:

**First panic point:** When no in-progress snapshot is found, the code attempts to find a snapshot before the ledger history start version and panics if none exists. [4](#0-3) 

**Second panic point:** When attempting to locate a tree snapshot before the target version, the code panics if none is found. [5](#0-4) 

**Attack Vector:**
1. Validator operator initiates database restore with parameters pointing to incomplete/corrupted backup storage
2. Parameters specify `--target-version` that exceeds available snapshots
3. Or backup storage is missing critical state snapshots
4. `Command::run()` invokes `RestoreCoordinator::run()` which calls `run_impl().await`
5. When metadata view cannot find required snapshots, `expect()` panics inside async context
6. Panic propagates through the Tokio main runtime, crashing the entire process

The execution flow is fully async: [6](#0-5) [7](#0-6) [8](#0-7) 

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria for "Validator node slowdowns" and "Significant protocol violations."

**Operational Impact:**
- Validator operators attempting disaster recovery from backup experience immediate process crashes
- Failed restore attempts prevent validators from rejoining the network after database corruption or data loss
- Multiple failed restore attempts could significantly delay validator availability
- In coordinated incident scenarios (e.g., network-wide issue requiring multiple validators to restore), this could impact network liveness

**Scope Limitation:**
This does NOT crash running validator nodes during normal operation. The vulnerability only manifests during explicit database restoration procedures using the db-tool. However, database restoration is a critical operational capability for validator availability and disaster recovery.

## Likelihood Explanation
**Likelihood: Medium to High**

This issue will occur whenever:
1. Backup storage is incomplete or corrupted (e.g., failed backup operations, storage degradation)
2. Restore parameters are misconfigured (incorrect target version, wrong backup path)
3. Backup metadata is inconsistent with actual backup contents
4. Network interruptions cause partial backup downloads

These scenarios are realistic in production environments:
- Storage failures are common in distributed systems
- Configuration errors during incident response under pressure
- Backup corruption over time without verification
- Network issues during backup synchronization

The vulnerability is deterministic and easily triggered with malformed parameters, requiring no special privileges beyond access to run the db-tool.

## Recommendation
Replace `expect()` calls with proper error propagation using the `?` operator. The `select_state_snapshot()` method already returns a `Result`, allowing graceful error handling.

**Fix for lines 177-179:**
```rust
let kv_snapshot = match self.global_opt.run_mode.get_in_progress_state_kv_snapshot() {
    Ok(Some(ver)) => {
        if db_next_version >= ver {
            None
        } else {
            let snapshot = metadata_view.select_state_snapshot(ver)?;
            ensure!(
                snapshot.is_some() && snapshot.as_ref().unwrap().version == ver,
                "cannot find in-progress state snapshot {}",
                ver
            );
            snapshot
        }
    },
    Ok(None) | Err(_) => {
        assert_eq!(
            db_next_version, 0,
            "DB should be empty if no in-progress state snapshot found"
        );
        metadata_view
            .select_state_snapshot(std::cmp::min(lhs, max_txn_ver))?
            .ok_or_else(|| anyhow!("Cannot find any snapshot before ledger history start version {}", std::cmp::min(lhs, max_txn_ver)))?
    },
};
```

**Fix for lines 193-195:**
```rust
let tree_snapshot = if let Some((latest_tree_version, _)) = latest_tree_version {
    let snapshot = metadata_view.select_state_snapshot(latest_tree_version)?;
    ensure!(
        snapshot.is_some() && snapshot.as_ref().unwrap().version == latest_tree_version,
        "cannot find tree snapshot {}",
        latest_tree_version
    );
    snapshot.unwrap()
} else {
    metadata_view
        .select_state_snapshot(target_version)?
        .ok_or_else(|| anyhow!("Cannot find tree snapshot before target version {}", target_version))?
};
```

This ensures errors are propagated gracefully up the call stack, providing actionable error messages to operators rather than crashing the process.

## Proof of Concept

**Reproduction Steps:**

1. Create an empty or incomplete backup directory:
```bash
mkdir /tmp/empty_backup
mkdir /tmp/target_db
```

2. Run the restore command with parameters that will fail to find snapshots:
```bash
aptos-debugger aptos-db restore bootstrap-db \
    --target-db-dir /tmp/target_db \
    --local-fs-dir /tmp/empty_backup \
    --target-version 1000000
```

**Expected Result:** Process crashes with panic message "Cannot find any snapshot before ledger history start version" or "Cannot find tree snapshot before target version"

**Correct Behavior:** Should return a proper error Result with descriptive message, allowing graceful shutdown and operator intervention.

**Alternative PoC:** Point to a backup storage that contains transaction backups but missing state snapshot metadata files, triggering the same panic condition.

## Notes
While this vulnerability does not directly crash running validator nodes during consensus operations, it represents a significant operational security issue affecting disaster recovery capabilities. The use of `expect()` in async contexts violates Rust best practices and creates brittle failure modes that impact validator availability during critical recovery scenarios. Proper error handling would allow operators to diagnose and correct backup issues without process crashes.

### Citations

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L71-88)
```rust
    pub async fn run(self) -> Result<()> {
        info!("Restore coordinator started.");
        COORDINATOR_START_TS.set(unix_timestamp_sec());

        let ret = self.run_impl().await;

        if let Err(e) = &ret {
            error!(
                error = ?e,
                "Restore coordinator failed."
            );
            COORDINATOR_FAIL_TS.set(unix_timestamp_sec());
        } else {
            info!("Restore coordinator exiting with success.");
            COORDINATOR_SUCC_TS.set(unix_timestamp_sec());
        }

        ret
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L172-180)
```rust
            Ok(None) | Err(_) => {
                assert_eq!(
                    db_next_version, 0,
                    "DB should be empty if no in-progress state snapshot found"
                );
                metadata_view
                    .select_state_snapshot(std::cmp::min(lhs, max_txn_ver))
                    .expect("Cannot find any snapshot before ledger history start version")
            },
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L183-196)
```rust
        let tree_snapshot = if let Some((latest_tree_version, _)) = latest_tree_version {
            let snapshot = metadata_view.select_state_snapshot(latest_tree_version)?;

            ensure!(
                snapshot.is_some() && snapshot.as_ref().unwrap().version == latest_tree_version,
                "cannot find tree snapshot {}",
                latest_tree_version
            );
            snapshot.unwrap()
        } else {
            metadata_view
                .select_state_snapshot(target_version)?
                .expect("Cannot find tree snapshot before target version")
        };
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L111-122)
```rust
    pub fn select_state_snapshot(
        &self,
        target_version: Version,
    ) -> Result<Option<StateSnapshotBackupMeta>> {
        Ok(self
            .state_snapshot_backups
            .iter()
            .sorted()
            .rev()
            .find(|m| m.version <= target_version)
            .cloned())
    }
```

**File:** crates/aptos-debugger/src/main.rs (L14-19)
```rust
#[tokio::main]
async fn main() -> Result<()> {
    Logger::new().level(Level::Info).init();
    let _mp = MetricsPusher::start(vec![]);

    Cmd::parse().run().await
```

**File:** storage/db-tool/src/restore.rs (L66-126)
```rust
    pub async fn run(self) -> Result<()> {
        match self {
            Command::Oneoff(oneoff) => {
                match oneoff {
                    Oneoff::EpochEnding {
                        storage,
                        opt,
                        global,
                    } => {
                        EpochEndingRestoreController::new(
                            opt,
                            global.try_into()?,
                            storage.init_storage().await?,
                        )
                        .run(None)
                        .await?;
                    },
                    Oneoff::StateSnapshot {
                        storage,
                        opt,
                        global,
                    } => {
                        StateSnapshotRestoreController::new(
                            opt,
                            global.try_into()?,
                            storage.init_storage().await?,
                            None, /* epoch_history */
                        )
                        .run()
                        .await?;
                    },
                    Oneoff::Transaction {
                        storage,
                        opt,
                        global,
                    } => {
                        TransactionRestoreController::new(
                            opt,
                            global.try_into()?,
                            storage.init_storage().await?,
                            None, /* epoch_history */
                            VerifyExecutionMode::NoVerify,
                        )
                        .run()
                        .await?;
                    },
                }
            },
            Command::BootstrapDB(bootstrap) => {
                RestoreCoordinator::new(
                    bootstrap.opt,
                    bootstrap.global.try_into()?,
                    bootstrap.storage.init_storage().await?,
                )
                .run()
                .await?;
            },
        }

        Ok(())
    }
```
