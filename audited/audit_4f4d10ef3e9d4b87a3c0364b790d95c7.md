# Audit Report

## Title
Consensus Observer Proof Cache Denial of Service via Ineffective Cache Size

## Summary
The `BlockPayload::verify_payload_signatures()` function in the consensus observer creates a ProofCache with size 1, which becomes ineffective when verifying multiple proofs in parallel. This allows malicious subscribed peers to cause CPU exhaustion through repeated expensive BLS signature verifications, leading to validator node performance degradation.

## Finding Description

The vulnerability exists in the consensus observer's block payload verification logic. [1](#0-0) 

When a `BlockPayload` message is received from a subscribed peer, the system creates a dummy ProofCache with capacity of only 1 entry, then uses it to verify multiple proofs in parallel. [2](#0-1) 

The ProofCache is designed to avoid re-verification of already-validated proof signatures by caching the mapping between BatchInfoExt and AggregateSignature. [3](#0-2) 

In normal consensus operation, the proof cache is properly configured with reasonable capacity, TTL, and initial size. [4](#0-3) 

However, with a cache size of 1 and parallel verification (using rayon's `par_iter`), the cache becomes useless:
- Multiple threads verify different proofs simultaneously
- Each thread attempts to use the single-slot cache
- Constant cache evictions occur as threads compete for the slot
- Every proof undergoes full cryptographic verification via `verify_multi_signatures()`

BLS multi-signature verification is computationally expensive, requiring public key aggregation and signature verification operations. [5](#0-4) 

**Attack Scenario:**
1. A malicious or compromised validator subscribes to the consensus observer
2. The attacker sends BlockPayload messages containing the maximum number of proofs (up to 20 by default based on `receiver_max_num_batches`) [6](#0-5) 
3. Each message triggers signature verification with the ineffective size-1 cache [7](#0-6) 
4. The observer performs full BLS verification for all proofs without caching benefits
5. By flooding the observer with such messages, the attacker causes sustained CPU exhaustion

## Impact Explanation

This vulnerability qualifies as **Medium severity** under the Aptos bug bounty criteria for the following reasons:

1. **Performance Degradation**: The attack causes validator node slowdowns by forcing excessive cryptographic operations. While "Validator node slowdowns" is listed under High severity in the bug bounty program, this specific issue has limited scope as it only affects nodes running consensus observers, not all validators.

2. **Resource Exhaustion**: Breaks the "Resource Limits" critical invariant by allowing computational resource exhaustion through ineffective caching.

3. **Limited Scope**: The attack only affects consensus observer functionality, not core consensus safety or liveness. The main consensus path uses properly-sized caches.

4. **Availability Impact**: Sustained attacks could degrade observer performance to the point where they cannot keep up with legitimate consensus messages, potentially affecting state synchronization.

The issue does NOT cause:
- Consensus safety violations
- Fund loss or theft
- Network-wide liveness failures
- State corruption

## Likelihood Explanation

**Likelihood: Medium**

**Attack Requirements:**
- Attacker must be a subscribed peer (validator or authorized node)
- Subscription verification prevents arbitrary attackers from sending messages [8](#0-7) 
- Attacker needs ability to craft BlockPayload messages with multiple proofs

**Ease of Exploitation:**
- Simple to execute once subscription access is obtained
- No sophisticated cryptographic manipulation required
- Attacker just sends legitimate-looking BlockPayload messages with maximum proofs
- No timing constraints or race conditions to exploit

**Real-World Scenarios:**
- Compromised validator node running as consensus publisher
- Malicious validator attempting to degrade observer performance
- Byzantine validator in the validator set

## Recommendation

Replace the dummy cache with a properly-sized shared cache or reuse the epoch manager's proof cache:

**Option 1: Create reasonable-sized cache**
```rust
pub fn verify_payload_signatures(&self, epoch_state: &EpochState) -> Result<(), Error> {
    // Create a properly-sized proof cache (matching test configurations)
    let proof_cache = ProofCache::new(1024);
    
    let payload_proofs = self.transaction_payload.payload_proofs();
    let validator_verifier = &epoch_state.verifier;
    payload_proofs
        .par_iter()
        .with_min_len(2)
        .try_for_each(|proof| proof.verify(validator_verifier, &proof_cache))
        .map_err(|error| {
            Error::InvalidMessageError(format!(
                "Failed to verify the payload proof signatures! Error: {:?}",
                error
            ))
        })?;

    Ok(())
}
```

**Option 2: Accept cache as parameter (preferred)**
Pass the EpochManager's shared proof_cache to the verification function to enable cross-message caching:

```rust
pub fn verify_payload_signatures(
    &self, 
    epoch_state: &EpochState,
    proof_cache: &ProofCache
) -> Result<(), Error> {
    let payload_proofs = self.transaction_payload.payload_proofs();
    let validator_verifier = &epoch_state.verifier;
    payload_proofs
        .par_iter()
        .with_min_len(2)
        .try_for_each(|proof| proof.verify(validator_verifier, proof_cache))
        .map_err(|error| {
            Error::InvalidMessageError(format!(
                "Failed to verify the payload proof signatures! Error: {:?}",
                error
            ))
        })?;

    Ok(())
}
```

This would require passing the observer's or epoch manager's proof_cache through the call chain.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_consensus_types::proof_of_store::ProofOfStore;
    use aptos_types::{
        aggregate_signature::AggregateSignature,
        validator_verifier::{ValidatorConsensusInfo, ValidatorVerifier},
    };
    use aptos_crypto::{ed25519::Ed25519PrivateKey, PrivateKey, Uniform};
    use std::time::Instant;

    #[test]
    fn test_ineffective_cache_performance_degradation() {
        // Setup: Create validator verifier with multiple validators
        let mut signers = vec![];
        let mut infos = vec![];
        for _ in 0..4 {
            let private_key = Ed25519PrivateKey::generate_for_testing();
            let public_key = private_key.public_key();
            let signer = ValidatorSigner::new(
                AccountAddress::random(),
                public_key.clone(),
                private_key,
            );
            infos.push(ValidatorConsensusInfo::new(
                signer.author(),
                public_key,
                1,
            ));
            signers.push(signer);
        }
        let validator_verifier = ValidatorVerifier::new(infos);

        // Create block payload with multiple proofs (simulating attack)
        let mut proofs = vec![];
        for i in 0..20 {
            let batch_info = create_batch_info_for_test(i);
            let mut signatures = vec![];
            for signer in &signers {
                signatures.push(signer.sign(&batch_info).unwrap());
            }
            let aggregate_sig = AggregateSignature::new(
                create_bitvec(4),
                Some(aggregate_bls_signatures(&signatures)),
            );
            proofs.push(ProofOfStore::new(batch_info, aggregate_sig));
        }

        let transaction_payload = BlockTransactionPayload::new_in_quorum_store(
            vec![],
            proofs,
        );
        let block_info = BlockInfo::new(/* ... */);
        let block_payload = BlockPayload::new(block_info, transaction_payload);

        let epoch_state = create_epoch_state_with_verifier(validator_verifier);

        // Measure performance degradation: verify multiple times
        // With size-1 cache, each verification does full crypto work
        let start = Instant::now();
        for _ in 0..10 {
            assert!(block_payload.verify_payload_signatures(&epoch_state).is_ok());
        }
        let ineffective_cache_time = start.elapsed();

        // Compare with properly-sized cache (simulated by modifying code)
        // Expected: Orders of magnitude faster with effective caching
        println!("Time with size-1 cache (no caching): {:?}", ineffective_cache_time);
        
        // An attacker sending such payloads repeatedly will cause sustained CPU load
        // on the consensus observer node, degrading its performance
    }
}
```

**Attack Execution:**
1. Attacker subscribes to consensus observer as a validator
2. Constructs BlockPayload messages with 20 proofs (maximum allowed)
3. Sends messages continuously to the observer
4. Each message forces 20 full BLS signature verifications without caching
5. Observer CPU usage spikes, potentially impacting consensus participation

**Notes**

The vulnerability exists because the consensus observer uses a temporary, undersized cache for a performance-critical operation. While the signature verification itself remains secure (no bypass occurs), the ineffective caching creates an exploitable performance degradation vector. This is particularly concerning for validators running consensus observers, as sustained attacks could impact their ability to participate effectively in consensus.

The fix is straightforward: either use a reasonably-sized cache (1024 entries as in tests and similar to the main consensus path) or better yet, share the epoch manager's proof_cache across verification calls to maximize cache efficiency.

### Citations

**File:** consensus/src/consensus_observer/network/observer_message.rs (L962-964)
```rust
    pub fn verify_payload_signatures(&self, epoch_state: &EpochState) -> Result<(), Error> {
        // Create a dummy proof cache to verify the proofs
        let proof_cache = ProofCache::new(1);
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L967-978)
```rust
        let payload_proofs = self.transaction_payload.payload_proofs();
        let validator_verifier = &epoch_state.verifier;
        payload_proofs
            .par_iter()
            .with_min_len(2)
            .try_for_each(|proof| proof.verify(validator_verifier, &proof_cache))
            .map_err(|error| {
                Error::InvalidMessageError(format!(
                    "Failed to verify the payload proof signatures! Error: {:?}",
                    error
                ))
            })?;
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L635-652)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
        let batch_info_ext: BatchInfoExt = self.info.clone().into();
        if let Some(signature) = cache.get(&batch_info_ext) {
            if signature == self.multi_signature {
                return Ok(());
            }
        }
        let result = validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!(
                "Failed to verify ProofOfStore for batch: {:?}",
                self.info
            ));
        if result.is_ok() {
            cache.insert(batch_info_ext, self.multi_signature.clone());
        }
        result
    }
```

**File:** consensus/src/epoch_manager.rs (L250-254)
```rust
            proof_cache: Cache::builder()
                .max_capacity(node_config.consensus.proof_cache_capacity)
                .initial_capacity(1_000)
                .time_to_live(Duration::from_secs(20))
                .build(),
```

**File:** types/src/validator_verifier.rs (L345-386)
```rust
    pub fn verify_multi_signatures<T: CryptoHash + Serialize>(
        &self,
        message: &T,
        multi_signature: &AggregateSignature,
    ) -> std::result::Result<(), VerifyError> {
        // Verify the number of signature is not greater than expected.
        Self::check_num_of_voters(self.len() as u16, multi_signature.get_signers_bitvec())?;
        let mut pub_keys = vec![];
        let mut authors = vec![];
        for index in multi_signature.get_signers_bitvec().iter_ones() {
            let validator = self
                .validator_infos
                .get(index)
                .ok_or(VerifyError::UnknownAuthor)?;
            authors.push(validator.address);
            pub_keys.push(validator.public_key());
        }
        // Verify the quorum voting power of the authors
        self.check_voting_power(authors.iter(), true)?;
        #[cfg(any(test, feature = "fuzzing"))]
        {
            if self.quorum_voting_power == 0 {
                // This should happen only in case of tests.
                // TODO(skedia): Clean up the test behaviors to not rely on empty signature
                // verification
                return Ok(());
            }
        }
        // Verify empty multi signature
        let multi_sig = multi_signature
            .sig()
            .as_ref()
            .ok_or(VerifyError::EmptySignature)?;
        // Verify the optimistically aggregated signature.
        let aggregated_key =
            PublicKey::aggregate(pub_keys).map_err(|_| VerifyError::FailedToAggregatePubKey)?;

        multi_sig
            .verify(message, &aggregated_key)
            .map_err(|_| VerifyError::InvalidMultiSignature)?;
        Ok(())
    }
```

**File:** config/src/config/quorum_store_config.rs (L122-122)
```rust
            receiver_max_num_batches: 20,
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L401-413)
```rust
        let verified_payload = if block_epoch == epoch_state.epoch {
            // Verify the block proof signatures
            if let Err(error) = block_payload.verify_payload_signatures(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify block payload signatures! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                        block_payload.block(), peer_network_id, error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
                return;
            }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L578-594)
```rust
        // Verify the message is from the peers we've subscribed to
        if let Err(error) = self
            .subscription_manager
            .verify_message_for_subscription(peer_network_id)
        {
            // Update the rejected message counter
            increment_rejected_message_counter(&peer_network_id, &message);

            // Log the error and return
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Received message that was not from an active subscription! Error: {:?}",
                    error,
                ))
            );
            return;
        }
```
