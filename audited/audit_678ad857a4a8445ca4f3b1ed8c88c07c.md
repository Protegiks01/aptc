# Audit Report

## Title
Vector Desynchronization in Transaction Restore Allows State Corruption via Unverified write_sets

## Summary
The `save_before_replay_version()` function in `restore.rs` performs sequential drain operations on five parallel vectors (`txns`, `persisted_aux_info`, `txn_infos`, `event_vecs`, `write_sets`) without verifying they remain synchronized. Critically, the `write_sets` vector is never cryptographically verified during backup loading, creating a pathway for malformed backups to cause transaction-to-writeset misalignment and permanent state database corruption.

## Finding Description

The backup restoration process loads transaction data into five parallel vectors that must remain synchronized throughout processing. However, a critical verification gap exists: [1](#0-0) 

The `write_sets` vector is excluded from cryptographic verification. The `TransactionListWithProofV2::verify()` only validates `txns`, `persisted_aux_info`, `txn_infos`, and `event_vecs`: [2](#0-1) [3](#0-2) [4](#0-3) 

The only validation checks `txns.len()` matches the manifest, but never verifies `write_sets.len()` equals other vectors: [5](#0-4) 

Subsequently, the code performs multiple sequential drain operations assuming all vectors have identical lengths: [6](#0-5) [7](#0-6) [8](#0-7) 

**Attack Scenario:**

If a malformed backup contains `write_sets` with incorrect length or wrong element positions (due to corruption, deserialization bugs, or malicious tampering):

1. `LoadedChunk::load()` deserializes the backup without verifying `write_sets` alignment
2. Drain operations either panic (if `write_sets.len() < drain_index`) leaving vectors desynchronized, OR succeed but maintain wrong alignment
3. The `izip!` macro silently pairs transactions with mismatched write sets: [9](#0-8) 

4. `save_transactions_impl()` saves these misaligned pairs with separate independent loops, with NO length validation: [10](#0-9) 

**Example:** If `txns = [T0, T1, T2]` but `write_sets = [W0, W1, W5]` (W2 missing due to corruption), transaction T2 gets paired with write_set W5 instead of W2, causing state Merkle tree corruption.

## Impact Explanation

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

**High Severity Impact** per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Incorrect transaction-to-writeset mappings corrupt the state database permanently
- **Significant protocol violations**: Different nodes processing corrupted vs. valid backups could diverge in state roots
- **Potential consensus divergence**: If validators restore from corrupted backups, they compute different state roots for identical blocks, breaking deterministic execution

This does not reach Critical severity because:
- Requires access to backup files (not arbitrary network attack)
- Does not directly cause fund theft or total network halt
- Recoverable through re-syncing from valid backups

## Likelihood Explanation

**Medium-High Likelihood:**

**Attack Requirements:**
- Access to backup files during creation, storage, or transmission (achievable for operators, cloud storage attackers, or MITM attackers)
- Ability to craft BCS-valid but structurally malformed backup where `write_sets` differs from other vectors
- No special validator privileges needed

**Natural Occurrence:**
- Disk corruption during backup creation
- Bugs in backup serialization/deserialization code
- Network transmission errors causing partial write_set corruption
- Race conditions in backup generation

**Ease of Exploitation:**
The code provides NO defense against this class of corruption, making exploitation straightforward once a malformed backup exists.

## Recommendation

**Immediate Fix: Add comprehensive vector length validation**

In `LoadedChunk::load()` after line 145, add:

```rust
// Verify all vectors have the same length
ensure!(
    write_sets.len() == txns.len(),
    "write_sets length ({}) does not match txns length ({})",
    write_sets.len(),
    txns.len()
);
ensure!(
    persisted_aux_info.len() == txns.len(),
    "persisted_aux_info length ({}) does not match txns length ({})",
    persisted_aux_info.len(),
    txns.len()
);
ensure!(
    txn_infos.len() == txns.len(),
    "txn_infos length ({}) does not match txns length ({})",
    txn_infos.len(),
    txns.len()
);
ensure!(
    event_vecs.len() == txns.len(),
    "event_vecs length ({}) does not match txns length ({})",
    event_vecs.len(),
    txns.len()
);
```

In `save_transactions_impl()` at line 205, add:

```rust
// Defensive check: all slices must have same length
ensure!(
    txns.len() == persisted_aux_info.len()
        && txns.len() == txn_infos.len()
        && txns.len() == events.len()
        && txns.len() == write_sets.len(),
    "Vector length mismatch in save_transactions: txns={}, aux={}, infos={}, events={}, writesets={}",
    txns.len(), persisted_aux_info.len(), txn_infos.len(), events.len(), write_sets.len()
);
```

**Long-term Fix:**
Include `write_sets` in cryptographic verification by extending `TransactionListWithProof` to include write set hashes, verified against transaction infos.

## Proof of Concept

```rust
// Proof of Concept: Demonstrate vector desynchronization vulnerability
// This test would be added to storage/backup/backup-cli/src/backup_types/transaction/restore.rs

#[cfg(test)]
mod drain_safety_tests {
    use super::*;
    
    #[test]
    #[should_panic(expected = "write_sets length")]
    fn test_mismatched_vector_lengths_cause_corruption() {
        // Simulate a malformed LoadedChunk with mismatched write_sets
        let mut txns = vec![mock_transaction(); 100];
        let mut persisted_aux_info = vec![PersistedAuxiliaryInfo::None; 100];
        let mut txn_infos = vec![mock_txn_info(); 100];
        let mut event_vecs = vec![vec![]; 100];
        let mut write_sets = vec![mock_write_set(); 90]; // Only 90 write_sets!
        
        let target_version = 50;
        let first_version = 0;
        let num_to_keep = (target_version - first_version + 1) as usize;
        
        // First drain succeeds
        txns.drain(num_to_keep..);
        persisted_aux_info.drain(num_to_keep..);
        txn_infos.drain(num_to_keep..);
        event_vecs.drain(num_to_keep..);
        
        // This should panic because write_sets is too short
        // But if it doesn't panic, vectors become desynchronized
        write_sets.drain(num_to_keep..); // Will panic if num_to_keep > 90
        
        // If we reach here, vectors are now different lengths
        assert_eq!(txns.len(), write_sets.len(), 
                   "VULNERABILITY: Vectors are desynchronized!");
    }
    
    #[test]
    fn test_izip_silently_drops_mismatched_elements() {
        // Demonstrate that izip! stops at shortest vector
        let txns = vec![1, 2, 3];
        let write_sets = vec![10, 20]; // One short!
        
        let pairs: Vec<_> = izip!(txns, write_sets).collect();
        
        // Silent data loss: transaction 3 is dropped
        assert_eq!(pairs.len(), 2);
        assert_eq!(pairs, vec![(1, 10), (2, 20)]);
        // Transaction 3 has no write_set paired with it!
    }
}
```

## Notes

This vulnerability demonstrates a critical gap in defensive programming: the code assumes vector synchronization but never enforces it. The `write_sets` vector bypassing cryptographic verification is particularly concerning since write sets directly modify blockchain state. Any corruption in transaction-to-writeset mapping permanently corrupts the state Merkle tree, potentially causing consensus divergence across the network if different nodes process different versions of corrupted backups.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L139-145)
```rust
        ensure!(
            manifest.first_version + (txns.len() as Version) == manifest.last_version + 1,
            "Number of items in chunks doesn't match that in manifest. first_version: {}, last_version: {}, items in chunk: {}",
            manifest.first_version,
            manifest.last_version,
            txns.len(),
        );
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L156-186)
```rust
        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
        // and disassemble it to get things back.
        let (txn_list_with_proof, persisted_aux_info) = txn_list_with_proof.into_parts();
        let txns = txn_list_with_proof.transactions;
        let range_proof = txn_list_with_proof
            .proof
            .ledger_info_to_transaction_infos_proof;
        let txn_infos = txn_list_with_proof.proof.transaction_infos;
        let event_vecs = txn_list_with_proof.events.expect("unknown to be Some.");

        Ok(Self {
            manifest,
            txns,
            persisted_aux_info,
            txn_infos,
            event_vecs,
            range_proof,
            write_sets,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L474-483)
```rust
                    // remove the txns that exceeds the target_version to be restored
                    if target_version < last_version {
                        let num_to_keep = (target_version - first_version + 1) as usize;
                        txns.drain(num_to_keep..);
                        persisted_aux_info.drain(num_to_keep..);
                        txn_infos.drain(num_to_keep..);
                        event_vecs.drain(num_to_keep..);
                        write_sets.drain(num_to_keep..);
                        last_version = target_version;
                    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L485-495)
```rust
                    // remove the txns that are before the global_first_version
                    if global_first_version > first_version {
                        let num_to_remove = (global_first_version - first_version) as usize;

                        txns.drain(..num_to_remove);
                        persisted_aux_info.drain(..num_to_remove);
                        txn_infos.drain(..num_to_remove);
                        event_vecs.drain(..num_to_remove);
                        write_sets.drain(..num_to_remove);
                        first_version = global_first_version;
                    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L497-506)
```rust
                    // identify txns to be saved before the first_to_replay version
                    if first_version < first_to_replay {
                        let num_to_save =
                            (min(first_to_replay, last_version + 1) - first_version) as usize;
                        let txns_to_save: Vec<_> = txns.drain(..num_to_save).collect();
                        let persisted_aux_info_to_save: Vec<_> =
                            persisted_aux_info.drain(..num_to_save).collect();
                        let txn_infos_to_save: Vec<_> = txn_infos.drain(..num_to_save).collect();
                        let event_vecs_to_save: Vec<_> = event_vecs.drain(..num_to_save).collect();
                        let write_sets_to_save = write_sets.drain(..num_to_save).collect();
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L530-533)
```rust
                    Ok(stream::iter(
                        izip!(txns, persisted_aux_info, txn_infos, write_sets, event_vecs)
                            .map(Result::<_>::Ok),
                    ))
```

**File:** types/src/transaction/mod.rs (L2308-2315)
```rust
        // Verify the lengths of the transactions and transaction infos match
        ensure!(
            self.proof.transaction_infos.len() == self.get_num_transactions(),
            "The number of TransactionInfo objects ({}) does not match the number of \
             transactions ({}).",
            self.proof.transaction_infos.len(),
            self.get_num_transactions(),
        );
```

**File:** types/src/transaction/mod.rs (L2340-2345)
```rust
            ensure!(
                event_lists.len() == self.get_num_transactions(),
                "The length of event_lists ({}) does not match the number of transactions ({}).",
                event_lists.len(),
                self.get_num_transactions(),
            );
```

**File:** types/src/transaction/mod.rs (L2816-2822)
```rust
    // Verify the lengths of the auxiliary infos and transaction infos match
    ensure!(
        auxiliary_infos.len() == transaction_infos.len(),
        "The number of auxiliary infos ({}) does not match the number of transaction infos ({})",
        auxiliary_infos.len(),
        transaction_infos.len(),
    );
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L206-267)
```rust
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }

    for (idx, aux_info) in persisted_aux_info.iter().enumerate() {
        PersistedAuxiliaryInfoDb::put_persisted_auxiliary_info(
            first_version + idx as Version,
            aux_info,
            &mut ledger_db_batch.persisted_auxiliary_info_db_batches,
        )?;
    }

    for (idx, txn_info) in txn_infos.iter().enumerate() {
        TransactionInfoDb::put_transaction_info(
            first_version + idx as Version,
            txn_info,
            &mut ledger_db_batch.transaction_info_db_batches,
        )?;
    }

    ledger_db
        .transaction_accumulator_db()
        .put_transaction_accumulator(
            first_version,
            txn_infos,
            &mut ledger_db_batch.transaction_accumulator_db_batches,
        )?;

    ledger_db.event_db().put_events_multiple_versions(
        first_version,
        events,
        &mut ledger_db_batch.event_db_batches,
    )?;

    if ledger_db.enable_storage_sharding() {
        for (idx, txn_events) in events.iter().enumerate() {
            for event in txn_events {
                if let Some(event_key) = event.event_key() {
                    if *event_key == new_block_event_key() {
                        LedgerMetadataDb::put_block_info(
                            first_version + idx as Version,
                            event,
                            &mut ledger_db_batch.ledger_metadata_db_batches,
                        )?;
                    }
                }
            }
        }
    }
    // insert changes in write set schema batch
    for (idx, ws) in write_sets.iter().enumerate() {
        WriteSetDb::put_write_set(
            first_version + idx as Version,
            ws,
            &mut ledger_db_batch.write_set_db_batches,
        )?;
    }
```
