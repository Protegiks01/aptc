# Audit Report

## Title
Critical Use-After-Free Vulnerability in Move VM Function Pointer Caching

## Summary
The `FunctionPtr::from_loaded_function()` method creates raw pointers to `Arc<Function>` instances and stores them as HashMap keys in `InterpreterFunctionCaches`. These raw pointers can become dangling when the underlying `Arc<Function>` is dropped due to module cache flushes, leading to use-after-free vulnerabilities that can cause node crashes, memory corruption, or consensus splits.

## Finding Description
The vulnerability exists in the function pointer caching mechanism used by the Move VM interpreter: [1](#0-0) 

This code extracts a raw pointer from an `Arc<Function>` using `Arc::as_ptr()` and stores it in a HashMap. The comment claims this is safe because "the loader guarantees that any loaded function has exactly one `Arc<Function>`", but this guarantee is violated when module caches are flushed.

The raw pointer is used as a key in `InterpreterFunctionCaches`: [2](#0-1) 

The cache persists throughout a transaction's execution: [3](#0-2) 

However, the module cache can be flushed during transaction execution in multiple scenarios: [4](#0-3) 

When flushed, the module cache is cleared: [5](#0-4) 

**Attack Scenario:**
1. Transaction begins, `InterpreterFunctionCaches` is created
2. Function F from Module M is called, creating a `LoadedFunction` with `Arc<Module>` and `Arc<Function>`
3. `FunctionPtr` extracts raw pointer to the `Arc<Function>` and stores it in the cache HashMap
4. Function F returns, Frame is dropped, and if no other references exist, `LoadedFunction` is dropped
5. Module cache flush is triggered (e.g., cache size limit exceeded)
6. Module M is deallocated, including all `Arc<Function>` in its `function_defs`
7. The raw pointer in `FunctionPtr` now points to freed memory
8. If Function F is called again or the HashMap is accessed, use-after-free occurs

The vulnerability breaks the **Move VM Safety** invariant (memory safety) and can lead to **Deterministic Execution** violations if different validators experience cache flushes at different points.

## Impact Explanation
This is a **Critical Severity** vulnerability:

- **Node Crashes**: Accessing freed memory causes undefined behavior, potentially crashing validator nodes
- **Consensus Splits**: Memory corruption from use-after-free can cause non-deterministic execution, where validators produce different state roots for identical blocks
- **Memory Corruption**: Use-after-free allows arbitrary memory to be accessed, potentially compromising execution integrity

The impact qualifies as Critical because it can cause:
- **Consensus/Safety violations** - Different validators may crash or produce different results
- **Total loss of liveness** - Multiple validator crashes can halt the network
- **Non-recoverable network partition** - Consensus splits may require coordination to resolve

## Likelihood Explanation
The likelihood is **MEDIUM to HIGH**:

**Triggering Conditions:**
- Module cache flush occurs naturally when cache size limits are exceeded
- Common in networks with high transaction volume or many unique modules
- No special privileges required - any transaction can contribute to cache pressure

**Mitigating Factors:**
- Requires specific timing where a function returns, cache is flushed, then function is called again
- Some deployments may have cache limits set high enough to avoid frequent flushes
- Module cache retains Aptos Framework, reducing likelihood for system functions

However, the vulnerability is **exploitable** by an attacker who can:
1. Deploy multiple modules to fill the cache
2. Execute transactions that repeatedly call and return from functions
3. Trigger cache flushes by exceeding size limits

## Recommendation
Replace raw pointer usage with proper reference-counted storage. The `InterpreterFunctionCaches` should maintain ownership of loaded functions to prevent premature deallocation:

**Option 1: Store LoadedFunction with cache**
```rust
pub struct InterpreterFunctionCaches {
    function_instruction_caches: HashMap<FunctionPtr, (Rc<LoadedFunction>, Rc<RefCell<FrameTypeCache>>)>,
    // ...
}
```

**Option 2: Use stable IDs instead of raw pointers**
```rust
// Use module ID + function name + type args as stable key
#[derive(Clone, Eq, PartialEq, Hash)]
pub(crate) struct FunctionCacheKey {
    module_id: ModuleId,
    function_name: Identifier,
    ty_args_id: TypeVecId,
}
```

**Option 3: Clear cache on module cache flush**
Add a callback mechanism so `InterpreterFunctionCaches` is notified when modules are flushed and can clear stale entries.

## Proof of Concept

```rust
// Reproduction steps (pseudo-code for clarity):

// 1. Start transaction execution
let mut function_caches = InterpreterFunctionCaches::new();

// 2. Execute function from module M
let module = loader.load_module(&module_id);  // Arc<Module>
let function = module.get_function("foo");     // Arc<Function>
let loaded_fn = LoadedFunction { 
    owner: LoadedFunctionOwner::Module(module.clone()),
    function: function.clone(),
    // ...
};

// 3. Get cache, creating FunctionPtr
let ptr = FunctionPtr::from_loaded_function(&loaded_fn);
let cache = function_caches.get_or_create_frame_cache(&loaded_fn);

// 4. Function returns, drop LoadedFunction
drop(loaded_fn);  // Drops Arc<Module> and Arc<Function>

// 5. Flush module cache
module_cache.flush();  // Clears all Arc<Module> references

// 6. Access cached FunctionPtr - USE AFTER FREE
// If we try to use the cached ptr, it points to freed memory
let cached = function_caches.function_instruction_caches.get(&ptr);
// ptr.0 is now a dangling pointer!

// 7. Calling the same function again creates confusion:
// - New Arc<Function> may be at different address
// - Old FunctionPtr in cache is stale
// - HashMap lookup may find wrong entry or access freed memory
```

**Concrete Rust Test:**
```rust
#[test]
fn test_function_ptr_use_after_free() {
    // Setup VM with module cache
    let mut cache_manager = ModuleCacheManager::new();
    
    // Deploy and load module with function
    let module_id = /* ... */;
    let loaded_fn = /* load function from module */;
    
    // Create function pointer and cache it
    let mut fn_caches = InterpreterFunctionCaches::new();
    let _ = fn_caches.get_or_create_frame_cache(&loaded_fn);
    
    // Drop the loaded function
    drop(loaded_fn);
    
    // Flush module cache (simulating cache pressure)
    cache_manager.module_cache.flush();
    
    // At this point, FunctionPtr in fn_caches contains dangling pointer
    // Any access to the cached entry risks use-after-free
    
    // Load same function again - may get different Arc<Function> instance
    let loaded_fn_2 = /* load same function */;
    let _ = fn_caches.get_or_create_frame_cache(&loaded_fn_2);
    
    // Undefined behavior: may access freed memory or wrong cache entry
}
```

**Notes:**
This vulnerability requires careful coordination of cache management and function lifetimes. The code incorrectly assumes that function pointer identity remains stable across module cache flushes, violating Rust's memory safety guarantees by using raw pointers without ensuring the referenced data remains alive.

### Citations

**File:** third_party/move/move-vm/runtime/src/loader/function.rs (L193-202)
```rust
#[derive(Copy, Clone, Eq, PartialEq, Debug)]
pub(crate) struct FunctionPtr(*const Function);

impl FunctionPtr {
    pub(crate) fn from_loaded_function(function: &LoadedFunction) -> Self {
        // Pointer identity can be used since the loader guarantees that any loaded function has
        // exactly one `Arc<Function>`.
        Self(Arc::as_ptr(&function.function))
    }
}
```

**File:** third_party/move/move-vm/runtime/src/interpreter_caches.rs (L17-20)
```rust
pub struct InterpreterFunctionCaches {
    function_instruction_caches: HashMap<FunctionPtr, Rc<RefCell<FrameTypeCache>>>,
    generic_function_instruction_caches: HashMap<GenericFunctionPtr, Rc<RefCell<FrameTypeCache>>>,
}
```

**File:** third_party/move/move-vm/runtime/src/interpreter.rs (L177-206)
```rust
    pub(crate) fn entrypoint<LoaderImpl>(
        function: LoadedFunction,
        args: Vec<Value>,
        data_cache: &mut impl MoveVmDataCache,
        function_caches: &mut InterpreterFunctionCaches,
        loader: &LoaderImpl,
        ty_depth_checker: &TypeDepthChecker<LoaderImpl>,
        layout_converter: &LayoutConverter<LoaderImpl>,
        gas_meter: &mut impl GasMeter,
        traversal_context: &mut TraversalContext,
        extensions: &mut NativeContextExtensions,
        trace_logeer: &mut impl TraceRecorder,
    ) -> VMResult<Vec<Value>>
    where
        LoaderImpl: Loader,
    {
        InterpreterImpl::entrypoint(
            function,
            args,
            data_cache,
            function_caches,
            loader,
            ty_depth_checker,
            layout_converter,
            gas_meter,
            traversal_context,
            extensions,
            trace_logeer,
        )
    }
```

**File:** aptos-move/block-executor/src/code_cache_global_manager.rs (L99-184)
```rust
    fn check_ready(
        &mut self,
        storage_environment: AptosEnvironment,
        config: &BlockExecutorModuleCacheLocalConfig,
        transaction_slice_metadata: TransactionSliceMetadata,
    ) -> Result<(), VMStatus> {
        // If we execute non-consecutive sequence of transactions, we need to flush everything.
        if !transaction_slice_metadata.is_immediately_after(&self.transaction_slice_metadata) {
            self.module_cache.flush();
            self.environment = None;
        }
        // Record the new metadata for this slice of transactions.
        self.transaction_slice_metadata = transaction_slice_metadata;

        // Next, check the environment. If the current environment has not been set, or is
        // different, we reset it to the new one, and flush the module cache.
        let environment_requires_update = self.environment.as_ref() != Some(&storage_environment);
        if environment_requires_update {
            if storage_environment.gas_feature_version() >= RELEASE_V1_34 {
                let flush_verifier_cache = self.environment.as_ref().is_none_or(|e| {
                    e.verifier_config_bytes() != storage_environment.verifier_config_bytes()
                });
                if flush_verifier_cache {
                    // Additionally, if the verifier config changes, we flush static verifier cache
                    // as well.
                    RuntimeEnvironment::flush_verified_module_cache();
                }
            }

            self.environment = Some(storage_environment);
            self.module_cache.flush();
        }

        let environment = self.environment.as_ref().expect("Environment must be set");
        let runtime_environment = environment.runtime_environment();
        RuntimeEnvironment::log_verified_cache_size();

        let struct_name_index_map_size = runtime_environment
            .struct_name_index_map_size()
            .map_err(|err| err.finish(Location::Undefined).into_vm_status())?;
        STRUCT_NAME_INDEX_MAP_NUM_ENTRIES.set(struct_name_index_map_size as i64);

        // If the environment caches too many struct names, flush type caches. Also flush module
        // caches because they contain indices for struct names.
        if struct_name_index_map_size > config.max_struct_name_index_map_num_entries {
            runtime_environment.flush_all_caches();
            self.module_cache.flush();
        }

        let num_interned_tys = runtime_environment.ty_pool().num_interned_tys();
        NUM_INTERNED_TYPES.set(num_interned_tys as i64);
        let num_interned_ty_vecs = runtime_environment.ty_pool().num_interned_ty_vecs();
        NUM_INTERNED_TYPE_VECS.set(num_interned_ty_vecs as i64);
        let num_interned_module_ids = runtime_environment.module_id_pool().len();
        NUM_INTERNED_MODULE_IDS.set(num_interned_module_ids as i64);

        if num_interned_tys > config.max_interned_tys
            || num_interned_ty_vecs > config.max_interned_ty_vecs
        {
            runtime_environment.ty_pool().flush();
            self.module_cache.flush();
        }

        if num_interned_module_ids > config.max_interned_module_ids {
            runtime_environment.module_id_pool().flush();
            runtime_environment.struct_name_index_map().flush();
            self.module_cache.flush();
        }

        let module_cache_size_in_bytes = self.module_cache.size_in_bytes();
        GLOBAL_MODULE_CACHE_SIZE_IN_BYTES.set(module_cache_size_in_bytes as i64);
        GLOBAL_MODULE_CACHE_NUM_MODULES.set(self.module_cache.num_modules() as i64);

        // If module cache stores too many modules, flush it as well.
        if module_cache_size_in_bytes > config.max_module_cache_size_in_bytes {
            self.module_cache.flush();
        }

        let num_non_generic_layout_entries = self.module_cache.num_cached_layouts();
        GLOBAL_LAYOUT_CACHE_NUM_NON_ENTRIES.set(num_non_generic_layout_entries as i64);
        if num_non_generic_layout_entries > config.max_layout_cache_size {
            self.module_cache.flush_layout_cache();
        }

        Ok(())
    }
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L155-160)
```rust
    /// Flushes all caches.
    pub fn flush(&mut self) {
        self.module_cache.clear();
        self.size = 0;
        self.struct_layouts.clear();
    }
```
