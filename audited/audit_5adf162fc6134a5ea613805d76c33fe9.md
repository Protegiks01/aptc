# Audit Report

## Title
Committed Transactions Can Enter Mempool Due to Stale Checkpoint Reads and Uninitialized Sequence Number Tracking

## Summary
A race condition in the mempool transaction processing flow allows already-committed transactions to enter the mempool when the state checkpoint lags behind recent commits and the mempool has not received commit notifications for the affected accounts. This occurs because `process_incoming_transactions` reads account sequence numbers from stale checkpoints while the mempool's internal tracking (`account_sequence_numbers`) is uninitialized for accounts without prior commit notifications.

## Finding Description
The vulnerability exists in the transaction validation flow within the mempool coordinator. When transactions are received from the network, the processing task reads account sequence numbers from the database using `latest_state_checkpoint_view()`. [1](#0-0) 

However, this method returns the state at the **last checkpoint**, not the latest committed state. [2](#0-1) 

Checkpoints are only created at block boundaries via `StateCheckpoint` transactions, not for every individual transaction. [3](#0-2) 

The checkpoint creation is managed by `BufferedState` which commits at intervals or when explicitly synchronized. [4](#0-3) 

This creates a window where the checkpoint shows an outdated sequence number (e.g., 4) while transactions with sequence numbers 5-7 have already been committed. When these stale values are used to validate incoming transactions, the protection mechanism in `TransactionStore::insert()` fails due to a `max()` operation that compares the checkpoint value with `account_sequence_numbers`. [5](#0-4) 

If the account has never received a commit notification, this HashMap returns `None` (defaulting to 0 via `map_or`), causing `max(4, 0) = 4`, which allows transactions 5-7 to pass the validation check at line 301. [6](#0-5) 

The `account_sequence_numbers` HashMap is initialized empty and only populated by commit notifications. [7](#0-6) [8](#0-7) 

The VM validator also uses the same stale checkpoint for validation. [9](#0-8) [10](#0-9) 

**Attack Scenario:**
1. Account X has transactions seq 0-7 committed on-chain
2. Last checkpoint was created at a block before seq 5-7 were committed (showing seq 4)
3. Mempool has never received commit notification for account X (fresh start, or account never tracked)
4. Attacker broadcasts already-committed transactions X:5, X:6, X:7
5. Task reads checkpoint → gets seq 4
6. Transactions pass initial filter (5 ≥ 4, 6 ≥ 4, 7 ≥ 4) at lines 362-393 in tasks.rs [11](#0-10) 
7. In `insert()`: `max(4, 0) = 4` (since account_sequence_numbers[X] = None → 0)
8. Check `5 < 4`? False → transaction PASSES
9. Committed transactions X:5, X:6, X:7 enter mempool and are indexed for consensus pulling and broadcast

This violates the critical invariant that committed transactions must not exist in the mempool.

## Impact Explanation
This vulnerability represents **Medium Severity** per the Aptos bug bounty criteria:

- **State inconsistencies requiring intervention**: The mempool temporarily contains committed transactions, violating state consistency guarantees
- **Resource waste**: Committed transactions undergo unnecessary VM validation, storage in multiple indexes (priority_index, timeline_index, hash_index), and consume mempool capacity
- **Broadcast amplification**: Accepted transactions are added to timeline_index and can be rebroadcast to other nodes via `read_timeline()` [12](#0-11) , propagating the inconsistency across the network
- **Consensus coordination overhead**: Although consensus has `exclude_transactions` checks for in-progress transactions [13](#0-12) , these filters are designed for uncommitted transactions being processed by consensus, not for already-committed transactions

The issue does not qualify as Critical because:
- It doesn't cause permanent funds loss (transactions already committed cannot be re-executed)
- It doesn't violate consensus safety (consensus re-validates transactions before execution)
- Committed transactions are eventually cleaned up when commit notifications arrive or through garbage collection

It doesn't qualify as High because it doesn't directly cause node slowdowns, though resource waste could contribute to performance degradation under sustained attack.

## Likelihood Explanation
This vulnerability has **HIGH likelihood** of occurring in production:

**Preconditions (all realistic):**
1. **Checkpoint lag**: Occurs naturally as checkpoints are created only at block boundaries via StateCheckpoint transactions, creating a window of several transactions between checkpoint and latest commit
2. **Uninitialized tracking**: Happens regularly after mempool restarts, node synchronization, or for accounts first appearing in the network that haven't been tracked by this specific mempool instance
3. **Transaction rebroadcast**: Common in distributed systems where nodes may receive transaction broadcasts after the transactions are committed elsewhere due to network propagation delays

**Triggering conditions:**
- Any node restart or state sync operation (clears in-memory `account_sequence_numbers`)
- Any account that hasn't been tracked by this specific mempool instance
- Normal network propagation delays between commit and broadcast
- High transaction throughput where multiple transactions commit between checkpoint creation intervals

The vulnerability is not theoretical—it represents a real race condition in the production transaction processing pipeline that can occur during normal network operation without any sophisticated attack coordination.

## Recommendation
Implement one or more of the following fixes:

1. **Use latest committed version instead of checkpoint**: Modify `process_incoming_transactions` to read from the latest committed state rather than the checkpoint, or query the account sequence number directly from the committed state view.

2. **Initialize account_sequence_numbers from checkpoint**: When reading from checkpoint in `process_incoming_transactions`, if the account is not in `account_sequence_numbers`, initialize it with the checkpoint value before passing to `insert()`.

3. **Add committed transaction check**: Before inserting into mempool, query if the transaction has already been committed by checking against the latest ledger version.

Recommended fix (option 2 - minimal change):
```rust
// In process_incoming_transactions, after reading account sequence numbers
for (idx, (t, _, _)) in transactions.iter().enumerate() {
    if let Ok(Some(sequence_num)) = account_seq_numbers[idx] {
        // Update mempool's tracking if account not present
        if smp.mempool.lock().transactions.get_account_sequence_number(&t.sender()).is_none() {
            smp.mempool.lock().transactions.account_sequence_numbers
                .entry(t.sender()).or_insert(sequence_num);
        }
    }
}
```

## Proof of Concept
A complete Rust integration test demonstrating this vulnerability should be added, showing:
1. Commit transactions for an account up to sequence number 7
2. Create a checkpoint at sequence number 4
3. Restart mempool (clear `account_sequence_numbers`)
4. Broadcast transactions 5, 6, 7 to mempool
5. Verify they are accepted and present in mempool indexes
6. Verify they can be read from timeline for broadcast

The test should use the existing mempool test infrastructure in `mempool/src/tests/` to demonstrate the vulnerability in a controlled environment.

## Notes
The vulnerability is exacerbated by the fact that both the mempool transaction processing and the VM validator use the same stale checkpoint view, so there is no defense-in-depth layer to catch already-committed transactions. The `exclude_transactions` mechanism in consensus is designed for a different purpose (filtering in-progress transactions) and does not protect against this race condition.

### Citations

**File:** mempool/src/shared_mempool/tasks.rs (L329-332)
```rust
    let state_view = smp
        .db
        .latest_state_checkpoint_view()
        .expect("Failed to get latest state checkpoint view.");
```

**File:** mempool/src/shared_mempool/tasks.rs (L362-393)
```rust
            if let Ok(account_sequence_num) = account_seq_numbers[idx] {
                match account_sequence_num {
                    Some(sequence_num) => {
                        if t.sequence_number() >= sequence_num {
                            return Some((t, Some(sequence_num), ready_time_at_sender, priority));
                        } else {
                            statuses.push((
                                t,
                                (
                                    MempoolStatus::new(MempoolStatusCode::VmError),
                                    Some(DiscardedVMStatus::SEQUENCE_NUMBER_TOO_OLD),
                                ),
                            ));
                        }
                    },
                    None => {
                        return Some((t, None, ready_time_at_sender, priority));
                    },
                }
            } else {
                // Failed to get account's onchain sequence number
                statuses.push((
                    t,
                    (
                        MempoolStatus::new(MempoolStatusCode::VmError),
                        Some(DiscardedVMStatus::RESOURCE_DOES_NOT_EXIST),
                    ),
                ));
            }
            None
        })
        .collect();
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L812-820)
```rust
    fn get_latest_state_checkpoint_version(&self) -> Result<Option<Version>> {
        gauged_api("get_latest_state_checkpoint_version", || {
            Ok(self
                .state_store
                .current_state_locked()
                .last_checkpoint()
                .version())
        })
    }
```

**File:** types/src/transaction/mod.rs (L2960-2963)
```rust
    /// Transaction to let the executor update the global state tree and record the root hash
    /// in the TransactionInfo
    /// The hash value inside is unique block id which can generate unique hash of state checkpoint transaction
    StateCheckpoint(HashValue),
```

**File:** storage/aptosdb/src/state_store/buffered_state.rs (L99-108)
```rust
    fn maybe_commit(&mut self, checkpoint: Option<StateWithSummary>, sync_commit: bool) {
        if let Some(checkpoint) = checkpoint {
            if !checkpoint.is_the_same(&self.last_snapshot)
                && (sync_commit
                    || self.estimated_items >= self.target_items
                    || self.buffered_versions() >= TARGET_SNAPSHOT_INTERVAL_IN_VERSION)
            {
                self.enqueue_commit(checkpoint);
            }
        }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L115-115)
```rust
            account_sequence_numbers: HashMap::new(),
```

**File:** mempool/src/core_mempool/transaction_store.rs (L244-249)
```rust
        let account_sequence_number = account_sequence_number.map(|seq_num| {
            max(
                seq_num,
                self.get_account_sequence_number(&address).map_or(0, |v| *v),
            )
        });
```

**File:** mempool/src/core_mempool/transaction_store.rs (L296-308)
```rust
        if let ReplayProtector::SequenceNumber(txn_seq_num) = txn.get_replay_protector() {
            let acc_seq_num = account_sequence_number.expect(
                "Account sequence number is always provided for transactions with sequence number",
            );
            self.clean_committed_transactions_below_account_seq_num(&address, acc_seq_num);
            if txn_seq_num < acc_seq_num {
                return MempoolStatus::new(MempoolStatusCode::InvalidSeqNumber).with_message(
                    format!(
                        "transaction sequence number is {}, current sequence number is  {}",
                        txn_seq_num, acc_seq_num,
                    ),
                );
            }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L682-683)
```rust
                self.account_sequence_numbers
                    .insert(*account, new_account_seq_number);
```

**File:** mempool/src/core_mempool/transaction_store.rs (L774-838)
```rust
    pub(crate) fn read_timeline(
        &self,
        sender_bucket: MempoolSenderBucket,
        timeline_id: &MultiBucketTimelineIndexIds,
        count: usize,
        before: Option<Instant>,
        // The priority of the receipient of the transactions
        priority_of_receiver: BroadcastPeerPriority,
    ) -> (Vec<(SignedTransaction, u64)>, MultiBucketTimelineIndexIds) {
        let mut batch = vec![];
        let mut batch_total_bytes: u64 = 0;
        let mut last_timeline_id = timeline_id.id_per_bucket.clone();

        // Add as many transactions to the batch as possible
        for (i, bucket) in self
            .timeline_index
            .get(&sender_bucket)
            .unwrap_or_else(|| {
                panic!(
                    "Unable to get the timeline index for the sender bucket {}",
                    sender_bucket
                )
            })
            .read_timeline(timeline_id, count, before)
            .iter()
            .enumerate()
            .rev()
        {
            for (address, replay_protector) in bucket {
                if let Some(txn) = self.get_mempool_txn(address, *replay_protector) {
                    let transaction_bytes = txn.txn.raw_txn_bytes_len() as u64;
                    if batch_total_bytes.saturating_add(transaction_bytes) > self.max_batch_bytes {
                        break; // The batch is full
                    } else {
                        batch.push((
                            txn.txn.clone(),
                            aptos_infallible::duration_since_epoch_at(
                                &txn.insertion_info.ready_time,
                            )
                            .as_millis() as u64,
                        ));
                        batch_total_bytes = batch_total_bytes.saturating_add(transaction_bytes);
                        if let TimelineState::Ready(timeline_id) = txn.timeline_state {
                            last_timeline_id[i] = timeline_id;
                        }
                        let bucket = self.get_bucket(txn.ranking_score, &txn.get_sender());
                        Mempool::log_txn_latency(
                            &txn.insertion_info,
                            bucket.as_str(),
                            BROADCAST_BATCHED_LABEL,
                            priority_of_receiver.to_string().as_str(),
                        );
                        counters::core_mempool_txn_ranking_score(
                            BROADCAST_BATCHED_LABEL,
                            BROADCAST_BATCHED_LABEL,
                            bucket.as_str(),
                            txn.ranking_score,
                        );
                    }
                }
            }
        }

        (batch, last_timeline_id.into())
    }
```

**File:** vm-validator/src/vm_validator.rs (L55-57)
```rust
        let db_state_view = db_reader
            .latest_state_checkpoint_view()
            .expect("Get db view cannot fail");
```

**File:** vm-validator/src/vm_validator.rs (L64-68)
```rust
    fn db_state_view(&self) -> DbStateView {
        self.db_reader
            .latest_state_checkpoint_view()
            .expect("Get db view cannot fail")
    }
```

**File:** mempool/src/core_mempool/mempool.rs (L417-430)
```rust
    /// Fetches next block of transactions for consensus.
    /// `return_non_full` - if false, only return transactions when max_txns or max_bytes is reached
    ///                     Should always be true for Quorum Store.
    /// `include_gas_upgraded` - Return transactions that had gas upgraded, even if they are in
    ///                          exclude_transactions. Should only be true for Quorum Store.
    /// `exclude_transactions` - transactions that were sent to Consensus but were not committed yet
    ///  mempool should filter out such transactions.
    #[allow(clippy::explicit_counter_loop)]
    pub(crate) fn get_batch(
        &self,
        max_txns: u64,
        max_bytes: u64,
        return_non_full: bool,
        exclude_transactions: BTreeMap<TransactionSummary, TransactionInProgress>,
```
