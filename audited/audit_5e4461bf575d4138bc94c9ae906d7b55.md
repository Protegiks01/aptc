# Audit Report

## Title
Cache Worker State Recovery Vulnerability Leading to Stale Data Serving and File Store Worker Crashes

## Summary
The indexer-grpc cache worker fails to validate or clear Redis cache state on restart, causing it to serve stale transaction data and potentially crash the file store worker when resuming from a file store checkpoint that is behind the cached version pointer.

## Finding Description

The cache worker's state recovery mechanism has a critical flaw in how it handles Redis cache state after a crash or restart. The vulnerability exists in the interaction between three key operations:

1. **Restart Logic**: The cache worker reads the starting version from file store metadata without checking the existing Redis cache state [1](#0-0) 

2. **Version Update Logic**: The Lua script in `update_cache_latest_version` uses `max()` to handle overlaps, keeping the higher version even when processing older data [2](#0-1) 

3. **Overlap Handling**: Return code 1 (overlap) is treated as success, not an error [3](#0-2) 

**Attack Scenario:**

1. System running normally: Cache worker at version 10000, file store at version 8000
2. Cache worker crashes (OOM, hardware failure, or process restart)
3. Redis retains: `latest_version=10000` and transaction data up to version 10000
4. Cache worker restarts, reads file store metadata: `version=8000`
5. Worker begins reprocessing from version 8000, writing new transaction data
6. When calling `update_cache_latest_version(1000, 9000)`:
   - Lua script sees Redis `latest_version=10000`
   - Returns overlap (code 1), sets version to `max(9000, 10000)=10000`
   - Worker continues, believing cache state is consistent
7. Redis now contains: `latest_version=10000`, fresh data [8000-9000), **stale data [9000-10000)**
8. File store worker reads `cache_operator.get_latest_version()` â†’ returns 10000
9. File store worker calls `get_transactions(9000, 1000)` expecting valid data
10. Either gets stale/inconsistent data and writes it to persistent storage, OR if data was evicted, the call fails and file store worker panics [4](#0-3) 

The `get_transactions` method enforces that all requested transactions must be present: [5](#0-4) 

If transactions are missing due to eviction, this causes a panic in the file store worker.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program due to "API crashes" and "Significant protocol violations":

1. **File Store Worker Crashes**: When the file store worker attempts to read from the gap of stale/missing data, it will panic, causing indexer service disruption
2. **Data Inconsistency**: Stale transaction data may be persisted to file storage, causing permanent data corruption in the indexer infrastructure
3. **Service Availability**: The indexer-grpc service becomes unreliable during and after cache worker restarts, affecting all downstream consumers

While this does not directly impact blockchain consensus (indexers are read-only), it violates critical data consistency guarantees for the indexer infrastructure that many applications depend on.

## Likelihood Explanation

**High Likelihood**: Cache worker crashes/restarts are common operational events caused by:
- Out of memory conditions when processing large transaction batches
- Process updates/deployments
- Container orchestration (Kubernetes) pod restarts
- Hardware failures or maintenance

The file store worker naturally lags behind the cache worker by design (150,000 versions), making the race condition window large. Every cache worker restart when file store is behind creates this vulnerability.

## Recommendation

Implement cache state validation and cleanup on cache worker startup:

```rust
pub async fn run(&mut self) -> Result<()> {
    loop {
        let conn = self.redis_client.get_tokio_connection_manager().await?;
        let mut rpc_client = create_grpc_client(self.fullnode_grpc_address.clone()).await;

        let file_store_operator: Box<dyn FileStoreOperator> = self.file_store.create();
        let mut starting_version = file_store_operator.get_latest_version().await;
        
        while starting_version.is_none() {
            starting_version = file_store_operator.get_latest_version().await;
            tokio::time::sleep(std::time::Duration::from_millis(FILE_STORE_METADATA_WAIT_MS)).await;
        }
        let starting_version = starting_version.unwrap();

        // NEW: Validate Redis cache state against file store version
        let mut cache_operator = CacheOperator::new(conn.clone(), self.cache_storage_format);
        let redis_latest_version = cache_operator.get_latest_version().await?.unwrap_or(0);
        
        if redis_latest_version > starting_version {
            tracing::warn!(
                redis_version = redis_latest_version,
                file_store_version = starting_version,
                "[Indexer Cache] Redis cache ahead of file store. Resetting cache state."
            );
            // Reset the latest_version pointer to match file store
            cache_operator.update_cache_latest_version(0, starting_version).await?;
        }
        
        // Continue with existing logic...
```

Additionally, modify the Lua script to reject overlaps when restarting from a lower version:
- Return error code 2 (gap) if attempting to set a version lower than current, or
- Implement explicit cache clearing when detecting restart from lower version

## Proof of Concept

```rust
#[tokio::test]
async fn test_cache_worker_restart_stale_data() {
    // Setup: Mock Redis with version 10000 and file store at 8000
    let redis_client = redis::Client::open("redis://127.0.0.1/").unwrap();
    let mut conn = redis_client.get_tokio_connection_manager().await.unwrap();
    
    // Simulate cache state before crash
    let _: () = conn.set("latest_version", "10000").await.unwrap();
    for v in 8000..10000 {
        let key = format!("{}", v);
        let _: () = conn.set(&key, format!("stale_data_{}", v)).await.unwrap();
    }
    
    // Simulate file store at version 8000
    let file_store_version = 8000_u64;
    
    // Cache worker restarts and processes [8000, 9000)
    let mut cache_operator = CacheOperator::new(conn.clone(), StorageFormat::Base64UncompressedProto);
    
    // Write new transaction data [8000, 9000)
    let transactions = (8000..9000).map(|v| Transaction {
        version: v,
        ..Default::default()
    }).collect();
    cache_operator.update_cache_transactions(transactions).await.unwrap();
    
    // Update version - THIS SHOULD FAIL BUT DOESN'T
    let result = cache_operator.update_cache_latest_version(1000, 9000).await;
    assert!(result.is_ok()); // BUG: Returns Ok even though we're behind
    
    // Check latest version - STILL AT 10000
    let latest = cache_operator.get_latest_version().await.unwrap().unwrap();
    assert_eq!(latest, 10000); // BUG: Stale version pointer
    
    // File store worker tries to read version 9500
    let result = cache_operator.get_transactions(9500, 500).await;
    // Either gets stale data or panics if evicted
}
```

**Notes**

This vulnerability is specific to the indexer-grpc auxiliary service and does not affect core blockchain consensus or validator operations. However, it represents a significant operational reliability issue for the indexer infrastructure that powers many ecosystem applications. The cache worker should implement atomic state recovery that ensures Redis cache consistency with the file store checkpoint on every restart.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L123-145)
```rust
            let mut starting_version = file_store_operator.get_latest_version().await;
            while starting_version.is_none() {
                starting_version = file_store_operator.get_latest_version().await;
                tracing::warn!(
                    "[Indexer Cache] File store metadata not found. Waiting for {} ms.",
                    FILE_STORE_METADATA_WAIT_MS
                );
                tokio::time::sleep(std::time::Duration::from_millis(
                    FILE_STORE_METADATA_WAIT_MS,
                ))
                .await;
            }

            // There's a guarantee at this point that starting_version is not null
            let starting_version = starting_version.unwrap();

            let file_store_metadata = file_store_operator.get_file_store_metadata().await.unwrap();

            tracing::info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Starting cache worker with version {}",
                starting_version
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L39-57)
```rust
const CACHE_SCRIPT_UPDATE_LATEST_VERSION: &str = r#"
    local latest_version = redis.call("GET", KEYS[1])
    local num_of_versions = tonumber(ARGV[1])
    local current_version = tonumber(ARGV[2])
    if latest_version then
        if tonumber(latest_version) + num_of_versions < current_version then
            return 2
        elseif tonumber(latest_version) + num_of_versions == current_version then
            redis.call("SET", KEYS[1], current_version)
            return 0
        else
            redis.call("SET", KEYS[1], math.max(current_version, tonumber(latest_version)))
            return 1
        end
    else
        redis.call("SET", KEYS[1], ARGV[1])
        return 0
    end
"#;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L359-363)
```rust
            2 => {
                tracing::error!(version=version, "Redis latest version update failed. The version is beyond the next expected version.");
                Err(anyhow::anyhow!("Version is not right."))
            },
            _ => Ok(()),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L389-392)
```rust
        ensure!(
            transactions.len() == transaction_count as usize,
            "Failed to get all transactions from cache."
        );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store/src/processor.rs (L162-165)
```rust
                    let transactions = cache_operator_clone
                        .get_transactions(start_version, FILE_ENTRY_TRANSACTION_COUNT)
                        .await
                        .unwrap();
```
