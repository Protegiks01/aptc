# Audit Report

## Title
Memory Leak in ProofCoordinator: Unbounded Growth of batch_info_to_time HashMap Due to Incomplete Cleanup in expire()

## Summary
The `expire()` function in `ProofCoordinator` fails to remove entries from the `batch_info_to_time` HashMap when batches expire without completing. This creates a memory leak that causes unbounded HashMap growth, eventually leading to memory exhaustion and validator node instability.

## Finding Description

The `ProofCoordinator` maintains two parallel HashMap structures to track batches during proof-of-store formation. [1](#0-0) 

When a batch is initialized via the `init_proof()` function, entries are added to both HashMaps. [2](#0-1) 

There are two cleanup paths:

**Path 1: Successful proof completion** - When a batch receives enough signatures to form a quorum, the `add_signature()` function removes the entry from `batch_info_to_time` and uses the elapsed duration for metrics. [3](#0-2) 

**Path 2: Expiration without completion** - When a batch times out before achieving quorum, the `expire()` function only removes entries from `batch_info_to_proof`, but does NOT remove from `batch_info_to_time`. [4](#0-3) 

This asymmetry creates a memory leak. Every batch that expires without completing leaves a permanent entry in `batch_info_to_time` containing a `BatchInfoExt` key and `Instant` value. The leaked entries accumulate indefinitely with no cleanup mechanism.

**Triggering Conditions:**
Batch timeouts are normal operational events, as evidenced by the dedicated `TIMEOUT_BATCHES_COUNT` counter that tracks them. [5](#0-4) [6](#0-5) 

Common triggers include:
- Network partitions preventing signature propagation
- Validator unavailability or slow response times  
- Normal operations where some batches naturally fail to achieve quorum within the timeout window

## Impact Explanation

**Severity: Medium** (aligns with "State inconsistencies requiring intervention")

**Resource Exhaustion:**
- Each leaked entry contains a `BatchInfoExt` structure (with digest, epoch, batch_id metadata) and an `Instant` timestamp
- Over days/weeks of continuous operation with even modest failure rates, thousands of entries accumulate
- HashMap growth degrades performance due to increased lookup times and memory pressure
- Eventually leads to out-of-memory (OOM) conditions requiring node restart

**Operational Impact:**
- Validator nodes experience progressive memory growth and slowdown
- Memory alerts trigger requiring manual intervention  
- Node restarts needed to clear leaked memory
- Reduced consensus participation during recovery

**Why Medium and not High/Critical:**
- Does not directly compromise consensus safety or cause fund loss
- Gradual degradation rather than immediate failure
- Recoverable through node restart (though requires operator intervention)
- Does not affect blockchain state correctness, only node availability

This fits the Medium severity definition: "State inconsistencies requiring intervention" - the node's internal memory state becomes inconsistent with unbounded growth, requiring operator intervention to resolve.

## Likelihood Explanation

**Likelihood: High**

This vulnerability will manifest in all production validator deployments given sufficient time:

1. **Natural Occurrence:** Batch timeouts are tracked as normal operational metrics, indicating they are expected events rather than rare edge cases.

2. **No Recovery Mechanism:** Code analysis confirms that `batch_info_to_time` entries are only removed in the successful completion path. There is no cleanup logic in `expire()`, `CommitNotification`, or any other code path.

3. **Permanent Accumulation:** The leak is permanent until node restart - every timed-out batch leaves an entry that persists indefinitely.

4. **Network Stress Amplification:** During network issues or high load, batch expiry rates increase, accelerating the memory leak proportionally.

Given that batch expiry is a documented operational occurrence and there is no cleanup mechanism, this leak will eventually affect all running validators.

## Recommendation

Add cleanup logic to the `expire()` function to remove entries from `batch_info_to_time` when batches timeout:

```rust
async fn expire(&mut self) {
    let mut batch_ids = vec![];
    for signed_batch_info_info in self.timeouts.expire() {
        // ADD THIS LINE: Remove from batch_info_to_time on expiry
        self.batch_info_to_time.remove(&signed_batch_info_info);
        
        if let Some(state) = self.batch_info_to_proof.remove(&signed_batch_info_info) {
            if !state.completed {
                batch_ids.push(signed_batch_info_info.batch_id());
            }
            Self::update_counters_on_expire(&state);
            // ... rest of existing logic
        }
    }
    // ... rest of function
}
```

## Proof of Concept

The memory leak can be demonstrated through static code analysis:

1. Batch initialization adds to both HashMaps at lines 290-304
2. Successful completion removes from `batch_info_to_time` at line 340  
3. Timeout expiry only removes from `batch_info_to_proof` at line 372
4. No other code paths interact with `batch_info_to_time` (verified via codebase search)

A runtime PoC would involve:
1. Starting a validator node
2. Monitoring the size of `batch_info_to_time` HashMap
3. Forcing batch timeouts through network delays or validator unavailability
4. Observing that `batch_info_to_time` grows monotonically while `batch_info_to_proof` is properly cleaned up
5. Confirming memory usage increases proportionally over time

This can be validated by instrumenting the ProofCoordinator with logging or metrics to track HashMap sizes.

---

**Notes:**

This vulnerability affects validator node availability through resource exhaustion. While it doesn't directly compromise consensus safety or cause fund loss, it requires manual operator intervention to resolve, fitting the Medium severity category. The high likelihood stems from batch timeouts being normal operational events with no automated cleanup mechanism for leaked entries.

### Citations

**File:** consensus/src/quorum_store/proof_coordinator.rs (L233-235)
```rust
    batch_info_to_proof: HashMap<BatchInfoExt, IncrementalProofState>,
    // to record the batch creation time
    batch_info_to_time: HashMap<BatchInfoExt, Instant>,
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L290-304)
```rust
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info_ext(signed_batch_info.batch_info().clone()),
            );
        } else {
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info(
                    signed_batch_info.batch_info().info().clone(),
                ),
            );
        }
        self.batch_info_to_time
            .entry(signed_batch_info.batch_info().clone())
            .or_insert(Instant::now());
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L338-346)
```rust
                let duration = self
                    .batch_info_to_time
                    .remove(signed_batch_info.batch_info())
                    .ok_or(
                        // Batch created without recording the time!
                        SignedBatchInfoError::NoTimeStamps,
                    )?
                    .elapsed();
                counters::BATCH_TO_POS_DURATION.observe_duration(duration);
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L369-402)
```rust
    async fn expire(&mut self) {
        let mut batch_ids = vec![];
        for signed_batch_info_info in self.timeouts.expire() {
            if let Some(state) = self.batch_info_to_proof.remove(&signed_batch_info_info) {
                if !state.completed {
                    batch_ids.push(signed_batch_info_info.batch_id());
                }
                Self::update_counters_on_expire(&state);

                // We skip metrics if the proof did not complete and did not get a self vote, as it
                // is considered a proof that was re-inited due to a very late vote.
                if !state.completed && !state.self_voted {
                    continue;
                }

                if !state.completed {
                    counters::TIMEOUT_BATCHES_COUNT.inc();
                    info!(
                        LogSchema::new(LogEvent::IncrementalProofExpired),
                        digest = signed_batch_info_info.digest(),
                        self_voted = state.self_voted,
                    );
                }
            }
        }
        if self
            .batch_generator_cmd_tx
            .send(BatchGeneratorCommand::ProofExpiration(batch_ids))
            .await
            .is_err()
        {
            warn!("Failed to send proof expiration to batch generator");
        }
    }
```

**File:** consensus/src/quorum_store/counters.rs (L734-740)
```rust
/// Count of the timeout batches at the sender side.
pub static TIMEOUT_BATCHES_COUNT: Lazy<IntCounter> = Lazy::new(|| {
    register_int_counter!(
        "quorum_store_timeout_batch_count",
        "Count of the timeout batches at the sender side."
    )
    .unwrap()
```
