# Audit Report

## Title
Unbounded Memory Exhaustion in State Snapshot Restore via Malicious Chunk Size Claims

## Summary
The state snapshot restore process in the backup-cli does not validate that the number of state values loaded from a chunk's blob file matches the claimed indices in the chunk metadata. An attacker can craft a malicious backup manifest where a single chunk claims to contain billions of accounts, causing the restore process to load all records into an unbounded Vec, leading to memory exhaustion and node crashes before proof verification occurs.

## Finding Description

The vulnerability exists in the state snapshot restore logic, which processes backup chunks without validating the correspondence between metadata claims and actual data size.

The `StateSnapshotChunk` struct contains metadata fields that claim index ranges: [1](#0-0) 

During restore, the `read_state_value` function loads all state values from the chunk's blob file into an unbounded Vec with no size validation: [2](#0-1) 

The restore process calls this function for each chunk and passes the resulting Vec directly to processing: [3](#0-2) 

**Critical Gap**: There is NO validation that `blobs.len() == chunk.last_idx - chunk.first_idx + 1`. The chunk metadata fields `first_idx` and `last_idx` are only used for logging and metrics, not for bounds checking.

**Attack Path**:
1. Attacker compromises backup storage or tricks operator into using malicious backup
2. Attacker creates StateSnapshotBackup manifest with chunk claiming: `first_idx: 0, last_idx: 10_000_000_000`
3. Corresponding blobs file contains 10 billion actual BCS-serialized (StateKey, StateValue) records
4. When restore runs, `read_state_value` reads all 10 billion records into memory via the unbounded loop
5. Node exhausts memory and crashes BEFORE proof verification (line 391 in JellyfishMerkleRestore) can occur

**Contrast with State-Sync Path**: The state-sync bootstrapper properly validates chunk sizes: [4](#0-3) 

This validation is MISSING in the backup restore path.

## Impact Explanation

This is **HIGH severity** per Aptos bug bounty criteria:

- **Validator node crashes**: Memory exhaustion causes immediate node failure
- **Service disruption**: Operators attempting restore from compromised backups experience repeated crashes
- **No recovery path**: Restore cannot complete, preventing disaster recovery scenarios
- **Denial of availability**: Affects node operators during critical restore operations

While not causing consensus violations or fund loss, this directly impacts validator node availability and operational resilience, qualifying as "Validator node slowdowns/crashes" under High Severity ($50,000 category).

The vulnerability breaks **Invariant #9**: "Resource Limits: All operations must respect gas, storage, and computational limits" - the restore operation violates memory resource limits.

## Likelihood Explanation

**Medium-High Likelihood**:

**Attacker Requirements**:
- Compromise backup storage location (S3 bucket, local filesystem, command adapter storage)
- OR social engineer operator to restore from attacker-controlled backup source
- Create malicious manifest + blobs file (technically straightforward)

**Exploitation Complexity**: Low
- BCS serialization format is well-documented
- No authentication/authorization checks on backup files
- Standard backup restore procedure triggers vulnerability automatically

**Real-World Scenarios**:
- Compromised backup storage credentials
- Supply chain attacks on backup infrastructure
- Malicious insider with backup access
- Operator using untrusted backup source during emergency recovery

The legitimate backup creation process uses 100,000 item chunks: [5](#0-4) 

However, this does not prevent external creation of malicious manifests with arbitrary chunk sizes.

## Recommendation

Implement chunk size validation in the restore path before loading data:

```rust
async fn read_state_value(
    storage: &Arc<dyn BackupStorage>,
    file_handle: FileHandle,
    expected_count: usize, // NEW: pass expected count from chunk metadata
) -> Result<Vec<(StateKey, StateValue)>> {
    const MAX_CHUNK_SIZE: usize = 100_000; // Match backup creation limit
    
    // Validate expected count before loading
    ensure!(
        expected_count <= MAX_CHUNK_SIZE,
        "Chunk claims {} items, exceeds maximum {}",
        expected_count,
        MAX_CHUNK_SIZE
    );
    
    let mut file = storage.open_for_read(&file_handle).await?;
    let mut chunk = Vec::with_capacity(expected_count); // Pre-allocate with validated size
    
    while let Some(record_bytes) = file.read_record_bytes().await? {
        chunk.push(bcs::from_bytes(&record_bytes)?);
        
        // Validate we don't exceed expected count during read
        ensure!(
            chunk.len() <= expected_count,
            "Chunk contains more items than claimed: {} > {}",
            chunk.len(),
            expected_count
        );
    }
    
    // Validate final count matches expectation
    ensure!(
        chunk.len() == expected_count,
        "Chunk size mismatch: expected {}, got {}",
        expected_count,
        chunk.len()
    );
    
    Ok(chunk)
}
```

Update call site:
```rust
let expected_count = (chunk.last_idx - chunk.first_idx + 1);
let blobs = Self::read_state_value(&storage, chunk.blobs.clone(), expected_count).await?;
```

This ensures:
1. Maximum chunk size enforcement (100,000 items)
2. Early rejection of oversized claims before memory allocation
3. Validation that actual data matches metadata claims
4. Consistent bounds checking throughout the read process

## Proof of Concept

```rust
#[cfg(test)]
mod security_tests {
    use super::*;
    use crate::storage::test_util::start_test_db_with_storage;
    use aptos_temppath::TempPath;
    use std::io::Write;
    
    #[tokio::test]
    async fn test_malicious_chunk_memory_exhaustion() {
        // Setup test storage
        let tmpdir = TempPath::new();
        let storage = Arc::new(start_test_db_with_storage(&tmpdir));
        
        // Create malicious manifest claiming 100 million accounts
        let malicious_manifest = StateSnapshotBackup {
            version: 100,
            epoch: 1,
            root_hash: HashValue::zero(),
            chunks: vec![
                StateSnapshotChunk {
                    first_idx: 0,
                    last_idx: 100_000_000, // Claims 100M accounts
                    first_key: HashValue::zero(),
                    last_key: HashValue::new([0xFF; 32]),
                    blobs: "malicious_blobs.bin".to_string(),
                    proof: "proof.bin".to_string(),
                }
            ],
            proof: "backup_proof.bin".to_string(),
        };
        
        // Create blob file with 100M actual records
        // Each record: 4-byte size prefix + BCS(StateKey, StateValue)
        let mut blob_file = std::fs::File::create(tmpdir.path().join("malicious_blobs.bin")).unwrap();
        for i in 0..100_000_000 {
            let key = StateKey::raw(format!("key_{}", i).as_bytes());
            let value = StateValue::new_legacy(vec![0u8; 100]);
            let record = bcs::to_bytes(&(key, value)).unwrap();
            let size = (record.len() as u32).to_be_bytes();
            blob_file.write_all(&size).unwrap();
            blob_file.write_all(&record).unwrap();
        }
        
        // Attempt restore - should exhaust memory
        let restore_controller = StateSnapshotRestoreController::new(
            StateSnapshotRestoreOpt {
                manifest_handle: "malicious_manifest.json".to_string(),
                version: 100,
                validate_modules: false,
                restore_mode: StateSnapshotRestoreMode::Default,
            },
            GlobalRestoreOptions::default(),
            storage,
            None,
        );
        
        // This will consume massive memory and likely OOM before completing
        let result = restore_controller.run().await;
        
        // In production, node would crash with OOM
        // In test with memory limits, this should fail
        assert!(result.is_err(), "Should fail due to memory constraints");
    }
}
```

**Notes**:
- The PoC demonstrates the vulnerability but requires significant disk space and time for 100M records
- A smaller test (1M records) can demonstrate the unbounded allocation issue
- Production exploitation would target node memory limits (typically 32-64GB), requiring ~10-50M accounts depending on value sizes
- The vulnerability is exploitable before any cryptographic verification occurs, as proof checking happens in `JellyfishMerkleRestore::add_chunk_impl` AFTER the Vec is already in memory

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L12-27)
```rust
pub struct StateSnapshotChunk {
    /// index of the first account in this chunk over all accounts.
    pub first_idx: usize,
    /// index of the last account in this chunk over all accounts.
    pub last_idx: usize,
    /// key of the first account in this chunk.
    pub first_key: HashValue,
    /// key of the last account in this chunk.
    pub last_key: HashValue,
    /// Repeated `len(record) + record` where `record` is BCS serialized tuple
    /// `(key, state_value)`
    pub blobs: FileHandle,
    /// BCS serialized `SparseMerkleRangeProof` that proves this chunk adds up to the root hash
    /// indicated in the backup (`StateSnapshotBackup::root_hash`).
    pub proof: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L187-215)
```rust
        let futs_iter = chunks.into_iter().enumerate().map(|(chunk_idx, chunk)| {
            let storage = storage.clone();
            async move {
                tokio::spawn(async move {
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
                    Result::<_>::Ok((chunk_idx, chunk, blobs, proof))
                })
                .await?
            }
        });
        let con = self.concurrent_downloads;
        let mut futs_stream = stream::iter(futs_iter).buffered_x(con * 2, con);
        let mut start = None;
        while let Some((chunk_idx, chunk, mut blobs, proof)) = futs_stream.try_next().await? {
            start = start.or_else(|| Some(Instant::now()));
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["add_state_chunk"]);
            let receiver = receiver.clone();
            if self.validate_modules {
                blobs = tokio::task::spawn_blocking(move || {
                    Self::validate_modules(&blobs);
                    blobs
                })
                .await?;
            }
            tokio::task::spawn_blocking(move || {
                receiver.lock().as_mut().unwrap().add_chunk(blobs, proof)
            })
            .await??;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L253-266)
```rust
    async fn read_state_value(
        storage: &Arc<dyn BackupStorage>,
        file_handle: FileHandle,
    ) -> Result<Vec<(StateKey, StateValue)>> {
        let mut file = storage.open_for_read(&file_handle).await?;

        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L937-946)
```rust
        // Verify the end index and number of state values is valid
        let expected_num_state_values = state_value_chunk_with_proof
            .last_index
            .checked_sub(state_value_chunk_with_proof.first_index)
            .and_then(|version| version.checked_add(1)) // expected_num_state_values = last_index - first_index + 1
            .ok_or_else(|| {
                Error::IntegerOverflow("The expected number of state values has overflown!".into())
            })?;
        let num_state_values = state_value_chunk_with_proof.raw_values.len() as u64;
        if expected_num_state_values != num_state_values {
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L276-290)
```rust
        const CHUNK_SIZE: usize = if cfg!(test) { 2 } else { 100_000 };

        let count = self.client.get_state_item_count(self.version()).await?;
        let version = self.version();
        let client = self.client.clone();

        let chunks_stream = futures::stream::unfold(0, move |start_idx| async move {
            if start_idx >= count {
                return None;
            }

            let next_start_idx = start_idx + CHUNK_SIZE;
            let chunk_size = CHUNK_SIZE.min(count - start_idx);

            Some(((start_idx, chunk_size), next_start_idx))
```
