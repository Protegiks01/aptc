# Audit Report

## Title
Denial of Service via Unbounded `utils::powers()` in DKG Sigma Protocol Verification

## Summary
The `utils::powers()` function has O(n) complexity for computing n powers, and can be exploited for denial of service in the DKG (Distributed Key Generation) sigma protocol verification path. An attacker can craft a malicious weighted transcript with arbitrarily large inner vector dimensions, causing validators to allocate excessive memory and perform millions of field multiplications during verification, leading to node slowdowns or crashes.

## Finding Description

The security question asks about `verify_msm_terms()` at line 132 of `msm.rs`, which is currently unused (all call sites are commented out). [1](#0-0)  However, the underlying issue with `utils::powers()` manifests in a different, **actively used** code path: the sigma protocol verification in DKG transcript validation.

**Complexity Analysis:**
The `utils::powers()` function has **O(n) time and space complexity**, not O(n^2). [2](#0-1)  It performs a single loop of n iterations, each doing one multiplication.

**The Attack Vector:**

When verifying weighted DKG transcripts, the code calls `hom.verify()` which triggers sigma protocol verification. [3](#0-2) 

The verification flow:
1. `msm_terms_for_verify()` counts total elements in the public statement via `public_statement.clone().into_iter().count()` [4](#0-3) 

2. This count is passed to `utils::powers(beta, number_of_beta_powers)` [5](#0-4) 

3. The public statement is a `TupleCodomainShape` containing the transcript's Cs, Rs, and Vs fields [6](#0-5) 

4. `WeightedCodomainShape` flattens all nested vectors when iterated: `self.chunks.into_iter().flatten().flatten()` and `self.randomness.into_iter().flatten()` [7](#0-6) 

**Missing Validation:**
The verification only checks outer dimensions (Cs.len() and Vs.len() must equal num_players) but **does not validate inner dimensions**: [8](#0-7) 

An attacker can craft a transcript with:
- `Cs.len() = num_players` ✓ (passes check)
- `Cs[i].len() = 1,000,000` ✗ (unchecked!)
- `Cs[i][j].len() = 1,000` ✗ (unchecked!)
- Total flattened elements = billions

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**High Severity** - This qualifies as "Validator node slowdowns" per the Aptos bug bounty program.

When a malicious transcript is submitted and validators attempt verification:
1. The iterator count materializes billions of elements
2. `utils::powers()` allocates a `Vec` with billions of `ScalarField` elements (memory exhaustion)
3. Performs billions of field multiplications (CPU exhaustion)
4. Validator node becomes unresponsive or crashes
5. Multiple validators affected simultaneously if transcript is broadcast

This is a **targeted availability attack** on the DKG subsystem, disrupting validator operations during epoch transitions.

## Likelihood Explanation

**Medium-to-High likelihood:**
- Attacker can craft malicious transcripts via BCS serialization
- No authentication required to submit transcripts
- No size limits on transcript deserialization
- The sigma protocol verification happens **before** the range proof validation that would detect structure mismatches [9](#0-8) 
- Attack is repeatable and requires minimal resources from attacker side

## Recommendation

Add explicit validation of inner dimensions before sigma protocol verification:

```rust
// In weighted_transcriptv2.rs, after line 487, add:

// Validate total flattened size of Cs matches expected bounds
let cs_flat: Vec<_> = self.subtrs.Cs.iter().flatten().flatten().collect();
if cs_flat.len() != sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize {
    bail!(
        "Expected {} total ciphertext chunks, but got {}",
        sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
        cs_flat.len()
    );
}

// Validate Rs dimensions
let rs_flat: Vec<_> = self.subtrs.Rs.iter().flatten().collect();
if rs_flat.len() != sc.get_total_num_players() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize {
    bail!(
        "Expected {} randomness elements, but got {}",
        sc.get_total_num_players() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
        rs_flat.len()
    );
}

// Validate Vs dimensions
let vs_flat: Vec<_> = self.subtrs.Vs.iter().flatten().collect();
if vs_flat.len() != sc.get_total_weight() {
    bail!("Expected {} commitment shares, but got {}", sc.get_total_weight(), vs_flat.len());
}
```

This ensures the transcript structure matches expected dimensions **before** expensive cryptographic operations.

## Proof of Concept

```rust
// Proof of Concept: Craft malicious transcript
use aptos_dkg::pvss::chunky::weighted_transcriptv2::*;
use ark_bls12_381::{Bls12_381, G1Projective, G2Projective};

fn craft_malicious_transcript() -> Subtranscript<Bls12_381> {
    let num_players = 10; // Valid outer dimension
    let malicious_inner_size = 1_000_000; // Huge inner dimension
    
    let mut Cs = Vec::new();
    for _ in 0..num_players {
        let mut player_cs = Vec::new();
        for _ in 0..malicious_inner_size {
            // Create huge inner vectors
            player_cs.push(vec![G1Projective::default(); 1000]);
        }
        Cs.push(player_cs);
    }
    
    let Rs = vec![vec![G1Projective::default(); malicious_inner_size]; num_players];
    let Vs = vec![vec![G2Projective::default(); malicious_inner_size]; num_players];
    
    Subtranscript {
        V0: G2Projective::default(),
        Vs,
        Cs,
        Rs,
    }
}

// When this transcript is verified:
// 1. Total elements = 10 * 1M * 1000 = 10 billion
// 2. utils::powers(beta, 10_000_000_000) attempts to allocate 10B elements
// 3. Node crashes or becomes unresponsive
```

## Notes

While the specific function `verify_msm_terms()` mentioned in the security question is currently unused, the broader security concern about `utils::powers()` DoS is valid and exploitable through the sigma protocol verification path. The O(n) complexity itself is not the issue—the problem is the **lack of bounds checking on n** before calling the function with potentially attacker-controlled values.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L474-487)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L514-529)
```rust
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    TupleCodomainShape(
                        self.sharing_proof.range_proof_commitment.clone(),
                        chunked_elgamal::WeightedCodomainShape {
                            chunks: self.subtrs.Cs.clone(),
                            randomness: self.subtrs.Rs.clone(),
                        },
                    ),
                    chunked_scalar_mul::CodomainShape(self.subtrs.Vs.clone()),
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L532-539)
```rust
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L564-564)
```rust
        // let (sigma_bases, sigma_scalars, beta_powers) = hom.verify_msm_terms(
```

**File:** crates/aptos-crypto/src/utils.rs (L12-25)
```rust
pub fn powers<T>(base: T, count: usize) -> Vec<T>
where
    T: MulAssign + One + Copy,
{
    let mut powers = Vec::with_capacity(count);
    let mut current = T::one();

    for _ in 0..count {
        powers.push(current);
        current *= base;
    }

    powers
}
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L97-97)
```rust
        let powers_of_beta = utils::powers(beta, number_of_beta_powers);
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L120-120)
```rust
        let number_of_beta_powers = public_statement.clone().into_iter().count(); // TODO: maybe pass the into_iter version in merge_msm_terms?
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L177-181)
```rust
    fn into_iter(self) -> Self::IntoIter {
        let mut combined: Vec<T> = self.chunks.into_iter().flatten().flatten().collect();
        combined.extend(self.randomness.into_iter().flatten());
        combined.into_iter()
    }
```
