# Audit Report

## Title
Byzantine Peers Can Exploit Bidirectional Health Check Reset to Avoid Disconnection Despite Chronic Unresponsiveness

## Summary
The health checker's failure counting mechanism can be gamed by Byzantine peers through strategic use of inbound ping messages. A malicious peer can repeatedly fail to respond to outbound health checks while sending periodic inbound pings to reset their failure counter, allowing them to remain connected indefinitely despite being chronically unresponsive.

## Finding Description

The health checker protocol tracks per-peer failure counts and disconnects peers when failures exceed a configurable threshold (default: 3). [1](#0-0)  However, the failure counter is reset through two independent mechanisms that create an exploitable asymmetry.

The disconnection check occurs when an outbound ping fails: [2](#0-1) 

The failure counter can be reset in two ways:

1. **Successful outbound ping response**: When a peer successfully responds to our ping, the counter resets via `reset_peer_round_state()`. [3](#0-2) 

2. **Receiving inbound ping**: When a peer sends us a ping request, we **unconditionally** reset their failure counter via `reset_peer_failures()`. [4](#0-3) 

The `reset_peer_failures()` method unconditionally sets failures to 0: [5](#0-4) 

**The Core Vulnerability**: Receiving an inbound ping from a peer does NOT prove that the peer will respond to outbound pings. These are independent health indicators that should be tracked separately, but the current implementation conflates them.

**Exploitation Scenario**:
1. Byzantine peer connects to honest node
2. Honest node sends periodic outbound pings (every 10 seconds by default)
3. Byzantine peer ignores 3 consecutive outbound pings (failure count reaches 3)
4. Just before the 4th ping, Byzantine peer sends an inbound ping to the honest node
5. Honest node receives inbound ping and unconditionally resets Byzantine peer's failure counter to 0
6. Byzantine peer repeats this pattern indefinitely

The peer maintains connectivity while being responsive only ~25% of the time (1 inbound ping per 4 outbound ping intervals). The threshold value is discoverable from the open-source codebase or through trial-and-error. [6](#0-5) 

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program criteria for "Validator node slowdowns" and "Significant protocol violations":

**If Byzantine Validators Exploit This**:
- Consensus delays: Unresponsive validators cause timeout-based delays in block production
- Increased round times: Other validators waste time waiting for responses from strategically unresponsive peers
- Degraded network resilience: The actual Byzantine tolerance is reduced since malicious validators remain in the active set while contributing minimally

**If Byzantine Full Nodes Exploit This**:
- State sync delays: Full nodes attempting to sync state waste resources on unresponsive peers
- Mempool inefficiency: Transaction propagation is degraded
- Wasted connection slots: Limited connection slots are occupied by unreliable peers

**Amplification via Coordination**: Multiple Byzantine nodes could coordinate this pattern, with each peer sending inbound pings to others in the coordinated set to keep all of them connected, amplifying the degradation effect.

**Why Not Critical**: This does not directly cause consensus safety violations, fund theft, or permanent network partition. However, it significantly degrades network performance and violates protocol assumptions about peer reliability.

## Likelihood Explanation

**High Likelihood** - This attack is:
- **Easy to execute**: Requires only basic network peer capabilities (connect, send pings, ignore received pings)
- **Low resource cost**: Minimal computation or bandwidth required
- **Hard to detect**: The behavior appears as natural network variability - intermittent connectivity is common in distributed systems
- **No special privileges needed**: Any peer accepted into the network can perform this attack
- **Discoverable threshold**: The `ping_failures_tolerated` value is in public source code and defaults to 3

The only requirement is that the attacker can connect to the network as a peer, which is the normal operation for both validators and full nodes.

## Recommendation

**Separate inbound and outbound health tracking**: The failure counter should independently track outbound ping failures and should NOT be reset by inbound ping activity. Receiving an inbound ping only proves the peer can initiate health checks, not that they respond to them.

**Proposed Fix**:

```rust
// In interface.rs - HealthCheckData structure:
pub struct HealthCheckData {
    pub round: u64,
    pub outbound_failures: u64,  // Track outbound ping failures
    pub last_inbound_ping: Option<u64>,  // Track inbound ping activity separately
}

// In mod.rs - handle_ping_request():
fn handle_ping_request(
    &mut self,
    peer_id: PeerId,
    ping: Ping,
    protocol: ProtocolId,
    res_tx: oneshot::Sender<Result<Bytes, RpcError>>,
) {
    // ... existing pong response code ...
    
    // Record inbound ping timestamp but DO NOT reset outbound failure counter
    self.network_interface.record_inbound_ping(peer_id, self.round);
    
    let _ = res_tx.send(Ok(message.into()));
}

// In mod.rs - handle_ping_response():
// Only reset outbound_failures when peer successfully responds to OUR ping
if pong.0 == req_nonce {
    self.network_interface.reset_outbound_failures(peer_id, round);
}

// Disconnection logic remains based on outbound_failures only
if outbound_failures > self.ping_failures_tolerated {
    // disconnect
}
```

**Alternative Mitigation** (if full separation is not desired):
- Implement exponential backoff for reset effectiveness
- Track success/failure ratio over a time window instead of absolute count
- Add rate limiting on how frequently inbound pings can reset the counter (e.g., max once per N rounds)

## Proof of Concept

The following test demonstrates the vulnerability by showing that a peer can fail outbound pings but avoid disconnection by sending inbound pings:

```rust
#[tokio::test]
async fn byzantine_peer_exploits_inbound_ping_reset() {
    let ping_failures_tolerated = 3;
    let (mut harness, health_checker) = TestHarness::new_permissive(ping_failures_tolerated);

    let test = async move {
        let peer_id = PeerId::new([0x42; PeerId::LENGTH]);
        harness.send_new_peer_notification(peer_id).await;

        // Repeat the exploit pattern 3 times to show it works indefinitely
        for _iteration in 0..3 {
            // Peer fails to respond to 3 outbound pings (reaching threshold)
            for _ in 0..ping_failures_tolerated {
                harness.trigger_ping().await;
                harness.expect_ping_send_not_ok().await;
            }
            
            // At this point, peer should be at failure threshold (3 failures)
            // Next failure would trigger disconnection
            
            // Byzantine peer sends inbound ping to reset counter
            let res_rx = harness.send_inbound_ping(peer_id, 0).await;
            expect_pong(res_rx).await;
            
            // Counter is now reset to 0, disconnection avoided
            // Peer can repeat this pattern indefinitely
        }
        
        // After 3 iterations of 3 failures each (9 total failures),
        // peer should be disconnected, but they're still connected
        // because they gamed the system with inbound pings
        
        // Verify peer is still connected (no disconnect happened)
        assert!(harness.peers_and_metadata
            .get_connected_peers(NetworkId::Validator)
            .contains(&peer_id));
    };
    
    future::join(health_checker.start(), test).await;
}
```

This test would demonstrate that a peer can maintain connectivity through repeated cycles of failing outbound pings (staying at the threshold) while strategically sending inbound pings to reset their failure counter, effectively being unresponsive 75% of the time without disconnection.

**Notes**

The vulnerability exists because the health checker conflates two independent measurements:
1. **Inbound health**: Can the peer initiate health checks to us?
2. **Outbound health**: Does the peer respond to our health checks?

A peer being able to send us pings (proving inbound health) does not prove they will respond to our pings (outbound health). Byzantine peers can exploit this conflation to maintain connectivity while being selectively unresponsive, degrading network performance without triggering protective disconnection mechanisms.

This is particularly concerning for validator networks where consensus performance depends on timely peer responses. The default configuration allows peers to be unresponsive 75% of the time before the next disconnection check, and by timing inbound pings appropriately, they can avoid disconnection indefinitely.

### Citations

**File:** config/src/config/network_config.rs (L40-40)
```rust
pub const PING_FAILURES_TOLERATED: u64 = 3;
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L109-109)
```rust
    ping_failures_tolerated: u64,
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L302-303)
```rust
        // Record Ingress HC here and reset failures.
        self.network_interface.reset_peer_failures(peer_id);
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L326-329)
```rust
                    // Update last successful ping to current round.
                    // If it's not in storage, don't bother updating it
                    self.network_interface
                        .reset_peer_round_state(peer_id, round);
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L360-364)
```rust
                let failures = self
                    .network_interface
                    .get_peer_failures(peer_id)
                    .unwrap_or(0);
                if failures > self.ping_failures_tolerated {
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L120-123)
```rust
    pub fn reset_peer_failures(&mut self, peer_id: PeerId) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            health_check_data.failures = 0;
        }
```
