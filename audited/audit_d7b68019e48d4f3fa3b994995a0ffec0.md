# Audit Report

## Title
Module Validation Bypass via Race Condition in requires_module_validation()

## Summary
A race condition in the `requires_module_validation()` function allows transactions to be committed without proper module validation. When transaction status changes from `Executing` to `Executed` between the validation requirement check and processing, and the transaction subsequently gets aborted and re-executed, the new incarnation can bypass module validation entirely.

## Finding Description

The vulnerability exists in the interaction between `requires_module_validation()` in `scheduler_status.rs` and the module validation requirement tracking in `cold_validation.rs`. [1](#0-0) 

The function acquires a lock, checks the transaction status, and returns the incarnation with a boolean indicating execution state. However, the lock is released immediately after the check. [2](#0-1) 

The caller in `activate_pending_requirements()` iterates through transactions without holding locks simultaneously, creating a race window where:

1. Thread A calls `requires_module_validation(txn)` → returns `(incarnation_N, true)` for `Executing` status
2. Thread B calls `finish_execution()` → changes status to `Executed`, performs validation
3. Thread C aborts the transaction → incarnation advances to N+1
4. Thread A records stale data `(incarnation_N, true)` in active requirements

Later, when the dedicated worker processes this requirement: [3](#0-2) 

The `defer_module_validation()` detects the incarnation mismatch and returns `None`, causing `validation_requirement_processed()` to be called with `validation_still_needed=false`. [4](#0-3) 

When `validation_still_needed=false`, the deferred status is **not** updated. The commit check then fails to block the new incarnation: [5](#0-4) 

The check compares `deferred_status[txn]` (set for incarnation N) against `blocked_incarnation_status(incarnation_N+1)`, which are different values, allowing the commit to proceed without validation.

**Attack Scenario:**
1. Transaction T3 commits and publishes module M
2. Transaction T5 at incarnation 0 is executing (reading old module M)
3. Validation requirements are recorded for transactions 4-9
4. `activate_pending_requirements()` scans: sees T5 is `Executing(0)`, records `(0, true)`
5. T5 finishes execution, validates with deferred requirements, completes
6. T5 is aborted by T4, incarnation advances to 1
7. T5 re-executes at incarnation 1, reads newly published module M
8. Dedicated worker processes stale requirement for T5 incarnation 0, discards it
9. T5 incarnation 1 commits **without module validation**

## Impact Explanation

This vulnerability breaks the **Transaction Validation** and **Deterministic Execution** invariants:

- Transactions can be committed with unvalidated module reads
- Different validators may have different timing, causing some to validate and others to skip validation
- This can lead to consensus splits where validators disagree on transaction outcomes
- Severity: **Medium** - State inconsistencies requiring intervention, as different nodes may commit different state roots

The impact is limited to scenarios with concurrent module publishing and transaction aborts, but when triggered, it violates critical consensus properties.

## Likelihood Explanation

The likelihood is **Medium** because it requires:
- Concurrent transaction execution (normal operation mode)
- Module publishing transactions (less common but regular occurrence)
- Transaction aborts during validation window (common in contended workloads)
- Specific timing: status change between check and recording

While each condition individually is common, the precise race window is narrow. However, in high-throughput scenarios with frequent module updates (e.g., contract upgrades), this becomes more probable.

## Recommendation

Fix the race condition by either:

**Option 1: Atomic snapshot with verification**
Modify `activate_pending_requirements()` to verify incarnations haven't changed:

```rust
let new_versions: BTreeMap<TxnIndex, (Incarnation, bool)> = (starting_idx..ending_idx)
    .filter_map(|txn_idx| {
        let status = &statuses.statuses[txn_idx as usize];
        let guard = status.status_with_incarnation.lock();
        
        match guard.status {
            SchedulingStatus::Executing(_) => Some((txn_idx, (guard.incarnation(), true))),
            SchedulingStatus::Executed => Some((txn_idx, (guard.incarnation(), false))),
            _ => None,
        }
    })
    .collect();

// After collecting, verify all incarnations are still valid
for (txn_idx, (incarnation, _)) in &new_versions {
    if statuses.incarnation(*txn_idx) > *incarnation {
        // Incarnation advanced, discard this requirement entirely
        return Ok(true); // Reset worker
    }
}
```

**Option 2: Track validation per incarnation correctly**
When `validation_still_needed=false` due to incarnation mismatch, clear the deferred status:

```rust
if validation_still_needed {
    self.deferred_requirements_status[txn_idx as usize]
        .fetch_max(blocked_incarnation_status(incarnation), Ordering::Relaxed);
} else if /* incarnation mismatch detected */ {
    // Clear stale validation status
    self.deferred_requirements_status[txn_idx as usize]
        .store(0, Ordering::Relaxed);
}
```

## Proof of Concept

```rust
#[test]
fn test_module_validation_race_bypass() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let num_txns = 10;
    let statuses = ExecutionStatuses::new(num_txns);
    let requirements = ColdValidationRequirements::<ModuleId>::new(num_txns);
    
    // Transaction 5 starts executing
    let incarnation_0 = statuses.start_executing(5).unwrap().unwrap();
    assert_eq!(incarnation_0, 0);
    
    // Simulate module publish at txn 3
    requirements.record_requirements(0, 3, 9, BTreeSet::from([module_id_test()])).unwrap();
    
    let barrier = Arc::new(Barrier::new(2));
    let statuses_clone = Arc::new(statuses);
    let requirements_clone = Arc::new(requirements);
    
    // Thread 1: Start scanning requirements
    let b1 = barrier.clone();
    let s1 = statuses_clone.clone();
    let handle1 = thread::spawn(move || {
        // This will see txn 5 as Executing(0)
        let result = s1.requires_module_validation(5);
        b1.wait(); // Sync point
        result
    });
    
    // Thread 2: Finish execution and abort
    let b2 = barrier.clone();
    let s2 = statuses_clone.clone();
    let handle2 = thread::spawn(move || {
        b2.wait(); // Sync point
        // Finish execution
        s2.finish_execution(5, 0).unwrap();
        // Abort immediately
        s2.start_abort(5, 0).unwrap();
        s2.finish_abort(5, 0, false).unwrap();
        // Re-execute
        s2.start_executing(5).unwrap();
        s2.finish_execution(5, 1).unwrap();
    });
    
    let validation_req = handle1.join().unwrap();
    handle2.join().unwrap();
    
    // Thread 1 saw (0, true), but txn is now at incarnation 1
    assert_eq!(validation_req, Some((0, true)));
    assert_eq!(statuses_clone.incarnation(5), 1);
    
    // Process the stale requirement
    requirements_clone.activate_pending_requirements(&statuses_clone).unwrap();
    
    // Check if txn 5 incarnation 1 is blocked - it should be, but isn't due to bug
    let is_blocked = requirements_clone.is_commit_blocked(5, 1);
    
    // BUG: Transaction can commit without validation!
    assert!(!is_blocked, "Transaction should be blocked but isn't - validation bypass!");
}
```

**Notes:**
The race condition is subtle and timing-dependent. The vulnerability allows transactions to bypass critical module validation checks, potentially causing consensus divergence between validators that process the race differently. This violates the fundamental requirement that all validators must execute transactions deterministically.

### Citations

**File:** aptos-move/block-executor/src/scheduler_status.rs (L793-805)
```rust
    pub(crate) fn requires_module_validation(
        &self,
        txn_idx: TxnIndex,
    ) -> Option<(Incarnation, bool)> {
        let status = &self.statuses[txn_idx as usize];
        let status_guard = status.status_with_incarnation.lock();

        match status_guard.status {
            SchedulingStatus::Executing(_) => Some((status_guard.incarnation(), true)),
            SchedulingStatus::Executed => Some((status_guard.incarnation(), false)),
            SchedulingStatus::PendingScheduling | SchedulingStatus::Aborted => None,
        }
    }
```

**File:** aptos-move/block-executor/src/cold_validation.rs (L370-381)
```rust
        if validation_still_needed {
            // min_idx_with_unprocessed_validation_requirement may be increased below, after
            // deferred status is already updated. When checking if txn can be committed, the
            // access order is opposite, ensuring that if minimum index is higher, we will
            // also observe the incremented count below (even w. Relaxed ordering).
            //
            // The reason for using fetch_max is because the deferred requirement can be
            // fulfilled by a different worker (the one executing the txn), which may report
            // the requirement as completed before the current worker sets the status here.
            self.deferred_requirements_status[txn_idx as usize]
                .fetch_max(blocked_incarnation_status(incarnation), Ordering::Relaxed);
        }
```

**File:** aptos-move/block-executor/src/cold_validation.rs (L421-431)
```rust
    pub(crate) fn is_commit_blocked(&self, txn_idx: TxnIndex, incarnation: Incarnation) -> bool {
        // The order of checks is important to avoid a concurrency bugs (since recording
        // happens in the opposite order). We first check that there are no unscheduled
        // requirements below (incl.) the given index, and then that there are no scheduled
        // but yet unfulfilled (validated) requirements for the index.
        self.min_idx_with_unprocessed_validation_requirement
            .load(Ordering::Relaxed)
            <= txn_idx
            || self.deferred_requirements_status[txn_idx as usize].load(Ordering::Relaxed)
                == blocked_incarnation_status(incarnation)
    }
```

**File:** aptos-move/block-executor/src/cold_validation.rs (L483-489)
```rust
        let new_versions: BTreeMap<TxnIndex, (Incarnation, bool)> = (starting_idx..ending_idx)
            .filter_map(|txn_idx| {
                statuses
                    .requires_module_validation(txn_idx)
                    .map(|(incarnation, is_executing)| (txn_idx, (incarnation, is_executing)))
            })
            .collect();
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1109-1134)
```rust
            if is_deferred {
                let defer_outcome = self.txn_statuses.defer_module_validation(
                    txn_idx,
                    incarnation,
                    modules_to_validate,
                )?;

                if defer_outcome == Some(false) {
                    // defer call did not succeed because the incarnation had finished execution.
                    // Ask the caller (the dedicated worker) to process the requirements normally.
                    return Ok(Some(TaskKind::ModuleValidation(
                        txn_idx,
                        incarnation,
                        modules_to_validate,
                    )));
                }

                self.cold_validation_requirements
                    .validation_requirement_processed(
                        worker_id,
                        txn_idx,
                        incarnation,
                        // When the defer call was not successful because the requirements were no
                        // longer relevant, validation_still_needed parameter must be passed as false.
                        defer_outcome == Some(true),
                    )?;
```
