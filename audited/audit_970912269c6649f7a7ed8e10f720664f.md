# Audit Report

## Title
Consensus Observer Denial of Service via Garbage Collection of Legitimate Blocks

## Summary
An attacker can exploit missing epoch/round validation in the pending block store to cause a Denial of Service. By flooding the store with blocks containing artificially high epoch/round values, the attacker forces garbage collection to preferentially remove legitimate blocks with lower epoch/round values, preventing the consensus observer from processing valid consensus updates.

## Finding Description

The consensus observer accepts ordered blocks from subscribed peers without validating that epoch/round values are reasonable relative to the current epoch state. While `pop_last()` at line 217 cannot directly select malicious blocks due to the `split_off()` operation, there is a critical vulnerability in the garbage collection mechanism. [1](#0-0) 

In `process_ordered_block_message()`, blocks are inserted into the pending block store after only checking if they're behind the last ordered block or already pending. There is **no validation** to ensure epoch/round values are within a reasonable range of the current epoch state. [2](#0-1) 

The pending block store uses a `BTreeMap<(u64, Round), Arc<PendingBlockWithMetadata>>` with capacity limits (150 blocks for mainnet, 300 for test networks). [3](#0-2) 

When capacity is reached, garbage collection is triggered: [4](#0-3) 

The critical flaw is at line 179: `pop_first()` removes the entry with the **LOWEST** (epoch, round) key due to BTreeMap's natural ordering. An attacker can exploit this by:

1. Establishing a subscription as a consensus publisher (normal network operation)
2. Sending 150+ blocks with artificially high epoch/round values (e.g., epoch 999999, rounds 0-149)
3. These blocks pass all validation checks and fill the pending block store
4. When legitimate blocks for the current epoch (e.g., epoch 10) arrive, they trigger garbage collection
5. `pop_first()` removes blocks with the lowest (epoch, round) - the **legitimate** blocks at epoch 10
6. The attacker's epoch 999999 blocks remain in the store
7. The observer cannot process legitimate consensus messages and falls behind

The epoch validation only occurs later in `process_ordered_block()` when blocks are removed from the pending store for processing: [5](#0-4) 

By this point, the damage is done - legitimate blocks have already been garbage collected.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program:

- **Validator node slowdowns**: The consensus observer cannot process legitimate blocks, causing the node to fall behind consensus
- **Significant protocol violations**: Breaks the consensus observer's ability to maintain synchronized state
- **Potential liveness impact**: If multiple observer nodes are attacked simultaneously, network observers may enter fallback mode, degrading network performance

While not a Critical severity issue (no direct fund loss or permanent network partition), this represents a significant availability attack that can impact multiple consensus observer nodes across the network.

## Likelihood Explanation

The attack likelihood is **MEDIUM to HIGH**:

**Attacker Requirements:**
- Must be a subscribed peer (validator or VFN) or compromise one
- Can send ordered block messages via established subscription
- Needs to send ~150-300 malicious blocks to fill the pending store

**Ease of Exploitation:**
- No cryptographic forgery required (only need valid subscription)
- No special timing or race conditions needed
- Attack persists until manual intervention or node restart
- Can target multiple observer nodes simultaneously

**Detection Difficulty:**
- Malicious blocks appear structurally valid (pass `verify_ordered_blocks()`)
- May appear as legitimate future-epoch blocks
- Requires monitoring of epoch/round distributions in pending store

## Recommendation

Add epoch/round validation before inserting blocks into the pending block store. The validation should ensure blocks are within a reasonable range of the current epoch state:

```rust
// In process_ordered_block_message(), after line 676:
let first_block = ordered_block.first_block();
let first_block_epoch_round = (first_block.epoch(), first_block.round());

// Get current epoch state to validate block is not too far in the future
let current_epoch = self.get_epoch_state().epoch;
let max_future_epoch_delta = 1; // Allow blocks from next epoch only

// Validate epoch is not unreasonably high
if first_block.epoch() > current_epoch + max_future_epoch_delta {
    warn!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Received block with epoch too far in future! Current epoch: {}, Block epoch: {}. Ignoring: {:?}",
            current_epoch, first_block.epoch(), first_block_epoch_round
        ))
    );
    increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
    return;
}
```

Additionally, consider changing the garbage collection strategy to remove based on insertion time rather than epoch/round ordering, or implement FIFO eviction for same-priority blocks.

## Proof of Concept

```rust
#[test]
fn test_dos_via_high_epoch_blocks() {
    // Setup: Create pending block store with capacity 10
    let consensus_observer_config = ConsensusObserverConfig {
        max_num_pending_blocks: 10,
        ..Default::default()
    };
    let pending_block_store = Arc::new(Mutex::new(
        PendingBlockStore::new(consensus_observer_config)
    ));
    
    // Step 1: Insert 10 legitimate blocks at epoch 10
    let mut legitimate_blocks = vec![];
    for i in 0..10 {
        let ordered_block = create_ordered_block(10, i * 100, 1, i);
        let observed_block = ObservedOrderedBlock::new_for_testing(ordered_block.clone());
        let pending_block = PendingBlockWithMetadata::new_with_arc(
            PeerNetworkId::random(),
            Instant::now(),
            observed_block,
        );
        pending_block_store.lock().insert_pending_block(pending_block);
        legitimate_blocks.push(ordered_block);
    }
    
    // Verify legitimate blocks are stored
    assert_eq!(pending_block_store.lock().blocks_without_payloads.len(), 10);
    
    // Step 2: Attacker inserts 10 blocks with artificially high epoch
    for i in 0..10 {
        let malicious_block = create_ordered_block(999999, i * 100, 1, i);
        let observed_block = ObservedOrderedBlock::new_for_testing(malicious_block);
        let pending_block = PendingBlockWithMetadata::new_with_arc(
            PeerNetworkId::random(),
            Instant::now(),
            observed_block,
        );
        pending_block_store.lock().insert_pending_block(pending_block);
    }
    
    // Step 3: Verify that legitimate blocks were garbage collected
    // and malicious high-epoch blocks remain
    let remaining_blocks = pending_block_store.lock().blocks_without_payloads.clone();
    assert_eq!(remaining_blocks.len(), 10);
    
    // All remaining blocks should have epoch 999999 (malicious)
    for ((epoch, _round), _block) in remaining_blocks.iter() {
        assert_eq!(*epoch, 999999, "Legitimate blocks should have been removed!");
    }
    
    // Step 4: Verify legitimate blocks can no longer be inserted
    let new_legitimate_block = create_ordered_block(10, 2000, 1, 0);
    let observed_block = ObservedOrderedBlock::new_for_testing(new_legitimate_block);
    let pending_block = PendingBlockWithMetadata::new_with_arc(
        PeerNetworkId::random(),
        Instant::now(),
        observed_block,
    );
    pending_block_store.lock().insert_pending_block(pending_block);
    
    // The new legitimate block should be immediately garbage collected
    let remaining_blocks = pending_block_store.lock().blocks_without_payloads.clone();
    for ((epoch, _round), _block) in remaining_blocks.iter() {
        assert_eq!(*epoch, 999999, "DoS successful: only malicious blocks remain!");
    }
}
```

## Notes

While the security question specifically asked about `pop_last()` selecting malicious blocks, the `split_off()` operation prevents that direct attack vector. However, this analysis uncovered a more serious vulnerability in the garbage collection mechanism that achieves a similar denial of service outcome through a different code path. The vulnerability leverages the same missing validation (no epoch/round reasonableness checks) and the same data structure (BTreeMap keyed by epoch/round) identified in the security question.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L673-714)
```rust
        // Get the epoch and round of the first block
        let first_block = ordered_block.first_block();
        let first_block_epoch_round = (first_block.epoch(), first_block.round());

        // Determine if the block is behind the last ordered block, or if it is already pending
        let last_ordered_block = self.observer_block_data.lock().get_last_ordered_block();
        let block_out_of_date =
            first_block_epoch_round <= (last_ordered_block.epoch(), last_ordered_block.round());
        let block_pending = self
            .observer_block_data
            .lock()
            .existing_pending_block(&ordered_block);

        // If the block is out of date or already pending, ignore it
        if block_out_of_date || block_pending {
            // Update the metrics for the dropped ordered block
            update_metrics_for_dropped_ordered_block_message(peer_network_id, &ordered_block);
            return;
        }

        // Update the metrics for the received ordered block
        update_metrics_for_ordered_block_message(peer_network_id, &ordered_block);

        // Create a new pending block with metadata
        let observed_ordered_block = ObservedOrderedBlock::new(ordered_block);
        let pending_block_with_metadata = PendingBlockWithMetadata::new_with_arc(
            peer_network_id,
            message_received_time,
            observed_ordered_block,
        );

        // If all payloads exist, process the block. Otherwise, store it
        // in the pending block store and wait for the payloads to arrive.
        if self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        } else {
            self.observer_block_data
                .lock()
                .insert_pending_block(pending_block_with_metadata);
        }
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L728-752)
```rust
        let epoch_state = self.get_epoch_state();
        if ordered_block.proof_block_info().epoch() == epoch_state.epoch {
            if let Err(error) = ordered_block.verify_ordered_proof(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify ordered proof! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                        ordered_block.proof_block_info(),
                        peer_network_id,
                        error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
                return;
            }
        } else {
            // Drop the block and log an error (the block should always be for the current epoch)
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Received ordered block for a different epoch! Ignoring: {:?}",
                    ordered_block.proof_block_info()
                ))
            );
            return;
        };
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L112-154)
```rust
    pub fn insert_pending_block(&mut self, pending_block: Arc<PendingBlockWithMetadata>) {
        // Get the first block in the ordered blocks
        let first_block = pending_block.ordered_block().first_block();

        // Insert the block into the store using the epoch round of the first block
        let first_block_epoch_round = (first_block.epoch(), first_block.round());
        match self.blocks_without_payloads.entry(first_block_epoch_round) {
            Entry::Occupied(_) => {
                // The block is already in the store
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "A pending block was already found for the given epoch and round: {:?}",
                        first_block_epoch_round
                    ))
                );
            },
            Entry::Vacant(entry) => {
                // Insert the block into the store
                entry.insert(pending_block.clone());
            },
        }

        // Insert the block into the hash store using the hash of the first block
        let first_block_hash = first_block.id();
        match self.blocks_without_payloads_by_hash.entry(first_block_hash) {
            Entry::Occupied(_) => {
                // The block is already in the hash store
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "A pending block was already found for the given block hash: {:?}",
                        first_block_hash
                    ))
                );
            },
            Entry::Vacant(entry) => {
                // Insert the block into the hash store
                entry.insert(pending_block);
            },
        }

        // Perform garbage collection if the store is too large
        self.garbage_collect_pending_blocks();
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L156-195)
```rust
    /// Garbage collects the pending blocks store by removing
    /// the oldest blocks if the store is too large.
    fn garbage_collect_pending_blocks(&mut self) {
        // Verify that both stores have the same number of entries.
        // If not, log an error as this should never happen.
        let num_pending_blocks = self.blocks_without_payloads.len() as u64;
        let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
        if num_pending_blocks != num_pending_blocks_by_hash {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "The pending block stores have different numbers of entries: {} and {} (by hash)",
                    num_pending_blocks, num_pending_blocks_by_hash
                ))
            );
        }

        // Calculate the number of blocks to remove
        let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
        let num_blocks_to_remove = num_pending_blocks.saturating_sub(max_pending_blocks);

        // Remove the oldest blocks if the store is too large
        for _ in 0..num_blocks_to_remove {
            if let Some((oldest_epoch_round, pending_block)) =
                self.blocks_without_payloads.pop_first()
            {
                // Log a warning message for the removed block
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "The pending block store is too large: {:?} blocks. Removing the block for the oldest epoch and round: {:?}",
                        num_pending_blocks, oldest_epoch_round
                    ))
                );

                // Remove the block from the hash store
                let first_block = pending_block.ordered_block().first_block();
                self.blocks_without_payloads_by_hash
                    .remove(&first_block.id());
            }
        }
    }
```

**File:** config/src/config/consensus_observer_config.rs (L72-72)
```rust
            max_num_pending_blocks: 150, // 150 blocks (sufficient for existing production networks)
```
