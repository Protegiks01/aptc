# Audit Report

## Title
Unbounded Memory Allocation in Backup Restore Due to Missing Magic Number Validation

## Summary
The Aptos backup format lacks magic number validation and file integrity checks, allowing attackers with write access to backup storage to cause denial-of-service by crafting malicious backup files with arbitrarily large record size prefixes. The `read_record_bytes()` function performs unbounded memory allocation based on untrusted size values read from backup files, leading to memory exhaustion and restore process crashes.

## Finding Description
The backup/restore system in Aptos uses a simple binary format consisting of a 4-byte big-endian size prefix followed by BCS-serialized data. The `read_record_bytes()` function reads this format without any validation: [1](#0-0) 

The vulnerability occurs at line 54 where the record size is read as an untrusted u32 value (up to 4GB), and line 60 where `BytesMut::with_capacity(record_size)` attempts to allocate that exact amount of memory without any bounds checking.

The backup format creation confirms there are no magic numbers or checksums written: [2](#0-1) 

This pattern is used throughout all backup types (epoch endings, state snapshots, transactions): [3](#0-2) [4](#0-3) [5](#0-4) 

**Attack Scenario:**
1. Attacker gains write access to backup storage (S3, GCS, local filesystem) through credential compromise, insider access, or storage service vulnerability
2. Attacker replaces legitimate backup files with malicious versions containing records with large size prefixes (e.g., 0x3FFFFFFF = ~1GB each)
3. Node operator initiates restore operation from the compromised backup
4. For each malicious record, `read_record_bytes()` attempts to allocate the specified memory amount
5. Multiple large allocations exhaust available memory, causing OOM kills of the restore process
6. Restore operation fails catastrophically, preventing node recovery

The storage layer provides no protection: [6](#0-5) 

While semantic validation (signature verification, Merkle proofs) occurs after deserialization, the memory exhaustion attack succeeds before any cryptographic validation can occur: [7](#0-6) 

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria:

- **"Validator node slowdowns"**: Restore operations consuming excessive memory slow down or crash node recovery
- **"API crashes"**: The restore process crashes due to out-of-memory conditions
- **Operational Security**: Critical infrastructure (backup/restore) becomes unreliable and vulnerable to tampering

**Resource Limits Invariant Violation**: The documented invariant states "All operations must respect gas, storage, and computational limits." Unbounded memory allocation from untrusted input violates this principle.

The impact is amplified because:
1. Backup/restore is a critical recovery mechanism for validators
2. Failed restores can prevent nodes from rejoining the network after incidents
3. No early detection mechanism exists for corrupted/malicious backups
4. The attack requires no blockchain-level privileges (only storage access)

## Likelihood Explanation
**Likelihood: Medium**

**Attack Requirements:**
- Write access to backup storage location (S3, GCS, etc.)
- Knowledge of the simple backup format structure

**Feasibility:**
- High: Trivial to create malicious backup files (4-byte size prefix manipulation)
- Medium: Requires compromised backup credentials or insider access
- Realistic scenarios include:
  - Compromised AWS/GCS IAM credentials
  - Supply chain attacks on backup infrastructure
  - Malicious operators with backup system access
  - Vulnerabilities in cloud storage services

**Complexity:** Low - the attack is straightforward to execute once storage access is obtained.

## Recommendation

**Immediate Fix:**
Add bounded memory allocation with configurable limits:

```rust
const MAX_RECORD_SIZE: usize = 100 * 1024 * 1024; // 100MB reasonable limit

async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
    // read record size
    let mut size_buf = BytesMut::with_capacity(4);
    self.read_full_buf_or_none(&mut size_buf).await?;
    if size_buf.is_empty() {
        return Ok(None);
    }

    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
    
    // ADD BOUNDS CHECK
    ensure!(
        record_size <= MAX_RECORD_SIZE,
        "Record size {} exceeds maximum allowed size {}",
        record_size,
        MAX_RECORD_SIZE
    );
    
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }

    let mut record_buf = BytesMut::with_capacity(record_size);
    self.read_full_buf_or_none(&mut record_buf).await?;
    if record_buf.is_empty() {
        bail!("Hit EOF when reading record.")
    }

    Ok(Some(record_buf.freeze()))
}
```

**Defense-in-Depth Enhancements:**

1. **Add magic number validation:**
```rust
const BACKUP_MAGIC: &[u8] = b"APTOSBACKUP\0";
const FORMAT_VERSION: u32 = 1;

// Write at file start:
file.write_all(BACKUP_MAGIC).await?;
file.write_all(&FORMAT_VERSION.to_be_bytes()).await?;

// Verify on read:
let mut magic = vec![0u8; BACKUP_MAGIC.len()];
file.read_exact(&mut magic).await?;
ensure!(magic == BACKUP_MAGIC, "Invalid backup file magic number");
```

2. **Add file-level checksums (SHA256)** to detect tampering
3. **Consider signing backup manifests** with operator keys for authenticity
4. **Implement progressive memory allocation** instead of allocating full size upfront

## Proof of Concept

```rust
#[cfg(test)]
mod attack_poc {
    use super::*;
    use tokio::io::AsyncWriteExt;
    use std::io::Cursor;

    #[tokio::test]
    async fn test_memory_exhaustion_attack() {
        // Create malicious backup with 1GB record size prefix
        let malicious_size: u32 = 1_000_000_000; // 1GB
        let mut malicious_backup = Vec::new();
        malicious_backup.extend_from_slice(&malicious_size.to_be_bytes());
        malicious_backup.extend_from_slice(&[0u8; 100]); // Minimal data
        
        // Attempt to read - this will try to allocate 1GB
        let mut cursor = Cursor::new(malicious_backup);
        
        // This should fail with OOM on memory-constrained systems
        // or succeed but allocate 1GB unnecessarily
        let result = cursor.read_record_bytes().await;
        
        // Current behavior: attempts allocation regardless of available memory
        // Expected behavior: should reject with "Record size exceeds limit" error
        match result {
            Ok(Some(bytes)) => {
                println!("VULNERABLE: Allocated {} bytes", bytes.len());
                assert!(false, "Should have rejected oversized record");
            },
            Err(e) => {
                // May fail due to OOM or incomplete read, but not validation
                println!("Failed (but not due to validation): {}", e);
            },
            _ => {}
        }
    }
    
    #[tokio::test]
    async fn test_multiple_large_records() {
        // Multiple 500MB records to exhaust memory
        let mut malicious_backup = Vec::new();
        for _ in 0..5 {
            let size: u32 = 500_000_000;
            malicious_backup.extend_from_slice(&size.to_be_bytes());
            malicious_backup.extend_from_slice(&[0u8; 100]);
        }
        
        let mut cursor = Cursor::new(malicious_backup);
        
        // Attempting to read all records will exhaust memory
        let mut records = Vec::new();
        while let Ok(Some(record)) = cursor.read_record_bytes().await {
            records.push(record);
            if records.len() >= 5 {
                break;
            }
        }
        
        println!("VULNERABLE: Successfully allocated {} records", records.len());
    }
}
```

## Notes

This vulnerability represents a defense-in-depth issue where the backup format's lack of integrity validation (magic numbers, checksums, signatures) combined with unbounded memory allocation creates a practical DoS vector. While the attack requires backup storage access (not blockchain-level privileges), this represents a realistic threat model given:

1. Cloud credential compromises are common
2. Supply chain attacks on infrastructure are increasing
3. The simplicity of the attack (trivial to execute)
4. The severity of impact (failed node recovery)

The fix is straightforward and should be implemented alongside broader backup format hardening measures.

### Citations

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-67)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
        if record_buf.is_empty() {
            bail!("Hit EOF when reading record.")
        }

        Ok(Some(record_buf.freeze()))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/backup.rs (L106-107)
```rust
            chunk_bytes.extend((record_bytes.len() as u32).to_be_bytes());
            chunk_bytes.extend(&record_bytes);
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L113-147)
```rust
                ensure!(
                    li.ledger_info().epoch() == next_epoch,
                    "LedgerInfo epoch not expected. Expected: {}, actual: {}.",
                    li.ledger_info().epoch(),
                    next_epoch,
                );
                let wp_manifest = waypoint_iter.next().ok_or_else(|| {
                    anyhow!("More LedgerInfo's found than waypoints in manifest.")
                })?;
                let wp_li = Waypoint::new_epoch_boundary(li.ledger_info())?;
                ensure!(
                    *wp_manifest == wp_li,
                    "Waypoints don't match. In manifest: {}, In chunk: {}",
                    wp_manifest,
                    wp_li,
                );
                if let Some(wp_trusted) = self.trusted_waypoints.get(&wp_li.version()) {
                    ensure!(
                        *wp_trusted == wp_li,
                        "Waypoints don't match. In backup: {}, trusted: {}",
                        wp_li,
                        wp_trusted,
                    );
                } else if let Some(pre_li) = previous_li {
                    pre_li
                        .ledger_info()
                        .next_epoch_state()
                        .ok_or_else(|| {
                            anyhow!(
                                "Next epoch state not found from LI at epoch {}.",
                                pre_li.ledger_info().epoch()
                            )
                        })?
                        .verify(&li)?;
                }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L167-169)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L261-263)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L112-112)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L98-109)
```rust
    async fn open_for_read(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
        let path = self.dir.join(file_handle);
        let file = OpenOptions::new()
            .read(true)
            .open(&path)
            .await
            .err_notes(&path)?;
        Ok(Box::new(file))
    }
```
