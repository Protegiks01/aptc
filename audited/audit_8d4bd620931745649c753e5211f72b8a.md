# Audit Report

## Title
Database Schema Mismatch Causes Incomplete Deletion of V2 Batches Leading to Unbounded Database Growth

## Summary
The `update_certified_timestamp` method in `batch_store.rs` only deletes expired batches from the V1 database schema, failing to delete V2 batches from the separate V2 column family. This causes permanent accumulation of expired V2 batches in the database, leading to unbounded storage growth and potential node slowdowns.

## Finding Description
The Aptos consensus layer uses a QuorumStore to manage transaction batches with two database schemas: V1 (using `BatchSchema` in the "batch" column family) and V2 (using `BatchV2Schema` in the "batch_v2" column family). These store different batch formats: `PersistedValue<BatchInfo>` for V1 and `PersistedValue<BatchInfoExt>` for V2. [1](#0-0) [2](#0-1) 

When batches expire during normal consensus operation, the `update_certified_timestamp` method is called on every block commit: [3](#0-2) 

This method clears expired batches from the in-memory cache but only deletes them from the V1 database schema: [4](#0-3) 

The critical bug is on line 536: `self.db.delete_batches(expired_keys)` only invokes the V1 deletion method, which operates on the "batch" column family: [5](#0-4) 

However, when V2 batches are enabled (via `enable_batch_v2` configuration), batches are created and stored in the separate "batch_v2" column family: [6](#0-5) [7](#0-6) 

The V2 deletion method exists but is never called during normal operation: [8](#0-7) 

**Attack Sequence:**
1. Validator enables `enable_batch_v2` configuration flag
2. V2 batches are created and stored in "batch_v2" column family via `save_batch_v2`
3. These batches are also cached in memory
4. On block commit, `notify_commit` calls `update_certified_timestamp`
5. `clear_expired_payload` removes expired V2 batches from cache
6. `delete_batches` is called but only deletes from "batch" column family
7. V2 batches remain permanently in "batch_v2" column family
8. Process repeats on every block commit, accumulating undeletable V2 batches

**Invariant Violations:**
- **State Consistency**: Expired batches should be completely removed from storage
- **Resource Limits**: Database storage must be bounded and properly managed

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria:

**Validator Node Slowdowns**: The unbounded accumulation of V2 batches causes:
- Continuous database growth without cleanup
- Increased disk I/O during database operations
- Slower node restart times as cache repopulation reads all accumulated V2 batches
- Degraded performance over time affecting consensus participation

**Significant Protocol Violations**: The bug breaks the fundamental guarantee that expired batches are cleaned up from storage, violating the QuorumStore's storage management invariants.

**State Inconsistencies**: On node restart, the `populate_cache_and_gc_expired_batches_v2` method loads all V2 batches from the database: [9](#0-8) 

Expired V2 batches that should have been deleted will be loaded back into memory if they fall within the expiration buffer window, potentially causing:
- Memory exhaustion from accumulated expired batches
- Confusion in batch retrieval logic
- Quota management inconsistencies

The configuration shows V2 batches are disabled by default but are a supported configurable feature: [10](#0-9) [11](#0-10) 

## Likelihood Explanation
**Likelihood: High (when enable_batch_v2 is enabled)**

- Triggers automatically on every block commit (multiple times per second)
- No attacker action required beyond enabling the feature flag
- Accumulates continuously without any cleanup mechanism
- Will manifest 100% of the time when V2 batches are used
- Currently mitigated only by the feature being disabled by default

The frequency of block commits (several per second) means expired V2 batches accumulate rapidly, with database growth proportional to consensus activity.

## Recommendation
The `update_certified_timestamp` method must distinguish between V1 and V2 batches and delete them from their respective column families. However, the current implementation clears the cache before deletion, making version detection impossible.

**Recommended Fix**: Modify `clear_expired_payload` to track batch versions and delete appropriately:

```rust
pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> (Vec<HashValue>, Vec<HashValue>) {
    let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
    let expired_digests = self.expirations.lock().expire(expiration_time);
    let mut v1_ret = Vec::new();
    let mut v2_ret = Vec::new();
    
    for h in expired_digests {
        let removed_value = match self.db_cache.entry(h) {
            Occupied(entry) => {
                if entry.get().expiration() <= expiration_time {
                    self.persist_subscribers.remove(entry.get().digest());
                    Some(entry.remove())
                } else {
                    None
                }
            },
            Vacant(_) => unreachable!("Expired entry not in cache"),
        };
        
        if let Some(value) = removed_value {
            let is_v2 = value.batch_info().is_v2();
            self.free_quota(value);
            if is_v2 {
                v2_ret.push(h);
            } else {
                v1_ret.push(h);
            }
        }
    }
    (v1_ret, v2_ret)
}

pub fn update_certified_timestamp(&self, certified_time: u64) {
    trace!("QS: batch reader updating time {:?}", certified_time);
    self.last_certified_time
        .fetch_max(certified_time, Ordering::SeqCst);

    let (v1_expired_keys, v2_expired_keys) = self.clear_expired_payload(certified_time);
    
    if let Err(e) = self.db.delete_batches(v1_expired_keys) {
        debug!("Error deleting v1 batches: {:?}", e)
    }
    if let Err(e) = self.db.delete_batches_v2(v2_expired_keys) {
        debug!("Error deleting v2 batches: {:?}", e)
    }
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_v2_batch_deletion_bug() {
    use aptos_temppath::TempPath;
    use aptos_types::validator_signer::ValidatorSigner;
    use std::sync::Arc;
    
    // Setup
    let tmp_dir = TempPath::new();
    let db = Arc::new(QuorumStoreDB::new(&tmp_dir));
    let signer = ValidatorSigner::random(None);
    let epoch = 1;
    
    // Create BatchStore with V2 enabled
    let batch_store = BatchStore::new(
        epoch,
        false,
        0,
        db.clone(),
        1_000_000,
        10_000_000,
        100,
        signer,
        Duration::from_secs(60).as_micros() as u64,
    );
    
    // Create and persist a V2 batch
    let batch_info = BatchInfoExt::new_v2(
        signer.author(),
        BatchId::new_for_test(1),
        epoch,
        1000, // expiration
        HashValue::random(),
        10,
        1000,
        0,
        BatchKind::Normal,
    );
    
    let persisted_value = PersistedValue::new(batch_info.clone(), Some(vec![]));
    batch_store.save(&persisted_value).unwrap();
    
    // Verify V2 batch exists in database
    assert!(db.get_batch_v2(batch_info.digest()).unwrap().is_some());
    
    // Advance time past expiration and call update_certified_timestamp
    batch_store.update_certified_timestamp(2000);
    
    // BUG: V2 batch still exists in database despite being expired
    assert!(db.get_batch_v2(batch_info.digest()).unwrap().is_some(), 
        "V2 batch was not deleted from database!");
    
    // V1 batches would be properly deleted
    // This demonstrates the inconsistency between V1 and V2 handling
}
```

## Notes
This vulnerability specifically affects the deletion path during normal consensus operation. The epoch change logic correctly handles both V1 and V2 batches separately, but the continuous cleanup mechanism triggered on every block commit only handles V1 batches. The issue becomes critical when `enable_batch_v2` is enabled, causing rapid database growth proportional to consensus activity. The separate V2 deletion method exists in the codebase but is never invoked from the primary cleanup path.

### Citations

**File:** consensus/src/quorum_store/schema.rs (L14-26)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";

#[derive(Debug)]
pub(crate) struct BatchSchema;

impl Schema for BatchSchema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfo>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_CF_NAME;
}
```

**File:** consensus/src/quorum_store/schema.rs (L48-56)
```rust
#[derive(Debug)]
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L168-170)
```rust
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>) {
        self.batch_reader
            .update_certified_timestamp(block_timestamp);
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L501-513)
```rust
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-539)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L93-101)
```rust
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L123-131)
```rust
    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L190-200)
```rust
        if self.config.enable_batch_v2 {
            // TODO(ibalajiarun): Specify accurate batch kind
            let batch_kind = BatchKind::Normal;
            Batch::new_v2(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
                batch_kind,
```

**File:** config/src/config/quorum_store_config.rs (L101-102)
```rust
    pub enable_payload_v2: bool,
    pub enable_batch_v2: bool,
```

**File:** config/src/config/quorum_store_config.rs (L143-144)
```rust
            enable_payload_v2: false,
            enable_batch_v2: false,
```
