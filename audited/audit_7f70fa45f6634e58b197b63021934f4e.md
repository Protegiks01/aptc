# Audit Report

## Title
TOCTOU Race Condition in Latest Ledger Info Update Causes Epoch Regression

## Summary
The `update_latest_ledger_info()` function contains a Time-of-Check-Time-of-Use (TOCTOU) race condition that allows the in-memory latest ledger info to regress to an earlier epoch when concurrent database operations occur. This happens because the check and update operations are not atomic, enabling interleaving between state snapshot finalization and regular commits.

## Finding Description

The vulnerability exists in the `update_latest_ledger_info()` function which performs a non-atomic check-then-update operation on the latest ledger info. [1](#0-0) 

The race condition occurs because:

1. **Non-atomic check-then-update**: The function reads the current latest ledger info, checks if it should update based on epoch comparison, then writes the new value. These three operations are not atomic.

2. **ArcSwap limitations**: The `latest_ledger_info` field uses `ArcSwap<Option<LedgerInfoWithSignatures>>` which provides atomic individual operations but NOT atomic check-then-update semantics. [2](#0-1) [3](#0-2) 

3. **Unsynchronized callers**: The function is called from `finalize_state_snapshot()` without holding any locks: [4](#0-3) 

Meanwhile, `commit_ledger()` holds the `commit_lock` but calls `post_commit()` which directly calls `set_latest_ledger_info()` without the epoch check: [5](#0-4) [6](#0-5) 

**Race Scenario:**
1. Thread A (state sync) calls `finalize_state_snapshot()` with epoch 100 ledger infos
2. Thread B (consensus) calls `commit_ledger()` with epoch 101 ledger info
3. Thread A reads current latest ledger info (epoch 99) in `update_latest_ledger_info()`
4. Thread B (holding `commit_lock`) writes epoch 101 via `set_latest_ledger_info()`
5. Thread A checks: epoch 99 < epoch 100, proceeds to update
6. Thread A writes epoch 100, overwriting epoch 101
7. **Result**: Latest ledger info regresses from epoch 101 to epoch 100

This violates the **State Consistency** invariant requiring atomic state transitions and can lead to **Consensus Safety** violations as nodes may disagree on the current epoch.

## Impact Explanation

**Severity: High to Critical**

This vulnerability has severe implications:

1. **Epoch Regression**: The latest ledger info can regress to an earlier epoch, causing validators to have inconsistent views of the current epoch.

2. **Consensus Disagreement**: Different nodes may have different latest ledger infos, potentially causing them to accept/reject blocks inconsistently, leading to consensus failures or chain splits.

3. **State Sync Failures**: Nodes attempting to sync may fail or sync to incorrect states if the latest ledger info is incorrect.

4. **Validator Set Confusion**: Epoch changes determine validator set changes. An incorrect epoch could cause nodes to use the wrong validator set for verification.

This meets **High Severity** criteria (significant protocol violations) and potentially **Critical Severity** if it leads to consensus safety violations or non-recoverable network partitions.

## Likelihood Explanation

**Likelihood: Medium to High**

This race condition can occur in normal operational scenarios:

1. **State sync is common**: Nodes regularly fall behind and perform state sync while the network continues processing blocks through consensus.

2. **Concurrent operations**: State sync (`finalize_state_snapshot`) and consensus commits (`commit_ledger`) run on separate code paths without mutual exclusion.

3. **Window of vulnerability**: The race window exists whenever state sync finalization overlaps with a consensus commit, which can happen during:
   - Node startup/catch-up
   - Network partitions/recovery
   - Fast sync operations
   - Regular state sync during normal operation

The vulnerability is not easily exploitable by an external attacker but can occur naturally during normal node operations, making it a significant reliability and safety concern.

## Recommendation

Implement atomic compare-and-swap semantics for the latest ledger info update. The fix should ensure that the epoch check and update happen atomically:

**Solution 1: Use a mutex to protect the entire check-then-update operation**

```rust
pub(crate) fn update_latest_ledger_info(
    ledger_metadata_db: &LedgerMetadataDb,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    // Acquire a lock to make check-then-update atomic
    let _lock = ledger_metadata_db.latest_ledger_info_update_lock.lock();
    
    if let Some(li) = ledger_metadata_db.get_latest_ledger_info_option() {
        if li.ledger_info().epoch() > ledger_infos.last().unwrap().ledger_info().epoch() {
            return Ok(());
        }
    }
    ledger_metadata_db.set_latest_ledger_info(ledger_infos.last().unwrap().clone());
    Ok(())
}
```

**Solution 2: Use compare-and-swap loop**

```rust
pub(crate) fn update_latest_ledger_info(
    ledger_metadata_db: &LedgerMetadataDb,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    let new_li = ledger_infos.last().unwrap().clone();
    let new_epoch = new_li.ledger_info().epoch();
    
    loop {
        let current = ledger_metadata_db.latest_ledger_info.load();
        
        // Check if update is needed
        if let Some(ref current_li) = **current {
            if current_li.ledger_info().epoch() >= new_epoch {
                return Ok(());
            }
        }
        
        // Attempt atomic swap
        let new_value = Arc::new(Some(new_li.clone()));
        if ledger_metadata_db.latest_ledger_info
            .compare_and_swap(&current, new_value)
            .is_ok() {
            break;
        }
        // If swap failed, retry the loop
    }
    
    Ok(())
}
```

**Solution 3: Ensure finalize_state_snapshot acquires commit_lock**

Make `finalize_state_snapshot()` acquire the same `commit_lock` that `commit_ledger()` uses to ensure mutual exclusion between the two operations.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;

    #[test]
    fn test_race_condition_in_update_latest_ledger_info() {
        // Setup: Create LedgerMetadataDb with epoch 99
        let db = setup_test_db_with_epoch(99);
        let ledger_metadata_db = Arc::new(db);
        
        // Prepare ledger infos for epochs 100 and 101
        let epoch_100_infos = vec![create_ledger_info(100)];
        let epoch_101_infos = vec![create_ledger_info(101)];
        
        let barrier = Arc::new(Barrier::new(2));
        let db1 = Arc::clone(&ledger_metadata_db);
        let db2 = Arc::clone(&ledger_metadata_db);
        let barrier1 = Arc::clone(&barrier);
        let barrier2 = Arc::clone(&barrier);
        
        // Thread 1: Update to epoch 100 (simulating state sync)
        let handle1 = thread::spawn(move || {
            barrier1.wait();
            update_latest_ledger_info(&db1, &epoch_100_infos)
        });
        
        // Thread 2: Update to epoch 101 (simulating consensus commit)
        let handle2 = thread::spawn(move || {
            barrier2.wait();
            // Simulate direct set_latest_ledger_info (as done in post_commit)
            db2.set_latest_ledger_info(epoch_101_infos[0].clone());
        });
        
        handle1.join().unwrap().unwrap();
        handle2.join().unwrap();
        
        // Verify: The latest ledger info should be epoch 101, not 100
        let latest = ledger_metadata_db.get_latest_ledger_info_option().unwrap();
        let latest_epoch = latest.ledger_info().epoch();
        
        // This assertion can fail due to the race condition
        // Expected: 101, but may get 100 due to race
        assert_eq!(latest_epoch, 101, 
            "Race condition caused epoch regression from 101 to {}", 
            latest_epoch);
    }
}
```

**Notes:**

The vulnerability is a classic TOCTOU race condition where the gap between checking the current value and updating it allows another thread to modify the value, causing the check to become stale. This is particularly dangerous in a consensus system where epoch consistency is critical for validator set management and block verification. The fix requires either making the check-then-update operation atomic through proper synchronization or redesigning the update logic to use atomic compare-and-swap primitives.

### Citations

**File:** storage/aptosdb/src/backup/restore_utils.rs (L61-74)
```rust
pub(crate) fn update_latest_ledger_info(
    ledger_metadata_db: &LedgerMetadataDb,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    if let Some(li) = ledger_metadata_db.get_latest_ledger_info_option() {
        if li.ledger_info().epoch() > ledger_infos.last().unwrap().ledger_info().epoch() {
            // No need to update latest ledger info.
            return Ok(());
        }
    }
    ledger_metadata_db.set_latest_ledger_info(ledger_infos.last().unwrap().clone());

    Ok(())
}
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L94-98)
```rust
    pub(crate) fn get_latest_ledger_info_option(&self) -> Option<LedgerInfoWithSignatures> {
        let ledger_info_ptr = self.latest_ledger_info.load();
        let ledger_info: &Option<_> = ledger_info_ptr.deref();
        ledger_info.clone()
    }
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L180-183)
```rust
    pub(crate) fn set_latest_ledger_info(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) {
        self.latest_ledger_info
            .store(Arc::new(Some(ledger_info_with_sigs)));
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-241)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
            ensure!(
                num_transaction_outputs == 1,
                "Number of transaction outputs should == 1, but got: {}",
                num_transaction_outputs
            );
            ensure!(
                num_transaction_infos == 1,
                "Number of transaction infos should == 1, but got: {}",
                num_transaction_infos
            );

            // TODO(joshlind): include confirm_or_save_frozen_subtrees in the change set
            // bundle below.

            // Update the merkle accumulator using the given proof
            let frozen_subtrees = output_with_proof
                .proof
                .ledger_info_to_transaction_infos_proof
                .left_siblings();
            restore_utils::confirm_or_save_frozen_subtrees(
                self.ledger_db.transaction_accumulator_db_raw(),
                version,
                frozen_subtrees,
                None,
            )?;

            // Create a single change set for all further write operations
            let mut ledger_db_batch = LedgerDbSchemaBatches::new();
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
            // Save the target transactions, outputs, infos and events
            let (transactions, outputs): (Vec<Transaction>, Vec<TransactionOutput>) =
                output_with_proof
                    .transactions_and_outputs
                    .into_iter()
                    .unzip();
            let events = outputs
                .clone()
                .into_iter()
                .map(|output| output.events().to_vec())
                .collect::<Vec<_>>();
            let wsets: Vec<WriteSet> = outputs
                .into_iter()
                .map(|output| output.write_set().clone())
                .collect();
            let transaction_infos = output_with_proof.proof.transaction_infos;
            // We should not save the key value since the value is already recovered for this version
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;

            // Save the epoch ending ledger infos
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;

            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;

            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;

            restore_utils::update_latest_ledger_info(self.ledger_db.metadata_db(), ledger_infos)?;
            self.state_store.reset();

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L662-669)
```rust
        if let Some(x) = ledger_info_with_sigs {
            self.ledger_db
                .metadata_db()
                .set_latest_ledger_info(x.clone());

            LEDGER_VERSION.set(x.ledger_info().version() as i64);
            NEXT_BLOCK_EPOCH.set(x.ledger_info().next_block_epoch() as i64);
        }
```
