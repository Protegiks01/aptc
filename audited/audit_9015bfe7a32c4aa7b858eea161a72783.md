# Audit Report

## Title
V2 Batch Deletion Failures Cause Database Inconsistency and Batch Retrieval Errors

## Summary
Two critical bugs in batch deletion logic prevent V2 batches from being properly removed from the database. This causes V2 batches to persist indefinitely in the V2 DB table even after expiration, leading to database bloat and potential batch retrieval failures when cache metadata becomes inconsistent with actual database state.

## Finding Description

The QuorumStore batch storage system maintains two separate database tables (V1 and V2) for backward compatibility. However, the deletion logic contains two critical bugs that fail to delete V2 batches:

**Bug 1: Epoch Transition Garbage Collection** [1](#0-0) 

The function `gc_previous_epoch_batches_from_db_v2()` reads V2 batches from the V2 database table but incorrectly calls `delete_batches()` (line 241) instead of `delete_batches_v2()`. This attempts to delete V2 batch digests from the V1 table, leaving V2 batches permanently in the database.

**Bug 2: Runtime Expiration Cleanup** [2](#0-1) 

The function `update_certified_timestamp()` clears expired batches from cache but only calls `delete_batches()` (line 536), which only removes entries from the V1 table. V2 batches remain in the V2 DB table indefinitely.

**Database Schema Separation** [3](#0-2) 

V1 and V2 batches are stored in completely separate RocksDB column families (`BatchSchema` and `BatchV2Schema`). The deletion methods operate on different tables, so calling the wrong deletion method has no effect on the actual data.

**Batch Retrieval Logic** [4](#0-3) 

When retrieving batches with evicted payloads, `get_batch_from_local()` uses the cache's `is_v2()` metadata to determine which database table to query. If cache metadata becomes inconsistent with actual DB storage due to the deletion bugs, retrieval from the wrong table fails even when data exists.

**Exploitation Scenario:**

1. V2 batch (digest D, expiration T1) is created and persisted to V2 DB table and cache
2. Batch expires; `clear_expired_payload()` removes it from cache
3. Bug triggers: `delete_batches()` is called, which tries to delete from V1 table (no effect)
4. V2 DB table still contains digest D (zombie entry)
5. Later, a V1 batch with same digest D (same transaction payload) but different expiration T2 is received from a peer
6. Cache is updated with V1 variant due to higher expiration or normal cache replacement logic [5](#0-4) 
7. Payload is evicted from cache due to memory pressure (metadata-only mode)
8. Execution engine requests the batch via `get_batch_from_local(D)`
9. Cache indicates V1 variant: `value.batch_info().is_v2()` returns false
10. System calls `get_batch_from_db(D, false)` to query V1 table
11. V1 table doesn't have the entry (was never saved there or was deleted)
12. Fetch fails with "Could not get batch from db"
13. However, V2 table still contains digest D (from step 4)
14. Execution/consensus stalls because batch cannot be retrieved

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: When batch retrieval fails due to version mismatch, execution is blocked waiting for batch data that exists but cannot be accessed. This causes validator performance degradation.

2. **Significant Protocol Violations**: The QuorumStore protocol assumes batch data persists correctly and can be retrieved when needed. These bugs violate the storage consistency invariant, causing consensus/execution disruptions.

3. **Database Bloat**: V2 batches accumulate indefinitely without deletion, consuming disk space and degrading database performance over time.

4. **Liveness Impact**: If critical batches become unretrievable due to version mismatch, affected validators cannot execute blocks, impacting network liveness.

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." The inability to retrieve persisted batch data violates storage consistency guarantees.

## Likelihood Explanation

**Likelihood: Medium to High**

This issue occurs under normal network conditions when:
- V2 batches are actively used in the network
- Batches expire during runtime or epoch transitions (frequent occurrence)
- The same transaction payload is rebroadcast or recreated across different batch versions
- Memory pressure causes payload eviction from cache (common in production)

The bug is deterministic and will occur on every V2 batch expiration. Given that Aptos validators process thousands of batches daily, the accumulation of zombie V2 entries in the database is guaranteed. The version mismatch scenario becomes more likely as the network operates longer and more inconsistent state accumulates.

## Recommendation

**Fix 1: Correct Epoch GC Deletion**
```rust
fn gc_previous_epoch_batches_from_db_v2(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
    let db_content = db
        .get_all_batches_v2()
        .expect("failed to read data from db");
    // ... existing logic ...
    
    // FIX: Use delete_batches_v2 instead of delete_batches
    db.delete_batches_v2(expired_keys)  // Changed from delete_batches
        .expect("Deletion of expired keys should not fail");
}
```

**Fix 2: Handle V2 Batches in Runtime Expiration**
```rust
pub fn update_certified_timestamp(&self, certified_time: u64) {
    trace!("QS: batch reader updating time {:?}", certified_time);
    self.last_certified_time
        .fetch_max(certified_time, Ordering::SeqCst);

    let expired_keys = self.clear_expired_payload(certified_time);
    
    // FIX: Delete from both V1 and V2 tables
    // Note: Expired batches could be in either table depending on version
    if let Err(e) = self.db.delete_batches(expired_keys.clone()) {
        debug!("Error deleting V1 batches: {:?}", e)
    }
    if let Err(e) = self.db.delete_batches_v2(expired_keys) {
        debug!("Error deleting V2 batches: {:?}", e)
    }
}
```

Alternative: Track version metadata for each digest in `expirations` to delete from the correct table.

## Proof of Concept

```rust
#[test]
fn test_v2_batch_deletion_bug() {
    use aptos_consensus_types::proof_of_store::BatchInfoExt;
    use std::sync::Arc;
    
    // Setup: Create batch store with V2 batch
    let db = Arc::new(QuorumStoreDB::new(test_dir));
    let batch_store = BatchStore::new(/* params */);
    
    // Step 1: Create V2 batch
    let v2_batch = create_test_batch_v2(digest, epoch, expiration);
    let persist_request = PersistedValue::new(v2_batch.clone(), Some(payload));
    
    // Step 2: Persist to V2 table
    batch_store.save(&persist_request).unwrap();
    assert!(db.get_batch_v2(&digest).unwrap().is_some());
    
    // Step 3: Simulate expiration and cleanup
    batch_store.clear_expired_payload(expiration + 1);
    batch_store.update_certified_timestamp(expiration + 1);
    
    // BUG: V2 batch remains in V2 DB table
    assert!(db.get_batch_v2(&digest).unwrap().is_some(), 
            "V2 batch should be deleted but remains due to bug");
    
    // Step 4: Simulate V1 batch with same digest
    let v1_batch = create_test_batch_v1(digest, epoch, expiration + 100);
    batch_store.insert_to_cache(&v1_batch.into()).unwrap();
    
    // Step 5: Evict payload from cache
    // (simulate memory pressure)
    
    // Step 6: Attempt retrieval - fails due to version mismatch
    let result = batch_store.get_batch_from_local(&digest);
    // Cache says V1, queries V1 table, but data only in V2 table
    assert!(result.is_err(), "Retrieval should fail due to version mismatch");
}
```

**Notes**

The core vulnerability is the incorrect deletion method calls that prevent V2 batches from being removed from the database. While the exact version mismatch scenario requires specific network conditions (same payload in different versions), the deletion bugs are deterministic and affect all V2 batches. This causes guaranteed database bloat and potential retrieval failures that degrade validator performance and network liveness.

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L212-243)
```rust
    fn gc_previous_epoch_batches_from_db_v2(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-539)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L571-585)
```rust
    pub(crate) fn get_batch_from_local(
        &self,
        digest: &HashValue,
    ) -> ExecutorResult<PersistedValue<BatchInfoExt>> {
        if let Some(value) = self.db_cache.get(digest) {
            if value.payload_storage_mode() == StorageMode::PersistedOnly {
                self.get_batch_from_db(digest, value.batch_info().is_v2())
            } else {
                // Available in memory.
                Ok(value.clone())
            }
        } else {
            Err(ExecutorError::CouldNotGetData)
        }
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L92-154)
```rust
impl QuorumStoreStorage for QuorumStoreDB {
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }

    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>> {
        let mut iter = self.db.iter::<BatchSchema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfo>>>>()
    }

    fn save_batch(&self, batch: PersistedValue<BatchInfo>) -> Result<(), DbError> {
        trace!(
            "QS: db persists digest {} expiration {:?}",
            batch.digest(),
            batch.expiration()
        );
        self.put::<BatchSchema>(batch.digest(), &batch)
    }

    fn get_batch(&self, digest: &HashValue) -> Result<Option<PersistedValue<BatchInfo>>, DbError> {
        Ok(self.db.get::<BatchSchema>(digest)?)
    }

    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }

    fn get_all_batches_v2(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfoExt>>> {
        let mut iter = self.db.iter::<BatchV2Schema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfoExt>>>>()
    }

    fn save_batch_v2(&self, batch: PersistedValue<BatchInfoExt>) -> Result<(), DbError> {
        trace!(
            "QS: db persists digest {} expiration {:?}",
            batch.digest(),
            batch.expiration()
        );
        self.put::<BatchV2Schema>(batch.digest(), &batch)
    }

    fn get_batch_v2(
        &self,
        digest: &HashValue,
    ) -> Result<Option<PersistedValue<BatchInfoExt>>, DbError> {
        Ok(self.db.get::<BatchV2Schema>(digest)?)
    }
```
