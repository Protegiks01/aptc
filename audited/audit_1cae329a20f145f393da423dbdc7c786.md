# Audit Report

## Title
Block Output Limit Bypass via Deletion Operation Size Underestimation

## Summary
The `materialized_size()` function systematically underestimates the size of deletion operations by failing to account for `StateValueMetadata` that is included in serialized outputs. This allows attackers to bypass the `block_output_limit`, potentially causing validator slowdowns when processing oversized blocks.

## Finding Description

The `output_approx_size()` function in the block executor relies on `VMOutput::materialized_size()` to estimate transaction output sizes for enforcing block output limits. [1](#0-0) 

The `materialized_size()` implementation calculates size by summing state keys and write operation lengths: [2](#0-1) 

For deletion operations, `write_len()` returns `None`, resulting in zero bytes counted for the write operation: [3](#0-2) 

However, deletion operations with metadata are serialized with `PersistedStateValueMetadata`: [4](#0-3) 

This metadata consumes 17-25 bytes per deletion (2-3 u64 fields plus enum discriminator) that are NOT counted in `materialized_size()`, but ARE included in the actual serialized output.

The block executor uses the underestimated size to enforce the block output limit: [5](#0-4) 

The default block output limit is 4 MB: [6](#0-5) 

**Attack Flow:**
1. Attacker creates state keys (costs gas but accumulates deletable state)
2. Submits transactions with numerous deletion operations
3. Each deletion is counted as only `state_key.size()` bytes in `materialized_size()`
4. Actual serialized output includes additional 20 bytes average per deletion (metadata + overhead)
5. Block passes the `block_output_limit` check with underestimated size
6. Actual block output exceeds intended limit when materialized

**Example Calculation:**
- To bypass limit by 1 MB: ~52,000 deletions needed (1,048,576 / 20)
- These deletions count as ~40 bytes each (avg state key size) = ~2 MB estimated
- Actual size: ~2 MB + 1 MB (metadata) = ~3 MB
- Can fill block to apparent 4 MB that actually materializes to ~5 MB (+25% overrun)

## Impact Explanation

This vulnerability allows bypassing the block output limit, which is designed to prevent validators from processing excessively large blocks. While the underestimation magnitude (~20 bytes per deletion) makes actual memory exhaustion on modern validator hardware (32+ GB RAM) unlikely, it does enable creation of blocks that are 20-25% larger than intended.

According to the Aptos bug bounty severity categories, this qualifies as **High Severity** under "Validator node slowdowns" because:
- Validators must process larger-than-intended blocks
- Network throughput could be degraded
- Consensus timing may be affected by unexpected block sizes
- The invariant "Resource Limits: All operations must respect gas, storage, and computational limits" is violated

The attack does not reach Critical severity because it does not cause total loss of liveness, permanent network partition, or actual memory exhaustion crashes.

## Likelihood Explanation

**Likelihood: Medium to High**

The attack is feasible but constrained by economic factors:

**Requirements:**
- Attacker must first create state keys to delete (gas cost)
- Must submit multiple transactions with deletions (gas cost)
- Needs coordination across transactions to maximize deletions per block

**Feasibility:**
- Attack is technically straightforward - just submit transactions with many delete operations
- Gas costs make large-scale exploitation expensive but not prohibitive
- Block gas limits constrain number of operations per block
- Multiple attackers or sustained attack over multiple blocks could amplify impact

**Detection:**
- Block output size monitoring would reveal discrepancy
- Unusual deletion-heavy transaction patterns could be flagged
- Currently no mitigation in place

## Recommendation

Fix the `materialized_size()` calculation to account for deletion metadata. The `write_len()` method should return the size of serialized metadata for deletions instead of `None`:

**Option 1: Fix `write_len()` in `WriteOpSize`**

Modify the `write_len()` method to return metadata size for deletions. The deletion metadata size can be estimated based on `PersistedStateValueMetadata` structure (17-25 bytes depending on V0/V1).

**Option 2: Adjust `materialized_size()` calculation**

Add explicit handling in `materialized_size()` to account for deletion metadata:

```rust
// In output.rs materialized_size()
for (state_key, write_size) in ... {
    let write_bytes = match write_size.write_len() {
        Some(len) => len,
        None => 25, // Estimated deletion metadata size (conservative V1 size)
    };
    size += state_key.size() as u64 + write_bytes;
}
```

**Option 3: Use actual serialized size**

For critical size enforcement, consider using actual BCS serialized size instead of approximation, though this may impact performance.

## Proof of Concept

```rust
// Rust PoC demonstrating the underestimation
#[test]
fn test_deletion_size_underestimation() {
    use aptos_types::write_set::{WriteOp, WriteOpSize};
    use aptos_types::state_store::state_value::StateValueMetadata;
    
    // Create a deletion with metadata
    let metadata = StateValueMetadata::new_impl(100, 50, 1000000);
    let deletion = WriteOp::deletion(metadata);
    
    // Get the WriteOpSize
    let write_op_size = deletion.write_op_size();
    
    // write_len() returns None for deletions
    assert_eq!(write_op_size.write_len(), None);
    
    // But actual serialization includes metadata
    let serialized = bcs::to_bytes(&deletion.to_persistable()).unwrap();
    let actual_size = serialized.len();
    
    // Demonstrate underestimation: counted as 0 but actually 20+ bytes
    let counted_size = write_op_size.write_len().unwrap_or(0);
    println!("Counted size: {}", counted_size);
    println!("Actual size: {}", actual_size);
    assert!(actual_size > 17); // At least 17 bytes for V0, more for V1
    assert_eq!(counted_size, 0); // But counted as 0!
}
```

**Notes**

The vulnerability exists in the size calculation mechanism and affects all transaction types that perform deletions. Resource group deletions may have even larger underestimations if inner operations are not properly accounted for. The fix should be applied consistently across all write operation types to ensure accurate block output size estimation.

### Citations

**File:** aptos-move/aptos-vm/src/block_executor/mod.rs (L136-138)
```rust
    fn output_approx_size(&self) -> u64 {
        self.guard.materialized_size()
    }
```

**File:** aptos-move/aptos-vm-types/src/output.rs (L124-138)
```rust
    pub fn materialized_size(&self) -> u64 {
        let mut size = 0;
        for (state_key, write_size) in self
            .change_set
            .write_set_size_iter()
            .chain(self.module_write_set.write_set_size_iter())
        {
            size += state_key.size() as u64 + write_size.write_len().unwrap_or(0);
        }

        for event in self.change_set.events_iter() {
            size += event.size() as u64;
        }
        size
    }
```

**File:** types/src/write_set.rs (L46-63)
```rust
#[derive(Serialize, Deserialize)]
#[serde(rename = "WriteOp")]
pub enum PersistedWriteOp {
    Creation(Bytes),
    Modification(Bytes),
    Deletion,
    CreationWithMetadata {
        data: Bytes,
        metadata: PersistedStateValueMetadata,
    },
    ModificationWithMetadata {
        data: Bytes,
        metadata: PersistedStateValueMetadata,
    },
    DeletionWithMetadata {
        metadata: PersistedStateValueMetadata,
    },
}
```

**File:** types/src/write_set.rs (L349-364)
```rust
pub enum WriteOpSize {
    Creation { write_len: u64 },
    Modification { write_len: u64 },
    Deletion,
}

impl WriteOpSize {
    pub fn write_len(&self) -> Option<u64> {
        match self {
            WriteOpSize::Creation { write_len } | WriteOpSize::Modification { write_len } => {
                Some(*write_len)
            },
            WriteOpSize::Deletion => None,
        }
    }
}
```

**File:** aptos-move/block-executor/src/limit_processor.rs (L143-154)
```rust
        if let Some(per_block_output_limit) = self.block_gas_limit_type.block_output_limit() {
            let accumulated_output = self.get_accumulated_approx_output_size();
            if accumulated_output >= per_block_output_limit {
                counters::EXCEED_PER_BLOCK_OUTPUT_LIMIT_COUNT.inc_with(&[mode]);
                info!(
                    "[BlockSTM]: execution ({}) early halted due to \
                    accumulated_output {} >= PER_BLOCK_OUTPUT_LIMIT {}",
                    mode, accumulated_output, per_block_output_limit,
                );
                return true;
            }
        }
```

**File:** types/src/on_chain_config/execution_config.rs (L151-151)
```rust
            block_output_limit: Some(4 * 1024 * 1024),
```
