# Audit Report

## Title
Race Condition in Indexer gRPC Service Causes Panic During Startup

## Summary
The indexer-grpc data service v2 contains a race condition where the `fetching_latest_data_task` field can be accessed before initialization, causing a panic that crashes the entire service. This occurs when client requests arrive during the narrow startup window before the background fetch task has stored its first instance.

## Finding Description

The vulnerability exists in the interaction between two components:

**Initialization Flow:** [1](#0-0) 

The `fetching_latest_data_task` is initialized as `None` when `FetchManager` is created.

**Background Task Spawning:** [2](#0-1) 

The background task `continuously_fetch_latest_data()` is spawned asynchronously without waiting for it to initialize the task.

**Request Processing:** [3](#0-2) 

Request processing begins immediately after spawning, without synchronization.

**Vulnerable Access Pattern:** [4](#0-3) 

When a client request reaches the head of available data (i.e., `starting_version >= end_version`), the code attempts to read and unwrap the task. If the task is still `None`, this causes a panic.

**Attack Scenario:**
1. Indexer service starts and initializes `fetching_latest_data_task` to `None`
2. Background task is spawned but hasn't executed its first iteration yet
3. Attacker sends a request with `starting_version = known_latest_version + 1` (or higher, up to `known_latest_version + 10000`)
4. Request passes validation and calls `get_data()`
5. Condition `starting_version >= end_version` is true (since `end_version = known_latest_version + 1`)
6. Code attempts `.unwrap()` on `None`
7. **Panic** - entire service crashes with: `thread panicked at 'called `Option::unwrap()` on a `None` value'`

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria for "API crashes". The impact includes:

- **Denial of Service**: The indexer gRPC service immediately crashes when exploited
- **Service Disruption**: Applications relying on the indexer for blockchain data queries become unavailable
- **Persistent DoS**: Attacker can repeatedly crash the service on each restart by monitoring for service availability and immediately sending malicious requests
- **No Impact on Consensus**: The core blockchain and validators continue operating normally; this affects only the indexer API layer

While this does not affect blockchain consensus or validator operations, it disrupts the data accessibility layer that many applications depend on.

## Likelihood Explanation

**Likelihood: High**

The attack is highly feasible because:
- **No Authentication Required**: Any client can send requests to the indexer service
- **Timing Window**: The race condition window exists on every service restart
- **Easy Detection**: Attackers can monitor for service availability (e.g., connection attempts)
- **Simple Exploit**: Only requires sending a single request with `starting_version` set to `known_latest_version + 1`
- **Validation Bypass**: Requests with `starting_version` up to `known_latest_version + 10000` pass validation

The attacker needs no special privileges and can automate the attack to trigger on every restart.

## Recommendation

Initialize the task before accepting requests, or use a safer access pattern. Here are two solutions:

**Solution 1: Ensure task is initialized before accepting requests**
```rust
pub fn run(&'a self, mut handler_rx: Receiver<...>) {
    info!("Running LiveDataService...");
    tokio_scoped::scope(|scope| {
        // Wait for initial task to be set before processing requests
        scope.spawn(async move {
            let task = self.in_memory_cache.fetch_manager.fetch_latest_data().boxed().shared();
            *self.in_memory_cache.fetch_manager.fetching_latest_data_task.write().await = Some(task.clone());
            
            // Now continue with the loop
            loop {
                let task = self.in_memory_cache.fetch_manager.fetch_latest_data().boxed().shared();
                *self.in_memory_cache.fetch_manager.fetching_latest_data_task.write().await = Some(task.clone());
                let _ = task.await;
            }
        });
        
        // Ensure task is initialized before processing requests
        while self.in_memory_cache.fetch_manager.fetching_latest_data_task.blocking_read().is_none() {
            std::thread::sleep(Duration::from_millis(10));
        }
        
        while let Some((request, response_sender)) = handler_rx.blocking_recv() {
            // ... process requests
        }
    });
}
```

**Solution 2: Handle None gracefully in get_data()**
```rust
while starting_version >= self.data_manager.read().await.end_version {
    trace!("Reached head, wait...");
    
    // Use if-let to handle None case gracefully
    if let Some(task) = self.fetch_manager.fetching_latest_data_task.read().await.as_ref() {
        let num_transactions = task.clone().await;
        trace!("Done waiting, got {num_transactions} transactions at head.");
    } else {
        // Task not initialized yet, sleep and retry
        tokio::time::sleep(Duration::from_millis(50)).await;
    }
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_race_condition_panic() {
    use std::sync::Arc;
    
    // Create a mock connection manager and config
    let connection_manager = Arc::new(ConnectionManager::new(/* params */));
    let config = LiveDataServiceConfig { 
        num_slots: 1000, 
        size_limit_bytes: 10_000_000 
    };
    
    // Create service
    let service = LiveDataService::new(
        1, // chain_id
        config,
        connection_manager.clone(),
        10000, // max_transaction_filter_size_bytes
    );
    
    // Simulate starting the service WITHOUT waiting for initialization
    let (tx, mut rx) = tokio::sync::mpsc::channel(1);
    
    tokio::spawn(async move {
        service.run(rx);
    });
    
    // Give minimal time for spawning but not initialization
    tokio::time::sleep(Duration::from_millis(1)).await;
    
    // Send request that will reach the vulnerable code path
    let known_latest_version = connection_manager.known_latest_version();
    let (response_tx, mut response_rx) = tokio::sync::mpsc::channel(1);
    
    let request = Request::new(GetTransactionsRequest {
        starting_version: Some(known_latest_version + 1), // This will trigger the race
        transactions_count: Some(100),
        batch_size: Some(10),
        transaction_filter: None,
    });
    
    tx.send((request, response_tx)).await.unwrap();
    
    // The service will panic with:
    // thread 'tokio-runtime-worker' panicked at 'called `Option::unwrap()` on a `None` value'
    // at ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs:58:18
}
```

## Notes

This vulnerability only affects the indexer-grpc service, not the core blockchain consensus or validator operations. The blockchain continues to operate normally even when the indexer crashes. However, the indexer is a critical infrastructure component that many applications depend on for querying blockchain data, making this a significant availability issue that qualifies as High Severity under the "API crashes" category.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L30-30)
```rust
            fetching_latest_data_task: RwLock::new(None),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L67-73)
```rust
            scope.spawn(async move {
                let _ = self
                    .in_memory_cache
                    .fetch_manager
                    .continuously_fetch_latest_data()
                    .await;
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L74-74)
```rust
            while let Some((request, response_sender)) = handler_rx.blocking_recv() {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L50-60)
```rust
        while starting_version >= self.data_manager.read().await.end_version {
            trace!("Reached head, wait...");
            let num_transactions = self
                .fetch_manager
                .fetching_latest_data_task
                .read()
                .await
                .as_ref()
                .unwrap()
                .clone()
                .await;
```
