# Audit Report

## Title
TOCTOU Race Condition in Safety Data Persistence Allows Consensus Safety Violation in Shared Volume Deployments

## Summary
The `OnDiskStorage::write()` implementation uses an insecure temporary file pattern without atomic write guarantees or file locking. In containerized validator deployments where temp/data directories are shared across containers (misconfiguration scenario), a compromised container can exploit a race condition to corrupt another validator's safety data, enabling double-voting and breaking consensus safety guarantees. [1](#0-0) 

## Finding Description

The vulnerability exists in the critical path where validators persist consensus safety data (last voted round, epoch, preferred round) to disk. The `OnDiskStorage` backend is used by `PersistentSafetyStorage` to store this security-critical state. [2](#0-1) 

**Attack Flow:**

1. **Setup**: In a misconfigured deployment, validators in separate containers share a volume mounted at `/opt/aptos/data` (the default `data_dir`). The safety rules backend is configured with `type: "on_disk_storage"` and `path: secure-data.json`. [3](#0-2) 

2. **Temp File Creation**: When `OnDiskStorage` is instantiated, it creates a temp path in the same directory as the target file. The temp path uses a predictable naming pattern that is reused for all subsequent writes. [4](#0-3) 

3. **Race Condition Window**: When a validator votes and updates safety data, `set_safety_data()` is called, which triggers `OnDiskStorage::write()`. This function:
   - Creates/truncates the temp file
   - Writes new safety data (including updated `last_voted_round`)
   - **Critical race window exists here**
   - Renames temp file to actual file

4. **Attack Execution**: A compromised container monitors the shared directory. When it detects a write to the temp file, it races to:
   - Read the temp file contents
   - Replace contents with older safety data (lower `last_voted_round`)
   - Complete before the `fs::rename()` executes

5. **Impact**: The corrupted safety data is persisted. When the victim validator restarts, it loads the rolled-back safety state. [5](#0-4) 

6. **Consensus Violation**: The validator's `verify_and_update_last_vote_round()` check now uses the corrupted `last_voted_round` value. The validator can vote for rounds it already voted for, creating conflicting votes (equivocation). [6](#0-5) 

**Why This Breaks Safety**: The "First voting rule" enforces that `round > safety_data.last_voted_round`. By rolling back `last_voted_round` from 100 to 90, a validator that previously voted for rounds 91-100 can now vote for those rounds again with different block proposals, creating equivocating votes that violate BFT safety assumptions. [7](#0-6) 

## Impact Explanation

**Severity: Critical** - This vulnerability enables a **Consensus Safety Violation**, which qualifies for Critical severity under the Aptos bug bounty program.

The attack breaks the fundamental invariant: **"Consensus Safety: AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine"**. While equivocation detection exists at the network layer, the vulnerability allows an attacker to force a validator into Byzantine behavior, effectively increasing the Byzantine validator count. [8](#0-7) 

If an attacker compromises one container and can repeatedly corrupt safety data of other validators, they can:
- Force multiple validators into equivocating states
- Potentially push the network over the 1/3 Byzantine tolerance threshold
- Cause chain splits or safety violations
- Disrupt consensus without requiring actual validator key compromise

## Likelihood Explanation

**Likelihood: Medium-to-Low** in production, but **High** in certain deployment scenarios:

**Required Conditions:**
1. Misconfigured container deployment with shared volumes across validator containers
2. Containers running with same user/permissions allowing cross-container file access
3. One container compromised (RCE, supply chain attack, etc.)
4. Victim validator must restart to load corrupted data (or cache disabled)

**Realistic Scenarios:**
- Development/testing environments with shared volumes
- Cost-saving misconfigurations in cloud deployments
- Docker Compose setups for small networks
- Sidecar containers in same K8s pod sharing emptyDir volumes [9](#0-8) 

The default K8s deployment uses per-validator PersistentVolumeClaims, which prevents this attack. However, the question explicitly explores the misconfiguration scenario, making the vulnerability relevant. [10](#0-9) 

## Recommendation

**Immediate Fix**: Implement atomic writes with file locking in `OnDiskStorage::write()`:

```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    
    // Use O_EXCL to prevent file reuse attacks
    let mut temp_file = OpenOptions::new()
        .write(true)
        .create_new(true)
        .open(self.temp_path.path())?;
    
    // Acquire exclusive lock
    temp_file.lock_exclusive()
        .map_err(|e| Error::IOError(format!("Failed to lock file: {}", e)))?;
    
    // Write and sync to disk
    temp_file.write_all(&contents)?;
    temp_file.sync_all()?;
    
    // Atomic rename (lock is released on drop)
    fs::rename(&self.temp_path, &self.file_path)?;
    Ok(())
}
```

**Long-term Solutions:**
1. Add HMAC/signature verification to safety data files
2. Use unique temp file names per write (not reused)
3. Document deployment requirement: validators must have isolated volumes
4. Add runtime detection of shared volume scenarios with warnings
5. Consider moving to Vault storage for production deployments

**Additional Hardening:**
- Set restrictive file permissions (0600) on safety data files
- Implement file integrity monitoring
- Add checksums to detect tampering

## Proof of Concept

```rust
// poc_safety_data_corruption.rs
// Simulates the race condition attack

use std::fs::{self, File};
use std::io::Write;
use std::path::PathBuf;
use std::thread;
use std::time::Duration;

fn main() {
    let shared_dir = PathBuf::from("/tmp/shared_validator_data");
    fs::create_dir_all(&shared_dir).unwrap();
    
    let target_file = shared_dir.join("secure-data.json");
    let temp_file = shared_dir.join("temp_file_predictable");
    
    // Simulate legitimate validator writing safety data
    let validator_thread = thread::spawn(move || {
        let temp_path = temp_file.clone();
        for round in 1..=100 {
            let safety_data = format!(r#"{{"last_voted_round":{}}}"#, round);
            
            // Simulate OnDiskStorage::write() pattern
            let mut file = File::create(&temp_path).unwrap();
            file.write_all(safety_data.as_bytes()).unwrap();
            
            // Small delay simulating write time
            thread::sleep(Duration::from_micros(100));
            
            // Rename to actual file
            fs::rename(&temp_path, &target_file).unwrap();
            
            thread::sleep(Duration::from_millis(10));
        }
    });
    
    // Simulate attacker in compromised container
    thread::sleep(Duration::from_millis(5));
    let attacker_thread = thread::spawn(move || {
        let temp_path = temp_file;
        for _ in 0..50 {
            // Detect temp file write
            if temp_path.exists() {
                // Race to corrupt before rename
                let corrupted = r#"{"last_voted_round":10}"#;
                if let Ok(mut file) = File::create(&temp_path) {
                    let _ = file.write_all(corrupted.as_bytes());
                    println!("✓ Corrupted safety data!");
                }
            }
            thread::sleep(Duration::from_micros(500));
        }
    });
    
    validator_thread.join().unwrap();
    attacker_thread.join().unwrap();
    
    // Check final state
    let final_data = fs::read_to_string(&target_file).unwrap();
    println!("Final safety data: {}", final_data);
    
    if final_data.contains("\"last_voted_round\":10") {
        println!("⚠️  VULNERABILITY CONFIRMED: Safety data rolled back!");
    }
}
```

## Notes

This vulnerability requires the specific misconfiguration of shared volumes across validator containers. The default Kubernetes Helm deployment uses isolated PersistentVolumeClaims per validator, which prevents this attack. However, the lack of defensive programming (file locking, atomic writes, integrity checks) in `OnDiskStorage` makes it vulnerable when deployed in shared-volume scenarios, which may occur in development, testing, or cost-optimized deployments.

The vulnerability is particularly concerning because it affects the core consensus safety mechanism (`SafetyRules`) that prevents double-voting, which is fundamental to BFT safety guarantees.

### Citations

**File:** secure/storage/src/on_disk.rs (L42-50)
```rust
        let file_dir = file_path
            .parent()
            .map_or_else(PathBuf::new, |p| p.to_path_buf());

        Self {
            file_path,
            temp_path: TempPath::new_with_temp_dir(file_dir),
            time_service,
        }
```

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L24-28)
```rust
pub struct PersistentSafetyStorage {
    enable_cached_safety_data: bool,
    cached_safety_data: Option<SafetyData>,
    internal_store: Storage,
}
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L134-148)
```rust
    pub fn safety_data(&mut self) -> Result<SafetyData, Error> {
        if !self.enable_cached_safety_data {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            return self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
        }

        if let Some(cached_safety_data) = self.cached_safety_data.clone() {
            Ok(cached_safety_data)
        } else {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            let safety_data: SafetyData = self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
            self.cached_safety_data = Some(safety_data.clone());
            Ok(safety_data)
        }
    }
```

**File:** docker/compose/aptos-node/validator.yaml (L11-13)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L77-92)
```rust
        self.verify_and_update_last_vote_round(
            proposed_block.block_data().round(),
            &mut safety_data,
        )?;
        self.safe_to_vote(proposed_block, timeout_cert)?;

        // Record 1-chain data
        self.observe_qc(proposed_block.quorum_cert(), &mut safety_data);
        // Construct and sign vote
        let author = self.signer()?.author();
        let ledger_info = self.construct_ledger_info_2chain(proposed_block, vote_data.hash())?;
        let signature = self.sign(&ledger_info)?;
        let vote = Vote::new_with_signature(vote_data, author, ledger_info, signature);

        safety_data.last_vote = Some(vote.clone());
        self.persistent_storage.set_safety_data(safety_data)?;
```

**File:** consensus/src/pending_votes.rs (L287-308)
```rust
        if let Some((previously_seen_vote, previous_li_digest)) =
            self.author_to_vote.get(&vote.author())
        {
            // is it the same vote?
            if &li_digest == previous_li_digest {
                // we've already seen an equivalent vote before
                let new_timeout_vote = vote.is_timeout() && !previously_seen_vote.is_timeout();
                if !new_timeout_vote {
                    // it's not a new timeout vote
                    return VoteReceptionResult::DuplicateVote;
                }
            } else {
                // we have seen a different vote for the same round
                error!(
                    SecurityEvent::ConsensusEquivocatingVote,
                    remote_peer = vote.author(),
                    vote = vote,
                    previous_vote = previously_seen_vote
                );

                return VoteReceptionResult::EquivocateVote;
            }
```

**File:** docker/compose/validator-testnet/docker-compose.yaml (L33-36)
```yaml
    volumes:
      - type: volume
        source: aptos-shared
        target: /opt/aptos/var
```

**File:** terraform/helm/aptos-node/templates/validator.yaml (L240-242)
```yaml
      - name: aptos-data
        persistentVolumeClaim:
          claimName: {{ include "aptos-validator.fullname" $ }}-{{$i}}-validator-e{{ $.Values.chain.era }}
```
