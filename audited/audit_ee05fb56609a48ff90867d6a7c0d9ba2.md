# Audit Report

## Title
Dynamic Prefetching Freeze Timer Manipulation Enables Persistent State Sync Performance Degradation

## Summary
An attacker controlling malicious network peers can exploit the dynamic prefetching freeze mechanism to force state sync operations to run at minimum concurrency (3 requests instead of up to 30) indefinitely, while maintaining an excellent peer reputation score that prevents exclusion. This is achieved by providing mostly successful responses but timing occasional failures to keep the prefetch limit increase frozen permanently.

## Finding Description

The vulnerability exists in the interaction between two mechanisms in the state sync data streaming service:

1. **Dynamic Prefetching** [1](#0-0)  increases the max concurrent requests on successful responses, and [2](#0-1)  decreases it on failures while freezing increases for 30 seconds.

2. **Peer Reputation** [3](#0-2)  scores peers based on success/failure ratio, excluding peers when scores drop below 25.0.

The critical flaw is at [4](#0-3)  where every failure resets the freeze timer to the current time, regardless of when the last failure occurred. This allows an attacker to maintain a permanent freeze by causing failures more frequently than the 30-second freeze duration.

**Attack Execution:**

An attacker controlling malicious peers executes the following pattern:
- Provide 25 successful responses (taking ~25 seconds at 1 second per request)
- Cause 1 timeout/failure
- Repeat indefinitely

**Why This Works:**

1. **Peer Score Remains High**: With a 25:1 success-to-failure ratio, the peer score remains at maximum (100.0) because [5](#0-4)  adds 1.0 per success while [6](#0-5)  multiplies by 0.95 per failure, converging to score = 500.0 (capped at 100.0).

2. **Freeze Stays Active**: Failures occur every 26 seconds, which is less than the 30-second freeze duration [7](#0-6) . The check at [8](#0-7)  prevents increases during the freeze.

3. **Prefetch Limit Decreases**: At [9](#0-8)  successful responses should increase the limit, but they don't because of the freeze. Each failure at [10](#0-9)  decreases the limit by 2, driving it to the minimum of 3 [11](#0-10) .

4. **No Exclusion**: The peer is never excluded because [12](#0-11)  only ignores peers with scores below 25.0, and this peer maintains score 100.0.

## Impact Explanation

This vulnerability causes **persistent performance degradation** of state synchronization operations:

- State sync runs at 1/10th normal capacity (3 vs 30 max concurrent requests)
- New validators attempting to join the network experience 10x slower synchronization
- Existing validators that fall behind (e.g., after downtime) take 10x longer to catch up
- Network onboarding capacity is severely reduced

According to the Aptos bug bounty criteria, this qualifies as **High Severity** under "Validator node slowdowns". While it doesn't completely halt operations (minimum concurrency is 3, not 0), it significantly degrades the network's ability to onboard new validators and maintain synchronization, which are critical for network health and decentralization.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Control over network peers (can be achieved by running malicious nodes)
- Ability to selectively timeout or delay responses
- No privileged validator access required

**Feasibility:**
- The attack pattern is straightforward: provide mostly good responses with occasional strategic timeouts
- Timing is not difficult (one failure every 26 seconds)
- Multiple malicious peers can coordinate to affect different syncing nodes

**Limitations:**
- Requires malicious nodes to be selected by the data client's peer selection algorithm
- If sufficient honest peers exist, they may be preferred over time
- However, with the peer maintaining perfect scores, it will continue to be selected

## Recommendation

The freeze mechanism should distinguish between isolated failures and patterns of manipulation. Implement one of the following fixes:

**Option 1: Freeze Duration Based on Failure Frequency (Recommended)**

Modify the freeze mechanism to track failure frequency rather than resetting on every failure:

```rust
// In DynamicPrefetchingState
fn is_prefetching_value_frozen(&self) -> bool {
    match self.last_timeout_instant {
        Some(last_failure_time) => {
            let time_since_last_failure = 
                self.time_service.now().duration_since(last_failure_time);
            let max_freeze_duration = Duration::from_secs(
                self.get_dynamic_prefetching_config().timeout_freeze_duration_secs,
            );
            
            // Only freeze if this is the first failure after a period of success
            // Don't reset freeze on subsequent failures during the freeze period
            time_since_last_failure < max_freeze_duration
        },
        None => false,
    }
}

pub fn decrease_max_concurrent_requests(&mut self) {
    if !self.is_dynamic_prefetching_enabled() {
        return;
    }
    
    // Only update last_timeout_instant if not currently frozen
    // This prevents resetting the timer on repeated failures
    if !self.is_prefetching_value_frozen() {
        self.last_timeout_instant = Some(self.time_service.now());
    }
    
    // Proceed with decrease logic...
}
```

**Option 2: Penalize Repeated Failures During Freeze**

Track failures during the freeze period and apply additional penalties to peer score for patterns indicating manipulation.

## Proof of Concept

```rust
#[test]
fn test_freeze_timer_manipulation_attack() {
    use crate::dynamic_prefetching::DynamicPrefetchingState;
    use aptos_config::config::{DataStreamingServiceConfig, DynamicPrefetchingConfig};
    use aptos_time_service::TimeService;
    
    // Setup config with default values
    let dynamic_prefetching_config = DynamicPrefetchingConfig {
        enable_dynamic_prefetching: true,
        initial_prefetching_value: 3,
        max_prefetching_value: 30,
        min_prefetching_value: 3,
        prefetching_value_increase: 1,
        prefetching_value_decrease: 2,
        timeout_freeze_duration_secs: 30,
        ..Default::default()
    };
    
    let config = DataStreamingServiceConfig {
        dynamic_prefetching: dynamic_prefetching_config,
        ..Default::default()
    };
    
    let time_service = TimeService::mock();
    let mut state = DynamicPrefetchingState::new(config, time_service.clone());
    
    // Simulate attacker pattern: 25 successes, 1 failure, repeat
    let initial_value = 3;
    let mut current_value = initial_value;
    
    for cycle in 0..10 {
        // 25 successful responses (should increase by 25 if not frozen)
        for _ in 0..25 {
            state.increase_max_concurrent_requests();
            time_service.into_mock().advance_secs(1);
        }
        
        // 1 failure (decreases by 2, freezes for 30s)
        state.decrease_max_concurrent_requests();
        current_value = current_value.saturating_sub(2).max(3);
        time_service.into_mock().advance_secs(1);
        
        // After first cycle, verify freeze is keeping value low
        if cycle > 0 {
            assert_eq!(
                current_value, 3,
                "Prefetch limit should stay at minimum due to freeze manipulation"
            );
        }
    }
    
    // Demonstrate that peer score would remain high (100.0) with 25:1 ratio
    // while prefetch limit is stuck at minimum (3)
    println!("Attack successful: Prefetch limit stuck at {} despite good peer score", current_value);
}
```

This PoC demonstrates how the freeze timer manipulation keeps the prefetch limit at minimum while the attacker maintains an excellent peer reputation through a high success-to-failure ratio.

### Citations

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L61-77)
```rust
    fn is_prefetching_value_frozen(&self) -> bool {
        match self.last_timeout_instant {
            Some(last_failure_time) => {
                // Get the time since the last failure and max freeze duration
                let time_since_last_failure =
                    self.time_service.now().duration_since(last_failure_time);
                let max_freeze_duration = Duration::from_secs(
                    self.get_dynamic_prefetching_config()
                        .timeout_freeze_duration_secs,
                );

                // Check if the time since the last failure is less than the freeze duration
                time_since_last_failure < max_freeze_duration
            },
            None => false, // No failures have occurred
        }
    }
```

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L109-126)
```rust
    pub fn increase_max_concurrent_requests(&mut self) {
        // If dynamic prefetching is disabled, or the value is currently frozen, do nothing
        if !self.is_dynamic_prefetching_enabled() || self.is_prefetching_value_frozen() {
            return;
        }

        // Otherwise, get and increase the current max
        let dynamic_prefetching_config = self.get_dynamic_prefetching_config();
        let amount_to_increase = dynamic_prefetching_config.prefetching_value_increase;
        let max_dynamic_concurrent_requests = self
            .max_dynamic_concurrent_requests
            .saturating_add(amount_to_increase);

        // Bound the value by the configured maximum
        let max_prefetching_value = dynamic_prefetching_config.max_prefetching_value;
        self.max_dynamic_concurrent_requests =
            min(max_dynamic_concurrent_requests, max_prefetching_value);
    }
```

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L128-150)
```rust
    /// Decreases the maximum number of concurrent requests that should be executing.
    /// This is typically called after a timeout is received.
    pub fn decrease_max_concurrent_requests(&mut self) {
        // If dynamic prefetching is disabled, do nothing
        if !self.is_dynamic_prefetching_enabled() {
            return;
        }

        // Update the last failure time
        self.last_timeout_instant = Some(self.time_service.now());

        // Otherwise, get and decrease the current max
        let dynamic_prefetching_config = self.get_dynamic_prefetching_config();
        let amount_to_decrease = dynamic_prefetching_config.prefetching_value_decrease;
        let max_dynamic_concurrent_requests = self
            .max_dynamic_concurrent_requests
            .saturating_sub(amount_to_decrease);

        // Bound the value by the configured minimum
        let min_prefetching_value = dynamic_prefetching_config.min_prefetching_value;
        self.max_dynamic_concurrent_requests =
            max(max_dynamic_concurrent_requests, min_prefetching_value);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L152-160)
```rust
    fn is_ignored(&self) -> bool {
        // Only ignore peers if the config allows it
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }

        // Otherwise, ignore peers with a low score
        self.score <= IGNORE_PEER_THRESHOLD
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L162-174)
```rust
    /// Updates the score of the peer according to a successful operation
    fn update_score_success(&mut self) {
        self.score = f64::min(self.score + SUCCESSFUL_RESPONSE_DELTA, MAX_SCORE);
    }

    /// Updates the score of the peer according to an error
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```

**File:** config/src/config/state_sync_config.rs (L319-319)
```rust
            min_prefetching_value: 3,
```

**File:** config/src/config/state_sync_config.rs (L322-322)
```rust
            timeout_freeze_duration_secs: 30,
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L508-511)
```rust
                        if !client_request.is_new_data_request() {
                            self.dynamic_prefetching_state
                                .increase_max_concurrent_requests();
                        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L530-532)
```rust
                        // Decrease the prefetching limit on an error
                        self.dynamic_prefetching_state
                            .decrease_max_concurrent_requests();
```
