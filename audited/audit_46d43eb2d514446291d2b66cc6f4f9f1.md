# Audit Report

## Title
Schema Evolution Vulnerability in Token Event Deserialization Causes Silent Data Loss During Historical Event Processing

## Summary
The `MutateTokenPropertyMapEvent` and related event structs lack schema evolution support (no `Option<>` fields, no `#[serde(default)]` attributes), causing BCS deserialization failures when the struct schema is modified. During indexer processing of historical events, deserialization errors are silently caught and events are discarded, leading to permanent data loss in the indexer without affecting consensus.

## Finding Description

The `MutateTokenPropertyMapEvent` struct uses strict BCS deserialization without any schema evolution mechanism: [1](#0-0) 

When V2 events (`MutatePropertyMap`) are translated to V1 format, the translator deserializes the event data using BCS: [2](#0-1) 

The critical vulnerability occurs in the batch processing logic where translation errors are caught and events are silently discarded: [3](#0-2) 

If a developer adds a new required field to `MutatePropertyMap` or `MutateTokenPropertyMapEvent` (e.g., `timestamp: u64`) without using `Option<>` or `#[serde(default)]`, all historical events stored on-chain with the old schema will fail BCS deserialization. The error handling code catches these failures and silently skips the events: [4](#0-3) 

Events are stored permanently in the database as BCS-encoded bytes: [5](#0-4) 

## Impact Explanation

This is a **High Severity** issue per the bug bounty program's "Significant protocol violations" category. While it doesn't directly compromise consensus or funds, it causes:

1. **Data Integrity Violation**: Token property mutation history is permanently lost in the indexer
2. **API Response Corruption**: Historical event queries return incomplete data
3. **Silent Failure Mode**: No clear error indicationâ€”events are simply missing
4. **Irreversible Data Loss**: Once skipped during indexing, events cannot be recovered without re-indexing from genesis

The impact affects all users querying token history via APIs, potentially impacting NFT marketplaces, wallets, and analytics platforms that rely on complete event data.

## Likelihood Explanation

**High Likelihood**: This will occur whenever developers need to extend event schemas during protocol evolution, which is a normal maintenance activity. The lack of schema evolution support makes this inevitable unless:
- All future fields are added as `Option<>` types retroactively
- Event schemas are frozen permanently (limiting protocol evolution)
- A hard fork is executed with full re-indexing

## Recommendation

Implement schema evolution support for all event structs by:

1. **Use `Option<>` for new fields**:
```rust
#[derive(Debug, Deserialize, Serialize)]
pub struct MutateTokenPropertyMapEvent {
    old_id: TokenId,
    new_id: TokenId,
    keys: Vec<String>,
    values: Vec<Vec<u8>>,
    types: Vec<String>,
    #[serde(default)]
    timestamp: Option<u64>,  // New field as Option
}
```

2. **Add struct-level default support**:
```rust
#[derive(Debug, Deserialize, Serialize)]
#[serde(default)]
pub struct MutateTokenPropertyMapEvent {
    // fields...
}
```

3. **Implement explicit versioning**:
```rust
#[derive(Debug, Deserialize, Serialize)]
#[serde(tag = "version")]
pub enum MutateTokenPropertyMapEvent {
    V1 { old_id: TokenId, new_id: TokenId, keys: Vec<String>, values: Vec<Vec<u8>>, types: Vec<String> },
    V2 { old_id: TokenId, new_id: TokenId, keys: Vec<String>, values: Vec<Vec<u8>>, types: Vec<String>, timestamp: u64 },
}
```

4. **Improve error handling** to fail loudly rather than silently skipping events:
```rust
// Change from Ok(None) to propagating critical errors
Err(e) => {
    let is_ignored_error = /* existing logic */;
    if !is_ignored_error {
        return Err(e);  // Fail loudly for deserialization errors
    }
    Ok(None)
}
```

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_bcs_deserialization_fails_with_schema_evolution() {
    use aptos_types::account_config::TokenId;
    use move_core_types::account_address::AccountAddress;
    
    // Old struct version (current)
    #[derive(Debug, serde::Deserialize, serde::Serialize)]
    struct OldEvent {
        old_id: TokenId,
        new_id: TokenId,
        keys: Vec<String>,
        values: Vec<Vec<u8>>,
        types: Vec<String>,
    }
    
    // New struct version with additional field (without Option)
    #[derive(Debug, serde::Deserialize, serde::Serialize)]
    struct NewEvent {
        old_id: TokenId,
        new_id: TokenId,
        keys: Vec<String>,
        values: Vec<Vec<u8>>,
        types: Vec<String>,
        timestamp: u64,  // NEW REQUIRED FIELD
    }
    
    // Create and serialize old event
    let old_event = OldEvent {
        old_id: TokenId::new(/* ... */),
        new_id: TokenId::new(/* ... */),
        keys: vec![],
        values: vec![],
        types: vec![],
    };
    let serialized = bcs::to_bytes(&old_event).unwrap();
    
    // Attempt to deserialize with new struct definition
    let result: Result<NewEvent, _> = bcs::from_bytes(&serialized);
    
    // This will fail with "missing field `timestamp`"
    assert!(result.is_err());
    println!("Deserialization failed as expected: {:?}", result.unwrap_err());
    
    // In production, this causes the event to be silently skipped
    // during indexer processing, resulting in permanent data loss
}
```

## Notes

This vulnerability exists for both `MutateTokenPropertyMapEvent` (V1) and `MutatePropertyMap` (V2), with the V2 translator being the active production code path affected. The same issue applies to other event types in the codebase that lack schema evolution support. A comprehensive audit of all event struct definitions is recommended.

### Citations

**File:** types/src/account_config/events/mutate_token_property_map_event.rs (L15-22)
```rust
#[derive(Debug, Deserialize, Serialize)]
pub struct MutateTokenPropertyMapEvent {
    old_id: TokenId,
    new_id: TokenId,
    keys: Vec<String>,
    values: Vec<Vec<u8>>,
    types: Vec<String>,
}
```

**File:** storage/indexer/src/event_v2_translator.rs (L716-716)
```rust
        let mutate = MutatePropertyMap::try_from_bytes(v2.event_data())?;
```

**File:** storage/indexer/src/db_indexer.rs (L448-484)
```rust
                    if self.indexer_db.event_v2_translation_enabled() {
                        if let ContractEvent::V2(v2) = event {
                            if let Some(translated_v1_event) =
                                self.translate_event_v2_to_v1(v2).map_err(|e| {
                                    anyhow::anyhow!(
                                        "Failed to translate event: {:?}. Error: {}",
                                        v2,
                                        e
                                    )
                                })?
                            {
                                let key = *translated_v1_event.key();
                                let sequence_number = translated_v1_event.sequence_number();
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
                                event_keys.insert(key);
                                batch
                                    .put::<EventByKeySchema>(
                                        &(key, sequence_number),
                                        &(version, idx as u64),
                                    )
                                    .expect("Failed to put events by key to a batch");
                                batch
                                    .put::<EventByVersionSchema>(
                                        &(key, version, sequence_number),
                                        &(idx as u64),
                                    )
                                    .expect("Failed to put events by version to a batch");
                                batch
                                    .put::<TranslatedV1EventSchema>(
                                        &(version, idx as u64),
                                        &translated_v1_event,
                                    )
                                    .expect("Failed to put translated v1 events to a batch");
                            }
                        }
                    }
```

**File:** storage/indexer/src/db_indexer.rs (L562-580)
```rust
            let result = translator.translate_event_v2_to_v1(v2, &self.event_v2_translation_engine);
            match result {
                Ok(v1) => Ok(Some(v1)),
                Err(e) => {
                    // If the token object collection uses ConcurrentSupply, skip the translation and ignore the error.
                    // This is expected, as the event handle won't be found in either FixedSupply or UnlimitedSupply.
                    let is_ignored_error = (v2.type_tag() == &*MINT_TYPE
                        || v2.type_tag() == &*BURN_TYPE)
                        && e.to_string().contains("resource not found");
                    if !is_ignored_error {
                        warn!(
                            "Failed to translate event: {:?}. Error: {}",
                            v2,
                            e.to_string()
                        );
                    }
                    Ok(None)
                },
            }
```

**File:** storage/aptosdb/src/schema/event/mod.rs (L49-56)
```rust
impl ValueCodec<EventSchema> for ContractEvent {
    fn encode_value(&self) -> Result<Vec<u8>> {
        bcs::to_bytes(self).map_err(Into::into)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        bcs::from_bytes(data).map_err(Into::into)
    }
```
