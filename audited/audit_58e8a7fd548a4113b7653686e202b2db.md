# Audit Report

## Title
CFG Construction Complexity Attack: Unmetered Verification Enables Validator DoS via Maximum Branching Bytecode

## Summary
The Move bytecode verifier constructs Control Flow Graphs (CFGs) and performs loop reducibility analysis **before** enforcing the `max_basic_blocks` limit. An attacker can deploy modules with pathologically complex control flow that pass deserialization but trigger expensive verification operations, causing validator resource exhaustion. Gas is charged per byte, not per verification complexity.

## Finding Description

The vulnerability exists in the module verification pipeline where expensive CFG construction and loop analysis occur before block count limits are checked.

**Attack Flow:**

1. Attacker crafts bytecode with maximum branching using patterns like alternating `BrTrue` instructions
2. Module passes deserialization (limited to 65,535 instructions) [1](#0-0) 
3. Within transaction size limit (64 KB), attacker can create ~10,000-15,000 basic blocks [2](#0-1) 
4. During verification, `CodeUnitVerifier::verify_function` is invoked [3](#0-2) 
5. This calls `control_flow::verify_function`, which constructs the CFG via `FunctionView::function` [4](#0-3) 
6. The `FunctionView` constructor calls `VMControlFlowGraph::new()` to build the CFG [5](#0-4) 
7. `verify_reducibility` performs expensive loop analysis [6](#0-5) 
8. **Only after** these operations, the `max_basic_blocks` limit (1024) is checked [7](#0-6) 
9. Verification fails, but validator has already wasted significant computation

**Key Technical Details:**

The CFG construction in `VMControlFlowGraph::new()` must:
- Iterate through all instructions to identify basic blocks [8](#0-7) 
- Create basic block structures [9](#0-8) 
- Perform loop analysis with depth-first numbering [10](#0-9) 

Then `verify_reducibility` creates `LoopSummary` and `LoopPartition`, iterating through all nodes [11](#0-10) 

**Critical Gap:** The metering mechanism exists but is **explicitly disabled** for control flow verification [12](#0-11) 

The `LimitsVerifier` that runs earlier does NOT check basic blocks - it only verifies type nodes, function parameters, and struct definitions [13](#0-12) 

## Impact Explanation

**High Severity - Validator Node Slowdowns**

This vulnerability aligns with Aptos bug bounty HIGH severity criteria for "Validator Node Slowdowns: Significant performance degradation affecting consensus, DoS through resource exhaustion."

**Concrete Impact:**

1. **Resource Exhaustion**: Each malicious module forces validators to process thousands of basic blocks during CFG construction and loop analysis before rejection
2. **Network-Wide Effect**: All validators must verify published modules in transactions, affecting the entire network
3. **Low Attack Cost**: Gas is charged per transaction byte (64 KB max), but computational cost is disproportionately higher with ~10,000-15,000 basic blocks vs 1024 limit
4. **Amplification Potential**: Multiple concurrent malicious module publishing transactions could significantly degrade validator performance
5. **Consensus Impact**: Sustained attacks could increase block production latency, cause validator stragglers, and degrade network throughput

The production configuration sets `max_basic_blocks: Some(1024)` [14](#0-13)  but this limit is enforced too late in the verification pipeline.

## Likelihood Explanation

**High Likelihood**

- **Attacker Requirements**: Any account with sufficient gas to submit a module publishing transaction (regular users)
- **Technical Complexity**: Low - generating bytecode with alternating branch instructions is straightforward
- **Detection Difficulty**: Malicious modules appear as normal verification failures in logs
- **No Rate Limiting**: Module verification occurs for every publishing attempt, even those that ultimately fail
- **Disabled Protection**: The TODO comment confirms metering is not implemented for control flow verification [12](#0-11) 

Branch instructions (`BrTrue`, `BrFalse`, `Branch`) create new basic blocks at their target offsets [15](#0-14)  and the basic block construction algorithm identifies these during CFG building [16](#0-15) 

## Recommendation

**Immediate Fix:** Move the `max_basic_blocks` check to occur BEFORE expensive CFG construction:

1. Add a pre-check in `control_flow::verify_function` that counts potential basic blocks by scanning for branch instructions before calling `FunctionView::function`
2. Enable metering for control flow verification by implementing the TODO at line 41
3. Consider adding a `max_instructions` limit as an early check before any verification

**Code Location for Fix:** [17](#0-16) 

**Proposed Implementation:**
- Before line 50, add a fast pre-scan of `code.code` to count branch instructions
- If potential basic blocks exceed limit, return error immediately
- This prevents expensive CFG construction for obviously malicious modules

## Proof of Concept

A PoC would construct Move bytecode with alternating `BrTrue` instructions targeting sequential offsets:

```
Bytecode pattern (pseudo-code):
0: BrTrue 1
1: BrTrue 2  
2: BrTrue 3
...
N: Ret
```

Each `BrTrue` creates a new basic block, allowing ~10,000-15,000 blocks within the 64 KB transaction limit. When this module is submitted via a transaction, validators will:

1. Accept the transaction (valid bytecode, within size limits)
2. Attempt verification
3. Execute expensive CFG construction processing all blocks
4. Execute loop analysis traversing the CFG
5. Finally fail at the `max_basic_blocks` check
6. Reject the module, having wasted computational resources

A complete Rust test would use the Move bytecode API to programmatically generate such a module and measure verification time before and after the limit check.

### Citations

**File:** third_party/move/move-binary-format/src/file_format_common.rs (L61-61)
```rust
pub const BYTECODE_COUNT_MAX: u64 = 65535;
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L73-76)
```rust
            max_transaction_size_in_bytes: NumBytes,
            "max_transaction_size_in_bytes",
            64 * 1024
        ],
```

**File:** third_party/move/move-bytecode-verifier/src/verifier.rs (L158-158)
```rust
        CodeUnitVerifier::verify_module(config, module)?;
```

**File:** third_party/move/move-bytecode-verifier/src/code_unit_verifier.rs (L138-145)
```rust
        let function_view = control_flow::verify_function(
            verifier_config,
            module,
            index,
            function_definition,
            code,
            meter,
        )?;
```

**File:** third_party/move/move-bytecode-verifier/src/code_unit_verifier.rs (L147-152)
```rust
        if let Some(limit) = verifier_config.max_basic_blocks {
            if function_view.cfg().blocks().len() > limit {
                return Err(
                    PartialVMError::new(StatusCode::TOO_MANY_BASIC_BLOCKS).at_code_offset(index, 0)
                );
            }
```

**File:** third_party/move/move-binary-format/src/binary_views.rs (L449-449)
```rust
            cfg: VMControlFlowGraph::new(&code.code),
```

**File:** third_party/move/move-bytecode-verifier/src/control_flow.rs (L35-54)
```rust
pub fn verify_function<'a>(
    verifier_config: &'a VerifierConfig,
    module: &'a CompiledModule,
    index: FunctionDefinitionIndex,
    function_definition: &'a FunctionDefinition,
    code: &'a CodeUnit,
    _meter: &mut impl Meter, // TODO: metering
) -> PartialVMResult<FunctionView<'a>> {
    let function_handle = module.function_handle_at(function_definition.function);

    if module.version() <= 5 {
        control_flow_v5::verify(verifier_config, Some(index), code)?;
        Ok(FunctionView::function(module, index, code, function_handle))
    } else {
        verify_fallthrough(Some(index), code)?;
        let function_view = FunctionView::function(module, index, code, function_handle);
        verify_reducibility(verifier_config, &function_view)?;
        Ok(function_view)
    }
}
```

**File:** third_party/move/move-bytecode-verifier/src/control_flow.rs (L126-179)
```rust
    let summary = LoopSummary::new(function_view.cfg());
    let mut partition = LoopPartition::new(&summary);

    // Iterate through nodes in reverse pre-order so more deeply nested loops (which would appear
    // later in the pre-order) are processed first.
    for head in summary.preorder().rev() {
        // If a node has no back edges, it is not a loop head, so doesn't need to be processed.
        let back = summary.back_edges(head);
        if back.is_empty() {
            continue;
        }

        // Collect the rest of the nodes in `head`'s loop, in `body`.  Start with the nodes that
        // jump back to the head, and grow `body` by repeatedly following predecessor edges until
        // `head` is found again.

        let mut body = BTreeSet::new();
        for node in back {
            let node = partition.containing_loop(*node);

            if node != head {
                body.insert(node);
            }
        }

        let mut frontier: Vec<_> = body.iter().copied().collect();
        while let Some(node) = frontier.pop() {
            for pred in summary.pred_edges(node) {
                let pred = partition.containing_loop(*pred);

                // `pred` can eventually jump back to `head`, so is part of its body.  If it is not
                // a descendant of `head`, it implies that `head` does not dominate a node in its
                // loop, therefore the CFG is not reducible, according to Property 1 (see doc
                // comment).
                if !summary.is_descendant(/* ancestor */ head, /* descendant */ pred) {
                    return err(StatusCode::INVALID_LOOP_SPLIT, summary.block(pred));
                }

                let body_extended = pred != head && body.insert(pred);
                if body_extended {
                    frontier.push(pred);
                }
            }
        }

        // Collapse all the nodes in `body` into `head`, so it appears as one node when processing
        // outer loops (this performs a sequence of Operation 4(b), followed by a 4(a)).
        let depth = partition.collapse_loop(head, &body);
        if let Some(max_depth) = verifier_config.max_loop_depth {
            if depth as usize > max_depth {
                return err(StatusCode::LOOP_MAX_DEPTH_REACHED, summary.block(head));
            }
        }
    }
```

**File:** third_party/move/move-binary-format/src/control_flow_graph.rs (L90-92)
```rust
        for pc in 0..code.len() {
            VMControlFlowGraph::record_block_ids(pc as CodeOffset, code, &mut block_ids);
        }
```

**File:** third_party/move/move-binary-format/src/control_flow_graph.rs (L98-112)
```rust
        for pc in 0..code.len() {
            let co_pc = pc as CodeOffset;

            // Create a basic block
            if Self::is_end_of_block(co_pc, code, &block_ids) {
                let exit = co_pc;
                exit_to_entry.insert(exit, entry);
                let successors = Bytecode::get_successors(co_pc, code);
                let bb = BasicBlock { exit, successors };
                blocks.insert(entry, bb);
                entry = co_pc + 1;
            }
        }
        let blocks = blocks;
        assert_eq!(entry, code_len);
```

**File:** third_party/move/move-binary-format/src/control_flow_graph.rs (L133-202)
```rust
        let mut exploration: Map<BlockId, Exploration> = Map::new();
        let mut stack = vec![ENTRY_BLOCK_ID];

        // For every loop in the CFG that is reachable from the entry block, there is an entry in
        // `loop_heads` mapping to all the back edges pointing to it, and vice versa.
        //
        // Entry in `loop_heads` implies loop in the CFG is justified by the comments in the loop
        // below.  Loop in the CFG implies entry in `loop_heads` is justified by considering the
        // point at which the first node in that loop, `F` is added to the `exploration` map:
        //
        // - By definition `F` is part of a loop, meaning there is a block `L` such that:
        //
        //     F - ... -> L -> F
        //
        // - `F` will not transition to `Done` until all the nodes reachable from it (including `L`)
        //   have been visited.
        // - Because `F` is the first node seen in the loop, all the other nodes in the loop
        //   (including `L`) will be visited while `F` is `InProgress`.
        // - Therefore, we will process the `L -> F` edge while `F` is `InProgress`.
        // - Therefore, we will record a back edge to it.
        let mut loop_heads: Map<BlockId, Set<BlockId>> = Map::new();

        // Blocks appear in `post_order` after all the blocks in their (non-reflexive) sub-graph.
        let mut post_order = Vec::with_capacity(blocks.len());

        while let Some(block) = stack.pop() {
            match exploration.entry(block) {
                Entry::Vacant(entry) => {
                    // Record the fact that exploration of this block and its sub-graph has started.
                    entry.insert(Exploration::InProgress);

                    // Push the block back on the stack to finish processing it, and mark it as done
                    // once its sub-graph has been traversed.
                    stack.push(block);

                    for succ in &blocks[&block].successors {
                        match exploration.get(succ) {
                            // This successor has never been visited before, add it to the stack to
                            // be explored before `block` gets marked `Done`.
                            None => stack.push(*succ),

                            // This block's sub-graph was being explored, meaning it is a (reflexive
                            // transitive) predecessor of `block` as well as being a successor,
                            // implying a loop has been detected -- greedily choose the successor
                            // block as the loop head.
                            Some(Exploration::InProgress) => {
                                loop_heads.entry(*succ).or_default().insert(block);
                            },

                            // Cross-edge detected, this block and its entire sub-graph (modulo
                            // cycles) has already been explored via a different path, and is
                            // already present in `post_order`.
                            Some(Exploration::Done) => { /* skip */ },
                        };
                    }
                },

                Entry::Occupied(mut entry) => match entry.get() {
                    // Already traversed the sub-graph reachable from this block, so skip it.
                    Exploration::Done => continue,

                    // Finish up the traversal by adding this block to the post-order traversal
                    // after its sub-graph (modulo cycles).
                    Exploration::InProgress => {
                        post_order.push(block);
                        entry.insert(Exploration::Done);
                    },
                },
            }
        }
```

**File:** third_party/move/move-binary-format/src/control_flow_graph.rs (L238-247)
```rust
    fn record_block_ids(pc: CodeOffset, code: &[Bytecode], block_ids: &mut Set<BlockId>) {
        let bytecode = &code[pc as usize];

        if let Some(offset) = bytecode.offset() {
            block_ids.insert(*offset);
        }

        if bytecode.is_branch() && pc + 1 < (code.len() as CodeOffset) {
            block_ids.insert(pc + 1);
        }
```

**File:** third_party/move/move-bytecode-verifier/src/limits.rs (L31-34)
```rust
        limit_check.verify_function_handles(config)?;
        limit_check.verify_struct_handles(config)?;
        limit_check.verify_type_nodes(config)?;
        limit_check.verify_definitions(config)
```

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L160-160)
```rust
        max_basic_blocks: Some(1024),
```

**File:** third_party/move/move-binary-format/src/file_format.rs (L3211-3213)
```rust
            Bytecode::BrFalse(offset) | Bytecode::BrTrue(offset) | Bytecode::Branch(offset) => {
                Some(offset)
            },
```
