# Audit Report

## Title
HotStateView Temporal Inconsistency Causes Non-Deterministic Execution and Consensus Divergence

## Summary
The `get_persisted_state()` function returns a tuple of `(Arc<dyn HotStateView>, State)` where the `HotStateView` is a shared mutable data structure that can be updated asynchronously by background threads, while the `State` represents a snapshot at a specific version. This temporal mismatch allows validators executing the same block at different times to read different values from the hot state, breaking deterministic execution and potentially causing consensus divergence.

## Finding Description

The vulnerability exists in the lifetime and consistency relationship between `HotStateView` and `State` returned by `get_persisted_state()`. [1](#0-0) 

The implementation delegates to the state store: [2](#0-1) 

Which retrieves from persisted state: [3](#0-2) 

The critical issue is in `HotState.get_committed()`: [4](#0-3) 

This returns:
1. `self.base` - An `Arc<HotStateBase>` which is a **shared reference** to a concurrent DashMap
2. `state` - A **cloned snapshot** of the committed State at a specific version

The `HotStateBase` is concurrently modified by a background committer thread: [5](#0-4) 

The race condition manifests during state queries: [6](#0-5) 

When a validator creates a `CachedStateView` for block execution: [7](#0-6) 

**Attack Scenario:**
1. Blockchain is at version 100, account A has balance 1000 (stored in hot state)
2. Version 101 is committed, updating A's balance to 500
3. Background `StateSnapshotCommitter` processes version 101
4. Validator V1 calls `get_persisted_state()` at T1, receives `(hot_base_ref, state_v100)`
5. Background `HotState` committer updates shared `hot_base_ref` with version 101 data at T2
6. Validator V1 executes block at version 102, queries account A's balance at T3
   - Checks speculative state: not modified yet, so not found
   - Checks hot state: `hot_base_ref.get_state_slot(A)` returns balance = 500 (from v101)
   - **Uses value 500 from version 101, not 1000 from version 100**
7. Validator V2 calls `get_persisted_state()` before T2, sees balance 1000
8. V1 and V2 compute different state roots for the same block

The `StateSlot` contains version metadata, but it's discarded during extraction: [8](#0-7) 

No version validation occurs - the VM receives values from mismatched versions without detection.

## Impact Explanation

**Critical Severity** - This vulnerability breaks the fundamental invariant of deterministic execution in a blockchain consensus system:

1. **Consensus Divergence**: Different validators executing identical blocks can produce different state roots, causing consensus failure and potential chain splits

2. **Non-Deterministic Execution**: The same transaction can yield different results depending on when the validator queries the hot state relative to background commit operations

3. **State Root Mismatch**: Validators will fail to agree on the correct state root hash, preventing block finalization

4. **Potential Chain Split**: If a sufficient number of validators see different hot state views, they may form incompatible forks requiring manual intervention or a hard fork to resolve

This violates the **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks" and represents a **Consensus/Safety violation** qualifying as Critical Severity under the Aptos bug bounty program.

## Likelihood Explanation

**High Likelihood** - This is not an exploitable attack but a **natural race condition** that can occur during normal operation:

- Happens whenever `get_persisted_state()` is called around the time background state commits are processed
- More likely during high transaction throughput when commits happen frequently  
- Does not require malicious actor - timing differences in validator execution naturally trigger the race
- Validators with different hardware performance or network latency are more susceptible
- The hot state feature appears to be actively developed (multiple TODO comments reference it), suggesting this issue may not have been discovered yet

## Recommendation

**Fix 1: Version-Stamped HotStateView**

Create a snapshot of the `HotStateBase` at the time of `get_persisted_state()` that is immutable and tied to the specific State version:

```rust
// In hot_state.rs
pub fn get_committed(&self) -> (Arc<dyn HotStateView>, State) {
    let state = self.committed.lock().clone();
    
    // Create an immutable snapshot of the current hot state
    let hot_snapshot = Arc::new(HotStateSnapshot::from_base(&self.base, state.version()));
    
    (hot_snapshot, state)
}

// New immutable snapshot type
struct HotStateSnapshot {
    data: HashMap<StateKey, StateSlot>,
    version: Option<Version>,
}

impl HotStateView for HotStateSnapshot {
    fn get_state_slot(&self, state_key: &StateKey) -> Option<StateSlot> {
        self.data.get(state_key).cloned()
    }
}
```

**Fix 2: Version Validation in Query Path**

Add version checks when retrieving values from hot state:

```rust
// In cached_state_view.rs
} else if let Some(slot) = self.hot.get_state_slot(state_key) {
    // Validate that the slot's version doesn't exceed our base version
    if let Some((value_version, _)) = slot.into_state_value_and_version_opt() {
        if let Some(base_ver) = self.base_version() {
            if value_version > base_ver {
                // Value is from the future, fall back to DB
                return self.query_from_db(state_key);
            }
        }
    }
    slot
}
```

**Recommended Approach**: Fix 1 is preferred as it addresses the root cause by ensuring the `HotStateView` is truly immutable and consistent with the State version.

## Proof of Concept

```rust
// Test demonstrating the race condition
#[test]
fn test_hot_state_temporal_inconsistency() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let db = setup_test_db();
    let barrier = Arc::new(Barrier::new(3));
    
    // Thread 1: Validator V1 gets persisted state early
    let barrier1 = barrier.clone();
    let db1 = db.clone();
    let handle1 = thread::spawn(move || {
        let (hot_view1, state1) = db1.reader.get_persisted_state().unwrap();
        let version1 = state1.version();
        barrier1.wait(); // Wait for commit to happen
        
        // Query hot state after commit
        let key = test_key();
        let value1 = hot_view1.get_state_slot(&key);
        (version1, value1)
    });
    
    // Thread 2: Background commit happens
    let barrier2 = barrier.clone();
    let db2 = db.clone();
    let handle2 = thread::spawn(move || {
        barrier2.wait();
        // Commit new version that updates hot state
        commit_new_state(&db2, test_key(), "new_value");
        barrier2.wait();
    });
    
    // Thread 3: Validator V2 gets persisted state after commit
    let barrier3 = barrier.clone();
    let db3 = db.clone();
    let handle3 = thread::spawn(move || {
        barrier3.wait(); // Wait for commit
        barrier3.wait(); // Ensure commit completed
        
        let (hot_view2, state2) = db3.reader.get_persisted_state().unwrap();
        let version2 = state2.version();
        let key = test_key();
        let value2 = hot_view2.get_state_slot(&key);
        (version2, value2)
    });
    
    let (ver1, val1) = handle1.join().unwrap();
    handle2.join().unwrap();
    let (ver2, val2) = handle3.join().unwrap();
    
    // Both validators query at the "same" persisted version
    // but get different values from hot state
    assert_eq!(ver1, ver2, "Versions should match");
    assert_ne!(val1, val2, "BUG: Values differ despite same version!");
}
```

## Notes

The hot state optimization feature appears to be relatively new based on numerous `TODO(HotState)` comments throughout the codebase. This temporal inconsistency issue likely stems from the concurrent nature of the hot state cache not being properly isolated from the snapshot semantics expected by the execution layer. The fix requires ensuring that when a `State` snapshot is created, its associated `HotStateView` represents the same point-in-time view, not a live mutable reference to the current hot state.

### Citations

**File:** storage/storage-interface/src/lib.rs (L416-416)
```rust
        fn get_persisted_state(&self) -> Result<(Arc<dyn HotStateView>, State)>;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L252-253)
```rust
    fn get_persisted_state(&self) -> Result<(Arc<dyn HotStateView>, State)> {
        Ok(self.persisted_state.get_state())
```

**File:** storage/aptosdb/src/state_store/persisted_state.rs (L46-48)
```rust
    pub fn get_state(&self) -> (Arc<dyn HotStateView>, State) {
        self.hot_state.get_committed()
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L131-136)
```rust
    pub fn get_committed(&self) -> (Arc<dyn HotStateView>, State) {
        let state = self.committed.lock().clone();
        let base = self.base.clone();

        (base, state)
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L235-275)
```rust
    fn commit(&mut self, to_commit: &State) {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["hot_state_commit"]);

        let mut n_insert = 0;
        let mut n_update = 0;
        let mut n_evict = 0;

        let delta = to_commit.make_delta(&self.committed.lock());
        for shard_id in 0..NUM_STATE_SHARDS {
            for (key, slot) in delta.shards[shard_id].iter() {
                if slot.is_hot() {
                    let key_size = key.size();
                    self.total_key_bytes += key_size;
                    self.total_value_bytes += slot.size();
                    if let Some(old_slot) = self.base.shards[shard_id].insert(key, slot) {
                        self.total_key_bytes -= key_size;
                        self.total_value_bytes -= old_slot.size();
                        n_update += 1;
                    } else {
                        n_insert += 1;
                    }
                } else if let Some((key, old_slot)) = self.base.shards[shard_id].remove(&key) {
                    self.total_key_bytes -= key.size();
                    self.total_value_bytes -= old_slot.size();
                    n_evict += 1;
                }
            }
            self.heads[shard_id] = to_commit.latest_hot_key(shard_id);
            self.tails[shard_id] = to_commit.oldest_hot_key(shard_id);
            assert_eq!(
                self.base.shards[shard_id].len(),
                to_commit.num_hot_items(shard_id)
            );

            debug_assert!(self.validate_lru(shard_id).is_ok());
        }

        COUNTER.inc_with_by(&["hot_state_insert"], n_insert);
        COUNTER.inc_with_by(&["hot_state_update"], n_update);
        COUNTER.inc_with_by(&["hot_state_evict"], n_evict);
    }
```

**File:** storage/storage-interface/src/state_store/state_view/cached_state_view.rs (L236-250)
```rust
        let ret = if let Some(slot) = self.speculative.get_state_slot(state_key) {
            COUNTER.inc_with(&["sv_hit_speculative"]);
            slot
        } else if let Some(slot) = self.hot.get_state_slot(state_key) {
            COUNTER.inc_with(&["sv_hit_hot"]);
            slot
        } else if let Some(base_version) = self.base_version() {
            COUNTER.inc_with(&["sv_cold"]);
            StateSlot::from_db_get(
                self.cold
                    .get_state_value_with_version_by_version(state_key, base_version)?,
            )
        } else {
            StateSlot::ColdVacant
        };
```

**File:** execution/executor/src/block_executor/mod.rs (L226-233)
```rust
                let state_view = {
                    let _timer = OTHER_TIMERS.timer_with(&["get_state_view"]);
                    CachedStateView::new(
                        StateViewId::BlockExecution { block_id },
                        Arc::clone(&self.db.reader),
                        parent_output.result_state().latest().clone(),
                    )?
                };
```

**File:** types/src/state_store/mod.rs (L65-69)
```rust
    fn get_state_value(&self, state_key: &Self::Key) -> StateViewResult<Option<StateValue>> {
        // if not implemented, delegate to get_state_slot.
        self.get_state_slot(state_key)
            .map(StateSlot::into_state_value_opt)
    }
```
