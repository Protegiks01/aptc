# Audit Report

## Title
State Snapshot Restore Ordering Assumption Violation Leads to Restore Failure

## Summary
The state snapshot restore process assumes chunks in manifests are sorted by `last_key` when using `skip_while` to resume interrupted restores. If chunks are unsorted due to malicious manifests or buggy backup software, the resume logic incorrectly skips unprocessed chunks, causing restore failure that affects validator availability.

## Finding Description

The vulnerability exists in the resume logic that determines which chunks to skip during interrupted restore operations. [1](#0-0) 

The code retrieves the resume point (hash of the last successfully restored key) and uses `skip_while` to skip chunks where `chunk.last_key <= resume_point`. The `skip_while` iterator adapter has specific semantics: it skips elements from the start while the predicate is true, then stops at the first false predicate and yields all remaining elements.

**Critical Assumption**: This logic assumes chunks are sorted by `last_key` in ascending order. If sorted, once we encounter the first chunk with `last_key > resume_point`, all subsequent chunks will also satisfy this condition, making `skip_while` safe.

**Violation**: The manifest structure provides no ordering guarantees in its type definition: [2](#0-1) 

During normal backup operations, chunks are created in order and maintained by `try_buffered_x`: [3](#0-2) 

The `try_buffered_x` implementation maintains order through `FuturesOrderedX`: [4](#0-3) [5](#0-4) 

However, **no validation** exists to verify chunks remain sorted when manifests are loaded from storage: [6](#0-5) 

The system validates proofs and root hash but does not check chunk ordering.

**Attack Scenario**:
1. Attacker creates malicious manifest with unsorted chunks (Chunk 0: `0x03`, Chunk 1: `0x50`, Chunk 2: `0x12`)
2. Victim processes Chunks 0-1, crashes at progress = `0x50`
3. On resume, `skip_while(|chunk| chunk.last_key <= 0x50)` skips all three chunks including unprocessed Chunk 2
4. Result: Incomplete state leads to root hash mismatch and restore failure

The internal chunk-level overlap detection cannot prevent this: [7](#0-6) 

This only handles overlaps within chunks, not manifest-level ordering violations.

**Failure Detection**: The vulnerability causes restore failure, not silent corruption. The Merkle proof verification detects the incomplete state: [8](#0-7) 

## Impact Explanation

**Severity: High**

This vulnerability falls under the **High severity** category per Aptos bug bounty criteria: "Validator node slowdowns" - validators cannot restore from backups, affecting their ability to recover from failures.

Impact:
1. **Restore Failure**: The root hash verification will detect incomplete state and cause restore to fail
2. **Validator Availability**: Validators cannot recover using compromised backups, affecting network participation
3. **Obscured Root Cause**: Error manifests as "root hash mismatch" without indicating the actual cause (manifest ordering violation)

This is **NOT Critical** severity because:
- Failures are detected via cryptographic verification (not silent)
- Does not cause consensus breaks or fund theft
- Does not affect running validators, only recovery operations
- Requires specific conditions to trigger

The vulnerability represents a defense-in-depth failure where external inputs (backup manifests) are not properly validated.

## Likelihood Explanation

**Likelihood: Medium**

While normal Aptos backup operations produce correctly sorted chunks, the vulnerability can be triggered through:

1. **Malicious Backup Distribution**: Compromised backup sources distributing corrupted manifests
2. **Buggy Third-Party Tools**: Non-standard backup implementations that don't maintain ordering
3. **Supply Chain Attacks**: Compromise of backup distribution infrastructure
4. **Storage Corruption**: Cloud storage errors or manual manifest modifications

Attack requirements:
- Validator obtains unsorted manifest from external source (realistic during disaster recovery)
- Restore interruption occurs (common for large state snapshots)
- Resume operation is attempted (standard recovery procedure)

Per the storage README, validators may use externally-provided backup sources for emergency recovery, making this scenario realistic despite validator operators being trusted roles. [9](#0-8) 

## Recommendation

Add validation when loading manifests to ensure chunks are sorted by `last_key`:

```rust
// After loading manifest at line 124
let chunks = manifest.chunks;
for i in 1..chunks.len() {
    ensure!(
        chunks[i-1].last_key < chunks[i].last_key,
        "Manifest chunks must be sorted by last_key. Chunk {} has last_key {:?}, but chunk {} has last_key {:?}",
        i-1, chunks[i-1].last_key, i, chunks[i].last_key
    );
}
```

This provides defense-in-depth by rejecting malformed manifests early with a clear error message.

## Proof of Concept

The vulnerability can be demonstrated by:
1. Creating a manifest with unsorted chunks
2. Performing partial restore
3. Attempting resume with the malformed manifest
4. Observing that unprocessed chunks are incorrectly skipped

The restore will fail with a root hash mismatch rather than succeeding with corrupted state, confirming the vulnerability causes availability issues rather than correctness violations.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-136)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L165-174)
```rust
        let resume_point_opt = receiver.lock().as_mut().unwrap().previous_key_hash()?;
        let chunks = if let Some(resume_point) = resume_point_opt {
            manifest
                .chunks
                .into_iter()
                .skip_while(|chunk| chunk.last_key <= resume_point)
                .collect()
        } else {
            manifest.chunks
        };
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L29-51)
```rust
/// State snapshot backup manifest, representing a complete state view at specified version.
#[derive(Deserialize, Serialize)]
pub struct StateSnapshotBackup {
    /// Version at which this state snapshot is taken.
    pub version: Version,
    /// Epoch in which this state snapshot is taken.
    pub epoch: u64,
    /// Hash of the state tree root.
    pub root_hash: HashValue,
    /// All account blobs in chunks.
    pub chunks: Vec<StateSnapshotChunk>,
    /// BCS serialized
    /// `Tuple(TransactionInfoWithProof, LedgerInfoWithSignatures)`.
    ///   - The `TransactionInfoWithProof` is at `Version` above, and carries the same `root_hash`
    /// above; It proves that at specified version the root hash is as specified in a chain
    /// represented by the LedgerInfo below.
    ///   - The signatures on the `LedgerInfoWithSignatures` has a version greater than or equal to
    /// the version of this backup but is within the same epoch, so the signatures on it can be
    /// verified by the validator set in the same epoch, which can be provided by an
    /// `EpochStateBackup` recovered prior to this to the DB; Requiring it to be in the same epoch
    /// limits the requirement on such `EpochStateBackup` to no older than the same epoch.
    pub proof: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L253-266)
```rust
        let chunks: Vec<_> = chunk_manifest_fut_stream
            .try_buffered_x(8, 4) // 4 concurrently, at most 8 results in buffer.
            .map_ok(|chunk_manifest| {
                let last_idx = chunk_manifest.last_idx;
                info!(
                    last_idx = last_idx,
                    values_per_second =
                        ((last_idx + 1) as f64 / start.elapsed().as_secs_f64()) as u64,
                    "Chunk written."
                );
                chunk_manifest
            })
            .try_collect()
            .await?;
```

**File:** storage/backup/backup-cli/src/utils/stream/try_buffered_x.rs (L37-43)
```rust
    pub(super) fn new(stream: St, n: usize, max_in_progress: usize) -> Self {
        Self {
            stream: stream.into_stream().fuse(),
            in_progress_queue: FuturesOrderedX::new(max_in_progress),
            max: n,
        }
    }
```

**File:** storage/backup/backup-cli/src/utils/stream/futures_ordered_x.rs (L76-118)
```rust
impl<Fut: Future> FuturesOrderedX<Fut> {
    /// Constructs a new, empty `FuturesOrdered`
    ///
    /// The returned `FuturesOrdered` does not contain any futures and, in this
    /// state, `FuturesOrdered::poll_next` will return `Poll::Ready(None)`.
    pub fn new(max_in_progress: usize) -> FuturesOrderedX<Fut> {
        FuturesOrderedX {
            in_progress_queue: FuturesUnorderedX::new(max_in_progress),
            queued_outputs: BinaryHeap::new(),
            next_incoming_index: 0,
            next_outgoing_index: 0,
        }
    }

    /// Returns the number of futures contained in the queue.
    ///
    /// This represents the total number of in-flight futures, both
    /// those currently processing and those that have completed but
    /// which are waiting for earlier futures to complete.
    pub fn len(&self) -> usize {
        self.in_progress_queue.len() + self.queued_outputs.len()
    }

    /// Returns `true` if the queue contains no futures
    #[allow(dead_code)]
    pub fn is_empty(&self) -> bool {
        self.in_progress_queue.is_empty() && self.queued_outputs.is_empty()
    }

    /// Push a future into the queue.
    ///
    /// This function submits the given future to the internal set for managing.
    /// This function will not call `poll` on the submitted future. The caller
    /// must ensure that `FuturesOrdered::poll` is called in order to receive
    /// task notifications.
    pub fn push(&mut self, future: Fut) {
        let wrapped = OrderWrapper {
            data: future,
            index: self.next_incoming_index,
        };
        self.next_incoming_index += 1;
        self.in_progress_queue.push(wrapped);
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L88-104)
```rust
    pub fn add_chunk(&mut self, mut chunk: Vec<(K, V)>) -> Result<()> {
        // load progress
        let progress_opt = self.db.get_progress(self.version)?;

        // skip overlaps
        if let Some(progress) = progress_opt {
            let idx = chunk
                .iter()
                .position(|(k, _v)| CryptoHash::hash(k) > progress.key_hash)
                .unwrap_or(chunk.len());
            chunk = chunk.split_off(idx);
        }

        // quit if all skipped
        if chunk.is_empty() {
            return Ok(());
        }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L689-696)
```rust
        // Verify the proof now that we have all the siblings
        proof
            .verify(
                self.expected_root_hash,
                SparseMerkleLeafNode::new(*previous_key, previous_leaf.value_hash()),
                left_siblings,
            )
            .map_err(Into::into)
```

**File:** storage/README.md (L279-282)
```markdown
When emergency happens and the need to do the somewhat manual bootstrapping is
high, Aptos will provide a backup source in the form of a yaml config file. Otherwise
one can play with a config created by herself (probably the same one used in the
backup process described in the previous section.).
```
