# Audit Report

## Title
Unbounded BlockRetrievalResponse Size Can Exceed Network Message Limits Causing Synchronization Denial-of-Service

## Summary
The `BlockRetrievalResponse` structure lacks serialized size validation before network transmission. When quorum store is enabled, an attacker can request up to 100 blocks, and if each block contains large transaction payloads (up to 6 MiB), the total serialized response can exceed the network's `MAX_MESSAGE_SIZE` limit of 64 MiB, causing message sending to fail and preventing nodes from synchronizing.

## Finding Description
The consensus block retrieval mechanism allows peers to request blocks from other nodes to synchronize their state. The configuration permits receiving up to 100 blocks per request when quorum store is enabled. [1](#0-0) 

Each block can contain payloads with transactions up to 6 MiB in size: [2](#0-1) 

However, the network layer enforces a maximum message size of 64 MiB: [3](#0-2) 

The vulnerability occurs in the block retrieval flow:

1. A peer sends a `BlockRetrievalRequest` with `num_blocks=100`
2. The receiving node's `spawn_block_retrieval_task` validates that the request doesn't exceed `max_blocks_per_receiving_request_quorum_store_override` (100 blocks): [4](#0-3) 

3. The `process_block_retrieval_inner` function retrieves up to 100 blocks from storage and creates a `BlockRetrievalResponse`: [5](#0-4) 

4. The response is then serialized and sent without checking the total serialized size: [6](#0-5) 

5. When the serialized message exceeds 64 MiB, the network layer's `stream_message` function fails with an error: [7](#0-6) 

The blocks can contain full transaction payloads via the `Payload` enum, including `DirectMempool` (containing `Vec<SignedTransaction>`) or `QuorumStoreInlineHybrid` variants: [8](#0-7) 

**Attack Scenario:**
- Attacker identifies a chain segment where blocks contain large transaction payloads (e.g., 100 blocks Ã— 3-6 MiB each = 300-600 MiB total)
- Attacker sends `BlockRetrievalRequest` with `num_blocks=100` targeting this segment
- Victim node attempts to respond with all 100 blocks
- Serialized response size: 300-600 MiB (far exceeding 64 MiB limit)
- Network layer fails to send the message
- Attacker never receives the blocks needed for synchronization

## Impact Explanation
This vulnerability enables a **Denial-of-Service attack against block synchronization**, qualifying as **Medium Severity** under the Aptos bug bounty program for the following reasons:

1. **State Inconsistencies Requiring Intervention**: Targeted nodes cannot synchronize with the network, creating state divergence that may require manual intervention or alternative sync methods.

2. **Consensus Liveness Impact**: If multiple nodes are prevented from synchronizing, it can degrade network liveness as nodes fall behind and cannot participate effectively in consensus.

3. **Limited but Exploitable**: While the attack doesn't directly cause fund loss or complete network failure, it can selectively prevent specific nodes from catching up to the network, which could be exploited strategically during epoch transitions or governance votes.

The impact is magnified when quorum store is enabled (the default configuration), as this allows requesting 100 blocks instead of just 10.

## Likelihood Explanation
The likelihood of exploitation is **MODERATE to HIGH**:

1. **Easy to Execute**: Any network peer can send block retrieval requests without special privileges or validator status.

2. **Natural Occurrence Possible**: Legitimate nodes may unintentionally trigger this when blocks contain many large transactions, causing synchronization failures even without malicious intent.

3. **Configuration Dependent**: The vulnerability is most severe when:
   - Quorum store is enabled (default: `max_blocks_per_receiving_request_quorum_store_override: 100`)
   - Blocks contain transaction-heavy payloads (`DirectMempool` or `QuorumStoreInlineHybrid`)
   - Block sizes approach the configured maximum (`max_receiving_block_bytes: 6 MiB`)

4. **Attack Requirements**: Attacker only needs:
   - Network connectivity to target node
   - Knowledge of block IDs in the chain
   - Ability to identify block ranges with large payloads

## Recommendation
Implement a serialized size check before sending `BlockRetrievalResponse`. The fix should validate that the total serialized size doesn't exceed `MAX_APPLICATION_MESSAGE_SIZE` (approximately 62 MiB): [9](#0-8) 

**Proposed Fix Location:**

In `consensus/src/block_storage/sync_manager.rs`, modify `process_block_retrieval` to check response size:

```rust
pub async fn process_block_retrieval(
    &self,
    request: IncomingBlockRetrievalRequest,
) -> anyhow::Result<()> {
    let response = self.process_block_retrieval_inner(&request.req).await;
    let response_bytes = request
        .protocol
        .to_bytes(&ConsensusMsg::BlockRetrievalResponse(response))?;
    
    // ADD SIZE CHECK HERE
    ensure!(
        response_bytes.len() <= MAX_APPLICATION_MESSAGE_SIZE,
        "BlockRetrievalResponse size {} exceeds maximum allowed size {}",
        response_bytes.len(),
        MAX_APPLICATION_MESSAGE_SIZE
    );
    
    request
        .response_sender
        .send(Ok(response_bytes.into()))
        .map_err(|_| anyhow::anyhow!("Failed to send block retrieval response"))
}
```

**Alternative Solutions:**

1. **Implement chunking**: If response exceeds size limit, automatically reduce number of blocks and return `NotEnoughBlocks` status, allowing requester to make multiple smaller requests.

2. **Pre-calculate size**: Estimate total size during `process_block_retrieval_inner` and stop adding blocks once approaching the limit.

3. **Lower max_blocks_per_receiving_request**: Reduce the configuration value to ensure even with maximum-sized blocks, the response stays within limits (e.g., reduce from 100 to 10 blocks).

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[tokio::test]
async fn test_oversized_block_retrieval_response() {
    use consensus_types::block_retrieval::{BlockRetrievalRequest, BlockRetrievalRequestV2};
    use consensus_types::common::Payload;
    use aptos_types::transaction::SignedTransaction;
    
    // Create 100 blocks, each with 5 MiB of transaction payload
    let mut blocks = Vec::new();
    for i in 0..100 {
        let large_txns: Vec<SignedTransaction> = create_large_transactions(5 * 1024 * 1024);
        let payload = Payload::DirectMempool(large_txns);
        let block = create_test_block_with_payload(i, payload);
        blocks.push(block);
    }
    
    // Request all 100 blocks
    let request = BlockRetrievalRequest::V2(BlockRetrievalRequestV2::new(
        blocks[0].id(),
        100, // num_blocks
        0,   // target_round
    ));
    
    // Process the request
    let response = block_store.process_block_retrieval_inner(&request).await;
    
    // Attempt to serialize
    let protocol = ProtocolId::ConsensusDirectSend;
    let result = protocol.to_bytes(&ConsensusMsg::BlockRetrievalResponse(response));
    
    // This will succeed in serialization but fail when attempting to send
    assert!(result.is_ok());
    let response_bytes = result.unwrap();
    
    // Verify the response exceeds MAX_MESSAGE_SIZE
    assert!(response_bytes.len() > MAX_MESSAGE_SIZE);
    println!("Response size: {} bytes (exceeds {} MiB limit)", 
             response_bytes.len(), MAX_MESSAGE_SIZE / (1024 * 1024));
    
    // When attempting to send via network layer, stream_message() will fail
    // assert!(stream.stream_message(network_msg).await.is_err());
}
```

**Notes:**
- The vulnerability is exploitable in production configurations where quorum store is enabled
- The attack can be repeated to continuously prevent specific nodes from synchronizing
- Mitigation requires implementing size checks before response serialization
- The fix should be applied at the consensus layer before network transmission

### Citations

**File:** config/src/config/consensus_config.rs (L231-231)
```rust
            max_receiving_block_bytes: 6 * 1024 * 1024, // 6MB
```

**File:** config/src/config/consensus_config.rs (L370-370)
```rust
            max_blocks_per_receiving_request_quorum_store_override: 100,
```

**File:** config/src/config/network_config.rs (L47-48)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
```

**File:** config/src/config/network_config.rs (L50-50)
```rust
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** consensus/src/epoch_manager.rs (L609-614)
```rust
                        if v2.num_blocks() > max_blocks_allowed {
                            warn!(
                                "Ignore block retrieval with too many blocks: {}",
                                v2.num_blocks()
                            );
                            continue;
```

**File:** consensus/src/block_storage/sync_manager.rs (L543-591)
```rust
    pub async fn process_block_retrieval_inner(
        &self,
        request: &BlockRetrievalRequest,
    ) -> Box<BlockRetrievalResponse> {
        let mut blocks = vec![];
        let mut status = BlockRetrievalStatus::Succeeded;
        let mut id = request.block_id();

        match &request {
            BlockRetrievalRequest::V1(req) => {
                while (blocks.len() as u64) < req.num_blocks() {
                    if let Some(executed_block) = self.get_block(id) {
                        blocks.push(executed_block.block().clone());
                        if req.match_target_id(id) {
                            status = BlockRetrievalStatus::SucceededWithTarget;
                            break;
                        }
                        id = executed_block.parent_id();
                    } else {
                        status = BlockRetrievalStatus::NotEnoughBlocks;
                        break;
                    }
                }
            },
            BlockRetrievalRequest::V2(req) => {
                while (blocks.len() as u64) < req.num_blocks() {
                    if let Some(executed_block) = self.get_block(id) {
                        if !executed_block.block().is_genesis_block() {
                            blocks.push(executed_block.block().clone());
                        }
                        if req.is_window_start_block(executed_block.block()) {
                            status = BlockRetrievalStatus::SucceededWithTarget;
                            break;
                        }
                        id = executed_block.parent_id();
                    } else {
                        status = BlockRetrievalStatus::NotEnoughBlocks;
                        break;
                    }
                }
            },
        }

        if blocks.is_empty() {
            status = BlockRetrievalStatus::IdNotFound;
        }

        Box::new(BlockRetrievalResponse::new(status, blocks))
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L606-609)
```rust
        let response = self.process_block_retrieval_inner(&request.req).await;
        let response_bytes = request
            .protocol
            .to_bytes(&ConsensusMsg::BlockRetrievalResponse(response))?;
```

**File:** network/framework/src/protocols/stream/mod.rs (L268-273)
```rust
        ensure!(
            message_data_len <= self.max_message_size,
            "Message length {} exceeds max message size {}!",
            message_data_len,
            self.max_message_size,
        );
```

**File:** consensus/consensus-types/src/common.rs (L208-224)
```rust
#[derive(Deserialize, Serialize, Clone, Debug, PartialEq, Eq)]
pub enum Payload {
    DirectMempool(Vec<SignedTransaction>),
    InQuorumStore(ProofWithData),
    InQuorumStoreWithLimit(ProofWithDataWithTxnLimit),
    QuorumStoreInlineHybrid(
        Vec<(BatchInfo, Vec<SignedTransaction>)>,
        ProofWithData,
        Option<u64>,
    ),
    OptQuorumStore(OptQuorumStorePayload),
    QuorumStoreInlineHybridV2(
        Vec<(BatchInfo, Vec<SignedTransaction>)>,
        ProofWithData,
        PayloadExecutionLimit,
    ),
}
```
