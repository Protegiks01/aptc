# Audit Report

## Title
Consensus Message Replay DoS via Lack of Network-Layer Deduplication

## Summary
The NetworkMessage layer lacks replay protection (nonces, timestamps), requiring all protocols to implement their own. While consensus implements epoch/round-based deduplication, there is no message deduplication before expensive cryptographic verification, allowing an attacker to cause validator slowdowns by replaying valid consensus messages.

## Finding Description

The `NetworkMessage` enum at line 39 contains no replay protection mechanisms: [1](#0-0) 

Each protocol must implement its own replay prevention. For consensus messages, the `EpochManager` checks epochs before verification: [2](#0-1) 

However, messages matching the current epoch are immediately queued for asynchronous verification via `bounded_executor`: [3](#0-2) 

The `bounded_executor.spawn()` method BLOCKS when at capacity: [4](#0-3) 

The default capacity is only 16 concurrent tasks: [5](#0-4) 

The `EpochManager` processes messages serially in an event loop: [6](#0-5) 

**Attack Path:**
1. Attacker captures or crafts valid `VoteMsg` messages for the current epoch (but potentially different rounds)
2. Attacker replays these messages repeatedly to fill the bounded executor's 16-slot capacity
3. Each message passes `check_epoch()` since epoch matches
4. All 16 executor slots fill with verification tasks
5. The 17th message blocks on `bounded_executor.spawn().await`
6. This blocks the entire `EpochManager` event loop
7. Legitimate consensus messages cannot be processed while blocked
8. Validator experiences severe slowdowns and may miss voting opportunities

## Impact Explanation

This qualifies as **High Severity** per the bug bounty criteria:
- **Validator node slowdowns**: Directly causes validators to slow down or stop processing consensus messages
- **Liveness impact**: Affected validators cannot participate in consensus rounds
- **Network-wide effect**: Multiple validators can be targeted simultaneously

The vulnerability breaks the **Consensus Safety** invariant by degrading liveness through resource exhaustion at the protocol level, not generic network flooding.

## Likelihood Explanation

**HIGH** - Attack requirements:
- Attacker needs to capture or craft valid consensus messages for current epoch (publicly observable)
- No special privileges required
- Low complexity - simple message replay attack
- Can be executed from any network peer
- Affects all validators running default configuration

The attack is practical because:
1. Consensus messages are not encrypted and can be observed/captured
2. No authentication prevents message replay at network layer
3. Small bounded executor capacity (16) is easily exhausted
4. No rate limiting before expensive verification

## Recommendation

Implement message deduplication BEFORE expensive verification:

```rust
// In EpochManager, add a recent messages cache
struct EpochManager {
    // ... existing fields
    recent_message_hashes: Mutex<LruCache<HashValue, ()>>,
}

async fn process_message(&mut self, peer_id: AccountAddress, consensus_msg: ConsensusMsg) -> anyhow::Result<()> {
    // ... existing code
    
    let maybe_unverified_event = self.check_epoch(peer_id, consensus_msg).await?;
    
    if let Some(unverified_event) = maybe_unverified_event {
        // NEW: Check message hash before verification
        let msg_hash = hash_message(&unverified_event);
        {
            let mut cache = self.recent_message_hashes.lock();
            if cache.contains(&msg_hash) {
                // Duplicate message, drop silently
                return Ok(());
            }
            cache.put(msg_hash, ());
        }
        
        // ... continue with verification
    }
    Ok(())
}
```

This prevents replayed messages from consuming verification resources.

## Proof of Concept

```rust
// Pseudocode for exploit
async fn exploit_validator(target: PeerId) {
    // Step 1: Capture a valid VoteMsg from current epoch
    let captured_vote = intercept_consensus_message().await;
    
    // Step 2: Verify it's for current epoch
    assert_eq!(captured_vote.epoch(), current_epoch);
    
    // Step 3: Replay the SAME message 100 times rapidly
    for _ in 0..100 {
        network.send_direct(target, captured_vote.clone()).await;
    }
    
    // Result: Target validator's bounded executor fills up (16 slots)
    // All subsequent spawns block, EpochManager event loop stalls
    // Validator stops processing legitimate messages
    // Consensus participation degraded
}
```

**Note**: While this demonstrates validator slowdowns (High severity), it fundamentally relies on message flooding. Given the explicit exclusion of "Network-level DoS attacks" from scope, this finding may not qualify for the bug bounty despite meeting technical criteria for High severity validator slowdowns.

---

**Notes**: The lack of replay protection at the NetworkMessage layer is an architectural choice that requires careful protocol-level mitigation. The vulnerability emerges from the interaction between: (1) no network-layer deduplication, (2) blocking bounded executor, (3) serial message processing. However, the distinction between "protocol-level resource exhaustion" and "network-level DoS" may exclude this from bounty scope.

### Citations

**File:** network/framework/src/protocols/wire/messaging/v1/mod.rs (L38-45)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Deserialize, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub enum NetworkMessage {
    Error(ErrorCode),
    RpcRequest(RpcRequest),
    RpcResponse(RpcResponse),
    DirectSendMsg(DirectSendMsg),
}
```

**File:** consensus/src/epoch_manager.rs (L1587-1622)
```rust
            self.bounded_executor
                .spawn(async move {
                    match monitor!(
                        "verify_message",
                        unverified_event.clone().verify(
                            peer_id,
                            &epoch_state.verifier,
                            &proof_cache,
                            quorum_store_enabled,
                            peer_id == my_peer_id,
                            max_num_batches,
                            max_batch_expiry_gap_usecs,
                        )
                    ) {
                        Ok(verified_event) => {
                            Self::forward_event(
                                quorum_store_msg_tx,
                                round_manager_tx,
                                buffered_proposal_tx,
                                peer_id,
                                verified_event,
                                payload_manager,
                                pending_blocks,
                            );
                        },
                        Err(e) => {
                            error!(
                                SecurityEvent::ConsensusInvalidMessage,
                                remote_peer = peer_id,
                                error = ?e,
                                unverified_event = unverified_event
                            );
                        },
                    }
                })
                .await;
```

**File:** consensus/src/epoch_manager.rs (L1646-1647)
```rust
                if event.epoch()? == self.epoch() {
                    return Ok(Some(event));
```

**File:** consensus/src/epoch_manager.rs (L1931-1936)
```rust
                (peer, msg) = network_receivers.consensus_messages.select_next_some() => {
                    monitor!("epoch_manager_process_consensus_messages",
                    if let Err(e) = self.process_message(peer, msg).await {
                        error!(epoch = self.epoch(), error = ?e, kind = error_kind(&e));
                    });
                },
```

**File:** crates/bounded-executor/src/executor.rs (L41-52)
```rust
    /// Spawn a [`Future`] on the `BoundedExecutor`. This function is async and
    /// will block if the executor is at capacity until one of the other spawned
    /// futures completes. This function returns a [`JoinHandle`] that the caller
    /// can `.await` on for the results of the [`Future`].
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor.spawn(future_with_permit(future, permit))
    }
```

**File:** config/src/config/consensus_config.rs (L379-379)
```rust
            num_bounded_executor_tasks: 16,
```
