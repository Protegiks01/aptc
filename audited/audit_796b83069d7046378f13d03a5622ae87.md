# Audit Report

## Title
Non-Atomic State Merkle DB Catch-Up with Inadequate Atomicity Guarantees

## Summary
The `catch_up_state_merkle_db()` operation performs non-atomic multi-shard writes to the state merkle database. If the operation fails midway (OOM, disk full, process crash), it leaves the Jellyfish Merkle tree in a partially-updated state across 16 shards and the metadata database, requiring manual recovery intervention.

## Finding Description

The vulnerability exists in the state merkle database commit flow used during catch-up operations. [1](#0-0) 

When `catch_up_state_merkle_db()` is called, it replays write sets from the ledger database to bring the state merkle database up to the target version: [2](#0-1) 

During replay, each version commits via the buffered state mechanism with `sync_commit=true`: [3](#0-2) 

The commit path flows through `StateMerkleBatchCommitter` which calls `StateMerkleDb::commit()`: [4](#0-3) 

**The Critical Non-Atomicity Issue:**

The commit operation consists of 17 separate RocksDB write operations:
1. Lines 157-168: Write to 16 shards in parallel (each is a separate `write_schemas()` call)
2. Line 170: Write to metadata DB top levels (separate `write_schemas()` call)

Each individual `write_schemas()` is atomic within its RocksDB instance: [5](#0-4) 

However, there is **no transaction coordinator** ensuring atomicity across the 17 separate databases. If the process crashes, runs out of memory, or encounters disk full errors:

- Some shards (0-16) may have been successfully written with nodes at version V
- Other shards may still be at version V-1
- The metadata DB may or may not have the root node at version V

**Failure Scenarios:**

1. **Partial Shard Writes**: Process crashes after N shards (0 < N < 16) complete but before all 16 finish
2. **Shard Success, Metadata Failure**: All shards write successfully but the `commit_top_levels()` fails at line 170
3. **Mid-Replay Failure**: During catch-up of many versions (e.g., catching up 100,000 versions), failure at version 50,000 leaves 50,000 versions partially committed

**Recovery Mechanism Analysis:**

While recovery mechanisms exist, they have limitations: [6](#0-5) 

The recovery uses `get_max_version_in_state_merkle_db()` which checks all shards: [7](#0-6) 

And `find_tree_root_at_or_before()` to find a consistent root: [8](#0-7) 

**However, recovery can fail if:**

1. Disk is still full when recovery attempts to write truncation batches
2. The truncation operation itself encounters errors midway
3. Multiple recovery attempts compound the inconsistency
4. The truncate command uses `crash_if_difference_is_too_large=false`, allowing larger inconsistencies: [9](#0-8) 

**Invariant Violation:**

This breaks **Critical Invariant #4: State Consistency** - "State transitions must be atomic and verifiable via Merkle proofs". During the inconsistent window, different shards contain nodes at different versions, making the Merkle tree unverifiable and potentially causing state root mismatches between nodes.

## Impact Explanation

**Severity: Medium (up to $10,000)**

This qualifies as Medium severity under "State inconsistencies requiring intervention" because:

1. **Availability Impact**: If recovery fails (e.g., persistent disk space issues), the database becomes unusable and requires manual intervention or restore from backup
2. **Consensus Risk**: If multiple validator nodes experience partial failures during truncate operations and fail to converge to the same recovered state, this could cause state root mismatches
3. **Operational Risk**: The db_debugger truncate tool is used for database recovery, and failures in this tool compound the original issue

This does not reach High severity because:
- It's not directly exploitable for fund theft
- Recovery mechanisms usually work under normal conditions
- Impact is limited to database consistency rather than consensus safety
- Requires privileged access to trigger (running db_debugger tool)

## Likelihood Explanation

**Likelihood: Medium to High**

This is likely to occur because:

1. **Common Failure Modes**: OOM and disk full are common operational issues, especially during:
   - Large-scale catch-up operations (100,000+ versions)
   - Node recovery after extended downtime
   - State sync operations on resource-constrained nodes

2. **Long-Running Operations**: The catch-up process for large version ranges takes significant time, increasing the window for failures

3. **No Checkpointing**: Each version is committed separately without intermediate checkpoints, so a failure at version 99,999 of 100,000 loses all progress

4. **Compounding Failures**: If disk space is exhausted during catch-up, the recovery truncation also requires disk space, potentially causing a death spiral

## Recommendation

Implement one of the following solutions:

**Option 1: Batch Commits with Checkpointing**

Modify the catch-up logic to commit in larger batches and record checkpoint progress that survives crashes:

```rust
// In catch_up_state_merkle_db()
const CATCH_UP_CHECKPOINT_INTERVAL: usize = 1000;

for (i, version) in (snapshot_next_version..num_transactions).enumerate() {
    // Process version...
    
    if i % CATCH_UP_CHECKPOINT_INTERVAL == 0 {
        // Record checkpoint in a separate progress table
        record_catch_up_checkpoint(version)?;
    }
}

// On restart, resume from last checkpoint instead of starting over
let last_checkpoint = get_catch_up_checkpoint()?;
let resume_version = last_checkpoint.unwrap_or(snapshot_next_version);
```

**Option 2: Two-Phase Commit Protocol**

Implement a write-ahead log (WAL) for state merkle commits:

```rust
// In StateMerkleDb::commit()
pub fn commit(&self, version: Version, ...) -> Result<()> {
    // Phase 1: Prepare - write intent log
    self.write_commit_intent(version)?;
    
    // Phase 2: Execute - write actual data
    THREAD_MANAGER.get_io_pool().install(|| {
        batches_for_shards.into_par_iter().enumerate().for_each(...)
    });
    self.commit_top_levels(version, top_levels_batch)?;
    
    // Phase 3: Commit - mark as complete
    self.clear_commit_intent(version)?;
}
```

On recovery, check for incomplete commit intents and either complete or roll back.

**Option 3: Atomic Multi-Shard Commit**

Use RocksDB's `WriteBatch` across a unified column family structure instead of separate databases:

```rust
// Consolidate all shards into a single RocksDB instance with shard-prefixed keys
let mut unified_batch = WriteBatch::default();
for (shard_id, batch) in batches_for_shards.enumerate() {
    unified_batch.merge(batch.with_prefix(shard_id));
}
unified_batch.merge(top_levels_batch);
self.unified_db.write(unified_batch)?; // Single atomic write
```

## Proof of Concept

The following demonstrates the vulnerability:

```rust
// File: storage/aptosdb/tests/state_merkle_catchup_failure_test.rs

#[test]
fn test_catch_up_partial_failure() {
    use std::sync::atomic::{AtomicBool, Ordering};
    use std::sync::Arc;
    
    // Setup: Create DB with initial state
    let tmp_dir = TempPath::new();
    let db = AptosDB::new_for_test_with_sharding(&tmp_dir, 1000);
    
    // Commit 100 versions
    for v in 0..100 {
        let txns = generate_test_transaction(v);
        db.save_transactions_for_test(&txns, v, None, true).unwrap();
    }
    drop(db);
    
    // Simulate disk full during catch-up at version 50
    let inject_failure = Arc::new(AtomicBool::new(false));
    let fail_at_version = 50;
    
    // Hook into write_schemas to inject failure
    // (In real PoC, use LD_PRELOAD or similar to intercept write syscalls)
    
    // Run truncate to earlier version, then catch up
    let truncate_cmd = TruncateCmd {
        db_dir: tmp_dir.path().to_path_buf(),
        target_version: 50,
        opt_out_backup_checkpoint: true,
        // ... other params
    };
    
    // This should fail at version 50
    let result = truncate_cmd.run();
    assert!(result.is_err());
    
    // Open DB again and check consistency
    let db = AptosDB::open(...);
    
    // Verify: Check if shards are at different versions
    let max_version = get_max_version_in_state_merkle_db(&db.state_merkle_db).unwrap();
    let current_version = get_current_version_in_state_merkle_db(&db.state_merkle_db).unwrap();
    
    // BUG: These may differ due to partial commit
    assert_ne!(max_version, current_version, "Inconsistent state detected!");
    
    // Demonstrate recovery may fail if resources still constrained
    // (Truncation requires writing batches, which may also fail)
}
```

To reproduce in production:
1. Run db_debugger truncate on a node with limited disk space
2. Monitor disk usage to reach 100% during catch-up
3. Observe process failure with error
4. Inspect state merkle shards using db_tool to see version mismatches
5. Attempt recovery with same disk constraints - may fail repeatedly

**Expected Outcome:** The database enters an inconsistent state that persists across restarts until resources are freed or manual intervention occurs.

### Citations

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L137-142)
```rust
        StateStore::sync_commit_progress(
            Arc::clone(&ledger_db),
            Arc::clone(&state_kv_db),
            Arc::clone(&state_merkle_db),
            /*crash_if_difference_is_too_large=*/ false,
        );
```

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L148-159)
```rust
            if state_merkle_db_version < target_version {
                println!(
                    "Trying to catch up state merkle db, by replaying write set in ledger db."
                );
                let version = StateStore::catch_up_state_merkle_db(
                    Arc::clone(&ledger_db),
                    hot_state_merkle_db,
                    Arc::clone(&state_merkle_db),
                    Arc::clone(&state_kv_db),
                )?;
                println!("Done! current_version: {:?}", version);
            }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L469-498)
```rust
            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L505-550)
```rust
    pub fn catch_up_state_merkle_db(
        ledger_db: Arc<LedgerDb>,
        hot_state_merkle_db: Option<Arc<StateMerkleDb>>,
        state_merkle_db: Arc<StateMerkleDb>,
        state_kv_db: Arc<StateKvDb>,
    ) -> Result<Option<Version>> {
        use aptos_config::config::NO_OP_STORAGE_PRUNER_CONFIG;

        let state_merkle_pruner = StateMerklePrunerManager::new(
            Arc::clone(&state_merkle_db),
            NO_OP_STORAGE_PRUNER_CONFIG.state_merkle_pruner_config,
        );
        let epoch_snapshot_pruner = StateMerklePrunerManager::new(
            Arc::clone(&state_merkle_db),
            NO_OP_STORAGE_PRUNER_CONFIG.state_merkle_pruner_config,
        );
        let state_kv_pruner = StateKvPrunerManager::new(
            Arc::clone(&state_kv_db),
            NO_OP_STORAGE_PRUNER_CONFIG.ledger_pruner_config,
        );
        let state_db = Arc::new(StateDb {
            ledger_db,
            hot_state_merkle_db,
            state_merkle_db,
            state_kv_db,
            state_merkle_pruner,
            epoch_snapshot_pruner,
            state_kv_pruner,
            skip_usage: false,
        });
        let current_state = Arc::new(Mutex::new(LedgerStateWithSummary::new_empty(
            HotStateConfig::default(),
        )));
        let persisted_state = PersistedState::new_empty(HotStateConfig::default());
        let _ = Self::create_buffered_state_from_latest_snapshot(
            &state_db,
            0,
            /*hack_for_tests=*/ false,
            /*check_max_versions_after_snapshot=*/ false,
            current_state.clone(),
            persisted_state,
            HotStateConfig::default(),
        )?;
        let base_version = current_state.lock().version();
        Ok(base_version)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L687-690)
```rust
            buffered_state.update(
                updated, 0,    /* estimated_items, doesn't matter since we sync-commit */
                true, /* sync_commit */
            )?;
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L147-171)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        top_levels_batch: impl IntoRawBatch,
        batches_for_shards: Vec<impl IntoRawBatch + Send>,
    ) -> Result<()> {
        ensure!(
            batches_for_shards.len() == NUM_STATE_SHARDS,
            "Shard count mismatch."
        );
        THREAD_MANAGER.get_io_pool().install(|| {
            batches_for_shards
                .into_par_iter()
                .enumerate()
                .for_each(|(shard_id, batch)| {
                    self.db_shard(shard_id)
                        .write_schemas(batch)
                        .unwrap_or_else(|err| {
                            panic!("Failed to commit state merkle shard {shard_id}: {err}")
                        });
                })
        });

        self.commit_top_levels(version, top_levels_batch)
    }
```

**File:** storage/schemadb/src/lib.rs (L289-303)
```rust
    fn write_schemas_inner(&self, batch: impl IntoRawBatch, option: &WriteOptions) -> DbResult<()> {
        let labels = [self.name.as_str()];
        let _timer = APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS.timer_with(&labels);

        let raw_batch = batch.into_raw_batch(self)?;

        let serialized_size = raw_batch.inner.size_in_bytes();
        self.inner
            .write_opt(raw_batch.inner, option)
            .into_db_res()?;

        raw_batch.stats.commit();
        APTOS_SCHEMADB_BATCH_COMMIT_BYTES.observe_with(&[&self.name], serialized_size as f64);

        Ok(())
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L208-245)
```rust
pub(crate) fn find_tree_root_at_or_before(
    ledger_metadata_db: &LedgerMetadataDb,
    state_merkle_db: &StateMerkleDb,
    version: Version,
) -> Result<Option<Version>> {
    if let Some(closest_version) =
        find_closest_node_version_at_or_before(state_merkle_db.metadata_db(), version)?
    {
        if root_exists_at_version(state_merkle_db, closest_version)? {
            return Ok(Some(closest_version));
        }

        // It's possible that it's a partial commit when sharding is not enabled,
        // look again for the previous version:
        if version == 0 {
            return Ok(None);
        }
        if let Some(closest_version) =
            find_closest_node_version_at_or_before(state_merkle_db.metadata_db(), version - 1)?
        {
            if root_exists_at_version(state_merkle_db, closest_version)? {
                return Ok(Some(closest_version));
            }

            // Now we are probably looking at a pruned version in this epoch, look for the previous
            // epoch ending:
            let mut iter = ledger_metadata_db.db().iter::<EpochByVersionSchema>()?;
            iter.seek_for_prev(&version)?;
            if let Some((closest_epoch_version, _)) = iter.next().transpose()? {
                if root_exists_at_version(state_merkle_db, closest_epoch_version)? {
                    return Ok(Some(closest_epoch_version));
                }
            }
        }
    }

    Ok(None)
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L263-284)
```rust
pub(crate) fn get_max_version_in_state_merkle_db(
    state_merkle_db: &StateMerkleDb,
) -> Result<Option<Version>> {
    let mut version = get_current_version_in_state_merkle_db(state_merkle_db)?;
    let num_real_shards = state_merkle_db.hack_num_real_shards();
    if num_real_shards > 1 {
        for shard_id in 0..num_real_shards {
            let shard_version = find_closest_node_version_at_or_before(
                state_merkle_db.db_shard(shard_id),
                Version::MAX,
            )?;
            if version.is_none() {
                version = shard_version;
            } else if let Some(shard_version) = shard_version {
                if shard_version > version.unwrap() {
                    version = Some(shard_version);
                }
            }
        }
    }
    Ok(version)
}
```
