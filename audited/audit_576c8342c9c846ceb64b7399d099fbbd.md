# Audit Report

## Title
Conditional SyncInfo Verification Leads to Consensus Safety Violation via State-Dependent Acceptance

## Summary
The ProposalMsg verification process in Aptos consensus is non-deterministic, depending on each validator's local synchronization state. The `verify_well_formed()` function performs only structural validation of SyncInfo without cryptographic verification, while full signature verification occurs conditionally in `sync_up()` based on `has_newer_certificates()`. This allows a malicious proposer to craft proposals with forged SyncInfo signatures that will be accepted by synchronized validators but rejected by behind validators, causing consensus divergence and violating BFT safety guarantees.

## Finding Description

The vulnerability stems from the split verification logic for ProposalMsg across multiple functions with state-dependent behavior:

**1. Initial Verification Phase (Non-Cryptographic)**

The `verify_well_formed()` function performs structural consistency checks without cryptographic verification: [1](#0-0) 

This function only validates that:
- The proposal is not a NIL block
- Epochs match between proposal and SyncInfo
- The proposal's parent_id matches the SyncInfo's HQC certified block ID (structural match, not signature verification)
- Round consistency is maintained

Critically, it does NOT verify the cryptographic signatures on the SyncInfo's `highest_quorum_cert`, `highest_ordered_cert`, or `highest_commit_cert`.

**2. Postponed Verification**

The `verify()` method explicitly postpones SyncInfo verification: [2](#0-1) 

The comment at line 116 confirms: "Note that we postpone the verification of SyncInfo until it's being used."

**3. Conditional Cryptographic Verification**

The actual cryptographic verification occurs in `sync_up()`, but ONLY when `has_newer_certificates()` returns true: [3](#0-2) 

If `has_newer_certificates()` returns false (line 880), the function returns `Ok(())` without any cryptographic verification (line 905). When it returns true, `sync_info.verify()` is called (line 888), which performs full signature verification: [4](#0-3) 

**4. State-Dependent Behavior**

The `has_newer_certificates()` comparison is based on local state: [5](#0-4) 

**Attack Path:**

1. Normal network asynchrony causes validators to have different local states (e.g., Node A at round 100, Node B at round 95)
2. A malicious proposer (legitimately elected for round 101) creates a ProposalMsg with:
   - Valid proposal block with valid signatures
   - SyncInfo with structurally correct but cryptographically invalid signatures (forged HQC/HOC/HCC)
3. The proposal undergoes verification:
   - Both nodes: `verify_well_formed()` passes (structural checks only)
   - Both nodes: `process_proposal_msg()` calls `sync_up()`
4. State-dependent divergence occurs:
   - **Node A** (synced): `has_newer_certificates()` returns false → no verification → accepts proposal
   - **Node B** (behind): `has_newer_certificates()` returns true → verification fails → rejects proposal
5. Processing flow diverges: [6](#0-5) 

The error propagation (line 750's `?` operator) means Node B rejects the proposal entirely, while Node A proceeds to `process_proposal()` and creates a vote: [7](#0-6) 

This violates the fundamental consensus safety invariant: **all honest validators must agree on whether a proposal is valid, regardless of their synchronization state**.

## Impact Explanation

**Severity: Critical** (Consensus/Safety Violations - up to $1,000,000)

This vulnerability directly violates the safety property of AptosBFT consensus, meeting the Critical severity criteria defined in the Aptos bug bounty program.

**Concrete Impacts:**

1. **Consensus Divergence**: Different honest validators make conflicting decisions about the same proposal's validity based solely on local state, not proposal content
2. **Chain Splits**: Synchronized validators may vote for and commit blocks that behind validators reject, potentially creating competing chains
3. **Double-Spending**: Conflicting transactions could be committed on different validator subsets
4. **Network Partition**: The validator set may split into incompatible groups, requiring manual intervention or hardfork to resolve

This is a **fundamental BFT consensus safety violation**. In a correct BFT implementation, proposal validity must be deterministic and agreed upon by all honest validators (< 1/3 Byzantine assumption). The state-dependent verification breaks this guarantee.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly exploitable because:

1. **Normal Network Conditions Trigger the Bug**: Network asynchrony causing different validator synchronization states is expected and constant in distributed systems
2. **No Special Attacker Capabilities**: Any validator who becomes proposer through normal round rotation can exploit this - no additional privileges required
3. **Low Execution Complexity**: The attacker simply crafts a ProposalMsg with valid proposal structure but forged SyncInfo signatures
4. **No Detection Mechanism**: The conditional verification appears intentional (per code comment at line 116), so it won't be flagged by monitoring systems
5. **Persistent Attack Surface**: As long as any network asynchrony exists (always), validators will have different local states, making the attack consistently exploitable

The attack requires the malicious validator to be the proposer, which happens automatically through consensus protocol's proposer rotation.

## Recommendation

The SyncInfo verification must be made deterministic and always performed, regardless of local synchronization state. Proposed fix:

1. **Always verify SyncInfo cryptographically** in `ProposalMsg::verify()` before accepting any proposal
2. Remove conditional verification from `sync_up()` - the SyncInfo should already be verified by this point
3. Ensure `verify_well_formed()` is called after cryptographic verification, not before

Recommended code change in `proposal_msg.rs`:

```rust
pub fn verify(
    &self,
    sender: Author,
    validator: &ValidatorVerifier,
    proof_cache: &ProofCache,
    quorum_store_enabled: bool,
) -> Result<()> {
    // ... existing verification logic ...
    
    // ALWAYS verify SyncInfo before proceeding
    self.sync_info.verify(validator)?;
    
    self.verify_well_formed()
}
```

This ensures all validators perform identical cryptographic verification regardless of their local state.

## Proof of Concept

A malicious validator can exploit this vulnerability when elected as proposer:

1. Create a valid Block for round R with valid QC
2. Craft a SyncInfo with:
   - Correct structure (epochs match, block IDs match)
   - Valid certificate block information
   - **Forged/invalid BLS signatures** on the certificates
3. Broadcast the ProposalMsg

**Expected Behavior**: All honest validators should either accept or reject the proposal uniformly.

**Actual Behavior**:
- Validators with `local_highest_certified_round >= SyncInfo.highest_certified_round`: Skip verification, accept proposal, create votes
- Validators with `local_highest_certified_round < SyncInfo.highest_certified_round`: Perform verification, fail on invalid signatures, reject proposal

**Result**: Consensus divergence where the validator set splits on the same proposal's validity, violating BFT safety guarantees.

The vulnerability can be demonstrated by:
1. Setting up a network with validators at different sync states
2. Injecting a ProposalMsg with valid proposal but forged SyncInfo signatures
3. Observing different acceptance/rejection behavior across validators
4. Confirming that voting behavior diverges based on local state rather than proposal validity

### Citations

**File:** consensus/consensus-types/src/proposal_msg.rs (L33-79)
```rust
    pub fn verify_well_formed(&self) -> Result<()> {
        ensure!(
            !self.proposal.is_nil_block(),
            "Proposal {} for a NIL block",
            self.proposal
        );
        self.proposal
            .verify_well_formed()
            .context("Fail to verify ProposalMsg's block")?;
        ensure!(
            self.proposal.round() > 0,
            "Proposal for {} has an incorrect round of 0",
            self.proposal,
        );
        ensure!(
            self.proposal.epoch() == self.sync_info.epoch(),
            "ProposalMsg has different epoch number from SyncInfo"
        );
        ensure!(
            self.proposal.parent_id()
                == self.sync_info.highest_quorum_cert().certified_block().id(),
            "Proposal HQC in SyncInfo certifies {}, but block parent id is {}",
            self.sync_info.highest_quorum_cert().certified_block().id(),
            self.proposal.parent_id(),
        );
        let previous_round = self
            .proposal
            .round()
            .checked_sub(1)
            .ok_or_else(|| anyhow!("proposal round overflowed!"))?;

        let highest_certified_round = std::cmp::max(
            self.proposal.quorum_cert().certified_block().round(),
            self.sync_info.highest_timeout_round(),
        );
        ensure!(
            previous_round == highest_certified_round,
            "Proposal {} does not have a certified round {}",
            self.proposal,
            previous_round
        );
        ensure!(
            self.proposal.author().is_some(),
            "Proposal {} does not define an author",
            self.proposal
        );
        Ok(())
```

**File:** consensus/consensus-types/src/proposal_msg.rs (L82-118)
```rust
    pub fn verify(
        &self,
        sender: Author,
        validator: &ValidatorVerifier,
        proof_cache: &ProofCache,
        quorum_store_enabled: bool,
    ) -> Result<()> {
        if let Some(proposal_author) = self.proposal.author() {
            ensure!(
                proposal_author == sender,
                "Proposal author {:?} doesn't match sender {:?}",
                proposal_author,
                sender
            );
        }
        let (payload_result, sig_result) = rayon::join(
            || {
                self.proposal().payload().map_or(Ok(()), |p| {
                    p.verify(validator, proof_cache, quorum_store_enabled)
                })
            },
            || {
                self.proposal()
                    .validate_signature(validator)
                    .map_err(|e| format_err!("{:?}", e))
            },
        );
        payload_result?;
        sig_result?;

        // if there is a timeout certificate, verify its signatures
        if let Some(tc) = self.sync_info.highest_2chain_timeout_cert() {
            tc.verify(validator).map_err(|e| format_err!("{:?}", e))?;
        }
        // Note that we postpone the verification of SyncInfo until it's being used.
        self.verify_well_formed()
    }
```

**File:** consensus/src/round_manager.rs (L726-765)
```rust
    pub async fn process_proposal_msg(&mut self, proposal_msg: ProposalMsg) -> anyhow::Result<()> {
        fail_point!("consensus::process_proposal_msg", |_| {
            Err(anyhow::anyhow!("Injected error in process_proposal_msg"))
        });

        observe_block(
            proposal_msg.proposal().timestamp_usecs(),
            BlockStage::ROUND_MANAGER_RECEIVED,
        );
        info!(
            self.new_log(LogEvent::ReceiveProposal)
                .remote_peer(proposal_msg.proposer()),
            block_round = proposal_msg.proposal().round(),
            block_hash = proposal_msg.proposal().id(),
            block_parent_hash = proposal_msg.proposal().quorum_cert().certified_block().id(),
        );

        let in_correct_round = self
            .ensure_round_and_sync_up(
                proposal_msg.proposal().round(),
                proposal_msg.sync_info(),
                proposal_msg.proposer(),
            )
            .await
            .context("[RoundManager] Process proposal")?;
        if in_correct_round {
            self.process_proposal(proposal_msg.take_proposal()).await
        } else {
            sample!(
                SampleRate::Duration(Duration::from_secs(30)),
                warn!(
                    "[sampled] Stale proposal {}, current round {}",
                    proposal_msg.proposal(),
                    self.round_state.current_round()
                )
            );
            counters::ERROR_COUNT.inc();
            Ok(())
        }
    }
```

**File:** consensus/src/round_manager.rs (L878-906)
```rust
    async fn sync_up(&mut self, sync_info: &SyncInfo, author: Author) -> anyhow::Result<()> {
        let local_sync_info = self.block_store.sync_info();
        if sync_info.has_newer_certificates(&local_sync_info) {
            info!(
                self.new_log(LogEvent::ReceiveNewCertificate)
                    .remote_peer(author),
                "Local state {},\n remote state {}", local_sync_info, sync_info
            );
            // Some information in SyncInfo is ahead of what we have locally.
            // First verify the SyncInfo (didn't verify it in the yet).
            sync_info.verify(&self.epoch_state.verifier).map_err(|e| {
                error!(
                    SecurityEvent::InvalidSyncInfoMsg,
                    sync_info = sync_info,
                    remote_peer = author,
                    error = ?e,
                );
                VerifyError::from(e)
            })?;
            SYNC_INFO_RECEIVED_WITH_NEWER_CERT.inc();
            let result = self
                .block_store
                .add_certs(sync_info, self.create_block_retriever(author))
                .await;
            self.process_certificates().await?;
            result
        } else {
            Ok(())
        }
```

**File:** consensus/src/round_manager.rs (L1111-1313)
```rust
    async fn process_proposal(&mut self, proposal: Block) -> anyhow::Result<()> {
        let author = proposal
            .author()
            .expect("Proposal should be verified having an author");

        if !self.vtxn_config.enabled()
            && matches!(
                proposal.block_data().block_type(),
                BlockType::ProposalExt(_)
            )
        {
            counters::UNEXPECTED_PROPOSAL_EXT_COUNT.inc();
            bail!("ProposalExt unexpected while the vtxn feature is disabled.");
        }

        if let Some(vtxns) = proposal.validator_txns() {
            for vtxn in vtxns {
                let vtxn_type_name = vtxn.type_name();
                ensure!(
                    is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                    "unexpected validator txn: {:?}",
                    vtxn_type_name
                );
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
            }
        }

        let (num_validator_txns, validator_txns_total_bytes): (usize, usize) =
            proposal.validator_txns().map_or((0, 0), |txns| {
                txns.iter().fold((0, 0), |(count_acc, size_acc), txn| {
                    (count_acc + 1, size_acc + txn.size_in_bytes())
                })
            });

        let num_validator_txns = num_validator_txns as u64;
        let validator_txns_total_bytes = validator_txns_total_bytes as u64;
        let vtxn_count_limit = self.vtxn_config.per_block_limit_txn_count();
        let vtxn_bytes_limit = self.vtxn_config.per_block_limit_total_bytes();
        let author_hex = author.to_hex();
        PROPOSED_VTXN_COUNT
            .with_label_values(&[&author_hex])
            .inc_by(num_validator_txns);
        PROPOSED_VTXN_BYTES
            .with_label_values(&[&author_hex])
            .inc_by(validator_txns_total_bytes);
        info!(
            vtxn_count_limit = vtxn_count_limit,
            vtxn_count_proposed = num_validator_txns,
            vtxn_bytes_limit = vtxn_bytes_limit,
            vtxn_bytes_proposed = validator_txns_total_bytes,
            proposer = author_hex,
            "Summarizing proposed validator txns."
        );

        ensure!(
            num_validator_txns <= vtxn_count_limit,
            "process_proposal failed with per-block vtxn count limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_txn_count(),
            num_validator_txns
        );
        ensure!(
            validator_txns_total_bytes <= vtxn_bytes_limit,
            "process_proposal failed with per-block vtxn bytes limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_total_bytes(),
            validator_txns_total_bytes
        );
        let payload_len = proposal.payload().map_or(0, |payload| payload.len());
        let payload_size = proposal.payload().map_or(0, |payload| payload.size());
        ensure!(
            num_validator_txns + payload_len as u64 <= self.local_config.max_receiving_block_txns,
            "Payload len {} exceeds the limit {}",
            payload_len,
            self.local_config.max_receiving_block_txns,
        );

        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );

        ensure!(
            self.proposer_election.is_valid_proposal(&proposal),
            "[RoundManager] Proposer {} for block {} is not a valid proposer for this round or created duplicate proposal",
            author,
            proposal,
        );

        // If the proposal contains any inline transactions that need to be denied
        // (e.g., due to filtering) drop the message and do not vote for the block.
        if let Err(error) = self
            .block_store
            .check_denied_inline_transactions(&proposal, &self.block_txn_filter_config)
        {
            counters::REJECTED_PROPOSAL_DENY_TXN_COUNT.inc();
            bail!(
                "[RoundManager] Proposal for block {} contains denied inline transactions: {}. Dropping proposal!",
                proposal.id(),
                error
            );
        }

        if !proposal.is_opt_block() {
            // Validate that failed_authors list is correctly specified in the block.
            let expected_failed_authors = self.proposal_generator.compute_failed_authors(
                proposal.round(),
                proposal.quorum_cert().certified_block().round(),
                false,
                self.proposer_election.clone(),
            );
            ensure!(
                proposal.block_data().failed_authors().is_some_and(|failed_authors| *failed_authors == expected_failed_authors),
                "[RoundManager] Proposal for block {} has invalid failed_authors list {:?}, expected {:?}",
                proposal.round(),
                proposal.block_data().failed_authors(),
                expected_failed_authors,
            );
        }

        let block_time_since_epoch = Duration::from_micros(proposal.timestamp_usecs());

        ensure!(
            block_time_since_epoch < self.round_state.current_round_deadline(),
            "[RoundManager] Waiting until proposal block timestamp usecs {:?} \
            would exceed the round duration {:?}, hence will not vote for this round",
            block_time_since_epoch,
            self.round_state.current_round_deadline(),
        );

        observe_block(proposal.timestamp_usecs(), BlockStage::SYNCED);
        if proposal.is_opt_block() {
            observe_block(proposal.timestamp_usecs(), BlockStage::SYNCED_OPT_BLOCK);
        }

        // Since processing proposal is delayed due to backpressure or payload availability, we add
        // the block to the block store so that we don't need to fetch it from remote once we
        // are out of the backpressure. Please note that delayed processing of proposal is not
        // guaranteed to add the block to the block store if we don't get out of the backpressure
        // before the timeout, so this is needed to ensure that the proposed block is added to
        // the block store irrespective. Also, it is possible that delayed processing of proposal
        // tries to add the same block again, which is okay as `insert_block` call
        // is idempotent.
        self.block_store
            .insert_block(proposal.clone())
            .await
            .context("[RoundManager] Failed to insert the block into BlockStore")?;

        let block_store = self.block_store.clone();
        if block_store.check_payload(&proposal).is_err() {
            debug!("Payload not available locally for block: {}", proposal.id());
            counters::CONSENSUS_PROPOSAL_PAYLOAD_AVAILABILITY
                .with_label_values(&["missing"])
                .inc();
            let start_time = Instant::now();
            let deadline = self.round_state.current_round_deadline();
            let future = async move {
                (
                    block_store.wait_for_payload(&proposal, deadline).await,
                    proposal,
                    start_time,
                )
            }
            .boxed();
            self.futures.push(future);
            return Ok(());
        }

        counters::CONSENSUS_PROPOSAL_PAYLOAD_AVAILABILITY
            .with_label_values(&["available"])
            .inc();

        self.check_backpressure_and_process_proposal(proposal).await
    }

    async fn check_backpressure_and_process_proposal(
        &mut self,
        proposal: Block,
    ) -> anyhow::Result<()> {
        let author = proposal
            .author()
            .expect("Proposal should be verified having an author");

        if self.block_store.vote_back_pressure() {
            counters::CONSENSUS_WITHOLD_VOTE_BACKPRESSURE_TRIGGERED.observe(1.0);
            // In case of back pressure, we delay processing proposal. This is done by resending the
            // same proposal to self after some time.
            Self::resend_verified_proposal_to_self(
                self.block_store.clone(),
                self.buffered_proposal_tx.clone(),
                proposal,
                author,
                BACK_PRESSURE_POLLING_INTERVAL_MS,
                self.local_config.round_initial_timeout_ms,
            )
            .await;
            return Ok(());
        }

        counters::CONSENSUS_WITHOLD_VOTE_BACKPRESSURE_TRIGGERED.observe(0.0);
        self.process_verified_proposal(proposal).await
```

**File:** consensus/consensus-types/src/sync_info.rs (L138-212)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let epoch = self.highest_quorum_cert.certified_block().epoch();
        ensure!(
            epoch == self.highest_ordered_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HQC"
        );
        ensure!(
            epoch == self.highest_commit_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HCC"
        );
        if let Some(tc) = &self.highest_2chain_timeout_cert {
            ensure!(epoch == tc.epoch(), "Multi epoch in SyncInfo - TC and HQC");
        }

        ensure!(
            self.highest_quorum_cert.certified_block().round()
                >= self.highest_ordered_cert().commit_info().round(),
            "HQC has lower round than HOC"
        );

        ensure!(
            self.highest_ordered_round() >= self.highest_commit_round(),
            format!(
                "HOC {} has lower round than HLI {}",
                self.highest_ordered_cert(),
                self.highest_commit_cert()
            )
        );

        ensure!(
            *self.highest_ordered_cert().commit_info() != BlockInfo::empty(),
            "HOC has no committed block"
        );

        ensure!(
            *self.highest_commit_cert().commit_info() != BlockInfo::empty(),
            "HLI has empty commit info"
        );

        // we don't have execution in unit tests, so this check would fail
        #[cfg(not(any(test, feature = "fuzzing")))]
        {
            ensure!(
                !self.highest_commit_cert().commit_info().is_ordered_only(),
                "HLI {} has ordered only commit info",
                self.highest_commit_cert().commit_info()
            );
        }

        self.highest_quorum_cert
            .verify(validator)
            .and_then(|_| {
                self.highest_ordered_cert
                    .as_ref()
                    .map_or(Ok(()), |cert| cert.verify(validator))
                    .context("Fail to verify ordered certificate")
            })
            .and_then(|_| {
                // we do not verify genesis ledger info
                if self.highest_commit_cert.commit_info().round() > 0 {
                    self.highest_commit_cert
                        .verify(validator)
                        .context("Fail to verify commit certificate")?
                }
                Ok(())
            })
            .and_then(|_| {
                if let Some(tc) = &self.highest_2chain_timeout_cert {
                    tc.verify(validator)?;
                }
                Ok(())
            })
            .context("Fail to verify SyncInfo")?;
        Ok(())
    }
```

**File:** consensus/consensus-types/src/sync_info.rs (L218-223)
```rust
    pub fn has_newer_certificates(&self, other: &SyncInfo) -> bool {
        self.highest_certified_round() > other.highest_certified_round()
            || self.highest_timeout_round() > other.highest_timeout_round()
            || self.highest_ordered_round() > other.highest_ordered_round()
            || self.highest_commit_round() > other.highest_commit_round()
    }
```
