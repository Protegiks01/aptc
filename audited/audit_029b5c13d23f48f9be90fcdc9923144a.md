# Audit Report

## Title
Race Condition in Module Validation Allows Non-Deterministic Transaction Validation Leading to Consensus Failure

## Summary
A race condition exists in `CapturedReads::validate_module_reads()` where module override flags can be set by a committing transaction while another transaction is concurrently validating its module reads. This allows the validation to pass incorrectly when it should fail, breaking consensus determinism and potentially causing chain splits.

## Finding Description

The block executor validates that modules read from the global cache during transaction execution have not been overridden by subsequent module publications. This validation occurs in the `validate_module_reads()` function, which iterates over captured module reads and checks if each module from `GlobalCache` is still marked as "not overridden." [1](#0-0) 

The critical vulnerability occurs because this validation is NOT atomic. When multiple modules are checked, the function iterates through them one by one: [2](#0-1) 

Meanwhile, during parallel execution, when a transaction commits and publishes modules, it marks them as overridden in the global cache: [3](#0-2) 

This module publishing happens through `publish_module_write_set()`, which calls: [4](#0-3) 

The race condition occurs when:

1. **Thread A (validating T1)**: Transaction T1 at index 10 executed earlier and read modules A, B, C from global cache
2. **Thread A begins validation**: Iterates through modules, checking each via `contains_not_overridden()`
3. **Thread A checks module A**: Returns `true` (not overridden yet) ✓
4. **Thread A checks module B**: Returns `true` (not overridden yet) ✓
5. **Thread B (committing T2)**: Transaction T2 at index 6 enters `prepare_and_queue_commit_ready_txn()` and marks modules A, B, C as overridden via `mark_overridden()`
6. **Thread A checks module C**: Returns `true` (already checked before override) ✓
7. **Thread A**: Validation completes successfully ✗

The key issue is that T1's validation passed even though it read stale module versions. Transaction T2 published new versions of these modules, but T1 validated with the old versions and committed successfully. This breaks **Invariant #1: Deterministic Execution**.

Different validators observing different thread scheduling will produce different validation outcomes:
- Validator V1: Thread scheduling allows all checks before override → validation passes
- Validator V2: Thread scheduling causes override during iteration → validation fails

This leads to divergent state roots and consensus failure.

## Impact Explanation

This is a **Critical Severity** vulnerability under the Aptos Bug Bounty program as it constitutes a **Consensus/Safety violation**:

1. **Non-Deterministic Execution**: Different validators can produce different validation results for the same transaction based on thread timing
2. **State Divergence**: Validators will compute different state roots for identical blocks
3. **Chain Split Risk**: The network could fork into multiple chains following different validation outcomes
4. **Requires Hard Fork**: Recovery would require coordinated network-wide intervention
5. **Breaks Core Invariant**: Violates the fundamental guarantee that "all validators must produce identical state roots for identical blocks"

The vulnerability affects all validators during normal operation and does not require any malicious input or Byzantine behavior—it's a pure concurrency bug in the implementation.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

The race condition can occur during normal block execution whenever:
- Parallel execution is enabled (the default mode)
- A block contains transactions that publish Move modules
- Other transactions in the same block read those modules from global cache
- Thread scheduling allows validation to complete before module override flags are set

While the timing window is narrow (between validation iteration and module override), it can occur naturally without any attacker intervention. The likelihood increases with:
- Higher transaction throughput
- More module publishing activity
- More CPU cores (more parallelism = more race opportunities)
- Stress conditions (high load increases scheduling variability)

## Recommendation

**Immediate Fix**: Add synchronization to ensure module validation checks are atomic with respect to module override operations. Specifically:

**Option 1 - Atomic Snapshot**: Capture all module override states atomically before validation begins:

```rust
pub(crate) fn validate_module_reads(
    &self,
    global_module_cache: &GlobalModuleCache<K, DC, VC, S>,
    per_block_module_cache: &SyncModuleCache<K, DC, VC, S, Option<TxnIndex>>,
    maybe_updated_module_keys: Option<&BTreeSet<K>>,
) -> bool {
    if self.non_delayed_field_speculative_failure {
        return false;
    }
    
    // ATOMIC SNAPSHOT: Collect all override states before validating
    let mut override_snapshot = HashMap::new();
    for key in self.module_reads.keys() {
        override_snapshot.insert(
            key.clone(), 
            global_module_cache.contains_not_overridden(key)
        );
    }
    
    let validate = |key: &K, read: &ModuleRead<DC, VC, S>| match read {
        ModuleRead::GlobalCache(_) => {
            // Use snapshot instead of live check
            *override_snapshot.get(key).unwrap_or(&false)
        },
        ModuleRead::PerBlockCache(previous) => {
            let current_version = per_block_module_cache.get_module_version(key);
            let previous_version = previous.as_ref().map(|(_, version)| *version);
            current_version == previous_version
        },
    };
    
    // Rest of validation logic unchanged...
}
```

**Option 2 - Read-Write Lock**: Protect both module publishing and validation with a shared RwLock at the global module cache level (heavier weight but guarantees consistency).

**Long-term**: Consider a version-based approach where modules carry version numbers and validation checks version equality rather than override flags.

## Proof of Concept

```rust
#[test]
fn test_module_validation_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    // Setup: Create global module cache with module M
    let mut global_cache = GlobalModuleCache::empty();
    let module_m = mock_verified_code(0, MockExtension::new(8));
    global_cache.insert(ModuleId::new(AccountAddress::ZERO, "M".parse().unwrap()), module_m);
    
    // Transaction T1 reads module M from global cache
    let mut captured_reads_t1 = CapturedReads::new(None);
    captured_reads_t1.capture_global_cache_read(
        ModuleId::new(AccountAddress::ZERO, "M".parse().unwrap()),
        global_cache.get(&ModuleId::new(AccountAddress::ZERO, "M".parse().unwrap())).unwrap()
    );
    
    let global_cache = Arc::new(global_cache);
    let captured_reads = Arc::new(captured_reads_t1);
    let barrier = Arc::new(Barrier::new(2));
    
    // Thread 1: Validate T1's module reads
    let global_cache_clone = global_cache.clone();
    let captured_reads_clone = captured_reads.clone();
    let barrier_clone = barrier.clone();
    let validation_thread = thread::spawn(move || {
        barrier_clone.wait(); // Sync start
        // This validation may pass if it completes before override
        captured_reads_clone.validate_module_reads(
            &*global_cache_clone,
            &per_block_cache, // mock this
            None
        )
    });
    
    // Thread 2: Mark module M as overridden (simulating T2 commit)
    let global_cache_clone = global_cache.clone();
    let barrier_clone = barrier.clone();
    let override_thread = thread::spawn(move || {
        barrier_clone.wait(); // Sync start
        // Small delay to increase race likelihood
        thread::sleep(std::time::Duration::from_micros(10));
        global_cache_clone.mark_overridden(
            &ModuleId::new(AccountAddress::ZERO, "M".parse().unwrap())
        );
    });
    
    let validation_result = validation_thread.join().unwrap();
    override_thread.join().unwrap();
    
    // Race condition: validation might pass even though module was overridden
    // Expected: validation should ALWAYS fail, but due to race it might pass
    // Run this test multiple times to observe non-deterministic behavior
}
```

**Notes:**
- The race window is timing-dependent and may require multiple runs to reproduce
- On multi-core systems with high parallelism, the race becomes more likely
- The PoC demonstrates the fundamental issue: validation outcome depends on thread scheduling rather than logical correctness

### Citations

**File:** aptos-move/block-executor/src/captured_reads.rs (L1050-1089)
```rust
    pub(crate) fn validate_module_reads(
        &self,
        global_module_cache: &GlobalModuleCache<K, DC, VC, S>,
        per_block_module_cache: &SyncModuleCache<K, DC, VC, S, Option<TxnIndex>>,
        maybe_updated_module_keys: Option<&BTreeSet<K>>,
    ) -> bool {
        if self.non_delayed_field_speculative_failure {
            return false;
        }

        let validate = |key: &K, read: &ModuleRead<DC, VC, S>| match read {
            ModuleRead::GlobalCache(_) => global_module_cache.contains_not_overridden(key),
            ModuleRead::PerBlockCache(previous) => {
                let current_version = per_block_module_cache.get_module_version(key);
                let previous_version = previous.as_ref().map(|(_, version)| *version);
                current_version == previous_version
            },
        };

        match maybe_updated_module_keys {
            Some(updated_module_keys) if updated_module_keys.len() <= self.module_reads.len() => {
                // When updated_module_keys is smaller, iterate over it and lookup in module_reads
                updated_module_keys
                    .iter()
                    .filter(|&k| self.module_reads.contains_key(k))
                    .all(|key| validate(key, self.module_reads.get(key).unwrap()))
            },
            Some(updated_module_keys) => {
                // When module_reads is smaller, iterate over it and filter by updated_module_keys
                self.module_reads
                    .iter()
                    .filter(|(k, _)| updated_module_keys.contains(k))
                    .all(|(key, read)| validate(key, read))
            },
            None => self
                .module_reads
                .iter()
                .all(|(key, read)| validate(key, read)),
        }
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1043-1057)
```rust
        // Publish modules before we decrease validation index (in V1) so that validations observe
        // the new module writes as well.
        if last_input_output.publish_module_write_set(
            txn_idx,
            global_module_cache,
            versioned_cache,
            runtime_environment,
            &scheduler,
        )? {
            side_effect_at_commit = true;
        }

        if side_effect_at_commit {
            scheduler.wake_dependencies_and_decrease_validation_idx(txn_idx)?;
        }
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L272-319)
```rust
pub(crate) fn add_module_write_to_module_cache<T: BlockExecutableTransaction>(
    write: &ModuleWrite<T::Value>,
    txn_idx: TxnIndex,
    runtime_environment: &RuntimeEnvironment,
    global_module_cache: &GlobalModuleCache<ModuleId, CompiledModule, Module, AptosModuleExtension>,
    per_block_module_cache: &impl ModuleCache<
        Key = ModuleId,
        Deserialized = CompiledModule,
        Verified = Module,
        Extension = AptosModuleExtension,
        Version = Option<TxnIndex>,
    >,
) -> Result<(), PanicError> {
    let state_value = write
        .write_op()
        .as_state_value()
        .ok_or_else(|| PanicError::CodeInvariantError("Modules cannot be deleted".to_string()))?;

    // Since we have successfully serialized the module when converting into this transaction
    // write, the deserialization should never fail.
    let compiled_module = runtime_environment
        .deserialize_into_compiled_module(state_value.bytes())
        .map_err(|err| {
            let msg = format!("Failed to construct the module from state value: {:?}", err);
            PanicError::CodeInvariantError(msg)
        })?;
    let extension = Arc::new(AptosModuleExtension::new(state_value));

    per_block_module_cache
        .insert_deserialized_module(
            write.module_id().clone(),
            compiled_module,
            extension,
            Some(txn_idx),
        )
        .map_err(|err| {
            let msg = format!(
                "Failed to insert code for module {}::{} at version {} to module cache: {:?}",
                write.module_address(),
                write.module_name(),
                txn_idx,
                err
            );
            PanicError::CodeInvariantError(msg)
        })?;
    global_module_cache.mark_overridden(write.module_id());
    Ok(())
}
```
