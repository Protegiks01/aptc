# Audit Report

## Title
Error Classification TOCTOU Vulnerability: Peer-Triggered Pruning Errors Misclassified as Storage Failures

## Summary
The `From<AptosDbError>` implementation unconditionally converts all database errors to `StorageErrorEncountered`, including errors caused by malicious peers requesting pruned data. A TOCTOU race condition between moderator validation (using cached storage summary) and actual storage operations allows peers to generate cascading storage error events that should be classified as `InvalidRequest`, leading to resource exhaustion through error logging/metrics and misleading operational monitoring. [1](#0-0) 

## Finding Description

The storage service implements a request moderator that validates peer requests using a cached `StorageServerSummary` refreshed every 100ms. [2](#0-1)  The moderator checks if requested version ranges are available before processing. [3](#0-2) 

However, a TOCTOU vulnerability exists between validation and execution:

1. **Validation Phase**: The moderator validates requests using `can_service()` which checks if transaction/state ranges are available in the cached summary [4](#0-3) 

2. **Race Window**: Between validation and storage access, data can be pruned OR the request may target versions at the exact pruning boundary

3. **Storage Access Phase**: When storage operations execute, they perform pruning checks [5](#0-4)  that return `AptosDbError` with messages like "Transaction at version X is pruned, min available version is Y"

4. **Error Misclassification**: ALL `AptosDbError` variants are automatically converted to `StorageErrorEncountered` [1](#0-0)  regardless of whether they represent true storage failures or peer misbehavior

5. **Resource Consumption**: Each error increments the `STORAGE_ERRORS_ENCOUNTERED` metric (unbounded) and generates sampled log entries every 5 seconds [6](#0-5) 

**Attack Scenario:**

A malicious peer can:
1. Query the storage server summary to identify `min_readable_version` from transaction ranges
2. Send 500 requests (the default limit before blocking) targeting versions at or just below the pruning boundary [7](#0-6) 
3. Exploit the 100ms cache refresh window where versions become pruned after validation but before execution
4. Each failed request increments storage error metrics and logs, misleading monitoring systems
5. After 500 requests, the peer is blocked for 5 minutes with exponential backoff [8](#0-7) 
6. Multiple coordinating peers can amplify this attack (validators and VFNs are never blocked regardless of invalid request count) [9](#0-8) 

The vulnerability breaks the **Resource Limits** invariant by allowing unbounded metric increments per peer (up to 500 per 5-minute period) and misclassifies peer misbehavior as infrastructure failures.

## Impact Explanation

This vulnerability meets **Medium severity** criteria per the Aptos bug bounty program as it causes:

1. **Resource Exhaustion**: While logs are sampled, metrics counters are incremented for every error without sampling, allowing a peer to generate 500 storage error events before being blocked

2. **Operational Misdirection**: Storage errors trigger infrastructure monitoring alerts and investigations, wasting operator time on false positives when the actual issue is peer misbehavior. This masks genuine storage issues and peer attacks

3. **Coordinated Amplification**: Multiple malicious peers can coordinate to generate thousands of false storage errors across the network. Validators and VFNs are never blocked, allowing sustained attacks from trusted network tiers [10](#0-9) 

4. **State Inconsistencies in Monitoring**: The monitoring system shows storage health degradation when the actual root cause is peer behavior, potentially leading to incorrect operational responses

While this does not directly cause fund loss or consensus violations, it represents a state inconsistency requiring intervention (false error classification) and resource consumption that degrades node operational visibility.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is readily exploitable because:

1. **Trivial Discovery**: Any peer can query the storage summary to identify pruning boundaries [11](#0-10) 

2. **Guaranteed Race Window**: With 100ms cache refresh intervals and continuous pruning, there's always a window where validated requests can target newly-pruned data

3. **No Special Privileges Required**: Any network peer can exploit this; no validator access needed

4. **Repeatable Attack**: After the 5-minute block period expires, the same peer can repeat the attack with exponentially increasing block durations

5. **Amplification via Multiple Peers**: An attacker controlling multiple peer identities can generate sustained false storage errors

The attack requires only basic network access and timing around pruning operations, making it highly feasible for motivated adversaries.

## Recommendation

Implement error discrimination in the `From<AptosDbError>` conversion to distinguish peer-caused errors from genuine storage failures:

```rust
impl From<aptos_storage_interface::AptosDbError> for Error {
    fn from(error: aptos_storage_interface::AptosDbError) -> Self {
        match error {
            // Peer-caused errors (requesting unavailable data)
            AptosDbError::NotFound(_) => Error::InvalidRequest(error.to_string()),
            AptosDbError::MissingRootError(_) => Error::InvalidRequest(format!(
                "Requested version has been pruned: {}", error
            )),
            AptosDbError::TooManyRequested(requested, max) => Error::InvalidRequest(format!(
                "Too many items requested: {} (max: {})", requested, max
            )),
            
            // Genuine storage failures
            AptosDbError::Other(_) 
            | AptosDbError::RocksDbIncompleteResult(_)
            | AptosDbError::OtherRocksDbError(_)
            | AptosDbError::BcsError(_)
            | AptosDbError::IoError(_)
            | AptosDbError::RecvError(_)
            | AptosDbError::ParseIntError(_)
            | AptosDbError::HotStateError => Error::StorageErrorEncountered(error.to_string()),
        }
    }
}
```

Additionally:
1. Add version range validation at storage operation time (double-check after cache)
2. Track pruning-related peer errors in a separate metric from storage failures
3. Consider reducing the 500 request threshold for pruning-boundary requests specifically

## Proof of Concept

**Rust Test Reproduction Steps:**

```rust
// In state-sync/storage-service/server/src/tests/request_moderator.rs

#[tokio::test]
async fn test_toctou_pruning_error_misclassification() {
    // 1. Setup storage with pruning enabled
    let (mut mock_client, service, _mock_time, peer_mgr, storage) = 
        MockClient::new(None, None);
    
    // 2. Prune data to create a min_readable_version > 0
    // (In production this happens continuously)
    let min_readable_version = 1000;
    
    // 3. Peer queries storage summary (sees data available up to V)
    let summary_request = StorageServiceRequest::new(
        DataRequest::GetStorageServerSummary,
        false,
    );
    let summary = mock_client.send_request(summary_request).await.unwrap();
    
    // 4. Peer sends request for version below min_readable_version
    // This passes moderator validation if cache is stale
    let request = StorageServiceRequest::new(
        DataRequest::GetTransactionsWithProof(TransactionsWithProofRequest {
            proof_version: min_readable_version + 100,
            start_version: min_readable_version - 50, // Pruned
            end_version: min_readable_version - 1,
            include_events: false,
        }),
        false,
    );
    
    // 5. Request passes moderator but fails at storage with pruning error
    let response = mock_client.send_request(request).await;
    
    // 6. Verify error is misclassified as StorageErrorEncountered
    match response {
        Err(StorageServiceError::InternalError(msg)) => {
            assert!(msg.contains("pruned"), 
                "Expected pruning error classified as storage error");
        },
        _ => panic!("Expected InternalError from pruning, got: {:?}", response),
    }
    
    // 7. Verify STORAGE_ERRORS_ENCOUNTERED metric was incremented
    // (not INVALID_REQUEST metric)
    let metrics = get_storage_error_metrics();
    assert!(metrics["storage_error"] > 0, "Storage error metric should increment");
}
```

The PoC demonstrates that peer requests for pruned data are misclassified as storage errors rather than invalid requests, allowing malicious peers to exhaust error logging resources while masking their misbehavior as infrastructure failures.

## Notes

The vulnerability is particularly concerning because:
- Validators and VFNs are never rate-limited regardless of invalid request count, allowing sustained attacks from semi-trusted network tiers
- The error misclassification directly undermines operational monitoring and incident response
- The fix is straightforward (error discrimination) but the impact persists in current deployments

### Citations

**File:** state-sync/storage-service/server/src/error.rs (L43-46)
```rust
impl From<aptos_storage_interface::AptosDbError> for Error {
    fn from(error: aptos_storage_interface::AptosDbError) -> Self {
        Error::StorageErrorEncountered(error.to_string())
    }
```

**File:** config/src/config/state_sync_config.rs (L201-201)
```rust
            max_invalid_requests_per_peer: 500,
```

**File:** config/src/config/state_sync_config.rs (L213-213)
```rust
            min_time_to_ignore_peers_secs: 300, // 5 minutes
```

**File:** config/src/config/state_sync_config.rs (L215-215)
```rust
            storage_summary_refresh_interval_ms: 100, // Optimal for <= 10 blocks per second
```

**File:** state-sync/storage-service/server/src/moderator.rs (L54-68)
```rust
        // If the peer is a PFN and has sent too many invalid requests, start ignoring it
        if self.ignore_start_time.is_none()
            && peer_network_id.network_id().is_public_network()
            && self.invalid_request_count >= self.max_invalid_requests
        {
            // TODO: at some point we'll want to terminate the connection entirely

            // Start ignoring the peer
            self.ignore_start_time = Some(self.time_service.now());

            // Log the fact that we're now ignoring the peer
            warn!(LogSchema::new(LogEntry::RequestModeratorIgnoredPeer)
                .peer_network_id(peer_network_id)
                .message("Ignoring peer due to too many invalid requests!"));
        }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-196)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L364-392)
```rust
        // Handle a lot of invalid requests for a validator
        let peer_network_id = PeerNetworkId::new(NetworkId::Validator, PeerId::random());
        for _ in 0..max_invalid_requests * 10 {
            unhealthy_peer_state.increment_invalid_request_count(&peer_network_id);
        }

        // Verify the peer is not ignored and that the number of invalid requests is correct
        assert!(!unhealthy_peer_state.is_ignored());
        assert_eq!(
            unhealthy_peer_state.invalid_request_count,
            max_invalid_requests * 10
        );

        // Create another unhealthy peer state
        let mut unhealthy_peer_state =
            UnhealthyPeerState::new(max_invalid_requests, 1, time_service.clone());

        // Handle a lot of invalid requests for a VFN
        let peer_network_id = PeerNetworkId::new(NetworkId::Vfn, PeerId::random());
        for _ in 0..max_invalid_requests * 20 {
            unhealthy_peer_state.increment_invalid_request_count(&peer_network_id);
        }

        // Verify the peer is not ignored and that the number of invalid requests is correct
        assert!(!unhealthy_peer_state.is_ignored());
        assert_eq!(
            unhealthy_peer_state.invalid_request_count,
            max_invalid_requests * 20
        );
```

**File:** state-sync/storage-service/types/src/responses.rs (L749-753)
```rust
            GetTransactionsWithProof(request) => self.can_service_transactions_with_proof(
                request.start_version,
                request.end_version,
                request.proof_version,
            ),
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L261-271)
```rust
    pub(super) fn error_if_ledger_pruned(&self, data_type: &str, version: Version) -> Result<()> {
        let min_readable_version = self.ledger_pruner.get_min_readable_version();
        ensure!(
            version >= min_readable_version,
            "{} at version {} is pruned, min available version is {}.",
            data_type,
            version,
            min_readable_version
        );
        Ok(())
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L152-169)
```rust
                Err(error) => {
                    // Update the error counter
                    increment_counter(
                        &metrics::STORAGE_ERRORS_ENCOUNTERED,
                        peer_network_id.network_id(),
                        error.get_label().into(),
                    );

                    // Periodically log the failure
                    sample!(
                            SampleRate::Duration(Duration::from_secs(ERROR_LOG_FREQUENCY_SECS)),
                            warn!(LogSchema::new(LogEntry::StorageServiceError)
                                .error(&error)
                                .peer_network_id(peer_network_id)
                                .request(&request)
                                .optimistic_fetch_related(optimistic_fetch_related)
                        );
                    );
```

**File:** state-sync/storage-service/server/src/handler.rs (L222-226)
```rust
            DataRequest::GetStorageServerSummary => {
                let data_response = self.get_storage_server_summary();
                StorageServiceResponse::new(data_response, request.use_compression)
                    .map_err(|error| error.into())
            },
```
