# Audit Report

## Title
Node Crash Due to Unhandled Panic in Cross-Shard Communication During Shutdown

## Summary
The `send_cross_shard_msg()` function in `RemoteCrossShardClient` uses `.unwrap()` on a channel send operation without checking if the receiver is still alive. When the `NetworkController` is shut down during active block execution, the channel receivers are dropped, causing subsequent send operations to panic and crash the executor thread, leading to node unavailability.

## Finding Description

The vulnerability exists in the shutdown sequence of the remote executor service. The critical code path is: [1](#0-0) 

When a cross-shard message is sent, it calls `.unwrap()` on the channel send result. In crossbeam channels, `send()` returns `Err(SendError)` if the receiver has been dropped, which causes the unwrap to panic.

The problematic shutdown sequence occurs as follows:

1. **ExecutorService starts and spawns a worker thread:** [2](#0-1) 

Note that the `JoinHandle` is not stored, so there's no way to wait for the thread to finish.

2. **The worker thread runs the executor service loop:** [3](#0-2) 

3. **During block execution, cross-shard messages are sent via hooks:** [4](#0-3) 

4. **When shutdown is called, only the NetworkController is stopped:** [5](#0-4) 

5. **NetworkController shutdown stops the outbound handler, dropping all receivers:** [6](#0-5) 

6. **When receivers are dropped, the outbound handler task terminates:** [7](#0-6) 

**The race condition:** If the executor thread is in the middle of executing a block when `shutdown()` is called, it will continue trying to send cross-shard messages and execution results after the receivers have been dropped. This causes panics at:
- Cross-shard messages: line 58 in `remote_cross_shard_client.rs`
- Execution results: [8](#0-7) 

The panic occurs in the executor thread pool, which can crash the node depending on panic handling configuration.

## Impact Explanation

This issue qualifies as **High Severity** under the Aptos bug bounty criteria for the following reasons:

1. **Validator node crashes:** When the panic occurs, it crashes the executor service thread, causing the validator node to become unavailable for block execution.

2. **Loss of validator uptime:** Affected validators lose uptime, which impacts:
   - Validator rewards (validators are penalized for downtime)
   - Network health (reduced validator participation)
   - Consensus performance (fewer validators participating)

3. **Reproducible during normal operations:** This can occur during:
   - Graceful node shutdown while blocks are being executed
   - Error recovery paths that trigger cleanup
   - Network controller failures or timeouts
   - Resource exhaustion scenarios that trigger shutdown

While this doesn't cause network-wide availability loss (only affects individual nodes), it meets the "Validator node crashes" criterion for High severity.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability is likely to occur in production environments because:

1. **No synchronization between shutdown and execution:** The shutdown path does not wait for active block execution to complete before closing channels.

2. **Common trigger scenarios:**
   - Node operators performing rolling upgrades/restarts
   - Automated health checks triggering restarts on degraded nodes
   - Error handlers calling cleanup while execution is in progress
   - Network partitions causing coordinator disconnections

3. **Timing window:** The race condition window is relatively large - it spans the entire duration of block execution, which can take hundreds of milliseconds to seconds depending on block size and complexity.

4. **No recovery mechanism:** Once the panic occurs, the node requires manual restart.

The likelihood is not "Critical" because it requires specific timing (shutdown during execution), but this timing is common enough in production environments to be a realistic concern.

## Recommendation

Implement graceful shutdown with proper synchronization:

**Option 1: Check channel status before sending (Defensive)**
```rust
fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
    let input_message = bcs::to_bytes(&msg).unwrap();
    let tx = self.message_txs[shard_id][round].lock().unwrap();
    if let Err(e) = tx.send(Message::new(input_message)) {
        warn!("Failed to send cross-shard message: {:?}. Channel may be closed during shutdown.", e);
        // Optionally: set a shutdown flag or return an error to halt execution
    }
}
```

**Option 2: Store JoinHandle and coordinate shutdown (Better)**
```rust
pub struct ExecutorService {
    shard_id: ShardId,
    controller: NetworkController,
    executor_service: Arc<ShardedExecutorService<RemoteStateViewClient>>,
    executor_thread: Option<JoinHandle<()>>,  // Add this
}

pub fn start(&mut self) {
    self.controller.start();
    let thread_name = format!("ExecutorService-{}", self.shard_id);
    let executor_service_clone = self.executor_service.clone();
    let handle = thread::Builder::new()
        .name(thread_name)
        .spawn(move || {
            executor_service_clone.start();
        })
        .expect("Failed to spawn thread");
    self.executor_thread = Some(handle);  // Store handle
}

pub fn shutdown(&mut self) {
    // First, signal the executor to stop by closing command channel
    // (this happens naturally when controller shuts down)
    
    // Wait for executor thread to finish
    if let Some(handle) = self.executor_thread.take() {
        handle.join().expect("Executor thread panicked");
    }
    
    // Then shutdown the network controller
    self.controller.shutdown();
}
```

**Option 3: Use Result returns instead of unwrap (Most robust)**
Change the `CrossShardClient` trait to return `Result<(), SendError>` and propagate errors up the call stack, allowing the executor to handle shutdown gracefully.

## Proof of Concept

```rust
// Add to execution/executor-service/src/tests.rs

#[test]
#[should_panic(expected = "SendError")]
fn test_shutdown_during_execution_causes_panic() {
    use std::thread;
    use std::time::Duration;
    
    let num_shards = 2;
    let (mut executor_client, mut executor_services) =
        create_thread_remote_executor_shards(num_shards, Some(2));
    
    // Wait for services to be ready
    thread::sleep(Duration::from_millis(100));
    
    // Start a long-running block execution in a separate thread
    let executor_handle = thread::spawn(move || {
        // Execute a block with cross-shard dependencies
        let transactions = test_utils::generate_test_transactions_with_cross_shard_deps(100);
        executor_client.execute_block(transactions);
    });
    
    // Give execution time to start
    thread::sleep(Duration::from_millis(50));
    
    // Trigger shutdown while execution is in progress
    executor_services.iter_mut().for_each(|service| {
        service.shutdown();
    });
    
    // The executor thread will panic when trying to send cross-shard messages
    // after the channels are closed
    executor_handle.join().expect("Executor panicked during shutdown");
}
```

**Notes**

This vulnerability demonstrates a critical flaw in the lifecycle management of the remote executor service. The lack of coordination between the network layer shutdown and the execution layer creates a race condition that can crash validator nodes during normal operational scenarios. While individual node crashes don't cause network-wide failures, they impact validator rewards, network resilience, and could be exploited in combination with other attacks to degrade network performance.

The fix requires either defensive error handling throughout the message sending paths, or better yet, a redesigned shutdown sequence that ensures all execution completes before network resources are torn down.

### Citations

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L55-59)
```rust
    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
        let input_message = bcs::to_bytes(&msg).unwrap();
        let tx = self.message_txs[shard_id][round].lock().unwrap();
        tx.send(Message::new(input_message)).unwrap();
    }
```

**File:** execution/executor-service/src/remote_executor_service.rs (L57-67)
```rust
    pub fn start(&mut self) {
        self.controller.start();
        let thread_name = format!("ExecutorService-{}", self.shard_id);
        let builder = thread::Builder::new().name(thread_name);
        let executor_service_clone = self.executor_service.clone();
        builder
            .spawn(move || {
                executor_service_clone.start();
            })
            .expect("Failed to spawn thread");
    }
```

**File:** execution/executor-service/src/remote_executor_service.rs (L69-71)
```rust
    pub fn shutdown(&mut self) {
        self.controller.shutdown();
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L222-260)
```rust
        loop {
            let command = self.coordinator_client.receive_execute_command();
            match command {
                ExecutorShardCommand::ExecuteSubBlocks(
                    state_view,
                    transactions,
                    concurrency_level_per_shard,
                    onchain_config,
                ) => {
                    num_txns += transactions.num_txns();
                    trace!(
                        "Shard {} received ExecuteBlock command of block size {} ",
                        self.shard_id,
                        num_txns
                    );
                    let exe_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "execute_block"]);
                    let ret = self.execute_block(
                        transactions,
                        state_view.as_ref(),
                        BlockExecutorConfig {
                            local: BlockExecutorLocalConfig::default_with_concurrency_level(
                                concurrency_level_per_shard,
                            ),
                            onchain: onchain_config,
                        },
                    );
                    drop(state_view);
                    drop(exe_timer);

                    let _result_tx_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "result_tx"]);
                    self.coordinator_client.send_execution_result(ret);
                },
                ExecutorShardCommand::Stop => {
                    break;
                },
            }
        }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L125-130)
```rust
                        self.cross_shard_client.send_cross_shard_msg(
                            *dependent_shard_id,
                            *round_id,
                            message,
                        );
                    }
```

**File:** secure/net/src/network_controller/mod.rs (L155-166)
```rust
    pub fn shutdown(&mut self) {
        info!("Shutting down network controller at {}", self.listen_addr);
        if let Some(shutdown_signal) = self.inbound_server_shutdown_tx.take() {
            shutdown_signal.send(()).unwrap();
        }

        if let Some(shutdown_signal) = self.outbound_task_shutdown_tx.take() {
            shutdown_signal.send(Message::new(vec![])).unwrap_or_else(|_| {
                warn!("Failed to send shutdown signal to outbound task; probably already shutdown");
            })
        }
    }
```

**File:** secure/net/src/network_controller/outbound_handler.rs (L128-136)
```rust
                    Err(e) => {
                        warn!(
                            "{:?} for outbound handler on {:?}. This can happen in shutdown,\
                             but should not happen otherwise",
                            e.to_string(),
                            socket_addr
                        );
                        return;
                    },
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L115-119)
```rust
    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
        let remote_execution_result = RemoteExecutionResult::new(result);
        let output_message = bcs::to_bytes(&remote_execution_result).unwrap();
        self.result_tx.send(Message::new(output_message)).unwrap();
    }
```
