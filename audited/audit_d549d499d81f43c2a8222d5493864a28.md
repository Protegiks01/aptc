# Audit Report

## Title
Randomness Share Replay Vulnerability After RandStore Reset

## Summary
Randomness shares are cryptographically bound only to (epoch, round) rather than (epoch, round, block_id), and lack replay protection after `RandStore::reset()`. This allows old shares to be replayed and accepted for different blocks at the same round after a reset, potentially causing different blocks to receive identical randomness values, breaking randomness unpredictability guarantees.

## Finding Description

The Aptos randomness generation system has a critical design flaw where cryptographic shares are not bound to specific blocks. When `RandStore::reset()` clears future rounds during sync operations, old randomness shares can be replayed and accepted without validation against the specific block they should correspond to.

**Root Cause 1: Shares Not Bound to Block ID**

Randomness shares are cryptographically signed over `RandMetadata` which contains only `epoch` and `round`: [1](#0-0) 

The `FullRandMetadata` structure includes `block_id`, but it is explicitly marked as "not used for signing": [2](#0-1) 

During share generation and verification, only the `RandMetadata` (epoch, round) is used in the cryptographic signature: [3](#0-2) 

**Root Cause 2: Inadequate Metadata Validation**

When shares are added to a `RandItem` in `PendingDecision` state, the validation only checks that the share's metadata matches the `RandMetadata` portion (epoch, round), not the full `block_id`: [4](#0-3) 

Similarly, when shares are retained during metadata addition, only the `RandMetadata` is compared: [5](#0-4) 

**Root Cause 3: No Replay Protection After Reset**

The `reset()` function clears all round data for rounds >= target round, but provides no mechanism to prevent old shares from being replayed: [6](#0-5) 

The only validation when adding shares checks epoch and round bounds, with no replay protection: [7](#0-6) 

**Attack Scenario:**

1. Validator is syncing or experiences a fork at round R with block B1 (block_id = H1)
2. Shares are generated and broadcast for (epoch, R)
3. Attacker captures these shares from the network
4. During sync, `reset(R)` is called, clearing the `RandItem` for round R
5. Validator processes a different block B2 at round R (block_id = H2, different content)
6. Attacker replays the captured shares for (epoch, R)
7. Shares pass all validation (epoch matches, round within bounds, cryptographically valid for (epoch, R))
8. Shares are aggregated and produce the same randomness for B2 as would have been produced for B1
9. Different blocks at the same round receive identical randomness, breaking unpredictability

This violates the **Deterministic Execution** invariant (different blocks should have different randomness) and **Cryptographic Correctness** (randomness should be unique and unpredictable per block).

## Impact Explanation

**Severity: High** - Significant protocol violation

This vulnerability breaks the randomness unpredictability guarantee, which is critical for:
- Leader election fairness
- Validator selection randomness
- Any on-chain applications relying on per-block randomness

The impact includes:
1. **Randomness Predictability**: Attackers who capture shares can predict future randomness if the same round is re-processed with a different block
2. **Fork Resolution Manipulation**: During fork resolution, attackers could manipulate which randomness value is used
3. **Consensus Safety Concerns**: While not a direct consensus break, it undermines the randomness beacon's security properties

This qualifies as **High Severity** per the bug bounty criteria as a "significant protocol violation" that compromises the randomness generation subsystem's core security properties.

## Likelihood Explanation

**Likelihood: Medium**

The attack requires:
1. Network access to capture shares (any peer can do this)
2. A `reset()` event occurring (happens during sync operations and epoch transitions)
3. Ability to replay network messages (straightforward for network attackers)

Reset events occur during:
- Sync operations when validators fall behind
- Epoch transitions
- Fork resolution

These are regular network conditions, making the vulnerability exploitable in practice. While BFT consensus prevents different blocks at the same round under normal operation, sync and fork scenarios create windows where this vulnerability can be exploited.

## Recommendation

**Fix 1: Bind shares to block_id**

Modify the cryptographic signature to include the full `FullRandMetadata` including `block_id`:

```rust
// In types/src/randomness.rs, update FullRandMetadata
#[derive(Clone, Serialize, Deserialize, Debug, PartialEq, Eq, Hash)]
pub struct FullRandMetadata {
    pub epoch: u64,
    pub round: Round,
    pub block_id: HashValue,  // Include in signing
    pub timestamp: u64,  // not used for signing
}
```

Update share generation and verification to use `FullRandMetadata` instead of just `RandMetadata`:

```rust
// In consensus/src/rand/rand_gen/types.rs
impl TShare for Share {
    fn verify(
        &self,
        rand_config: &RandConfig,
        full_metadata: &FullRandMetadata,  // Use full metadata
        author: &Author,
    ) -> anyhow::Result<()> {
        // ... 
        WVUF::verify_share(
            &rand_config.vuf_pp,
            apk,
            bcs::to_bytes(&full_metadata)  // Sign over full metadata
                .map_err(|e| anyhow!("Serialization failed: {}", e))?
                .as_slice(),
            &self.share,
        )?;
        // ...
    }
}
```

**Fix 2: Add replay protection**

Maintain a persistent or epoch-local record of processed shares to prevent replay:

```rust
pub struct RandStore<S> {
    // ... existing fields ...
    processed_shares: HashMap<ShareId, HashValue>,  // Track share -> block_id mapping
}

impl<S: TShare> RandStore<S> {
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        let share_id = share.share_id();
        
        // Check if this share was already processed for a different block
        if let Some(existing_block_id) = self.processed_shares.get(&share_id) {
            let current_block_id = /* get current block_id for this round */;
            ensure!(
                existing_block_id == &current_block_id,
                "Share replay detected for different block"
            );
        }
        
        // ... rest of validation ...
    }
}
```

**Fix 3: Enhance metadata validation**

Update the metadata check to compare full `FullRandMetadata` including `block_id`:

```rust
// In rand_store.rs, RandItem::add_share
RandItem::PendingDecision {
    metadata,
    share_aggregator,
} => {
    ensure!(
        metadata == share.full_metadata(),  // Compare full metadata including block_id
        "[RandStore] RandShare metadata from {} mismatch with block metadata!",
        share.author(),
    );
    // ...
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod replay_attack_test {
    use super::*;
    use aptos_crypto::HashValue;
    
    #[tokio::test]
    async fn test_share_replay_after_reset() {
        // Setup: Create RandStore and generate shares for block B1
        let epoch = 1;
        let round = 100;
        let block_id_1 = HashValue::random();
        let block_id_2 = HashValue::random();  // Different block
        
        let (decision_tx, mut decision_rx) = unbounded();
        let mut rand_store = RandStore::new(
            epoch,
            Author::ONE,
            rand_config.clone(),
            None,
            decision_tx,
        );
        
        // Add metadata for block B1
        let metadata_1 = FullRandMetadata::new(epoch, round, block_id_1, 1000);
        rand_store.add_rand_metadata(metadata_1);
        
        // Generate and add shares for block B1
        let shares: Vec<_> = (0..5)
            .map(|i| create_share(RandMetadata { epoch, round }, authors[i]))
            .collect();
        
        for share in &shares {
            rand_store.add_share(share.clone(), PathType::Slow).unwrap();
        }
        
        // Capture the randomness generated for B1
        let randomness_1 = decision_rx.next().await.unwrap();
        
        // Simulate reset (e.g., during sync)
        rand_store.reset(round);
        
        // Add metadata for different block B2 at same round
        let metadata_2 = FullRandMetadata::new(epoch, round, block_id_2, 2000);
        rand_store.add_rand_metadata(metadata_2);
        
        // ATTACK: Replay old shares from B1
        for share in &shares {
            // These shares should be rejected but are accepted
            rand_store.add_share(share.clone(), PathType::Slow).unwrap();
        }
        
        // Verify that same randomness is generated for B2
        let randomness_2 = decision_rx.next().await.unwrap();
        
        // VULNERABILITY: Different blocks get same randomness!
        assert_eq!(randomness_1.randomness(), randomness_2.randomness());
        assert_ne!(block_id_1, block_id_2);  // But blocks are different
        
        println!("VULNERABILITY CONFIRMED: Different blocks at same round received identical randomness");
    }
}
```

## Notes

This vulnerability is architectural rather than a simple implementation bug. The randomness system was designed to bind shares to (epoch, round) for simplicity, but this creates a security gap during sync and fork scenarios. The fix requires updating the cryptographic layer to include `block_id` in signatures, which is a breaking change to the randomness protocol.

The vulnerability is particularly concerning because it can be exploited passively by network observers without requiring validator privileges or Byzantine behavior. Any attacker monitoring the network can capture shares and replay them during reset events.

### Citations

**File:** types/src/randomness.rs (L23-27)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, Default, PartialEq, Eq, Hash)]
pub struct RandMetadata {
    pub epoch: u64,
    pub round: Round,
}
```

**File:** types/src/randomness.rs (L29-35)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, PartialEq, Eq, Hash)]
pub struct FullRandMetadata {
    pub metadata: RandMetadata,
    // not used for signing
    pub block_id: HashValue,
    pub timestamp: u64,
}
```

**File:** consensus/src/rand/rand_gen/types.rs (L65-72)
```rust
            WVUF::verify_share(
                &rand_config.vuf_pp,
                apk,
                bcs::to_bytes(&rand_metadata)
                    .map_err(|e| anyhow!("Serialization failed: {}", e))?
                    .as_slice(),
                &self.share,
            )?;
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L91-99)
```rust
    fn retain(&mut self, rand_config: &RandConfig, rand_metadata: &FullRandMetadata) {
        self.shares
            .retain(|_, share| share.metadata() == &rand_metadata.metadata);
        self.total_weight = self
            .shares
            .keys()
            .map(|author| rand_config.get_peer_weight(author))
            .sum();
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L146-157)
```rust
            RandItem::PendingDecision {
                metadata,
                share_aggregator,
            } => {
                ensure!(
                    &metadata.metadata == share.metadata(),
                    "[RandStore] RandShare metadata from {} mismatch with block metadata!",
                    share.author(),
                );
                share_aggregator.add_share(rand_config.get_peer_weight(share.author()), share);
                Ok(())
            },
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-288)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```
