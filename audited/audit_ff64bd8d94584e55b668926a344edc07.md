# Audit Report

## Title
Cache Poisoning Vulnerability in Proof-of-Store Verification Enables Performance DoS Attack

## Summary
The `ProofCache` in the QuorumStore consensus component uses `BatchInfoExt` as the cache key but can store different `AggregateSignature` values for the same batch. A Byzantine validator can exploit this by creating multiple cryptographically valid proofs with different validator signature sets, causing cache thrashing and forcing all validators to perform expensive BLS signature re-verification repeatedly.

## Finding Description

The vulnerability exists in the proof verification caching mechanism. The `ProofCache` is defined as `Cache<BatchInfoExt, AggregateSignature>` where `BatchInfoExt` uniquely identifies a batch, but different quorum subsets produce different aggregate signatures. [1](#0-0) 

The critical flaw is in the `ProofOfStore::verify()` method. When a proof is verified, the cache is checked for a matching signature. If the cached signature differs from the incoming proof's signature, the code falls through to full BLS verification. After successful verification, the cache is overwritten with the new signature. [2](#0-1) 

This creates a cache poisoning scenario because BLS aggregate signatures depend on which validators signed. The `verify_multi_signatures` method aggregates public keys based on the validator bitmask, meaning different validator sets (each with >2/3 voting power) produce different but equally valid aggregate signatures for the same batch. [3](#0-2) 

**Attack Execution:**

A Byzantine validator authors a batch and collects signatures from validators. Instead of creating one proof immediately upon reaching quorum (as the honest `ProofCoordinator` does), the attacker waits and collects signatures from multiple overlapping quorum subsets. [4](#0-3) 

The attacker then creates multiple valid proofs (P1 with signature S1 from validator set V1, P2 with signature S2 from validator set V2) and broadcasts them to different nodes. When nodes receive these proofs via `UnverifiedEvent::ProofOfStoreMsgV2`, they must verify them before processing. [5](#0-4) 

The cache thrashing occurs because:
- Node A receives P1, verifies it, caches signature S1
- Node B receives P2, verifies it, caches signature S2  
- When Node A receives P2, cache returns S1 ≠ S2, forcing full BLS verification and overwriting cache with S2
- When Node B receives P1, cache returns S2 ≠ S1, forcing full BLS verification and overwriting cache with S1

While duplicate batch insertion is prevented at the `BatchProofQueue` level, this protection occurs AFTER the expensive verification stage. [6](#0-5) 

## Impact Explanation

This vulnerability enables a **Performance Denial-of-Service attack** classified as **High Severity - Validator Node Slowdowns** per the Aptos Bug Bounty program.

BLS signature verification requires expensive pairing operations on elliptic curves. The `verify_multi_signatures` operation aggregates public keys and performs cryptographic verification. [7](#0-6) 

Each cache miss forces re-verification, consuming significant CPU resources. A single Byzantine validator can create multiple valid proofs for every batch they author. With the QuorumStore's high batch creation rate, this compounds across all validators in the network, causing network-wide performance degradation. The cache mechanism, designed to optimize verification, becomes completely ineffective.

This affects **all validators** network-wide, not just individual nodes, making it a systemic availability issue impacting consensus performance.

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is highly feasible because:

1. **Low barrier to entry**: Any single Byzantine validator can execute this attack (within the <1/3 Byzantine assumption)
2. **Uses normal capabilities**: The attacker uses standard batch authoring and signature collection - operations every validator performs
3. **Natural propagation**: Proofs propagate through the P2P network automatically via consensus gossip
4. **Hard to detect**: Both proofs are cryptographically valid with proper >2/3 quorum signatures, making them indistinguishable from legitimate behavior
5. **Sustainable attack**: The attacker can repeat this for every batch they author throughout their validator tenure

The only requirement is being an active validator (requiring stake), but this is explicitly within the protocol's Byzantine fault tolerance model of <1/3 malicious validators.

## Recommendation

Implement deterministic proof aggregation or proof uniqueness enforcement:

**Option 1: Canonical Signature Selection**
Modify the cache to accept any valid signature for a batch, not requiring exact signature matching. When a proof with different but valid signature arrives, accept the cached verification result rather than re-verifying.

**Option 2: First-Proof-Wins Policy**
Extend the duplicate detection to the network layer. Once a valid proof for a batch is verified and cached, reject any subsequent proofs for the same batch regardless of signature differences. This requires coordination across the verification and insertion stages.

**Option 3: Deterministic Aggregation Rule**
Enforce a deterministic rule for which validators' signatures to aggregate (e.g., lowest validator indices that reach quorum). This prevents creation of multiple valid proofs for the same batch.

## Proof of Concept

While a full executable PoC would require running a modified validator node with altered `ProofCoordinator` logic, the attack can be demonstrated as follows:

1. Deploy a modified validator that bypasses the `completed` flag in `IncrementalProofState` 
2. Collect signatures from validators as they arrive
3. When sufficient voting power is reached, do not immediately create proof
4. Continue collecting additional signatures
5. Create multiple `ProofOfStore` objects with different validator subsets
6. Broadcast different proofs to different network peers
7. Monitor verification metrics to observe repeated expensive BLS verification operations

The code paths for this attack are confirmed through the cited verification flow where every `ProofOfStoreMsg` received triggers `verify()` with the shared `proof_cache`, and cache mismatches force full cryptographic re-verification.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L616-616)
```rust
pub type ProofCache = Cache<BatchInfoExt, AggregateSignature>;
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L635-652)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
        let batch_info_ext: BatchInfoExt = self.info.clone().into();
        if let Some(signature) = cache.get(&batch_info_ext) {
            if signature == self.multi_signature {
                return Ok(());
            }
        }
        let result = validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!(
                "Failed to verify ProofOfStore for batch: {:?}",
                self.info
            ));
        if result.is_ok() {
            cache.insert(batch_info_ext, self.multi_signature.clone());
        }
        result
    }
```

**File:** types/src/validator_verifier.rs (L345-386)
```rust
    pub fn verify_multi_signatures<T: CryptoHash + Serialize>(
        &self,
        message: &T,
        multi_signature: &AggregateSignature,
    ) -> std::result::Result<(), VerifyError> {
        // Verify the number of signature is not greater than expected.
        Self::check_num_of_voters(self.len() as u16, multi_signature.get_signers_bitvec())?;
        let mut pub_keys = vec![];
        let mut authors = vec![];
        for index in multi_signature.get_signers_bitvec().iter_ones() {
            let validator = self
                .validator_infos
                .get(index)
                .ok_or(VerifyError::UnknownAuthor)?;
            authors.push(validator.address);
            pub_keys.push(validator.public_key());
        }
        // Verify the quorum voting power of the authors
        self.check_voting_power(authors.iter(), true)?;
        #[cfg(any(test, feature = "fuzzing"))]
        {
            if self.quorum_voting_power == 0 {
                // This should happen only in case of tests.
                // TODO(skedia): Clean up the test behaviors to not rely on empty signature
                // verification
                return Ok(());
            }
        }
        // Verify empty multi signature
        let multi_sig = multi_signature
            .sig()
            .as_ref()
            .ok_or(VerifyError::EmptySignature)?;
        // Verify the optimistically aggregated signature.
        let aggregated_key =
            PublicKey::aggregate(pub_keys).map_err(|_| VerifyError::FailedToAggregatePubKey)?;

        multi_sig
            .verify(message, &aggregated_key)
            .map_err(|_| VerifyError::InvalidMultiSignature)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L329-336)
```rust
            if !value.completed && value.check_voting_power(validator_verifier, true) {
                let proof = {
                    let _timer = counters::SIGNED_BATCH_INFO_VERIFY_DURATION.start_timer();
                    value.aggregate_and_verify(validator_verifier)?
                };
                // proof validated locally, so adding to cache
                self.proof_cache
                    .insert(proof.info().clone(), proof.multi_signature().clone());
```

**File:** consensus/src/round_manager.rs (L221-228)
```rust
            UnverifiedEvent::ProofOfStoreMsgV2(p) => {
                if !self_message {
                    p.verify(max_num_batches, validator, proof_cache)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["proof_of_store_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::ProofOfStoreMsg(p)
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L180-188)
```rust
        let batch_key = BatchKey::from_info(proof.info());
        if self
            .items
            .get(&batch_key)
            .is_some_and(|item| item.proof.is_some() || item.is_committed())
        {
            counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
            return;
        }
```
