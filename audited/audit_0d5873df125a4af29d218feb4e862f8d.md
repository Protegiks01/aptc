# Audit Report

## Title
Timeout Task Executor Exhaustion via Channel Backpressure

## Summary
The `ScheduledTask::run()` method is documented as lightweight but has no enforcement mechanism. The production implementation `SendTask::run()` can block indefinitely when the bounded timeout channel fills, consuming tokio executor threads and potentially causing consensus performance degradation.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Lack of Enforcement**: [1](#0-0) 
The trait documentation states run() should be "lightweight and does not take long time to complete" but provides no runtime enforcement.

2. **Blocking Send Operation**: [2](#0-1) 
The `SendTask::run()` implementation calls `sender.send(message).await`, which uses the futures Sink trait. This await can block indefinitely if the channel is full.

3. **Bounded Channel**: [3](#0-2) 
The timeout channel has a fixed capacity of 1,024 messages.

4. **Shared Executor**: [4](#0-3) [5](#0-4) 
The timeout tasks run on the same tokio runtime as consensus processing.

When consensus processing slows (due to network issues, heavy load, or execution delays), timeout messages accumulate faster than they're consumed. Once the channel reaches capacity, subsequent `SendTask::run()` futures park awaiting channel space. These parked futures hold executor threads, reducing resources available for consensus message processing, creating a positive feedback loop.

The underlying channel implementation confirms blocking behavior: [6](#0-5) 
The mpsc::channel is bounded, and the Sink implementation will return Poll::Pending when full.

## Impact Explanation

This qualifies as **Medium severity** per the Aptos bug bounty program (validator node slowdowns). Under sustained load conditions, the cascading effect can:

1. Exhaust executor threads with blocked timeout tasks
2. Starve consensus message processing of runtime resources  
3. Increase round timeout durations, slowing block production
4. Potentially lead to temporary consensus liveness degradation

While this doesn't cause permanent network failure or fund loss, it can significantly degrade validator performance during stress conditions, violating the **Resource Limits** invariant (all operations must respect computational limits).

## Likelihood Explanation

Likelihood is **Low to Medium** under normal operation but increases during:
- Network congestion causing slow message processing
- Execution pipeline backpressure
- High transaction load
- State sync operations

For the channel to fill (1,024 entries), consensus would need to process timeouts slower than rounds progress. While each round aborts previous timeouts [7](#0-6) , rapid round progression can cause multiple timeout futures to be in-flight simultaneously, attempting to send to the bounded channel.

## Recommendation

Implement one of these mitigations:

**Option 1: Use Unbounded Channel for Timeouts**
```rust
let (timeout_sender, timeout_receiver) =
    aptos_channels::new_unbounded(&counters::PENDING_ROUND_TIMEOUTS);
```
Since timeouts are rate-limited by round progression and old ones are aborted, unbounded is safe.

**Option 2: Non-blocking Send with Error Handling**
Modify `SendTask` to use `try_send()` instead of async `send()`:
```rust
fn run(&mut self) -> Pin<Box<dyn Future<Output = ()> + Send>> {
    let mut sender = self.sender.take().expect("...");
    let message = self.message.take().expect("...");
    let r = async move {
        if let Err(e) = sender.try_send(message) {
            warn!("Timeout send failed (channel full): {:?}", e);
            counters::TIMEOUT_SEND_FAILURES.inc();
        }
    };
    r.boxed()
}
```

**Option 3: Add Timeout to Send Operation**
Wrap the send in a timeout to prevent indefinite blocking:
```rust
use tokio::time::{timeout, Duration};

let r = async move {
    match timeout(Duration::from_millis(100), sender.send(message)).await {
        Ok(Ok(())) => {},
        Ok(Err(e)) => error!("Timeout send error: {:?}", e),
        Err(_) => warn!("Timeout send timed out (channel backpressure)"),
    }
};
```

**Recommended**: Option 1 (unbounded channel) is safest given the natural rate limiting.

## Proof of Concept

```rust
// Add to consensus/src/util/time_service.rs tests
#[tokio::test]
async fn test_timeout_channel_backpressure() {
    use futures::StreamExt;
    
    // Create small channel to demonstrate issue
    let (tx, mut rx) = aptos_channels::new(2, &counters::PENDING_ROUND_TIMEOUTS);
    let time_service = ClockTimeService::new(tokio::runtime::Handle::current());
    
    // Fill channel
    tx.send(1u64).await.unwrap();
    tx.send(2u64).await.unwrap();
    
    // Schedule timeout that will block trying to send
    let task = SendTask::make(tx.clone(), 3u64);
    let _handle = time_service.run_after(Duration::from_millis(10), task);
    
    // Wait for timeout to fire
    tokio::time::sleep(Duration::from_millis(50)).await;
    
    // Verify channel is still full (send is blocked)
    assert_eq!(rx.next().await, Some(1));
    assert_eq!(rx.next().await, Some(2));
    
    // Now the blocked send should complete
    tokio::time::sleep(Duration::from_millis(10)).await;
    assert_eq!(rx.next().await, Some(3));
}
```

This test demonstrates that when the channel is full, the timeout task's send operation blocks until space becomes available, holding executor resources during the wait.

### Citations

**File:** consensus/src/util/time_service.rs (L51-52)
```rust
    /// It is expected that this function is lightweight and does not take long time to complete
    fn run(&mut self) -> Pin<Box<dyn Future<Output = ()> + Send>>;
```

**File:** consensus/src/util/time_service.rs (L81-96)
```rust
    fn run(&mut self) -> Pin<Box<dyn Future<Output = ()> + Send>> {
        let mut sender = self
            .sender
            .take()
            .expect("Expect to be able to take sender");
        let message = self
            .message
            .take()
            .expect("Expect to be able to take message");
        let r = async move {
            if let Err(e) = sender.send(message).await {
                error!("Error on send: {:?}", e);
            };
        };
        r.boxed()
    }
```

**File:** consensus/src/consensus_provider.rs (L56-56)
```rust
    let runtime = aptos_runtimes::spawn_named_runtime("consensus".into(), None);
```

**File:** consensus/src/consensus_provider.rs (L74-74)
```rust
    let time_service = Arc::new(ClockTimeService::new(runtime.handle().clone()));
```

**File:** consensus/src/consensus_provider.rs (L76-77)
```rust
    let (timeout_sender, timeout_receiver) =
        aptos_channels::new(1_024, &counters::PENDING_ROUND_TIMEOUTS);
```

**File:** crates/channel/src/lib.rs (L119-121)
```rust
pub fn new<T>(size: usize, gauge: &IntGauge) -> (Sender<T>, Receiver<T>) {
    gauge.set(0);
    let (sender, receiver) = mpsc::channel(size);
```

**File:** consensus/src/liveness/round_state.rs (L350-352)
```rust
        if let Some(handle) = self.abort_handle.replace(abort_handle) {
            handle.abort();
        }
```
