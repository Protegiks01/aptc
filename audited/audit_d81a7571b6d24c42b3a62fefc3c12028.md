# Audit Report

## Title
Sharding Configuration Mismatch in Database Truncation Causes Silent Data Corruption

## Summary
The database truncation tool accepts a user-provided sharding configuration flag that determines how to open and truncate the database. When this flag does not match the actual physical database structure on disk, the truncation operation silently fails to delete data from the majority of shards, leaving stale data that violates state consistency guarantees and can cause consensus divergence.

## Finding Description

The vulnerability exists in the database truncation command implementation. The truncate command accepts a `sharding_config` parameter via command-line arguments that controls whether the database should be opened and processed in sharded mode. [1](#0-0) 

When `enable_storage_sharding` is false, the `StateKvDb::new()` function returns early with all shard references pointing to the ledger database and sets `enabled_sharding: false`. [2](#0-1) 

During truncation, the system calls `truncate_state_kv_db_shards()` which iterates over `state_kv_db.hack_num_real_shards()` to determine how many shards to process. [3](#0-2) 

The `hack_num_real_shards()` method returns 1 when `enabled_sharding` is false, or 16 when true. [4](#0-3) 

**Attack Scenario:**
1. A production database exists with 16 physical shard directories (created with `enable_storage_sharding=true`)
2. An operator runs the truncate command: `truncate --db-dir /path/to/db --target-version 500 --opt-out-backup-checkpoint`
3. The operator forgets or is unaware of the need to specify `--enable-storage-sharding`
4. The truncation opens the database with `enable_storage_sharding=false`
5. Only 1 "shard" (the ledger database) is processed for truncation
6. The 16 physical shard directories on disk are NOT truncated
7. Metadata is updated to indicate truncation succeeded to version 500
8. Physical shard data from version 501-1000 remains on disk
9. When the node restarts with correct sharding configuration, it reads stale data from shards

This breaks the **State Consistency** invariant because the database metadata claims data has been truncated while physical storage contains stale data.

## Impact Explanation

This vulnerability qualifies as **Critical Severity** per the Aptos bug bounty criteria because it causes:

1. **State inconsistencies requiring intervention** (Medium severity baseline)
2. **Potential Consensus/Safety violations** (Critical severity) - When nodes restart after incomplete truncation, they may diverge on state, leading to consensus failures
3. **Silent data corruption** - No error is raised, making the issue difficult to detect

The impact is particularly severe because:
- Mainnet and testnet use sharded storage by default
- The truncation tool is used for emergency recovery and database maintenance
- Operators may not be aware of the sharding configuration requirement
- The database appears to truncate successfully while remaining corrupted
- Multiple nodes affected by this could fork from the correct chain

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to occur because:

1. **Default behavior is unsafe**: The `enable_storage_sharding` flag defaults to false if not specified [5](#0-4) 
2. **No validation**: There is no check to verify the provided configuration matches the actual database structure
3. **Silent failure**: No error or warning is raised when sharding configuration is mismatched
4. **Operational complexity**: Node operators may not be familiar with internal storage sharding details
5. **Emergency usage**: The truncate tool is often used during incidents when operators are under time pressure

## Recommendation

Implement validation to ensure the sharding configuration matches the actual database structure before performing truncation. The fix should:

1. **Detect actual database structure**: Check for the existence of shard directories on disk
2. **Validate configuration match**: Compare detected structure with provided configuration
3. **Fail safely**: Return an error if mismatch is detected
4. **Provide clear error message**: Guide operators to use correct configuration

**Suggested Implementation:**

Add validation in `Cmd::run()` before opening the database:

```rust
// In storage/aptosdb/src/db_debugger/truncate/mod.rs
pub fn run(self) -> Result<()> {
    // Validate sharding configuration matches actual database
    let actual_sharding = detect_database_sharding(&self.db_dir)?;
    if actual_sharding != self.sharding_config.enable_storage_sharding {
        return Err(AptosDbError::Other(format!(
            "Sharding configuration mismatch: database is {} but --enable-storage-sharding is {}. \
            Physical database structure: {}. Please specify the correct sharding flag.",
            if actual_sharding { "sharded" } else { "non-sharded" },
            if self.sharding_config.enable_storage_sharding { "true" } else { "false" },
            if actual_sharding { "16 shard directories exist" } else { "single database" }
        )));
    }
    // ... rest of existing code
}

fn detect_database_sharding(db_dir: &PathBuf) -> Result<bool> {
    // Check if state_kv_db shard directories exist
    let shard_0_path = db_dir.join("state_kv_db").join("shard_0");
    Ok(shard_0_path.exists())
}
```

## Proof of Concept

```rust
#[test]
fn test_sharding_mismatch_vulnerability() {
    use aptos_temppath::TempPath;
    use aptos_config::config::DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD;
    
    let tmp_dir = TempPath::new();
    
    // Step 1: Create a SHARDED database with data up to version 100
    let db = AptosDB::new_for_test_with_sharding(&tmp_dir, DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD);
    
    // Create test transactions
    let (blocks, _) = arb_blocks_to_commit_with_block_nums(100, 101).new_tree(&mut Default::default()).current();
    for (txns_to_commit, ledger_info_with_sigs) in blocks.iter() {
        db.save_transactions_for_test(txns_to_commit, 0, Some(ledger_info_with_sigs), true).unwrap();
    }
    
    let original_version = db.expect_synced_version();
    assert_eq!(original_version, 99);
    drop(db);
    
    // Step 2: Run truncate with MISMATCHED config (non-sharded on sharded DB)
    let cmd = Cmd {
        db_dir: tmp_dir.path().to_path_buf(),
        target_version: 50,
        ledger_db_batch_size: 15,
        opt_out_backup_checkpoint: true,
        backup_checkpoint_dir: None,
        sharding_config: ShardingConfig {
            enable_storage_sharding: false, // WRONG! DB is actually sharded
        },
    };
    
    cmd.run().unwrap(); // Should fail but doesn't
    
    // Step 3: Reopen with CORRECT sharding config and verify corruption
    let db = AptosDB::new_for_test_with_sharding(&tmp_dir, DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD);
    
    // Step 4: Check physical shards - they should be truncated but AREN'T
    let (_, _, _, state_kv_db) = AptosDB::open_dbs(
        &StorageDirPaths::from_path(tmp_dir.path()),
        RocksdbConfigs {
            enable_storage_sharding: true, // Correct config
            ..Default::default()
        },
        None,
        None,
        false,
        0,
        true,
    ).unwrap();
    
    // Verify stale data exists in physical shards
    for shard_id in 0..NUM_STATE_SHARDS {
        let mut iter = state_kv_db.db_shard(shard_id).iter::<StateValueByKeyHashSchema>().unwrap();
        iter.seek_to_first();
        
        let mut found_stale_data = false;
        for item in iter {
            let ((_, version), _) = item.unwrap();
            if version > 50 {
                found_stale_data = true;
                println!("VULNERABILITY: Found stale data at version {} in shard {}", version, shard_id);
                break;
            }
        }
        
        // This assertion SHOULD fail, proving the vulnerability
        assert!(found_stale_data, "Shard {} contains stale data that should have been truncated", shard_id);
    }
}
```

## Notes

This vulnerability affects any production deployment using sharded storage (which includes mainnet and testnet). The database debugger truncate tool is a critical operational tool used for emergency recovery, making this a high-priority fix. The recommended solution adds minimal overhead while preventing silent data corruption that could lead to consensus failures across the network.

### Citations

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L43-44)
```rust
    #[clap(flatten)]
    sharding_config: ShardingConfig,
```

**File:** storage/aptosdb/src/state_kv_db.rs (L62-70)
```rust
        let sharding = rocksdb_configs.enable_storage_sharding;
        if !sharding {
            info!("State K/V DB is not enabled!");
            return Ok(Self {
                state_kv_metadata_db: Arc::clone(&ledger_db),
                state_kv_db_shards: arr![Arc::clone(&ledger_db); 16],
                hot_state_kv_db_shards: None,
                enabled_sharding: false,
            });
```

**File:** storage/aptosdb/src/state_kv_db.rs (L285-291)
```rust
    pub(crate) fn hack_num_real_shards(&self) -> usize {
        if self.enabled_sharding {
            NUM_STATE_SHARDS
        } else {
            1
        }
    }
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L118-127)
```rust
pub(crate) fn truncate_state_kv_db_shards(
    state_kv_db: &StateKvDb,
    target_version: Version,
) -> Result<()> {
    (0..state_kv_db.hack_num_real_shards())
        .into_par_iter()
        .try_for_each(|shard_id| {
            truncate_state_kv_db_single_shard(state_kv_db, shard_id, target_version)
        })
}
```

**File:** storage/aptosdb/src/db_debugger/mod.rs (L17-21)
```rust
#[derive(Parser, Clone)]
pub struct ShardingConfig {
    #[clap(long)]
    enable_storage_sharding: bool,
}
```
