# Audit Report

## Title
Lack of Transaction Priority in Validator Transaction Pool Enables Delayed JWK Security Updates

## Summary
The validator transaction pool operates as a strict FIFO queue with no priority mechanism, allowing security-critical JWK (JSON Web Key) updates to be delayed behind less time-sensitive transactions such as DKG results. This design limitation can prevent timely responses to key compromise incidents.

## Finding Description

The `process_quorum_certified_update()` function in the JWK consensus manager submits quorum-certified JWK updates to the validator transaction pool using `vtxn_pool.put()` with `None` as the third parameter [1](#0-0) .

The third parameter is a `pull_notification_tx` channel for notifications, **not** a priority indicator [2](#0-1) . The validator transaction pool has no priority mechanism whatsoever—all transactions are queued in strict FIFO order based on insertion sequence numbers [3](#0-2) .

When transactions are pulled from the pool, they are retrieved in sequence number order (FIFO) [4](#0-3) . The consensus system pulls validator transactions with strict per-block limits—by default only 2 transactions per block [5](#0-4) .

Both DKG transactions and JWK updates compete for these same 2 slots per block [6](#0-5) . If DKG transactions arrive first, JWK updates queue behind them [7](#0-6) .

**Attack Scenario:**
1. Multiple DKG transactions enter the pool during epoch transition
2. A security incident requires urgent JWK key rotation for a compromised issuer
3. The JWK update enters the pool but queues behind DKG transactions
4. With only 2 validator transactions per block, the JWK update is delayed by multiple blocks (potentially minutes)
5. Compromised keys remain active longer than necessary

Multiple OIDC issuers can have concurrent JWK updates that all queue behind each other [8](#0-7) , amplifying the delay.

## Impact Explanation

This is a **Medium severity** issue per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Delayed key updates leave the authentication system in an inconsistent security state
- **Limited security impact**: While this doesn't cause direct fund loss, it prevents timely security responses
- **Authentication security**: JWK updates control authentication keys for the entire chain

The impact is not Critical/High because:
- No direct fund theft or consensus safety violation
- The system eventually processes all updates
- Most key rotations are planned, not emergency responses

However, in incident response scenarios (e.g., suspected key compromise), delays of multiple blocks can be significant.

## Likelihood Explanation

**Moderate likelihood:**
- Occurs naturally during epoch transitions when DKG and JWK updates coincide
- Multiple OIDC providers updating simultaneously increases queue depth
- No attacker control required—this is a design limitation affecting normal operations
- Becomes more likely as the number of supported OIDC providers grows

While not directly exploitable by unprivileged attackers, the issue affects the system's ability to respond to security incidents, which is a realistic operational concern.

## Recommendation

Implement a priority-aware validator transaction pool:

1. **Add priority field to validator transactions:**
```rust
pub enum ValidatorTxnPriority {
    High,    // For security-critical updates (JWK key rotations)
    Normal,  // For routine updates (DKG results)
}
```

2. **Modify pool to support priority queues:**
```rust
struct PoolStateInner {
    next_seq_num: u64,
    seq_nums_by_topic: HashMap<Topic, u64>,
    high_priority_queue: BTreeMap<u64, PoolItem>,
    normal_priority_queue: BTreeMap<u64, PoolItem>,
}
```

3. **Update pull logic to prioritize high-priority transactions:**
```rust
fn pull(&mut self, ...) -> Vec<ValidatorTransaction> {
    // First pull from high_priority_queue
    // Then fill remaining capacity from normal_priority_queue
}
```

4. **Mark JWK updates as high priority:**
```rust
let vtxn_guard = self.vtxn_pool.put(
    Topic::JWK_CONSENSUS(issuer.clone()),
    Arc::new(txn),
    None,
    ValidatorTxnPriority::High  // Add priority parameter
);
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_jwk_delayed_by_dkg() {
    use aptos_types::validator_txn::{ValidatorTransaction, Topic};
    use aptos_validator_transaction_pool::VTxnPoolState;
    use std::sync::Arc;
    
    let pool = VTxnPoolState::default();
    
    // Simulate DKG transactions entering pool first
    let dkg_txn1 = ValidatorTransaction::dummy(b"dkg1".to_vec());
    let dkg_txn2 = ValidatorTransaction::dummy(b"dkg2".to_vec());
    let _guard1 = pool.put(Topic::DKG, Arc::new(dkg_txn1), None);
    let _guard2 = pool.put(Topic::DKG, Arc::new(dkg_txn2), None);
    
    // Critical JWK update arrives
    let jwk_txn = ValidatorTransaction::ObservedJWKUpdate(/* urgent key rotation */);
    let _guard3 = pool.put(
        Topic::JWK_CONSENSUS(b"critical_issuer".to_vec()),
        Arc::new(jwk_txn),
        None
    );
    
    // Pull with per-block limit of 2 transactions
    let filter = aptos_validator_transaction_pool::TransactionFilter::empty();
    let pulled = pool.pull(
        std::time::Instant::now() + std::time::Duration::from_secs(1),
        2,  // max 2 transactions per block
        2097152,
        filter
    );
    
    // Verify: DKG transactions are pulled first, JWK delayed to next block
    assert_eq!(pulled.len(), 2);
    assert!(matches!(pulled[0], ValidatorTransaction::DKGResult(_)));
    assert!(matches!(pulled[1], ValidatorTransaction::DKGResult(_)));
    // JWK update must wait for next block despite being security-critical
}
```

## Notes

This finding represents a **design limitation** in the validator transaction pool architecture rather than a traditional implementation bug. The FIFO queue was likely chosen for simplicity, but the lack of priority differentiation between routine operations (DKG) and security-critical updates (JWK key rotations) creates operational risk during incident response scenarios.

The issue is particularly relevant as Aptos scales to support more OIDC providers, increasing the likelihood of concurrent JWK updates that queue behind each other. While the current 2-transaction-per-block limit is configurable on-chain, increasing it doesn't solve the fundamental priority problem.

### Citations

**File:** crates/aptos-jwk-consensus/src/jwk_manager/mod.rs (L336-338)
```rust
                let vtxn_guard =
                    self.vtxn_pool
                        .put(Topic::JWK_CONSENSUS(issuer.clone()), Arc::new(txn), None);
```

**File:** crates/validator-transaction-pool/src/lib.rs (L56-82)
```rust
    /// Append a txn to the pool.
    /// Return a txn guard that allows you to later delete the txn from the pool.
    pub fn put(
        &self,
        topic: Topic,
        txn: Arc<ValidatorTransaction>,
        pull_notification_tx: Option<aptos_channel::Sender<(), Arc<ValidatorTransaction>>>,
    ) -> TxnGuard {
        let mut pool = self.inner.lock();
        let seq_num = pool.next_seq_num;
        pool.next_seq_num += 1;

        pool.txn_queue.insert(seq_num, PoolItem {
            topic: topic.clone(),
            txn,
            pull_notification_tx,
        });

        if let Some(old_seq_num) = pool.seq_nums_by_topic.insert(topic.clone(), seq_num) {
            pool.txn_queue.remove(&old_seq_num);
        }

        TxnGuard {
            pool: self.inner.clone(),
            seq_num,
        }
    }
```

**File:** crates/validator-transaction-pool/src/lib.rs (L114-124)
```rust
pub struct PoolStateInner {
    /// Incremented every time a txn is pushed in. The txn gets the old value as its sequence number.
    next_seq_num: u64,

    /// Track Topic -> seq_num mapping.
    /// We allow only 1 txn per topic and this index helps find the old txn when adding a new one for the same topic.
    seq_nums_by_topic: HashMap<Topic, u64>,

    /// Txns ordered by their sequence numbers (i.e. time they entered the pool).
    txn_queue: BTreeMap<u64, PoolItem>,
}
```

**File:** crates/validator-transaction-pool/src/lib.rs (L152-199)
```rust
    pub fn pull(
        &mut self,
        deadline: Instant,
        mut max_items: u64,
        mut max_bytes: u64,
        filter: TransactionFilter,
    ) -> Vec<ValidatorTransaction> {
        let mut ret = vec![];
        let mut seq_num_lower_bound = 0;

        // Check deadline at the end of every iteration to ensure validator txns get a chance no matter what current proposal delay is.
        while max_items >= 1 && max_bytes >= 1 {
            // Find the seq_num of the first txn that satisfies the quota.
            if let Some(seq_num) = self
                .txn_queue
                .range(seq_num_lower_bound..)
                .filter(|(_, item)| {
                    item.txn.size_in_bytes() as u64 <= max_bytes
                        && !filter.should_exclude(&item.txn)
                })
                .map(|(seq_num, _)| *seq_num)
                .next()
            {
                // Update the quota usage.
                // Send the pull notification if requested.
                let PoolItem {
                    txn,
                    pull_notification_tx,
                    ..
                } = self.txn_queue.get(&seq_num).unwrap();
                if let Some(tx) = pull_notification_tx {
                    let _ = tx.push((), txn.clone());
                }
                max_items -= 1;
                max_bytes -= txn.size_in_bytes() as u64;
                seq_num_lower_bound = seq_num + 1;
                ret.push(txn.as_ref().clone());

                if Instant::now() >= deadline {
                    break;
                }
            } else {
                break;
            }
        }

        ret
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L125-126)
```rust
const VTXN_CONFIG_PER_BLOCK_LIMIT_TXN_COUNT_DEFAULT: u64 = 2;
const VTXN_CONFIG_PER_BLOCK_LIMIT_TOTAL_BYTES_DEFAULT: u64 = 2097152; //2MB
```

**File:** types/src/validator_txn.rs (L14-18)
```rust
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, CryptoHasher, BCSCryptoHash)]
pub enum ValidatorTransaction {
    DKGResult(DKGTranscript),
    ObservedJWKUpdate(jwks::QuorumCertifiedUpdate),
}
```

**File:** types/src/validator_txn.rs (L55-64)
```rust
#[derive(Clone, Debug, Eq, Hash, PartialEq)]
#[allow(non_camel_case_types)]
pub enum Topic {
    DKG,
    JWK_CONSENSUS(jwks::Issuer),
    JWK_CONSENSUS_PER_KEY_MODE {
        issuer: jwks::Issuer,
        kid: jwks::KID,
    },
}
```

**File:** consensus/src/payload_client/mixed.rs (L65-79)
```rust
        let mut validator_txns = self
            .validator_txn_pool_client
            .pull(
                params.max_poll_time,
                min(
                    params.max_txns.count(),
                    self.validator_txn_config.per_block_limit_txn_count(),
                ),
                min(
                    params.max_txns.size_in_bytes(),
                    self.validator_txn_config.per_block_limit_total_bytes(),
                ),
                validator_txn_filter,
            )
            .await;
```
