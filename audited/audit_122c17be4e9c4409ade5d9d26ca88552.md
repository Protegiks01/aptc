# Audit Report

## Title
Consensus Observer Queue Corruption via Duplicate Round Blocks Leading to Randomness Generation Denial of Service

## Summary
The `BlockQueue::push_back()` function in the randomness generation module accepts `QueueItem` without validating that blocks have unique rounds. When blocks with duplicate rounds are inserted, the queue enters a corrupted state where `num_undecided_blocks` can never reach zero, permanently blocking randomness generation and causing observer node failure.

## Finding Description

The vulnerability exists in the consensus observer's ordered block validation and randomness generation queue management. The attack chain is as follows:

1. **Validation Gap**: When consensus observers receive `OrderedBlock` messages from the network, the `verify_ordered_blocks()` method validates block chaining but does not enforce round uniqueness constraints. [1](#0-0) 

The validation only checks: (a) non-empty blocks, (b) last block ID matches proof, and (c) parent-child ID chaining. It does NOT validate that `child.round() > parent.round()`, unlike the `Block::verify_well_formed()` method used in normal consensus. [2](#0-1) 

2. **Queue Corruption**: When `QueueItem::new()` processes blocks with duplicate rounds, it creates a HashMap `offsets_by_round` where duplicate rounds overwrite each other (HashMap semantics keep only the last occurrence). [3](#0-2) 

If blocks contain rounds [1, 2, 2, 3]:
- `offsets_by_round` = {1: 0, 2: 2, 3: 3} (only 3 entries, missing the first round-2 block)
- `num_undecided_blocks` = 4 (all blocks)

3. **Permanent Stall**: The `set_randomness()` function can only update blocks present in `offsets_by_round`. Blocks at indexes not mapped become unreachable. [4](#0-3) 

Since one block with round 2 (at index 1) is not in `offsets_by_round`, calling `set_randomness(2, ...)` only updates index 2. The block at index 1 never receives randomness, so `num_undecided_blocks` can never decrement to zero.

4. **Dequeue Failure**: The `dequeue_rand_ready_prefix()` function only removes items where `num_undecided() == 0`, so the corrupted item remains stuck permanently. [5](#0-4) 

5. **Attack Vector**: A malicious or compromised consensus publisher constructs an `OrderedBlock` with duplicate rounds but valid parent-child chaining, bypassing `verify_ordered_blocks()` but causing queue corruption when processed by observers. [6](#0-5) 

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This vulnerability causes **state inconsistencies requiring intervention** in consensus observer nodes:

1. **Observer Liveness Failure**: Affected observers cannot process randomness for subsequent blocks, halting their ability to follow the chain beyond the corrupted block batch
2. **Partial Network Impact**: If multiple observers subscribe to a compromised publisher, they all become stuck simultaneously
3. **Manual Recovery Required**: The queue corruption is permanent; nodes require restart and state reset to recover
4. **Observer Ecosystem Damage**: Impacts services relying on observers (indexers, APIs, analytics) causing downstream failures

This does not reach Critical severity because:
- It affects observers, not consensus validators (no safety violation)
- It does not cause fund loss or permanent network partition
- Validators continue operating normally

However, it exceeds Low severity due to:
- Clear DoS impact on critical infrastructure
- Requires manual intervention for recovery
- Can affect multiple nodes simultaneously

## Likelihood Explanation

**Likelihood: Low-to-Medium**

**Requirements for exploitation:**
1. Attacker must be a malicious consensus publisher (validator) OR exploit a separate vulnerability allowing message injection
2. Attacker must construct blocks with duplicate rounds that pass ID chaining validation
3. Observers must be subscribed to the malicious publisher
4. Randomness generation must be enabled on observers

**Mitigating factors:**
- Assumes Byzantine validator behavior (but BFT should tolerate up to 1/3)
- Subscription mechanism limits blast radius
- Honest validators would not send such messages

**Aggravating factors:**
- Once triggered, impact is immediate and permanent
- No runtime detection or alerting for this condition
- Simple to construct exploit (just duplicate round values)
- Could be triggered accidentally by consensus bugs

The likelihood is elevated from Low because Byzantine fault tolerance assumptions should include validator misbehavior, and the validation gap represents a clear defense-in-depth failure.

## Recommendation

**Add round uniqueness validation to `verify_ordered_blocks()`:**

```rust
pub fn verify_ordered_blocks(&self) -> Result<(), Error> {
    // Existing validations...
    
    // NEW: Verify blocks have strictly increasing rounds
    let mut prev_round: Option<Round> = None;
    for block in &self.blocks {
        let current_round = block.round();
        if let Some(prev) = prev_round {
            if current_round <= prev {
                return Err(Error::InvalidMessageError(
                    format!(
                        "Blocks do not have strictly increasing rounds! Previous round: {}, Current round: {}",
                        prev, current_round
                    )
                ));
            }
        }
        prev_round = Some(current_round);
    }
    
    Ok(())
}
```

**Alternative: Add validation in `QueueItem::new()`:**

```rust
pub fn new(ordered_blocks: OrderedBlocks, broadcast_handle: Option<Vec<DropGuard>>) -> Self {
    let len = ordered_blocks.ordered_blocks.len();
    assert!(len > 0);
    let offsets_by_round: HashMap<Round, usize> = ordered_blocks
        .ordered_blocks
        .iter()
        .enumerate()
        .map(|(idx, b)| (b.round(), idx))
        .collect();
    
    // NEW: Detect duplicate rounds
    assert_eq!(
        offsets_by_round.len(),
        len,
        "QueueItem created with duplicate rounds: {} blocks but {} unique rounds",
        len,
        offsets_by_round.len()
    );
    
    Self {
        ordered_blocks,
        offsets_by_round,
        num_undecided_blocks: len,
        broadcast_handle,
    }
}
```

The first approach (network validation) is preferred as it prevents malformed data from entering the system.

## Proof of Concept

```rust
#[cfg(test)]
mod exploit_test {
    use super::*;
    use crate::rand::rand_gen::test_utils::create_ordered_blocks;
    use aptos_types::randomness::Randomness;

    #[test]
    #[should_panic(expected = "can never reach zero")]
    fn test_duplicate_rounds_cause_permanent_queue_corruption() {
        let mut queue = BlockQueue::new();
        
        // Attacker sends OrderedBlock with duplicate round 2
        // This would pass verify_ordered_blocks() if blocks are properly chained
        let rounds_with_duplicate = vec![1, 2, 2, 3];
        let malicious_item = QueueItem::new(
            create_ordered_blocks(rounds_with_duplicate), 
            None
        );
        
        // Verify the corruption: offsets_by_round has only 3 entries for 4 blocks
        assert_eq!(malicious_item.num_blocks(), 4);
        assert_eq!(malicious_item.offsets_by_round.len(), 3); // Only {1, 2, 3}
        assert_eq!(malicious_item.num_undecided(), 4);
        
        queue.push_back(malicious_item);
        
        // Try to set randomness for all rounds
        assert!(queue.set_randomness(1, Randomness::default()));
        assert!(queue.set_randomness(2, Randomness::default())); // Only updates index 2
        assert!(queue.set_randomness(3, Randomness::default()));
        
        // Block at index 1 (also round 2) never received randomness
        // num_undecided is now 1, can never reach 0
        let item = queue.queue.values().next().unwrap();
        assert_eq!(item.num_undecided(), 1, "Queue stuck with 1 undecided block");
        
        // Dequeue attempt fails - queue permanently blocked
        let dequeued = queue.dequeue_rand_ready_prefix();
        assert_eq!(dequeued.len(), 0, "Cannot dequeue corrupted item");
        
        panic!("Queue can never reach zero undecided blocks - permanent DoS");
    }
}
```

This PoC demonstrates that duplicate rounds create an unrecoverable queue state where blocks remain permanently stuck, blocking the randomness generation pipeline.

## Notes

The vulnerability represents a **defense-in-depth failure** where network message validation relies solely on block ID chaining without enforcing consensus round invariants. While the current subscription model limits exposure to trusted validators, Byzantine fault tolerance principles require resilience against up to 1/3 malicious validators. The lack of round validation in `verify_ordered_blocks()` violates this principle and creates an exploitable DoS vector against observer infrastructure.

### Citations

**File:** consensus/src/consensus_observer/network/observer_message.rs (L227-266)
```rust
    pub fn verify_ordered_blocks(&self) -> Result<(), Error> {
        // Verify that we have at least one ordered block
        if self.blocks.is_empty() {
            return Err(Error::InvalidMessageError(
                "Received empty ordered block!".to_string(),
            ));
        }

        // Verify the last block ID matches the ordered proof block ID
        if self.last_block().id() != self.proof_block_info().id() {
            return Err(Error::InvalidMessageError(
                format!(
                    "Last ordered block ID does not match the ordered proof ID! Number of blocks: {:?}, Last ordered block ID: {:?}, Ordered proof ID: {:?}",
                    self.blocks.len(),
                    self.last_block().id(),
                    self.proof_block_info().id()
                )
            ));
        }

        // Verify the blocks are correctly chained together (from the last block to the first)
        let mut expected_parent_id = None;
        for block in self.blocks.iter().rev() {
            if let Some(expected_parent_id) = expected_parent_id {
                if block.id() != expected_parent_id {
                    return Err(Error::InvalidMessageError(
                        format!(
                            "Block parent ID does not match the expected parent ID! Block ID: {:?}, Expected parent ID: {:?}",
                            block.id(),
                            expected_parent_id
                        )
                    ));
                }
            }

            expected_parent_id = Some(block.parent_id());
        }

        Ok(())
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L287-301)
```rust
        if let Err(error) = self
            .execution_client
            .finalize_order(
                ordered_block.blocks().clone(),
                WrappedLedgerInfo::new(VoteData::dummy(), ordered_block.ordered_proof().clone()),
            )
            .await
        {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to finalize ordered block! Error: {:?}",
                    error
                ))
            );
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L658-671)
```rust
        // Verify the ordered blocks before processing
        if let Err(error) = ordered_block.verify_ordered_blocks() {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify ordered blocks! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                    ordered_block.proof_block_info(),
                    peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        };
```

**File:** consensus/src/rand/rand_gen/block_queue.rs (L25-40)
```rust
    pub fn new(ordered_blocks: OrderedBlocks, broadcast_handle: Option<Vec<DropGuard>>) -> Self {
        let len = ordered_blocks.ordered_blocks.len();
        assert!(len > 0);
        let offsets_by_round: HashMap<Round, usize> = ordered_blocks
            .ordered_blocks
            .iter()
            .enumerate()
            .map(|(idx, b)| (b.round(), idx))
            .collect();
        Self {
            ordered_blocks,
            offsets_by_round,
            num_undecided_blocks: len,
            broadcast_handle,
        }
    }
```

**File:** consensus/src/rand/rand_gen/block_queue.rs (L69-82)
```rust
    pub fn set_randomness(&mut self, round: Round, rand: Randomness) -> bool {
        let offset = self.offset(round);
        if !self.blocks()[offset].has_randomness() {
            observe_block(
                self.blocks()[offset].timestamp_usecs(),
                BlockStage::RAND_ADD_DECISION,
            );
            self.blocks_mut()[offset].set_randomness(rand);
            self.num_undecided_blocks -= 1;
            true
        } else {
            false
        }
    }
```

**File:** consensus/src/rand/rand_gen/block_queue.rs (L118-137)
```rust
    pub fn dequeue_rand_ready_prefix(&mut self) -> Vec<OrderedBlocks> {
        let mut rand_ready_prefix = vec![];
        while let Some((_starting_round, item)) = self.queue.first_key_value() {
            if item.num_undecided() == 0 {
                let (_, item) = self.queue.pop_first().unwrap();
                for block in item.blocks() {
                    observe_block(block.timestamp_usecs(), BlockStage::RAND_READY);
                }
                let QueueItem { ordered_blocks, .. } = item;
                debug_assert!(ordered_blocks
                    .ordered_blocks
                    .iter()
                    .all(|block| block.has_randomness()));
                rand_ready_prefix.push(ordered_blocks);
            } else {
                break;
            }
        }
        rand_ready_prefix
    }
```
