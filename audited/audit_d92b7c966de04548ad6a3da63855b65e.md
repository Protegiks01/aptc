# Audit Report

## Title
Stale Connection State Updates Can Corrupt Peer Metadata During Simultaneous Dial Scenarios

## Summary
The `update_connection_state()` method in `PeersAndMetadata` does not verify connection IDs when updating peer connection states, allowing stale state updates from old connections to overwrite the state of new connections during simultaneous dial or rapid reconnection scenarios. This creates inconsistent state where a peer exists in `active_peers` (indicating it's connected) but is marked as `Disconnecting` or `Disconnected` in the peer metadata, causing applications to incorrectly exclude active peers from message delivery.

## Finding Description

The Aptos network framework maintains peer connection state in two separate layers:

1. **PeerManager layer**: `active_peers` HashMap tracking active connections [1](#0-0) 

2. **Application metadata layer**: `ConnectionState` enum (Connected, Disconnecting, Disconnected) stored in `PeersAndMetadata` [2](#0-1) 

When a peer connection is being torn down, the health checker or disconnect logic calls `update_connection_state()` to mark the peer as `Disconnecting` before the actual disconnect completes. However, this method has a critical flaw - it does not validate that it's updating state for the correct connection: [3](#0-2) 

Notice that `update_connection_state()` takes only `peer_network_id` and `connection_state` as parameters, with no `connection_id` verification. This contrasts with `remove_peer_metadata()`, which correctly validates connection IDs: [4](#0-3) 

**Exploitation Scenario:**

1. Validator A has an active connection to Validator B (connection_id=100)
2. Network health checker detects slow response and initiates disconnect sequence
3. Health checker calls `update_connection_state(peer_A, Disconnecting)` for connection_id=100
4. Before the state update completes, a simultaneous dial occurs and connection_id=101 is established
5. PeerManager's `add_peer()` handles simultaneous dial tie-breaking, replaces old connection with new one [5](#0-4) 
6. New connection calls `insert_connection_metadata()` which sets state to `Connected` [6](#0-5) 
7. The delayed `update_connection_state(peer_A, Disconnecting)` from step 3 now executes
8. **Result**: Peer A has connection_id=101 in `active_peers` but `ConnectionState::Disconnecting` in metadata

This inconsistent state causes critical issues:

**Impact on Consensus Observer System:**

The consensus publisher uses `get_connected_peers_and_metadata()` to identify active subscribers for consensus message broadcasting: [7](#0-6) 

The `is_connected()` check filters out peers in `Disconnecting` state: [8](#0-7) 

This means an active validator connection will be incorrectly removed from the active subscribers list, preventing consensus update delivery.

**Impact on Application Layer:**

Applications calling `get_available_peers()` will exclude the affected peer: [9](#0-8) 

## Impact Explanation

This vulnerability meets **High Severity** criteria per the Aptos bug bounty program:

1. **Validator Node Issues**: Active validator connections can be incorrectly excluded from message delivery, potentially causing validators to miss consensus updates, block proposals, or state synchronization messages.

2. **Significant Protocol Violations**: The vulnerability violates the network layer's state consistency invariant - the peer metadata should accurately reflect the actual connection state maintained in `active_peers`.

3. **State Inconsistencies**: Creates a split-brain scenario where the PeerManager believes a peer is connected (it's in `active_peers`) but applications believe the peer is disconnecting (based on metadata state).

While this doesn't directly cause consensus safety violations (validators can still communicate through existing channels), it degrades network reliability and could contribute to liveness issues if multiple validators are affected simultaneously during network instability.

## Likelihood Explanation

This vulnerability is **highly likely** to occur in production environments:

1. **Simultaneous Dial Scenarios Are Common**: The codebase includes explicit tie-breaking logic for simultaneous dials, indicating this is a known and frequent occurrence [10](#0-9) 

2. **Network Instability Triggers Reconnections**: Validators experiencing network latency or packet loss will trigger health check failures, initiating disconnect sequences that can race with automatic reconnection attempts.

3. **No Protection Against Stale Updates**: There is no timestamp, sequence number, or connection ID verification to prevent stale state updates from being applied.

4. **Wide Attack Window**: The race window extends from when `update_connection_state()` is called until the peer is actually removed from `active_peers`, which could be hundreds of milliseconds depending on system load.

## Recommendation

Add connection ID validation to `update_connection_state()` to match the protection already present in `remove_peer_metadata()`:

```rust
/// Updates the connection state associated with the given peer.
/// If no peer metadata exists, or the connection id doesn't match, an error is returned.
pub fn update_connection_state(
    &self,
    peer_network_id: PeerNetworkId,
    connection_id: ConnectionId,  // ADD THIS PARAMETER
    connection_state: ConnectionState,
) -> Result<(), Error> {
    // Grab the write lock for the peer metadata
    let mut peers_and_metadata = self.peers_and_metadata.write();

    // Fetch the peer metadata for the given network
    let peer_metadata_for_network =
        get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

    // Update the connection state for the peer
    if let Some(peer_metadata) = peer_metadata_for_network.get_mut(&peer_network_id.peer_id()) {
        // ADD CONNECTION ID VALIDATION
        let active_connection_id = peer_metadata.connection_metadata.connection_id;
        if active_connection_id != connection_id {
            return Err(Error::UnexpectedError(format!(
                "Cannot update connection state for stale connection! Given: {:?}, active: {:?}",
                connection_id, active_connection_id
            )));
        }
        
        peer_metadata.connection_state = connection_state;
    } else {
        return Err(missing_peer_metadata_error(&peer_network_id));
    }

    // Update the cached peers and metadata
    self.set_cached_peers_and_metadata(peers_and_metadata.clone());

    Ok(())
}
```

All call sites must be updated to pass the connection_id parameter. The health checker should obtain the connection_id from the peer metadata before calling `update_connection_state()`.

## Proof of Concept

```rust
#[tokio::test]
async fn test_stale_connection_state_update_race() {
    use aptos_config::network_id::NetworkId;
    use aptos_types::PeerId;
    use network::application::{
        metadata::{ConnectionState, PeerMetadata},
        storage::PeersAndMetadata,
    };
    use network::transport::ConnectionMetadata;
    
    // Setup
    let network_id = NetworkId::Validator;
    let peers_and_metadata = PeersAndMetadata::new(&[network_id]);
    let peer_id = PeerId::random();
    let peer_network_id = PeerNetworkId::new(network_id, peer_id);
    
    // Step 1: Establish first connection (connection_id = 1)
    let conn_metadata_1 = ConnectionMetadata::mock_with_connection_id(peer_id, 1);
    peers_and_metadata
        .insert_connection_metadata(peer_network_id, conn_metadata_1.clone())
        .unwrap();
    
    // Verify initial state is Connected
    let metadata = peers_and_metadata.get_metadata_for_peer(peer_network_id).unwrap();
    assert_eq!(metadata.get_connection_state(), ConnectionState::Connected);
    assert_eq!(metadata.connection_metadata.connection_id, 1.into());
    
    // Step 2: Start disconnect process (but delay the state update)
    // Simulate: health checker calls update_connection_state(Disconnecting) for conn_id=1
    let stale_update = tokio::spawn({
        let peers_and_metadata = peers_and_metadata.clone();
        async move {
            tokio::time::sleep(Duration::from_millis(50)).await;
            // This update is for the OLD connection (conn_id=1)
            peers_and_metadata
                .update_connection_state(peer_network_id, ConnectionState::Disconnecting)
                .unwrap();
        }
    });
    
    // Step 3: Before stale update completes, establish new connection (connection_id = 2)
    tokio::time::sleep(Duration::from_millis(10)).await;
    let conn_metadata_2 = ConnectionMetadata::mock_with_connection_id(peer_id, 2);
    peers_and_metadata
        .insert_connection_metadata(peer_network_id, conn_metadata_2.clone())
        .unwrap();
    
    // New connection should be Connected
    let metadata = peers_and_metadata.get_metadata_for_peer(peer_network_id).unwrap();
    assert_eq!(metadata.get_connection_state(), ConnectionState::Connected);
    assert_eq!(metadata.connection_metadata.connection_id, 2.into());
    
    // Step 4: Wait for stale update to complete
    stale_update.await.unwrap();
    
    // Step 5: VULNERABILITY - Stale update corrupted the new connection's state
    let metadata = peers_and_metadata.get_metadata_for_peer(peer_network_id).unwrap();
    
    // Connection ID is for the NEW connection (2)
    assert_eq!(metadata.connection_metadata.connection_id, 2.into());
    
    // But state was overwritten by STALE update meant for OLD connection (1)
    assert_eq!(metadata.get_connection_state(), ConnectionState::Disconnecting);
    // ^^^ THIS IS THE BUG: New active connection marked as Disconnecting
    
    // Step 6: Verify impact - peer excluded from connected peers
    let connected_peers = peers_and_metadata
        .get_connected_peers_and_metadata()
        .unwrap();
    assert!(!connected_peers.contains_key(&peer_network_id)); 
    // ^^^ Active peer incorrectly excluded from connected peers list
}
```

This PoC demonstrates how a stale `update_connection_state()` call from an old connection can corrupt the metadata of a new connection, creating the inconsistent state that breaks peer discovery and message delivery.

### Citations

**File:** network/framework/src/peer_manager/mod.rs (L81-87)
```rust
    active_peers: HashMap<
        PeerId,
        (
            ConnectionMetadata,
            aptos_channel::Sender<ProtocolId, PeerRequest>,
        ),
    >,
```

**File:** network/framework/src/peer_manager/mod.rs (L557-579)
```rust
    /// In the event two peers simultaneously dial each other we need to be able to do
    /// tie-breaking to determine which connection to keep and which to drop in a deterministic
    /// way. One simple way is to compare our local PeerId with that of the remote's PeerId and
    /// keep the connection where the peer with the greater PeerId is the dialer.
    ///
    /// Returns `true` if the existing connection should be dropped and `false` if the new
    /// connection should be dropped.
    fn simultaneous_dial_tie_breaking(
        own_peer_id: PeerId,
        remote_peer_id: PeerId,
        existing_origin: ConnectionOrigin,
        new_origin: ConnectionOrigin,
    ) -> bool {
        match (existing_origin, new_origin) {
            // If the remote dials while an existing connection is open, the older connection is
            // dropped.
            (ConnectionOrigin::Inbound, ConnectionOrigin::Inbound) => true,
            // We should never dial the same peer twice, but if we do drop the old connection
            (ConnectionOrigin::Outbound, ConnectionOrigin::Outbound) => true,
            (ConnectionOrigin::Inbound, ConnectionOrigin::Outbound) => remote_peer_id < own_peer_id,
            (ConnectionOrigin::Outbound, ConnectionOrigin::Inbound) => own_peer_id < remote_peer_id,
        }
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L625-655)
```rust
        // Check for and handle simultaneous dialing
        if let Entry::Occupied(active_entry) = self.active_peers.entry(peer_id) {
            let (curr_conn_metadata, _) = active_entry.get();
            if Self::simultaneous_dial_tie_breaking(
                self.network_context.peer_id(),
                peer_id,
                curr_conn_metadata.origin,
                conn_meta.origin,
            ) {
                let (_, peer_handle) = active_entry.remove();
                // Drop the existing connection and replace it with the new connection
                drop(peer_handle);
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing existing connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                send_new_peer_notification = false;
            } else {
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing incoming connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                // Drop the new connection and keep the one already stored in active_peers
                self.disconnect(connection);
                return Ok(());
            }
        }
```

**File:** network/framework/src/application/metadata.rs (L11-18)
```rust
/// The current connection state of a peer
/// TODO: Allow nodes that are unhealthy to stay connected
#[derive(Clone, Copy, Debug, Deserialize, Eq, Ord, PartialEq, PartialOrd, Serialize)]
pub enum ConnectionState {
    Connected,
    Disconnecting,
    Disconnected, // Currently unused (TODO: fix this!)
}
```

**File:** network/framework/src/application/metadata.rs (L50-53)
```rust
    /// Returns true iff the peer is still connected
    pub fn is_connected(&self) -> bool {
        self.connection_state == ConnectionState::Connected
    }
```

**File:** network/framework/src/application/storage.rs (L199-204)
```rust
        peer_metadata_for_network
            .entry(peer_network_id.peer_id())
            .and_modify(|peer_metadata| {
                peer_metadata.connection_metadata = connection_metadata.clone()
            })
            .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));
```

**File:** network/framework/src/application/storage.rs (L235-251)
```rust
            // Don't remove the peer if the connection doesn't match!
            // For now, remove the peer entirely, we could in the future
            // have multiple connections for a peer
            let active_connection_id = entry.get().connection_metadata.connection_id;
            if active_connection_id == connection_id {
                let peer_metadata = entry.remove();
                let event = ConnectionNotification::LostPeer(
                    peer_metadata.connection_metadata.clone(),
                    peer_network_id.network_id(),
                );
                self.broadcast(event);
                peer_metadata
            } else {
                return Err(Error::UnexpectedError(format!(
                    "The peer connection id did not match! Given: {:?}, found: {:?}.",
                    connection_id, active_connection_id
                )));
```

**File:** network/framework/src/application/storage.rs (L266-290)
```rust
    pub fn update_connection_state(
        &self,
        peer_network_id: PeerNetworkId,
        connection_state: ConnectionState,
    ) -> Result<(), Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Update the connection state for the peer
        if let Some(peer_metadata) = peer_metadata_for_network.get_mut(&peer_network_id.peer_id()) {
            peer_metadata.connection_state = connection_state;
        } else {
            // Unable to find the peer metadata for the given peer
            return Err(missing_peer_metadata_error(&peer_network_id));
        }

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        Ok(())
    }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L103-127)
```rust
        // Get the connected peers and metadata
        let peers_and_metadata = self.consensus_observer_client.get_peers_and_metadata();
        let connected_peers_and_metadata =
            match peers_and_metadata.get_connected_peers_and_metadata() {
                Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
                Err(error) => {
                    // We failed to get the connected peers and metadata
                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::UnexpectedError)
                        .message(&format!(
                            "Failed to get connected peers and metadata! Error: {:?}",
                            error
                        )));
                    return;
                },
            };

        // Identify the active subscribers that are no longer connected
        let connected_peers: HashSet<PeerNetworkId> =
            connected_peers_and_metadata.keys().cloned().collect();
        let disconnected_subscribers: HashSet<PeerNetworkId> = active_subscribers
            .difference(&connected_peers)
            .cloned()
            .collect();

```

**File:** network/framework/src/application/interface.rs (L214-223)
```rust
    fn get_available_peers(&self) -> Result<Vec<PeerNetworkId>, Error> {
        let supported_protocol_ids: Vec<ProtocolId> = self
            .direct_send_protocols_and_preferences
            .iter()
            .chain(self.rpc_protocols_and_preferences.iter())
            .cloned()
            .collect();
        self.peers_and_metadata
            .get_connected_supported_peers(&supported_protocol_ids)
    }
```
