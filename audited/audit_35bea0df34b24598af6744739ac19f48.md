# Audit Report

## Title
Storage Service Response Creation CPU Exhaustion via Unbounded Serialization/Compression

## Summary
The storage service's response creation process at lines 443-453 in `handler.rs` performs expensive BCS serialization and LZ4 compression operations that are not rate-limited or cost-bounded. An attacker can request maximum-sized data chunks (up to 40 MiB for v2 requests) with varying parameters to bypass the LRU cache, causing CPU exhaustion across up to 64 concurrent blocking threads. [1](#0-0) 

## Finding Description

The vulnerability exists in the separation between data fetch cost and response creation cost. The storage service enforces size limits during data fetching but does not account for the computational cost of serialization and compression during response creation.

**Attack Flow:**

1. **Data Fetch Phase** (lines 434-440 in handler.rs): Uses `bcs::serialized_size` to check if data fits within size limits without actually serializing the data. [2](#0-1) 

2. **Response Creation Phase** (lines 443-453 in handler.rs): Performs full BCS serialization via `bcs::to_bytes` followed by LZ4 compression, which are computationally expensive operations. [3](#0-2) 

3. **Request Processing**: Each incoming request spawns a blocking task without computational cost limits. [4](#0-3) 

**Exploitation:**
- Attacker sends multiple concurrent requests for different transaction ranges (e.g., versions 0-3000, 1-3001, 2-3002, etc.)
- Each request bypasses the 500-entry LRU cache due to different parameters
- Maximum request size is 40 MiB for v2 transaction data [5](#0-4) 

- Up to 64 concurrent blocking threads process these requests simultaneously [6](#0-5) 

**Why Existing Protections Fail:**

1. **Request Moderator** only tracks invalid requests, not computational cost of valid requests [7](#0-6) 

2. **LRU Cache** has only 500 entries and can be trivially bypassed by varying request parameters [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program category "Validator node slowdowns":

- **CPU Exhaustion**: 64 concurrent threads each serializing and compressing up to 40 MiB causes sustained high CPU usage
- **Service Degradation**: Legitimate storage service requests experience increased latency
- **Cascading Effects**: Slow storage service responses can impact state synchronization, affecting new nodes joining the network or nodes catching up after downtime
- **No Financial Loss**: Does not directly lead to fund theft or consensus violations, but degrades network availability

The attack breaks the documented invariant: "Resource Limits: All operations must respect gas, storage, and computational limits" - valid requests can consume unbounded CPU resources.

## Likelihood Explanation

**Likelihood: High**

- **No Authentication Required**: Any network peer can send storage service requests
- **Simple to Execute**: Attacker only needs to send valid requests with varying version ranges
- **Low Attack Cost**: Minimal bandwidth required to trigger expensive server-side computation
- **Difficult to Detect**: Requests appear valid and are processed normally
- **No Validator Access Needed**: Exploitable from any fullnode connection to the network

## Recommendation

Implement computational cost limiting for response creation:

1. **Add per-peer rate limiting based on computational cost**, not just request validity:
   - Track cumulative serialization/compression time per peer
   - Temporarily throttle peers exceeding cost budgets
   - Apply limits to all network types (not just public networks)

2. **Pre-check serialization cost before response creation**:
   - Use a cost model that accounts for data size AND structure complexity
   - Reject requests that would exceed cost thresholds before starting expensive operations

3. **Implement adaptive chunk size reduction**:
   - If response creation exceeds time budget, reduce chunk size for subsequent requests from that peer
   - Add telemetry for response creation latency per request type

4. **Enhance LRU cache effectiveness**:
   - Increase cache size based on available memory
   - Add cache hit/miss metrics per peer to detect cache bypass attempts

Example fix for handler.rs:

```rust
// Add cost tracking before response creation
let estimated_cost = estimate_serialization_cost(&data_response);
if !self.request_moderator.check_computational_budget(peer_network_id, estimated_cost) {
    return Err(Error::TooManyExpensiveRequests(...));
}

// Existing response creation with timeout
let create_storage_response = || { ... };
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_storage_service_cpu_exhaustion() {
    // Setup: Start storage service server
    let (storage_service, runtime, storage) = setup_storage_service().await;
    
    // Attack: Send 64 concurrent requests for maximum-sized chunks
    let mut handles = vec![];
    for i in 0..64 {
        let storage_client = storage_service.clone();
        let handle = runtime.spawn(async move {
            let request = StorageServiceRequest {
                data_request: DataRequest::GetTransactionDataWithProof(
                    GetTransactionDataWithProofRequest {
                        start_version: i, // Vary to bypass cache
                        end_version: i + 3000, // Large chunk
                        proof_version: i + 3000,
                        include_events: true,
                        transaction_data_request_type: TransactionDataRequestType::TransactionData,
                    }
                ),
                use_compression: true, // Trigger expensive compression
            };
            
            let start = Instant::now();
            let response = storage_client.send_request(request).await;
            let duration = start.elapsed();
            
            // Each request should take significant time due to serialization/compression
            println!("Request {} took {:?}", i, duration);
            response
        });
        handles.push(handle);
    }
    
    // Observe: All 64 threads performing expensive serialization/compression
    // Expected: CPU usage spikes to 100% across multiple cores
    // Expected: Response times increase significantly
    for handle in handles {
        handle.await.unwrap();
    }
}
```

**Notes:**
- This vulnerability is distinct from network-level DoS (out of scope) as it exploits application logic allowing expensive computation via valid requests
- The attack vector is particularly concerning for public fullnodes serving state sync requests to many peers
- The 64-thread blocking pool limit provides some protection but is insufficient against sustained attacks

### Citations

**File:** state-sync/storage-service/server/src/handler.rs (L442-453)
```rust
        // Create the storage response and time the operation
        let create_storage_response = || {
            StorageServiceResponse::new(data_response, request.use_compression)
                .map_err(|error| error.into())
        };
        let storage_response = utils::execute_and_time_duration(
            &metrics::STORAGE_RESPONSE_CREATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            create_storage_response,
            None,
        )?;
```

**File:** state-sync/storage-service/server/src/storage.rs (L1511-1517)
```rust
fn get_num_serialized_bytes<T: ?Sized + Serialize>(
    data: &T,
) -> aptos_storage_service_types::Result<u64, Error> {
    let num_serialized_bytes = bcs::serialized_size(data)
        .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
    Ok(num_serialized_bytes as u64)
}
```

**File:** state-sync/storage-service/types/src/responses.rs (L74-94)
```rust
    pub fn new(data_response: DataResponse, perform_compression: bool) -> Result<Self, Error> {
        if perform_compression {
            // Serialize and compress the raw data
            let raw_data = bcs::to_bytes(&data_response)
                .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
            let compressed_data = aptos_compression::compress(
                raw_data,
                CompressionClient::StateSync,
                MAX_APPLICATION_MESSAGE_SIZE,
            )?;

            // Create the compressed response
            let label = data_response.get_label().to_string() + COMPRESSION_SUFFIX_LABEL;
            Ok(StorageServiceResponse::CompressedResponse(
                label,
                compressed_data,
            ))
        } else {
            Ok(StorageServiceResponse::RawResponse(data_response))
        }
    }
```

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** config/src/config/state_sync_config.rs (L19-21)
```rust
// The maximum message size per state sync message (for v2 data requests)
const CLIENT_MAX_MESSAGE_SIZE_V2: usize = 20 * 1024 * 1024; // 20 MiB (used for v2 data requests)
const SERVER_MAX_MESSAGE_SIZE_V2: usize = 40 * 1024 * 1024; // 40 MiB (used for v2 data requests)
```

**File:** config/src/config/state_sync_config.rs (L202-202)
```rust
            max_lru_cache_size: 500, // At ~0.6MiB per chunk, this should take no more than 0.5GiB
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-196)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```
