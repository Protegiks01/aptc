# Audit Report

## Title
Byzantine Validator OptQS Denial-of-Service via Window Manipulation

## Summary
Byzantine validators can systematically disable Optimistic Quorum Store (OptQS) by proposing blocks with unavailable payload batches, causing the failure window to grow exponentially and preventing OptQS from re-enabling, thereby permanently degrading network throughput.

## Finding Description

The `ExponentialWindowFailureTracker` in the consensus layer tracks proposal failures to determine when to enable OptQS. Byzantine validators can exploit this mechanism to keep OptQS permanently disabled through the following attack path: [1](#0-0) 

When a Byzantine validator becomes proposer with OptQS enabled, they create a block with `OptQuorumStorePayload` referencing batches from their local queue that were never properly broadcast to the network. [2](#0-1) 

When honest validators receive this proposal, they check payload availability locally: [3](#0-2) 

Missing batches cause validators to timeout with `PayloadUnavailable` status: [4](#0-3) 

This triggers window doubling in the failure tracker: [5](#0-4) 

The window grows exponentially (2→4→8→16→32→64→100) and is capped at `max_window=100`: [6](#0-5) 

Once the window reaches maximum size, OptQS is only enabled when `last_consecutive_success_count >= 100`: [7](#0-6) 

Byzantine validators (even with <1/3 stake) can periodically trigger failures to prevent reaching 100 consecutive successes, keeping OptQS disabled indefinitely. The `exclude_authors` mechanism only prevents pulling batches from specific authors but doesn't prevent window growth: [8](#0-7) 

## Impact Explanation

This constitutes a **High Severity** liveness degradation attack per the Aptos bug bounty criteria ("Validator node slowdowns" and "Significant protocol violations"). OptQS is a critical throughput optimization - keeping it disabled reduces network transaction capacity significantly. While the network continues to function using standard quorum store payloads, the persistent throughput degradation impacts all users and validators.

## Likelihood Explanation

**High likelihood** of exploitation:
- Byzantine validators naturally become proposers proportional to their stake (e.g., 10% stake = proposer ~10% of rounds)
- No special coordination required beyond normal proposer duties  
- Attack is stealthy - appears as network issues rather than malicious behavior
- Once window reaches max size, maintaining the attack requires only periodic failures (e.g., one failure per 100 rounds)
- Multiple Byzantine validators can coordinate to cycle through the `exclude_authors` list

## Recommendation

Implement rate-limiting on window growth and add Byzantine-resistance to the failure tracking:

1. **Cap window growth rate**: Limit window doubling to occur only after multiple consecutive `PayloadUnavailable` failures from the same proposer, not on every single failure.

2. **Add author-specific tracking**: Track failure rates per validator author. If a specific validator consistently causes `PayloadUnavailable` (e.g., >X% of their proposals), permanently exclude them from OptQS rather than growing the global window.

3. **Implement window decay**: Add gradual window reduction over time (e.g., halve window every N successful rounds) rather than requiring all-history successes for reset.

4. **Add payload availability validation**: Before including batches in OptQS payload, verify they were broadcast to >f+1 validators using proof-of-dissemination.

## Proof of Concept

```rust
// Simulation of the attack showing window growth
#[test]
fn test_byzantine_optqs_dos() {
    let (_signers, verifier) = random_validator_verifier(10, None, false);
    let mut tracker = ExponentialWindowFailureTracker::new(
        100, 
        verifier.get_ordered_account_addresses()
    );
    
    // Initial state: OptQS enabled
    assert_eq!(tracker.window, 2);
    tracker.push(NewRoundReason::QCReady);
    tracker.push(NewRoundReason::QCReady);
    assert_eq!(tracker.last_consecutive_success_count, 2);
    // OptQS would be enabled (2 >= 2)
    
    // Byzantine proposer causes PayloadUnavailable
    tracker.push(NewRoundReason::Timeout(
        RoundTimeoutReason::PayloadUnavailable {
            missing_authors: BitVec::with_num_bits(10),
        }
    ));
    assert_eq!(tracker.window, 4);
    assert_eq!(tracker.last_consecutive_success_count, 0);
    
    // Need 4 successes to enable OptQS again
    for _ in 0..3 {
        tracker.push(NewRoundReason::QCReady);
    }
    assert_eq!(tracker.last_consecutive_success_count, 3);
    // OptQS still disabled (3 < 4)
    
    // Byzantine proposer strikes again
    tracker.push(NewRoundReason::Timeout(
        RoundTimeoutReason::PayloadUnavailable {
            missing_authors: BitVec::with_num_bits(10),
        }
    ));
    assert_eq!(tracker.window, 8);
    assert_eq!(tracker.last_consecutive_success_count, 0);
    
    // Continue pattern - window keeps growing
    // After several Byzantine attacks:
    for _ in 0..5 {
        tracker.push(NewRoundReason::Timeout(
            RoundTimeoutReason::PayloadUnavailable {
                missing_authors: BitVec::with_num_bits(10),
            }
        ));
    }
    assert_eq!(tracker.window, 100); // Capped at max
    
    // Now need 100 consecutive successes to enable OptQS
    // But Byzantine validators can easily prevent this
    for _ in 0..99 {
        tracker.push(NewRoundReason::QCReady);
    }
    assert_eq!(tracker.last_consecutive_success_count, 99);
    // Still one failure away from enabling OptQS
    
    tracker.push(NewRoundReason::Timeout(
        RoundTimeoutReason::PayloadUnavailable {
            missing_authors: BitVec::with_num_bits(10),
        }
    ));
    // Reset to 0 - OptQS remains disabled
    assert_eq!(tracker.last_consecutive_success_count, 0);
    assert_eq!(tracker.window, 100);
}
```

## Notes

This vulnerability exploits the assumption that `PayloadUnavailable` failures are due to network issues rather than malicious behavior. The exponential backoff is a safety mechanism, but Byzantine validators can weaponize it to degrade network performance within their stake allocation. The issue is exacerbated because the `exclude_authors` mechanism operates within the already-enlarged window rather than preventing window growth itself.

### Citations

**File:** consensus/src/liveness/proposal_status_tracker.rs (L49-52)
```rust
    pub(crate) fn push(&mut self, status: NewRoundReason) {
        self.past_round_statuses.push_back(status);
        self.compute_failure_window();
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L65-78)
```rust
    fn compute_failure_window(&mut self) {
        self.last_consecutive_success_count = self.last_consecutive_statuses_matching(|reason| {
            !matches!(
                reason,
                NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable { .. })
            )
        });
        if self.last_consecutive_success_count == 0 {
            self.window *= 2;
            self.window = self.window.min(self.max_window);
        } else if self.last_consecutive_success_count == self.past_round_statuses.len() {
            self.window = 2;
        }
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L137-143)
```rust
        if tracker.last_consecutive_success_count < tracker.window {
            warn!(
                "Skipping OptQS: (last_consecutive_successes) {} < {} (window)",
                tracker.last_consecutive_success_count, tracker.window
            );
            return None;
        }
```

**File:** consensus/src/quorum_store/proof_manager.rs (L129-152)
```rust
        let (opt_batches, opt_batch_txns_size) =
            // TODO(ibalajiarun): Support unique txn calculation
            if let Some(ref params) = request.maybe_optqs_payload_pull_params {
                let max_opt_batch_txns_size = request.max_txns - txns_with_proof_size;
                let max_opt_batch_txns_after_filtering = request.max_txns_after_filtering - cur_unique_txns;
                let (opt_batches, opt_payload_size, _) =
                    self.batch_proof_queue.pull_batches(
                        &excluded_batches
                            .iter()
                            .cloned()
                            .chain(proof_block.iter().map(|proof| proof.info().clone()))
                            .collect(),
                        &params.exclude_authors,
                        max_opt_batch_txns_size,
                        max_opt_batch_txns_after_filtering,
                        request.soft_max_txns_after_filtering,
                        request.return_non_full,
                        request.block_timestamp,
                        Some(params.minimum_batch_age_usecs),
                    );
                (opt_batches, opt_payload_size)
            } else {
                (Vec::new(), PayloadTxnsSize::zero())
            };
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/src/round_manager.rs (L968-983)
```rust
    fn compute_timeout_reason(&self, round: Round) -> RoundTimeoutReason {
        if self.round_state().vote_sent().is_some() {
            return RoundTimeoutReason::NoQC;
        }

        match self.block_store.get_block_for_round(round) {
            None => RoundTimeoutReason::ProposalNotReceived,
            Some(block) => {
                if let Err(missing_authors) = self.block_store.check_payload(block.block()) {
                    RoundTimeoutReason::PayloadUnavailable { missing_authors }
                } else {
                    RoundTimeoutReason::Unknown
                }
            },
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L901-904)
```rust
        let failures_tracker = Arc::new(Mutex::new(ExponentialWindowFailureTracker::new(
            100,
            epoch_state.verifier.get_ordered_account_addresses(),
        )));
```
