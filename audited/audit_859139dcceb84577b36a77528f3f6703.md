# Audit Report

## Title
Event Storm Attack: Silent Message Loss in Peer Connection Notification System Causes HealthChecker State Corruption

## Summary
The `broadcast()` function in `PeersAndMetadata` silently drops `NewPeer`/`LostPeer` connection events when subscriber channels overflow (capacity: 1000). During rapid peer churn, the HealthChecker maintains incorrect state about connected peers, failing to monitor genuinely connected peers and wasting resources on disconnected phantoms, leading to validator performance degradation. [1](#0-0) 

## Finding Description

The vulnerability exists in the peer connection notification system. When peers connect or disconnect, `PeersAndMetadata` broadcasts events to all subscribers through bounded tokio channels with a capacity of 1000 events. [2](#0-1) 

The `broadcast()` function uses `try_send()` which is non-blocking. When a subscriber's channel is full, the event is **silently dropped** with only a warning log: [3](#0-2) 

The HealthChecker subscribes to these events and relies **entirely** on the event stream to maintain its internal `health_check_data` HashMap, with **no reconciliation mechanism**: [4](#0-3) 

When connection events are processed, the HealthChecker updates its local state: [5](#0-4) 

The HealthChecker's `connected_peers()` method reads only from its local state, not from the ground truth: [6](#0-5) 

**Attack Scenario:**
1. Attacker causes thousands of peers to rapidly connect/disconnect (via DDoS, network manipulation, or malicious peer behavior)
2. Each event broadcasts to all subscribers' bounded channels (1000 capacity)
3. If subscribers don't drain channels fast enough, channels fill up
4. New events are silently dropped (line 378-384 in storage.rs)
5. HealthChecker's state becomes permanently inconsistent with reality

**Impact on Validators:**

If HealthChecker misses **NewPeer events**:
- Won't create health check data for newly connected validators
- Won't ping those validators to monitor liveness
- If those validators later become unresponsive, HealthChecker won't detect it and initiate disconnection
- Stale connections to unresponsive validators remain open, causing consensus message timeouts and delays

If HealthChecker misses **LostPeer events**:
- Continues trying to ping already-disconnected peers
- Wastes CPU, network bandwidth, and memory on phantom peers
- Accumulates failures and attempts to disconnect already-disconnected peers (no-op but still wasteful)

The HealthChecker is responsible for maintaining validator liveness monitoring as documented: [7](#0-6) 

## Impact Explanation

This qualifies as **High Severity** under Aptos Bug Bounty criteria:
- **Validator node slowdowns**: HealthChecker with corrupted state wastes resources pinging phantom peers and fails to detect genuinely unresponsive peers, causing degraded validator performance
- **Significant protocol violations**: The protocol expectation is that subscribers receive all connection events, but events are being silently dropped during high churn

While this does not directly break consensus safety, it degrades validator liveness and performance:
- Undetected unresponsive peers cause consensus message delivery delays
- Wasted resources reduce validator capacity
- In extreme cases with many missed events, validators could experience significant performance degradation affecting consensus participation

This is NOT a "network-level DoS" (which is out of scope). This is an **application-level resource management bug** in event handling logic that can be exploited via network events.

## Likelihood Explanation

**High Likelihood:**
- Attack requires only the ability to cause peer churn (achievable via network-level actions)
- No special permissions or validator access required
- The 1000-event buffer can be filled rapidly during legitimate network instability or targeted attacks
- Public fullnode networks experience high peer churn naturally
- Validators connecting to many VFNs/PFNs are exposed to this attack surface

**Exploitation Requirements:**
- Ability to cause rapid peer connections/disconnections (DDoS, network manipulation, or malicious peers)
- Sustain high event rate long enough to fill 1000-capacity channels
- Target validators during periods of high network activity

## Recommendation

**Solution 1: Add Periodic Reconciliation**
The HealthChecker should periodically reconcile its local state with the ground truth from `PeersAndMetadata`:

```rust
// In HealthChecker::start(), add periodic reconciliation
let reconciliation_interval = Duration::from_secs(30);
let reconciliation_ticker = self.time_service.interval(reconciliation_interval);
tokio::pin!(reconciliation_ticker);

// In the event loop, add:
_ = reconciliation_ticker.select_next_some() => {
    self.reconcile_peer_state();
}

// Add method to HealthChecker:
fn reconcile_peer_state(&mut self) {
    let ground_truth = self.network_interface
        .get_peers_and_metadata()
        .get_connected_peers_and_metadata()
        .unwrap_or_default();
    
    let self_network_id = self.network_context.network_id();
    
    // Add missing peers
    for (peer_network_id, _) in ground_truth.iter() {
        if peer_network_id.network_id() == self_network_id {
            let peer_id = peer_network_id.peer_id();
            if !self.network_interface.health_check_data.read().contains_key(&peer_id) {
                self.network_interface.create_peer_and_health_data(peer_id, self.round);
            }
        }
    }
    
    // Remove stale peers
    let known_peers: Vec<PeerId> = self.network_interface.health_check_data.read().keys().cloned().collect();
    for peer_id in known_peers {
        let peer_network_id = PeerNetworkId::new(self_network_id, peer_id);
        if !ground_truth.contains_key(&peer_network_id) {
            self.network_interface.remove_peer_and_health_data(&peer_id);
        }
    }
}
```

**Solution 2: Use Unbounded Channel or Larger Buffer**
Increase `NOTIFICATION_BACKLOG` significantly or use unbounded channels:

```rust
const NOTIFICATION_BACKLOG: usize = 10000; // 10x increase
```

**Solution 3: Add Backpressure**
Use blocking `send()` instead of `try_send()` to apply backpressure, but this could cause PeerManager to block on slow subscribers.

**Recommended Approach: Combination of 1 and 2**
- Implement periodic reconciliation (Solution 1) as a safety mechanism
- Increase buffer size to 10000 (Solution 2) to handle legitimate bursts
- Add metrics to monitor dropped events

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[tokio::test]
async fn test_event_storm_drops_messages() {
    use network::application::storage::PeersAndMetadata;
    use network::peer_manager::ConnectionNotification;
    use aptos_config::network_id::NetworkId;
    use aptos_types::PeerId;
    
    // Create PeersAndMetadata with subscriber
    let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Validator]);
    let mut receiver = peers_and_metadata.subscribe();
    
    // Generate 2000 rapid connect/disconnect events (exceeds 1000 capacity)
    for i in 0..2000 {
        let peer_id = PeerId::random();
        let conn_meta = ConnectionMetadata::mock(peer_id);
        
        // Insert peer (triggers NewPeer broadcast)
        peers_and_metadata.insert_connection_metadata(
            PeerNetworkId::new(NetworkId::Validator, peer_id),
            conn_meta.clone()
        ).unwrap();
        
        // Remove peer (triggers LostPeer broadcast)
        peers_and_metadata.remove_peer_metadata(
            PeerNetworkId::new(NetworkId::Validator, peer_id),
            conn_meta.connection_id
        ).unwrap();
    }
    
    // Count received events (should be 4000, but will be < 1000 due to drops)
    let mut received_count = 0;
    while let Ok(_) = receiver.try_recv() {
        received_count += 1;
    }
    
    // Assert that messages were dropped
    assert!(received_count < 4000, "Expected message loss, but got all events");
    println!("Received only {} out of 4000 events - {} events silently dropped", 
             received_count, 4000 - received_count);
}
```

The PoC demonstrates that during rapid peer churn exceeding the channel capacity, events are silently dropped, causing HealthChecker to maintain incorrect state about connected peers.

## Notes

This vulnerability affects the **HealthChecker** specifically. The **ConnectivityManager** is less affected because it uses a different channel type (`conn_notifs_channel`) with LIFO semantics that keeps only the last event per peer: [8](#0-7) 

The issue is in the application-level event broadcasting logic, not the network protocol itself, distinguishing it from "network-level DoS attacks" that are out of scope.

### Citations

**File:** network/framework/src/application/storage.rs (L31-35)
```rust
// notification_backlog is how many ConnectionNotification items can be queued waiting for an app to receive them.
// Beyond this, new messages will be dropped if the app is not handling them fast enough.
// We make this big enough to fit an initial burst of _all_ the connected peers getting notified.
// Having 100 connected peers is common, 500 not unexpected
const NOTIFICATION_BACKLOG: usize = 1000;
```

**File:** network/framework/src/application/storage.rs (L53-54)
```rust
    subscribers: Mutex<Vec<tokio::sync::mpsc::Sender<ConnectionNotification>>>,
}
```

**File:** network/framework/src/application/storage.rs (L371-395)
```rust
    fn broadcast(&self, event: ConnectionNotification) {
        let mut listeners = self.subscribers.lock();
        let mut to_del = vec![];
        for i in 0..listeners.len() {
            let dest = listeners.get_mut(i).unwrap();
            if let Err(err) = dest.try_send(event.clone()) {
                match err {
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
                    TrySendError::Closed(_) => {
                        to_del.push(i);
                    },
                }
            }
        }
        for evict in to_del.into_iter() {
            listeners.swap_remove(evict);
        }
    }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L160-163)
```rust
        let connection_events = self
            .connection_events_injection
            .take()
            .unwrap_or_else(|| self.network_interface.get_peers_and_metadata().subscribe());
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L209-228)
```rust
                conn_event = connection_events.select_next_some() => {
                    match conn_event {
                        ConnectionNotification::NewPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.create_peer_and_health_data(
                                    metadata.remote_peer_id, self.round
                                );
                            }
                        }
                        ConnectionNotification::LostPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.remove_peer_and_health_data(
                                    &metadata.remote_peer_id
                                );
                            }
                        }
                    }
                }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L59-61)
```rust
    pub fn connected_peers(&self) -> Vec<PeerId> {
        self.health_check_data.read().keys().cloned().collect()
    }
```

**File:** network/README.md (L41-43)
```markdown
Validator health information, determined using periodic liveness probes, is not
shared between validators; instead, each validator directly monitors its peers
for liveness using the [`HealthChecker`] protocol.
```

**File:** network/framework/src/peer_manager/conn_notifs_channel.rs (L18-20)
```rust
pub fn new() -> (Sender, Receiver) {
    aptos_channel::new(QueueStyle::LIFO, 1, None)
}
```
