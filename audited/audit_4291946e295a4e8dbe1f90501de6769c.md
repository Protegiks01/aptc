# Audit Report

## Title
Stale Latency Measurements Cause JWK Consensus to Preferentially Contact Slow/Unresponsive Peers

## Summary
The `sort_peers_by_latency()` function in JWK consensus relies on peer monitoring latency measurements that can become stale when peers become slow or unresponsive. Failed latency pings do not remove old measurements, and peers with no latency data default to 0.0 (best possible latency), causing JWK consensus to preferentially contact slow or unresponsive validators first. This degrades consensus performance and can cause temporary liveness issues.

## Finding Description

The JWK consensus network layer uses `sort_peers_by_latency()` to prioritize peers for communication during reliable broadcast operations. [1](#0-0) 

This function delegates to the underlying network storage implementation which sorts peers by ascending latency (lowest latency first). [2](#0-1) 

The critical vulnerability lies in how latency data is sourced and maintained. When latency data is unavailable, the implementation defaults to 0.0 via `unwrap_or_default()`, treating peers with no latency measurements as having the best possible latency. [3](#0-2) 

Latency measurements are collected by the peer monitoring service, which sends ping requests every 30 seconds with a 20-second timeout. [4](#0-3) 

When latency pings fail, the failure counter is incremented but **old successful measurements are retained**. [5](#0-4) 

After 3 consecutive failures, only a warning is loggedâ€”the peer is **not disconnected**. A TODO comment explicitly acknowledges this gap. [6](#0-5) 

The reliable broadcast mechanism used by JWK consensus sorts peers by latency before sending messages, meaning slow peers with stale measurements are contacted first. [7](#0-6) 

**Attack/Failure Scenario:**

1. A validator initially has good latency (e.g., 50ms average from 10 successful pings)
2. The validator becomes slow due to network degradation, resource exhaustion, or malicious behavior
3. Latency pings to this validator timeout after 20 seconds
4. After 3 failures, a warning is logged but the validator remains connected
5. The old 50ms latency measurements persist in the system
6. Alternatively, if enough time passes and all measurements age out, the latency defaults to 0.0
7. `sort_peers_by_latency()` ranks this slow validator as having low latency (50ms) or best latency (0.0)
8. JWK consensus contacts this validator first during reliable broadcast
9. RPC requests timeout after 1 second (configured in epoch_manager.rs), causing delays
10. Retries with exponential backoff further degrade performance [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty criteria because it causes:

1. **Performance degradation**: JWK consensus wastes time attempting to contact slow/unresponsive validators first, with each RPC timing out after 1 second
2. **Temporary liveness impact**: If multiple validators have stale latency measurements, the cumulative timeout delays can prevent timely consensus completion
3. **State inconsistencies**: Delays in JWK consensus could lead to validator transactions not being processed in time

The issue does not reach High severity because:
- Eventual progress is still possible through the retry mechanism
- It does not cause permanent consensus failure
- It is not a direct consensus safety violation

However, it falls clearly into Medium severity as it can cause "state inconsistencies requiring intervention" when JWK consensus fails to make timely progress, potentially requiring manual investigation or configuration changes.

## Likelihood Explanation

This vulnerability has **high likelihood** of occurring in production because:

1. **Natural network conditions**: Network degradation, congestion, or routing issues are common in distributed systems
2. **Validator resource constraints**: Validators may become temporarily overloaded during high traffic periods
3. **No attacker privileges required**: The vulnerability manifests through normal network behavior
4. **Large time window**: With 30-second ping intervals and 3 failures tolerated, stale measurements can persist for 90+ seconds
5. **Exacerbated by default behavior**: The 0.0 default for missing latency data makes the problem worse

Additionally, a malicious validator could deliberately exploit this by:
- Responding to health checker pings (which use different intervals/messages) to avoid disconnection
- Delaying or dropping latency ping requests to appear as having no latency data
- Being ranked as having 0.0 latency and contacted first, then timing out RPC requests

## Recommendation

Implement the following fixes:

1. **Implement peer disconnection on latency failures** as indicated by the TODO comment:

```rust
// In latency_info.rs, modify handle_request_failure:
fn handle_request_failure(&self, peer_network_id: &PeerNetworkId) -> bool {
    self.request_tracker.write().record_response_failure();
    
    let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
    if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
        warn!(LogSchema::new(LogEntry::LatencyPing)
            .event(LogEvent::TooManyPingFailures)
            .peer(peer_network_id)
            .message("Too many ping failures occurred for the peer!"));
        return true; // Signal that disconnection should occur
    }
    false
}
```

2. **Clear latency measurements on consecutive failures**:

```rust
// In latency_info.rs:
pub fn clear_latency_measurements_on_failure(&mut self) {
    let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
    if num_consecutive_failures >= 2 { // Clear after 2 failures
        self.recorded_latency_ping_durations_secs.clear();
    }
}
```

3. **Use a high default latency instead of 0.0**:

```rust
// In storage.rs, line 461:
.unwrap_or(f64::MAX) // Or use a high value like 999.0
```

4. **Add timestamp validation** to detect stale measurements:

```rust
// Track measurement timestamps and invalidate data older than a threshold
const MAX_LATENCY_DATA_AGE_SECS: u64 = 60;
```

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_stale_latency_causes_slow_peer_selection() {
    // Setup: Create JWK consensus with 4 validators
    let validators = vec![peer1, peer2, peer3, peer4];
    
    // Step 1: peer1 has good initial latency (50ms)
    update_peer_latency(peer1, 0.05); // 50ms
    update_peer_latency(peer2, 0.1);  // 100ms
    update_peer_latency(peer3, 0.15); // 150ms
    update_peer_latency(peer4, 0.2);  // 200ms
    
    // Step 2: peer1 becomes slow but latency pings timeout
    // Simulate 3 consecutive latency ping timeouts for peer1
    for _ in 0..3 {
        simulate_latency_ping_timeout(peer1);
        advance_time(30_000); // 30 second intervals
    }
    
    // Step 3: Verify peer1 is NOT disconnected (only warning logged)
    assert!(is_peer_connected(peer1));
    
    // Step 4: Verify peer1 still has stale 50ms latency
    let mut peer_list = validators.clone();
    network_sender.sort_peers_by_latency(&mut peer_list);
    
    // Step 5: peer1 should be sorted first (lowest latency)
    assert_eq!(peer_list[0], peer1);
    
    // Step 6: Attempt JWK consensus broadcast
    let start = Instant::now();
    let result = reliable_broadcast.broadcast(message, aggregator).await;
    let duration = start.elapsed();
    
    // Step 7: Verify significant delay due to peer1 timeout (1 second)
    assert!(duration > Duration::from_secs(1));
    
    // Step 8: Demonstrate that if all latency data expires, it's even worse
    clear_all_latency_measurements(peer1);
    network_sender.sort_peers_by_latency(&mut peer_list);
    
    // peer1 now has 0.0 default latency - sorted absolutely first!
    assert_eq!(peer_list[0], peer1);
}
```

## Notes

The vulnerability is exacerbated by the disconnect between two independent ping systems:
1. **Health Checker** (10-second interval, disconnects after 3 failures) [9](#0-8) 
2. **Latency Monitoring** (30-second interval, only logs warnings) [10](#0-9) 

A validator can remain connected (passing health checks) while having stale latency data, creating the exact conditions for this vulnerability. The comment on line 444 incorrectly states "decreasing latency" when the actual sort order is ascending (lowest first), which may indicate developer confusion about the behavior.

### Citations

**File:** crates/aptos-jwk-consensus/src/network_interface.rs (L86-89)
```rust
    pub fn sort_peers_by_latency(&self, peers: &mut [PeerId]) {
        self.network_client
            .sort_peers_by_latency(NetworkId::Validator, peers)
    }
```

**File:** network/framework/src/application/storage.rs (L444-470)
```rust
    /// Sorts the give peer slice in the order of decreasing latency.
    pub fn sort_peers_by_latency(&self, network_id: NetworkId, peers: &mut [PeerId]) {
        let _timer = counters::OP_MEASURE
            .with_label_values(&["sort_peers"])
            .start_timer();

        let cached_peers_and_metadata = self.cached_peers_and_metadata.load();

        peers.sort_unstable_by(|peer_network_a, peer_network_b| {
            let get_latency = |&network_id, peer| -> f64 {
                cached_peers_and_metadata
                    .get(&network_id)
                    .and_then(|peers| peers.get(peer))
                    .and_then(|peer| {
                        peer.get_peer_monitoring_metadata()
                            .average_ping_latency_secs
                    })
                    .unwrap_or_default()
            };

            let a_latency = get_latency(&network_id, peer_network_a);
            let b_latency = get_latency(&network_id, peer_network_b);
            b_latency
                .partial_cmp(&a_latency)
                .expect("latency is never NaN")
        })
    }
```

**File:** config/src/config/peer_monitoring_config.rs (L47-56)
```rust
impl Default for LatencyMonitoringConfig {
    fn default() -> Self {
        Self {
            latency_ping_interval_ms: 30_000, // 30 seconds
            latency_ping_timeout_ms: 20_000,  // 20 seconds
            max_latency_ping_failures: 3,
            max_num_latency_pings_to_retain: 10,
        }
    }
}
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L59-72)
```rust
    /// Handles a ping failure for the specified peer
    fn handle_request_failure(&self, peer_network_id: &PeerNetworkId) {
        // Update the number of ping failures for the request tracker
        self.request_tracker.write().record_response_failure();

        // TODO: If the number of ping failures is too high, disconnect from the node
        let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
        if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::TooManyPingFailures)
                .peer(peer_network_id)
                .message("Too many ping failures occurred for the peer!"));
        }
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L161-166)
```rust
            let mut receivers = receivers;
            network_sender.sort_peers_by_latency(&mut receivers);

            for receiver in receivers {
                rpc_futures.push(send_message(receiver, None));
            }
```

**File:** crates/aptos-jwk-consensus/src/epoch_manager.rs (L204-212)
```rust
            let rb = ReliableBroadcast::new(
                self.my_addr,
                epoch_state.verifier.get_ordered_account_addresses(),
                Arc::new(network_sender),
                ExponentialBackoff::from_millis(5),
                aptos_time_service::TimeService::real(),
                Duration::from_millis(1000),
                BoundedExecutor::new(8, tokio::runtime::Handle::current()),
            );
```

**File:** config/src/config/network_config.rs (L38-40)
```rust
pub const PING_INTERVAL_MS: u64 = 10_000;
pub const PING_TIMEOUT_MS: u64 = 20_000;
pub const PING_FAILURES_TOLERATED: u64 = 3;
```
