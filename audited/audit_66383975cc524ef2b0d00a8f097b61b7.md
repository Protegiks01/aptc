# Audit Report

## Title
Liveness Vulnerability: Indefinite Blocking in ExecutionSchedulePhase Due to Missing Timeouts and Non-Abortable Futures

## Summary
The `ExecutionSchedulePhase::process()` function can experience permanent liveness loss when processing ordered blocks due to missing timeout mechanisms and non-abortable execution futures. If any block's `ledger_update` operation hangs indefinitely (due to executor bugs, resource exhaustion, or database issues), all descendant blocks and future execution are permanently blocked, causing total loss of network liveness.

## Finding Description

The vulnerability exists in the execution pipeline's dependency chain and lack of timeout/abort mechanisms: [1](#0-0) 

The `process()` function creates a future that sequentially waits for compute results from each block. For each block, it calls `wait_for_compute_result().await`: [2](#0-1) 

This awaits the `ledger_update_fut`, which is created without abort handles (making it non-abortable): [3](#0-2) 

The critical issue is in the `ledger_update` function's parent dependency: [4](#0-3) 

Each block's ledger_update **must wait** for its parent's ledger_update to complete. This creates a dependency chain where if any parent block's ledger_update hangs, all descendants are blocked.

The executor calls are wrapped in `spawn_blocking` without timeouts: [5](#0-4) 

**Attack Scenario:**

While Byzantine validators cannot directly craft blocks that hang execution selectively, the system's lack of defensive mechanisms means:

1. Any bug in the executor, database deadlock, or resource exhaustion can cause `ledger_update` to hang
2. Once one block hangs, the dependency chain propagates the hang to all future blocks
3. The reset mechanism cannot help because it waits for non-abortable futures: [6](#0-5) [7](#0-6) 

The `wait_until_finishes()` will hang indefinitely if `ledger_update_fut` never completes.

## Impact Explanation

**Critical Severity** - Total loss of liveness/network availability. Once a block's execution hangs, the entire consensus network becomes permanently blocked:

- No new blocks can be executed (execution pipeline blocked)
- No transactions can be committed (consensus cannot progress)
- Network requires manual intervention or hard fork to recover
- All validator nodes affected simultaneously

This meets the **Critical Severity** criteria: "Total loss of liveness/network availability" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Moderate to High Likelihood:**

- Requires a trigger condition (executor bug, database issue, resource exhaustion)
- Does NOT require Byzantine validator behavior - can occur naturally
- No defense mechanisms exist (no timeouts, cannot abort)
- Once triggered, affects 100% of validators simultaneously
- The dependency chain amplifies the impact across all future blocks

The lack of timeouts and abort mechanisms means any transient issue becomes permanent.

## Recommendation

Implement multi-layered timeout and abort mechanisms:

1. **Add timeout to wait_for_compute_result():**
```rust
pub async fn wait_for_compute_result(&self) -> ExecutorResult<(StateComputeResult, Duration)> {
    let fut = self.pipeline_futs()
        .ok_or(ExecutorError::InternalError {
            error: "Pipeline aborted".to_string(),
        })?
        .ledger_update_fut;
    
    // Add timeout (e.g., 30 seconds)
    tokio::time::timeout(Duration::from_secs(30), fut)
        .await
        .map_err(|_| ExecutorError::InternalError {
            error: "Ledger update timeout".to_string(),
        })?
        .map(|(compute_result, execution_time, _)| (compute_result, execution_time))
        .map_err(|e| ExecutorError::InternalError {
            error: e.to_string(),
        })
}
```

2. **Make critical futures abortable:** [8](#0-7) 

Change `None` to `Some(&mut abort_handles)` for `execute_fut` and `ledger_update_fut`.

3. **Add timeout to spawn_blocking operations:**
```rust
let result = tokio::time::timeout(
    Duration::from_secs(30),
    tokio::task::spawn_blocking(move || {
        executor.ledger_update(block_clone.id(), block_clone.parent_id())
            .map_err(anyhow::Error::from)
    })
).await
.map_err(|_| anyhow!("Ledger update timeout"))??;
```

## Proof of Concept

This is difficult to create a direct PoC since it requires triggering executor hanging conditions. However, the vulnerability can be demonstrated conceptually:

```rust
// Hypothetical test demonstrating the hang
#[tokio::test]
async fn test_execution_schedule_phase_hangs_on_blocked_ledger_update() {
    // Create a mock block that will hang in ledger_update
    let hanging_block = create_mock_hanging_block();
    let dependent_block = create_block_with_parent(hanging_block.id());
    
    let ordered_blocks = vec![hanging_block, dependent_block];
    let phase = ExecutionSchedulePhase::new();
    
    let request = ExecutionRequest { ordered_blocks };
    
    // This will hang indefinitely with no timeout
    let result = tokio::time::timeout(
        Duration::from_secs(5),
        phase.process(request)
    ).await;
    
    // Test expects timeout, proving the vulnerability
    assert!(result.is_err(), "ExecutionSchedulePhase should timeout but hangs indefinitely");
}
```

The actual trigger would require:
- Injecting a fault into the executor's database layer
- Causing resource exhaustion in the blocking thread pool
- Exploiting a bug in the executor's state management

**Notes**

This vulnerability represents a **fundamental liveness guarantee failure** in the consensus protocol. The sequential processing model combined with unabortable, timeout-less futures means any transient issue becomes a permanent network failure. While not directly exploitable by Byzantine validators in a targeted manner, the lack of defensive mechanisms makes the system extremely fragile to:

- Database deadlocks or I/O hangs
- Resource exhaustion scenarios  
- Executor bugs that cause infinite loops
- Network or storage layer issues

The impact is catastrophic because once triggered, recovery requires manual intervention or a hard fork. All honest validators are affected simultaneously, making this a critical availability vulnerability even though it's not a traditional Byzantine fault scenario.

### Citations

**File:** consensus/src/pipeline/execution_schedule_phase.rs (L70-77)
```rust
        let fut = async move {
            for b in ordered_blocks.iter_mut() {
                let (compute_result, execution_time) = b.wait_for_compute_result().await?;
                b.set_compute_result(compute_result, execution_time);
            }
            Ok(ordered_blocks)
        }
        .boxed();
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L103-113)
```rust
    // Wait for futures involved executor/state sync to complete
    pub async fn wait_until_finishes(self) {
        let _ = join5(
            self.execute_fut,
            self.ledger_update_fut,
            self.pre_commit_fut,
            self.commit_ledger_fut,
            self.notify_state_sync_fut,
        )
        .await;
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L549-560)
```rust
    pub async fn wait_for_compute_result(&self) -> ExecutorResult<(StateComputeResult, Duration)> {
        self.pipeline_futs()
            .ok_or(ExecutorError::InternalError {
                error: "Pipeline aborted".to_string(),
            })?
            .ledger_update_fut
            .await
            .map(|(compute_result, execution_time, _)| (compute_result, execution_time))
            .map_err(|e| ExecutorError::InternalError {
                error: e.to_string(),
            })
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L489-511)
```rust
        let execute_fut = spawn_shared_fut(
            Self::execute(
                prepare_fut.clone(),
                parent.execute_fut.clone(),
                rand_check_fut.clone(),
                self.executor.clone(),
                block.clone(),
                self.validators.clone(),
                self.block_executor_onchain_config.clone(),
                self.persisted_auxiliary_info_version,
            ),
            None,
        );
        let ledger_update_fut = spawn_shared_fut(
            Self::ledger_update(
                rand_check_fut.clone(),
                execute_fut.clone(),
                parent.ledger_update_fut.clone(),
                self.executor.clone(),
                block.clone(),
            ),
            None,
        );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L874-883)
```rust
    async fn ledger_update(
        rand_check: TaskFuture<RandResult>,
        execute_fut: TaskFuture<ExecuteResult>,
        parent_block_ledger_update_fut: TaskFuture<LedgerUpdateResult>,
        executor: Arc<dyn BlockExecutorTrait>,
        block: Arc<Block>,
    ) -> TaskResult<LedgerUpdateResult> {
        let mut tracker = Tracker::start_waiting("ledger_update", &block);
        let (_, _, prev_epoch_end_timestamp) = parent_block_ledger_update_fut.await?;
        let execution_time = execute_fut.await?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L887-893)
```rust
        let result = tokio::task::spawn_blocking(move || {
            executor
                .ledger_update(block_clone.id(), block_clone.parent_id())
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```

**File:** consensus/src/pipeline/buffer_manager.rs (L552-557)
```rust
        while let Some(item) = self.buffer.pop_front() {
            for b in item.get_blocks() {
                if let Some(futs) = b.abort_pipeline() {
                    futs.wait_until_finishes().await;
                }
            }
```
