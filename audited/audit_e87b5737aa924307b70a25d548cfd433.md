# Audit Report

## Title
Unmetered EpochRetrievalRequest Abuse Enables Validator Free-Riding and Resource Exhaustion

## Summary
The `EpochRetrievalRequest` handling in the consensus layer lacks rate limiting, request tracking, and gas costs. Malicious validators can spam these requests to force honest validators to perform expensive database queries and network transmissions, effectively offloading blockchain state storage costs while degrading honest validator performance.

## Finding Description

The `EpochRetrievalRequest` mechanism allows validators to request epoch change proofs from peers to catch up when behind. However, the implementation has no safeguards against abuse: [1](#0-0) 

The `process_epoch_retrieval` method performs expensive operations without any cost or rate limiting: [2](#0-1) 

**Key vulnerabilities:**

1. **No per-peer request tracking**: The same peer can send unlimited requests with no deduplication
2. **No rate limiting**: Only generic network byte-rate limits exist (100 KiB/s), but these don't prevent request spam
3. **No request cost**: Database queries execute before any throttling occurs
4. **No backoff mechanism**: Honest validators respond to every request immediately

The database query can retrieve up to 100 epoch ending ledger infos per request: [3](#0-2) [4](#0-3) 

**Attack Flow:**

1. Malicious validator joins network but doesn't store full blockchain state
2. Periodically sends `EpochRetrievalRequest(start_epoch: 0, end_epoch: current)` to multiple honest validators
3. Each honest validator:
   - Queries RocksDB via `get_epoch_ending_ledger_info_iter` (lines 1050-1054)
   - Loads up to 100 `LedgerInfoWithSignatures` into memory
   - Serializes into `EpochChangeProof` 
   - Transmits potentially megabytes of data back [5](#0-4) 

4. Malicious validator avoids storage costs and can request same data repeatedly
5. Honest validators experience CPU (DB reads), memory (data loading), disk I/O, and network bandwidth exhaustion

**No Protection Found:**

Network-level rate limiting is optional and byte-based, not request-count based: [6](#0-5) [7](#0-6) 

The constants show 100 KiB/s per IP, which is generous and doesn't prevent request flooding: [8](#0-7) 

## Impact Explanation

**Medium Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: Repeated database queries and network transmissions degrade performance on honest validators
- **State inconsistencies requiring intervention**: If many validators adopt free-riding behavior, network reliability degrades
- **Resource exhaustion**: Honest validators subsidize malicious validators' operation costs

This breaks the **Resource Limits** invariant: consensus-layer operations are supposed to respect computational limits, but EpochRetrievalRequest handling has unbounded per-peer cost.

While not directly causing fund loss or consensus safety violations, this enables a form of validator "parasitism" where malicious actors can participate in the network without bearing honest participation costs (storing blockchain state).

## Likelihood Explanation

**High likelihood** of exploitation:

- **Low attacker barrier**: Any validator can send these messages; no special privileges required
- **Easy to automate**: Simple to script periodic `EpochRetrievalRequest` messages
- **Economic incentive**: Storage costs for full nodes are significant; avoiding them is profitable
- **No detection**: Without per-peer metrics, abuse is hard to distinguish from legitimate catch-up

The only friction is that validators must authenticate via NoiseIK protocol, but this is normal validator network participation.

## Recommendation

Implement multi-layered protections:

**1. Per-Peer Request Tracking with Rate Limiting:**

```rust
// In EpochManager struct, add:
struct EpochManager {
    // ... existing fields ...
    epoch_request_tracker: Arc<Mutex<HashMap<AccountAddress, RequestTracker>>>,
}

struct RequestTracker {
    last_request_time: Instant,
    request_count: usize,
    last_requested_range: Option<(u64, u64)>,
}

// In process_epoch_retrieval, add:
fn process_epoch_retrieval(
    &mut self,
    request: EpochRetrievalRequest,
    peer_id: AccountAddress,
) -> anyhow::Result<()> {
    // Rate limiting check
    let mut tracker_map = self.epoch_request_tracker.lock();
    let tracker = tracker_map.entry(peer_id).or_insert_with(|| RequestTracker {
        last_request_time: Instant::now(),
        request_count: 0,
        last_requested_range: None,
    });
    
    // Allow max 10 requests per minute per peer
    const MAX_REQUESTS_PER_MINUTE: usize = 10;
    const REQUEST_WINDOW: Duration = Duration::from_secs(60);
    
    if tracker.last_request_time.elapsed() < REQUEST_WINDOW {
        tracker.request_count += 1;
        if tracker.request_count > MAX_REQUESTS_PER_MINUTE {
            warn!("Peer {} exceeded epoch retrieval rate limit", peer_id);
            return Ok(()); // Silently drop
        }
    } else {
        tracker.request_count = 1;
        tracker.last_request_time = Instant::now();
    }
    
    // Deduplication: Check if same range was requested recently
    if let Some((last_start, last_end)) = tracker.last_requested_range {
        if last_start == request.start_epoch && last_end == request.end_epoch {
            if tracker.last_request_time.elapsed() < Duration::from_secs(30) {
                return Ok(()); // Ignore duplicate request within 30s
            }
        }
    }
    tracker.last_requested_range = Some((request.start_epoch, request.end_epoch));
    
    // ... existing code to fetch and send proof ...
}
```

**2. Response Caching:**
Cache recently sent `EpochChangeProof` objects to avoid redundant database queries.

**3. Backpressure Signaling:**
If a peer requests too frequently, send a backpressure signal or temporarily reduce priority of their requests.

**4. Reputation Integration:**
Track epoch retrieval abuse in the leader reputation system to penalize free-riding validators.

## Proof of Concept

```rust
// Add to consensus/src/epoch_manager_test.rs

#[tokio::test]
async fn test_epoch_retrieval_spam() {
    // Setup: Create two validators, victim and attacker
    let (mut victim_epoch_mgr, mut attacker_network) = setup_epoch_manager_test();
    
    // Attacker sends 100 rapid EpochRetrievalRequests for the same epoch range
    let request = EpochRetrievalRequest {
        start_epoch: 0,
        end_epoch: 10,
    };
    
    let start_time = Instant::now();
    let mut db_query_count = 0;
    
    for _ in 0..100 {
        // Send request
        let msg = ConsensusMsg::EpochRetrievalRequest(Box::new(request.clone()));
        victim_epoch_mgr.process_message(attacker_peer_id, msg).await;
        
        // Count database queries (would need instrumentation)
        db_query_count += 1;
    }
    
    let elapsed = start_time.elapsed();
    
    // Verify: All 100 requests triggered database queries
    // Expected: Should have been rate-limited after ~10 requests
    assert!(db_query_count == 100, 
        "Vulnerability: All {} requests were processed without rate limiting", 
        db_query_count);
    
    // Verify: No per-peer tracking exists
    // Expected: Should have cached/deduplicated identical requests
    assert!(elapsed < Duration::from_secs(1),
        "All requests processed in {}ms without deduplication",
        elapsed.as_millis());
}
```

**Notes:**
- Network-level rate limiting (100 KiB/s) only throttles response bytes after queries execute
- Multiple connections from different IPs can bypass IP-based limits
- The `MAX_NUM_EPOCH_ENDING_LEDGER_INFO` limit (100 epochs) caps response size but doesn't prevent request spam
- Validators using this attack can maintain voting power while avoiding state storage costs, creating unfair economic advantage

### Citations

**File:** consensus/src/epoch_manager.rs (L451-476)
```rust
    fn process_epoch_retrieval(
        &mut self,
        request: EpochRetrievalRequest,
        peer_id: AccountAddress,
    ) -> anyhow::Result<()> {
        debug!(
            LogSchema::new(LogEvent::ReceiveEpochRetrieval)
                .remote_peer(peer_id)
                .epoch(self.epoch()),
            "[EpochManager] receive {}", request,
        );
        let proof = self
            .storage
            .aptos_db()
            .get_epoch_ending_ledger_infos(request.start_epoch, request.end_epoch)
            .map_err(DbError::from)
            .context("[EpochManager] Failed to get epoch proof")?;
        let msg = ConsensusMsg::EpochChangeProof(Box::new(proof));
        if let Err(err) = self.network_sender.send_to(peer_id, msg) {
            warn!(
                "[EpochManager] Failed to send epoch proof to {}, with error: {:?}",
                peer_id, err,
            );
        }
        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L1677-1686)
```rust
            ConsensusMsg::EpochRetrievalRequest(request) => {
                ensure!(
                    request.end_epoch <= self.epoch(),
                    "[EpochManager] Received EpochRetrievalRequest beyond what we have locally"
                );
                monitor!(
                    "process_epoch_retrieval",
                    self.process_epoch_retrieval(*request, peer_id)
                )?;
            },
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L995-1005)
```rust
    fn get_epoch_ending_ledger_infos(
        &self,
        start_epoch: u64,
        end_epoch: u64,
    ) -> Result<(Vec<LedgerInfoWithSignatures>, bool)> {
        self.get_epoch_ending_ledger_infos_impl(
            start_epoch,
            end_epoch,
            MAX_NUM_EPOCH_ENDING_LEDGER_INFO,
        )
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1036-1064)
```rust
    pub(super) fn get_epoch_ending_ledger_infos_impl(
        &self,
        start_epoch: u64,
        end_epoch: u64,
        limit: usize,
    ) -> Result<(Vec<LedgerInfoWithSignatures>, bool)> {
        self.check_epoch_ending_ledger_infos_request(start_epoch, end_epoch)?;

        let (paging_epoch, more) = if end_epoch - start_epoch > limit as u64 {
            (start_epoch + limit as u64, true)
        } else {
            (end_epoch, false)
        };

        let lis = self
            .ledger_db
            .metadata_db()
            .get_epoch_ending_ledger_info_iter(start_epoch, paging_epoch)?
            .collect::<Result<Vec<_>>>()?;

        ensure!(
            lis.len() == (paging_epoch - start_epoch) as usize,
            "DB corruption: missing epoch ending ledger info for epoch {}",
            lis.last()
                .map(|li| li.ledger_info().next_block_epoch() - 1)
                .unwrap_or(start_epoch),
        );
        Ok((lis, more))
    }
```

**File:** storage/aptosdb/src/common.rs (L9-9)
```rust
pub(crate) const MAX_NUM_EPOCH_ENDING_LEDGER_INFO: usize = 100;
```

**File:** config/src/config/network_config.rs (L52-53)
```rust
pub const IP_BYTE_BUCKET_RATE: usize = 102400 /* 100 KiB */;
pub const IP_BYTE_BUCKET_SIZE: usize = IP_BYTE_BUCKET_RATE;
```

**File:** config/src/config/network_config.rs (L116-119)
```rust
    /// Inbound rate limiting configuration, if not specified, no rate limiting
    pub inbound_rate_limit_config: Option<RateLimitConfig>,
    /// Outbound rate limiting configuration, if not specified, no rate limiting
    pub outbound_rate_limit_config: Option<RateLimitConfig>,
```

**File:** config/src/config/network_config.rs (L368-377)
```rust
pub struct RateLimitConfig {
    /// Maximum number of bytes/s for an IP
    pub ip_byte_bucket_rate: usize,
    /// Maximum burst of bytes for an IP
    pub ip_byte_bucket_size: usize,
    /// Initial amount of tokens initially in the bucket
    pub initial_bucket_fill_percentage: u8,
    /// Allow for disabling the throttles
    pub enabled: bool,
}
```
