# Audit Report

## Title
Consensus Configuration Parse Failure Can Cause Network Split During Epoch Transitions

## Summary
The `start_new_epoch()` function in `epoch_manager.rs` silently falls back to a default consensus configuration when on-chain config parsing fails, without any validation that all validators are using the same configuration. This can lead to validators operating under different consensus rules, causing a consensus split and network partition.

## Finding Description

In the epoch transition logic, when validators receive reconfiguration notifications, they attempt to parse the on-chain consensus configuration. If parsing fails, validators silently fall back to a hardcoded default configuration and continue operation. [1](#0-0) 

The critical issue is that parsing failure only generates a warning, not an error or panic. Different validators could obtain different parse results in the following scenarios:

1. **Version Mismatch During Rolling Upgrades**: When validators run different code versions (e.g., during rolling upgrades), a new config format like `OnChainConsensusConfig::V5` may be published that older validators cannot deserialize. Old validators fall back to the default V4 configuration, while new validators use the actual V5 configuration.

2. **Malformed Configuration Data**: If governance publishes a consensus config with corrupted or malformed BCS-serialized bytes, some validators may fail to parse it while others might handle the error differently.

The default configuration differs significantly from potential on-chain configurations: [2](#0-1) 

Key differences include:
- Default uses Jolteon consensus, but on-chain could specify DAG
- Default has `order_vote_enabled: false`, but on-chain could have it enabled
- Different proposer election mechanisms
- Different validator transaction configurations

Most critically, the code branches into completely different consensus protocols based on the config: [3](#0-2) 

If some validators execute `start_new_epoch_with_dag()` while others execute `start_new_epoch_with_jolteon()`, they are running incompatible consensus protocols and cannot communicate or reach agreement.

Furthermore, there is no mechanism to detect or prevent this divergence:
- `EpochState` contains only epoch number and validator verifier, no config commitment: [4](#0-3) 

- Block data structures do not include any consensus config hash or verification
- No consensus validation that all validators successfully parsed the same configuration

## Impact Explanation

This vulnerability meets **Critical Severity** criteria as it can cause:

1. **Consensus/Safety Violations**: Validators operating under different consensus rules violate the fundamental safety property that all honest validators follow the same protocol. This breaks the "Consensus Safety" invariant that AptosBFT must prevent chain splits under < 1/3 Byzantine nodes.

2. **Non-recoverable Network Partition**: If validators split between DAG and Jolteon consensus (or other fundamental configuration differences), they cannot communicate or reach consensus. This creates a permanent network partition that requires a hard fork to resolve.

3. **Total Loss of Liveness**: The network would halt as validators cannot form quorums when operating under different consensus rules.

## Likelihood Explanation

**Likelihood: Medium to High** during operational events

This can occur in realistic scenarios:

1. **During Rolling Upgrades**: When validators are upgrading their software in a staggered manner (standard practice for availability), there's a window where different validators run different code versions. If a governance proposal to update consensus config is executed during this window using a newer format, the split occurs immediately.

2. **Malformed Config Publication**: While governance requires stake and approval, bugs in config serialization or human error during proposal creation could result in malformed bytes being published. The Move validation only checks that bytes are non-empty, not that they're valid: [5](#0-4) 

3. **Accidental Misconfiguration**: An honest governance proposal could accidentally publish a config format that some validators cannot parse, especially if proposers are unaware of the version distribution across validators.

The vulnerability is not easily exploitable by a single malicious unprivileged attacker, but can be triggered through:
- Operational timing during upgrades
- Governance proposal errors (governance proposals can be submitted by any participant with sufficient stake)
- Coordination failures during network upgrades

## Recommendation

Implement multiple safeguards to prevent configuration divergence:

1. **Fail-Safe on Parse Errors**: Instead of falling back to default, validators should panic or halt if they cannot parse the on-chain configuration. This ensures the issue is detected immediately rather than causing a silent split:

```rust
let consensus_config = onchain_consensus_config
    .expect("CRITICAL: Failed to parse on-chain consensus config. This validator cannot safely proceed with epoch transition.");
```

2. **Include Config Commitment in EpochState**: Add a hash of the consensus configuration to the `EpochState` struct so that validators must agree on the configuration as part of epoch validation:

```rust
pub struct EpochState {
    pub epoch: u64,
    pub verifier: Arc<ValidatorVerifier>,
    pub consensus_config_hash: HashValue, // Add this field
}
```

3. **Version Compatibility Checks**: Add explicit version checks before epoch transition to ensure all validators can handle the config format:

```rust
if let Err(error) = &onchain_consensus_config {
    error!("CRITICAL: Failed to read on-chain consensus config: {}", error);
    panic!("Cannot proceed with epoch transition - incompatible consensus config");
}
```

4. **Move Contract Validation**: Add validation in the Move contract to check that config bytes are deserializable before accepting them:

```move
public fun set_for_next_epoch(account: &signer, config: vector<u8>) {
    system_addresses::assert_aptos_framework(account);
    assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
    // Add: assert!(validate_config_format(&config), error::invalid_argument(EINVALID_CONFIG));
    std::config_buffer::upsert<ConsensusConfig>(ConsensusConfig {config});
}
```

## Proof of Concept

This vulnerability requires operational coordination to demonstrate, but the flow would be:

1. Deploy a test network with validators running different code versions (e.g., mix of v1.8 and v1.9)
2. Submit a governance proposal to update consensus config using a format only recognized by v1.9
3. Execute the governance proposal to trigger epoch change
4. Observe that v1.8 validators log warnings and use default config
5. Observe that v1.9 validators use the new config
6. Verify that the two groups cannot form consensus (network halts or splits)

**Rust Test Pseudocode:**
```rust
#[test]
fn test_consensus_split_on_parse_failure() {
    // Setup: Two validators with different config parsing behavior
    let mut validator_a = setup_validator_with_config_parser_v1();
    let mut validator_b = setup_validator_with_config_parser_v2();
    
    // Publish a V5 config that V1 parser cannot handle
    let v5_config = create_v5_consensus_config();
    publish_config_to_storage(&v5_config);
    
    // Trigger epoch transition for both validators
    let payload = create_reconfig_payload_at_version(epoch_version);
    
    validator_a.start_new_epoch(payload.clone()).await;
    validator_b.start_new_epoch(payload.clone()).await;
    
    // Assert: They should be using different configs
    assert_ne!(
        validator_a.get_consensus_config(),
        validator_b.get_consensus_config()
    );
    
    // Assert: They cannot form consensus
    assert!(validators_cannot_reach_consensus(validator_a, validator_b));
}
```

---

**Notes:**

While this vulnerability has a clear potential impact, the practical exploitability is limited because:
- It requires either a rolling upgrade window or governance to publish problematic configs
- Governance is generally a trusted component in the Aptos security model
- Production deployments should coordinate upgrades to avoid this scenario

However, the **lack of defensive programming** is concerning. The code should fail-safe rather than silently diverge, as the consequences of configuration mismatch are catastrophic to consensus. The vulnerability demonstrates a violation of defense-in-depth principles and could be triggered by operational errors, bugs in config serialization, or malicious governance proposals.

### Citations

**File:** consensus/src/epoch_manager.rs (L1178-1201)
```rust
        let onchain_consensus_config: anyhow::Result<OnChainConsensusConfig> = payload.get();
        let onchain_execution_config: anyhow::Result<OnChainExecutionConfig> = payload.get();
        let onchain_randomness_config_seq_num: anyhow::Result<RandomnessConfigSeqNum> =
            payload.get();
        let randomness_config_move_struct: anyhow::Result<RandomnessConfigMoveStruct> =
            payload.get();
        let onchain_jwk_consensus_config: anyhow::Result<OnChainJWKConsensusConfig> = payload.get();
        let dkg_state = payload.get::<DKGState>();

        if let Err(error) = &onchain_consensus_config {
            warn!("Failed to read on-chain consensus config {}", error);
        }

        if let Err(error) = &onchain_execution_config {
            warn!("Failed to read on-chain execution config {}", error);
        }

        if let Err(error) = &randomness_config_move_struct {
            warn!("Failed to read on-chain randomness config {}", error);
        }

        self.epoch_state = Some(epoch_state.clone());

        let consensus_config = onchain_consensus_config.unwrap_or_default();
```

**File:** consensus/src/epoch_manager.rs (L1293-1328)
```rust
        if consensus_config.is_dag_enabled() {
            warn!("DAG doesn't support secret sharing");
            self.start_new_epoch_with_dag(
                epoch_state,
                loaded_consensus_key.clone(),
                consensus_config,
                execution_config,
                onchain_randomness_config,
                jwk_consensus_config,
                network_sender,
                payload_client,
                payload_manager,
                rand_config,
                fast_rand_config,
                rand_msg_rx,
                secret_share_manager_rx,
            )
            .await
        } else {
            self.start_new_epoch_with_jolteon(
                loaded_consensus_key.clone(),
                epoch_state,
                consensus_config,
                execution_config,
                onchain_randomness_config,
                jwk_consensus_config,
                network_sender,
                payload_client,
                payload_manager,
                rand_config,
                fast_rand_config,
                rand_msg_rx,
                secret_share_manager_rx,
            )
            .await
        }
```

**File:** types/src/on_chain_config/consensus_config.rs (L443-451)
```rust
impl Default for OnChainConsensusConfig {
    fn default() -> Self {
        OnChainConsensusConfig::V4 {
            alg: ConsensusAlgorithmConfig::default_if_missing(),
            vtxn: ValidatorTxnConfig::default_if_missing(),
            window_size: DEFAULT_WINDOW_SIZE,
        }
    }
}
```

**File:** types/src/epoch_state.rs (L19-22)
```rust
pub struct EpochState {
    pub epoch: u64,
    pub verifier: Arc<ValidatorVerifier>,
}
```

**File:** aptos-move/framework/aptos-framework/sources/configs/consensus_config.move (L23-27)
```text
    public(friend) fun initialize(aptos_framework: &signer, config: vector<u8>) {
        system_addresses::assert_aptos_framework(aptos_framework);
        assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
        move_to(aptos_framework, ConsensusConfig { config });
    }
```
