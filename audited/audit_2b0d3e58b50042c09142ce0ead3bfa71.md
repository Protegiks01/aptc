# Audit Report

## Title
Lost Update Vulnerability in GCS Metadata Writes Allows Backup Metadata Rollback

## Summary
The `update_metadata()` function in the GCS backup system lacks atomic write protection, allowing concurrent updates from multiple nodes to arbitrarily overwrite each other. This creates a race condition where a slower node can overwrite metadata written by a faster node, causing the metadata to incorrectly reference an older epoch than the latest available snapshot, resulting in data loss during restore operations.

## Finding Description

The table info backup system has a critical Time-Of-Check-To-Time-Of-Use (TOCTOU) race condition between reading metadata and updating it. The vulnerability exists in the interaction between two functions:

1. **Metadata Check** (table_info_service.rs): The system reads the current metadata to determine if a backup is needed. [1](#0-0) 

2. **Metadata Update** (gcs.rs): After uploading a snapshot, the system writes new metadata without any concurrency control. [2](#0-1) 

The `update_metadata()` function uses `UploadObjectRequest` with default parameters, which provides no preconditions like `if_generation_match` or `if_metageneration_match` to prevent concurrent write conflicts. [3](#0-2) 

**Attack Scenario:**

1. Initial state: `metadata.json` contains `{ chain_id: 1, epoch: 100 }`
2. Node A (slow) reaches epoch 101, reads metadata showing epoch 100, proceeds to backup
3. Node B (fast) reaches epoch 101, reads metadata showing epoch 100, proceeds to backup
4. Node B completes upload and updates metadata to epoch 101
5. Node B continues processing, reaches epoch 102, uploads snapshot, updates metadata to epoch 102
6. Node A finally completes its epoch 101 upload and updates metadata to epoch 101
7. **Final state**: metadata shows epoch 101, but snapshot for epoch 102 exists and is orphaned

The developers acknowledge this issue exists: [4](#0-3) 

## Impact Explanation

This vulnerability causes **state inconsistencies requiring manual intervention**, qualifying as **Medium severity** under Aptos bug bounty criteria:

- **Data Loss on Restore**: When a fullnode needs to restore from backup, it reads the metadata to determine which snapshot to use. With corrupted metadata pointing to epoch 101 instead of 102, the restore process will use an older snapshot, losing all indexed data from the later epoch.

- **Indexer Inconsistency**: Fullnodes serving indexer queries would have inconsistent data compared to the actual blockchain state, affecting external applications and users relying on table info data.

- **Operational Impact**: Requires manual intervention to detect and correct the metadata inconsistency, as the system has no mechanism to detect or recover from this state automatically.

While this affects indexer infrastructure rather than core consensus, fullnodes rely on accurate backup/restore for operational continuity. The backup system is explicitly part of the fullnode configuration and deployment. [5](#0-4) 

## Likelihood Explanation

**Likelihood: Medium**

This requires:
1. **Misconfiguration**: Multiple fullnodes configured with backup enabled to the same GCS bucket (not enforced by the application)
2. **Timing Conditions**: One node must be significantly slower than another, creating epoch offset
3. **No Explicit Prevention**: The TODO comment confirms this scenario is unhandled

While typical Terraform deployments only enable backup for one node, the application layer does not enforce this constraint. Operators could inadvertently configure multiple backup nodes, or nodes could be redeployed/migrated without proper coordination. [6](#0-5) 

## Recommendation

Implement atomic metadata updates using GCS generation/metageneration preconditions:

```rust
pub async fn update_metadata(&self, chain_id: u64, epoch: u64) -> anyhow::Result<()> {
    let metadata = BackupRestoreMetadata::new(chain_id, epoch);
    
    // Read current metadata to get generation number
    let current_generation = match self.get_metadata_with_generation().await {
        Ok((_, generation)) => Some(generation),
        Err(_) => None, // No existing metadata
    };
    
    loop {
        // Set precondition to only succeed if generation matches
        let precondition = current_generation.map(|gen| {
            // Only allow update if our read generation still matches
            format!("if-generation-match: {}", gen)
        });
        
        match self.gcs_client.upload_object_with_precondition(
            &UploadObjectRequest {
                bucket: self.bucket_name.clone(),
                if_generation_match: current_generation,
                ..Default::default()
            },
            serde_json::to_vec(&metadata).unwrap(),
            &UploadType::Simple(Media {
                name: Borrowed(METADATA_FILE_NAME),
                content_type: Borrowed(JSON_FILE_TYPE),
                content_length: None,
            }),
        ).await {
            Ok(_) => return Ok(()),
            Err(Error::Response(err)) if err.code == 412 => {
                // Precondition failed - another node updated metadata
                // Re-read and check if we should still proceed
                match self.get_metadata().await {
                    Some(current) if current.epoch >= epoch => {
                        // Newer or equal epoch already backed up, skip
                        return Ok(());
                    },
                    _ => {
                        // Retry with new generation
                        continue;
                    }
                }
            },
            Err(Error::Response(err)) if err.is_retriable() && err.code == 429 => {
                tokio::time::sleep(Duration::from_millis(500)).await;
                continue;
            },
            Err(err) => anyhow::bail!("Failed to update metadata: {}", err),
        }
    }
}
```

Additionally, add application-level validation to prevent multiple backup nodes from being configured to the same bucket.

## Proof of Concept

```rust
// Simulated PoC demonstrating the race condition
// Note: This requires actual GCS setup and multiple node instances to fully reproduce

#[tokio::test]
async fn test_concurrent_metadata_update_race() {
    let bucket_name = "test-bucket";
    let operator = GcsBackupRestoreOperator::new(bucket_name.to_string()).await;
    
    // Initial state: epoch 100
    operator.update_metadata(1, 100).await.unwrap();
    
    // Spawn two concurrent backup operations
    let op1 = operator.clone();
    let op2 = operator.clone();
    
    let handle1 = tokio::spawn(async move {
        // Slow node backing up epoch 101
        tokio::time::sleep(Duration::from_secs(2)).await;
        op1.update_metadata(1, 101).await.unwrap();
    });
    
    let handle2 = tokio::spawn(async move {
        // Fast node backing up epoch 101 then 102
        op2.update_metadata(1, 101).await.unwrap();
        tokio::time::sleep(Duration::from_millis(100)).await;
        op2.update_metadata(1, 102).await.unwrap();
    });
    
    handle1.await.unwrap();
    handle2.await.unwrap();
    
    // Expected: metadata.epoch == 102
    // Actual: metadata.epoch == 101 (last writer wins, even if older)
    let final_metadata = operator.get_metadata().await.unwrap();
    assert_eq!(final_metadata.epoch, 102, 
        "Metadata should reflect latest epoch 102, but shows {} due to lost update", 
        final_metadata.epoch);
}
```

The test demonstrates that without atomic preconditions, the last writer (slow Node A with epoch 101) can overwrite the metadata written by Node B (with epoch 102), creating an inconsistent state where the metadata points to an older epoch than the latest available snapshot.

## Notes

This vulnerability specifically affects the table info indexer backup/restore system, which is ancillary infrastructure rather than core consensus. However, it represents a valid data integrity issue that can cause operational failures and data loss during disaster recovery scenarios. The explicit TODO comment in the codebase confirms this is a known but unaddressed concurrency issue.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/table_info_service.rs (L544-576)
```rust
    let backup_metadata = backup_restore_operator.get_metadata().await;
    if let Some(metadata) = backup_metadata {
        if metadata.chain_id != (ledger_chain_id as u64) {
            panic!(
                "Table Info backup chain id does not match with current network. Expected: {}, found in backup: {}",
                context.chain_id().id(),
                metadata.chain_id
            );
        }
    } else {
        aptos_logger::warn!(
            epoch = epoch,
            snapshot_folder_name = snapshot_folder_name,
            "[Table Info] No backup metadata found. Skipping the backup."
        );
    }

    let start_time = std::time::Instant::now();
    // temporary path to store the snapshot
    let snapshot_dir = context
        .node_config
        .get_data_dir()
        .join(snapshot_folder_name.clone());
    // If the backup is for old epoch, clean up and return.
    if let Some(metadata) = backup_metadata {
        aptos_logger::info!(
            epoch = epoch,
            metadata_epoch = metadata.epoch,
            snapshot_folder_name = snapshot_folder_name,
            snapshot_dir = snapshot_dir.to_str(),
            "[Table Info] Checking the metadata before backup."
        );
        if metadata.epoch >= epoch {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/table_info_service.rs (L599-599)
```rust
    // TODO: add checks to handle concurrent backup jobs.
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/backup_restore/gcs.rs (L124-162)
```rust
    pub async fn update_metadata(&self, chain_id: u64, epoch: u64) -> anyhow::Result<()> {
        let metadata = BackupRestoreMetadata::new(chain_id, epoch);
        loop {
            match self
                .gcs_client
                .upload_object(
                    &UploadObjectRequest {
                        bucket: self.bucket_name.clone(),
                        ..Default::default()
                    },
                    serde_json::to_vec(&metadata).unwrap(),
                    &UploadType::Simple(Media {
                        name: Borrowed(METADATA_FILE_NAME),
                        content_type: Borrowed(JSON_FILE_TYPE),
                        content_length: None,
                    }),
                )
                .await
            {
                Ok(_) => {
                    aptos_logger::info!(
                        "[Table Info] Successfully updated metadata to GCS bucket: {}",
                        METADATA_FILE_NAME
                    );
                    return Ok(());
                },
                // https://cloud.google.com/storage/quotas
                // add retry logic due to: "Maximum rate of writes to the same object name: One write per second"
                Err(Error::Response(err)) if (err.is_retriable() && err.code == 429) => {
                    info!("Retried with rateLimitExceeded on gcs single object at epoch {} when updating the metadata", epoch);
                    tokio::time::sleep(Duration::from_millis(500)).await;
                    continue;
                },
                Err(err) => {
                    anyhow::bail!("Failed to update metadata: {}", err);
                },
            }
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/runtime.rs (L93-98)
```rust
        let backup_restore_operator = match node_config.indexer_table_info.table_info_service_mode {
            TableInfoServiceMode::Backup(gcs_bucket_name) => Some(Arc::new(
                GcsBackupRestoreOperator::new(gcs_bucket_name).await,
            )),
            _ => None,
        };
```

**File:** terraform/fullnode/gcp/kubernetes.tf (L84-95)
```terraform
      backup = {
        # only enable backup for fullnode 0
        enable       = count.index == var.backup_fullnode_index ? var.enable_backup : false
        nodeSelector = local.utility_nodeSelector
        tolerations  = local.utility_tolerations
        config = {
          location = "gcs"
          gcs = {
            bucket = google_storage_bucket.backup.name
          }
        }
      }
```
