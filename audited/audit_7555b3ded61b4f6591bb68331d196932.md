# Audit Report

## Title
Unbounded Memory Growth in JWK Consensus via Malicious Peer RPC Requests

## Summary
The `KeyLevelConsensusManager` in the JWK consensus subsystem allows unbounded growth of the `states_by_key` HashMap through malicious peer RPC requests. A Byzantine validator can spam `KeyLevelObservationRequest` messages with arbitrary (issuer, kid) pairs, causing memory exhaustion and validator node crashes.

## Finding Description

The vulnerability exists in the `process_peer_request` function which handles incoming RPC requests from peer validators. [1](#0-0) 

When a peer sends a `KeyLevelObservationRequest`, the code unconditionally creates an entry in the `states_by_key` HashMap using `.entry(...).or_default()`, regardless of whether consensus has been started for that (issuer, kid) pair. [2](#0-1) 

The default `ConsensusState` is `NotStarted`. [3](#0-2) 

When the state is `NotStarted`, the function returns early without sending a response. [4](#0-3) 

**Critical Issue**: The entry created by `.entry(...).or_default()` **persists in the HashMap** even though no response is sent.

**Attack Path**:
1. A Byzantine validator crafts `KeyLevelObservationRequest` messages with millions of unique (issuer, kid) pairs
2. Each request creates a new entry in the victim validator's `states_by_key` HashMap
3. The cleanup mechanism in `reset_with_on_chain_state` fails to remove these fake entries [5](#0-4) 
4. For issuers not in on-chain state, both `new_onchain_jwks.get(issuer).unwrap_or_default()` and `self.onchain_jwks.get(issuer).unwrap_or_default()` return 0, so the retention condition `0 == 0` is true, keeping the fake entries
5. Memory grows unbounded until the validator crashes

**Broken Invariant**: "Resource Limits: All operations must respect gas, storage, and computational limits" - The unbounded HashMap growth violates memory resource limits.

## Impact Explanation

This vulnerability enables a **Byzantine validator** (assumed within the 1/3 Byzantine fault tolerance model) to cause memory exhaustion on all honest validators, leading to:

- **Validator node crashes** (High severity per bug bounty: "Validator node slowdowns, API crashes")
- **Network availability degradation** - if multiple validators crash simultaneously (potentially Critical: "Total loss of liveness/network availability")
- **Consensus disruption** - crashed validators cannot participate in consensus

The impact is **High to Critical** severity. A single Byzantine validator can target all honest validators simultaneously by broadcasting spam requests through the P2P network, potentially causing network-wide outages.

## Likelihood Explanation

**Likelihood: Medium to High**

**Requirements**:
- Attacker needs control of one validator node (within BFT threat model)
- No special privileges beyond being a validator
- No rate limiting or request validation exists in the code

**Feasibility**:
- Attack is trivial to execute - simply send RPC requests with unique byte strings for issuer/kid
- No cryptographic challenges or consensus participation required
- Network layer accepts these requests without validation [6](#0-5) 
- The observation interval is every 10 seconds, but RPC requests have no such limitation [7](#0-6) 

**Mitigating Factors**:
- Requires validator stake (economic cost)
- Validator could be identified and removed through governance
- However, damage occurs before removal

## Recommendation

Implement the following mitigations:

1. **Add bounds checking** on `states_by_key` HashMap size:
```rust
const MAX_CONSENSUS_STATES: usize = 1000; // Reasonable limit based on expected OIDC providers

pub fn process_peer_request(&mut self, rpc_req: IncomingRpcRequest) -> Result<()> {
    let IncomingRpcRequest { msg, mut response_sender, .. } = rpc_req;
    match msg {
        JWKConsensusMsg::KeyLevelObservationRequest(request) => {
            let ObservedKeyLevelUpdateRequest { issuer, kid, .. } = request;
            
            // Check if entry exists before creating
            if let Some(consensus_state) = self.states_by_key.get(&(issuer.clone(), kid.clone())) {
                // Process existing entry...
            } else {
                // Reject if HashMap is at capacity
                if self.states_by_key.len() >= MAX_CONSENSUS_STATES {
                    warn!("states_by_key at capacity, rejecting request");
                    return Ok(());
                }
                // Entry doesn't exist and not started - don't create it
                return Ok(());
            }
        },
        _ => bail!("unexpected rpc: {}", msg.name()),
    }
}
```

2. **Validate issuer against on-chain `SupportedOIDCProviders`** before creating entries:
```rust
// Only accept requests for issuers that are actually configured on-chain
let is_valid_issuer = self.onchain_jwks.contains_key(&issuer);
if !is_valid_issuer {
    debug!("Rejecting request for unknown issuer");
    return Ok(());
}
```

3. **Add epoch validation**:
```rust
if request.epoch != self.epoch_state.epoch {
    debug!("Rejecting request from wrong epoch");
    return Ok(());
}
```

4. **Improve cleanup** in `reset_with_on_chain_state` to remove entries for non-existent issuers:
```rust
self.states_by_key.retain(|(issuer, _), _| {
    // Remove entries for issuers not in new on-chain state
    new_onchain_jwks.contains_key(issuer)
});
```

## Proof of Concept

```rust
#[cfg(test)]
mod security_tests {
    use super::*;
    
    #[test]
    fn test_unbounded_hashmap_growth_via_peer_requests() {
        // Setup: Create a KeyLevelConsensusManager
        let consensus_key = Arc::new(PrivateKey::generate_for_testing());
        let my_addr = AccountAddress::random();
        let epoch_state = Arc::new(EpochState::empty());
        let (rb_tx, _rb_rx) = aptos_channel::new(QueueStyle::FIFO, 10, None);
        let rb = ReliableBroadcast::new(/* ... */);
        let vtxn_pool = VTxnPoolState::default();
        
        let mut manager = KeyLevelConsensusManager::new(
            consensus_key,
            my_addr,
            epoch_state,
            rb,
            vtxn_pool,
        );
        
        // Attack: Send many requests with unique (issuer, kid) pairs
        for i in 0..10000 {
            let fake_issuer = format!("fake_issuer_{}", i).into_bytes();
            let fake_kid = format!("fake_kid_{}", i).into_bytes();
            
            let request = ObservedKeyLevelUpdateRequest {
                epoch: 0,
                issuer: fake_issuer,
                kid: fake_kid,
            };
            
            let rpc_req = IncomingRpcRequest {
                msg: JWKConsensusMsg::KeyLevelObservationRequest(request),
                sender: AccountAddress::random(),
                response_sender: Box::new(DummyRpcResponseSender::new(/* ... */)),
            };
            
            manager.process_peer_request(rpc_req).unwrap();
        }
        
        // Verify: HashMap has grown to 10000 entries
        assert_eq!(manager.states_by_key.len(), 10000);
        
        // Verify: Cleanup doesn't remove these entries
        manager.reset_with_on_chain_state(AllProvidersJWKs::default()).unwrap();
        
        // VULNERABILITY: Entries persist because unwrap_or_default() returns 0 for both sides
        assert_eq!(manager.states_by_key.len(), 10000); // Still 10000!
    }
}
```

## Notes

- This vulnerability affects the per-key JWK consensus mode specifically
- The issue also exists in `process_new_observation` but is less severe as observations come from local JWK fetching (rate-limited by 10-second intervals) and would require a compromised OIDC provider
- The peer RPC attack vector is more critical as it has no rate limiting and can be triggered by any Byzantine validator
- Similar pattern may exist in the issuer-level consensus manager (`jwk_manager/mod.rs`) and should be audited

### Citations

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L59-59)
```rust
    states_by_key: HashMap<(Issuer, KID), ConsensusState<ObservedKeyLevelUpdate>>,
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L244-254)
```rust
        self.states_by_key.retain(|(issuer, _), _| {
            new_onchain_jwks
                .get(issuer)
                .map(|jwks| jwks.version)
                .unwrap_or_default()
                == self
                    .onchain_jwks
                    .get(issuer)
                    .map(|jwks| jwks.version)
                    .unwrap_or_default()
        });
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L274-277)
```rust
                let consensus_state = self
                    .states_by_key
                    .entry((issuer.clone(), kid.clone()))
                    .or_default();
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L279-285)
```rust
                    ConsensusState::NotStarted => {
                        debug!(
                            issuer = String::from_utf8(issuer.clone()).ok(),
                            kid = String::from_utf8(kid.clone()).ok(),
                            "key-level jwk consensus not started"
                        );
                        return Ok(());
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L399-399)
```rust
                        Duration::from_secs(10),
```

**File:** crates/aptos-jwk-consensus/src/types.rs (L167-170)
```rust
impl<T: Debug + Clone + Eq + PartialEq> Default for ConsensusState<T> {
    fn default() -> Self {
        Self::NotStarted
    }
```

**File:** crates/aptos-jwk-consensus/src/network.rs (L191-203)
```rust
                Event::RpcRequest(peer_id, msg, protocol, response_sender) => {
                    let req = IncomingRpcRequest {
                        msg,
                        sender: peer_id,
                        response_sender: Box::new(RealRpcResponseSender {
                            inner: Some(response_sender),
                            protocol,
                        }),
                    };

                    if let Err(e) = self.rpc_tx.push(peer_id, (peer_id, req)) {
                        warn!(error = ?e, "aptos channel closed");
                    };
```
