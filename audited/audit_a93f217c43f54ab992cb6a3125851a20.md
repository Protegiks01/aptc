# Audit Report

## Title
Node Startup Failure Due to Missing Schema Migration in EventStorePruner Progress Metadata

## Summary
Aptos nodes cannot start after upgrading to a new version if the `DbMetadataValue` enum schema has changed. The EventStorePruner initialization attempts to deserialize stored progress metadata using BCS, but lacks schema migration logic, causing deserialization failures that propagate as panics and prevent node startup.

## Finding Description

The `EventStorePruner` stores its pruning progress in RocksDB using the `DbMetadataValue` enum, which is serialized with BCS (Binary Canonical Serialization). When a node is upgraded to a new version where this enum's structure has changed, the initialization fails catastrophically: [1](#0-0) 

The `get_or_initialize_subpruner_progress` function attempts to deserialize stored metadata: [2](#0-1) 

This function calls SchemaDB's `get` method, which deserializes using BCS: [3](#0-2) 

The `DbMetadataValue` enum is serialized using BCS with variant discriminators: [4](#0-3) [5](#0-4) 

**Critical Issue**: BCS enum deserialization fails if:
1. Enum variants are reordered (discriminator mismatch)
2. Variants are removed (unknown discriminator)
3. The inner `Version` type structure changes
4. New required fields are added to existing variants

When deserialization fails, the error propagates through the initialization chain: [6](#0-5) 

Finally reaching the pruner manager where it causes a panic: [7](#0-6) 

**Evidence of Schema Evolution**: The `DbMetadataValue` enum has evolved over time, containing the `StateSnapshotProgress` variant that was added for state snapshot functionality: [8](#0-7) 

This demonstrates that the schema DOES change across versions, making this vulnerability realistic.

## Impact Explanation

**Critical Severity** - This issue causes **total loss of liveness/network availability**:

1. **Node Startup Failure**: All nodes attempting to upgrade with schema changes cannot start, resulting in a panic during `LedgerPruner` initialization
2. **Network-Wide Outage**: If a coordinated upgrade is performed across the network and the schema has changed, ALL nodes will fail to start simultaneously
3. **No Automatic Recovery**: The node cannot recover without manual intervention (database migration or wipe)
4. **Violates Availability Invariant**: This breaks the fundamental requirement that nodes must be able to restart and rejoin the network

The severity aligns with the Aptos bug bounty **Critical** category: "Total loss of liveness/network availability" and potentially "Non-recoverable network partition (requires hardfork)" if database migration becomes necessary.

## Likelihood Explanation

**High Likelihood**:

1. **Schema Evolution is Common**: The existence of `StateSnapshotProgress` as a second variant proves that `DbMetadataValue` has evolved and will likely continue to evolve
2. **No Migration Infrastructure**: There is no schema versioning, migration logic, or compatibility layer in the storage system
3. **BCS Strict Deserialization**: BCS strictly validates enum discriminators and will fail on any schema mismatch
4. **Affects All Nodes**: Every node performing the upgrade will encounter this issue if the schema changes
5. **Realistic Scenario**: Adding new pruning features, optimizations, or tracking additional metadata would naturally require schema changes

This is not a theoretical issue - it's an operational time bomb that will trigger during any release that modifies the `DbMetadataValue` enum structure.

## Recommendation

Implement a schema versioning and migration system for metadata storage:

1. **Add Schema Version Field**: Wrap `DbMetadataValue` with a versioned container that includes a schema version number

2. **Implement Migration Logic**: Add migration functions that can convert old schema versions to new ones during deserialization

3. **Graceful Fallback**: If deserialization fails, implement fallback logic that:
   - Attempts migration from known older formats
   - Logs warnings about schema mismatches
   - Initializes to safe defaults if migration fails (e.g., re-scan from genesis or last known good state)

4. **Replace Panic with Error Recovery**: Remove the `.expect()` calls in the initialization chain and implement proper error handling that allows the node to start in a degraded mode or automatically trigger database reconstruction

Example fix outline:
```rust
// Add versioned wrapper
#[derive(Serialize, Deserialize)]
pub enum VersionedDbMetadataValue {
    V1(DbMetadataValueV1),  // Original format
    V2(DbMetadataValue),     // Current format
}

// Implement migration in decode_value
impl ValueCodec<DbMetadataSchema> for DbMetadataValue {
    fn decode_value(data: &[u8]) -> Result<Self> {
        // Try current version first
        if let Ok(v) = bcs::from_bytes::<DbMetadataValue>(data) {
            return Ok(v);
        }
        
        // Try legacy formats with migration
        if let Ok(v1) = bcs::from_bytes::<DbMetadataValueV1>(data) {
            return Ok(migrate_v1_to_v2(v1));
        }
        
        // Return error if all attempts fail
        Err(anyhow!("Failed to deserialize metadata with any known schema version"))
    }
}

// Update initialization to handle migration failures gracefully
pub(in crate::pruner) fn new(...) -> Result<Self> {
    let progress = match get_or_initialize_subpruner_progress(...) {
        Ok(p) => p,
        Err(e) => {
            warn!("Failed to load pruner progress, reinitializing: {}", e);
            // Safe fallback: start from metadata_progress
            metadata_progress
        }
    };
    // ... rest of initialization
}
```

## Proof of Concept

To demonstrate this vulnerability:

1. **Setup**: Start with a node running version V1 with `DbMetadataValue` enum having only `Version` variant
2. **Store Progress**: Run the pruner to store progress metadata
3. **Modify Schema**: Add a new variant or reorder existing variants in `DbMetadataValue` enum
4. **Upgrade**: Restart the node with the modified code
5. **Observe**: Node panics during `LedgerPruner::new()` with deserialization error

Rust test reproduction:
```rust
#[test]
fn test_metadata_schema_incompatibility() {
    // Simulate old version storing metadata
    let old_metadata = DbMetadataValue::Version(1000);
    let serialized = bcs::to_bytes(&old_metadata).unwrap();
    
    // Simulate schema change: reorder enum variants
    #[derive(Serialize, Deserialize)]
    enum DbMetadataValueV2 {
        StateSnapshotProgress(StateSnapshotProgress), // Now first variant
        Version(Version),                              // Now second variant
    }
    
    // Attempt to deserialize with new schema
    let result = bcs::from_bytes::<DbMetadataValueV2>(&serialized);
    
    // This will fail because discriminator 0 (Version in old schema)
    // now maps to StateSnapshotProgress in new schema
    assert!(result.is_err());
}
```

## Notes

This vulnerability specifically affects the **EventStorePruner** as mentioned in the security question, but the same issue exists in ALL sub-pruners that use `DbMetadataValue` for progress tracking:
- `TransactionAccumulatorPruner`
- `TransactionInfoPruner`
- `TransactionPruner`
- `WriteSetPruner`
- `PersistedAuxiliaryInfoPruner`

All these pruners share the same initialization pattern and would fail identically during schema migration. The fix should be applied system-wide to all metadata persistence mechanisms in the storage layer.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L90-94)
```rust
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```

**File:** storage/schemadb/src/lib.rs (L216-232)
```rust
    pub fn get<S: Schema>(&self, schema_key: &S::Key) -> DbResult<Option<S::Value>> {
        let _timer = APTOS_SCHEMADB_GET_LATENCY_SECONDS.timer_with(&[S::COLUMN_FAMILY_NAME]);

        let k = <S::Key as KeyCodec<S>>::encode_key(schema_key)?;
        let cf_handle = self.get_cf_handle(S::COLUMN_FAMILY_NAME)?;

        let result = self.inner.get_cf(cf_handle, k).into_db_res()?;
        APTOS_SCHEMADB_GET_BYTES.observe_with(
            &[S::COLUMN_FAMILY_NAME],
            result.as_ref().map_or(0.0, |v| v.len() as f64),
        );

        result
            .map(|raw_value| <S::Value as ValueCodec<S>>::decode_value(&raw_value))
            .transpose()
            .map_err(Into::into)
    }
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L24-45)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub(crate) enum DbMetadataValue {
    Version(Version),
    StateSnapshotProgress(StateSnapshotProgress),
}

impl DbMetadataValue {
    pub fn expect_version(self) -> Version {
        match self {
            Self::Version(version) => version,
            _ => unreachable!("expected Version, got {:?}", self),
        }
    }

    pub fn expect_state_snapshot_progress(self) -> StateSnapshotProgress {
        match self {
            Self::StateSnapshotProgress(progress) => progress,
            _ => unreachable!("expected KeyHashAndUsage, got {:?}", self),
        }
    }
}
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L91-99)
```rust
impl ValueCodec<DbMetadataSchema> for DbMetadataValue {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L138-142)
```rust
        let event_store_pruner = Box::new(EventStorePruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db.clone(),
        )?);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L146-149)
```rust
        let pruner = Arc::new(
            LedgerPruner::new(ledger_db, internal_indexer_db)
                .expect("Failed to create ledger pruner."),
        );
```

**File:** storage/indexer_schemas/src/metadata.rs (L44-49)
```rust
#[derive(Clone, Copy, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub struct StateSnapshotProgress {
    pub key_hash: HashValue,
    pub usage: StateStorageUsage,
}
```
