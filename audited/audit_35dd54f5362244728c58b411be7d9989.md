# Audit Report

## Title
Incomplete Transaction Backup Cleanup Failure Leading to Storage Exhaustion and Operational Blind Spots

## Summary

The transaction backup system in `storage/backup/backup-cli/src/backup_types/transaction/backup.rs` fails to clean up partial backup data when storage errors (such as disk full) occur during chunk writes. Errors are propagated correctly, but incomplete backup directories remain on disk without metadata entries, making them invisible to standard backup query tools. Operators cannot easily identify which backups are incomplete without manual filesystem inspection.

## Finding Description

The backup flow creates a directory with a random suffix, writes chunks sequentially, then writes a manifest and metadata. [1](#0-0) 

When a disk full error occurs during chunk writes, the error propagates via the `?` operator: [2](#0-1) 

However, there is no cleanup mechanism. The `BackupHandle` is just a type alias to `String` with no `Drop` implementation: [3](#0-2) 

The critical issue is that metadata is only saved AFTER the manifest is successfully written: [4](#0-3) 

When operators query backup status, only backups with metadata entries are visible: [5](#0-4) [6](#0-5) 

**Exploitation Path:**
1. Backup process starts, creating directory `transaction_12345-.a1b2/`
2. Storage fills during chunk write operations
3. `write_all()` or `shutdown()` returns `std::io::Error`
4. Error propagates, backup fails with logged error
5. Partial files remain in `transaction_12345-.a1b2/` directory
6. No manifest file created, no metadata saved
7. Standard backup query tools show no indication of the incomplete backup
8. Repeated failures accumulate orphaned directories, consuming storage

## Impact Explanation

This qualifies as **Medium Severity** under "State inconsistencies requiring intervention":

1. **Storage Exhaustion Risk**: Repeated backup failures accumulate partial data, potentially filling disk space and affecting validator operations
2. **Operational Blind Spot**: Operators cannot identify incomplete backups through standard tools, requiring manual filesystem inspection
3. **Disaster Recovery Impact**: In crisis scenarios, operators may waste critical time discovering that expected backups are incomplete
4. **No Automatic Cleanup**: System provides no mechanism to identify or remove orphaned backup directories

While this doesn't directly affect consensus, execution, or funds, it creates significant operational risk that could cascade into availability issues if disk space is exhausted.

## Likelihood Explanation

**HIGH likelihood** - This occurs naturally during operational conditions:
- Production systems regularly face storage capacity constraints
- Backup operations are continuous and large
- No attacker action required
- Affects all nodes running backup coordinators
- Cannot be prevented through configuration alone

## Recommendation

Implement backup cleanup on failure using RAII pattern:

1. **Create `BackupGuard` struct** that holds a reference to storage and tracks completion status
2. **Implement `Drop`** to remove incomplete backup directories
3. **Mark completion** only after metadata is successfully saved
4. **Add verification command** to list orphaned backup directories

Example implementation structure:
```rust
struct BackupGuard {
    storage: Arc<dyn BackupStorage>,
    backup_handle: BackupHandle,
    completed: bool,
}

impl Drop for BackupGuard {
    fn drop(&mut self) {
        if !self.completed {
            // Clean up incomplete backup directory
        }
    }
}
```

Additionally, add operator tooling:
- `aptos-db-tool backup verify-storage` command to scan for orphaned directories
- Periodic cleanup job in backup coordinator
- Enhanced logging with backup directory paths

## Proof of Concept

```rust
#[tokio::test]
async fn test_disk_full_leaves_orphaned_backup() {
    // 1. Set up mock storage with limited space
    let storage = Arc::new(MockStorage::new_with_limited_space(1024));
    
    // 2. Attempt backup with data larger than available space
    let controller = TransactionBackupController::new(
        TransactionBackupOpt {
            start_version: 0,
            num_transactions: 100000, // Will exceed space
        },
        GlobalBackupOpt::default(),
        client,
        storage.clone(),
    );
    
    // 3. Backup should fail with storage error
    let result = controller.run().await;
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("No space"));
    
    // 4. Verify orphaned directory exists
    let backup_dirs = storage.list_backup_directories().await.unwrap();
    assert!(backup_dirs.len() > 0); // Orphaned directory present
    
    // 5. Verify no metadata entry
    let metadata_files = storage.list_metadata_files().await.unwrap();
    assert!(metadata_files.is_empty()); // No metadata saved
    
    // 6. Standard query shows no backup
    let view = MetadataView::load(storage).await.unwrap();
    let state = view.get_storage_state().unwrap();
    assert!(state.latest_transaction_version.is_none());
}
```

## Notes

While errors are correctly propagated through the `?` operator and logged, the lack of automatic cleanup creates an operational security issue. Operators relying on standard backup query tools (`aptos-db-tool backup query backup-storage-state`) will not see incomplete backups, as these tools only enumerate metadata entries. This creates a dangerous blind spot where storage capacity can be silently consumed by failed backup attempts, and operators may incorrectly assume backup coverage is complete when querying the system.

The backup system should follow the principle of "fail-safe" operation where failures leave the system in a clean, identifiable state rather than accumulating hidden partial data.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L71-127)
```rust
    async fn run_impl(self) -> Result<FileHandle> {
        let backup_handle = self
            .storage
            .create_backup_with_random_suffix(&self.backup_name())
            .await?;

        let mut chunks = Vec::new();
        let mut chunk_bytes = Vec::new();

        let mut transactions_file = self
            .client
            .get_transactions(self.start_version, self.num_transactions)
            .await?;
        let mut current_ver: u64 = self.start_version;
        let mut chunk_first_ver: u64 = self.start_version;

        while let Some(record_bytes) = transactions_file.read_record_bytes().await? {
            if should_cut_chunk(&chunk_bytes, &record_bytes, self.max_chunk_size) {
                let chunk = self
                    .write_chunk(
                        &backup_handle,
                        &chunk_bytes,
                        chunk_first_ver,
                        current_ver - 1,
                    )
                    .await?;
                chunks.push(chunk);
                chunk_bytes = vec![];
                chunk_first_ver = current_ver;
            }

            chunk_bytes.extend((record_bytes.len() as u32).to_be_bytes());
            chunk_bytes.extend(&record_bytes);
            current_ver += 1;
        }

        assert!(!chunk_bytes.is_empty());
        let expected_next_version = self.start_version + self.num_transactions as u64;
        ensure!(
            current_ver == expected_next_version,
            "Server did not return all transactions requested. Expecting last version {}, got {}",
            expected_next_version,
            current_ver,
        );
        let chunk = self
            .write_chunk(
                &backup_handle,
                &chunk_bytes,
                chunk_first_ver,
                current_ver - 1,
            )
            .await?;
        chunks.push(chunk);

        self.write_manifest(&backup_handle, self.start_version, current_ver - 1, chunks)
            .await
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L177-178)
```rust
        chunk_file.write_all(chunk_bytes).await?;
        chunk_file.shutdown().await?;
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L210-214)
```rust
        let metadata =
            Metadata::new_transaction_backup(first_version, last_version, manifest_handle.clone());
        self.storage
            .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
            .await?;
```

**File:** storage/backup/backup-cli/src/storage/mod.rs (L33-34)
```rust
pub type BackupHandle = String;
pub type BackupHandleRef = str;
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L29-46)
```rust
    pub(crate) fn new(metadata_vec: Vec<Metadata>, file_handles: Vec<FileHandle>) -> Self {
        let mut epoch_ending_backups = Vec::new();
        let mut state_snapshot_backups = Vec::new();
        let mut transaction_backups = Vec::new();
        let mut identity = None;
        let mut compaction_timestamps = Vec::new();

        for meta in metadata_vec {
            match meta {
                Metadata::EpochEndingBackup(e) => epoch_ending_backups.push(e),
                Metadata::StateSnapshotBackup(s) => state_snapshot_backups.push(s),
                Metadata::TransactionBackup(t) => transaction_backups.push(t),
                Metadata::Identity(i) => identity = Some(i),
                Metadata::CompactionTimestamps(t) => compaction_timestamps.push(t),
            }
        }
        epoch_ending_backups.sort_unstable();
        epoch_ending_backups.dedup();
```

**File:** storage/db-tool/src/backup.rs (L227-235)
```rust
                OneShotQueryType::BackupStorageState(opt) => {
                    let view = cache::sync_and_load(
                        &opt.metadata_cache,
                        opt.storage.init_storage().await?,
                        opt.concurrent_downloads.get(),
                    )
                    .await?;
                    println!("{}", view.get_storage_state()?)
                },
```
