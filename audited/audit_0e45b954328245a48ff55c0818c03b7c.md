# Audit Report

## Title
Cache Version Offset Bug Causing Transaction Data Misalignment in Indexer GRPC Data Service

## Summary
A logic error in the `update_data()` function causes transactions to be stored at incorrect version positions when overlapping data arrives during cache eviction. The bug stems from variable shadowing where the `start_version` parameter is overwritten before being used in version calculation, resulting in an offset that poisons the cache with misaligned transaction data.

## Finding Description

The vulnerability exists in the `update_data()` function where a critical variable shadowing issue causes incorrect version assignment. [1](#0-0) 

The logic flow is:
1. `num_to_skip` is calculated as the difference between the cache's current `self.start_version` and the incoming `start_version` parameter
2. The `start_version` parameter is then **overwritten** with the maximum of itself and `self.start_version`
3. When iterating through transactions with `enumerate().skip(num_to_skip)`, the loop index `i` starts from `num_to_skip` (not zero)
4. The version calculation uses the **overwritten** `start_version` plus the index `i`

**Example Scenario:**
- Cache window: versions [100, 200], `self.start_version = 100`
- Incoming data: `start_version = 90`, transactions representing versions [90-109]
- Calculation: `num_to_skip = 100 - 90 = 10`
- Variable shadowing: `start_version` becomes `100` (loses original value `90`)
- Loop iteration: First element after `skip(10)` has `i = 10`, representing transaction at actual version 100
- **Bug**: `version = 100 + 10 = 110` (should be `90 + 10 = 100`)
- **Result**: Transaction for version 100 is incorrectly stored at cache position 110 [2](#0-1) 

**Race Condition Trigger:**
This bug manifests through a race condition between concurrent cache operations:

1. Thread A (user request handler) calls `get_data()` requesting version 100 [3](#0-2) 
2. Thread A finds cache miss at line 73, releases read lock, initiates `fetch_past_data(100)` [4](#0-3) 
3. Thread B (background fetcher) acquires write lock, processes new incoming data, cache fills up
4. Thread B triggers eviction logic, advancing `self.start_version` from 100 to 105 [5](#0-4) 
5. Thread A's `fetch_past_data(100)` completes, fetches transactions [100-119] from upstream [6](#0-5) 
6. Thread A acquires write lock, calls `update_data(100, transactions)`
7. **Bug triggers**: `start_version(100) < self.start_version(105)`, causing 5-version offset in all stored positions

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria - "State inconsistencies requiring intervention"

This vulnerability causes **cache poisoning** in the indexer GRPC data service, leading to:

1. **Data Integrity Violation**: Clients querying version X receive transaction data from version (X - offset)
2. **User Financial Risk**: Wallets, block explorers, and dApps relying on indexer data may display incorrect balances, transaction histories, or account states
3. **Service Degradation**: Requires cache invalidation/restart to restore correct data alignment
4. **Cascading Effects**: Downstream services consuming indexer data propagate incorrect information

**Important Scope Limitation**: This vulnerability affects the **indexer service layer** (ecosystem component), not the core blockchain consensus, execution, or state management systems. The blockchain's actual state remains unaffected - only the off-chain indexer cache is compromised.

## Likelihood Explanation

**Likelihood: Moderate**

The race condition becomes more probable under these conditions:

1. **High Load**: Frequent cache evictions due to sustained high transaction volume
2. **Cache Pressure**: When cache size limit is reached regularly (lines 107-117 eviction logic)
3. **Concurrent Requests**: Multiple clients requesting historical data while background fetcher processes new blocks
4. **No Special Privileges Required**: Occurs naturally during normal operation, no attacker control needed

The race window exists between the read lock release at line 74 and write lock acquisition during `update_data()`, making it timing-dependent but realistically exploitable under production load.

## Recommendation

**Fix**: Preserve the original `start_version` parameter value before shadowing:

```rust
pub(super) fn update_data(&mut self, start_version: u64, transactions: Vec<Transaction>) {
    let end_version = start_version + transactions.len() as u64;
    
    // ... existing checks ...
    
    let num_to_skip = self.start_version.saturating_sub(start_version);
    let original_start_version = start_version;  // Preserve original value
    let adjusted_start_version = start_version.max(self.start_version);  // Use different name
    
    // ... size tracking ...
    
    for (i, transaction) in transactions
        .into_iter()
        .enumerate()
        .skip(num_to_skip as usize)
    {
        // Use original_start_version for correct version calculation
        let version = original_start_version + i as u64;
        let slot_index = version as usize % self.num_slots;
        
        // ... rest of logic ...
    }
    
    // Use adjusted_start_version for end_version comparisons
    if end_version > self.end_version {
        // ... existing logic ...
    }
}
```

**Alternative Fix**: Calculate version based on the relationship between loop index and skipped count:

```rust
let version = adjusted_start_version + (i as u64 - num_to_skip);
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_protos::transaction::v1::Transaction;
    
    #[test]
    fn test_cache_poisoning_via_version_offset() {
        // Initialize cache with window [100, 200]
        let mut data_manager = DataManager::new(200, 1000, 1024 * 1024);
        data_manager.start_version = 100;
        data_manager.end_version = 200;
        
        // Simulate race: cache eviction happens, start_version advances to 105
        data_manager.start_version = 105;
        
        // Now update_data is called with stale start_version = 100
        let mut transactions = Vec::new();
        for v in 100..110 {
            let mut txn = Transaction::default();
            txn.version = v;
            transactions.push(txn);
        }
        
        data_manager.update_data(100, transactions);
        
        // Bug: Transaction for version 100 should be at position 100,
        // but due to offset bug, it's at position 110
        let txn_at_100 = data_manager.get_data(100);
        let txn_at_110 = data_manager.get_data(110);
        
        // Demonstrate cache poisoning
        assert!(txn_at_100.is_none() || txn_at_100.as_ref().unwrap().version != 100);
        assert!(txn_at_110.is_some());
        assert_eq!(txn_at_110.as_ref().unwrap().version, 100); // Wrong version at this position!
        
        println!("Cache poisoning confirmed: version 100 data stored at position 110");
    }
}
```

---

**Notes:**
- This vulnerability is limited to the indexer-grpc ecosystem service and does not affect core blockchain consensus, Move VM execution, or on-chain state
- The bug requires specific timing (race condition) but becomes likely under production load with cache pressure
- Impact is classified as Medium severity due to data integrity issues requiring operational intervention, not Critical/High as it doesn't compromise blockchain security fundamentals

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L69-70)
```rust
        let num_to_skip = self.start_version.saturating_sub(start_version);
        let start_version = start_version.max(self.start_version);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L75-87)
```rust
        for (i, transaction) in transactions
            .into_iter()
            .enumerate()
            .skip(num_to_skip as usize)
        {
            let version = start_version + i as u64;
            let slot_index = version as usize % self.num_slots;
            if let Some(transaction) = self.data[slot_index].take() {
                size_decreased += transaction.encoded_len();
            }
            size_increased += transaction.encoded_len();
            self.data[version as usize % self.num_slots] = Some(Box::new(transaction));
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L107-117)
```rust
        if self.total_size >= self.size_limit_bytes {
            while self.total_size >= self.eviction_target {
                if let Some(transaction) =
                    self.data[self.start_version as usize % self.num_slots].take()
                {
                    self.total_size -= transaction.encoded_len();
                    drop(transaction);
                }
                self.start_version += 1;
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L40-47)
```rust
    pub(super) async fn get_data(
        &'a self,
        starting_version: u64,
        ending_version: u64,
        max_num_transactions_per_batch: usize,
        max_bytes_per_batch: usize,
        filter: &Option<BooleanTransactionFilter>,
    ) -> Option<(Vec<Transaction>, usize, u64)> {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L73-76)
```rust
            if data_manager.get_data(starting_version).is_none() {
                drop(data_manager);
                self.fetch_manager.fetch_past_data(starting_version).await;
                continue;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L48-64)
```rust
    async fn fetch_and_update_cache(
        data_client: Arc<DataClient>,
        data_manager: Arc<RwLock<DataManager>>,
        version: u64,
    ) -> usize {
        let transactions = data_client.fetch_transactions(version).await;
        let len = transactions.len();

        if len > 0 {
            data_manager
                .write()
                .await
                .update_data(version, transactions);
        }

        len
    }
```
