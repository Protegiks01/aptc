# Audit Report

## Title
Missing Chunk Count Validation in PVSS Decryption Enables Partial Secret Reconstruction

## Summary
The `le_chunks_to_scalar()` function and its usage in PVSS share decryption lack validation of the expected chunk count, allowing reconstruction from an arbitrary number of chunks. Combined with insufficient verification-time checks on per-share chunk counts, this creates a potential information leakage vector where partial secret key shares can be reconstructed from incomplete chunk sets.

## Finding Description

The vulnerability exists in the chunked PVSS (Publicly Verifiable Secret Sharing) implementation used for Distributed Key Generation (DKG). The core issue spans two locations: [1](#0-0) 

The `le_chunks_to_scalar()` function accepts an arbitrary-length slice of chunks and reconstructs a field element without validating that the slice contains the expected number of chunks (`num_chunks_per_scalar(pp.ell)`). [2](#0-1) 

During share decryption in `decrypt_own_share()`, the code processes whatever chunks are present in the ciphertext without validating the count matches `num_chunks_per_scalar(pp.ell)`. The only check is a debug assertion that doesn't run in production: [3](#0-2) 

The verification phase also lacks explicit per-share chunk count validation: [4](#0-3) 

The verification iterates over whatever chunks exist (`for j in 0..Cs_flat[i].len()`) rather than enforcing that each share must have exactly `num_chunks_per_scalar(pp.ell)` chunks.

**Attack Scenario:**
If a malicious dealer can craft a PVSS transcript where some ciphertext rows contain fewer chunks than expected, honest validators would:
1. Decrypt the available chunks via BSGS discrete log
2. Call `le_chunks_to_scalar()` with the incomplete chunk vector
3. Reconstruct a **partial value** representing only the lower-order bits

For example, with `ell=16` and expected 4 chunks, if only 2 chunks are provided:
- Expected reconstruction: `chunk[0] + chunk[1]*2^16 + chunk[2]*2^32 + chunk[3]*2^48`
- Actual reconstruction: `chunk[0] + chunk[1]*2^16`
- **Information leaked**: Lower 32 bits of the secret share

## Impact Explanation

**Severity: Medium** (aligned with "Limited information leaks" category)

While the vulnerability exists in production code (`debug_assert_eq!` doesn't run in release builds), the actual exploitability depends on whether other cryptographic checks (sigma protocol, range proof, low-degree test, multi-pairing check) prevent malformed transcripts from being accepted during verification. 

The impact includes:
- **Information Leakage**: Partial reconstruction of secret key shares reveals lower-order bits
- **DKG Protocol Violation**: In the distributed key generation context, partial shares could compromise the randomness properties
- **Defense-in-Depth Failure**: Missing validation at decryption time violates security best practices

The impact is not Critical because:
- The verification phase includes multiple cryptographic checks that may prevent this
- Full secret compromise requires additional vulnerabilities
- The leak is partial (lower-order bits only)

## Likelihood Explanation

**Likelihood: Low to Medium**

The likelihood depends on whether the verification checks adequately prevent malformed transcripts:

**Factors increasing likelihood:**
- No explicit chunk count validation exists in verification or decryption code
- The verification only checks total chunk count, not per-share counts
- Debug assertions don't run in production

**Factors decreasing likelihood:**
- Sigma protocol and multi-pairing checks may detect inconsistencies
- Range proof verification may catch malformed chunk sets
- Low-degree test validates polynomial structure

A rigorous cryptographic analysis is needed to determine if the existing verification checks fully prevent partial chunk attacks.

## Recommendation

Add explicit validation at both verification and decryption time:

**1. Add verification-time check:**
```rust
// In weighted_transcript.rs verify() function, after line 153
let expected_chunks_per_share = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;
for (player_id, cs) in self.subtrs.Cs.iter().enumerate() {
    for (share_idx, chunk_vec) in cs.iter().enumerate() {
        if chunk_vec.len() != expected_chunks_per_share {
            bail!(
                "Player {} share {} has {} chunks, expected {}",
                player_id,
                share_idx,
                chunk_vec.len(),
                expected_chunks_per_share
            );
        }
    }
}
```

**2. Add decryption-time check:**
```rust
// In weighted_transcript.rs decrypt_own_share(), before line 372
let expected_chunks = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;
if dealt_chunked_secret_key_share_fr.len() != expected_chunks {
    panic!(
        "Chunk count mismatch: got {}, expected {}",
        dealt_chunked_secret_key_share_fr.len(),
        expected_chunks
    );
}
```

**3. Add validation in le_chunks_to_scalar:**
```rust
// In chunks.rs le_chunks_to_scalar(), after line 36
let expected_chunks = (F::MODULUS_BIT_SIZE as u8).div_ceil(num_bits) as usize;
assert_eq!(
    chunks.len(),
    expected_chunks,
    "Expected {} chunks of {} bits each, got {}",
    expected_chunks,
    num_bits,
    chunks.len()
);
```

## Proof of Concept

```rust
// Test demonstrating partial reconstruction
#[test]
fn test_partial_chunk_reconstruction_leaks_info() {
    use ark_bls12_381::Fr;
    use ark_ff::UniformRand;
    use ark_std::test_rng;
    
    let mut rng = test_rng();
    let num_bits = 16u8;
    let original: Fr = Fr::rand(&mut rng);
    
    // Normal reconstruction
    let full_chunks = scalar_to_le_chunks(num_bits, &original);
    let reconstructed_full = le_chunks_to_scalar(num_bits, &full_chunks);
    assert_eq!(original, reconstructed_full);
    
    // Partial reconstruction (only first 2 out of 4 chunks)
    let partial_chunks = &full_chunks[0..2];
    let reconstructed_partial = le_chunks_to_scalar(num_bits, partial_chunks);
    
    // The partial reconstruction is NOT equal to the original
    assert_ne!(original, reconstructed_partial);
    
    // But it leaks the lower-order bits!
    // This demonstrates information leakage when chunks are missing
    let base = Fr::from(1u128 << num_bits);
    let expected_partial = full_chunks[0] + full_chunks[1] * base;
    assert_eq!(reconstructed_partial, expected_partial);
    
    println!("Original: {:?}", original);
    println!("Partial (lower 32 bits leaked): {:?}", reconstructed_partial);
}
```

## Notes

This vulnerability highlights a defense-in-depth failure where cryptographic verification checks may prevent the attack, but explicit validation is missing at the decryption layer. The actual exploitability requires deeper cryptographic analysis of whether the sigma protocol, range proof, and pairing checks adequately enforce uniform chunk counts across all shares. Even if verification prevents this, adding explicit validation improves code robustness and makes security properties explicit rather than relying on implicit cryptographic guarantees.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/chunks.rs (L32-48)
```rust
pub fn le_chunks_to_scalar<F: PrimeField>(num_bits: u8, chunks: &[F]) -> F {
    assert!(
        num_bits.is_multiple_of(8) && num_bits > 0 && num_bits <= 64, // TODO: so make num_bits a u8?
        "Invalid chunk size"
    );

    let base = F::from(1u128 << num_bits); // need u128 in the case where `num_bits` is 64, because of `chunk * multiplier`
    let mut acc = F::zero();
    let mut multiplier = F::one();

    for &chunk in chunks {
        acc += chunk * multiplier;
        multiplier *= base;
    }

    acc
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L255-262)
```rust
        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L317-380)
```rust
    #[allow(non_snake_case)]
    fn decrypt_own_share(
        &self,
        sc: &Self::SecretSharingConfig,
        player: &Player,
        dk: &Self::DecryptPrivKey,
        pp: &Self::PublicParameters,
    ) -> (Self::DealtSecretKeyShare, Self::DealtPubKeyShare) {
        let weight = sc.get_player_weight(player);

        let Cs = &self.Cs[player.id];

        // TODO: put an assert here saying that len(Cs) = weight

        let ephemeral_keys: Vec<_> = self
            .Rs
            .iter()
            .take(weight)
            .map(|R_i_vec| R_i_vec.iter().map(|R_i| R_i.mul(dk.dk)).collect::<Vec<_>>())
            .collect();

        if let Some(first_key) = ephemeral_keys.first() {
            debug_assert_eq!(
                first_key.len(),
                Cs[0].len(),
                "Number of ephemeral keys does not match the number of ciphertext chunks"
            );
        }

        let mut sk_shares: Vec<Scalar<E::ScalarField>> = Vec::with_capacity(weight);
        let pk_shares = self.get_public_key_share(sc, player);

        for i in 0..weight {
            // TODO: should really put this in a separate function
            let dealt_encrypted_secret_key_share_chunks: Vec<_> = Cs[i]
                .iter()
                .zip(ephemeral_keys[i].iter())
                .map(|(C_ij, ephemeral_key)| C_ij.sub(ephemeral_key))
                .collect();

            let dealt_chunked_secret_key_share = bsgs::dlog_vec(
                pp.pp_elgamal.G.into_group(),
                &dealt_encrypted_secret_key_share_chunks,
                &pp.table,
                pp.get_dlog_range_bound(),
            )
            .expect("BSGS dlog failed");

            let dealt_chunked_secret_key_share_fr: Vec<E::ScalarField> =
                dealt_chunked_secret_key_share
                    .iter()
                    .map(|&x| E::ScalarField::from(x))
                    .collect();

            let dealt_secret_key_share =
                chunks::le_chunks_to_scalar(pp.ell, &dealt_chunked_secret_key_share_fr);

            sk_shares.push(Scalar(dealt_secret_key_share));
        }

        (
            sk_shares, pk_shares, // TODO: review this formalism... why do we need this here?
        )
    }
```
