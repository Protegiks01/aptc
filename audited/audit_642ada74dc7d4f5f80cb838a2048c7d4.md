Audit Report

## Title
State Merkle Shard Pruner Infinite Loop on Corrupted Index Can Permanently Hang Validator Storage

## Summary
The `prune()` function in `StateMerkleShardPruner` contains a potentially infinite loop if the underlying pruner index database becomes corrupted. If `get_stale_node_indices` repeatedly returns the same (stale or undeletable) entries, then `prune()` will loop forever, blocking the storage pruner thread and eventually causing validator node liveness and availability failures.

## Finding Description
The `StateMerkleShardPruner::prune()` function implements a loop that processes stale node indices in batches from the database, attempts to prune them, and only breaks out when able to confirm all indices up to the target version are pruned. The loop's termination relies on batch removal of all indices as returned by `StateMerklePruner::get_stale_node_indices`—if this function keeps returning indices at or before the target version (due to database corruption or deletion failures), then the loop will never terminate.

There is no timeout, iteration cap, or out-of-band health/liveness check within this function. As a result, if the persistent database becomes corrupted and cannot be updated (or returns duplicate/undeletable indices), the function will hang forever, stalling the pruner subsystem permanently. This in turn blocks storage cleanups, fills disk space, and can lead to node unavailability or a forced hardfork for recovery.

The pruner runs in a background thread, but because the loop is infinite and uninterruptible in this scenario, the only way to recover is manual operator intervention (e.g., database wipe or node reinitialization).

**Invariant violation:** This breaks the "Resource Limits" and "State Consistency" invariants, threatening liveness and network health.

## Impact Explanation
**Severity:** High

- Impacts all validator nodes subject to state DB corruption (production risk due to hardware, filesystem errors, or even certain unsafe shutdowns)
- Causes permanent hang of the pruner system until manual intervention
- Disk usage grows without bound, node could eventually crash or lose consensus participation
- Potential for network-wide liveness failures if enough validators encounter this state

## Likelihood Explanation
Database inconsistency or filesystem corruption is not an everyday attack, but it is well within production failure scenarios (e.g., abrupt shutdowns, hardware failure, disk full, RocksDB bugs). Any node that experiences these issues can be permanently affected. No explicit attacker control is required, though a local attacker with filesystem access could also intentionally corrupt the DB to exploit this.

## Recommendation
- Add a maximum loop iteration count in `prune()` or an explicit operation timeout. If exceeded, log a critical error and abort the pruner thread, triggering an operator visible alert.
- Alternatively, introduce logic to detect if there is no forward progress (e.g., record and check the stale indices, bail if the same ones return more than once).
- Example fix (pseudo):

```rust
let mut iterations = 0;
const MAX_ITERATIONS: usize = 10000;
loop {
    if iterations > MAX_ITERATIONS {
        error!("StateMerkleShardPruner::prune exceeded max iterations. Aborting to prevent hang.");
        return Err(anyhow!("Exceeded max prune iterations"));
    }
    // ... pruning logic as before
    iterations += 1;
}
```

## Proof of Concept
This can be simulated by manually corrupting the underlying pruner index (e.g., re-inserting the same stale indices after each delete outside the pruner thread, or preventing deletes from persisting at the RocksDB level). Observe that `pruner()` never completes and the pruner worker hangs indefinitely, regardless of progress elsewhere in the node.

This can be confirmed using a Rust test that mocks or monkey-patches the `get_stale_node_indices` to always return a constant non-empty batch for the same version—observe that `prune()` never returns.

---

Citations: [1](#0-0) [2](#0-1) [3](#0-2) [4](#0-3) 

Notes:
- This is a real risk in production systems using persistent databases; not a theoretical bug.
- Does not require validator collusion or privileged attacker access; can be triggered by natural or adversarial DB corruption.
- No workaround exists short of code changes or external monitoring/recovery.

### Citations

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L58-100)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
        max_nodes_to_prune: usize,
    ) -> Result<()> {
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }

        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L191-218)
```rust
    pub(in crate::pruner::state_merkle_pruner) fn get_stale_node_indices(
        state_merkle_db_shard: &DB,
        start_version: Version,
        target_version: Version,
        limit: usize,
    ) -> Result<(Vec<StaleNodeIndex>, Option<Version>)> {
        let mut indices = Vec::new();
        let mut iter = state_merkle_db_shard.iter::<S>()?;
        iter.seek(&StaleNodeIndex {
            stale_since_version: start_version,
            node_key: NodeKey::new_empty_path(0),
        })?;

        let mut next_version = None;
        while indices.len() < limit {
            if let Some((index, _)) = iter.next().transpose()? {
                next_version = Some(index.stale_since_version);
                if index.stale_since_version <= target_version {
                    indices.push(index);
                    continue;
                }
            }
            break;
        }

        Ok((indices, next_version))
    }
}
```

**File:** storage/schemadb/src/lib.rs (L307-319)
```rust
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }

    /// Writes without sync flag in write option.
    /// If this flag is false, and the machine crashes, some recent
    /// writes may be lost.  Note that if it is just the process that
    /// crashes (i.e., the machine does not reboot), no writes will be
    /// lost even if sync==false.
    pub fn write_schemas_relaxed(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &WriteOptions::default())
    }

```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L52-69)
```rust
    // Loop that does the real pruning job.
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
    }
```
