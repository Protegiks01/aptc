# Audit Report

## Title
API Memory Exhaustion Through Unbounded Event Data Aggregation

## Summary

The Events API endpoint lacks validation on the total size of event data fetched per request, allowing an attacker to cause memory exhaustion on API nodes by querying large events. While individual events are limited to 1MB during transaction execution, the API can fetch up to 100 events per request (100MB total) without any aggregate size validation, leading to potential API server crashes or degraded performance.

## Finding Description

The vulnerability exists in the event retrieval flow where the API loads all requested events into memory without checking the total response size: [1](#0-0) 

The `list()` function calls `context.get_events()` which retrieves all events up to the page limit: [2](#0-1) 

The page limit is controlled by `max_events_page_size` which defaults to 100 events: [3](#0-2) 

While individual events are limited to 1MB during transaction execution: [4](#0-3) 

This limit is enforced during transaction execution but NOT when reading events through the API: [5](#0-4) 

**Attack Path:**

1. Attacker submits transactions that emit events close to the 1MB limit (valid and accepted by the network)
2. Multiple such transactions are committed, each containing large events
3. Attacker issues GET requests to `/accounts/:address/events/:creation_number?limit=100`
4. API server loads 100 events × ~1MB each = ~100MB per request into memory
5. Multiple concurrent requests from the attacker exhaust available memory
6. API server crashes or becomes unresponsive, affecting all users

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." While the API has request size limits for POST operations: [6](#0-5) 

No equivalent response size limit exists for GET operations that return event data.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program criteria for "API crashes" and "Validator node slowdowns":

- **Availability Impact**: API servers can be crashed or made unresponsive, denying service to all users
- **Resource Exhaustion**: Memory exhaustion can cascade to other services on the same node
- **Low Attack Cost**: Attacker pays transaction gas fees once to create large events, then can query them repeatedly for free
- **Amplification Factor**: Single transaction creates reusable attack vector for unlimited API requests

The attack does not require validator access, special permissions, or sophisticated exploits—any user can emit large events and query them repeatedly.

## Likelihood Explanation

**Likelihood: High**

- **Ease of Exploitation**: Trivial to execute; requires only standard transaction submission and HTTP GET requests
- **Attack Cost**: Minimal—only transaction gas fees for initial event creation
- **Detection Difficulty**: GET requests appear legitimate; no obvious signature of abuse
- **Persistence**: Once large events are created on-chain, they remain queryable indefinitely
- **Concurrent Amplification**: Multiple concurrent requests multiply the impact

The only barrier is the attacker's willingness to pay gas fees for transactions that emit maximum-size events, which is economically feasible for motivated attackers.

## Recommendation

Implement aggregate response size validation in the events API:

```rust
// In api/src/events.rs, modify the list() function:

const MAX_EVENT_RESPONSE_SIZE: usize = 10 * 1024 * 1024; // 10MB limit

fn list(
    &self,
    latest_ledger_info: LedgerInfo,
    accept_type: AcceptType,
    page: Page,
    event_key: EventKey,
) -> BasicResultWith404<Vec<VersionedEvent>> {
    let ledger_version = latest_ledger_info.version();
    let events = self
        .context
        .get_events(
            &event_key,
            page.start_option(),
            page.limit(&latest_ledger_info)?,
            ledger_version,
        )
        .context(format!("Failed to find events by key {}", event_key))
        .map_err(|err| {
            BasicErrorWith404::internal_with_code(
                err,
                AptosErrorCode::InternalError,
                &latest_ledger_info,
            )
        })?;

    // Validate total response size
    let total_size: usize = events.iter()
        .map(|e| e.event.event_data().len())
        .sum();
    
    if total_size > MAX_EVENT_RESPONSE_SIZE {
        return Err(BasicErrorWith404::bad_request_with_code(
            format!("Total event data size ({} bytes) exceeds maximum allowed ({} bytes). Please reduce the limit parameter.", 
                total_size, MAX_EVENT_RESPONSE_SIZE),
            AptosErrorCode::InvalidInput,
            &latest_ledger_info,
        ));
    }

    // Continue with existing conversion logic...
}
```

**Additional Recommendations:**

1. Add configuration parameter for `max_event_response_size_bytes` in `ApiConfig`
2. Implement early termination in `context.get_events()` if size threshold exceeded
3. Add monitoring/alerting for requests approaching size limits
4. Consider implementing streaming responses for large event sets

## Proof of Concept

```move
// Move module to create large events
module attacker::large_events {
    use std::vector;
    use aptos_framework::event;
    
    struct LargeEvent has drop, store {
        // Create event close to 1MB limit
        data: vector<u8>,
    }
    
    #[event]
    struct LargeEventV2 has drop, store {
        data: vector<u8>,
    }
    
    public entry fun emit_large_event(account: &signer) {
        let large_data = vector::empty<u8>();
        let i = 0;
        // Create ~900KB of data (accounting for other fields)
        while (i < 900000) {
            vector::push_back(&mut large_data, (i % 256) as u8);
            i = i + 1;
        };
        
        event::emit(LargeEventV2 {
            data: large_data,
        });
    }
}
```

**Exploitation Steps:**

```bash
# 1. Deploy the module and call emit_large_event 10 times
# This creates 10 events of ~900KB each

# 2. Query the events API
curl "http://api-node:8080/v1/accounts/0xATTACKER_ADDRESS/events/CREATION_NUMBER?limit=100"

# 3. Repeat step 2 with multiple concurrent requests
# Each request loads ~9MB into memory
# With 50 concurrent requests = 450MB memory allocated
# Repeat to exhaust available memory
```

## Notes

This vulnerability demonstrates a common API security anti-pattern: enforcing limits at write-time but not at read-time. While the Move VM correctly validates event sizes during transaction execution, the API layer lacks equivalent protections when aggregating events for responses. The fix requires minimal code changes but significantly improves API resilience against resource exhaustion attacks.

### Citations

**File:** api/src/events.rs (L155-178)
```rust
    fn list(
        &self,
        latest_ledger_info: LedgerInfo,
        accept_type: AcceptType,
        page: Page,
        event_key: EventKey,
    ) -> BasicResultWith404<Vec<VersionedEvent>> {
        let ledger_version = latest_ledger_info.version();
        let events = self
            .context
            .get_events(
                &event_key,
                page.start_option(),
                page.limit(&latest_ledger_info)?,
                ledger_version,
            )
            .context(format!("Failed to find events by key {}", event_key))
            .map_err(|err| {
                BasicErrorWith404::internal_with_code(
                    err,
                    AptosErrorCode::InternalError,
                    &latest_ledger_info,
                )
            })?;
```

**File:** api/src/context.rs (L1084-1111)
```rust
    pub fn get_events(
        &self,
        event_key: &EventKey,
        start: Option<u64>,
        limit: u16,
        ledger_version: u64,
    ) -> Result<Vec<EventWithVersion>> {
        let (start, order) = if let Some(start) = start {
            (start, Order::Ascending)
        } else {
            (u64::MAX, Order::Descending)
        };
        let mut res = if !db_sharding_enabled(&self.node_config) {
            self.db
                .get_events(event_key, start, order, limit as u64, ledger_version)?
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| anyhow!("Internal indexer reader doesn't exist"))?
                .get_events(event_key, start, order, limit as u64, ledger_version)?
        };
        if order == Order::Descending {
            res.reverse();
            Ok(res)
        } else {
            Ok(res)
        }
    }
```

**File:** config/src/config/api_config.rs (L97-97)
```rust
const DEFAULT_REQUEST_CONTENT_LENGTH_LIMIT: u64 = 8 * 1024 * 1024; // 8 MB
```

**File:** config/src/config/api_config.rs (L99-132)
```rust
pub const DEFAULT_MAX_PAGE_SIZE: u16 = 100;
const DEFAULT_MAX_ACCOUNT_RESOURCES_PAGE_SIZE: u16 = 9999;
const DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE: u16 = 9999;
const DEFAULT_MAX_VIEW_GAS: u64 = 2_000_000; // We keep this value the same as the max number of gas allowed for one single transaction defined in aptos-gas.

fn default_enabled() -> bool {
    true
}

fn default_disabled() -> bool {
    false
}

impl Default for ApiConfig {
    fn default() -> ApiConfig {
        ApiConfig {
            enabled: default_enabled(),
            address: format!("{}:{}", DEFAULT_ADDRESS, DEFAULT_PORT)
                .parse()
                .unwrap(),
            tls_cert_path: None,
            tls_key_path: None,
            content_length_limit: None,
            failpoints_enabled: default_disabled(),
            bcs_output_enabled: default_enabled(),
            json_output_enabled: default_enabled(),
            compression_enabled: default_enabled(),
            encode_submission_enabled: default_enabled(),
            transaction_submission_enabled: default_enabled(),
            transaction_simulation_enabled: default_enabled(),
            max_submit_transaction_batch_size: DEFAULT_MAX_SUBMIT_TRANSACTION_BATCH_SIZE,
            max_block_transactions_page_size: *MAX_RECEIVING_BLOCK_TXNS as u16,
            max_transactions_page_size: DEFAULT_MAX_PAGE_SIZE,
            max_events_page_size: DEFAULT_MAX_PAGE_SIZE,
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L164-167)
```rust
            max_bytes_per_event: NumBytes,
            { 5.. => "max_bytes_per_event" },
            1 << 20, // a single event is 1MB max
        ],
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L115-125)
```rust
        let mut total_event_size = 0;
        for event in change_set.events_iter() {
            let size = event.event_data().len() as u64;
            if size > self.max_bytes_per_event {
                return storage_write_limit_reached(None);
            }
            total_event_size += size;
            if total_event_size > self.max_bytes_all_events_per_transaction {
                return storage_write_limit_reached(None);
            }
        }
```
