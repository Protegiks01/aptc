# Audit Report

## Title
Unbounded Task Spawning DoS in RandManager Randomness Generation

## Summary
The `RandManager::spawn_aggregate_shares_task()` function spawns a new tokio task for each incoming block without any bounds or rate limiting. During high throughput, catch-up scenarios, or when processing many historical blocks, this can lead to unbounded task accumulation that exhausts system resources (memory and tokio runtime threads), causing validator node slowdowns or crashes.

## Finding Description

The vulnerability exists in the randomness generation pipeline where blocks flow from consensus to the RandManager for randomness generation before execution.

**Vulnerable Code Flow:**

1. When consensus orders blocks, they are sent to `ExecutionProxyClient::finalize_order()` [1](#0-0) 

2. Blocks flow through an **unbounded channel** to the RandManager [2](#0-1) 

3. In `RandManager::process_incoming_blocks()`, for **each individual block** in the ordered batch, the code calls `process_incoming_metadata()` [3](#0-2) 

4. Each call to `process_incoming_metadata()` spawns a new task via `spawn_aggregate_shares_task()` [4](#0-3) 

5. The task is spawned using unbounded `tokio::spawn()` without any executor limits [5](#0-4) 

6. Each task sleeps for 300ms then performs network multicasting [6](#0-5) 

7. Tasks are only aborted when blocks are dequeued from the `BlockQueue` (when randomness is ready) [7](#0-6) 

**The Critical Issue:**

If blocks arrive faster than randomness can be generated, the queue grows unbounded and tasks accumulate indefinitely. Unlike the verification task which uses a `BoundedExecutor` [8](#0-7) , the aggregate shares tasks have no bounds.

**Why Existing Backpressure Doesn't Help:**

The BufferManager has backpressure that stops accepting blocks when `highest_committed_round + MAX_BACKLOG < latest_round` [9](#0-8) , but this applies **AFTER** the RandManager in the pipeline. The RandManager receives blocks through unbounded channels and spawns tasks before any backpressure can take effect [10](#0-9) 

**Attack Scenarios:**

1. **High Throughput**: During legitimate network congestion, consensus may order many blocks rapidly (e.g., catching up after downtime)
2. **Path Batching**: The `path_from_ordered_root()` function can return many blocks in a single batch [11](#0-10) 
3. **Byzantine Validator**: A malicious validator could propose many valid blocks that pass consensus, causing task accumulation

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This vulnerability causes **resource exhaustion** leading to:
- **Validator node slowdowns**: Tokio runtime becomes saturated with pending tasks
- **Memory exhaustion**: Each task holds memory (Arc clones, state objects)
- **Cascading failures**: If randomness generation falls behind, subsequent blocks compound the problem
- **Potential node crashes**: Extreme cases could trigger OOM conditions

This matches the **High Severity** criterion of "Validator node slowdowns" ($50,000 tier) or **Medium Severity** for "state inconsistencies requiring intervention" as the randomness generation pipeline becomes blocked.

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits" - unbounded task spawning violates resource constraints.

While this doesn't directly cause consensus safety violations or fund loss, it degrades network availability and validator performance, which are critical for network operation.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can be triggered through:

1. **Normal Operation**: During high-throughput periods or network catch-up scenarios, many blocks are legitimately ordered in quick succession
2. **State Sync/Recovery**: When a validator rejoins after downtime, it processes historical blocks rapidly
3. **No Special Access Required**: The vulnerability is triggered by the normal consensus block ordering mechanism

The likelihood is elevated because:
- No Byzantine behavior required - can occur during legitimate operations
- The unbounded channel and task spawning are fundamental to the current design
- The 300ms sleep per task means even moderate block rates (3-4 blocks/sec) can cause accumulation
- No existing safeguards prevent this scenario

## Recommendation

Implement bounded task spawning with the following approach:

1. **Use BoundedExecutor for task spawning**: Replace `tokio::spawn()` with the existing `BoundedExecutor` that's already used for verification tasks

2. **Add queue size limits**: Implement a maximum queue size in `BlockQueue` and apply backpressure when the limit is reached

3. **Rate limit task creation**: Add a semaphore to limit concurrent aggregation tasks per round

**Proposed Fix:**

```rust
// In RandManager::new(), store the bounded_executor
pub struct RandManager<S: TShare, D: TAugmentedData> {
    // ... existing fields ...
    bounded_executor: BoundedExecutor,
}

// Modify spawn_aggregate_shares_task to use bounded executor
fn spawn_aggregate_shares_task(&self, metadata: RandMetadata) -> DropGuard {
    let rb = self.reliable_broadcast.clone();
    let aggregate_state = Arc::new(ShareAggregateState::new(
        self.rand_store.clone(),
        metadata.clone(),
        self.config.clone(),
    ));
    let epoch_state = self.epoch_state.clone();
    let round = metadata.round;
    let rand_store = self.rand_store.clone();
    
    let task = async move {
        tokio::time::sleep(Duration::from_millis(300)).await;
        // ... rest of task logic ...
    };
    
    let (abort_handle, abort_registration) = AbortHandle::new_pair();
    
    // Use bounded_executor instead of tokio::spawn
    let bounded_executor = self.bounded_executor.clone();
    tokio::spawn(async move {
        let _ = bounded_executor.spawn(Abortable::new(task, abort_registration)).await;
    });
    
    DropGuard::new(abort_handle)
}
```

Additionally, add monitoring for queue depth and alert when approaching limits:

```rust
// In process_incoming_blocks
fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
    const MAX_PENDING_BLOCKS: usize = 100;
    
    if self.block_queue.queue().len() >= MAX_PENDING_BLOCKS {
        warn!("RandManager queue saturated: {} blocks pending", 
              self.block_queue.queue().len());
    }
    
    // ... existing logic ...
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod task_spawning_dos_test {
    use super::*;
    use tokio::time::{sleep, Duration};
    use std::sync::atomic::{AtomicUsize, Ordering};
    
    #[tokio::test(flavor = "multi_thread", worker_threads = 4)]
    async fn test_unbounded_task_spawning_exhaustion() {
        // Simulate rapid block arrival scenario
        const NUM_BLOCKS: usize = 1000;
        let task_counter = Arc::new(AtomicUsize::new(0));
        
        // Simulate what happens in spawn_aggregate_shares_task
        let mut handles = vec![];
        
        for block_id in 0..NUM_BLOCKS {
            let counter_clone = task_counter.clone();
            
            // This mimics the unbounded tokio::spawn in the actual code
            let handle = tokio::spawn(async move {
                counter_clone.fetch_add(1, Ordering::SeqCst);
                
                // Simulate the 300ms sleep from the actual code
                sleep(Duration::from_millis(300)).await;
                
                // Simulate network broadcast work
                sleep(Duration::from_millis(100)).await;
                
                counter_clone.fetch_sub(1, Ordering::SeqCst);
            });
            
            handles.push(handle);
            
            // Simulate blocks arriving faster than they can be processed
            // (10ms between blocks vs 400ms to process each)
            sleep(Duration::from_millis(10)).await;
        }
        
        // Check peak concurrent tasks
        sleep(Duration::from_millis(500)).await;
        let peak_tasks = task_counter.load(Ordering::SeqCst);
        
        println!("Peak concurrent tasks: {}", peak_tasks);
        println!("Total spawned tasks: {}", NUM_BLOCKS);
        
        // With 10ms arrival rate and 400ms processing time,
        // we expect ~40 concurrent tasks at peak
        // In a real scenario with 1000 blocks, this could be much higher
        assert!(peak_tasks > 30, 
                "Expected significant task accumulation, got {}", peak_tasks);
        
        // This demonstrates resource exhaustion potential
        // In production, this would consume tokio threads and memory
        
        // Cleanup
        for handle in handles {
            let _ = handle.await;
        }
    }
}
```

**To reproduce in actual codebase:**

1. Set up a test validator network with randomness enabled
2. Simulate a catch-up scenario where 100+ blocks are ordered rapidly
3. Monitor tokio runtime metrics and memory usage
4. Observe task queue growth and resource consumption
5. Measure RandManager queue depth over time

The vulnerability manifests when blocks arrive at a rate exceeding the randomness generation throughput, causing unbounded accumulation of both queued blocks and active aggregation tasks.

## Notes

This vulnerability is particularly concerning because:

1. **No Byzantine actors required**: Can be triggered by legitimate network conditions
2. **Cascading effect**: Once the RandManager falls behind, it struggles to catch up, making the problem self-reinforcing
3. **Critical path**: Randomness generation is in the critical consensus path, so degradation affects overall network performance
4. **Multiple unbounded resources**: Both the channel and task spawning are unbounded, compounding the issue

The fix should be implemented carefully to ensure it doesn't introduce artificial bottlenecks that harm legitimate throughput, but the current unlimited design is clearly problematic for availability and resource management.

### Citations

**File:** consensus/src/pipeline/execution_client.rs (L233-233)
```rust
        let (ordered_block_tx, ordered_block_rx) = unbounded::<OrderedBlocks>();
```

**File:** consensus/src/pipeline/execution_client.rs (L335-336)
```rust
                        let _ = rand_manager_input_tx.send(ordered_blocks.clone()).await;
                        let _ = secret_share_manager_input_tx.send(ordered_blocks.clone()).await;
```

**File:** consensus/src/pipeline/execution_client.rs (L590-624)
```rust
    async fn finalize_order(
        &self,
        blocks: Vec<Arc<PipelinedBlock>>,
        ordered_proof: WrappedLedgerInfo,
    ) -> ExecutorResult<()> {
        assert!(!blocks.is_empty());
        let mut execute_tx = match self.handle.read().execute_tx.clone() {
            Some(tx) => tx,
            None => {
                debug!("Failed to send to buffer manager, maybe epoch ends");
                return Ok(());
            },
        };

        for block in &blocks {
            block.set_insertion_time();
            if let Some(tx) = block.pipeline_tx().lock().as_mut() {
                tx.order_proof_tx
                    .take()
                    .map(|tx| tx.send(ordered_proof.clone()));
            }
        }

        if execute_tx
            .send(OrderedBlocks {
                ordered_blocks: blocks,
                ordered_proof: ordered_proof.ledger_info().clone(),
            })
            .await
            .is_err()
        {
            debug!("Failed to send to buffer manager, maybe epoch ends");
        }
        Ok(())
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L135-142)
```rust
        let broadcast_handles: Vec<_> = blocks
            .ordered_blocks
            .iter()
            .map(|block| FullRandMetadata::from(block.block()))
            .map(|metadata| self.process_incoming_metadata(metadata))
            .collect();
        let queue_item = QueueItem::new(blocks, Some(broadcast_handles));
        self.block_queue.push_back(queue_item);
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L168-168)
```rust
        self.spawn_aggregate_shares_task(metadata.metadata)
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L234-259)
```rust
            bounded_executor
                .spawn(async move {
                    match bcs::from_bytes::<RandMessage<S, D>>(rand_gen_msg.req.data()) {
                        Ok(msg) => {
                            if msg
                                .verify(
                                    &epoch_state_clone,
                                    &config_clone,
                                    &fast_config_clone,
                                    rand_gen_msg.sender,
                                )
                                .is_ok()
                            {
                                let _ = tx.unbounded_send(RpcRequest {
                                    req: msg,
                                    protocol: rand_gen_msg.protocol,
                                    response_sender: rand_gen_msg.response_sender,
                                });
                            }
                        },
                        Err(e) => {
                            warn!("Invalid rand gen message: {}", e);
                        },
                    }
                })
                .await;
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L274-292)
```rust
            tokio::time::sleep(Duration::from_millis(300)).await;
            let maybe_existing_shares = rand_store.lock().get_all_shares_authors(round);
            if let Some(existing_shares) = maybe_existing_shares {
                let epoch = epoch_state.epoch;
                let request = RequestShare::new(metadata.clone());
                let targets = epoch_state
                    .verifier
                    .get_ordered_account_addresses_iter()
                    .filter(|author| !existing_shares.contains(author))
                    .collect::<Vec<_>>();
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Start broadcasting share request for {}",
                    targets.len(),
                );
                rb.multicast(request, aggregate_state, targets)
                    .await
                    .expect("Broadcast cannot fail");
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L301-301)
```rust
        tokio::spawn(Abortable::new(task, abort_registration));
```

**File:** consensus/src/rand/rand_gen/block_queue.rs (L118-136)
```rust
    pub fn dequeue_rand_ready_prefix(&mut self) -> Vec<OrderedBlocks> {
        let mut rand_ready_prefix = vec![];
        while let Some((_starting_round, item)) = self.queue.first_key_value() {
            if item.num_undecided() == 0 {
                let (_, item) = self.queue.pop_first().unwrap();
                for block in item.blocks() {
                    observe_block(block.timestamp_usecs(), BlockStage::RAND_READY);
                }
                let QueueItem { ordered_blocks, .. } = item;
                debug_assert!(ordered_blocks
                    .ordered_blocks
                    .iter()
                    .all(|block| block.has_randomness()));
                rand_ready_prefix.push(ordered_blocks);
            } else {
                break;
            }
        }
        rand_ready_prefix
```

**File:** consensus/src/pipeline/buffer_manager.rs (L906-910)
```rust
    fn need_back_pressure(&self) -> bool {
        const MAX_BACKLOG: Round = 20;

        self.back_pressure_enabled && self.highest_committed_round + MAX_BACKLOG < self.latest_round
    }
```

**File:** consensus/src/block_storage/block_store.rs (L327-329)
```rust
        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();
```
