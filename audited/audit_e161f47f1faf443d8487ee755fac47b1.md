# Audit Report

## Title
Unbounded Memory Allocation via Indexer GRPC Configuration Parameters Leading to OOM Crash

## Summary
The Aptos indexer GRPC service lacks validation on configuration parameters `processor_task_count`, `processor_batch_size`, and `output_batch_size`. Setting these to maximum values (65535) causes unbounded concurrent task spawning and massive memory allocation, leading to out-of-memory (OOM) crashes when GRPC clients connect.

## Finding Description

The indexer GRPC configuration accepts three critical parameters without any bounds validation or sanitization: [1](#0-0) 

The `ConfigSanitizer` implementation only validates storage dependencies, not parameter bounds: [2](#0-1) 

These unchecked values flow directly into the runtime where they control critical resource allocation: [3](#0-2) 

When a GRPC client requests transactions, the `get_batches()` method creates batches based on `processor_task_count`: [4](#0-3) 

For each batch, `fetch_transactions_from_storage()` spawns a separate tokio task, with ALL tasks running concurrently: [5](#0-4) 

**Attack Path:**

1. Configuration file contains:
   - `processor_task_count: 65535`
   - `processor_batch_size: 65535`
   - `output_batch_size: 65535`

2. Node starts with this configuration (no validation errors)

3. GRPC client connects and requests transactions covering a large version range

4. `get_batches()` creates up to 65,535 batch metadata structures

5. `fetch_transactions_from_storage()` spawns 65,535 concurrent tokio tasks

6. Each task loads up to 65,535 transactions via `fetch_raw_txns_with_retries()`

7. With conservative 1KB average transaction size: 65,535 × 65,535 × 1KB ≈ 4.29 GB
   With realistic 10KB average (including events, state changes): ≈ 42.9 GB

8. Memory exhaustion causes OOM kill or system crash

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**High Severity** per Aptos Bug Bounty criteria:
- **API crashes**: The indexer GRPC service will crash on first client connection
- **Validator node slowdowns**: If running on a validator node, OOM can cause performance degradation or complete node failure
- **Availability impact**: Indexer fullnodes become unavailable, disrupting ecosystem services that depend on transaction streaming

The vulnerability affects any node running the indexer GRPC service with misconfigured values, particularly:
- Indexer fullnodes (commonly operated by ecosystem participants)
- Data service nodes
- Archive nodes providing historical transaction access

## Likelihood Explanation

**Moderate to High Likelihood:**

1. **Honest Misconfiguration**: Operators unfamiliar with safe values might set "high" values thinking it improves performance
2. **Template Reuse**: Malicious or poorly designed configuration templates could spread these values
3. **No Warning**: The configuration loads silently without warnings about dangerous values
4. **Single Point of Failure**: Any single GRPC client request triggers the OOM condition

The lack of validation means there's no safety net between configuration and catastrophic failure.

## Recommendation

Add comprehensive validation in the `ConfigSanitizer` implementation:

```rust
impl ConfigSanitizer for IndexerGrpcConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        if !node_config.indexer_grpc.enabled {
            return Ok(());
        }

        // Validate storage dependencies (existing check)
        if !node_config.storage.enable_indexer
            && !node_config
                .indexer_table_info
                .table_info_service_mode
                .is_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "storage.enable_indexer must be true or indexer_table_info.table_info_service_mode must be IndexingOnly if indexer_grpc.enabled is true".to_string(),
            ));
        }

        // NEW: Validate processor_task_count
        const MAX_PROCESSOR_TASK_COUNT: u16 = 100;
        let processor_task_count = node_config
            .indexer_grpc
            .processor_task_count
            .unwrap_or_else(|| get_default_processor_task_count(node_config.indexer_grpc.use_data_service_interface));
        
        if processor_task_count > MAX_PROCESSOR_TASK_COUNT {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("processor_task_count ({}) exceeds maximum safe value ({})", 
                    processor_task_count, MAX_PROCESSOR_TASK_COUNT),
            ));
        }

        // NEW: Validate processor_batch_size
        const MAX_PROCESSOR_BATCH_SIZE: u16 = 10_000;
        if node_config.indexer_grpc.processor_batch_size > MAX_PROCESSOR_BATCH_SIZE {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("processor_batch_size ({}) exceeds maximum safe value ({})",
                    node_config.indexer_grpc.processor_batch_size, MAX_PROCESSOR_BATCH_SIZE),
            ));
        }

        // NEW: Validate output_batch_size
        const MAX_OUTPUT_BATCH_SIZE: u16 = 1_000;
        if node_config.indexer_grpc.output_batch_size > MAX_OUTPUT_BATCH_SIZE {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("output_batch_size ({}) exceeds maximum safe value ({})",
                    node_config.indexer_grpc.output_batch_size, MAX_OUTPUT_BATCH_SIZE),
            ));
        }

        Ok(())
    }
}
```

These limits should be based on:
- Available system memory
- Expected transaction size
- Concurrent task overhead
- Network bandwidth considerations

## Proof of Concept

```rust
#[test]
fn test_oom_attack_via_config() {
    use aptos_config::config::{NodeConfig, IndexerGrpcConfig};
    use std::net::{SocketAddr, Ipv4Addr, SocketAddrV4};
    
    // Create malicious configuration
    let mut node_config = NodeConfig::default();
    node_config.indexer_grpc = IndexerGrpcConfig {
        enabled: true,
        use_data_service_interface: false,
        address: SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(127, 0, 0, 1), 50051)),
        processor_task_count: Some(65535),  // Maximum u16
        processor_batch_size: 65535,        // Maximum u16
        output_batch_size: 65535,           // Maximum u16
        transaction_channel_size: 35,
        max_transaction_filter_size_bytes: 10_000,
    };
    
    // Enable storage indexer to pass existing validation
    node_config.storage.enable_indexer = true;
    
    // This should FAIL with the fix, but currently PASSES
    let result = IndexerGrpcConfig::sanitize(
        &node_config,
        NodeType::Validator,
        Some(ChainId::mainnet()),
    );
    
    // Currently this assertion fails (no validation)
    // With the fix, it should succeed (validation catches the issue)
    assert!(result.is_err(), "Configuration with extreme values should be rejected");
}
```

To demonstrate the actual OOM (requires running node):

1. Create a config file with malicious values
2. Start an indexer fullnode with this config
3. Connect a GRPC client requesting a large transaction range
4. Observe OOM crash via system logs/monitoring

**Notes:**
The vulnerability exists because configuration validation is incomplete. While the `sanitize()` method checks storage dependencies, it completely ignores bounds on resource allocation parameters. The concurrent task spawning pattern in `fetch_transactions_from_storage()` amplifies the impact, as all tasks allocate memory simultaneously before any results are consumed.

### Citations

**File:** config/src/config/indexer_grpc_config.rs (L46-52)
```rust
    pub processor_task_count: Option<u16>,

    /// Number of transactions each processor will process
    pub processor_batch_size: u16,

    /// Number of transactions returned in a single stream response
    pub output_batch_size: u16,
```

**File:** config/src/config/indexer_grpc_config.rs (L103-128)
```rust
impl ConfigSanitizer for IndexerGrpcConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        if !node_config.indexer_grpc.enabled {
            return Ok(());
        }

        if !node_config.storage.enable_indexer
            && !node_config
                .indexer_table_info
                .table_info_service_mode
                .is_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "storage.enable_indexer must be true or indexer_table_info.table_info_service_mode must be IndexingOnly if indexer_grpc.enabled is true".to_string(),
            ));
        }
        Ok(())
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L54-79)
```rust
    let processor_task_count = node_config
        .indexer_grpc
        .processor_task_count
        .unwrap_or_else(|| get_default_processor_task_count(use_data_service_interface));
    let processor_batch_size = node_config.indexer_grpc.processor_batch_size;
    let output_batch_size = node_config.indexer_grpc.output_batch_size;
    let transaction_channel_size = node_config.indexer_grpc.transaction_channel_size;
    let max_transaction_filter_size_bytes =
        node_config.indexer_grpc.max_transaction_filter_size_bytes;

    runtime.spawn(async move {
        let context = Arc::new(Context::new(
            chain_id,
            db,
            mp_sender,
            node_config,
            indexer_reader,
        ));
        let service_context = ServiceContext {
            context: context.clone(),
            processor_task_count,
            processor_batch_size,
            output_batch_size,
            transaction_channel_size,
            max_transaction_filter_size_bytes,
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L244-261)
```rust
        let mut storage_fetch_tasks = vec![];
        let ledger_version = self.highest_known_version;
        for batch in batches {
            let context = self.context.clone();
            let task = tokio::spawn(async move {
                Self::fetch_raw_txns_with_retries(context.clone(), ledger_version, batch).await
            });
            storage_fetch_tasks.push(task);
        }

        let transactions_from_storage =
            match futures::future::try_join_all(storage_fetch_tasks).await {
                Ok(res) => res,
                Err(err) => panic!(
                    "[Indexer Fullnode] Error fetching transaction batches: {:?}",
                    err
                ),
            };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L293-318)
```rust
    async fn get_batches(&mut self) -> Vec<TransactionBatchInfo> {
        if !self.ensure_highest_known_version().await {
            return vec![];
        }

        let mut starting_version = self.current_version;
        let mut num_fetches = 0;
        let mut batches = vec![];
        let end_version = std::cmp::min(self.end_version, self.highest_known_version + 1);

        while num_fetches < self.processor_task_count && starting_version < end_version {
            let num_transactions_to_fetch = std::cmp::min(
                self.processor_batch_size as u64,
                end_version - starting_version,
            ) as u16;

            batches.push(TransactionBatchInfo {
                start_version: starting_version,
                head_version: self.highest_known_version,
                num_transactions_to_fetch,
            });
            starting_version += num_transactions_to_fetch as u64;
            num_fetches += 1;
        }
        batches
    }
```
