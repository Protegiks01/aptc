# Audit Report

## Title
Module Validation Bypass in State Snapshot Restore Allows Invalid Bytecode Acceptance

## Summary
The `validate_modules` flag in the replay-verify tool fails to prevent invalid Move modules from being written to the database. Even when validation is enabled, modules that fail bytecode verification are only logged as errors but still accepted into the state, corrupting the database with invalid bytecode.

## Finding Description

The replay-verify tool is designed to restore and verify blockchain state from backups. It includes a `validate_modules` flag intended to verify Move bytecode safety during state snapshot restoration. However, this security control is fundamentally broken. [1](#0-0) 

The flag defaults to `false`, meaning no validation occurs by default. Even when explicitly enabled, the validation implementation is critically flawed: [2](#0-1) 

The `validate_modules` function is called to verify bytecode, but it only logs errors without preventing invalid modules from being added: [3](#0-2) 

**Critical flaw**: Lines 242-246 show that when module verification fails, only an `error!()` log is emitted. The function does not return an error, does not filter out the invalid module from the blob, and does not abort the restore process. The blobs are returned unchanged and subsequently written to the database via `add_chunk()`.

**Attack Scenario:**
1. Attacker creates a malicious backup containing Move modules with invalid bytecode (e.g., stack safety violations, type safety violations, or malformed instructions)
2. Victim runs `replay-verify` tool with `validate_modules=true` (or worse, with default `false`)
3. Invalid modules are written to AptosDB through the StateSnapshotReceiver
4. Database state is now corrupted with invalid bytecode that bypassed verification

This breaks the **State Consistency** invariant - the database should only contain valid, verified state data. It also undermines the **Move VM Safety** invariant by allowing unverified bytecode into the system.

## Impact Explanation

**Severity: High** - This qualifies as a "Significant protocol violation" under the Aptos bug bounty program.

**State Corruption**: The database contains invalid Move modules that should never have been accepted. This violates data integrity guarantees and could cause unpredictable behavior.

**Security Control Bypass**: The `validate_modules` flag is advertised as a security feature but provides no actual protection. This is a false sense of security.

**Verification Tool Failure**: The replay-verify tool's core purpose is to verify backup integrity, but it cannot detect invalid modules even when validation is explicitly enabled.

**Potential Consequences**:
- If these modules are referenced by later transactions, the VM will fail during module loading
- State divergence between nodes restoring from different backups
- Backup verification processes give false positives
- Corrupted state may propagate if used for state sync or snapshots

While the Move VM will catch invalid modules during execution via `build_locally_verified_module`, the damage is already done - invalid data exists in the canonical blockchain state database. [4](#0-3) 

## Likelihood Explanation

**Likelihood: Medium-High**

**Attack Feasibility**: 
- Attacker needs ability to create malicious backup files or compromise backup storage
- No validator privileges required
- Attack is straightforward - craft invalid Move bytecode and include in backup

**Triggering Conditions**:
- Victim runs replay-verify or restore tools (common operational procedures)
- Default configuration is vulnerable (`validate_modules=false`)
- Even security-conscious users enabling the flag are still vulnerable

**Real-World Scenarios**:
- Node operators restoring from backups after data loss
- Archive nodes verifying historical data integrity
- Disaster recovery procedures
- Testing and validation workflows

## Recommendation

**Fix the validation logic to actually reject invalid modules:**

```rust
fn validate_modules(blob: &[(StateKey, StateValue)]) -> Result<()> {
    let features = Features::default();
    let config = aptos_prod_verifier_config(LATEST_GAS_FEATURE_VERSION, &features);
    
    for (key, value) in blob {
        if let StateKeyInner::AccessPath(p) = key.inner() {
            if let Path::Code(module_id) = p.get_path() {
                let module = CompiledModule::deserialize(value.bytes())
                    .map_err(|e| anyhow!("Module {:?} failed to deserialize: {:?}", module_id, e))?;
                
                verify_module_with_config(&config, &module)
                    .map_err(|e| anyhow!("Module {:?} failed validation: {:?}", module_id, e))?;
            }
        }
    }
    Ok(())
}
```

**Update the call site to handle validation errors:**

```rust
if self.validate_modules {
    blobs = tokio::task::spawn_blocking(move || {
        Self::validate_modules(&blobs)?;
        Ok(blobs)
    })
    .await??;
}
```

**Additional recommendations**:
1. Change default to `validate_modules=true` for safety
2. Add clear documentation warning about security implications
3. Implement validation statistics/metrics to track validation failures
4. Consider adding a strict mode that aborts on any validation failure

## Proof of Concept

```rust
#[tokio::test]
async fn test_invalid_module_acceptance() {
    use aptos_types::state_store::{state_key::StateKey, state_value::StateValue};
    use move_binary_format::file_format::*;
    use move_core_types::identifier::Identifier;
    use move_core_types::account_address::AccountAddress;
    use move_core_types::language_storage::ModuleId;
    
    // Create a malformed Move module with invalid bytecode
    let mut module = CompiledModule {
        version: 6,
        self_module_handle_idx: ModuleHandleIndex(0),
        module_handles: vec![ModuleHandle {
            address: AddressIdentifierIndex(0),
            name: IdentifierIndex(0),
        }],
        struct_handles: vec![],
        function_handles: vec![],
        field_handles: vec![],
        friend_decls: vec![],
        struct_defs: vec![],
        struct_def_instantiations: vec![],
        function_defs: vec![
            // Create function with invalid stack operations
            FunctionDefinition {
                function: FunctionHandleIndex(0),
                visibility: Visibility::Public,
                is_entry: false,
                acquires_global_resources: vec![],
                code: Some(CodeUnit {
                    locals: SignatureIndex(0),
                    code: vec![
                        // Invalid: Pop from empty stack
                        Bytecode::Pop,
                        Bytecode::Ret,
                    ],
                }),
            }
        ],
        function_instantiations: vec![],
        signatures: vec![Signature(vec![])],
        identifiers: vec![Identifier::new("TestModule").unwrap()],
        address_identifiers: vec![AccountAddress::ZERO],
        constant_pool: vec![],
        metadata: vec![],
    };
    
    let mut module_bytes = vec![];
    module.serialize(&mut module_bytes).unwrap();
    
    let module_id = ModuleId::new(AccountAddress::ZERO, Identifier::new("TestModule").unwrap());
    let state_key = StateKey::module_id(&module_id);
    let state_value = StateValue::new_legacy(module_bytes.into());
    
    let blobs = vec![(state_key, state_value)];
    
    // Validate with current implementation
    // This should fail but only logs error
    StateSnapshotRestoreController::validate_modules(&blobs);
    
    // The blobs are still returned unchanged and would be written to DB
    assert_eq!(blobs.len(), 1); // Invalid module still present
    
    println!("VULNERABILITY: Invalid module passed validation and would be written to database!");
}
```

## Notes

This vulnerability represents a critical gap between security intention and implementation. The validation mechanism exists but is non-functional, creating a false sense of security that is arguably worse than having no validation at all. Organizations relying on this tool for backup verification or disaster recovery are unknowingly accepting potentially malicious or corrupted data into their blockchain state.

### Citations

**File:** storage/db-tool/src/replay_verify.rs (L50-51)
```rust
    #[clap(long)]
    validate_modules: bool,
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L205-215)
```rust
            if self.validate_modules {
                blobs = tokio::task::spawn_blocking(move || {
                    Self::validate_modules(&blobs);
                    blobs
                })
                .await?;
            }
            tokio::task::spawn_blocking(move || {
                receiver.lock().as_mut().unwrap().add_chunk(blobs, proof)
            })
            .await??;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L233-251)
```rust
    fn validate_modules(blob: &[(StateKey, StateValue)]) {
        // TODO: Instead of using default features, fetch them from the state.
        let features = Features::default();

        let config = aptos_prod_verifier_config(LATEST_GAS_FEATURE_VERSION, &features);
        for (key, value) in blob {
            if let StateKeyInner::AccessPath(p) = key.inner() {
                if let Path::Code(module_id) = p.get_path() {
                    if let Ok(module) = CompiledModule::deserialize(value.bytes()) {
                        if let Err(err) = verify_module_with_config(&config, &module) {
                            error!("Module {:?} failed validation: {:?}", module_id, err);
                        }
                    } else {
                        error!("Module {:?} failed to deserialize", module_id);
                    }
                }
            }
        }
    }
```

**File:** third_party/move/move-vm/runtime/src/storage/environment.rs (L178-201)
```rust
    pub fn build_locally_verified_module(
        &self,
        compiled_module: Arc<CompiledModule>,
        module_size: usize,
        module_hash: &[u8; 32],
    ) -> VMResult<LocallyVerifiedModule> {
        if !VERIFIED_MODULES_CACHE.contains(module_hash) {
            let _timer =
                VM_TIMER.timer_with_label("move_bytecode_verifier::verify_module_with_config");

            // For regular execution, we cache already verified modules. Note that this even caches
            // verification for the published modules. This should be ok because as long as the
            // hash is the same, the deployed bytecode and any dependencies are the same, and so
            // the cached verification result can be used.
            move_bytecode_verifier::verify_module_with_config(
                &self.vm_config().verifier_config,
                compiled_module.as_ref(),
            )?;
            check_natives(compiled_module.as_ref())?;
            VERIFIED_MODULES_CACHE.put(*module_hash);
        }

        Ok(LocallyVerifiedModule(compiled_module, module_size))
    }
```
