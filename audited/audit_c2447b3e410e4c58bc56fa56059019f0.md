# Audit Report

## Title
Missing Batch Payload Verification Allows Malicious Validators to Bypass Quota Limits and Cause Resource Exhaustion

## Summary
A malicious validator can broadcast `SignedBatchInfo` messages with falsified `num_bytes` values. When honest validators fetch these batches, they fail to verify that the received payload size matches the claimed `num_bytes`, causing `update_quota()` to be called with incorrect values. This bypasses quota enforcement and allows resource exhaustion attacks on victim validators.

## Finding Description

The security question asks about integer underflow in `update_quota()`. **Direct integer underflow is not possible** - all subtractions in `update_quota()` are protected by comparison checks. [1](#0-0) 

However, a **critical quota bypass vulnerability** exists in the batch fetching mechanism. The attack exploits missing payload verification when batches are retrieved from remote validators:

**Attack Flow:**

1. **Malicious Batch Creation**: A malicious validator creates a `BatchInfo` with legitimate transactions (e.g., 1MB payload) but falsifies the `num_bytes` field to a much lower value (e.g., 1000 bytes). The `digest` field is the hash of the payload only, not the entire `BatchInfo` structure. [2](#0-1) 

2. **Signature & Broadcast**: The malicious validator signs this falsified `BatchInfo` and broadcasts it via `SignedBatchInfo` messages. Other validators cannot detect the false `num_bytes` at this stage because they don't have the payload yet. [3](#0-2) 

3. **Batch Request**: When honest validators need the batch (e.g., for block execution), they request it via `BatchRequest` using the digest. [4](#0-3) 

4. **Unverified Response**: The malicious validator responds with a `BatchResponse::Batch` containing the real payload. The requesting validator extracts the payload **without verifying** it matches the claimed `num_bytes`. [5](#0-4) 

5. **Quota Bypass**: The fetched payload is combined with the original (falsified) `BatchInfo` and persisted. The `update_quota()` function is called with the false low `num_bytes` value instead of the actual payload size. [6](#0-5) 

6. **Resource Exhaustion**: The malicious validator repeats this process, storing many large batches on victim validators while consuming minimal quota. This leads to memory and disk exhaustion.

**Broken Invariant**: Resource Limits invariant #9 - "All operations must respect gas, storage, and computational limits." The quota system is designed to prevent resource exhaustion, but this vulnerability bypasses it completely.

## Impact Explanation

**Critical Severity** - This vulnerability enables resource exhaustion attacks that can crash validator nodes:

- **Node Failure**: Victim validators can run out of memory or disk space, causing crashes and loss of liveness
- **Network Partition**: If enough validators are attacked simultaneously, the network could lose consensus capability
- **Requires Hard Fork**: Recovery may require manual intervention or network restart
- **Byzantine Threshold**: Even with < 1/3 Byzantine validators, malicious actors can impact honest nodes

The impact qualifies as **Critical** per Aptos bug bounty criteria: "Total loss of liveness/network availability" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**High Likelihood**:

- **Low Attack Complexity**: The attacker only needs to control one validator node and can construct malicious batches programmatically
- **No Coordination Required**: A single malicious validator can attack multiple victims independently
- **Detection Difficult**: The attack is silent until resource exhaustion occurs
- **Immediate Exploitability**: No race conditions or timing requirements

The attack is feasible because:
1. Validators can construct arbitrary `BatchInfo` structures [7](#0-6) 
2. Batch serving doesn't validate payload size [8](#0-7) 
3. Batch fetching doesn't verify payloads [9](#0-8) 

## Recommendation

**Add payload verification** when batches are fetched remotely. The `Batch::verify()` method already exists and checks that `payload.num_bytes()` matches `batch_info.num_bytes()`. [10](#0-9) 

**Fix Location 1**: In `batch_requester.rs`, verify the batch before returning the payload:

```rust
Ok(BatchResponse::Batch(batch)) => {
    counters::RECEIVED_BATCH_RESPONSE_COUNT.inc();
    // ADD VERIFICATION HERE
    batch.verify().context("Batch verification failed")?;
    let payload = batch.into_transactions();
    return Ok(payload);
}
```

**Fix Location 2**: Alternatively, verify when combining payload with batch_info in `batch_store.rs`:

```rust
let payload = requester.request_batch(...).await?;
// ADD VERIFICATION HERE
let batch = Batch::new_generic(batch_info.clone(), BatchPayload::new(batch_info.author(), payload.clone()));
batch.verify().context("Fetched batch verification failed")?;
batch_store.persist(vec![PersistedValue::new(batch_info.into(), Some(payload.clone()))]);
```

## Proof of Concept

```rust
// This PoC demonstrates the vulnerability (pseudo-code for clarity)
#[tokio::test]
async fn test_quota_bypass_via_false_num_bytes() {
    // Setup: Create validator nodes
    let (malicious_validator, honest_validator) = setup_validators();
    
    // Step 1: Malicious validator creates batch with large payload
    let large_payload = vec![create_transaction(); 10000]; // 1MB of transactions
    let actual_num_bytes = calculate_payload_size(&large_payload); // ~1,000,000
    
    // Step 2: Create BatchInfo with FALSIFIED num_bytes
    let malicious_batch_info = BatchInfo::new(
        malicious_validator.peer_id(),
        batch_id,
        epoch,
        expiration,
        hash(&large_payload), // Correct digest
        large_payload.len() as u64,
        1000, // FAKE num_bytes (should be ~1,000,000)
        gas_bucket_start,
    );
    
    // Step 3: Sign and broadcast to honest validator
    let signed_batch_info = malicious_validator.sign(&malicious_batch_info);
    honest_validator.receive_signed_batch_info(signed_batch_info);
    
    // Step 4: Honest validator requests batch
    let batch_request = BatchRequest::new(
        honest_validator.peer_id(),
        epoch,
        malicious_batch_info.digest(),
    );
    
    // Step 5: Malicious validator responds with real payload
    // (BatchResponse contains both false batch_info and real payload)
    let response = malicious_validator.handle_batch_request(batch_request);
    
    // Step 6: Honest validator processes response WITHOUT verification
    // Quota is updated with false num_bytes (1000 instead of 1,000,000)
    let result = honest_validator.process_batch_response(response);
    
    // Verification: Check that quota was bypassed
    let quota_used = honest_validator.get_quota_used();
    assert!(quota_used < actual_num_bytes / 100); // Used <1% of actual quota
    
    // Step 7: Repeat attack until memory exhaustion
    for _ in 0..1000 {
        // Malicious validator can store 1000 * 1MB = 1GB
        // while only consuming ~1MB of quota
    }
    
    // Result: Honest validator crashes due to OOM
}
```

**Notes:**
- The original security question about "integer underflow" is incorrect - `update_quota()` has proper bounds checking
- However, the **quota bypass vulnerability** discovered is more severe than a simple underflow
- This vulnerability affects the same system (quota management) and has the same ultimate impact (resource exhaustion)

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L64-84)
```rust
    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L663-723)
```rust
    fn get_or_fetch_batch(
        &self,
        batch_info: BatchInfo,
        responders: Vec<PeerId>,
    ) -> Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>> {
        let mut responders = responders.into_iter().collect();

        self.inflight_fetch_requests
            .lock()
            .entry(*batch_info.digest())
            .and_modify(|fetch_unit| {
                fetch_unit.responders.lock().append(&mut responders);
            })
            .or_insert_with(|| {
                let responders = Arc::new(Mutex::new(responders));
                let responders_clone = responders.clone();

                let inflight_requests_clone = self.inflight_fetch_requests.clone();
                let batch_store = self.batch_store.clone();
                let requester = self.batch_requester.clone();

                let fut = async move {
                    let batch_digest = *batch_info.digest();
                    defer!({
                        inflight_requests_clone.lock().remove(&batch_digest);
                    });
                    // TODO(ibalajiarun): Support V2 batch
                    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
                        Ok(value.take_payload().expect("Must have payload"))
                    } else {
                        // Quorum store metrics
                        counters::MISSED_BATCHES_COUNT.inc();
                        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
                        Ok(payload)
                    }
                }
                .boxed()
                .shared();

                tokio::spawn(fut.clone());

                BatchFetchUnit {
                    responders: responders_clone,
                    fut,
                }
            })
            .fut
            .clone()
    }
```

**File:** consensus/src/quorum_store/types.rs (L182-203)
```rust
impl Batch<BatchInfo> {
    pub fn new(
        batch_id: BatchId,
        payload: Vec<SignedTransaction>,
        epoch: u64,
        expiration: u64,
        batch_author: PeerId,
        gas_bucket_start: u64,
    ) -> Self {
        let payload = BatchPayload::new(batch_author, payload);
        let batch_info = BatchInfo::new(
            batch_author,
            batch_id,
            epoch,
            expiration,
            payload.hash(),
            payload.num_txns() as u64,
            payload.num_bytes() as u64,
            gas_bucket_start,
        );
        Self::new_generic(batch_info, payload)
    }
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L60-81)
```rust
impl BatchInfo {
    pub fn new(
        author: PeerId,
        batch_id: BatchId,
        epoch: u64,
        expiration: u64,
        digest: HashValue,
        num_txns: u64,
        num_bytes: u64,
        gas_bucket_start: u64,
    ) -> Self {
        Self {
            author,
            batch_id,
            epoch,
            expiration,
            digest,
            num_txns,
            num_bytes,
            gas_bucket_start,
        }
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L459-482)
```rust
    pub fn verify(
        &self,
        sender: PeerId,
        max_batch_expiry_gap_usecs: u64,
        validator: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        if sender != self.signer {
            bail!("Sender {} mismatch signer {}", sender, self.signer);
        }

        if self.expiration()
            > aptos_infallible::duration_since_epoch().as_micros() as u64
                + max_batch_expiry_gap_usecs
        {
            bail!(
                "Batch expiration too far in future: {} > {}",
                self.expiration(),
                aptos_infallible::duration_since_epoch().as_micros() as u64
                    + max_batch_expiry_gap_usecs
            );
        }

        Ok(validator.optimistic_verify(self.signer, &self.info, &self.signature)?)
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L101-180)
```rust
    pub(crate) async fn request_batch(
        &self,
        digest: HashValue,
        expiration: u64,
        responders: Arc<Mutex<BTreeSet<PeerId>>>,
        mut subscriber_rx: oneshot::Receiver<PersistedValue<BatchInfoExt>>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let validator_verifier = self.validator_verifier.clone();
        let mut request_state = BatchRequesterState::new(responders, self.retry_limit);
        let network_sender = self.network_sender.clone();
        let request_num_peers = self.request_num_peers;
        let my_peer_id = self.my_peer_id;
        let epoch = self.epoch;
        let retry_interval = Duration::from_millis(self.retry_interval_ms as u64);
        let rpc_timeout = Duration::from_millis(self.rpc_timeout_ms as u64);

        monitor!("batch_request", {
            let mut interval = time::interval(retry_interval);
            let mut futures = FuturesUnordered::new();
            let request = BatchRequest::new(my_peer_id, epoch, digest);
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
                    },
                    Some(response) = futures.next() => {
                        match response {
                            Ok(BatchResponse::Batch(batch)) => {
                                counters::RECEIVED_BATCH_RESPONSE_COUNT.inc();
                                let payload = batch.into_transactions();
                                return Ok(payload);
                            }
                            // Short-circuit if the chain has moved beyond expiration
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
                            }
                            Ok(BatchResponse::BatchV2(_)) => {
                                error!("Batch V2 response is not supported");
                            }
                            Err(e) => {
                                counters::RECEIVED_BATCH_RESPONSE_ERROR_COUNT.inc();
                                debug!("QS: batch request error, digest:{}, error:{:?}", digest, e);
                            }
                        }
                    },
                    result = &mut subscriber_rx => {
                        match result {
                            Ok(persisted_value) => {
                                counters::RECEIVED_BATCH_FROM_SUBSCRIPTION_COUNT.inc();
                                let (_, maybe_payload) = persisted_value.unpack();
                                return Ok(maybe_payload.expect("persisted value must exist"));
                            }
                            Err(err) => {
                                debug!("channel closed: {}", err);
                            }
                        };
                    },
                }
            }
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
        })
    }
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L404-438)
```rust
        spawn_named!("batch_serve", async move {
            info!(epoch = epoch, "Batch retrieval task starts");
            while let Some(rpc_request) = batch_retrieval_rx.next().await {
                counters::RECEIVED_BATCH_REQUEST_COUNT.inc();
                let response = if let Ok(value) =
                    batch_store.get_batch_from_local(&rpc_request.req.digest())
                {
                    let batch: Batch<BatchInfoExt> = value.try_into().unwrap();
                    let batch: Batch<BatchInfo> = batch
                        .try_into()
                        .expect("Batch retieval requests must be for V1 batch");
                    BatchResponse::Batch(batch)
                } else {
                    match aptos_db_clone.get_latest_ledger_info() {
                        Ok(ledger_info) => BatchResponse::NotFound(ledger_info),
                        Err(e) => {
                            let e = anyhow::Error::from(e);
                            error!(epoch = epoch, error = ?e, kind = error_kind(&e));
                            continue;
                        },
                    }
                };

                let msg = ConsensusMsg::BatchResponseV2(Box::new(response));
                let bytes = rpc_request.protocol.to_bytes(&msg).unwrap();
                if let Err(e) = rpc_request
                    .response_sender
                    .send(Ok(bytes.into()))
                    .map_err(|_| anyhow::anyhow!("Failed to send block retrieval response"))
                {
                    warn!(epoch = epoch, error = ?e, kind = error_kind(&e));
                }
            }
            info!(epoch = epoch, "Batch retrieval task stops");
        });
```
