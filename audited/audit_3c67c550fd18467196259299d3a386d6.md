# Audit Report

## Title
Forked Chain Injection Through Unverified Transaction Streaming Endpoint

## Summary
The `get_transactions_from_node()` gRPC streaming endpoint serves transactions to indexer clients without including or requiring verification of cryptographic proofs that would establish these transactions belong to the canonical chain. Byzantine fullnodes can exploit this to serve transactions from forked chains, corrupting indexer state and enabling double-spend detection failures.

## Finding Description

The vulnerability exists in the transaction streaming architecture where cryptographic proofs are generated but systematically discarded before transmission to clients.

**Server-Side Flow (Proof Discarding):**

The fullnode gRPC service implements transaction streaming in the server trait: [1](#0-0) 

The implementation creates an `IndexerStreamCoordinator` that fetches transactions: [2](#0-1) 

The coordinator calls `context.get_transactions()` which retrieves data from storage: [3](#0-2) 

The storage layer generates `TransactionOutputListWithProofV2` containing cryptographic proofs: [4](#0-3) 

However, the proofs are immediately discarded via `.consume_output_list_with_proof()`: [5](#0-4) 

Only the transaction data and infos are extracted - the proofs are thrown away: [6](#0-5) 

**Protocol Definition (No Proof Fields):**

The protobuf definition for streamed transactions contains no proof fields: [7](#0-6) 

The `Transaction` protobuf message includes `accumulator_root_hash` but no cryptographic proof path: [8](#0-7) 

**Client-Side Flow (No Verification):**

Indexer clients receive transactions and perform only basic validation: [9](#0-8) 

The client only validates that `chain_id` matches - a trivial integer that can be spoofed: [10](#0-9) 

No cryptographic verification, proof validation, or ledger info checking occurs in any indexer client component.

**Attack Scenario:**

1. Attacker operates a modified fullnode that has experienced a consensus fork (or deliberately creates one by modifying consensus logic)
2. The forked chain maintains the same `chain_id` as the canonical chain
3. Victim indexer connects to the malicious fullnode's gRPC endpoint
4. Indexer requests transactions starting from version X: `GetTransactionsFromNodeRequest { starting_version: X }`
5. Malicious fullnode serves transactions from its forked database
6. Indexer validates only `chain_id` (which matches) and sequential versions
7. Indexer stores forked transactions in its database
8. Applications querying the indexer receive incorrect data:
   - Balances may be wrong if transfers occurred differently in the fork
   - Smart contract states reflect fork execution rather than canonical chain
   - Same transaction hash may map to different outcomes
9. Double-spend detection fails because the indexer shows different transaction results than the canonical chain

**Invariant Violation:**

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." While Merkle proofs exist in the system, they are never transmitted to or verified by indexer clients, making state transitions unverifiable.

## Impact Explanation

**Critical Severity** - This vulnerability enables systematic corruption of indexer infrastructure, which forms the data layer for the entire Aptos ecosystem:

1. **Double-Spend Detection Failures**: Indexers showing forked transactions cannot detect when the same funds are spent differently on the canonical chain vs. the fork. Wallets relying on indexer data may show incorrect balances.

2. **Smart Contract State Corruption**: DeFi protocols, NFT marketplaces, and other dApps querying indexer state receive incorrect data about contract states, token ownership, and transaction history.

3. **Systemic Trust Failure**: Block explorers, analytics platforms, and data providers all rely on indexers. Corruption spreads across the ecosystem.

4. **Undetectable Attack**: No cryptographic evidence of tampering exists. The indexer has no way to prove it received forked data versus canonical data.

This qualifies as **Critical** under the Aptos bug bounty program as it enables significant state inconsistencies requiring intervention and affects the security guarantees of the entire ecosystem beyond just the node itself.

## Likelihood Explanation

**Medium-High Likelihood:**

**Attacker Requirements:**
- Operate a fullnode (low barrier - publicly accessible software)
- Induce or wait for a consensus fork (moderate - can be artificially created through network partitioning or consensus bugs)
- Social engineering or network manipulation to get indexers to connect (moderate difficulty)

**Likelihood Factors:**
- Many indexer operators run their own fullnodes and could unknowingly operate forked nodes
- Network issues, misconfigurations, or consensus bugs can cause legitimate forks
- Indexers have no mechanism to detect they're connected to a forked node
- The attack leaves no cryptographic evidence and may go undetected for extended periods

**Detection Difficulty:**
- Indexers cannot cryptographically verify canonical chain membership
- Cross-validation requires connecting to multiple independent fullnodes
- Divergence may only be noticed through out-of-band comparison with canonical chain

## Recommendation

Implement cryptographic proof transmission and verification in the gRPC streaming protocol:

**1. Modify Protocol to Include Proofs:**

Add proof fields to `TransactionsFromNodeResponse` protobuf:
```protobuf
message TransactionsFromNodeResponse {
  oneof response {
    StreamStatus status = 1;
    TransactionsOutputWithProof data = 2;  // Changed
  }
  uint32 chain_id = 3;
  LedgerInfoWithSignatures ledger_info = 4;  // Added
}

message TransactionsOutputWithProof {
  repeated aptos.transaction.v1.Transaction transactions = 1;
  TransactionAccumulatorProof proof = 2;  // Added
}
```

**2. Modify Server to Include Proofs:**

In `context.rs`, preserve proofs instead of discarding them:
```rust
pub fn get_transactions_with_proof(
    &self,
    start_version: u64,
    limit: u16,
    ledger_version: u64,
) -> Result<(Vec<TransactionOnChainData>, TransactionInfoListWithProof, LedgerInfo)> {
    let data = self.db.get_transaction_outputs(start_version, limit as u64, ledger_version)?;
    // Keep the proof instead of consuming it
    let proof = data.consume_output_list_with_proof().proof;
    let ledger_info = self.get_latest_ledger_info()?;
    // Return both data and proof
}
```

**3. Modify Client to Verify Proofs:**

In indexer clients, add proof verification:
```rust
async fn verify_and_process_response(
    response: TransactionsFromNodeResponse,
    trusted_state: &mut TrustedState,
) -> Result<()> {
    match response.response {
        Response::Data(data) => {
            // Verify ledger info signatures
            let ledger_info = response.ledger_info
                .ok_or("Missing ledger info")?;
            trusted_state.verify_and_ratchet(&ledger_info)?;
            
            // Verify transaction proof against ledger info
            data.proof.verify(
                ledger_info.ledger_info(),
                data.transactions.first().version,
                &data.transactions
            )?;
            
            // Only process if verification succeeds
            process_transactions(data.transactions).await?;
        }
    }
}
```

**4. Initialize Trusted State:**

Clients must bootstrap with a trusted waypoint or ledger info from a known-good source before accepting streamed transactions.

## Proof of Concept

**Setup:**
1. Run two fullnodes - one canonical, one deliberately forked
2. Create a fork by network partitioning during consensus
3. Connect indexer to forked fullnode

**Forked Fullnode Setup:**
```rust
// Modified fullnode that serves from a forked database
// In fullnode_data_service.rs, the service already serves whatever is in its DB
// To create a fork, simply:
// 1. Start fullnode
// 2. Network partition it during consensus
// 3. Let it diverge from canonical chain
// 4. Reconnect it (it will have forked state in DB)
```

**Indexer Client Test:**
```rust
#[tokio::test]
async fn test_forked_chain_injection() {
    // Connect to canonical fullnode
    let canonical_client = create_grpc_client(canonical_url).await;
    
    // Connect to forked fullnode
    let forked_client = create_grpc_client(forked_url).await;
    
    // Request same transaction range from both
    let request = GetTransactionsFromNodeRequest {
        starting_version: Some(1000),
        transactions_count: Some(100),
    };
    
    let canonical_txns = fetch_all_transactions(canonical_client, request.clone()).await;
    let forked_txns = fetch_all_transactions(forked_client, request).await;
    
    // Both have same chain_id but different transaction content
    assert_eq!(canonical_txns.chain_id, forked_txns.chain_id);
    
    // Transactions diverge (different hashes, different state roots)
    for i in 0..canonical_txns.transactions.len() {
        let canonical_hash = canonical_txns.transactions[i].info.hash;
        let forked_hash = forked_txns.transactions[i].info.hash;
        
        // Forked transactions differ but indexer accepts them without verification
        if canonical_hash != forked_hash {
            println!("Fork detected at version {}", 1000 + i);
            println!("Canonical: {:?}", canonical_hash);
            println!("Forked: {:?}", forked_hash);
            
            // Demonstrate: indexer would accept forked_txns with no validation
            // This corrupts indexer state with fork data
        }
    }
}
```

**Expected Behavior:** Indexer accepts forked transactions because:
- `chain_id` matches (both claim to be mainnet/testnet)
- Version numbers are sequential
- No cryptographic verification prevents acceptance

**Actual Impact:** Indexer now stores incorrect transaction data, breaking all downstream applications relying on this indexer.

### Citations

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.tonic.rs (L179-185)
```rust
        async fn get_transactions_from_node(
            &self,
            request: tonic::Request<super::GetTransactionsFromNodeRequest>,
        ) -> std::result::Result<
            tonic::Response<Self::GetTransactionsFromNodeStream>,
            tonic::Status,
        >;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L103-117)
```rust
            let mut coordinator = IndexerStreamCoordinator::new(
                context,
                starting_version,
                ending_version,
                processor_task_count,
                processor_batch_size,
                output_batch_size,
                tx.clone(),
                // For now the request for this interface doesn't include a txn filter
                // because it is only used for the txn stream filestore worker, which
                // needs every transaction. Later we may add support for txn filtering
                // to this interface too.
                None,
                Some(abort_handle.clone()),
            );
```

**File:** api/src/context.rs (L831-850)
```rust
    pub fn get_transactions(
        &self,
        start_version: u64,
        limit: u16,
        ledger_version: u64,
    ) -> Result<Vec<TransactionOnChainData>> {
        let data = self
            .db
            .get_transaction_outputs(start_version, limit as u64, ledger_version)?
            .consume_output_list_with_proof();

        let txn_start_version = data
            .get_first_output_version()
            .ok_or_else(|| format_err!("no start version from database"))?;
        ensure!(
            txn_start_version == start_version,
            "invalid start version from database: {} != {}",
            txn_start_version,
            start_version
        );
```

**File:** api/src/context.rs (L852-876)
```rust
        let infos = data.proof.transaction_infos;
        let transactions_and_outputs = data.transactions_and_outputs;

        ensure!(
            transactions_and_outputs.len() == infos.len(),
            "invalid data size from database: {}, {}",
            transactions_and_outputs.len(),
            infos.len(),
        );

        transactions_and_outputs
            .into_iter()
            .zip(infos)
            .enumerate()
            .map(
                |(i, ((txn, txn_output), info))| -> Result<TransactionOnChainData> {
                    let version = start_version + i as u64;
                    let (write_set, events, _, _, _) = txn_output.unpack();
                    let h = self.get_accumulator_root_hash(version)?;
                    let txn: TransactionOnChainData =
                        (version, txn, info, events, h, write_set).into();
                    Ok(self.maybe_translate_v2_to_v1_events(txn))
                },
            )
            .collect()
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L423-428)
```rust
            let proof = TransactionInfoListWithProof::new(
                self.ledger_db
                    .transaction_accumulator_db()
                    .get_transaction_range_proof(Some(start_version), limit, ledger_version)?,
                txn_infos,
            );
```

**File:** protos/proto/aptos/internal/fullnode/v1/fullnode_data.proto (L18-54)
```text
message TransactionsOutput {
  repeated aptos.transaction.v1.Transaction transactions = 1;
}

message StreamStatus {
  enum StatusType {
    STATUS_TYPE_UNSPECIFIED = 0;
    // Signal for the start of the stream.
    STATUS_TYPE_INIT = 1;
    // Signal for the end of the batch.
    STATUS_TYPE_BATCH_END = 2;
  }
  StatusType type = 1;
  // Required. Start version of current batch/stream, inclusive.
  uint64 start_version = 2;
  // End version of current *batch*, inclusive.
  optional uint64 end_version = 3 [jstype = JS_STRING];
}

message GetTransactionsFromNodeRequest {
  // Required; start version of current stream.
  // If not set will panic somewhere
  optional uint64 starting_version = 1 [jstype = JS_STRING];

  // Optional; number of transactions to return in current stream.
  // If not set, response streams infinitely.
  optional uint64 transactions_count = 2 [jstype = JS_STRING];
}

message TransactionsFromNodeResponse {
  oneof response {
    StreamStatus status = 1;
    TransactionsOutput data = 2;
  }
  // Making sure that all the responses include a chain id
  uint32 chain_id = 3;
}
```

**File:** protos/proto/aptos/transaction/v1/transaction.proto (L169-179)
```text
message TransactionInfo {
  bytes hash = 1;
  bytes state_change_hash = 2;
  bytes event_root_hash = 3;
  optional bytes state_checkpoint_hash = 4;
  uint64 gas_used = 5 [jstype = JS_STRING];
  bool success = 6;
  string vm_status = 7;
  bytes accumulator_root_hash = 8;
  repeated WriteSetChange changes = 9;
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L286-314)
```rust
async fn verify_fullnode_init_signal(
    cache_operator: &mut CacheOperator<redis::aio::ConnectionManager>,
    init_signal: TransactionsFromNodeResponse,
    file_store_metadata: FileStoreMetadata,
) -> Result<(ChainID, StartingVersion)> {
    let (fullnode_chain_id, starting_version) = match init_signal
        .response
        .expect("[Indexer Cache] Response type does not exist.")
    {
        Response::Status(status_frame) => {
            match StatusType::try_from(status_frame.r#type)
                .expect("[Indexer Cache] Invalid status type.")
            {
                StatusType::Init => (init_signal.chain_id, status_frame.start_version),
                _ => {
                    bail!("[Indexer Cache] Streaming error: first frame is not INIT signal.");
                },
            }
        },
        _ => {
            bail!("[Indexer Cache] Streaming error: first frame is not siganl frame.");
        },
    };

    // Guaranteed that chain id is here at this point because we already ensure that fileworker did the set up
    let chain_id = cache_operator.get_chain_id().await?.unwrap();
    if chain_id != fullnode_chain_id as u64 {
        bail!("[Indexer Cache] Chain ID mismatch between fullnode init signal and cache.");
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L382-384)
```rust
        if received.chain_id as u64 != fullnode_chain_id as u64 {
            panic!("[Indexer Cache] Chain id mismatch happens during data streaming.");
        }
```
