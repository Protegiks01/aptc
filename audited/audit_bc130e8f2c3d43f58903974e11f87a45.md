# Audit Report

## Title
Fixed Stream Timeout Threshold Enables Liveness Attack via Forced Stream Recreation Cycle

## Summary
The `max_num_stream_timeouts` configuration parameter creates a fixed threshold (default: 12) that allows attackers to force perpetual data stream termination and recreation, preventing stable state synchronization and degrading node operational availability.

## Finding Description

The state sync driver uses a fixed counter to track consecutive stream timeouts and forcibly terminates streams after exactly 12 timeouts. This creates a deterministic attack surface where an adversary controlling or degrading peer connections can force nodes into a perpetual cycle of stream resets. [1](#0-0) [2](#0-1) 

The timeout logic tracks consecutive failures and returns a `CriticalDataStreamTimeout` error when the threshold is exceeded: [3](#0-2) 

Both the bootstrapper and continuous syncer handle this error by resetting the active stream: [4](#0-3) [5](#0-4) 

When the stream is reset, it terminates the current stream and sets `active_data_stream` to `None`: [6](#0-5) 

On the next `drive_progress` call, a new stream is automatically initialized: [7](#0-6) 

**Attack Flow:**
1. Attacker controls or degrades sufficient peer connections (via Sybil attack, network DoS, or protocol-level resource exhaustion)
2. Data streaming service requests timeout because peers don't respond within `max_stream_wait_time_ms` (5000ms default)
3. After 12 consecutive timeouts (60 seconds total), `CriticalDataStreamTimeout` is triggered
4. Stream is reset, flushing in-memory state via `reset_chunk_executor()`
5. New stream is created from current synced version
6. If attack persists, new stream encounters same timeout issues
7. Cycle repeats indefinitely, preventing stable synchronization

**Invariant Violation:**
This breaks the liveness guarantee that nodes should be able to synchronize reliably with the network under reasonable conditions. The fixed threshold creates a deterministic point where an attacker can force stream termination regardless of actual network conditions or data availability.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria:

**"Validator node slowdowns"**: The constant stream recreation cycle causes significant performance degradation. Each reset triggers:
- Stream termination overhead
- Chunk executor reset flushing in-memory state
- New stream initialization and request setup
- Loss of buffered/prefetched data
- Additional network round-trips

**"Significant protocol violations"**: The attack prevents nodes from maintaining stable state synchronization, a core protocol requirement. Affected nodes:
- Cannot reliably catch up to the network
- Fall progressively further behind
- May become unable to participate in consensus (validators) or serve requests (fullnodes)
- Experience degraded operational availability

The attack does not reach Critical severity because:
- It does not cause permanent network partition (recovers when attack stops)
- It does not violate consensus safety or cause fund loss
- It does not require a hardfork to resolve

## Likelihood Explanation

**Likelihood: Medium-to-High** depending on network topology and peer diversity.

**Feasible Attack Scenarios:**
1. **Sybil Attack on Peer Connections**: Attacker runs many malicious nodes that accept connections but delay or drop data requests, causing timeouts
2. **Targeted Network DoS**: Attacker performs network-level attacks (DDoS, routing manipulation) against honest peers serving the victim node
3. **Small Network Exploitation**: In networks with limited peer diversity, controlling a smaller fraction of peers is sufficient
4. **Protocol-Level Resource Exhaustion**: Attacker floods honest peers with requests, degrading their response times to legitimate requests

**Mitigating Factors:**
- Multi-fetch sends requests to multiple peers simultaneously
- Peer scoring demotes poorly-performing peers over time
- Dynamic prefetching adjusts request rates based on conditions
- Large, diverse peer sets reduce attack feasibility

**Aggravating Factors:**
- Fixed threshold is deterministic and predictable
- No adaptive backoff or threshold adjustment based on network conditions
- Stream reset flushes all buffered state, maximizing progress loss
- Attack can be sustained with intermittent rather than constant degradation

**Attack Complexity:** Medium - requires controlling peer connections or performing network-level attacks, but no cryptographic breaks or validator compromise needed.

## Recommendation

Implement adaptive timeout thresholds and circuit breaker patterns:

```rust
// In StateSyncDriverConfig
pub struct StateSyncDriverConfig {
    // ... existing fields ...
    
    /// Base timeout threshold (starts here)
    pub base_num_stream_timeouts: u64,
    
    /// Maximum timeout threshold before giving up
    pub max_num_stream_timeouts: u64,
    
    /// Factor to increase threshold on each reset
    pub stream_timeout_backoff_factor: u64,
}

impl Default for StateSyncDriverConfig {
    fn default() -> Self {
        Self {
            // ... existing defaults ...
            base_num_stream_timeouts: 12,
            max_num_stream_timeouts: 100,
            stream_timeout_backoff_factor: 2,
        }
    }
}
```

Track consecutive stream resets and apply exponential backoff:

```rust
// In Bootstrapper and ContinuousSyncer
pub struct Bootstrapper {
    // ... existing fields ...
    consecutive_stream_resets: u64,
    current_timeout_threshold: u64,
}

impl Bootstrapper {
    async fn reset_active_stream(&mut self, notification_and_feedback: Option<NotificationAndFeedback>) -> Result<(), Error> {
        // ... existing reset logic ...
        
        // Increment reset counter and apply backoff
        self.consecutive_stream_resets += 1;
        let config = &self.driver_configuration.config;
        self.current_timeout_threshold = std::cmp::min(
            config.base_num_stream_timeouts * config.stream_timeout_backoff_factor.pow(self.consecutive_stream_resets as u32),
            config.max_num_stream_timeouts
        );
        
        warn!("Stream reset #{}, new timeout threshold: {}", 
              self.consecutive_stream_resets, 
              self.current_timeout_threshold);
    }
    
    // Reset counter on successful progress
    fn on_successful_notification(&mut self) {
        if self.consecutive_stream_resets > 0 {
            info!("Resetting stream timeout backoff after successful progress");
            self.consecutive_stream_resets = 0;
            self.current_timeout_threshold = self.driver_configuration.config.base_num_stream_timeouts;
        }
    }
}
```

Additionally, implement circuit breaker pattern:
- After N consecutive stream resets within time window T, enter "degraded mode"
- In degraded mode, increase timeouts, reduce concurrent requests, and log warnings
- Automatically recover when successful notifications resume

## Proof of Concept

The existing test demonstrates the vulnerability pattern: [8](#0-7) 

This test shows:
1. After 5 non-critical timeouts, the 6th triggers `CriticalDataStreamTimeout`
2. Stream is automatically reinitialized
3. Timeout counter resets to 0
4. Cycle can repeat indefinitely

**Extended PoC to demonstrate liveness attack:**

```rust
#[tokio::test]
async fn test_perpetual_stream_reset_attack() {
    // Create configuration with short timeout for faster testing
    let mut driver_configuration = create_full_node_driver_configuration();
    driver_configuration.config.max_stream_wait_time_ms = 100;
    driver_configuration.config.max_num_stream_timeouts = 3;

    // Create mock client that never sends notifications (simulates unresponsive peers)
    let mut mock_streaming_client = create_mock_streaming_client();
    let mut expectation_sequence = Sequence::new();
    
    // Simulate 10 stream reset cycles
    for i in 0..10 {
        let (_notification_sender, data_stream_listener) = create_data_stream_listener();
        let data_stream_id = data_stream_listener.data_stream_id;
        
        mock_streaming_client
            .expect_get_all_epoch_ending_ledger_infos()
            .times(1)
            .return_once(move |_| Ok(data_stream_listener))
            .in_sequence(&mut expectation_sequence);
            
        mock_streaming_client
            .expect_terminate_stream_with_feedback()
            .with(eq(data_stream_id), eq(None))
            .return_const(Ok(()))
            .in_sequence(&mut expectation_sequence);
    }

    let (mut bootstrapper, _) = create_bootstrapper(driver_configuration, mock_streaming_client, None, true);
    let global_data_summary = create_global_summary(1);

    // Demonstrate 10 reset cycles with no progress
    let initial_version = fetch_pre_committed_version(bootstrapper.storage.clone()).unwrap();
    
    for cycle in 0..10 {
        // Initialize stream
        drive_progress(&mut bootstrapper, &global_data_summary, false).await.unwrap();
        
        // Hit timeout threshold
        for _ in 0..3 {
            let error = drive_progress(&mut bootstrapper, &global_data_summary, false).await.unwrap_err();
            assert_matches!(error, Error::CriticalDataStreamTimeout(_) | Error::DataStreamNotificationTimeout(_));
        }
        
        // Verify no synchronization progress made
        let current_version = fetch_pre_committed_version(bootstrapper.storage.clone()).unwrap();
        assert_eq!(current_version, initial_version, "No progress after {} reset cycles", cycle + 1);
    }
    
    println!("Successfully demonstrated 10 stream reset cycles with zero synchronization progress");
}
```

This PoC demonstrates that an attacker who can sustain peer unresponsiveness can prevent synchronization indefinitely, validating the liveness attack vector.

### Citations

**File:** config/src/config/state_sync_config.rs (L120-121)
```rust
    /// The maximum number of stream timeouts allowed before termination
    pub max_num_stream_timeouts: u64,
```

**File:** config/src/config/state_sync_config.rs (L145-145)
```rust
            max_num_stream_timeouts: 12,
```

**File:** state-sync/state-sync-driver/src/utils.rs (L200-238)
```rust
pub async fn get_data_notification(
    max_stream_wait_time_ms: u64,
    max_num_stream_timeouts: u64,
    active_data_stream: Option<&mut DataStreamListener>,
) -> Result<DataNotification, Error> {
    let active_data_stream = active_data_stream
        .ok_or_else(|| Error::UnexpectedError("The active data stream does not exist!".into()))?;

    let timeout_ms = Duration::from_millis(max_stream_wait_time_ms);
    if let Ok(data_notification) = timeout(timeout_ms, active_data_stream.select_next_some()).await
    {
        // Update the metrics for the data notification receive latency
        metrics::observe_duration(
            &metrics::DATA_NOTIFICATION_LATENCIES,
            metrics::NOTIFICATION_CREATE_TO_RECEIVE,
            data_notification.creation_time,
        );

        // Reset the number of consecutive timeouts for the data stream
        active_data_stream.num_consecutive_timeouts = 0;
        Ok(data_notification)
    } else {
        // Increase the number of consecutive timeouts for the data stream
        active_data_stream.num_consecutive_timeouts += 1;

        // Check if we've timed out too many times
        if active_data_stream.num_consecutive_timeouts >= max_num_stream_timeouts {
            Err(Error::CriticalDataStreamTimeout(format!(
                "{:?}",
                max_num_stream_timeouts
            )))
        } else {
            Err(Error::DataStreamNotificationTimeout(format!(
                "{:?}",
                timeout_ms
            )))
        }
    }
}
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L414-441)
```rust
    pub async fn drive_progress(
        &mut self,
        global_data_summary: &GlobalDataSummary,
    ) -> Result<(), Error> {
        if self.is_bootstrapped() {
            return Err(Error::AlreadyBootstrapped(
                "The bootstrapper should not attempt to make progress!".into(),
            ));
        }

        if self.active_data_stream.is_some() {
            // We have an active data stream. Process any notifications!
            self.process_active_stream_notifications().await?;
        } else if self.storage_synchronizer.pending_storage_data() {
            // Wait for any pending data to be processed
            sample!(
                SampleRate::Duration(Duration::from_secs(PENDING_DATA_LOG_FREQ_SECS)),
                info!("Waiting for the storage synchronizer to handle pending data!")
            );
        } else {
            // Fetch a new data stream to start streaming data
            self.initialize_active_data_stream(global_data_summary)
                .await?;
        }

        // Check if we've now bootstrapped
        self.notify_listeners_if_bootstrapped().await
    }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L582-598)
```rust
    /// Attempts to fetch a data notification from the active stream
    async fn fetch_next_data_notification(&mut self) -> Result<DataNotification, Error> {
        let max_stream_wait_time_ms = self.driver_configuration.config.max_stream_wait_time_ms;
        let max_num_stream_timeouts = self.driver_configuration.config.max_num_stream_timeouts;
        let result = utils::get_data_notification(
            max_stream_wait_time_ms,
            max_num_stream_timeouts,
            self.active_data_stream.as_mut(),
        )
        .await;
        if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
            // If the stream has timed out too many times, we need to reset it
            warn!("Resetting the currently active data stream due to too many timeouts!");
            self.reset_active_stream(None).await?;
        }
        result
    }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1539-1556)
```rust
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L182-198)
```rust
    /// Attempts to fetch a data notification from the active stream
    async fn fetch_next_data_notification(&mut self) -> Result<DataNotification, Error> {
        let max_stream_wait_time_ms = self.driver_configuration.config.max_stream_wait_time_ms;
        let max_num_stream_timeouts = self.driver_configuration.config.max_num_stream_timeouts;
        let result = utils::get_data_notification(
            max_stream_wait_time_ms,
            max_num_stream_timeouts,
            self.active_data_stream.as_mut(),
        )
        .await;
        if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
            // If the stream has timed out too many times, we need to reset it
            warn!("Resetting the currently active data stream due to too many timeouts!");
            self.reset_active_stream(None).await?;
        }
        result
    }
```

**File:** state-sync/state-sync-driver/src/tests/bootstrapper.rs (L282-343)
```rust
async fn test_critical_timeout() {
    // Create a driver configuration with a genesis waypoint and a stream timeout of 1 second
    let mut driver_configuration = create_full_node_driver_configuration();
    driver_configuration.config.max_stream_wait_time_ms = 1000;
    driver_configuration.config.max_num_stream_timeouts = 6;

    // Create the mock streaming client
    let mut mock_streaming_client = create_mock_streaming_client();
    let mut expectation_sequence = Sequence::new();
    let (_notification_sender_1, data_stream_listener_1) = create_data_stream_listener();
    let (_notification_sender_2, data_stream_listener_2) = create_data_stream_listener();
    let data_stream_id_1 = data_stream_listener_1.data_stream_id;
    for data_stream_listener in [data_stream_listener_1, data_stream_listener_2] {
        mock_streaming_client
            .expect_get_all_epoch_ending_ledger_infos()
            .times(1)
            .with(eq(1))
            .return_once(move |_| Ok(data_stream_listener))
            .in_sequence(&mut expectation_sequence);
    }
    mock_streaming_client
        .expect_terminate_stream_with_feedback()
        .with(eq(data_stream_id_1), eq(None))
        .return_const(Ok(()));

    // Create the bootstrapper
    let (mut bootstrapper, _) =
        create_bootstrapper(driver_configuration, mock_streaming_client, None, true);

    // Create a global data summary where epoch 0 and 1 have ended
    let global_data_summary = create_global_summary(1);

    // Drive progress to initialize the epoch ending data stream
    drive_progress(&mut bootstrapper, &global_data_summary, false)
        .await
        .unwrap();

    // Drive progress and verify we get non-critical timeouts
    for _ in 0..5 {
        let error = drive_progress(&mut bootstrapper, &global_data_summary, false)
            .await
            .unwrap_err();
        assert_matches!(error, Error::DataStreamNotificationTimeout(_));
    }

    // Drive progress again and verify we get a critical timeout
    let error = drive_progress(&mut bootstrapper, &global_data_summary, false)
        .await
        .unwrap_err();
    assert_matches!(error, Error::CriticalDataStreamTimeout(_));

    // Drive progress to initialize the epoch ending data stream again
    drive_progress(&mut bootstrapper, &global_data_summary, false)
        .await
        .unwrap();

    // Drive progress again and verify we get a non-critical timeout
    let error = drive_progress(&mut bootstrapper, &global_data_summary, false)
        .await
        .unwrap_err();
    assert_matches!(error, Error::DataStreamNotificationTimeout(_));
}
```
