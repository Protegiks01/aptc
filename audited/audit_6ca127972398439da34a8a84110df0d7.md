# Audit Report

## Title
Unhandled Panic in Indexer-GRPC Fullnode Causes Process Termination on Block Info Retrieval Failure

## Summary
The `convert_to_api_txns()` function and `process_next_batch()` function in the indexer-grpc-fullnode stream coordinator contain panic paths when `get_block_info_by_version()` fails. These panics terminate the entire indexer-grpc-fullnode process, leaving clients with incomplete transaction data and no recovery mechanism. This vulnerability can be triggered by legitimate requests for pruned transaction versions or during database errors.

## Finding Description

The indexer-grpc-fullnode service provides transaction streaming to clients through GRPC. Two critical panic points exist in the transaction processing pipeline:

**First Panic Point** - In `process_next_batch()`: [1](#0-0) 

**Second Panic Point** - In `convert_to_api_txns()`: [2](#0-1) 

Both locations call `get_block_info_by_version()` and use `unwrap_or_else()` with a panic handler, which crashes the entire process on any failure.

The `get_block_info_by_version()` function can legitimately fail in several scenarios:

1. **Ledger Pruning** (most common): When the requested version has been pruned from the database. The pruning check occurs here: [3](#0-2) 

The implementation validates the requested version: [4](#0-3) 

2. **Version Not Synced**: If the requested version exceeds the synced version: [5](#0-4) 

3. **Missing NewBlockEvent**: If the event cannot be found in the event store: [6](#0-5) 

**Ledger pruning is enabled by default** with a 90 million version window: [7](#0-6) 

**Attack Path:**
1. Attacker identifies a fullnode that has pruned old transaction data (versions < min_readable_version)
2. Attacker sends a `GetTransactionsFromNodeRequest` via GRPC starting at a pruned version
3. The stream coordinator processes the request in the spawned tokio task: [8](#0-7) 

4. When `process_next_batch()` is called, `get_block_info_by_version()` fails due to pruning
5. The `unwrap_or_else()` triggers a panic, terminating the entire indexer-grpc-fullnode process
6. All connected clients are abruptly disconnected with incomplete data
7. No error message is sent to clients; the stream simply terminates

This breaks the **API Availability** invariant - the service should handle errors gracefully and return appropriate error responses to clients rather than crashing the entire process.

## Impact Explanation

This vulnerability qualifies as **High Severity** according to the Aptos bug bounty program criteria:
- **API crashes**: Explicitly listed as High severity. The panic terminates the entire indexer-grpc-fullnode process.
- **Validator node slowdowns**: While this affects fullnodes primarily, the crash causes service disruption.

**Concrete Impact:**
1. **Denial of Service**: A single malicious or misconfigured client request can crash the entire indexer-grpc-fullnode service
2. **Data Integrity**: Clients receive incomplete transaction batches with no indication of failure
3. **No Recovery Mechanism**: The process must be manually restarted; no automatic recovery exists
4. **Cascading Failures**: All connected clients are simultaneously disconnected, potentially causing downstream indexer failures

The vulnerability does not directly affect consensus or validator operations, but it severely impacts the indexer infrastructure that many ecosystem applications depend on.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to occur in production environments:

1. **Natural Occurrence**: After ~90 million transactions (default prune_window), any fullnode will have pruned old data. Clients requesting historical data before the prune window will trigger the panic.

2. **Low Attack Complexity**: Any client can trigger this by sending a GRPC request with `starting_version` set to a pruned version. No authentication or special privileges required.

3. **Common Use Case**: Historical blockchain data requests are common for blockchain explorers, analytics tools, and data indexers performing backfills.

4. **Multiple Failure Scenarios**: Beyond pruning, database errors, race conditions during state sync, or corrupted data can also trigger the panic.

5. **Production Configuration**: Pruning is enabled by default, making this exploitable on any long-running fullnode.

## Recommendation

Replace the panic-based error handling with graceful error propagation to the client. The fix should:

1. **Return Result Types**: Change functions to return `Result<T, Status>` instead of panicking
2. **Send Error Responses**: Transmit proper error messages to clients via the GRPC stream
3. **Log Errors**: Log failures for monitoring without terminating the process
4. **Validate Version Range**: Pre-validate requested versions against `min_readable_version` before processing

**Recommended Fix:**

```rust
// In convert_to_api_txns(), replace panic with Result propagation:
fn convert_to_api_txns(
    context: Arc<Context>,
    raw_txns: Vec<TransactionOnChainData>,
) -> Result<Vec<(APITransaction, TransactionSizeInfo)>, String> {
    if raw_txns.is_empty() {
        return Ok(vec![]);
    }
    let first_version = raw_txns.first().map(|txn| txn.version).unwrap();
    
    // Replace panic with error return
    let (_, _, block_event) = context
        .db
        .get_block_info_by_version(first_version)
        .map_err(|e| format!("Could not get block_info for version {}: {:?}", first_version, e))?;
    
    // ... rest of function
}

// In process_next_batch(), handle errors gracefully:
pub async fn process_next_batch(&mut self) -> Vec<Result<EndVersion, Status>> {
    // ... existing code ...
    
    // Replace panic with error status
    let block_event_result = self
        .context
        .db
        .get_block_info_by_version(end_version as u64);
    
    let (_, _, block_event) = match block_event_result {
        Ok(info) => info,
        Err(e) => {
            let error_status = Status::unavailable(format!(
                "Block info unavailable for version {}: {:?}", 
                end_version, e
            ));
            // Send error to client instead of panicking
            let _ = self.transactions_sender.send(Err(error_status)).await;
            return vec![];
        }
    };
    
    // ... rest of function
}
```

Additionally, add version validation in `get_transactions_from_node()`:

```rust
// Validate starting_version against min_readable_version
let min_readable = context.db.get_min_readable_version()?;
if starting_version < min_readable {
    return Err(Status::out_of_range(format!(
        "Requested version {} is pruned. Minimum available version is {}", 
        starting_version, min_readable
    )));
}
```

## Proof of Concept

```rust
// Reproduction steps:

// 1. Start an Aptos fullnode with default configuration (pruning enabled)
// 2. Wait for ledger to exceed 90 million versions, or manually configure 
//    a smaller prune_window for testing

// 3. Use the following GRPC client code to trigger the panic:

use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient, GetTransactionsFromNodeRequest,
};
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Connect to indexer-grpc-fullnode
    let mut client = FullnodeDataClient::connect("http://127.0.0.1:50051").await?;
    
    // Request transactions at version 0 (guaranteed to be pruned if prune_window passed)
    let request = Request::new(GetTransactionsFromNodeRequest {
        starting_version: Some(0), // Pruned version
        transactions_count: Some(1000),
    });
    
    // This will cause the fullnode process to panic and crash
    let mut stream = client.get_transactions_from_node(request).await?.into_inner();
    
    // Attempt to read from stream - will fail when process crashes
    while let Some(response) = stream.message().await? {
        println!("Received response: {:?}", response);
    }
    
    Ok(())
}

// Expected behavior: Indexer-grpc-fullnode process crashes with panic message:
// "[Indexer Fullnode] Could not get block_info for version 0"
// 
// Correct behavior: Should return GRPC error: 
// Status { code: OutOfRange, message: "Version 0 is pruned, min available version is 90000000" }
```

**Testing on Existing Infrastructure:**
- Query any long-running Aptos fullnode's current `min_readable_version`
- Send a transaction stream request with `starting_version` below that threshold
- Observe process panic and crash

## Notes

This vulnerability affects the indexer infrastructure layer, not core consensus. However, it represents a critical operational security issue as:

1. The indexer-grpc-fullnode is a key component for blockchain data access
2. Many ecosystem applications depend on reliable transaction streaming
3. The lack of graceful error handling violates basic API resilience principles
4. The default pruning configuration makes this exploitable on all production fullnodes

The fix requires careful error propagation through the async task boundaries and proper GRPC error status handling to maintain stream integrity while communicating failures to clients.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L119-128)
```rust
        let (_, _, block_event) = self
            .context
            .db
            .get_block_info_by_version(end_version as u64)
            .unwrap_or_else(|_| {
                panic!(
                    "[Indexer Fullnode] Could not get block_info for version {}",
                    end_version,
                )
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L376-384)
```rust
        let (_, _, block_event) = context
            .db
            .get_block_info_by_version(first_version)
            .unwrap_or_else(|_| {
                panic!(
                    "[Indexer Fullnode] Could not get block_info for start version {}",
                    first_version,
                )
            });
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L261-271)
```rust
    pub(super) fn error_if_ledger_pruned(&self, data_type: &str, version: Version) -> Result<()> {
        let min_readable_version = self.ledger_pruner.get_min_readable_version();
        ensure!(
            version >= min_readable_version,
            "{} at version {} is pruned, min available version is {}.",
            data_type,
            version,
            min_readable_version
        );
        Ok(())
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L344-348)
```rust
        let synced_version = self.ensure_synced_version()?;
        ensure!(
            version <= synced_version,
            "Requested version {version} > synced version {synced_version}",
        );
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L351-354)
```rust
            let (first_version, event_index, block_height) = self
                .event_store
                .lookup_event_before_or_at_version(&new_block_event_key(), version)?
                .ok_or_else(|| AptosDbError::NotFound("NewBlockEvent".to_string()))?;
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L779-789)
```rust
    fn get_block_info_by_version(
        &self,
        version: Version,
    ) -> Result<(Version, Version, NewBlockEvent)> {
        gauged_api("get_block_info", || {
            self.error_if_ledger_pruned("NewBlockEvent", version)?;

            let (block_height, block_info) = self.get_raw_block_info_by_version(version)?;
            self.to_api_block_info(block_height, block_info)
        })
    }
```

**File:** config/src/config/storage_config.rs (L387-395)
```rust
impl Default for LedgerPrunerConfig {
    fn default() -> Self {
        LedgerPrunerConfig {
            enable: true,
            prune_window: 90_000_000,
            batch_size: 5_000,
            user_pruning_window_offset: 200_000,
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L101-117)
```rust
        tokio::spawn(async move {
            // Initialize the coordinator that tracks starting version and processes transactions
            let mut coordinator = IndexerStreamCoordinator::new(
                context,
                starting_version,
                ending_version,
                processor_task_count,
                processor_batch_size,
                output_batch_size,
                tx.clone(),
                // For now the request for this interface doesn't include a txn filter
                // because it is only used for the txn stream filestore worker, which
                // needs every transaction. Later we may add support for txn filtering
                // to this interface too.
                None,
                Some(abort_handle.clone()),
            );
```
