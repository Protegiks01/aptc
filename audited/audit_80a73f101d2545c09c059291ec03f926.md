# Audit Report

## Title
Metadata Race Condition in Backup Operations Causes Orphaned Backups

## Summary
A race condition exists in all backup controller implementations (`write_manifest()` functions) where the manifest file is written and flushed to storage before the corresponding metadata entry is saved. If the backup process crashes between these two operations, the manifest becomes permanently orphaned and undiscoverable by the restore system, violating backup integrity guarantees.

## Finding Description

The vulnerability exists in three backup controller implementations where metadata is saved separately after manifest persistence:

**Transaction Backup Controller:** [1](#0-0) 

**Epoch Ending Backup Controller:** [2](#0-1) 

**State Snapshot Backup Controller:** [3](#0-2) 

In all three cases, the pattern is identical:
1. Manifest object is created and serialized
2. Manifest is written to storage and flushed (`.shutdown().await?`)
3. Metadata object is created pointing to the manifest
4. Metadata is saved to storage

**Critical Gap:** Between steps 2 and 4, if the process crashes (hardware failure, OOM, network disruption, pod eviction), the manifest exists in storage but has no metadata entry.

**Discovery Mechanism Dependency:**
The restore system discovers backups ONLY through metadata files: [4](#0-3) 

The restore coordinator relies on this metadata view: [5](#0-4) 

**No Cleanup Mechanism:**
The garbage collection system only tracks metadata files, not manifest files: [6](#0-5) 

Orphaned manifests will persist indefinitely in storage with no mechanism for discovery or cleanup.

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria ("State inconsistencies requiring intervention")

**Impact Details:**
1. **Backup Unavailability:** Orphaned backups cannot be used for disaster recovery despite containing valid data
2. **Storage Waste:** Manifest files and their associated chunk files consume storage indefinitely
3. **Data Loss Risk:** If critical backups are orphaned during disaster recovery windows, chain state may be unrecoverable
4. **Silent Failure:** No error indicationâ€”the backup appears to complete successfully before the crash

**Scope:**
- Affects all backup operations: continuous backups, one-time backups, and compacted backups
- Impacts transaction backups, epoch ending backups, and state snapshot backups
- All storage backends (LocalFs, S3, GCS, Azure) are affected

This does NOT cause:
- Direct fund loss or theft
- Consensus violations or chain splits  
- Validator node crashes or API failures

Therefore, it correctly maps to **Medium severity** as a state consistency issue requiring manual intervention.

## Likelihood Explanation

**Likelihood: Medium to High**

**Realistic Crash Scenarios:**
1. **Hardware Failures:** Disk failures, server crashes during backup operations
2. **Cloud Storage Network Issues:** Connection drops during S3/GCS/Azure uploads
3. **Memory Exhaustion:** OOM kills during long-running backup processes
4. **Container Orchestration:** Kubernetes pod evictions during backup windows
5. **Manual Intervention:** Operator terminations during maintenance
6. **Resource Contention:** CPU/IO starvation causing process termination

**Attack Amplification:**
While primarily a reliability issue, an adversary could potentially:
- Trigger resource exhaustion attacks during backup windows
- Disrupt network connections during cloud storage operations
- Time attacks to coincide with backup schedules

**Production Reality:**
Backup operations are long-running processes (minutes to hours for large state snapshots) that interact with external storage systems, making them inherently vulnerable to various interruption scenarios.

## Recommendation

**Solution: Implement atomic backup operations using a two-phase commit pattern**

```rust
async fn write_manifest(
    &self,
    backup_handle: &BackupHandleRef,
    first_version: Version,
    last_version: Version,
    chunks: Vec<TransactionChunk>,
) -> Result<FileHandle> {
    let manifest = TransactionBackup {
        first_version,
        last_version,
        chunks,
    };
    
    // Create metadata BEFORE writing manifest
    let metadata = Metadata::new_transaction_backup(
        first_version, 
        last_version, 
        // Use a deterministic handle based on backup_handle
        format!("{}/transaction.manifest", backup_handle)
    );
    
    // Write metadata FIRST (smaller file, less likely to fail)
    self.storage
        .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
        .await?;
    
    // Then write manifest
    let (manifest_handle, mut manifest_file) = self
        .storage
        .create_for_write(backup_handle, Self::manifest_name())
        .await?;
    manifest_file
        .write_all(&serde_json::to_vec(&manifest)?)
        .await?;
    manifest_file.shutdown().await?;
    
    // Verify metadata still exists (detect race conditions)
    // If metadata is missing, cleanup and return error
    
    Ok(manifest_handle)
}
```

**Alternative: Add orphan detection and recovery**
- Implement periodic scans for manifest files without corresponding metadata
- Create recovery tools to regenerate metadata from orphaned manifests
- Add transaction logging for backup operations

**Apply to all three backup controllers:**
- `transaction/backup.rs`
- `epoch_ending/backup.rs`  
- `state_snapshot/backup.rs`

## Proof of Concept

```rust
#[tokio::test]
async fn test_backup_metadata_race_condition() {
    use crate::backup_types::transaction::backup::TransactionBackupController;
    use std::sync::Arc;
    use tokio::time::{sleep, Duration};
    
    // Setup backup controller with test storage
    let storage = Arc::new(TestStorage::new());
    let client = Arc::new(TestBackupClient::new());
    let controller = TransactionBackupController::new(
        TransactionBackupOpt {
            start_version: 0,
            num_transactions: 1000,
        },
        GlobalBackupOpt::default(),
        client,
        Arc::clone(&storage),
    );
    
    // Spawn backup operation
    let backup_handle = tokio::spawn(async move {
        controller.run().await
    });
    
    // Simulate crash after manifest write but before metadata save
    // Monitor storage for manifest write completion
    while !storage.manifest_exists("transaction_0-") {
        sleep(Duration::from_millis(10)).await;
    }
    
    // Crash the backup process immediately after manifest is written
    backup_handle.abort();
    
    // Verify orphan state
    assert!(storage.manifest_exists("transaction_0-999.manifest"));
    assert!(!storage.metadata_exists("transaction_0-999.meta"));
    
    // Attempt restore - should fail to discover the backup
    let restore_storage = Arc::new(TestStorage::from_existing(storage));
    let metadata_view = metadata::cache::sync_and_load(
        &MetadataCacheOpt::default(),
        restore_storage,
        1,
    ).await.unwrap();
    
    // Backup is invisible to restore system
    assert!(metadata_view.select_transaction_backups(0, 999).is_empty());
    
    // But manifest file exists in storage (orphaned)
    assert!(storage.list_all_files().iter().any(|f| f.contains("transaction") && f.contains("manifest")));
}
```

**Notes:**
- This vulnerability represents a violation of backup system atomicity guarantees
- All three backup types are affected by the same pattern
- The garbage collection system cannot clean up orphaned manifests
- Manual intervention would be required to identify and recover orphaned backups
- Consider implementing write-ahead logging or transactional semantics for backup operations

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L201-214)
```rust
        let (manifest_handle, mut manifest_file) = self
            .storage
            .create_for_write(backup_handle, Self::manifest_name())
            .await?;
        manifest_file
            .write_all(&serde_json::to_vec(&manifest)?)
            .await?;
        manifest_file.shutdown().await?;

        let metadata =
            Metadata::new_transaction_backup(first_version, last_version, manifest_handle.clone());
        self.storage
            .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
            .await?;
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/backup.rs (L186-205)
```rust
        let (manifest_handle, mut manifest_file) = self
            .storage
            .create_for_write(backup_handle, Self::manifest_name())
            .await?;
        manifest_file
            .write_all(&serde_json::to_vec(&manifest)?)
            .await?;
        manifest_file.shutdown().await?;

        let metadata = Metadata::new_epoch_ending_backup(
            first_epoch,
            last_epoch,
            manifest.waypoints.first().expect("No waypoints.").version(),
            manifest.waypoints.last().expect("No waypoints.").version(),
            manifest_handle.clone(),
        );

        self.storage
            .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
            .await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L473-489)
```rust
        let (manifest_handle, mut manifest_file) = self
            .storage
            .create_for_write(backup_handle, Self::manifest_name())
            .await?;
        manifest_file
            .write_all(&serde_json::to_vec(&manifest)?)
            .await?;
        manifest_file.shutdown().await?;

        let metadata = Metadata::new_state_snapshot_backup(
            self.epoch,
            self.version(),
            manifest_handle.clone(),
        );
        self.storage
            .save_metadata_line(&metadata.name(), &metadata.to_text_line()?)
            .await?;
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L114-122)
```rust
    let mut remote_file_handles = storage.list_metadata_files().await?;
    if remote_file_handles.is_empty() {
        initialize_identity(&storage).await.context(
            "\
            Backup storage appears empty and failed to put in identity metadata, \
            no point to go on. If you believe there is content in the backup, check authentication.\
            ",
        )?;
        remote_file_handles = storage.list_metadata_files().await?;
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L117-122)
```rust
        let metadata_view = metadata::cache::sync_and_load(
            &self.metadata_cache_opt,
            Arc::clone(&self.storage),
            self.global_opt.concurrent_downloads,
        )
        .await?;
```

**File:** storage/backup/backup-cli/src/coordinators/backup.rs (L419-419)
```rust
        let files = metaview.get_file_handles();
```
