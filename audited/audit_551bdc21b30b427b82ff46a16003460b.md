# Audit Report

## Title
Pruner Deadlock Due to Inconsistent min_readable_version After Database Truncation

## Summary
The state merkle pruner can enter a permanent deadlock where it never triggers pruning, leading to unbounded storage growth. This occurs when `min_readable_version` is persisted at a high value during state sync, but the database is subsequently truncated to a lower version. The pruner's activation condition becomes impossible to satisfy, causing indefinite storage accumulation.

## Finding Description

The vulnerability exists in the pruner activation logic. When state sync completes via `finalize_state_snapshot()`, it unconditionally persists `min_readable_version` to the snapshot's target version for all pruners. [1](#0-0) 

The pruner's activation condition checks whether `latest_version >= min_readable_version + prune_window`. If this condition is not satisfied, the pruner never activates. [2](#0-1) 

However, if the database undergoes truncation after `finalize_state_snapshot()` completes, the database's commit progress is rolled back but the pruner progress metadata is **not** reset. The truncation logic explicitly sets `OverallCommitProgress` back to the target version: [3](#0-2) 

The `sync_commit_progress` function truncates the databases but does not update any pruner progress keys defined in the metadata schema: [4](#0-3) 

The pruner progress keys include `StateMerklePrunerProgress`, `StateKvPrunerProgress`, `LedgerPrunerProgress`, and their shard-specific variants: [5](#0-4) 

On node restart, the pruner manager loads the persisted (high) `min_readable_version` from disk: [6](#0-5) 

During initialization, `maybe_set_pruner_target_db_version` is called with the current synced version, but this does NOT reset `min_readable_version` if it's inconsistently high—it only checks the activation condition: [7](#0-6) 

**Attack Scenario:**
1. Node syncs to version 100 normally
2. State sync initiates to catch up to version 1,000,000
3. `finalize_state_snapshot(1000000)` completes, persisting `StateMerklePrunerProgress = 1000000`
4. Node crashes or database corruption is detected
5. Truncation logic rolls back ledger to version 100, but leaves `StateMerklePrunerProgress = 1000000` unchanged
6. On restart, `get_synced_version()` returns 100, but pruner loads `min_readable_version = 1000000`
7. For all subsequent commits (101, 102, ..., 999,999), the condition `latest_version >= 1000000 + prune_window` fails
8. Pruner never executes, storage grows without bounds until disk exhaustion

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria because it causes validator node slowdowns and potential crashes. Affected validators will experience:
- Unbounded storage growth consuming all available disk space
- Node crashes when disk space is exhausted
- Network participation degradation as nodes struggle with I/O operations on bloated databases
- Potential for cascading failures if multiple validators hit this condition during coordinated state sync attempts

The bug bounty program explicitly lists "Validator Node Slowdowns" as a HIGH severity impact. While not directly causing loss of funds or consensus violations, the availability impact on validator infrastructure qualifies this as High severity.

## Likelihood Explanation

This vulnerability has **medium-to-high likelihood** of occurrence:

- State sync followed by crashes/restarts is a common operational scenario in production environments
- The database truncation mechanism is explicitly designed for crash recovery scenarios
- No validation exists on startup to detect pruner progress inconsistencies with the actual database version
- The db_debugger truncation tool is used by node operators for manual recovery, making this exploitable through normal operational procedures
- Once triggered, the condition is permanent until manual intervention (resetting pruner progress metadata) or the ledger naturally catches up to the high version
- The bug is deterministic—once the inconsistency occurs, the pruner will never activate

## Recommendation

Implement validation and reset logic during database truncation and startup:

1. **During Truncation**: Reset all pruner progress metadata keys to match the target truncation version:
   - `DbMetadataKey::StateMerklePrunerProgress`
   - `DbMetadataKey::StateKvPrunerProgress`
   - `DbMetadataKey::LedgerPrunerProgress`
   - All shard-specific progress keys

2. **During Startup**: Add validation in `new_with_dbs()` or initialization to detect and correct inconsistent pruner progress:
   ```rust
   // Pseudo-code fix
   let synced_version = ledger_db.metadata_db().get_synced_version()?;
   let pruner_min_readable = state_merkle_pruner.get_min_readable_version();
   
   if pruner_min_readable > synced_version {
       warn!("Detected inconsistent pruner progress, resetting to synced version");
       state_merkle_pruner.save_min_readable_version(synced_version)?;
   }
   ```

3. **In sync_commit_progress()**: Add explicit pruner progress reset after truncation operations.

## Proof of Concept

While a full end-to-end PoC requires setting up state sync infrastructure, the logic vulnerability can be demonstrated through the following sequence:

1. Initialize AptosDB with state sync completing at version 1,000,000
2. Call `finalize_state_snapshot(1000000)` which persists pruner progress
3. Simulate crash and call truncation to version 100
4. Restart the node (reinitialize pruner managers)
5. Observe that `get_min_readable_version()` returns 1,000,000
6. Commit transactions at versions 101, 102, etc.
7. Verify that `maybe_set_pruner_target_db_version()` never activates pruning because `101 < 1000000 + prune_window`

The core logic flaw is evident from the code structure: truncation updates `OverallCommitProgress` but never touches the pruner progress metadata, creating a permanent inconsistency.

## Notes

This vulnerability represents a critical gap in the database recovery logic where state management components (pruners) are not properly synchronized with the core database truncation operations. The issue is particularly concerning because:

1. It's deterministic and permanent once triggered
2. It affects all pruner types (state merkle, state kv, ledger)
3. The only recovery is manual intervention or waiting for the ledger to naturally catch up
4. It can affect multiple validators simultaneously if they undergo similar recovery procedures

The fix should ensure that all metadata related to database progress is atomically consistent across truncation operations.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L225-234)
```rust
            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_pruner_manager.rs (L67-72)
```rust
    fn maybe_set_pruner_target_db_version(&self, latest_version: Version) {
        let min_readable_version = self.get_min_readable_version();
        if self.is_pruner_enabled() && latest_version >= min_readable_version + self.prune_window {
            self.set_pruner_target_db_version(latest_version);
        }
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_pruner_manager.rs (L119-124)
```rust
        let min_readable_version = pruner_utils::get_state_merkle_pruner_progress(&state_merkle_db)
            .expect("Must succeed.");

        PRUNER_VERSIONS
            .with_label_values(&[S::name(), "min_readable"])
            .set(min_readable_version as i64);
```

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L130-135)
```rust
        let mut batch = SchemaBatch::new();
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        ledger_db.metadata_db().write_schemas(batch)?;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L49-72)
```rust
pub enum DbMetadataKey {
    LedgerPrunerProgress,
    StateMerklePrunerProgress,
    EpochEndingStateMerklePrunerProgress,
    StateKvPrunerProgress,
    StateSnapshotKvRestoreProgress(Version),
    LedgerCommitProgress,
    StateKvCommitProgress,
    OverallCommitProgress,
    StateKvShardCommitProgress(ShardId),
    StateMerkleCommitProgress,
    StateMerkleShardCommitProgress(ShardId),
    EventPrunerProgress,
    TransactionAccumulatorPrunerProgress,
    TransactionInfoPrunerProgress,
    TransactionPrunerProgress,
    WriteSetPrunerProgress,
    StateMerkleShardPrunerProgress(ShardId),
    EpochEndingStateMerkleShardPrunerProgress(ShardId),
    StateKvShardPrunerProgress(ShardId),
    StateMerkleShardRestoreProgress(ShardId, Version),
    TransactionAuxiliaryDataPrunerProgress,
    PersistedAuxiliaryInfoPrunerProgress,
}
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L162-181)
```rust
        if !readonly {
            if let Some(version) = myself.get_synced_version()? {
                myself
                    .ledger_pruner
                    .maybe_set_pruner_target_db_version(version);
                myself
                    .state_store
                    .state_kv_pruner
                    .maybe_set_pruner_target_db_version(version);
            }
            if let Some(version) = myself.get_latest_state_checkpoint_version()? {
                myself
                    .state_store
                    .state_merkle_pruner
                    .maybe_set_pruner_target_db_version(version);
                myself
                    .state_store
                    .epoch_snapshot_pruner
                    .maybe_set_pruner_target_db_version(version);
            }
```
