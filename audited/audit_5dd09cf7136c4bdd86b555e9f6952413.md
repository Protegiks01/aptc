# Audit Report

## Title
Out-of-Bounds Panic in DKG PVSS Proof Verification Due to Missing Witness Dimension Validation

## Summary
The `WeightedHomomorphism::new()` function and its associated `msm_terms()` method lack validation that the witness dimensions match the encryption keys array length. A malicious dealer can craft a PVSS transcript with a proof containing oversized witness dimensions, causing validator nodes to panic with an out-of-bounds array access during verification.

## Finding Description

The DKG (Distributed Key Generation) PVSS protocol uses a sigma protocol to prove knowledge of shares. The verification flow has a critical bounds checking vulnerability:

1. **Construction without validation**: The `WeightedHomomorphism::new()` function accepts `eks` (encryption keys) as a parameter but performs no validation on its length relative to expected dimensions. [1](#0-0) 

2. **Unsafe array access**: The `msm_terms()` method iterates over `input.plaintext_chunks` and directly accesses `self.eks[i]` without bounds checking. [2](#0-1) 

3. **Deserialized untrusted witness**: During verification, the proof's witness (`proof.z`) is deserialized from network data and passed to `msm_terms()` without dimension validation. [3](#0-2) 

4. **Incomplete validation**: While the verification code validates that the public statement dimensions (`self.subtrs.Cs.len()`) match `sc.get_total_num_players()`, it does NOT validate that the witness dimensions (`proof.z.chunked_plaintexts.len()`) match. [4](#0-3) 

**Attack Path**:
- A malicious dealer creates a PVSS transcript with a valid-looking public statement but crafts `sharing_proof.SoK.z.chunked_plaintexts` to have more elements than `eks.len()`
- When honest validators receive this transcript and call `verify()`, the homomorphism is constructed with the correct `eks` length
- During sigma protocol verification, `msm_terms(&proof.z)` is called, which iterates over the oversized `proof.z.chunked_plaintexts`
- When the iterator reaches `i >= eks.len()`, the access `self.eks[i]` panics with an index out of bounds error
- The validator node crashes

## Impact Explanation

This is a **HIGH severity** Denial-of-Service vulnerability according to Aptos bug bounty criteria ("Validator node slowdowns" and "API crashes"):

- **Availability Impact**: Any validator attempting to verify the malicious transcript will immediately panic and crash
- **Network Disruption**: During DKG ceremonies (validator set updates, randomness generation), a single malicious dealer can crash all honest validators attempting to verify their transcript
- **DKG Protocol Failure**: If enough validators crash during DKG, the protocol cannot complete, preventing epoch transitions and validator set updates
- **Resource Limits Invariant Violation**: The code violates the invariant that "all operations must respect computational limits" - a malformed input causes unbounded resource consumption (crash)

This does NOT reach Critical severity because:
- It does not cause loss of funds
- It does not violate consensus safety (though it impacts liveness)
- Nodes can recover by restarting (no permanent damage)
- It requires participation in DKG (limited attack surface compared to general transaction processing)

## Likelihood Explanation

**Likelihood: HIGH**

- **Attacker Requirements**: Any node participating in DKG as a dealer can trigger this vulnerability
- **Complexity**: Trivial to exploit - simply deserialize a proof, modify the witness dimensions, re-serialize
- **Detection**: The malformed transcript would propagate through gossip before being detected, maximizing impact
- **Frequency**: Occurs during every DKG ceremony if an attacker is present as a dealer
- **No Authentication Bypass Needed**: The vulnerability is in the verification path, not authentication

The only limiting factor is that DKG is not continuously running, but occurs during:
- Validator set changes
- Periodic randomness generation
- Network upgrades requiring validator reconfiguration

## Recommendation

Add dimension validation in multiple defensive layers:

**Layer 1 - Constructor Validation** (in `WeightedHomomorphism::new()`):
```rust
pub fn new(
    lagr_g1: &'a [E::G1Affine],
    xi_1: E::G1Affine,
    pp: &'a chunked_elgamal::PublicParameters<E::G1>,
    eks: &'a [E::G1Affine],
) -> Result<Self, anyhow::Error> {
    // Validate that lagr_g1 has sufficient elements for the polynomial degree
    // This depends on the secret sharing configuration
    
    Ok(Self {
        hom1: /* ... */,
        hom2: /* ... */,
    })
}
```

**Layer 2 - Witness Validation** (before calling `msm_terms()`):
```rust
// In verify() or msm_terms_for_verify()
fn msm_terms(&self, input: &Self::Domain) -> Self::CodomainShape<Self::MsmInput> {
    // Validate witness dimensions match homomorphism configuration
    if input.plaintext_chunks.len() > self.eks.len() {
        panic!("Witness plaintext_chunks length {} exceeds eks length {}", 
               input.plaintext_chunks.len(), self.eks.len());
    }
    
    // Continue with existing logic...
}
```

**Layer 3 - Explicit Transcript Validation** (in `verify()` method):
```rust
// Add to weighted_transcript.rs verify() method after line 146
if self.sharing_proof.SoK.z.chunked_plaintexts.len() != sc.get_total_num_players() {
    bail!(
        "Expected {} plaintext chunks in proof witness, but got {}",
        sc.get_total_num_players(),
        self.sharing_proof.SoK.z.chunked_plaintexts.len()
    );
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod exploit_poc {
    use super::*;
    use crate::pvss::chunky::{
        hkzg_chunked_elgamal::{HkzgWeightedElgamalWitness, WeightedHomomorphism},
        weighted_transcript::Transcript,
    };
    use aptos_crypto::weighted_config::WeightedConfigArkworks;
    use ark_bn254::Bn254;
    
    #[test]
    #[should_panic(expected = "index out of bounds")]
    fn test_oversized_witness_causes_panic() {
        // Setup: Create a valid transcript first
        let sc = WeightedConfigArkworks::<Fr>::new(2, vec![1, 1, 1]).unwrap();
        let mut rng = rand::thread_rng();
        
        // Generate valid parameters
        let pp = PublicParameters::<Bn254>::default();
        let eks: Vec<_> = (0..3).map(|_| {
            G1Affine::rand(&mut rng)
        }).collect();
        
        // Create malicious proof with oversized witness
        let mut malicious_proof = WeightedProof::<Bn254>::generate(&sc, 16, &mut rng);
        
        // ATTACK: Extend witness dimensions beyond eks.len()
        malicious_proof.z.chunked_plaintexts.push(vec![
            vec![Scalar(Fr::rand(&mut rng)); 16]
        ]);
        malicious_proof.z.chunked_plaintexts.push(vec![
            vec![Scalar(Fr::rand(&mut rng)); 16]
        ]);
        // Now witness has 5 elements but eks only has 3
        
        // Construct homomorphism (no validation)
        let lagr_g1 = vec![G1Affine::rand(&mut rng); 100];
        let hom = WeightedHomomorphism::<Bn254>::new(
            &lagr_g1,
            G1Affine::rand(&mut rng),
            &pp.pp_elgamal,
            &eks, // Only 3 elements
        );
        
        // Create fake statement
        let statement = /* construct valid-looking statement */;
        
        // Trigger the vulnerability
        // This will panic when msm_terms() tries to access eks[3]
        hom.verify(&statement, &malicious_proof, &()).expect("Should panic before this");
    }
}
```

## Notes

- The vulnerability exists in both `weighted_transcript.rs` and `weighted_transcriptv2.rs` verification paths
- The `lagr_g1` parameter mentioned in the security question is validated indirectly through the polynomial degree checks in the range proof, but `eks` has no such validation
- The sigma protocol framework is generic and assumes callers validate witness dimensions before constructing homomorphisms - this is a violation of the principle of least privilege
- This vulnerability demonstrates the danger of deserializing complex cryptographic proofs from untrusted sources without comprehensive validation

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/hkzg_chunked_elgamal.rs (L191-242)
```rust
    pub fn new(
        lagr_g1: &'a [E::G1Affine],
        xi_1: E::G1Affine,
        pp: &'a chunked_elgamal::PublicParameters<E::G1>,
        eks: &'a [E::G1Affine],
    ) -> Self {
        // Set up the HKZG homomorphism, and use a projection map to lift it to HkzgElgamalWitness
        let lifted_hkzg = LiftedHkzgWeighted::<E> {
            hom: univariate_hiding_kzg::CommitmentHomomorphism {
                msm_basis: lagr_g1,
                xi_1,
            },
            // The projection map ignores the `elgamal_randomness` component, and flattens the vector of chunked plaintexts after adding a zero
            projection: |dom: &HkzgWeightedElgamalWitness<E::ScalarField>| {
                let HkzgWeightedElgamalWitness {
                    hkzg_randomness,
                    chunked_plaintexts,
                    ..
                } = dom;
                let flattened_chunked_plaintexts: Vec<Scalar<E::ScalarField>> =
                    std::iter::once(Scalar(E::ScalarField::ZERO))
                        .chain(chunked_plaintexts.iter().flatten().flatten().cloned())
                        .collect();
                univariate_hiding_kzg::Witness::<E::ScalarField> {
                    hiding_randomness: hkzg_randomness.clone(),
                    values: flattened_chunked_plaintexts,
                }
            },
        };
        // Set up the chunked_elgamal homomorphism, and use a projection map to lift it to HkzgElgamalWitness
        let lifted_chunked_elgamal = LiftedWeightedChunkedElgamal::<E::G1> {
            hom: chunked_elgamal::WeightedHomomorphism { pp, eks },
            // The projection map simply ignores the `hkzg_randomness` component
            projection: |dom: &HkzgWeightedElgamalWitness<E::ScalarField>| {
                let HkzgWeightedElgamalWitness {
                    chunked_plaintexts,
                    elgamal_randomness,
                    ..
                } = dom;
                chunked_elgamal::WeightedWitness {
                    plaintext_chunks: chunked_plaintexts.clone(),
                    plaintext_randomness: elgamal_randomness.clone(),
                }
            },
        };

        // Combine the two lifted homomorphisms just constructed, into the required TupleHomomorphism
        Self {
            hom1: lifted_hkzg,
            hom2: lifted_chunked_elgamal,
        }
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L229-260)
```rust
    fn msm_terms(&self, input: &Self::Domain) -> Self::CodomainShape<Self::MsmInput> {
        // C_{i,j} = z_{i,j} * G_1 + r_j * ek[i]
        let Cs = input
            .plaintext_chunks
            .iter()
            .enumerate()
            .map(|(i, z_i)| {
                // here `i` is the player's id
                chunks_vec_msm_terms::<C>(self.pp, self.eks[i], z_i, &input.plaintext_randomness)
            })
            .collect();

        // R_j = r_j * H_1
        let Rs = input
            .plaintext_randomness
            .iter()
            .map(|inner_vec| {
                inner_vec
                    .iter()
                    .map(|&r_j| MsmInput {
                        bases: vec![self.pp.H],
                        scalars: vec![r_j.0],
                    })
                    .collect()
            })
            .collect();

        WeightedCodomainShape {
            chunks: Cs,
            randomness: Rs,
        }
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L103-133)
```rust
    #[allow(non_snake_case)]
    fn msm_terms_for_verify<Ct: Serialize, H>(
        &self,
        public_statement: &Self::Codomain,
        proof: &Proof<C::ScalarField, H>,
        cntxt: &Ct,
    ) -> Self::MsmInput
    where
        H: homomorphism::Trait<Domain = Self::Domain, Codomain = Self::Codomain>, // Need this because the lifetime was changed
    {
        let prover_first_message = match &proof.first_proof_item {
            FirstProofItem::Commitment(A) => A,
            FirstProofItem::Challenge(_) => {
                panic!("Missing implementation - expected commitment, not challenge")
            },
        };

        let number_of_beta_powers = public_statement.clone().into_iter().count(); // TODO: maybe pass the into_iter version in merge_msm_terms?

        let (c, powers_of_beta) = self.compute_verifier_challenges(public_statement, prover_first_message, cntxt, number_of_beta_powers);

        let msm_terms_for_prover_response = self.msm_terms(&proof.z);

        Self::merge_msm_terms(
            msm_terms_for_prover_response.into_iter().collect(),
            prover_first_message,
            public_statement,
            &powers_of_beta,
            c,
        )
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L133-190)
```rust
        if eks.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} encryption keys, but got {}",
                sc.get_total_num_players(),
                eks.len()
            );
        }
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }

        // Initialize the **identical** PVSS SoK context
        let sok_cntxt = (
            &spks[self.dealer.id],
            sid.clone(),
            self.dealer.id,
            DST.to_vec(),
        ); // As above, this is a bit hacky... though we have access to `self` now

        {
            // Verify the PoK
            let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
            let lagr_g1: &[E::G1Affine] = match &pp.pk_range_proof.ck_S.msm_basis {
                SrsBasis::Lagrange { lagr: lagr_g1 } => lagr_g1,
                SrsBasis::PowersOfTau { .. } => {
                    bail!("Expected a Lagrange basis, received powers of tau basis instead")
                },
            };
            let hom = hkzg_chunked_elgamal::WeightedHomomorphism::<E>::new(
                lagr_g1,
                pp.pk_range_proof.ck_S.xi_1,
                &pp.pp_elgamal,
                &eks_inner,
            );
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    self.sharing_proof.range_proof_commitment.clone(),
                    chunked_elgamal::WeightedCodomainShape {
                        chunks: self.subtrs.Cs.clone(),
                        randomness: self.subtrs.Rs.clone(),
                    },
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```
