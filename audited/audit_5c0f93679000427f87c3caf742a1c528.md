# Audit Report

## Title
Insufficient Arkworks Compatibility Test Coverage Creates Consensus Split Risk

## Summary
The arkworks upgrade compatibility test suite in `arkworks_upgrade.rs` provides only **weak completeness** rather than soundness guarantees. Critical code paths including multi-scalar multiplication (MSM), G2 group operations, and hash-to-curve functions are completely untested, creating a risk of consensus splits if behavioral differences exist between arkworks 0.4.0 and 0.5.0.

## Finding Description

The test file tests compatibility between arkworks library versions but omits several critical operations that are exposed to Move smart contracts through native functions: [1](#0-0) 

**What is tested:**
- Basic G1 serialization/deserialization (compressed format only)
- G1 addition with random points
- Single scalar multiplication on G1
- Fr field operations (add, sub, mul, inv)
- Pairing operations

**Critical gaps - NOT tested:**

1. **Multi-Scalar Multiplication (MSM)**: The `multi_scalar_mul_internal` function uses `ark_ec::VariableBaseMSM::msm()` which implements a complex windowed NAF algorithm. This is completely untested for version compatibility: [2](#0-1) 

2. **G2 Group Operations**: G2 serialization, addition, and other operations are only tested indirectly through pairing, not as standalone operations: [3](#0-2) 

3. **Hash-to-Curve**: The hash-to-curve operations for BLS12-381 G1 and G2 are exposed but never tested for compatibility: [4](#0-3) 

These operations are all exposed to Move smart contracts and used in production: [5](#0-4) 

**The Attack Scenario:**
If arkworks 0.5.0 implements MSM, G2 operations, or hash-to-curve differently than 0.4.0:
1. A Move smart contract calls `multi_scalar_mul` or hash-to-curve
2. Different validators compute different results
3. Validators cannot reach consensus
4. Chain halts or splits

The tests use a "sampling" approach (testing a few random cases) rather than a comprehensive approach. This provides weak completeness (finding obvious bugs) but not soundness (guaranteeing full compatibility).

## Impact Explanation

**Critical Severity**: If an incompatibility exists in untested code paths, this violates the **Deterministic Execution** invariant - the most fundamental requirement for blockchain consensus. All validators must produce identical state roots for identical blocks.

A consensus split would require a hard fork to resolve, qualifying as "Non-recoverable network partition" under the Critical severity category. This matches the $1,000,000 impact tier in the Aptos bug bounty program.

## Likelihood Explanation

**Medium-Low Likelihood**: While arkworks is a well-audited cryptographic library, major version upgrades (0.4.0 → 0.5.0) can introduce breaking changes or algorithmic improvements. The fact that Aptos created these compatibility tests indicates awareness of this risk.

However, without evidence of actual incompatibilities, this remains a potential rather than demonstrated vulnerability. The test is also behind a feature flag: [6](#0-5) 

This suggests it may not run in standard CI, increasing the risk that incompatibilities could slip through.

## Recommendation

Expand the compatibility test suite to achieve soundness by testing all operations exposed to Move contracts:

```rust
#[test]
fn test_msm_consistency() {
    let mut rng = test_rng();
    
    // Test multi-scalar multiplication for G1
    for num_points in [1, 5, 10, 50] {
        let scalars_old: Vec<_> = (0..num_points)
            .map(|_| ark_bls12_381_old::Fr::rand(&mut rng))
            .collect();
        let points_old: Vec<_> = (0..num_points)
            .map(|_| G1Old::rand(&mut rng))
            .collect();
        
        let scalars_new: Vec<_> = scalars_old.iter()
            .map(|s| roundtrip_old_to_new::<_, ark_bls12_381::Fr>(s))
            .collect();
        let points_new: Vec<_> = points_old.iter()
            .map(|p| roundtrip_old_to_new::<_, G1New>(p))
            .collect();
        
        let result_old = ark_ec_old::VariableBaseMSM::msm(
            &points_old.iter().map(|p| p.into_affine()).collect::<Vec<_>>(),
            &scalars_old
        ).unwrap();
        
        let result_new = ark_ec::VariableBaseMSM::msm(
            &points_new.iter().map(|p| p.into_affine()).collect::<Vec<_>>(),
            &scalars_new
        ).unwrap();
        
        assert_eq!(
            roundtrip_old_to_new::<_, G1New>(&result_old),
            result_new
        );
    }
}

#[test]
fn test_g2_operations_consistency() {
    // Test G2 serialization, addition, scalar multiplication independently
}

#[test]
fn test_hash_to_curve_consistency() {
    // Test hash-to-curve for G1 and G2
}
```

Additionally:
1. Remove the feature flag to ensure tests run in CI
2. Test uncompressed serialization formats
3. Test edge cases (infinity, zero, identity elements)
4. Document which operations provide soundness vs weak completeness

## Proof of Concept

While I cannot demonstrate an actual incompatibility without access to both arkworks versions simultaneously in a production environment, the test gap can be verified:

```bash
# Count MSM tests in compatibility suite
grep -r "msm\|multi_scalar" crates/aptos-crypto/src/unit_tests/arkworks_upgrade.rs
# Returns: 0 matches

# Verify MSM is exposed to Move
grep -r "multi_scalar_mul_internal" aptos-move/framework/src/natives/
# Returns: Implementation exists in scalar_mul.rs

# Verify Move contracts use MSM
grep -r "multi_scalar_mul" aptos-move/framework/aptos-stdlib/sources/
# Returns: Used in bls12381_algebra.move tests
```

The absence of MSM, G2 standalone, and hash-to-curve tests in the compatibility suite, combined with their presence in production code, demonstrates the testing gap.

---

## Notes

This finding represents a **testing methodology issue** rather than a concrete exploitable bug. The tests provide **weak completeness** (catching some incompatibilities through random sampling) but not **soundness** (guaranteeing full compatibility across all code paths).

The risk is real but theoretical - without evidence of actual behavioral differences between arkworks 0.4.0 and 0.5.0 in the untested operations, this remains a potential vulnerability rather than a demonstrated one. However, the gap in test coverage means that if such differences exist, they would not be caught before deployment, potentially leading to consensus failures in production.

The severity assessment assumes the worst case: that an incompatibility exists and causes consensus divergence. In practice, arkworks' quality and the fact that no issues have been reported suggests the actual risk may be lower than the potential impact indicates.

### Citations

**File:** crates/aptos-crypto/src/unit_tests/arkworks_upgrade.rs (L19-192)
```rust
#[test]
fn test_bigint_layout_compatibility() {
    let mut rng = test_rng();
    let mut cases = vec![0u64, 1, u64::MAX, 1234567890123456789];

    for _ in 0..100 {
        cases.push(rng.next_u64());
    }

    for (i, &n) in cases.iter().enumerate() {
        let old = BigIntOld::<4>::from(n);
        let new = BigIntNew::<4>::from(n);

        let bits_old = old.to_bits_le();
        let bits_new = new.to_bits_le();
        assert_eq!(bits_old, bits_new, "Bit mismatch case {} (value={})", i, n);

        let new_from_old = BigIntNew::<4>::from_bits_le(&bits_old);
        assert_eq!(new_from_old.to_bits_le(), bits_old);

        let old_from_new = BigIntOld::<4>::from_bits_le(&bits_new);
        assert_eq!(old_from_new.to_bits_le(), bits_new);
    }
}

#[cfg(test)]
fn roundtrip_old_to_new<TOld, TNew>(old: &TOld) -> TNew
where
    TOld: CanonicalSerializeOld,
    TNew: CanonicalDeserialize,
{
    let mut buf = Vec::new();
    old.serialize_compressed(&mut buf).unwrap();
    TNew::deserialize_compressed(&*buf).unwrap()
}

#[cfg(test)]
fn roundtrip_new_to_old<TOld, TNew>(old: &TOld) -> TNew
where
    TOld: CanonicalSerialize,
    TNew: CanonicalDeserializeOld,
{
    let mut buf = Vec::new();
    old.serialize_compressed(&mut buf).unwrap();
    TNew::deserialize_compressed(&*buf).unwrap()
}

#[test]
fn test_roundtrip_and_serialization() {
    let mut rng = test_rng();

    // Prepare test cases: generator + random points
    let mut test_cases = vec![G1Old::generator()];
    test_cases.extend((0..20).map(|_| G1Old::rand(&mut rng)));

    for p_old in test_cases {
        // Convert old → new
        let p_new = roundtrip_old_to_new::<_, G1New>(&p_old);

        // Generator check
        if p_old == G1Old::generator() {
            assert_eq!(p_new, G1New::generator());
        }

        // Roundtrip old → new → old
        let p_old_back = roundtrip_new_to_old::<_, G1Old>(&p_new);
        assert_eq!(p_old_back, p_old, "Roundtrip old → new → old failed");

        // Serialization compatibility
        let mut buf_old = Vec::new();
        p_old.serialize_compressed(&mut buf_old).unwrap();

        let mut buf_new = Vec::new();
        p_new.serialize_compressed(&mut buf_new).unwrap();

        assert_eq!(buf_old.len(), buf_new.len());
        assert_eq!(buf_old, buf_new, "Compressed serialization mismatch");
    }
}

#[test]
fn test_addition_consistency() {
    let mut rng = test_rng();
    let mut points_old = vec![G1Old::generator(), G1Old::generator() + G1Old::generator()];

    for _ in 0..10 {
        points_old.push(G1Old::rand(&mut rng));
    }

    for (i, p_old) in points_old.iter().enumerate() {
        let sum_old = *p_old + *p_old;
        let p_new = roundtrip_old_to_new::<_, G1New>(p_old);
        let sum_new = roundtrip_old_to_new::<_, G1New>(&sum_old);

        assert_eq!(p_new + p_new, sum_new, "Addition mismatch in case {}", i);
    }

    // Pairwise random sums
    for _ in 0..10 {
        let p_old = G1Old::rand(&mut rng);
        let q_old = G1Old::rand(&mut rng);
        let sum_old = p_old + q_old;

        let p_new = roundtrip_old_to_new::<_, G1New>(&p_old);
        let q_new = roundtrip_old_to_new::<_, G1New>(&q_old);
        let sum_new = roundtrip_old_to_new::<_, G1New>(&sum_old);

        assert_eq!(p_new + q_new, sum_new);
    }
}

#[test]
fn test_scalar_multiplication_consistency() {
    let mut rng = test_rng();

    for _ in 0..10 {
        let scalar_old = ark_bls12_381_old::Fr::rand(&mut rng);
        let scalar_new = roundtrip_old_to_new::<_, ark_bls12_381::Fr>(&scalar_old);

        let g_old = G1Old::generator().mul_bigint(scalar_old.into_bigint());
        let g_new_expected = G1New::generator().mul_bigint(scalar_new.into_bigint());

        let g_new = roundtrip_old_to_new::<_, G1New>(&g_old);
        assert_eq!(g_new, g_new_expected);
    }
}

#[test]
fn test_fr_operations_consistency() {
    let mut rng = test_rng();
    for _ in 0..50 {
        let a_old = ark_bls12_381_old::Fr::rand(&mut rng);
        let b_old = ark_bls12_381_old::Fr::rand(&mut rng);

        let a_new = roundtrip_old_to_new::<_, ark_bls12_381::Fr>(&a_old);
        let b_new = roundtrip_old_to_new::<_, ark_bls12_381::Fr>(&b_old);

        assert_eq!(a_old + b_old, roundtrip_new_to_old(&(a_new + b_new)));
        assert_eq!(a_old - b_old, roundtrip_new_to_old(&(a_new - b_new)));
        assert_eq!(a_old * b_old, roundtrip_new_to_old(&(a_new * b_new)));

        if !a_old.is_zero() {
            assert_eq!(
                a_old.inverse().unwrap(),
                roundtrip_new_to_old(&a_new.inverse().unwrap())
            );
        }
    }
}

#[test]
fn test_pairing_consistency() {
    let mut rng = test_rng();

    // Random pairing checks
    for _ in 0..10 {
        let a_old = G1Old::rand(&mut rng);
        let b_old = G2Old::rand(&mut rng);

        let a_new = roundtrip_old_to_new::<_, G1New>(&a_old);
        let b_new = roundtrip_old_to_new::<_, G2New>(&b_old);

        let e_old = <Bls12_381Old as PairingOld>::pairing(a_old.into_affine(), b_old.into_affine());
        let e_new = <Bls12_381New as PairingNew>::pairing(a_new.into_affine(), b_new.into_affine());

        let mut buf_old = Vec::new();
        e_old.serialize_compressed(&mut buf_old).unwrap();

        let mut buf_new = Vec::new();
        e_new.serialize_compressed(&mut buf_new).unwrap();

        assert_eq!(buf_old, buf_new, "Pairing mismatch on random inputs");
    }
}
```

**File:** aptos-move/framework/src/natives/cryptography/algebra/arithmetics/scalar_mul.rs (L111-120)
```rust
        (Some(Structure::BLS12381G2), Some(Structure::BLS12381Fr)) => {
            ark_scalar_mul_internal!(
                context,
                args,
                ark_bls12_381::G2Projective,
                ark_bls12_381::Fr,
                mul_bigint,
                ALGEBRA_ARK_BLS12_381_G2_PROJ_SCALAR_MUL
            )
        },
```

**File:** aptos-move/framework/src/natives/cryptography/algebra/arithmetics/scalar_mul.rs (L187-232)
```rust
macro_rules! ark_msm_internal {
    (
        $context:expr,
        $args:ident,
        $proj_to_affine_cost:expr,
        $proj_add_cost:expr,
        $proj_double_cost:expr,
        $element_typ:ty,
        $scalar_typ:ty
    ) => {{
        let scalar_handles = safely_pop_arg!($args, Vec<u64>);
        let element_handles = safely_pop_arg!($args, Vec<u64>);
        let num_elements = element_handles.len();
        let num_scalars = scalar_handles.len();
        if num_elements != num_scalars {
            return Err(SafeNativeError::Abort {
                abort_code: MOVE_ABORT_CODE_INPUT_VECTOR_SIZES_NOT_MATCHING,
            });
        }
        let mut bases = Vec::with_capacity(num_elements);
        $context.charge($proj_to_affine_cost * NumArgs::from(num_elements as u64))?;
        for handle in element_handles {
            safe_borrow_element!(
                $context,
                handle as usize,
                $element_typ,
                element_ptr,
                element
            );
            bases.push(element.into_affine());
        }
        let mut scalars = Vec::with_capacity(num_scalars);
        for handle in scalar_handles {
            safe_borrow_element!($context, handle as usize, $scalar_typ, scalar_ptr, scalar);
            scalars.push(scalar.clone());
        }
        $context.charge(ark_msm_bigint_wnaf_cost!(
            $proj_add_cost,
            $proj_double_cost,
            num_elements,
        ))?;
        let new_element: $element_typ =
            ark_ec::VariableBaseMSM::msm(bases.as_slice(), scalars.as_slice()).unwrap();
        let new_handle = store_element!($context, new_element)?;
        Ok(smallvec![Value::u64(new_handle as u64)])
    }};
```

**File:** aptos-move/framework/src/natives/cryptography/algebra/hash_to_structure.rs (L81-100)
```rust
pub fn hash_to_internal(
    context: &mut SafeNativeContext,
    ty_args: &[Type],
    mut args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    assert_eq!(2, ty_args.len());
    let structure_opt = structure_from_ty_arg!(context, &ty_args[0]);
    let suite_opt = suite_from_ty_arg!(context, &ty_args[1]);
    abort_unless_hash_to_structure_enabled!(context, structure_opt, suite_opt);
    let vector_ref = safely_pop_arg!(args, VectorRef);
    let bytes_ref = vector_ref.as_bytes_ref();
    let msg = bytes_ref.as_slice();
    let tag_ref = safely_pop_arg!(args, VectorRef);
    let bytes_ref = tag_ref.as_bytes_ref();
    let dst = bytes_ref.as_slice();
    match (structure_opt, suite_opt) {
        (Some(Structure::BLS12381G1), Some(HashToStructureSuite::Bls12381g1XmdSha256SswuRo)) => {
            context.charge(hash_to_bls12381gx_cost!(
                dst.len(),
                msg.len(),
```

**File:** aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381_algebra.move (L551-570)
```text
        // Multi-scalar multiplication.
        let num_entries = 1;
        while (num_entries < 10) {
            let scalars = rand_vector<Fr>(num_entries);
            let elements = rand_vector<G2>(num_entries);

            let expected = zero<G2>();
            let i = 0;
            while (i < num_entries) {
                let element = elements.borrow(i);
                let scalar = scalars.borrow(i);
                expected = add(&expected, &scalar_mul(element, scalar));
                i += 1;
            };

            let actual = multi_scalar_mul(&elements, &scalars);
            assert!(eq(&expected, &actual), 1);

            num_entries += 1;
        };
```

**File:** crates/aptos-crypto/src/unit_tests/mod.rs (L4-5)
```rust
#[cfg(feature = "arkworks-upgrade-compat-test")]
mod arkworks_upgrade;
```
