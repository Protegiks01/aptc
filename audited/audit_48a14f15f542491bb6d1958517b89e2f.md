# Audit Report

## Title
Memory Exhaustion via Unbounded File Reads in Indexer GRPC Local File Store

## Summary
The `get_raw_file()` function in the local file store operator reads entire transaction files into memory without size validation, allowing files up to several gigabytes to cause out-of-memory crashes of the indexer service.

## Finding Description

The vulnerability exists in the `LocalFileStoreOperator::get_raw_file()` implementation, which uses `tokio::fs::read()` to load entire files into memory without any size checks: [1](#0-0) 

This function is called by the data service when serving transaction requests to clients: [2](#0-1) 

Each transaction file contains exactly 1,000 transactions: [3](#0-2) 

The maximum size per transaction in the stored protobuf format can be extremely large due to:

1. **Raw transaction data**: Up to 1 MB for governance transactions [4](#0-3) 

2. **Events**: Up to 10 MB per transaction [5](#0-4) 

3. **State changes**: Up to 10 MB per transaction [6](#0-5) 

These limits are enforced during transaction execution: [7](#0-6) 

**Attack Vector:**

An attacker can create transactions that maximize their size by:
1. Using maximum transaction payload (1 MB for governance transactions, 64 KB for regular)
2. Generating maximum events (10 MB worth)
3. Generating maximum state changes (10 MB worth)

With 1,000 such transactions per file, the theoretical maximum is **~21 GB per file** (uncompressed). Even with LZ4 compression, files can reach **several gigabytes**, easily exceeding typical server memory limits and causing OOM crashes.

The data service directly calls this function when serving client requests: [8](#0-7) 

## Impact Explanation

This is **HIGH severity** per Aptos bug bounty criteria: "API crashes" causing indexer service unavailability.

When triggered, this vulnerability causes:
- **Complete indexer service crash** due to out-of-memory conditions
- **Denial of service** for all users querying blockchain data through the indexer
- **Service disruption** requiring manual intervention to restart

The indexer-grpc service is critical infrastructure that provides transaction data to:
- Block explorers
- Analytics platforms  
- Dapp backends
- Monitoring systems

Its unavailability severely impacts the Aptos ecosystem's operational capabilities.

## Likelihood Explanation

**HIGH likelihood** - This can be triggered in two ways:

1. **On-chain attack** (More realistic): An attacker with sufficient funds can create expensive transactions that legitimately maximize events and state changes. While costly (due to gas fees), this is economically feasible for a determined attacker and results in organically large files that crash the indexer during normal operation.

2. **Filesystem attack** (Less common): If an attacker compromises the indexer server's filesystem access, they can manually place arbitrarily large files that trigger OOM when accessed.

The vulnerability is triggered during normal indexer operation when serving client requests, requiring no special access or timing.

## Recommendation

Implement file size validation before reading into memory. Add a maximum file size check and use streaming reads for large files:

```rust
async fn get_raw_file(&self, version: u64) -> anyhow::Result<Vec<u8>> {
    let file_entry_key = FileEntry::build_key(version, self.storage_format).to_string();
    let file_path = self.path.join(file_entry_key);
    
    // Check file size before reading
    const MAX_FILE_SIZE: u64 = 100 * 1024 * 1024; // 100 MB limit
    
    match tokio::fs::metadata(&file_path).await {
        Ok(metadata) => {
            let file_size = metadata.len();
            if file_size > MAX_FILE_SIZE {
                anyhow::bail!(
                    "[Indexer File] File size {} exceeds maximum allowed size {}",
                    file_size,
                    MAX_FILE_SIZE
                );
            }
        },
        Err(err) if err.kind() == std::io::ErrorKind::NotFound => {
            anyhow::bail!("[Indexer File] Transactions file not found. Gap might happen between cache and file store. {}", err)
        },
        Err(err) => {
            anyhow::bail!("[Indexer File] Error checking file metadata: {}", err);
        }
    }
    
    match tokio::fs::read(file_path).await {
        Ok(file) => Ok(file),
        Err(err) => {
            anyhow::bail!("[Indexer File] Error reading transaction file: {}", err);
        }
    }
}
```

Additionally, consider implementing:
- Streaming decompression for compressed files
- Memory pooling for file reads
- Circuit breakers to detect and handle OOM conditions gracefully
- Monitoring alerts for unusually large transaction files

## Proof of Concept

```rust
// PoC: Create a large file and trigger OOM
use tokio::fs;
use std::path::PathBuf;

#[tokio::test]
async fn test_oom_large_file() {
    // Setup: Create a test directory
    let test_dir = PathBuf::from("/tmp/indexer_test");
    fs::create_dir_all(&test_dir).await.unwrap();
    
    // Create a maliciously large file (e.g., 5GB)
    let large_file_path = test_dir.join("files/1000.json");
    fs::create_dir_all(large_file_path.parent().unwrap()).await.unwrap();
    
    // Write 5GB of data
    let chunk = vec![0u8; 10 * 1024 * 1024]; // 10MB chunks
    let mut file = fs::File::create(&large_file_path).await.unwrap();
    for _ in 0..500 {
        use tokio::io::AsyncWriteExt;
        file.write_all(&chunk).await.unwrap();
    }
    
    // Trigger the vulnerability
    let operator = LocalFileStoreOperator::new(test_dir, false);
    
    // This will attempt to read 5GB into memory and likely OOM
    let result = operator.get_raw_file(1000).await;
    
    // On systems with insufficient memory, this will crash
    // before reaching this assertion
    assert!(result.is_ok() || result.is_err());
}
```

**Notes**

The vulnerability affects the indexer-grpc service, which is separate from the consensus layer but critical for ecosystem functionality. While the indexer itself is not part of consensus validation, its unavailability significantly impacts user experience and operational capabilities. The issue arises from the lack of defensive programming around file size limits, violating the principle that "all operations must respect resource limits."

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/local.rs (L58-74)
```rust
    async fn get_raw_file(&self, version: u64) -> anyhow::Result<Vec<u8>> {
        let file_entry_key = FileEntry::build_key(version, self.storage_format).to_string();
        let file_path = self.path.join(file_entry_key);
        match tokio::fs::read(file_path).await {
            Ok(file) => Ok(file),
            Err(err) => {
                if err.kind() == std::io::ErrorKind::NotFound {
                    anyhow::bail!("[Indexer File] Transactions file not found. Gap might happen between cache and file store. {}", err)
                } else {
                    anyhow::bail!(
                        "[Indexer File] Error happens when transaction file. {}",
                        err
                    );
                }
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/mod.rs (L59-86)
```rust
    async fn get_transactions_with_durations(
        &self,
        version: u64,
        retries: u8,
    ) -> Result<(Vec<Transaction>, f64, f64)> {
        let io_start_time = std::time::Instant::now();
        let bytes = self.get_raw_file_with_retries(version, retries).await?;
        let io_duration = io_start_time.elapsed().as_secs_f64();
        let decoding_start_time = std::time::Instant::now();
        let storage_format = self.storage_format();

        let transactions_in_storage = tokio::task::spawn_blocking(move || {
            FileEntry::new(bytes, storage_format).into_transactions_in_storage()
        })
        .await
        .context("Converting storage bytes to FileEntry transactions thread panicked")?;

        let decoding_duration = decoding_start_time.elapsed().as_secs_f64();
        Ok((
            transactions_in_storage
                .transactions
                .into_iter()
                .skip((version % FILE_ENTRY_TRANSACTION_COUNT) as usize)
                .collect(),
            io_duration,
            decoding_duration,
        ))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L12-12)
```rust
pub const FILE_ENTRY_TRANSACTION_COUNT: u64 = 1000;
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L73-81)
```rust
            max_transaction_size_in_bytes: NumBytes,
            "max_transaction_size_in_bytes",
            64 * 1024
        ],
        [
            max_transaction_size_in_bytes_gov: NumBytes,
            { RELEASE_V1_13.. => "max_transaction_size_in_bytes.gov" },
            1024 * 1024
        ],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L159-162)
```rust
            max_bytes_all_write_ops_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_write_ops_per_transaction" },
            10 << 20, // all write ops from a single transaction are 10MB max
        ],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L169-172)
```rust
            max_bytes_all_events_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_events_per_transaction"},
            10 << 20, // all events from a single transaction are 10MB max
        ],
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L86-128)
```rust
    pub fn check_change_set(&self, change_set: &impl ChangeSetInterface) -> Result<(), VMStatus> {
        let storage_write_limit_reached = |maybe_message: Option<&str>| {
            let mut err = PartialVMError::new(StatusCode::STORAGE_WRITE_LIMIT_REACHED);
            if let Some(message) = maybe_message {
                err = err.with_message(message.to_string())
            }
            Err(err.finish(Location::Undefined).into_vm_status())
        };

        if self.max_write_ops_per_transaction != 0
            && change_set.num_write_ops() as u64 > self.max_write_ops_per_transaction
        {
            return storage_write_limit_reached(Some("Too many write ops."));
        }

        let mut write_set_size = 0;
        for (key, op_size) in change_set.write_set_size_iter() {
            if let Some(len) = op_size.write_len() {
                let write_op_size = len + (key.size() as u64);
                if write_op_size > self.max_bytes_per_write_op {
                    return storage_write_limit_reached(None);
                }
                write_set_size += write_op_size;
            }
            if write_set_size > self.max_bytes_all_write_ops_per_transaction {
                return storage_write_limit_reached(None);
            }
        }

        let mut total_event_size = 0;
        for event in change_set.events_iter() {
            let size = event.event_data().len() as u64;
            if size > self.max_bytes_per_event {
                return storage_write_limit_reached(None);
            }
            total_event_size += size;
            if total_event_size > self.max_bytes_all_events_per_transaction {
                return storage_write_limit_reached(None);
            }
        }

        Ok(())
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L779-787)
```rust
async fn data_fetch_from_filestore(
    starting_version: u64,
    file_store_operator: Arc<Box<dyn FileStoreOperator>>,
    request_metadata: Arc<IndexerGrpcRequestMetadata>,
) -> anyhow::Result<Vec<Transaction>> {
    // Data is evicted from the cache. Fetch from file store.
    let (transactions, io_duration, decoding_duration) = file_store_operator
        .get_transactions_with_durations(starting_version, NUM_DATA_FETCH_RETRIES)
        .await?;
```
