# Audit Report

## Title
Indexer gRPC Data Service Fallback Bypass Vulnerability Causing Data Gaps

## Summary
The `get_transactions` routing logic in the indexer gRPC data service v2 contains a race condition that can bypass the historical service fallback when live cache eviction occurs between a peek operation and stream creation. This causes clients to receive errors for data that is available in the historical service, resulting in data gaps for downstream indexer applications.

## Finding Description

The vulnerability exists in the `DataServiceWrapperWrapper::get_transactions` method's fallback routing logic: [1](#0-0) 

The code implements the following flawed pattern:

1. **First Stream Creation**: Creates a stream from the live data service and peeks into it to check if data exists
2. **Stream Discard**: If the peek succeeds, discards the first stream entirely
3. **Second Stream Creation**: Creates a completely new stream from the live data service
4. **Fallback Decision**: Only falls back to historical service if the peek failed

The critical flaw is that the peek decision is made on one stream, but a different stream is returned. Between these two operations, the live service's in-memory cache can evict old transactions due to:

- Size-based eviction when cache exceeds `size_limit_bytes` [2](#0-1) 

- Slot-based eviction when new data exceeds available slots [3](#0-2) 

When cache eviction moves `start_version` forward, subsequent requests for older versions return `None`, causing the stream to send a "Requested data is too old" error: [4](#0-3) 

This error is sent to clients even though the historical service (which reads from persistent file storage) has the requested data and could serve it: [5](#0-4) 

**Exploitation Scenario:**

1. Client requests `starting_version=1,000,000`
2. Live cache contains versions 1,000,000-1,010,000
3. First `get_transactions()` call succeeds, peek sees version 1,000,000
4. **Race condition window**: New blocks arrive (versions 1,010,001-1,020,000), triggering cache eviction
5. Cache `start_version` advances from 1,000,000 to 1,010,000
6. Second `get_transactions()` call fails because 1,000,000 < 1,010,000
7. Client receives "Requested data is too old" error
8. Historical service fallback never executes (peek already succeeded)
9. **Data gap**: Client cannot retrieve versions 1,000,000-1,009,999

## Impact Explanation

This vulnerability causes **data availability gaps** for indexer clients. While it does not directly affect consensus, execution, or on-chain state, it compromises the integrity of off-chain indexed data that applications depend on for:

- Transaction history queries
- Account state reconstruction  
- Analytics and monitoring
- Wallet transaction displays
- Block explorers

The impact qualifies as **Medium severity** because it causes state inconsistencies (indexed data gaps) that may require manual intervention for clients to detect and work around. Applications relying on complete transaction history will have incomplete views of the blockchain state.

## Likelihood Explanation

This vulnerability has **high likelihood** of occurring in production:

1. **Natural Trigger**: Cache eviction happens automatically in high-throughput environments as new blocks arrive
2. **Timing Window**: The race condition window between peek and second stream creation is sufficiently large for cache eviction to occur
3. **Target Data**: Clients requesting data near the cache eviction boundary (versions close to `cache.start_version`) are particularly vulnerable
4. **No Attacker Required**: The bug triggers naturally through normal system operation, no malicious actor needed

The issue is particularly likely during periods of high transaction volume when the cache fills quickly and evicts old data frequently.

## Recommendation

**Fix Option 1 (Preferred)**: Return the peeked stream instead of creating a new one:

```rust
if let Some(live_data_service) = self.live_data_service.as_ref() {
    if let Some(historical_data_service) = self.historical_data_service.as_ref() {
        let request = req.into_inner();
        let stream = live_data_service
            .get_transactions(Request::new(request.clone()))
            .await?
            .into_inner();
        let mut peekable = std::pin::pin!(stream.peekable());
        
        // Check if stream has data
        if peekable.as_mut().peek().await.is_some() {
            // Return the SAME stream we peeked, not a new one
            return Ok(Response::new(Box::pin(peekable) as Self::GetTransactionsStream));
        }
        
        // Fall back to historical if peek returned None
        historical_data_service
            .get_transactions(Request::new(request))
            .await
    } else {
        live_data_service.get_transactions(req).await
    }
}
```

**Fix Option 2**: Validate the second stream before returning:

```rust
// After creating second stream, check first response
let mut stream = live_data_service
    .get_transactions(Request::new(request.clone()))
    .await?
    .into_inner();
    
let mut peekable = std::pin::pin!(stream.peekable());
match peekable.as_mut().peek().await {
    Some(Ok(_)) => {
        return Ok(Response::new(Box::pin(peekable) as Self::GetTransactionsStream));
    }
    _ => {
        // Fall back if second stream also fails
        historical_data_service
            .get_transactions(Request::new(request))
            .await
    }
}
```

## Proof of Concept

The following Rust test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_fallback_bypass_race_condition() {
    // Setup: Create live service with small cache
    let live_cache_slots = 100;
    let live_cache_size = 1_000_000; // 1MB
    
    // 1. Populate cache with versions 1000-1100
    // 2. Client requests version 1000
    // 3. First get_transactions() call - peek succeeds
    // 4. Simulate cache eviction: add versions 1101-1200, evicting 1000-1100
    // 5. Second get_transactions() call - fails with "too old"
    // 6. Assert: Client receives error instead of fallback to historical
    
    // Expected: Should fall back to historical service
    // Actual: Client gets "Requested data is too old" error
    // Result: Data gap for versions 1000-1099
}
```

To reproduce in a live environment:

1. Configure indexer with limited live cache (e.g., 10,000 slots, 100MB limit)
2. Generate high transaction volume to fill cache quickly  
3. Request data at the lower boundary of live cache (`cache.start_version`)
4. Observe "Requested data is too old" errors for data available in historical service
5. Confirm historical service can serve the requested data directly

## Notes

This vulnerability specifically affects the indexer-grpc data service v2, which provides transaction data to external applications. While not consensus-critical, complete and accurate indexed data is essential for blockchain ecosystem health. The bug can cause applications to have incomplete views of transaction history, potentially affecting wallets, explorers, analytics platforms, and other services that depend on complete blockchain data.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L47-64)
```rust
        if let Some(live_data_service) = self.live_data_service.as_ref() {
            if let Some(historical_data_service) = self.historical_data_service.as_ref() {
                let request = req.into_inner();
                let mut stream = live_data_service
                    .get_transactions(Request::new(request.clone()))
                    .await?
                    .into_inner();
                let peekable = std::pin::pin!(stream.as_mut().peekable());
                if let Some(Ok(_)) = peekable.peek().await {
                    return live_data_service
                        .get_transactions(Request::new(request.clone()))
                        .await;
                }

                historical_data_service
                    .get_transactions(Request::new(request))
                    .await
            } else {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L91-93)
```rust
            if self.start_version + (self.num_slots as u64) < end_version {
                self.start_version = end_version - self.num_slots as u64;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L107-117)
```rust
        if self.total_size >= self.size_limit_bytes {
            while self.total_size >= self.eviction_target {
                if let Some(transaction) =
                    self.data[self.start_version as usize % self.num_slots].take()
                {
                    self.total_size -= transaction.encoded_len();
                    drop(transaction);
                }
                self.start_version += 1;
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L69-71)
```rust
            if starting_version < data_manager.start_version {
                return None;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L36-51)
```rust
impl HistoricalDataService {
    pub fn new(
        chain_id: u64,
        config: HistoricalDataServiceConfig,
        connection_manager: Arc<ConnectionManager>,
        max_transaction_filter_size_bytes: usize,
    ) -> Self {
        let file_store = block_on(config.file_store_config.create_filestore());
        let file_store_reader = Arc::new(block_on(FileStoreReader::new(chain_id, file_store)));
        Self {
            chain_id,
            connection_manager: connection_manager.clone(),
            file_store_reader,
            max_transaction_filter_size_bytes,
        }
    }
```
