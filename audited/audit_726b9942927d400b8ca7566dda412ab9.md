# Audit Report

## Title
Unbounded Memory Allocation in Backup Restoration Enables Validator Node Denial of Service

## Summary
The `read_record_bytes()` function in the backup restoration system fails to validate record size values read from backup files, allowing a malicious backup file creator to trigger excessive memory allocation (up to 4GB) via a crafted size header. This causes out-of-memory (OOM) crashes on validator nodes attempting backup restoration, resulting in denial of service.

## Finding Description

The backup restoration system uses a custom record format where each record is prefixed with a 4-byte big-endian size header (u32) followed by the actual data. When reading records, the `read_record_bytes()` function extracts this size value and directly uses it to allocate memory without any validation. [1](#0-0) 

The critical vulnerability occurs at line 54 where `record_size` is read from the untrusted backup file, and line 60 where `BytesMut::with_capacity(record_size)` attempts to allocate that exact amount of memory without any bounds checking.

Since `record_size` is derived from a u32 value, an attacker can set it to u32::MAX (4,294,967,295 bytes ≈ 4GB). When `BytesMut::with_capacity()` is called with this value, it attempts to allocate 4GB of memory immediately, causing memory exhaustion and OOM crashes.

This function is invoked in three critical restore operations:

**Transaction Restore:** [2](#0-1) 

**Epoch Ending Restore:** [3](#0-2) 

**State Snapshot Restore:** [4](#0-3) 

While the backup creation process enforces a `max_chunk_size` limit (default 128MB): [5](#0-4) 

This limit is only enforced during backup **creation**, not during restoration. The restoration code path contains no equivalent size validation, violating the **Resource Limits** invariant that states "all operations must respect gas, storage, and computational limits."

**Attack Scenario:**

1. Attacker gains write access to backup storage (S3, GCS, local filesystem, or other configured storage backend)
2. Attacker creates a malicious backup file with format:
   - 4 bytes: `0xFF 0xFF 0xFF 0xFF` (u32::MAX = 4,294,967,295)
   - 0+ bytes: arbitrary or no data
3. Validator node initiates backup restoration operation
4. `read_record_bytes()` reads the size header and attempts to allocate 4GB
5. System runs out of memory, triggering OOM killer or crash
6. Validator node becomes unavailable

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria, specifically:
- **"Validator node slowdowns"** - Memory exhaustion causes severe performance degradation before crash
- **"API crashes"** - The restoration process crashes the entire node

The impact extends beyond a single validator:
- **Availability Loss**: Affected validators cannot complete backup restoration, preventing disaster recovery
- **Operational Disruption**: Multiple validators using shared or compromised backup storage can be simultaneously affected
- **Recovery Prevention**: If all backup files are poisoned, the network cannot recover from catastrophic failures using backups

While this does not directly break consensus safety (validators continue operating normally unless they attempt restoration), it severely undermines network resilience and operational continuity.

## Likelihood Explanation

**Likelihood: Medium to High**

The exploitability depends on backup storage access controls:

**High Likelihood Scenarios:**
- Backup storage has weak access controls or is publicly writable
- Multiple validators share a common backup repository
- Compromised backup storage credentials (S3 keys, service account tokens)
- Insider threat with backup storage access

**Medium Likelihood Scenarios:**
- Individual validators maintain private backup storage with strong access controls
- Backup storage requires authentication and authorization

The attack requires:
- ✅ No cryptographic keys or validator privileges
- ✅ No deep protocol knowledge
- ✅ Simple file manipulation (4 bytes changed)
- ✅ Predictable outcome (guaranteed OOM)

Given that backup storage configurations vary widely and cloud storage misconfigurations are common, the likelihood is substantial.

## Recommendation

Implement strict size validation before memory allocation. The fix should enforce a maximum record size consistent with the `max_chunk_size` limit used during backup creation:

```rust
async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
    
    // read record size
    let mut size_buf = BytesMut::with_capacity(4);
    self.read_full_buf_or_none(&mut size_buf).await?;
    if size_buf.is_empty() {
        return Ok(None);
    }

    // empty record
    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }

    // ADD VALIDATION: Enforce maximum record size
    const MAX_RECORD_SIZE: usize = 256 * 1024 * 1024; // 256MB (2x max_chunk_size for safety)
    if record_size > MAX_RECORD_SIZE {
        bail!(
            "Record size {} exceeds maximum allowed size {}",
            record_size,
            MAX_RECORD_SIZE
        );
    }

    // read record
    let mut record_buf = BytesMut::with_capacity(record_size);
    self.read_full_buf_or_none(&mut record_buf).await?;
    if record_buf.is_empty() {
        bail!("Hit EOF when reading record.")
    }

    Ok(Some(record_buf.freeze()))
}
```

The recommended maximum should be configurable but default to a reasonable multiple of `max_chunk_size` (e.g., 256MB) to accommodate legitimate large records while preventing extreme allocations.

## Proof of Concept

```rust
// File: storage/backup/backup-cli/tests/oom_exploit_test.rs

use bytes::BytesMut;
use storage_backup_cli::utils::read_record_bytes::ReadRecordBytes;

#[tokio::test]
async fn test_malicious_backup_oom() {
    // Create malicious backup file with 4GB size header
    let mut malicious_data = Vec::new();
    
    // Size header: u32::MAX (4,294,967,295 bytes ≈ 4GB)
    malicious_data.extend_from_slice(&u32::MAX.to_be_bytes());
    
    // No actual data follows (simulating truncated/malicious file)
    // When read_record_bytes tries to read 4GB, it will:
    // 1. Allocate 4GB via BytesMut::with_capacity()
    // 2. Cause OOM before even reading data
    
    let mut reader = malicious_data.as_slice();
    
    // This will attempt to allocate 4GB and crash
    // In production, this would trigger OOM killer
    let result = reader.read_record_bytes().await;
    
    // Expected: Should fail due to validation (after fix)
    // Actual (before fix): OOM crash or allocation failure
    assert!(result.is_err(), "Should reject oversized record");
}

#[tokio::test] 
async fn test_reasonable_size_accepted() {
    // Create valid backup file with reasonable size
    let data = vec![0u8; 1024]; // 1KB of data
    let mut valid_data = Vec::new();
    
    valid_data.extend_from_slice(&(data.len() as u32).to_be_bytes());
    valid_data.extend_from_slice(&data);
    
    let mut reader = valid_data.as_slice();
    let result = reader.read_record_bytes().await;
    
    assert!(result.is_ok(), "Should accept reasonable record size");
    assert_eq!(result.unwrap().unwrap().len(), 1024);
}
```

**Reproduction Steps:**

1. Create a malicious backup file: `echo -ne '\xFF\xFF\xFF\xFF' > malicious.chunk`
2. Configure validator to use this file for restoration
3. Initiate backup restoration: `aptos-db-tool restore --transaction-manifest malicious.chunk`
4. Observe memory allocation spike to 4GB and OOM crash

**Notes**

- The vulnerability exists in the core backup restoration path, affecting all three restore types (transactions, epoch endings, state snapshots)
- The backup creation process enforces a 128MB chunk size limit, but restoration has no equivalent protection
- BytesMut::with_capacity() performs immediate memory reservation, making the OOM crash deterministic
- Cloud storage misconfigurations (publicly writable buckets) are common and would enable this attack
- The fix requires minimal code changes but significantly improves resilience against malicious or corrupted backup files

### Citations

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-67)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
        if record_buf.is_empty() {
            bail!("Hit EOF when reading record.")
        }

        Ok(Some(record_buf.freeze()))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L112-112)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L167-167)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L261-261)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L52-57)
```rust
    #[clap(
        long = "max-chunk-size",
        default_value_t = 134217728,
        help = "Maximum chunk file size in bytes."
    )]
    pub max_chunk_size: usize,
```
