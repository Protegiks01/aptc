# Audit Report

## Title
State Sync Liveness Failure When All Peers Are Ignored Due to Empty GlobalDataSummary with Zero Chunk Sizes

## Summary
When all peers become ignored (due to low peer scores), `calculate_global_data_summary()` returns `GlobalDataSummary::empty()` with all optimal chunk sizes set to zero. This empty summary bypasses validation checks and gets cached by the streaming service. Existing data streams then use these zero chunk sizes to create invalid data requests (where `start_index > end_index`), causing state sync to halt indefinitely even when peers recover.

## Finding Description
The vulnerability involves a multi-step failure chain in the state synchronization system: [1](#0-0) 

When `storage_summaries` is empty (because all peers are ignored or disconnected), the function returns `GlobalDataSummary::empty()`. [2](#0-1) 

This empty summary has all chunk sizes set to 0 (epoch, state, transaction, and transaction_output chunk sizes). [3](#0-2) 

The critical flaw is that `fetch_global_data_summary()` only validates chunk sizes when the summary is NOT empty. If the summary is empty, it just logs a message and returns `Ok(global_data_summary)`, allowing the zero-chunk-size summary to be cached. [4](#0-3) 

Once cached, existing data streams retrieve this empty summary and use it to create requests: [5](#0-4) 

With `optimal_chunk_size = 0`:
- `num_items_to_fetch = min(total_items_to_fetch, 0) = 0`
- `request_end_index = request_start_index + 0 - 1 = request_start_index - 1`
- This creates requests where the end index is less than the start index
- `total_items_to_fetch` never decreases (since we subtract 0), creating an infinite loop bounded only by `max_number_of_requests` [6](#0-5) 

When these malformed requests reach storage service peers, they are rejected with `Error::InvalidRequest` because `end < start`.

**Attack Path:**
1. Node has active state sync streams syncing successfully
2. All peers receive repeated bad responses or send malicious data
3. Peer scores drop below `IGNORE_PEER_THRESHOLD` (25.0) for all connected peers
4. All peers become ignored, making `storage_summaries` empty
5. Empty `GlobalDataSummary` with zero chunk sizes is cached
6. Existing data streams use this cached summary to create new batch requests
7. Requests are created with invalid index ranges (start > end)
8. All requests are rejected by peers with `InvalidRequest` errors
9. State sync halts indefinitely, unable to make progress even after peers recover

## Impact Explanation
This is a **High Severity** vulnerability according to the Aptos bug bounty criteria:
- **Significant protocol violation**: State sync becomes completely non-functional
- **Loss of liveness**: Nodes cannot sync state until manual intervention
- **Validator node slowdowns**: Affected nodes cannot participate in consensus if they fall behind

The vulnerability affects network availability by preventing nodes from catching up to the current blockchain state. While the driver checks for empty summaries before creating NEW streams, EXISTING streams are not protected and will continue attempting to use the zero-chunk-size summary indefinitely.

## Likelihood Explanation
**Likelihood: Medium to High**

This vulnerability can occur in realistic scenarios:

1. **Network partition or poor connectivity**: If a node temporarily loses connection to high-quality peers and only connects to malicious or faulty peers
2. **Malicious peer attacks**: Adversaries can intentionally send invalid data to reduce peer scores below the ignore threshold
3. **Software bugs in peers**: Legitimate peers with bugs that cause them to send invalid responses
4. **Byzantine behavior**: Malicious validators attempting to prevent nodes from syncing

The peer scoring system is designed to protect against bad peers, but the side effect of ignoring ALL peers simultaneously was not properly handled. The vulnerability requires no special privileges - any network peer can trigger score decreases through bad responses.

## Recommendation
Add validation to prevent zero chunk sizes from being cached, even when the global summary is empty. The fix should be applied in `fetch_global_data_summary()`:

```rust
fn fetch_global_data_summary<T: AptosDataClientInterface + Send + Clone + 'static>(
    aptos_data_client: T,
) -> Result<GlobalDataSummary, Error> {
    // Fetch the global data summary from the data client
    let global_data_summary = aptos_data_client.get_global_data_summary();

    // Periodically log if the global data summary is empty.
    if global_data_summary.is_empty() {
        sample!(
            SampleRate::Duration(Duration::from_secs(GLOBAL_DATA_REFRESH_LOG_FREQ_SECS)),
            info!(LogSchema::new(LogEntry::RefreshGlobalData)
                .message("Latest global data summary is empty."))
        );
        // Return an error instead of Ok to prevent caching empty summaries
        return Err(Error::AptosDataClientResponseIsInvalid(
            "Global data summary is empty - no valid peers available".to_string()
        ));
    } else {
        verify_optimal_chunk_sizes(&global_data_summary.optimal_chunk_sizes)?;
    }

    Ok(global_data_summary)
}
```

Additionally, add a safeguard in `create_data_client_request_batch()` to detect and reject zero chunk sizes:

```rust
fn create_data_client_request_batch(
    start_index: u64,
    end_index: u64,
    max_number_of_requests: u64,
    optimal_chunk_size: u64,
    stream_engine: StreamEngine,
) -> Result<Vec<DataClientRequest>, Error> {
    if start_index > end_index {
        return Ok(vec![]);
    }

    // Add validation for zero chunk size
    if optimal_chunk_size == 0 {
        return Err(Error::AptosDataClientResponseIsInvalid(
            "Cannot create requests with zero chunk size".to_string()
        ));
    }

    // ... rest of function
}
```

## Proof of Concept
The following Rust test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_empty_global_summary_causes_invalid_requests() {
    use crate::global_summary::{GlobalDataSummary, OptimalChunkSizes};
    use crate::stream_engine::*;
    
    // Create an empty global data summary with zero chunk sizes
    let empty_summary = GlobalDataSummary::empty();
    assert_eq!(empty_summary.optimal_chunk_sizes.transaction_chunk_size, 0);
    
    // Create a stream engine that would normally make valid requests
    let stream_engine = /* initialize with valid stream request */;
    
    // Try to create requests with the empty summary
    let result = create_data_client_request_batch(
        100,  // start_index
        200,  // end_index  
        10,   // max_number_of_requests
        empty_summary.optimal_chunk_sizes.transaction_chunk_size, // 0
        stream_engine,
    );
    
    // With chunk_size = 0:
    // - num_items_to_fetch = min(101, 0) = 0
    // - request_end_index = 100 + 0 - 1 = 99
    // - Creates request with start=100, end=99 (invalid!)
    
    // The function will create invalid requests or error
    // These invalid requests would be rejected by peers
    // State sync would halt
}
```

**Notes**
The vulnerability specifically affects the liveness of state synchronization but does not compromise consensus safety or data integrity. The node will remain stuck until either: (1) peers recover and their scores increase above the ignore threshold, or (2) the node is manually restarted with new peer connections. This represents a significant availability issue that could affect validator participation and network health.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L339-355)
```rust
    pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
        // Gather all storage summaries, but exclude peers that are ignored
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();

        // If we have no peers, return an empty global summary
        if storage_summaries.is_empty() {
            return GlobalDataSummary::empty();
        }
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L52-60)
```rust
impl OptimalChunkSizes {
    pub fn empty() -> Self {
        OptimalChunkSizes {
            epoch_chunk_size: 0,
            state_chunk_size: 0,
            transaction_chunk_size: 0,
            transaction_output_chunk_size: 0,
        }
    }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L431-451)
```rust
fn refresh_global_data_summary<T: AptosDataClientInterface + Send + Clone + 'static>(
    aptos_data_client: T,
    cached_global_data_summary: Arc<ArcSwap<GlobalDataSummary>>,
) {
    // Fetch the global data summary and update the cache
    match fetch_global_data_summary(aptos_data_client) {
        Ok(global_data_summary) => {
            // Update the cached global data summary
            cached_global_data_summary.store(Arc::new(global_data_summary));
        },
        Err(error) => {
            // Otherwise, log an error and increment the error counter
            sample!(
                SampleRate::Duration(Duration::from_secs(GLOBAL_DATA_REFRESH_LOG_FREQ_SECS)),
                warn!(LogSchema::new(LogEntry::RefreshGlobalData)
                    .event(LogEvent::Error)
                    .error(&error))
            );
            metrics::increment_counter(&metrics::GLOBAL_DATA_SUMMARY_ERROR, error.get_label());
        },
    }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L455-474)
```rust
fn fetch_global_data_summary<T: AptosDataClientInterface + Send + Clone + 'static>(
    aptos_data_client: T,
) -> Result<GlobalDataSummary, Error> {
    // Fetch the global data summary from the data client
    let global_data_summary = aptos_data_client.get_global_data_summary();

    // Periodically log if the global data summary is empty.
    // Otherwise, verify that all optimal chunk sizes are valid.
    if global_data_summary.is_empty() {
        sample!(
            SampleRate::Duration(Duration::from_secs(GLOBAL_DATA_REFRESH_LOG_FREQ_SECS)),
            info!(LogSchema::new(LogEntry::RefreshGlobalData)
                .message("Latest global data summary is empty."))
        );
    } else {
        verify_optimal_chunk_sizes(&global_data_summary.optimal_chunk_sizes)?;
    }

    Ok(global_data_summary)
}
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2070-2096)
```rust
    while total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
        // Calculate the number of items to fetch in this request
        let num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size);

        // Calculate the start and end indices for the request
        let request_start_index = next_index_to_request;
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;

        // Create the data client requests
        let data_client_request =
            create_data_client_request(request_start_index, request_end_index, &stream_engine)?;
        data_client_requests.push(data_client_request);

        // Update the local loop state
        next_index_to_request = request_end_index
            .checked_add(1)
            .ok_or_else(|| Error::IntegerOverflow("Next index to request has overflown!".into()))?;
        total_items_to_fetch = total_items_to_fetch
            .checked_sub(num_items_to_fetch)
            .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;
        num_requests_made = num_requests_made.checked_add(1).ok_or_else(|| {
            Error::IntegerOverflow("Number of payload requests has overflown!".into())
        })?;
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L1485-1494)
```rust
fn inclusive_range_len(start: u64, end: u64) -> aptos_storage_service_types::Result<u64, Error> {
    // len = end - start + 1
    let len = end.checked_sub(start).ok_or_else(|| {
        Error::InvalidRequest(format!("end ({}) must be >= start ({})", end, start))
    })?;
    let len = len
        .checked_add(1)
        .ok_or_else(|| Error::InvalidRequest(format!("end ({}) must not be u64::MAX", end)))?;
    Ok(len)
}
```
