# Audit Report

## Title
BorrowEdgeSet Overflow State Corruption Allows Reference Safety Bypass in Move Bytecode Verifier

## Summary
The `BorrowEdgeSet` struct in the Move borrow graph can enter an inconsistent state where `overflown = true` but `edges` is empty, violating the invariant that an overflown set must contain exactly one catch-all weak edge. This allows the bytecode verifier to incorrectly determine that a reference has no active borrows, bypassing Move's reference safety checks and potentially allowing writes to borrowed references. [1](#0-0) 

## Finding Description

The vulnerability occurs in the interaction between `BorrowEdgeSet`'s overflow handling and edge removal during graph operations. When a `BorrowEdgeSet` exceeds `MAX_EDGE_SET_SIZE` (10 edges), it enters an "overflow" state where all edges are replaced with a single catch-all weak edge representing "any possible borrow path": [2](#0-1) 

The catch-all edge has `strong: false` and `path: vec![]`. However, the `remove()` method can delete this catch-all edge without resetting the `overflown` flag: [3](#0-2) 

This is exploitable through the `factor()` operation in `BorrowGraph`, which removes edges that match a given path prefix: [4](#0-3) 

Since `BorrowEdge` equality is based only on `strong` and `path` (not `loc`): [5](#0-4) 

Any edge with `strong: false, path: vec![]` will match the catch-all edge. When `factor()` is called with an empty path (e.g., during `add_strong_borrow`), it checks if the path is a prefix of existing edges: [6](#0-5) 

The empty path is a prefix of itself, so the catch-all edge gets removed, leaving `overflown = true` with an empty edge set.

**Attack Scenario:**
1. Create a reference with >10 different field borrows to the same child reference (triggers overflow)
2. Perform an operation that calls `add_copy()` or `add_strong_borrow()` (e.g., copying a reference)
3. This triggers `factor()` with an empty path, removing the catch-all edge
4. The borrow graph now has `overflown = true` but `edges.is_empty() = true`

When the bytecode verifier checks if a reference is writable, it iterates over the edges: [7](#0-6) 

An empty edge set returns empty maps, causing `has_consistent_borrows()` to return false: [8](#0-7) 

This makes `is_writable()` return true incorrectly: [9](#0-8) 

The bytecode verifier then allows `WriteRef` operations on references that should be considered borrowed: [10](#0-9) 

## Impact Explanation

This is a **HIGH severity** vulnerability that violates Move's core reference safety guarantees. The impact includes:

1. **Move VM Safety Violation**: The bytecode verifier will accept invalid Move bytecode that violates borrow checking rules, allowing writes through references that have active borrows.

2. **Deterministic Execution Risk**: If this bug manifests differently across validators (e.g., due to timing or optimization differences), it could cause consensus divergence as validators disagree on whether bytecode is valid.

3. **Memory Safety Compromise**: While Move is designed to prevent memory unsafety, this bug creates scenarios where aliased mutable references could exist, potentially leading to data races or use-after-free conditions in the Move VM's reference semantics.

This meets the **High Severity** criteria: "Significant protocol violations" - specifically, a fundamental violation of Move's type safety and borrow checking system.

## Likelihood Explanation

The likelihood is **MEDIUM to HIGH**:

**Favorable conditions for exploitation:**
- Complex Move modules with deeply nested structs and many fields can naturally create >10 borrow edges
- The `add_copy()` operation (triggered by reference copying) is common in Move code
- The bug is deterministic once triggered

**Limiting factors:**
- Requires specific patterns of complex borrows followed by reference copies
- The overflow threshold of 10 edges requires intentional or naturally complex code
- Most Move code doesn't create such deep borrow graphs

However, a malicious actor crafting Move modules specifically to exploit this could reliably trigger the vulnerability.

## Recommendation

**Fix 1: Prevent removal of catch-all edge when overflown**

Modify `BorrowEdgeSet::remove()` to check if the set is overflown and prevent removal of the catch-all edge: [3](#0-2) 

```rust
pub(crate) fn remove(&mut self, edge: &BorrowEdge<Loc, Lbl>) -> bool {
    // Don't remove edges from overflown sets - they contain the essential catch-all edge
    if self.overflown {
        debug_assert!(!self.is_empty());
        return false;
    }
    let was_removed = self.edges.remove(edge);
    debug_assert!(was_removed);
    was_removed
}
```

**Fix 2: Reset overflown flag when edges become empty**

Alternatively, if removal is intentional, reset the `overflown` flag when the set becomes empty:

```rust
pub(crate) fn remove(&mut self, edge: &BorrowEdge<Loc, Lbl>) -> bool {
    let was_removed = self.edges.remove(edge);
    debug_assert!(was_removed);
    if self.edges.is_empty() {
        self.overflown = false;
    }
    was_removed
}
```

**Fix 3: Strengthen invariant checks**

Update the debug assertions to catch this inconsistent state: [11](#0-10) 

```rust
pub(crate) fn iter(&self) -> std::collections::btree_set::Iter<'_, BorrowEdge<Loc, Lbl>> {
    debug_assert!(!self.overflown || !self.is_empty(), "Overflown set must contain catch-all edge");
    self.edges.iter()
}
```

**Recommended approach:** Implement Fix 1 to prevent the inconsistent state from occurring, as removal of edges from overflown sets should not be allowed since they represent conservative approximations.

## Proof of Concept

```rust
#[cfg(test)]
mod test_borrow_edge_overflow_corruption {
    use move_borrow_graph::graph::BorrowGraph;
    use move_borrow_graph::references::RefID;

    #[test]
    fn test_overflow_corruption_via_factor() {
        let mut graph = BorrowGraph::<(), String>::new();
        
        // Create parent and child references
        let parent = RefID::new(0);
        let child = RefID::new(1);
        graph.new_ref(parent, true);
        graph.new_ref(child, true);
        
        // Add 11 different field borrows from parent to child (trigger overflow)
        for i in 0..11 {
            graph.add_strong_field_borrow((), parent, format!("field{}", i), child);
        }
        
        // At this point, the edge set from parent to child should be overflown
        // with a single catch-all weak edge
        
        // Now add a strong epsilon borrow which calls factor with empty path
        let new_child = RefID::new(2);
        graph.new_ref(new_child, true);
        graph.add_strong_borrow((), parent, new_child);
        
        // This triggers factor(parent, (), vec![], new_child)
        // The factor method will find the catch-all edge (path = vec![])
        // and remove it, leaving overflown = true but edges empty
        
        // Now check if parent is writable (should be false due to borrows)
        // But due to the bug, has_consistent_borrows will return false
        // because it iterates over an empty edge set
        let is_writable = graph.is_writable(parent);
        
        // BUG: This assertion should fail, but passes due to the vulnerability
        // The parent should NOT be writable because it has active borrows to child
        assert!(!is_writable, "Parent should not be writable with active borrows");
    }
}
```

**Notes**

The vulnerability exists in the Move borrow graph implementation shared between both the Move compiler and bytecode verifier. The security question correctly identifies this as a High severity issue where the `overflown` flag can become corrupted through the `remove()` operation during graph factoring. While the question asks about two scenarios ("overflown = true with >1 element" and "overflown = false with catch-all edge"), the actual exploitable bug is the third scenario discovered: **overflown = true with 0 elements**, which violates the critical invariant that overflown sets must contain the catch-all weak edge representing conservative borrow approximation.

### Citations

**File:** third_party/move/move-borrow-graph/src/references.rs (L49-54)
```rust
pub(crate) struct BorrowEdgeSet<Loc: Copy, Lbl: Clone + Ord> {
    edges: BTreeSet<BorrowEdge<Loc, Lbl>>,
    // true if the set has hit the `MAX_EDGE_SET_SIZE`
    // See `MAX_EDGE_SET_SIZE` for more details
    overflown: bool,
}
```

**File:** third_party/move/move-borrow-graph/src/references.rs (L106-113)
```rust
        if self.edges.len() + 1 > MAX_EDGE_SET_SIZE {
            let loc = edge.loc;
            self.edges = BTreeSet::from([BorrowEdge {
                strong: false,
                path: vec![],
                loc,
            }]);
            self.overflown = true
```

**File:** third_party/move/move-borrow-graph/src/references.rs (L119-123)
```rust
    pub(crate) fn remove(&mut self, edge: &BorrowEdge<Loc, Lbl>) -> bool {
        let was_removed = self.edges.remove(edge);
        debug_assert!(was_removed);
        was_removed
    }
```

**File:** third_party/move/move-borrow-graph/src/references.rs (L133-136)
```rust
    pub(crate) fn iter(&self) -> std::collections::btree_set::Iter<'_, BorrowEdge<Loc, Lbl>> {
        debug_assert!(self.overflown || !self.is_empty());
        self.edges.iter()
    }
```

**File:** third_party/move/move-borrow-graph/src/references.rs (L204-207)
```rust
impl<Loc: Copy, Lbl: Clone + Ord> PartialEq for BorrowEdge<Loc, Lbl> {
    fn eq(&self, other: &BorrowEdge<Loc, Lbl>) -> bool {
        BorrowEdgeNoLoc::new(self) == BorrowEdgeNoLoc::new(other)
    }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L64-76)
```rust
        for (borrower, edges) in &borrowed_by.0 {
            let borrower = *borrower;
            for edge in edges {
                match edge.path.first() {
                    None => full_borrows.insert(borrower, edge.loc),
                    Some(f) => field_borrows
                        .entry(f.clone())
                        .or_default()
                        .insert(borrower, edge.loc),
                };
            }
        }
        (full_borrows, field_borrows)
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L218-223)
```rust
            for parent_to_child_edge in parent_to_child_edges {
                if paths::leq(&path, &parent_to_child_edge.path) {
                    let factored_edge = (*child_id, parent_to_child_edge.clone());
                    needs_factored.push(factored_edge);
                }
            }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L227-229)
```rust
        for (child_id, parent_to_child_edge) in &needs_factored {
            let parent_to_child_edges = parent.borrowed_by.0.get_mut(child_id).unwrap();
            assert!(parent_to_child_edges.remove(parent_to_child_edge));
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L479-489)
```rust
    pub fn has_consistent_borrows(&self, id: RefID, label_opt: Option<Lbl>) -> bool {
        let (full_borrows, field_borrows) = self.borrowed_by(id);
        !full_borrows.is_empty() || {
            match label_opt {
                None => field_borrows.values().any(|borrows| !borrows.is_empty()),
                Some(label) => field_borrows
                    .get(&label)
                    .map(|borrows| !borrows.is_empty())
                    .unwrap_or(false),
            }
        }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L514-517)
```rust
    pub fn is_writable(&self, id: RefID) -> bool {
        assert!(self.is_mutable(id));
        !self.has_consistent_borrows(id, None)
    }
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/abstract_state.rs (L367-374)
```rust
    pub fn write_ref(&mut self, offset: CodeOffset, id: RefID) -> PartialVMResult<()> {
        if !self.is_writable(id) {
            return Err(self.error(StatusCode::WRITEREF_EXISTS_BORROW_ERROR, offset));
        }

        self.release(id);
        Ok(())
    }
```
