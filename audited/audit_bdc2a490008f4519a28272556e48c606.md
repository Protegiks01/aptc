# Audit Report

## Title
Inadequate Stream Cleanup on Early Client Disconnection Leading to Resource Exhaustion in Fullnode gRPC Service

## Summary
When a client closes the gRPC stream before receiving all requested transactions, the server fails to immediately cancel ongoing processing tasks. This results in wasted database I/O, CPU resources, and memory allocation for data that will never be delivered, creating a resource exhaustion attack vector.

## Finding Description

The `GetTransactionsFromNode` gRPC streaming service spawns an asynchronous task to process and stream transaction batches to clients. [1](#0-0) 

When a client closes the stream prematurely, the receiver end of the channel (`rx`) is dropped, closing the channel. However, the spawned task does not detect this disconnection immediately. Instead, it continues processing the current batch through multiple stages:

1. **Database Fetching**: Multiple `tokio::spawn` tasks fetch transactions from storage [2](#0-1) 

2. **CPU-Intensive Processing**: Multiple `tokio::task::spawn_blocking` tasks convert transactions to protobuf format [3](#0-2) 

3. **Detection Only on Send**: Disconnection is only detected when attempting to send processed data through the closed channel [4](#0-3) 

The critical issue is that **none of the spawned sub-tasks have cancellation mechanisms**. There are no:
- JoinHandles stored for cleanup
- CancellationTokens passed to sub-tasks  
- Abort checks during processing phases

While the code includes an `abort_handle`, it's only checked in the main loop [5](#0-4)  and is never set to true for individual stream cancellationsâ€”it's only initialized and intended for service-wide shutdown [6](#0-5) 

**Attack Scenario:**
1. Malicious client opens multiple gRPC streams requesting large transaction ranges
2. Immediately closes connections after receiving the init message [7](#0-6) 
3. Server continues processing entire batches (fetching, converting, encoding)
4. Only detects disconnect when attempting to send completed batch
5. Repeat with multiple concurrent connections to exhaust node resources

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria for the following reasons:

**Resource Exhaustion Vector**: An attacker can force the fullnode to waste significant resources:
- Database I/O operations continue fetching transactions that will never be delivered
- CPU cycles are consumed in transaction conversion and protobuf encoding via blocking tasks
- Memory is allocated for processed batches that are immediately discarded
- Multiple concurrent malicious streams can severely degrade fullnode performance

**Bounded but Repeatable**: While each disconnect wastes only one batch worth of resources, the attack is:
- Trivially repeatable with no cost to the attacker
- Amplified across multiple concurrent connections
- Sustained over time to cause persistent degradation

**Service Availability Impact**: This affects the availability and reliability of the fullnode's indexer gRPC service, which is critical infrastructure for:
- Blockchain explorers and analytics platforms
- Indexing services that rely on transaction streaming
- Applications requiring historical transaction data

While this does not directly impact consensus or validator operations, it represents a clear resource management violation and denial-of-service vector against critical data availability infrastructure.

## Likelihood Explanation

**High Likelihood** of occurrence because:

1. **Low Attack Complexity**: Any client can connect to the public gRPC endpoint and close the connection
2. **No Authentication Required**: The endpoint is designed to be publicly accessible
3. **Immediate Trigger**: The vulnerability is triggered on every early disconnect, no special conditions needed
4. **No Detection**: There are no rate limits or abuse detection mechanisms in the code
5. **Repeatable**: The attack can be automated and sustained indefinitely

The only barrier is network access to a fullnode's gRPC port, which is typically available for legitimate indexing purposes.

## Recommendation

Implement proper cancellation handling using Tokio's cancellation primitives:

**Solution 1: Use CancellationToken**
```rust
use tokio_util::sync::CancellationToken;

async fn get_transactions_from_node(/*...*/) -> Result</*...*/, Status> {
    let (tx, rx) = mpsc::channel(transaction_channel_size);
    let cancel_token = CancellationToken::new();
    let cancel_token_clone = cancel_token.clone();
    
    tokio::spawn(async move {
        let mut coordinator = IndexerStreamCoordinator::new(
            // ... existing params ...
            Some(cancel_token_clone),
        );
        
        // In processing loop:
        tokio::select! {
            _ = cancel_token_clone.cancelled() => {
                info!("Stream cancelled by client disconnect");
                break;
            }
            results = coordinator.process_next_batch() => {
                // ... existing logic ...
            }
        }
    });
    
    // When ReceiverStream is dropped, cancel the token
    let output_stream = ReceiverStream::new(rx)
        .inspect(|_| {}) // Monitor for drop
        .on_drop(move || cancel_token.cancel());
}
```

**Solution 2: Check Channel Capacity**
Add periodic checks for channel closure:
```rust
// In process_next_batch before expensive operations:
if self.transactions_sender.is_closed() {
    return vec![]; // Exit early
}
```

**Solution 3: Store JoinHandles for Cleanup**
Track spawned tasks and abort them on disconnect:
```rust
let mut task_handles = vec![];
for batch in batches {
    let handle = tokio::spawn(/* ... */);
    task_handles.push(handle);
}

// Check if channel closed before awaiting
if self.transactions_sender.is_closed() {
    for handle in task_handles {
        handle.abort();
    }
    return vec![];
}
```

The recommended approach combines early detection via channel state checks with proper task cancellation propagation.

## Proof of Concept

```rust
use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient,
    GetTransactionsFromNodeRequest,
};
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Connect to fullnode gRPC endpoint
    let mut client = FullnodeDataClient::connect("http://127.0.0.1:50051").await?;
    
    // Attack: Open 100 concurrent streams and immediately close them
    let mut handles = vec![];
    for i in 0..100 {
        let mut client_clone = client.clone();
        let handle = tokio::spawn(async move {
            println!("[Attack {}] Opening stream...", i);
            
            // Request large range of transactions
            let request = Request::new(GetTransactionsFromNodeRequest {
                starting_version: Some(0),
                transactions_count: Some(1_000_000), // Request 1M transactions
            });
            
            // Open stream
            let mut stream = client_clone
                .get_transactions_from_node(request)
                .await
                .unwrap()
                .into_inner();
            
            // Receive only init message
            let _init = stream.message().await.unwrap();
            println!("[Attack {}] Received init, now closing stream", i);
            
            // Drop stream immediately - server will continue processing!
            drop(stream);
            
            println!("[Attack {}] Stream closed, but server still processing batch", i);
        });
        handles.push(handle);
    }
    
    // Wait for all attack streams
    for handle in handles {
        handle.await?;
    }
    
    println!("Attack complete. Server wasted resources on 100 disconnected streams.");
    println!("Each stream triggered full batch processing despite immediate disconnect.");
    
    Ok(())
}
```

**Expected Behavior**: Server should immediately cancel processing when stream is closed.

**Actual Behavior**: Server continues fetching from database, converting transactions, and encoding protobuf until it attempts to send, wasting resources on data that will never be delivered.

**Verification**: Monitor fullnode CPU usage, database queries, and memory allocation during the attack. You will observe sustained resource consumption despite all clients disconnecting immediately after the init message.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L101-101)
```rust
        tokio::spawn(async move {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L120-128)
```rust
            match tx.send(Result::<_, Status>::Ok(init_status)).await {
                Ok(_) => {
                    // TODO: Add request details later
                    info!(
                        start_version = starting_version,
                        chain_id = ledger_chain_id,
                        service_type = SERVICE_TYPE,
                        "[Indexer Fullnode] Init connection"
                    );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L139-142)
```rust
                if abort_handle.load(Ordering::SeqCst) {
                    info!("FullnodeDataService is aborted.");
                    break;
                }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L170-200)
```rust
            let task = tokio::task::spawn_blocking(move || {
                let raw_txns = batch;
                let api_txns = Self::convert_to_api_txns(context, raw_txns);
                let pb_txns = Self::convert_to_pb_txns(api_txns);
                // Apply filter if present.
                let pb_txns = if let Some(ref filter) = filter {
                    pb_txns
                        .into_iter()
                        .filter(|txn| filter.matches(txn))
                        .collect::<Vec<_>>()
                } else {
                    pb_txns
                };
                let mut responses = vec![];
                // Wrap in stream response object and send to channel
                for chunk in pb_txns.chunks(output_batch_size as usize) {
                    for chunk in chunk_transactions(chunk.to_vec(), MESSAGE_SIZE_LIMIT) {
                        let item = TransactionsFromNodeResponse {
                            response: Some(transactions_from_node_response::Response::Data(
                                TransactionsOutput {
                                    transactions: chunk,
                                },
                            )),
                            chain_id: ledger_chain_id as u32,
                        };
                        responses.push(item);
                    }
                }
                responses
            });
            tasks.push(task);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L222-225)
```rust
            if self.transactions_sender.send(Ok(response)).await.is_err() {
                // Error from closed channel. This means the client has disconnected.
                return vec![];
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L248-251)
```rust
            let task = tokio::spawn(async move {
                Self::fetch_raw_txns_with_retries(context.clone(), ledger_version, batch).await
            });
            storage_fetch_tasks.push(task);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L83-83)
```rust
            abort_handle: Arc::new(AtomicBool::new(false)),
```
