# Audit Report

## Title
BCS Deserialization Bomb in Backup Restore Leading to Out-of-Memory Node Crash

## Summary
The `load_bcs_file()` function in the backup-cli component deserializes BCS-encoded backup files without size or complexity limits, allowing malicious backup files with enormous vector allocations to cause out-of-memory crashes before any validation occurs. This violates the Resource Limits invariant and enables denial-of-service attacks against nodes restoring from compromised backup sources.

## Finding Description
The vulnerability exists in the backup restore pathway where proof files are deserialized. [1](#0-0) 

The `load_bcs_file()` function calls `bcs::from_bytes()` directly on the entire file contents without any size validation. [2](#0-1) 

The critical issue is the order of operations:
1. File is read entirely into memory (unbounded)
2. BCS deserialization allocates memory for all structures (unbounded)  
3. **Only after successful deserialization**, verification methods are called

The structures being deserialized contain unbounded vectors. For example, `AccumulatorProof` contains a `siblings` vector: [3](#0-2) 

While verification checks exist to limit proof depth to 63: [4](#0-3) 

These checks occur in the `verify()` method AFTER deserialization completes. Similarly, `AccumulatorRangeProof` has two unbounded vectors that are only validated post-deserialization: [5](#0-4) 

With validation at: [6](#0-5) 

**Attack Flow:**

In state snapshot restore: [7](#0-6) 

And in transaction restore: [8](#0-7) 

An attacker crafting a malicious proof file with billions of `HashValue` entries (32 bytes each) in the `siblings`, `left_siblings`, or `right_siblings` vectors would cause:
- BCS to allocate gigabytes of memory during deserialization
- Node OOM crash before `verify()` is ever called
- Complete failure of the restore operation

The backup-cli tool is used to restore from public backup sources, as documented: [9](#0-8) 

## Impact Explanation
**Severity: High** - Validator node slowdowns and crashes

This vulnerability enables a denial-of-service attack affecting node availability:
- **Validator Impact**: Validators attempting to restore from compromised backups crash and cannot rejoin the network
- **Network Impact**: If multiple validators restore simultaneously (e.g., after widespread outage), cascading failures occur
- **Recovery Complexity**: Operators must identify and remove malicious backup files before retry

While this doesn't directly cause consensus violations or fund loss, it significantly impacts network liveness and validator availability, qualifying as High severity under "Validator node slowdowns" and "API crashes."

## Likelihood Explanation  
**Likelihood: Medium-High** given public backup infrastructure

The attack requires compromising backup storage, but several factors increase likelihood:
1. **Public Backups**: Documentation encourages operators to restore from Aptos-hosted public backups
2. **Supply Chain Risk**: Compromise of cloud storage credentials (AWS, GCS, Azure) or infrastructure
3. **Operator Trust**: Operators may restore from third-party or untrusted backup sources
4. **No Integrity Checks**: Beyond Merkle proof verification (which occurs post-deserialization), no additional size/signature validation exists

While requiring infrastructure compromise, the centralized nature of public backup sources creates a high-value target.

## Recommendation
Implement size limits during BCS deserialization using `bcs::from_bytes_with_limit()`:

```rust
async fn load_bcs_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
    let bytes = self.read_all(file_handle).await?;
    // Limit to 100MB for proof files - adjust based on actual requirements
    const MAX_PROOF_SIZE: usize = 100 * 1024 * 1024;
    ensure!(
        bytes.len() <= MAX_PROOF_SIZE,
        "Proof file exceeds maximum size: {} bytes (max: {})",
        bytes.len(),
        MAX_PROOF_SIZE
    );
    Ok(bcs::from_bytes_with_limit(&bytes, MAX_PROOF_SIZE)?)
}
```

Additionally, implement pre-deserialization validation of vector lengths at the BCS layer or add streaming deserialization with incremental validation.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_crypto::HashValue;
    use aptos_types::proof::AccumulatorProof;
    use aptos_crypto::hash::TransactionAccumulatorHasher;
    
    #[test]
    fn test_deserialization_bomb() {
        // Create a proof with an enormous siblings vector
        let mut malicious_siblings = Vec::new();
        // Allocate 1 million hash values = 32 MB
        // In real attack, could use billions
        for _ in 0..1_000_000 {
            malicious_siblings.push(HashValue::random());
        }
        
        let proof: AccumulatorProof<TransactionAccumulatorHasher> = 
            AccumulatorProof::new(malicious_siblings);
        
        // Serialize to BCS
        let bcs_bytes = bcs::to_bytes(&proof).unwrap();
        println!("BCS encoded size: {} bytes", bcs_bytes.len());
        
        // Deserialization will allocate all memory BEFORE any validation
        // With 1 billion entries this would allocate 32 GB
        let deserialized: AccumulatorProof<TransactionAccumulatorHasher> = 
            bcs::from_bytes(&bcs_bytes).unwrap();
        
        // Verification happens AFTER allocation
        let result = deserialized.verify(
            HashValue::random(),
            HashValue::random(), 
            0
        );
        
        // This will fail validation (too many siblings)
        // but memory was already allocated during deserialization
        assert!(result.is_err());
        println!("Proof siblings length: {}", deserialized.siblings().len());
    }
}
```

Compile and run: `cargo test -p aptos-types test_deserialization_bomb`

This demonstrates that arbitrarily large vectors can be deserialized before validation, enabling OOM attacks through malicious backup files.

## Notes
The vulnerability is exacerbated by the documented use of public backup sources for node bootstrapping. While the backup-cli is an operator tool requiring server access, the reliance on centralized public backup infrastructure creates a supply chain attack vector that could affect multiple operators simultaneously. The fix should include both size limits and consideration of cryptographic signatures on backup files for additional integrity assurance.

### Citations

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L24-29)
```rust
    async fn read_all(&self, file_handle: &FileHandleRef) -> Result<Vec<u8>> {
        let mut file = self.open_for_read(file_handle).await?;
        let mut bytes = Vec::new();
        file.read_to_end(&mut bytes).await?;
        Ok(bytes)
    }
```

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L31-33)
```rust
    async fn load_bcs_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
        Ok(bcs::from_bytes(&self.read_all(file_handle).await?)?)
    }
```

**File:** types/src/proof/definition.rs (L33-40)
```rust
#[derive(Clone, Serialize, Deserialize)]
pub struct AccumulatorProof<H> {
    /// All siblings in this proof, including the default ones. Siblings are ordered from the bottom
    /// level to the root level.
    siblings: Vec<HashValue>,

    phantom: PhantomData<H>,
}
```

**File:** types/src/proof/definition.rs (L74-79)
```rust
        ensure!(
            self.siblings.len() <= MAX_ACCUMULATOR_PROOF_DEPTH,
            "Accumulator proof has more than {} ({}) siblings.",
            MAX_ACCUMULATOR_PROOF_DEPTH,
            self.siblings.len()
        );
```

**File:** types/src/proof/definition.rs (L576-586)
```rust
pub struct AccumulatorRangeProof<H> {
    /// The siblings on the left of the path from the first leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    left_siblings: Vec<HashValue>,

    /// The sliblings on the right of the path from the last leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    right_siblings: Vec<HashValue>,

    phantom: PhantomData<H>,
}
```

**File:** types/src/proof/definition.rs (L636-647)
```rust
        ensure!(
            self.left_siblings.len() <= MAX_ACCUMULATOR_PROOF_DEPTH,
            "Proof has more than {} ({}) left siblings.",
            MAX_ACCUMULATOR_PROOF_DEPTH,
            self.left_siblings.len(),
        );
        ensure!(
            self.right_siblings.len() <= MAX_ACCUMULATOR_PROOF_DEPTH,
            "Proof has more than {} ({}) right siblings.",
            MAX_ACCUMULATOR_PROOF_DEPTH,
            self.right_siblings.len(),
        );
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L125-127)
```rust
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L147-151)
```rust
        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
```

**File:** docker/compose/data-restore/docker-compose.yaml (L14-22)
```yaml
      # Depends on which cloud backup data you use, replace this with either:
      # `s3.yaml` (AWS S3)
      # `gcs.yaml` (GCP GCS)
      # You can update the yaml file to specify where you want to download data from,
      # default data resource is hosted by AptosLabs.
      - type: bind
        source: ./s3.yaml
        target: /opt/aptos/etc/restore.yaml
        read_only: true
```
