# Audit Report

## Title
Concurrent Batch Processing Race Condition Causes Stale Object Metadata in Indexer Deletion Records

## Summary
The indexer's `Object::from_delete_resource()` function can record object deletions with stale metadata when concurrent batch processors query the database before earlier batches commit. This leads to inconsistent historical records where deleted objects show ownership and attributes from outdated states rather than their actual last state before deletion.

## Finding Description

The Aptos indexer processes blockchain transactions in concurrent batches to improve throughput. Each batch processor maintains an in-memory HashMap (`all_current_objects`) containing objects modified within that specific batch. When processing object deletions, the code first checks this HashMap, then falls back to querying the database if the object wasn't modified in the current batch. [1](#0-0) 

The vulnerability occurs in concurrent processing scenarios: [2](#0-1) 

Multiple processor tasks spawn concurrently and each calls `process_next_batch()` to fetch and process different transaction batches in parallel. The shared transaction fetcher provides batches on a first-come-first-served basis with no ordering guarantees. [3](#0-2) 

**Attack Scenario:**

1. Object X exists in database at version 100: `owner=Alice, allow_ungated_transfer=false`
2. **Batch 1** (versions 100-200): Transaction 150 modifies Object X to `owner=Bob, allow_ungated_transfer=true`
   - Processor Task 1 processes this batch
   - Task 1's HashMap contains: `{X: {owner: Bob, ...}}`
   - Task 1 begins database transaction but hasn't committed
3. **Batch 2** (versions 201-300): Transaction 250 deletes Object X
   - Processor Task 2 processes this batch **concurrently**
   - Task 2's HashMap is empty (Object X not modified in this batch)
   - Task 2 calls `get_object_owner(conn, X)` which queries the database
   - PostgreSQL READ COMMITTED isolation shows only committed data
   - Database query returns: `owner=Alice` (Task 1's changes not yet committed)
   - Task 2 creates deletion record using stale metadata: `(version=250, owner=Alice, is_deleted=true)`
4. Task 1 commits: `objects` table gets `(version=150, owner=Bob, is_deleted=false)`
5. Task 2 commits: `objects` table gets `(version=250, owner=Alice, is_deleted=true)` ← **WRONG**

The `current_objects` table upsert has a WHERE clause to prevent older versions from overwriting newer ones: [4](#0-3) 

However, this WHERE clause (`last_transaction_version <= excluded.last_transaction_version`) allows Task 2's commit because version 250 > version 150, even though Task 2 used metadata from version 100.

**Final State:**
- Historical `objects` table shows two inconsistent records for Object X
- Version 150: `owner=Bob, is_deleted=false` (correct intermediate state)
- Version 250: `owner=Alice, is_deleted=true` (incorrect - uses stale metadata from before version 150)
- Applications querying object history see wrong ownership at deletion time

The developers acknowledged this issue: [5](#0-4) 

## Impact Explanation

This vulnerability causes **data integrity violations in the indexer's historical records**. While it doesn't affect blockchain consensus or on-chain state (the indexer is an off-chain component), it impacts all systems relying on indexer data:

- **NFT/Token Ownership**: Block explorers, wallets, and marketplaces would display incorrect ownership history
- **Audit Trails**: Forensic analysis and compliance systems would see fabricated state transitions
- **Asset Tracking**: Applications tracking asset provenance would follow wrong ownership chains
- **Analytics**: Historical analytics and reporting tools would operate on corrupted data

Per the bug bounty severity categories, this qualifies as **Medium Severity** ("State inconsistencies requiring intervention") as it corrupts the indexer's database state, requiring manual intervention to identify and correct affected records. It could potentially qualify as **High Severity** if the indexer API is considered a critical protocol component for ecosystem applications.

## Likelihood Explanation

**Likelihood: HIGH**

This race condition occurs naturally during normal indexer operation whenever:
1. Multiple processor tasks are configured (controlled by `processor_tasks` parameter, typically ≥2 for performance)
2. An object is modified in one batch and deleted in a subsequent batch
3. Both batches are processed concurrently (common in high-throughput scenarios)

No attacker action is required - any normal transaction sequence that modifies then deletes objects can trigger this vulnerability. The issue affects all object types tracked by the indexer including NFTs, tokens, and generic Move objects.

## Recommendation

**Immediate Fix:** Implement serialization for object metadata queries during concurrent batch processing.

**Option 1: Read-Your-Writes Consistency**
Pass transaction version context to `get_object_owner()` and only query for states committed before the delete transaction's version:

```rust
pub fn from_delete_resource(
    delete_resource: &DeleteResource,
    txn_version: i64,
    write_set_change_index: i64,
    object_mapping: &HashMap<CurrentObjectPK, CurrentObject>,
    conn: &mut PgPoolConnection,
    max_visible_version: i64, // New parameter
) -> anyhow::Result<Option<(Self, CurrentObject)>> {
    // ...
    let previous_object = if let Some(object) = object_mapping.get(&resource.address) {
        object.clone()
    } else {
        match Self::get_object_owner_at_version(conn, &resource.address, max_visible_version) {
            // Query only committed data before delete transaction
            // ...
        }
    };
}
```

**Option 2: Single-Threaded Processing for Objects**
Maintain a global HashMap of objects being processed across all batches, protected by a mutex:

```rust
// In runtime.rs or tailer.rs
static GLOBAL_OBJECT_CACHE: Lazy<Mutex<HashMap<String, CurrentObject>>> = 
    Lazy::new(|| Mutex::new(HashMap::new()));

// Update on each write, check on each delete
```

**Option 3: Enforce Sequential Batch Commits**
Sort batches by version and commit them in order, even if processing happens concurrently:

```rust
// After try_join_all, sort results by version
batches.sort_by_key(|b| b.start_version);
for batch in batches {
    commit_batch_to_db(batch)?;
}
```

**Long-term Solution:** Replace HashMap/database hybrid approach with a proper KV store as indicated by the TODO comment at line 196.

## Proof of Concept

**Setup:**
1. Configure indexer with `processor_tasks >= 2` in `IndexerConfig`
2. Create Object X on-chain at version 100

**Exploitation Steps:**

```rust
// Transaction at version 150: Modify Object X
// Move code:
public entry fun modify_object(owner: &signer, obj_addr: address) {
    let obj = object::address_to_object<ObjectCore>(obj_addr);
    object::transfer(owner, obj, @new_owner); // Changes owner
}

// Transaction at version 250: Delete Object X  
// Move code:
public entry fun delete_object(owner: &signer, obj_addr: address) {
    let obj = object::address_to_object<ObjectCore>(obj_addr);
    // Triggers ObjectGroup resource deletion
}

// Verification query after indexer processing:
SELECT transaction_version, owner_address, is_deleted 
FROM objects 
WHERE object_address = 'X' 
ORDER BY transaction_version;

// Expected Result:
// version=150, owner=new_owner, is_deleted=false
// version=250, owner=new_owner, is_deleted=true

// Actual Result (with race condition):
// version=150, owner=new_owner, is_deleted=false  
// version=250, owner=old_owner, is_deleted=true  ← WRONG
```

The race condition is observable by:
1. Monitoring indexer logs for concurrent batch processing
2. Querying database immediately after both batches commit
3. Comparing `owner_address` at version 250 vs version 150
4. If they differ, the race condition occurred

**Notes**

This vulnerability is specific to the **indexer component** - an off-chain service that provides indexed views of blockchain data. It does **not** affect blockchain consensus, on-chain state, or fund custody. The blockchain itself maintains correct state; only the indexer's PostgreSQL database contains corrupted historical records.

The issue is exacerbated by the indexer's design choice to use concurrent batch processing for performance, combined with the HashMap-database hybrid approach for object metadata lookups. The token ownership indexer has a similar pattern that may be affected. [6](#0-5)

### Citations

**File:** crates/indexer/src/models/v2_objects.rs (L111-139)
```rust
    pub fn from_delete_resource(
        delete_resource: &DeleteResource,
        txn_version: i64,
        write_set_change_index: i64,
        object_mapping: &HashMap<CurrentObjectPK, CurrentObject>,
        conn: &mut PgPoolConnection,
    ) -> anyhow::Result<Option<(Self, CurrentObject)>> {
        if delete_resource.resource.to_string() == "0x1::object::ObjectGroup" {
            let resource = MoveResource::from_delete_resource(
                delete_resource,
                0, // Placeholder, this isn't used anyway
                txn_version,
                0, // Placeholder, this isn't used anyway
            );
            let previous_object = if let Some(object) = object_mapping.get(&resource.address) {
                object.clone()
            } else {
                match Self::get_object_owner(conn, &resource.address) {
                    Ok(owner) => owner,
                    Err(_) => {
                        aptos_logger::error!(
                            transaction_version = txn_version,
                            lookup_key = &resource.address,
                            "Missing object owner for object. You probably should backfill db.",
                        );
                        return Ok(None);
                    },
                }
            };
```

**File:** crates/indexer/src/models/v2_objects.rs (L166-167)
```rust
    /// This is actually not great because object owner can change. The best we can do now though
    fn get_object_owner(
```

**File:** crates/indexer/src/runtime.rs (L209-219)
```rust
    loop {
        let mut tasks = vec![];
        for _ in 0..processor_tasks {
            let other_tailer = tailer.clone();
            let task = tokio::spawn(async move { other_tailer.process_next_batch().await });
            tasks.push(task);
        }
        let batches = match futures::future::try_join_all(tasks).await {
            Ok(res) => res,
            Err(err) => panic!("Error processing transaction batches: {:?}", err),
        };
```

**File:** crates/indexer/src/processors/default_processor.rs (L444-469)
```rust
fn insert_current_objects(
    conn: &mut PgConnection,
    items_to_insert: &[CurrentObject],
) -> Result<(), diesel::result::Error> {
    use schema::current_objects::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), CurrentObject::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::current_objects::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict(object_address)
                .do_update()
                .set((
                    owner_address.eq(excluded(owner_address)),
                    state_key_hash.eq(excluded(state_key_hash)),
                    allow_ungated_transfer.eq(excluded(allow_ungated_transfer)),
                    last_guid_creation_num.eq(excluded(last_guid_creation_num)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    is_deleted.eq(excluded(is_deleted)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
                Some(" WHERE current_objects.last_transaction_version <= excluded.last_transaction_version "),
        )?;
    }
    Ok(())
```

**File:** crates/indexer/src/processors/default_processor.rs (L528-577)
```rust
        // TODO, merge this loop with above
        // Moving object handling here because we need a single object
        // map through transactions for lookups
        let mut all_objects = vec![];
        let mut all_current_objects = HashMap::new();
        for txn in &transactions {
            let (changes, txn_version) = match txn {
                Transaction::UserTransaction(user_txn) => (
                    user_txn.info.changes.clone(),
                    user_txn.info.version.0 as i64,
                ),
                Transaction::BlockMetadataTransaction(bmt_txn) => {
                    (bmt_txn.info.changes.clone(), bmt_txn.info.version.0 as i64)
                },
                _ => continue,
            };

            for (index, wsc) in changes.iter().enumerate() {
                let index = index as i64;
                match wsc {
                    WriteSetChange::WriteResource(inner) => {
                        if let Some((object, current_object)) =
                            &Object::from_write_resource(inner, txn_version, index).unwrap()
                        {
                            all_objects.push(object.clone());
                            all_current_objects
                                .insert(object.object_address.clone(), current_object.clone());
                        }
                    },
                    WriteSetChange::DeleteResource(inner) => {
                        // Passing all_current_objects into the function so that we can get the owner of the deleted
                        // resource if it was handled in the same batch
                        if let Some((object, current_object)) = Object::from_delete_resource(
                            inner,
                            txn_version,
                            index,
                            &all_current_objects,
                            &mut conn,
                        )
                        .unwrap()
                        {
                            all_objects.push(object.clone());
                            all_current_objects
                                .insert(object.object_address.clone(), current_object.clone());
                        }
                    },
                    _ => {},
                }
            }
        }
```

**File:** crates/indexer/src/models/token_models/v2_token_ownerships.rs (L274-306)
```rust
    /// This handles the case where token is burned and objectCore is deleted
    pub fn get_burned_nft_v2_from_delete_resource(
        write_resource: &DeleteResource,
        txn_version: i64,
        write_set_change_index: i64,
        txn_timestamp: chrono::NaiveDateTime,
        prior_nft_ownership: &HashMap<String, NFTOwnershipV2>,
        tokens_burned: &TokenV2Burned,
        conn: &mut PgPoolConnection,
    ) -> anyhow::Result<Option<(Self, CurrentTokenOwnershipV2)>> {
        if let Some(token_address) =
            tokens_burned.get(&standardize_address(&write_resource.address.to_string()))
        {
            let latest_nft_ownership: NFTOwnershipV2 = match prior_nft_ownership.get(token_address)
            {
                Some(inner) => inner.clone(),
                None => {
                    match CurrentTokenOwnershipV2Query::get_nft_by_token_data_id(
                        conn,
                        token_address,
                    ) {
                        Ok(nft) => nft,
                        Err(_) => {
                            aptos_logger::error!(
                                transaction_version = txn_version,
                                lookup_key = &token_address,
                                "Failed to find NFT for burned token. You probably should backfill db."
                            );
                            return Ok(None);
                        },
                    }
                },
            };
```
