# Audit Report

## Title
Configuration-Based Denial of Service: Zero-Capacity BoundedExecutor Blocks Mempool Operations

## Summary
The `shared_mempool_max_concurrent_inbound_syncs` configuration parameter in `MempoolConfig` can be set to 0, creating a zero-capacity `BoundedExecutor` that permanently blocks all inbound mempool synchronization, client transaction submissions, and reconfig event processing, rendering the node non-functional.

## Finding Description

The `shared_mempool_max_concurrent_inbound_syncs` field controls the concurrency limit for mempool's inbound message processing. [1](#0-0) 

This field has no validation preventing it from being set to 0. The `ConfigSanitizer::sanitize()` implementation is empty with only a TODO comment. [2](#0-1) 

When mempool's coordinator initializes, it creates a `BoundedExecutor` using this value. [3](#0-2) 

The `BoundedExecutor` uses a semaphore initialized with the capacity value. [4](#0-3) 

When spawning tasks, `BoundedExecutor::spawn()` calls `acquire_permit()` which blocks until a permit is available. [5](#0-4) 

With zero capacity, `acquire_permit().await` blocks forever since no permits exist. This affects:

1. **Inbound transaction broadcasts from peers** - blocked when processing network events [6](#0-5) 

2. **Client transaction submissions** - blocked when handling API requests [7](#0-6) 

3. **Reconfig events** - blocked when processing on-chain config updates [8](#0-7) 

4. **Transaction lookups by hash** - blocked for API queries [9](#0-8) 

Critically, consensus transaction pulls via `QuorumStoreRequest` are NOT affected since they're handled directly in the coordinator loop without using the bounded executor. [10](#0-9) 

## Impact Explanation

**High Severity** - This causes significant protocol violations and API crashes:

- **For Validators**: Can still propose blocks via consensus pulling from mempool, but cannot receive new transactions from peers or APIs. If mempool becomes empty, the validator can only propose empty blocks, severely degrading network throughput.

- **For Fullnodes (FN/PFN)**: Complete API failure - cannot accept client transaction submissions. Cannot receive transaction broadcasts from peers. The node becomes non-functional for its primary purpose of serving API requests and relaying transactions.

- **For Validator Fullnodes (VFN)**: Cannot receive transactions from connected PFNs or accept API submissions, isolating the VFN from both the public network and failing to serve its validator.

This meets the "High Severity" criteria from the Aptos bug bounty: "API crashes" and "Significant protocol violations."

## Likelihood Explanation

**Likelihood: Low to Medium**

This vulnerability requires local file system access to modify the node's YAML configuration file, meaning:
- **Node operator error**: Accidentally setting the value to 0 during configuration
- **Malicious node operator**: Intentionally sabotaging their own node
- **Compromised node**: Attacker with file system access modifying configs

While this requires privileged access and only affects the misconfigured node (not the network), the lack of validation makes accidental misconfiguration highly plausible. The default value is 4, and validator fullnodes optimize to 16, but nothing prevents 0.

## Recommendation

Add validation in `MempoolConfig::sanitize()` to enforce a minimum value of 1:

```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // Validate shared_mempool_max_concurrent_inbound_syncs
        if node_config.mempool.shared_mempool_max_concurrent_inbound_syncs == 0 {
            return Err(Error::ConfigValidationError(
                "shared_mempool_max_concurrent_inbound_syncs must be at least 1".to_string()
            ));
        }
        Ok(())
    }
}
```

Additionally, consider adding validation for other critical mempool parameters that could cause similar issues if set to inappropriate values.

## Proof of Concept

Create a minimal node config YAML with `shared_mempool_max_concurrent_inbound_syncs: 0`:

```yaml
base:
  role: "full_node"
  waypoint:
    from_config: "0:0000000000000000000000000000000000000000000000000000000000000000"

execution:
  genesis_file_location: "genesis.blob"

full_node_networks:
  - network_id: "public"
    listen_address: "/ip4/0.0.0.0/tcp/6180"

mempool:
  shared_mempool_max_concurrent_inbound_syncs: 0  # Trigger vulnerability

storage:
  dir: "./data"
  enable_indexer: false
```

**Steps to reproduce:**
1. Create a fullnode with the above configuration
2. Start the node - it will initialize successfully
3. Attempt to submit a transaction via API - the request will hang indefinitely
4. Monitor mempool metrics - inbound sync tasks will never complete
5. Check logs - no transaction processing will occur despite network connectivity

**Expected behavior:** Node should reject the configuration during initialization with a validation error.

**Actual behavior:** Node starts but becomes completely unresponsive to API requests and peer broadcasts.

**Notes**

While this vulnerability requires local configuration file access (limiting the attack surface to node operators or compromised nodes), it represents a significant footgun in the codebase. The empty `sanitize()` implementation with a TODO comment indicates this validation gap was recognized but never addressed. Given that misconfiguration can completely disable a node's mempool functionality, this should be treated as a High severity configuration validation issue requiring immediate remediation through enforcement of minimum values.

### Citations

**File:** config/src/config/mempool_config.rs (L68-69)
```rust
    /// Maximum Mempool inbound message workers.  Controls concurrency of Mempool consumption.
    pub shared_mempool_max_concurrent_inbound_syncs: usize,
```

**File:** config/src/config/mempool_config.rs (L176-184)
```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        Ok(()) // TODO: add reasonable verifications
    }
}
```

**File:** mempool/src/shared_mempool/coordinator.rs (L90-93)
```rust
    // Use a BoundedExecutor to restrict only `workers_available` concurrent
    // worker tasks that can process incoming transactions.
    let workers_available = smp.config.shared_mempool_max_concurrent_inbound_syncs;
    let bounded_executor = BoundedExecutor::new(workers_available, executor.clone());
```

**File:** mempool/src/shared_mempool/coordinator.rs (L112-114)
```rust
            msg = quorum_store_requests.select_next_some() => {
                tasks::process_quorum_store_request(&smp, msg);
            },
```

**File:** mempool/src/shared_mempool/coordinator.rs (L189-196)
```rust
            bounded_executor
                .spawn(tasks::process_client_transaction_submission(
                    smp.clone(),
                    txn,
                    callback,
                    task_start_timer,
                ))
                .await;
```

**File:** mempool/src/shared_mempool/coordinator.rs (L210-217)
```rust
            bounded_executor
                .spawn(tasks::process_client_get_transaction(
                    smp.clone(),
                    hash,
                    callback,
                    task_start_timer,
                ))
                .await;
```

**File:** mempool/src/shared_mempool/coordinator.rs (L284-290)
```rust
    bounded_executor
        .spawn(tasks::process_config_update(
            config_update,
            smp.validator.clone(),
            smp.broadcast_within_validator_network.clone(),
        ))
        .await;
```

**File:** mempool/src/shared_mempool/coordinator.rs (L332-341)
```rust
    bounded_executor
        .spawn(tasks::process_transaction_broadcast(
            smp_clone,
            transactions,
            message_id,
            timeline_state,
            peer,
            task_start_timer,
        ))
        .await;
```

**File:** crates/bounded-executor/src/executor.rs (L22-31)
```rust
impl BoundedExecutor {
    /// Create a new `BoundedExecutor` from an existing tokio [`Handle`]
    /// with a maximum concurrent task capacity of `capacity`.
    pub fn new(capacity: usize, executor: Handle) -> Self {
        let semaphore = Arc::new(Semaphore::new(capacity));
        Self {
            semaphore,
            executor,
        }
    }
```

**File:** crates/bounded-executor/src/executor.rs (L33-52)
```rust
    async fn acquire_permit(&self) -> OwnedSemaphorePermit {
        self.semaphore.clone().acquire_owned().await.unwrap()
    }

    fn try_acquire_permit(&self) -> Option<OwnedSemaphorePermit> {
        self.semaphore.clone().try_acquire_owned().ok()
    }

    /// Spawn a [`Future`] on the `BoundedExecutor`. This function is async and
    /// will block if the executor is at capacity until one of the other spawned
    /// futures completes. This function returns a [`JoinHandle`] that the caller
    /// can `.await` on for the results of the [`Future`].
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor.spawn(future_with_permit(future, permit))
    }
```
