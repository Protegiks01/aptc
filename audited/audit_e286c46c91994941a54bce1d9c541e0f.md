# Audit Report

## Title
Database Inconsistency from Non-Atomic Truncation Across Metadata and Shard Databases

## Summary
The `truncate_state_merkle_db` operation commits deletions to the metadata database separately from shard databases, creating a window where `StaleNodeIndexCrossEpochSchema` entries can be deleted from metadata but remain in shards if a validator crashes mid-operation. While automatic recovery exists, repeated crashes can require manual intervention to restore consistency.

## Finding Description

The truncation process in `truncate_state_merkle_db` performs non-atomic writes across multiple databases: [1](#0-0) 

The critical issue is at lines 174-176:
1. Line 174: Commits deletions to metadata DB atomically
2. Line 176: Commits deletions to shard DBs in parallel (separate atomic operations per shard)

This breaks the **State Consistency** invariant that "state transitions must be atomic." If a crash occurs after line 174 but before line 176 completes, the system enters an inconsistent state where:

- Metadata DB: `StaleNodeIndexCrossEpochSchema` entries at version > target deleted, progress updated
- Shard DBs: `StaleNodeIndexCrossEpochSchema` entries at version > target still present, progress not updated
- Different shards may be in different states if crash occurs mid-parallel execution [2](#0-1) 

The truncation loop completion check only examines the metadata DB: [3](#0-2) 

While automatic recovery exists via `sync_commit_progress`: [4](#0-3) 

The recovery mechanism itself calls `truncate_state_merkle_db` which can be interrupted again, creating potential for persistent inconsistency across restart cycles.

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Impacts:**

1. **Merkle Tree Integrity**: Shard DBs contain nodes that should not exist, potentially breaking merkle proof verification
2. **State Sync Issues**: Nodes querying state during inconsistency window may receive inconsistent data
3. **Storage Bloat**: Orphaned entries in shard DBs that metadata DB believes are deleted
4. **Progress Marker Desynchronization**: Different progress values across metadata and shards

The test validation confirms all shards should have consistent state post-truncation: [5](#0-4) 

## Likelihood Explanation

**Likelihood: Medium-Low**

Requires:
- Validator crash during active truncation operation (narrow time window)
- Truncation in progress (triggered by db_debugger tool or sync_commit_progress on startup)

Exacerbated by:
- Long-running truncations on large databases (wider time window)
- Systems with stability issues causing repeated crashes
- Hardware failures during database operations

While automatic recovery exists, repeated crashes during recovery can prevent convergence to consistent state, requiring manual intervention.

## Recommendation

Implement atomic truncation across all databases using a write-ahead log or two-phase commit protocol:

```rust
pub(crate) fn truncate_state_merkle_db(
    state_merkle_db: &StateMerkleDb,
    target_version: Version,
) -> Result<()> {
    loop {
        let current_version = get_current_version_in_state_merkle_db(state_merkle_db)?
            .expect("Current version of state merkle db must exist.");
        if current_version == target_version {
            break;
        }

        let version_before = find_closest_node_version_at_or_before(
            state_merkle_db.metadata_db(),
            current_version - 1,
        )?
        .expect("Must exist.");

        // ATOMIC COMMIT: Prepare batches for all DBs
        let mut top_levels_batch = SchemaBatch::new();
        delete_nodes_and_stale_indices_at_or_after_version(
            state_merkle_db.metadata_db(),
            current_version,
            None,
            &mut top_levels_batch,
        )?;

        let mut shard_batches = Vec::new();
        for shard_id in 0..state_merkle_db.hack_num_real_shards() {
            let mut batch = SchemaBatch::new();
            delete_nodes_and_stale_indices_at_or_after_version(
                state_merkle_db.db_shard(shard_id),
                version_before + 1,
                Some(shard_id),
                &mut batch,
            )?;
            shard_batches.push(batch);
        }

        // Write intent log before commits
        write_truncation_intent_log(version_before)?;
        
        // Commit all shards first
        for (shard_id, batch) in shard_batches.into_iter().enumerate() {
            state_merkle_db.db_shard(shard_id).write_schemas(batch)?;
        }
        
        // Commit metadata last (acts as commit point)
        state_merkle_db.commit_top_levels(version_before, top_levels_batch)?;
        
        // Clear intent log on success
        clear_truncation_intent_log()?;
    }

    Ok(())
}
```

Additionally, add consistency checks in `sync_commit_progress` to validate all shards match metadata state before declaring truncation complete.

## Proof of Concept

```rust
#[test]
fn test_truncation_crash_inconsistency() {
    use aptos_temppath::TempPath;
    use aptos_config::config::DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD;
    
    let tmp_dir = TempPath::new();
    let db = AptosDB::new_for_test_with_sharding(&tmp_dir, DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD);
    
    // Commit test data up to version 100
    let mut version = 0;
    for i in 0..10 {
        let (txns, li) = generate_test_block(i);
        db.save_transactions_for_test(&txns, version, Some(&li), true).unwrap();
        version += txns.len() as u64;
    }
    
    drop(db);
    
    // Simulate crash during truncation by manually:
    // 1. Opening DBs
    // 2. Deleting from metadata DB only
    // 3. NOT deleting from shard DBs
    // 4. Closing DBs
    
    let (ledger_db, _, state_merkle_db, state_kv_db) = AptosDB::open_dbs(
        &StorageDirPaths::from_path(&tmp_dir),
        RocksdbConfigs { enable_storage_sharding: true, ..Default::default() },
        None, None, false, 0, true,
    ).unwrap();
    
    // Delete from metadata DB only (simulating interrupted truncation)
    let mut batch = SchemaBatch::new();
    delete_stale_node_index_at_or_after_version::<StaleNodeIndexCrossEpochSchema>(
        state_merkle_db.metadata_db(), 51, &mut batch
    ).unwrap();
    state_merkle_db.metadata_db().write_schemas(batch).unwrap();
    
    // Verify inconsistency: metadata has no entries >= 51, but shards do
    let metadata_count = count_schema_entries::<StaleNodeIndexCrossEpochSchema>(
        state_merkle_db.metadata_db(), 51
    );
    let shard_count = count_schema_entries::<StaleNodeIndexCrossEpochSchema>(
        state_merkle_db.db_shard(0), 51
    );
    
    assert_eq!(metadata_count, 0, "Metadata should have no entries >= 51");
    assert!(shard_count > 0, "Shards should still have entries >= 51");
    
    println!("INCONSISTENCY DEMONSTRATED: Metadata={}, Shard0={}", 
             metadata_count, shard_count);
}
```

**Notes:**
This vulnerability represents an operational resilience issue rather than an active attack vector, as it requires validator crashes during specific database operations. However, it violates the atomic state transition invariant and can require manual intervention in scenarios with repeated crashes, qualifying as a state inconsistency requiring intervention per the Medium severity criteria.

### Citations

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L144-180)
```rust
pub(crate) fn truncate_state_merkle_db(
    state_merkle_db: &StateMerkleDb,
    target_version: Version,
) -> Result<()> {
    let status = StatusLine::new(Progress::new("Truncating State Merkle DB.", target_version));

    loop {
        let current_version = get_current_version_in_state_merkle_db(state_merkle_db)?
            .expect("Current version of state merkle db must exist.");
        status.set_current_version(current_version);
        assert_ge!(current_version, target_version);
        if current_version == target_version {
            break;
        }

        let version_before = find_closest_node_version_at_or_before(
            state_merkle_db.metadata_db(),
            current_version - 1,
        )?
        .expect("Must exist.");

        let mut top_levels_batch = SchemaBatch::new();

        delete_nodes_and_stale_indices_at_or_after_version(
            state_merkle_db.metadata_db(),
            current_version,
            None, // shard_id
            &mut top_levels_batch,
        )?;

        state_merkle_db.commit_top_levels(version_before, top_levels_batch)?;

        truncate_state_merkle_db_shards(state_merkle_db, version_before)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L182-206)
```rust
pub(crate) fn truncate_state_merkle_db_shards(
    state_merkle_db: &StateMerkleDb,
    target_version: Version,
) -> Result<()> {
    (0..state_merkle_db.hack_num_real_shards())
        .into_par_iter()
        .try_for_each(|shard_id| {
            truncate_state_merkle_db_single_shard(state_merkle_db, shard_id, target_version)
        })
}

pub(crate) fn truncate_state_merkle_db_single_shard(
    state_merkle_db: &StateMerkleDb,
    shard_id: usize,
    target_version: Version,
) -> Result<()> {
    let mut batch = SchemaBatch::new();
    delete_nodes_and_stale_indices_at_or_after_version(
        state_merkle_db.db_shard(shard_id),
        target_version + 1,
        Some(shard_id),
        &mut batch,
    )?;
    state_merkle_db.db_shard(shard_id).write_schemas(batch)
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L257-261)
```rust
pub(crate) fn get_current_version_in_state_merkle_db(
    state_merkle_db: &StateMerkleDb,
) -> Result<Option<Version>> {
    find_closest_node_version_at_or_before(state_merkle_db.metadata_db(), Version::MAX)
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L384-389)
```rust
                    let mut cross_iter = state_merkle_db.db_shard(i).iter::<StaleNodeIndexCrossEpochSchema>().unwrap();
                    cross_iter.seek_to_first();
                    for item in cross_iter {
                        let version = item.unwrap().0.stale_since_version;
                        prop_assert!(version <= target_version);
                    }
```
