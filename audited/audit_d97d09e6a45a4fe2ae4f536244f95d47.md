# Audit Report

## Title
Unbounded Channel Buffer Size in Indexer GRPC Data Service v2 Enables Memory Exhaustion

## Summary
The `data_service_response_channel_size` configuration parameter in the indexer-grpc-data-service-v2 lacks validation against maximum limits, allowing operators to configure arbitrarily large values (including `usize::MAX`). This can cause memory exhaustion and service unavailability when transaction response messages accumulate in the channel buffer.

## Finding Description

The `IndexerGrpcDataServiceConfig` struct defines a `data_service_response_channel_size` field with a default value of 5, but provides no validation to prevent extremely large values: [1](#0-0) 

The configuration struct implements the `RunnableConfig` trait but does NOT override the `validate()` method, relying on the default implementation which performs no validation: [2](#0-1) 

The framework calls `validate()` during service startup: [3](#0-2) 

But the default `validate()` implementation in the `RunnableConfig` trait simply returns `Ok(())`: [4](#0-3) 

The unvalidated `data_service_response_channel_size` value is then passed directly to the `DataServiceWrapper` constructor: [5](#0-4) 

Finally, this value is used without any bounds checking to create a tokio mpsc channel in the `get_transactions()` method: [6](#0-5) 

**Attack Scenario:**

1. An operator accidentally sets `data_service_response_channel_size: 18446744073709551615` (usize::MAX on 64-bit systems) in the YAML configuration file due to a typo or copy-paste error
2. Alternatively, an attacker who compromises configuration management systems modifies this value
3. The service starts successfully without validation errors
4. Multiple clients connect and request transaction streams via `get_transactions()`
5. Each client connection creates a channel with usize::MAX buffer capacity
6. If receivers are slow or disconnect while the sender continues producing `TransactionsResponse` messages, these messages accumulate in memory
7. With normal buffer size (5), back-pressure occurs quickly, limiting memory usage
8. With usize::MAX capacity, millions of messages can buffer before blocking, each potentially containing large transaction payloads
9. Memory consumption grows unbounded until the system runs out of memory (OOM)
10. The service crashes or becomes unresponsive, causing denial of service

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program:

- **Medium Severity criteria**: "State inconsistencies requiring intervention"
- The indexer-grpc-data-service-v2 is an infrastructure component that provides transaction data streaming to clients (indexers, analytics services)
- Service unavailability disrupts the broader Aptos ecosystem's ability to index and query blockchain data
- Recovery requires operator intervention to fix the configuration and restart the service
- While not consensus-critical, the indexer service is essential for ecosystem functionality

The vulnerability enables:
- Memory exhaustion leading to Out-of-Memory (OOM) kills
- Service crashes and unavailability
- Denial of service for all indexer clients
- Potential cascading failures if multiple services depend on the indexer

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability is realistic because:

1. **Configuration errors are common**: Operators frequently make typos or copy incorrect values from documentation or examples
2. **No validation feedback**: The service accepts any usize value without warnings or errors during startup
3. **Non-obvious impact**: Operators may not realize the memory implications of setting large buffer sizes
4. **Configuration drift**: Automated configuration management tools or scripts might generate incorrect values

The security question specifically mentions "configuration errors/attacks", acknowledging that:
- Human errors in configuration are expected and should be defended against
- Configuration files may be targets for attackers who gain access to deployment systems
- Input validation is a fundamental security practice regardless of trust boundaries

While configuration file access requires elevated privileges, the lack of validation violates defense-in-depth principles and fails to protect operators from their own mistakes.

## Recommendation

Add explicit validation to the `IndexerGrpcDataServiceConfig::validate()` method to enforce reasonable maximum limits on `data_service_response_channel_size`:

```rust
impl RunnableConfig for IndexerGrpcDataServiceConfig {
    fn validate(&self) -> Result<()> {
        const MAX_RESPONSE_CHANNEL_SIZE: usize = 10_000;
        
        if self.data_service_response_channel_size > MAX_RESPONSE_CHANNEL_SIZE {
            bail!(
                "data_service_response_channel_size ({}) exceeds maximum allowed value ({})",
                self.data_service_response_channel_size,
                MAX_RESPONSE_CHANNEL_SIZE
            );
        }
        
        if self.data_service_response_channel_size == 0 {
            bail!("data_service_response_channel_size must be greater than 0");
        }
        
        Ok(())
    }
    
    // ... rest of implementation
}
```

The maximum value should be chosen based on:
- Expected transaction response message sizes
- Available memory per service instance  
- Number of concurrent client connections
- Typical operating parameters

A value of 10,000 provides generous buffering (2,000x the default) while preventing catastrophic memory exhaustion.

## Proof of Concept

Create a malicious configuration file `malicious_config.yaml`:

```yaml
health_check_port: 8084
server_config:
  chain_id: 1
  service_config:
    listen_address: "0.0.0.0:50051"
  live_data_service_config:
    enabled: true
    num_slots: 5000000
    size_limit_bytes: 10000000000
  historical_data_service_config:
    enabled: false
    file_store_config:
      file_store_type: LocalFileStore
      local_file_store_path: /tmp/test
  grpc_manager_addresses: []
  self_advertised_address: "0.0.0.0:50051"
  data_service_response_channel_size: 18446744073709551615  # usize::MAX
```

**Steps to reproduce:**

1. Build the indexer-grpc-data-service-v2:
```bash
cd ecosystem/indexer-grpc/indexer-grpc-data-service-v2
cargo build --release
```

2. Run with malicious config:
```bash
./target/release/indexer-grpc-data-service-v2 -c malicious_config.yaml
```

3. Observe that the service starts without validation errors

4. Connect multiple clients and stream transactions:
```bash
grpcurl -plaintext -d '{"starting_version": 0}' \
  localhost:50051 aptos.indexer.v1.RawData/GetTransactions
```

5. Monitor memory usage as messages accumulate in the oversized channel buffers

**Expected behavior:** Service should reject the configuration with a clear error message about the invalid `data_service_response_channel_size` value.

**Actual behavior:** Service accepts the configuration and creates channels with usize::MAX capacity, enabling unbounded memory growth and eventual OOM.

## Notes

- The v1 indexer-grpc-data-service has the same vulnerability pattern (DEFAULT_MAX_RESPONSE_CHANNEL_SIZE = 3, no validation)
- Other channel buffer sizes in the Aptos codebase typically use small values (1-1024) with careful consideration
- The framework provides the `validate()` mechanism specifically to prevent such configuration errors
- Similar validation should be added for other resource-related configuration parameters

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L94-95)
```rust
    #[serde(default = "IndexerGrpcDataServiceConfig::default_data_service_response_channel_size")]
    pub data_service_response_channel_size: usize,
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L124-129)
```rust
        let service = DataServiceWrapper::new(
            connection_manager.clone(),
            handler_tx,
            self.data_service_response_channel_size,
            /*is_live_data_service=*/ true,
        );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L208-292)
```rust
#[async_trait::async_trait]
impl RunnableConfig for IndexerGrpcDataServiceConfig {
    async fn run(&self) -> Result<()> {
        let reflection_service = tonic_reflection::server::Builder::configure()
            // Note: It is critical that the file descriptor set is registered for every
            // file that the top level API proto depends on recursively. If you don't,
            // compilation will still succeed but reflection will fail at runtime.
            //
            // TODO: Add a test for this / something in build.rs, this is a big footgun.
            .register_encoded_file_descriptor_set(INDEXER_V1_FILE_DESCRIPTOR_SET)
            .register_encoded_file_descriptor_set(TRANSACTION_V1_TESTING_FILE_DESCRIPTOR_SET)
            .register_encoded_file_descriptor_set(UTIL_TIMESTAMP_FILE_DESCRIPTOR_SET)
            .build_v1alpha()
            .map_err(|e| anyhow::anyhow!("Failed to build reflection service: {}", e))?
            .send_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Gzip);

        let mut tasks = vec![];

        let live_data_service = self.create_live_data_service(&mut tasks).await;
        let historical_data_service = self.create_historical_data_service(&mut tasks).await;

        let wrapper = Arc::new(DataServiceWrapperWrapper::new(
            live_data_service,
            historical_data_service,
        ));
        let wrapper_service_raw =
            aptos_protos::indexer::v1::raw_data_server::RawDataServer::from_arc(wrapper.clone())
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
        let wrapper_service =
            aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);

        let listen_address = self.service_config.listen_address;
        let mut server_builder = Server::builder()
            .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
            .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION));
        if let Some(config) = &self.service_config.tls_config {
            let cert = tokio::fs::read(config.cert_path.clone()).await?;
            let key = tokio::fs::read(config.key_path.clone()).await?;
            let identity = tonic::transport::Identity::from_pem(cert, key);
            server_builder = server_builder
                .tls_config(tonic::transport::ServerTlsConfig::new().identity(identity))?;
            info!(
                grpc_address = listen_address.to_string().as_str(),
                "[Data Service] Starting gRPC server with TLS."
            );
        } else {
            info!(
                grpc_address = listen_address.to_string().as_str(),
                "[data service] starting gRPC server with non-TLS."
            );
        }

        tasks.push(tokio::spawn(async move {
            server_builder
                .add_service(wrapper_service)
                .add_service(wrapper_service_raw)
                .add_service(reflection_service)
                .serve(listen_address)
                .await
                .map_err(|e| anyhow::anyhow!(e))
        }));

        futures::future::try_join_all(tasks).await?;
        Ok(())
    }

    fn get_server_name(&self) -> String {
        "indexer_grpc_data_service_v2".to_string()
    }

    async fn status_page(&self) -> Result<Response, Rejection> {
        crate::status_page::status_page()
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L38-42)
```rust
        let config = load::<GenericConfig<C>>(&self.config_path)?;
        config
            .validate()
            .context("Config did not pass validation")?;
        run_server_with_config(config).await
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L114-116)
```rust
    fn validate(&self) -> Result<()> {
        Ok(())
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L138-148)
```rust
    async fn get_transactions(
        &self,
        req: Request<GetTransactionsRequest>,
    ) -> Result<Response<Self::GetTransactionsStream>, Status> {
        let (tx, rx) = channel(self.data_service_response_channel_size);
        self.handler_tx.send((req, tx)).await.unwrap();

        let output_stream = ReceiverStream::new(rx);
        let response = Response::new(Box::pin(output_stream) as Self::GetTransactionsStream);

        Ok(response)
```
