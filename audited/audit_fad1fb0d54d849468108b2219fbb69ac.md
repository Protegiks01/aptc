# Audit Report

## Title
Configuration Validation Bypass: Unchecked `window_for_chain_health` Causes Validator Node Panic and Consensus Halt

## Summary
The `window_for_chain_health` configuration parameter lacks validation in the config sanitizer, allowing operators to set invalid values that trigger a panic during consensus operations, causing complete validator node halt. The code explicitly documents that this value "must match one of the CHAIN_HEALTH_WINDOW_SIZES values" but provides no enforcement mechanism.

## Finding Description

The vulnerability exists in the interaction between the configuration system and the leader reputation module:

**1. Missing Validation:** The `ConsensusConfig::sanitize()` function validates various configuration parameters but completely omits validation for `window_for_chain_health`. [1](#0-0) 

**2. Hardcoded Allowed Values:** The allowed window sizes are hardcoded as a static array `[10, 30, 100, 300]`: [2](#0-1) 

**3. Documentation Without Enforcement:** The config struct includes a comment warning that the value must match allowed sizes, but this is purely documentary: [3](#0-2) 

**4. Panic on Mismatch:** During consensus operation, when `LeaderReputation::compute_chain_health_and_add_metrics()` is called, it searches for `window_for_chain_health` in the predefined sizes. If not found, it panics: [4](#0-3) 

**5. Critical Path Trigger:** This function is invoked on every round through `get_valid_proposer()`, which is called in multiple critical consensus paths: [5](#0-4) 

**Exploitation Path:**
1. Operator modifies `consensus.window_for_chain_health` in node config to an invalid value (e.g., 50, 200, or any value not in [10, 30, 100, 300])
2. Node starts successfully (config passes sanitization without validation)
3. `EpochManager` creates `LeaderReputation` with the misconfigured value: [6](#0-5) 

4. On first consensus round, `RoundManager` calls `get_valid_proposer()`
5. Panic occurs in `compute_chain_health_and_add_metrics()`
6. Validator node crashes and cannot participate in consensus

## Impact Explanation

**Severity: HIGH**

This meets the High severity criteria per Aptos bug bounty rules:
- **"Validator node slowdowns"** - More severe: complete validator node halt/crash
- **"API crashes"** - The panic causes the consensus module to crash

**Impact Scope:**
- Affected validators cannot propose blocks or vote
- Node requires restart with fixed configuration
- If multiple validators misconfigure (e.g., copy-paste config from documentation with typo), network liveness could be impacted
- No fund loss, but availability/liveness violation

**Why Not Critical:** Requires operator configuration error, not exploitable by external attackers without node access. Does not violate consensus safety (Byzantine agreement), only liveness for misconfigured nodes.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

**Factors Increasing Likelihood:**
1. **Easy to Misconfigure:** Simple typo (e.g., 100 → 1000) triggers the bug
2. **No Validation Feedback:** Operator receives no error during config loading
3. **Delayed Failure:** Node starts successfully; crash only occurs when consensus begins
4. **Documentation Gap:** Comment warns but provides no machine-readable constraint
5. **Copy-Paste Errors:** Operators sharing configs may propagate invalid values

**Factors Decreasing Likelihood:**
1. **Default is Valid:** Default value (100) is correct
2. **Operator Access Required:** External attackers cannot modify validator configs
3. **Single Point of Misconfiguration:** Only affects nodes with invalid config

**Real-World Scenario:** Operator adjusting performance, sees the window config, thinks "100 is too small, let's use 200 for better history" → node crashes on startup of consensus.

## Recommendation

**Add Configuration Validation:**

Add validation in `ConsensusConfig::sanitize()` to enforce the constraint:

```rust
impl ConfigSanitizer for ConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        
        // ... existing validations ...
        
        // Validate window_for_chain_health matches allowed values
        if !CHAIN_HEALTH_WINDOW_SIZES.contains(&node_config.consensus.window_for_chain_health) {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "window_for_chain_health must be one of {:?}, got {}",
                    CHAIN_HEALTH_WINDOW_SIZES,
                    node_config.consensus.window_for_chain_health
                ),
            ));
        }
        
        Ok(())
    }
}
```

**Alternative/Additional Mitigations:**
1. Replace panic with error logging and default to nearest valid window size
2. Make `CHAIN_HEALTH_WINDOW_SIZES` configurable or remove the constraint
3. Add unit test verifying sanitizer catches invalid values

## Proof of Concept

**Step 1:** Create a test node configuration with invalid `window_for_chain_health`:

```yaml
# node_config.yaml
consensus:
  window_for_chain_health: 50  # Invalid: not in [10, 30, 100, 300]
  # ... other configs ...
```

**Step 2:** Start validator node with this configuration:
- Config sanitization will PASS (no validation implemented)
- Node will start successfully

**Step 3:** When consensus begins (first epoch, first round):
- `EpochManager` creates `LeaderReputation` with `window_for_chain_health=50`
- `RoundManager::process_new_round_event()` calls `proposer_election.get_valid_proposer()`
- Inside `LeaderReputation::compute_chain_health_and_add_metrics()`, loop at line 613 iterates through `[10, 30, 100, 300]`
- None match `50`, so `result` remains `None`
- Line 686: `result.unwrap_or_else(|| panic!(...))` executes
- **Node crashes with panic message:** `"asked window size 50 not found in predefined window sizes: [10, 30, 100, 300]"`

**Expected Result:** Validator node immediately panics upon entering consensus, cannot participate in the network.

**Verification:** This can be tested by modifying the consensus config in any Aptos testnet node setup and observing the panic in logs during consensus initialization.

---

**Notes:**

While this vulnerability requires operator configuration access (not exploitable by external attackers), it represents a **defense-in-depth failure**. The explicit documentation stating the value "must match" combined with the complete absence of validation creates a significant operational risk. The severity is justified by the immediate and complete loss of validator node availability upon misconfiguration, meeting the High severity criteria for "API crashes" and "Validator node slowdowns" in the Aptos bug bounty program.

### Citations

**File:** config/src/config/consensus_config.rs (L83-85)
```rust
    // Used to decide if backoff is needed.
    // must match one of the CHAIN_HEALTH_WINDOW_SIZES values.
    pub window_for_chain_health: usize,
```

**File:** config/src/config/consensus_config.rs (L503-532)
```rust
impl ConfigSanitizer for ConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Verify that the safety rules and quorum store configs are valid
        SafetyRulesConfig::sanitize(node_config, node_type, chain_id)?;
        QuorumStoreConfig::sanitize(node_config, node_type, chain_id)?;

        // Verify that the consensus-only feature is not enabled in mainnet
        if let Some(chain_id) = chain_id {
            if chain_id.is_mainnet() && is_consensus_only_perf_test_enabled() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "consensus-only-perf-test should not be enabled in mainnet!".to_string(),
                ));
            }
        }

        // Sender block limits must be <= receiver block limits
        Self::sanitize_send_recv_block_limits(&sanitizer_name, &node_config.consensus)?;

        // Quorum store batches must be <= consensus blocks
        Self::sanitize_batch_block_limits(&sanitizer_name, &node_config.consensus)?;

        Ok(())
    }
```

**File:** consensus/src/counters.rs (L460-461)
```rust
/// Window sizes for which to measure chain health.
pub static CHAIN_HEALTH_WINDOW_SIZES: [usize; 4] = [10, 30, 100, 300];
```

**File:** consensus/src/liveness/leader_reputation.rs (L686-691)
```rust
        result.unwrap_or_else(|| {
            panic!(
                "asked window size {} not found in predefined window sizes: {:?}",
                self.window_for_chain_health, CHAIN_HEALTH_WINDOW_SIZES
            )
        })
```

**File:** consensus/src/round_manager.rs (L428-430)
```rust
        let prev_proposer = self
            .proposer_election
            .get_valid_proposer(new_round.saturating_sub(1));
```

**File:** consensus/src/epoch_manager.rs (L378-387)
```rust
                let proposer_election = Box::new(LeaderReputation::new(
                    epoch_state.epoch,
                    epoch_to_proposers,
                    voting_powers,
                    backend,
                    heuristic,
                    onchain_config.leader_reputation_exclude_round(),
                    leader_reputation_type.use_root_hash_for_seed(),
                    self.config.window_for_chain_health,
                ));
```
