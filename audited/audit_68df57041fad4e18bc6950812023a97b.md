# Audit Report

## Title
Non-Atomic Database Operations Can Create Orphaned Index Entries in Internal Indexer

## Summary
When the internal indexer is enabled, transaction pruning involves two separate, non-atomic database write operations that can leave the system in an inconsistent state. A failure or crash between these operations can cause the API to return references to non-existent transactions, violating state consistency guarantees.

## Finding Description

The `OrderedTransactionByAccountSchema` index maps `(account_address, sequence_number)` to transaction versions, enabling account-based transaction lookups. [1](#0-0) 

When DB sharding is enabled, the system maintains TWO separate databases:
1. **Main Ledger DB**: Stores actual transactions
2. **Internal Indexer DB**: Stores the `OrderedTransactionByAccountSchema` indices

The API conditionally queries these databases based on configuration: [2](#0-1) 

During transaction pruning, the `TransactionPruner` performs deletions on both databases in **separate, non-atomic operations**: [3](#0-2) 

**Critical Issue**: Lines 67 and 73 are separate `write_schemas()` calls to different databases. Each call is atomic within its own database but **not atomic with respect to each other**.

**Vulnerability Scenario:**
If a crash, disk failure, or error occurs after line 67 commits but before line 73 executes:
- Internal indexer DB successfully deletes index entries and updates progress (line 63-67)
- Main ledger DB retains transactions because line 73 never executes
- On restart, the indexer DB shows pruning completed (progress updated)
- The ledger DB will eventually prune these transactions on its next pruning cycle

However, the **reverse scenario** is more problematic:
If line 67 fails (e.g., indexer DB unavailable) but error handling is imperfect:
- Index entries remain in internal indexer DB  
- Transactions get deleted from main ledger DB (line 73)
- API queries return version numbers from stale indices
- `get_transaction_by_version()` returns `NotFound` errors [4](#0-3) 

When the indexer returns a version number, it's used to fetch the actual transaction from the main DB: [5](#0-4) 

If the transaction was pruned but the index entry remains, line 1085 will fail with `NotFound`, propagating an error to API consumers.

## Impact Explanation

**Severity: Medium**

This issue causes **state inconsistencies requiring intervention**, meeting the Medium severity criteria. Specifically:

1. **API Failures**: Users receive `NotFound` errors when querying transactions that should exist according to the index
2. **Data Integrity**: Violates the fundamental invariant that indices accurately reflect available data
3. **Service Degradation**: Account-based transaction queries become unreliable
4. **Manual Intervention Required**: Database inconsistencies require manual reconciliation or re-indexing

While this doesn't cause fund loss or consensus violations, it creates a verifiable state inconsistency that degrades service quality and requires operational intervention to resolve.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can occur through several realistic scenarios:

1. **Hardware Failures**: Disk errors during the write to either database
2. **Process Crashes**: Node crashes between the two write operations  
3. **Resource Exhaustion**: One database runs out of space while the other succeeds
4. **Configuration Drift**: Databases become independently corrupted or restored from backups at different points in time
5. **Network Partitions**: In distributed storage scenarios, network issues could cause one write to succeed and another to fail

The pruner runs continuously in production environments, making this a recurring exposure. Each pruning cycle represents an opportunity for the race condition to manifest.

## Recommendation

**Primary Fix**: Implement atomic cross-database transactions or use compensating transactions to ensure consistency.

**Option 1 - Two-Phase Commit**:
Implement proper two-phase commit protocol for cross-database operations to ensure both databases are updated atomically or both roll back.

**Option 2 - Write-Ahead Log**:
Log pruning operations before executing them, allowing recovery to complete or roll back partial operations on restart.

**Option 3 - Merge Pruning Batches**:
When internal indexer is enabled, modify the logic to ensure both databases are pruned in a single coordinated transaction:

```rust
// Modified approach - ensure coordinated pruning
if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
    if indexer_db.transaction_enabled() {
        // Create a single coordinated batch operation
        let mut combined_operation = CoordinatedPruningOperation::new();
        combined_operation.add_indexer_deletions(...);
        combined_operation.add_ledger_deletions(...);
        
        // Execute atomically or rollback both
        combined_operation.execute_or_rollback()?;
    }
}
```

**Option 4 - Consistency Checker**:
Implement a background consistency checker that detects and repairs orphaned indices:

```rust
// Periodic consistency verification
pub fn verify_index_consistency(&self) -> Result<Vec<OrphanedIndex>> {
    // Scan index entries
    // Verify corresponding transactions exist
    // Report discrepancies for repair
}
```

## Proof of Concept

```rust
// Reproduction steps demonstrating the vulnerability:

#[test]
fn test_orphaned_index_entries_from_pruning_failure() {
    // Setup: Create AptosDB with internal indexer enabled
    let (db, indexer_db) = create_test_dbs_with_indexer();
    
    // Step 1: Add transactions with account indices
    let account = AccountAddress::random();
    for seq in 0..100 {
        let txn = create_test_transaction(account, seq);
        db.save_transactions(&[txn], version, &[])?;
    }
    
    // Step 2: Inject failure after indexer DB write but before ledger DB write
    // This simulates a crash between lines 67 and 73
    let pruner = TransactionPruner::new(
        transaction_store,
        ledger_db,
        0,
        Some(indexer_db_with_injected_failure),
    )?;
    
    // Step 3: Attempt pruning - indexer write succeeds, ledger write fails
    // Due to injected failure after line 67
    let result = pruner.prune(0, 50);
    assert!(result.is_err()); // Pruning fails
    
    // Step 4: Verify inconsistent state
    // Check indexer DB - indices should be partially deleted
    let indexer_progress = indexer_db.get_transaction_version()?;
    
    // Check ledger DB - transactions still exist
    for v in 0..50 {
        assert!(db.get_transaction_by_version(v, 100, false).is_ok());
    }
    
    // Step 5: Query API - this should return NotFound due to index pointing
    // to transactions that will be pruned next cycle
    let api_result = api.get_account_ordered_transactions(
        account,
        0,
        50,
        100,
        &ledger_info,
    );
    
    // Expected: API returns errors for orphaned indices
    assert!(api_result.is_err());
}
```

**Notes:**
- The current implementation uses the `?` operator which should prevent partial commits in error scenarios, but crash scenarios between database writes remain vulnerable
- Each database tracks independent pruning progress via separate metadata keys, allowing drift over time
- Recovery from crashes may not properly reconcile the two databases' states
- No automated consistency verification exists to detect orphaned indices [6](#0-5) [7](#0-6)

### Citations

**File:** storage/indexer_schemas/src/schema/ordered_transaction_by_account/mod.rs (L1-28)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! This module defines physical storage schema for a transaction index via which the version of a
//! transaction sent by `account_address` with `sequence_number` can be found. With the version one
//! can resort to `TransactionSchema` for the transaction content.
//!
//! ```text
//! |<-------key------->|<-value->|
//! | address | seq_num | txn_ver |
//! ```

use crate::{schema::ORDERED_TRANSACTION_BY_ACCOUNT_CF_NAME, utils::ensure_slice_len_eq};
use anyhow::Result;
use aptos_schemadb::{
    define_pub_schema,
    schema::{KeyCodec, ValueCodec},
};
use aptos_types::{account_address::AccountAddress, transaction::Version};
use byteorder::{BigEndian, ReadBytesExt, WriteBytesExt};
use std::{convert::TryFrom, mem::size_of};

define_pub_schema!(
    OrderedTransactionByAccountSchema,
    Key,
    Version,
    ORDERED_TRANSACTION_BY_ACCOUNT_CF_NAME
);
```

**File:** api/src/context.rs (L900-923)
```rust
        let txns_res = if !db_sharding_enabled(&self.node_config) {
            self.db.get_account_ordered_transactions(
                address,
                start_seq_number,
                limit as u64,
                true,
                ledger_version,
            )
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| anyhow!("Indexer reader is None"))
                .map_err(|err| {
                    E::internal_with_code(err, AptosErrorCode::InternalError, ledger_info)
                })?
                .get_account_ordered_transactions(
                    address,
                    start_seq_number,
                    limit as u64,
                    true,
                    ledger_version,
                )
                .map_err(|e| AptosDbError::Other(e.to_string()))
        };
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-74)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
        self.ledger_db.transaction_db().prune_transactions(
            current_progress,
            target_version,
            &mut batch,
        )?;
        self.transaction_store
            .prune_transaction_summaries_by_account(&candidate_transactions, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
    }
```

**File:** storage/indexer/src/db_indexer.rs (L600-612)
```rust
            .get_account_ordered_transactions_iter(address, start_seq_num, limit, ledger_version)?
            .map(|result| {
                let (_seq_num, txn_version) = result?;
                self.main_db_reader.get_transaction_by_version(
                    txn_version,
                    ledger_version,
                    include_events,
                )
            })
            .collect::<Result<Vec<_>>>()?;

        Ok(AccountOrderedTransactionsWithProof::new(txns_with_proofs))
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1068-1100)
```rust
    pub(super) fn get_transaction_with_proof(
        &self,
        version: Version,
        ledger_version: Version,
        fetch_events: bool,
    ) -> Result<TransactionWithProof> {
        self.error_if_ledger_pruned("Transaction", version)?;

        let proof = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_with_proof(
                version,
                ledger_version,
                self.ledger_db.transaction_accumulator_db(),
            )?;

        let transaction = self.ledger_db.transaction_db().get_transaction(version)?;

        // If events were requested, also fetch those.
        let events = if fetch_events {
            Some(self.ledger_db.event_db().get_events_by_version(version)?)
        } else {
            None
        };

        Ok(TransactionWithProof {
            version,
            transaction,
            events,
            proof,
        })
    }
```

**File:** storage/indexer_schemas/src/metadata.rs (L31-42)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize, Hash, PartialOrd, Ord)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub enum MetadataKey {
    LatestVersion,
    EventPrunerProgress,
    TransactionPrunerProgress,
    StateSnapshotRestoreProgress(Version),
    EventVersion,
    StateVersion,
    TransactionVersion,
    EventV2TranslationVersion,
}
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L62-65)
```rust
    TransactionAccumulatorPrunerProgress,
    TransactionInfoPrunerProgress,
    TransactionPrunerProgress,
    WriteSetPrunerProgress,
```
