# Audit Report

## Title
Unauthenticated Cross-Shard Messages Allow Byzantine Shard to Fork Blockchain via State Root Divergence

## Summary
The remote sharded execution system lacks cryptographic authentication on cross-shard messages, allowing a Byzantine executor shard to send conflicting state updates to different shards. This causes honest shards to compute different state roots, violating the deterministic execution invariant and potentially forking the blockchain.

## Finding Description

The Aptos sharded execution architecture uses cross-shard messaging to communicate transaction results between executor shards during parallel block execution. When a transaction on one shard writes to a state key that another shard's transaction depends on, the source shard sends a `CrossShardMsg` containing the write operation. [1](#0-0) 

The critical vulnerability lies in how these messages are sent and received. The `RemoteCrossShardClient` serializes messages and sends them over an unauthenticated network channel: [2](#0-1) 

The receiving shard deserializes and immediately trusts the message without any validation of its source, authenticity, or integrity: [3](#0-2) 

The underlying network layer provides no authentication. The GRPC service accepts any message from any remote address: [4](#0-3) 

**Attack Scenario:**

1. Block B contains transactions partitioned across 3 executor shards (Shard 0, 1, 2)
2. Transaction T₀ on Byzantine Shard 0 writes state key K with value V
3. Transaction T₁ on Shard 1 has a cross-shard dependency: reads K from (Shard 0, T₀)
4. Transaction T₂ on Shard 2 has a cross-shard dependency: reads K from (Shard 0, T₀)
5. Byzantine Shard 0 sends `RemoteTxnWriteMsg(K, V₁)` to Shard 1
6. Byzantine Shard 0 sends `RemoteTxnWriteMsg(K, V₂)` to Shard 2, where V₁ ≠ V₂
7. Shard 1's `CrossShardStateView` is updated with K=V₁
8. Shard 2's `CrossShardStateView` is updated with K=V₂
9. When T₁ executes on Shard 1, it reads K=V₁
10. When T₂ executes on Shard 2, it reads K=V₂
11. Shard 1 produces output O₁, Shard 2 produces output O₂, where O₁ ≠ O₂

The coordinator aggregates results in order without cross-validation: [5](#0-4) 

The coordinator simply collects results from shards without verifying that they received consistent cross-shard state: [6](#0-5) 

This violates **Critical Invariant #1: Deterministic Execution** - "All validators must produce identical state roots for identical blocks." If different validators run with different Byzantine shards, or if the same validator experiences non-deterministic message delivery, they will compute different state roots and consensus will break.

## Impact Explanation

**Critical Severity** - This vulnerability enables a **Consensus Safety Violation**, which qualifies for the highest severity tier (up to $1,000,000) per the Aptos Bug Bounty program.

Specifically:
- **Breaks Consensus Safety**: Violates the fundamental blockchain invariant that all honest nodes must agree on the state after executing the same block
- **Causes State Root Divergence**: Different shards compute different transaction outputs, leading to different Merkle tree roots
- **Enables Blockchain Fork**: Validators that aggregate different results will disagree on the canonical chain state
- **Non-Recoverable Without Hardfork**: Once state divergence occurs and is committed, manual intervention or a hardfork would be required to restore consensus

The impact extends to:
- All transactions dependent on cross-shard state in the affected block
- All subsequent blocks building on divergent state
- Complete loss of consensus guarantees under the <1/3 Byzantine assumption

## Likelihood Explanation

**Likelihood Assessment: LOW to MEDIUM** (but impact is CRITICAL)

The vulnerability requires:
1. **Prerequisite**: Remote sharded execution must be enabled (appears to be experimental infrastructure)
2. **Attacker Capability**: Control over one executor shard's network communication
3. **Attack Complexity**: Moderate - requires understanding of cross-shard dependencies and ability to send different messages to different targets

However, this DOES NOT require:
- Compromising consensus keys
- Breaking cryptographic primitives  
- Controlling validator consensus participation
- Achieving >1/3 Byzantine validators

**Important Limitation**: This vulnerability requires access to executor shard infrastructure. In the current architecture, executor shards appear to be trusted components operated by validators themselves. This means exploitation would require either:
- Compromising a validator's executor shard infrastructure
- A future deployment model where executor shards are operated by separate, potentially untrusted parties

If executor shards are treated as trusted validator infrastructure, this may not meet the "unprivileged attacker" requirement of the bug bounty. However, from a defense-in-depth perspective, the system should be resilient against Byzantine components even within validator infrastructure.

## Recommendation

Implement cryptographic authentication and verification for all cross-shard messages:

**1. Message Authentication:**
- Each shard should sign `CrossShardMsg` with a shard-specific key
- Include message sequence numbers to prevent replay attacks
- Add Merkle proof linking the message to the block being executed

**2. Coordinator Verification:**
- Implement cross-validation where coordinator verifies consistency of cross-shard messages
- Before aggregating results, verify that all dependent shards received the same cross-shard state
- Add checksums/hashes of cross-shard state to shard outputs for validation

**3. Proposed Code Changes:**

Add to `CrossShardMsg`:
```rust
pub struct AuthenticatedCrossShardMsg {
    msg: CrossShardMsg,
    shard_signature: Signature,
    sequence_number: u64,
    block_id: HashValue,
}
```

Update `CrossShardCommitReceiver::start()` to verify signatures before accepting messages.

Add to coordinator result aggregation to verify cross-shard state consistency across shards before accepting execution results.

## Proof of Concept

**Conceptual PoC** (cannot be fully implemented without multi-shard test infrastructure):

```rust
// Simulated Byzantine Shard Attack
// This demonstrates the lack of validation in the message flow

use aptos_types::state_store::state_key::StateKey;
use aptos_types::write_set::WriteOp;

fn byzantine_attack_simulation() {
    // Setup: 3 shards executing a block with cross-shard dependencies
    let state_key = StateKey::raw(b"shared_key");
    
    // Byzantine Shard 0 creates two different messages
    let msg_to_shard1 = CrossShardMsg::RemoteTxnWriteMsg(
        RemoteTxnWrite::new(
            state_key.clone(),
            Some(WriteOp::legacy_modification(b"value_1".to_vec()))
        )
    );
    
    let msg_to_shard2 = CrossShardMsg::RemoteTxnWriteMsg(
        RemoteTxnWrite::new(
            state_key.clone(),
            Some(WriteOp::legacy_modification(b"value_2".to_vec())) // Different value!
        )
    );
    
    // Send different messages to different shards
    // In RemoteCrossShardClient::send_cross_shard_msg():
    // - No signature verification
    // - No source authentication
    // - No consistency checks
    
    // Result: Shard 1 and Shard 2 now have different state views
    // They will produce different transaction outputs
    // Different state roots will be computed
    // Consensus breaks
}
```

**Testing Approach:**
1. Set up a test environment with 3 remote executor shards
2. Modify one shard to send different `RemoteTxnWriteMsg` values to different target shards for the same state key
3. Execute a block with transactions having cross-shard dependencies
4. Verify that different shards compute different transaction outputs
5. Confirm that the coordinator aggregates inconsistent results without detecting the attack

## Notes

- This vulnerability affects the **remote sharded execution** infrastructure, which appears to be experimental/performance-oriented rather than core consensus functionality
- The threat model requires that executor shards be treated as potentially Byzantine, which may not match current deployment assumptions where shards are trusted validator infrastructure
- Even if current deployment treats shards as trusted, defense-in-depth principles suggest Byzantine fault tolerance should be implemented
- The lack of authentication violates standard distributed systems security practices for any cross-node communication
- If Aptos plans to support untrusted or semi-trusted executor shards in the future, this vulnerability would become immediately critical

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/messages.rs (L7-18)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub enum CrossShardMsg {
    RemoteTxnWriteMsg(RemoteTxnWrite),
    StopMsg,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct RemoteTxnWrite {
    state_key: StateKey,
    // The write op is None if the transaction is aborted.
    write_op: Option<WriteOp>,
}
```

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L55-66)
```rust
    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
        let input_message = bcs::to_bytes(&msg).unwrap();
        let tx = self.message_txs[shard_id][round].lock().unwrap();
        tx.send(Message::new(input_message)).unwrap();
    }

    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        let rx = self.message_rxs[current_round].lock().unwrap();
        let message = rx.recv().unwrap();
        let msg: CrossShardMsg = bcs::from_bytes(&message.to_bytes()).unwrap();
        msg
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L25-45)
```rust
impl CrossShardCommitReceiver {
    pub fn start<S: StateView + Sync + Send>(
        cross_shard_state_view: Arc<CrossShardStateView<S>>,
        cross_shard_client: Arc<dyn CrossShardClient>,
        round: RoundId,
    ) {
        loop {
            let msg = cross_shard_client.receive_cross_shard_msg(round);
            match msg {
                RemoteTxnWriteMsg(txn_commit_msg) => {
                    let (state_key, write_op) = txn_commit_msg.take();
                    cross_shard_state_view
                        .set_value(&state_key, write_op.and_then(|w| w.as_state_value()));
                },
                CrossShardMsg::StopMsg => {
                    trace!("Cross shard commit receiver stopped for round {}", round);
                    break;
                },
            }
        }
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L92-115)
```rust
impl NetworkMessageService for GRPCNetworkMessageServiceServerWrapper {
    async fn simple_msg_exchange(
        &self,
        request: Request<NetworkMessage>,
    ) -> Result<Response<Empty>, Status> {
        let _timer = NETWORK_HANDLER_TIMER
            .with_label_values(&[&self.self_addr.to_string(), "inbound_msgs"])
            .start_timer();
        let remote_addr = request.remote_addr();
        let network_message = request.into_inner();
        let msg = Message::new(network_message.message);
        let message_type = MessageType::new(network_message.message_type);

        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/mod.rs (L98-115)
```rust
        let num_rounds = sharded_output[0].len();
        let mut aggregated_results = vec![];
        let mut ordered_results = vec![vec![]; num_executor_shards * num_rounds];
        // Append the output from individual shards in the round order
        for (shard_id, results_from_shard) in sharded_output.into_iter().enumerate() {
            for (round, result) in results_from_shard.into_iter().enumerate() {
                ordered_results[round * num_executor_shards + shard_id] = result;
            }
        }

        for result in ordered_results.into_iter() {
            aggregated_results.extend(result);
        }

        // Lastly append the global output
        aggregated_results.extend(global_output);

        Ok(aggregated_results)
```

**File:** execution/executor-service/src/remote_executor_client.rs (L163-172)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        trace!("RemoteExecutorClient Waiting for results");
        let mut results = vec![];
        for rx in self.result_rxs.iter() {
            let received_bytes = rx.recv().unwrap().to_bytes();
            let result: RemoteExecutionResult = bcs::from_bytes(&received_bytes).unwrap();
            results.push(result.inner?);
        }
        Ok(results)
    }
```
