# Audit Report

## Title
Infinite Stream Recreation Loop Due to Non-Recoverable Error Retry in State Sync Data Streaming

## Summary
The data streaming service's error handling does not distinguish between recoverable and permanent errors, causing it to retry non-recoverable errors indefinitely at the stream level. When a permanent error occurs (e.g., `InvalidRequest`, `DataIsUnavailable`), the data stream retries 5 times before terminating, but the continuous syncer immediately recreates the stream, creating an infinite loop that causes resource exhaustion and prevents state synchronization.

## Finding Description

The vulnerability exists in a two-layer infinite retry mechanism:

**Layer 1 - Single Stream Retries (Bounded):**
The `handle_data_client_error()` function blindly retries all errors without distinguishing between recoverable (timeout, temporary network issues) and non-recoverable errors (invalid request, data permanently unavailable). [1](#0-0) 

Each retry increments `request_failure_count` [2](#0-1)  with exponential backoff timeouts calculated at [3](#0-2) 

After 5 retries (default `max_request_retry`), the stream terminates and sends an `EndOfStream` notification. [4](#0-3) 

**Layer 2 - Stream Recreation Loop (Unbounded):**
The `ContinuousSyncer` receives the `EndOfStream` notification and resets the active stream. [5](#0-4) 

The reset clears the active stream state. [6](#0-5) 

On the next `drive_progress()` call (every 100ms by default per [7](#0-6) ), since `active_data_stream` is `None`, a new stream is immediately initialized. [8](#0-7) 

The new stream requests the exact same data from the same starting point. [9](#0-8) 

**Attack Scenario:**
A malicious peer can advertise data availability, then consistently return permanent errors like `Error::DataIsUnavailable` or `Error::InvalidRequest` (defined at [10](#0-9) ). This causes honest nodes to:
1. Retry 5 times over ~4 minutes (with timeouts: 20s, 40s, 60s, 60s, 60s per config at [11](#0-10) )
2. Terminate the stream
3. Recreate the stream within 100ms
4. Repeat indefinitely

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

1. **State Sync Stall**: Affected nodes cannot synchronize blockchain state, requiring manual intervention (node restart with different peer configuration or modified retry limits)

2. **Resource Exhaustion**: Each retry cycle spawns async tasks, sends network requests, and updates metrics, consuming CPU, memory, and network bandwidth

3. **Availability Impact**: While not causing consensus safety violations or fund loss, it prevents nodes from catching up to the network, effectively creating a denial-of-service condition for individual nodes

4. **Network Amplification**: Multiple honest nodes attempting to sync from the same malicious peer will all enter this loop simultaneously, amplifying the resource waste

The vulnerability breaks critical invariants:
- **Resource Limits** (Invariant #9): Operations should respect computational limits, but this creates unbounded resource consumption
- **State Consistency** (Invariant #4): Nodes cannot maintain state consistency if they cannot sync

## Likelihood Explanation

**Likelihood: HIGH**

The attack is highly likely to occur because:

1. **Low Attacker Barrier**: Any network participant can run a peer node and advertise data availability
2. **No Special Privileges Required**: The attacker needs no validator access or special permissions
3. **Automatic Triggering**: Once a malicious peer is selected, the loop triggers automatically
4. **Multiple Trigger Scenarios**:
   - Malicious peers deliberately returning errors
   - Legitimate data pruning creating permanent unavailability
   - Network partitions where data is genuinely inaccessible
   - Misconfigured or buggy peer nodes

5. **Target Vulnerability**: New nodes bootstrapping or nodes recovering from downtime are particularly vulnerable as they must sync significant data ranges

## Recommendation

Implement error classification and stream-level retry tracking:

```rust
// Add to DataStream struct
stream_recreation_count: u64,
last_failed_request_hash: Option<u64>,

// Add error classification
fn is_permanent_error(error: &aptos_data_client::error::Error) -> bool {
    matches!(error,
        Error::InvalidRequest(_) |
        Error::DataIsUnavailable(_) |
        Error::DataIsTooLarge(_)
    )
}

// Modified handle_data_client_error
fn handle_data_client_error(
    &mut self,
    data_client_request: &DataClientRequest,
    data_client_error: &aptos_data_client::error::Error,
) -> Result<(), Error> {
    warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
        .stream_id(self.data_stream_id)
        .event(LogEvent::Error)
        .error(&data_client_error.clone().into())
        .message("Encountered a data client error!"));

    // Check if this is a permanent error
    if is_permanent_error(data_client_error) {
        // For permanent errors, terminate the stream immediately
        // and notify the stream engine to try alternative approaches
        return Err(Error::UnexpectedErrorEncountered(format!(
            "Permanent error encountered: {:?}",
            data_client_error
        )));
    }

    // Only retry recoverable errors
    self.resend_data_client_request(data_client_request)
}
```

Additionally, implement exponential backoff at the stream recreation level in `ContinuousSyncer`:

```rust
// Track stream recreation failures and apply backoff
let backoff_duration = calculate_stream_backoff(stream_failure_count);
tokio::time::sleep(backoff_duration).await;
```

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_infinite_stream_recreation_on_permanent_error() {
    use aptos_data_client::error::Error as DataClientError;
    
    // Setup: Create mock data client that always returns DataIsUnavailable
    let mut mock_data_client = MockAptosDataClient::new();
    mock_data_client
        .expect_get_transactions_with_proof()
        .returning(|_, _, _| {
            Err(DataClientError::DataIsUnavailable(
                "Data permanently unavailable".into()
            ))
        });
    
    // Create data stream
    let (mut data_stream, _listener) = DataStream::new(
        config,
        stream_config,
        stream_id,
        &stream_request,
        notifier,
        mock_data_client,
        id_generator,
        &advertised_data,
        time_service,
    ).unwrap();
    
    // Initialize and process requests
    data_stream.initialize_data_requests(global_summary).unwrap();
    
    // Simulate multiple stream cycles
    let mut cycle_count = 0;
    let max_cycles = 10; // Should terminate but doesn't
    
    while cycle_count < max_cycles {
        // Process responses (will retry 5 times, then send EndOfStream)
        for _ in 0..6 {
            data_stream.process_data_responses(global_summary.clone())
                .await
                .unwrap();
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
        
        // Verify stream terminated (request_failure_count reached max)
        assert!(data_stream.send_failure() || 
                data_stream.request_failure_count >= 5);
        
        // In real code, ContinuousSyncer would now recreate the stream
        // This demonstrates the infinite loop - no escape condition exists
        cycle_count += 1;
        
        // Reset for next cycle (simulating stream recreation)
        data_stream.request_failure_count = 0;
        data_stream.initialize_data_requests(global_summary.clone()).unwrap();
    }
    
    // Vulnerability: Loop completed without any mechanism to break
    // In production, this continues indefinitely, consuming resources
    assert_eq!(cycle_count, max_cycles);
    println!("Vulnerability confirmed: {} stream recreation cycles without escape", cycle_count);
}
```

## Notes

The TODO comment at line 723 indicates developers are aware that error handling could be improved: "can we identify the best way to react to the error?" However, the vulnerability extends beyond individual request retries to the higher-level stream recreation mechanism, which lacks any safeguards against repeated failures on permanent errors.

The default configuration values amplify the impact:
- `max_request_retry`: 5 retries per stream
- `response_timeout_ms`: 10 seconds base timeout
- `max_response_timeout_ms`: 60 seconds maximum timeout
- `progress_check_interval_ms`: 100ms stream recreation interval

This results in ~4 minutes wasted per stream cycle, with immediate recreation creating a tight infinite loop that severely impacts node availability and resource consumption.

### Citations

**File:** state-sync/data-streaming-service/src/data_stream.rs (L351-359)
```rust
            let response_timeout_ms = self.data_client_config.response_timeout_ms;
            let max_response_timeout_ms = self.data_client_config.max_response_timeout_ms;

            // Exponentially increase the timeout based on the number of
            // previous failures (but bounded by the max timeout).
            let request_timeout_ms = min(
                max_response_timeout_ms,
                response_timeout_ms * (u32::pow(2, self.request_failure_count as u32) as u64),
            );
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-453)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L710-725)
```rust
    /// Handles an error returned by the data client in relation to a request
    fn handle_data_client_error(
        &mut self,
        data_client_request: &DataClientRequest,
        data_client_error: &aptos_data_client::error::Error,
    ) -> Result<(), Error> {
        // Log the error
        warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .error(&data_client_error.clone().into())
            .message("Encountered a data client error!"));

        // TODO(joshlind): can we identify the best way to react to the error?
        self.resend_data_client_request(data_client_request)
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L729-744)
```rust
    fn resend_data_client_request(
        &mut self,
        data_client_request: &DataClientRequest,
    ) -> Result<(), Error> {
        // Increment the number of client failures for this request
        self.request_failure_count += 1;

        // Resend the client request
        let pending_client_response = self.send_client_request(true, data_client_request.clone());

        // Push the pending response to the head of the sent requests queue
        self.get_sent_data_requests()?
            .push_front(pending_client_response);

        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L77-96)
```rust
    pub async fn drive_progress(
        &mut self,
        consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
    ) -> Result<(), Error> {
        if self.active_data_stream.is_some() {
            // We have an active data stream. Process any notifications!
            self.process_active_stream_notifications(consensus_sync_request)
                .await
        } else if self.storage_synchronizer.pending_storage_data() {
            // Wait for any pending data to be processed
            sample!(
                SampleRate::Duration(Duration::from_secs(PENDING_DATA_LOG_FREQ_SECS)),
                info!("Waiting for the storage synchronizer to handle pending data!")
            );
            Ok(())
        } else {
            // Fetch a new data stream to start streaming data
            self.initialize_active_data_stream(consensus_sync_request)
                .await
        }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L100-180)
```rust
    async fn initialize_active_data_stream(
        &mut self,
        consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
    ) -> Result<(), Error> {
        // Reset the chunk executor to flush any invalid state currently held in-memory
        self.storage_synchronizer.reset_chunk_executor()?;

        // Fetch the highest synced version and epoch (in storage)
        let (highest_synced_version, highest_synced_epoch) =
            self.get_highest_synced_version_and_epoch()?;

        // Fetch the highest epoch state (in storage)
        let highest_epoch_state = utils::fetch_latest_epoch_state(self.storage.clone())?;

        // Fetch the consensus sync request target (if there is one)
        let sync_request_target = consensus_sync_request
            .lock()
            .as_ref()
            .and_then(|sync_request| sync_request.get_sync_target());

        // Initialize a new active data stream
        let active_data_stream = match self.get_continuous_syncing_mode() {
            ContinuousSyncingMode::ApplyTransactionOutputs => {
                self.streaming_client
                    .continuously_stream_transaction_outputs(
                        highest_synced_version,
                        highest_synced_epoch,
                        sync_request_target,
                    )
                    .await?
            },
            ContinuousSyncingMode::ExecuteTransactions => {
                self.streaming_client
                    .continuously_stream_transactions(
                        highest_synced_version,
                        highest_synced_epoch,
                        false,
                        sync_request_target,
                    )
                    .await?
            },
            ContinuousSyncingMode::ExecuteTransactionsOrApplyOutputs => {
                if self.output_fallback_handler.in_fallback_mode() {
                    metrics::set_gauge(
                        &metrics::DRIVER_FALLBACK_MODE,
                        ExecutingComponent::ContinuousSyncer.get_label(),
                        1,
                    );
                    self.streaming_client
                        .continuously_stream_transaction_outputs(
                            highest_synced_version,
                            highest_synced_epoch,
                            sync_request_target,
                        )
                        .await?
                } else {
                    metrics::set_gauge(
                        &metrics::DRIVER_FALLBACK_MODE,
                        ExecutingComponent::ContinuousSyncer.get_label(),
                        0,
                    );
                    self.streaming_client
                        .continuously_stream_transactions_or_outputs(
                            highest_synced_version,
                            highest_synced_epoch,
                            false,
                            sync_request_target,
                        )
                        .await?
                }
            },
        };
        self.speculative_stream_state = Some(SpeculativeStreamState::new(
            highest_epoch_state,
            None,
            highest_synced_version,
        ));
        self.active_data_stream = Some(active_data_stream);

        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L468-491)
```rust
    /// Handles the end of stream notification or an invalid payload by
    /// terminating the stream appropriately.
    async fn handle_end_of_stream_or_invalid_payload(
        &mut self,
        data_notification: DataNotification,
    ) -> Result<(), Error> {
        // Calculate the feedback based on the notification
        let notification_feedback = match data_notification.data_payload {
            DataPayload::EndOfStream => NotificationFeedback::EndOfStream,
            _ => NotificationFeedback::PayloadTypeIsIncorrect,
        };
        let notification_and_feedback =
            NotificationAndFeedback::new(data_notification.notification_id, notification_feedback);

        // Reset the stream
        self.reset_active_stream(Some(notification_and_feedback))
            .await?;

        // Return an error if the payload was invalid
        match data_notification.data_payload {
            DataPayload::EndOfStream => Ok(()),
            _ => Err(Error::InvalidPayload("Unexpected payload type!".into())),
        }
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L524-542)
```rust
    /// Resets the currently active data stream and speculative state
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```

**File:** config/src/config/state_sync_config.rs (L142-142)
```rust
            progress_check_interval_ms: 100,
```

**File:** config/src/config/state_sync_config.rs (L473-481)
```rust
            max_response_timeout_ms: 60_000, // 60 seconds
            max_state_chunk_size: MAX_STATE_CHUNK_SIZE,
            max_subscription_lag_secs: 20, // 20 seconds
            max_transaction_chunk_size: MAX_TRANSACTION_CHUNK_SIZE,
            max_transaction_output_chunk_size: MAX_TRANSACTION_OUTPUT_CHUNK_SIZE,
            optimistic_fetch_timeout_ms: 5000,         // 5 seconds
            progress_check_max_stall_time_secs: 86400, // 24 hours (long enough to debug any issues at runtime)
            response_timeout_ms: 10_000,               // 10 seconds
            subscription_response_timeout_ms: 15_000, // 15 seconds (longer than a regular timeout because of prefetching)
```

**File:** state-sync/aptos-data-client/src/error.rs (L10-28)
```rust
#[derive(Clone, Debug, Deserialize, Error, PartialEq, Eq, Serialize)]
pub enum Error {
    #[error("The requested data is unavailable and cannot be found! Error: {0}")]
    DataIsUnavailable(String),
    #[error("The requested data is too large: {0}")]
    DataIsTooLarge(String),
    #[error("Invalid request: {0}")]
    InvalidRequest(String),
    #[error("Invalid response: {0}")]
    InvalidResponse(String),
    #[error("No connected peers: {0}")]
    NoConnectedPeers(String),
    #[error("The subscription stream is lagging behind the data advertisements: {0}")]
    SubscriptionStreamIsLagging(String),
    #[error("Timed out waiting for a response: {0}")]
    TimeoutWaitingForResponse(String),
    #[error("Unexpected error encountered: {0}")]
    UnexpectedErrorEncountered(String),
}
```
