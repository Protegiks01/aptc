# Audit Report

## Title
Transaction Chunk Gap Detection Bypass Allows Silent Skipping of Versions During Restore

## Summary
The `loaded_chunk_stream()` function in transaction restore fails to validate that the first chunk begins at the expected version when `first_version` is explicitly provided. The continuity check at lines 363-382 only validates gaps between consecutive chunks but skips validation for the initial chunk, allowing attackers to supply malicious backups that omit arbitrary transaction ranges from the beginning of the restore window. [1](#0-0) 

## Finding Description

The vulnerability exists in a critical path where transaction backups are restored to rebuild node state. The code contains two separate but interacting flaws:

**Flaw 1: Filter allows chunks with gaps**

The filter at lines 360-362 permits any chunk where `last_version >= first_version`, regardless of where `first_version` of the chunk actually starts: [2](#0-1) 

**Flaw 2: Scan skips validation for the first chunk**

The scan operation initializes `last_chunk_last_version = 0` and only performs gap detection when `*last_chunk_last_version != 0`. For the very first chunk, this condition is false, so no validation occurs: [1](#0-0) 

**Exploitation Scenario:**

1. Attacker creates malicious backup with chunks:
   - Chunk 1: versions 150-200 (missing versions 100-149)
   - Chunk 2: versions 201-300

2. Victim initiates restore with `first_version = Some(100)`, `target_version = 300`

3. Filter evaluation:
   - Chunk 1: `150 <= 300 && 200 >= 100` → PASSES
   - Chunk 2: `201 <= 300 && 300 >= 100` → PASSES

4. Scan evaluation:
   - Initial: `last_chunk_last_version = 0`
   - Chunk 1 arrives: `0 != 0` is FALSE → Gap check SKIPPED → Set to 200
   - Chunk 2 arrives: `200 != 0 && 201 != 201` is FALSE → Continuity PASSES

5. In `run_impl()`, when `self.first_version.is_some()`, the code skips calling `confirm_or_save_frozen_subtrees()`, which would have peeked at the first chunk: [3](#0-2) 

6. In `save_before_replay_version()`, the logic at lines 485-495 checks if `global_first_version > first_version` to drain unwanted transactions. With `global_first_version = 100` and `chunk.first_version = 150`, the condition is FALSE, so no draining occurs: [4](#0-3) 

7. Transactions are saved starting at version 150, skipping versions 100-149: [5](#0-4) 

8. The database writer performs no version continuity validation: [6](#0-5) 

**Result:** The node's database now has a gap (versions 100-149 missing), leading to:
- Incorrect state root hash
- Consensus failures when attempting to sync with other nodes
- Potential chain split if multiple nodes restore from the same malicious backup
- Violation of deterministic execution invariant

This breaks the **State Consistency** invariant (#4) and the **Deterministic Execution** invariant (#1).

## Impact Explanation

**Severity: Critical**

This vulnerability meets Critical severity criteria per the Aptos bug bounty program:

1. **Consensus/Safety violations**: Restored nodes will have incorrect state, causing them to compute different state roots than honest nodes, breaking consensus safety guarantees.

2. **Non-recoverable network partition**: If multiple validators restore from the same malicious backup, they will form a separate partition with incorrect state, potentially requiring a hardfork to resolve.

3. **State Consistency violation**: The Jellyfish Merkle tree state will be inconsistent with the transaction history, violating the fundamental invariant that all nodes must have identical state for identical transaction sequences.

The attack is particularly dangerous because:
- The restore completes "successfully" with no error messages
- The corruption is silent and may not be detected until the node attempts consensus
- Multiple nodes restoring from the same source amplifies the impact
- Recovery requires identifying the gap and re-restoring from clean backups

## Likelihood Explanation

**Likelihood: Medium-High**

The vulnerability is exploitable in several realistic scenarios:

1. **Malicious backup provider**: An attacker operates a backup service and provides corrupted backup files to victims

2. **Compromised backup storage**: Attacker gains access to backup storage (S3, GCS, etc.) and modifies backup files

3. **Backup corruption**: Accidental deletion of backup chunks creates gaps that go undetected

4. **Two-phase restore attacks**: During phase 2 of restore operations, the `first_version` parameter is explicitly set, making the attack vector more likely to be triggered: [7](#0-6) 

The attack requires:
- Ability to supply or modify backup files (Medium difficulty)
- No validator privileges required (Low barrier)
- No insider access needed (Low barrier)
- Simple to execute once backup access is obtained (Low complexity)

The impact is amplified in production environments where operators may restore from untrusted or inadequately verified backup sources.

## Recommendation

Implement explicit validation that the first chunk begins at the expected version when `first_version` is provided:

```rust
fn loaded_chunk_stream(&self) -> Peekable<impl Stream<Item = Result<LoadedChunk>> + use<>> {
    let con = self.global_opt.concurrent_downloads;
    let manifest_handle_stream = stream::iter(self.manifest_handles.clone());
    let storage = self.storage.clone();
    let manifest_stream = manifest_handle_stream
        .map(move |hdl| {
            let storage = storage.clone();
            async move { storage.load_json_file(&hdl).await.err_notes(&hdl) }
        })
        .buffered_x(con * 3, con)
        .and_then(|m: TransactionBackup| future::ready(m.verify().map(|_| m)));

    let target_version = self.global_opt.target_version;
    let first_version = self.first_version.unwrap_or(0);
    let expected_first_version = self.first_version; // Store the expected value
    
    let chunk_manifest_stream = manifest_stream
        .map_ok(|m| stream::iter(m.chunks.into_iter().map(Result::<_>::Ok)))
        .try_flatten()
        .try_filter(move |c| {
            future::ready(c.first_version <= target_version && c.last_version >= first_version)
        })
        .scan(
            (0, true), // (last_version, is_first_chunk)
            move |state, chunk_res| {
                let (last_chunk_last_version, is_first_chunk) = state;
                let res = match &chunk_res {
                    Ok(chunk) => {
                        // NEW: Validate first chunk starts at expected version
                        if *is_first_chunk {
                            if let Some(expected) = expected_first_version {
                                if chunk.first_version != expected {
                                    return Some(Err(anyhow!(
                                        "First chunk does not start at expected version. Expected: {}, got: {}",
                                        expected,
                                        chunk.first_version
                                    )));
                                }
                            }
                            *is_first_chunk = false;
                        }
                        
                        // Existing continuity check
                        if *last_chunk_last_version != 0
                            && chunk.first_version != *last_chunk_last_version + 1
                        {
                            Some(Err(anyhow!(
                                "Chunk range not consecutive. expecting {}, got {}",
                                *last_chunk_last_version + 1,
                                chunk.first_version
                            )))
                        } else {
                            *last_chunk_last_version = chunk.last_version;
                            Some(chunk_res)
                        }
                    },
                    Err(_) => Some(chunk_res),
                };
                future::ready(res)
            });

    // ... rest of the function
}
```

**Alternative Fix:** Always call `confirm_or_save_frozen_subtrees()` and validate the first chunk's version matches `first_version`:

```rust
async fn run_impl(self) -> Result<()> {
    if self.manifest_handles.is_empty() {
        return Ok(());
    }

    let mut loaded_chunk_stream = self.loaded_chunk_stream();
    
    // Always get the actual first version from the stream
    let actual_first_version = self.confirm_or_save_frozen_subtrees(&mut loaded_chunk_stream).await?;
    
    // Validate it matches expectations if first_version was provided
    if let Some(expected) = self.first_version {
        ensure!(
            actual_first_version == expected,
            "First chunk version mismatch. Expected: {}, got: {}",
            expected,
            actual_first_version
        );
    }
    
    let first_version = actual_first_version;
    
    // ... rest of the function
}
```

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// Place in storage/backup/backup-cli/src/backup_types/transaction/tests.rs

#[tokio::test]
async fn test_chunk_gap_at_beginning_undetected() {
    // Setup: Create backup with missing initial chunk
    let tmpdir = TempDir::new().unwrap();
    let store = Arc::new(MockBackupStorage::new(&tmpdir));
    
    // Create chunks with gap: missing versions 100-149
    let chunk1 = create_transaction_chunk(150, 200); // Should start at 100
    let chunk2 = create_transaction_chunk(201, 300);
    
    let manifest = TransactionBackup {
        chunks: vec![chunk1, chunk2],
        // ... other fields
    };
    
    let manifest_handle = store.save_json(&manifest).await.unwrap();
    
    // Attempt restore with first_version = 100
    let controller = TransactionRestoreBatchController::new(
        global_opt,
        store,
        vec![manifest_handle],
        Some(100), // Expected to start at version 100
        None,
        None,
        VerifyExecutionMode::NoVerify,
        None,
    );
    
    // Expected: Error due to gap detection
    // Actual: Succeeds and silently skips versions 100-149
    let result = controller.run().await;
    
    // Vulnerability: This should fail but doesn't
    assert!(result.is_err(), "Should detect gap in chunks");
    assert!(result.unwrap_err().to_string().contains("gap") 
           || result.unwrap_err().to_string().contains("consecutive"));
}
```

## Notes

This vulnerability is particularly insidious because:

1. **Silent failure mode**: The restore operation completes without errors, giving operators false confidence in the restored state.

2. **Cascading impact**: If the corrupted node participates in consensus, it will produce different state roots, potentially causing widespread consensus failures.

3. **Two-phase restore vulnerability**: The two-phase restore pattern used in production explicitly sets `first_version`, making this attack vector more likely to occur: [8](#0-7) 

4. **No downstream validation**: Neither the database writer nor the state store performs version continuity validation, so the corruption propagates silently into persistent storage.

The fix must be applied to prevent state consistency violations that could compromise the entire network's integrity during disaster recovery scenarios.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L309-312)
```rust
        let first_version = self.first_version.unwrap_or(
            self.confirm_or_save_frozen_subtrees(&mut loaded_chunk_stream)
                .await?,
        );
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L360-362)
```rust
            .try_filter(move |c| {
                future::ready(c.first_version <= target_version && c.last_version >= first_version)
            })
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L363-382)
```rust
            .scan(0, |last_chunk_last_version, chunk_res| {
                let res = match &chunk_res {
                    Ok(chunk) => {
                        if *last_chunk_last_version != 0
                            && chunk.first_version != *last_chunk_last_version + 1
                        {
                            Some(Err(anyhow!(
                                "Chunk range not consecutive. expecting {}, got {}",
                                *last_chunk_last_version + 1,
                                chunk.first_version
                            )))
                        } else {
                            *last_chunk_last_version = chunk.last_version;
                            Some(chunk_res)
                        }
                    },
                    Err(_) => Some(chunk_res),
                };
                future::ready(res)
            });
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L485-495)
```rust
                    // remove the txns that are before the global_first_version
                    if global_first_version > first_version {
                        let num_to_remove = (global_first_version - first_version) as usize;

                        txns.drain(..num_to_remove);
                        persisted_aux_info.drain(..num_to_remove);
                        txn_infos.drain(..num_to_remove);
                        event_vecs.drain(..num_to_remove);
                        write_sets.drain(..num_to_remove);
                        first_version = global_first_version;
                    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L507-516)
```rust
                        tokio::task::spawn_blocking(move || {
                            restore_handler.save_transactions(
                                first_version,
                                &txns_to_save,
                                &persisted_aux_info_to_save,
                                &txn_infos_to_save,
                                &event_vecs_to_save,
                                write_sets_to_save,
                            )
                        })
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L193-213)
```rust
pub(crate) fn save_transactions_impl(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    txns: &[Transaction],
    persisted_aux_info: &[PersistedAuxiliaryInfo],
    txn_infos: &[TransactionInfo],
    events: &[Vec<ContractEvent>],
    write_sets: &[WriteSet],
    ledger_db_batch: &mut LedgerDbSchemaBatches,
    state_kv_batches: &mut ShardedStateKvSchemaBatch,
    kv_replay: bool,
) -> Result<()> {
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L289-300)
```rust
            TransactionRestoreBatchController::new(
                transaction_restore_opt,
                Arc::clone(&self.storage),
                txn_manifests,
                Some(db_next_version),
                Some((kv_replay_version, true /* only replay KV */)),
                epoch_history.clone(),
                VerifyExecutionMode::NoVerify,
                None,
            )
            .run()
            .await?;
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L360-371)
```rust
            TransactionRestoreBatchController::new(
                self.global_opt,
                self.storage,
                txn_manifests,
                first_version,
                replay_version,
                epoch_history,
                VerifyExecutionMode::NoVerify,
                None,
            )
            .run()
            .await?;
```
