# Audit Report

## Title
Database Error Panic in Batch Generator Causes Validator Crash

## Summary
The `BatchGenerator` in the consensus quorum store uses `expect()` on database write operations at line 183, causing the validator process to terminate if RocksDB encounters errors (disk full, I/O errors, corruption). This panic is caught by the global panic handler which exits the entire validator process, resulting in immediate loss of consensus participation.

## Finding Description

The vulnerability exists in the batch creation hot path where database errors are not handled gracefully. The critical code path is: [1](#0-0) 

This `save_batch_id()` call at line 183 occurs during normal batch creation in `create_new_batch()`, which is invoked periodically by the batch generator's main event loop: [2](#0-1) 

The database operations return `Result<(), DbError>` which can fail with various RocksDB errors: [3](#0-2) 

These errors include `IOError` (disk full, permission issues), `Corruption` (database corruption), `Busy` (lock contention), and others. The `write_schemas_relaxed` method uses non-synchronous writes: [4](#0-3) 

When the `expect()` panics, the global panic handler terminates the process: [5](#0-4) 

The panic handler explicitly exits the process with code 12, as confirmed by the comment: [6](#0-5) 

This handler is installed during validator startup: [7](#0-6) 

**Attack Scenario:**
1. Validator disk approaches capacity or experiences hardware I/O errors
2. Batch generator creates a new batch every few hundred milliseconds (normal operation)
3. RocksDB write fails with `IOError` due to disk full or I/O failure
4. `expect()` panics with "Could not save to db"
5. Global panic handler catches the panic and exits the validator process (exit code 12)
6. Validator goes offline and cannot participate in consensus
7. Network liveness degraded if multiple validators affected simultaneously

## Impact Explanation

This vulnerability qualifies as **Critical** severity under Aptos bug bounty criteria for the following reasons:

**Total Loss of Liveness/Network Availability**: If multiple validators experience disk space issues simultaneously (common in clusters with similar hardware/configuration), the network could experience severe liveness degradation or halt completely. This meets the Critical severity criterion of "Total loss of liveness/network availability."

**Validator Node Crashes**: At minimum, this causes individual validator crashes requiring manual intervention and restart, meeting the High severity criterion of "Validator node slowdowns."

The vulnerability breaks the following critical invariants:
- **Consensus Liveness**: Validators must remain operational to participate in consensus
- **Fault Tolerance**: The system should gracefully handle transient failures like disk full conditions
- **Error Recovery**: Database errors should not cause catastrophic process termination

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability is **highly likely** to occur in production environments:

1. **Disk Full Conditions**: Disk space exhaustion is a common operational issue, especially for validators that:
   - Run on fixed-size storage volumes
   - Experience rapid state growth
   - Have insufficient monitoring/alerting
   - Share disk space with other processes

2. **Hardware I/O Errors**: Storage hardware failures occur regularly in production infrastructure

3. **No Graceful Degradation**: The system provides no warning or recovery mechanism before crashing

4. **Periodic Trigger**: Batch creation happens every few hundred milliseconds, providing frequent opportunities for the error to manifest

5. **Production Evidence**: The existence of monitoring alerts for disk space suggests this is a known operational concern: [8](#0-7) 

## Recommendation

Replace all `expect()` calls on database operations with proper error handling that logs errors and either:
1. Returns an error to the caller for graceful handling
2. Enters a degraded mode where batch generation is paused
3. Implements retry logic with exponential backoff
4. Triggers an alert but keeps the validator running

**Recommended Fix:**

```rust
// In create_new_batch() at line 181-183
match self.db.save_batch_id(self.epoch, self.batch_id) {
    Ok(_) => {
        // Continue normal operation
    }
    Err(e) => {
        error!("Failed to save batch_id to database: {:?}. Entering degraded mode.", e);
        counters::BATCH_GENERATOR_DB_ERROR.inc();
        // Return error to caller instead of panicking
        // Caller can decide whether to retry, pause, or continue
        // This prevents validator crash while maintaining observability
        return Err(e);
    }
}
```

Similar fixes should be applied to:
- Line 89 and 101 in `BatchGenerator::new()` (during initialization)
- Lines 507, 512 in `batch_store.rs` 

Additionally, implement:
1. Disk space monitoring with alerting before critical thresholds
2. Database health checks before operations
3. Circuit breaker pattern for repeated database failures
4. Graceful degradation mode where validator remains online but batch generation is paused

## Proof of Concept

**Test Scenario: Simulate Disk Full Condition**

```rust
#[cfg(test)]
mod db_error_panic_test {
    use super::*;
    use std::sync::{Arc, Mutex};
    
    // Mock QuorumStoreStorage that can simulate failures
    struct FailingQuorumStoreDB {
        should_fail: Arc<Mutex<bool>>,
    }
    
    impl QuorumStoreStorage for FailingQuorumStoreDB {
        fn save_batch_id(&self, _epoch: u64, _batch_id: BatchId) -> Result<(), DbError> {
            if *self.should_fail.lock().unwrap() {
                // Simulate disk full / IO error
                Err(DbError::from(anyhow::anyhow!("No space left on device")))
            } else {
                Ok(())
            }
        }
        // ... other trait methods return Ok(())
    }
    
    #[tokio::test]
    #[should_panic(expected = "Could not save to db")]
    async fn test_batch_generator_panics_on_db_error() {
        // Setup failing database
        let failing_db = Arc::new(FailingQuorumStoreDB {
            should_fail: Arc::new(Mutex::new(false)),
        });
        
        let batch_generator = BatchGenerator::new(
            0, // epoch
            PeerId::random(),
            config,
            failing_db.clone(),
            batch_writer,
            mempool_tx,
            1000,
        );
        
        // Enable failures
        *failing_db.should_fail.lock().unwrap() = true;
        
        // This will panic when trying to save batch_id
        let txns = vec![create_test_transaction()];
        batch_generator.create_new_batch(txns, expiry_time, 0);
        
        // Test will pass because panic is expected
        // In production, this panic crashes the validator
    }
}
```

**Reproduction Steps:**
1. Deploy validator on a volume with limited disk space
2. Fill disk to near capacity (e.g., 95% full)
3. Monitor validator logs for batch generation activity
4. Trigger additional disk writes to push over capacity threshold
5. Observe validator crash with panic message "Could not save to db"
6. Verify validator process exited with code 12
7. Confirm validator is no longer participating in consensus

## Notes

This vulnerability also exists in similar form at:
- Lines 89 and 101 in the same file (during initialization, less critical)
- Lines 507 and 512 in `batch_store.rs` (similar panic on DB writes)

The use of `write_schemas_relaxed` (non-sync writes) means data loss on crash is expected by design, but the panic on errors is not. The system should handle transient failures gracefully rather than crashing the validator.

### Citations

**File:** consensus/src/quorum_store/batch_generator.rs (L173-183)
```rust
    fn create_new_batch(
        &mut self,
        txns: Vec<SignedTransaction>,
        expiry_time: u64,
        bucket_start: u64,
    ) -> Batch<BatchInfoExt> {
        let batch_id = self.batch_id;
        self.batch_id.increment();
        self.db
            .save_batch_id(self.epoch, self.batch_id)
            .expect("Could not save to db");
```

**File:** consensus/src/quorum_store/batch_generator.rs (L403-409)
```rust
    pub async fn start(
        mut self,
        mut network_sender: NetworkSender,
        mut cmd_rx: tokio::sync::mpsc::Receiver<BatchGeneratorCommand>,
        mut back_pressure_rx: tokio::sync::mpsc::Receiver<BackPressure>,
        mut interval: Interval,
    ) {
```

**File:** consensus/src/quorum_store/batch_generator.rs (L430-482)
```rust
                _ = interval.tick() => monitor!("batch_generator_handle_tick", {

                    let tick_start = Instant::now();
                    // TODO: refactor back_pressure logic into its own function
                    if self.back_pressure.txn_count {
                        // multiplicative decrease, every second
                        if back_pressure_decrease_latest.elapsed() >= back_pressure_decrease_duration {
                            back_pressure_decrease_latest = tick_start;
                            dynamic_pull_txn_per_s = std::cmp::max(
                                (dynamic_pull_txn_per_s as f64 * self.config.back_pressure.decrease_fraction) as u64,
                                self.config.back_pressure.dynamic_min_txn_per_s,
                            );
                            trace!("QS: dynamic_max_pull_txn_per_s: {}", dynamic_pull_txn_per_s);
                        }
                        counters::QS_BACKPRESSURE_TXN_COUNT.observe(1.0);
                        counters::QS_BACKPRESSURE_MAKE_STRICTER_TXN_COUNT.observe(1.0);
                        counters::QS_BACKPRESSURE_DYNAMIC_MAX.observe(dynamic_pull_txn_per_s as f64);
                    } else {
                        // additive increase, every second
                        if back_pressure_increase_latest.elapsed() >= back_pressure_increase_duration {
                            back_pressure_increase_latest = tick_start;
                            dynamic_pull_txn_per_s = std::cmp::min(
                                dynamic_pull_txn_per_s + self.config.back_pressure.additive_increase_when_no_backpressure,
                                self.config.back_pressure.dynamic_max_txn_per_s,
                            );
                            trace!("QS: dynamic_max_pull_txn_per_s: {}", dynamic_pull_txn_per_s);
                        }
                        counters::QS_BACKPRESSURE_TXN_COUNT.observe(
                            if dynamic_pull_txn_per_s < self.config.back_pressure.dynamic_max_txn_per_s { 1.0 } else { 0.0 }
                        );
                        counters::QS_BACKPRESSURE_MAKE_STRICTER_TXN_COUNT.observe(0.0);
                        counters::QS_BACKPRESSURE_DYNAMIC_MAX.observe(dynamic_pull_txn_per_s as f64);
                    }
                    if self.back_pressure.proof_count {
                        counters::QS_BACKPRESSURE_PROOF_COUNT.observe(1.0);
                    } else {
                        counters::QS_BACKPRESSURE_PROOF_COUNT.observe(0.0);
                    }
                    let since_last_non_empty_pull_ms = std::cmp::min(
                        tick_start.duration_since(last_non_empty_pull).as_millis(),
                        self.config.batch_generation_max_interval_ms as u128
                    ) as usize;
                    if (!self.back_pressure.proof_count
                        && since_last_non_empty_pull_ms >= self.config.batch_generation_min_non_empty_interval_ms)
                        || since_last_non_empty_pull_ms == self.config.batch_generation_max_interval_ms {

                        let dynamic_pull_max_txn = std::cmp::max(
                            (since_last_non_empty_pull_ms as f64 / 1000.0 * dynamic_pull_txn_per_s as f64) as u64, 1);
                        let pull_max_txn = std::cmp::min(
                            dynamic_pull_max_txn,
                            self.config.sender_max_total_txns as u64,
                        );
                        let batches = self.handle_scheduled_pull(pull_max_txn).await;
```

**File:** storage/schemadb/src/lib.rs (L316-318)
```rust
    pub fn write_schemas_relaxed(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &WriteOptions::default())
    }
```

**File:** storage/schemadb/src/lib.rs (L389-407)
```rust
fn to_db_err(rocksdb_err: rocksdb::Error) -> AptosDbError {
    match rocksdb_err.kind() {
        ErrorKind::Incomplete => AptosDbError::RocksDbIncompleteResult(rocksdb_err.to_string()),
        ErrorKind::NotFound
        | ErrorKind::Corruption
        | ErrorKind::NotSupported
        | ErrorKind::InvalidArgument
        | ErrorKind::IOError
        | ErrorKind::MergeInProgress
        | ErrorKind::ShutdownInProgress
        | ErrorKind::TimedOut
        | ErrorKind::Aborted
        | ErrorKind::Busy
        | ErrorKind::Expired
        | ErrorKind::TryAgain
        | ErrorKind::CompactionTooLarge
        | ErrorKind::ColumnFamilyDropped
        | ErrorKind::Unknown => AptosDbError::OtherRocksDbError(rocksdb_err.to_string()),
    }
```

**File:** crates/crash-handler/src/lib.rs (L21-25)
```rust
/// Invoke to ensure process exits on a thread panic.
///
/// Tokio's default behavior is to catch panics and ignore them.  Invoking this function will
/// ensure that all subsequent thread panics (even Tokio threads) will report the
/// details/backtrace and then exit.
```

**File:** crates/crash-handler/src/lib.rs (L26-57)
```rust
pub fn setup_panic_handler() {
    panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());

    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);

    // Wait till the logs have been flushed
    aptos_logger::flush();

    // Do not kill the process if the panics happened at move-bytecode-verifier.
    // This is safe because the `state::get_state()` uses a thread_local for storing states. Thus the state can only be mutated to VERIFIER by the thread that's running the bytecode verifier.
    //
    // TODO: once `can_unwind` is stable, we should assert it. See https://github.com/rust-lang/rust/issues/92988.
    if state::get_state() == VMState::VERIFIER || state::get_state() == VMState::DESERIALIZER {
        return;
    }

    // Kill the process
    process::exit(12);
```

**File:** aptos-node/src/lib.rs (L233-234)
```rust
    // Setup panic handler
    aptos_crash_handler::setup_panic_handler();
```
