# Audit Report

## Title
Unvalidated Write Set Integrity During Database Restore with KV Replay Enables State Corruption

## Summary
During database restore operations with `kv_replay=true`, write_sets from backup files are used to recalculate blockchain state without cryptographic validation against the `state_change_hash` field in TransactionInfo. This allows an attacker who can manipulate backup files to corrupt validator state, causing validator dysfunction and potential serving of incorrect state to clients.

## Finding Description

The vulnerability exists in the `save_transactions_impl()` function where state is recalculated from write_sets during backup restore operations. [1](#0-0) 

When `kv_replay=true`, the function calls `calculate_state_and_put_updates()` with write_sets from the backup, directly using them to recalculate the state Merkle tree and update the ledger state. These write_sets are **never validated** against the `state_change_hash` field in the corresponding TransactionInfo objects.

**Background on State Change Hash:**
TransactionInfo contains a `state_change_hash` field that represents the cryptographic hash of the write_set. [2](#0-1) 

During normal execution, the `ensure_match_transaction_info()` method validates that write_sets match their state_change_hash. [3](#0-2) 

**The Vulnerability Flow:**

1. During backup restore, `LoadedChunk.load()` reads transactions, events, and write_sets from backup files. [4](#0-3) 

2. The verification process creates a `TransactionListWithProof` that validates transaction hashes, event hashes, and TransactionInfo against the ledger accumulator. [5](#0-4) 

3. However, `TransactionListWithProof` does NOT include write_sets in its structure or verification. [6](#0-5) 

4. The verification only checks transaction hashes and event root hashes, not write_set hashes. [7](#0-6) 

5. The unvalidated write_sets are then used in `save_transactions_impl()` to recalculate state when kv_replay is enabled, with no validation that they match the state_change_hash in TransactionInfo.

**Attack Scenario:**
1. Attacker compromises backup storage or performs MITM during backup retrieval
2. Attacker modifies write_sets in backup files while keeping TransactionInfo unchanged
3. Validator performs database restore with `kv_replay=true`
4. Manipulated write_sets are used to recalculate state Merkle tree
5. Resulting state root differs from the correct state
6. When validator attempts to execute new blocks, state checkpoint validation fails
7. Validator becomes dysfunctional and cannot participate in consensus

## Impact Explanation

This vulnerability meets **High Severity** criteria per the Aptos bug bounty program:

1. **Validator Node Dysfunction**: Affected validators fail state checkpoint validation when attempting to execute blocks after restore, causing them to become non-functional. [8](#0-7) 

2. **Potential Incorrect State Serving**: If the validator serves read requests before executing blocks, it could serve incorrect state values to clients based on the corrupted state Merkle tree.

3. **Database Corruption**: The corrupted state persists in the database, requiring manual intervention and re-restore from a trusted backup source.

4. **Not a Direct Consensus Break**: While the security question asks about "validator disagreement," the cryptographic binding of TransactionInfo.state_checkpoint_hash to the ledger accumulator prevents consensus breaks. Compromised validators fail validation rather than creating invalid consensus.

The impact is classified as **High** (not Critical) because:
- It causes validator dysfunction (DoS) but not consensus breaks
- No loss of funds occurs
- Detection happens during subsequent block execution
- Requires backup storage compromise (reduces likelihood)

## Likelihood Explanation

**Likelihood: Medium to High**

**Attack Requirements:**
1. Compromise backup storage infrastructure OR
2. Perform man-in-the-middle attack during backup retrieval OR  
3. Social engineering to have validator restore from malicious backup

**Factors Increasing Likelihood:**
- Backup storage may not have the same security controls as production validators
- Restoration is a manual operation often performed during disaster recovery
- Operators under pressure during incidents may skip verification steps
- The optional `replay-verify` tool that would catch this is not part of standard restore workflow

**Factors Decreasing Likelihood:**
- Requires access to backup infrastructure
- Restoration with `kv_replay=true` is not always used
- Impact is detected when validator executes blocks (fails validation)

## Recommendation

Add cryptographic validation in `save_transactions_impl()` to verify write_sets match the state_change_hash in TransactionInfo before using them for kv_replay:

```rust
if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
    // ADDED: Validate write_sets against state_change_hash in txn_infos
    for (idx, (ws, txn_info)) in write_sets.iter().zip(txn_infos.iter()).enumerate() {
        let write_set_hash = CryptoHash::hash(ws);
        ensure!(
            write_set_hash == txn_info.state_change_hash(),
            "Write set hash mismatch at version {}: computed {:?}, expected {:?}",
            first_version + idx as Version,
            write_set_hash,
            txn_info.state_change_hash()
        )?;
    }
    
    let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
        &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
        &mut ledger_db_batch.ledger_metadata_db_batches,
        state_kv_batches,
    )?;
    state_store.set_state_ignoring_summary(ledger_state);
}
```

**Additional Recommendations:**
1. Make the `replay-verify` tool mandatory after kv_replay restores
2. Add cryptographic signatures to backup manifests binding write_sets
3. Document the security implications of kv_replay in operational guides

## Proof of Concept

```rust
#[test]
fn test_manipulated_write_set_detection() {
    use aptos_crypto::{hash::CryptoHash, HashValue};
    use aptos_types::{
        transaction::{Transaction, TransactionInfo, WriteSet},
        write_set::WriteSetMut,
    };
    
    // 1. Create a valid transaction with write_set
    let original_write_set = WriteSet::default(); // Simplified
    let state_change_hash = CryptoHash::hash(&original_write_set);
    
    // 2. Create TransactionInfo with correct state_change_hash
    let txn_info = TransactionInfo::new(
        HashValue::zero(), // transaction_hash
        state_change_hash,  // state_change_hash - CORRECT
        HashValue::zero(), // event_root_hash
        None,              // state_checkpoint_hash
        0,                 // gas_used
        ExecutionStatus::Success,
        None,              // auxiliary_info_hash
    );
    
    // 3. Simulate attacker manipulating write_set in backup
    let mut manipulated_ws_mut = WriteSetMut::default();
    // Add some malicious state changes
    manipulated_ws_mut.insert((StateKey::raw(b"malicious_key"), WriteOp::Deletion));
    let manipulated_write_set = manipulated_ws_mut.freeze().unwrap();
    
    // 4. Compute hash of manipulated write_set
    let manipulated_hash = CryptoHash::hash(&manipulated_write_set);
    
    // 5. Verify hashes don't match (demonstrates vulnerability)
    assert_ne!(
        manipulated_hash, 
        txn_info.state_change_hash(),
        "Manipulated write_set should not match TransactionInfo"
    );
    
    // 6. This mismatch should be detected during restore, but currently ISN'T
    // The current code would use manipulated_write_set to recalculate state
    // without checking this hash mismatch
    
    println!("Original state_change_hash: {:?}", state_change_hash);
    println!("Manipulated write_set hash: {:?}", manipulated_hash);
    println!("Vulnerability: Hashes differ but no validation occurs during kv_replay restore!");
}
```

**Notes:**
- The validation logic exists in `ensure_match_transaction_info()` but is never invoked during the kv_replay restore path
- The `replay-verify` coordinator tool would catch this issue, but it's optional and not run during standard restore operations
- State checkpoint validation eventually catches the corruption when executing new blocks, but by then the database is already corrupted

### Citations

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```

**File:** types/src/transaction/mod.rs (L1898-1908)
```rust
        let write_set_hash = CryptoHash::hash(self.write_set());
        ensure!(
            write_set_hash == txn_info.state_change_hash(),
            "{}: version:{}, write_set_hash:{:?}, expected:{:?}, write_set: {:?}, expected(if known): {:?}",
            ERR_MSG,
            version,
            write_set_hash,
            txn_info.state_change_hash(),
            self.write_set,
            expected_write_set,
        );
```

**File:** types/src/transaction/mod.rs (L2040-2042)
```rust
    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,
```

**File:** types/src/transaction/mod.rs (L2245-2250)
```rust
pub struct TransactionListWithProof {
    pub transactions: Vec<Transaction>,
    pub events: Option<Vec<Vec<ContractEvent>>>,
    pub first_transaction_version: Option<Version>,
    pub proof: TransactionInfoListWithProof,
}
```

**File:** types/src/transaction/mod.rs (L2317-2350)
```rust
        // Verify the transaction hashes match those of the transaction infos
        self.transactions
            .par_iter()
            .zip_eq(self.proof.transaction_infos.par_iter())
            .map(|(txn, txn_info)| {
                let txn_hash = CryptoHash::hash(txn);
                ensure!(
                    txn_hash == txn_info.transaction_hash(),
                    "The hash of transaction does not match the transaction info in proof. \
                     Transaction hash: {:x}. Transaction hash in txn_info: {:x}.",
                    txn_hash,
                    txn_info.transaction_hash(),
                );
                Ok(())
            })
            .collect::<Result<Vec<_>>>()?;

        // Verify the transaction infos are proven by the ledger info.
        self.proof
            .verify(ledger_info, self.get_first_transaction_version())?;

        // Verify the events if they exist.
        if let Some(event_lists) = &self.events {
            ensure!(
                event_lists.len() == self.get_num_transactions(),
                "The length of event_lists ({}) does not match the number of transactions ({}).",
                event_lists.len(),
                self.get_num_transactions(),
            );
            event_lists
                .into_par_iter()
                .zip_eq(self.proof.transaction_infos.par_iter())
                .map(|(events, txn_info)| verify_events_against_root_hash(events, txn_info))
                .collect::<Result<Vec<_>>>()?;
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L112-136)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
            let (txn, aux_info, txn_info, events, write_set): (
                _,
                PersistedAuxiliaryInfo,
                _,
                _,
                WriteSet,
            ) = match manifest.format {
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
                    (
                        txn,
                        PersistedAuxiliaryInfo::None,
                        txn_info,
                        events,
                        write_set,
                    )
                },
                TransactionChunkFormat::V1 => bcs::from_bytes(&record_bytes)?,
            };
            txns.push(txn);
            persisted_aux_info.push(aux_info);
            txn_infos.push(txn_info);
            event_vecs.push(events);
            write_sets.push(write_set);
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L156-167)
```rust
        // make a `TransactionListWithProof` to reuse its verification code.
        let txn_list_with_proof =
            TransactionListWithProofV2::new(TransactionListWithAuxiliaryInfos::new(
                TransactionListWithProof::new(
                    txns,
                    Some(event_vecs),
                    Some(manifest.first_version),
                    TransactionInfoListWithProof::new(range_proof, txn_infos),
                ),
                persisted_aux_info,
            ));
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
```

**File:** execution/executor/src/workflow/do_state_checkpoint.rs (L64-71)
```rust
            if let Some(idx) = last_checkpoint_index {
                ensure!(
                    known[idx] == Some(state_summary.last_checkpoint().root_hash()),
                    "Root hash mismatch with known hashes passed in. {:?} vs {:?}",
                    known[idx],
                    Some(&state_summary.last_checkpoint().root_hash()),
                );
            }
```
