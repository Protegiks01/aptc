# Audit Report

## Title
Subscription Stream Lag Detection Bypass via Unverified Version Manipulation

## Summary
A malicious peer can bypass subscription stream lag detection by sending responses with manipulated version numbers, preventing the lag timeout mechanism from triggering and keeping nodes stuck with non-functional data sources indefinitely.

## Finding Description

The `check_subscription_stream_lag()` function in the data streaming service performs lag detection by comparing response versions against advertised network versions. However, it extracts the version information from unverified response payloads before cryptographic proof verification occurs, creating a Time-of-Check-Time-of-Use (TOCTOU) vulnerability. [1](#0-0) 

The function extracts `highest_response_version` from the response payload by reading the `first_transaction_version` field and computing the highest version: [2](#0-1) 

If this extracted version is greater than or equal to the advertised version, the lag is immediately reset: [3](#0-2) 

However, cryptographic proof verification doesn't occur until much later in the executor pipeline: [4](#0-3) 

**Attack Flow:**

1. Node requests subscription data from a malicious peer
2. Malicious peer sends response with `first_transaction_version` set to a very high value (e.g., 1,000,000) but with invalid/mismatched proof data
3. `check_subscription_stream_lag()` extracts this high version number (line 555-584) and compares it with `highest_advertised_version`
4. Since the fake version â‰¥ advertised version, lag is reset (lines 599-602)
5. Later, proof verification fails in the executor (line 128), causing stream reset
6. Attacker repeats this process, preventing lag from ever accumulating beyond the timeout threshold

The lag detection mechanism is designed to fail streams that lag behind for longer than `max_subscription_stream_lag_secs`: [5](#0-4) 

By repeatedly resetting the lag counter before timeout, an attacker prevents this recovery mechanism from ever triggering.

## Impact Explanation

**Severity: HIGH** 

This vulnerability enables a Denial-of-Service attack against state synchronization by:

1. **Preventing Node Syncing**: Nodes cannot detect they're stuck with non-functional peers, preventing them from catching up to the network
2. **Validator Node Slowdowns**: Affected validator nodes cannot sync state, degrading network performance
3. **Protocol Violation**: The lag detection safety mechanism is completely bypassed

This meets the Aptos Bug Bounty **High Severity** criteria for "Validator node slowdowns" and "Significant protocol violations" (up to $50,000).

While not causing direct fund loss, this attack can:
- Prevent new nodes from joining the network
- Stall validator nodes that fall behind
- Reduce network liveness if many nodes are affected
- Force manual intervention to fix stuck nodes

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Attack Complexity**: Attacker only needs to control a single peer that gets selected for subscription
2. **No Special Privileges**: Any network participant can become a peer
3. **Trivial Exploitation**: Simply send responses with manipulated `first_transaction_version` fields
4. **Peer Selection**: The data client selects peers based on priority and latency, and malicious peers can optimize these metrics
5. **Persistent Effect**: The attack can be repeated indefinitely as long as the malicious peer remains selected

The attack requires:
- Network connectivity to target nodes
- Being selected as a subscription data provider (which happens naturally in P2P networks)
- Ability to send crafted responses (standard network capability)

No validator privileges, stake, or consensus participation is required.

## Recommendation

**Fix: Perform lag detection after proof verification, or use trusted version sources**

**Option 1: Move lag detection after proof verification**
```rust
// In process_data_responses(), only check lag AFTER the notification
// is successfully processed and verified
async fn process_data_responses(...) -> Result<(), Error> {
    // ... existing code ...
    
    match client_response {
        Ok(client_response) => {
            // Sanity check
            if sanity_check_client_response_type(...) {
                // Send to client for verification (this triggers executor verification)
                self.send_data_notification_to_client(...).await?;
                
                // ONLY check lag AFTER successful verification/processing
                if client_request.is_subscription_request() {
                    if let Err(error) = self.check_subscription_stream_lag(
                        &global_data_summary,
                        &client_response.payload,
                    ) {
                        self.notify_new_data_request_error(client_request, error)?;
                    }
                }
                // ... rest of processing ...
            }
        }
    }
}
```

**Option 2: Use verified ledger info for version tracking** [6](#0-5) 

Modify to track the highest *verified* version after executor confirmation, rather than using unverified payload versions.

**Option 3: Add version bounds checking**
```rust
// In check_subscription_stream_lag(), validate version is reasonable
let highest_response_version = /* extract version */;

// Reject obviously invalid versions
if highest_response_version > highest_advertised_version + MAX_VERSION_DRIFT {
    return Err(Error::UnexpectedErrorEncountered(
        format!("Response version {} exceeds advertised version {} by too much",
                highest_response_version, highest_advertised_version)
    ));
}
```

## Proof of Concept

```rust
// Proof of Concept for exploiting lag detection bypass
// This would be implemented as a malicious storage service peer

use aptos_storage_service_types::{
    requests::DataRequest,
    responses::{DataResponse, TransactionDataResponseType},
};
use aptos_types::transaction::{TransactionListWithProof, Version};

// Malicious peer implementation
impl MaliciousStorageService {
    async fn handle_subscription_request(
        &self,
        request: SubscribeTransactionsWithProofRequest,
    ) -> DataResponse {
        // Create a fake response with manipulated version
        let fake_version: Version = 999_999_999; // Very high fake version
        
        // Create transaction list with fake version but invalid proof
        let malicious_txn_list = TransactionListWithProof {
            transactions: vec![self.create_dummy_transaction()],
            events: None,
            first_transaction_version: Some(fake_version), // MANIPULATED
            proof: self.create_invalid_proof(), // Won't verify
        };
        
        let target_ledger_info = self.get_some_ledger_info();
        
        // Return response - lag detection will see version 999,999,999
        // and reset lag, even though proof will fail later
        DataResponse::NewTransactionsWithProof((
            malicious_txn_list,
            target_ledger_info,
        ))
    }
}

// Attack sequence:
// 1. Node connects to malicious peer for subscription
// 2. Malicious peer sends response with fake_version = 999,999,999
// 3. check_subscription_stream_lag() sees 999,999,999 >= advertised_version
// 4. Lag is reset (lines 599-602 of data_stream.rs)
// 5. Proof verification fails in executor
// 6. Stream resets, but lag counter was already cleared
// 7. Repeat indefinitely - lag never accumulates to timeout threshold
// 8. Node is stuck, cannot sync from other peers
```

**Test Scenario:**
1. Set `max_subscription_stream_lag_secs` to 10 seconds
2. Configure node to use malicious peer for subscriptions
3. Malicious peer sends responses every 5 seconds with `first_transaction_version` = MAX_U64
4. Observe that lag is reset every 5 seconds (before timeout)
5. Observe that proof verification fails every 5 seconds
6. Observe that node never switches to a different peer
7. Node remains stuck indefinitely despite continuous failures

## Notes

This vulnerability demonstrates a critical design flaw where security-sensitive checks rely on attacker-controlled, unverified data. The lag detection mechanism is meant to be a safety net for subscription streams, but by using unverified version numbers from response payloads, it can be trivially bypassed.

The fix requires ensuring that lag detection only uses cryptographically verified data, or that it occurs after the proof verification step where invalid data has already been rejected. The current design creates a TOCTOU vulnerability where the "check" (lag detection) happens before the "use" (proof verification), allowing attackers to manipulate the check without affecting the eventual verification failure.

### Citations

**File:** state-sync/data-streaming-service/src/data_stream.rs (L492-499)
```rust
                            if let Err(error) = self.check_subscription_stream_lag(
                                &global_data_summary,
                                &client_response.payload,
                            ) {
                                self.notify_new_data_request_error(client_request, error)?;
                                head_of_line_blocked = true; // We're now head of line blocked on the failed stream
                            }
                        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L549-631)
```rust
    fn check_subscription_stream_lag(
        &mut self,
        global_data_summary: &GlobalDataSummary,
        response_payload: &ResponsePayload,
    ) -> Result<(), aptos_data_client::error::Error> {
        // Get the highest version sent in the subscription response
        let highest_response_version = match response_payload {
            ResponsePayload::NewTransactionsWithProof((transactions_with_proof, _)) => {
                if let Some(first_version) = transactions_with_proof.get_first_transaction_version()
                {
                    let num_transactions = transactions_with_proof.get_num_transactions();
                    first_version
                        .saturating_add(num_transactions as u64)
                        .saturating_sub(1) // first_version + num_txns - 1
                } else {
                    return Err(aptos_data_client::error::Error::UnexpectedErrorEncountered(
                        "The first transaction version is missing from the stream response!".into(),
                    ));
                }
            },
            ResponsePayload::NewTransactionOutputsWithProof((outputs_with_proof, _)) => {
                if let Some(first_version) = outputs_with_proof.get_first_output_version() {
                    let num_outputs = outputs_with_proof.get_num_outputs();
                    first_version
                        .saturating_add(num_outputs as u64)
                        .saturating_sub(1) // first_version + num_outputs - 1
                } else {
                    return Err(aptos_data_client::error::Error::UnexpectedErrorEncountered(
                        "The first output version is missing from the stream response!".into(),
                    ));
                }
            },
            _ => {
                return Ok(()); // The response payload doesn't contain a subscription response
            },
        };

        // Get the highest advertised version
        let highest_advertised_version = global_data_summary
            .advertised_data
            .highest_synced_ledger_info()
            .map(|ledger_info| ledger_info.ledger_info().version())
            .ok_or_else(|| {
                aptos_data_client::error::Error::UnexpectedErrorEncountered(
                    "The highest synced ledger info is missing from the global data summary!"
                        .into(),
                )
            })?;

        // If the stream is not lagging behind, reset the lag and return
        if highest_response_version >= highest_advertised_version {
            self.reset_subscription_stream_lag();
            return Ok(());
        }

        // Otherwise, the stream is lagging behind the advertised version.
        // Check if the stream is beyond recovery (i.e., has failed).
        let current_stream_lag =
            highest_advertised_version.saturating_sub(highest_response_version);
        if let Some(mut subscription_stream_lag) = self.subscription_stream_lag.take() {
            // Check if the stream lag is beyond recovery
            if subscription_stream_lag
                .is_beyond_recovery(self.streaming_service_config, current_stream_lag)
            {
                return Err(
                    aptos_data_client::error::Error::SubscriptionStreamIsLagging(format!(
                        "The subscription stream is beyond recovery! Current lag: {:?}, last lag: {:?},",
                        current_stream_lag, subscription_stream_lag.version_lag
                    )),
                );
            }

            // The stream is lagging, but it's not yet beyond recovery
            self.set_subscription_stream_lag(subscription_stream_lag);
        } else {
            // The stream was not previously lagging, but it is now!
            let subscription_stream_lag =
                SubscriptionStreamLag::new(current_stream_lag, self.time_service.clone());
            self.set_subscription_stream_lag(subscription_stream_lag);
        }

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L964-993)
```rust
    /// Returns true iff the subscription stream lag is considered to be
    /// beyond recovery. This occurs when: (i) the stream is lagging for
    /// too long; and (ii) the lag has increased since the last check.
    fn is_beyond_recovery(
        &mut self,
        streaming_service_config: DataStreamingServiceConfig,
        current_stream_lag: u64,
    ) -> bool {
        // Calculate the total duration the stream has been lagging
        let current_time = self.time_service.now();
        let stream_lag_duration = current_time.duration_since(self.start_time);
        let max_stream_lag_duration =
            Duration::from_secs(streaming_service_config.max_subscription_stream_lag_secs);

        // If the lag is further behind and enough time has passed, the stream has failed
        let lag_has_increased = current_stream_lag > self.version_lag;
        let lag_duration_exceeded = stream_lag_duration >= max_stream_lag_duration;
        if lag_has_increased && lag_duration_exceeded {
            return true; // The stream is beyond recovery
        }

        // Otherwise, update the stream lag if we've caught up.
        // This will ensure the lag can only improve.
        if current_stream_lag < self.version_lag {
            self.version_lag = current_stream_lag;
        }

        false // The stream is not yet beyond recovery
    }
}
```

**File:** execution/executor/src/chunk_executor/mod.rs (L114-156)
```rust
    fn enqueue_chunk_by_execution(
        &self,
        txn_list_with_proof: TransactionListWithProofV2,
        verified_target_li: &LedgerInfoWithSignatures,
        epoch_change_li: Option<&LedgerInfoWithSignatures>,
    ) -> Result<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["chunk", "enqueue_by_execution"]);
        let _timer = EXECUTE_CHUNK.start_timer();

        self.maybe_initialize()?;

        // Verify input data.
        // In consensus-only mode, txn_list_with_proof is fake.
        if !cfg!(feature = "consensus-only-perf-test") {
            txn_list_with_proof.verify(
                verified_target_li.ledger_info(),
                txn_list_with_proof.get_first_transaction_version(),
            )?;
        }

        let (txn_list_with_proof, persisted_aux_info) = txn_list_with_proof.into_parts();
        // Compose enqueue_chunk parameters.
        let TransactionListWithProof {
            transactions,
            events: _,
            first_transaction_version: v,
            proof: txn_infos_with_proof,
        } = txn_list_with_proof;

        let chunk = ChunkToExecute {
            transactions,
            persisted_aux_info,
            first_version: v.ok_or_else(|| anyhow!("first version is None"))?,
        };
        let chunk_verifier = Arc::new(StateSyncChunkVerifier {
            txn_infos_with_proof,
            verified_target_li: verified_target_li.clone(),
            epoch_change_li: epoch_change_li.cloned(),
        });

        // Call the shared implementation.
        self.with_inner(|inner| inner.enqueue_chunk(chunk, chunk_verifier, "execute"))
    }
```
