# Audit Report

## Title
Non-Atomic State Restoration Causes Critical Database Inconsistency Between KV Store and Merkle Tree

## Summary
During state snapshot restoration, the key-value database and Jellyfish Merkle tree are committed non-atomically in parallel threads. When proof verification fails, the KV data has already been persisted to disk while the Merkle tree rejects the data, creating permanent state inconsistency that violates the fundamental invariant that KV store and Merkle tree must always be synchronized.

## Finding Description
The vulnerability exists in the state restoration mechanism when processing state snapshot chunks. In `StateSnapshotRestore::add_chunk`, when `restore_mode` is `Default`, two operations execute in parallel: [1](#0-0) 

The `kv_fn` closure writes KV data by calling `StateValueRestore::add_chunk`, which immediately commits data to the database: [2](#0-1) 

This calls `write_kv_batch` which commits the data: [3](#0-2) 

The commit operation persists data to RocksDB shards: [4](#0-3) 

Meanwhile, `tree_fn` adds data to in-memory `partial_nodes` structures and verifies the proof: [5](#0-4) 

**The Critical Flaw**: The verification happens at line 391 AFTER data has been added to partial_nodes (lines 373-388), but the KV commit (via `kv_fn`) happens in parallel and COMPLETES BEFORE verification results are checked. If verification fails:

1. `kv_fn` has already committed KV data to disk (immutable, no rollback)
2. `tree_fn` returns error, tree nodes are NOT written
3. Both results are checked, error is propagated
4. **KV database now contains data that the Merkle tree doesn't have**

The state synchronizer continues using the same receiver after errors: [6](#0-5) 

When proof verification fails (line 884-965), an error notification is sent but the loop continues (line 975), reusing the corrupted receiver for subsequent chunks.

**Attack Scenario**:
1. Attacker sends Chunk 1 with valid data â†’ both KV and tree committed successfully
2. Attacker sends Chunk 2 with arbitrary data and invalid proof:
   - `kv_fn` commits Chunk 2 data to KV database
   - `tree_fn` fails proof verification
   - add_chunk returns error
   - **KV database has Chunk 1 + Chunk 2, Merkle tree only has Chunk 1**
3. Subsequent queries read from KV database (incorrect data) while Merkle proofs use the tree (doesn't include Chunk 2)
4. State queries return data that cannot be proven via Merkle proofs
5. Different nodes may have different KV states depending on which malicious chunks they received

This violates Invariant #4 (State Consistency): "State transitions must be atomic and verifiable via Merkle proofs."

## Impact Explanation
This is **Critical Severity** under the Aptos bug bounty criteria:

- **State Consistency Violation**: The fundamental guarantee that all state values are verifiable via Merkle proofs is broken
- **Database Corruption**: Creates permanent inconsistency between KV store and Merkle tree that persists across node restarts
- **Consensus Safety Risk**: Different nodes may compute different state roots if they receive different malicious chunks, potentially causing consensus splits
- **Data Integrity Loss**: State queries return unverifiable data that doesn't match the committed Merkle tree

The impact aligns with "Consensus/Safety violations" and "State inconsistencies requiring intervention" in the Critical/Medium severity categories. Since this can cause nodes to diverge in their state views and potentially lead to consensus failures, it qualifies as Critical.

## Likelihood Explanation
**Likelihood: HIGH**

The attack is highly feasible because:

1. **Easy to Trigger**: Any peer participating in state sync can send chunks with invalid proofs
2. **No Special Privileges Required**: Attackers don't need validator access or special permissions
3. **Automatic Exploitation**: The vulnerability triggers automatically when any chunk with an invalid proof is received during state sync
4. **Network Exposure**: State sync is a normal network operation exposed to all peers
5. **No Detection**: The inconsistency is silent - the KV data is committed but subsequent operations may not immediately detect the mismatch

The attack becomes inevitable during:
- Fast sync operations where nodes download state snapshots
- State sync recovery after network partitions
- Backup/restore operations

Any malicious peer or compromised node can exploit this to corrupt downloading nodes' databases.

## Recommendation

Make KV and tree commits atomic by deferring both writes until AFTER proof verification succeeds:

```rust
fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
    // Store chunk for deferred commit
    let chunk_clone = chunk.clone();
    
    let tree_result = {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["jmt_add_chunk"]);
        self.tree_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk_impl(chunk.iter().map(|(k, v)| (k, v.hash())).collect(), proof)
    };
    
    // ONLY commit KV data if tree verification succeeded
    tree_result?;
    
    let kv_result = {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_add_chunk"]);
        self.kv_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk(chunk_clone)
    };
    
    kv_result
}
```

Alternatively, implement a two-phase commit:
1. Verify proof first (no writes)
2. If verification passes, commit both KV and tree atomically
3. If verification fails, reject chunk without any database writes

Also add a final consistency check in `finalize_state_snapshot` to verify the tree root hash matches the committed KV data.

## Proof of Concept

```rust
#[test]
fn test_state_inconsistency_on_verification_failure() {
    use aptos_types::state_store::state_key::StateKey;
    use aptos_types::state_store::state_value::StateValue;
    use aptos_crypto::HashValue;
    
    // Setup: Create state store and snapshot receiver
    let tmpdir = aptos_temppath::TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    let version = 100;
    let expected_root = db.state_store.get_root_hash(version).unwrap();
    
    let mut receiver = db.state_store
        .get_snapshot_receiver(version, expected_root)
        .unwrap();
    
    // Step 1: Send valid chunk
    let valid_chunk = vec![
        (StateKey::raw(b"key1"), StateValue::from(b"value1".to_vec())),
    ];
    let valid_proof = create_valid_proof(&valid_chunk, version, &db);
    receiver.add_chunk(valid_chunk.clone(), valid_proof).unwrap();
    
    // Step 2: Send chunk with INVALID proof (wrong siblings)
    let invalid_chunk = vec![
        (StateKey::raw(b"key2"), StateValue::from(b"malicious".to_vec())),
    ];
    let invalid_proof = SparseMerkleRangeProof::new(vec![HashValue::random()]);
    
    // This should fail verification
    let result = receiver.add_chunk(invalid_chunk.clone(), invalid_proof);
    assert!(result.is_err());
    
    // Step 3: Verify inconsistency
    // Query KV database - will have BOTH chunks
    let kv_value = db.state_store.get_state_value_by_key(&StateKey::raw(b"key2"), version);
    
    // Query via Merkle proof - will NOT have second chunk
    let tree_proof = db.state_store.get_value_with_proof_by_version(
        &StateKey::raw(b"key2"), 
        version
    );
    
    // VULNERABILITY: KV has the data but Merkle tree doesn't
    assert!(kv_value.is_ok()); // KV database has malicious data
    assert!(tree_proof.is_err() || tree_proof.unwrap().0.is_none()); // Tree doesn't have it
    
    // This proves state inconsistency!
}
```

## Notes
This vulnerability represents a fundamental design flaw in the state restoration architecture where atomicity guarantees are violated. The parallel execution of KV writes and proof verification is a performance optimization that sacrifices correctness. The fix requires either serializing the operations or implementing proper two-phase commit with rollback capabilities. This issue affects all nodes performing state sync and could be exploited to create widespread database corruption across the network.

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L88-127)
```rust
    pub fn add_chunk(&mut self, mut chunk: Vec<(K, V)>) -> Result<()> {
        // load progress
        let progress_opt = self.db.get_progress(self.version)?;

        // skip overlaps
        if let Some(progress) = progress_opt {
            let idx = chunk
                .iter()
                .position(|(k, _v)| CryptoHash::hash(k) > progress.key_hash)
                .unwrap_or(chunk.len());
            chunk = chunk.split_off(idx);
        }

        // quit if all skipped
        if chunk.is_empty() {
            return Ok(());
        }

        // save
        let mut usage = progress_opt.map_or(StateStorageUsage::zero(), |p| p.usage);
        let (last_key, _last_value) = chunk.last().unwrap();
        let last_key_hash = CryptoHash::hash(last_key);

        // In case of TreeOnly Restore, we only restore the usage of KV without actually writing KV into DB
        for (k, v) in chunk.iter() {
            usage.add_item(k.key_size() + v.value_size());
        }

        // prepare the sharded kv batch
        let kv_batch: StateValueBatch<K, Option<V>> = chunk
            .into_iter()
            .map(|(k, v)| ((k, self.version), Some(v)))
            .collect();

        self.db.write_kv_batch(
            self.version,
            &kv_batch,
            StateSnapshotProgress::new(last_key_hash, usage),
        )
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L228-258)
```rust
    fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
        let kv_fn = || {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_add_chunk"]);
            self.kv_restore
                .lock()
                .as_mut()
                .unwrap()
                .add_chunk(chunk.clone())
        };

        let tree_fn = || {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["jmt_add_chunk"]);
            self.tree_restore
                .lock()
                .as_mut()
                .unwrap()
                .add_chunk_impl(chunk.iter().map(|(k, v)| (k, v.hash())).collect(), proof)
        };
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => kv_fn()?,
            StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
        }

        Ok(())
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1242-1279)
```rust
impl StateValueWriter<StateKey, StateValue> for StateStore {
    // This already turns on sharded KV
    fn write_kv_batch(
        &self,
        version: Version,
        node_batch: &StateValueBatch,
        progress: StateSnapshotProgress,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_writer_write_chunk"]);
        let mut batch = SchemaBatch::new();
        let mut sharded_schema_batch = self.state_kv_db.new_sharded_native_batches();

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
            &DbMetadataValue::StateSnapshotProgress(progress),
        )?;

        if self.internal_indexer_db.is_some()
            && self
                .internal_indexer_db
                .as_ref()
                .unwrap()
                .statekeys_enabled()
        {
            let keys = node_batch.keys().map(|key| key.0.clone()).collect();
            self.internal_indexer_db
                .as_ref()
                .unwrap()
                .write_keys_to_indexer_db(&keys, version, progress)?;
        }
        self.shard_state_value_batch(
            &mut sharded_schema_batch,
            node_batch,
            self.state_kv_db.enabled_sharding(),
        )?;
        self.state_kv_db
            .commit(version, Some(batch), sharded_schema_batch)
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-208)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L336-413)
```rust
    /// Restores a chunk of states. This function will verify that the given chunk is correct
    /// using the proof and root hash, then write things to storage. If the chunk is invalid, an
    /// error will be returned and nothing will be written to storage.
    pub fn add_chunk_impl(
        &mut self,
        mut chunk: Vec<(&K, HashValue)>,
        proof: SparseMerkleRangeProof,
    ) -> Result<()> {
        if self.finished {
            info!("State snapshot restore already finished, ignoring entire chunk.");
            return Ok(());
        }

        if let Some(prev_leaf) = &self.previous_leaf {
            let skip_until = chunk
                .iter()
                .find_position(|(key, _hash)| key.hash() > *prev_leaf.account_key());
            chunk = match skip_until {
                None => {
                    info!("Skipping entire chunk.");
                    return Ok(());
                },
                Some((0, _)) => chunk,
                Some((num_to_skip, next_leaf)) => {
                    info!(
                        num_to_skip = num_to_skip,
                        next_leaf = next_leaf,
                        "Skipping leaves."
                    );
                    chunk.split_off(num_to_skip)
                },
            }
        };
        if chunk.is_empty() {
            return Ok(());
        }

        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;

        // Write the frozen nodes to storage.
        if self.async_commit {
            self.wait_for_async_commit()?;
            let (tx, rx) = channel();
            self.async_commit_result = Some(rx);

            let mut frozen_nodes = HashMap::new();
            std::mem::swap(&mut frozen_nodes, &mut self.frozen_nodes);
            let store = self.store.clone();

            IO_POOL.spawn(move || {
                let res = store.write_node_batch(&frozen_nodes);
                tx.send(res).unwrap();
            });
        } else {
            self.store.write_node_batch(&self.frozen_nodes)?;
            self.frozen_nodes.clear();
        }

        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L863-975)
```rust
        while let Some(storage_data_chunk) = state_snapshot_listener.next().await {
            // Start the snapshot timer for the state value chunk
            let _timer = metrics::start_timer(
                &metrics::STORAGE_SYNCHRONIZER_LATENCIES,
                metrics::STORAGE_SYNCHRONIZER_STATE_VALUE_CHUNK,
            );

            // Commit the state value chunk
            match storage_data_chunk {
                StorageDataChunk::States(notification_id, states_with_proof) => {
                    // Commit the state value chunk
                    let all_states_synced = states_with_proof.is_last_chunk();
                    let last_committed_state_index = states_with_proof.last_index;
                    let num_state_values = states_with_proof.raw_values.len();

                    let result = state_snapshot_receiver.add_chunk(
                        states_with_proof.raw_values,
                        states_with_proof.proof.clone(),
                    );

                    // Handle the commit result
                    match result {
                        Ok(()) => {
                            // Update the logs and metrics
                            info!(
                                LogSchema::new(LogEntry::StorageSynchronizer).message(&format!(
                                    "Committed a new state value chunk! Chunk size: {:?}, last persisted index: {:?}",
                                    num_state_values,
                                    last_committed_state_index
                                ))
                            );

                            // Update the chunk metrics
                            let operation_label =
                                metrics::StorageSynchronizerOperations::SyncedStates.get_label();
                            metrics::set_gauge(
                                &metrics::STORAGE_SYNCHRONIZER_OPERATIONS,
                                operation_label,
                                last_committed_state_index,
                            );
                            metrics::observe_value(
                                &metrics::STORAGE_SYNCHRONIZER_CHUNK_SIZES,
                                operation_label,
                                num_state_values as u64,
                            );

                            if !all_states_synced {
                                // Update the metadata storage with the last committed state index
                                if let Err(error) = metadata_storage
                                    .clone()
                                    .update_last_persisted_state_value_index(
                                        &target_ledger_info,
                                        last_committed_state_index,
                                        all_states_synced,
                                    )
                                {
                                    let error = format!("Failed to update the last persisted state index at version: {:?}! Error: {:?}", version, error);
                                    send_storage_synchronizer_error(
                                        error_notification_sender.clone(),
                                        notification_id,
                                        error,
                                    )
                                    .await;
                                }
                                decrement_pending_data_chunks(pending_data_chunks.clone());
                                continue; // Wait for the next chunk
                            }

                            // Finalize storage and send a commit notification
                            if let Err(error) = finalize_storage_and_send_commit(
                                chunk_executor,
                                &mut commit_notification_sender,
                                metadata_storage,
                                state_snapshot_receiver,
                                storage,
                                &epoch_change_proofs,
                                target_output_with_proof,
                                version,
                                &target_ledger_info,
                                last_committed_state_index,
                            )
                            .await
                            {
                                send_storage_synchronizer_error(
                                    error_notification_sender.clone(),
                                    notification_id,
                                    error,
                                )
                                .await;
                            }
                            decrement_pending_data_chunks(pending_data_chunks.clone());
                            return; // There's nothing left to do!
                        },
                        Err(error) => {
                            let error =
                                format!("Failed to commit state value chunk! Error: {:?}", error);
                            send_storage_synchronizer_error(
                                error_notification_sender.clone(),
                                notification_id,
                                error,
                            )
                            .await;
                        },
                    }
                },
                storage_data_chunk => {
                    unimplemented!(
                        "Invalid storage data chunk sent to state snapshot receiver! This shouldn't happen: {:?}",
                        storage_data_chunk
                    );
                },
            }
            decrement_pending_data_chunks(pending_data_chunks.clone());
```
