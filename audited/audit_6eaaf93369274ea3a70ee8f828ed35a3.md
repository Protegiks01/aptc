# Audit Report

## Title
Critical Node Liveness Failure Due to Corrupted Indexer Metadata Without Recovery Mechanism

## Summary
If the indexer metadata becomes corrupted and unreadable, the Aptos node will panic during startup and cannot recover automatically. There is no recovery mechanism, requiring manual deletion of the corrupted indexer database and potentially hours to days of downtime while rebuilding from the main ledger database or genesis.

## Finding Description

The indexer metadata schemas (`IndexerMetadataSchema` and `InternalIndexerMetadataSchema`) use BCS (Binary Canonical Serialization) to encode and decode metadata keys and values. [1](#0-0) 

When the database is opened, metadata is read to determine the latest indexed version. If the metadata is corrupted (due to disk corruption, incomplete writes, hardware failure, or file system errors), the `bcs::from_bytes()` call will fail during deserialization. [2](#0-1) 

The critical failure point occurs in the `InternalIndexerDBService` where database opening uses `.expect()` which causes a panic on any error: [3](#0-2) 

Additionally, the `get_indexer_db_for_restore()` method has the same vulnerability: [4](#0-3) 

Furthermore, during the `get_start_version()` call, if metadata reads return inconsistent values (which can happen during partial corruption), the code explicitly panics: [5](#0-4) 

The automatic catch-up mechanism only works if the indexer opens successfully: [6](#0-5) 

**There is no recovery mechanism in the codebase.** Even the official node wipe script only deletes ledger_db, state_merkle_db, and state_sync_db, completely omitting indexer databases: [7](#0-6) 

The storage README acknowledges that the internal indexer is experimental but provides no guidance on corruption recovery: [8](#0-7) 

## Impact Explanation

This vulnerability meets **Critical Severity** criteria per the Aptos Bug Bounty program for the following reasons:

1. **Total loss of liveness/network availability**: If indexer metadata corruption occurs on a validator node, that validator cannot participate in consensus until manual intervention occurs. If this affects multiple validators simultaneously (e.g., due to a software bug triggering corruption, hardware batch failure, or power outage affecting a data center), the network could lose consensus.

2. **Non-recoverable without manual intervention**: The node will repeatedly crash on startup with no automatic recovery path. An operator must:
   - Identify that indexer metadata is corrupted
   - Manually locate and delete the corrupted indexer database directory
   - Restart the node and wait for complete rebuild

3. **Extended downtime**: After manual deletion, the indexer must rebuild from the main ledger database. For a chain with millions of transactions, this could take hours to days depending on:
   - Number of transactions to reprocess
   - Disk I/O performance
   - CPU processing capacity
   - Network state sync speed

4. **Cascading failure potential**: If a bug in the indexer metadata writing logic causes systematic corruption across multiple nodes, this could trigger widespread node failures.

5. **No documented recovery procedure**: Operators have no official guidance on how to recover from this scenario, increasing mean time to recovery (MTTR).

## Likelihood Explanation

**Likelihood: Medium to High**

This can occur through:

1. **Disk/Hardware corruption**: SSDs can experience bit flips, HDDs can develop bad sectors, RAID controllers can fail - all causing database corruption
2. **Incomplete writes**: Power failures during metadata writes, OS crashes, or SIGKILL signals can leave metadata in an inconsistent state
3. **File system errors**: File system bugs, especially with journaling file systems under high load
4. **Software bugs**: Future bugs in the indexer writing logic could write malformed metadata
5. **Resource exhaustion**: Disk full scenarios during metadata writes could leave partial/corrupted data

The likelihood is increased because:
- Indexer metadata is written frequently (every batch of transactions)
- The `.expect()` pattern means ANY corruption causes immediate failure
- No checksums or validation before deserialization
- No fallback or recovery mechanism
- BCS deserialization is strict and will fail on any format violation

## Recommendation

Implement a multi-layered recovery mechanism:

### 1. Add Graceful Error Handling
Replace `.expect()` with proper error handling that attempts recovery:

```rust
pub fn get_indexer_db(node_config: &NodeConfig) -> Result<Option<InternalIndexerDB>> {
    if !node_config.indexer_db_config.is_internal_indexer_db_enabled() {
        return Ok(None);
    }
    
    let db_path_buf = node_config.storage.get_dir_paths().default_root_path().join(INTERNAL_INDEXER_DB);
    let rocksdb_config = node_config.storage.rocksdb_configs.index_db_config;
    
    match open_internal_indexer_db(db_path_buf.as_path(), &rocksdb_config) {
        Ok(db) => {
            let arc_db = Arc::new(db);
            Ok(Some(InternalIndexerDB::new(arc_db, node_config.indexer_db_config)))
        },
        Err(e) => {
            warn!("Failed to open internal indexer db: {}. Attempting recovery...", e);
            
            // Attempt to recover by deleting corrupted metadata and rebuilding
            if try_recover_indexer_db(&db_path_buf, &rocksdb_config, node_config)? {
                info!("Successfully recovered indexer database");
                let db = open_internal_indexer_db(db_path_buf.as_path(), &rocksdb_config)?;
                Ok(Some(InternalIndexerDB::new(Arc::new(db), node_config.indexer_db_config)))
            } else {
                bail!("Failed to recover indexer database. Manual intervention required.");
            }
        }
    }
}
```

### 2. Implement Metadata Validation
Add checksums to metadata entries and validate before deserialization:

```rust
impl ValueCodec<InternalIndexerMetadataSchema> for MetadataValue {
    fn encode_value(&self) -> Result<Vec<u8>> {
        let serialized = bcs::to_bytes(self)?;
        let checksum = calculate_checksum(&serialized);
        Ok([serialized, checksum.to_vec()].concat())
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        if data.len() < CHECKSUM_SIZE {
            bail!("Metadata too short to contain checksum");
        }
        
        let (serialized, checksum) = data.split_at(data.len() - CHECKSUM_SIZE);
        if !verify_checksum(serialized, checksum) {
            bail!("Metadata checksum validation failed - possible corruption");
        }
        
        Ok(bcs::from_bytes(serialized).context("Failed to deserialize metadata")?)
    }
}
```

### 3. Add Automatic Rebuild Capability
Implement automatic detection and rebuild on corruption:

```rust
fn try_recover_indexer_db(db_path: &Path, config: &RocksdbConfig, node_config: &NodeConfig) -> Result<bool> {
    warn!("Attempting automatic indexer database recovery");
    
    // Back up corrupted database for forensics
    let backup_path = db_path.with_extension("corrupted_backup");
    std::fs::rename(db_path, &backup_path)?;
    info!("Backed up corrupted database to {:?}", backup_path);
    
    // Create fresh database - will rebuild from main ledger DB automatically
    let db = open_internal_indexer_db(db_path, config)?;
    
    info!("Indexer database recovery initiated. Will rebuild from main ledger database.");
    Ok(true)
}
```

### 4. Add Monitoring and Alerting
Log corruption events for monitoring:

```rust
if let Err(e) = bcs::from_bytes(data) {
    error!(
        metadata_key = ?key,
        error = ?e,
        "CRITICAL: Indexer metadata corruption detected"
    );
    INDEXER_METADATA_CORRUPTION_COUNT.inc();
}
```

## Proof of Concept

```rust
// File: storage/indexer_schemas/src/schema/indexer_metadata/corruption_test.rs
#[cfg(test)]
mod corruption_tests {
    use super::*;
    use aptos_schemadb::DB;
    use tempfile::tempdir;
    
    #[test]
    fn test_corrupted_metadata_causes_open_failure() {
        // Create a temporary database
        let temp_dir = tempdir().unwrap();
        let db_path = temp_dir.path().join("test_indexer_db");
        
        // Open database and write valid metadata
        {
            let db = DB::open(
                &db_path,
                "test_indexer",
                internal_indexer_column_families(),
                &Default::default(),
            ).unwrap();
            
            // Write valid metadata
            let mut batch = SchemaBatch::new();
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::LatestVersion,
                &MetadataValue::Version(1000),
            ).unwrap();
            db.write_schemas(batch).unwrap();
        }
        
        // Corrupt the metadata by writing invalid BCS bytes
        {
            let db = DB::open(
                &db_path,
                "test_indexer",
                internal_indexer_column_families(),
                &Default::default(),
            ).unwrap();
            
            // Write corrupted metadata (invalid BCS format)
            let corrupted_data = vec![0xFF, 0xFF, 0xFF, 0xFF]; // Invalid BCS
            db.put_raw(
                INTERNAL_INDEXER_METADATA_CF_NAME,
                &bcs::to_bytes(&MetadataKey::LatestVersion).unwrap(),
                &corrupted_data,
            ).unwrap();
        }
        
        // Attempt to read - this should fail with BCS deserialization error
        {
            let db = DB::open(
                &db_path,
                "test_indexer",
                internal_indexer_column_families(),
                &Default::default(),
            ).unwrap();
            
            let result = db.get::<InternalIndexerMetadataSchema>(&MetadataKey::LatestVersion);
            
            // This demonstrates the vulnerability: corrupted metadata cannot be read
            assert!(result.is_err());
            assert!(result.unwrap_err().to_string().contains("deserialize"));
        }
        
        // In production, this error would cause .expect() to panic,
        // bringing down the entire node with no recovery mechanism
    }
}
```

To reproduce the actual node crash:

```bash
# 1. Start a node with internal indexer enabled
# 2. While running, corrupt the metadata:
#    - Locate the internal_indexer_db directory
#    - Use a hex editor to corrupt metadata files
#    - Or simulate by: dd if=/dev/urandom of=internal_indexer_db/MANIFEST-000001 bs=1 count=10 conv=notrunc
# 3. Restart the node
# 4. Observe panic: "Failed to open internal indexer db"
# 5. Node cannot start without manual deletion of corrupted database
```

---

**Notes:**

- This vulnerability affects both `IndexerMetadataSchema` and `InternalIndexerMetadataSchema`
- The issue is exacerbated by lack of documentation in the storage README about recovery procedures
- The automatic rebuild mechanism (in `open_indexer()`) only works if the database opens successfully - it cannot help with corruption
- Current error handling uses `.expect()` which is appropriate for programming errors but catastrophic for data corruption scenarios
- The vulnerability could affect API nodes and validator nodes that have indexer enabled
- Production deployments should implement disk health monitoring and regular backups of indexer databases as mitigation until this is fixed

### Citations

**File:** storage/indexer_schemas/src/schema/indexer_metadata/mod.rs (L25-42)
```rust
impl KeyCodec<IndexerMetadataSchema> for MetadataKey {
    fn encode_key(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(self)?)
    }

    fn decode_key(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

impl ValueCodec<IndexerMetadataSchema> for MetadataValue {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
```

**File:** storage/indexer/src/lib.rs (L73-75)
```rust
        let next_version = db
            .get::<IndexerMetadataSchema>(&MetadataKey::LatestVersion)?
            .map_or(0, |v| v.expect_version());
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L49-51)
```rust
        let arc_db = Arc::new(
            open_internal_indexer_db(db_path_buf.as_path(), &rocksdb_config)
                .expect("Failed to open internal indexer db"),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L74-76)
```rust
        let arc_db = Arc::new(
            open_internal_indexer_db(db_path, &rocksdb_config)
                .expect("Failed to open internal indexer db"),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L114-116)
```rust
            if start_version != state_start_version {
                panic!("Cannot start state indexer because the progress doesn't match.");
            }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L207-228)
```rust
        if indexer.next_version() < ledger_next_version {
            use aptos_storage_interface::state_store::state_view::db_state_view::DbStateViewAtVersion;
            let db: Arc<dyn DbReader> = self.state_store.clone();

            let state_view = db.state_view_at_version(Some(ledger_next_version - 1))?;
            let annotator = AptosValueAnnotator::new(&state_view);

            const BATCH_SIZE: Version = 10000;
            let mut next_version = indexer.next_version();
            while next_version < ledger_next_version {
                info!(next_version = next_version, "AptosDB Indexer catching up. ",);
                let end_version = std::cmp::min(ledger_next_version, next_version + BATCH_SIZE);
                let write_sets = self
                    .ledger_db
                    .write_set_db()
                    .get_write_sets(next_version, end_version)?;
                let write_sets_ref: Vec<_> = write_sets.iter().collect();
                indexer.index_with_annotator(&annotator, next_version, &write_sets_ref)?;

                next_version = end_version;
            }
        }
```

**File:** testsuite/pangu_lib/node_commands/wipe_node.py (L26-32)
```python
    ledger_db_path = path.join(util.APTOS_DATA_DIR, "db", util.LEDGER_DB_NAME)
    state_db_path = path.join(util.APTOS_DATA_DIR, "db", util.STATE_MERKLE_DB_NAME)
    state_sync_db_path = path.join(util.APTOS_DATA_DIR, "db", util.STATE_SYNC_DB_NAME)

    #
    # Deletion commands
    deletion_command = ["rm", "-rf", ledger_db_path, state_db_path, state_sync_db_path]
```

**File:** storage/README.md (L149-150)
```markdown
  # The internal indexer is experimental, and should be kept disabled.
  enable_indexer: false
```
