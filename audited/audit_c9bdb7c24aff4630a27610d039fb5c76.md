# Audit Report

## Title
ConsensusSessionKey Insufficient Uniqueness Allows Concurrent Session Conflicts and QC Rejection in JWK Consensus

## Summary
The `ConsensusSessionKey` type in per-key JWK consensus mode uses only `(Issuer, KID)` as the session identifier, omitting the actual JWK value (cryptographic key material). This insufficient uniqueness allows different JWK values with the same `(Issuer, KID)` to map to the same session key, causing concurrent consensus sessions to conflict. Combined with a race condition in the abort mechanism and a KLAST queue of size 1, this enables legitimate quorum-certified updates to be dropped or rejected, preventing valid JWK updates from being processed.

## Finding Description
The vulnerability exists in the JWK consensus per-key mode implementation. The session key is defined as a tuple of `(Issuer, KID)`: [1](#0-0) 

Where both types are `Vec<u8>`: [2](#0-1) 

For RSA JWKs, the `id()` method returns only the `kid` field: [3](#0-2) 

This means two different RSA_JWK instances with the same `kid` but different modulus/exponent values will produce the same session key. The consensus state is stored in a HashMap keyed by this session key: [4](#0-3) 

**Attack Path:**

1. A legitimate JWK update for `(issuer="google.com", kid="key1", modulus=N1)` starts consensus session C1
2. An observation of a different value `(issuer="google.com", kid="key1", modulus=N2)` arrives (could occur during legitimate OIDC provider key rotation or through attacker manipulation)
3. In `maybe_start_consensus`, the code checks if consensus is already in progress: [5](#0-4) 

4. Since `N1 != N2`, the check at line 187 fails, and a new consensus session C2 is started
5. The `states_by_key.insert()` call overwrites C1's state with C2's state: [6](#0-5) 

6. This drops the old `QuorumCertProcessGuard`, triggering its `Drop` implementation: [7](#0-6) 

7. **Race Condition**: If C1's async task has already completed `rb.broadcast().await` and is executing the synchronous code afterward, the abort won't prevent the QC from being pushed to the channel: [8](#0-7) 

8. After line 68 (await completes), the remaining code is synchronous with no more await points, so the task runs to completion even after abort is called

9. Both QC1 and QC2 are pushed to the channel with the same key `(issuer, kid)`

10. The channel uses KLAST queue style with size 1: [9](#0-8) 

11. KLAST drops the oldest message when full: [10](#0-9) 

12. QC1 is dropped, only QC2 remains

13. Alternatively, if QC1 arrives for processing after the state has been overwritten, it gets rejected: [11](#0-10) 

The state check at line 335 expects `InProgress`, but if the state has been overwritten or finished for a different value, the QC is rejected with an error at line 356-360.

## Impact Explanation
This vulnerability breaks the liveness guarantee of the JWK update mechanism, preventing legitimate JWK updates from being processed. The impact includes:

- **Keyless Authentication Failure**: JWK updates are critical for keyless authentication. Blocked updates prevent new keys from being recognized, breaking authentication for users
- **Localized Denial of Service**: Individual validators can have their JWK consensus disrupted for specific `(issuer, kid)` pairs
- **Consensus Mechanism Corruption**: Legitimate quorum-certified updates that validators worked to produce can be silently dropped or rejected

This qualifies as **High Severity** under Aptos bug bounty criteria:
- Significant protocol violation (JWK consensus mechanism failure)
- Validator node functionality degradation (inability to process legitimate JWK updates)
- Affects a critical subsystem (keyless authentication infrastructure)

## Likelihood Explanation
**Likelihood: Medium to High**

The vulnerability can be triggered in several scenarios:

1. **Legitimate OIDC Provider Key Rotation**: When an OIDC provider rotates their JWK, validators fetching at slightly different times may observe different values, naturally triggering the race condition

2. **Network Timing Variance**: The periodic fetch from OIDC providers (every 10 seconds) combined with network latency can cause validators to observe different values during provider updates

3. **Attacker-Induced**: An attacker with the ability to influence observations (via MITM, DNS poisoning, or compromised provider endpoints) can deliberately trigger rapid observations of different values

The race window is narrow but exploitable because:
- The async task completion and push to channel is not atomic with the state update
- KLAST queue size of 1 guarantees message loss under concurrent pushes
- No validation that incoming QCs match the current expected state value

## Recommendation

**Fix 1: Include JWK value hash in session key**

Modify `ConsensusSessionKey` to include a hash of the actual JWK value, making it unique per value:

```rust
// In per_key.rs
type ConsensusSessionKey = (Issuer, KID, HashValue);

fn session_key_from_qc(qc: &QuorumCertifiedUpdate) -> anyhow::Result<(Issuer, KID, HashValue)> {
    let KeyLevelUpdate { issuer, kid, .. } = 
        KeyLevelUpdate::try_from_issuer_level_repr(&qc.update)?;
    let value_hash = CryptoHash::hash(&qc.update);
    Ok((issuer, kid, value_hash))
}
```

**Fix 2: Validate QC matches expected value before processing**

In `process_quorum_certified_update`, verify that the incoming QC's value matches the state's expected value:

```rust
match state {
    ConsensusState::InProgress { my_proposal, .. } => {
        // Verify the QC matches what we're expecting
        if my_proposal.observed != key_level_update {
            return Err(anyhow!(
                "QC value mismatch: expected {:?}, got {:?}",
                my_proposal.observed, key_level_update
            ));
        }
        // Process QC...
    }
}
```

**Fix 3: Increase KLAST queue size or use proper deduplication**

Change the queue size from 1 to a larger value, or implement proper deduplication based on QC content hash rather than session key alone.

## Proof of Concept

```rust
// Rust integration test demonstrating the vulnerability
#[tokio::test]
async fn test_concurrent_jwk_consensus_conflict() {
    // Setup: Create a KeyLevelConsensusManager
    let manager = setup_test_manager();
    
    // Observation 1: JWK with kid="key1", modulus="N1"
    let jwk1 = RSA_JWK::new_256_aqab("key1", "N1");
    let issuer = issuer_from_str("google.com");
    
    // Start consensus for JWK1
    manager.process_new_observation(issuer.clone(), vec![JWK::RSA(jwk1)]).unwrap();
    
    // Verify consensus started
    let state1 = manager.states_by_key.get(&(issuer.clone(), "key1".as_bytes().to_vec()));
    assert!(matches!(state1, Some(ConsensusState::InProgress { .. })));
    
    // Observation 2: Different JWK with same kid="key1", different modulus="N2"
    let jwk2 = RSA_JWK::new_256_aqab("key1", "N2");
    
    // Process new observation - this should overwrite the first
    manager.process_new_observation(issuer.clone(), vec![JWK::RSA(jwk2)]).unwrap();
    
    // Verify the state was overwritten
    let state2 = manager.states_by_key.get(&(issuer.clone(), "key1".as_bytes().to_vec()));
    assert!(matches!(state2, Some(ConsensusState::InProgress { .. })));
    
    // If QC1 completes in the race window and gets pushed to channel,
    // it will either be dropped by KLAST or rejected when processed
    
    // Simulate QC1 arriving after state overwrite
    let qc1 = create_test_qc(issuer.clone(), "key1", "N1");
    let result = manager.process_quorum_certified_update(qc1);
    
    // Assert: QC1 is rejected because state expects N2, not N1
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("not expected"));
}
```

## Notes

The vulnerability is particularly concerning because:

1. **Silent Failure**: Dropped QCs produce no error visible to operators, making the issue difficult to detect
2. **Cascading Impact**: If multiple validators experience this, the network's ability to update JWKs collectively degrades
3. **Critical Subsystem**: JWK consensus underpins keyless authentication, a key feature for Aptos user experience

The root cause is a design flaw where the session key abstraction is insufficient to uniquely identify what value is being consensus-ed upon, violating the principle that concurrent sessions for different values should not conflict.

### Citations

**File:** crates/aptos-jwk-consensus/src/mode/per_key.rs (L12-12)
```rust
    type ConsensusSessionKey = (Issuer, KID);
```

**File:** types/src/jwks/mod.rs (L36-38)
```rust
pub type Issuer = Vec<u8>;
/// Type for JWK Key ID.
pub type KID = Vec<u8>;
```

**File:** types/src/jwks/rsa/mod.rs (L97-99)
```rust
    pub fn id(&self) -> Vec<u8> {
        self.kid.as_bytes().to_vec()
    }
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L59-59)
```rust
    states_by_key: HashMap<(Issuer, KID), ConsensusState<ObservedKeyLevelUpdate>>,
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L79-79)
```rust
        let (qc_update_tx, qc_update_rx) = aptos_channel::new(QueueStyle::KLAST, 1, None);
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L180-194)
```rust
        let consensus_already_started = match self
            .states_by_key
            .get(&(update.issuer.clone(), update.kid.clone()))
            .cloned()
        {
            Some(ConsensusState::InProgress { my_proposal, .. })
            | Some(ConsensusState::Finished { my_proposal, .. }) => {
                my_proposal.observed.to_upsert == update.to_upsert
            },
            _ => false,
        };

        if consensus_already_started {
            return Ok(());
        }
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L216-228)
```rust
        self.states_by_key.insert(
            (update.issuer.clone(), update.kid.clone()),
            ConsensusState::InProgress {
                my_proposal: ObservedKeyLevelUpdate {
                    author: self.my_addr,
                    observed: update,
                    signature,
                },
                abort_handle_wrapper: QuorumCertProcessGuard {
                    handle: abort_handle,
                },
            },
        );
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L334-361)
```rust
        match state {
            ConsensusState::InProgress { my_proposal, .. } => {
                let topic = Topic::JWK_CONSENSUS_PER_KEY_MODE {
                    issuer: issuer.clone(),
                    kid: kid.clone(),
                };
                let txn = ValidatorTransaction::ObservedJWKUpdate(issuer_level_repr.clone());
                let vtxn_guard = self.vtxn_pool.put(topic, Arc::new(txn), None);
                *state = ConsensusState::Finished {
                    vtxn_guard,
                    my_proposal: my_proposal.clone(),
                    quorum_certified: issuer_level_repr,
                };
                info!(
                    epoch = self.epoch_state.epoch,
                    issuer = issuer_str,
                    kid = kid_str,
                    base_version = key_level_update.base_version,
                    "certified key-level update accepted."
                );
                Ok(())
            },
            _ => Err(anyhow!(
                "qc update not expected for issuer {:?} in state {}",
                String::from_utf8(issuer.clone()),
                state.name()
            )),
        }
```

**File:** crates/aptos-jwk-consensus/src/types.rs (L96-101)
```rust
impl Drop for QuorumCertProcessGuard {
    fn drop(&mut self) {
        let QuorumCertProcessGuard { handle } = self;
        handle.abort();
    }
}
```

**File:** crates/aptos-jwk-consensus/src/update_certifier.rs (L67-79)
```rust
        let task = async move {
            let qc_update = rb.broadcast(req, agg_state).await.expect("cannot fail");
            ConsensusMode::log_certify_done(epoch, &qc_update);
            let session_key = ConsensusMode::session_key_from_qc(&qc_update);
            match session_key {
                Ok(key) => {
                    let _ = qc_update_tx.push(key, qc_update);
                },
                Err(e) => {
                    error!("JWK update QCed but could not identify the session key: {e}");
                },
            }
        };
```

**File:** crates/channel/src/message_queues.rs (L142-146)
```rust
                QueueStyle::LIFO | QueueStyle::KLAST => {
                    let oldest = key_message_queue.pop_front();
                    key_message_queue.push_back(message);
                    oldest
                },
```
