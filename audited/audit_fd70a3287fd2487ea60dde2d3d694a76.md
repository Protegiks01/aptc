# Audit Report

## Title
Peer Monitoring Service Lacks Error Weighting in Reputation Tracking, Enabling Malicious Peers to Maintain High Priority

## Summary
The peer monitoring service tracks consecutive failures that reset to zero upon any successful response, lacking cumulative error rate tracking or reputation degradation. This allows malicious peers to intersperse errors with valid responses to maintain artificially good metrics and high priority in mempool peer selection, enabling subtle network performance degradation attacks.

## Finding Description

The peer monitoring service client tracks peer health through three types of requests: latency pings, network information, and node information. However, the error tracking mechanism only counts **consecutive failures** and completely resets this count to zero upon any successful response. [1](#0-0) 

When a peer responds successfully, the consecutive failure counter is reset: [2](#0-1) 

The only consequence of errors is a warning log after exceeding the threshold (default: 3 consecutive failures): [3](#0-2) [4](#0-3) 

Critically, the peer monitoring metadata (including average latency and validator distance) is used by mempool to prioritize peers for transaction broadcasting: [5](#0-4) 

**Attack Path:**
1. Malicious peer connects to the network
2. For latency ping requests (every 30 seconds):
   - Respond successfully once (resets consecutive failures to 0)
   - Timeout/error on the next 2 requests (consecutive failures = 2)
   - Respond successfully again (resets consecutive failures to 0)
   - Repeat indefinitely
3. Average latency remains good because only successful responses are included in the calculation
4. Peer maintains high priority in mempool peer selection
5. Peer selectively delays or drops transactions while appearing healthy

**Broken Invariant:** The system fails to properly penalize peers exhibiting intermittent malicious behavior, breaking the network protocol's ability to identify and deprioritize misbehaving peers.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty program because it enables:

1. **Degraded Network Performance**: Malicious peers can selectively delay transaction propagation while maintaining high priority, causing state inconsistencies in mempool across nodes
2. **Resource Inefficiency**: Honest nodes waste resources attempting to sync with malicious peers that intentionally provide poor service
3. **Targeted Transaction Censorship**: Attackers can delay specific transactions without being detected or deprioritized

While this does not cause direct fund loss or consensus violations, it degrades network availability and requires intervention to identify and manually ban misbehaving peers.

## Likelihood Explanation

This vulnerability is **highly likely** to be exploited because:

1. **Low Technical Barrier**: Any network peer can implement this attack with minimal effort
2. **No Special Access Required**: Attack works from any public full node connection
3. **Difficult to Detect**: The pattern appears as intermittent network issues rather than malicious behavior
4. **No Automatic Mitigation**: The system never penalizes the peer beyond logging warnings
5. **Sustained Effect**: Once in high-priority pool, peer remains there indefinitely

The attack is sustainable over long periods and provides strategic advantage for transaction censorship or targeted performance degradation.

## Recommendation

Implement a cumulative error rate tracking system with reputation scoring that gradually degrades peer priority based on overall error frequency, not just consecutive failures. The solution should:

1. **Track Error Rate**: Maintain a sliding window of total errors vs. total requests
2. **Implement Reputation Scoring**: Similar to the state-sync data client's approach: [6](#0-5) 

3. **Apply Score-Based Deprioritization**: Use peer scores in mempool prioritization
4. **Gradual Recovery**: Allow scores to recover slowly over time with consistent good behavior

**Recommended Code Fix:**

Add to `RequestTracker`:
```rust
// Track total requests and errors for reputation calculation
total_requests: u64,
total_errors: u64,
error_rate_window_size: u64, // e.g., last 100 requests
```

Modify failure handling:
```rust
pub fn record_response_failure(&mut self) {
    self.num_consecutive_request_failures += 1;
    self.total_errors += 1;
    self.total_requests += 1;
}

pub fn record_response_success(&mut self) {
    self.num_consecutive_request_failures = 0; // Still reset consecutive
    self.total_requests += 1;
    // But retain total_errors for reputation calculation
}

pub fn get_error_rate(&self) -> f64 {
    if self.total_requests == 0 { return 0.0; }
    self.total_errors as f64 / self.total_requests as f64
}
```

Then use error rate to influence peer prioritization in mempool.

## Proof of Concept

```rust
#[tokio::test]
async fn test_intermittent_error_gaming() {
    use peer_monitoring_service::peer_states::request_tracker::RequestTracker;
    use aptos_time_service::TimeService;
    
    let time_service = TimeService::mock();
    let mut tracker = RequestTracker::new(1000, time_service);
    
    // Simulate attack pattern: 2 failures, 1 success, repeat
    for cycle in 0..10 {
        // Fail twice
        tracker.request_started();
        tracker.request_completed();
        tracker.record_response_failure();
        assert_eq!(tracker.get_num_consecutive_failures(), 1);
        
        tracker.request_started();
        tracker.request_completed();
        tracker.record_response_failure();
        assert_eq!(tracker.get_num_consecutive_failures(), 2);
        
        // Succeed once - RESETS everything
        tracker.request_started();
        tracker.request_completed();
        tracker.record_response_success();
        assert_eq!(tracker.get_num_consecutive_failures(), 0);
        
        // Peer maintains "good" reputation despite 66% error rate
    }
    
    // After 10 cycles: 20 errors, 10 successes = 66% error rate
    // But consecutive failures never exceeded threshold (3)
    // Peer remains in high-priority pool for mempool
    
    println!("Attack successful: 66% error rate but never flagged as malicious");
}
```

## Notes

This vulnerability is distinct from the state-sync data client's peer scoring system, which does implement proper error weighting. The peer monitoring service lacks this protection, creating an exploitable gap in the network's defense against malicious peers. The issue is particularly concerning because mempool peer prioritization directly relies on peer monitoring metadata for making critical decisions about transaction propagation.

### Citations

**File:** peer-monitoring-service/client/src/peer_states/request_tracker.rs (L92-104)
```rust
    /// Records a successful response for the request
    pub fn record_response_success(&mut self) {
        // Update the last response time
        self.last_response_time = Some(self.time_service.now());

        // Reset the number of consecutive failures
        self.num_consecutive_request_failures = 0;
    }

    /// Records a failure for the request
    pub fn record_response_failure(&mut self) {
        self.num_consecutive_request_failures += 1;
    }
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L60-72)
```rust
    fn handle_request_failure(&self, peer_network_id: &PeerNetworkId) {
        // Update the number of ping failures for the request tracker
        self.request_tracker.write().record_response_failure();

        // TODO: If the number of ping failures is too high, disconnect from the node
        let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
        if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::TooManyPingFailures)
                .peer(peer_network_id)
                .message("Too many ping failures occurred for the peer!"));
        }
    }
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L76-97)
```rust
    pub fn record_new_latency_and_reset_failures(
        &mut self,
        latency_ping_counter: u64,
        latency_ping_time_secs: f64,
    ) {
        // Update the request tracker with a successful response
        self.request_tracker.write().record_response_success();

        // Save the latency ping time
        self.recorded_latency_ping_durations_secs
            .insert(latency_ping_counter, latency_ping_time_secs);

        // Perform garbage collection on the recorded latency pings
        let max_num_latency_pings_to_retain = self
            .latency_monitoring_config
            .max_num_latency_pings_to_retain;
        if self.recorded_latency_ping_durations_secs.len() > max_num_latency_pings_to_retain {
            // We only need to pop a single element because insertion only happens in this method.
            // Thus, the size can only ever grow to be 1 greater than the max.
            let _ = self.recorded_latency_ping_durations_secs.pop_first();
        }
    }
```

**File:** config/src/config/peer_monitoring_config.rs (L47-55)
```rust
impl Default for LatencyMonitoringConfig {
    fn default() -> Self {
        Self {
            latency_ping_interval_ms: 30_000, // 30 seconds
            latency_ping_timeout_ms: 20_000,  // 20 seconds
            max_latency_ping_failures: 3,
            max_num_latency_pings_to_retain: 10,
        }
    }
```

**File:** mempool/src/shared_mempool/priority.rs (L74-120)
```rust
    fn compare_intelligent(
        &self,
        peer_a: &(PeerNetworkId, Option<&PeerMonitoringMetadata>),
        peer_b: &(PeerNetworkId, Option<&PeerMonitoringMetadata>),
    ) -> Ordering {
        // Deconstruct the peer tuples
        let (peer_network_id_a, monitoring_metadata_a) = peer_a;
        let (peer_network_id_b, monitoring_metadata_b) = peer_b;

        // First, compare the peers by health (e.g., sync lag)
        let unhealthy_ordering = compare_peer_health(
            &self.mempool_config,
            &self.time_service,
            monitoring_metadata_a,
            monitoring_metadata_b,
        );
        if !unhealthy_ordering.is_eq() {
            return unhealthy_ordering; // Only return if it's not equal
        }

        // Next, compare by network ID (i.e., Validator > VFN > Public)
        let network_ordering = compare_network_id(
            &peer_network_id_a.network_id(),
            &peer_network_id_b.network_id(),
        );
        if !network_ordering.is_eq() {
            return network_ordering; // Only return if it's not equal
        }

        // Otherwise, compare by peer distance from the validators.
        // This avoids badly configured/connected peers (e.g., broken VN-VFN connections).
        let distance_ordering =
            compare_validator_distance(monitoring_metadata_a, monitoring_metadata_b);
        if !distance_ordering.is_eq() {
            return distance_ordering; // Only return if it's not equal
        }

        // Otherwise, compare by peer ping latency (the lower the better)
        let latency_ordering = compare_ping_latency(monitoring_metadata_a, monitoring_metadata_b);
        if !latency_ordering.is_eq() {
            return latency_ordering; // Only return if it's not equal
        }

        // Otherwise, simply hash the peer IDs and compare the hashes.
        // In practice, this should be relatively rare.
        self.compare_hash(peer_network_id_a, peer_network_id_b)
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```
