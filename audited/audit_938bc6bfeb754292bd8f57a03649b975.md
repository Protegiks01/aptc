# Audit Report

## Title
Incorrect `more` Field in Epoch Change Proofs Causes Peer Desynchronization and State Sync Failures

## Summary
The storage service's `get_epoch_ending_ledger_infos_by_size` function unconditionally sets the `more` field to `false` in `EpochChangeProof` responses, even when the response is incomplete due to size limits, time limits, or missing data. This causes clients to incorrectly believe they have received all requested epoch-ending ledger infos, leading to verification failures and peer desynchronization. [1](#0-0) 

## Finding Description
The vulnerability exists in the size-and-time-aware chunking implementation of epoch ending ledger info retrieval. When a client requests epoch-ending ledger infos from `start_epoch` to `expected_end_epoch`, the server may return fewer epochs than requested due to:

1. **Size limitations**: Response exceeds `max_response_size` [2](#0-1) 

2. **Time limitations**: Storage read exceeds `max_storage_read_wait_time_ms` [3](#0-2) 

3. **Missing data**: The underlying storage iterator runs out of data prematurely [4](#0-3) 

In all three cases, the function creates an `EpochChangeProof` with `more = false`, incorrectly signaling that all requested epochs have been provided.

This breaks the epoch change verification protocol. When a client receives an incomplete `EpochChangeProof` with `more = false` and then receives a `latest_ledger_info` from an epoch beyond what was provided in the proof, the verification logic rejects it as inconsistent: [5](#0-4) 

The condition at line 183 requires `epoch_change_proof.more` to be `true` when the latest ledger info's epoch exceeds the proof's epoch range. Since `more` is incorrectly set to `false`, the verification fails with "Inconsistent epoch change proof and latest ledger info", even though the proof is simply incomplete, not inconsistent.

Contrast this with the underlying database implementation, which correctly determines the `more` field: [6](#0-5) 

The database correctly sets `more = true` when the requested range exceeds the limit, but the storage service layer discards this information in the new implementation.

## Impact Explanation
This is a **HIGH severity** vulnerability per the Aptos bug bounty program criteria:

1. **Validator Node Slowdowns**: Nodes repeatedly fail to verify valid epoch changes, causing them to retry requests, fall behind in synchronization, and experience degraded performance.

2. **Significant Protocol Violations**: The `more` field is part of the state synchronization protocol's contract. Setting it incorrectly violates the protocol's correctness guarantees and breaks the trust model between peers.

3. **Peer Desynchronization**: Different nodes may have different views of which epochs are "complete," leading to inconsistent state across the network. A node with incomplete epoch data marked as complete may make incorrect decisions about which peers to trust or which epoch changes to accept.

4. **State Sync Liveness Issues**: Nodes may become stuck unable to progress past certain epochs when legitimate epoch change proofs are rejected as "inconsistent." This is particularly problematic during network partitions or when syncing from lagging peers.

The impact is multiplied when the `enable_size_and_time_aware_chunking` configuration is enabled (which is likely for performance reasons), as this activates the buggy code path. [7](#0-6) 

## Likelihood Explanation
This vulnerability has **HIGH likelihood** of occurrence:

1. **Natural Triggers**: The bug is triggered naturally during normal operations when:
   - A node is syncing from a lagging peer that doesn't have all requested epochs
   - Response size limits are exceeded for large epoch change proofs
   - Storage read times exceed configured limits during heavy load

2. **No Attacker Required**: The vulnerability manifests without malicious intent. Any node that is behind in synchronization or experiences slow storage reads will serve incorrect `more` flags.

3. **Common Scenario**: During network upgrades or when new nodes join, they must sync through many epochs. If any peer in the sync path has size or time limitations, incorrect `more` flags will be served.

4. **Configuration Dependent**: When `enable_size_and_time_aware_chunking` is enabled (the modern, recommended configuration), the buggy code path is always used.

## Recommendation
The `more` field should be set to `true` whenever fewer epoch-ending ledger infos are returned than requested. The fix requires comparing the number of returned epochs against the expected number:

```rust
// After the while loop that fetches ledger infos
let num_fetched_ledger_infos = epoch_ending_ledger_infos.len() as u64;
let more = num_fetched_ledger_infos < num_ledger_infos_to_fetch;

// Create the epoch change proof with the correct 'more' flag
let epoch_change_proof = EpochChangeProof::new(epoch_ending_ledger_infos, more);
```

This ensures that:
- `more = true` when the response is truncated (due to size, time, or missing data)
- `more = false` only when all requested epochs were successfully returned
- Clients can correctly handle incomplete responses and make additional requests as needed

The same fix should be verified for consistency with the legacy implementation to ensure both code paths behave correctly.

## Proof of Concept
```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_incomplete_epoch_proof_incorrect_more_flag() {
    // Setup: Create a storage service with epochs 0-5 available
    let mut mock_db = MockDbReader::new();
    mock_db.set_available_epochs(0, 5);
    
    let storage_reader = StorageReader::new(
        StorageServiceConfig {
            max_epoch_chunk_size: 100,
            enable_size_and_time_aware_chunking: true,
            ..Default::default()
        },
        Arc::new(mock_db),
        TimeService::mock(),
    );
    
    // Client requests epochs 0-10
    let request = EpochEndingLedgerInfoRequest {
        start_epoch: 0,
        expected_end_epoch: 10,
    };
    
    // Server returns only epochs 0-5 (due to missing data)
    let result = storage_reader
        .get_epoch_ending_ledger_infos(request.start_epoch, request.expected_end_epoch)
        .unwrap();
    
    // BUG: more is set to false even though only 6 out of 11 epochs were returned
    assert_eq!(result.ledger_info_with_sigs.len(), 6);
    assert_eq!(result.more, false); // Should be true!
    
    // Now try to verify with a ledger info at epoch 7
    let latest_li = create_ledger_info_at_epoch(7);
    let trusted_state = TrustedState::from_epoch_waypoint(waypoint_at_epoch_0);
    
    // Verification fails with "Inconsistent epoch change proof and latest ledger info"
    // because more=false suggests all epochs were provided
    let verify_result = trusted_state.verify_and_ratchet_inner(&latest_li, &result);
    
    // This should succeed (or gracefully handle the incomplete proof)
    // but instead fails due to the incorrect 'more' flag
    assert!(verify_result.is_err());
    assert!(verify_result.unwrap_err().to_string().contains("Inconsistent"));
}
```

This test demonstrates that when fewer epochs are returned than requested, the `more` field is incorrectly set to `false`, causing subsequent verification to fail when it should succeed or prompt additional data fetching.

### Citations

**File:** state-sync/storage-service/server/src/storage.rs (L264-271)
```rust
                    if response_progress_tracker
                        .data_items_fits_in_response(true, num_serialized_bytes)
                    {
                        epoch_ending_ledger_infos.push(epoch_ending_ledger_info);
                        response_progress_tracker.add_data_item(num_serialized_bytes);
                    } else {
                        break; // Cannot add any more data items
                    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L276-284)
```rust
                None => {
                    // Log a warning that the iterator did not contain all the expected data
                    warn!(
                        "The epoch ending ledger info iterator is missing data! \
                        Start epoch: {:?}, expected end epoch: {:?}, num ledger infos to fetch: {:?}",
                        start_epoch, expected_end_epoch, num_ledger_infos_to_fetch
                    );
                    break;
                },
```

**File:** state-sync/storage-service/server/src/storage.rs (L288-289)
```rust
        // Create the epoch change proof
        let epoch_change_proof = EpochChangeProof::new(epoch_ending_ledger_infos, false);
```

**File:** state-sync/storage-service/server/src/storage.rs (L1097-1102)
```rust
        self.get_epoch_ending_ledger_infos_by_size(
            start_epoch,
            expected_end_epoch,
            self.config.max_network_chunk_bytes,
            self.config.enable_size_and_time_aware_chunking,
        )
```

**File:** state-sync/storage-service/server/src/storage.rs (L1436-1444)
```rust
    /// Checks if the storage read duration has overflowed the maximum wait time
    fn overflowed_storage_read_duration(&self) -> bool {
        let time_now = self.time_service.now();
        let time_elapsed_ms = time_now
            .duration_since(self.storage_read_start_time)
            .as_millis() as u64;

        time_elapsed_ms >= self.max_storage_read_wait_time_ms
    }
```

**File:** types/src/trusted_state.rs (L178-187)
```rust
            let verified_ledger_info = if epoch_change_li == latest_li {
                latest_li
            } else if latest_li.ledger_info().epoch() == new_epoch {
                new_epoch_state.verify(latest_li)?;
                latest_li
            } else if latest_li.ledger_info().epoch() > new_epoch && epoch_change_proof.more {
                epoch_change_li
            } else {
                bail!("Inconsistent epoch change proof and latest ledger info");
            };
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1036-1048)
```rust
    pub(super) fn get_epoch_ending_ledger_infos_impl(
        &self,
        start_epoch: u64,
        end_epoch: u64,
        limit: usize,
    ) -> Result<(Vec<LedgerInfoWithSignatures>, bool)> {
        self.check_epoch_ending_ledger_infos_request(start_epoch, end_epoch)?;

        let (paging_epoch, more) = if end_epoch - start_epoch > limit as u64 {
            (start_epoch + limit as u64, true)
        } else {
            (end_epoch, false)
        };
```
