# Audit Report

## Title
Missing Configuration Validation for DAG Consensus Quorum Store Batch Limits Can Cause Network Liveness Failure

## Summary
The DAG consensus configuration sanitizer fails to validate that quorum store batch size limits are compatible with DAG payload limits. This allows configurations where individual batches exceed per-node transaction limits, causing empty block generation and potential network liveness failure.

## Finding Description

The Aptos configuration sanitization system has a validation gap specific to DAG consensus. While traditional consensus properly validates that quorum store batch limits do not exceed block limits, DAG consensus lacks equivalent validation.

**Traditional Consensus Validation Chain:** [1](#0-0) [2](#0-1) 

This creates the transitive constraint: `sender_max_batch_txns` ≤ `receiver_max_batch_txns` ≤ `max_sending_block_txns`.

**DAG Consensus Validation Gap:**

The DAG consensus config includes a `quorum_store` field but its sanitizer does not validate batch limits against DAG payload limits: [3](#0-2) 

The `DagPayloadConfig` sanitizer only validates internal consistency: [4](#0-3) 

**Missing Validation:** There is no check that `quorum_store.receiver_max_batch_txns` ≤ `dag_payload_config.max_sending_txns_per_round` or that `quorum_store.receiver_max_batch_bytes` ≤ `dag_payload_config.max_sending_size_per_round_bytes`.

**Runtime Enforcement Mechanism:**

When DAG creates a new node, it calculates payload limits: [5](#0-4) 

These limits are divided among validators and passed to the payload client: [6](#0-5) 

The batch proof queue enforces these limits during batch pulling: [7](#0-6) 

If a single batch exceeds `max_txns`, the condition `cur_all_txns + batch.size() > max_txns` triggers immediately, setting `full = true` and returning an empty result, causing empty blocks.

## Impact Explanation

**Severity: Critical** - Total loss of liveness/network availability (up to $1,000,000 per Aptos Bug Bounty)

If DAG consensus validators are configured with:
- `quorum_store.sender_max_batch_txns = 15,000`
- `quorum_store.receiver_max_batch_txns = 15,000`  
- `dag_payload_config.max_sending_txns_per_round = 1,000`
- `dag_payload_config.max_receiving_txns_per_round = 20,000`

The sanitizers pass all checks (15,000 ≤ 15,000 ✓, 1,000 ≤ 20,000 ✓), but at runtime:
1. Batches are created with 15,000 transactions
2. Per-node limit = 1,000 / 100 validators = 10 transactions
3. Every batch exceeds the limit, resulting in empty nodes
4. No transactions are processed, causing network halt

This violates the critical invariant: "Resource Limits: All operations must respect gas, storage, and computational limits."

## Likelihood Explanation

**Likelihood: Medium**

While the default DAG configurations are safe (300 txns/batch, 10,000 txns/round), the vulnerability can manifest through:

1. **Operator Misconfiguration**: Administrators tuning performance parameters without understanding the constraint dependencies
2. **Configuration Template Errors**: Incorrect configuration templates distributed to validators
3. **Automated Configuration Systems**: Infrastructure-as-code deployments with invalid parameter combinations

The missing validation means there is no safety net preventing these scenarios. For a critical network with multiple operators, configuration errors are realistic risks that should be prevented at the validation layer.

## Recommendation

Add comprehensive validation in `DagConsensusConfig::sanitize()` to enforce batch/payload limit constraints:

```rust
impl ConfigSanitizer for DagConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        
        // Existing payload config validation
        DagPayloadConfig::sanitize(node_config, node_type, chain_id)?;
        
        // NEW: Validate quorum store batch limits against DAG payload limits
        let config = &node_config.dag_consensus;
        let batch_payload_pairs = [
            (
                config.quorum_store.receiver_max_batch_txns as u64,
                config.node_payload_config.max_sending_txns_per_round,
                "QS batch txns must not exceed DAG round txns",
            ),
            (
                config.quorum_store.receiver_max_batch_bytes as u64,
                config.node_payload_config.max_sending_size_per_round_bytes,
                "QS batch bytes must not exceed DAG round bytes",
            ),
        ];
        
        for (batch_limit, payload_limit, label) in &batch_payload_pairs {
            if *batch_limit > *payload_limit {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    format!("Failed {}: {} > {}", label, *batch_limit, *payload_limit),
                ));
            }
        }

        Ok(())
    }
}
```

Add corresponding test cases to verify the validation catches invalid configurations.

## Proof of Concept

Create a node configuration file `invalid_dag_config.yaml`:

```yaml
dag_consensus:
  node_payload_config:
    max_sending_txns_per_round: 1000
    max_receiving_txns_per_round: 20000
  quorum_store:
    sender_max_batch_txns: 15000
    receiver_max_batch_txns: 15000
```

Run configuration validation:
```rust
use aptos_config::config::{NodeConfig, ConfigSanitizer, NodeType};
use aptos_types::chain_id::ChainId;

let node_config = NodeConfig::load_from_path("invalid_dag_config.yaml").unwrap();

// This should fail but currently passes
let result = NodeConfig::sanitize(&node_config, NodeType::Validator, Some(ChainId::testnet()));

// Current behavior: result.is_ok() == true (BUG)
// Expected behavior: result.is_err() == true
```

The configuration passes validation but would cause liveness failures at runtime when batches of 15,000 transactions cannot fit within the 1,000 transaction per-round limit divided among validators.

## Notes

This vulnerability is specific to DAG consensus configurations. Traditional AptosBFT consensus has proper validation through the transitive chain of sanitizers. The fix should mirror the validation pattern used in `ConsensusConfig::sanitize_batch_block_limits()` but adapted for DAG's round-based limits. [8](#0-7)

### Citations

**File:** config/src/config/quorum_store_config.rs (L178-213)
```rust
    fn sanitize_send_recv_batch_limits(
        sanitizer_name: &str,
        config: &QuorumStoreConfig,
    ) -> Result<(), Error> {
        let send_recv_pairs = [
            (
                config.sender_max_batch_txns,
                config.receiver_max_batch_txns,
                "txns",
            ),
            (
                config.sender_max_batch_bytes,
                config.receiver_max_batch_bytes,
                "bytes",
            ),
            (
                config.sender_max_total_txns,
                config.receiver_max_total_txns,
                "total_txns",
            ),
            (
                config.sender_max_total_bytes,
                config.receiver_max_total_bytes,
                "total_bytes",
            ),
        ];
        for (send, recv, label) in &send_recv_pairs {
            if *send > *recv {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name.to_owned(),
                    format!("Failed {}: {} > {}", label, *send, *recv),
                ));
            }
        }
        Ok(())
    }
```

**File:** config/src/config/consensus_config.rs (L442-500)
```rust
    fn sanitize_batch_block_limits(
        sanitizer_name: &str,
        config: &ConsensusConfig,
    ) -> Result<(), Error> {
        // Note, we are strict here: receiver batch limits <= sender block limits
        let mut recv_batch_send_block_pairs = vec![
            (
                config.quorum_store.receiver_max_batch_txns as u64,
                config.max_sending_block_txns,
                "QS recv batch txns < max_sending_block_txns".to_string(),
            ),
            (
                config.quorum_store.receiver_max_batch_txns as u64,
                config.max_sending_block_txns_after_filtering,
                "QS recv batch txns < max_sending_block_txns_after_filtering ".to_string(),
            ),
            (
                config.quorum_store.receiver_max_batch_txns as u64,
                config.min_max_txns_in_block_after_filtering_from_backpressure,
                "QS recv batch txns < min_max_txns_in_block_after_filtering_from_backpressure"
                    .to_string(),
            ),
            (
                config.quorum_store.receiver_max_batch_bytes as u64,
                config.max_sending_block_bytes,
                "QS recv batch bytes < max_sending_block_bytes".to_string(),
            ),
        ];
        for backpressure_values in &config.pipeline_backpressure {
            recv_batch_send_block_pairs.push((
                config.quorum_store.receiver_max_batch_bytes as u64,
                backpressure_values.max_sending_block_bytes_override,
                format!(
                    "backpressure {} ms: QS recv batch bytes < max_sending_block_bytes_override",
                    backpressure_values.back_pressure_pipeline_latency_limit_ms,
                ),
            ));
        }
        for backoff_values in &config.chain_health_backoff {
            recv_batch_send_block_pairs.push((
                config.quorum_store.receiver_max_batch_bytes as u64,
                backoff_values.max_sending_block_bytes_override,
                format!(
                    "backoff {} %: bytes: QS recv batch bytes < max_sending_block_bytes_override",
                    backoff_values.backoff_if_below_participating_voting_power_percentage,
                ),
            ));
        }

        for (batch, block, label) in &recv_batch_send_block_pairs {
            if *batch > *block {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name.to_owned(),
                    format!("Failed {}: {} > {}", label, *batch, *block),
                ));
            }
        }
        Ok(())
    }
```

**File:** config/src/config/dag_consensus_config.rs (L35-77)
```rust
impl ConfigSanitizer for DagPayloadConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let dag_node_payload_config = &node_config.dag_consensus.node_payload_config;

        // Sanitize the payload size limits
        Self::sanitize_payload_size_limits(&sanitizer_name, dag_node_payload_config)?;

        Ok(())
    }
}

impl DagPayloadConfig {
    fn sanitize_payload_size_limits(
        sanitizer_name: &str,
        config: &DagPayloadConfig,
    ) -> Result<(), Error> {
        let send_recv_pairs = [
            (
                config.max_sending_txns_per_round,
                config.max_receiving_txns_per_round,
                "txns",
            ),
            (
                config.max_sending_size_per_round_bytes,
                config.max_receiving_size_per_round_bytes,
                "bytes",
            ),
        ];
        for (send, recv, label) in &send_recv_pairs {
            if *send > *recv {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name.to_owned(),
                    format!("Failed {}: {} > {}", label, *send, *recv),
                ));
            }
        }
        Ok(())
    }
```

**File:** config/src/config/dag_consensus_config.rs (L169-179)
```rust
impl ConfigSanitizer for DagConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        DagPayloadConfig::sanitize(node_config, node_type, chain_id)?;

        Ok(())
    }
}
```

**File:** consensus/src/dag/health/backoff.rs (L30-72)
```rust
    pub fn calculate_payload_limits(
        &self,
        round: Round,
        payload_config: &DagPayloadConfig,
    ) -> (u64, u64) {
        let chain_backoff = self
            .chain_health
            .get_round_payload_limits(round)
            .unwrap_or((u64::MAX, u64::MAX));
        let pipeline_backoff = self
            .pipeline_health
            .get_payload_limits()
            .unwrap_or((u64::MAX, u64::MAX));
        let voting_power_ratio = self.chain_health.voting_power_ratio(round);

        let max_txns_per_round = [
            payload_config.max_sending_txns_per_round,
            chain_backoff.0,
            pipeline_backoff.0,
        ]
        .into_iter()
        .min()
        .expect("must not be empty");

        let max_size_per_round_bytes = [
            payload_config.max_sending_size_per_round_bytes,
            chain_backoff.1,
            pipeline_backoff.1,
        ]
        .into_iter()
        .min()
        .expect("must not be empty");

        // TODO: figure out receiver side checks
        let max_txns = max_txns_per_round.saturating_div(
            (self.epoch_state.verifier.len() as f64 * voting_power_ratio).ceil() as u64,
        );
        let max_txn_size_bytes = max_size_per_round_bytes.saturating_div(
            (self.epoch_state.verifier.len() as f64 * voting_power_ratio).ceil() as u64,
        );

        (max_txns, max_txn_size_bytes)
    }
```

**File:** consensus/src/dag/dag_driver.rs (L255-292)
```rust
        let (max_txns, max_size_bytes) = self
            .health_backoff
            .calculate_payload_limits(new_round, &self.payload_config);

        let (validator_txns, payload) = match self
            .payload_client
            .pull_payload(
                PayloadPullParameters {
                    max_poll_time: Duration::from_millis(
                        self.payload_config.payload_pull_max_poll_time_ms,
                    ),
                    max_txns: PayloadTxnsSize::new(max_txns, max_size_bytes),
                    max_txns_after_filtering: max_txns,
                    soft_max_txns_after_filtering: max_txns,
                    max_inline_txns: PayloadTxnsSize::new(100, 100 * 1024),
                    maybe_optqs_payload_pull_params: None,
                    user_txn_filter: payload_filter,
                    pending_ordering: false,
                    pending_uncommitted_blocks: 0,
                    recent_max_fill_fraction: 0.0,
                    block_timestamp: self.time_service.now_unix_time(),
                },
                sys_payload_filter,
            )
            .await
        {
            Ok(payload) => payload,
            Err(e) => {
                error!("error pulling payload: {}", e);
                (
                    vec![],
                    Payload::empty(
                        self.quorum_store_enabled,
                        self.allow_batches_without_pos_in_proposal,
                    ),
                )
            },
        };
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L651-683)
```rust
                        if cur_all_txns + batch.size() > max_txns
                            || unique_txns > max_txns_after_filtering
                        {
                            // Exceeded the limit for requested bytes or number of transactions.
                            full = true;
                            return false;
                        }
                        cur_all_txns += batch.size();
                        // Add this batch to filtered_txns and calculate the number of
                        // unique transactions added in the result so far.
                        cur_unique_txns +=
                            item.txn_summaries
                                .as_ref()
                                .map_or(batch.num_txns(), |summaries| {
                                    summaries
                                        .iter()
                                        .filter(|summary| {
                                            filtered_txns.insert(**summary)
                                                && block_timestamp.as_secs()
                                                    < summary.expiration_timestamp_secs
                                        })
                                        .count() as u64
                                });
                        assert!(item.proof.is_none() == batches_without_proofs);
                        result.push(item);
                        if cur_all_txns == max_txns
                            || cur_unique_txns == max_txns_after_filtering
                            || cur_unique_txns >= soft_max_txns_after_filtering
                        {
                            full = true;
                            return false;
                        }
                    }
```

**File:** config/src/config/config_sanitizer.rs (L39-70)
```rust
impl ConfigSanitizer for NodeConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // If config sanitization is disabled, don't do anything!
        if node_config.node_startup.skip_config_sanitizer {
            return Ok(());
        }

        // Sanitize all of the sub-configs
        AdminServiceConfig::sanitize(node_config, node_type, chain_id)?;
        ApiConfig::sanitize(node_config, node_type, chain_id)?;
        BaseConfig::sanitize(node_config, node_type, chain_id)?;
        ConsensusConfig::sanitize(node_config, node_type, chain_id)?;
        DagConsensusConfig::sanitize(node_config, node_type, chain_id)?;
        ExecutionConfig::sanitize(node_config, node_type, chain_id)?;
        sanitize_failpoints_config(node_config, node_type, chain_id)?;
        sanitize_fullnode_network_configs(node_config, node_type, chain_id)?;
        IndexerGrpcConfig::sanitize(node_config, node_type, chain_id)?;
        InspectionServiceConfig::sanitize(node_config, node_type, chain_id)?;
        LoggerConfig::sanitize(node_config, node_type, chain_id)?;
        MempoolConfig::sanitize(node_config, node_type, chain_id)?;
        NetbenchConfig::sanitize(node_config, node_type, chain_id)?;
        StateSyncConfig::sanitize(node_config, node_type, chain_id)?;
        StorageConfig::sanitize(node_config, node_type, chain_id)?;
        InternalIndexerDBConfig::sanitize(node_config, node_type, chain_id)?;
        sanitize_validator_network_config(node_config, node_type, chain_id)?;

        Ok(()) // All configs passed validation
    }
```
