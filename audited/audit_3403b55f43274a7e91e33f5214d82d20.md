# Audit Report

## Title
Storage Leak in Large Package Publishing: StagingArea Not Cleaned Up on Failed Publish

## Summary
The `large_packages` module fails to clean up the `StagingArea` resource when package publishing aborts, causing permanent storage consumption and financial loss to users. Due to Move's transaction atomicity, when `publish_to_account`, `publish_to_object`, or `upgrade_object_code` abort, the subsequent `cleanup_staging_area` call never executes, leaving the staging area resource indefinitely in the user's account.

## Finding Description
The large package publishing workflow in the `large_packages` module uses a multi-transaction approach where users stage code chunks before final publication. The final publishing functions call cleanup after successful publish: [1](#0-0) [2](#0-1) [3](#0-2) 

However, in Move, when a function aborts, all subsequent code in that transaction is skipped. The `publish_package_txn` function can abort for numerous reasons: [4](#0-3) [5](#0-4) 

Abort conditions include:
- Upgrade policy violations (EUPGRADE_IMMUTABLE, EUPGRADE_WEAKER_POLICY)
- Module name clashes (EMODULE_NAME_CLASH)
- Missing dependencies (EPACKAGE_DEP_MISSING)
- Incompatible policies (EINCOMPATIBLE_POLICY_DISABLED)
- Missing modules in upgrade (EMODULE_MISSING)
- Permission failures
- Bytecode verification errors

When any of these aborts occur, the `cleanup_staging_area` call at the end of the publishing functions never executes, leaving the `StagingArea` resource permanently in storage: [6](#0-5) 

This resource contains potentially large amounts of data (metadata and code chunks via SmartTable), consuming storage that users have paid for but cannot use.

## Impact Explanation
This qualifies as **Medium severity** under the Aptos bug bounty program: "State inconsistencies requiring intervention" and "Limited funds loss or manipulation."

**Financial Impact:**
- Users pay storage gas fees for the `StagingArea` resource containing potentially hundreds of KB or MB of data
- Storage is permanently allocated until manual cleanup via the CLI command
- For large packages, storage costs can be significant

**State Inconsistency:**
- The `StagingArea` should be ephemeral but becomes permanent on failed publishes
- Users must manually intervene with `aptos move clear-staging-area` to recover
- The CLI warns about non-empty staging areas but doesn't prevent the issue [7](#0-6) 

## Likelihood Explanation
**High likelihood** - Package publishing can fail for many legitimate reasons:
- Developers testing upgrades with incompatible policies
- Module name conflicts during development
- Dependency resolution failures
- Bytecode verification issues
- Permission or access control failures

Each failed publish attempt leaves storage leaked unless users manually clean up. Given that large package publishing is intended for complex packages, the probability of encountering validation errors during development is high.

## Recommendation
Move the `cleanup_staging_area` call into a `finally`-equivalent pattern or restructure the code to ensure cleanup happens regardless of publish success. Since Move doesn't have try-catch or finally blocks, the recommended approach is:

**Option 1: Always cleanup first, then publish**
```move
public entry fun stage_code_chunk_and_publish_to_account(
    owner: &signer,
    metadata_chunk: vector<u8>,
    code_indices: vector<u16>,
    code_chunks: vector<vector<u8>>
) acquires StagingArea {
    let staging_area = stage_code_chunk_internal(owner, metadata_chunk, code_indices, code_chunks);
    
    // Extract data before cleanup
    let metadata = staging_area.metadata_serialized;
    let code = assemble_module_code(staging_area);
    
    // Cleanup BEFORE publish (so it always executes)
    cleanup_staging_area(owner);
    
    // Now publish (can abort without leaving staging area)
    code::publish_package_txn(owner, metadata, code);
}
```

**Option 2: Separate staging from publishing**
Document that users should explicitly call cleanup after any failed publish attempt, and add automatic cleanup in transaction epilogue or a scheduled cleanup mechanism.

## Proof of Concept
```move
#[test(account = @0xcafe)]
fun test_staging_area_leak_on_failed_publish(account: &signer) acquires StagingArea {
    // Stage some code chunks
    stage_code_chunk(account, vector[1, 2, 3], vector[0], vector[vector[4, 5, 6]]);
    
    // Verify staging area exists
    assert!(exists<StagingArea>(signer::address_of(account)), 0);
    
    // Attempt to publish with invalid metadata that will cause abort
    // (e.g., incompatible upgrade policy)
    let invalid_metadata = /* serialized metadata with arbitrary policy */;
    
    // This call will abort during publish_to_account
    stage_code_chunk_and_publish_to_account(
        account,
        vector[],
        vector[],
        vector[],
    ); // ABORTS with EINCOMPATIBLE_POLICY_DISABLED
    
    // After abort, staging area should NOT exist if cleanup worked
    // But it DOES exist because cleanup_staging_area was never called
    assert!(exists<StagingArea>(signer::address_of(account)), 1); // PASSES - proving leak
}
```

**Notes:**
- The vulnerability is confirmed by code analysis showing cleanup only executes after successful publish
- Any abort in the publish path prevents cleanup execution
- Manual cleanup via CLI is the only current recovery mechanism
- This breaks the Resource Limits invariant by allowing unbounded storage allocation for failed operations

### Citations

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L60-64)
```text
    struct StagingArea has key {
        metadata_serialized: vector<u8>,
        code: SmartTable<u64, vector<u8>>,
        last_module_idx: u64
    }
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L80-95)
```text
    public entry fun stage_code_chunk_and_publish_to_account(
        owner: &signer,
        metadata_chunk: vector<u8>,
        code_indices: vector<u16>,
        code_chunks: vector<vector<u8>>
    ) acquires StagingArea {
        let staging_area =
            stage_code_chunk_internal(
                owner,
                metadata_chunk,
                code_indices,
                code_chunks
            );
        publish_to_account(owner, staging_area);
        cleanup_staging_area(owner);
    }
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L97-112)
```text
    public entry fun stage_code_chunk_and_publish_to_object(
        owner: &signer,
        metadata_chunk: vector<u8>,
        code_indices: vector<u16>,
        code_chunks: vector<vector<u8>>
    ) acquires StagingArea {
        let staging_area =
            stage_code_chunk_internal(
                owner,
                metadata_chunk,
                code_indices,
                code_chunks
            );
        publish_to_object(owner, staging_area);
        cleanup_staging_area(owner);
    }
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L114-130)
```text
    public entry fun stage_code_chunk_and_upgrade_object_code(
        owner: &signer,
        metadata_chunk: vector<u8>,
        code_indices: vector<u16>,
        code_chunks: vector<vector<u8>>,
        code_object: Object<PackageRegistry>
    ) acquires StagingArea {
        let staging_area =
            stage_code_chunk_internal(
                owner,
                metadata_chunk,
                code_indices,
                code_chunks
            );
        upgrade_object_code(owner, staging_area, code_object);
        cleanup_staging_area(owner);
    }
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L168-228)
```text
    public fun publish_package(owner: &signer, pack: PackageMetadata, code: vector<vector<u8>>) acquires PackageRegistry {
        check_code_publishing_permission(owner);
        // Disallow incompatible upgrade mode. Governance can decide later if this should be reconsidered.
        assert!(
            pack.upgrade_policy.policy > upgrade_policy_arbitrary().policy,
            error::invalid_argument(EINCOMPATIBLE_POLICY_DISABLED),
        );

        let addr = signer::address_of(owner);
        if (!exists<PackageRegistry>(addr)) {
            move_to(owner, PackageRegistry { packages: vector::empty() })
        };

        // Checks for valid dependencies to other packages
        let allowed_deps = check_dependencies(addr, &pack);

        // Check package against conflicts
        // To avoid prover compiler error on spec
        // the package need to be an immutable variable
        let module_names = get_module_names(&pack);
        let package_immutable = &borrow_global<PackageRegistry>(addr).packages;
        let len = vector::length(package_immutable);
        let index = len;
        let upgrade_number = 0;
        vector::enumerate_ref(package_immutable
        , |i, old| {
            let old: &PackageMetadata = old;
            if (old.name == pack.name) {
                upgrade_number = old.upgrade_number + 1;
                check_upgradability(old, &pack, &module_names);
                index = i;
            } else {
                check_coexistence(old, &module_names)
            };
        });

        // Assign the upgrade counter.
        pack.upgrade_number = upgrade_number;

        let packages = &mut borrow_global_mut<PackageRegistry>(addr).packages;
        // Update registry
        let policy = pack.upgrade_policy;
        if (index < len) {
            *vector::borrow_mut(packages, index) = pack
        } else {
            vector::push_back(packages, pack)
        };

        event::emit(PublishPackage {
            code_address: addr,
            is_upgrade: upgrade_number > 0
        });

        // Request publish
        if (features::code_dependency_check_enabled())
            request_publish_with_allowed_deps(addr, module_names, allowed_deps, code, policy.policy)
        else
        // The new `request_publish_with_allowed_deps` has not yet rolled out, so call downwards
        // compatible code.
            request_publish(addr, module_names, code, policy.policy)
    }
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L256-259)
```text
    public entry fun publish_package_txn(owner: &signer, metadata_serialized: vector<u8>, code: vector<vector<u8>>)
    acquires PackageRegistry {
        publish_package(owner, util::from_bytes<PackageMetadata>(metadata_serialized), code)
    }
```

**File:** crates/aptos/src/move_tool/mod.rs (L1704-1714)
```rust
    if !is_staging_area_empty(txn_options, large_packages_module_address).await? {
        let message = format!(
            "The resource {}::large_packages::StagingArea under account {} is not empty.\
        \nThis may cause package publishing to fail if the data is unexpected. \
        \nUse the `aptos move clear-staging-area` command to clean up the `StagingArea` resource under the account.",
            large_packages_module_address, account_address,
        )
            .bold();
        println!("{}", message);
        prompt_yes_with_override("Do you want to proceed?", txn_options.prompt_options)?;
    }
```
