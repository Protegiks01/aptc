# Audit Report

## Title
Index Corruption in Subscriber Cleanup Causes Validator Node Crash and Memory Leak

## Summary
The `broadcast()` function in `PeersAndMetadata` contains a critical indexing bug when removing closed subscriber channels. Using `swap_remove()` with stale indices causes either validator node panics (crashes) or accumulation of dead channel objects, leading to memory leaks and availability issues.

## Finding Description

The `broadcast()` function maintains a vector of subscriber channels that receive peer connection/disconnection events. [1](#0-0) 

When broadcasting events, the function attempts to clean up closed channels by collecting their indices and then removing them. [2](#0-1) 

The bug occurs in the removal logic: indices of closed channels are collected during the first loop (lines 374-391), then removed using `swap_remove()` in a second loop (lines 392-394). The `swap_remove(i)` operation removes element at index `i` by swapping it with the last element and popping, which **invalidates all subsequent indices** in the `to_del` vector.

**Concrete Attack Scenario:**

Assume 5 active subscribers at indices `[0, 1, 2, 3, 4]`, and channels at indices `1, 2, 4` close simultaneously (e.g., during component restarts):

1. First loop collects `to_del = [1, 2, 4]`
2. `swap_remove(1)` swaps index 1 with index 4, then removes → vector now has 4 elements
3. `swap_remove(2)` removes index 2 → vector now has 3 elements (indices 0-2 only)
4. `swap_remove(4)` attempts to access index 4 → **PANIC** (out of bounds)

This panic crashes the validator node immediately. Even without panic, wrong elements get removed due to index corruption, leaving closed channels in the vector (memory leak) or incorrectly removing active channels.

The `broadcast()` function is invoked on every peer connection and disconnection event, [3](#0-2) [4](#0-3)  making this a frequent operation in validator nodes.

## Impact Explanation

**High Severity** - This meets the Aptos Bug Bounty criteria for High severity issues:

1. **Validator node crashes**: When 2+ non-consecutive subscriber indices close simultaneously, the next peer connection event triggers a panic, immediately crashing the validator. This violates the **Resource Limits** and **liveness** invariants.

2. **Memory leaks**: Even when panics don't occur, index misalignment causes closed channels to remain in the subscribers vector, accumulating dead `Sender` objects over time. This gradually exhausts node memory.

3. **Availability impact**: Both crash scenarios and memory exhaustion reduce validator uptime, affecting network liveness and potentially causing missed block proposals/votes.

According to Aptos Bug Bounty severity categories, "Validator node slowdowns" and "API crashes" qualify as High severity ($50,000). A validator crash directly impacts network availability.

## Likelihood Explanation

**High Likelihood:**

1. **Frequent trigger**: `broadcast()` is called on every peer connect/disconnect event, which occurs constantly in production networks with hundreds of peers.

2. **Natural occurrence**: Multiple subscribers close simultaneously during:
   - Component restarts (health checker, state sync, consensus observer)
   - Partial node failures under high load
   - Network partition recovery when multiple components reconnect
   - Graceful shutdowns where multiple components terminate

3. **No attacker requirements**: While an attacker cannot directly control subscriber lifecycle, they can indirectly trigger conditions leading to component failures through resource exhaustion or network disruption, both of which are common attack vectors.

4. **Observable in production**: Validator operators running multiple network-facing components will naturally experience this bug during normal operations.

## Recommendation

Replace the index-based removal with reverse iteration or use `retain()`:

**Option 1 - Reverse iteration (minimal change):**
```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    let mut to_del = vec![];
    for i in 0..listeners.len() {
        let dest = listeners.get_mut(i).unwrap();
        if let Err(err) = dest.try_send(event.clone()) {
            match err {
                TrySendError::Full(_) => {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(1)),
                        warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                    );
                },
                TrySendError::Closed(_) => {
                    to_del.push(i);
                },
            }
        }
    }
    // Remove in reverse order to maintain index validity
    for evict in to_del.into_iter().rev() {
        listeners.swap_remove(evict);
    }
}
```

**Option 2 - Use retain (cleaner):**
```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    listeners.retain_mut(|dest| {
        match dest.try_send(event.clone()) {
            Ok(_) => true,
            Err(TrySendError::Full(_)) => {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                );
                true
            },
            Err(TrySendError::Closed(_)) => false,
        }
    });
}
```

## Proof of Concept

```rust
#[test]
fn test_subscriber_cleanup_panic() {
    use tokio::sync::mpsc;
    
    let network_ids = vec![NetworkId::Validator];
    let peers_and_metadata = PeersAndMetadata::new(&network_ids);
    
    // Create 5 subscribers
    let mut receivers = vec![];
    for _ in 0..5 {
        receivers.push(peers_and_metadata.subscribe());
    }
    
    // Drop receivers at indices 1, 2, and 4 to close their channels
    drop(receivers.remove(4)); // Close index 4
    drop(receivers.remove(2)); // Close index 2  
    drop(receivers.remove(1)); // Close index 1
    
    // Trigger broadcast by inserting connection metadata
    let peer_id = PeerId::random();
    let connection_metadata = ConnectionMetadata::mock(peer_id);
    let peer_network_id = PeerNetworkId::new(NetworkId::Validator, peer_id);
    
    // This will panic with "swap_remove index (is 4) should be < len (is 3)"
    let result = std::panic::catch_unwind(|| {
        peers_and_metadata.insert_connection_metadata(
            peer_network_id,
            connection_metadata
        )
    });
    
    assert!(result.is_err(), "Expected panic due to index corruption");
}
```

**Notes**

The security question marked this as "Low" severity focusing on memory leaks, but the investigation reveals a more severe issue: **validator node crashes**. The `swap_remove()` index corruption causes out-of-bounds panics when multiple subscribers (2+) at non-consecutive indices close simultaneously—a common scenario during component restarts or partial node failures. Since `broadcast()` is invoked on every peer connection event [3](#0-2) [4](#0-3) , this bug has high likelihood and directly impacts validator availability, qualifying as **High severity** under Aptos Bug Bounty criteria.

### Citations

**File:** network/framework/src/application/storage.rs (L53-53)
```rust
    subscribers: Mutex<Vec<tokio::sync::mpsc::Sender<ConnectionNotification>>>,
```

**File:** network/framework/src/application/storage.rs (L211-211)
```rust
        self.broadcast(event);
```

**File:** network/framework/src/application/storage.rs (L245-245)
```rust
                self.broadcast(event);
```

**File:** network/framework/src/application/storage.rs (L371-395)
```rust
    fn broadcast(&self, event: ConnectionNotification) {
        let mut listeners = self.subscribers.lock();
        let mut to_del = vec![];
        for i in 0..listeners.len() {
            let dest = listeners.get_mut(i).unwrap();
            if let Err(err) = dest.try_send(event.clone()) {
                match err {
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
                    TrySendError::Closed(_) => {
                        to_del.push(i);
                    },
                }
            }
        }
        for evict in to_del.into_iter() {
            listeners.swap_remove(evict);
        }
    }
```
