# Audit Report

## Title
Thread Pool Starvation in Peer Monitoring Service via Unfair Resource Allocation

## Summary
The peer monitoring service lacks per-peer fairness mechanisms in its blocking thread pool allocation, allowing a single malicious peer to monopolize limited thread pool resources and degrade service quality for legitimate peers. However, error handling is not the specific attack vector - the vulnerability exists regardless of whether requests generate errors.

## Finding Description

The peer monitoring service implements a resource-bounded architecture with several constraints:

1. **Network Layer Limit**: Each peer connection is limited to 100 concurrent inbound RPC requests [1](#0-0) 

2. **Global Executor Limit**: The BoundedExecutor enforces a maximum of 1000 concurrent requests across all peers (default configuration) [2](#0-1) 

3. **Global Thread Pool**: The dedicated peer monitoring runtime is configured with only 64 blocking threads [3](#0-2) 

The vulnerability arises from a resource allocation mismatch: the per-peer limit (100) exceeds the global thread pool capacity (64), and there is no per-peer fairness mechanism at the executor or thread pool level.

**Attack Scenario:**
A malicious peer can send 100 concurrent requests (the maximum allowed per peer) to the peer monitoring service. Each request is processed via `spawn_blocking` [4](#0-3) , which:
1. Acquires a BoundedExecutor permit (blocking if at capacity)
2. Spawns a blocking task on the tokio thread pool
3. Waits for an available thread from the 64-thread pool

Since one peer's 100 concurrent requests exceed the 64 available threads, that peer can monopolize the entire thread pool, causing legitimate peers' requests to experience significant delays even after acquiring executor permits.

**Critical Finding Regarding Errors:**
The question specifically asks whether "generating many errors" causes thread pool starvation. Analysis of the error handling code reveals that errors are processed quickly through logging and metrics without blocking operations [5](#0-4) . Storage operations like `get_latest_ledger_info()` use in-memory caches (ArcSwap) for fast reads, making both normal and error paths relatively fast.

**Therefore, errors do NOT specifically exacerbate the starvation issue**. In fact, errors may complete faster than normal requests since invalid requests avoid storage I/O entirely.

## Impact Explanation

This vulnerability is classified as **Medium Severity** rather than the claimed High, for several reasons:

1. **Isolated Service**: The peer monitoring service runs in its own dedicated runtime [6](#0-5) , separate from critical consensus and execution services. Thread pool exhaustion here does not directly impact consensus safety or liveness.

2. **Non-Critical Function**: While the peer monitoring service supports health monitoring and peer prioritization for mempool transaction forwarding, it is not required for core consensus operations. Degraded performance here affects observability and optimization, not fundamental blockchain security.

3. **Existing Protections**: The system already implements multiple layers of protection:
   - Network-layer per-peer RPC limits (100 concurrent)
   - Network byte rate limiting (100 KiB/s per IP default) [7](#0-6) 
   - Global executor capacity limits (1000 concurrent requests)
   - Fast request processing (typically 1-10ms)

4. **Limited Real-World Impact**: The attack requires sustained 100 concurrent requests, which is the designed maximum capacity per peer. This is working as specified, albeit without per-peer fairness guarantees.

The issue does not meet High Severity criteria ("Validator node slowdowns") because the peer monitoring service is auxiliary rather than critical infrastructure.

## Likelihood Explanation

**Likelihood: Medium**

The attack is feasible but has practical limitations:

1. **Easy to Execute**: Any peer can connect and send requests up to the 100 concurrent limit
2. **Network Protections**: Byte rate limiting and RPC concurrency limits make sustained attacks more difficult
3. **Fast Processing**: Quick request completion (especially for errors) means threads are frequently released
4. **Observable**: High request volumes from a single peer would be evident in metrics and logs

The attack would cause noticeable degradation but not complete service failure, and would be detectable through monitoring.

## Recommendation

Implement per-peer fairness in the peer monitoring service's resource allocation:

**Option 1: Per-Peer Rate Limiting**
Add per-peer request rate tracking and exponential backoff for peers exceeding thresholds, similar to the storage service's `RequestModerator` pattern [8](#0-7) .

**Option 2: Fair Scheduling**
Modify the request handling to track active requests per peer and implement fair queuing when the thread pool approaches capacity. This could involve:
- Tracking per-peer active request counts
- Implementing a weighted fair queuing algorithm
- Temporarily reducing concurrency for peers with disproportionate usage

**Option 3: Reduce Per-Peer Limits**
Lower `MAX_CONCURRENT_INBOUND_RPCS` to align better with the thread pool capacity (e.g., reduce from 100 to 32), ensuring multiple peers can be served concurrently without resource monopolization.

## Proof of Concept

```rust
// Proof of Concept: Thread Pool Monopolization Test
// This test demonstrates that one peer can monopolize blocking threads

use peer_monitoring_service_server::PeerMonitoringServiceServer;
use std::sync::Arc;
use std::time::Duration;
use tokio::time::sleep;

#[tokio::test]
async fn test_single_peer_monopolizes_threads() {
    // Setup: Create peer monitoring service with default config
    // (64 blocking threads, 1000 max concurrent requests)
    
    // Malicious Peer: Send 100 concurrent GetNodeInformation requests
    let mut handles = vec![];
    for i in 0..100 {
        let handle = tokio::spawn(async move {
            // Send request that will block on thread pool
            let start = std::time::Instant::now();
            send_peer_monitoring_request(malicious_peer_id, GetNodeInformation).await;
            let elapsed = start.elapsed();
            println!("Malicious peer request {} completed in {:?}", i, elapsed);
        });
        handles.push(handle);
    }
    
    // Give malicious peer time to acquire threads
    sleep(Duration::from_millis(10)).await;
    
    // Legitimate Peer: Send 10 requests
    let mut legit_handles = vec![];
    for i in 0..10 {
        let handle = tokio::spawn(async move {
            let start = std::time::Instant::now();
            send_peer_monitoring_request(legitimate_peer_id, GetNodeInformation).await;
            let elapsed = start.elapsed();
            println!("Legitimate peer request {} completed in {:?}", i, elapsed);
            elapsed
        });
        legit_handles.push(handle);
    }
    
    // Wait for completion and measure delays
    let legit_latencies: Vec<Duration> = futures::future::join_all(legit_handles)
        .await
        .into_iter()
        .map(|r| r.unwrap())
        .collect();
    
    // Assert: Legitimate peer experiences significant delays
    let avg_latency = legit_latencies.iter().sum::<Duration>() / legit_latencies.len() as u32;
    println!("Average legitimate peer latency: {:?}", avg_latency);
    
    // Expected: Latencies are much higher than without monopolization
    // due to waiting for thread pool availability
}
```

---

**Notes:**

While this vulnerability exists as a fairness issue in resource allocation, it does NOT meet the High severity threshold claimed in the question for the following reasons:

1. **The question's specific premise is incorrect**: Generating errors does not specifically cause or exacerbate thread pool starvation. Error handling is fast and may even reduce thread hold times compared to normal storage operations.

2. **Limited actual impact**: The peer monitoring service is non-critical infrastructure with its own isolated runtime. Degradation here does not directly threaten consensus, state consistency, or fund security.

3. **Working as designed**: The system enforces per-peer limits (100 RPCs) and global limits (1000 requests, 64 threads) as specified. The lack of additional per-peer fairness is a design trade-off rather than an oversight.

4. **Existing mitigations**: Network-layer rate limiting, RPC concurrency limits, and fast processing provide substantial protection against sustained abuse.

This represents a **Medium severity** design limitation rather than a High severity exploitable vulnerability. The recommendation to add per-peer fairness would improve robustness but is not critical for security.

### Citations

**File:** network/framework/src/constants.rs (L14-15)
```rust
/// Limit on concurrent Inbound RPC requests before backpressure is applied
pub const MAX_CONCURRENT_INBOUND_RPCS: u32 = 100;
```

**File:** config/src/config/peer_monitoring_config.rs (L26-26)
```rust
            max_concurrent_requests: 1000,
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-27)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;
```

**File:** peer-monitoring-service/server/src/lib.rs (L105-121)
```rust
            self.bounded_executor
                .spawn_blocking(move || {
                    let response = Handler::new(
                        base_config,
                        peers_and_metadata,
                        start_time,
                        storage,
                        time_service,
                    )
                    .call(
                        peer_network_id.network_id(),
                        peer_monitoring_service_request,
                    );
                    log_monitoring_service_response(&response);
                    response_sender.send(response);
                })
                .await;
```

**File:** peer-monitoring-service/server/src/lib.rs (L185-203)
```rust
        match response {
            Err(error) => {
                // Log the error and update the counters
                increment_counter(
                    &metrics::PEER_MONITORING_ERRORS_ENCOUNTERED,
                    network_id,
                    error.get_label(),
                );
                error!(LogSchema::new(LogEntry::PeerMonitoringServiceError)
                    .error(&error)
                    .request(&request));

                // Return an appropriate response to the client
                match error {
                    Error::InvalidRequest(error) => {
                        Err(PeerMonitoringServiceError::InvalidRequest(error))
                    },
                    error => Err(PeerMonitoringServiceError::InternalError(error.to_string())),
                }
```

**File:** aptos-node/src/services.rs (L235-236)
```rust
    let peer_monitoring_service_runtime =
        aptos_runtimes::spawn_named_runtime("peer-mon".into(), None);
```

**File:** config/src/config/network_config.rs (L368-377)
```rust
pub struct RateLimitConfig {
    /// Maximum number of bytes/s for an IP
    pub ip_byte_bucket_rate: usize,
    /// Maximum burst of bytes for an IP
    pub ip_byte_bucket_size: usize,
    /// Initial amount of tokens initially in the bucket
    pub initial_bucket_fill_percentage: u8,
    /// Allow for disabling the throttles
    pub enabled: bool,
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L105-247)
```rust
pub struct RequestModerator {
    aptos_data_client_config: AptosDataClientConfig,
    cached_storage_server_summary: Arc<ArcSwap<StorageServerSummary>>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    storage_service_config: StorageServiceConfig,
    time_service: TimeService,
    unhealthy_peer_states: Arc<DashMap<PeerNetworkId, UnhealthyPeerState>>,
}

impl RequestModerator {
    pub fn new(
        aptos_data_client_config: AptosDataClientConfig,
        cached_storage_server_summary: Arc<ArcSwap<StorageServerSummary>>,
        peers_and_metadata: Arc<PeersAndMetadata>,
        storage_service_config: StorageServiceConfig,
        time_service: TimeService,
    ) -> Self {
        Self {
            aptos_data_client_config,
            cached_storage_server_summary,
            unhealthy_peer_states: Arc::new(DashMap::new()),
            peers_and_metadata,
            storage_service_config,
            time_service,
        }
    }

    /// Validates the given request and verifies that the peer is behaving
    /// correctly. If the request fails validation, an error is returned.
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }

    /// Refresh the unhealthy peer states and garbage collect disconnected peers
    pub fn refresh_unhealthy_peer_states(&self) -> Result<(), Error> {
        // Get the currently connected peers
        let connected_peers_and_metadata = self
            .peers_and_metadata
            .get_connected_peers_and_metadata()
            .map_err(|error| {
                Error::UnexpectedErrorEncountered(format!(
                    "Unable to get connected peers and metadata: {}",
                    error
                ))
            })?;

        // Remove disconnected peers and refresh ignored peer states
        let mut num_ignored_peers = 0;
        self.unhealthy_peer_states
            .retain(|peer_network_id, unhealthy_peer_state| {
                if connected_peers_and_metadata.contains_key(peer_network_id) {
                    // Refresh the ignored peer state
                    unhealthy_peer_state.refresh_peer_state(peer_network_id);

                    // If the peer is ignored, increment the ignored peer count
                    if unhealthy_peer_state.is_ignored() {
                        num_ignored_peers += 1;
                    }

                    true // The peer is still connected, so we should keep it
                } else {
                    false // The peer is no longer connected, so we should remove it
                }
            });

        // Update the number of ignored peers
        metrics::set_gauge(
            &metrics::IGNORED_PEER_COUNT,
            NetworkId::Public.as_str(),
            num_ignored_peers,
        );

        Ok(())
    }

    #[cfg(test)]
    /// Returns a copy of the unhealthy peer states for testing
    pub(crate) fn get_unhealthy_peer_states(
        &self,
    ) -> Arc<DashMap<PeerNetworkId, UnhealthyPeerState>> {
        self.unhealthy_peer_states.clone()
    }
}
```
