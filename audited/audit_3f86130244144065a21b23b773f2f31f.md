# Audit Report

## Title
Missing Vector Length Validation in Transaction Replayer Causes Node Crash via Out-of-Bounds Panic

## Summary
The `enqueue_chunks` function in the chunk executor fails to validate that all input vectors have equal lengths before processing. This allows corrupted or malicious backup data to trigger an out-of-bounds panic in `remove_and_apply`, causing node crashes during backup restoration operations.

## Finding Description

The vulnerability exists in the transaction replay system used during backup restoration. The security guarantee broken is **node availability during disaster recovery operations**.

**Attack Flow:**

1. **Missing Length Validation in `enqueue_chunks`**: [1](#0-0) 

The function only uses `transactions.len()` to calculate version ranges, with no validation that all five input vectors (`transactions`, `persisted_aux_info`, `transaction_infos`, `write_sets`, `event_vecs`) have equal lengths.

2. **Insufficient Validation in `LoadedChunk::load`**: [2](#0-1) 

Only `txns.len()` is validated against the manifest. Other vectors' lengths are not checked.

3. **Critical: `write_sets` Never Verified**: [3](#0-2) 

The `write_sets` vector is not included in the `TransactionListWithProofV2` verification, meaning its length is never validated against other vectors.

4. **Panic Trigger in `remove_and_apply`**: [4](#0-3) 

The `.drain(..num_txns)` operation will panic if `num_txns` exceeds any vector's length. This is the actual crash point.

5. **Safe but Misleading `.take()` in `verify_execution`**: [5](#0-4) 

While `.take()` itself doesn't panic (it just returns fewer elements), it creates inconsistent data structures when input vectors have mismatched lengths, leading to the panic later in `remove_and_apply`.

**Exploitation Scenario:**

An attacker who can control backup storage or perform MITM attacks on backup retrieval can craft malicious backup files where `write_sets` has fewer elements than other vectors. When a node operator restores from this backup:

- `LoadedChunk::load` successfully loads the data (no length check on `write_sets`)
- Data flows through `save_before_replay_version` using `izip!` which stops at shortest vector
- `enqueue_chunks` receives vectors with mismatched lengths
- `remove_and_apply` attempts `.drain(..num_txns)` based on `transactions.len()`
- **PANIC**: `write_sets.drain(..num_txns)` fails with index out of bounds

## Impact Explanation

**Severity: High** (per Aptos Bug Bounty criteria: "API crashes" and "Validator node slowdowns")

**Impact Details:**
- **Node Availability**: Validator or fullnode crashes during backup restoration
- **Disaster Recovery Failure**: Prevents nodes from recovering from backups during emergency scenarios
- **Bootstrap Denial**: New nodes cannot sync from compromised backups
- **Not Consensus-Breaking**: Does not affect normal block execution or consensus safety
- **Scope**: Only affects nodes performing backup restoration operations

This meets the High severity threshold as it causes "API crashes" and can prevent validator nodes from recovering from backups, though it does not directly compromise consensus.

## Likelihood Explanation

**Likelihood: Medium**

**Requirements for Exploitation:**
- Attacker must control backup storage or intercept backup retrieval
- Node operator must initiate restore from compromised backup
- Backup data corruption must be crafted specifically (mismatched vector lengths)

**Realistic Attack Vectors:**
1. **Compromised Backup Storage**: If cloud storage credentials are leaked
2. **Supply Chain Attack**: Malicious insider provides corrupted backup files
3. **MITM Attack**: Network interception during backup download
4. **Storage Corruption**: Accidental file corruption creating exploitable state

**Likelihood Assessment:**
While requiring specific conditions, backup restoration is a critical operation performed during:
- Disaster recovery scenarios
- New validator onboarding
- Network upgrades requiring state snapshot
- Testing and development environments

The lack of defensive validation makes this exploitable in practice, especially in environments where backup integrity verification is incomplete.

## Recommendation

Add comprehensive length validation in both `LoadedChunk::load` and `enqueue_chunks`:

**Fix 1 - In `LoadedChunk::load`** (after line 145):
```rust
ensure!(
    txns.len() == persisted_aux_info.len()
        && txns.len() == txn_infos.len()
        && txns.len() == event_vecs.len()
        && txns.len() == write_sets.len(),
    "Vector length mismatch in loaded chunk: txns={}, persisted_aux_info={}, txn_infos={}, event_vecs={}, write_sets={}",
    txns.len(),
    persisted_aux_info.len(),
    txn_infos.len(),
    event_vecs.len(),
    write_sets.len()
);
```

**Fix 2 - In `enqueue_chunks`** (after line 457):
```rust
let num_txns = transactions.len();
ensure!(
    persisted_aux_info.len() == num_txns,
    "persisted_aux_info length {} != transactions length {}",
    persisted_aux_info.len(),
    num_txns
);
ensure!(
    transaction_infos.len() == num_txns,
    "transaction_infos length {} != transactions length {}",
    transaction_infos.len(),
    num_txns
);
ensure!(
    write_sets.len() == num_txns,
    "write_sets length {} != transactions length {}",
    write_sets.len(),
    num_txns
);
ensure!(
    event_vecs.len() == num_txns,
    "event_vecs length {} != transactions length {}",
    event_vecs.len(),
    num_txns
);
```

## Proof of Concept

```rust
// Minimal PoC demonstrating the panic condition
// Place in execution/executor/src/chunk_executor/mod.rs test module

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    #[should_panic(expected = "range end index")]
    fn test_mismatched_vector_lengths_cause_panic() {
        // Simulate the exact condition that causes the panic
        let mut transactions = vec![Transaction::default(); 10];
        let mut persisted_aux_info = vec![PersistedAuxiliaryInfo::None; 10];
        let mut transaction_infos = vec![TransactionInfo::default(); 10];
        let mut write_sets = vec![WriteSet::default(); 7]; // SHORTER!
        let mut event_vecs = vec![vec![]; 10];
        
        // This is what happens in remove_and_apply
        let num_txns = 10;
        
        // These succeed
        let _ = transactions.drain(..num_txns);
        let _ = persisted_aux_info.drain(..num_txns);
        let _ = transaction_infos.drain(..num_txns);
        let _ = event_vecs.drain(..num_txns);
        
        // This PANICS because write_sets only has 7 elements
        let _ = write_sets.drain(..num_txns); // PANIC!
    }
}
```

**Integration Test Setup:**
To demonstrate the full attack path, create a corrupted backup file with mismatched vector lengths in `write_sets`, then attempt restoration. The node will panic during `enqueue_chunks` → `remove_and_replay_epoch` → `remove_and_apply` execution path.

## Notes

This vulnerability specifically affects the **disaster recovery and node bootstrapping** code paths, not normal consensus operations. While the security impact is real (node crashes prevent recovery), it does not compromise chain safety or enable fund theft. The fix is straightforward: add defensive length validation at data ingestion boundaries.

### Citations

**File:** execution/executor/src/chunk_executor/mod.rs (L447-459)
```rust
    fn enqueue_chunks(
        &self,
        mut transactions: Vec<Transaction>,
        mut persisted_aux_info: Vec<PersistedAuxiliaryInfo>,
        mut transaction_infos: Vec<TransactionInfo>,
        mut write_sets: Vec<WriteSet>,
        mut event_vecs: Vec<Vec<ContractEvent>>,
        verify_execution_mode: &VerifyExecutionMode,
    ) -> Result<usize> {
        let started = Instant::now();
        let num_txns = transactions.len();
        let chunk_begin = self.commit_queue.lock().expecting_version();
        let chunk_end = chunk_begin + num_txns as Version; // right-exclusive
```

**File:** execution/executor/src/chunk_executor/mod.rs (L606-617)
```rust
        let txns = transactions
            .iter()
            .take((end_version - begin_version) as usize)
            .cloned()
            .map(|t| t.into())
            .collect::<Vec<SignatureVerifiedTransaction>>();

        let auxiliary_info = persisted_aux_info
            .iter()
            .take((end_version - begin_version) as usize)
            .map(|persisted_aux_info| AuxiliaryInfo::new(*persisted_aux_info, None))
            .collect::<Vec<_>>();
```

**File:** execution/executor/src/chunk_executor/mod.rs (L666-673)
```rust
        let num_txns = (end_version - begin_version) as usize;
        let txn_infos: Vec<_> = transaction_infos.drain(..num_txns).collect();
        let (transactions, persisted_aux_info, transaction_outputs) = multizip((
            transactions.drain(..num_txns),
            persisted_aux_info.drain(..num_txns),
            txn_infos.iter(),
            write_sets.drain(..num_txns),
            event_vecs.drain(..num_txns),
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L139-145)
```rust
        ensure!(
            manifest.first_version + (txns.len() as Version) == manifest.last_version + 1,
            "Number of items in chunks doesn't match that in manifest. first_version: {}, last_version: {}, items in chunk: {}",
            manifest.first_version,
            manifest.last_version,
            txns.len(),
        );
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L177-185)
```rust
        Ok(Self {
            manifest,
            txns,
            persisted_aux_info,
            txn_infos,
            event_vecs,
            range_proof,
            write_sets,
        })
```
