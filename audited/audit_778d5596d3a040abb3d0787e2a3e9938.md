# Audit Report

## Title
Missing Signature Verification When Loading Certified Randomness Data from Database Allows Consensus Manipulation via Filesystem Attack

## Summary
The `AugDataStore::new()` function loads certified augmented data from the RandDb database without verifying cryptographic signatures. An attacker with filesystem access can inject malicious randomness data into the database that will be trusted and used in consensus upon node restart, potentially compromising the randomness generation protocol and consensus safety. [1](#0-0) 

## Finding Description
The Aptos consensus protocol uses a Weighted Verifiable Unpredictable Function (WVUF) for randomness generation. Each validator generates augmented data containing delta values that are used to compute augmented public keys (APKs) for randomness generation. These APKs are critical cryptographic parameters that directly influence the final randomness output used in consensus.

The `CertifiedAugData` type contains augmented data along with aggregate signatures from a quorum of validators, ensuring the data's authenticity: [2](#0-1) 

When `CertifiedAugData` is received over the network, it is properly verified through a dedicated verification task that checks the aggregate signatures: [3](#0-2) [4](#0-3) 

However, when the node restarts and loads data from the database, the critical verification step is bypassed. In `AugDataStore::new()`, the code loads all certified augmented data and directly calls the `augment()` method without verification: [5](#0-4) 

The `augment()` method updates the RandConfig with the loaded delta values, which then influence the APKs used for randomness generation: [6](#0-5) [7](#0-6) 

These corrupted APKs are then used in the critical randomness aggregation function: [8](#0-7) 

**Attack Path:**
1. Attacker gains filesystem access to a validator node (through OS vulnerability, stolen credentials, etc.)
2. Attacker stops the validator node process
3. Attacker modifies the RandDb database files (located at `db_root_path/rand_db/`) to inject malicious `CertifiedAugData` entries with crafted delta values
4. Attacker restarts the validator node
5. On startup, `AugDataStore::new()` loads the malicious data without calling `verify()`
6. The malicious deltas corrupt the augmented public keys in `RandConfig.keys.certified_apks`
7. The corrupted APKs are used in `WVUF::derive_eval()` to generate randomness for consensus rounds
8. The attacker can potentially bias or predict randomness outcomes, compromising consensus safety

## Impact Explanation
This vulnerability qualifies as **Critical Severity** under the Aptos Bug Bounty program due to:

1. **Consensus/Safety Violations**: The randomness generation is a critical component of the AptosBFT consensus protocol. Compromised randomness can lead to:
   - Predictable or biased leader selection
   - Manipulation of consensus outcomes
   - Potential chain splits if different nodes have different corrupted data
   - Violation of the BFT safety guarantees

2. **Breaks Cryptographic Correctness Invariant**: The vulnerability directly violates invariant #10 ("Cryptographic Correctness: BLS signatures, VRF, and hash operations must be secure") by accepting unauthenticated cryptographic data.

3. **Network-Wide Impact**: If multiple validators are compromised, the attacker gains increasing control over consensus randomness, potentially enabling:
   - Manipulation of validator rewards
   - Biased transaction ordering
   - Selective censorship of transactions

The database manipulation approach bypasses all network-level protections and signature verification that would normally prevent malicious data injection.

## Likelihood Explanation
The likelihood is **MEDIUM to HIGH** due to:

**Factors Increasing Likelihood:**
- Filesystem access vulnerabilities are common attack vectors (privilege escalation, stolen SSH keys, container escape, etc.)
- The attack requires no insider knowledge of validator private keys
- The attack is stealthy - modified database appears valid to RocksDB's integrity checks
- No additional cryptographic material needed beyond filesystem access
- The vulnerability is persistent - once database is corrupted, it affects all future restarts

**Factors Decreasing Likelihood:**
- Requires initial filesystem access to the validator node
- Requires node restart to take effect (though operators regularly restart for updates)
- May be detected if validators share state and notice inconsistencies

The attack is significantly easier than alternatives like:
- Stealing validator private keys (requires extracting cryptographic secrets)
- Network-based attacks (properly verified through signature checks)
- 51% attacks (requires massive stake)

## Recommendation
Add signature verification when loading certified augmented data from the database. The verification should use the same validation logic applied to network-received data:

**Recommended Fix in `consensus/src/rand/rand_gen/aug_data_store.rs`:**

```rust
pub fn new(
    epoch: u64,
    signer: Arc<ValidatorSigner>,
    config: RandConfig,
    fast_config: Option<RandConfig>,
    db: Arc<dyn RandStorage<D>>,
    verifier: Arc<ValidatorVerifier>, // Add verifier parameter
) -> Self {
    let all_data = db.get_all_aug_data().unwrap_or_default();
    let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
    if let Err(e) = db.remove_aug_data(to_remove) {
        error!("[AugDataStore] failed to remove aug data: {:?}", e);
    }

    let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
    let (to_remove, certified_data) =
        Self::filter_by_epoch(epoch, all_certified_data.into_iter());
    if let Err(e) = db.remove_certified_aug_data(to_remove) {
        error!(
            "[AugDataStore] failed to remove certified aug data: {:?}",
            e
        );
    }

    // CRITICAL FIX: Verify signatures before using the data
    let mut verified_certified_data = vec![];
    for (id, certified_data) in certified_data {
        match certified_data.verify(&verifier) {
            Ok(_) => {
                certified_data
                    .data()
                    .augment(&config, &fast_config, certified_data.author());
                verified_certified_data.push((id, certified_data));
            }
            Err(e) => {
                error!(
                    "[AugDataStore] Invalid signature for certified data from {}: {}. Removing from database.",
                    id.author(), e
                );
                // Remove invalid data from database
                if let Err(remove_err) = db.remove_certified_aug_data(vec![certified_data]) {
                    error!("[AugDataStore] Failed to remove invalid data: {}", remove_err);
                }
            }
        }
    }

    Self {
        epoch,
        signer,
        config,
        fast_config,
        data: aug_data
            .into_iter()
            .map(|(id, data)| (id.author(), data))
            .collect(),
        certified_data: verified_certified_data
            .into_iter()
            .map(|(id, data)| (id.author(), data))
            .collect(),
        db,
    }
}
```

Update the caller in `RandManager::new()` to pass the verifier: [9](#0-8) 

## Proof of Concept

```rust
// File: consensus/src/rand/rand_gen/storage/db_attack_poc.rs
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_crypto::{bls12381, Uniform};
    use aptos_types::{
        aggregate_signature::AggregateSignature,
        validator_verifier::ValidatorVerifier,
    };
    use rand::thread_rng;

    #[test]
    fn test_filesystem_attack_unverified_load() {
        // Setup: Create a RandDb with malicious data
        let tmpdir = tempfile::tempdir().unwrap();
        let db = RandDb::new(tmpdir.path());
        
        // Create malicious CertifiedAugData with arbitrary delta
        let malicious_author = Author::random();
        let malicious_delta = Delta::random(); // Attacker-chosen delta
        let malicious_aug_data = AugData::new(
            1, // epoch
            malicious_author,
            AugmentedData {
                delta: malicious_delta.clone(),
                fast_delta: None,
            }
        );
        
        // Create fake signatures (database has no validation)
        let fake_signatures = AggregateSignature::empty();
        let malicious_certified = CertifiedAugData::new(
            malicious_aug_data,
            fake_signatures,
        );
        
        // Attacker writes to database (simulating filesystem manipulation)
        db.save_certified_aug_data(&malicious_certified).unwrap();
        
        // Victim node restarts and loads data
        let loaded_data = db.get_all_certified_aug_data().unwrap();
        
        // VULNERABILITY: Data is loaded without verification
        assert_eq!(loaded_data.len(), 1);
        let (_, loaded_certified) = &loaded_data[0];
        
        // The malicious delta would be used in augment() without verification
        assert_eq!(loaded_certified.data().delta, malicious_delta);
        
        // In production, this would corrupt the RandConfig APKs
        // and compromise randomness generation
    }
    
    #[test] 
    fn test_network_receive_properly_verifies() {
        // Setup validator verifier
        let validator_verifier = create_test_verifier();
        
        // Attacker tries to send malicious data over network
        let malicious_certified = create_malicious_certified_data();
        
        // Network path DOES verify signatures
        let result = malicious_certified.verify(&validator_verifier);
        
        // Properly rejected due to invalid signatures
        assert!(result.is_err());
    }
}
```

**Reproduction Steps:**
1. Deploy Aptos validator node in test environment
2. Stop the validator process
3. Use RocksDB tools or direct file manipulation to inject malicious `CertifiedAugData` into the `rand_db/certified_aug_data` column family
4. Restart the validator
5. Observe that malicious data is loaded and used without verification
6. Monitor randomness generation to confirm compromised APKs are being used

## Notes

This vulnerability represents a **defense-in-depth failure** where cryptographic verification is properly implemented for network-received data but bypassed for database-loaded data. The implicit trust assumption is that "if data is in our database, it must be valid" - but this assumption breaks when an attacker gains filesystem access.

The fix should also consider similar patterns elsewhere in the codebase where cryptographic data is persisted and reloaded, particularly the key pair loading in `EpochManager`: [10](#0-9) 

While key pairs are generated locally and less susceptible to injection, defense-in-depth would suggest adding integrity checks there as well.

### Citations

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L44-88)
```rust
    pub fn new(
        epoch: u64,
        signer: Arc<ValidatorSigner>,
        config: RandConfig,
        fast_config: Option<RandConfig>,
        db: Arc<dyn RandStorage<D>>,
    ) -> Self {
        let all_data = db.get_all_aug_data().unwrap_or_default();
        let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
        if let Err(e) = db.remove_aug_data(to_remove) {
            error!("[AugDataStore] failed to remove aug data: {:?}", e);
        }

        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }

        for (_, certified_data) in &certified_data {
            certified_data
                .data()
                .augment(&config, &fast_config, certified_data.author());
        }

        Self {
            epoch,
            signer,
            config,
            fast_config,
            data: aug_data
                .into_iter()
                .map(|(id, data)| (id.author(), data))
                .collect(),
            certified_data: certified_data
                .into_iter()
                .map(|(id, data)| (id.author(), data))
                .collect(),
            db,
        }
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L97-148)
```rust
    fn aggregate<'a>(
        shares: impl Iterator<Item = &'a RandShare<Self>>,
        rand_config: &RandConfig,
        rand_metadata: RandMetadata,
    ) -> anyhow::Result<Randomness>
    where
        Self: Sized,
    {
        let timer = std::time::Instant::now();
        let mut apks_and_proofs = vec![];
        for share in shares {
            let id = rand_config
                .validator
                .address_to_validator_index()
                .get(share.author())
                .copied()
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with invalid share author: {}",
                        share.author
                    )
                })?;
            let apk = rand_config
                .get_certified_apk(share.author())
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with missing apk for share from {}",
                        share.author
                    )
                })?;
            apks_and_proofs.push((Player { id }, apk.clone(), share.share().share));
        }

        let proof = WVUF::aggregate_shares(&rand_config.wconfig, &apks_and_proofs);
        let metadata_serialized = bcs::to_bytes(&rand_metadata).map_err(|e| {
            anyhow!("Share::aggregate failed with metadata serialization error: {e}")
        })?;
        let eval = WVUF::derive_eval(
            &rand_config.wconfig,
            &rand_config.vuf_pp,
            metadata_serialized.as_slice(),
            &rand_config.get_all_certified_apk(),
            &proof,
            THREAD_MANAGER.get_exe_cpu_pool(),
        )
        .map_err(|e| anyhow!("Share::aggregate failed with WVUF derive_eval error: {e}"))?;
        debug!("WVUF derivation time: {} ms", timer.elapsed().as_millis());
        let eval_bytes = bcs::to_bytes(&eval)
            .map_err(|e| anyhow!("Share::aggregate failed with eval serialization error: {e}"))?;
        let rand_bytes = Sha3_256::digest(eval_bytes.as_slice()).to_vec();
        Ok(Randomness::new(rand_metadata, rand_bytes))
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L178-194)
```rust
    fn augment(
        &self,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        author: &Author,
    ) {
        let AugmentedData { delta, fast_delta } = self;
        rand_config
            .add_certified_delta(author, delta.clone())
            .expect("Add delta should succeed");

        if let (Some(config), Some(fast_delta)) = (fast_rand_config, fast_delta) {
            config
                .add_certified_delta(author, fast_delta.clone())
                .expect("Add delta for fast path should succeed");
        }
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L529-563)
```rust
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct CertifiedAugData<D> {
    aug_data: AugData<D>,
    signatures: AggregateSignature,
}

impl<D: TAugmentedData> CertifiedAugData<D> {
    pub fn new(aug_data: AugData<D>, signatures: AggregateSignature) -> Self {
        Self {
            aug_data,
            signatures,
        }
    }

    pub fn epoch(&self) -> u64 {
        self.aug_data.epoch()
    }

    pub fn id(&self) -> AugDataId {
        self.aug_data.id()
    }

    pub fn author(&self) -> &Author {
        self.aug_data.author()
    }

    pub fn verify(&self, verifier: &ValidatorVerifier) -> anyhow::Result<()> {
        verifier.verify_multi_signatures(&self.aug_data, &self.signatures)?;
        Ok(())
    }

    pub fn data(&self) -> &D {
        &self.aug_data.data
    }
}
```

**File:** consensus/src/rand/rand_gen/types.rs (L661-665)
```rust
    pub fn add_certified_delta(&self, peer: &Author, delta: Delta) -> anyhow::Result<()> {
        let apk = self.derive_apk(peer, delta)?;
        self.add_certified_apk(peer, apk)?;
        Ok(())
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L73-111)
```rust
    pub fn new(
        author: Author,
        epoch_state: Arc<EpochState>,
        signer: Arc<ValidatorSigner>,
        config: RandConfig,
        fast_config: Option<RandConfig>,
        outgoing_blocks: Sender<OrderedBlocks>,
        network_sender: Arc<NetworkSender>,
        db: Arc<dyn RandStorage<D>>,
        bounded_executor: BoundedExecutor,
        rb_config: &ReliableBroadcastConfig,
    ) -> Self {
        let rb_backoff_policy = ExponentialBackoff::from_millis(rb_config.backoff_policy_base_ms)
            .factor(rb_config.backoff_policy_factor)
            .max_delay(Duration::from_millis(rb_config.backoff_policy_max_delay_ms));
        let reliable_broadcast = Arc::new(ReliableBroadcast::new(
            author,
            epoch_state.verifier.get_ordered_account_addresses(),
            network_sender.clone(),
            rb_backoff_policy,
            TimeService::real(),
            Duration::from_millis(rb_config.rpc_timeout_ms),
            bounded_executor,
        ));
        let (decision_tx, decision_rx) = unbounded();
        let rand_store = Arc::new(Mutex::new(RandStore::new(
            epoch_state.epoch,
            author,
            config.clone(),
            fast_config.clone(),
            decision_tx,
        )));
        let aug_data_store = AugDataStore::new(
            epoch_state.epoch,
            signer,
            config.clone(),
            fast_config.clone(),
            db,
        );
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L221-261)
```rust
    async fn verification_task(
        epoch_state: Arc<EpochState>,
        mut incoming_rpc_request: aptos_channel::Receiver<Author, IncomingRandGenRequest>,
        verified_msg_tx: UnboundedSender<RpcRequest<S, D>>,
        rand_config: RandConfig,
        fast_rand_config: Option<RandConfig>,
        bounded_executor: BoundedExecutor,
    ) {
        while let Some(rand_gen_msg) = incoming_rpc_request.next().await {
            let tx = verified_msg_tx.clone();
            let epoch_state_clone = epoch_state.clone();
            let config_clone = rand_config.clone();
            let fast_config_clone = fast_rand_config.clone();
            bounded_executor
                .spawn(async move {
                    match bcs::from_bytes::<RandMessage<S, D>>(rand_gen_msg.req.data()) {
                        Ok(msg) => {
                            if msg
                                .verify(
                                    &epoch_state_clone,
                                    &config_clone,
                                    &fast_config_clone,
                                    rand_gen_msg.sender,
                                )
                                .is_ok()
                            {
                                let _ = tx.unbounded_send(RpcRequest {
                                    req: msg,
                                    protocol: rand_gen_msg.protocol,
                                    response_sender: rand_gen_msg.response_sender,
                                });
                            }
                        },
                        Err(e) => {
                            warn!("Invalid rand gen message: {}", e);
                        },
                    }
                })
                .await;
        }
    }
```

**File:** consensus/src/rand/rand_gen/network_messages.rs (L35-60)
```rust
impl<S: TShare, D: TAugmentedData> RandMessage<S, D> {
    pub fn verify(
        &self,
        epoch_state: &EpochState,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        sender: Author,
    ) -> anyhow::Result<()> {
        ensure!(self.epoch() == epoch_state.epoch);
        match self {
            RandMessage::RequestShare(_) => Ok(()),
            RandMessage::Share(share) => share.verify(rand_config),
            RandMessage::AugData(aug_data) => {
                aug_data.verify(rand_config, fast_rand_config, sender)
            },
            RandMessage::CertifiedAugData(certified_aug_data) => {
                certified_aug_data.verify(&epoch_state.verifier)
            },
            RandMessage::FastShare(share) => {
                share.share.verify(fast_rand_config.as_ref().ok_or_else(|| {
                    anyhow::anyhow!("[RandMessage] rand config for fast path not found")
                })?)
            },
            _ => bail!("[RandMessage] unexpected message type"),
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L1089-1096)
```rust
        let (augmented_key_pair, fast_augmented_key_pair) = if let Some((_, key_pair)) = self
            .rand_storage
            .get_key_pair_bytes()
            .map_err(NoRandomnessReason::RandDbNotAvailable)?
            .filter(|(epoch, _)| *epoch == new_epoch)
        {
            info!(epoch = new_epoch, "Recovering existing augmented key");
            bcs::from_bytes(&key_pair).map_err(NoRandomnessReason::KeyPairDeserializationError)?
```
