# Audit Report

## Title
Consensus Observer Missing Transaction Limit Validation Enables Resource Exhaustion Attack

## Summary
The `verify_payload_digests()` function in the consensus observer fails to validate that the total number of transactions in a payload respects the `transaction_limit` field. This allows malicious validators to send payloads with excessive transactions that pass validation, causing observers to waste bandwidth, CPU, and memory processing transactions that will never be executed.

## Finding Description

The consensus observer's payload verification in `BlockPayload::verify_payload_digests()` contains a critical missing validation. While the function checks that there are no *remaining* transactions after batch reconstruction (lines 946-954), it fails to validate that the *total* transaction count doesn't exceed the `transaction_limit` field. [1](#0-0) 

The vulnerability allows a Byzantine validator to construct a `BlockPayload` with:
- 10,000 transactions in the payload
- `transaction_limit: Some(100)`  
- Batch infos correctly accounting for all 10,000 transactions

The verification flow:
1. `verify_payload_digests()` extracts all 10,000 transactions
2. Batch reconstruction consumes all 10,000 transactions (lines 887-932)
3. Parallel digest verification processes all 10,000 transactions (lines 934-944)
4. Remaining transaction check finds zero remaining (lines 946-954) âœ“ PASS
5. Payload is accepted and stored

However, during execution, only 100 transactions are actually executed due to truncation: [2](#0-1) 

The `transaction_limit` field's purpose is enforced during execution via `len_for_execution()`: [3](#0-2) 

This returns `min(actual_txn_count, max_txns_to_execute)`, but the consensus observer never validates this constraint before accepting the payload.

**Attack Path:**
1. Byzantine validator creates block with bloated payload (10,000 txns, limit 100)
2. Consensus observer receives `BlockPayload` message
3. `verify_payload_digests()` is called, processes all 10,000 transactions
4. All batch digests verify correctly, no remaining transactions
5. Observer accepts and stores all 10,000 transactions
6. During execution, only 100 transactions execute (9,900 wasted)

## Impact Explanation

**HIGH Severity** - This meets the "Significant protocol violations" and "Validator node slowdowns" criteria:

1. **Resource Exhaustion**: Observers waste 100x bandwidth downloading unnecessary transactions
2. **CPU Exhaustion**: Parallel digest verification (using rayon) processes all excess transactions
3. **Memory Exhaustion**: Observers store all excess transactions in memory
4. **Network Amplification**: Each block could carry 100x more data than necessary
5. **DoS Vector**: Byzantine validators can repeatedly send bloated payloads to degrade observer performance

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

While this doesn't directly break consensus safety (validators still execute the same transactions), it significantly degrades observer node performance, which is critical for network scalability and light client support.

## Likelihood Explanation

**HIGH Likelihood:**
- Exploitable by any Byzantine validator (AptosBFT tolerates up to 1/3 Byzantine nodes by design)
- No special conditions required - just craft a block with excess transactions
- Trivial to execute repeatedly (every block proposal)
- No cryptographic challenges or race conditions
- Validators have full control over block contents

The only requirement is being a validator, which is within the consensus threat model (Byzantine fault tolerance assumes some validators are malicious).

## Recommendation

Add validation in `verify_payload_digests()` to check that the total transaction count doesn't exceed the `transaction_limit`:

```rust
pub fn verify_payload_digests(&self) -> Result<(), Error> {
    // Get the block info, transactions, payload proofs and inline batches
    let block_info = self.block.clone();
    let transactions = self.transaction_payload.transactions();
    let payload_proofs = self.transaction_payload.payload_proofs();
    let opt_and_inline_batches = self.transaction_payload.optqs_and_inline_batches();

    // Get the number of transactions, payload proofs and inline batches
    let num_transactions = transactions.len();
    let num_payload_proofs = payload_proofs.len();
    let num_opt_and_inline_batches = opt_and_inline_batches.len();

    // NEW: Validate that transaction count respects the transaction limit
    if let Some(limit) = self.transaction_payload.transaction_limit() {
        if num_transactions > limit as usize {
            return Err(Error::InvalidMessageError(format!(
                "Transaction count {} exceeds transaction_limit {}! This wastes resources.",
                num_transactions, limit
            )));
        }
    }

    // ... rest of the function
}
```

This ensures observers reject bloated payloads immediately, preventing resource waste.

## Proof of Concept

```rust
#[test]
fn test_verify_payload_digests_excess_transactions() {
    use aptos_types::transaction::{RawTransaction, Script, TransactionPayload};
    use aptos_crypto::{ed25519::Ed25519PrivateKey, PrivateKey, Uniform};
    
    // Create a block info
    let block_info = BlockInfo::random(1);
    
    // Create 1000 transactions
    let mut transactions = vec![];
    for i in 0..1000 {
        let private_key = Ed25519PrivateKey::generate_for_testing();
        let public_key = private_key.public_key();
        let sender = AccountAddress::random();
        
        let raw_txn = RawTransaction::new(
            sender,
            i,
            TransactionPayload::Script(Script::new(vec![], vec![], vec![])),
            1000000,
            1,
            0,
            ChainId::test(),
        );
        
        let signed_txn = SignedTransaction::new(
            raw_txn,
            public_key,
            private_key.sign(&raw_txn).unwrap(),
        );
        transactions.push(signed_txn);
    }
    
    // Create batch info that accounts for all 1000 transactions
    let batch_payload = BatchPayload::new(AccountAddress::random(), transactions.clone());
    let batch_digest = batch_payload.hash();
    let batch_info = BatchInfo::new(
        AccountAddress::random(),
        BatchId::new_for_test(1),
        1,
        1000, // num_txns = 1000
        batch_digest,
        1000000,
        1000000,
    );
    
    // Create transaction payload with transaction_limit = 100
    let payload_with_proof = PayloadWithProof::new(
        transactions,
        vec![ProofOfStore::new(batch_info, AggregateSignature::empty())],
    );
    let transaction_payload = BlockTransactionPayload::DeprecatedInQuorumStoreWithLimit(
        PayloadWithProofAndLimit::new(payload_with_proof, Some(100)) // limit = 100!
    );
    
    // Create block payload
    let block_payload = BlockPayload::new(block_info, transaction_payload);
    
    // Verify payload digests - THIS SHOULD FAIL but currently PASSES
    let result = block_payload.verify_payload_digests();
    
    // Currently this passes (BUG!), but it should fail with InvalidMessageError
    // because 1000 transactions > 100 transaction_limit
    assert!(result.is_err(), "Should reject payload with transactions > limit");
}
```

## Notes

The vulnerability exists because `verify_payload_digests()` was designed to prevent *excess* transactions (beyond what batches specify) but not *bloated* batches (batches specifying more transactions than the limit). The check at lines 946-954 only validates that all batch-specified transactions are present, not that the total respects execution limits. This oversight creates a significant DoS vector against consensus observers.

### Citations

**File:** consensus/src/consensus_observer/network/observer_message.rs (L874-958)
```rust
    /// Verifies the block payload digests and returns an error if the data is invalid
    pub fn verify_payload_digests(&self) -> Result<(), Error> {
        // Get the block info, transactions, payload proofs and inline batches
        let block_info = self.block.clone();
        let transactions = self.transaction_payload.transactions();
        let payload_proofs = self.transaction_payload.payload_proofs();
        let opt_and_inline_batches = self.transaction_payload.optqs_and_inline_batches();

        // Get the number of transactions, payload proofs and inline batches
        let num_transactions = transactions.len();
        let num_payload_proofs = payload_proofs.len();
        let num_opt_and_inline_batches = opt_and_inline_batches.len();

        // Gather the transactions for each payload batch
        let mut batches_and_transactions = vec![];
        let mut transactions_iter = transactions.into_iter();
        for proof_of_store in &payload_proofs {
            match reconstruct_batch(
                &block_info,
                &mut transactions_iter,
                proof_of_store.info(),
                true,
            ) {
                Ok(Some(batch_transactions)) => {
                    batches_and_transactions
                        .push((proof_of_store.info().clone(), batch_transactions));
                },
                Ok(None) => { /* Nothing needs to be done (the batch was expired) */ },
                Err(error) => {
                    return Err(Error::InvalidMessageError(format!(
                        "Failed to reconstruct payload proof batch! Num transactions: {:?}, \
                        num batches: {:?}, num inline batches: {:?}, failed batch: {:?}, Error: {:?}",
                        num_transactions, num_payload_proofs, num_opt_and_inline_batches, proof_of_store.info(), error
                    )));
                },
            }
        }

        // Gather the transactions for each inline batch
        for batch_info in opt_and_inline_batches.iter() {
            match reconstruct_batch(&block_info, &mut transactions_iter, batch_info, false) {
                Ok(Some(batch_transactions)) => {
                    batches_and_transactions.push((batch_info.clone(), batch_transactions));
                },
                Ok(None) => {
                    return Err(Error::UnexpectedError(format!(
                        "Failed to reconstruct inline/opt batch! Batch was unexpectedly skipped: {:?}",
                        batch_info
                    )));
                },
                Err(error) => {
                    return Err(Error::InvalidMessageError(format!(
                        "Failed to reconstruct inline/opt batch! Num transactions: {:?}, \
                        num batches: {:?}, num opt/inline batches: {:?}, failed batch: {:?}, Error: {:?}",
                        num_transactions, num_payload_proofs, num_opt_and_inline_batches, batch_info, error
                    )));
                },
            }
        }

        // Verify all the reconstructed batches (in parallel)
        batches_and_transactions
            .into_par_iter()
            .with_min_len(2)
            .try_for_each(|(batch_info, transactions)| verify_batch(&batch_info, transactions))
            .map_err(|error| {
                Error::InvalidMessageError(format!(
                    "Failed to verify the payload batches and transactions! Error: {:?}",
                    error
                ))
            })?;

        // Verify that there are no transactions remaining (all transactions should be consumed)
        let remaining_transactions = transactions_iter.as_slice();
        if !remaining_transactions.is_empty() {
            return Err(Error::InvalidMessageError(format!(
                "Failed to verify payload transactions! Num transactions: {:?}, \
                transactions remaining: {:?}. Expected: 0",
                num_transactions,
                remaining_transactions.len()
            )));
        }

        Ok(()) // All digests match
    }
```

**File:** consensus/src/block_preparer.rs (L106-108)
```rust
            if let Some(max_txns_from_block_to_execute) = max_txns_from_block_to_execute {
                shuffled_txns.truncate(max_txns_from_block_to_execute as usize);
            }
```

**File:** consensus/consensus-types/src/common.rs (L308-313)
```rust
            Payload::InQuorumStoreWithLimit(proof_with_status) => {
                // here we return the actual length of the payload; limit is considered at the stage
                // where we prepare the block from the payload
                (proof_with_status.proof_with_data.num_txns() as u64)
                    .min(proof_with_status.max_txns_to_execute.unwrap_or(u64::MAX))
            },
```
