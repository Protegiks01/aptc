# Audit Report

## Title
Integer Underflow in Indexer Timestamp Handling Due to Unsafe i64 to u64 Cast

## Summary
The Aptos indexer services contain multiple instances where protobuf `Timestamp.seconds` (i64) values are unsafely cast to u64 without validation. If negative timestamps are present in deserialized protobuf data, this causes integer wraparound leading to incorrect time calculations, cache TTL errors, and service degradation.

## Finding Description

The protobuf `Timestamp` struct uses signed integers for both fields: [1](#0-0) 

During deserialization, no validation enforces non-negative values: [2](#0-1) 

The vulnerability manifests in multiple locations where `timestamp.seconds` (i64) is unsafely cast to u64:

**Location 1 - Cache TTL Calculation:** [3](#0-2) 

This feeds into TTL calculation with unchecked arithmetic: [4](#0-3) 

**Location 2 - Historical Data Service:** [5](#0-4) 

**Location 3 - Live Data Manager:** [6](#0-5) 

**Location 4 - Metadata Manager:** [7](#0-6) 

**Attack Scenario:**

1. Attacker gains access to Redis cache or file store (via infrastructure compromise)
2. Injects malformed transaction data with `timestamp.seconds = -1`
3. When indexer deserializes: `CacheEntry::into_transaction()` accepts the malformed data [8](#0-7) 

4. The cast `(-1 as i64) as u64` produces `18446744073709551615`
5. In `get_ttl_in_seconds()`, subtraction `current_time - 18446744073709551615` underflows
6. Results in: incorrect TTL (wrapped value), wrong staleness detection, incorrect metrics

## Impact Explanation

This qualifies as **Medium Severity** under the bug bounty program because it causes:

- **State inconsistencies requiring intervention**: Cache entries receive incorrect TTL values, leading to data serving inconsistencies
- **Service degradation**: Wrong staleness detection may cause indexers to serve stale data or reject fresh data
- **Operational impact**: Incorrect latency metrics mislead operators about system health

However, this does NOT affect:
- Core consensus protocol (consensus uses u64 timestamps validated at block level) [9](#0-8) 
- Fund security or transaction validation
- Blockchain state integrity

## Likelihood Explanation

**Likelihood: LOW**

The vulnerability requires one of these conditions:
1. **Redis cache corruption**: Direct infrastructure access to inject malformed protobuf data
2. **Compromised indexer node**: Malicious indexer serving corrupted data to downstream services
3. **File store corruption**: Write access to indexer file storage

Normal blockchain operations are protected because:
- Blockchain timestamps originate as u64 microseconds from consensus
- Conversion to protobuf properly clamps values: [10](#0-9) 

External clients cannot inject timestamps as they only consume (not produce) indexer data.

## Recommendation

Add validation before casting i64 to u64:

```rust
// In cache_operator.rs line 267:
let timestamp_in_seconds = transaction.timestamp.map_or(0, |t| {
    if t.seconds < 0 {
        tracing::error!("Negative timestamp detected: {}", t.seconds);
        0
    } else {
        t.seconds as u64
    }
});

// In get_ttl_in_seconds() line 91-97:
pub fn get_ttl_in_seconds(timestamp_in_seconds: u64) -> u64 {
    let current_time = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    // Use saturating_sub to prevent underflow
    let age = current_time.saturating_sub(timestamp_in_seconds);
    BASE_EXPIRATION_EPOCH_TIME_IN_SECONDS.saturating_sub(age)
}
```

Apply similar validation in all other locations (historical_data_service.rs, data_manager.rs, metadata_manager.rs).

## Proof of Concept

```rust
#[test]
fn test_negative_timestamp_underflow() {
    use aptos_protos::util::timestamp::Timestamp;
    use std::time::{Duration, SystemTime, UNIX_EPOCH};
    
    // Create transaction with negative timestamp
    let malicious_timestamp = Timestamp {
        seconds: -1,
        nanos: 0,
    };
    
    // Simulate the unsafe cast
    let timestamp_u64 = malicious_timestamp.seconds as u64;
    assert_eq!(timestamp_u64, 18446744073709551615); // u64::MAX
    
    // Simulate Duration creation (as in historical_data_service.rs:193)
    let timestamp_since_epoch = Duration::new(
        malicious_timestamp.seconds as u64,
        malicious_timestamp.nanos as u32
    );
    
    let now_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
    
    // This will saturate to 0 due to the huge timestamp value
    let delta = now_since_epoch.saturating_sub(timestamp_since_epoch);
    
    // Demonstrates incorrect behavior: delta should be large (old timestamp)
    // but instead is 0 or very small due to wraparound
    println!("Delta: {:?} (incorrect due to underflow)", delta);
    
    // Demonstrate TTL calculation underflow
    let current_time = now_since_epoch.as_secs();
    // This subtraction underflows in release mode
    let age = current_time.wrapping_sub(timestamp_u64);
    println!("Age calculation result: {} (wrapped due to underflow)", age);
}
```

## Notes

While this is a genuine code quality issue, it has **limited exploitability** because:

1. **Infrastructure access required**: Attacker needs Redis/file store access, not achievable by external network peers
2. **Indexer-only impact**: Does not affect consensus, blockchain state, or funds
3. **Operational vs. security**: Primarily causes service degradation rather than security compromise

The vulnerability is valid but falls at the boundary of the "unprivileged attacker" requirement in the validation checklist. The indexer is an off-chain data serving component, and this issue doesn't break any of the 10 critical blockchain invariants listed in the security context.

### Citations

**File:** protos/rust/src/pb/aptos.util.timestamp.rs (L12-19)
```rust
    #[prost(int64, tag="1")]
    pub seconds: i64,
    /// Non-negative fractions of a second at nanosecond resolution. Negative
    /// second values with fractions must still have non-negative nanos values
    /// that count forward in time. Must be from 0 to 999,999,999
    /// inclusive.
    #[prost(int32, tag="2")]
    pub nanos: i32,
```

**File:** protos/rust/src/pb/aptos.util.timestamp.serde.rs (L94-96)
```rust
                            seconds__ =
                                Some(map.next_value::<::pbjson::private::NumberDeserialize<_>>()?.0)
                            ;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L91-97)
```rust
pub fn get_ttl_in_seconds(timestamp_in_seconds: u64) -> u64 {
    let current_time = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    BASE_EXPIRATION_EPOCH_TIME_IN_SECONDS - (current_time - timestamp_in_seconds)
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L267-267)
```rust
            let timestamp_in_seconds = transaction.timestamp.map_or(0, |t| t.seconds as u64);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L192-195)
```rust
                let timestamp_since_epoch =
                    Duration::new(timestamp.seconds as u64, timestamp.nanos as u32);
                let now_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
                let delta = now_since_epoch.saturating_sub(timestamp_since_epoch);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L96-99)
```rust
                let timestamp_since_epoch =
                    Duration::new(txn_timestamp.seconds as u64, txn_timestamp.nanos as u32);
                let now_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
                let latency = now_since_epoch.saturating_sub(timestamp_since_epoch);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L167-172)
```rust
    fn is_stale_timestamp(timestamp: Timestamp, threshold: Duration) -> bool {
        let timestamp_since_epoch = Duration::new(timestamp.seconds as u64, timestamp.nanos as u32);
        let now_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
        let staleness = now_since_epoch.saturating_sub(timestamp_since_epoch);

        staleness >= threshold
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L150-154)
```rust
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
            },
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
```

**File:** consensus/consensus-types/src/block.rs (L527-539)
```rust
            ensure!(
                self.timestamp_usecs() > parent.timestamp_usecs(),
                "Blocks must have strictly increasing timestamps"
            );

            let current_ts = duration_since_epoch();

            // we can say that too far is 5 minutes in the future
            const TIMEBOUND: u64 = 300_000_000;
            ensure!(
                self.timestamp_usecs() <= (current_ts.as_micros() as u64).saturating_add(TIMEBOUND),
                "Blocks must not be too far in the future"
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/convert.rs (L554-567)
```rust
pub fn convert_timestamp_secs(timestamp: u64) -> timestamp::Timestamp {
    let timestamp = std::cmp::min(timestamp, i64::MAX as u64);
    timestamp::Timestamp {
        seconds: timestamp as i64,
        nanos: 0,
    }
}

pub fn convert_timestamp_usecs(timestamp: u64) -> timestamp::Timestamp {
    let ts = Duration::from_micros(timestamp);
    timestamp::Timestamp {
        seconds: ts.as_secs() as i64,
        nanos: ts.subsec_nanos() as i32,
    }
```
