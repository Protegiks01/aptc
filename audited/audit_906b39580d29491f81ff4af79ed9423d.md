# Audit Report

## Title
Partial Batch Write Vulnerability in Sharded State KV Database Commit

## Summary
The `StateKvDb::commit()` function commits state updates across 16 shards in parallel without cross-shard atomicity. If any shard's RocksDB write fails (due to size limits, disk errors, or corruption), a panic occurs while other shards may have already successfully committed their data, creating a temporary inconsistent database state.

## Finding Description

The vulnerability exists in the parallel commit architecture for sharded state key-value data. [1](#0-0) 

The `commit()` function spawns 16 parallel tasks (one per shard) using `THREAD_MANAGER.get_io_pool().scope()`. Each task independently calls `commit_single_shard()` which writes to RocksDB: [2](#0-1) 

If any shard's write fails, the task panics (line 196). However, other parallel tasks may have already completed their `write_schemas()` calls, successfully persisting data to RocksDB. This creates partial writes where some shards contain data for version V while the overall `StateKvCommitProgress` remains at V-1 (since `write_progress(version)` at line 207 is never reached).

The `encode_value()` function uses BCS serialization without size validation: [3](#0-2) 

While VM-level validation exists for write operation sizes: [4](#0-3) 

The BCS serialization overhead can cause the encoded `Option<StateValue>` to exceed the raw data size checked during VM validation. Additionally, cumulative batch sizes across multiple operations in a shard could exceed RocksDB's `max_write_batch_group_size_bytes` limit.

A recovery mechanism exists: [5](#0-4) 

However, this truncation only occurs on restart. During the window between the partial write and node restart, the database is in an inconsistent state.

## Impact Explanation

**Severity: High**

This vulnerability breaks the **State Consistency** invariant (#4): "State transitions must be atomic and verifiable via Merkle proofs."

**Impact:**
1. **State Inconsistency**: Partial writes create database states where some shards have committed version V while others haven't, violating atomicity
2. **Recovery Dependency**: The system relies on the truncation mechanism during restart, which could fail due to disk corruption, permission issues, or filesystem errors
3. **Potential Consensus Divergence**: If truncation fails, different validator nodes could have different states for the same version
4. **Non-deterministic Behavior**: The partial write depends on thread scheduling and timing, making the issue non-deterministic

While the recovery mechanism mitigates exploitation, the fundamental design flaw remains: parallel shard commits without distributed transaction guarantees.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability can be triggered by:
1. **Oversized Values**: StateValues that pass VM validation (≤1MB) but exceed limits when BCS-serialized with metadata
2. **Batch Size Limits**: Multiple large state updates in a single shard exceeding cumulative WriteBatch limits  
3. **Resource Exhaustion**: Disk full, memory allocation failures, or I/O errors during write
4. **Corruption**: Database corruption detected by RocksDB during write

While these conditions are not trivially exploitable by unprivileged attackers, they can occur naturally under high load or through carefully crafted state updates that maximize serialization overhead.

## Recommendation

Implement cross-shard atomicity using one of these approaches:

**Option 1: Two-Phase Commit**
```rust
// Phase 1: Prepare all shards (write to temp location)
// Phase 2: Commit all shards atomically or rollback all on failure
```

**Option 2: Size Validation Before Encoding**
Add size checks before committing:
```rust
pub fn put_state_values(
    &self,
    state_update_refs: &PerVersionStateUpdateRefs,
    sharded_state_kv_batches: &mut ShardedStateKvSchemaBatch,
) -> Result<()> {
    // Pre-validate sizes
    for (batch, updates) in sharded_state_kv_batches.iter().zip(state_update_refs.shards.iter()) {
        for (key, update) in updates.iter() {
            if let Some(write_op) = update.state_op.as_write_op_opt() {
                if let Some(state_value) = write_op.as_state_value_opt() {
                    let encoded_size = bcs::to_bytes(&Some(state_value.clone()))?.len();
                    ensure!(encoded_size < MAX_ROCKSDB_VALUE_SIZE, "Value too large");
                }
            }
        }
    }
    // Proceed with commit...
}
```

**Option 3: Error Propagation Instead of Panic**
Replace panic with proper error propagation and rollback:
```rust
s.spawn(move |_| {
    self.commit_single_shard(version, shard_id, state_kv_batch)
        // Return error instead of panic
});
// Check all results and rollback on any failure
```

## Proof of Concept

```rust
// Reproduction steps:
// 1. Create a StateValue with maximum allowed size (1MB - ε)
// 2. Add metadata to push BCS-serialized size over limits
// 3. Submit transaction that creates this StateValue in multiple shards
// 4. Trigger write failure in one shard (simulate disk full via ulimit or syscall interception)
// 5. Observe partial writes: some shards committed, others didn't
// 6. Verify overall StateKvCommitProgress not updated
// 7. Attempt truncation recovery - if it fails, database remains inconsistent

#[test]
fn test_partial_batch_write() {
    // Setup test with 16 shards
    let state_kv_db = setup_test_db();
    
    // Create near-maximum size StateValue
    let large_data = vec![0u8; (1 << 20) - 100]; // 1MB - 100 bytes
    let state_value = StateValue::new_with_metadata(
        large_data.into(),
        StateValueMetadata::new(1000, 1000, &current_time),
    );
    
    // Create batches with multiple large values per shard
    let mut batches = state_kv_db.new_sharded_native_batches();
    for shard_id in 0..NUM_STATE_SHARDS {
        for i in 0..10 {
            let key = StateKey::raw(format!("shard{}_key{}", shard_id, i).as_bytes());
            batches[shard_id].put::<StateValueSchema>(
                &(key, version),
                &Some(state_value.clone()),
            )?;
        }
    }
    
    // Inject failure in shard 8 (simulate via mock or resource limit)
    inject_disk_full_for_shard(8);
    
    // Attempt commit - should panic with partial writes
    let result = state_kv_db.commit(version, None, batches);
    
    // Verify partial writes occurred
    assert!(result.is_err());
    verify_shards_0_to_7_have_data(version);
    verify_shard_8_has_no_data(version);
    verify_overall_progress_is_previous_version(version - 1);
}
```

## Notes

The vulnerability is mitigated by the truncation recovery mechanism during startup, but relies on that mechanism working correctly. If truncation fails or if the node serves queries before restarting, state inconsistencies could propagate. The fundamental issue is the lack of distributed transaction guarantees across parallel shard commits.

### Citations

**File:** storage/aptosdb/src/state_kv_db.rs (L164-168)
```rust
        if !readonly {
            if let Some(overall_kv_commit_progress) = get_state_kv_commit_progress(&state_kv_db)? {
                truncate_state_kv_db_shards(&state_kv_db, overall_kv_commit_progress)?;
            }
        }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-208)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L293-304)
```rust
    pub(crate) fn commit_single_shard(
        &self,
        version: Version,
        shard_id: usize,
        mut batch: impl WriteBatch,
    ) -> Result<()> {
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardCommitProgress(shard_id),
            &DbMetadataValue::Version(version),
        )?;
        self.state_kv_db_shards[shard_id].write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/schema/state_value/mod.rs (L61-69)
```rust
impl ValueCodec<StateValueSchema> for Option<StateValue> {
    fn encode_value(&self) -> Result<Vec<u8>> {
        bcs::to_bytes(self).map_err(Into::into)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        bcs::from_bytes(data).map_err(Into::into)
    }
}
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L101-113)
```rust
        let mut write_set_size = 0;
        for (key, op_size) in change_set.write_set_size_iter() {
            if let Some(len) = op_size.write_len() {
                let write_op_size = len + (key.size() as u64);
                if write_op_size > self.max_bytes_per_write_op {
                    return storage_write_limit_reached(None);
                }
                write_set_size += write_op_size;
            }
            if write_set_size > self.max_bytes_all_write_ops_per_transaction {
                return storage_write_limit_reached(None);
            }
        }
```
