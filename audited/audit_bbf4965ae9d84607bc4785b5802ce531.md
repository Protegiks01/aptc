# Audit Report

## Title
Fast Sync Split State Vulnerability Due to Non-Atomic Status Update in finalize_state_snapshot()

## Summary
The `finalize_state_snapshot()` function in `FastSyncStorageWrapper` can leave the system in a critical split state where reads and writes target different databases. When the underlying AptosDB finalization partially succeeds but fails before updating the `fast_sync_status` to `FINISHED`, the wrapper remains stuck in `STARTED` state, causing all subsequent read operations to use `temporary_db_with_genesis` while write operations use `db_for_fast_sync`.

## Finding Description

The vulnerability exists in the `finalize_state_snapshot()` method implementation: [1](#0-0) 

The function calls the underlying AptosDB's `finalize_state_snapshot()` which performs multiple non-atomic operations: [2](#0-1) 

The underlying finalization can fail at multiple points after partially committing data (e.g., after line 223 commits `ledger_db_batch`, but before lines 225-234 save minimum readable versions). When this occurs, the `?` operator propagates the error, preventing lines 167-168 from executing, leaving `fast_sync_status` permanently stuck at `STARTED`.

The database routing logic creates the split state:

**Write Operations:** [3](#0-2) 

Returns `db_for_fast_sync` when status is `STARTED` OR `FINISHED`.

**Read Operations:** [4](#0-3) 

Returns `temporary_db_with_genesis` when status is NOT `FINISHED`.

All DbReader operations delegate to this inconsistent routing: [5](#0-4) 

**Critical Issue**: There is NO recovery mechanism to reset the status. The status is only modified in two locations: [6](#0-5) [7](#0-6) 

**Attack Propagation:**
1. Fast sync initiates, status set to `STARTED`
2. State chunks written to `db_for_fast_sync`
3. `finalize_state_snapshot()` called on underlying DB
4. Partial success: some data committed (e.g., ledger_db_batch at line 223), then failure occurs (e.g., at line 225)
5. Error propagated via storage synchronizer error handling: [8](#0-7) 

6. Bootstrapper receives error and resets stream but does NOT reset the fast_sync_status: [9](#0-8) 

7. Node continues operating with status stuck at `STARTED`
8. All subsequent operations experience split state: writes to `db_for_fast_sync`, reads from `temporary_db_with_genesis`

## Impact Explanation

**Critical Severity** - This vulnerability violates fundamental state consistency guarantees:

1. **Breaks State Consistency Invariant**: State transitions are no longer atomic or consistent. The system maintains two divergent database views simultaneously.

2. **Consensus Divergence Risk**: If the node participates in consensus while in this state, it will produce incorrect votes and state roots based on reads from the wrong database, potentially causing consensus safety violations across the network.

3. **Incorrect Transaction Execution**: Any transaction execution will read state from `temporary_db_with_genesis` (containing only genesis data) while writing outputs to `db_for_fast_sync`, producing completely invalid state transitions.

4. **Non-Recoverable Without Manual Intervention**: The status flag has no automatic reset mechanism. The node will remain in this broken state indefinitely until manually restarted or the databases are manually reconciled.

5. **Network-Wide Impact**: If multiple nodes experience this failure during fast sync (e.g., due to coordinated network disruption), the entire network could experience consensus failures requiring hard fork intervention.

This meets the **Critical Severity** criteria: "Consensus/Safety violations" and "State inconsistencies requiring intervention."

## Likelihood Explanation

**High Likelihood** - This vulnerability can be triggered by common operational conditions:

1. **Network Disruptions**: Any network interruption during state snapshot finalization can cause partial writes
2. **Disk Space Issues**: Running out of disk space mid-finalization will trigger the failure
3. **Database Write Failures**: Any RocksDB write error during the multi-step finalization process
4. **Node Crashes**: Power failures or process crashes after partial commit
5. **Resource Exhaustion**: Memory or CPU exhaustion during finalization

The underlying `finalize_state_snapshot()` performs at least 8 separate operations that can fail independently. The lack of atomic transaction semantics across all these operations means partial success is a realistic scenario, not an edge case.

## Recommendation

Implement atomic state management with automatic rollback on failure:

```rust
fn finalize_state_snapshot(
    &self,
    version: Version,
    output_with_proof: TransactionOutputListWithProofV2,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    let status = self.get_fast_sync_status();
    assert_eq!(status, FastSyncStatus::STARTED);
    
    // Wrap in a guard that ensures status consistency
    let result = self.get_aptos_db_write_ref().finalize_state_snapshot(
        version,
        output_with_proof,
        ledger_infos,
    );
    
    match result {
        Ok(()) => {
            let mut status = self.fast_sync_status.write();
            *status = FastSyncStatus::FINISHED;
            Ok(())
        }
        Err(e) => {
            // CRITICAL FIX: Reset status to UNKNOWN on failure
            // This ensures subsequent operations don't experience split state
            let mut status = self.fast_sync_status.write();
            *status = FastSyncStatus::UNKNOWN;
            
            // Also consider: Signal to restart fast sync from scratch
            // or implement proper rollback of partial DB changes
            Err(e)
        }
    }
}
```

Additionally, the underlying AptosDB `finalize_state_snapshot()` should use database transactions to ensure atomicity of all operations or implement proper rollback mechanisms.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_config::config::{NodeConfig, NO_OP_STORAGE_PRUNER_CONFIG};
    
    #[test]
    fn test_split_state_on_partial_finalization_failure() {
        // Setup: Create FastSyncStorageWrapper
        let tmp_dir = TempPath::new();
        let mut config = NodeConfig::default();
        config.storage.dir = tmp_dir.path().to_path_buf();
        config.storage.storage_pruner_config = NO_OP_STORAGE_PRUNER_CONFIG;
        config.state_sync.state_sync_driver.bootstrapping_mode = 
            BootstrappingMode::ApplyTransactionOutputsFromGenesis;
        
        let wrapper = FastSyncStorageWrapper::initialize_dbs(&config, None, None)
            .unwrap()
            .right()
            .expect("Should create wrapper for empty DB with fast sync enabled");
        
        // Step 1: Start fast sync - status becomes STARTED
        let version = 100;
        let root_hash = HashValue::random();
        let _receiver = wrapper.get_state_snapshot_receiver(version, root_hash).unwrap();
        
        assert_eq!(wrapper.get_fast_sync_status(), FastSyncStatus::STARTED);
        
        // Step 2: Simulate partial finalization failure
        // (In real scenario, finalize_state_snapshot would partially succeed then fail)
        // We simulate this by NOT calling finalize_state_snapshot to completion
        
        // Step 3: Verify split state
        // Write operations target db_for_fast_sync
        let write_db = wrapper.get_aptos_db_write_ref();
        assert!(std::ptr::eq(write_db, wrapper.db_for_fast_sync.as_ref()));
        
        // Read operations target temporary_db_with_genesis  
        let read_db = wrapper.get_aptos_db_read_ref();
        assert!(std::ptr::eq(read_db, wrapper.temporary_db_with_genesis.as_ref()));
        
        // CRITICAL: Different databases are being used!
        assert!(!std::ptr::eq(read_db, write_db));
        
        // This split state persists - status remains STARTED with no recovery mechanism
        assert_eq!(wrapper.get_fast_sync_status(), FastSyncStatus::STARTED);
    }
}
```

**Notes:**
- This vulnerability affects any node performing fast sync during network instability or operational issues
- The split state persists indefinitely with no automatic recovery
- Multiple failure points exist in the underlying finalization process, making this a realistic scenario
- The lack of transactional semantics across both the status update and database operations is the root cause
- Impact is amplified during network-wide fast sync operations where multiple nodes could experience simultaneous failures

### Citations

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L126-132)
```rust
    pub(crate) fn get_aptos_db_read_ref(&self) -> &AptosDB {
        if self.is_fast_sync_bootstrap_finished() {
            self.db_for_fast_sync.as_ref()
        } else {
            self.temporary_db_with_genesis.as_ref()
        }
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L134-140)
```rust
    pub(crate) fn get_aptos_db_write_ref(&self) -> &AptosDB {
        if self.is_fast_sync_bootstrap_started() || self.is_fast_sync_bootstrap_finished() {
            self.db_for_fast_sync.as_ref()
        } else {
            self.temporary_db_with_genesis.as_ref()
        }
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L149-149)
```rust
        *self.fast_sync_status.write() = FastSyncStatus::STARTED;
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L154-170)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let status = self.get_fast_sync_status();
        assert_eq!(status, FastSyncStatus::STARTED);
        self.get_aptos_db_write_ref().finalize_state_snapshot(
            version,
            output_with_proof,
            ledger_infos,
        )?;
        let mut status = self.fast_sync_status.write();
        *status = FastSyncStatus::FINISHED;
        Ok(())
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L188-192)
```rust
impl DbReader for FastSyncStorageWrapper {
    fn get_read_delegatee(&self) -> &dyn DbReader {
        self.get_aptos_db_read_ref()
    }
}
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-241)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
            ensure!(
                num_transaction_outputs == 1,
                "Number of transaction outputs should == 1, but got: {}",
                num_transaction_outputs
            );
            ensure!(
                num_transaction_infos == 1,
                "Number of transaction infos should == 1, but got: {}",
                num_transaction_infos
            );

            // TODO(joshlind): include confirm_or_save_frozen_subtrees in the change set
            // bundle below.

            // Update the merkle accumulator using the given proof
            let frozen_subtrees = output_with_proof
                .proof
                .ledger_info_to_transaction_infos_proof
                .left_siblings();
            restore_utils::confirm_or_save_frozen_subtrees(
                self.ledger_db.transaction_accumulator_db_raw(),
                version,
                frozen_subtrees,
                None,
            )?;

            // Create a single change set for all further write operations
            let mut ledger_db_batch = LedgerDbSchemaBatches::new();
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
            // Save the target transactions, outputs, infos and events
            let (transactions, outputs): (Vec<Transaction>, Vec<TransactionOutput>) =
                output_with_proof
                    .transactions_and_outputs
                    .into_iter()
                    .unzip();
            let events = outputs
                .clone()
                .into_iter()
                .map(|output| output.events().to_vec())
                .collect::<Vec<_>>();
            let wsets: Vec<WriteSet> = outputs
                .into_iter()
                .map(|output| output.write_set().clone())
                .collect();
            let transaction_infos = output_with_proof.proof.transaction_infos;
            // We should not save the key value since the value is already recovered for this version
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;

            // Save the epoch ending ledger infos
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;

            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;

            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;

            restore_utils::update_latest_ledger_info(self.ledger_db.metadata_db(), ledger_infos)?;
            self.state_store.reset();

            Ok(())
        })
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1129-1136)
```rust
    storage
        .writer
        .finalize_state_snapshot(
            version,
            target_output_with_proof.clone(),
            epoch_change_proofs,
        )
        .map_err(|error| format!("Failed to finalize the state snapshot! Error: {:?}", error))?;
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1517-1536)
```rust
    pub async fn handle_storage_synchronizer_error(
        &mut self,
        notification_and_feedback: NotificationAndFeedback,
    ) -> Result<(), Error> {
        // Reset the active stream
        self.reset_active_stream(Some(notification_and_feedback))
            .await?;

        // Fallback to output syncing if we need to
        if let BootstrappingMode::ExecuteOrApplyFromGenesis = self.get_bootstrapping_mode() {
            self.output_fallback_handler.fallback_to_outputs();
            metrics::set_gauge(
                &metrics::DRIVER_FALLBACK_MODE,
                ExecutingComponent::Bootstrapper.get_label(),
                1,
            );
        }

        Ok(())
    }
```
