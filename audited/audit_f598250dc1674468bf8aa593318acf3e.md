# Audit Report

## Title
Missing Timeout in Sharded Block Executor Causes Indefinite Validator Hang on Shard Failure

## Summary
The `get_value()` function in `RemoteStateValue` and `receive_cross_shard_msg()` in cross-shard communication lack timeout mechanisms, causing validators using sharded execution to hang indefinitely when any shard fails to send cross-shard state updates. This breaks validator liveness guarantees and requires manual intervention.

## Finding Description

The sharded block executor in Aptos enables parallel transaction execution across multiple shards within a single validator. When transactions have cross-shard dependencies, the system uses `RemoteStateValue` to coordinate state sharing between shards.

**Critical Code Path:**

1. When executing a sub-block, `CrossShardStateView` is created with cross-shard state keys initialized as `RemoteStateValue::waiting()` [1](#0-0) 

2. When a transaction needs cross-shard state, it calls `get_state_value()` which invokes `get_value()` [2](#0-1) 

3. The `get_value()` function blocks indefinitely using `cvar.wait()` **without any timeout**: [3](#0-2) 

4. Meanwhile, `CrossShardCommitReceiver` waits for messages via `receive_cross_shard_msg()` [4](#0-3) 

5. All implementations of `receive_cross_shard_msg()` use blocking `recv()` **without timeout**:
   - LocalCrossShardClient: [5](#0-4) 
   - GlobalCrossShardClient: [6](#0-5) 
   - RemoteCrossShardClient: [7](#0-6) 

**Vulnerability Trigger:**

If any shard experiences:
- Process crash before sending cross-shard updates
- Network partition (in remote execution mode)
- Infinite loop or deadlock in transaction execution
- Hardware failure
- Software bug causing message omission

Then dependent shards will block forever at two levels:
1. `CrossShardCommitReceiver::start()` blocks on `receive_cross_shard_msg()` 
2. Transaction execution blocks on `get_value()` waiting for the value

The validator's executor threads hang permanently with no timeout to detect or recover from the failure.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty criteria:

1. **"Validator node slowdowns"** - The actual impact is worse than a slowdown; it's a complete hang. The validator cannot execute any blocks that require cross-shard coordination, effectively removing it from consensus participation.

2. **"Significant protocol violations"** - The validator violates liveness guarantees by being unable to make progress on block execution, requiring manual intervention (process restart) to recover.

While this affects individual validators (not the entire network), the lack of fault tolerance is a significant protocol violation. In Byzantine Fault Tolerant systems, components should gracefully handle failures of other components rather than hanging indefinitely.

**Network-wide Impact Consideration:**
If multiple validators enable sharded execution (which is optional) and experience simultaneous shard failures due to:
- Common software bugs triggered by specific transaction patterns
- Coordinated infrastructure issues
- Widespread network problems affecting remote shards

Then > 1/3 of validators by stake could be affected, potentially causing network liveness failure. However, this requires multiple validators to fail simultaneously.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability triggers when:
1. A validator enables sharded execution (optional feature)
2. Transactions with cross-shard dependencies are executed
3. A shard fails to send cross-shard updates

Factors increasing likelihood:
- Remote sharded execution increases failure surface (network partitions, machine crashes)
- Complex transaction workloads increase cross-shard dependencies
- Long-running blocks increase exposure window
- No circuit breaker or health monitoring

Factors decreasing likelihood:
- Sharded execution is optional, not all validators use it
- Local execution mode has lower failure rate (single process)
- Requires actual shard failure or bug trigger

## Recommendation

Implement timeout mechanisms at both levels of the blocking operations:

**Level 1: Add timeout to `get_value()`**
```rust
// In remote_state_value.rs
pub fn get_value(&self, timeout: Duration) -> Result<Option<StateValue>, TimeoutError> {
    let (lock, cvar) = &*self.value_condition;
    let mut status = lock.lock().unwrap();
    
    while let RemoteValueStatus::Waiting = *status {
        let (new_status, timeout_result) = cvar.wait_timeout(status, timeout).unwrap();
        status = new_status;
        
        if timeout_result.timed_out() {
            return Err(TimeoutError::CrossShardTimeout);
        }
    }
    
    match &*status {
        RemoteValueStatus::Ready(value) => Ok(value.clone()),
        RemoteValueStatus::Waiting => unreachable!(),
    }
}
```

**Level 2: Add timeout to `receive_cross_shard_msg()`**
```rust
// Update CrossShardClient trait
pub trait CrossShardClient: Send + Sync {
    fn receive_cross_shard_msg(
        &self, 
        current_round: RoundId,
        timeout: Duration
    ) -> Result<CrossShardMsg, TimeoutError>;
    // ... other methods
}

// In local_executor_shard.rs
fn receive_cross_shard_msg(
    &self, 
    current_round: RoundId,
    timeout: Duration
) -> Result<CrossShardMsg, TimeoutError> {
    self.message_rxs[current_round]
        .recv_timeout(timeout)
        .map_err(|_| TimeoutError::ChannelTimeout)
}
```

**Level 3: Handle timeouts in CrossShardCommitReceiver**
```rust
// In cross_shard_client.rs
impl CrossShardCommitReceiver {
    pub fn start<S: StateView + Sync + Send>(
        cross_shard_state_view: Arc<CrossShardStateView<S>>,
        cross_shard_client: Arc<dyn CrossShardClient>,
        round: RoundId,
    ) {
        let timeout = Duration::from_secs(30); // Configurable
        loop {
            match cross_shard_client.receive_cross_shard_msg(round, timeout) {
                Ok(CrossShardMsg::RemoteTxnWriteMsg(txn_commit_msg)) => {
                    let (state_key, write_op) = txn_commit_msg.take();
                    cross_shard_state_view.set_value(&state_key, write_op.and_then(|w| w.as_state_value()));
                },
                Ok(CrossShardMsg::StopMsg) => {
                    trace!("Cross shard commit receiver stopped for round {}", round);
                    break;
                },
                Err(TimeoutError) => {
                    error!("Timeout waiting for cross-shard message in round {}", round);
                    // Trigger shard failure recovery or abort execution
                    break;
                }
            }
        }
    }
}
```

**Configuration:** Add timeout values to `BlockExecutorConfig`:
- `cross_shard_message_timeout_ms`: Timeout for receiving cross-shard messages (default: 30000ms)
- `cross_shard_state_timeout_ms`: Timeout for waiting on remote state values (default: 60000ms)

## Proof of Concept

```rust
#[cfg(test)]
mod timeout_vulnerability_test {
    use super::*;
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_indefinite_hang_on_missing_cross_shard_update() {
        // Create a RemoteStateValue in waiting state
        let remote_value = Arc::new(RemoteStateValue::waiting());
        let remote_value_clone = remote_value.clone();
        
        // Spawn a thread that tries to get the value
        let get_thread = thread::spawn(move || {
            let start = std::time::Instant::now();
            // This will hang forever since no one calls set_value()
            let _value = remote_value_clone.get_value();
            start.elapsed()
        });
        
        // Wait for 5 seconds - the thread should still be blocked
        thread::sleep(Duration::from_secs(5));
        
        // Verify the thread is still running (would fail if it completed)
        assert!(!get_thread.is_finished(), 
            "Thread should hang indefinitely waiting for value");
        
        // This test demonstrates the hang. In production:
        // 1. A shard crashes before calling set_value()
        // 2. Dependent transactions block forever in get_value()
        // 3. The entire validator hangs on this block
        // 4. Manual intervention (restart) is required
        
        // Clean up: call set_value to unblock the thread
        remote_value.set_value(None);
        let elapsed = get_thread.join().unwrap();
        
        println!("Thread was blocked for {:?} (should be ~5s due to test sleep)", elapsed);
    }
    
    #[test]
    fn test_cross_shard_receiver_hang() {
        use crossbeam_channel::unbounded;
        
        let (tx, rx) = unbounded::<CrossShardMsg>();
        
        // Simulate CrossShardCommitReceiver blocking on receive
        let receive_thread = thread::spawn(move || {
            // This will block forever if no message is sent
            let _msg = rx.recv().unwrap();
        });
        
        thread::sleep(Duration::from_secs(2));
        
        // Verify the receiver thread is still blocked
        assert!(!receive_thread.is_finished(),
            "Receiver should hang waiting for cross-shard message");
        
        // In production: If the sending shard crashes, this receiver
        // hangs forever with no timeout to detect the failure
        
        // Clean up
        tx.send(CrossShardMsg::StopMsg).unwrap();
        receive_thread.join().unwrap();
    }
}
```

**Steps to Reproduce in Live Environment:**

1. Configure a validator with sharded execution enabled (num_shards > 1)
2. Submit a block with transactions that have cross-shard dependencies
3. During execution, forcefully kill one of the shard processes (simulating crash)
4. Observe that dependent shards hang indefinitely in `get_value()`
5. Observe that the validator stops making progress on consensus
6. Verify that only a manual restart recovers the validator

**Expected Behavior with Fix:** After timeout expiration, execution should abort gracefully and return an error, allowing the validator to retry or skip the problematic block rather than hanging indefinitely.

---

**Notes:**

The vulnerability exists as documented, but fails the strict validation criterion of "Exploitable by unprivileged attacker (no validator insider access required)". The shards are controlled by the validator operator (trusted role), and an external attacker cannot directly cause a shard to fail without first compromising the validator's infrastructure or triggering a separate bug.

However, this represents a critical **fault tolerance deficiency** in Byzantine Fault Tolerant systems. In BFT consensus, "Byzantine" behavior includes arbitrary failures (crashes, hangs, message omissions), not just malicious behavior. The lack of timeout means the system cannot recover from shard failures without manual intervention, violating fundamental BFT liveness guarantees.

The appropriate classification is a **design flaw affecting fault tolerance** rather than a directly exploitable vulnerability by external attackers.

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L32-34)
```rust
        for key in cross_shard_keys {
            cross_shard_data.insert(key, RemoteStateValue::waiting());
        }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L77-81)
```rust
    fn get_state_value(&self, state_key: &StateKey) -> Result<Option<StateValue>, StateViewError> {
        if let Some(value) = self.cross_shard_data.get(state_key) {
            return Ok(value.get_value());
        }
        self.base_view.get_state_value(state_key)
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/remote_state_value.rs (L29-39)
```rust
    pub fn get_value(&self) -> Option<StateValue> {
        let (lock, cvar) = &*self.value_condition;
        let mut status = lock.lock().unwrap();
        while let RemoteValueStatus::Waiting = *status {
            status = cvar.wait(status).unwrap();
        }
        match &*status {
            RemoteValueStatus::Ready(value) => value.clone(),
            RemoteValueStatus::Waiting => unreachable!(),
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L31-33)
```rust
        loop {
            let msg = cross_shard_client.receive_cross_shard_msg(round);
            match msg {
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L295-301)
```rust
    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        assert_eq!(
            current_round, GLOBAL_ROUND_ID,
            "Global shard client should only receive cross-shard messages in global round"
        );
        self.global_message_rx.recv().unwrap()
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L335-337)
```rust
    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        self.message_rxs[current_round].recv().unwrap()
    }
```

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L61-66)
```rust
    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        let rx = self.message_rxs[current_round].lock().unwrap();
        let message = rx.recv().unwrap();
        let msg: CrossShardMsg = bcs::from_bytes(&message.to_bytes()).unwrap();
        msg
    }
```
