# Audit Report

## Title
Unbounded Memory Growth Due to Unchecked Divergence Between ordered_root and commit_root in Consensus Block Storage

## Summary
The `send_for_execution()` function in BlockStore can cause unbounded memory accumulation by allowing `ordered_root` to advance arbitrarily far ahead of `commit_root` without enforcing gap bounds, leading to potential memory exhaustion and node crashes during catch-up scenarios or execution delays.

## Finding Description

The Aptos consensus implementation maintains two critical pointers: `ordered_root` (blocks sent for execution) and `commit_root` (blocks fully persisted). A design flaw allows these to diverge without bound checking, violating memory safety invariants.

**The Vulnerability Flow:** [1](#0-0) 

The `send_for_execution()` function updates `ordered_root` synchronously (line 338) before sending blocks to the execution pipeline asynchronously (lines 344-347). There is no check to prevent `ordered_root` from advancing too far ahead of `commit_root`. [2](#0-1) 

When nodes receive Quorum Certificates during catch-up or sync operations, `send_for_execution()` can be invoked multiple times rapidly via `insert_quorum_cert()`, with each invocation advancing `ordered_root` independently of `commit_root`'s progress.

**Memory Accumulation Points:**

1. **BlockTree Storage**: [3](#0-2) 
   All blocks between `commit_root` and the chain tip remain in the `id_to_block` HashMap until pruned.

2. **Unbounded Channel**: [4](#0-3) 
   Ordered blocks queue in an unbounded channel between BlockStore and BufferManager.

3. **Buffer Manager**: [5](#0-4) 
   Blocks accumulate in the Buffer structure during execution pipeline processing.

**Why Back Pressure Fails:**

The existing back pressure mechanisms are insufficient: [6](#0-5) 

The `vote_back_pressure()` check only prevents NEW voting when `ordered_round > commit_round + 12`, but doesn't prevent processing QCs that already exist from other validators during catch-up scenarios. [7](#0-6) 

The BufferManager's back pressure checks `latest_round` vs `highest_committed_round` with a 20-round gap, but this only gates accepting new blocks into the buffer. It doesn't prevent:
- The unbounded channel from accumulating blocks when back pressure is active
- BlockStore's `ordered_root` from advancing ahead of this check
- Blocks in BlockTree's HashMap from accumulating between `commit_root` and `ordered_root`

**Attack Scenario:**

When a validator node experiences slow execution (due to complex transactions, disk I/O bottlenecks, or resource contention) while simultaneously receiving multiple valid QCs from the network (during catch-up after downtime or network partition recovery):

1. Node receives QC₁ for round 100, commits it via `send_for_execution()` → `ordered_root` = 100
2. Before execution completes, receives QC₂ for round 115 → `ordered_root` = 115  
3. Pattern continues: QC₃ (round 130), QC₄ (round 145)...
4. `ordered_root` keeps advancing while `commit_root` remains stuck at previous value
5. All blocks from `commit_root` to current tip accumulate in memory
6. Eventually triggers OOM and node crash

## Impact Explanation

**Severity: High** (Validator node slowdowns / crashes)

This vulnerability enables memory exhaustion leading to validator node crashes, which qualifies as **High Severity** per Aptos bug bounty criteria: "Validator node slowdowns" and operational degradation.

**Affected Systems:**
- All validator nodes during catch-up scenarios
- Nodes experiencing execution delays (slow transactions, disk bottlenecks)
- Network-wide impact if multiple validators crash simultaneously during stress periods

**Invariant Violations:**
- Violates "Resource Limits: All operations must respect gas, storage, and computational limits" (memory is unbounded)
- Violates "State Consistency: State transitions must be atomic and verifiable" (inconsistent state when node crashes)

## Likelihood Explanation

**Likelihood: Medium-High**

This occurs naturally under legitimate operational conditions without requiring attacker action:

**Triggering Conditions:**
- Validator downtime followed by catch-up (common operational scenario)
- Network partitions healing (validators syncing multiple rounds)
- Execution pipeline slowdowns due to complex transactions
- Disk I/O saturation during high transaction volume
- Resource exhaustion on validator hardware

**Why Current Mitigations Fail:**
- The 12-round vote back pressure limit only affects new proposals, not processing existing QCs
- The 20-round buffer manager back pressure doesn't bound `ordered_root` advancement
- No explicit gap enforcement in `send_for_execution()` between `ordered_root` and `commit_root`

## Recommendation

Add explicit bound checking in `send_for_execution()` to prevent `ordered_root` from advancing beyond a safe distance from `commit_root`:

```rust
pub async fn send_for_execution(
    &self,
    finality_proof: WrappedLedgerInfo,
) -> anyhow::Result<()> {
    let block_id_to_commit = finality_proof.commit_info().id();
    let block_to_commit = self
        .get_block(block_id_to_commit)
        .ok_or_else(|| format_err!("Committed block id not found"))?;

    // First make sure that this commit is new.
    ensure!(
        block_to_commit.round() > self.ordered_root().round(),
        "Committed block round lower than root"
    );

    // ADD: Enforce maximum gap between ordered_root and commit_root
    let commit_round = self.commit_root().round();
    let max_gap = self.vote_back_pressure_limit * 2; // Use 2x the vote back pressure limit
    ensure!(
        block_to_commit.round() <= commit_round + max_gap,
        "Cannot advance ordered_root beyond safe bounds: block round {} exceeds commit_root {} + max_gap {}",
        block_to_commit.round(),
        commit_round,
        max_gap
    );

    // ... rest of function
}
```

Additionally, implement monitoring metrics to track the gap:
```rust
counters::ORDERED_COMMIT_GAP.set((self.ordered_root().round() - self.commit_root().round()) as i64);
```

## Proof of Concept

**Scenario Setup:**
```rust
// In a test environment, simulate the vulnerability:

#[tokio::test]
async fn test_unbounded_ordered_commit_divergence() {
    let (block_store, mut mock_execution) = setup_test_environment();
    
    // Simulate slow execution by not processing blocks
    mock_execution.pause_execution();
    
    // Send multiple QCs rapidly (simulating catch-up)
    for round in 100..200 {
        let qc = create_valid_qc_for_round(round);
        
        // This should succeed each time, advancing ordered_root
        block_store.send_for_execution(qc.into_wrapped_ledger_info())
            .await
            .expect("Should succeed");
        
        // Verify ordered_root advances
        assert_eq!(block_store.ordered_root().round(), round);
    }
    
    // commit_root hasn't moved due to paused execution
    assert_eq!(block_store.commit_root().round(), 99);
    
    // Gap is now 100 rounds - exceeds all back pressure limits!
    let gap = block_store.ordered_root().round() - block_store.commit_root().round();
    assert_eq!(gap, 100);
    
    // Memory accumulation: all 100 blocks remain in BlockTree
    assert_eq!(block_store.len(), 100);
    
    // This demonstrates unbounded growth potential
}
```

**Observation in Production:**
Monitor the gap metric during normal operation. Under heavy load or catch-up scenarios, observe the gap exceeding configured back pressure limits, confirming the vulnerability.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L312-350)
```rust
    pub async fn send_for_execution(
        &self,
        finality_proof: WrappedLedgerInfo,
    ) -> anyhow::Result<()> {
        let block_id_to_commit = finality_proof.commit_info().id();
        let block_to_commit = self
            .get_block(block_id_to_commit)
            .ok_or_else(|| format_err!("Committed block id not found"))?;

        // First make sure that this commit is new.
        ensure!(
            block_to_commit.round() > self.ordered_root().round(),
            "Committed block round lower than root"
        );

        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();

        assert!(!blocks_to_commit.is_empty());

        let finality_proof_clone = finality_proof.clone();
        self.pending_blocks
            .lock()
            .gc(finality_proof.commit_info().round());

        self.inner.write().update_ordered_root(block_to_commit.id());
        self.inner
            .write()
            .insert_ordered_cert(finality_proof_clone.clone());
        update_counters_for_ordered_blocks(&blocks_to_commit);

        self.execution_client
            .finalize_order(blocks_to_commit, finality_proof.clone())
            .await
            .expect("Failed to persist commit");

        Ok(())
    }
```

**File:** consensus/src/block_storage/block_store.rs (L691-704)
```rust
    fn vote_back_pressure(&self) -> bool {
        #[cfg(any(test, feature = "fuzzing"))]
        {
            if self.back_pressure_for_test.load(Ordering::Relaxed) {
                return true;
            }
        }
        let commit_round = self.commit_root().round();
        let ordered_round = self.ordered_root().round();
        counters::OP_COUNTERS
            .gauge("back_pressure")
            .set((ordered_round - commit_round) as i64);
        ordered_round > self.vote_back_pressure_limit + commit_round
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L186-189)
```rust
        if self.ordered_root().round() < qc.commit_info().round() {
            SUCCESSFUL_EXECUTED_WITH_REGULAR_QC.inc();
            self.send_for_execution(qc.into_wrapped_ledger_info())
                .await?;
```

**File:** consensus/src/block_storage/block_tree.rs (L73-101)
```rust
pub struct BlockTree {
    /// All the blocks known to this replica (with parent links)
    id_to_block: HashMap<HashValue, LinkableBlock>,
    /// Root of the tree. This is the root of ordering phase
    ordered_root_id: HashValue,
    /// Commit Root id: this is the root of commit phase
    commit_root_id: HashValue,
    /// Window Root id: this is the first item in the [`OrderedBlockWindow`](OrderedBlockWindow)
    window_root_id: HashValue,
    /// A certified block id with highest round
    highest_certified_block_id: HashValue,

    /// The quorum certificate of highest_certified_block
    highest_quorum_cert: Arc<QuorumCert>,
    /// The highest 2-chain timeout certificate (if any).
    highest_2chain_timeout_cert: Option<Arc<TwoChainTimeoutCertificate>>,
    /// The quorum certificate that has highest commit info.
    highest_ordered_cert: Arc<WrappedLedgerInfo>,
    /// The quorum certificate that has highest commit decision info.
    highest_commit_cert: Arc<WrappedLedgerInfo>,
    /// Map of block id to its completed quorum certificate (2f + 1 votes)
    id_to_quorum_cert: HashMap<HashValue, Arc<QuorumCert>>,
    /// To keep the IDs of the elements that have been pruned from the tree but not cleaned up yet.
    pruned_block_ids: VecDeque<HashValue>,
    /// Num pruned blocks to keep in memory.
    max_pruned_blocks_in_mem: usize,
    /// Round to Block index. We expect only one block per round.
    round_to_ids: BTreeMap<Round, HashValue>,
}
```

**File:** consensus/src/pipeline/execution_client.rs (L475-476)
```rust
                let (ordered_block_tx, ordered_block_rx) = unbounded();
                (ordered_block_tx, ordered_block_rx, None, None)
```

**File:** consensus/src/pipeline/buffer_manager.rs (L105-109)
```rust
pub struct BufferManager {
    author: Author,

    buffer: Buffer<BufferItem>,

```

**File:** consensus/src/pipeline/buffer_manager.rs (L906-910)
```rust
    fn need_back_pressure(&self) -> bool {
        const MAX_BACKLOG: Round = 20;

        self.back_pressure_enabled && self.highest_committed_round + MAX_BACKLOG < self.latest_round
    }
```
