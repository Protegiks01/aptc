# Audit Report

## Title
RPC Request Decompression Memory Amplification Attack via Unchecked Buffer Allocation

## Summary
The network layer's RPC request handling contains a memory amplification vulnerability where tiny compressed RPC requests can trigger allocation of up to 62 MiB per request before validation. An attacker can exploit this by sending malicious compressed RPC requests that claim large decompressed sizes in their header, causing excessive memory consumption and potential node degradation.

## Finding Description

The vulnerability exists in the decompression path for RPC requests using compressed protocols (e.g., `ConsensusRpcCompressed`, `MempoolDirectSend`). When an RPC request arrives:

1. The request passes frame size validation (limited to 4 MiB) [1](#0-0) 

2. It's queued for deserialization in a blocking task [2](#0-1) 

3. During deserialization, `protocol_id.from_bytes()` is called [3](#0-2) 

4. For compressed protocols, this triggers decompression [4](#0-3) 

5. **The vulnerability occurs here**: The decompression function reads the claimed decompressed size from the first 4 bytes of the compressed data, validates only that it's under MAX_APPLICATION_MESSAGE_SIZE (~62 MiB), and **immediately allocates that amount of memory** [5](#0-4) 

6. Only after allocation does it attempt actual decompression [6](#0-5) 

**Attack Path:**
- Attacker crafts compressed RPC requests where the first 4 bytes claim a decompressed size of 60 MiB
- The actual compressed payload is small (100 bytes to 4 MiB)
- Each request triggers 60 MiB memory allocation before decompression validation
- With `max_concurrent_inbound_rpcs` = 100 per connection [7](#0-6) 
- And `max_parallel_deserialization_tasks` = num_cpus (typically 32-64) [8](#0-7) 
- Peak memory consumption per application: 32 tasks × 60 MiB = ~2 GB
- Multiple connections and applications multiply the impact

This breaks the **Resource Limits** invariant that "all operations must respect gas, storage, and computational limits."

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: The memory amplification causes excessive allocation and potential memory pressure, leading to performance degradation. In extreme cases, it could trigger OOM conditions requiring node restart.

2. **State Inconsistencies Requiring Intervention**: While not causing permanent corruption, sustained attacks could force operators to restart nodes or implement emergency rate limiting, temporarily affecting network stability.

3. **Amplification Factor**: Up to 640x amplification (100 bytes input → 62 MiB allocation), enabling resource exhaustion with minimal attacker bandwidth.

The vulnerability does not directly cause fund loss or consensus violations, but can degrade node performance and availability, fitting the Medium severity category.

## Likelihood Explanation

**High Likelihood** of exploitation:

1. **No Authentication Required**: Any network peer can send RPC requests without being a validator
2. **Simple Exploit**: Attacker only needs to craft malformed compressed data with specific header bytes
3. **Multiple Attack Vectors**: Affects multiple compressed protocols (ConsensusRpcCompressed, MempoolDirectSend, DKGDirectSendCompressed, etc.) [9](#0-8) 
4. **Parallel Amplification**: Multiple connections and parallel deserialization tasks multiply the impact
5. **Low Cost**: Attacker needs minimal bandwidth to send 4 MiB requests that trigger 62 MiB allocations

The attack requires no special privileges and can be executed by any network adversary.

## Recommendation

Implement early size validation before memory allocation:

**Option 1 - Validate Before Allocation (Recommended):**

Modify `aptos_compression::decompress` to perform a preliminary decompression size check using LZ4's built-in size validation before allocating the full buffer. This prevents allocation based solely on untrusted header data.

**Option 2 - Add Compressed-to-Decompressed Ratio Limit:**

Add a configuration parameter `max_decompression_ratio` (e.g., 10x) and validate:
```
if decompressed_size > compressed_data.len() * max_decompression_ratio {
    return Err(DecompressionError("Decompression ratio too high"))
}
```

This should be added after line 107 in `crates/aptos-compression/src/lib.rs`, before the allocation on line 108.

**Option 3 - Reduce MAX_APPLICATION_MESSAGE_SIZE:**

Lower the maximum decompressed size limit to reduce amplification potential, though this may impact legitimate large messages.

**Additional Mitigation:**
Implement per-peer memory allocation tracking and enforce stricter limits on concurrent deserialization tasks per peer to prevent resource exhaustion from multiple connections.

## Proof of Concept

```rust
// Proof of Concept - Malicious RPC Request Generator
// This demonstrates creating a compressed payload that claims 60 MiB decompressed size
// but contains minimal actual data

use aptos_network::protocols::wire::messaging::v1::{RpcRequest, NetworkMessage};
use aptos_network::ProtocolId;

fn create_amplification_attack_request() -> RpcRequest {
    // Create malicious compressed payload
    // First 4 bytes claim decompressed size of 60 MiB (0x03C00000)
    let claimed_size: i32 = 60 * 1024 * 1024;
    let mut malicious_payload = vec![
        (claimed_size & 0xFF) as u8,
        ((claimed_size >> 8) & 0xFF) as u8,
        ((claimed_size >> 16) & 0xFF) as u8,
        ((claimed_size >> 24) & 0xFF) as u8,
    ];
    
    // Append invalid/minimal LZ4 compressed data
    malicious_payload.extend_from_slice(&[0u8; 96]);
    
    RpcRequest {
        protocol_id: ProtocolId::ConsensusRpcCompressed,
        request_id: 1,
        priority: 0,
        raw_request: malicious_payload,
    }
}

// Attack execution:
// 1. Open multiple connections to target validator
// 2. Send 100 malicious RPC requests per connection
// 3. Each request triggers 60 MiB allocation during deserialization
// 4. With 32 parallel deserialization tasks: 32 × 60 MiB = ~2 GB peak allocation
// 5. Decompression fails but memory was already allocated
// 6. Repeat to exhaust node memory and cause performance degradation
```

**Testing Steps:**
1. Deploy modified network node with instrumented memory tracking
2. Send crafted RPC requests with ConsensusRpcCompressed protocol
3. Monitor memory allocation during deserialization phase
4. Observe 60 MiB allocation per request before decompression validation
5. Verify performance degradation under sustained attack

## Notes

The vulnerability is particularly severe because:

1. **Memory allocation happens speculatively** based on untrusted input before any validation of the actual compressed data integrity.

2. **Multiple protocol variants are affected**: All compressed protocol types (ConsensusRpcCompressed, MempoolDirectSend, DKGDirectSendCompressed, JWKConsensusDirectSendCompressed) share this vulnerability [10](#0-9) 

3. **The amplification is multiplicative** across connections, deserialization tasks, and protocol handlers, making the attack highly effective.

4. **Existing protections are insufficient**: While `max_concurrent_inbound_rpcs` limits queued requests and `max_frame_size` limits input size, neither prevents the memory amplification during deserialization [11](#0-10)

### Citations

**File:** config/src/config/network_config.rs (L49-49)
```rust
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
```

**File:** config/src/config/network_config.rs (L182-184)
```rust
        if self.max_parallel_deserialization_tasks.is_none() {
            self.max_parallel_deserialization_tasks = Some(num_cpus::get());
        }
```

**File:** network/framework/src/protocols/network/mod.rs (L217-219)
```rust
        let data_event_stream = peer_mgr_notifs_rx.map(|notification| {
            tokio::task::spawn_blocking(move || received_message_to_event(notification))
        });
```

**File:** network/framework/src/protocols/network/mod.rs (L307-308)
```rust
    match request.to_message() {
        Ok(msg) => Some(msg),
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L156-172)
```rust
    fn encoding(self) -> Encoding {
        match self {
            ProtocolId::ConsensusDirectSendJson | ProtocolId::ConsensusRpcJson => Encoding::Json,
            ProtocolId::ConsensusDirectSendCompressed | ProtocolId::ConsensusRpcCompressed => {
                Encoding::CompressedBcs(RECURSION_LIMIT)
            },
            ProtocolId::ConsensusObserver => Encoding::CompressedBcs(RECURSION_LIMIT),
            ProtocolId::DKGDirectSendCompressed | ProtocolId::DKGRpcCompressed => {
                Encoding::CompressedBcs(RECURSION_LIMIT)
            },
            ProtocolId::JWKConsensusDirectSendCompressed
            | ProtocolId::JWKConsensusRpcCompressed => Encoding::CompressedBcs(RECURSION_LIMIT),
            ProtocolId::MempoolDirectSend => Encoding::CompressedBcs(USER_INPUT_RECURSION_LIMIT),
            ProtocolId::MempoolRpc => Encoding::Bcs(USER_INPUT_RECURSION_LIMIT),
            _ => Encoding::Bcs(RECURSION_LIMIT),
        }
    }
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L233-241)
```rust
            Encoding::CompressedBcs(limit) => {
                let compression_client = self.get_compression_client();
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
                self.bcs_decode(&raw_bytes, limit)
```

**File:** crates/aptos-compression/src/lib.rs (L101-108)
```rust
    let decompressed_size = match get_decompressed_size(compressed_data, max_size) {
        Ok(size) => size,
        Err(error) => {
            let error_string = format!("Failed to get decompressed size: {}", error);
            return create_decompression_error(&client, error_string);
        },
    };
    let mut raw_data = vec![0u8; decompressed_size];
```

**File:** crates/aptos-compression/src/lib.rs (L111-114)
```rust
    if let Err(error) = lz4::block::decompress_to_buffer(compressed_data, None, &mut raw_data) {
        let error_string = format!("Failed to decompress the data: {}", error);
        return create_decompression_error(&client, error_string);
    };
```

**File:** network/framework/src/constants.rs (L15-15)
```rust
pub const MAX_CONCURRENT_INBOUND_RPCS: u32 = 100;
```

**File:** network/framework/src/protocols/rpc/mod.rs (L213-223)
```rust
        if self.inbound_rpc_tasks.len() as u32 == self.max_concurrent_inbound_rpcs {
            // Increase counter of declined requests
            counters::rpc_messages(
                network_context,
                REQUEST_LABEL,
                INBOUND_LABEL,
                DECLINED_LABEL,
            )
            .inc();
            return Err(RpcError::TooManyPending(self.max_concurrent_inbound_rpcs));
        }
```
