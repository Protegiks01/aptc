# Audit Report

## Title
Indefinite Blocking in Local Testnet Startup Due to Missing Per-Call Timeouts in Health Check Wait Loop

## Summary
The `wait_for_startup()` helper function in the local testnet health checker lacks per-call timeout protection around individual health check operations. If any health check operation hangs indefinitely (such as an HTTP request waiting for a response that never arrives), the entire testnet startup process blocks permanently, rendering the local testnet unavailable.

## Finding Description

The vulnerability exists in the health check waiting logic that lacks timeout protection at the individual operation level. [1](#0-0) 

The `wait_for_startup()` helper function implements a retry loop with an overall timeout of 120 seconds. However, the timeout check `start.elapsed() < max_wait` only executes at the **start** of each loop iteration. If the `check_fn().await` call hangs indefinitely, execution never returns to check the elapsed time, causing the entire function to block permanently.

This is particularly problematic for the HTTP health check implementation: [2](#0-1) 

The HTTP health check uses `reqwest::get()` directly without any explicit timeout configuration. According to reqwest's default behavior (confirmed by the codebase's consistent pattern of using explicit timeouts elsewhere), this call has no request timeout and can hang indefinitely if the server accepts the TCP connection but never sends an HTTP response.

The main `wait_for_startup()` function in `mod.rs` uses `join_all()` to wait for all health check futures: [3](#0-2) 

Since `join_all()` waits for ALL futures to complete, a single hanging health check blocks the entire startup sequence.

**Attack Path:**
1. User runs `aptos node run-local-testnet`
2. One of the services (Node API, Faucet, Indexer API, or Postgres) accepts TCP connections but does not respond to HTTP requests (due to bug, misconfiguration, or malicious behavior)
3. The corresponding health check calls `reqwest::get()` which hangs indefinitely waiting for a response
4. The `wait_for_startup()` helper blocks permanently at `check_fn().await`
5. `join_all()` waits forever for the hanging future
6. Testnet startup never completes
7. User cannot use the local testnet for development

**Contrast with Ready Server:**
The codebase already implements proper timeout protection in the ready server: [4](#0-3) 

The ready server correctly wraps each `health_checker.check()` call with `tokio::time::timeout(Duration::from_secs(3))`, preventing indefinite blocking.

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty program)

This issue causes **complete denial of service** for the local testnet tool, falling under "State inconsistencies requiring intervention" from the Medium severity category. While this affects only the local development testnet (not production validator nodes or the main Aptos network), it completely prevents developers from using the local testnet for testing and development.

The impact is limited to:
- Local development environments only
- No effect on production validators or consensus
- No funds at risk
- Can be worked around by killing and restarting the process

However, it represents a legitimate availability vulnerability where the testnet becomes permanently unavailable without any timeout or recovery mechanism.

## Likelihood Explanation

**Likelihood: Medium**

This vulnerability can occur in several realistic scenarios:

1. **Service Misconfiguration**: A locally running service (Node API, Faucet, Indexer API, Postgres) is misconfigured and accepts connections but doesn't respond properly
2. **Resource Exhaustion**: A service runs out of resources (threads, memory) and hangs while processing requests
3. **Network Issues**: Network-level issues cause TCP connections to establish but HTTP layer to hang
4. **Buggy Service Implementation**: A bug in any of the testnet services causes request handling to deadlock
5. **Intentional Attack**: For shared development environments, a malicious user could run a TCP server that accepts connections but never responds

The vulnerability requires no special privileges to trigger - it occurs naturally whenever any health-checked service misbehaves in a specific way. Given the complexity of running multiple services (node, faucet, postgres, indexer), such failures are reasonably likely during development.

## Recommendation

Add per-call timeout protection around the `check_fn().await` invocation, similar to the pattern already used in the ready server:

```rust
async fn wait_for_startup<F, Fut>(check_fn: F, error_message: String) -> Result<()>
where
    F: Fn() -> Fut,
    Fut: futures::Future<Output = Result<()>>,
{
    let max_wait = Duration::from_secs(MAX_WAIT_S);
    let wait_interval = Duration::from_millis(WAIT_INTERVAL_MS);
    let per_check_timeout = Duration::from_secs(30); // Reasonable per-call timeout

    let start = Instant::now();
    let mut started_successfully = false;

    let mut last_error_message = None;
    while start.elapsed() < max_wait {
        // Add timeout wrapper around the check call
        match tokio::time::timeout(per_check_timeout, check_fn()).await {
            Ok(Ok(_)) => {
                started_successfully = true;
                break;
            },
            Ok(Err(err)) => {
                last_error_message = Some(format!("{:#}", err));
            },
            Err(_) => {
                last_error_message = Some("Health check timed out".to_string());
            },
        }
        tokio::time::sleep(wait_interval).await
    }

    if !started_successfully {
        let error_message = match last_error_message {
            Some(last_error_message) => format!("{}: {}", error_message, last_error_message),
            None => error_message,
        };
        return Err(anyhow!(error_message));
    }

    Ok(())
}
```

This ensures that even if an individual health check operation hangs, it will be terminated after the per-call timeout, allowing the retry loop to continue and eventually fail gracefully if the service doesn't recover within the overall MAX_WAIT_S period.

## Proof of Concept

Create a malicious HTTP server that accepts connections but never responds:

```rust
// Run this in a separate terminal before starting the local testnet
use tokio::net::TcpListener;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let listener = TcpListener::bind("127.0.0.1:8080").await?;
    println!("Malicious server listening on 127.0.0.1:8080");
    println!("This server accepts connections but never sends responses");
    
    loop {
        let (mut socket, addr) = listener.accept().await?;
        println!("Accepted connection from {}", addr);
        
        // Spawn a task that keeps the connection open but never responds
        tokio::spawn(async move {
            // Read the request but never write a response
            let mut buf = vec![0u8; 1024];
            loop {
                match socket.try_read(&mut buf) {
                    Ok(0) => break, // Connection closed
                    Ok(n) => println!("Read {} bytes, but not responding", n),
                    Err(ref e) if e.kind() == std::io::ErrorKind::WouldBlock => {
                        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
                    }
                    Err(e) => {
                        println!("Error reading: {}", e);
                        break;
                    }
                }
            }
        });
    }
}
```

Then configure the local testnet to use a service on port 8080 (or modify the node API port to 8080), and run:

```bash
aptos node run-local-testnet
```

**Expected Result**: The testnet startup will hang indefinitely at "Node API is starting, please wait..." and never complete, requiring manual process termination.

**With Fix Applied**: The health check would timeout after 30 seconds per attempt, retry multiple times over the 120-second window, and eventually fail with a clear error message rather than hanging indefinitely.

---

**Notes:**
- This vulnerability only affects the local testnet CLI tool used for development, not production validator nodes or the main Aptos network
- The issue demonstrates a missing defensive programming pattern (per-call timeouts) that the codebase already implements correctly in the ready server
- The fix is straightforward and follows existing patterns in the codebase

### Citations

**File:** crates/aptos/src/node/local_testnet/health_checker.rs (L47-52)
```rust
            HealthChecker::Http(url, _) => {
                reqwest::get(Url::clone(url))
                    .await
                    .with_context(|| format!("Failed to GET {}", url))?;
                Ok(())
            },
```

**File:** crates/aptos/src/node/local_testnet/health_checker.rs (L190-224)
```rust
async fn wait_for_startup<F, Fut>(check_fn: F, error_message: String) -> Result<()>
where
    F: Fn() -> Fut,
    Fut: futures::Future<Output = Result<()>>,
{
    let max_wait = Duration::from_secs(MAX_WAIT_S);
    let wait_interval = Duration::from_millis(WAIT_INTERVAL_MS);

    let start = Instant::now();
    let mut started_successfully = false;

    let mut last_error_message = None;
    while start.elapsed() < max_wait {
        match check_fn().await {
            Ok(_) => {
                started_successfully = true;
                break;
            },
            Err(err) => {
                last_error_message = Some(format!("{:#}", err));
            },
        }
        tokio::time::sleep(wait_interval).await
    }

    if !started_successfully {
        let error_message = match last_error_message {
            Some(last_error_message) => format!("{}: {}", error_message, last_error_message),
            None => error_message,
        };
        return Err(anyhow!(error_message));
    }

    Ok(())
}
```

**File:** crates/aptos/src/node/local_testnet/mod.rs (L181-191)
```rust
        // We use join_all because we expect all of these to return.
        for f in futures::future::join_all(futures).await {
            f.map_err(|err| {
                CliError::UnexpectedError(format!(
                    "One of the services failed to start up: {:?}. \
                    Please check the logs at {} for more information.",
                    err,
                    test_dir.display(),
                ))
            })?;
        }
```

**File:** crates/aptos/src/node/local_testnet/ready_server.rs (L115-124)
```rust
        // Use timeout since some of these checks can take quite a while if the
        // underlying service is not ready. This is best effort of course, see the docs
        // for tokio::time::timeout for more information.
        match timeout(Duration::from_secs(3), health_checker.check()).await {
            Ok(Ok(())) => ready.push(health_checker.clone()),
            _ => {
                not_ready.push(health_checker.clone());
            },
        }
    }
```
