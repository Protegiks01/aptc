# Audit Report

## Title
Missing Configuration Validation for Request Moderator Parameters Enables Denial of Service

## Summary
The `max_invalid_requests_per_peer` and `min_time_to_ignore_peers_secs` configuration parameters in `StorageServiceConfig` are not validated during configuration loading. Invalid values (0, overflow-prone large values) can be set, completely disabling the request moderator's peer blocking mechanism and enabling denial-of-service attacks from malicious peers sending invalid storage service requests.

## Finding Description

The storage service request moderator implements a security mechanism to protect nodes from malicious peers that send excessive invalid requests. Two critical configuration parameters control this protection: [1](#0-0) [2](#0-1) 

These parameters are used to track and block misbehaving peers: [3](#0-2) [4](#0-3) 

**Critical Vulnerability: No validation exists for these parameters.** 

The `StorageServiceConfig` struct does not implement the `ConfigSanitizer` trait, unlike other critical configurations: [5](#0-4) 

**Attack Scenarios:**

1. **`min_time_to_ignore_peers_secs = 0`**: The condition on line 82 (`ignored_duration >= Duration::from_secs(0)`) is always true, immediately unblocking peers on every refresh cycle (every 1 second). The exponential backoff is broken because `0 * 2 = 0`. Malicious peers can continuously send invalid requests without effective blocking.

2. **`min_time_to_ignore_peers_secs >= 2^63`**: Due to Rust's wrapping arithmetic in release builds, when the value is doubled (line 90), it overflows: `2^63 * 2 = 0` (wrapping). After the first unblock, the mechanism degrades to Scenario 1.

3. **`max_invalid_requests_per_peer = 0`**: The check `invalid_request_count >= 0` (line 57) triggers immediately after the first invalid request, blocking all peers aggressively and causing operational failures.

The refresh mechanism runs every 1 second: [6](#0-5) 

When values are read from configuration, they are used directly without validation: [7](#0-6) 

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria:

- **Resource Exhaustion**: With `min_time_to_ignore_peers_secs = 0`, the node cannot effectively rate-limit malicious peers, leading to continuous processing of invalid requests and resource exhaustion.
  
- **Denial of Service**: Malicious peers can overwhelm the storage service with invalid requests, degrading node performance or causing liveness failures.

- **Operational Failures**: With `max_invalid_requests_per_peer = 0`, legitimate peers are over-blocked, preventing normal state synchronization.

- **Defense-in-Depth Violation**: Configuration validation is a critical security control. Its absence allows security mechanisms to be inadvertently disabled.

The impact is contained to individual misconfigured nodes rather than network-wide consensus violations, justifying Medium rather than Critical severity.

## Likelihood Explanation

**Moderate Likelihood**:

1. Node operators may accidentally set these values to 0 when attempting to disable certain features, unaware of the security implications.

2. Large values near u64::MAX could be set by operators attempting to "effectively disable" blocking, not understanding the overflow behavior.

3. Configuration files can be generated programmatically or copied from examples with placeholder values.

4. Once a node is misconfigured, exploitation is trivial - any network peer can send invalid storage requests.

## Recommendation

Implement configuration validation in `StorageServiceConfig` by adding a `ConfigSanitizer` implementation:

```rust
impl ConfigSanitizer for StorageServiceConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let storage_service_config = &node_config.state_sync.storage_service;

        // Validate max_invalid_requests_per_peer
        if storage_service_config.max_invalid_requests_per_peer == 0 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "max_invalid_requests_per_peer must be greater than 0".to_string(),
            ));
        }

        // Validate min_time_to_ignore_peers_secs
        if storage_service_config.min_time_to_ignore_peers_secs == 0 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "min_time_to_ignore_peers_secs must be greater than 0".to_string(),
            ));
        }

        // Prevent overflow in exponential backoff (u64::MAX / 2^10 allows ~10 doublings)
        const MAX_SAFE_IGNORE_TIME: u64 = u64::MAX / 1024;
        if storage_service_config.min_time_to_ignore_peers_secs > MAX_SAFE_IGNORE_TIME {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "min_time_to_ignore_peers_secs must not exceed {} to prevent overflow",
                    MAX_SAFE_IGNORE_TIME
                ),
            ));
        }

        Ok(())
    }
}
```

Update the `StateSyncConfig::sanitize` to call this validation:

```rust
impl ConfigSanitizer for StateSyncConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        StateSyncDriverConfig::sanitize(node_config, node_type, chain_id)?;
        StorageServiceConfig::sanitize(node_config, node_type, chain_id)?;
        Ok(())
    }
}
```

Additionally, use `saturating_mul` instead of unchecked multiplication to prevent overflow:

```rust
// In UnhealthyPeerState::refresh_peer_state, line 90:
self.min_time_to_ignore_secs = self.min_time_to_ignore_secs.saturating_mul(2);
```

## Proof of Concept

**Test demonstrating the vulnerability:**

```rust
#[test]
fn test_zero_min_time_blocks_ineffective() {
    use aptos_time_service::TimeService;
    use aptos_types::PeerId;
    
    // Create unhealthy peer state with INVALID min_time = 0
    let max_invalid_requests = 5;
    let min_time_to_ignore_peers_secs = 0; // VULNERABLE VALUE
    let time_service = TimeService::mock();
    let mut unhealthy_peer_state = UnhealthyPeerState::new(
        max_invalid_requests,
        min_time_to_ignore_peers_secs,
        time_service.clone(),
    );

    // Send max invalid requests to trigger blocking
    let peer_network_id = PeerNetworkId::new(NetworkId::Public, PeerId::random());
    for _ in 0..max_invalid_requests {
        unhealthy_peer_state.increment_invalid_request_count(&peer_network_id);
    }

    // Peer should be ignored
    assert!(unhealthy_peer_state.is_ignored());

    // Advance time by ANY amount (even 0 seconds)
    let time_service = time_service.into_mock();
    time_service.advance(Duration::from_millis(1)); // Minimal advancement

    // VULNERABILITY: Peer is immediately unblocked because 0 >= 0 is always true
    unhealthy_peer_state.refresh_peer_state(&peer_network_id);
    assert!(!unhealthy_peer_state.is_ignored()); // Peer is no longer ignored!

    // VULNERABILITY: Exponential backoff is broken (0 * 2 = 0)
    assert_eq!(unhealthy_peer_state.min_time_to_ignore_secs, 0);

    // Peer can immediately send more invalid requests and repeat the cycle
    // This renders the blocking mechanism completely ineffective
}

#[test]
fn test_overflow_large_min_time() {
    use aptos_time_service::TimeService;
    use aptos_types::PeerId;
    
    // Create unhealthy peer state with value that will overflow
    let max_invalid_requests = 5;
    let min_time_to_ignore_peers_secs = 1u64 << 63; // 2^63
    let time_service = TimeService::mock();
    let mut unhealthy_peer_state = UnhealthyPeerState::new(
        max_invalid_requests,
        min_time_to_ignore_peers_secs,
        time_service.clone(),
    );

    // Trigger blocking
    let peer_network_id = PeerNetworkId::new(NetworkId::Public, PeerId::random());
    for _ in 0..max_invalid_requests {
        unhealthy_peer_state.increment_invalid_request_count(&peer_network_id);
    }

    // Wait the initial large duration
    let time_service = time_service.into_mock();
    time_service.advance(Duration::from_secs(min_time_to_ignore_peers_secs));

    // Refresh - this doubles the value, causing overflow
    unhealthy_peer_state.refresh_peer_state(&peer_network_id);

    // VULNERABILITY: 2^63 * 2 = 0 (overflow with wrapping)
    assert_eq!(unhealthy_peer_state.min_time_to_ignore_secs, 0);

    // Now the peer can be immediately unblocked on every subsequent refresh
}
```

**Configuration file to reproduce:**

```yaml
state_sync:
  storage_service:
    max_invalid_requests_per_peer: 0  # Invalid - should be rejected
    min_time_to_ignore_peers_secs: 0  # Invalid - should be rejected
```

The node will accept this configuration and start with a completely ineffective request moderation system.

## Notes

- The vulnerability exists because `StorageServiceConfig` does not implement `ConfigSanitizer`, unlike `StateSyncDriverConfig` which validates other parameters.
- While node operators are considered trusted, defense-in-depth principles require validating all security-critical configurations to prevent accidental misconfigurations.
- The overflow issue with large values is particularly subtle and could occur unintentionally when operators set "very large" values thinking they're effectively disabling the timeout.
- Once a node is misconfigured, any network peer (untrusted actor) can exploit it by sending invalid storage service requests, making this exploitable without privileged access.

### Citations

**File:** config/src/config/state_sync_config.rs (L163-164)
```rust
    /// Maximum number of invalid requests per peer
    pub max_invalid_requests_per_peer: u64,
```

**File:** config/src/config/state_sync_config.rs (L187-188)
```rust
    /// Minimum time (secs) to ignore peers after too many invalid requests
    pub min_time_to_ignore_peers_secs: u64,
```

**File:** config/src/config/state_sync_config.rs (L487-496)
```rust
impl ConfigSanitizer for StateSyncConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // Sanitize the state sync driver config
        StateSyncDriverConfig::sanitize(node_config, node_type, chain_id)
    }
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L50-68)
```rust
    pub fn increment_invalid_request_count(&mut self, peer_network_id: &PeerNetworkId) {
        // Increment the invalid request count
        self.invalid_request_count += 1;

        // If the peer is a PFN and has sent too many invalid requests, start ignoring it
        if self.ignore_start_time.is_none()
            && peer_network_id.network_id().is_public_network()
            && self.invalid_request_count >= self.max_invalid_requests
        {
            // TODO: at some point we'll want to terminate the connection entirely

            // Start ignoring the peer
            self.ignore_start_time = Some(self.time_service.now());

            // Log the fact that we're now ignoring the peer
            warn!(LogSchema::new(LogEntry::RequestModeratorIgnoredPeer)
                .peer_network_id(peer_network_id)
                .message("Ignoring peer due to too many invalid requests!"));
        }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L79-98)
```rust
    pub fn refresh_peer_state(&mut self, peer_network_id: &PeerNetworkId) {
        if let Some(ignore_start_time) = self.ignore_start_time {
            let ignored_duration = self.time_service.now().duration_since(ignore_start_time);
            if ignored_duration >= Duration::from_secs(self.min_time_to_ignore_secs) {
                // Reset the invalid request count
                self.invalid_request_count = 0;

                // Reset the ignore start time
                self.ignore_start_time = None;

                // Double the min time to ignore the peer
                self.min_time_to_ignore_secs *= 2;

                // Log the fact that we're no longer ignoring the peer
                warn!(LogSchema::new(LogEntry::RequestModeratorIgnoredPeer)
                    .peer_network_id(peer_network_id)
                    .message("No longer ignoring peer! Enough time has elapsed."));
            }
        }
    }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L164-177)
```rust
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
```

**File:** state-sync/storage-service/server/src/lib.rs (L363-379)
```rust
        self.runtime.spawn(async move {
            // Create a ticker for the refresh interval
            let duration = Duration::from_millis(config.request_moderator_refresh_interval_ms);
            let ticker = time_service.interval(duration);
            futures::pin_mut!(ticker);

            // Periodically refresh the peer states
            loop {
                ticker.next().await;

                // Refresh the unhealthy peer states
                if let Err(error) = request_moderator.refresh_unhealthy_peer_states() {
                    error!(LogSchema::new(LogEntry::RequestModeratorRefresh)
                        .error(&error)
                        .message("Failed to refresh the request moderator!"));
                }
            }
```
