# Audit Report

## Title
Randomness Share Aggregation Failure Due to Missing Error Response in RequestShare Handler

## Summary
The `RequestShare` handler in `rand_manager.rs` fails to send any response when `get_self_share()` returns an error, causing RPC timeouts and potential share aggregation failures. This can block randomness generation and degrade consensus performance during network delays or node restarts. [1](#0-0) 

## Finding Description

When a validator receives a `RequestShare` RPC for randomness generation, it attempts to retrieve its share using `get_self_share()`. The function validates that the requested round is not in the future by checking against `highest_known_round`: [2](#0-1) 

If this check fails (requested round > highest_known_round), `get_self_share()` returns an `Err`, and the handler only logs a warning without sending any response to the requester. This breaks the RPC contract where the requester expects either a successful response or an error response.

The critical flaw is that the handler already has logic to generate shares on-demand when `get_self_share()` returns `Ok(None)`, but this regeneration is bypassed when an error is returned: [3](#0-2) 

The `RequestShare` message contains all necessary metadata to generate a share via `S::generate()`, but the overly strict future-round check prevents this on-demand generation.

**Attack Path:**
1. During network delays, partitions, or node restarts, some validators lag behind by 1-2 rounds
2. A leader validator initiates share aggregation for round R via `spawn_aggregate_shares_task()`
3. The leader sends `RequestShare(R)` via reliable broadcast to all validators
4. Behind validators have `highest_known_round < R`, causing `get_self_share()` to return `Err`
5. No response is sent, causing 10-second RPC timeout per the configuration: [4](#0-3) 

6. Reliable broadcast retries with exponential backoff but continues timing out: [5](#0-4) 

7. If more than f validators (where 3f+1 is total) are behind, the leader cannot aggregate the required threshold (2f+1) of shares: [6](#0-5) 

8. Randomness generation fails, blocking consensus progress until validators catch up

## Impact Explanation

This issue qualifies as **High Severity** under the Aptos bug bounty criteria:

**Validator Node Slowdowns**: Each timeout wastes 10 seconds per validator, with exponential backoff causing repeated delays. In a network with N validators and M rounds behind, this creates NÃ—M timeout cycles, significantly degrading performance.

**Liveness Impact**: If more than f validators are behind simultaneously (realistic during network partitions, rolling restarts, or state sync), the share aggregation threshold cannot be met. This blocks randomness generation, which is required for consensus to progress. While not a permanent liveness failure (validators eventually catch up), this can halt the network for extended periods.

**Resource Waste**: Continuous RPC retries consume network bandwidth and CPU cycles across all participating validators, amplifying during network instability when the system needs maximum efficiency.

## Likelihood Explanation

**High Likelihood** during normal operations:

**Network Delays**: Validators in geographically distributed deployments routinely experience 1-2 round delays due to network latency variations. When share aggregation starts immediately after block processing, validators on slower paths haven't seen the block yet.

**Rolling Restarts**: During validator software upgrades, nodes restart sequentially. Restarting validators haven't processed recent rounds, triggering this timeout behavior systematically.

**State Sync**: New validators joining the network or validators recovering from crashes go through state sync, during which they're behind by hundreds of rounds. Share requests to these validators will timeout repeatedly.

**Network Partitions**: Partial network partitions cause subsets of validators to diverge in their view of the current round, guaranteeing timeout behavior until partition heals.

The issue occurs in production environments, not just adversarial scenarios, making it highly likely to impact real deployments.

## Recommendation

Modify the `RequestShare` handler to generate shares on-demand even when `get_self_share()` returns an error, mirroring the behavior for `Ok(None)`:

**Fixed Implementation:**
```rust
RandMessage::RequestShare(request) => {
    let result = self.rand_store.lock().get_self_share(request.rand_metadata());
    let share = match result {
        Ok(maybe_share) => {
            maybe_share.unwrap_or_else(|| {
                // reproduce previous share if not found
                let share = S::generate(&self.config, request.rand_metadata().clone());
                self.rand_store.lock().add_share(share.clone(), PathType::Slow)
                    .expect("Add self share should succeed");
                share
            })
        },
        Err(e) => {
            // Generate share on-demand even for future rounds
            warn!("[RandManager] Generating share for future round: {}", e);
            let share = S::generate(&self.config, request.rand_metadata().clone());
            // Attempt to add, but don't fail if round is too far in future
            let _ = self.rand_store.lock().add_share(share.clone(), PathType::Slow);
            share
        }
    };
    self.process_response(protocol, response_sender, RandMessage::Share(share));
}
```

This ensures that:
1. Every `RequestShare` RPC receives a response, preventing timeouts
2. Shares can be generated on-demand using metadata from the request
3. The system tolerates validators being behind without performance degradation
4. The future-round safeguard in `add_share()` (FUTURE_ROUNDS_TO_ACCEPT) provides sufficient protection: [7](#0-6) 

## Proof of Concept

**Test Scenario Setup:**
```rust
// consensus/src/rand/rand_gen/rand_manager_test.rs (new test)

#[tokio::test]
async fn test_request_share_for_future_round_responds() {
    // Setup: Create a validator that is behind (highest_known_round = 10)
    // Request share for round 15 (future round)
    // Verify: Response is sent instead of timeout
    
    let (validator, request_rx) = setup_test_validator(epoch=1, highest_round=10);
    
    // Send RequestShare for round 15
    let future_metadata = RandMetadata::new(epoch=1, round=15, ...);
    let request = RequestShare::new(future_metadata);
    
    let (response_tx, response_rx) = oneshot::channel();
    send_rpc_request(validator, request, response_tx);
    
    // Currently: This times out after 10 seconds
    // Expected: Should receive response immediately with generated share
    let result = tokio::time::timeout(
        Duration::from_secs(1), 
        response_rx
    ).await;
    
    assert!(result.is_ok(), "Should receive response, not timeout");
    
    let share = result.unwrap().unwrap();
    assert_eq!(share.metadata().round, 15);
}
```

**Realistic Reproduction:**
1. Deploy testnet with 4 validators (f=1, threshold=3)
2. Introduce 2-second network delay to validators 2 and 3
3. Observe validator 1 processing round R, starting share aggregation
4. Monitor RPC logs showing 10-second timeouts to validators 2 and 3
5. Measure consensus latency increase of 10+ seconds per round
6. Verify share aggregation completes only after delayed validators catch up

## Notes

The vulnerability stems from an overly defensive check that prevents on-demand share generation. The `RequestShare` message contains complete metadata (`RandMetadata`) sufficient for deterministic share generation via `S::generate()`. The existing codebase already demonstrates this pattern for the `Ok(None)` case, confirming the approach is safe and intended.

The future-round protection should occur at the `add_share()` level (which already has `FUTURE_ROUNDS_TO_ACCEPT` tolerance), not at the RPC response level where it creates unnecessary timeouts.

### Citations

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L397-412)
```rust
                        RandMessage::RequestShare(request) => {
                            let result = self.rand_store.lock().get_self_share(request.rand_metadata());
                            match result {
                                Ok(maybe_share) => {
                                    let share = maybe_share.unwrap_or_else(|| {
                                        // reproduce previous share if not found
                                        let share = S::generate(&self.config, request.rand_metadata().clone());
                                        self.rand_store.lock().add_share(share.clone(), PathType::Slow).expect("Add self share should succeed");
                                        share
                                    });
                                    self.process_response(protocol, response_sender, RandMessage::Share(share));
                                },
                                Err(e) => {
                                    warn!("[RandManager] Failed to get share: {}", e);
                                }
                            }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L41-49)
```rust
    pub fn try_aggregate(
        self,
        rand_config: &RandConfig,
        rand_metadata: FullRandMetadata,
        decision_tx: Sender<Randomness>,
    ) -> Either<Self, RandShare<S>> {
        if self.total_weight < rand_config.threshold() {
            return Either::Left(self);
        }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L323-338)
```rust
    pub fn get_self_share(
        &mut self,
        metadata: &RandMetadata,
    ) -> anyhow::Result<Option<RandShare<S>>> {
        ensure!(
            metadata.round <= self.highest_known_round,
            "Request share from future round {}, highest known round {}",
            metadata.round,
            self.highest_known_round
        );
        Ok(self
            .rand_map
            .get(&metadata.round)
            .and_then(|item| item.get_self_share())
            .filter(|share| share.metadata() == metadata))
    }
```

**File:** config/src/config/consensus_config.rs (L373-378)
```rust
            rand_rb_config: ReliableBroadcastConfig {
                backoff_policy_base_ms: 2,
                backoff_policy_factor: 100,
                backoff_policy_max_delay_ms: 10000,
                rpc_timeout_ms: 10000,
            },
```

**File:** crates/reliable-broadcast/src/lib.rs (L191-200)
```rust
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```
