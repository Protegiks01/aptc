# Audit Report

## Title
Transaction Skipping Vulnerability in DBIndexer Due to Asynchronous Commit Failure

## Summary
The `DBIndexer::process_a_batch()` function returns success immediately after sending a batch to an asynchronous committer thread, before verifying the database write completed. If the committer thread panics during the write operation, the caller updates its in-memory version counter while the batch remains unpersisted, causing permanent transaction skipping in the indexer database.

## Finding Description

The vulnerability exists in the asynchronous batch processing architecture of the internal indexer: [1](#0-0) 

The `process_a_batch()` function increments a local `version` variable inside the `try_for_each` closure for each processed transaction. After processing, it sends the batch to a separate committer thread via an unbounded channel: [2](#0-1) 

The function returns `Ok(version)` immediately after the channel send succeeds, **without waiting for database persistence**. The committer thread runs asynchronously: [3](#0-2) 

The critical issue: the committer uses `.expect()` which panics on any database write failure. When this happens:

1. The main thread has already returned success and incremented its `start_version`
2. The batch is never written to the database
3. The committer thread panics silently (no error propagated to caller)
4. The next batch processing starts from the incremented version
5. All transactions in the failed batch are **permanently skipped**

The caller in the service layer maintains an in-memory version counter that gets out of sync with the persisted version: [4](#0-3) 

The `start_version` is updated based on the return value from `process()`, not re-read from the database. This means after a committer panic, the service continues indexing from a version that was never persisted, creating permanent gaps in the transaction history.

**Invariant Broken:** State Consistency - The indexer must maintain sequential, complete transaction history without gaps. This vulnerability violates that guarantee.

## Impact Explanation

**Severity: HIGH**

This qualifies as HIGH severity under the Aptos bug bounty criteria for the following reasons:

1. **Significant Protocol Violation**: Violates the fundamental invariant that the indexer must index all transactions sequentially without gaps. Applications querying the indexer receive incomplete data.

2. **Permanent State Corruption**: Once transactions are skipped, they are permanently missing from the indexer database unless manual recovery is performed. Event queries, account transaction history, and state key lookups will return incorrect results.

3. **Data Integrity Impact**: 
   - Event-based applications miss critical events
   - Account transaction history becomes incomplete
   - State synchronization may fail or produce incorrect results
   - Downstream systems relying on complete transaction logs are compromised

4. **Not Critical Because**: While serious, this affects only the auxiliary indexer database, not the consensus or main execution database. The blockchain itself continues operating correctly, and funds are not at risk.

The impact falls under "State inconsistencies requiring intervention" (Medium) and "Significant protocol violations" (High), qualifying it as **HIGH severity**.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

The vulnerability is highly likely to occur in production environments:

1. **Realistic Trigger Conditions**:
   - Disk space exhaustion (common in long-running validators)
   - I/O errors from failing storage hardware
   - RocksDB internal errors or corruption
   - File permission issues
   - Resource limits (file descriptors, memory)

2. **No Protective Mechanisms**:
   - No health monitoring of committer thread
   - No retry logic for failed writes
   - Unbounded channel masks receiver death
   - `.expect()` causes immediate panic rather than graceful error handling

3. **Silent Failure Mode**: The vulnerability occurs silently without alerting operators until queries reveal missing data.

4. **Production Frequency**: Database write failures occur regularly in real-world deployments, making this a practical concern rather than theoretical.

## Recommendation

Implement synchronous write verification with proper error handling:

**Solution 1: Synchronous Write Confirmation**
Replace the async committer with synchronous writes in `process_a_batch()`, or implement a synchronous confirmation mechanism where the function waits for write completion before returning success.

**Solution 2: Error Propagation from Committer**
Replace `.expect()` with proper error handling that propagates failures back to the main thread via a result channel or shared state. The main thread should check for committer health before returning success.

**Solution 3: Version Reconciliation**
Before each batch, verify that the in-memory `start_version` matches `get_persisted_version() + 1`. If they diverge, return an error forcing recovery from persisted state.

**Recommended Fix:**
```rust
// In process_a_batch, after sending batch:
self.sender
    .send(Some(batch))
    .map_err(|e| AptosDbError::Other(e.to_string()))?;

// Add synchronous confirmation:
// Wait for committer to signal write completion
// or verify persisted version matches expected version
let expected_version = version - 1;
loop {
    match self.indexer_db.get_persisted_version()? {
        Some(v) if v >= expected_version => break,
        _ => std::thread::sleep(Duration::from_millis(10)),
    }
}

Ok(version)
```

**Additional Safeguards:**
- Replace `.expect()` in committer with graceful error handling
- Add health monitoring for committer thread
- Implement bounded channel with backpressure
- Add metrics/alerts for write failures
- Periodic version reconciliation checks

## Proof of Concept

**Reproduction Steps:**

1. **Setup**: Run a validator node with internal indexer enabled
2. **Trigger**: Fill the disk partition where the indexer database resides
3. **Observe**: 
   - Process continues indexing subsequent transactions
   - Database shows version gaps
   - Queries for skipped transactions return "not found"

**Rust Test Simulation:**
```rust
#[test]
fn test_committer_failure_causes_skipping() {
    // Setup indexer with limited disk space mock
    let (mut service, mock_db) = setup_test_indexer();
    
    // Configure mock DB to fail on specific write
    mock_db.set_fail_on_version(105);
    
    // Process transactions 100-109
    let result = service.db_indexer.process(100, 110);
    
    // Main thread thinks it succeeded
    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 110);
    
    // But database only has transactions up to 104
    let persisted = service.db_indexer.indexer_db.get_persisted_version().unwrap();
    assert_eq!(persisted, Some(104));
    
    // Next batch processes from 110, skipping 105-109
    let next_result = service.db_indexer.process(110, 120);
    assert!(next_result.is_ok());
    
    // Transactions 105-109 are permanently missing
    for v in 105..110 {
        assert!(service.get_transaction(v).is_err());
    }
}
```

**Verification:**
Check indexer database for version gaps by comparing consecutive persisted versions in metadata schema against actual indexed transaction ranges.

## Notes

This vulnerability specifically affects the **internal indexer database** used for efficient event and transaction queries, not the main AptosDB consensus database. While this limits the severity (preventing it from being Critical), it still represents a serious data integrity issue for applications relying on complete transaction history. The fix requires careful synchronization between the batch processing and commit threads to ensure atomicity of the version counter updates with database persistence.

### Citations

**File:** storage/indexer/src/db_indexer.rs (L62-76)
```rust
    pub fn run(&self) {
        loop {
            let batch_opt = self
                .receiver
                .recv()
                .expect("Failed to receive batch from DB Indexer");
            if let Some(batch) = batch_opt {
                self.db
                    .write_schemas(batch)
                    .expect("Failed to write batch to indexer db");
            } else {
                break;
            }
        }
    }
```

**File:** storage/indexer/src/db_indexer.rs (L418-500)
```rust
        db_iter.try_for_each(|res| {
            let (txn, events, writeset) = res?;
            if let Some(signed_txn) = txn.try_as_signed_user_txn() {
                if self.indexer_db.transaction_enabled() {
                    if let ReplayProtector::SequenceNumber(seq_num) = signed_txn.replay_protector()
                    {
                        batch.put::<OrderedTransactionByAccountSchema>(
                            &(signed_txn.sender(), seq_num),
                            &version,
                        )?;
                    }
                }
            }

            if self.indexer_db.event_enabled() {
                events.iter().enumerate().try_for_each(|(idx, event)| {
                    if let ContractEvent::V1(v1) = event {
                        batch
                            .put::<EventByKeySchema>(
                                &(*v1.key(), v1.sequence_number()),
                                &(version, idx as u64),
                            )
                            .expect("Failed to put events by key to a batch");
                        batch
                            .put::<EventByVersionSchema>(
                                &(*v1.key(), version, v1.sequence_number()),
                                &(idx as u64),
                            )
                            .expect("Failed to put events by version to a batch");
                    }
                    if self.indexer_db.event_v2_translation_enabled() {
                        if let ContractEvent::V2(v2) = event {
                            if let Some(translated_v1_event) =
                                self.translate_event_v2_to_v1(v2).map_err(|e| {
                                    anyhow::anyhow!(
                                        "Failed to translate event: {:?}. Error: {}",
                                        v2,
                                        e
                                    )
                                })?
                            {
                                let key = *translated_v1_event.key();
                                let sequence_number = translated_v1_event.sequence_number();
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
                                event_keys.insert(key);
                                batch
                                    .put::<EventByKeySchema>(
                                        &(key, sequence_number),
                                        &(version, idx as u64),
                                    )
                                    .expect("Failed to put events by key to a batch");
                                batch
                                    .put::<EventByVersionSchema>(
                                        &(key, version, sequence_number),
                                        &(idx as u64),
                                    )
                                    .expect("Failed to put events by version to a batch");
                                batch
                                    .put::<TranslatedV1EventSchema>(
                                        &(version, idx as u64),
                                        &translated_v1_event,
                                    )
                                    .expect("Failed to put translated v1 events to a batch");
                            }
                        }
                    }
                    Ok::<(), AptosDbError>(())
                })?;
            }

            if self.indexer_db.statekeys_enabled() {
                writeset.write_op_iter().for_each(|(state_key, write_op)| {
                    if write_op.is_creation() || write_op.is_modification() {
                        batch
                            .put::<StateKeysSchema>(state_key, &())
                            .expect("Failed to put state keys to a batch");
                    }
                });
            }
            version += 1;
            Ok::<(), AptosDbError>(())
        })?;
```

**File:** storage/indexer/src/db_indexer.rs (L546-549)
```rust
        self.sender
            .send(Some(batch))
            .map_err(|e| AptosDbError::Other(e.to_string()))?;
        Ok(version)
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L183-197)
```rust
            let next_version = self.db_indexer.process(start_version, target_version)?;
            INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::InternalIndexerDBProcessed,
                Some(start_version as i64),
                Some(next_version as i64),
                None,
                None,
                Some(step_timer.elapsed().as_secs_f64()),
                None,
                Some((next_version - start_version) as i64),
                None,
            );
            start_version = next_version;
```
