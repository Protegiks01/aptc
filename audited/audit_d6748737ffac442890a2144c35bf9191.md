# Audit Report

## Title
Hot State LRU Memory Limit Bypass via Delayed Eviction After Checkpoint Boundaries

## Summary
The hot state LRU cache can exceed the configured `max_items_per_shard` memory limit when state updates are processed after checkpoint boundaries. The eviction mechanism only triggers at checkpoints, allowing unbounded growth of the LRU between the last checkpoint and the end of a processing batch.

## Finding Description
The vulnerability exists in the state update processing logic where LRU eviction is only performed at checkpoint boundaries, violating the **Resource Limits** invariant that requires all operations to respect configured memory constraints. [1](#0-0) 

The `State::update()` method processes state updates in two phases:
1. **Checkpoint-bounded phase** (lines 208-230): Iterates through checkpoint versions, applying updates and calling `lru.maybe_evict()` after each checkpoint
2. **Post-checkpoint phase** (lines 231-243): Processes remaining updates after the last checkpoint with NO subsequent eviction

The critical issue occurs when `update_with_memorized_reads()` processes updates for the latest version (non-checkpoint transactions): [2](#0-1) 

At line 467, an empty checkpoint list `&[]` is passed, causing all updates to be processed in the second loop without any eviction. Each unique state key inserted increases `num_items`: [3](#0-2) 

Checkpoints only occur at block boundaries (BlockMetadataTransaction) or epoch changes: [4](#0-3) 

Chunks can contain thousands of transactions without checkpoints (confirmed by test cases), and blocks can contain up to 5,000 transactions: [5](#0-4) 

**Attack Scenario:**
1. Attacker submits transactions touching many unique state keys (not previously in hot state)
2. These transactions are executed in a chunk after the last checkpoint
3. Each new unique key insertion increases the LRU size via `HotStateLRU::insert()`
4. Since no eviction occurs after processing non-checkpoint updates, the LRU grows beyond `max_items_per_shard` (default 250,000) [6](#0-5) 

## Impact Explanation
This is a **Medium Severity** issue per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Memory usage exceeds configured limits
- **Validator node slowdowns**: Excessive memory consumption degrades performance
- Affects all validators deterministically (same transactions processed by all nodes)
- Can cause out-of-memory conditions on validators with limited resources
- Temporary impact (eviction occurs at next checkpoint), but sustained attacks can maintain elevated memory usage

The configured limit exists to prevent memory exhaustion. Bypassing it violates the system's resource management guarantees.

## Likelihood Explanation
**High Likelihood:**
- Any transaction sender can trigger this by touching many unique state keys
- No special privileges or validator collusion required
- Regular transaction flow automatically creates this condition when blocks contain transactions between checkpoints
- With blocks containing up to 5,000 transactions and each potentially touching 10+ unique keys, the excess can be significant (50,000+ keys per block, ~3,125 per shard on average)
- Chunks in state sync scenarios can span multiple blocks without checkpoints, amplifying the issue

## Recommendation
Add eviction after processing all updates, not just at checkpoints:

```rust
// In State::update() method, after line 243, add:
// Perform final eviction to enforce capacity limits
evictions.extend(lru.maybe_evict().into_iter().map(|(key, slot)| {
    insertions.remove(&key);
    assert!(slot.is_hot());
    key
}));
```

Alternative fix: Modify `update_with_memorized_reads()` to always pass current version as a checkpoint when processing latest updates, ensuring eviction occurs:

```rust
// At line 467, instead of passing &[], pass the latest version:
let latest_ckpt = [batched.last_version().expect("Must have updates")];
let (new_latest, hot_state_updates) = base_of_latest.update(
    persisted_hot_view,
    persisted_snapshot,
    batched,
    per_version,
    &latest_ckpt,  // Changed from &[]
    reads,
);
```

## Proof of Concept

```rust
#[cfg(test)]
mod poc_lru_overflow {
    use super::*;
    use aptos_types::{
        state_store::{state_key::StateKey, state_value::StateValue},
        write_set::{WriteOp, WriteSet, WriteSetMut},
    };

    #[test]
    fn test_lru_exceeds_capacity_without_checkpoint() {
        // Create a small capacity for testing
        let config = HotStateConfig {
            max_items_per_shard: 100,  // Small limit for demonstration
            ..Default::default()
        };
        
        let state = State::new_empty(config);
        
        // Create 200 unique state keys (2x the per-shard limit)
        // These will be distributed across 16 shards (~12-13 per shard on average)
        let mut write_sets = vec![];
        for i in 0..200 {
            let key = StateKey::raw(format!("key_{}", i).as_bytes());
            let value = StateValue::new_legacy(vec![i as u8].into());
            let write_op = WriteOp::modification(value.bytes().clone(), value.metadata().clone());
            let ws = WriteSetMut::from_iter(vec![(key, write_op)]).freeze().unwrap();
            write_sets.push(ws);
        }
        
        // Create StateUpdateRefs WITHOUT any checkpoints
        let updates = StateUpdateRefs::index_write_sets(
            0,
            write_sets.iter(),
            write_sets.len(),
            vec![],  // Empty checkpoint list - this is the key!
        );
        
        // Process updates
        let cache = ShardedStateCache::new_empty(/* ... */);
        let persisted = State::new_empty(config);
        let (new_state, _) = state.update_with_memorized_reads(
            Arc::new(/* persisted hot view */),
            &persisted,
            &updates,
            &cache,
        );
        
        // Verify that at least one shard exceeds the 100 item limit
        let mut exceeded = false;
        for shard_id in 0..NUM_STATE_SHARDS {
            if new_state.num_hot_items(shard_id) > 100 {
                exceeded = true;
                println!("Shard {} has {} items, exceeds limit of 100", 
                         shard_id, new_state.num_hot_items(shard_id));
            }
        }
        
        assert!(exceeded, "Expected at least one shard to exceed capacity limit");
    }
}
```

## Notes
This vulnerability demonstrates a gap between the intended resource limit (`max_items_per_shard`) and its actual enforcement. While eviction eventually occurs at the next checkpoint, the temporary violation can cause memory spikes that affect validator stability, especially under sustained load or during state synchronization scenarios where chunks may span many transactions without checkpoints.

### Citations

**File:** storage/storage-interface/src/state_store/state.rs (L208-243)
```rust
                    for ckpt_version in all_checkpoint_versions {
                        for (key, update) in
                            all_updates.take_while_ref(|(_k, u)| u.version <= *ckpt_version)
                        {
                            evictions.remove(*key);
                            if let Some(hot_state_value) = Self::apply_one_update(
                                &mut lru,
                                overlay,
                                cache,
                                key,
                                update,
                                self.hot_state_config.refresh_interval_versions,
                            ) {
                                insertions.insert((*key).clone(), hot_state_value);
                            }
                        }
                        // Only evict at the checkpoints.
                        evictions.extend(lru.maybe_evict().into_iter().map(|(key, slot)| {
                            insertions.remove(&key);
                            assert!(slot.is_hot());
                            key
                        }));
                    }
                    for (key, update) in all_updates {
                        evictions.remove(*key);
                        if let Some(hot_state_value) = Self::apply_one_update(
                            &mut lru,
                            overlay,
                            cache,
                            key,
                            update,
                            self.hot_state_config.refresh_interval_versions,
                        ) {
                            insertions.insert((*key).clone(), hot_state_value);
                        }
                    }
```

**File:** storage/storage-interface/src/state_store/state.rs (L462-469)
```rust
            let (new_latest, hot_state_updates) = base_of_latest.update(
                persisted_hot_view,
                persisted_snapshot,
                batched,
                per_version,
                &[],
                reads,
            );
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L49-58)
```rust
    pub fn insert(&mut self, key: StateKey, slot: StateSlot) {
        assert!(
            slot.is_hot(),
            "Should not insert cold slots into hot state."
        );
        if self.delete(&key).is_none() {
            self.num_items += 1;
        }
        self.insert_as_head(key, slot);
    }
```

**File:** execution/executor-types/src/transactions_with_output.rs (L195-203)
```rust
        (
            transactions_with_output
                .iter()
                .positions(|(txn, output, _)| {
                    txn.is_non_reconfig_block_ending() || output.has_new_epoch_event()
                })
                .collect(),
            is_reconfig,
        )
```

**File:** config/src/config/consensus_config.rs (L20-24)
```rust
const MAX_SENDING_BLOCK_TXNS_AFTER_FILTERING: u64 = 1800;
const MAX_SENDING_OPT_BLOCK_TXNS_AFTER_FILTERING: u64 = 1000;
const MAX_SENDING_BLOCK_TXNS: u64 = 5000;
pub(crate) static MAX_RECEIVING_BLOCK_TXNS: Lazy<u64> =
    Lazy::new(|| 10000.max(2 * MAX_SENDING_BLOCK_TXNS));
```

**File:** config/src/config/storage_config.rs (L256-264)
```rust
impl Default for HotStateConfig {
    fn default() -> Self {
        Self {
            max_items_per_shard: 250_000,
            refresh_interval_versions: 100_000,
            delete_on_restart: true,
            compute_root_hash: true,
        }
    }
```
