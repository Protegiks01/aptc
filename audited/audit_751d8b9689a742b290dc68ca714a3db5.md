# Audit Report

## Title
Missing Request Timeout Enables Compression-Based CPU Exhaustion DoS on Indexer gRPC Data Service

## Summary
The indexer-grpc-data-service-v2 accepts compressed gRPC requests (Zstd and Gzip) without implementing request-level timeouts, allowing attackers to exhaust CPU resources by sending compute-intensive compressed payloads that decompress within the 256MB size limit but require excessive CPU time to process.

## Finding Description

The `run()` function in the indexer-grpc-data-service-v2 configures the gRPC server to accept compressed requests using both Zstd and Gzip encodings, with a maximum decompressed message size of 256MB. [1](#0-0) 

The server configuration only sets HTTP2 keepalive timeouts but lacks request-level timeouts: [2](#0-1) 

In contrast, other gRPC services in the codebase properly configure request timeouts using `Server::builder().timeout()`: [3](#0-2) 

The MAX_MESSAGE_SIZE constant is set to 256MB, which controls the decompressed message size: [4](#0-3) 

**Attack Vector:**
1. Attacker crafts payloads with high compression ratios (e.g., highly repetitive data compressed to ~1MB that expands to ~250MB)
2. These payloads are designed to maximize CPU time during decompression (e.g., using maximum Zstd compression level or pathological patterns)
3. The `max_decoding_message_size` limit only validates the **decompressed** size, not compression ratio or CPU consumption
4. Without request timeouts, the server must complete decompression regardless of CPU time
5. Multiple concurrent requests from the attacker exhaust CPU resources, causing service degradation or complete unavailability

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty criteria for the following reasons:

1. **API Service Disruption**: The attack causes degradation or complete unavailability of the indexer gRPC data service, which is used by downstream applications and users to query blockchain data. This aligns with "State inconsistencies requiring intervention" requiring operator action to restore service.

2. **Non-Consensus Component**: Unlike consensus-critical vulnerabilities, this affects an auxiliary indexing service that doesn't directly impact blockchain state transitions, validator operations, or fund security. The core blockchain continues to operate normally.

3. **Resource Exhaustion**: The attack exploits missing CPU limits rather than logic bugs in consensus, execution, or state management. While serious for service availability, it doesn't compromise blockchain integrity.

4. **Operator Intervention Required**: Service restoration requires restarting affected nodes or implementing rate limiting at the infrastructure level.

The vulnerability does not qualify as High Severity ("API crashes") because complete API crashes require more severe conditions than CPU exhaustion from a single attack vector, and the indexer service can be architecturally separated from critical validator infrastructure.

## Likelihood Explanation

**Likelihood: High**

1. **No Special Privileges Required**: Any client can send gRPC requests to the public indexer endpoint without authentication.

2. **Low Attack Complexity**: 
   - Standard compression tools can create highly compressed payloads
   - The attack requires only basic gRPC client knowledge
   - No cryptographic operations or complex protocol manipulation needed

3. **Easy to Execute at Scale**: 
   - Attacker can send concurrent requests from multiple connections
   - Small compressed payloads mean low bandwidth requirements for the attacker
   - The 256MB decompression limit per request is generous, allowing significant CPU consumption per request

4. **Detection Challenges**: 
   - Compressed requests appear legitimate at the network level
   - Without CPU time monitoring, the attack resembles heavy legitimate usage
   - HAProxy rate limits may not prevent slow-burn CPU exhaustion attacks

## Recommendation

Implement request-level timeouts on the gRPC server to bound CPU consumption during decompression and request processing. Add the `.timeout()` method to the server builder configuration:

**File**: `ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs`

Add a timeout constant alongside existing HTTP2 timeouts:
```rust
const GRPC_REQUEST_TIMEOUT_DURATION: std::time::Duration = std::time::Duration::from_secs(30);
```

Modify the server builder configuration:
```rust
let mut server_builder = Server::builder()
    .timeout(GRPC_REQUEST_TIMEOUT_DURATION)  // Add this line
    .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
    .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION));
```

**Additional Recommendations:**

1. **Compression Ratio Limits**: Consider implementing compression ratio checks (e.g., reject requests where decompressed size / compressed size > 100x)

2. **Concurrency Limits**: Use Tower middleware to limit concurrent requests per client IP:
   ```rust
   use tower::ServiceBuilder;
   use tower::limit::ConcurrencyLimitLayer;
   
   ServiceBuilder::new()
       .layer(ConcurrencyLimitLayer::new(10))
       .service(wrapper_service)
   ```

3. **Resource Monitoring**: Add metrics for decompression time and CPU usage per request to detect anomalous patterns

4. **Progressive Backoff**: Implement automatic client throttling when CPU thresholds are exceeded

## Proof of Concept

```rust
// PoC: Compression-based DoS attack on indexer-grpc-data-service-v2
// 
// This PoC demonstrates sending highly compressed payloads to exhaust CPU resources
// Run against a local indexer-grpc-data-service-v2 instance

use aptos_protos::indexer::v1::{
    data_service_client::DataServiceClient, GetTransactionsRequest,
};
use tonic::codec::CompressionEncoding;
use std::time::Instant;
use tokio;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Connect to the indexer data service
    let mut client = DataServiceClient::connect("http://localhost:50051")
        .await?
        .send_compressed(CompressionEncoding::Zstd)
        .accept_compressed(CompressionEncoding::Zstd)
        .max_encoding_message_size(256 * (1 << 20));

    // Create a highly compressible payload (repetitive data)
    // This will compress to ~1MB but decompress to ~250MB
    let repetitive_data = vec![0u8; 250_000_000];
    
    // Simulate multiple concurrent requests
    let num_concurrent = 10;
    let mut handles = vec![];
    
    for i in 0..num_concurrent {
        let mut client_clone = client.clone();
        
        handles.push(tokio::spawn(async move {
            let start = Instant::now();
            
            // Send request with highly compressed payload
            let request = GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: Some(1000),
                // Attach large repetitive data as filter (if supported)
                batch_size: Some(100),
            };
            
            match client_clone.get_transactions(request).await {
                Ok(response) => {
                    println!("Request {} completed in {:?}", i, start.elapsed());
                },
                Err(e) => {
                    println!("Request {} failed: {} after {:?}", i, e, start.elapsed());
                }
            }
        }));
    }
    
    // Wait for all requests
    for handle in handles {
        let _ = handle.await;
    }
    
    println!("\nAttack complete. Monitor server CPU usage during execution.");
    println!("Expected behavior: High CPU usage with no timeout enforcement.");
    println!("With fix: Requests should timeout after 30 seconds.");
    
    Ok(())
}
```

**Expected Results:**
- **Without Fix**: Server CPU usage spikes to 100%, requests take minutes to complete, service becomes unresponsive
- **With Fix**: Requests timeout after 30 seconds, CPU usage remains bounded, service remains available for legitimate requests

**Test Environment Setup:**
1. Deploy indexer-grpc-data-service-v2 locally following README instructions
2. Compile and run the PoC client
3. Monitor server CPU usage using `top` or `htop`
4. Observe service degradation without timeout protection

## Notes

While the indexer-grpc services are auxiliary infrastructure rather than consensus-critical components, they are part of the official Aptos Core codebase and provide essential API functionality for ecosystem applications. The absence of request-level timeouts represents a concrete security gap compared to other gRPC services in the codebase that properly implement timeout protection.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L236-248)
```rust
            aptos_protos::indexer::v1::raw_data_server::RawDataServer::from_arc(wrapper.clone())
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
        let wrapper_service =
            aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L251-253)
```rust
        let mut server_builder = Server::builder()
            .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
            .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION));
```

**File:** secure/net/src/grpc_network_service/mod.rs (L75-78)
```rust
        Server::builder()
            .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
            .add_service(
                NetworkMessageServiceServer::new(self).max_decoding_message_size(MAX_MESSAGE_SIZE),
```
