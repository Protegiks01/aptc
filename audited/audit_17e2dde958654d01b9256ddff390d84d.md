# Audit Report

## Title
Unbounded Memory Allocation in Epoch Ending Backup Restore Leading to Out-of-Memory Denial of Service

## Summary
The `read_chunk()` function in the epoch ending backup restore process lacks size limits, allowing malicious or corrupted backup chunks to cause out-of-memory (OOM) conditions by loading millions of `LedgerInfoWithSignatures` objects into memory without bounds checking.

## Finding Description

The vulnerability exists in the backup restore subsystem where epoch ending ledger information is loaded from backup files. [1](#0-0) 

The `read_chunk()` function reads all records from a backup chunk file into a `Vec` with no upper bound on the number of items. It iteratively reads each serialized `LedgerInfoWithSignatures` record and deserializes it into memory until EOF is reached.

The manifest verification only validates epoch range consistency but does not enforce practical limits on the total size of epoch ranges. [2](#0-1) 

During the restore preheat phase, chunks are validated to ensure the number of items matches the declared epoch range, but this happens AFTER the entire chunk has been loaded into memory. [3](#0-2) 

**Attack Scenario:**
1. Attacker creates a malicious backup with a manifest declaring a huge epoch range (e.g., epochs 0 to 10,000,000)
2. Corresponding chunk file contains 10 million serialized `LedgerInfoWithSignatures` objects
3. When a node operator initiates restore from this backup, `read_chunk()` loads all 10 million items into memory
4. Each `LedgerInfoWithSignatures` consists of a `LedgerInfo` (BlockInfo + HashValue, ~200-300 bytes) and an `AggregateSignature` (BLS signature + bitmask, ~100 bytes), totaling ~400-500 bytes per item [4](#0-3) 
5. Total memory consumption: 10,000,000 Ã— 500 bytes = ~5 GB
6. This causes OOM on systems with limited memory, crashing the restore process

While backups are created with chunk size limits during the backup process (default 128MB), these limits are not enforced during restore. [5](#0-4) 

**Invariant Violation:**
This breaks Critical Invariant #9: "Resource Limits: All operations must respect gas, storage, and computational limits." The restore operation should enforce memory limits even when processing potentially trusted input, as corruption, compromise, or errors can result in malformed backup files.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program for the following reasons:

1. **Validator Node Slowdowns/Crashes**: An OOM condition during restore will crash the node process or cause severe performance degradation, directly impacting validator availability.

2. **Operational Disruption**: Nodes attempting to restore from backups (during recovery, bootstrapping new nodes, or disaster recovery) will fail, potentially delaying network operations or preventing nodes from joining the network.

3. **Availability Impact**: While not a direct consensus attack, the inability to restore nodes from backups affects network resilience and validator set expansion.

The impact severity aligns with "Validator node slowdowns" and "API crashes" categorized as High Severity (up to $50,000) in the bug bounty program.

## Likelihood Explanation

**Likelihood: Medium-Low**

The exploitation requires:

1. **Attacker Capability**: Creating a malicious backup file with inflated epoch ranges and corresponding chunk data
2. **Delivery Mechanism**: Getting a node operator to restore from the malicious backup through:
   - Compromising backup storage infrastructure (cloud buckets, local storage)
   - Man-in-the-middle attacks during backup downloads
   - Supply chain attacks on backup distribution
   - Backup file corruption (unintentional trigger)

While backup systems are typically controlled by trusted operators, several realistic scenarios enable exploitation:
- Compromised cloud storage credentials
- Shared backup infrastructure among multiple operators
- Automated backup fetching from potentially untrusted sources
- Backup mirroring from public or semi-public repositories

The vulnerability is particularly concerning because:
- No runtime validation catches the issue before memory exhaustion
- The failure mode (OOM crash) is severe rather than graceful degradation
- Recovery requires manual intervention after identifying the malicious backup

## Recommendation

Implement multiple layers of defense:

### 1. Maximum Items Per Chunk Limit
Add a configurable maximum number of items per chunk in `read_chunk()`:

```rust
const MAX_ITEMS_PER_CHUNK: usize = 500_000; // ~250MB at 500 bytes/item

async fn read_chunk(
    &self,
    file_handle: &FileHandleRef,
) -> Result<Vec<LedgerInfoWithSignatures>> {
    let mut file = self.storage.open_for_read(file_handle).await?;
    let mut chunk = Vec::new();
    
    while let Some(record_bytes) = file.read_record_bytes().await? {
        ensure!(
            chunk.len() < MAX_ITEMS_PER_CHUNK,
            "Chunk exceeds maximum size limit. Items read: {}, limit: {}",
            chunk.len(),
            MAX_ITEMS_PER_CHUNK
        );
        chunk.push(bcs::from_bytes(&record_bytes)?);
    }
    
    Ok(chunk)
}
```

### 2. Manifest Epoch Range Validation
Add validation for reasonable epoch ranges in manifest verification:

```rust
const MAX_EPOCHS_PER_BACKUP: u64 = 1_000_000;

pub fn verify(&self) -> Result<()> {
    let epoch_range = self.last_epoch - self.first_epoch + 1;
    ensure!(
        epoch_range <= MAX_EPOCHS_PER_BACKUP,
        "Epoch range too large: {}, maximum allowed: {}",
        epoch_range,
        MAX_EPOCHS_PER_BACKUP
    );
    // ... existing validation ...
}
```

### 3. Memory-Bounded Processing
Consider streaming/incremental processing instead of loading entire chunks into memory:

```rust
async fn read_chunk_streaming(
    &self,
    file_handle: &FileHandleRef,
) -> Result<impl Stream<Item = Result<LedgerInfoWithSignatures>>> {
    // Return a stream that deserializes items on-demand
}
```

### 4. Early Validation
Check chunk item count matches manifest expectations before loading:

```rust
// In preheat_impl, before reading chunk:
let expected_count = (chunk.last_epoch - chunk.first_epoch + 1) as usize;
ensure!(
    expected_count <= MAX_ITEMS_PER_CHUNK,
    "Manifest claims {} items in chunk, exceeds limit of {}",
    expected_count,
    MAX_ITEMS_PER_CHUNK
);
```

## Proof of Concept

```rust
#[cfg(test)]
mod oom_tests {
    use super::*;
    use aptos_types::ledger_info::{LedgerInfo, LedgerInfoWithSignatures};
    use aptos_types::aggregate_signature::AggregateSignature;
    use aptos_types::block_info::BlockInfo;
    use std::io::Write;
    use tempfile::NamedTempFile;
    
    #[tokio::test]
    async fn test_malicious_chunk_causes_oom() {
        // Create a temporary file with millions of records
        let mut chunk_file = NamedTempFile::new().unwrap();
        
        // Create a sample LedgerInfoWithSignatures
        let ledger_info = LedgerInfo::new(
            BlockInfo::empty(),
            HashValue::zero(),
        );
        let lis = LedgerInfoWithSignatures::new(
            ledger_info,
            AggregateSignature::empty(),
        );
        let record_bytes = bcs::to_bytes(&lis).unwrap();
        
        // Write 2 million records (~1GB if 500 bytes each)
        // This would cause OOM on systems with <2GB available memory
        for _ in 0..2_000_000 {
            let size = (record_bytes.len() as u32).to_be_bytes();
            chunk_file.write_all(&size).unwrap();
            chunk_file.write_all(&record_bytes).unwrap();
        }
        chunk_file.flush().unwrap();
        
        // Attempt to read the chunk - this will consume ~1GB of memory
        // and potentially OOM on constrained systems
        let storage = Arc::new(LocalFs::new(/* ... */));
        let file_handle = /* reference to chunk_file */;
        
        // This call will load all 2M items into memory at once
        let result = read_chunk(&storage, &file_handle).await;
        
        // On systems with sufficient memory, this succeeds but uses excessive RAM
        // On constrained systems (validators with limited memory), this causes OOM crash
        assert!(result.is_ok());
        let chunk = result.unwrap();
        assert_eq!(chunk.len(), 2_000_000);
        
        // Memory usage at this point: ~1GB+ allocated for the Vec
    }
}
```

## Notes

While backup files are typically considered trusted input in operational contexts, defense-in-depth principles require robust validation of all external input, including backup data. Systems should gracefully handle corrupted, compromised, or malformed backups rather than crash with OOM errors. The proposed mitigations align with the "Resource Limits" critical invariant and improve overall system resilience during recovery operations.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L98-105)
```rust
            ensure!(
                chunk.first_epoch + lis.len() as u64 == chunk.last_epoch + 1,
                "Number of items in chunks doesn't match that in manifest. \
                first_epoch: {}, last_epoch: {}, items in chunk: {}",
                chunk.first_epoch,
                chunk.last_epoch,
                lis.len(),
            );
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L160-172)
```rust
    async fn read_chunk(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Vec<LedgerInfoWithSignatures>> {
        let mut file = self.storage.open_for_read(file_handle).await?;
        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/manifest.rs (L29-68)
```rust
    pub fn verify(&self) -> Result<()> {
        // check number of waypoints
        ensure!(
            self.first_epoch <= self.last_epoch
                && self.last_epoch - self.first_epoch + 1 == self.waypoints.len() as u64,
            "Malformed manifest. first epoch: {}, last epoch {}, num waypoints {}",
            self.first_epoch,
            self.last_epoch,
            self.waypoints.len(),
        );

        // check chunk ranges
        ensure!(!self.chunks.is_empty(), "No chunks.");
        let mut next_epoch = self.first_epoch;
        for chunk in &self.chunks {
            ensure!(
                chunk.first_epoch == next_epoch,
                "Chunk ranges not continuous. Expected first epoch: {}, actual: {}.",
                next_epoch,
                chunk.first_epoch,
            );
            ensure!(
                chunk.last_epoch >= chunk.first_epoch,
                "Chunk range invalid. [{}, {}]",
                chunk.first_epoch,
                chunk.last_epoch,
            );
            next_epoch = chunk.last_epoch + 1;
        }

        // check last epoch in chunk matches manifest
        ensure!(
            next_epoch - 1 == self.last_epoch, // okay to -1 because chunks is not empty.
            "Last epoch in chunks: {}, in manifest: {}",
            next_epoch - 1,
            self.last_epoch,
        );

        Ok(())
    }
```

**File:** types/src/ledger_info.rs (L240-246)
```rust
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub struct LedgerInfoWithV0 {
    ledger_info: LedgerInfo,
    /// Aggregated BLS signature of all the validators that signed the message. The bitmask in the
    /// aggregated signature can be used to find out the individual validators signing the message
    signatures: AggregateSignature,
}
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L51-57)
```rust
    // Defaults to 128MB, so concurrent chunk downloads won't take up too much memory.
    #[clap(
        long = "max-chunk-size",
        default_value_t = 134217728,
        help = "Maximum chunk file size in bytes."
    )]
    pub max_chunk_size: usize,
```
