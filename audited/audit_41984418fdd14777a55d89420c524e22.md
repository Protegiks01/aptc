# Audit Report

## Title
ValidatorInfo Schema Evolution: Network Partition Risk Due to BCS Strict Serialization Without Backward Compatibility

## Summary
The `ValidatorInfo` struct uses strict BCS serialization without any default value mechanism or optional field support. If new fields are added in future protocol versions, old validators will fail to deserialize the `ValidatorSet`, causing complete network partition rather than successfully deserializing with default values. This breaks the deterministic execution invariant and requires a hard fork to recover.

## Finding Description

The security question asks whether old validators can deserialize new `ValidatorInfo` with default values that break consensus. **The actual behavior is worse**: old validators **cannot deserialize at all**, causing immediate network partition. [1](#0-0) 

The `ValidatorInfo` struct is a simple serializable struct with no default value support. When validators fetch the validator set during epoch changes, deserialization occurs through the `OnChainConfig` trait: [2](#0-1) 

This uses `bcs::from_bytes()` which requires exact schema matching. BCS (Binary Canonical Serialization) fails if the byte stream doesn't match the struct definition exactly.

During epoch transitions, validators construct the `ValidatorVerifier` from the deserialized `ValidatorSet`: [3](#0-2) 

**Attack Scenario:**

1. Protocol upgrade adds a new field to `ValidatorInfo` (bypassing Move compatibility via emergency governance action or `upgrade_policy_arbitrary()`)
2. New epoch begins, `ValidatorSet` with new schema is written to on-chain storage
3. Old validators attempt to fetch: `ValidatorSet::fetch_config()` → `bcs::from_bytes()` → **DESERIALIZATION FAILS**
4. Old validators cannot construct `ValidatorVerifier`, cannot verify quorum certificates, **cannot participate in consensus**
5. New validators successfully deserialize and continue consensus
6. **Network splits**: subset of validators frozen, unable to participate

Move's compatibility system normally prevents this: [4](#0-3) [5](#0-4) 

However, compatibility can be bypassed using policy 0 (arbitrary upgrade), which is explicitly allowed for emergency situations.

## Impact Explanation

**Severity: CRITICAL** (Non-recoverable network partition requiring hard fork)

This violates Critical Invariant #1 (Deterministic Execution) and #2 (Consensus Safety):
- Validators disagree on the validator set composition
- Subset of validators permanently excluded from consensus
- Cannot be recovered without coordinated hard fork
- Affects all validators not upgraded simultaneously

Per Aptos bug bounty: "Non-recoverable network partition (requires hardfork)" qualifies as Critical Severity.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH during protocol upgrades**

This scenario is realistic because:
1. Protocol upgrades with schema changes are planned (Aptos is actively evolving)
2. Validator upgrades are not atomic - there's always a window with mixed versions
3. Emergency upgrades might bypass compatibility checks
4. No versioning or graceful degradation mechanism exists

Historical precedent: Many blockchains have experienced upgrade-related network splits when schema changes were not carefully coordinated.

## Recommendation

**Immediate Actions:**

1. **Add Versioning to ValidatorInfo:**
```rust
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub enum ValidatorInfoVersioned {
    V1(ValidatorInfoV1),
    V2(ValidatorInfoV2),
    // Future versions
}
```

2. **Implement Backward-Compatible Deserialization:**
Add custom deserialize logic that can handle multiple schema versions gracefully.

3. **Add Protocol Version Checks:**
Before epoch transitions, verify all active validators support the current protocol version. Reject epoch changes if incompatible validators exist.

4. **Add Monitoring:**
Implement alerts for deserialization failures in `ValidatorSet::fetch_config()` to detect version mismatches early.

5. **Enforce Coordinated Upgrades:**
Require validator upgrades to complete across >2/3 of voting power before enabling new schema features.

**Long-term:**
Adopt a formal upgrade protocol that enforces validator version compatibility before schema-breaking changes can take effect.

## Proof of Concept

This vulnerability requires actual protocol upgrade to demonstrate. A conceptual PoC:

```rust
// Simulating the vulnerability scenario
#[test]
fn test_validator_info_schema_mismatch() {
    // Step 1: Old validator has ValidatorInfo with 3 fields
    #[derive(Serialize, Deserialize)]
    struct ValidatorInfoOld {
        account_address: AccountAddress,
        consensus_voting_power: u64,
        config: ValidatorConfig,
    }
    
    // Step 2: New protocol adds field
    #[derive(Serialize, Deserialize)]
    struct ValidatorInfoNew {
        account_address: AccountAddress,
        consensus_voting_power: u64,
        config: ValidatorConfig,
        new_field: u64,  // NEW FIELD
    }
    
    // Step 3: Serialize with new schema
    let new_info = ValidatorInfoNew { /* ... */, new_field: 100 };
    let bytes = bcs::to_bytes(&new_info).unwrap();
    
    // Step 4: Old validator tries to deserialize
    let result = bcs::from_bytes::<ValidatorInfoOld>(&bytes);
    
    // Result: DESERIALIZATION FAILS
    assert!(result.is_err());
    // Old validator cannot construct ValidatorVerifier
    // Old validator cannot participate in consensus
    // Network partition occurs
}
```

**Notes**

The current implementation does NOT allow old validators to "deserialize new ValidatorInfo with default values" as stated in the security question. Instead, BCS strict serialization causes deserialization to **fail completely**, which is arguably more severe than silent default value usage. The network partition risk is real and occurs during any schema-breaking protocol upgrade without coordinated validator updates. While Move's compatibility system provides some protection, it can be bypassed for emergency upgrades, creating this critical vulnerability window.

### Citations

**File:** types/src/validator_info.rs (L18-29)
```rust
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct ValidatorInfo {
    // The validator's account address. AccountAddresses are initially derived from the account
    // auth pubkey; however, the auth key can be rotated, so one should not rely on this
    // initial property.
    pub account_address: AccountAddress,
    // Voting power of this validator
    consensus_voting_power: u64,
    // Validator config
    config: ValidatorConfig,
}
```

**File:** types/src/on_chain_config/mod.rs (L162-165)
```rust
    fn deserialize_default_impl(bytes: &[u8]) -> Result<Self> {
        bcs::from_bytes::<Self>(bytes)
            .map_err(|e| format_err!("[on-chain config] Failed to deserialize into config: {}", e))
    }
```

**File:** types/src/validator_verifier.rs (L563-586)
```rust
impl From<&ValidatorSet> for ValidatorVerifier {
    fn from(validator_set: &ValidatorSet) -> Self {
        let sorted_validator_infos: BTreeMap<u64, ValidatorConsensusInfo> = validator_set
            .payload()
            .map(|info| {
                (
                    info.config().validator_index,
                    ValidatorConsensusInfo::new(
                        info.account_address,
                        info.consensus_public_key().clone(),
                        info.consensus_voting_power(),
                    ),
                )
            })
            .collect();
        let validator_infos: Vec<_> = sorted_validator_infos.values().cloned().collect();
        for info in validator_set.payload() {
            assert_eq!(
                validator_infos[info.config().validator_index as usize].address,
                info.account_address
            );
        }
        ValidatorVerifier::new(validator_infos)
    }
```

**File:** third_party/move/move-binary-format/src/compatibility.rs (L350-377)
```rust
    fn struct_layout_compatible(
        &self,
        old_struct: &StructDefinitionView<CompiledModule>,
        new_struct: &StructDefinitionView<CompiledModule>,
    ) -> bool {
        if old_struct.variant_count() == 0 {
            // Old is regular struct, new needs to be as well (i.e. have zero variants) and compatible
            // fields.
            new_struct.variant_count() == 0
                && self.fields_compatible(
                    old_struct.fields_optional_variant(None),
                    new_struct.fields_optional_variant(None),
                )
        } else {
            // Enum: the prefix of variants in the old definition must be the same as in the new one.
            // (a) the variant names need to match
            // (b) the variant fields need to be compatible
            old_struct.variant_count() <= new_struct.variant_count()
                && (0..old_struct.variant_count()).all(|i| {
                    let v_idx = i as VariantIndex;
                    old_struct.variant_name(v_idx) == new_struct.variant_name(v_idx)
                        && self.fields_compatible(
                            old_struct.fields_optional_variant(Some(v_idx)),
                            new_struct.fields_optional_variant(Some(v_idx)),
                        )
                })
        }
    }
```

**File:** third_party/move/move-binary-format/src/compatibility.rs (L379-406)
```rust
    fn fields_compatible<'a, 'b>(
        &self,
        mut old_fields: impl Iterator<Item = FieldDefinitionView<'a, CompiledModule>>,
        mut new_fields: impl Iterator<Item = FieldDefinitionView<'b, CompiledModule>>,
    ) -> bool {
        loop {
            match (old_fields.next(), new_fields.next()) {
                (Some(old_field), Some(new_field)) => {
                    // Require names and types to be equal. Notice this is a stricter definition
                    // than required. We could in principle choose that changing the name
                    // (but not position or type) of a field is compatible. The VM does not care about
                    // the name of a field but clients presumably do.
                    if old_field.name() != new_field.name()
                        || !self.signature_token_compatible(
                            old_field.module(),
                            old_field.signature_token(),
                            new_field.module(),
                            new_field.signature_token(),
                        )
                    {
                        return false;
                    }
                },
                (None, None) => return true,
                _ => return false,
            }
        }
    }
```
