# Audit Report

## Title
Metric Inflation Vulnerability Due to Non-Idempotent Counter Updates in Indexer Transaction Processor

## Summary
The `update_status_success()` function in the Aptos indexer increments Prometheus counter metrics on every invocation, even when processing the same version range multiple times. This violates the idempotency guarantee and causes metric inflation during crash recovery scenarios or manual reprocessing operations.

## Finding Description

The Aptos indexer is designed to be idempotent to handle crash recovery and reprocessing scenarios. However, while the database operations use UPSERT patterns and are truly idempotent, the metric instrumentation is not. [1](#0-0) 

The function increments `PROCESSOR_SUCCESSES` counter metric on every call, regardless of whether this version range was already processed. This counter is defined as: [2](#0-1) 

Additionally, `PROCESSOR_INVOCATIONS` is incremented in the calling function: [3](#0-2) 

**Exploitation Scenario:**

The indexer uses two separate database tables for status tracking:
1. `processor_statuses` (plural) - updated within `update_status_success()` via `apply_processor_status()`
2. `processor_status` (singular) - updated later via `update_last_processed_version()` [4](#0-3) 

During crash recovery, the indexer reads the starting version from `processor_status`: [5](#0-4) 

**Attack Path:**
1. Indexer processes versions 100-199 successfully
2. `process_transactions_with_status()` completes, calling `update_status_success()`
3. Metrics incremented: `PROCESSOR_SUCCESSES` += 1, `PROCESSOR_INVOCATIONS` += 1
4. Database table `processor_statuses` updated via UPSERT (idempotent)
5. **Crash occurs before `update_last_processed_version()` updates `processor_status` table**
6. On restart, `get_start_version()` reads stale value (version 99) from `processor_status`
7. Same versions 100-199 are reprocessed
8. Metrics incremented **again**: `PROCESSOR_SUCCESSES` += 1, `PROCESSOR_INVOCATIONS` += 1
9. Database operations are idempotent (no duplication), but metrics are inflated

The codebase even has a test that demonstrates repeated processing is expected to be idempotent: [6](#0-5) 

However, this test only verifies database idempotency, not metric idempotency.

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Operational Impact:**
- **Incorrect Monitoring**: Inflated success counters provide false confidence about indexer health
- **Alert Suppression**: Rate-based alerts (e.g., "success rate dropped below 95%") may not trigger when they should
- **Capacity Planning**: Inflated throughput metrics lead to incorrect infrastructure sizing decisions
- **SLA Violations**: Reported metrics don't reflect actual processed transaction counts, violating service level agreements
- **Incident Response**: During outages with frequent restarts, metrics become completely unreliable, hampering debugging

While this doesn't directly affect consensus or funds, it violates the documented idempotency guarantee and creates "state inconsistencies requiring intervention" - operators cannot trust their metrics and must manually verify processing status through database queries.

## Likelihood Explanation

**High Likelihood** - This will occur in production under normal circumstances:

1. **Crash Recovery**: Any indexer crash between `process_transactions_with_status()` and `update_last_processed_version()` triggers this bug. With multiple parallel processor tasks, crashes are frequent during deployment rollouts, infrastructure failures, or OOM conditions.

2. **Manual Reprocessing**: Operators frequently need to reprocess historical data for:
   - Bug fixes in processing logic
   - Schema migrations
   - Data consistency repairs
   - Each reprocessing operation inflates metrics

3. **No Special Privileges Required**: This is not an attack requiring insider access - it's a bug triggered by normal operational events that any indexer operator will encounter.

4. **Race Condition Window**: The window between the two database updates is non-trivial (involves multiple batch writes), making crashes during this window highly probable.

## Recommendation

Make metric updates idempotent by checking if the version range was already processed successfully before incrementing counters:

```rust
fn update_status_success(&self, processing_result: &ProcessingResult) {
    aptos_logger::debug!(
        "[{}] Marking processing version OK from versions {} to {}",
        self.name(),
        processing_result.start_version,
        processing_result.end_version
    );
    
    // Check if this version range was already processed
    let mut conn = self.get_conn();
    let already_processed = self.check_already_processed(
        &mut conn, 
        processing_result.start_version, 
        processing_result.end_version
    );
    
    // Only increment metrics for newly processed versions
    if !already_processed {
        PROCESSOR_SUCCESSES.with_label_values(&[self.name()]).inc();
        LATEST_PROCESSED_VERSION
            .with_label_values(&[self.name()])
            .set(processing_result.end_version as i64);
    }
    
    let psms = ProcessorStatusModel::from_versions(
        self.name(),
        processing_result.start_version,
        processing_result.end_version,
        true,
        None,
    );
    self.apply_processor_status(&psms);
}

fn check_already_processed(&self, conn: &mut PgPoolConnection, start: u64, end: u64) -> bool {
    use schema::processor_statuses::dsl::*;
    let count: i64 = processor_statuses
        .filter(name.eq(self.name()))
        .filter(version.ge(start as i64))
        .filter(version.le(end as i64))
        .filter(success.eq(true))
        .count()
        .get_result(conn)
        .unwrap_or(0);
    count == ((end - start + 1) as i64)
}
```

Alternatively, use Prometheus Gauges instead of Counters for these metrics, or ensure `processor_status` is updated atomically with `processor_statuses`.

## Proof of Concept

```rust
#[cfg(test)]
mod metric_inflation_test {
    use super::*;
    use crate::counters::PROCESSOR_SUCCESSES;
    
    #[tokio::test]
    async fn test_metric_inflation_on_reprocessing() {
        // Setup indexer with test database
        let (conn_pool, tailer) = setup_test_indexer().await;
        
        // Get initial metric value
        let initial_successes = PROCESSOR_SUCCESSES
            .with_label_values(&["test_processor"])
            .get();
        
        // Process a transaction
        let test_txn = create_test_transaction(version: 100);
        tailer.processor
            .process_transactions_with_status(vec![test_txn.clone()])
            .await
            .unwrap();
        
        let after_first = PROCESSOR_SUCCESSES
            .with_label_values(&["test_processor"])
            .get();
        assert_eq!(after_first, initial_successes + 1);
        
        // Process SAME transaction again (simulating crash recovery)
        tailer.processor
            .process_transactions_with_status(vec![test_txn.clone()])
            .await
            .unwrap();
        
        let after_second = PROCESSOR_SUCCESSES
            .with_label_values(&["test_processor"])
            .get();
        
        // BUG: Counter is incremented again despite idempotent processing
        assert_eq!(after_second, initial_successes + 2); // FAILS - should be +1
        
        // Verify database is idempotent (only one entry)
        let db_count = count_processor_status_entries(&conn_pool, "test_processor", 100);
        assert_eq!(db_count, 1); // PASSES - database is idempotent
    }
}
```

This test demonstrates that while database writes are idempotent, metrics are inflated on every reprocessing operation, violating the system's idempotency guarantee.

## Notes

This vulnerability is particularly concerning because:
- The existing test suite explicitly tests for idempotency but only validates database behavior, not metrics
- The issue affects all indexer processors (DefaultProcessor, TokenProcessor, CoinProcessor, StakeProcessor)
- Metric inflation is cumulative and unbounded - repeated crashes cause exponential divergence from true values
- The `LATEST_PROCESSED_VERSION` gauge is correctly idempotent (uses `.set()` instead of `.inc()`), showing the developers understood idempotency requirements but inconsistently applied them

### Citations

**File:** crates/indexer/src/indexer/transaction_processor.rs (L74-76)
```rust
        PROCESSOR_INVOCATIONS
            .with_label_values(&[self.name()])
            .inc();
```

**File:** crates/indexer/src/indexer/transaction_processor.rs (L112-131)
```rust
    fn update_status_success(&self, processing_result: &ProcessingResult) {
        aptos_logger::debug!(
            "[{}] Marking processing version OK from versions {} to {}",
            self.name(),
            processing_result.start_version,
            processing_result.end_version
        );
        PROCESSOR_SUCCESSES.with_label_values(&[self.name()]).inc();
        LATEST_PROCESSED_VERSION
            .with_label_values(&[self.name()])
            .set(processing_result.end_version as i64);
        let psms = ProcessorStatusModel::from_versions(
            self.name(),
            processing_result.start_version,
            processing_result.end_version,
            true,
            None,
        );
        self.apply_processor_status(&psms);
    }
```

**File:** crates/indexer/src/counters.rs (L30-38)
```rust
/// Number of times any given processor has completed successfully
pub static PROCESSOR_SUCCESSES: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "indexer_processor_success_count",
        "Number of times a given processor has completed successfully",
        &["processor_name"]
    )
    .unwrap()
});
```

**File:** crates/indexer/src/runtime.rs (L163-176)
```rust
    let starting_version_from_db_short = tailer
        .get_start_version(&processor_name)
        .unwrap_or_else(|e| panic!("Failed to get starting version: {:?}", e))
        .unwrap_or_else(|| {
            info!(
                processor_name = processor_name,
                "No starting version from db so starting from version 0"
            );
            0
        }) as u64;
    let start_version = match config.starting_version {
        None => starting_version_from_db_short,
        Some(version) => version,
    };
```

**File:** crates/indexer/src/runtime.rs (L250-261)
```rust

        tailer
            .update_last_processed_version(&processor_name, batch_end_version)
            .unwrap_or_else(|e| {
                error!(
                    processor_name = processor_name,
                    end_version = batch_end_version,
                    error = format!("{:?}", e),
                    "Failed to update last processed version!"
                );
                panic!("Failed to update last processed version: {:?}", e);
            });
```

**File:** crates/indexer/src/indexer/tailer.rs (L815-825)
```rust
        // We run it twice to ensure we don't explode. Idempotency!
        tailer
            .processor
            .process_transactions_with_status(vec![user_txn.clone()])
            .await
            .unwrap();
        tailer
            .processor
            .process_transactions_with_status(vec![user_txn.clone()])
            .await
            .unwrap();
```
