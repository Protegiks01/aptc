# Audit Report

## Title
Unicode Normalization Bypass in NFT Metadata Crawler Blacklist Allowing Malicious Endpoint Access

## Summary
The NFT metadata crawler's URI blacklist mechanism uses basic string matching without Unicode normalization, allowing attackers to bypass blacklisted domains using IDN homoglyphs (lookalike Unicode characters). This enables directing the crawler to malicious endpoints despite operator-configured security controls.

## Finding Description

The NFT metadata crawler implements a URI blacklist mechanism to prevent processing of known-malicious domains. However, the blacklist check performs substring matching without Unicode normalization, creating a security control bypass. [1](#0-0) 

The `is_blacklisted_uri` function uses Rust's built-in `contains()` method, which performs byte-level string comparison without any Unicode normalization. This means that visually identical strings with different Unicode codepoints are treated as distinct.

The blacklist check is performed at two critical points in the parsing flow:

1. When validating the main `asset_uri` from NFT metadata: [2](#0-1) 

2. When validating the `raw_image_uri` extracted from JSON: [3](#0-2) 

**Attack Scenario:**

An attacker can exploit this by:

1. **Operator Configuration**: The crawler operator adds `malicious.com` to the URI blacklist to block known malicious domains.

2. **Attacker Registration**: The attacker registers an IDN (Internationalized Domain Name) using Cyrillic or other lookalike characters, such as:
   - `malіcious.com` (using Cyrillic 'і' U+0456 instead of Latin 'i' U+0069)
   - `malicious․com` (using ONE DOT LEADER U+2024 instead of FULL STOP U+002E)
   - `malіcіous.com` (multiple Cyrillic substitutions)

3. **NFT Creation**: The attacker creates an NFT with metadata URI pointing to `https://malіcious.com/metadata.json`

4. **Blacklist Bypass**: When the crawler processes this NFT:
   - The `contains()` check compares bytes: `"https://malіcious.com/metadata.json".contains("malicious.com")`
   - This returns `false` because the Cyrillic 'і' (bytes: 0xD1 0x96) differs from Latin 'i' (byte: 0x69)
   - The blacklist check passes, allowing the URI through

5. **Malicious Access**: The crawler proceeds to fetch from the attacker's domain: [4](#0-3) 

The `reqwest::Client` HTTP library uses the `url` crate, which DOES perform IDNA (Internationalized Domain Names in Applications) encoding. This means the browser/HTTP client will successfully resolve the IDN domain to its Punycode representation and connect to the attacker's server, despite the blacklist check having "passed."

The same vulnerability exists in the URI parser's arweave detection logic: [5](#0-4) 

While this particular check is less critical (it's a passthrough for arweave URIs rather than a security control), it demonstrates the systemic lack of Unicode normalization throughout the URI handling code.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria because:

1. **Security Control Bypass**: The blacklist is an explicit security mechanism designed to prevent the crawler from accessing known-malicious or problematic domains. Bypassing this control undermines the security posture of the entire crawler infrastructure.

2. **Resource Exhaustion**: Malicious endpoints can serve responses designed to exhaust crawler resources:
   - Large files approaching `max_file_size_bytes` limits repeatedly
   - Slow responses to tie up crawler threads
   - Complex images requiring excessive processing time

3. **Malicious Content Injection**: Content fetched from bypassed domains gets stored in Google Cloud Storage and served via CDN: [6](#0-5) 

This creates a supply chain attack vector where malicious content could be served to downstream consumers of the NFT metadata.

4. **Crawler Fingerprinting**: Malicious endpoints can track and fingerprint crawler requests to gather intelligence about the infrastructure.

However, this does NOT constitute:
- Direct blockchain consensus impact
- Fund loss or theft  
- Validator node compromise
- Core protocol violation

Therefore, it fits the **Medium** severity category: "State inconsistencies requiring intervention" and security control bypass with limited but real security impact.

## Likelihood Explanation

**Likelihood: HIGH**

The attack is highly likely to occur because:

1. **Low Barrier to Entry**: 
   - Registering IDN domains with homoglyphs is straightforward and inexpensive
   - No special permissions or insider access required
   - Attacker only needs to create an NFT with a malicious URI (standard blockchain operation)

2. **Blacklists Are Common**: Operators frequently use blacklists to block problematic domains discovered during operations, making this a regularly used security control

3. **No Detection**: The crawler has no mechanism to detect or alert on IDN/homoglyph usage, so bypasses would go unnoticed

4. **Well-Known Attack Pattern**: Unicode normalization attacks are well-documented in web security and have been exploited in various contexts (phishing, URL filtering bypass, etc.)

5. **Multiple Attack Points**: The vulnerability exists at both the `asset_uri` and `raw_image_uri` validation points, providing multiple exploitation opportunities

## Recommendation

Implement Unicode normalization and IDNA encoding before performing blacklist checks:

```rust
use idna;
use unicode_normalization::UnicodeNormalization;

fn is_blacklisted_uri(&mut self, uri: &str) -> bool {
    // Normalize the input URI using NFKC (Compatibility Decomposition followed by Canonical Composition)
    let normalized_uri = uri.nfkc().collect::<String>();
    
    // Parse the URL to extract and normalize the domain
    if let Ok(parsed_url) = url::Url::parse(&normalized_uri) {
        if let Some(domain) = parsed_url.domain() {
            // Convert IDN to ASCII using Punycode
            let ascii_domain = idna::domain_to_ascii(domain)
                .unwrap_or_else(|_| domain.to_string());
            
            // Check against blacklist using normalized domain
            for blacklist_entry in &self.parser_config.uri_blacklist {
                let normalized_blacklist = blacklist_entry.nfkc().collect::<String>();
                let ascii_blacklist = idna::domain_to_ascii(&normalized_blacklist)
                    .unwrap_or(normalized_blacklist);
                
                // Check if normalized domain contains normalized blacklist entry
                if ascii_domain.contains(&ascii_blacklist) {
                    return true;
                }
            }
        }
    }
    
    // Fallback to original comparison for non-parseable URIs
    self.parser_config
        .uri_blacklist
        .iter()
        .any(|blacklist_uri| {
            let normalized_blacklist = blacklist_uri.nfkc().collect::<String>();
            normalized_uri.contains(&normalized_blacklist)
        })
}
```

Additionally, add validation to warn operators when URIs contain non-ASCII characters in domains:

```rust
fn validate_uri_safety(&self, uri: &str) -> Option<String> {
    if let Ok(parsed) = url::Url::parse(uri) {
        if let Some(domain) = parsed.domain() {
            if !domain.is_ascii() {
                return Some(format!("Warning: URI contains non-ASCII domain: {}", domain));
            }
        }
    }
    None
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_unicode_homoglyph_blacklist_bypass() {
        // Simulate blacklist configuration
        let blacklist = vec!["malicious.com".to_string()];
        
        // Test case 1: Normal ASCII domain - should be blocked
        let normal_uri = "https://malicious.com/metadata.json";
        let is_blocked_normal = blacklist.iter().any(|b| normal_uri.contains(b));
        assert!(is_blocked_normal, "Normal ASCII domain should be blocked");
        
        // Test case 2: Cyrillic 'і' (U+0456) instead of Latin 'i' (U+0069)
        let cyrillic_uri = "https://malіcious.com/metadata.json";  // Note: і is Cyrillic
        let is_blocked_cyrillic = blacklist.iter().any(|b| cyrillic_uri.contains(b));
        assert!(!is_blocked_cyrillic, "Cyrillic homoglyph bypasses blacklist - VULNERABILITY");
        
        // Test case 3: Demonstrate the bytes are different
        let latin_i = 'i';  // U+0069
        let cyrillic_i = 'і';  // U+0456
        assert_ne!(
            latin_i as u32, 
            cyrillic_i as u32,
            "Characters have different codepoints but look identical"
        );
        
        // Test case 4: Multiple homoglyphs
        let multiple_homoglyphs = "https://mаlіcіous.com/metadata.json";  // а, і, і are Cyrillic
        let is_blocked_multiple = blacklist.iter().any(|b| multiple_homoglyphs.contains(b));
        assert!(!is_blocked_multiple, "Multiple homoglyphs bypass blacklist - VULNERABILITY");
        
        // Test case 5: Verify the HTTP client would resolve the IDN
        // (This would require actual network testing, but demonstrates the full attack)
        use url::Url;
        let parsed = Url::parse(cyrillic_uri).expect("IDN URL parses successfully");
        assert_eq!(parsed.scheme(), "https");
        // The url crate will handle IDNA encoding when the request is made
        
        println!("VULNERABILITY CONFIRMED: Unicode homoglyphs bypass blacklist checks");
        println!("Attacker can use: {}", cyrillic_uri);
        println!("While blacklist blocks: {}", normal_uri);
        println!("Both resolve to same/similar domains but contain() check fails");
    }
}
```

## Notes

This vulnerability is particularly concerning because:

1. **Invisible to Operators**: Visually, `malіcious.com` appears identical to `malicious.com` in most fonts, making it difficult for operators to detect the bypass

2. **Systemic Issue**: The lack of Unicode normalization affects multiple URI checks throughout the codebase, suggesting a broader code review is warranted

3. **Real-World Precedent**: Similar vulnerabilities have been exploited in phishing attacks, browser security bypasses, and web application firewall evasion

4. **Compound Risk**: When combined with other vulnerabilities in image processing or JSON parsing (not analyzed here), the impact could escalate

The fix requires adding the `idna` and `unicode-normalization` crates as dependencies and systematically normalizing all URI comparisons throughout the codebase.

### Citations

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L94-100)
```rust
        if self.is_blacklisted_uri(&self.asset_uri.clone()) {
            self.log_info("Found match in URI blacklist, marking as do_not_parse");
            self.model.set_do_not_parse(true);
            self.upsert();
            SKIP_URI_COUNT.with_label_values(&["blacklist"]).inc();
            return Ok(());
        }
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L142-160)
```rust
                let cdn_json_uri_result = write_json_to_gcs(
                    &self.parser_config.bucket,
                    &self.asset_uri,
                    &json,
                    &self.gcs_client,
                )
                .await;

                if let Err(e) = cdn_json_uri_result.as_ref() {
                    self.log_warn(
                        "Failed to write JSON to GCS, maybe upload timed out?",
                        Some(e),
                    );
                }

                let cdn_json_uri = cdn_json_uri_result
                    .map(|value| format!("{}{}", self.parser_config.cdn_prefix, value))
                    .ok();
                self.model.set_cdn_json_uri(cdn_json_uri);
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L206-212)
```rust
            if self.is_blacklisted_uri(&raw_image_uri) {
                self.log_info("Found match in URI blacklist, marking as do_not_parse");
                self.model.set_do_not_parse(true);
                self.upsert();
                SKIP_URI_COUNT.with_label_values(&["blacklist"]).inc();
                return Ok(());
            }
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L386-391)
```rust
    fn is_blacklisted_uri(&mut self, uri: &str) -> bool {
        self.parser_config
            .uri_blacklist
            .iter()
            .any(|blacklist_uri| uri.contains(blacklist_uri))
    }
```

**File:** ecosystem/nft-metadata-crawler/src/utils/json_parser.rs (L60-64)
```rust
                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get JSON")?;
```

**File:** ecosystem/nft-metadata-crawler/src/utils/uri_parser.rs (L22-25)
```rust
        if uri.contains("arweave.net") {
            PARSE_URI_TYPE_COUNT.with_label_values(&["arweave"]).inc();
            return Ok(uri.to_string());
        }
```
