# Audit Report

## Title
Race Condition in BlockStore Tree Replacement Causes Validator Node Crash

## Summary
A time-of-check-time-of-use (TOCTOU) race condition exists in `send_for_execution()` where the function makes multiple separate read lock acquisitions assuming the `ordered_root` remains consistent. When `rebuild()` replaces the block tree between these operations, it can cause `path_from_ordered_root()` to return `None`, triggering a panic and crashing the validator node.

## Finding Description

The `send_for_execution()` function in BlockStore performs multiple sequential read operations assuming tree consistency: [1](#0-0) 

The vulnerability occurs because:

1. **Line 323**: Reads `ordered_root().round()` (e.g., round 5) and validates that `block_to_commit.round()` (e.g., round 7) is greater
2. **Race Window**: Another thread can call `rebuild()` which replaces the entire tree with a new `ordered_root` at a higher round (e.g., round 10)
3. **Line 328**: Calls `path_from_ordered_root(block_id_to_commit)` which now uses the NEW ordered_root at round 10

The `path_from_root_to_block` implementation breaks when the target block's round is less than or equal to the root round: [2](#0-1) 

When the block's round (7) â‰¤ new root's round (10), the loop breaks immediately at line 529, and since the block_id won't match the new root_id, it returns `None` at line 541.

The `rebuild()` function is called during state sync and replaces the tree atomically: [3](#0-2) [4](#0-3) 

Both `send_for_execution` and `rebuild` can execute concurrently since they're called from different async contexts with no mutual exclusion: [5](#0-4) 

This breaks the **State Consistency** invariant (atomic state transitions) and can cause **Total loss of liveness** if multiple validators crash simultaneously.

## Impact Explanation

**High Severity** - This qualifies as "API crashes" and "Validator node slowdowns" per the Aptos bug bounty program:

- **Immediate Impact**: Validator node panic/crash when the assertion fails
- **Network Impact**: If multiple validators experience this race simultaneously (likely during network-wide state sync events), it can cause significant liveness degradation
- **Consensus Disruption**: Crashed validators cannot participate in consensus, reducing the effective validator set size
- **Recovery Required**: Node operators must manually restart affected validators

While a single node crash may not halt the network, this vulnerability could cause cascading failures during critical sync periods when many nodes are catching up simultaneously.

## Likelihood Explanation

**Medium to High Likelihood**:

- **Trigger Conditions**: 
  - Occurs when `send_for_execution` and `rebuild` run concurrently
  - `rebuild` is triggered during state sync (when node is behind)
  - `send_for_execution` is called when processing quorum certificates
  
- **Frequency Factors**:
  - State sync happens regularly when validators restart or fall behind
  - Block commits happen continuously during normal operation
  - The race window is small but exists between every pair of read operations
  - Network-wide sync events (e.g., after downtime) increase probability

- **Attacker Influence**: 
  - Limited direct control, but an attacker could potentially increase likelihood by:
    - Sending sync info messages to trigger state syncs
    - Timing attacks during known sync periods
  - Requires no special privileges

## Recommendation

**Fix 1: Atomic Read Operation**
Acquire a single read lock and extract all needed data atomically:

```rust
pub async fn send_for_execution(
    &self,
    finality_proof: WrappedLedgerInfo,
) -> anyhow::Result<()> {
    let block_id_to_commit = finality_proof.commit_info().id();
    
    // Acquire lock once and extract all data atomically
    let (block_to_commit, ordered_root_round, blocks_to_commit) = {
        let tree_guard = self.inner.read();
        let ordered_root_round = tree_guard.ordered_root().round();
        let block_to_commit = tree_guard.get_block(&block_id_to_commit)
            .ok_or_else(|| format_err!("Committed block id not found"))?;
        
        ensure!(
            block_to_commit.round() > ordered_root_round,
            "Committed block round lower than root"
        );
        
        let blocks = tree_guard.path_from_ordered_root(block_id_to_commit)
            .ok_or_else(|| format_err!("Failed to get path from ordered root"))?;
        
        (block_to_commit, ordered_root_round, blocks)
    };
    
    ensure!(!blocks_to_commit.is_empty(), "No blocks to commit");
    
    // Rest of the function...
}
```

**Fix 2: Handle None Case Gracefully**
If atomicity cannot be maintained, handle the race condition gracefully:

```rust
let blocks_to_commit = self
    .path_from_ordered_root(block_id_to_commit)
    .ok_or_else(|| format_err!("Block tree changed during commit, retrying"))?;
```

**Recommendation**: Implement Fix 1 (atomic read) as it provides stronger consistency guarantees and eliminates the race condition entirely.

## Proof of Concept

```rust
#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
async fn test_rebuild_send_for_execution_race() {
    use std::sync::Arc;
    use std::time::Duration;
    
    // Setup: Create BlockStore with initial state at round 5
    let block_store = setup_block_store_with_root_round(5).await;
    
    // Create a block at round 7 to commit
    let block_7 = create_test_block(7);
    let qc_7 = create_test_qc(&block_7);
    block_store.insert_block(block_7.clone()).await.unwrap();
    
    let bs_clone = block_store.clone();
    
    // Thread A: Try to send block 7 for execution
    let handle_a = tokio::spawn(async move {
        // Add small delay to increase race window
        tokio::time::sleep(Duration::from_micros(100)).await;
        bs_clone.send_for_execution(qc_7.into_wrapped_ledger_info()).await
    });
    
    // Thread B: Rebuild tree with new root at round 10
    let handle_b = tokio::spawn(async move {
        let new_root = create_root_info_at_round(10);
        let new_metadata = create_root_metadata();
        block_store.rebuild(new_root, new_metadata, vec![], vec![]).await;
    });
    
    // Wait for both operations
    let result_a = handle_a.await.unwrap();
    handle_b.await.unwrap();
    
    // If race occurs, result_a will be a panic or error
    // Expected: Panic at assert!(!blocks_to_commit.is_empty())
    assert!(result_a.is_err() || panic_occurred);
}
```

**Expected Result**: The test triggers a panic in `send_for_execution` when the race condition occurs, demonstrating that readers can observe inconsistent state spanning both the old and new tree during tree replacement.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L259-264)
```rust
        let inner = if let Some(tree_to_replace) = tree_to_replace {
            *tree_to_replace.write() = tree;
            tree_to_replace
        } else {
            Arc::new(RwLock::new(tree))
        };
```

**File:** consensus/src/block_storage/block_store.rs (L323-331)
```rust
            block_to_commit.round() > self.ordered_root().round(),
            "Committed block round lower than root"
        );

        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();

        assert!(!blocks_to_commit.is_empty());
```

**File:** consensus/src/block_storage/block_tree.rs (L527-542)
```rust
        loop {
            match self.get_block(&cur_block_id) {
                Some(ref block) if block.round() <= root_round => {
                    break;
                },
                Some(block) => {
                    cur_block_id = block.parent_id();
                    res.push(block);
                },
                None => return None,
            }
        }
        // At this point cur_block.round() <= self.root.round()
        if cur_block_id != root_id {
            return None;
        }
```

**File:** consensus/src/block_storage/sync_manager.rs (L186-189)
```rust
        if self.ordered_root().round() < qc.commit_info().round() {
            SUCCESSFUL_EXECUTED_WITH_REGULAR_QC.inc();
            self.send_for_execution(qc.into_wrapped_ledger_info())
                .await?;
```

**File:** consensus/src/block_storage/sync_manager.rs (L313-314)
```rust
        self.rebuild(root, root_metadata, blocks, quorum_certs)
            .await;
```
