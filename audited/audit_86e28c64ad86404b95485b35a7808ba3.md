# Audit Report

## Title
Race Condition Between Module Publishing and Layout Cache Invalidation in Concurrent Block Execution

## Summary
A race condition exists between module publication and layout cache invalidation during parallel transaction execution. When a transaction publishes a new module version, there is a critical window where the new module is visible but the layout cache still contains layouts computed from the old module version. Concurrent transactions can retrieve stale layouts and use them with new module code, potentially causing state inconsistencies.

## Finding Description

The vulnerability exists in the module publishing flow during parallel block execution. When a transaction publishes modules: [1](#0-0) 

The critical issue is that modules are added to the cache and marked as visible BEFORE the layout cache is flushed: [2](#0-1) 

During the race window between module publication (line 564-570) and cache flush (line 574), a concurrent transaction can:

1. Request a layout for a struct from the newly published module
2. Retrieve the OLD cached layout (computed from the old module version) 
3. Load the NEW module code (now visible in the cache)
4. Use the mismatched old layout with new module code

The layout cache implementation uses DashMap for thread-safe access: [3](#0-2) 

However, the `StructKey` used for caching does not include version information: [4](#0-3) 

When layouts are loaded from cache, the system re-reads modules for gas charging but does NOT verify the layout matches the current module version: [5](#0-4) 

## Impact Explanation

This vulnerability has **High to Critical** severity potential because it breaks the **Deterministic Execution** invariant. Different validators could experience different timing of the race condition, leading to:

1. **Consensus Splits**: Validators using stale layouts may compute different state roots for the same block
2. **State Corruption**: Incorrect serialization/deserialization using mismatched layout+module pairs
3. **Non-deterministic Behavior**: Transaction outcomes depend on precise timing of cache operations

While the module validation system attempts to catch inconsistencies, it validates MODULE reads, not LAYOUT CACHE accesses. The layout version is never checked against the module version being used.

## Likelihood Explanation

**Likelihood: Medium to High** in production scenarios with:
- High transaction throughput with parallel execution enabled
- Frequent module upgrades (governance or framework updates)
- Multiple concurrent transactions accessing the same structs

The race window is small but real, and becomes more likely under load when many transactions execute concurrently.

## Recommendation

**Immediate Fix**: Flush the layout cache BEFORE making new modules visible, not after:

```rust
// In publish_module_write_set():
if published {
    // Flush layout cache FIRST, before modules become visible
    global_module_cache.flush_layout_cache();
    
    // Then add modules to cache
    for write in output_before_guard.module_write_set().values() {
        add_module_write_to_module_cache::<T>(
            write, txn_idx, runtime_environment, 
            global_module_cache, versioned_cache.module_cache()
        )?;
    }
    
    scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
}
```

**Long-term Fix**: Include version/txn_idx in StructKey to make layouts version-specific, or remove the TODO and refactor enum layouts as suggested in the comment at line 164-166 of code_cache_global.rs.

## Proof of Concept

This race condition is timing-dependent and difficult to reliably reproduce. A proof of concept would require:

1. Set up parallel block executor with high concurrency
2. Transaction T1: Publish module with modified struct layout
3. Multiple concurrent transactions T2-Tn: Access the modified struct
4. Introduce delays to widen the race window
5. Observe non-deterministic state roots or deserialization errors

Due to the timing-sensitive nature and lack of direct observability of internal cache state, a definitive PoC demonstrating consensus split would require instrumentation of the Aptos validator codebase and controlled execution timing.

---

**Notes:**

While this race condition genuinely exists in the code, demonstrating a **concrete exploitable path to consensus failure** requires proving that:
1. The stale layout actually causes different serialization behavior
2. This survives the module validation checks  
3. It leads to different state roots across validators

The module validation system and other consistency checks may prevent this from manifesting as an actual security issue in practice. However, the race condition is a clear violation of defensive programming principles and should be fixed to ensure deterministic execution guarantees.

### Citations

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L559-577)
```rust
        for write in output_before_guard.module_write_set().values() {
            published = true;
            if scheduler.is_v2() {
                module_ids_for_v2.insert(write.module_id().clone());
            }
            add_module_write_to_module_cache::<T>(
                write,
                txn_idx,
                runtime_environment,
                global_module_cache,
                versioned_cache.module_cache(),
            )?;
        }
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
        Ok(published)
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L86-97)
```rust
/// A global cache for verified code and derived information (such as layouts) that is concurrently
/// accessed during the block execution. Module cache is read-only, and modified safely only at
/// block boundaries. Layout cache can be modified during execution of the block.
pub struct GlobalModuleCache<K, D, V, E> {
    /// Module cache containing the verified code.
    module_cache: HashMap<K, Entry<D, V, E>>,
    /// Sum of serialized sizes (in bytes) of all cached modules.
    size: usize,
    /// Cached layouts of structs or enums. This cache stores roots only and is invalidated when
    /// modules are published.
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L272-319)
```rust
pub(crate) fn add_module_write_to_module_cache<T: BlockExecutableTransaction>(
    write: &ModuleWrite<T::Value>,
    txn_idx: TxnIndex,
    runtime_environment: &RuntimeEnvironment,
    global_module_cache: &GlobalModuleCache<ModuleId, CompiledModule, Module, AptosModuleExtension>,
    per_block_module_cache: &impl ModuleCache<
        Key = ModuleId,
        Deserialized = CompiledModule,
        Verified = Module,
        Extension = AptosModuleExtension,
        Version = Option<TxnIndex>,
    >,
) -> Result<(), PanicError> {
    let state_value = write
        .write_op()
        .as_state_value()
        .ok_or_else(|| PanicError::CodeInvariantError("Modules cannot be deleted".to_string()))?;

    // Since we have successfully serialized the module when converting into this transaction
    // write, the deserialization should never fail.
    let compiled_module = runtime_environment
        .deserialize_into_compiled_module(state_value.bytes())
        .map_err(|err| {
            let msg = format!("Failed to construct the module from state value: {:?}", err);
            PanicError::CodeInvariantError(msg)
        })?;
    let extension = Arc::new(AptosModuleExtension::new(state_value));

    per_block_module_cache
        .insert_deserialized_module(
            write.module_id().clone(),
            compiled_module,
            extension,
            Some(txn_idx),
        )
        .map_err(|err| {
            let msg = format!(
                "Failed to insert code for module {}::{} at version {} to module cache: {:?}",
                write.module_address(),
                write.module_name(),
                txn_idx,
                err
            );
            PanicError::CodeInvariantError(msg)
        })?;
    global_module_cache.mark_overridden(write.module_id());
    Ok(())
}
```

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L79-83)
```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
}
```

**File:** third_party/move/move-vm/runtime/src/storage/loader/lazy.rs (L203-221)
```rust
    fn load_layout_from_cache(
        &self,
        gas_meter: &mut impl DependencyGasMeter,
        traversal_context: &mut TraversalContext,
        key: &StructKey,
    ) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
        let entry = self.module_storage.get_struct_layout(key)?;
        let (layout, modules) = entry.unpack();
        for module_id in modules.iter() {
            // Re-read all modules for this layout, so that transaction gets invalidated
            // on module publish. Also, we re-read them in exactly the same way as they
            // were traversed during layout construction, so gas charging should be exactly
            // the same as on the cache miss.
            if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
                return Some(Err(err));
            }
        }
        Some(Ok(layout))
    }
```
