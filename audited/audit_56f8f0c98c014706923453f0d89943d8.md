# Audit Report

## Title
Validator Node Panic Due to Unvalidated Author in Persisted Augmented Data During Startup

## Summary
The `AugDataStore::new()` function in the consensus randomness generation module deserializes `CertifiedAugData` from the database and immediately uses it without validating that the author exists in the current epoch's validator set. This causes a panic when the code attempts to look up an invalid author, leading to validator node crashes on startup.

## Finding Description

The vulnerability exists in the startup path of the randomness generation subsystem. When a validator node starts, `AugDataStore::new()` loads previously persisted augmented data from the RandDb database: [1](#0-0) 

The deserialized `CertifiedAugData` is immediately used to call the `augment()` method without any validation that the author field corresponds to a validator in the current epoch's validator set. The `augment()` method then calls `add_certified_delta()`, which internally calls `get_id()` to look up the author: [2](#0-1) 

The `.expect()` call panics if the author is not found in the validator index. This breaks the **Resource Limits** and **Deterministic Execution** invariants, as a validator node that should be operational becomes unavailable due to unvalidated persistent state.

**Attack Path:**
1. During normal operation or through database corruption, `CertifiedAugData` with an author not in the current validator set gets persisted to the database (this could occur during epoch transitions if old data isn't properly cleaned, or through database corruption)
2. The validator node restarts
3. `AugDataStore::new()` loads the data and calls `.augment()` on it
4. The `get_id()` lookup fails and panics with "Peer should be in the index!"
5. The validator node crashes and cannot restart

While the `filter_by_epoch()` function filters out data from different epochs, it only checks the epoch number, not whether the author is valid for the current epoch's validator set: [3](#0-2) 

## Impact Explanation

**Severity: High** (Validator node crashes)

Per the Aptos bug bounty criteria, this qualifies as **High Severity** under "Validator node slowdowns" and "API crashes" - though a complete crash is more severe than a slowdown. The impact includes:

1. **Availability Impact**: Affected validator nodes cannot restart and participate in consensus
2. **Liveness Risk**: If multiple validators are affected, the network could face liveness issues
3. **Operational Risk**: Requires manual intervention to recover (database cleanup or restoration)

While this doesn't cause consensus safety violations (no chain splits or double-spending), it directly impacts network availability and validator reliability.

## Likelihood Explanation

**Likelihood: Medium-Low**

The vulnerability requires one of these conditions:
1. **Database corruption**: Bit flips, disk errors, or file system issues that corrupt the author field in persisted data
2. **Epoch transition edge cases**: Rare scenarios where data from an old validator set persists with the current epoch number
3. **Software bugs**: Other code paths that write invalid data to the database

The most likely scenario is database corruption or edge cases during epoch transitions where validator set changes occur. The vulnerability is deterministic once triggered - any node with corrupted data will consistently panic on startup.

## Recommendation

Add validation in `AugDataStore::new()` to verify that all deserialized authors exist in the current validator set before using the data:

```rust
pub fn new(
    epoch: u64,
    signer: Arc<ValidatorSigner>,
    config: RandConfig,
    fast_config: Option<RandConfig>,
    db: Arc<dyn RandStorage<D>>,
) -> Self {
    let all_data = db.get_all_aug_data().unwrap_or_default();
    let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
    if let Err(e) = db.remove_aug_data(to_remove) {
        error!("[AugDataStore] failed to remove aug data: {:?}", e);
    }

    let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
    let (to_remove, certified_data) =
        Self::filter_by_epoch(epoch, all_certified_data.into_iter());
    if let Err(e) = db.remove_certified_aug_data(to_remove) {
        error!(
            "[AugDataStore] failed to remove certified aug data: {:?}",
            e
        );
    }

    // ADDED: Validate and filter out data with authors not in current validator set
    let certified_data = certified_data
        .into_iter()
        .filter(|(id, data)| {
            if config.validator.address_to_validator_index().contains_key(&id.author()) {
                true
            } else {
                error!(
                    "[AugDataStore] Removing certified data with invalid author {} for epoch {}",
                    id.author(), epoch
                );
                // Attempt to remove from DB
                if let Err(e) = db.remove_certified_aug_data(vec![data.clone()]) {
                    error!("[AugDataStore] Failed to remove invalid certified data: {:?}", e);
                }
                false
            }
        })
        .collect::<Vec<_>>();

    for (_, certified_data) in &certified_data {
        certified_data
            .data()
            .augment(&config, &fast_config, certified_data.author());
    }

    Self {
        epoch,
        signer,
        config,
        fast_config,
        data: aug_data
            .into_iter()
            .map(|(id, data)| (id.author(), data))
            .collect(),
        certified_data: certified_data
            .into_iter()
            .map(|(id, data)| (id.author(), data))
            .collect(),
        db,
    }
}
```

Additionally, change the `.expect()` calls in `get_id()` to return proper errors instead of panicking, and handle these errors gracefully at call sites.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_types::validator_verifier::ValidatorVerifier;
    use std::collections::HashMap;

    #[test]
    #[should_panic(expected = "Peer should be in the index!")]
    fn test_invalid_author_causes_panic() {
        // Setup: Create a RandConfig with a specific validator set
        let validator_set = vec![/* valid validators */];
        let config = RandConfig::new(/* ... */);
        
        // Create RandDb and manually insert CertifiedAugData with invalid author
        let db = Arc::new(RandDb::new(test_db_path));
        
        // Create certified data with an author NOT in the validator set
        let invalid_author = Author::random();
        let malicious_data = CertifiedAugData::new(
            AugData::new(1, invalid_author, AugmentedData { 
                delta: Delta::default(),
                fast_delta: None 
            }),
            AggregateSignature::empty()
        );
        
        // Save it to database
        db.save_certified_aug_data(&malicious_data).unwrap();
        
        // This should panic when trying to use the data
        let store = AugDataStore::new(1, signer, config, None, db);
    }
}
```

## Notes

The core issue is insufficient validation of persistent state during startup. The database is treated as a trusted source, but corruption or edge cases can lead to inconsistent state that causes panics. The fix should validate all deserialized data against current epoch configuration before use, with graceful error handling rather than panics.

### Citations

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L28-42)
```rust
    fn filter_by_epoch<T>(
        epoch: u64,
        all_data: impl Iterator<Item = (AugDataId, T)>,
    ) -> (Vec<T>, Vec<(AugDataId, T)>) {
        let mut to_remove = vec![];
        let mut to_keep = vec![];
        for (id, data) in all_data {
            if id.epoch() != epoch {
                to_remove.push(data)
            } else {
                to_keep.push((id, data))
            }
        }
        (to_remove, to_keep)
    }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L57-71)
```rust
        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }

        for (_, certified_data) in &certified_data {
            certified_data
                .data()
                .augment(&config, &fast_config, certified_data.author());
        }
```

**File:** consensus/src/rand/rand_gen/types.rs (L630-636)
```rust
    pub fn get_id(&self, peer: &Author) -> usize {
        *self
            .validator
            .address_to_validator_index()
            .get(peer)
            .expect("Peer should be in the index!")
    }
```
