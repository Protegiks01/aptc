# Audit Report

## Title
State Inconsistency via Pruner Error Masking Leading to Merkle Tree Corruption

## Summary
The pruner worker's error handling masks pruner failures, allowing `StateKvPruner` and `StateMerklePruner` to diverge in their `min_readable_version` values. This creates windows where Merkle proofs reference pruned state values or vice versa, breaking state consistency guarantees and causing state sync failures.

## Finding Description

The vulnerability exists in the pruner worker's error handling mechanism. When a pruner fails, the error is logged but execution continues, allowing independent pruner workers to drift out of sync. [1](#0-0) 

Each pruner (`StateKvPruner` and `StateMerklePruner`) maintains separate `min_readable_version` tracking through independent `PrunerManager` instances: [2](#0-1) 

Within each pruner, a critical two-phase operation occurs: metadata pruning followed by shard pruning. For `StateKvPruner`: [3](#0-2) 

The metadata pruner atomically updates progress to the database: [4](#0-3) 

**Critical Flow Analysis:**

1. If metadata pruning succeeds (updating DB progress to version Y) but shard pruning fails (lines 68-78), the error propagates up
2. Error is caught in `pruner_worker.rs` and logged, but execution continues
3. In-memory progress is NOT updated (line 81 never executes)
4. Next iteration attempts to prune from old in-memory progress, but metadata DB already shows new progress

More critically, `StateKvPruner` and `StateMerklePruner` run as independent workers with separate target versions and failure modes. Validation checks use separate `min_readable_version` values: [5](#0-4) 

**Exploitation Scenario:**

If `StateKvPruner` advances to version 1000 while `StateMerklePruner` repeatedly fails and stays at version 500:
- State values from versions 500-999 are pruned (deleted from StateKvDb)
- Merkle nodes for versions 500-999 still exist (not pruned from StateMerkleDb)

When `get_state_value_with_proof_by_version_ext` is called for version 750: [6](#0-5) 

The check passes (750 >= 500) and retrieves Merkle leaf data: [7](#0-6) 

At line 231, `expect_value_by_version` attempts to retrieve the state value: [8](#0-7) 

**This fails with `NotFound` because the state value was already pruned**, breaking the invariant that versions >= `min_readable_version` should be fully accessible with proofs.

## Impact Explanation

**Severity: HIGH** (per Aptos bug bounty criteria)

This vulnerability causes:

1. **State Sync Failures**: Nodes attempting to sync state cannot obtain valid state proofs for versions in the divergence window, preventing network synchronization
2. **API Crashes**: RPC queries for `get_state_value_with_proof` fail unexpectedly for supposedly available versions
3. **Consensus Invariant Violation**: Breaks "State Consistency: State transitions must be atomic and verifiable via Merkle proofs"
4. **Database Corruption**: Merkle tree structure references non-existent state values, creating logical corruption

This qualifies as **Significant protocol violations** and **API crashes** under High Severity criteria.

## Likelihood Explanation

**Likelihood: MEDIUM**

While the error masking is guaranteed to occur when pruners fail, the exploitation requires:

1. **Asymmetric Failures**: One pruner must fail repeatedly while the other succeeds. This can occur due to:
   - Different storage backend issues (if StateMerkleDb and StateKvDb use different disks)
   - Shard-specific corruption affecting only one pruner
   - Resource exhaustion affecting one database more than the other

2. **Sustained Failures**: The divergence accumulates over multiple pruning cycles (hours to days depending on prune window)

3. **Natural Occurrence**: In production environments with storage issues, this divergence is inevitable given the current error handling

An attacker could accelerate this through storage exhaustion attacks targeting one database, though this is not strictly necessaryâ€”the bug manifests naturally under operational stress.

## Recommendation

Implement coordinated pruning with atomic progress tracking:

```rust
// In pruner_worker.rs, modify work() to halt on errors:
fn work(&self) {
    while !self.quit_worker.load(Ordering::SeqCst) {
        let pruner_result = self.pruner.prune(self.batch_size);
        if pruner_result.is_err() {
            error!(error = ?pruner_result.err().unwrap(), 
                "Pruner has error, halting pruning until resolved.");
            // Sleep longer and retry, don't mask the error
            sleep(Duration::from_secs(60));
            continue;
        }
        // ... rest of logic
    }
}
```

Additionally, add cross-pruner synchronization checks in `PrunerManager`:

```rust
// Before setting target version, verify all pruners are synchronized
pub fn verify_pruner_sync(&self) -> Result<()> {
    let state_kv_min = self.state_kv_pruner.get_min_readable_version();
    let state_merkle_min = self.state_merkle_pruner.get_min_readable_version();
    
    ensure!(
        state_kv_min.abs_diff(state_merkle_min) < MAX_PRUNER_DIVERGENCE,
        "Pruners out of sync: state_kv={}, state_merkle={}",
        state_kv_min, state_merkle_min
    );
    Ok(())
}
```

Within each pruner, make metadata and shard progress updates atomic by deferring metadata progress write until after shard completion.

## Proof of Concept

```rust
// Rust reproduction test for storage/aptosdb/src/pruner/test.rs
#[test]
fn test_pruner_divergence_corruption() {
    // Setup: Initialize AptosDB with two pruners
    let db = setup_test_db();
    
    // Commit state up to version 1000
    for v in 0..1000 {
        commit_test_state(&db, v);
    }
    
    // Enable pruning with window of 100 versions
    db.state_kv_pruner.set_target_version(900); // Prune up to 900
    db.state_merkle_pruner.set_target_version(900);
    
    // Simulate StateKvPruner success, StateMerklePruner failure
    // by injecting error into StateMerklePruner's shard pruning
    inject_pruner_error(&db.state_merkle_pruner);
    
    // Run pruning cycles
    for _ in 0..10 {
        db.state_kv_pruner.prune(100).unwrap(); // Succeeds
        let _ = db.state_merkle_pruner.prune(100); // Fails, error masked
    }
    
    // Verify divergence
    let state_kv_min = db.state_kv_pruner.get_min_readable_version();
    let state_merkle_min = db.state_merkle_pruner.get_min_readable_version();
    assert!(state_kv_min > state_merkle_min); // Divergence detected
    
    // Attempt to get state with proof in divergence window
    let version_in_gap = (state_merkle_min + state_kv_min) / 2;
    let key_hash = HashValue::random();
    
    // This should fail: Merkle proof exists but state value is pruned
    let result = db.get_state_value_with_proof_by_version_ext(
        &key_hash, 
        version_in_gap, 
        0, 
        false
    );
    
    // Expect NotFound error despite passing min_readable check
    assert!(result.is_err());
    assert!(matches!(result.unwrap_err(), AptosDbError::NotFound(_)));
}
```

## Notes

The vulnerability manifests when pruners experience asymmetric failure rates due to storage backend issues, resource contention, or corruption. The error masking in `pruner_worker.rs` allows silent divergence between independent pruner workers, violating the fundamental assumption that state values and their Merkle proofs remain synchronized. This breaks state sync operations and API guarantees, constituting a High severity protocol violation.

### Citations

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L53-69)
```rust
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L60-77)
```rust
        let state_merkle_pruner = StateMerklePrunerManager::new(
            Arc::clone(&state_merkle_db),
            pruner_config.state_merkle_pruner_config,
        );
        let epoch_snapshot_pruner = StateMerklePrunerManager::new(
            Arc::clone(&state_merkle_db),
            pruner_config.epoch_snapshot_pruner_config.into(),
        );
        let state_kv_pruner =
            StateKvPrunerManager::new(Arc::clone(&state_kv_db), pruner_config.ledger_pruner_config);
        let state_store = Arc::new(StateStore::new(
            Arc::clone(&ledger_db),
            hot_state_merkle_db,
            Arc::clone(&state_merkle_db),
            Arc::clone(&state_kv_db),
            state_merkle_pruner,
            epoch_snapshot_pruner,
            state_kv_pruner,
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L273-315)
```rust
    pub(super) fn error_if_state_merkle_pruned(
        &self,
        data_type: &str,
        version: Version,
    ) -> Result<()> {
        let min_readable_version = self
            .state_store
            .state_db
            .state_merkle_pruner
            .get_min_readable_version();
        if version >= min_readable_version {
            return Ok(());
        }

        let min_readable_epoch_snapshot_version = self
            .state_store
            .state_db
            .epoch_snapshot_pruner
            .get_min_readable_version();
        if version >= min_readable_epoch_snapshot_version {
            self.ledger_db.metadata_db().ensure_epoch_ending(version)
        } else {
            bail!(
                "{} at version {} is pruned. snapshots are available at >= {}, epoch snapshots are available at >= {}",
                data_type,
                version,
                min_readable_version,
                min_readable_epoch_snapshot_version,
            )
        }
    }

    pub(super) fn error_if_state_kv_pruned(&self, data_type: &str, version: Version) -> Result<()> {
        let min_readable_version = self.state_store.state_kv_pruner.get_min_readable_version();
        ensure!(
            version >= min_readable_version,
            "{} at version {} is pruned, min available version is {}.",
            data_type,
            version,
            min_readable_version
        );
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L49-86)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_pruner__prune"]);

        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning state kv data."
            );
            self.metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.shard_pruners.par_iter().try_for_each(|shard_pruner| {
                    shard_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| {
                            anyhow!(
                                "Failed to prune state kv shard {}: {err}",
                                shard_pruner.shard_id(),
                            )
                        })
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning state kv data is done.");
        }

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L67-72)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        self.state_kv_db.metadata_db().write_schemas(batch)
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L677-693)
```rust
    fn get_state_value_with_proof_by_version_ext(
        &self,
        key_hash: &HashValue,
        version: Version,
        root_depth: usize,
        use_hot_state: bool,
    ) -> Result<(Option<StateValue>, SparseMerkleProofExt)> {
        gauged_api("get_state_value_with_proof_by_version_ext", || {
            self.error_if_state_merkle_pruned("State merkle", version)?;

            self.state_store.get_state_value_with_proof_by_version_ext(
                key_hash,
                version,
                root_depth,
                use_hot_state,
            )
        })
```

**File:** storage/aptosdb/src/state_store/mod.rs (L208-236)
```rust
    /// Get the state value with proof given the state key and version
    fn get_state_value_with_proof_by_version_ext(
        &self,
        key_hash: &HashValue,
        version: Version,
        root_depth: usize,
        use_hot_state: bool,
    ) -> Result<(Option<StateValue>, SparseMerkleProofExt)> {
        let db = if use_hot_state {
            if self.state_merkle_db.sharding_enabled() {
                self.hot_state_merkle_db
                    .as_ref()
                    .ok_or(AptosDbError::HotStateError)?
            } else {
                // Unsharded unit tests still rely on this.
                &self.state_merkle_db
            }
        } else {
            &self.state_merkle_db
        };
        let (leaf_data, proof) = db.get_with_proof_ext(key_hash, version, root_depth)?;
        Ok((
            match leaf_data {
                Some((_val_hash, (key, ver))) => Some(self.expect_value_by_version(&key, ver)?),
                None => None,
            },
            proof,
        ))
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L320-330)
```rust
    fn expect_value_by_version(
        &self,
        state_key: &StateKey,
        version: Version,
    ) -> Result<StateValue> {
        self.get_state_value_by_version(state_key, version)
            .and_then(|opt| {
                opt.ok_or_else(|| {
                    AptosDbError::NotFound(format!(
                        "State Value is missing for key {:?} by version {}",
                        state_key, version
```
