# Audit Report

## Title
Expired Transactions Waste Network Resources During Mempool Broadcast

## Summary
The mempool broadcasts transactions to peers without checking if they have expired, causing peers to waste CPU and bandwidth validating transactions that will inevitably fail the expiration check in the Move prologue.

## Finding Description

Transaction expiration timestamps are encoded in the BCS-serialized `SignedTransaction` payload and validated during VM prologue execution. However, there is a timing gap where transactions that were valid when added to mempool can expire before being broadcast to peers.

**Attack Flow:**

1. Attacker submits a transaction with `expiration_timestamp_secs = current_time + 1 second`
2. Transaction passes initial validation in `validate_transaction()` which executes the Move prologue checking `timestamp::now_seconds() < txn_expiration_time` [1](#0-0) 
3. Transaction is added to mempool
4. Transaction sits in mempool for >1 second and becomes expired
5. The `determine_broadcast_batch()` function selects expired transactions from mempool timeline for broadcast WITHOUT any expiration check [2](#0-1) 
6. Expired transactions are sent over the network to peers [3](#0-2) 
7. Each receiving peer performs full validation including:
   - Signature verification (CPU intensive)
   - Database state reads for sequence numbers [4](#0-3) 
   - VM prologue execution with gas metering [5](#0-4) 
8. Only after all validation does the prologue fail with `PROLOGUE_ETRANSACTION_EXPIRED` [6](#0-5) 

**Root Cause:**

While `gc_by_expiration_time()` exists to remove expired transactions [7](#0-6) , it is only called when consensus requests a batch [8](#0-7)  or when processing committed transactions [9](#0-8) . It is NOT called before peer broadcasts, allowing expired transactions to propagate.

## Impact Explanation

This is **Low Severity** per Aptos bug bounty criteria as it causes:
- Wasted network bandwidth propagating expired transactions
- Wasted CPU on peer nodes performing signature verification and VM validation
- Minor resource exhaustion without consensus, safety, or fund impact

The issue is limited because:
- Each peer validates only once per transaction
- No transaction commits or state changes occur
- No consensus safety violation
- No fund loss or availability impact

## Likelihood Explanation

**High likelihood** of occurrence:
- Any user can submit transactions with short expiration times
- Network delays naturally cause propagation lag
- Periodic broadcasts happen every `shared_mempool_tick_interval_ms` without expiration checks
- No special privileges or complex setup required

## Recommendation

Call `gc_by_expiration_time()` before broadcasting transactions to peers. Add expiration cleanup in `execute_broadcast()`:

```rust
// In mempool/src/shared_mempool/network.rs, execute_broadcast():
pub async fn execute_broadcast<TransactionValidator: TransactionValidation>(
    &self,
    peer: PeerNetworkId,
    backoff: bool,
    smp: &mut SharedMempool<NetworkClient, TransactionValidator>,
    scheduled_broadcasts: &mut FuturesUnordered<ScheduledBroadcast>,
    executor: Handle,
) {
    // Add expiration GC before determining broadcast batch
    let curr_time = aptos_infallible::duration_since_epoch();
    smp.mempool.lock().gc_by_expiration_time(curr_time);
    
    // Continue with existing broadcast logic...
}
```

## Proof of Concept

```rust
// Add to mempool/src/tests/shared_mempool_test.rs
#[tokio::test]
async fn test_expired_transaction_broadcast() {
    use std::time::Duration;
    
    // Setup two-node mempool network
    let (mut node1, mut node2) = setup_two_node_network();
    
    // Create transaction expiring in 1 second
    let txn = create_signed_transaction(
        /* expiration */ SystemTime::now() + Duration::from_secs(1)
    );
    
    // Submit to node1 - passes validation
    node1.submit_transaction(txn.clone()).await.unwrap();
    assert!(node1.mempool.lock().get_by_hash(txn.committed_hash()).is_some());
    
    // Wait for expiration
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // Trigger broadcast to node2
    node1.broadcast_to_peer(node2.peer_id()).await;
    
    // Verify node2 received and validated the expired transaction
    // (wasting resources), then rejected it
    assert!(node2.mempool.lock().get_by_hash(txn.committed_hash()).is_none());
    
    // Check metrics show validation occurred
    let validation_count = counters::TRANSACTIONS_VALIDATED.get();
    assert!(validation_count > 0, "Transaction was validated despite being expired");
}
```

## Notes

- The `bcs_payload.rs` file mentioned in the question is just a wrapper for BCS bytes and doesn't contain validation logic [10](#0-9) 
- Transaction expiration is stored in the `SignedTransaction` structure itself via `expiration_timestamp_secs()` field [11](#0-10) 
- The vulnerability exists because broadcast scheduling is time-based rather than transaction-validity-based
- Attackers cannot manipulate the blockchain timestamp itself, only their transaction's expiration field

### Citations

**File:** aptos-move/framework/aptos-framework/sources/transaction_validation.move (L139-142)
```text
        assert!(
            timestamp::now_seconds() < txn_expiration_time,
            error::invalid_argument(PROLOGUE_ETRANSACTION_EXPIRED),
        );
```

**File:** mempool/src/shared_mempool/network.rs (L370-570)
```rust
    fn determine_broadcast_batch<TransactionValidator: TransactionValidation>(
        &self,
        peer: PeerNetworkId,
        scheduled_backoff: bool,
        smp: &mut SharedMempool<NetworkClient, TransactionValidator>,
    ) -> Result<
        (
            MempoolMessageId,
            Vec<(SignedTransaction, u64, BroadcastPeerPriority)>,
            Option<&str>,
        ),
        BroadcastError,
    > {
        let mut sync_states = self.sync_states.write();
        // If we don't have any info about the node, we shouldn't broadcast to it
        let state = sync_states
            .get_mut(&peer)
            .ok_or_else(|| BroadcastError::PeerNotFound(peer))?;

        // If backoff mode is on for this peer, only execute broadcasts that were scheduled as a backoff broadcast.
        // This is to ensure the backoff mode is actually honored (there is a chance a broadcast was scheduled
        // in non-backoff mode before backoff mode was turned on - ignore such scheduled broadcasts).
        if state.broadcast_info.backoff_mode && !scheduled_backoff {
            return Err(BroadcastError::PeerNotScheduled(peer));
        }

        // Sync peer's pending broadcasts with latest mempool state.
        // A pending or retry broadcast might become empty if the corresponding txns were committed through
        // another peer, so don't track broadcasts for committed txns.
        let mempool = smp.mempool.lock();
        state.broadcast_info.sent_messages = state
            .broadcast_info
            .sent_messages
            .clone()
            .into_iter()
            .filter(|(message_id, _batch)| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeMap<MempoolMessageId, SystemTime>>();
        state.broadcast_info.retry_messages = state
            .broadcast_info
            .retry_messages
            .clone()
            .into_iter()
            .filter(|message_id| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeSet<MempoolMessageId>>();

        // Check for batch to rebroadcast:
        // 1. Batch that did not receive ACK in configured window of time
        // 2. Batch that an earlier ACK marked as retriable
        let mut pending_broadcasts = 0;
        let mut expired_message_id = None;

        // Find earliest message in timeline index that expired.
        // Note that state.broadcast_info.sent_messages is ordered in decreasing order in the timeline index
        for (message, sent_time) in state.broadcast_info.sent_messages.iter() {
            let deadline = sent_time.add(Duration::from_millis(
                self.mempool_config.shared_mempool_ack_timeout_ms,
            ));
            if SystemTime::now().duration_since(deadline).is_ok() {
                expired_message_id = Some(message);
            } else {
                pending_broadcasts += 1;
            }

            // The maximum number of broadcasts sent to a single peer that are pending a response ACK at any point.
            // If the number of un-ACK'ed un-expired broadcasts reaches this threshold, we do not broadcast anymore
            // and wait until an ACK is received or a sent broadcast expires.
            // This helps rate-limit egress network bandwidth and not overload a remote peer or this
            // node's network sender.
            if pending_broadcasts >= self.mempool_config.max_broadcasts_per_peer {
                return Err(BroadcastError::TooManyPendingBroadcasts(peer));
            }
        }
        let retry_message_id = state.broadcast_info.retry_messages.iter().next_back();

        let (message_id, transactions, metric_label) =
            match std::cmp::max(expired_message_id, retry_message_id) {
                Some(message_id) => {
                    let metric_label = if Some(message_id) == expired_message_id {
                        Some(counters::EXPIRED_BROADCAST_LABEL)
                    } else {
                        Some(counters::RETRY_BROADCAST_LABEL)
                    };

                    let txns = message_id
                        .decode()
                        .into_iter()
                        .flat_map(|(sender_bucket, start_end_pairs)| {
                            if self.node_type.is_validator() {
                                mempool
                                    .timeline_range(sender_bucket, start_end_pairs)
                                    .into_iter()
                                    .map(|(txn, ready_time)| {
                                        (txn, ready_time, BroadcastPeerPriority::Primary)
                                    })
                                    .collect::<Vec<_>>()
                            } else {
                                self.prioritized_peers_state
                                    .get_sender_bucket_priority_for_peer(&peer, sender_bucket)
                                    .map_or_else(Vec::new, |priority| {
                                        mempool
                                            .timeline_range(sender_bucket, start_end_pairs)
                                            .into_iter()
                                            .map(|(txn, ready_time)| {
                                                (txn, ready_time, priority.clone())
                                            })
                                            .collect::<Vec<_>>()
                                    })
                            }
                        })
                        .collect::<Vec<_>>();
                    (message_id.clone(), txns, metric_label)
                },
                None => {
                    // Fresh broadcast

                    // If the peer doesn't have any sender_buckets assigned, let's not broadcast to the peer
                    let mut sender_buckets: Vec<(MempoolSenderBucket, BroadcastPeerPriority)> =
                        if self.node_type.is_validator() {
                            (0..self.mempool_config.num_sender_buckets)
                                .map(|sender_bucket| {
                                    (sender_bucket, BroadcastPeerPriority::Primary)
                                })
                                .collect()
                        } else {
                            self.prioritized_peers_state
                                .get_sender_buckets_for_peer(&peer)
                                .ok_or_else(|| {
                                    BroadcastError::PeerNotPrioritized(
                                        peer,
                                        self.prioritized_peers_state.get_peer_priority(&peer),
                                    )
                                })?
                                .clone()
                                .into_iter()
                                .collect()
                        };
                    // Sort sender_buckets based on priority. Primary peer should be first.
                    sender_buckets.sort_by(|(_, priority_a), (_, priority_b)| {
                        if priority_a == priority_b {
                            std::cmp::Ordering::Equal
                        } else if *priority_a == BroadcastPeerPriority::Primary {
                            std::cmp::Ordering::Less
                        } else {
                            std::cmp::Ordering::Greater
                        }
                    });
                    let max_txns = self.mempool_config.shared_mempool_batch_size;
                    let mut output_txns = vec![];
                    let mut output_updates = vec![];
                    for (sender_bucket, peer_priority) in sender_buckets {
                        let before = match peer_priority {
                            BroadcastPeerPriority::Primary => None,
                            BroadcastPeerPriority::Failover => Some(
                                Instant::now()
                                    - Duration::from_millis(
                                        self.mempool_config.shared_mempool_failover_delay_ms,
                                    ),
                            ),
                        };
                        if max_txns > 0 {
                            let old_timeline_id = state.timelines.get(&sender_bucket).unwrap();
                            let (txns, new_timeline_id) = mempool.read_timeline(
                                sender_bucket,
                                old_timeline_id,
                                max_txns,
                                before,
                                peer_priority.clone(),
                            );
                            output_txns.extend(
                                txns.into_iter()
                                    .map(|(txn, ready_time)| {
                                        (txn, ready_time, peer_priority.clone())
                                    })
                                    .collect::<Vec<_>>(),
                            );
                            output_updates
                                .push((sender_bucket, (old_timeline_id.clone(), new_timeline_id)));
                        }
                    }
                    (
                        MempoolMessageId::from_timeline_ids(output_updates),
                        output_txns,
                        None,
                    )
                },
            };

        if transactions.is_empty() {
            return Err(BroadcastError::NoTransactions(peer));
        }

        Ok((message_id, transactions, metric_label))
    }
```

**File:** mempool/src/shared_mempool/network.rs (L636-678)
```rust
    pub async fn execute_broadcast<TransactionValidator: TransactionValidation>(
        &self,
        peer: PeerNetworkId,
        scheduled_backoff: bool,
        smp: &mut SharedMempool<NetworkClient, TransactionValidator>,
    ) -> Result<(), BroadcastError> {
        // Start timer for tracking broadcast latency.
        let start_time = Instant::now();
        let (message_id, transactions, metric_label) =
            self.determine_broadcast_batch(peer, scheduled_backoff, smp)?;
        let num_txns = transactions.len();
        let send_time = SystemTime::now();
        self.send_batch_to_peer(peer, message_id.clone(), transactions)
            .await?;
        let num_pending_broadcasts =
            self.update_broadcast_state(peer, message_id.clone(), send_time)?;
        notify_subscribers(SharedMempoolNotification::Broadcast, &smp.subscribers);

        // Log all the metrics
        let latency = start_time.elapsed();
        trace!(
            LogSchema::event_log(LogEntry::BroadcastTransaction, LogEvent::Success)
                .peer(&peer)
                .message_id(&message_id)
                .backpressure(scheduled_backoff)
                .num_txns(num_txns)
        );
        let network_id = peer.network_id();
        counters::shared_mempool_broadcast_size(network_id, num_txns);
        // TODO: Rethink if this metric is useful
        counters::shared_mempool_pending_broadcasts(&peer).set(num_pending_broadcasts as i64);
        counters::shared_mempool_broadcast_latency(network_id, latency);
        if let Some(label) = metric_label {
            counters::shared_mempool_broadcast_type_inc(network_id, label);
        }
        if scheduled_backoff {
            counters::shared_mempool_broadcast_type_inc(
                network_id,
                counters::BACKPRESSURE_BROADCAST_LABEL,
            );
        }
        Ok(())
    }
```

**File:** mempool/src/shared_mempool/tasks.rs (L335-350)
```rust
    let account_seq_numbers = IO_POOL.install(|| {
        transactions
            .par_iter()
            .map(|(t, _, _)| match t.replay_protector() {
                ReplayProtector::Nonce(_) => Ok(None),
                ReplayProtector::SequenceNumber(_) => {
                    get_account_sequence_number(&state_view, t.sender())
                        .map(Some)
                        .inspect_err(|e| {
                            error!(LogSchema::new(LogEntry::DBError).error(e));
                            counters::DB_ERROR.inc();
                        })
                },
            })
            .collect::<Vec<_>>()
    });
```

**File:** mempool/src/shared_mempool/tasks.rs (L486-503)
```rust
    // Track latency: VM validation
    let vm_validation_timer = counters::PROCESS_TXN_BREAKDOWN_LATENCY
        .with_label_values(&[counters::VM_VALIDATION_LABEL])
        .start_timer();
    let validation_results = VALIDATION_POOL.install(|| {
        transactions
            .par_iter()
            .map(|t| {
                let result = smp.validator.read().validate_transaction(t.0.clone());
                // Pre-compute the hash and length if the transaction is valid, before locking mempool
                if result.is_ok() {
                    t.0.committed_hash();
                    t.0.txn_bytes_len();
                }
                result
            })
            .collect::<Vec<_>>()
    });
```

**File:** mempool/src/shared_mempool/tasks.rs (L665-665)
```rust
                    mempool.gc_by_expiration_time(curr_time);
```

**File:** mempool/src/shared_mempool/tasks.rs (L741-741)
```rust
        pool.gc_by_expiration_time(block_timestamp);
```

**File:** aptos-move/aptos-vm/src/transaction_validation.rs (L107-245)
```rust
pub(crate) fn run_script_prologue(
    session: &mut SessionExt<impl AptosMoveResolver>,
    module_storage: &impl ModuleStorage,
    serialized_signers: &SerializedSigners,
    txn_data: &TransactionMetadata,
    features: &Features,
    log_context: &AdapterLogSchema,
    traversal_context: &mut TraversalContext,
    is_simulation: bool,
) -> Result<(), VMStatus> {
    let txn_replay_protector = txn_data.replay_protector();
    let txn_authentication_key = txn_data.authentication_proof().optional_auth_key();
    let txn_gas_price = txn_data.gas_unit_price();
    let txn_max_gas_units = txn_data.max_gas_amount();
    let txn_expiration_timestamp_secs = txn_data.expiration_timestamp_secs();
    let chain_id = txn_data.chain_id();
    let mut gas_meter = UnmeteredGasMeter;

    // Use the new prologues that takes signer from both sender and optional gas payer
    if features.is_account_abstraction_enabled()
        || features.is_derivable_account_abstraction_enabled()
    {
        let secondary_auth_keys: Vec<MoveValue> = txn_data
            .secondary_authentication_proofs
            .iter()
            .map(|auth_key| auth_key.optional_auth_key().as_move_value())
            .collect();
        let replay_protector_move_value = if features.is_transaction_payload_v2_enabled() {
            txn_replay_protector
                .to_move_value()
                .simple_serialize()
                .unwrap()
        } else {
            match txn_replay_protector {
                ReplayProtector::SequenceNumber(seq_num) => {
                    MoveValue::U64(seq_num).simple_serialize().unwrap()
                },
                ReplayProtector::Nonce(_) => {
                    unreachable!("Orderless transactions are discarded already")
                },
            }
        };

        let (prologue_function_name, serialized_args) =
            if let (Some(_fee_payer), Some(fee_payer_auth_key)) = (
                txn_data.fee_payer(),
                txn_data
                    .fee_payer_authentication_proof
                    .as_ref()
                    .map(|proof| proof.optional_auth_key()),
            ) {
                let serialized_args = vec![
                    serialized_signers.sender(),
                    serialized_signers
                        .fee_payer()
                        .ok_or_else(|| VMStatus::error(StatusCode::UNREACHABLE, None))?,
                    txn_authentication_key
                        .as_move_value()
                        .simple_serialize()
                        .unwrap(),
                    fee_payer_auth_key
                        .as_move_value()
                        .simple_serialize()
                        .unwrap(),
                    replay_protector_move_value,
                    MoveValue::vector_address(txn_data.secondary_signers())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::Vector(secondary_auth_keys)
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_gas_price.into())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_max_gas_units.into())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_expiration_timestamp_secs)
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U8(chain_id.id()).simple_serialize().unwrap(),
                    MoveValue::Bool(is_simulation).simple_serialize().unwrap(),
                ];
                (
                    if features.is_transaction_payload_v2_enabled() {
                        &APTOS_TRANSACTION_VALIDATION.unified_prologue_fee_payer_v2_name
                    } else {
                        &APTOS_TRANSACTION_VALIDATION.unified_prologue_fee_payer_name
                    },
                    serialized_args,
                )
            } else {
                let serialized_args = vec![
                    serialized_signers.sender(),
                    txn_authentication_key
                        .as_move_value()
                        .simple_serialize()
                        .unwrap(),
                    replay_protector_move_value,
                    MoveValue::vector_address(txn_data.secondary_signers())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::Vector(secondary_auth_keys)
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_gas_price.into())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_max_gas_units.into())
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U64(txn_expiration_timestamp_secs)
                        .simple_serialize()
                        .unwrap(),
                    MoveValue::U8(chain_id.id()).simple_serialize().unwrap(),
                    MoveValue::Bool(is_simulation).simple_serialize().unwrap(),
                ];
                (
                    if features.is_transaction_payload_v2_enabled() {
                        &APTOS_TRANSACTION_VALIDATION.unified_prologue_v2_name
                    } else {
                        &APTOS_TRANSACTION_VALIDATION.unified_prologue_name
                    },
                    serialized_args,
                )
            };
        session
            .execute_function_bypass_visibility(
                &APTOS_TRANSACTION_VALIDATION.module_id(),
                prologue_function_name,
                vec![],
                serialized_args,
                &mut gas_meter,
                traversal_context,
                module_storage,
            )
            .map(|_return_vals| ())
            .map_err(expect_no_verification_errors)
            .or_else(|err| convert_prologue_error(err, log_context))
```

**File:** mempool/src/core_mempool/transaction_store.rs (L119-121)
```rust
            expiration_time_index: TTLIndex::new(Box::new(|t: &MempoolTransaction| {
                Duration::from_secs(t.txn.expiration_timestamp_secs())
            })),
```

**File:** mempool/src/core_mempool/transaction_store.rs (L909-911)
```rust
    pub(crate) fn gc_by_expiration_time(&mut self, block_time: Duration) {
        self.gc(self.eager_expire_time(block_time), false);
    }
```

**File:** api/src/bcs_payload.rs (L1-89)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! This module defines a Poem payload type for BCS. JSON is already natively
//! supported. This type just helps with representing BCS bytes in the spec.

// Previously the Bcs payload type took a T, not Vec<u8>. For more information
// about that effort, see https://github.com/aptos-labs/aptos-core/issues/2277.

use aptos_api_types::mime_types::BCS;
use poem::{http::header, FromRequest, IntoResponse, Request, RequestBody, Response, Result};
use poem_openapi::{
    impl_apirequest_for_payload,
    payload::{ParsePayload, Payload},
    registry::{MetaMediaType, MetaResponse, MetaResponses, MetaSchemaRef, Registry},
    types::Type,
    ApiResponse,
};
use std::ops::{Deref, DerefMut};

/// A wrapper struct for a payload containing BCS encoded bytes
#[derive(Debug, Clone, Eq, PartialEq)]
pub struct Bcs(pub Vec<u8>);

impl Deref for Bcs {
    type Target = Vec<u8>;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl DerefMut for Bcs {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.0
    }
}

impl Payload for Bcs {
    const CONTENT_TYPE: &'static str = BCS;

    fn schema_ref() -> MetaSchemaRef {
        Vec::<u8>::schema_ref()
    }

    #[allow(unused_variables)]
    fn register(registry: &mut Registry) {
        Vec::<u8>::register(registry);
    }
}

impl ParsePayload for Bcs {
    const IS_REQUIRED: bool = true;

    async fn from_request(request: &Request, body: &mut RequestBody) -> Result<Self> {
        let data = Vec::<u8>::from_request(request, body).await?;
        Ok(Self(data))
    }
}

impl IntoResponse for Bcs {
    fn into_response(self) -> Response {
        Response::builder()
            .header(header::CONTENT_TYPE, Self::CONTENT_TYPE)
            .body(self.0)
    }
}

impl ApiResponse for Bcs {
    fn meta() -> MetaResponses {
        MetaResponses {
            responses: vec![MetaResponse {
                description: "BCS: Binary Canonical Serialization",
                status: Some(200),
                content: vec![MetaMediaType {
                    content_type: Self::CONTENT_TYPE,
                    schema: Self::schema_ref(),
                }],
                headers: vec![],
            }],
        }
    }

    fn register(registry: &mut Registry) {
        Vec::<u8>::register(registry);
    }
}

impl_apirequest_for_payload!(Bcs);
```
