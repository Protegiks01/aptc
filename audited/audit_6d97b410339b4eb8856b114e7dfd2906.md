# Audit Report

## Title
Off-By-One Error in TableItemRequest Type Recursion Validation Allows Types That Fail Serialization

## Summary
The `TableItemRequest` validation uses an incorrect comparison operator (`>` instead of `>=`) when checking recursion depth, allowing deeply nested types with 9 levels that bypass validation but later fail during TypeTag serialization. This creates an inconsistency between the API's type validation and Move's serialization limits.

## Finding Description
The `MoveType::verify()` function in `api/types/src/move_types.rs` implements recursion depth checking to prevent excessively nested types. However, it uses an incorrect comparison operator that allows one additional level of nesting beyond what the underlying Move type system can safely serialize. [1](#0-0) 

The verification check at line 692 uses `recursion_count > MAX_RECURSIVE_TYPES_ALLOWED`, which allows recursion counts from 0 to 8 (9 total levels). However, the Move core type serialization uses a different check: [2](#0-1) [3](#0-2) 

The serialization check at line 30 uses `*r >= MAX_TYPE_TAG_NESTING`, which only allows depths from 0 to 7 (8 total levels) in production code.

**Attack Path:**
1. Attacker crafts a `TableItemRequest` with `key_type` set to a deeply nested type: `vector<vector<vector<vector<vector<vector<vector<vector<u64>>>>>>>>`  (8 nested vectors)
2. The request is submitted to `/tables/{handle}/item` endpoint
3. `TableItemRequest::verify()` is called, which invokes `MoveType::verify(0)`
4. Verification passes because the deepest recursion_count reaches 8, and `8 > 8` evaluates to false
5. Later, when `MoveType` is converted to `TypeTag` and serialized with BCS, the serialization fails because depth reaches 8 and `8 >= 8` evaluates to true
6. This causes unexpected errors in request processing [4](#0-3) [5](#0-4) 

The Move core tests explicitly document this inconsistency: [6](#0-5) 

## Impact Explanation
This vulnerability qualifies as **High Severity** under the "API crashes" or "Significant protocol violations" category because:

1. **API Reliability**: The validation layer is supposed to prevent types that cannot be safely processed. By allowing types that later fail serialization, the API accepts malformed requests that cause processing errors.

2. **DoS Potential**: An attacker can flood the API with requests containing 9-level nested types. Each request passes initial validation but fails during processing, consuming resources without completing successfully.

3. **Invariant Violation**: This breaks the **Resource Limits** invariant (#9) which states "All operations must respect gas, storage, and computational limits." The validation is explicitly designed to enforce these limits but fails to do so correctly.

4. **Inconsistent Behavior**: The discrepancy between validation and serialization creates unpredictable behavior where validated input later fails, violating the principle of fail-fast validation.

## Likelihood Explanation
This vulnerability is **highly likely** to be exploitable:

1. **No Special Privileges Required**: Any user can send TableItemRequest to the public API
2. **Simple to Exploit**: Crafting the malicious input requires only constructing a nested type string
3. **Reliable Trigger**: The off-by-one error consistently allows exactly one extra level
4. **Wide Attack Surface**: Affects all table lookup endpoints accepting type parameters

## Recommendation
Fix the comparison operator in `MoveType::verify()` to match the serialization check:

```rust
// In api/types/src/move_types.rs, line 692
// BEFORE:
if recursion_count > MAX_RECURSIVE_TYPES_ALLOWED {

// AFTER:
if recursion_count >= MAX_RECURSIVE_TYPES_ALLOWED {
```

This ensures validation rejects types at the same depth limit that serialization enforces, maintaining consistency between validation and processing layers.

Additionally, consider adding integration tests that verify the limits match between API validation and Move serialization.

## Proof of Concept

```rust
#[test]
fn test_table_item_request_recursion_bypass() {
    use aptos_api_types::{MoveType, TableItemRequest, VerifyInput};
    use serde_json::json;

    // Construct a type with 8 nested vectors (9 total levels including base type)
    let mut nested_type = MoveType::U64;
    for _ in 0..8 {
        nested_type = MoveType::Vector {
            items: Box::new(nested_type),
        };
    }

    let request = TableItemRequest {
        key_type: nested_type.clone(),
        value_type: MoveType::U64,
        key: json!(0),
    };

    // Verification PASSES due to off-by-one error
    assert!(request.verify().is_ok(), "Verification should pass with 9 levels");

    // However, converting to TypeTag and serializing would FAIL
    use move_core_types::language_storage::TypeTag;
    use std::convert::TryInto;
    
    let type_tag: TypeTag = (&nested_type).try_into().unwrap();
    
    // BCS serialization will fail at depth 8
    let result = bcs::to_bytes(&type_tag);
    assert!(result.is_err(), "Serialization should fail at depth 8");
}
```

**Notes**
The vulnerability stems from an inconsistency between two independent checks that were intended to enforce the same limit. The comment at line 686-687 explicitly states the API constant should match Move's `safe_serialize::MAX_TYPE_TAG_NESTING`, but the different comparison operators (`>` vs `>=`) cause them to diverge by one level. This is a classic off-by-one error that undermines the defensive validation layer designed to protect the API from malformed inputs.

### Citations

**File:** api/types/src/move_types.rs (L686-698)
```rust
/// Maximum number of recursive types - Same as (non-public)
/// move_core_types::safe_serialize::MAX_TYPE_TAG_NESTING
pub const MAX_RECURSIVE_TYPES_ALLOWED: u8 = 8;

impl VerifyInputWithRecursion for MoveType {
    fn verify(&self, recursion_count: u8) -> anyhow::Result<()> {
        if recursion_count > MAX_RECURSIVE_TYPES_ALLOWED {
            bail!(
                "Move type {} has gone over the limit of recursive types {}",
                self,
                MAX_RECURSIVE_TYPES_ALLOWED
            );
        }
```

**File:** third_party/move/move-core/types/src/safe_serialize.rs (L11-11)
```rust
pub(crate) const MAX_TYPE_TAG_NESTING: u8 = 8;
```

**File:** third_party/move/move-core/types/src/safe_serialize.rs (L28-34)
```rust
    TYPE_TAG_DEPTH.with(|depth| {
        let mut r = depth.borrow_mut();
        if *r >= MAX_TYPE_TAG_NESTING_WHEN_SERIALIZING {
            return Err(S::Error::custom(
                "type tag nesting exceeded during serialization",
            ));
        }
```

**File:** api/types/src/table.rs (L18-23)
```rust
impl VerifyInput for TableItemRequest {
    fn verify(&self) -> anyhow::Result<()> {
        self.key_type.verify(0)?;
        self.value_type.verify(0)
    }
}
```

**File:** api/src/state.rs (L156-162)
```rust
        table_item_request
            .0
            .verify()
            .context("'table_item_request' invalid")
            .map_err(|err| {
                BasicErrorWith404::bad_request_with_code_no_info(err, AptosErrorCode::InvalidInput)
            })?;
```

**File:** third_party/move/move-core/types/src/language_storage.rs (L687-709)
```rust
    #[test]
    fn test_nested_type_tag_vector_serde() {
        let mut type_tags = vec![make_type_tag_struct(TypeTag::U8)];

        let limit = MAX_TYPE_TAG_NESTING;
        while type_tags.len() < limit.into() {
            type_tags.push(make_type_tag_vector(type_tags.last().unwrap().clone()));
        }

        // Note for this test serialize can handle one more nesting than deserialize
        // Both directions work
        let output = bcs::to_bytes(type_tags.last().unwrap()).unwrap();
        bcs::from_bytes::<TypeTag>(&output).unwrap();

        // One more, serialize passes, deserialize fails
        type_tags.push(make_type_tag_vector(type_tags.last().unwrap().clone()));
        let output = bcs::to_bytes(type_tags.last().unwrap()).unwrap();
        bcs::from_bytes::<TypeTag>(&output).unwrap_err();

        // One more and serialize fails
        type_tags.push(make_type_tag_vector(type_tags.last().unwrap().clone()));
        bcs::to_bytes(type_tags.last().unwrap()).unwrap_err();
    }
```
