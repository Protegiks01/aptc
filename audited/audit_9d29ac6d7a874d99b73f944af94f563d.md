# Audit Report

## Title
Memory Exhaustion Attack via Unbounded Witness Dimensions in DKG Sigma Protocol Verification

## Summary
A malicious validator can cause memory exhaustion on other validators by submitting a DKG transcript containing a sigma protocol proof with extremely large witness dimensions. The vulnerability exists because witness vector dimensions are not validated before memory allocation during proof verification, allowing an attacker to force unbounded memory consumption.

## Finding Description
The DKG (Distributed Key Generation) implementation uses sigma protocols to prove correct encryption of secret shares. When validators receive DKG transcripts from peers, they deserialize and verify the embedded proofs. The vulnerability chain is:

1. **Unbounded Deserialization**: DKG transcripts are deserialized without size limits in the VM transaction processor: [1](#0-0) 

2. **Witness Structure with Nested Vectors**: The `HkzgWeightedElgamalWitness` contains deeply nested vectors with no dimension constraints: [2](#0-1) 

3. **Unchecked Memory Allocation**: During verification, the `msm_terms` function allocates memory proportional to witness dimensions without bounds checking: [3](#0-2) 

4. **Vector Operations Without Size Validation**: The `Witness` trait implementation for `Vec<W>` processes vectors without size limits: [4](#0-3) 

**Attack Path**:
A Byzantine validator crafts a `DKGTranscript` with a malicious `SharingProof` containing an `HkzgWeightedElgamalWitness` where:
- `chunked_plaintexts: Vec<Vec<Vec<Scalar>>>` has dimensions [1000][1000][1000]
- `elgamal_randomness: Vec<Vec<Scalar>>` has dimensions [1000][1000]

When other validators verify this transcript, the `msm_terms` function iterates through these nested structures, allocating millions of `MsmInput` objects (each containing two `Vec` allocations), causing memory exhaustion.

The verification flow passes through: [5](#0-4) 

And processes the witness in the tuple homomorphism: [6](#0-5) 

**Broken Invariant**: This violates the "Resource Limits: All operations must respect gas, storage, and computational limits" invariant, as the verification process can consume unbounded memory based on attacker-controlled input dimensions.

## Impact Explanation
**Severity: Medium** - This qualifies as a validator node slowdown/crash attack (up to $10,000 per Aptos bug bounty).

While existing checks validate the number of players and chunks at the transcript level: [7](#0-6) 

These checks do NOT validate the dimensions of the witness vectors within the proof itself. An attacker can bypass these by keeping outer dimensions valid while inflating inner vector dimensions in the proof witness.

The attack can:
- Cause Out-Of-Memory (OOM) crashes on validator nodes processing the malicious transcript
- Trigger memory pressure leading to node slowdowns and degraded performance
- Potentially affect consensus liveness if multiple validators crash simultaneously

This does NOT directly steal funds or violate consensus safety, but impacts network availability and validator operations.

## Likelihood Explanation
**Likelihood: Medium-High** - The attack is feasible for any Byzantine validator:
- Requires only a single malicious validator (within AptosBFT's 1/3 Byzantine fault tolerance)
- No special permissions beyond validator status needed
- Easy to construct the malicious payload (just inflate vector dimensions during BCS serialization)
- Affects all validators that receive and verify the transcript
- No existing mitigation or size validation in the codebase

## Recommendation
Implement strict bounds checking on witness dimensions before processing. Add validation in the transcript verification path:

**Fix 1**: Add size limit to BCS deserialization:
```rust
// In aptos-move/aptos-vm/src/validator_txns/dkg.rs
const MAX_TRANSCRIPT_BYTES: usize = 10_000_000; // 10MB limit

let transcript = bcs::from_bytes_with_limit::<Transcript>(
    dkg_node.transcript_bytes.as_slice(),
    MAX_TRANSCRIPT_BYTES
).map_err(|_| Expected(TranscriptDeserializationFailed))?;
```

**Fix 2**: Validate witness dimensions in transcript verification:
```rust
// In crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs
// After line 153, add witness dimension checks:
fn validate_witness_dimensions<E: Pairing>(
    witness: &HkzgWeightedElgamalWitness<E::ScalarField>,
    sc: &WeightedConfigArkworks<E::ScalarField>,
    max_chunks: usize,
) -> anyhow::Result<()> {
    ensure!(
        witness.chunked_plaintexts.len() <= sc.get_total_num_players(),
        "Witness chunked_plaintexts outer dimension exceeds player count"
    );
    
    for player_chunks in &witness.chunked_plaintexts {
        ensure!(
            player_chunks.len() <= sc.get_max_weight(),
            "Player chunk count exceeds max weight"
        );
        for chunk_vec in player_chunks {
            ensure!(
                chunk_vec.len() <= max_chunks,
                "Chunk dimension exceeds maximum"
            );
        }
    }
    
    ensure!(
        witness.elgamal_randomness.len() <= sc.get_max_weight(),
        "ElGamal randomness outer dimension exceeds max weight"
    );
    for rand_vec in &witness.elgamal_randomness {
        ensure!(
            rand_vec.len() <= max_chunks,
            "ElGamal randomness inner dimension exceeds maximum"
        );
    }
    
    Ok(())
}
```

Call this validation before verifying the proof.

## Proof of Concept
```rust
// Test demonstrating memory exhaustion attack
#[test]
fn test_malicious_witness_dimensions() {
    use aptos_dkg::pvss::chunky::hkzg_chunked_elgamal::HkzgWeightedElgamalWitness;
    
    // Attacker creates witness with extreme dimensions
    let malicious_witness = HkzgWeightedElgamalWitness {
        hkzg_randomness: univariate_hiding_kzg::CommitmentRandomness::rand(&mut rng),
        // 1000 x 1000 x 1000 = 1 billion field elements
        chunked_plaintexts: vec![
            vec![
                vec![Scalar::rand(&mut rng); 1000]; 1000
            ]; 1000
        ],
        // 1000 x 1000 = 1 million field elements  
        elgamal_randomness: vec![vec![Scalar::rand(&mut rng); 1000]; 1000],
    };
    
    // Serialize into transcript
    let proof = create_malicious_proof_with_witness(malicious_witness);
    let transcript_bytes = bcs::to_bytes(&create_transcript_with_proof(proof)).unwrap();
    
    // When victim validator deserializes and verifies:
    let transcript = bcs::from_bytes(&transcript_bytes).unwrap();
    
    // This will allocate ~2 billion Vec objects (2 per MsmInput * 1 billion elements)
    // causing memory exhaustion
    let result = verify_transcript(&params, &transcript);
    
    // Expected: OOM or extreme memory pressure
    assert!(result.is_err() || memory_used > THRESHOLD);
}
```

### Citations

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L106-109)
```rust
        let transcript = bcs::from_bytes::<<DefaultDKG as DKGTrait>::Transcript>(
            dkg_node.transcript_bytes.as_slice(),
        )
        .map_err(|_| Expected(TranscriptDeserializationFailed))?;
```

**File:** crates/aptos-dkg/src/pvss/chunky/hkzg_chunked_elgamal.rs (L47-51)
```rust
pub struct HkzgWeightedElgamalWitness<F: PrimeField> {
    pub hkzg_randomness: univariate_hiding_kzg::CommitmentRandomness<F>,
    pub chunked_plaintexts: Vec<Vec<Vec<Scalar<F>>>>, // For each player, plaintexts z_i, which are chunked z_{i,j}
    pub elgamal_randomness: Vec<Vec<Scalar<F>>>, // For at most max_weight, for each chunk, a blinding factor
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L229-260)
```rust
    fn msm_terms(&self, input: &Self::Domain) -> Self::CodomainShape<Self::MsmInput> {
        // C_{i,j} = z_{i,j} * G_1 + r_j * ek[i]
        let Cs = input
            .plaintext_chunks
            .iter()
            .enumerate()
            .map(|(i, z_i)| {
                // here `i` is the player's id
                chunks_vec_msm_terms::<C>(self.pp, self.eks[i], z_i, &input.plaintext_randomness)
            })
            .collect();

        // R_j = r_j * H_1
        let Rs = input
            .plaintext_randomness
            .iter()
            .map(|inner_vec| {
                inner_vec
                    .iter()
                    .map(|&r_j| MsmInput {
                        bases: vec![self.pp.H],
                        scalars: vec![r_j.0],
                    })
                    .collect()
            })
            .collect();

        WeightedCodomainShape {
            chunks: Cs,
            randomness: Rs,
        }
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L218-229)
```rust
impl<F: PrimeField, W: Witness<F>> Witness<F> for Vec<W> {
    fn scaled_add(self, other: &Self, c: F) -> Self {
        self.into_iter()
            .zip(other.iter())
            .map(|(a, b)| a.scaled_add(b, c))
            .collect()
    }

    fn rand<R: RngCore + CryptoRng>(&self, rng: &mut R) -> Self {
        self.iter().map(|elem| elem.rand(rng)).collect()
    }
}
```

**File:** types/src/dkg/real_dkg/mod.rs (L332-374)
```rust
    fn verify_transcript(
        params: &Self::PublicParams,
        trx: &Self::Transcript,
    ) -> anyhow::Result<()> {
        // Verify dealer indices are valid.
        let dealers = trx
            .main
            .get_dealers()
            .iter()
            .map(|player| player.id)
            .collect::<Vec<usize>>();
        let num_validators = params.session_metadata.dealer_validator_set.len();
        ensure!(
            dealers.iter().all(|id| *id < num_validators),
            "real_dkg::verify_transcript failed with invalid dealer index."
        );

        let all_eks = params.pvss_config.eks.clone();

        let addresses = params.verifier.get_ordered_account_addresses();
        let dealers_addresses = dealers
            .iter()
            .filter_map(|&pos| addresses.get(pos))
            .cloned()
            .collect::<Vec<_>>();

        let spks = dealers_addresses
            .iter()
            .filter_map(|author| params.verifier.get_public_key(author))
            .collect::<Vec<_>>();

        let aux = dealers_addresses
            .iter()
            .map(|address| (params.pvss_config.epoch, address))
            .collect::<Vec<_>>();

        trx.main.verify(
            &params.pvss_config.wconfig,
            &params.pvss_config.pp,
            &spks,
            &all_eks,
            &aux,
        )?;
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L358-358)
```rust
        let (first_msm_terms_of_response, second_msm_terms_of_response) = self.msm_terms(&proof.z);
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L140-153)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```
