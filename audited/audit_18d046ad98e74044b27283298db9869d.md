# Audit Report

## Title
Missing Cryptographic Verification of Randomness in Block Prologue Allows Potential State Divergence

## Summary
The `process_block_prologue_ext()` function in the AptosVM accepts randomness from `BlockMetadataWithRandomness` without performing cryptographic verification that the randomness was correctly generated via the WVUF (Weighted Verifiable Unpredictable Function) protocol. This creates a potential state divergence vulnerability if validators independently compute different randomness values for the same block.

## Finding Description

The Aptos blockchain generates per-block randomness through a distributed protocol where validators contribute WVUF shares that are aggregated to produce the final randomness seed. However, the execution layer does not verify this randomness before using it.

**Vulnerability Location:** [1](#0-0) 

In `process_block_prologue_ext()`, the function extracts randomness from `BlockMetadataWithRandomness` and passes it directly to the Move VM without any cryptographic verification: [2](#0-1) 

The randomness is converted to a Move value and passed to the block prologue function with no validation that it matches the expected WVUF output for the block's metadata.

**Randomness Generation Flow:**

The randomness generation occurs in the consensus layer through these steps:

1. When a block is ordered, validators generate WVUF shares based on block metadata: [3](#0-2) 

2. Shares are broadcast to all validators and verified: [4](#0-3) 

3. Shares are aggregated when threshold is met: [5](#0-4) 

4. The randomness is set on the PipelinedBlock and later included in BlockMetadataWithRandomness during execution: [6](#0-5) 

**The Critical Gap:**

Each validator independently aggregates shares and computes randomness locally. The metadata used as WVUF input includes the block_id (which is the hash of BlockData): [7](#0-6) 

The BlockData hash includes the timestamp that the proposer controls within constraints: [8](#0-7) 

**Attack Scenario:**

While WVUF properties prevent a single proposer from predicting or biasing randomness, the lack of VM verification creates a state divergence risk:

1. If network conditions or Byzantine behavior cause different validators to receive different sets of shares (even if both sets meet the threshold), they will compute different randomness values
2. Each validator executes the block with their locally-computed randomness
3. The VM accepts the randomness without verification
4. Validators produce different state roots for the same block
5. This violates the **Deterministic Execution** invariant

**Proper Verification:**

The test suite demonstrates how randomness should be verified: [9](#0-8) 

This verification:
- Fetches the DKG state
- Derives the expected randomness from the shared secret
- Compares it with the actual on-chain randomness

However, this verification is **not performed in the production VM code**.

## Impact Explanation

**Severity Assessment: Medium to High**

This vulnerability breaks the **Deterministic Execution** invariant, which states "All validators must produce identical state roots for identical blocks."

**Potential Impacts:**

1. **State Divergence (Medium-High)**: If validators execute with different randomness, they compute different state roots, preventing consensus from progressing. This requires manual intervention to resolve.

2. **Liveness Failure (Medium)**: Validators cannot agree on the next block when their state roots diverge, causing the network to stall until the issue is resolved.

3. **Smart Contract Security (High)**: Applications relying on randomness assume all validators see the same random values. State divergence could cause transactions to succeed on some validators and fail on others, breaking application invariants.

The impact is somewhat mitigated because:
- Consensus voting should detect state root mismatches and prevent safety violations
- The reliable broadcast mechanism helps ensure share delivery
- WVUF threshold properties provide some resilience

However, the lack of verification removes a critical defense-in-depth layer.

## Likelihood Explanation

**Likelihood: Low to Medium**

The exploit requires:

1. **Network manipulation**: Causing different validators to aggregate different sets of shares (both meeting threshold)
2. **Timing windows**: Exploiting the window between share broadcast and aggregation
3. **Byzantine coordination**: Potentially requiring coordination with malicious validators to selectively deliver shares

Factors affecting likelihood:

**Increasing likelihood:**
- Network partitions or latency spikes during share broadcast
- Byzantine validators selectively delivering shares to different validators
- Race conditions in share arrival ordering

**Decreasing likelihood:**
- Reliable broadcast mechanism ensures eventual share delivery
- Cryptographic verification of shares before aggregation
- Consensus layer detection of state root divergence
- WVUF threshold properties (requires multiple Byzantine validators to bias)

While not easily exploitable by a single malicious proposer, the vulnerability creates an attack surface for sophisticated Byzantine adversaries or network-level attackers.

## Recommendation

Implement cryptographic verification of randomness in the VM before accepting it. The verification should:

1. **Fetch DKG state from on-chain storage**
2. **Derive expected randomness** from the DKG shared secret and block metadata
3. **Verify the provided randomness matches** the expected value
4. **Reject the block** if verification fails

**Suggested Implementation Location:**

Add verification in `process_block_prologue_ext()` before line 2528:

```rust
// Verify randomness if present
if let Some(ref rand) = randomness {
    verify_randomness_matches_expected(
        resolver,
        epoch,
        round,
        &id,
        rand,
    )?;
}
```

The verification function should:
- Access the DKG state resource from on-chain storage
- Reconstruct the expected randomness using WVUF evaluation
- Compare with the provided randomness
- Return an error if they don't match

This ensures defense-in-depth: even if consensus-layer mechanisms fail, the VM rejects invalid randomness.

## Proof of Concept

**Scenario: State Divergence via Differential Share Delivery**

```rust
// Conceptual PoC (requires test framework setup)
// This demonstrates how different validators could execute 
// the same block with different randomness

#[test]
fn test_randomness_state_divergence() {
    // Setup two validator nodes
    let validator1 = setup_validator(1);
    let validator2 = setup_validator(2);
    
    // Create a block at round R
    let block = create_test_block(epoch, round);
    let metadata = FullRandMetadata::from(&block);
    
    // Simulate byzantine share delivery:
    // Validator 1 receives shares from validators {1, 2, 3, 4}
    let shares1 = vec![
        generate_share(metadata.clone(), validator_keys[0]),
        generate_share(metadata.clone(), validator_keys[1]),
        generate_share(metadata.clone(), validator_keys[2]),
        generate_share(metadata.clone(), validator_keys[3]),
    ];
    
    // Validator 2 receives shares from validators {1, 2, 3, 5}  
    // (different 4th share due to network manipulation)
    let shares2 = vec![
        generate_share(metadata.clone(), validator_keys[0]),
        generate_share(metadata.clone(), validator_keys[1]),
        generate_share(metadata.clone(), validator_keys[2]),
        generate_share(metadata.clone(), validator_keys[4]), // Different!
    ];
    
    // Both sets meet threshold, but produce different randomness
    let rand1 = aggregate_shares(shares1, &rand_config);
    let rand2 = aggregate_shares(shares2, &rand_config);
    
    assert_ne!(rand1, rand2, "Different share sets produce different randomness");
    
    // Create BlockMetadataWithRandomness for each validator
    let metadata_txn1 = block.new_metadata_with_randomness(&validators, Some(rand1));
    let metadata_txn2 = block.new_metadata_with_randomness(&validators, Some(rand2));
    
    // Execute on both validators
    let (_, output1) = validator1.vm.process_block_prologue_ext(
        &resolver1,
        &module_storage,
        metadata_txn1,
        &log_context,
    ).unwrap();
    
    let (_, output2) = validator2.vm.process_block_prologue_ext(
        &resolver2,
        &module_storage,
        metadata_txn2,
        &log_context,
    ).unwrap();
    
    // State roots diverge!
    assert_ne!(
        output1.change_set().state_root_hash(),
        output2.change_set().state_root_hash(),
        "Validators computed different state roots due to different randomness"
    );
    
    // This breaks the Deterministic Execution invariant
}
```

**Note:** This PoC is conceptual and demonstrates the theoretical vulnerability. In practice, reproducing this requires:
- Controlling network delivery to cause differential share sets
- Both share sets meeting the WVUF threshold
- Executing the blocks before consensus catches the divergence

The key point is that **the VM provides no defense** against this scenario - it blindly accepts whatever randomness is provided.

---

**Notes:**

The vulnerability stems from an architectural assumption that consensus-layer mechanisms (reliable broadcast, share verification, WVUF properties) are sufficient to ensure all validators compute identical randomness. However, defense-in-depth principles dictate that the execution layer should independently verify critical inputs like randomness, rather than trusting upstream components. The absence of VM-level verification creates an unnecessary attack surface and violates the principle of least privilege.

### Citations

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2469-2550)
```rust
    fn process_block_prologue_ext(
        &self,
        resolver: &impl AptosMoveResolver,
        module_storage: &impl AptosModuleStorage,
        block_metadata_ext: BlockMetadataExt,
        log_context: &AdapterLogSchema,
    ) -> Result<(VMStatus, VMOutput), VMStatus> {
        fail_point!("move_adapter::process_block_prologue_ext", |_| {
            Err(VMStatus::error(
                StatusCode::UNKNOWN_INVARIANT_VIOLATION_ERROR,
                None,
            ))
        });

        let mut gas_meter = UnmeteredGasMeter;
        let mut session = self.new_session(
            resolver,
            SessionId::block_meta_ext(&block_metadata_ext),
            None,
        );

        let block_metadata_with_randomness = match block_metadata_ext {
            BlockMetadataExt::V0(_) => unreachable!(),
            BlockMetadataExt::V1(v1) => v1,
        };

        let BlockMetadataWithRandomness {
            id,
            epoch,
            round,
            proposer,
            previous_block_votes_bitvec,
            failed_proposer_indices,
            timestamp_usecs,
            randomness,
        } = block_metadata_with_randomness;

        let args = vec![
            MoveValue::Signer(AccountAddress::ZERO), // Run as 0x0
            MoveValue::Address(AccountAddress::from_bytes(id.to_vec()).unwrap()),
            MoveValue::U64(epoch),
            MoveValue::U64(round),
            MoveValue::Address(proposer),
            failed_proposer_indices
                .into_iter()
                .map(|i| i as u64)
                .collect::<Vec<_>>()
                .as_move_value(),
            previous_block_votes_bitvec.as_move_value(),
            MoveValue::U64(timestamp_usecs),
            randomness
                .as_ref()
                .map(Randomness::randomness_cloned)
                .as_move_value(),
        ];

        let traversal_storage = TraversalStorage::new();
        let mut traversal_context = TraversalContext::new(&traversal_storage);

        session
            .execute_function_bypass_visibility(
                &BLOCK_MODULE,
                BLOCK_PROLOGUE_EXT,
                vec![],
                serialize_values(&args),
                &mut gas_meter,
                &mut traversal_context,
                module_storage,
            )
            .map(|_return_vals| ())
            .or_else(|e| {
                expect_only_successful_execution(e, BLOCK_PROLOGUE_EXT.as_str(), log_context)
            })?;
        SYSTEM_TRANSACTIONS_EXECUTED.inc();

        let output = get_system_transaction_output(
            session,
            module_storage,
            &self.storage_gas_params(log_context)?.change_set_configs,
        )?;
        Ok((VMStatus::Executed, output))
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L145-168)
```rust
    fn process_incoming_metadata(&self, metadata: FullRandMetadata) -> DropGuard {
        let self_share = S::generate(&self.config, metadata.metadata.clone());
        info!(LogSchema::new(LogEvent::BroadcastRandShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(metadata.round()));
        let mut rand_store = self.rand_store.lock();
        rand_store.update_highest_known_round(metadata.round());
        rand_store
            .add_share(self_share.clone(), PathType::Slow)
            .expect("Add self share should succeed");

        if let Some(fast_config) = &self.fast_config {
            let self_fast_share =
                FastShare::new(S::generate(fast_config, metadata.metadata.clone()));
            rand_store
                .add_share(self_fast_share.rand_share(), PathType::Fast)
                .expect("Add self share for fast path should succeed");
        }

        rand_store.add_rand_metadata(metadata.clone());
        self.network_sender
            .broadcast_without_self(RandMessage::<S, D>::Share(self_share).into_network_message());
        self.spawn_aggregate_shares_task(metadata.metadata)
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L196-206)
```rust
    fn process_randomness(&mut self, randomness: Randomness) {
        let rand = hex::encode(randomness.randomness());
        info!(
            metadata = randomness.metadata(),
            rand = rand,
            "Processing decisioned randomness."
        );
        if let Some(block) = self.block_queue.item_mut(randomness.round()) {
            block.set_randomness(randomness.round(), randomness);
        }
    }
```

**File:** consensus/src/rand/rand_gen/network_messages.rs (L35-60)
```rust
impl<S: TShare, D: TAugmentedData> RandMessage<S, D> {
    pub fn verify(
        &self,
        epoch_state: &EpochState,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        sender: Author,
    ) -> anyhow::Result<()> {
        ensure!(self.epoch() == epoch_state.epoch);
        match self {
            RandMessage::RequestShare(_) => Ok(()),
            RandMessage::Share(share) => share.verify(rand_config),
            RandMessage::AugData(aug_data) => {
                aug_data.verify(rand_config, fast_rand_config, sender)
            },
            RandMessage::CertifiedAugData(certified_aug_data) => {
                certified_aug_data.verify(&epoch_state.verifier)
            },
            RandMessage::FastShare(share) => {
                share.share.verify(fast_rand_config.as_ref().ok_or_else(|| {
                    anyhow::anyhow!("[RandMessage] rand config for fast path not found")
                })?)
            },
            _ => bail!("[RandMessage] unexpected message type"),
        }
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L97-148)
```rust
    fn aggregate<'a>(
        shares: impl Iterator<Item = &'a RandShare<Self>>,
        rand_config: &RandConfig,
        rand_metadata: RandMetadata,
    ) -> anyhow::Result<Randomness>
    where
        Self: Sized,
    {
        let timer = std::time::Instant::now();
        let mut apks_and_proofs = vec![];
        for share in shares {
            let id = rand_config
                .validator
                .address_to_validator_index()
                .get(share.author())
                .copied()
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with invalid share author: {}",
                        share.author
                    )
                })?;
            let apk = rand_config
                .get_certified_apk(share.author())
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with missing apk for share from {}",
                        share.author
                    )
                })?;
            apks_and_proofs.push((Player { id }, apk.clone(), share.share().share));
        }

        let proof = WVUF::aggregate_shares(&rand_config.wconfig, &apks_and_proofs);
        let metadata_serialized = bcs::to_bytes(&rand_metadata).map_err(|e| {
            anyhow!("Share::aggregate failed with metadata serialization error: {e}")
        })?;
        let eval = WVUF::derive_eval(
            &rand_config.wconfig,
            &rand_config.vuf_pp,
            metadata_serialized.as_slice(),
            &rand_config.get_all_certified_apk(),
            &proof,
            THREAD_MANAGER.get_exe_cpu_pool(),
        )
        .map_err(|e| anyhow!("Share::aggregate failed with WVUF derive_eval error: {e}"))?;
        debug!("WVUF derivation time: {} ms", timer.elapsed().as_millis());
        let eval_bytes = bcs::to_bytes(&eval)
            .map_err(|e| anyhow!("Share::aggregate failed with eval serialization error: {e}"))?;
        let rand_bytes = Sha3_256::digest(eval_bytes.as_slice()).to_vec();
        Ok(Randomness::new(rand_metadata, rand_bytes))
    }
```

**File:** consensus/consensus-types/src/randomness.rs (L7-16)
```rust
impl From<&Block> for FullRandMetadata {
    fn from(block: &Block) -> Self {
        Self::new(
            block.epoch(),
            block.round(),
            block.id(),
            block.timestamp_usecs(),
        )
    }
}
```

**File:** consensus/consensus-types/src/block_data.rs (L72-133)
```rust
#[derive(Deserialize, Serialize, Clone, Debug, PartialEq, Eq, CryptoHasher)]
/// Block has the core data of a consensus block that should be persistent when necessary.
/// Each block must know the id of its parent and keep the QuorurmCertificate to that parent.
pub struct BlockData {
    /// Epoch number corresponds to the set of validators that are active for this block.
    epoch: u64,
    /// The round of a block is an internal monotonically increasing counter used by Consensus
    /// protocol.
    round: Round,
    /// The approximate physical time a block is proposed by a proposer.  This timestamp is used
    /// for
    /// * Time-dependent logic in smart contracts (the current time of execution)
    /// * Clients determining if they are relatively up-to-date with respect to the block chain.
    ///
    /// It makes the following guarantees:
    ///   1. Time Monotonicity: Time is monotonically increasing in the block chain.
    ///      (i.e. If H1 < H2, H1.Time < H2.Time).
    ///   2. If a block of transactions B is agreed on with timestamp T, then at least
    ///      f+1 honest validators think that T is in the past. An honest validator will
    ///      only vote on a block when its own clock >= timestamp T.
    ///   3. If a block of transactions B has a QC with timestamp T, an honest validator
    ///      will not serve such a block to other validators until its own clock >= timestamp T.
    ///   4. Current: an honest validator is not issuing blocks with a timestamp in the
    ///       future. Currently we consider a block is malicious if it was issued more
    ///       that 5 minutes in the future.
    timestamp_usecs: u64,
    /// Contains the quorum certified ancestor and whether the quorum certified ancestor was
    /// voted on successfully
    quorum_cert: QuorumCert,
    /// If a block is a real proposal, contains its author and signature.
    block_type: BlockType,
}

impl CryptoHash for BlockData {
    type Hasher = BlockDataHasher;

    fn hash(&self) -> HashValue {
        let mut state = Self::Hasher::default();
        if self.is_opt_block() {
            #[derive(Serialize)]
            struct OptBlockDataForHash<'a> {
                epoch: u64,
                round: Round,
                timestamp_usecs: u64,
                quorum_cert_vote_data: &'a VoteData,
                block_type: &'a BlockType,
            }

            let opt_block_data_for_hash = OptBlockDataForHash {
                epoch: self.epoch,
                round: self.round,
                timestamp_usecs: self.timestamp_usecs,
                quorum_cert_vote_data: self.quorum_cert.vote_data(),
                block_type: &self.block_type,
            };
            bcs::serialize_into(&mut state, &opt_block_data_for_hash)
                .expect("OptBlockDataForHash must be serializable");
        } else {
            bcs::serialize_into(&mut state, &self).expect("BlockData must be serializable");
        }
        state.finish()
    }
```

**File:** testsuite/smoke-test/src/randomness/mod.rs (L204-256)
```rust
async fn verify_randomness(
    decrypt_key_map: &HashMap<AccountAddress, <DefaultDKG as DKGTrait>::NewValidatorDecryptKey>,
    rest_client: &Client,
    version: u64,
) -> Result<()> {
    // Fetch resources.
    let (dkg_state, on_chain_block_randomness) = tokio::join!(
        get_on_chain_resource_at_version::<DKGState>(rest_client, version),
        get_on_chain_resource_at_version::<PerBlockRandomness>(rest_client, version)
    );

    ensure!(
        on_chain_block_randomness.seed.is_some(),
        "randomness verification failed with seed missing"
    );

    // Derive the shared secret.
    let dkg_session = dkg_state
        .last_completed
        .ok_or_else(|| anyhow!("randomness verification failed with missing dkg result"))?;
    let dkg_pub_params = DefaultDKG::new_public_params(&dkg_session.metadata);
    let transcript =
        bcs::from_bytes::<<DefaultDKG as DKGTrait>::Transcript>(dkg_session.transcript.as_slice())
            .map_err(|_| {
                anyhow!(
                "randomness verification failed with on-chain dkg transcript deserialization error"
            )
            })?;
    let dealt_secret = dealt_secret_from_shares(
        dkg_session
            .metadata
            .target_validator_consensus_infos_cloned(),
        decrypt_key_map,
        &dkg_pub_params,
        &transcript,
    );

    // Compare the outputs from 2 paths.
    let rand_metadata = RandMetadata {
        epoch: on_chain_block_randomness.epoch,
        round: on_chain_block_randomness.round,
    };
    let input = bcs::to_bytes(&rand_metadata).unwrap();
    let output = WVUF::eval(&dealt_secret, input.as_slice());
    let output_serialized = bcs::to_bytes(&output).unwrap();
    let expected_randomness_seed = Sha3_256::digest(output_serialized.as_slice()).to_vec();

    ensure!(
        expected_randomness_seed == on_chain_block_randomness.seed.clone().unwrap(),
        "randomness verification failed with final check failure"
    );
    Ok(())
}
```
