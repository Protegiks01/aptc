# Audit Report

## Title
Non-Atomic Block Data Clearing Causes Race Condition Between State Clearing and Execution Pipeline

## Summary
The `clear_block_data()` function in the consensus observer performs three sequential clearing operations across three separate data stores, but the payload store has its own independent mutex that creates a critical race window. The execution pipeline, which runs asynchronously and holds a direct reference to the payload store via `Arc<Mutex<...>>`, can observe partially cleared state where payloads are deleted but ordered blocks still exist, causing execution failures and potential node crashes.

## Finding Description
The vulnerability exists in the non-atomic clearing sequence at [1](#0-0) 

The clearing operation performs three sequential steps:

1. `clear_all_payloads()` - acquires and releases its own mutex on `block_payloads`
2. `clear_all_ordered_blocks()` - clears ordered blocks (no separate mutex)  
3. `clear_missing_blocks()` - clears pending blocks (no separate mutex)

The critical issue is that `block_payloads` has its own separate `Arc<Mutex<BTreeMap<...>>>` as shown at [2](#0-1) , and this same reference is held by the `ConsensusObserverPayloadManager` as `txns_pool` [3](#0-2) .

**Race Condition Window:**

When `clear_pending_block_state()` is invoked at [4](#0-3) , it holds the `observer_block_data` mutex but:

1. Calls `clear_all_payloads()` [5](#0-4)  which acquires the `block_payloads` mutex, clears the map, then **releases** the mutex
2. Between this release and the subsequent `clear_all_ordered_blocks()` call, the execution pipeline can acquire the `block_payloads` mutex

**Concurrent Execution Path:**

The execution pipeline runs asynchronously after blocks are finalized at [6](#0-5) . When it needs transactions, it calls `get_transactions_for_observer()` [7](#0-6)  which directly accesses the same `block_payloads` map.

**Exploitation Scenario:**

1. Observer receives and finalizes ordered blocks, sending them to the execution pipeline
2. Execution pipeline begins async processing
3. Peer sends invalid messages or disconnects, triggering subscription check failure [8](#0-7) 
4. `clear_pending_block_state()` is called
5. `clear_all_payloads()` removes all payloads and releases its mutex
6. **Race window:** Execution pipeline acquires `block_payloads` mutex before `clear_all_ordered_blocks()` executes
7. Execution pipeline tries to retrieve payload for a block that was in `ordered_blocks`
8. Payload is missing â†’ `InternalError` returned [9](#0-8) 
9. Execution pipeline fails with critical error

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs". The three data stores represent a single logical state that should be cleared atomically, but the separate mutex on `block_payloads` breaks atomicity.

## Impact Explanation
This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: Execution failures cause repeated error handling and potential retries
- **Significant protocol violations**: The consensus observer fails to maintain consistent state between data stores
- **Potential node crashes**: Internal errors in the execution pipeline may cause panic or require node restart

The impact affects consensus observer nodes specifically, which are critical for network scalability and decentralization. Multiple nodes experiencing this race condition simultaneously could impact network liveness.

## Likelihood Explanation
**Likelihood: Medium to High**

This race condition can occur during normal operation without malicious intent:
- Network instability causing peer disconnections
- Subscription timeout or health check failures  
- Message processing errors

An attacker with peer-level access can deliberately trigger this by:
1. Establishing subscription as consensus peer
2. Sending valid blocks to populate the execution pipeline
3. Immediately sending invalid messages or disconnecting
4. Triggering rapid subscription failures to maximize race window
5. Repeating to cause persistent execution failures

The race window is narrow but the triggering condition (`check_and_manage_subscriptions` failure) is externally controllable, making exploitation feasible with moderate effort.

## Recommendation
Ensure atomic clearing of all three data stores by introducing a unified clearing operation that holds the `block_payloads` mutex for the entire duration:

```rust
// In block_data.rs
pub fn clear_block_data(&mut self) -> LedgerInfoWithSignatures {
    // Hold the payload mutex for entire operation
    let mut block_payloads = self.block_payload_store.get_block_payloads().lock();
    block_payloads.clear();
    
    // Clear other stores while still holding payload mutex
    self.ordered_block_store.clear_all_ordered_blocks();
    self.pending_block_store.clear_missing_blocks();
    
    // Release mutex implicitly at end of scope
    drop(block_payloads);
    
    self.root()
}
```

Additionally, consider adding a barrier or synchronization with the execution pipeline before clearing:
1. Pause or drain the execution pipeline
2. Clear all data stores atomically  
3. Call `execution_client.reset()`
4. Resume execution pipeline

This ensures no in-flight blocks can access cleared state.

## Proof of Concept

```rust
// Reproduction scenario (pseudo-Rust test)
#[tokio::test]
async fn test_clear_block_data_race_condition() {
    // Setup consensus observer with execution pipeline
    let observer = setup_consensus_observer();
    
    // 1. Send ordered block to observer
    let ordered_block = create_test_ordered_block(epoch: 1, round: 10);
    observer.process_ordered_block_message(peer, ordered_block).await;
    
    // 2. Block gets finalized and sent to execution pipeline
    // Execution pipeline now holds reference to block_payloads
    
    // 3. Spawn concurrent task simulating execution pipeline
    let payload_store = observer.get_block_payloads(); // Arc<Mutex<...>>
    let execution_task = tokio::spawn(async move {
        tokio::time::sleep(Duration::from_micros(100)).await; // Wait for clearing to start
        
        // Try to get transactions (this is what execution pipeline does)
        let payloads = payload_store.lock();
        let result = payloads.get(&(1, 10)); // epoch 1, round 10
        
        // RACE: Payload should exist but will be None if cleared
        assert!(result.is_some(), "Race condition: payload cleared before ordered blocks!");
    });
    
    // 4. Trigger clear_pending_block_state (simulating subscription failure)
    tokio::time::sleep(Duration::from_micros(50)).await; // Small delay
    observer.clear_pending_block_state().await;
    
    // 5. Race: execution_task tries to access payload after clear_all_payloads()
    //    but before clear_all_ordered_blocks()
    let result = execution_task.await;
    assert!(result.is_err()); // Task will fail due to missing payload
}
```

To reproduce in production:
1. Setup consensus observer node
2. Subscribe to consensus updates from peer
3. Allow blocks to be processed and sent to execution pipeline
4. Trigger subscription failure (disconnect peer, send invalid message)
5. Monitor logs for "Missing payload data for block epoch X, round Y!" errors
6. Observe execution failures and potential node instability

### Citations

**File:** consensus/src/consensus_observer/observer/block_data.rs (L93-105)
```rust
    pub fn clear_block_data(&mut self) -> LedgerInfoWithSignatures {
        // Clear the payload store
        self.block_payload_store.clear_all_payloads();

        // Clear the ordered blocks
        self.ordered_block_store.clear_all_ordered_blocks();

        // Clear the pending blocks
        self.pending_block_store.clear_missing_blocks();

        // Return the root ledger info
        self.root()
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L35-35)
```rust
    block_payloads: Arc<Mutex<BTreeMap<(u64, Round), BlockPayloadStatus>>>,
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L60-62)
```rust
    pub fn clear_all_payloads(&self) {
        self.block_payloads.lock().clear();
    }
```

**File:** consensus/src/payload_manager/co_payload_manager.rs (L36-58)
```rust
    let block_payload = match block_payloads.lock().entry((block.epoch(), block.round())) {
        Entry::Occupied(mut value) => match value.get_mut() {
            BlockPayloadStatus::AvailableAndVerified(block_payload) => block_payload.clone(),
            BlockPayloadStatus::AvailableAndUnverified(_) => {
                // This shouldn't happen (the payload should already be verified)
                let error = format!(
                    "Payload data for block epoch {}, round {} is unverified!",
                    block.epoch(),
                    block.round()
                );
                return Err(InternalError { error });
            },
        },
        Entry::Vacant(_) => {
            // This shouldn't happen (the payload should already be present)
            let error = format!(
                "Missing payload data for block epoch {}, round {}!",
                block.epoch(),
                block.round()
            );
            return Err(InternalError { error });
        },
    };
```

**File:** consensus/src/payload_manager/co_payload_manager.rs (L79-79)
```rust
    txns_pool: Arc<Mutex<BTreeMap<(u64, Round), BlockPayloadStatus>>>,
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L204-213)
```rust
        if let Err(error) = self
            .subscription_manager
            .check_and_manage_subscriptions()
            .await
        {
            // Log the failure and clear the pending block state
            warn!(LogSchema::new(LogEntry::ConsensusObserver)
                .message(&format!("Subscription checks failed! Error: {:?}", error)));
            self.clear_pending_block_state().await;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L218-234)
```rust
    async fn clear_pending_block_state(&self) {
        // Clear the observer block data
        let root = self.observer_block_data.lock().clear_block_data();

        // Reset the execution pipeline for the root
        if let Err(error) = self.execution_client.reset(&root).await {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to reset the execution pipeline for the root! Error: {:?}",
                    error
                ))
            );
        }

        // Increment the cleared block state counter
        metrics::increment_counter_without_labels(&metrics::OBSERVER_CLEARED_BLOCK_STATE);
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L287-294)
```rust
        if let Err(error) = self
            .execution_client
            .finalize_order(
                ordered_block.blocks().clone(),
                WrappedLedgerInfo::new(VoteData::dummy(), ordered_block.ordered_proof().clone()),
            )
            .await
        {
```
