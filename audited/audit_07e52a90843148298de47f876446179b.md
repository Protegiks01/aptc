# Audit Report

## Title
Malicious Peers Can Evade Banning Through Compression Protocol Violations in Data Streaming Service

## Summary
The data streaming service fails to penalize peers that violate compression protocol requirements. When the Aptos data client returns `InvalidResponse` errors for compression violations, the streaming service's `handle_data_client_error` function only retries the request without calling `notify_bad_response` to penalize the malicious peer. This allows attackers to repeatedly send invalid responses without being banned, causing resource exhaustion and validator node slowdowns.

## Finding Description

The Aptos state sync system uses a peer scoring mechanism to identify and ignore misbehaving peers. When peers send malicious or invalid responses, they should be penalized through the `ResponseCallback::notify_bad_response` mechanism, which reduces their score and eventually causes them to be ignored. [1](#0-0) 

However, the data streaming service's error handling has a critical gap. When the data client detects compression protocol violations, it returns an `InvalidResponse` error: [2](#0-1) 

This error propagates back to the streaming service and is handled by `handle_data_client_error`: [3](#0-2) 

Notice the TODO comment on line 723: "can we identify the best way to react to the error?" The function only logs the error and retries the request—it never calls `notify_bad_response` to penalize the peer.

In contrast, when sanity check failures occur or proof verification fails, the streaming service correctly penalizes peers: [4](#0-3) 

**Attack Path:**

1. Attacker runs malicious peer nodes that advertise data availability
2. When nodes request compressed data, malicious peers send uncompressed data (or vice versa)
3. Data client detects compression violation and returns `InvalidResponse` error
4. Streaming service receives error at line 523-535 of `process_data_responses`: [5](#0-4) 

5. `handle_data_client_error` is called but does NOT penalize the peer
6. Request is retried up to `max_request_retry` times (default configuration)
7. Malicious peer's score remains unchanged—it is never banned
8. Same peer can be selected for subsequent requests, repeating the attack
9. With multiple Sybil peers using this technique, victim nodes experience severe slowdowns

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program for two reasons:

1. **Validator node slowdowns**: Malicious peers can force victim nodes to waste computational resources on repeated retries and exponential backoff, causing state sync delays. In a network dominated by malicious Sybil peers, new validators or nodes recovering from downtime may be unable to sync efficiently.

2. **Significant protocol violations**: The peer reputation system is a critical security mechanism. Its failure to penalize compression protocol violations undermines network health and enables persistent misbehavior.

While this doesn't directly cause consensus breaks or fund theft, it degrades network reliability and availability—particularly impacting nodes trying to join or catch up with the network.

## Likelihood Explanation

**Likelihood: High**

- **Low barrier to entry**: Any network participant can run a peer and send responses with incorrect compression settings
- **No authentication required**: The attack works against the state sync protocol without requiring validator keys or stake
- **Sybil amplification**: Attackers can run multiple malicious peer identities to maximize impact
- **Persistent effect**: Since peers are never banned, the attack can continue indefinitely
- **No detection**: The current implementation only logs errors without triggering alerts for repeated compression violations from the same peer

The TODO comment at line 723 suggests developers were aware that error differentiation was needed but never implemented it, making this an existing gap rather than a theoretical issue.

## Recommendation

Modify `handle_data_client_error` to differentiate between error types and call `notify_bad_response` for errors that indicate malicious behavior:

```rust
fn handle_data_client_error(
    &mut self,
    data_client_request: &DataClientRequest,
    data_client_error: &aptos_data_client::error::Error,
) -> Result<(), Error> {
    // Log the error
    warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
        .stream_id(self.data_stream_id)
        .event(LogEvent::Error)
        .error(&data_client_error.clone().into())
        .message("Encountered a data client error!"));

    // Identify errors that indicate malicious peer behavior
    match data_client_error {
        aptos_data_client::error::Error::InvalidResponse(_) => {
            // Compression violations or invalid response formats indicate
            // potential malicious behavior - penalize the peer
            // Note: We need the response context to notify, which requires
            // refactoring to pass it through to this function
            warn!("Peer sent invalid response - should be penalized");
            // TODO: Add mechanism to notify bad response for protocol violations
        },
        aptos_data_client::error::Error::DataIsUnavailable(_) |
        aptos_data_client::error::Error::TimeoutWaitingForResponse(_) |
        aptos_data_client::error::Error::NoConnectedPeers(_) => {
            // These are not necessarily malicious - just retry
        },
        _ => {
            // Other errors should be evaluated case-by-case
        }
    }

    self.resend_data_client_request(data_client_request)
}
```

Additionally, the data client should call `notify_bad_response` directly when detecting compression violations: [2](#0-1) 

Before returning the error, add:
```rust
context.response_callback.notify_bad_response(ResponseError::InvalidData);
```

## Proof of Concept

```rust
// Add to state-sync/data-streaming-service/src/tests/data_stream.rs

#[tokio::test]
async fn test_compression_violation_does_not_penalize_peer() {
    // Setup: Create a data stream with a mock peer
    let (mut data_stream, mut mock_client, _listener) = 
        create_data_stream_with_mock_client().await;
    
    // Get initial peer score
    let peer = create_mock_peer();
    let initial_score = mock_client.get_peer_score(&peer);
    
    // Simulate peer sending response with wrong compression
    // (requested compressed but peer sent uncompressed)
    let error = aptos_data_client::error::Error::InvalidResponse(
        "Requested compressed data, but the response was uncompressed!".to_string()
    );
    
    // Inject the error into the pending response
    let pending_response = data_stream.get_sent_data_requests().unwrap().front().unwrap();
    pending_response.lock().client_response = Some(Err(error));
    
    // Process the error
    data_stream.process_data_responses(GlobalDataSummary::empty()).await.unwrap();
    
    // Verify: Peer score should have decreased, but it doesn't (BUG!)
    let final_score = mock_client.get_peer_score(&peer);
    
    // This assertion FAILS, demonstrating the vulnerability
    assert!(
        final_score < initial_score,
        "Peer score should decrease after compression violation, but it remains unchanged! \
         Initial: {}, Final: {}. This allows malicious peers to evade banning.",
        initial_score, final_score
    );
}
```

This test demonstrates that compression protocol violations do not reduce peer scores, allowing malicious peers to evade the reputation system's banning mechanism.

## Notes

The vulnerability exists because of a design inconsistency: proof verification errors and sanity check failures correctly use `notify_bad_response`, but data client errors from the network layer (like compression violations) are only logged and retried. The TODO comment in `handle_data_client_error` explicitly acknowledges this gap but it was never addressed. The `From` trait conversion to `AptosDataClientError(String)` is a symptom of treating all data client errors generically rather than differentiating malicious behavior from benign failures.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L45-62)
```rust
pub enum ErrorType {
    /// A response or error that's not actively malicious but also doesn't help
    /// us make progress, e.g., timeouts, remote errors, invalid data, etc...
    NotUseful,
    /// A response or error that appears to be actively hindering progress or
    /// attempting to deceive us, e.g., invalid proof.
    Malicious,
}

impl From<ResponseError> for ErrorType {
    fn from(error: ResponseError) -> Self {
        match error {
            ResponseError::InvalidData | ResponseError::InvalidPayloadDataType => {
                ErrorType::NotUseful
            },
            ResponseError::ProofVerificationError => ErrorType::Malicious,
        }
    }
```

**File:** state-sync/aptos-data-client/src/client.rs (L736-748)
```rust
        // Ensure the response obeys the compression requirements
        let (context, storage_response) = storage_response.into_parts();
        if request.use_compression && !storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested compressed data, but the response was uncompressed! Response: {:?}",
                storage_response.get_label()
            )));
        } else if !request.use_compression && storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested uncompressed data, but the response was compressed! Response: {:?}",
                storage_response.get_label()
            )));
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L523-538)
```rust
                Err(error) => {
                    // Handle the error depending on the request type
                    if client_request.is_new_data_request() {
                        // The request was for new data. We should notify the
                        // stream engine and clear the requests queue.
                        self.notify_new_data_request_error(client_request, error)?;
                    } else {
                        // Decrease the prefetching limit on an error
                        self.dynamic_prefetching_state
                            .decrease_max_concurrent_requests();

                        // Handle the error and simply retry
                        self.handle_data_client_error(client_request, &error)?;
                    }
                    break; // We're now head of line blocked on the failed request
                },
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L695-708)
```rust
    /// Handles a client response that failed sanity checks
    fn handle_sanity_check_failure(
        &mut self,
        data_client_request: &DataClientRequest,
        response_context: &ResponseContext,
    ) -> Result<(), Error> {
        error!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .message("Encountered a client response that failed the sanity checks!"));

        self.notify_bad_response(response_context, ResponseError::InvalidPayloadDataType);
        self.resend_data_client_request(data_client_request)
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L710-725)
```rust
    /// Handles an error returned by the data client in relation to a request
    fn handle_data_client_error(
        &mut self,
        data_client_request: &DataClientRequest,
        data_client_error: &aptos_data_client::error::Error,
    ) -> Result<(), Error> {
        // Log the error
        warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .error(&data_client_error.clone().into())
            .message("Encountered a data client error!"));

        // TODO(joshlind): can we identify the best way to react to the error?
        self.resend_data_client_request(data_client_request)
    }
```
