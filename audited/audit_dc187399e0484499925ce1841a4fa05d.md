# Audit Report

## Title
Unbounded Memory Exhaustion in State Snapshot Restore via Malicious Chunk Files

## Summary
The `read_state_value()` function in the state snapshot restore process loads all records from a backup chunk file into memory without any limit on the number of records. An attacker who can provide malicious backup files can create chunks with millions of small records, causing unbounded memory growth and crashing validator nodes during restore operations.

## Finding Description
The vulnerability exists in the `read_state_value()` function [1](#0-0)  where records are read from backup files during state snapshot restoration.

The function initializes an empty vector and continuously pushes records until EOF without any capacity or count limits. [2](#0-1) 

While the `read_record_bytes()` implementation limits individual record sizes to u32::MAX bytes (~4GB) [3](#0-2) , there is **no limit on the total number of records** in a chunk file.

During backup creation, chunks are limited to `max_chunk_size` (default 128MB) [4](#0-3)  using the `should_cut_chunk()` function [5](#0-4) . However, **this limit is not enforced during restore** - the code trusts the chunk files to be well-formed.

The vulnerability is exploited before proof verification occurs. The execution flow shows: [6](#0-5)  where `read_state_value()` loads all records into memory first, then the proof is loaded. Even if proof verification later fails at [7](#0-6) , the memory exhaustion has already occurred.

**Attack Scenario:**
1. Attacker compromises backup storage (cloud bucket, file server) or provides malicious backups to node operators
2. Attacker creates a chunk file with millions of tiny records (e.g., 10 million records Ã— 100 bytes = 1GB in memory)
3. Node operator initiates restore from backup [8](#0-7) 
4. For each chunk, `read_state_value()` allocates unbounded memory
5. Node runs out of memory and crashes before proof verification can reject the malicious data

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation
This is a **HIGH severity** vulnerability according to Aptos bug bounty criteria:

- **Validator node slowdowns/crashes**: Nodes attempting to restore from compromised backups will experience memory exhaustion and crash
- **Operational disruption**: Prevents validator nodes from bootstrapping or recovering from backups, impacting network availability
- **DoS vector**: While not affecting consensus directly (running nodes are unaffected), it prevents new nodes from joining or existing nodes from recovering

This does NOT qualify as Critical severity because:
- It does not affect consensus safety or cause chain splits
- It does not enable fund theft or minting
- Running validator nodes are not affected
- It requires backup storage compromise, not direct network attacks

## Likelihood Explanation
**MEDIUM likelihood** of exploitation:

**Attacker Requirements:**
- Compromise backup storage (cloud buckets, S3, GCS, etc.) or convince node operators to use untrusted backup sources
- Create malicious backup files with valid manifest structure but oversized chunks
- Node operators must attempt restore from these compromised backups

**Realistic Scenarios:**
- Cloud storage misconfigurations or compromises (common attack vector)
- Supply chain attacks on backup providers
- Man-in-the-middle attacks during backup downloads (if not using TLS)
- Social engineering to distribute "helpful" bootstrap snapshots

**Mitigating Factors:**
- Node operators typically trust their own backup infrastructure
- Backups may have cryptographic verification (though this occurs AFTER memory allocation)
- Not all nodes restore from backups frequently

## Recommendation
Implement chunk size validation during restore to match the limits enforced during backup creation:

```rust
async fn read_state_value(
    storage: &Arc<dyn BackupStorage>,
    file_handle: FileHandle,
) -> Result<Vec<(StateKey, StateValue)>> {
    let mut file = storage.open_for_read(&file_handle).await?;
    
    // Add configurable limit (default to max_chunk_size expectation)
    const MAX_RECORDS_PER_CHUNK: usize = 10_000_000; // Reasonable upper bound
    const MAX_CHUNK_BYTES: usize = 256 * 1024 * 1024; // 256MB safety margin
    
    let mut chunk = Vec::new();
    let mut total_bytes = 0usize;
    let mut record_count = 0usize;

    while let Some(record_bytes) = file.read_record_bytes().await? {
        record_count += 1;
        total_bytes += record_bytes.len();
        
        ensure!(
            record_count <= MAX_RECORDS_PER_CHUNK,
            "Chunk exceeds maximum record count: {} records (max: {})",
            record_count,
            MAX_RECORDS_PER_CHUNK
        );
        
        ensure!(
            total_bytes <= MAX_CHUNK_BYTES,
            "Chunk exceeds maximum byte size: {} bytes (max: {})",
            total_bytes,
            MAX_CHUNK_BYTES
        );
        
        chunk.push(bcs::from_bytes(&record_bytes)?);
    }

    Ok(chunk)
}
```

**Additional Safeguards:**
1. Pre-allocate vector capacity based on expected chunk size
2. Add telemetry/logging for abnormally large chunks
3. Consider streaming verification instead of loading entire chunks into memory
4. Document expected chunk size limits in manifest validation

## Proof of Concept
```rust
// PoC demonstrating memory exhaustion via malicious chunk file
// This would be run as a Rust integration test

use std::io::Write;
use tempfile::NamedTempFile;
use bytes::Bytes;

#[tokio::test]
async fn test_unbounded_chunk_memory_exhaustion() {
    // Create malicious chunk file with 10 million tiny records
    let mut chunk_file = NamedTempFile::new().unwrap();
    
    // Each record: 4-byte size + minimal StateKey/StateValue (50 bytes)
    let tiny_record = vec![0u8; 50];
    let record_size = (tiny_record.len() as u32).to_be_bytes();
    
    const MALICIOUS_RECORD_COUNT: usize = 10_000_000;
    
    for _ in 0..MALICIOUS_RECORD_COUNT {
        chunk_file.write_all(&record_size).unwrap();
        chunk_file.write_all(&tiny_record).unwrap();
    }
    chunk_file.flush().unwrap();
    
    // Total size: ~540 MB on disk, but will allocate ~500MB+ in RAM for Vec
    // On systems with limited memory, this will cause OOM
    
    // Attempt to restore (will exhaust memory)
    let file_handle = chunk_file.path().to_string_lossy().to_string();
    
    // This call will allocate unbounded memory and potentially crash
    // In production, this would happen during:
    // StateSnapshotRestoreController::run() -> read_state_value()
    
    // Expected: Should enforce MAX_RECORDS_PER_CHUNK limit
    // Actual: No limit, grows Vec unboundedly until OOM
}

// Attack script outline:
// 1. Create StateSnapshotBackup manifest with malicious chunk reference
// 2. Generate chunk file with 10M+ tiny records
// 3. Upload to backup storage or provide to target node operator
// 4. When restore is initiated, node crashes with OOM before proof verification
```

**Notes:**
- The vulnerability affects the backup-cli tool used by node operators for restoration, not the live consensus protocol
- While backups have cryptographic verification through LedgerInfo signatures [9](#0-8) , memory exhaustion occurs before this verification completes
- The restore coordinator processes chunks concurrently [10](#0-9) , potentially amplifying memory pressure if multiple malicious chunks are processed simultaneously

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L96-105)
```rust
    pub async fn run(self) -> Result<()> {
        let name = self.name();
        let start = Instant::now();
        info!("{} started. Manifest: {}", name, self.manifest_handle);
        self.run_impl()
            .await
            .map_err(|e| anyhow!("{} failed: {}", name, e))?;
        info!(time = start.elapsed().as_secs(), "{} succeeded.", name);
        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L125-136)
```rust
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L191-192)
```rust
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L198-199)
```rust
        let con = self.concurrent_downloads;
        let mut futs_stream = stream::iter(futs_iter).buffered_x(con * 2, con);
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L212-215)
```rust
            tokio::task::spawn_blocking(move || {
                receiver.lock().as_mut().unwrap().add_chunk(blobs, proof)
            })
            .await??;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L253-266)
```rust
    async fn read_state_value(
        storage: &Arc<dyn BackupStorage>,
        file_handle: FileHandle,
    ) -> Result<Vec<(StateKey, StateValue)>> {
        let mut file = storage.open_for_read(&file_handle).await?;

        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-67)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
        if record_buf.is_empty() {
            bail!("Hit EOF when reading record.")
        }

        Ok(Some(record_buf.freeze()))
    }
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L52-57)
```rust
    #[clap(
        long = "max-chunk-size",
        default_value_t = 134217728,
        help = "Maximum chunk file size in bytes."
    )]
    pub max_chunk_size: usize,
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L411-413)
```rust
pub(crate) fn should_cut_chunk(chunk: &[u8], record: &[u8], max_chunk_size: usize) -> bool {
    !chunk.is_empty() && chunk.len() + record.len() + size_of::<u32>() > max_chunk_size
}
```
