# Audit Report

## Title
Indexer File Store Backfiller Vulnerable to Version Number Manipulation Causing Data Integrity Loss and Denial of Service

## Summary
The indexer file store backfiller's batch formation logic trusts version numbers from untrusted gRPC sources without verification. By exploiting `pop_first()` semantics on a BTreeMap sorted by these unverified version numbers, a malicious fullnode can cause the backfiller to skip transaction batches, leading to permanent gaps in the file store and system hang.

## Finding Description

The backfiller's `backfill()` function receives transactions from a gRPC stream and buffers them in a BTreeMap keyed by version number. [1](#0-0) 

Transactions are inserted into this buffer using version numbers directly from the untrusted stream: [2](#0-1) 

Upon receiving a BatchEnd signal, the code pops the first 1000 transactions using `pop_first()`: [3](#0-2) 

The worker validation only checks internal batch consistency (alignment to 1000 and sequential ordering within the batch), but does NOT verify that the batch represents the correct next sequence of versions: [4](#0-3) 

**Attack Scenario:**
1. Attacker runs a malicious fullnode or compromises an existing one
2. Backfiller connects via gRPC requesting transactions starting from version 0
3. Malicious fullnode sends:
   - Versions 0-1999 normally
   - Then versions 3000-3999 (skipping 2000-2999)
4. BTreeMap contains: {0, 1, 2, ..., 1999, 3000, 3001, ..., 3999}
5. First BatchEnd pops versions 0-999 → uploaded successfully
6. Second BatchEnd pops versions 1000-1999 → uploaded successfully  
7. Third BatchEnd pops versions 3000-3999:
   - Validation passes (3000 % 1000 == 0 ✓, internally sequential ✓)
   - Batch uploaded to file store
8. Progress tracker waits for version 2000: [5](#0-4) 
9. System hangs indefinitely (version 2000 never arrives)
10. File store has permanent gap (versions 2000-2999 missing)

The fundamental issue is that the backfiller requests transactions from a specific starting version but never verifies that received transactions actually start from that version. [6](#0-5) 

Additionally, while the Aptos protocol includes cryptographic proofs in TransactionListWithProof structures, the backfiller performs no proof verification, making it fully trust the malicious data.

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **API/Infrastructure Crashes**: The backfiller becomes permanently hung, requiring manual intervention to restart with correct data source
2. **Significant Protocol Violations**: The indexer file store, which serves as the source of truth for downstream consumers, contains permanent gaps
3. **Data Integrity Loss**: Any service depending on the file store for complete historical transaction data will have missing batches
4. **No Automatic Recovery**: The system cannot self-recover; requires manual detection, debugging, and data remediation

This falls under the "Validator node slowdowns" and "API crashes" categories worth up to $50,000 in the bug bounty program.

## Likelihood Explanation

**Medium to High Likelihood:**

**Feasibility:**
- Anyone can run a fullnode and point the backfiller at it
- No privileged access required
- No cryptographic barriers (no proof verification)
- Simple attack: modify fullnode to send arbitrary version numbers

**Probability:**
- Accidental: Database corruption or network issues could cause similar symptoms
- Intentional: Attacker motivation exists (disrupting indexer infrastructure, causing downstream service failures)
- The TODO comment at line 148 suggests developers are aware of potential data structure issues but haven't addressed the security implications

**Detection Difficulty:**
- Gap may not be immediately obvious
- Progress tracking silently hangs
- No alerts for missing batches
- Requires manual inspection of file store completeness

## Recommendation

**Immediate Fixes:**

1. **Verify received version sequence before batch formation:**
```rust
// After line 283, before batching:
let expected_next = self.starting_version + (num_processed * 1000);
for txn in &transactions {
    if txn.version < expected_next || txn.version >= expected_next + transactions_count {
        anyhow::bail!("Received transaction version {} outside expected range [{}, {})", 
                      txn.version, expected_next, expected_next + transactions_count);
    }
}
```

2. **Add validation at batch formation:**
```rust
// At line 294, verify batch starts at expected version:
let expected_start = next_version_to_process;
let (first_version, _) = transactions_buffer.first_key_value()
    .ok_or_else(|| anyhow::anyhow!("Buffer empty"))?;
ensure!(*first_version == expected_start, 
        "Batch formation error: expected version {}, got {}",
        expected_start, first_version);
```

3. **Implement cryptographic proof verification:**
    - Use the existing `TransactionListWithProof::verify()` methods
    - Verify against trusted LedgerInfo from a known-good source
    - Reject any transactions failing proof validation

4. **Add comprehensive monitoring:**
    - Alert on version gaps in buffer
    - Track expected vs. received version ranges  
    - Log and alert on validation failures

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_malicious_fullnode_version_skip() {
    // Setup: Create backfiller expecting versions 0-2999
    let mut processor = create_test_processor(0, Some(3000)).await;
    
    // Attack: Malicious fullnode sends versions with gap
    let malicious_stream = create_malicious_stream(vec![
        // Send normal batches 0-1999
        create_batch(0, 1000),
        create_batch(1000, 1000),
        // Skip 2000-2999, send 3000-3999 instead
        create_batch(3000, 1000),
    ]);
    
    // Expected: System should detect gap and reject
    // Actual: System processes batch 3000-3999 and hangs
    let result = processor.backfill_with_stream(malicious_stream).await;
    
    // Verify vulnerability:
    // 1. Batch 3000-3999 was uploaded to file store
    assert!(file_store.has_batch(3000));
    // 2. Batch 2000-2999 is missing (gap)
    assert!(!file_store.has_batch(2000));
    // 3. Progress tracker is stuck at 2000
    assert_eq!(read_progress_file(), 2000);
    // 4. System is hung (result times out or hangs)
    assert!(result.is_err() || times_out(result));
}
```

---

**Notes**

This vulnerability specifically affects the indexer infrastructure layer, not consensus or on-chain security. However, it represents a significant data integrity and availability issue for the Aptos indexer ecosystem. The root cause is insufficient input validation and missing cryptographic proof verification despite the protocol providing these mechanisms.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L107-110)
```rust
        let request = tonic::Request::new(GetTransactionsFromNodeRequest {
            starting_version: Some(expected_starting_version),
            transactions_count,
        });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L146-147)
```rust
        let mut transactions_buffer = BTreeMap::new();
        let mut next_version_to_process = self.starting_version;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L189-199)
```rust
                        ensure!(transactions.len() == 1000, "Unexpected transaction count");
                        ensure!(
                            transactions[0].version % 1000 == 0,
                            "Unexpected starting version"
                        );
                        for (ide, t) in transactions.iter().enumerate() {
                            ensure!(
                                t.version == transactions[0].version + ide as u64,
                                "Unexpected version"
                            );
                        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L227-233)
```rust
                            if finished_starting_versions.contains(&next_version_to_process) {
                                finished_starting_versions.remove(&next_version_to_process);
                                next_version_to_process += 1000;
                                need_to_update = true;
                            } else {
                                break;
                            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L280-284)
```rust
                    for txn in transactions {
                        let version = txn.version;
                        // Partial batch may be received; split and insert into buffer.
                        transactions_buffer.insert(version, txn);
                    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L290-298)
```rust
                    while transactions_buffer.len() >= 1000 {
                        // Take the first 1000 transactions.
                        let mut transactions = Vec::new();
                        // Pop the first 1000 transactions from buffer.
                        for _ in 0..1000 {
                            let (_, txn) = transactions_buffer.pop_first().unwrap();
                            transactions.push(txn);
                        }
                        sender.send(transactions).await?;
```
