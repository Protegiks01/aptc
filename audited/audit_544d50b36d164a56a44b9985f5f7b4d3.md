# Audit Report

## Title
Consensus Safety Violation via Missing fsync in OnDiskStorage Allows Stale one_chain_round After Crash

## Summary
The `OnDiskStorage.write()` method lacks an explicit `fsync` call before returning success, creating a durability gap where safety-critical consensus state (`one_chain_round`) can be lost during crashes. This allows validators to sign timeouts that violate the 2-chain consensus safety invariant after restart, potentially enabling consensus safety violations.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Order Vote Construction**: When `guarded_construct_and_sign_order_vote()` processes an order vote proposal, it updates `one_chain_round` in memory via `observe_qc()` [1](#0-0) 

2. **State Persistence**: The updated safety data is then persisted to disk [2](#0-1) 

3. **Missing fsync**: The `OnDiskStorage.write()` method writes data but never calls `sync_all()` or `sync_data()` on the file handle before returning [3](#0-2) 

**Attack Scenario:**

1. Validator receives order vote proposal with QC for round 10
2. `observe_qc()` updates `one_chain_round` to 10 in memory
3. Order vote is signed and constructed successfully
4. `set_safety_data()` writes to disk without fsync
5. Function returns `Ok(order_vote)` - vote may be broadcast
6. **Power failure or kernel panic** before OS flushes write buffers
7. On restart, file contains old data with `one_chain_round = 5`
8. Validator receives timeout request with QC for round 6
9. Safety check `qc_round >= safety_data.one_chain_round` evaluates to `6 >= 5` (PASSES incorrectly)
10. Validator signs timeout, violating the consensus invariant

**Invariant Violation:**

The 2-chain consensus protocol enforces: "A validator MUST NOT sign a timeout if the timeout's QC round is less than the highest observed 1-chain round" [4](#0-3) 

With stale `one_chain_round`, this check passes incorrectly, allowing the validator to participate in both:
- Order voting on round 10 (before crash)  
- Timeout voting with QC for round 6 (after crash)

This breaks the safety guarantee that prevents validators from supporting conflicting consensus paths.

## Impact Explanation

**Medium Severity** per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: The validator's persisted safety state becomes inconsistent with its actual voting history
- **Potential Consensus Safety Impact**: If multiple validators experience this race condition (e.g., during datacenter power events), it could contribute to BFT safety violations
- **Not Critical** because: Requires specific crash timing and affects individual validators probabilistically rather than being a deterministic exploit

The vulnerability meets the Medium severity category defined as "State inconsistencies requiring intervention" - operators would need to manually reconcile validator safety state after crashes to ensure consensus safety.

## Likelihood Explanation

**Medium-Low Likelihood:**
- Requires crash/power failure during narrow timing window (between write() and OS buffer flush)
- Modern filesystems and OS write-back caching make this window 10-100ms typically  
- More likely in environments with:
  - Frequent power failures
  - Aggressive OS write caching
  - High consensus throughput (more order votes = more opportunities)
  - Hardware failures (disk controller issues)
  
**Not Exploitable by External Attacker:**
- External attackers cannot trigger crashes at precise timing
- Would require physical access or separate vulnerability to crash validator
- Natural occurrence rather than deliberate exploit

**Realistic in Production:**
- Validators run in datacenters with potential power events
- Software crashes from other bugs could trigger this
- Risk increases with network scale (more validators = higher probability)

## Recommendation

Add explicit fsync before the rename operation in `OnDiskStorage.write()`:

```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    let mut file = File::create(self.temp_path.path())?;
    file.write_all(&contents)?;
    file.sync_all()?;  // ADD THIS LINE - ensure data is durably persisted
    fs::rename(&self.temp_path, &self.file_path)?;
    Ok(())
}
```

The fix ensures that:
1. All data is flushed from OS buffers to disk
2. File metadata is synced
3. Only after durable persistence does the function return success
4. The atomic rename then switches to the new file

**Alternative consideration**: Use `sync_data()` instead of `sync_all()` if metadata sync latency is too high, though `sync_all()` provides stronger guarantees.

## Proof of Concept

```rust
// Reproduction test for OnDiskStorage durability issue
// Place in: secure/storage/src/on_disk.rs tests section

#[test]
fn test_ondisk_storage_durability_race() {
    use std::process::{Command, Stdio};
    use tempfile::TempDir;
    
    let temp_dir = TempDir::new().unwrap();
    let storage_path = temp_dir.path().join("safety_data.json");
    
    // Simulate the race condition:
    // 1. Write safety data with one_chain_round = 10
    // 2. Don't sync
    // 3. Simulate crash by forcibly dropping without proper cleanup
    // 4. Read back - may see stale data depending on OS write buffering
    
    let mut storage = OnDiskStorage::new(storage_path.clone());
    
    // Write initial state
    let initial_data = SafetyData::new(1, 0, 0, 5, None, 0);
    storage.set("safety_data", initial_data.clone()).unwrap();
    
    // Write updated state (simulating order vote updating one_chain_round)
    let updated_data = SafetyData::new(1, 0, 0, 10, None, 0);
    storage.set("safety_data", updated_data.clone()).unwrap();
    
    // Simulate crash by dropping storage without proper cleanup
    // In real scenario, this would be kernel panic or power loss
    // before OS flushes buffers
    drop(storage);
    
    // Force unclean shutdown simulation
    // In production this would be actual power loss
    
    // Read back after "restart"
    let mut restarted_storage = OnDiskStorage::new(storage_path);
    let recovered_data: SafetyData = restarted_storage
        .get("safety_data")
        .unwrap()
        .value;
    
    // Without fsync, one_chain_round may be stale (5 instead of 10)
    // This demonstrates the durability gap
    println!("Recovered one_chain_round: {} (expected 10)", 
             recovered_data.one_chain_round);
    
    // The test would need actual crash simulation to reliably reproduce
    // In practice, this requires:
    // - Process crash during write window
    // - OS buffer not yet flushed to disk
    // - Probabilistic rather than deterministic
}
```

**Notes:**
- The durability issue is inherent to missing fsync, confirmed by code inspection [3](#0-2) 
- Reliable reproduction requires actual crash injection (SIGKILL during write window)
- Impact on consensus safety depends on timing and number of affected validators
- The vulnerability affects the consensus safety invariant enforcement [4](#0-3)

### Citations

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L108-108)
```rust
        self.observe_qc(order_vote_proposal.quorum_cert(), &mut safety_data);
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L117-117)
```rust
        self.persistent_storage.set_safety_data(safety_data)?;
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L121-145)
```rust
    /// Core safety timeout rule for 2-chain protocol. Return success if 1 and 2 are true
    /// 1. round == timeout.qc.round + 1 || round == tc.round + 1
    /// 2. timeout.qc.round >= one_chain_round
    fn safe_to_timeout(
        &self,
        timeout: &TwoChainTimeout,
        maybe_tc: Option<&TwoChainTimeoutCertificate>,
        safety_data: &SafetyData,
    ) -> Result<(), Error> {
        let round = timeout.round();
        let qc_round = timeout.hqc_round();
        let tc_round = maybe_tc.map_or(0, |tc| tc.round());
        if (round == next_round(qc_round)? || round == next_round(tc_round)?)
            && qc_round >= safety_data.one_chain_round
        {
            Ok(())
        } else {
            Err(Error::NotSafeToTimeout(
                round,
                qc_round,
                tc_round,
                safety_data.one_chain_round,
            ))
        }
    }
```

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```
