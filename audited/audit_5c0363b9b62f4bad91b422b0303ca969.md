# Audit Report

## Title
Unhandled Metric Encoding Failures Cause Cascading Cache Worker Process Termination

## Summary
The indexer-grpc-cache-worker's metrics endpoint handler uses `.unwrap()` when encoding Prometheus metrics, causing the entire cache worker process to terminate via `process::exit(1)` if metric encoding fails. This violates fault isolation principles and causes indexer service degradation.

## Finding Description
The security question asks whether Prometheus metric collection errors are silently ignored or cascade to cache worker failures. The answer is: **they cascade catastrophically**.

In the metrics endpoint handler, metric encoding errors cause process termination: [1](#0-0) 

The `.unwrap()` on line 212 causes a panic if `encoder.encode()` fails. This panic occurs in the `probes_and_metrics_handler` task.

The server framework's task orchestration shows that if the probes/metrics handler panics, it terminates the entire process: [2](#0-1) 

When the metrics handler task fails (line 60-66), it calls `process::exit(1)`, killing the cache worker entirely.

The cache worker uses this framework: [3](#0-2) 

**How errors propagate:**
1. Prometheus metrics are registered at startup with `.unwrap()` [4](#0-3) 
2. During runtime, metrics are incremented throughout the worker [5](#0-4) 
3. When Prometheus scrapes `/metrics`, encoding occurs
4. If encoding fails (OOM, corrupted state, encoder bug), it panics the handler
5. Handler panic triggers `process::exit(1)`, terminating the cache worker

## Impact Explanation
This qualifies as **Medium Severity** under "State inconsistencies requiring intervention" category because:

1. **Indexer Service Degradation**: Cache worker termination stops transaction cache updates, forcing clients to use slower file store access
2. **Requires Manual Intervention**: The process must be manually restarted
3. **Poor Fault Isolation**: A non-critical component (metrics) crashes a critical service component

However, this is **NOT** a high-severity vulnerability because:
- The indexer is not consensus-critical
- No funds are at risk
- No blockchain state corruption occurs
- Other indexer components continue functioning

## Likelihood Explanation
**Low likelihood** in normal operation. Metric encoding failures are rare and typically occur only due to:
- Extreme memory pressure (OOM during encoding)
- Internal Prometheus encoder bugs (very rare)
- Corrupted metric state (unlikely in safe Rust)

However, the **design flaw is certain**: any metric encoding failure WILL crash the process.

## Recommendation
Replace the `.unwrap()` with graceful error handling, following the pattern used in other Aptos components: [6](#0-5) 

**Recommended fix** for `ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs` lines 203-217:

```rust
let metrics_endpoint = warp::path("metrics").map(|| {
    let metrics = aptos_metrics_core::gather();
    let mut encode_buffer = vec![];
    let encoder = TextEncoder::new();
    
    // Handle encoding errors gracefully instead of panicking
    if let Err(error) = encoder.encode(&metrics, &mut encode_buffer) {
        error!("Failed to encode metrics: {}", error);
        return Response::builder()
            .status(warp::http::StatusCode::INTERNAL_SERVER_ERROR)
            .body(b"Failed to encode metrics".to_vec());
    }

    Response::builder()
        .header("Content-Type", "text/plain")
        .body(encode_buffer)
});
```

This logs the error and returns HTTP 500 instead of crashing the process.

## Proof of Concept
This vulnerability is difficult to demonstrate with a reliable PoC because metric encoding is extremely stable. However, the logic flow can be traced:

```rust
// Simulated test (conceptual - requires mocking encoder failures)
#[tokio::test]
async fn test_metric_encoding_failure_crashes_worker() {
    // 1. Start cache worker with normal config
    // 2. Simulate metric encoding failure (requires patching Prometheus encoder)
    // 3. Make request to /metrics endpoint
    // 4. Observe: Process exits with code 1 instead of returning HTTP 500
    // Expected: Process should continue running, return 500 for that request
}
```

## Notes
While this passes some validation criteria (lies in Aptos Core, affects availability), it **fails critical checks**:
- Not exploitable by unprivileged attacker without DoS (excluded from scope)
- Doesn't break any of the 10 critical Aptos invariants
- Affects off-chain indexer, not consensus/execution/state management
- No realistic attack path without resource exhaustion

This is better classified as an **operational reliability issue** rather than a security vulnerability. The indexer-grpc-cache-worker is infrastructure for serving data to external clients, not part of core blockchain security.

**Assessment**: While the error handling should be fixed, this does not meet the strict criteria for a bounty-eligible security vulnerability per the exclusions (DoS attacks out of scope, non-consensus-critical component).

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L53-76)
```rust
    let task_handler = tokio::spawn(async move {
        register_probes_and_metrics_handler(config_clone, health_port).await;
        anyhow::Ok(())
    });
    let main_task_handler =
        tokio::spawn(async move { config.run().await.expect("task should exit with Ok.") });
    tokio::select! {
        res = task_handler => {
            if let Err(e) = res {
                error!("Probes and metrics handler panicked or was shutdown: {:?}", e);
                process::exit(1);
            } else {
                panic!("Probes and metrics handler exited unexpectedly");
            }
        },
        res = main_task_handler => {
            if let Err(e) = res {
                error!("Main task panicked or was shutdown: {:?}", e);
                process::exit(1);
            } else {
                panic!("Main task exited unexpectedly");
            }
        },
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L203-217)
```rust
    let metrics_endpoint = warp::path("metrics").map(|| {
        // Metrics encoding.
        let metrics = aptos_metrics_core::gather();
        let mut encode_buffer = vec![];
        let encoder = TextEncoder::new();
        // If metrics encoding fails, we want to panic and crash the process.
        encoder
            .encode(&metrics, &mut encode_buffer)
            .context("Failed to encode metrics")
            .unwrap();

        Response::builder()
            .header("Content-Type", "text/plain")
            .body(encode_buffer)
    });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/lib.rs (L44-66)
```rust
#[async_trait::async_trait]
impl RunnableConfig for IndexerGrpcCacheWorkerConfig {
    async fn run(&self) -> Result<()> {
        let mut worker = Worker::new(
            self.fullnode_grpc_address.clone(),
            self.redis_main_instance_address.clone(),
            self.file_store_config.clone(),
            self.enable_cache_compression,
        )
        .await
        .context("Failed to create cache worker")?;
        worker
            .run()
            .await
            .context("Failed to run cache worker")
            .expect("Cache worker failed");
        Ok(())
    }

    fn get_server_name(&self) -> String {
        "idxcachewrkr".to_string()
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/metrics.rs (L10-17)
```rust
pub static ERROR_COUNT: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "indexer_grpc_cache_worker_errors",
        "Number of errors that cache worker has encountered",
        &["error_type"]
    )
    .unwrap()
});
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L268-270)
```rust
                            ERROR_COUNT
                                .with_label_values(&["failed_to_update_cache_version"])
                                .inc();
```

**File:** crates/aptos-inspection-service/src/server/utils.rs (L32-47)
```rust
pub fn get_encoded_metrics(encoder: impl Encoder) -> Vec<u8> {
    // Gather and encode the metrics
    let metric_families = get_metric_families();
    let mut encoded_buffer = vec![];
    if let Err(error) = encoder.encode(&metric_families, &mut encoded_buffer) {
        error!("Failed to encode metrics! Error: {}", error);
        return vec![];
    }

    // Update the total metric bytes counter
    NUM_METRICS
        .with_label_values(&["total_bytes"])
        .inc_by(encoded_buffer.len() as u64);

    encoded_buffer
}
```
