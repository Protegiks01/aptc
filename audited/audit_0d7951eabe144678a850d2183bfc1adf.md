# Audit Report

## Title
Insufficient Distance Validation Enables Peer Selection Monopolization in State Sync

## Summary
The state sync peer selection mechanism trusts self-reported `distance_from_validators` values from peers without proper validation for distances ≥2. Attackers can forge low distance values to monopolize state sync request handling, enabling denial-of-service attacks against syncing nodes and potential eclipse attacks.

## Finding Description

The vulnerability exists in the peer monitoring service's validation of network distance metadata. When a peer responds with its `distance_from_validators`, the client performs sanity checks but fails to properly validate distances ≥2. [1](#0-0) 

For distance values of 0 or 1, strict validation occurs checking peer roles and network IDs. However, for distance ≥2, only a trivial upper bound check is performed (≤100), with no validation that the distance is topologically correct or consistent with the peer's actual network position.

The distance calculation itself relies on a trust chain where each peer trusts the self-reported distances from its connected peers: [2](#0-1) 

This creates a vulnerability where a malicious peer can claim an arbitrarily low distance (e.g., 2) without any mechanism to verify this claim against the actual network topology.

The peer selection algorithm in state sync uses distance as a primary selection criterion: [3](#0-2) 

The function groups peers by distance using a BTreeMap (which sorts by key), then iterates through distances in ascending order, preferentially selecting peers with lower distances. This is used for both optimistic fetch requests and subscription requests: [4](#0-3) [5](#0-4) 

**Attack Scenario:**

1. Attacker operates a modified public fullnode that reports `distance_from_validators = 2`
2. Legitimate public fullnodes typically have distance 3-6+ (validator → VFN → PFN chains)
3. The forged distance passes validation (2 ≤ 100)
4. When state sync selects peers, the malicious node is heavily prioritized
5. The attacker monopolizes state sync requests, enabling:
   - Serving stale (but cryptographically valid) data to slow synchronization
   - Selective request dropping to cause sync stalls
   - Eclipse attacks when combined with multiple malicious nodes
   - Resource exhaustion through inefficient responses

While cryptographic proof verification prevents serving truly invalid data, attackers can serve old but valid blocks that pass all verification checks, significantly degrading sync performance.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria:

- **Validator node slowdowns**: Validators attempting to sync or catch up would be directed to malicious peers, causing significant synchronization delays
- **Significant protocol violations**: The peer selection protocol's trust assumptions are violated, breaking the intended security model
- **Availability impact**: Coordinated attacks using multiple malicious nodes with forged distances could effectively eclipse targeted nodes from the honest network

While this does not directly enable consensus breaks or fund theft (due to proof verification), it represents a significant attack on network liveness and availability. In scenarios where rapid synchronization is critical (e.g., validators rejoining after downtime), this could impact network operation.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attack complexity**: Low - requires only running modified node software
- **Attacker requirements**: Minimal - any entity can join the public network
- **Detection difficulty**: Medium - malicious behavior may be gradual and hard to distinguish from legitimate network issues
- **Economic incentive**: Various motivations including:
  - Disrupting competitor validators
  - Preparing for subsequent attacks
  - Degrading network reputation
  - Censorship or selective targeting

The attack is highly feasible because:
1. No special privileges or stake is required
2. The malicious peer appears legitimate initially (passes validation)
3. Peer scoring degrades malicious peers slowly over time
4. Attackers can rotate through multiple malicious nodes

## Recommendation

Implement proper topological validation for distance values ≥2. The validation should verify that a peer's claimed distance is consistent with measurable network properties:

1. **Stricter role-based validation**: Extend distance validation to check peer roles for all distance values:
   - Distance 2: Should typically be PFNs connected to VFNs
   - Distance 3+: Verify claimed distance is reasonable given peer role

2. **Relative distance validation**: Before accepting a peer's distance, validate it against our own calculated distance:
   ```rust
   // In handle_monitoring_service_response, add:
   let our_distance = get_distance_from_validators(&self.base_config, peers_and_metadata);
   let reasonable_peer_distance = peer_distance <= our_distance + 1 && 
                                   peer_distance >= our_distance.saturating_sub(1);
   if !reasonable_peer_distance && peer_distance >= 2 {
       // Reject implausible distance claims
   }
   ```

3. **Cross-validation with multiple peers**: Track distance claims from multiple peers and flag outliers:
   - Maintain a running distribution of peer distances
   - Reject distance claims that are statistical outliers
   - Implement reputation decay for peers with inconsistent distance reporting

4. **Independent distance measurement**: Implement active probing to verify distance claims:
   - Query a peer's connected peers and verify their reported topology
   - Cross-reference with known validator sets from consensus
   - Use timing-based heuristics as a sanity check

## Proof of Concept

```rust
#[cfg(test)]
mod test_distance_forgery {
    use super::*;
    use aptos_config::{
        config::{BaseConfig, NodeConfig, PeerRole, RoleType},
        network_id::{NetworkId, PeerNetworkId},
    };
    use aptos_network::application::storage::PeersAndMetadata;
    use aptos_peer_monitoring_service_types::{
        response::NetworkInformationResponse, PeerMonitoringMetadata,
    };
    use aptos_types::PeerId;
    use std::collections::BTreeMap;
    use std::sync::Arc;

    #[test]
    fn test_malicious_peer_monopolizes_selection() {
        // Setup: Create peers with various distances
        let peers_and_metadata = Arc::new(PeersAndMetadata::new(&[]));
        
        // Legitimate peers at realistic distances
        let legitimate_peer_1 = PeerNetworkId::new(NetworkId::Public, PeerId::random());
        let legitimate_peer_2 = PeerNetworkId::new(NetworkId::Public, PeerId::random());
        update_peer_distance(&peers_and_metadata, legitimate_peer_1, 5, 0.1);
        update_peer_distance(&peers_and_metadata, legitimate_peer_2, 6, 0.1);
        
        // Malicious peer claiming false low distance
        let malicious_peer = PeerNetworkId::new(NetworkId::Public, PeerId::random());
        update_peer_distance(&peers_and_metadata, malicious_peer, 2, 0.1); // FORGED!
        
        // Create serviceable peers set
        let mut serviceable_peers = HashSet::new();
        serviceable_peers.insert(legitimate_peer_1);
        serviceable_peers.insert(legitimate_peer_2);
        serviceable_peers.insert(malicious_peer);
        
        // Perform peer selection multiple times
        let mut malicious_selected = 0;
        let num_trials = 100;
        
        for _ in 0..num_trials {
            let selected = choose_random_peers_by_distance_and_latency(
                serviceable_peers.clone(),
                peers_and_metadata.clone(),
                1,
            );
            
            if selected.contains(&malicious_peer) {
                malicious_selected += 1;
            }
        }
        
        // Malicious peer should be selected disproportionately often
        // With distance 2 vs 5,6 and equal latency, it should be selected ~90%+ of the time
        assert!(
            malicious_selected > 80,
            "Malicious peer with forged distance was selected {} times out of {}, \
             demonstrating selection bias",
            malicious_selected, num_trials
        );
    }
    
    fn update_peer_distance(
        peers_and_metadata: &Arc<PeersAndMetadata>,
        peer: PeerNetworkId,
        distance: u64,
        latency: f64,
    ) {
        let metadata = PeerMonitoringMetadata::new(
            Some(latency),
            Some(latency),
            Some(NetworkInformationResponse {
                connected_peers: BTreeMap::new(),
                distance_from_validators: distance,
            }),
            None,
            None,
        );
        peers_and_metadata.update_peer_monitoring_metadata(peer, metadata).unwrap();
    }
}
```

This proof of concept demonstrates that a malicious peer with a forged low distance value will be preferentially selected for state sync requests, confirming the vulnerability's exploitability.

### Citations

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L116-141)
```rust
        // Sanity check the response depth from the peer metadata
        let network_id = peer_network_id.network_id();
        let is_valid_depth = match network_info_response.distance_from_validators {
            0 => {
                // Verify the peer is a validator and has the correct network id
                let peer_is_validator = peer_metadata.get_connection_metadata().role.is_validator();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_validator_network(), // We're a validator
                    RoleType::FullNode => network_id.is_vfn_network(),        // We're a VFN
                };
                peer_is_validator && peer_has_correct_network
            },
            1 => {
                // Verify the peer is a VFN and has the correct network id
                let peer_is_vfn = peer_metadata.get_connection_metadata().role.is_vfn();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_vfn_network(), // We're a validator
                    RoleType::FullNode => network_id.is_public_network(), // We're a VFN or PFN
                };
                peer_is_vfn && peer_has_correct_network
            },
            distance_from_validators => {
                // The distance must be less than or equal to the max
                distance_from_validators <= MAX_DISTANCE_FROM_VALIDATORS
            },
        };
```

**File:** peer-monitoring-service/server/src/lib.rs (L296-340)
```rust
/// Returns the distance from the validators using the given base config
/// and the peers and metadata information.
fn get_distance_from_validators(
    base_config: &BaseConfig,
    peers_and_metadata: Arc<PeersAndMetadata>,
) -> u64 {
    // Get the connected peers and metadata
    let connected_peers_and_metadata = match peers_and_metadata.get_connected_peers_and_metadata() {
        Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
        Err(error) => {
            warn!(LogSchema::new(LogEntry::PeerMonitoringServiceError).error(&error.into()));
            return MAX_DISTANCE_FROM_VALIDATORS;
        },
    };

    // If we're a validator and we have active validator peers, we're in the validator set.
    // TODO: figure out if we need to deal with validator set forks here.
    if base_config.role.is_validator() {
        for peer_metadata in connected_peers_and_metadata.values() {
            if peer_metadata.get_connection_metadata().role.is_validator() {
                return 0;
            }
        }
    }

    // Otherwise, go through our peers, find the min, and return a distance relative to the min
    let mut min_peer_distance_from_validators = MAX_DISTANCE_FROM_VALIDATORS;
    for peer_metadata in connected_peers_and_metadata.values() {
        if let Some(ref latest_network_info_response) = peer_metadata
            .get_peer_monitoring_metadata()
            .latest_network_info_response
        {
            min_peer_distance_from_validators = min(
                min_peer_distance_from_validators,
                latest_network_info_response.distance_from_validators,
            );
        }
    }

    // We're one hop away from the peer
    min(
        MAX_DISTANCE_FROM_VALIDATORS,
        min_peer_distance_from_validators + 1,
    )
}
```

**File:** state-sync/aptos-data-client/src/utils.rs (L26-64)
```rust
pub fn choose_random_peers_by_distance_and_latency(
    peers: HashSet<PeerNetworkId>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    num_peers_to_choose: usize,
) -> HashSet<PeerNetworkId> {
    // Group peers and latency weights by validator distance, i.e., distance -> [(peer, latency weight)]
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for peer in peers {
        if let Some((distance, latency)) =
            get_distance_and_latency_for_peer(&peers_and_metadata, peer)
        {
            let latency_weight = convert_latency_to_weight(latency);
            peers_and_latencies_by_distance
                .entry(distance)
                .or_insert_with(Vec::new)
                .push((peer, latency_weight));
        }
    }

    // Select the peers by distance and latency weights. Note: BTreeMaps are
    // sorted by key, so the entries will be sorted by distance in ascending order.
    let mut selected_peers = HashSet::new();
    for (_, peers_and_latencies) in peers_and_latencies_by_distance {
        // Select the peers by latency weights
        let num_peers_remaining = num_peers_to_choose.saturating_sub(selected_peers.len()) as u64;
        let peers = choose_random_peers_by_weight(num_peers_remaining, peers_and_latencies);

        // Add the peers to the entire set
        selected_peers.extend(peers);

        // If we have selected enough peers, return early
        if selected_peers.len() >= num_peers_to_choose {
            return selected_peers;
        }
    }

    // Return the selected peers
    selected_peers
}
```

**File:** state-sync/aptos-data-client/src/client.rs (L346-365)
```rust
    /// Chooses several peers to service the given optimistic fetch
    /// request. Peers are selected first by priority, and then by
    /// validator distance and latency (within priority groups).
    fn choose_peers_for_optimistic_fetch(
        &self,
        request: &StorageServiceRequest,
        serviceable_peers_by_priorities: Vec<HashSet<PeerNetworkId>>,
        num_peers_for_request: usize,
    ) -> crate::error::Result<HashSet<PeerNetworkId>, Error> {
        // Select peers by priority (starting with the highest priority first)
        let mut selected_peers = HashSet::new();
        for serviceable_peers in serviceable_peers_by_priorities {
            // Select peers by distance and latency
            let num_peers_remaining = num_peers_for_request.saturating_sub(selected_peers.len());
            let peers = self.choose_random_peers_by_distance_and_latency(
                serviceable_peers,
                num_peers_remaining,
            );

            // Add the peers to the entire set
```

**File:** state-sync/aptos-data-client/src/client.rs (L505-510)
```rust
        // Otherwise, choose a new peer to handle the subscription request
        let selected_peer = self
            .choose_random_peers_by_distance_and_latency(serviceable_peers, 1)
            .into_iter()
            .next();

```
