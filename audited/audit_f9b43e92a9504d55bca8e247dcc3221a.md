# Audit Report

## Title
State KV Database Recovery Fails to Validate Per-Shard Progress Leading to Consensus Failure

## Summary

The `get_state_kv_commit_progress()` function used during database recovery in `open_sharded()` only reads the overall commit progress from the metadata database without checking individual shard progress values. This can lead to incomplete or incorrect truncation where some shards have their progress metadata set higher than their actual data, causing state inconsistency and consensus failures across the network.

## Finding Description

The vulnerability exists in the state KV database recovery logic during node restart. When `StateKvDb::open_sharded()` is called, it invokes recovery truncation to ensure database consistency: [1](#0-0) 

The `get_state_kv_commit_progress()` function only reads the overall `StateKvCommitProgress` from the metadata database: [2](#0-1) [3](#0-2) 

This implementation does NOT check the per-shard progress values (`StateKvShardCommitProgress(shard_id)`) that are stored in each individual shard database: [4](#0-3) 

The problem is that during normal commits, each shard writes its own progress, and only after all shards succeed is the overall progress written: [5](#0-4) 

**The Critical Flaw:** If database inconsistency occurs (through corruption, partial restore, disk failure, or bugs), some shards may have less data than the overall progress indicates. The recovery code will then call `truncate_state_kv_db_single_shard()` which blindly sets each shard's progress to the overall progress value without verifying the shard actually has data up to that version: [6](#0-5) 

**Attack Scenario:**
1. Database has overall progress = 1000 in metadata DB
2. Shards 0-14 have actual data and progress = 1000
3. Shard 15 has actual data only up to version 999 (due to corruption/restore issue)
4. Node restarts, recovery reads overall progress = 1000
5. Truncation sets shard 15's progress metadata to 1000, but actual data still only goes to 999
6. System now believes shard 15 has data for version 1000, but it doesn't
7. Queries for version 1000 state keys in shard 15 return no data
8. Different nodes compute different state roots for version 1000
9. **Consensus failure** - network cannot agree on state

**Contrast with Pruner Code:** The pruner subsystem correctly handles this by checking each shard's progress individually: [7](#0-6) [8](#0-7) 

The pruner uses `get_or_initialize_subpruner_progress()` which reads each shard's progress and ensures consistency with the metadata progress. The commit recovery code lacks this crucial check.

## Impact Explanation

This vulnerability meets **High Severity** criteria as specified in the security question:

1. **Consensus Violations:** Nodes with inconsistent shard data will compute different state roots for the same version, causing consensus disagreement and potential network splits.

2. **State Consistency Violation:** Breaks the critical invariant that "State transitions must be atomic and verifiable via Merkle proofs." The state root will be incorrect because it includes data that doesn't exist in all shards.

3. **Non-Recoverable Without Intervention:** Once shard progress metadata is incorrectly set ahead of actual data, normal operations cannot detect or fix this. Manual database reconstruction may be required.

4. **Affects All Validators:** Any validator experiencing database corruption, backup/restore issues, or disk failures could encounter this bug, propagating inconsistency across the network.

This directly impacts consensus safety and state consistency, which are foundation-level guarantees required for blockchain operation.

## Likelihood Explanation

**High Likelihood** due to multiple triggering scenarios:

1. **Hardware Failures:** Disk corruption affecting some shard DBs but not the metadata DB
2. **Backup/Restore Operations:** Restoring from backups where metadata DB and shard DBs are from different points in time
3. **Partial Crashes:** System crashes that corrupt some but not all database files
4. **Manual Interventions:** Database maintenance or debugging operations that modify metadata without updating all shards
5. **Software Bugs:** Any bug in the commit path that allows overall progress to advance without all shards succeeding (despite panic protection)

The vulnerability is deterministic once the inconsistent state occurs - every node restart will set incorrect progress metadata. There's no randomness or timing dependency.

## Recommendation

Modify `open_sharded()` to check all shard progress values and use the minimum, following the same pattern as the pruner code:

```rust
pub(crate) fn open_sharded(
    db_paths: &StorageDirPaths,
    state_kv_db_config: RocksdbConfig,
    env: Option<&Env>,
    block_cache: Option<&Cache>,
    readonly: bool,
) -> Result<Self> {
    // ... existing code to open metadata DB and shards ...
    
    let state_kv_db = Self {
        state_kv_metadata_db,
        state_kv_db_shards,
        hot_state_kv_db_shards,
        enabled_sharding: true,
    };

    if !readonly {
        // Get overall progress from metadata DB
        let metadata_progress = get_state_kv_commit_progress(&state_kv_db)?;
        
        if let Some(metadata_progress) = metadata_progress {
            // Check each shard's progress and find minimum
            let mut min_shard_progress = metadata_progress;
            for shard_id in 0..NUM_STATE_SHARDS {
                let shard_progress = get_progress(
                    state_kv_db.db_shard(shard_id),
                    &DbMetadataKey::StateKvShardCommitProgress(shard_id),
                )?;
                if let Some(shard_progress) = shard_progress {
                    min_shard_progress = std::cmp::min(min_shard_progress, shard_progress);
                } else {
                    // Shard has no progress, use 0
                    min_shard_progress = 0;
                    break;
                }
            }
            
            // Use the minimum progress for truncation
            let overall_kv_commit_progress = std::cmp::min(metadata_progress, min_shard_progress);
            
            info!(
                metadata_progress = metadata_progress,
                actual_min_progress = overall_kv_commit_progress,
                "State KV DB recovery: using minimum shard progress for truncation"
            );
            
            truncate_state_kv_db_shards(&state_kv_db, overall_kv_commit_progress)?;
        }
    }

    Ok(state_kv_db)
}
```

Additionally, add validation after truncation to verify all shards have consistent progress.

## Proof of Concept

```rust
// Reproduction test (add to storage/aptosdb/src/state_kv_db.rs tests)
#[test]
fn test_inconsistent_shard_progress_recovery() {
    use tempfile::tempdir;
    use crate::schema::db_metadata::{DbMetadataKey, DbMetadataSchema, DbMetadataValue};
    
    let tmpdir = tempdir().unwrap();
    let db_paths = StorageDirPaths::from_path(tmpdir.path());
    
    // Create and populate database
    let state_kv_db = StateKvDb::open_sharded(
        &db_paths,
        RocksdbConfig::default(),
        None,
        None,
        false,
    ).unwrap();
    
    // Simulate commit to version 1000 on all shards
    for shard_id in 0..NUM_STATE_SHARDS {
        state_kv_db.db_shard(shard_id).put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardCommitProgress(shard_id),
            &DbMetadataValue::Version(1000),
        ).unwrap();
    }
    state_kv_db.write_progress(1000).unwrap();
    
    // Simulate corruption: set shard 15's progress to 999
    state_kv_db.db_shard(15).put::<DbMetadataSchema>(
        &DbMetadataKey::StateKvShardCommitProgress(15),
        &DbMetadataValue::Version(999),
    ).unwrap();
    
    drop(state_kv_db);
    
    // Reopen database - recovery should detect inconsistency
    let recovered_db = StateKvDb::open_sharded(
        &db_paths,
        RocksdbConfig::default(),
        None,
        None,
        false,
    ).unwrap();
    
    // Check if shard 15's progress was incorrectly set to 1000
    let shard_15_progress = recovered_db.db_shard(15)
        .get::<DbMetadataSchema>(&DbMetadataKey::StateKvShardCommitProgress(15))
        .unwrap()
        .map(|v| v.expect_version());
    
    let overall_progress = get_state_kv_commit_progress(&recovered_db).unwrap();
    
    // BUG: Shard 15's progress will be 1000 (from truncation)
    // even though it should be 999 based on pre-recovery state
    assert_eq!(shard_15_progress, Some(1000)); // This demonstrates the bug
    assert_eq!(overall_progress, Some(1000));
    
    // The correct behavior would be:
    // - Detect that shard 15 is at 999
    // - Use 999 as the overall progress
    // - Truncate all shards to 999
}
```

## Notes

This vulnerability is particularly insidious because:

1. It only manifests during database recovery after inconsistency occurs
2. The inconsistency silently corrupts progress metadata without immediate error
3. The pruner code demonstrates the correct pattern, but commit recovery doesn't follow it
4. Once the incorrect progress is set, there's no automatic detection or correction mechanism

The fix should also add assertions or validation to detect when shard progress diverges from the overall progress, similar to how the pruner initializes with consistency checks.

### Citations

**File:** storage/aptosdb/src/state_kv_db.rs (L164-168)
```rust
        if !readonly {
            if let Some(overall_kv_commit_progress) = get_state_kv_commit_progress(&state_kv_db)? {
                truncate_state_kv_db_shards(&state_kv_db, overall_kv_commit_progress)?;
            }
        }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-208)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L293-304)
```rust
    pub(crate) fn commit_single_shard(
        &self,
        version: Version,
        shard_id: usize,
        mut batch: impl WriteBatch,
    ) -> Result<()> {
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardCommitProgress(shard_id),
            &DbMetadataValue::Version(version),
        )?;
        self.state_kv_db_shards[shard_id].write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L57-62)
```rust
pub(crate) fn get_state_kv_commit_progress(state_kv_db: &StateKvDb) -> Result<Option<Version>> {
    get_progress(
        state_kv_db.metadata_db(),
        &DbMetadataKey::StateKvCommitProgress,
    )
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L129-142)
```rust
pub(crate) fn truncate_state_kv_db_single_shard(
    state_kv_db: &StateKvDb,
    shard_id: usize,
    target_version: Version,
) -> Result<()> {
    let mut batch = SchemaBatch::new();
    delete_state_value_and_index(
        state_kv_db.db_shard(shard_id),
        target_version + 1,
        &mut batch,
        state_kv_db.enabled_sharding(),
    )?;
    state_kv_db.commit_single_shard(target_version, shard_id, batch)
}
```

**File:** storage/aptosdb/src/utils/mod.rs (L14-18)
```rust
pub(crate) fn get_progress(db: &DB, progress_key: &DbMetadataKey) -> Result<Option<Version>> {
    Ok(db
        .get::<DbMetadataSchema>(progress_key)?
        .map(|v| v.expect_version()))
}
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L24-45)
```rust
impl StateKvShardPruner {
    pub(in crate::pruner) fn new(
        shard_id: usize,
        db_shard: Arc<DB>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            &db_shard,
            &DbMetadataKey::StateKvShardPrunerProgress(shard_id),
            metadata_progress,
        )?;
        let myself = Self { shard_id, db_shard };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up state kv shard {shard_id}."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```
