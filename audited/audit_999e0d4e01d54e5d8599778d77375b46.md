# Audit Report

## Title
V2 Event Primary Key Collision Causes Token Activity Data Loss in Legacy Indexer

## Summary
When the `module_event_migration_enabled()` feature flag is active, token events are emitted as V2 (module) events. These V2 events are converted to API Events with dummy GUID and sequence number values (all zeros). When multiple V2 token events occur in a single transaction, they produce duplicate primary keys in the `token_activities` table, causing the indexer to overwrite earlier events with later ones, resulting in data loss of token activity history.

## Finding Description

The vulnerability exists in the interaction between V2 event conversion and the legacy token indexer: [1](#0-0) 

When ContractEvent::V2 events are converted to API Events, they receive DUMMY_GUID (account_address = 0x0, creation_number = 0) and DUMMY_SEQUENCE_NUMBER (0). 

The token framework can emit events as either V1 or V2 depending on the feature flag: [2](#0-1) 

The legacy token indexer processes these events: [3](#0-2) 

Creating TokenActivity records with this primary key: [4](#0-3) 

The primary key tuple is extracted from API Event fields: [5](#0-4) 

When multiple V2 token events exist in one transaction, they all produce the same primary key: `(transaction_version, "0x0", 0, 0)`. The database insert uses on_conflict().do_update(): [6](#0-5) 

This causes later events to overwrite earlier ones, losing all but the last token activity per transaction.

**Attack Scenario:**
1. Attacker enables module_event_migration or waits for it to be enabled
2. Submits transaction performing multiple token operations (e.g., minting 5 tokens, or transferring to 3 recipients)
3. All token events are emitted as V2 events with dummy identifiers
4. Indexer processes them with identical primary keys
5. Only the last event is stored; previous 4 are lost
6. Token activity history is incomplete and incorrect

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria: "State inconsistencies requiring intervention."

The indexer database maintains critical state about token activities that applications rely on for:
- Token transfer history and ownership tracking
- NFT marketplace transaction records
- Analytics and reporting
- Compliance and auditing

The data loss creates inconsistencies between actual on-chain events and indexed records, requiring manual intervention to identify and restore missing data. While the blockchain state remains correct, applications depending on indexed data will provide incorrect information to users.

## Likelihood Explanation

**High likelihood** when the `module_event_migration_enabled()` feature flag is active:
- Any transaction with multiple token operations triggers the issue
- Common scenarios include: batch minting, multi-recipient transfers, token swaps
- No special privileges required - any user can trigger it
- Automatic and deterministic once conditions are met
- Affects all legacy token indexer instances

## Recommendation

The legacy token indexer should not process V2 events, or should use a different primary key strategy. Recommended fixes:

1. **Option A**: Filter out V2 events in `from_transaction()` since they lack proper identifiers:
```rust
pub fn from_transaction(transaction: &APITransaction) -> Vec<Self> {
    let mut token_activities = vec![];
    if let APITransaction::UserTransaction(user_txn) = transaction {
        for (index, event) in user_txn.events.iter().enumerate() {
            // Skip V2 events - they should use the V2 indexer
            if event.guid.account_address.to_string() == "0x0" && 
               event.guid.creation_number.0 == 0 &&
               event.sequence_number.0 == 0 {
                continue;
            }
            // ... rest of processing
```

2. **Option B**: Use `event_index` in the primary key for V2 events to ensure uniqueness:
```rust
#[diesel(primary_key(
    transaction_version,
    event_account_address,
    event_creation_number,
    event_sequence_number,
    event_index  // Add this for V2 event disambiguation
))]
```

3. **Option C (Preferred)**: Deprecate legacy indexer for V2 events and direct users to the proper V2-aware indexer infrastructure.

## Proof of Concept

**Setup:**
1. Enable `module_event_migration_enabled()` feature flag
2. Deploy token contract using `aptos_token` framework

**Exploit Steps:**
```move
// Move transaction that emits multiple token events
script {
    use aptos_framework::aptos_token::token;
    
    fun exploit(creator: &signer) {
        // Create collection
        token::create_collection(creator, ...);
        
        // Mint 5 tokens - emits 5 MintTokenEvent (V2)
        token::mint(creator, collection, name1, ...);
        token::mint(creator, collection, name2, ...);
        token::mint(creator, collection, name3, ...);
        token::mint(creator, collection, name4, ...);
        token::mint(creator, collection, name5, ...);
    }
}
```

**Verification:**
1. Submit transaction executing the script
2. Query indexer `token_activities` table for the transaction version
3. Observe only 1 TokenActivity record exists instead of 5
4. The record contains data from the 5th mint, while mints 1-4 are lost

**Expected:** 5 separate token activity records  
**Actual:** 1 record (the last event overwrites the first 4)

---

**Notes:**
This is an indexer-layer vulnerability, not a blockchain consensus or execution issue. The on-chain event data remains intact and correct. The vulnerability affects data integrity in the off-chain indexing infrastructure that applications depend on for querying historical token activities. The severity is assessed as Medium due to state inconsistencies requiring intervention to restore accurate indexed data.

### Citations

**File:** api/types/src/transaction.rs (L877-893)
```rust
impl From<(&ContractEvent, serde_json::Value)> for Event {
    fn from((event, data): (&ContractEvent, serde_json::Value)) -> Self {
        match event {
            ContractEvent::V1(v1) => Self {
                guid: (*v1.key()).into(),
                sequence_number: v1.sequence_number().into(),
                typ: v1.type_tag().into(),
                data,
            },
            ContractEvent::V2(v2) => Self {
                guid: *DUMMY_GUID,
                sequence_number: *DUMMY_SEQUENCE_NUMBER,
                typ: v2.type_tag().into(),
                data,
            },
        }
    }
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1204-1220)
```text
        if (std::features::module_event_migration_enabled()) {
            event::emit(
                CreateCollection {
                    creator: account_addr,
                    collection_name: name,
                    uri,
                    description,
                    maximum,
                }
            );
        } else {
            event::emit_event<CreateCollectionEvent>(
                &mut collection_handle.create_collection_events,
                CreateCollectionEvent {
                    creator: account_addr,
                    collection_name: name,
                    uri,
```

**File:** crates/indexer/src/processors/token_processor.rs (L503-513)
```rust
                .on_conflict((
                    transaction_version,
                    event_account_address,
                    event_creation_number,
                    event_sequence_number,
                ))
                .do_update()
                .set((
                    inserted_at.eq(excluded(inserted_at)),
                    event_index.eq(excluded(event_index)),
                )),
```

**File:** crates/indexer/src/processors/token_processor.rs (L912-913)
```rust
            let mut activities = TokenActivity::from_transaction(txn);
            all_token_activities.append(&mut activities);
```

**File:** crates/indexer/src/models/token_models/token_activities.rs (L18-25)
```rust
#[derive(Debug, Deserialize, FieldCount, Identifiable, Insertable, Serialize)]
#[diesel(primary_key(
    transaction_version,
    event_account_address,
    event_creation_number,
    event_sequence_number
))]
#[diesel(table_name = token_activities)]
```

**File:** crates/indexer/src/models/token_models/token_activities.rs (L90-92)
```rust
        let event_account_address = standardize_address(&event.guid.account_address.to_string());
        let event_creation_number = event.guid.creation_number.0 as i64;
        let event_sequence_number = event.sequence_number.0 as i64;
```
