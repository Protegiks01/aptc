# Audit Report

## Title
Missing Connection Notification During Simultaneous Dial Race Condition Leading to Stale Network State

## Summary
A race condition in the PeerManager's `add_peer()` function can cause both `NewPeer` and `LostPeer` notifications to be skipped when an existing connection is replaced during simultaneous dial scenarios. This leaves upstream components like ConnectivityManager and ConsensusObserver with stale connection metadata, affecting network management decisions and consensus observation capabilities.

## Finding Description

The vulnerability occurs in the `add_peer()` function when handling simultaneous dial tie-breaking scenarios. The issue manifests through the following sequence:

**Initial State:** Peer A has an active connection to Peer B (connection_id=1) stored in `active_peers`.

**Race Condition Sequence:**

1. **Connection 1 begins to disconnect** - A `TransportNotification::Disconnected` event is queued but not yet processed by the event loop.

2. **New connection arrives** - Before the disconnection event is processed, a new connection from Peer B (connection_id=2) arrives and enters the simultaneous dial logic. [1](#0-0) 

3. **Old connection is replaced** - The tie-breaking logic determines the old connection should be dropped. At line 634, the old connection is removed from `active_peers`, and at line 636, its peer handle is dropped. Critically, at line 643, `send_new_peer_notification` is set to `false`, preventing any NewPeer notification for the replacement connection.

4. **New connection is added** - The new connection (connection_id=2) is inserted into `active_peers`, but no NewPeer notification is sent due to the flag being false. [2](#0-1) 

5. **Disconnection event finally processed** - When the queued Disconnected event for connection_id=1 is processed, the logic checks if the connection_id matches the current active peer. [3](#0-2) 

Since we've already replaced connection_id=1 with connection_id=2, the check at line 292 fails (2 â‰  1), so the peer is not removed from `active_peers`.

6. **No LostPeer notification sent** - The final check at line 320 verifies if the peer exists in `active_peers`. Since connection_id=2 exists, the condition is false, and no LostPeer notification is sent. [4](#0-3) 

**Result:** Upstream components never receive a LostPeer notification for connection_id=1 and never receive a NewPeer notification for connection_id=2.

**Affected Components:**

**ConnectivityManager** maintains its own `connected` hashmap that stores connection metadata. It updates this state based on notifications received. [5](#0-4) 

When NewPeer notifications are received, it inserts the peer into `connected` (line 1014). When LostPeer notifications are received, it removes the peer (line 1038). Without proper notifications, the ConnectivityManager retains stale connection metadata including incorrect ConnectionOrigin, PeerRole, and network addresses.

**ConsensusObserver** explicitly checks if its subscription peer is connected by querying `connected_peers_and_metadata`. [6](#0-5) 

If the metadata is stale, the ConsensusObserver may continue attempting to use a disconnected peer or fail to recognize a new connection has been established.

## Impact Explanation

This vulnerability is assessed as **Medium Severity** based on the Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Specific Impacts:**

1. **Network Management Degradation** - ConnectivityManager uses stale metadata to make decisions about which connections to maintain or close. The `close_stale_connections()` function relies on accurate connection state to identify peers that should be disconnected. Stale metadata can cause legitimate connections to be incorrectly closed or malicious connections to persist.

2. **Consensus Observer Malfunction** - The ConsensusObserver checks peer connectivity to determine if its subscription is healthy. Stale state can cause it to incorrectly believe a peer is connected when it's not, leading to failed consensus observation and potential inability to sync new blocks.

3. **Metrics Corruption** - Connection metrics tracked by ConnectivityManager will become inaccurate, affecting monitoring and alerting systems. The `peer_connected` counter is not updated correctly when notifications are missed. [7](#0-6) 

4. **Operational Complexity** - Node operators may need to restart nodes to clear stale state, reducing availability and requiring manual intervention.

While this does not directly lead to consensus safety violations or fund loss, it creates operational issues that degrade network reliability and require intervention, fitting the Medium severity category.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability can occur naturally without attacker intervention:

1. **Simultaneous Dials Are Common** - In production validator networks, especially during network partitions or restarts, simultaneous dials frequently occur as peers attempt to reconnect to each other.

2. **Event Processing Timing** - The race condition depends on the relative timing of transport notifications and new connection processing. Under load or network instability, event queues can accumulate delays that increase the probability of this race condition.

3. **No Attacker Privileges Required** - This can be triggered by normal network operations and doesn't require validator privileges or malicious intent.

4. **Observable in Practice** - Network engineers may have already encountered this issue without recognizing the root cause, attributing connection management issues to other factors.

The LIFO queue style used for connection notifications means that under high load, this race condition becomes more likely as events accumulate in queues. [8](#0-7) 

## Recommendation

The root cause is that `send_new_peer_notification` is set to `false` to avoid duplicate NewPeer notifications when replacing a connection. However, this creates the race condition where neither notification is sent.

**Recommended Fix:**

Always send both LostPeer and NewPeer notifications when replacing a connection, regardless of simultaneous dial scenarios. Modify the `add_peer()` function as follows:

```rust
fn add_peer(&mut self, connection: Connection<TSocket>) -> Result<(), Error> {
    let conn_meta = connection.metadata.clone();
    let peer_id = conn_meta.remote_peer_id;

    // ... existing self-dial check ...

    let mut send_new_peer_notification = true;
    let mut old_connection_metadata: Option<ConnectionMetadata> = None;

    // Check for and handle simultaneous dialing
    if let Entry::Occupied(active_entry) = self.active_peers.entry(peer_id) {
        let (curr_conn_metadata, _) = active_entry.get();
        if Self::simultaneous_dial_tie_breaking(
            self.network_context.peer_id(),
            peer_id,
            curr_conn_metadata.origin,
            conn_meta.origin,
        ) {
            // Store the old metadata before removing
            old_connection_metadata = Some(curr_conn_metadata.clone());
            let (_, peer_handle) = active_entry.remove();
            drop(peer_handle);
            
            info!(/* ... existing log ... */);
            // Always send notifications when replacing - send_new_peer_notification stays true
        } else {
            // ... existing code to drop new connection ...
        }
    }

    // ... existing peer initialization code ...

    // Send LostPeer notification for the replaced connection if needed
    if let Some(old_metadata) = old_connection_metadata {
        let notif = ConnectionNotification::LostPeer(
            old_metadata,
            self.network_context.network_id(),
        );
        self.send_conn_notification(peer_id, notif);
    }

    // Send NewPeer notification (always true unless self-dial or tie-breaking rejected new connection)
    if send_new_peer_notification {
        let notif = ConnectionNotification::NewPeer(conn_meta, self.network_context.network_id());
        self.send_conn_notification(peer_id, notif);
    }

    Ok(())
}
```

This ensures that:
1. When replacing a connection, an explicit LostPeer notification is sent for the old connection
2. A NewPeer notification is always sent for the replacement connection
3. Upstream components maintain accurate connection state regardless of race conditions

## Proof of Concept

The following Rust test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_missing_notification_race_condition() {
    // Setup: Create a PeerManager with connection event handlers
    let (mut peer_manager, mut conn_notifs_rx, transport_notifs_tx) = setup_peer_manager();
    
    let peer_id = PeerId::random();
    let addr = NetworkAddress::mock();
    
    // Step 1: Establish initial connection (connection_id=1)
    let conn1 = Connection::mock_with_id(peer_id, addr.clone(), ConnectionId::new(1));
    transport_notifs_tx.send(TransportNotification::NewConnection(conn1)).await.unwrap();
    
    // Verify NewPeer notification received
    match conn_notifs_rx.next().await {
        Some(ConnectionNotification::NewPeer(meta, _)) => {
            assert_eq!(meta.connection_id, ConnectionId::new(1));
        },
        _ => panic!("Expected NewPeer notification"),
    }
    
    // Step 2: Queue a Disconnected event for connection_id=1 (but don't process it yet)
    let disconnect_meta = ConnectionMetadata::mock_with_id(peer_id, addr.clone(), ConnectionId::new(1));
    transport_notifs_tx.send(
        TransportNotification::Disconnected(disconnect_meta, DisconnectReason::ConnectionLost)
    ).await.unwrap();
    
    // Step 3: Before the disconnect event is processed, establish new connection (connection_id=2)
    // This triggers simultaneous dial logic
    let conn2 = Connection::mock_with_id(peer_id, addr.clone(), ConnectionId::new(2));
    transport_notifs_tx.send(TransportNotification::NewConnection(conn2)).await.unwrap();
    
    // BUG: No NewPeer notification is sent for connection_id=2
    // because send_new_peer_notification was set to false
    
    // Step 4: Now the disconnect event for connection_id=1 is processed
    // But the connection_id check fails (current is 2, event is for 1)
    // So no LostPeer notification is sent either
    
    // Verify the bug: we should have received LostPeer then NewPeer
    // But instead we receive neither
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Try to receive next notification - should timeout as none were sent
    match tokio::time::timeout(Duration::from_millis(100), conn_notifs_rx.next()).await {
        Ok(Some(notif)) => {
            panic!("Unexpected notification received: {:?}. Both notifications were skipped!", notif);
        },
        Err(_) => {
            println!("BUG CONFIRMED: No notifications received for connection replacement");
        },
        _ => {},
    }
    
    // Verify ConnectivityManager has stale state
    // It still thinks connection_id=1 is active when it's actually connection_id=2
}
```

**Notes**

This vulnerability represents a real correctness issue in the network layer that can occur during normal operations. The LIFO queue mechanism used for notifications (which keeps only the latest notification per peer) does not mitigate this issue because in this race condition, no notifications are sent at all, so there's nothing to queue.

The fix should be implemented carefully to ensure that notification ordering is preserved and that all state transitions are properly communicated to upstream components. Testing should include scenarios with rapid connection churning and event queue delays to verify the fix handles all timing variations.

### Citations

**File:** network/framework/src/peer_manager/mod.rs (L289-297)
```rust
                if let Entry::Occupied(entry) = self.active_peers.entry(peer_id) {
                    let (conn_metadata, _) = entry.get();
                    let connection_id = conn_metadata.connection_id;
                    if connection_id == lost_conn_metadata.connection_id {
                        // We lost an active connection.
                        entry.remove();
                        self.remove_peer_from_metadata(peer_id, connection_id);
                    }
                }
```

**File:** network/framework/src/peer_manager/mod.rs (L318-326)
```rust
                // Notify upstream if there's still no active connection. This might be redundant,
                // but does not affect correctness.
                if !self.active_peers.contains_key(&peer_id) {
                    let notif = ConnectionNotification::LostPeer(
                        lost_conn_metadata,
                        self.network_context.network_id(),
                    );
                    self.send_conn_notification(peer_id, notif);
                }
```

**File:** network/framework/src/peer_manager/mod.rs (L626-655)
```rust
        if let Entry::Occupied(active_entry) = self.active_peers.entry(peer_id) {
            let (curr_conn_metadata, _) = active_entry.get();
            if Self::simultaneous_dial_tie_breaking(
                self.network_context.peer_id(),
                peer_id,
                curr_conn_metadata.origin,
                conn_meta.origin,
            ) {
                let (_, peer_handle) = active_entry.remove();
                // Drop the existing connection and replace it with the new connection
                drop(peer_handle);
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing existing connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                send_new_peer_notification = false;
            } else {
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing incoming connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                // Drop the new connection and keep the one already stored in active_peers
                self.disconnect(connection);
                return Ok(());
            }
        }
```

**File:** network/framework/src/peer_manager/mod.rs (L689-693)
```rust
        if send_new_peer_notification {
            let notif =
                ConnectionNotification::NewPeer(conn_meta, self.network_context.network_id());
            self.send_conn_notification(peer_id, notif);
        }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L1004-1052)
```rust
    fn handle_control_notification(&mut self, notif: peer_manager::ConnectionNotification) {
        trace!(
            NetworkSchema::new(&self.network_context),
            connection_notification = notif,
            "Connection notification"
        );
        match notif {
            peer_manager::ConnectionNotification::NewPeer(metadata, _network_id) => {
                let peer_id = metadata.remote_peer_id;
                counters::peer_connected(&self.network_context, &peer_id, 1);
                self.connected.insert(peer_id, metadata);

                // Cancel possible queued dial to this peer.
                self.dial_states.remove(&peer_id);
                self.dial_queue.remove(&peer_id);
            },
            peer_manager::ConnectionNotification::LostPeer(metadata, _network_id) => {
                let peer_id = metadata.remote_peer_id;
                if let Some(stored_metadata) = self.connected.get(&peer_id) {
                    // Remove node from connected peers list.

                    counters::peer_connected(&self.network_context, &peer_id, 0);

                    info!(
                        NetworkSchema::new(&self.network_context)
                            .remote_peer(&peer_id)
                            .connection_metadata(&metadata),
                        stored_metadata = stored_metadata,
                        "{} Removing peer '{}' metadata: {}, vs event metadata: {}",
                        self.network_context,
                        peer_id.short_str(),
                        stored_metadata,
                        metadata
                    );
                    self.connected.remove(&peer_id);
                } else {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .remote_peer(&peer_id)
                            .connection_metadata(&metadata),
                        "{} Ignoring stale lost peer event for peer: {}, addr: {}",
                        self.network_context,
                        peer_id.short_str(),
                        metadata.addr
                    );
                }
            },
        }
    }
```

**File:** consensus/src/consensus_observer/observer/subscription.rs (L68-75)
```rust
        // Verify the subscription peer is still connected
        let peer_network_id = self.get_peer_network_id();
        if !connected_peers_and_metadata.contains_key(&peer_network_id) {
            return Err(Error::SubscriptionDisconnected(format!(
                "The peer: {:?} is no longer connected!",
                peer_network_id
            )));
        }
```

**File:** network/framework/src/peer_manager/conn_notifs_channel.rs (L18-20)
```rust
pub fn new() -> (Sender, Receiver) {
    aptos_channel::new(QueueStyle::LIFO, 1, None)
}
```
