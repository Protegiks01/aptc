# Audit Report

## Title
Inspection Service Identity Information Endpoint Enables Validator Deanonymization Through Unauthenticated Peer ID Disclosure

## Summary
The `/identity_information` endpoint on the inspection service exposes peer IDs for all configured networks (validator, VFN, and public) without any authentication mechanism. When this service is accessible (due to misconfigured firewalls or non-Kubernetes deployments), attackers can map validator IP addresses to their on-chain identities, enabling targeted attacks on specific validators.

## Finding Description

The inspection service exposes validator identity information through an unauthenticated HTTP endpoint that is enabled by default and bound to all network interfaces.

**Vulnerable Code Path:**

The endpoint is registered and routes to the identity handler: [1](#0-0) 

The handler exposes peer IDs for all configured networks when enabled: [2](#0-1) 

**Configuration Issues:**

1. **Enabled by default**: The `expose_identity_information` flag defaults to `true` [3](#0-2) 

2. **Bound to all interfaces**: The service binds to `0.0.0.0:9101` by default, making it accessible from any network interface [4](#0-3) 

3. **No authentication mechanism**: The inspection service has no authentication layer, only configuration flags to disable endpoints [5](#0-4) 

4. **No mainnet sanitizer protection**: The sanitizer only checks `expose_configuration` for mainnet validators, not `expose_identity_information` [6](#0-5) 

**Attack Mechanism:**

While validator peer IDs can be derived from on-chain network addresses stored in the `ValidatorSet` resource: [7](#0-6) 

The critical vulnerability is that the inspection service creates a direct **IP-to-peer-ID mapping**. Peer IDs are derived from x25519 public keys: [8](#0-7) 

These public keys are embedded in network addresses as the `NoiseIK` protocol: [9](#0-8) 

**Exploitation Steps:**

1. Attacker scans the internet for nodes with port 9101 accessible
2. Attacker sends `GET /identity_information` to each accessible node (no authentication required)
3. Attacker receives peer IDs for validator network, VFN network, and public network
4. Attacker queries on-chain `ValidatorSet` to get all validator network addresses
5. Attacker derives peer IDs from on-chain x25519 public keys
6. Attacker correlates exposed peer IDs with derived peer IDs to map IP addresses to specific validators
7. Attacker launches targeted DDoS attacks, social engineering, or physical security threats against identified validators

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty program because it enables:

1. **Validator node slowdowns**: Attackers can identify specific validator IP addresses and launch targeted network-level attacks, causing performance degradation that falls under "Validator node slowdowns" (High severity - up to $50,000).

2. **Significant protocol violations**: By mapping the entire validator topology, attackers can strategically target validators to disrupt consensus, partition the network, or coordinate attacks during critical periods like epoch transitions.

3. **Privacy violation**: Validators' network infrastructure becomes fully transparent to attackers, exposing operational security details like geographic distribution, cloud provider choice, and network architecture.

While production Kubernetes deployments include `NetworkPolicy` restrictions: [10](#0-9) 

Many validators run in bare-metal environments, development networks, or with misconfigured firewalls where these protections don't exist.

## Likelihood Explanation

**High likelihood in the following scenarios:**

1. **Bare-metal deployments**: Validators not using Kubernetes lack automatic NetworkPolicy protection
2. **Misconfigured firewalls**: Operators who don't properly restrict port 9101
3. **Development/testnet environments**: Often have relaxed security configurations
4. **Internal compromise**: Attackers who gain access to monitoring or health-checking pods can query all validators

**Medium likelihood overall** because:
- Production Kubernetes deployments have protection
- But the insecure default (enabled + no auth + bound to 0.0.0.0) creates significant risk
- The sanitizer explicitly allows this configuration on mainnet validators

In contrast, the admin service requires authentication on mainnet: [11](#0-10) 

This shows the Aptos team recognizes sensitive endpoints need protection, but the inspection service lacks similar safeguards.

## Recommendation

**Immediate fixes:**

1. **Disable by default for mainnet validators**: Add sanitizer check to prevent exposing identity information on mainnet:

```rust
// In config/src/config/inspection_service_config.rs, update sanitize():
if let Some(chain_id) = chain_id {
    if node_type.is_validator() && chain_id.is_mainnet() {
        if inspection_service_config.expose_configuration {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Mainnet validators should not expose the node configuration!".to_string(),
            ));
        }
        if inspection_service_config.expose_identity_information {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Mainnet validators should not expose identity information!".to_string(),
            ));
        }
    }
}
```

2. **Add authentication mechanism**: Implement authentication similar to the admin service, requiring a passcode for sensitive endpoints.

3. **Bind to localhost by default**: Change the default address from `0.0.0.0` to `127.0.0.1` to prevent external access by default.

4. **Documentation**: Add prominent security warnings in validator setup documentation about firewall requirements.

## Proof of Concept

**Attack Simulation:**

```bash
#!/bin/bash
# Step 1: Scan for accessible inspection services
for ip in $(cat potential_validator_ips.txt); do
  timeout 2 curl -s "http://${ip}:9101/identity_information" > "${ip}_identity.txt" 2>&1
  if [ $? -eq 0 ]; then
    echo "Found accessible inspection service at ${ip}"
  fi
done

# Step 2: Extract peer IDs
grep "peer ID:" *_identity.txt | awk '{print $NF}' > exposed_peer_ids.txt

# Step 3: Query on-chain ValidatorSet (using Aptos CLI or REST API)
aptos move view --function-id 0x1::stake::get_validator_set \
  --url https://fullnode.mainnet.aptoslabs.com/v1 > validator_set.json

# Step 4: Parse network addresses and derive peer IDs
# (Implementation would parse NetworkAddress and extract x25519 pubkeys)

# Step 5: Correlate exposed peer IDs with on-chain validator addresses
# Output: IP_ADDRESS -> VALIDATOR_ADDRESS mapping

# Step 6: Launch targeted attack
# attacker can now DDoS specific validators by their identified IP addresses
```

**Testing on local node:**

```bash
# Start a validator node with default inspection service config
# Query the endpoint without authentication
curl http://localhost:9101/identity_information

# Expected output (no authentication required):
# Identity Information:
#     - Validator network (Validator), peer ID: <PEER_ID>
#     - Fullnode network (vfn), peer ID: <PEER_ID>
```

This proves that peer IDs are exposed without any authentication, enabling the correlation attack described above.

## Notes

The vulnerability stems from an **insecure default configuration** rather than a logic bug in the code. The inspection service is working as designed, but the design assumes operators will implement network-level protections. This creates a significant security risk, especially for validators in non-Kubernetes environments or during initial setup phases before firewall rules are properly configured.

The fact that the admin service requires authentication on mainnet while the inspection service does not suggests inconsistent security posture across similar debugging/administrative interfaces.

### Citations

**File:** crates/aptos-inspection-service/src/server/mod.rs (L127-131)
```rust
        IDENTITY_INFORMATION_PATH => {
            // /identity_information
            // Exposes the identity information of the node
            identity_information::handle_identity_information_request(&node_config)
        },
```

**File:** crates/aptos-inspection-service/src/server/identity_information.rs (L13-26)
```rust
pub fn handle_identity_information_request(node_config: &NodeConfig) -> (StatusCode, Body, String) {
    // Only return identity information if the endpoint is enabled
    let (status_code, body) = if node_config.inspection_service.expose_identity_information {
        let identity_information = get_identity_information(node_config);
        (StatusCode::OK, Body::from(identity_information))
    } else {
        (
            StatusCode::FORBIDDEN,
            Body::from(IDENTITY_INFO_DISABLED_MESSAGE),
        )
    };

    (status_code, body, CONTENT_TYPE_TEXT.into())
}
```

**File:** crates/aptos-inspection-service/src/server/identity_information.rs (L29-52)
```rust
fn get_identity_information(node_config: &NodeConfig) -> String {
    let mut identity_information = Vec::<String>::new();
    identity_information.push("Identity Information:".into());

    // If the validator network is configured, fetch the identity information
    if let Some(validator_network) = &node_config.validator_network {
        identity_information.push(format!(
            "\t- Validator network ({}), peer ID: {}",
            validator_network.network_id,
            validator_network.peer_id()
        ));
    }

    // For each fullnode network, fetch the identity information
    for fullnode_network in &node_config.full_node_networks {
        identity_information.push(format!(
            "\t- Fullnode network ({}), peer ID: {}",
            fullnode_network.network_id,
            fullnode_network.peer_id()
        ));
    }

    identity_information.join("\n") // Separate each entry with a newline to construct the output
}
```

**File:** config/src/config/inspection_service_config.rs (L26-36)
```rust
impl Default for InspectionServiceConfig {
    fn default() -> InspectionServiceConfig {
        InspectionServiceConfig {
            address: "0.0.0.0".to_string(),
            port: 9101,
            expose_configuration: false,
            expose_identity_information: true,
            expose_peer_information: true,
            expose_system_information: true,
        }
    }
```

**File:** config/src/config/inspection_service_config.rs (L54-68)
```rust
        // Verify that mainnet validators do not expose the configuration
        if let Some(chain_id) = chain_id {
            if node_type.is_validator()
                && chain_id.is_mainnet()
                && inspection_service_config.expose_configuration
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "Mainnet validators should not expose the node configuration!".to_string(),
                ));
            }
        }

        Ok(())
    }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L161-168)
```text
    struct ValidatorConfig has key, copy, store, drop {
        consensus_pubkey: vector<u8>,
        network_addresses: vector<u8>,
        // to make it compatible with previous definition, remove later
        fullnode_addresses: vector<u8>,
        // Index in the active set if the validator corresponding to this stake pool is active.
        validator_index: u64,
    }
```

**File:** types/src/account_address.rs (L140-146)
```rust
pub fn from_identity_public_key(identity_public_key: x25519::PublicKey) -> AccountAddress {
    let mut array = [0u8; AccountAddress::LENGTH];
    let pubkey_slice = identity_public_key.as_slice();
    // keep only the last 16 bytes
    array.copy_from_slice(&pubkey_slice[x25519::PUBLIC_KEY_SIZE - AccountAddress::LENGTH..]);
    AccountAddress::new(array)
}
```

**File:** types/src/network_address/mod.rs (L122-122)
```rust
    NoiseIK(x25519::PublicKey),
```

**File:** terraform/helm/aptos-node/templates/networkpolicy.yaml (L39-56)
```yaml
  - from:
    - namespaceSelector: {}
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: monitoring
    ports:
    - protocol: TCP
      port: 9101
  # Node Health Checker accesses these ports
  - from:
    - namespaceSelector: {}
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: node-health-checker
    ports:
    - protocol: TCP
      port: 9101
    - protocol: TCP
```

**File:** config/src/config/admin_service_config.rs (L67-76)
```rust
        if node_config.admin_service.enabled == Some(true) {
            if let Some(chain_id) = chain_id {
                if chain_id.is_mainnet()
                    && node_config.admin_service.authentication_configs.is_empty()
                {
                    return Err(Error::ConfigSanitizerFailed(
                        sanitizer_name,
                        "Must enable authentication for AdminService on mainnet.".into(),
                    ));
                }
```
