# Audit Report

## Title
Concurrent sync_for_duration Requests Cause Permanent Consensus Deadlock Due to Single Request Slot

## Summary
The state sync notification handler can only track one active `sync_for_duration` request at a time. When both consensus and consensus observer concurrently call `sync_for_duration`, the second request overwrites the first, causing the first caller to permanently deadlock while waiting for a response that will never arrive. This results in complete consensus liveness failure requiring node restart.

## Finding Description

The vulnerability exists in the interaction between multiple ExecutionProxy instances and a single shared state sync request slot.

**Architecture Overview:**

Aptos creates two separate ExecutionProxy instances that share the same ConsensusNotifier: [1](#0-0) [2](#0-1) 

Both execution proxies use the same `state_sync_notifier` parameter to communicate with state sync. When `sync_for_duration` is called, it holds a mutex during the entire sync operation: [3](#0-2) 

However, since each ExecutionProxy has its own `write_mutex`, they can call `sync_for_duration` concurrently without blocking each other.

**The Critical Flaw:**

State sync's ConsensusNotificationHandler maintains only ONE slot for tracking active sync requests: [4](#0-3) 

When a new sync duration notification arrives, it unconditionally OVERWRITES any existing request: [5](#0-4) 

Each `sync_for_duration` call creates its own unique callback channel: [6](#0-5) 

When the stored sync request is satisfied, state sync responds ONLY to the callback of whichever notification is currently stored: [7](#0-6) 

**Exploitation Scenario:**

1. Regular consensus calls `sync_for_duration(30s)` at T=0
   - Sends notification A to state sync with callback_A
   - State sync stores Request A in `consensus_sync_request`
   - Consensus awaits on callback_A

2. Consensus observer enters fallback mode and calls `sync_for_duration(10s)` at T=5
   - Sends notification B to state sync with callback_B
   - State sync OVERWRITES Request A with Request B in `consensus_sync_request`
   - Notification A's callback_A is now orphaned
   - Consensus observer awaits on callback_B

3. At T=15, Request B's duration expires
   - State sync responds to callback_B
   - Consensus observer receives response successfully

4. Consensus remains permanently blocked awaiting callback_A, which will NEVER receive a response

The consensus observer's fallback mechanism is triggered during normal operation when the observer detects it's falling behind: [8](#0-7) 

## Impact Explanation

**Severity: CRITICAL** (up to $1,000,000 per Aptos Bug Bounty)

This vulnerability causes **Total loss of liveness/network availability**:

1. **Consensus Deadlock**: The blocked consensus component cannot make progress on block execution, voting, or committing new blocks
2. **Non-Recoverable Without Restart**: The awaiting task is permanently blocked with no timeout mechanism
3. **Validator Unavailability**: The affected validator cannot participate in consensus, reducing network capacity
4. **Cascading Failures**: If multiple validators are affected simultaneously, consensus may fail to achieve quorum

The impact qualifies as Critical severity because it results in complete consensus unavailability requiring manual intervention (node restart), which maps directly to "Total loss of liveness/network availability" in the bug bounty criteria.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This vulnerability occurs through normal operational scenarios:

1. **Consensus Observer is Production-Ready**: Consensus observer is an officially supported feature enabled via configuration
2. **Fallback is Designed Behavior**: The observer's fallback to state sync is an intentional mechanism for catching up when falling behind
3. **No Special Conditions Required**: Any time both components need to sync simultaneously (e.g., after network partition, during catchup, or when lagging), the race condition can occur
4. **No Attacker Action Needed**: This is a pure race condition bug that manifests during legitimate operations

The timing window is not narrow - sync operations typically run for several seconds, providing ample opportunity for the race to occur.

## Recommendation

**Solution: Support Multiple Concurrent Sync Requests**

Modify `ConsensusNotificationHandler` to track multiple active sync requests instead of a single slot. Replace the single `Option<ConsensusSyncRequest>` with a map keyed by a unique request ID:

```rust
pub struct ConsensusNotificationHandler {
    consensus_listener: ConsensusNotificationListener,
    
    // Changed: Track multiple sync requests with unique IDs
    consensus_sync_requests: Arc<Mutex<HashMap<Uuid, ConsensusSyncRequest>>>,
    
    time_service: TimeService,
}
```

When initializing a sync request, generate a unique ID and store it:

```rust
pub async fn initialize_sync_duration_request(
    &mut self,
    sync_duration_notification: ConsensusSyncDurationNotification,
) -> Result<(), Error> {
    let start_time = self.time_service.now();
    let request_id = Uuid::new_v4();
    
    let consensus_sync_request =
        ConsensusSyncRequest::new_with_duration(request_id, start_time, sync_duration_notification);
    
    self.consensus_sync_requests
        .lock()
        .insert(request_id, consensus_sync_request);
    
    Ok(())
}
```

When checking progress, iterate over all active requests and satisfy those whose conditions are met:

```rust
async fn check_sync_request_progress(&mut self) -> Result<(), Error> {
    let latest_synced_ledger_info =
        utils::fetch_latest_synced_ledger_info(self.storage.clone())?;
    
    let mut satisfied_requests = Vec::new();
    
    // Find all satisfied requests
    let requests = self.consensus_notification_handler
        .get_sync_requests()
        .lock();
    
    for (id, request) in requests.iter() {
        if request.sync_request_satisfied(&latest_synced_ledger_info, self.time_service.clone()) {
            satisfied_requests.push(*id);
        }
    }
    
    drop(requests);
    
    // Handle each satisfied request
    for request_id in satisfied_requests {
        self.consensus_notification_handler
            .handle_satisfied_sync_request(request_id, latest_synced_ledger_info.clone())
            .await?;
    }
    
    Ok(())
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_concurrent_sync_requests {
    use super::*;
    use aptos_consensus_notifications::new_consensus_notifier_listener_pair;
    use std::time::Duration;
    use tokio::time::timeout;

    #[tokio::test]
    async fn test_overlapping_sync_for_duration_causes_deadlock() {
        // Create consensus notifier (simulating shared state sync interface)
        let (consensus_notifier_1, mut consensus_listener) =
            new_consensus_notifier_listener_pair(10000);
        
        // Clone to simulate second execution proxy (consensus observer)
        let consensus_notifier_2 = consensus_notifier_1.clone();

        // Spawn state sync handler that processes ONE request at a time
        tokio::spawn(async move {
            // Process first notification
            if let Some(notification) = consensus_listener.select_next_some().await {
                // Simulate state sync storing this request
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
            
            // Process second notification - OVERWRITES first
            if let Some(notification) = consensus_listener.select_next_some().await {
                // Second notification overwrites the first
                // Wait for duration to expire
                tokio::time::sleep(Duration::from_millis(500)).await;
                
                // Respond ONLY to second notification
                if let ConsensusNotification::SyncForDuration(sync_notif) = notification {
                    let _ = consensus_listener.respond_to_sync_duration_notification(
                        sync_notif,
                        Ok(()),
                        Some(create_test_ledger_info()),
                    );
                }
            }
        });

        // First caller (consensus) - will be orphaned
        let handle1 = tokio::spawn(async move {
            consensus_notifier_1
                .sync_for_duration(Duration::from_secs(10))
                .await
        });

        // Brief delay to ensure first notification is processed
        tokio::time::sleep(Duration::from_millis(50)).await;

        // Second caller (consensus observer) - will succeed
        let handle2 = tokio::spawn(async move {
            consensus_notifier_2
                .sync_for_duration(Duration::from_millis(100))
                .await
        });

        // Second caller should succeed
        let result2 = timeout(Duration::from_secs(2), handle2).await;
        assert!(result2.is_ok(), "Second caller should receive response");

        // First caller will DEADLOCK (timeout demonstrates this)
        let result1 = timeout(Duration::from_secs(2), handle1).await;
        assert!(result1.is_err(), "First caller is deadlocked - never receives response");
        
        println!("VULNERABILITY CONFIRMED: First sync_for_duration call never receives response!");
    }

    fn create_test_ledger_info() -> LedgerInfoWithSignatures {
        use aptos_types::{
            aggregate_signature::AggregateSignature,
            block_info::BlockInfo,
            ledger_info::{LedgerInfo, LedgerInfoWithSignatures},
        };
        use aptos_crypto::HashValue;
        
        LedgerInfoWithSignatures::new(
            LedgerInfo::new(BlockInfo::empty(), HashValue::zero()),
            AggregateSignature::empty(),
        )
    }
}
```

## Notes

This vulnerability demonstrates a critical architectural flaw where multiple independent components (consensus and consensus observer) share a resource (state sync notification handler) that cannot handle concurrent requests. The single-slot design assumes only one caller will ever request sync operations, which is violated in production configurations where consensus observer is enabled.

The vulnerability is exacerbated by the lack of timeout handling on the caller side - the `await` on the callback receiver has no timeout, so blocked callers wait indefinitely.

### Citations

**File:** consensus/src/consensus_provider.rs (L65-72)
```rust
    let execution_proxy = ExecutionProxy::new(
        Arc::new(BlockExecutor::<AptosVMBlockExecutor>::new(aptos_db)),
        txn_notifier,
        state_sync_notifier,
        node_config.transaction_filters.execution_filter.clone(),
        node_config.consensus.enable_pre_commit,
        None,
    );
```

**File:** consensus/src/consensus_provider.rs (L158-165)
```rust
        let execution_proxy = ExecutionProxy::new(
            Arc::new(BlockExecutor::<AptosVMBlockExecutor>::new(aptos_db.clone())),
            txn_notifier,
            state_sync_notifier,
            node_config.transaction_filters.execution_filter.clone(),
            node_config.consensus.enable_pre_commit,
            None,
        );
```

**File:** consensus/src/state_computer.rs (L137-156)
```rust
        let mut latest_logical_time = self.write_mutex.lock().await;

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by the BlockExecutor to prevent a memory leak.
        self.executor.finish();

        // Inject an error for fail point testing
        fail_point!("consensus::sync_for_duration", |_| {
            Err(anyhow::anyhow!("Injected error in sync_for_duration").into())
        });

        // Invoke state sync to synchronize for the specified duration. Here, the
        // ChunkExecutor will process chunks and commit to storage. However, after
        // block execution and commits, the internal state of the ChunkExecutor may
        // not be up to date. So, it is required to reset the cache of the
        // ChunkExecutor in state sync when requested to sync.
        let result = monitor!(
            "sync_for_duration",
            self.state_sync_notifier.sync_for_duration(duration).await
        );
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L216-217)
```rust
    // The latest consensus sync request that has been received
    consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L254-256)
```rust
        let consensus_sync_request =
            ConsensusSyncRequest::new_with_duration(start_time, sync_duration_notification);
        self.consensus_sync_request = Arc::new(Mutex::new(Some(consensus_sync_request)));
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L327-337)
```rust
        let mut sync_request_lock = self.consensus_sync_request.lock();
        let consensus_sync_request = sync_request_lock.take();

        // Notify consensus of the satisfied request
        match consensus_sync_request {
            Some(ConsensusSyncRequest::SyncDuration(_, sync_duration_notification)) => {
                self.respond_to_sync_duration_notification(
                    sync_duration_notification,
                    Ok(()),
                    Some(latest_synced_ledger_info),
                )?;
```

**File:** state-sync/inter-component/consensus-notifications/src/lib.rs (L144-146)
```rust
        // Create a consensus sync duration notification
        let (notification, callback_receiver) = ConsensusSyncDurationNotification::new(duration);
        let sync_duration_notification = ConsensusNotification::SyncForDuration(notification);
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L150-153)
```rust
                let latest_synced_ledger_info = match execution_client
                    .clone()
                    .sync_for_duration(fallback_duration)
                    .await
```
