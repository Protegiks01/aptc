# Audit Report

## Title
Consensus Observer Permanent Deadlock Due to Uncleaned Fallback Sync Handle on Failure

## Summary
The `sync_for_fallback()` function in the consensus observer sets the `fallback_sync_handle` to `Some()` synchronously before the async state sync operation completes. When the sync operation fails immediately, the spawned task terminates without sending a completion notification, leaving the handle set permanently. This causes the observer to believe it is still syncing when it has already failed, resulting in a permanent deadlock where the observer can never make progress or recover.

## Finding Description

The vulnerability exists in the state synchronization logic for the consensus observer's fallback mode. When the observer detects it is not making progress, it enters fallback mode by calling `sync_for_fallback()`. [1](#0-0) 

The critical race condition occurs at line 186, where `fallback_sync_handle` is set to `Some(DropGuard::new(abort_handle))` immediately after spawning the async task. However, the spawned task can fail immediately when calling `execution_client.sync_for_duration()`: [2](#0-1) 

When the sync operation fails, the task logs an error and returns early (line 159), which means:
1. The success notification is never sent (lines 164-173 are skipped)
2. The metrics are never cleared (lines 175-180 are skipped)  
3. The `fallback_sync_handle` remains `Some()` forever

The `in_fallback_mode()` method checks if this handle is set: [3](#0-2) 

In the observer's main progress check loop, when `in_fallback_mode()` returns true, it returns early without performing any other checks or operations: [4](#0-3) 

The handle is only cleared when a success notification is processed: [5](#0-4) 

Since no notification is sent on failure, `clear_active_fallback_sync()` is never called, and the observer remains permanently stuck.

The `sync_for_duration()` operation can fail in multiple ways: [6](#0-5) 

Failures can occur from:
- State sync notifier errors (line 155)
- Executor reset failures (line 167)
- Fail point injections (lines 144-146)
- Network connectivity issues
- Database errors

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under the Aptos bug bounty program because it causes **"Total loss of liveness/network availability"**.

Once the observer enters this state:
- The observer permanently stops processing new consensus messages
- Progress checks always return early without taking action
- The observer cannot enter fallback mode again (it thinks it's already in fallback)
- The observer cannot manage subscriptions or check syncing progress
- No automatic recovery mechanism exists - only a node restart can fix it

This breaks the fundamental liveness guarantee of consensus observer nodes, rendering them completely non-functional. Since this can occur due to transient network or database errors (which are common in distributed systems), affected nodes will experience permanent outages requiring manual intervention.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly likely to occur in production environments because:

1. **Common Trigger Conditions**: Any transient failure during state sync triggers this bug:
   - Network timeouts or connection failures
   - Database I/O errors
   - Resource exhaustion
   - State sync service unavailability

2. **No Special Attack Required**: This is not an attack - it's a natural race condition that occurs during normal operations when state sync fails

3. **Deterministic Outcome**: Once triggered, the deadlock is guaranteed - there is no probabilistic element

4. **No Recovery Path**: The observer has no self-healing mechanism and will remain stuck indefinitely

## Recommendation

The `sync_for_fallback()` function must be modified to ensure the `fallback_sync_handle` is cleared when the sync operation fails. The recommended fix is to wrap the sync operation in a mechanism that guarantees cleanup on both success and failure paths.

**Recommended Fix:**

Modify the spawned task to always send a notification (success or failure), or add explicit cleanup on the failure path:

```rust
pub fn sync_for_fallback(&mut self) {
    // ... existing setup code ...
    
    // Clone required components
    let consensus_observer_config = self.consensus_observer_config;
    let execution_client = self.execution_client.clone();
    let sync_notification_sender = self.state_sync_notification_sender.clone();
    
    // Spawn task with proper cleanup
    let (abort_handle, abort_registration) = AbortHandle::new_pair();
    tokio::spawn(Abortable::new(
        async move {
            // Set metrics
            metrics::set_gauge_with_label(
                &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                metrics::STATE_SYNCING_FOR_FALLBACK,
                1,
            );
            
            let fallback_duration = Duration::from_millis(
                consensus_observer_config.observer_fallback_duration_ms
            );
            
            // Perform sync operation
            let sync_result = execution_client
                .clone()
                .sync_for_duration(fallback_duration)
                .await;
            
            // ALWAYS clear metrics, regardless of success/failure
            metrics::set_gauge_with_label(
                &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                metrics::STATE_SYNCING_FOR_FALLBACK,
                0,
            );
            
            // Process result
            match sync_result {
                Ok(latest_synced_ledger_info) => {
                    // Send success notification
                    let notification = StateSyncNotification::fallback_sync_completed(
                        latest_synced_ledger_info
                    );
                    if let Err(error) = sync_notification_sender.send(notification) {
                        error!(LogSchema::new(LogEntry::ConsensusObserver)
                            .message(&format!(
                                "Failed to send fallback sync notification! Error: {:?}",
                                error
                            ))
                        );
                    }
                },
                Err(error) => {
                    error!(LogSchema::new(LogEntry::ConsensusObserver)
                        .message(&format!(
                            "Failed to sync for fallback! Error: {:?}",
                            error
                        ))
                    );
                    // Send failure notification to trigger cleanup
                    // Option 1: Add a new notification variant for failures
                    // Option 2: Use the channel closure to detect task completion
                    // Option 3: Clear the handle using a separate mechanism
                }
            }
        },
        abort_registration,
    ));
    
    self.fallback_sync_handle = Some(DropGuard::new(abort_handle));
}
```

Additionally, add a mechanism in the main observer loop to detect when the fallback task has terminated without sending a notification, and clear the handle accordingly.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use crate::pipeline::execution_client::DummyExecutionClient;
    use aptos_types::{aggregate_signature::AggregateSignature, ledger_info::LedgerInfo};
    use std::sync::Arc;

    /// This test demonstrates the vulnerability where fallback_sync_handle
    /// remains set even after the sync task fails
    #[tokio::test]
    async fn test_fallback_sync_handle_not_cleared_on_failure() {
        // Create a state sync manager with DummyExecutionClient (which fails)
        let consensus_observer_config = ConsensusObserverConfig::default();
        let (state_sync_notification_sender, mut notification_receiver) = 
            tokio::sync::mpsc::unbounded_channel();
        
        let mut state_sync_manager = StateSyncManager::new(
            consensus_observer_config,
            Arc::new(DummyExecutionClient), // This will fail sync_for_duration
            state_sync_notification_sender,
        );

        // Verify initial state - not in fallback mode
        assert!(!state_sync_manager.in_fallback_mode());

        // Trigger fallback sync (which will fail immediately)
        state_sync_manager.sync_for_fallback();

        // The handle is set immediately
        assert!(state_sync_manager.in_fallback_mode());

        // Wait for the task to fail
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

        // Try to receive notification (will timeout because task failed)
        let notification = tokio::time::timeout(
            tokio::time::Duration::from_millis(100),
            notification_receiver.recv()
        ).await;
        
        // No notification was received (task failed and returned early)
        assert!(notification.is_err());

        // VULNERABILITY: The observer still thinks it's in fallback mode
        // even though the sync task has already terminated
        assert!(state_sync_manager.in_fallback_mode());
        
        // The observer is now permanently stuck and cannot make progress
        // This assertion demonstrates the deadlock condition
    }
}
```

## Notes

The same vulnerability pattern may exist in `sync_to_commit()` function which follows a similar structure. A comprehensive audit should verify that all async state sync operations properly handle failures and clean up their state handles.

### Citations

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L100-103)
```rust
    /// Returns true iff state sync is currently executing in fallback mode
    pub fn in_fallback_mode(&self) -> bool {
        self.fallback_sync_handle.is_some()
    }
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L117-187)
```rust
    pub fn sync_for_fallback(&mut self) {
        // Log that we're starting to sync in fallback mode
        info!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Started syncing in fallback mode! Syncing duration: {:?} ms!",
                self.consensus_observer_config.observer_fallback_duration_ms
            ))
        );

        // Update the state sync fallback counter
        metrics::increment_counter_without_labels(&metrics::OBSERVER_STATE_SYNC_FALLBACK_COUNTER);

        // Clone the required components for the state sync task
        let consensus_observer_config = self.consensus_observer_config;
        let execution_client = self.execution_client.clone();
        let sync_notification_sender = self.state_sync_notification_sender.clone();

        // Spawn a task to sync for the fallback
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(
            async move {
                // Update the state sync metrics now that we're syncing for the fallback
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    1, // We're syncing for the fallback
                );

                // Get the fallback duration
                let fallback_duration =
                    Duration::from_millis(consensus_observer_config.observer_fallback_duration_ms);

                // Sync for the fallback duration
                let latest_synced_ledger_info = match execution_client
                    .clone()
                    .sync_for_duration(fallback_duration)
                    .await
                {
                    Ok(latest_synced_ledger_info) => latest_synced_ledger_info,
                    Err(error) => {
                        error!(LogSchema::new(LogEntry::ConsensusObserver)
                            .message(&format!("Failed to sync for fallback! Error: {:?}", error)));
                        return;
                    },
                };

                // Notify consensus observer that we've synced for the fallback
                let state_sync_notification =
                    StateSyncNotification::fallback_sync_completed(latest_synced_ledger_info);
                if let Err(error) = sync_notification_sender.send(state_sync_notification) {
                    error!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to send state sync notification for fallback! Error: {:?}",
                            error
                        ))
                    );
                }

                // Clear the state sync metrics now that we're done syncing
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    0, // We're no longer syncing for the fallback
                );
            },
            abort_registration,
        ));

        // Save the sync task handle
        self.fallback_sync_handle = Some(DropGuard::new(abort_handle));
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L168-177)
```rust
    async fn check_progress(&mut self) {
        debug!(LogSchema::new(LogEntry::ConsensusObserver)
            .message("Checking consensus observer progress!"));

        // If we've fallen back to state sync, we should wait for it to complete
        if self.state_sync_manager.in_fallback_mode() {
            info!(LogSchema::new(LogEntry::ConsensusObserver)
                .message("Waiting for state sync to complete fallback syncing!",));
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L934-965)
```rust
        // Verify that there is an active fallback sync
        if !self.state_sync_manager.in_fallback_mode() {
            // Log the error and return early
            error!(LogSchema::new(LogEntry::ConsensusObserver).message(
                "Failed to process fallback sync notification! No active fallback sync found!"
            ));
            return;
        }

        // Reset the fallback manager state
        self.observer_fallback_manager
            .reset_syncing_progress(&latest_synced_ledger_info);

        // Update the root with the latest synced ledger info
        self.observer_block_data
            .lock()
            .update_root(latest_synced_ledger_info);

        // If the epoch has changed, end the current epoch and start the latest one
        let current_epoch_state = self.get_epoch_state();
        if epoch > current_epoch_state.epoch {
            // Wait for the latest epoch to start
            self.execution_client.end_epoch().await;
            self.wait_for_epoch_start().await;
        };

        // Reset the pending block state
        self.clear_pending_block_state().await;

        // Reset the state sync manager for the synced fallback
        self.state_sync_manager.clear_active_fallback_sync();
    }
```

**File:** consensus/src/state_computer.rs (L132-174)
```rust
    async fn sync_for_duration(
        &self,
        duration: Duration,
    ) -> Result<LedgerInfoWithSignatures, StateSyncError> {
        // Grab the logical time lock
        let mut latest_logical_time = self.write_mutex.lock().await;

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by the BlockExecutor to prevent a memory leak.
        self.executor.finish();

        // Inject an error for fail point testing
        fail_point!("consensus::sync_for_duration", |_| {
            Err(anyhow::anyhow!("Injected error in sync_for_duration").into())
        });

        // Invoke state sync to synchronize for the specified duration. Here, the
        // ChunkExecutor will process chunks and commit to storage. However, after
        // block execution and commits, the internal state of the ChunkExecutor may
        // not be up to date. So, it is required to reset the cache of the
        // ChunkExecutor in state sync when requested to sync.
        let result = monitor!(
            "sync_for_duration",
            self.state_sync_notifier.sync_for_duration(duration).await
        );

        // Update the latest logical time
        if let Ok(latest_synced_ledger_info) = &result {
            let ledger_info = latest_synced_ledger_info.ledger_info();
            let synced_logical_time = LogicalTime::new(ledger_info.epoch(), ledger_info.round());
            *latest_logical_time = synced_logical_time;
        }

        // Similarly, after state synchronization, we have to reset the cache of
        // the BlockExecutor to guarantee the latest committed state is up to date.
        self.executor.reset()?;

        // Return the result
        result.map_err(|error| {
            let anyhow_error: anyhow::Error = error.into();
            anyhow_error.into()
        })
    }
```
