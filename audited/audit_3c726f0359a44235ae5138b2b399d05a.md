# Audit Report

## Title
Resource Exhaustion via Runaway Live Mode Connections in Indexer gRPC Data Service

## Summary
The `data_fetcher_task()` function in the indexer-grpc-data-service contains a resource leak vulnerability when operating in "live mode" (`transactions_count = None`). The infinite loop combined with a 120-second send timeout allows slow or malicious clients to cause detached tasks to accumulate, holding Redis connections, file store operators, and memory indefinitely until timeout-based cleanup occurs.

## Finding Description

The vulnerability exists in the live streaming mode of the indexer gRPC data service. When a client requests transaction streaming without specifying `transactions_count`, the service enters an infinite loop that only terminates when the channel send operation fails. [1](#0-0) 

The critical issue is the combination of three factors:

**1. Detached Task Spawning:** The task is spawned via `tokio::spawn` without storing its JoinHandle, making it impossible to track or cancel. [2](#0-1) 

**2. Long Send Timeout:** Each send operation can block for up to 120 seconds waiting for a slow receiver. [3](#0-2) [4](#0-3) 

**3. Small Channel Buffer:** The default response channel size is only 3, meaning the buffer fills quickly with slow clients. [5](#0-4) 

**Attack Scenario:**

1. Attacker opens multiple gRPC connections in live mode (no `transactions_count` specified)
2. Each connection spawns a detached `data_fetcher_task` that holds:
   - Redis connection manager
   - File store operator resources
   - Cache operator resources
   - In-memory data structures [6](#0-5) 

3. Attacker consumes data slowly enough to keep HTTP/2 keepalive alive but fast enough to fill the 3-item channel buffer
4. Send operations block for up to 120 seconds per chunk
5. Even with HTTP/2 keepalive (60s interval + 10s timeout), cleanup can take 70-190 seconds per connection [7](#0-6) 

6. During this window, resources remain held and new connections can be opened faster than old ones are cleaned up

**Lack of Connection Tracking:** The `CONNECTION_COUNT` metric only increments, never decrements, preventing proper monitoring of active connections. [8](#0-7) [9](#0-8) 

## Impact Explanation

This vulnerability enables **resource exhaustion attacks** against the Aptos indexer infrastructure. While the indexer-grpc service is not part of the core consensus layer, it is critical infrastructure for the Aptos ecosystem:

- **Service Availability:** Attackers can degrade or deny service to legitimate applications querying blockchain data
- **Resource Consumption:** Accumulation of stuck tasks exhausts Redis connections, file handles, and memory
- **Cascading Failures:** Resource exhaustion in the indexer service can impact dependent applications and services

This meets **Medium Severity** criteria as state inconsistencies and service degradation requiring operational intervention. The v2 service implementation demonstrates recognition of this issue through its redesigned connection management with explicit tracking and immediate failure detection. [10](#0-9) [11](#0-10) 

## Likelihood Explanation

**High Likelihood:** The vulnerability is trivial to exploit:
- No authentication bypass required (uses standard gRPC client)
- Attack requires only opening connections and consuming data slowly
- No special privileges or insider access needed
- Can be executed from any network location with gRPC access
- Low resource cost for attacker (each malicious connection is lightweight)
- High impact potential (each connection holds significant server resources)

The default configuration with a 3-item buffer and 120-second timeout makes the service particularly vulnerable to this attack pattern.

## Recommendation

Implement the following mitigations from the v2 service architecture:

**1. Immediate Failure Detection:** Replace `send_timeout` with `send().await` to detect disconnections immediately instead of waiting 120 seconds.

**2. Connection Tracking:** Implement explicit connection manager to track active streams and clean up properly:
```rust
// Track connection on start
connection_manager.insert_active_stream(&id, starting_version, ending_version);

// In the loop, use immediate send
if response_sender.send(Ok(response)).await.is_err() {
    warn!("Client dropped.");
    break;
}

// Clean up on exit
connection_manager.remove_active_stream(&id);
```

**3. Cancellation Tokens:** Store task JoinHandles and use cancellation tokens to allow forceful cleanup:
```rust
let cancel_token = CancellationToken::new();
let task_handle = tokio::spawn({
    let cancel = cancel_token.clone();
    async move {
        tokio::select! {
            _ = cancel.cancelled() => { /* cleanup */ }
            _ = data_fetcher_task(...) => {}
        }
    }
});
// Store task_handle for later cancellation
```

**4. Connection Limits:** Implement per-client connection limits and rate limiting to prevent accumulation attacks.

**5. Monitoring:** Fix `CONNECTION_COUNT` to track both connections and disconnections using a gauge instead of a counter.

## Proof of Concept

```rust
// Malicious gRPC client (pseudo-code)
use aptos_protos::indexer::v1::raw_data_client::RawDataClient;
use aptos_protos::indexer::v1::GetTransactionsRequest;

#[tokio::main]
async fn main() {
    let mut tasks = vec![];
    
    // Open many connections
    for i in 0..100 {
        tasks.push(tokio::spawn(async move {
            let mut client = RawDataClient::connect("http://indexer:50051")
                .await
                .unwrap();
            
            // Request live mode (transactions_count = None)
            let request = GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: None, // Live mode
                batch_size: Some(1),
            };
            
            let mut stream = client.get_transactions(request)
                .await
                .unwrap()
                .into_inner();
            
            // Consume data very slowly - keep connection alive but cause backpressure
            while let Some(resp) = stream.message().await.unwrap() {
                tokio::time::sleep(Duration::from_secs(30)).await; // Slow consumption
            }
        }));
    }
    
    futures::future::join_all(tasks).await;
}
```

This PoC demonstrates how an attacker can open multiple live-mode connections that consume data slowly, causing the server to accumulate detached tasks holding resources for extended periods (70-190 seconds each), eventually exhausting available connections and memory.

## Notes

While this vulnerability affects the indexer-grpc service rather than core consensus, it represents a valid resource exhaustion attack against critical Aptos infrastructure. The v2 service redesign with explicit connection management and immediate failure detection confirms this was recognized as a design flaw requiring remediation. Organizations running v1 indexer services should migrate to v2 or apply the recommended mitigations.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L58-60)
```rust
// The server will retry to send the response to the client and give up after RESPONSE_CHANNEL_SEND_TIMEOUT.
// This is to prevent the server from being occupied by a slow client.
const RESPONSE_CHANNEL_SEND_TIMEOUT: Duration = Duration::from_secs(120);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L151-153)
```rust
        CONNECTION_COUNT
            .with_label_values(&request_metadata.get_label_values())
            .inc();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L192-208)
```rust
        tokio::spawn({
            let request_metadata = request_metadata.clone();
            async move {
                data_fetcher_task(
                    redis_client,
                    file_store_operator,
                    cache_storage_format,
                    request_metadata,
                    transactions_count,
                    tx,
                    txns_to_strip_filter,
                    current_version,
                    in_memory_cache,
                )
                .await;
            }
        });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L386-412)
```rust
    let mut connection_start_time = Some(std::time::Instant::now());
    let mut transactions_count = transactions_count;

    // Establish redis connection
    let conn = match redis_client.get_tokio_connection_manager().await {
        Ok(conn) => conn,
        Err(e) => {
            ERROR_COUNT
                .with_label_values(&["redis_connection_failed"])
                .inc();
            // Connection will be dropped anyway, so we ignore the error here.
            let _result = tx
                .send_timeout(
                    Err(Status::unavailable(
                        "[Data Service] Cannot connect to Redis; please retry.",
                    )),
                    RESPONSE_CHANNEL_SEND_TIMEOUT,
                )
                .await;
            error!(
                error = e.to_string(),
                "[Data Service] Failed to get redis connection."
            );
            return;
        },
    };
    let mut cache_operator = CacheOperator::new(conn, cache_storage_format);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L468-505)
```rust
    loop {
        // 1. Fetch data from cache and file store.
        let transaction_data = match get_data_with_tasks(
            current_version,
            transactions_count,
            chain_id,
            &mut cache_operator,
            file_store_operator.clone(),
            request_metadata.clone(),
            cache_storage_format,
            in_memory_cache.clone(),
        )
        .await
        {
            DataFetchSubTaskResult::BatchSuccess(txns) => txns,
            DataFetchSubTaskResult::Success(_) => {
                unreachable!("Fetching from multiple tasks will never return a single vector")
            },
            DataFetchSubTaskResult::NoResults => continue,
        };

        let mut transaction_data = ensure_sequential_transactions(transaction_data);

        // TODO: Unify the truncation logic for start and end.
        if let Some(count) = transactions_count {
            if count == 0 {
                // End the data stream.
                // Since the client receives all the data it requested, we don't count it as a short connection.
                connection_start_time = None;
                break;
            } else if (count as usize) < transaction_data.len() {
                // Trim the data to the requested end version.
                transaction_data.truncate(count as usize);
                transactions_count = Some(0);
            } else {
                transactions_count = Some(count - transaction_data.len() as u64);
            }
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L883-887)
```rust
        tx.send_timeout(
            Result::<TransactionsResponse, Status>::Ok(resp_item.clone()),
            RESPONSE_CHANNEL_SEND_TIMEOUT,
        )
        .await?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L23-24)
```rust
// Default max response channel size.
const DEFAULT_MAX_RESPONSE_CHANNEL_SIZE: usize = 3;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L26-30)
```rust
// HTTP2 ping interval and timeout.
// This can help server to garbage collect dead connections.
// tonic server: https://docs.rs/tonic/latest/tonic/transport/server/struct.Server.html#method.http2_keepalive_interval
const HTTP2_PING_INTERVAL_DURATION: std::time::Duration = std::time::Duration::from_secs(60);
const HTTP2_PING_TIMEOUT_DURATION: std::time::Duration = std::time::Duration::from_secs(10);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/metrics.rs (L72-85)
```rust
pub static CONNECTION_COUNT: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "indexer_grpc_data_service_connection_count_v2",
        "Count of connections that data service has established",
        &[
            "identifier_type",
            "identifier",
            "email",
            "application_name",
            "processor"
        ],
    )
    .unwrap()
});
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L218-223)
```rust
                if response_sender.send(Ok(response)).await.is_err() {
                    info!(stream_id = id, "Client dropped.");
                    COUNTER
                        .with_label_values(&["live_data_service_client_dropped"])
                        .inc();
                    break;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L236-238)
```rust
        self.connection_manager
            .update_stream_progress(&id, next_version, size_bytes);
        self.connection_manager.remove_active_stream(&id);
```
