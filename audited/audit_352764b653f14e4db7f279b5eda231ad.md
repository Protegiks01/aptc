# Audit Report

## Title
Decryption Key Verification DoS: Byzantine Validators Can Exhaust CPU Resources Through Unbounded Pairing Operations

## Summary
Byzantine validators can flood honest validators with invalid `SecretShare` messages containing malformed decryption keys, forcing victims to perform expensive BLS pairing operations without sufficient rate limiting. This causes CPU exhaustion and validator node slowdowns, degrading consensus performance.

## Finding Description

The secret sharing mechanism in Aptos consensus relies on BLS signature verification through expensive pairing operations. When validators receive `SecretShare` messages from peers, they verify the decryption key shares using two pairing operations per message. [1](#0-0) 

The verification flow proceeds as follows:

1. Byzantine validators send `SecretShare` messages to target validators through the consensus network
2. Messages are queued in per-peer channels with a buffer size of 10 messages per validator [2](#0-1) [3](#0-2) 

3. A verification task processes incoming messages using a bounded executor limited to 16 concurrent tasks [4](#0-3) [5](#0-4) 

4. Each message triggers signature verification which calls `verify_bls()` performing two expensive pairing operations **without any cheap pre-validation checks** [6](#0-5) [7](#0-6) 

**Attack Vector:**
- With 100 validators, if 10 Byzantine validators each send 10 invalid messages (queue capacity), that's 100 queued verification requests
- Each request performs 2 pairing operations (extremely expensive cryptographic operations)
- Even with the bounded executor limiting concurrency to 16, all 100 messages will be processed sequentially
- Byzantine validators can continuously send new invalid messages as old ones are processed
- No rate limiting prevents sustained flooding beyond the per-peer queue

**Invariant Violation:**
This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." There is no effective rate limiting or CPU budgeting for pairing operations in decryption key verification.

## Impact Explanation

**Severity: High** - "Validator node slowdowns"

The impact includes:
- **CPU Exhaustion**: Pairing operations are among the most expensive cryptographic operations. Continuous verification of invalid shares can consume significant CPU resources
- **Consensus Degradation**: Validators experiencing CPU exhaustion may miss voting deadlines, slow block proposal/validation, or fail to participate in consensus rounds effectively
- **Amplification**: With n validators, up to f < n/3 Byzantine validators can coordinate to maximize impact
- **Sustained Attack**: Unlike one-time attacks, this can be sustained continuously as long as Byzantine validators remain in the validator set

This does not reach Critical severity because:
- It does not directly cause consensus safety violations or fund loss
- The network remains operational, though degraded
- Byzantine validators are limited to < 1/3 of the validator set per BFT assumptions

## Likelihood Explanation

**Likelihood: High**

The attack is highly feasible because:
1. **Low Attacker Requirements**: Any Byzantine validator can execute this attack without special infrastructure or coordination
2. **Detectable but Not Preventable**: While network monitoring might detect unusual message patterns, there's no mechanism to prevent or rate-limit the expensive verification operations
3. **BFT Assumption**: The system must tolerate up to f < n/3 Byzantine validators, making this threat realistic
4. **No Authentication Cost**: Once authenticated at the network layer (noise handshake), validators can send messages without per-message authentication overhead
5. **Continuous Vector**: The attack can be sustained indefinitely, not requiring sophisticated timing or state manipulation

## Recommendation

Implement **cheap pre-validation checks** before expensive pairing operations and add **adaptive rate limiting**:

**Fix 1: Add Point Validation**
Before performing pairing operations, validate that the signature point is on the curve and in the correct subgroup (cheap checks):

```rust
fn verify_bls(
    verification_key_g2: G2Affine,
    digest: &Digest,
    offset: G2Affine,
    signature: G1Affine,
) -> Result<()> {
    // ADDED: Cheap point validation before expensive pairing
    if !signature.is_on_curve() || !signature.is_in_correct_subgroup_assuming_on_curve() {
        return Err(anyhow::anyhow!("invalid signature point"));
    }
    
    let hashed_offset: G1Affine = symmetric::hash_g2_element(offset)?;

    if PairingSetting::pairing(digest.as_g1() + hashed_offset, verification_key_g2)
        == PairingSetting::pairing(signature, G2Affine::generator())
    {
        Ok(())
    } else {
        Err(anyhow::anyhow!("bls verification error"))
    }
}
```

**Fix 2: Implement Per-Peer Rate Limiting with Backpressure**
Track verification failures per peer and implement exponential backoff:

```rust
// In SecretShareManager
struct VerificationMetrics {
    failure_count: HashMap<Author, (u64, Instant)>,
    backoff_duration: HashMap<Author, Duration>,
}

impl VerificationMetrics {
    fn should_rate_limit(&mut self, author: &Author) -> bool {
        if let Some((count, last_failure)) = self.failure_count.get(author) {
            let backoff = self.backoff_duration.get(author)
                .unwrap_or(&Duration::from_millis(100));
            if last_failure.elapsed() < *backoff {
                return true; // Rate limit
            }
        }
        false
    }
    
    fn record_failure(&mut self, author: &Author) {
        let entry = self.failure_count.entry(*author).or_insert((0, Instant::now()));
        entry.0 += 1;
        entry.1 = Instant::now();
        
        // Exponential backoff: 100ms, 200ms, 400ms, ...
        let backoff = Duration::from_millis(100 * 2_u64.pow((entry.0 as u32).min(10)));
        self.backoff_duration.insert(*author, backoff);
    }
}
```

**Fix 3: Global CPU Budget**
Track total pairing operations per time window and reject verification requests if budget exceeded.

## Proof of Concept

```rust
#[cfg(test)]
mod dos_test {
    use super::*;
    use crate::shared::key_derivation::{BIBEMasterPublicKey, BIBEDecryptionKey};
    use crate::shared::digest::Digest;
    use crate::group::{Fr, G1Affine, G2Affine};
    use ark_ec::AffineRepr;
    use ark_ff::UniformRand;
    use std::time::Instant;
    
    #[test]
    fn test_decryption_key_verification_dos() {
        let mut rng = rand::thread_rng();
        
        // Setup: Create a valid public key
        let msk = Fr::rand(&mut rng);
        let mpk = BIBEMasterPublicKey((G2Affine::generator() * msk).into());
        
        // Create a valid digest
        let digest = Digest::new_for_testing(&mut rng);
        
        // Attack: Create many invalid decryption keys
        let num_invalid_keys = 100;
        let mut invalid_keys = Vec::new();
        
        for _ in 0..num_invalid_keys {
            // Create random invalid signature
            let invalid_sig = G1Affine::rand(&mut rng);
            invalid_keys.push(BIBEDecryptionKey {
                signature_g1: invalid_sig,
            });
        }
        
        // Measure CPU time for verifying invalid keys
        let start = Instant::now();
        let mut failures = 0;
        
        for key in &invalid_keys {
            // This performs 2 expensive pairing operations per invalid key
            if mpk.verify_decryption_key(&digest, key).is_err() {
                failures += 1;
            }
        }
        
        let elapsed = start.elapsed();
        
        println!("Verified {} invalid keys in {:?}", num_invalid_keys, elapsed);
        println!("Average time per verification: {:?}", elapsed / num_invalid_keys);
        println!("Failures: {}/{}", failures, num_invalid_keys);
        
        // Assert that all invalid keys failed (as expected)
        assert_eq!(failures, num_invalid_keys);
        
        // Demonstrate the DoS: Each verification takes significant time
        // With 10 Byzantine validators each sending 10 messages = 100 verifications
        // At ~1-10ms per verification = 100ms - 1s of CPU time per wave
        // Repeated continuously = sustained CPU exhaustion
    }
}
```

## Notes

This vulnerability exploits the lack of **defense in depth** in cryptographic verification. While the bounded executor provides some concurrency limiting, it does not prevent sequential processing of a large queue of malicious messages. The combination of:
1. No cheap pre-validation
2. Limited per-peer queuing (10 messages) that allows accumulation across multiple Byzantine peers
3. No adaptive rate limiting based on verification failures
4. Expensive pairing operations (2 per message)

creates a viable DoS attack vector for Byzantine validators within the standard BFT threat model (< 1/3 malicious).

### Citations

**File:** crates/aptos-batch-encryption/src/shared/key_derivation.rs (L118-133)
```rust
fn verify_bls(
    verification_key_g2: G2Affine,
    digest: &Digest,
    offset: G2Affine,
    signature: G1Affine,
) -> Result<()> {
    let hashed_offset: G1Affine = symmetric::hash_g2_element(offset)?;

    if PairingSetting::pairing(digest.as_g1() + hashed_offset, verification_key_g2)
        == PairingSetting::pairing(signature, G2Affine::generator())
    {
        Ok(())
    } else {
        Err(anyhow::anyhow!("bls verification error"))
    }
}
```

**File:** consensus/src/epoch_manager.rs (L1285-1291)
```rust
        let (secret_share_manager_tx, secret_share_manager_rx) =
            aptos_channel::new::<AccountAddress, IncomingSecretShareRequest>(
                QueueStyle::KLAST,
                self.config.internal_per_key_channel_size,
                None,
            );
        self.secret_share_manager_tx = Some(secret_share_manager_tx);
```

**File:** config/src/config/consensus_config.rs (L242-242)
```rust
            internal_per_key_channel_size: 10,
```

**File:** config/src/config/consensus_config.rs (L379-379)
```rust
            num_bounded_executor_tasks: 16,
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L205-235)
```rust
    async fn verification_task(
        epoch_state: Arc<EpochState>,
        mut incoming_rpc_request: aptos_channel::Receiver<Author, IncomingSecretShareRequest>,
        verified_msg_tx: UnboundedSender<SecretShareRpc>,
        config: SecretShareConfig,
        bounded_executor: BoundedExecutor,
    ) {
        while let Some(dec_msg) = incoming_rpc_request.next().await {
            let tx = verified_msg_tx.clone();
            let epoch_state_clone = epoch_state.clone();
            let config_clone = config.clone();
            bounded_executor
                .spawn(async move {
                    match bcs::from_bytes::<SecretShareMessage>(dec_msg.req.data()) {
                        Ok(msg) => {
                            if msg.verify(&epoch_state_clone, &config_clone).is_ok() {
                                let _ = tx.unbounded_send(SecretShareRpc {
                                    msg,
                                    protocol: dec_msg.protocol,
                                    response_sender: dec_msg.response_sender,
                                });
                            }
                        },
                        Err(e) => {
                            warn!("Invalid dec message: {}", e);
                        },
                    }
                })
                .await;
        }
    }
```

**File:** crates/aptos-batch-encryption/src/shared/encryption_key.rs (L27-33)
```rust
    pub fn verify_decryption_key(
        &self,
        digest: &Digest,
        decryption_key: &BIBEDecryptionKey,
    ) -> Result<()> {
        BIBEMasterPublicKey(self.sig_mpk_g2).verify_decryption_key(digest, decryption_key)
    }
```

**File:** types/src/secret_sharing.rs (L75-82)
```rust
    pub fn verify(&self, config: &SecretShareConfig) -> anyhow::Result<()> {
        let index = config.get_id(self.author());
        let decryption_key_share = self.share().clone();
        // TODO(ibalajiarun): Check index out of bounds
        config.verification_keys[index]
            .verify_decryption_key_share(&self.metadata.digest, &decryption_key_share)?;
        Ok(())
    }
```
