# Audit Report

## Title
Module Publishing Validation Bypass via WriteSetPayload::Script

## Summary
The `execute_write_set()` function allows scripts in `WriteSetPayload::Script` transactions to call `code::publish_package_txn()`, which updates the `PackageRegistry` resource but never actually publishes the module bytecode to storage. This bypasses all native-level validations and creates an inconsistent blockchain state.

## Finding Description
In the `execute_write_set()` function, when processing `WriteSetPayload::Script`, the code executes the script and then forcibly returns an empty `ModuleWriteSet`, regardless of whether the script attempted to publish modules. [1](#0-0) 

When a script calls `code::publish_package_txn()`, the Move function performs Move-level validations and updates the `PackageRegistry` resource to record the published modules. It then calls the native function `request_publish` which stores a `PublishRequest` in the `NativeCodeContext`. [2](#0-1) [3](#0-2) 

However, the `execute_write_set()` function never calls `extract_publish_request()` to retrieve this request. Instead, it simply calls `tmp_session.finish()` which does not extract publish requests, and returns an empty `ModuleWriteSet`. [4](#0-3) 

In contrast, normal user transactions properly handle module publishing by extracting the publish request and performing comprehensive validations: [5](#0-4) 

The bypassed validations include:
- `validate_publish_request()` - metadata consistency and native function validation
- `reject_unstable_bytecode()` - prevents unstable code on mainnet  
- Complexity checks via `check_module_complexity()`
- Compatibility checks
- Module initialization (`init_module` functions)
- Actual module publication via `convert_modules_into_write_ops()` [6](#0-5) 

This creates a critical inconsistency where `PackageRegistry` claims modules are published, but the actual module bytecode does not exist in storage.

## Impact Explanation
This is a **HIGH severity** vulnerability that breaks the **State Consistency** invariant. The impact includes:

1. **State Corruption**: The blockchain enters an inconsistent state where the `PackageRegistry` metadata claims modules exist but the actual bytecode is missing from storage.

2. **Validation Bypass**: All critical native-level security checks are circumvented, including unstable bytecode rejection on mainnet, module complexity limits, and compatibility verification.

3. **Module Initialization Failure**: The `init_module` functions are never executed, potentially leaving modules in an uninitialized state if the metadata claims otherwise.

4. **Consensus Risk**: Different nodes may handle this inconsistency differently during transaction execution, potentially causing consensus disagreement if transactions attempt to import these "phantom" modules.

5. **Protocol Violation**: While `WriteSetPayload` transactions are restricted to genesis/waypoint operations, a compromised genesis generation process or malicious script could exploit this to corrupt the chain's initial state.

This meets the "Significant protocol violations" criteria for High Severity ($50,000) in the Aptos bug bounty program.

## Likelihood Explanation
The likelihood is **MEDIUM** because:

**Constraints:**
- Requires ability to inject scripts into `WriteSetPayload::Script` transactions
- These are only used in genesis transactions and waypoint updates, not user-submitted transactions
- Requires some level of privileged access to the genesis/waypoint generation process

**Realistic Scenarios:**
- Compromised genesis generation tooling or supply chain attack
- Malicious insider with access to genesis creation
- Governance-initiated waypoint update with a crafted malicious script
- Emergency recovery procedures using a compromised script

While the attack surface is limited, the operations that use these transactions (genesis, network upgrades) are critical and do occur in practice.

## Recommendation
The `execute_write_set()` function must extract and properly process any `PublishRequest` created during script execution. The fix should:

1. Extract the publish request after script execution
2. If a publish request exists, validate and process it through the same path as normal transactions
3. Return the actual `ModuleWriteSet` instead of forcibly returning empty

Recommended fix:

```rust
WriteSetPayload::Script { script, execute_as } => {
    let mut tmp_session = self.new_session(resolver, session_id, None);
    let senders = match txn_sender {
        None => vec![serialized_signer(execute_as)],
        Some(sender) => vec![serialized_signer(&sender), serialized_signer(execute_as)],
    };

    let traversal_storage = TraversalStorage::new();
    let mut traversal_context = TraversalContext::new(&traversal_storage);

    self.validate_and_execute_script(
        &mut tmp_session,
        &SerializedSigners::new(senders, None),
        code_storage,
        &mut UnmeteredGasMeter,
        &mut traversal_context,
        script,
        &mut NoOpTraceRecorder,
    )?;

    // Extract and process publish request
    let maybe_publish_request = tmp_session.extract_publish_request();
    
    if let Some(publish_request) = maybe_publish_request {
        // Validate and process the publish request
        let modules = self.deserialize_module_bundle(&publish_request.bundle)?;
        self.validate_publish_request(
            code_storage,
            &mut traversal_context,
            &mut UnmeteredGasMeter,
            &modules,
            publish_request.expected_modules,
            publish_request.allowed_deps,
        )?;
        
        // Actually publish the modules
        let module_write_set = convert_modules_into_write_ops(
            resolver,
            self.features(),
            code_storage,
            publish_request.bundle.into_bytes(),
        )?;
        
        let change_set_configs = ChangeSetConfigs::unlimited_at_gas_feature_version(
            self.gas_feature_version()
        );
        let change_set = tmp_session.finish(&change_set_configs, code_storage)?;
        
        Ok((change_set, module_write_set))
    } else {
        let change_set_configs = ChangeSetConfigs::unlimited_at_gas_feature_version(
            self.gas_feature_version()
        );
        let change_set = tmp_session.finish(&change_set_configs, code_storage)?;
        Ok((change_set, ModuleWriteSet::empty()))
    }
},
```

Alternatively, if the intention is to disallow module publishing through write set scripts entirely, add a check that aborts if a publish request is detected:

```rust
// After script execution, ensure no publish requests were made
if tmp_session.extract_publish_request().is_some() {
    return Err(VMStatus::error(
        StatusCode::FEATURE_UNDER_GATING,
        Some("Module publishing is not allowed in write set scripts".to_string()),
    ));
}
```

## Proof of Concept

```move
// malicious_genesis_script.move
script {
    use aptos_framework::code;
    use std::vector;
    use std::string;

    fun main(admin: &signer) {
        // Prepare malicious module metadata
        let metadata = /* serialized PackageMetadata with unstable bytecode */;
        let malicious_code = vector[/* malicious module bytecode */];
        
        // This will update PackageRegistry but modules won't be published
        code::publish_package_txn(admin, metadata, malicious_code);
        
        // Result: PackageRegistry claims module exists, but bytecode is missing
        // All native validations (unstable bytecode check, compatibility, etc.) are bypassed
    }
}
```

Rust test demonstrating the issue:
```rust
#[test]
fn test_write_set_script_module_publishing_bypass() {
    let genesis_key = /* ... */;
    let malicious_script = compile_script("malicious_genesis_script.move");
    
    let write_set_payload = WriteSetPayload::Script {
        script: malicious_script,
        execute_as: AccountAddress::ONE,
    };
    
    let genesis_txn = Transaction::GenesisTransaction(write_set_payload);
    
    // Execute the genesis transaction
    let output = executor.execute_transaction(genesis_txn);
    
    // Verify inconsistency:
    // 1. PackageRegistry at address ONE shows module published
    let registry = executor.read_resource::<PackageRegistry>(AccountAddress::ONE);
    assert!(registry.packages.len() > 0); // Module metadata exists
    
    // 2. But actual module bytecode doesn't exist in module storage
    let module_exists = executor.module_exists(
        AccountAddress::ONE, 
        "MaliciousModule"
    );
    assert!(!module_exists); // Module bytecode missing!
    
    // 3. ModuleWriteSet was empty
    assert!(output.module_write_set().is_empty());
}
```

## Notes
This vulnerability specifically affects the handling of module publishing in `WriteSetPayload::Script` transactions. The comment at line 2321-2322 acknowledges that "scripts should be able to publish modules" but states "this should be done through native context, and so the module write set must always be empty." However, the implementation does not prevent scripts from calling `publish_package_txn()`, nor does it properly handle the resulting `PublishRequest`. This creates the described state inconsistency and validation bypass.

### Citations

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L1464-1597)
```rust
    fn resolve_pending_code_publish_and_finish_user_session(
        &self,
        mut session: UserSession,
        resolver: &impl AptosMoveResolver,
        module_storage: &impl AptosModuleStorage,
        gas_meter: &mut impl AptosGasMeter,
        traversal_context: &mut TraversalContext,
        change_set_configs: &ChangeSetConfigs,
    ) -> Result<UserSessionChangeSet, VMStatus> {
        let maybe_publish_request = session.execute(|session| session.extract_publish_request());
        if maybe_publish_request.is_none() {
            let change_set = session.finish(change_set_configs, module_storage)?;
            return UserSessionChangeSet::new(
                change_set,
                ModuleWriteSet::empty(),
                change_set_configs,
            );
        }

        let PublishRequest {
            destination,
            bundle,
            expected_modules,
            allowed_deps,
            check_compat: _,
        } = maybe_publish_request.expect("Publish request exists");

        let modules = self.deserialize_module_bundle(&bundle)?;
        let modules: &Vec<CompiledModule> =
            traversal_context.referenced_module_bundles.alloc(modules);

        // Whether loading modules lazily, or as a full transitive closure, we always need to meter
        // 1) old versions of modules because they are used for compatibility checks, and 2) new
        // modules.
        if self.gas_feature_version() >= RELEASE_V1_10 {
            // Charge old versions of existing modules, in case of upgrades.
            for module in modules.iter() {
                let addr = module.self_addr();
                let name = module.self_name();

                if !traversal_context.visit_if_not_special_address(addr, name) {
                    continue;
                }

                let size_if_old_module_exists = module_storage
                    .unmetered_get_module_size(addr, name)?
                    .map(|v| v as u64);
                if let Some(old_size) = size_if_old_module_exists {
                    gas_meter
                        .charge_dependency(
                            DependencyKind::Existing,
                            addr,
                            name,
                            NumBytes::new(old_size),
                        )
                        .map_err(|err| {
                            err.finish(Location::Module(ModuleId::new(*addr, name.to_owned())))
                        })?;
                }
            }

            // Charge all modules in the bundle that is about to be published.
            for (module, blob) in modules.iter().zip(bundle.iter()) {
                let addr = module.self_addr();
                let name = module.self_name();
                gas_meter
                    .charge_dependency(
                        DependencyKind::New,
                        addr,
                        name,
                        NumBytes::new(blob.code().len() as u64),
                    )
                    .map_err(|err| err.finish(Location::Undefined))?;

                // In case of lazy loading: add all modules in a bundle as visited to avoid double
                // charging during module initialization.
                if self.features().is_lazy_loading_enabled() {
                    traversal_context.visit_if_not_special_address(addr, name);
                }
            }

            // Charge all immediate dependencies of a published package.
            self.charge_package_dependencies(
                module_storage,
                gas_meter,
                traversal_context,
                modules,
            )?;
        }

        for (module, blob) in modules.iter().zip(bundle.iter()) {
            // TODO(Gas): Make budget configurable.
            let budget = 2048 + blob.code().len() as u64 * 20;
            move_binary_format::check_complexity::check_module_complexity(module, budget)
                .map_err(|err| err.finish(Location::Undefined))?;
        }

        self.validate_publish_request(
            module_storage,
            traversal_context,
            gas_meter,
            modules,
            expected_modules,
            allowed_deps,
        )?;

        let check_struct_layout = true;
        let check_friend_linking = !self
            .features()
            .is_enabled(FeatureFlag::TREAT_FRIEND_AS_PRIVATE);
        // TODO(#17171): remove this once 1.34 is in production.
        let function_compat_bug = self.gas_feature_version() < gas_feature_versions::RELEASE_V1_34;
        let compatibility_checks = Compatibility::new(
            check_struct_layout,
            check_friend_linking,
            self.timed_features()
                .is_enabled(TimedFeatureFlag::EntryCompatibility),
            function_compat_bug,
        );

        session.finish_with_module_publishing_and_initialization(
            resolver,
            module_storage,
            gas_meter,
            traversal_context,
            self.features(),
            self.gas_feature_version(),
            change_set_configs,
            destination,
            bundle,
            modules,
            compatibility_checks,
        )
    }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2297-2324)
```rust
            WriteSetPayload::Script { script, execute_as } => {
                let mut tmp_session = self.new_session(resolver, session_id, None);
                let senders = match txn_sender {
                    None => vec![serialized_signer(execute_as)],
                    Some(sender) => vec![serialized_signer(&sender), serialized_signer(execute_as)],
                };

                let traversal_storage = TraversalStorage::new();
                let mut traversal_context = TraversalContext::new(&traversal_storage);

                self.validate_and_execute_script(
                    &mut tmp_session,
                    &SerializedSigners::new(senders, None),
                    code_storage,
                    &mut UnmeteredGasMeter,
                    &mut traversal_context,
                    script,
                    &mut NoOpTraceRecorder,
                )?;

                let change_set_configs =
                    ChangeSetConfigs::unlimited_at_gas_feature_version(self.gas_feature_version());
                let change_set = tmp_session.finish(&change_set_configs, code_storage)?;

                // While scripts should be able to publish modules, this should be done through
                // native context, and so the module write set must always be empty.
                Ok((change_set, ModuleWriteSet::empty()))
            },
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L168-228)
```text
    public fun publish_package(owner: &signer, pack: PackageMetadata, code: vector<vector<u8>>) acquires PackageRegistry {
        check_code_publishing_permission(owner);
        // Disallow incompatible upgrade mode. Governance can decide later if this should be reconsidered.
        assert!(
            pack.upgrade_policy.policy > upgrade_policy_arbitrary().policy,
            error::invalid_argument(EINCOMPATIBLE_POLICY_DISABLED),
        );

        let addr = signer::address_of(owner);
        if (!exists<PackageRegistry>(addr)) {
            move_to(owner, PackageRegistry { packages: vector::empty() })
        };

        // Checks for valid dependencies to other packages
        let allowed_deps = check_dependencies(addr, &pack);

        // Check package against conflicts
        // To avoid prover compiler error on spec
        // the package need to be an immutable variable
        let module_names = get_module_names(&pack);
        let package_immutable = &borrow_global<PackageRegistry>(addr).packages;
        let len = vector::length(package_immutable);
        let index = len;
        let upgrade_number = 0;
        vector::enumerate_ref(package_immutable
        , |i, old| {
            let old: &PackageMetadata = old;
            if (old.name == pack.name) {
                upgrade_number = old.upgrade_number + 1;
                check_upgradability(old, &pack, &module_names);
                index = i;
            } else {
                check_coexistence(old, &module_names)
            };
        });

        // Assign the upgrade counter.
        pack.upgrade_number = upgrade_number;

        let packages = &mut borrow_global_mut<PackageRegistry>(addr).packages;
        // Update registry
        let policy = pack.upgrade_policy;
        if (index < len) {
            *vector::borrow_mut(packages, index) = pack
        } else {
            vector::push_back(packages, pack)
        };

        event::emit(PublishPackage {
            code_address: addr,
            is_upgrade: upgrade_number > 0
        });

        // Request publish
        if (features::code_dependency_check_enabled())
            request_publish_with_allowed_deps(addr, module_names, allowed_deps, code, policy.policy)
        else
        // The new `request_publish_with_allowed_deps` has not yet rolled out, so call downwards
        // compatible code.
            request_publish(addr, module_names, code, policy.policy)
    }
```

**File:** aptos-move/framework/src/natives/code.rs (L284-362)
```rust
fn native_request_publish(
    context: &mut SafeNativeContext,
    _ty_args: &[Type],
    mut args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    debug_assert!(matches!(args.len(), 4 | 5));
    let with_allowed_deps = args.len() == 5;

    context.charge(CODE_REQUEST_PUBLISH_BASE)?;

    let policy = safely_pop_arg!(args, u8);
    let mut code = vec![];
    for module in safely_pop_arg!(args, Vec<Value>) {
        let module_code = module.value_as::<Vec<u8>>()?;

        context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(module_code.len() as u64))?;
        code.push(module_code);
    }

    let allowed_deps = if with_allowed_deps {
        let mut allowed_deps: BTreeMap<AccountAddress, BTreeSet<String>> = BTreeMap::new();

        for dep in safely_pop_arg!(args, Vec<Value>) {
            let (account, module_name) = unpack_allowed_dep(dep)?;

            let entry = allowed_deps.entry(account);

            if let Entry::Vacant(_) = &entry {
                // TODO: Is the 32 here supposed to indicate the length of an account address in bytes?
                context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(32))?;
            }

            context
                .charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(module_name.len() as u64))?;
            entry.or_default().insert(module_name);
        }

        Some(allowed_deps)
    } else {
        None
    };

    let mut expected_modules = BTreeSet::new();
    for name in safely_pop_arg!(args, Vec<Value>) {
        let str = get_move_string(name)?;

        // TODO(Gas): fine tune the gas formula
        context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(str.len() as u64))?;
        expected_modules.insert(str);
    }

    let destination = safely_pop_arg!(args, AccountAddress);

    // Add own modules to allowed deps
    let allowed_deps = allowed_deps.map(|mut allowed| {
        allowed
            .entry(destination)
            .or_default()
            .extend(expected_modules.clone());
        allowed
    });

    let code_context = context.extensions_mut().get_mut::<NativeCodeContext>();
    if code_context.requested_module_bundle.is_some() || !code_context.enabled {
        // Can't request second time or if publish requests are not allowed.
        return Err(SafeNativeError::Abort {
            abort_code: EALREADY_REQUESTED,
        });
    }
    code_context.requested_module_bundle = Some(PublishRequest {
        destination,
        bundle: ModuleBundle::new(code),
        expected_modules,
        allowed_deps,
        check_compat: policy != ARBITRARY_POLICY,
    });

    Ok(smallvec![])
}
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/session/mod.rs (L161-247)
```rust
    pub fn finish(
        self,
        configs: &ChangeSetConfigs,
        module_storage: &impl ModuleStorage,
    ) -> VMResult<VMChangeSet> {
        // Note: enabled by 1.38 gas feature version.
        let is_1_38_release = module_storage
            .runtime_environment()
            .vm_config()
            .propagate_dependency_limit_error;
        let function_extension = module_storage.as_function_value_extension();

        let resource_converter = |value: Value,
                                  layout: TriompheArc<MoveTypeLayout>,
                                  has_aggregator_lifting: bool|
         -> PartialVMResult<BytesWithResourceLayout> {
            let serialization_result = if has_aggregator_lifting {
                // We allow serialization of native values here because we want to
                // temporarily store native values (via encoding to ensure deterministic
                // gas charging) in block storage.
                ValueSerDeContext::new(function_extension.max_value_nest_depth())
                    .with_delayed_fields_serde()
                    .with_func_args_deserialization(&function_extension)
                    .serialize(&value, &layout)?
                    .map(|bytes| (bytes.into(), Some(layout)))
            } else {
                // Otherwise, there should be no native values so ensure
                // serialization fails here if there are any.
                ValueSerDeContext::new(function_extension.max_value_nest_depth())
                    .with_func_args_deserialization(&function_extension)
                    .serialize(&value, &layout)?
                    .map(|bytes| (bytes.into(), None))
            };
            serialization_result.ok_or_else(|| {
                let status_code = if is_1_38_release {
                    StatusCode::VALUE_SERIALIZATION_ERROR
                } else {
                    StatusCode::INTERNAL_TYPE_ERROR
                };
                PartialVMError::new(status_code)
                    .with_message(format!("Error when serializing resource {}.", value))
            })
        };

        let Self {
            data_cache,
            mut extensions,
            resolver,
            is_storage_slot_metadata_enabled,
        } = self;

        let change_set = data_cache
            .into_custom_effects(&resource_converter)
            .map_err(|e| e.finish(Location::Undefined))?;

        let (change_set, resource_group_change_set) =
            Self::split_and_merge_resource_groups(resolver, module_storage, change_set)
                .map_err(|e| e.finish(Location::Undefined))?;

        let table_context: NativeTableContext = extensions.remove();
        let table_change_set = table_context
            .into_change_set(&function_extension)
            .map_err(|e| e.finish(Location::Undefined))?;

        let aggregator_context: NativeAggregatorContext = extensions.remove();
        let aggregator_change_set = aggregator_context
            .into_change_set()
            .map_err(|e| e.finish(Location::Undefined))?;

        let event_context: NativeEventContext = extensions.remove();
        let events = event_context.legacy_into_events();

        let woc = WriteOpConverter::new(resolver, is_storage_slot_metadata_enabled);

        let change_set = Self::convert_change_set(
            &woc,
            change_set,
            resource_group_change_set,
            events,
            table_change_set,
            aggregator_change_set,
            configs.legacy_resource_creation_as_modification(),
        )
        .map_err(|e| e.finish(Location::Undefined))?;

        Ok(change_set)
    }
```
