# Audit Report

## Title
Cross-Version Deserialization Failure in ShamirThresholdConfig Due to Skipped Domain Field

## Summary
The `ShamirThresholdConfig<F>` struct skips serialization of its critical `domain` field, instead reconstructing it during deserialization using `Radix2EvaluationDomain::new(n)`. If the arkworks library changes how this domain is constructed between Aptos versions, validators running different versions would reconstruct incompatible configurations from identical serialized data, causing randomness generation failures and potential consensus issues. [1](#0-0) 

## Finding Description
The `ShamirThresholdConfig` struct contains a `domain` field marked with `#[serde(skip)]`, meaning it is not included in serialization. During deserialization, the custom `Deserialize` implementation reconstructs this domain: [2](#0-1) 

This breaks the **Deterministic Execution** invariant because:

1. **DKG Configuration Reconstruction**: During epoch transitions, validators call `new_public_params()` to reconstruct the DKG configuration from on-chain metadata: [3](#0-2) 

2. **Config Usage in Critical Operations**: The reconstructed `wconfig` (containing `ShamirThresholdConfig`) is used for:
   - Decrypting secret shares from DKG transcripts
   - Computing Lagrange coefficients for secret reconstruction
   - Randomness generation [4](#0-3) 

3. **Domain-Dependent Operations**: The domain directly affects critical cryptographic operations: [5](#0-4) 

**Attack Scenario During Rolling Upgrade:**
- Validator A runs Aptos v1.0 with arkworks v0.4.0
- Validator B upgrades to Aptos v2.0 with arkworks v0.5.0 (hypothetically with changed domain construction)
- Both validators read the same DKG transcript from on-chain storage
- Both call `new_public_params()` with identical metadata
- Validator A reconstructs domain using old arkworks behavior
- Validator B reconstructs domain using new arkworks behavior  
- Both decrypt shares using incompatible domains
- Randomness reconstruction produces different values or fails
- Consensus breaks due to divergent randomness generation

## Impact Explanation
This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Concrete Impact:**
1. **Randomness Generation Failures**: Validators cannot agree on reconstructed randomness values, breaking the randomness beacon
2. **Epoch Transition Deadlock**: DKG failures prevent epoch transitions, halting network progress
3. **Consensus Degradation**: Mixed validator versions produce non-deterministic results
4. **Manual Intervention Required**: Network operators must coordinate version upgrades to avoid DKG sessions during transition periods

While existing arkworks compatibility tests verify cryptographic primitives: [6](#0-5) 

These tests do **not** cover the `ShamirThresholdConfig` domain reconstruction path, leaving this vulnerability undetected.

## Likelihood Explanation
**Likelihood: Medium**

**Prerequisites:**
1. Arkworks library releases a version with changed `Radix2EvaluationDomain::new()` behavior
2. Aptos upgrades to this new arkworks version
3. Validators perform a rolling upgrade during an active DKG session

**Mitigating Factors:**
- Arkworks library maintains backward compatibility (generally)
- Coordinated upgrades outside DKG windows reduce risk
- The feature flag `arkworks-upgrade-compat-test` shows awareness of version issues [7](#0-6) 

**Amplifying Factors:**
- No explicit version compatibility checks for domain reconstruction
- DKG sessions are long-lived (entire epoch transitions)
- Emergency upgrades cannot wait for DKG completion

## Recommendation

**Solution 1: Serialize Domain Metadata**
Serialize sufficient metadata to deterministically reconstruct the domain, rather than relying on arkworks library behavior:

```rust
#[derive(Debug, Clone, Copy, Serialize, PartialEq, Eq)]
pub struct ShamirThresholdConfig<F: FftField> {
    pub n: usize,
    pub t: usize,
    // Store domain size to verify reconstruction
    domain_size: usize,
    #[serde(skip)]
    pub domain: Radix2EvaluationDomain<F>,
}

impl<'de, F: FftField> Deserialize<'de> for ShamirThresholdConfig<F> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct BasicFields {
            n: usize,
            t: usize,
            domain_size: usize,
        }

        let BasicFields { n, t, domain_size } = BasicFields::deserialize(deserializer)?;
        let domain = Radix2EvaluationDomain::new(n)
            .ok_or_else(|| serde::de::Error::custom(format!("Invalid domain size: {}", n)))?;
        
        // Verify reconstructed domain matches expected size
        if domain.size() != domain_size {
            return Err(serde::de::Error::custom(format!(
                "Domain size mismatch: expected {}, got {}. Possible arkworks version incompatibility.",
                domain_size, domain.size()
            )));
        }

        Ok(ShamirThresholdConfig { n, t, domain_size, domain })
    }
}
```

**Solution 2: Version Pinning**
Add explicit version compatibility checks in DKG initialization:

```rust
const ARKWORKS_DOMAIN_VERSION: u32 = 1;

pub fn new_public_params(dkg_session_metadata: &DKGSessionMetadata) -> RealDKGPublicParams {
    // Verify arkworks domain compatibility
    verify_domain_compatibility(ARKWORKS_DOMAIN_VERSION)?;
    // ... existing code
}
```

**Solution 3: Extended Compatibility Tests**
Add tests specifically covering `ShamirThresholdConfig` serialization across arkworks versions:

```rust
#[test]
#[cfg(feature = "arkworks-upgrade-compat-test")]
fn test_shamir_threshold_config_domain_compatibility() {
    let config_new = ShamirThresholdConfig::<Fr>::new(5, 10);
    let bytes = bcs::to_bytes(&config_new).unwrap();
    let config_old: ShamirThresholdConfigOld<FrOld> = bcs::from_bytes(&bytes).unwrap();
    
    // Verify domain properties match
    assert_eq!(config_new.domain.size(), config_old.domain.size());
    assert_eq!(config_new.domain.element(0), roundtrip_old_to_new(&config_old.domain.element(0)));
}
```

## Proof of Concept

```rust
// Test demonstrating domain reconstruction dependency on arkworks version
#[test]
fn test_domain_reconstruction_version_sensitivity() {
    use ark_bn254::Fr;
    use bcs;
    
    // Create and serialize config with current arkworks version
    let config_v1 = ShamirThresholdConfig::<Fr>::new(3, 8);
    let serialized = bcs::to_bytes(&config_v1).unwrap();
    
    // Deserialize with same version - should work
    let config_v2: ShamirThresholdConfig<Fr> = bcs::from_bytes(&serialized).unwrap();
    assert_eq!(config_v1.domain.size(), config_v2.domain.size());
    
    // Simulate lagrange coefficient computation - must match
    let indices = vec![0, 1, 2];
    let lagrange_v1 = config_v1.lagrange_for_subset(&indices);
    let lagrange_v2 = config_v2.lagrange_for_subset(&indices);
    assert_eq!(lagrange_v1, lagrange_v2);
    
    // Note: If arkworks changes Radix2EvaluationDomain::new() behavior,
    // the domain size or element generation could differ, causing:
    // - Different Lagrange coefficients
    // - Failed secret reconstruction  
    // - Consensus divergence during DKG
    
    println!("Domain size: {}", config_v2.domain.size());
    println!("First omega: {:?}", config_v2.domain.element(0));
}

// Test cross-version DKG scenario
#[test]  
fn test_dkg_mixed_versions() {
    // Simulate validators with different arkworks versions
    // attempting to use the same DKG transcript
    
    let metadata = create_test_dkg_metadata();
    
    // Validator A (old version) reconstructs config
    let params_a = RealDKG::new_public_params(&metadata);
    
    // Validator B (new version with hypothetically changed domain)
    // would reconstruct different config from SAME metadata
    // Leading to different secret share decryptions
    
    // This test would require actual old arkworks version
    // but demonstrates the vulnerability surface
}
```

## Notes

The vulnerability is **conditional** on arkworks library changes, but the lack of safeguards means the system is fragile to such changes. The existing arkworks compatibility test infrastructure exists but doesn't cover this critical path. Given that DKG configuration reconstruction is fundamental to consensus randomness, and the Aptos team clearly cares about arkworks compatibility (evidenced by the test suite), this gap represents a real security risk during version upgrades.

### Citations

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L42-53)
```rust
#[derive(Debug, Clone, Copy, Serialize, PartialEq, Eq)]
pub struct ShamirThresholdConfig<F: FftField> {
    /// Total number of participants (shares)
    pub n: usize,
    /// Threshold number of shares required to reconstruct the secret. Note that in
    /// MPC literature `t` usually denotes the maximal adversary threshold, so `t + 1`
    /// shares would be required to reconstruct the secret
    pub t: usize,
    /// Used for FFT-based polynomial operations. Recomputed from `n` on deserialize
    #[serde(skip)]
    pub domain: Radix2EvaluationDomain<F>,
}
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L105-123)
```rust
impl<'de, F: FftField> Deserialize<'de> for ShamirThresholdConfig<F> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct BasicFields {
            n: usize,
            t: usize,
        }

        let BasicFields { n, t } = BasicFields::deserialize(deserializer)?;

        let domain = Radix2EvaluationDomain::new(n) // Note that `new(n)` internally does `n.next_power_of_two()`
            .ok_or_else(|| serde::de::Error::custom(format!("Invalid domain size: {}", n)))?;

        Ok(ShamirThresholdConfig { n, t, domain })
    }
}
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L253-290)
```rust
    pub fn lagrange_for_subset(&self, indices: &[usize]) -> Vec<F> {
        // Step 0: check that subset is large enough
        assert!(
            indices.len() >= self.t,
            "subset size {} is smaller than threshold t={}",
            indices.len(),
            self.t
        );

        let xs_vec: Vec<F> = indices.iter().map(|i| self.domain.element(*i)).collect();

        // Step 1: compute poly w/ roots at all x in xs, compute eval at 0
        let vanishing_poly = vanishing_poly::from_roots(&xs_vec);
        let vanishing_poly_at_0 = vanishing_poly.coeffs[0]; // vanishing_poly(0) = const term

        // Step 2 (numerators): for each x in xs, divide poly eval from step 1 by (-x) using batch inversion
        let mut neg_xs: Vec<F> = xs_vec.iter().map(|&x| -x).collect();
        batch_inversion(&mut neg_xs);
        let numerators: Vec<F> = neg_xs
            .iter()
            .map(|&inv_neg_x| vanishing_poly_at_0 * inv_neg_x)
            .collect();

        // Step 3a (denominators): Compute derivative of poly from step 1, and its evaluations
        let derivative = vanishing_poly.differentiate();
        let derivative_evals = derivative.evaluate_over_domain(self.domain).evals; // TODO: with a filter perhaps we don't have to store all evals, but then batch inversion becomes a bit more tedious

        // Step 3b: Only keep the relevant evaluations, then perform a batch inversion
        let mut denominators: Vec<F> = indices.iter().map(|i| derivative_evals[*i]).collect();
        batch_inversion(&mut denominators);

        // Step 4: compute Lagrange coefficients
        numerators
            .into_iter()
            .zip(denominators)
            .map(|(numerator, denom_inv)| numerator * denom_inv)
            .collect()
    }
```

**File:** types/src/dkg/real_dkg/mod.rs (L199-224)
```rust
    fn new_public_params(dkg_session_metadata: &DKGSessionMetadata) -> RealDKGPublicParams {
        let randomness_config = dkg_session_metadata
            .randomness_config_derived()
            .unwrap_or_else(OnChainRandomnessConfig::default_enabled);
        let secrecy_threshold = randomness_config
            .secrecy_threshold()
            .unwrap_or_else(|| *rounding::DEFAULT_SECRECY_THRESHOLD);
        let reconstruct_threshold = randomness_config
            .reconstruct_threshold()
            .unwrap_or_else(|| *rounding::DEFAULT_RECONSTRUCT_THRESHOLD);
        let maybe_fast_path_secrecy_threshold = randomness_config.fast_path_secrecy_threshold();

        let pvss_config = build_dkg_pvss_config(
            dkg_session_metadata.dealer_epoch,
            secrecy_threshold,
            reconstruct_threshold,
            maybe_fast_path_secrecy_threshold,
            &dkg_session_metadata.target_validator_consensus_infos_cloned(),
        );
        let verifier = ValidatorVerifier::new(dkg_session_metadata.dealer_consensus_infos_cloned());
        RealDKGPublicParams {
            session_metadata: dkg_session_metadata.clone(),
            pvss_config,
            verifier: verifier.into(),
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L1056-1072)
```rust
        let transcript = bcs::from_bytes::<<DefaultDKG as DKGTrait>::Transcript>(
            dkg_session.transcript.as_slice(),
        )
        .map_err(NoRandomnessReason::TranscriptDeserializationError)?;

        let vuf_pp = WvufPP::from(&dkg_pub_params.pvss_config.pp);

        // No need to verify the transcript.

        // keys for randomness generation
        let (sk, pk) = DefaultDKG::decrypt_secret_share_from_transcript(
            &dkg_pub_params,
            &transcript,
            my_index as u64,
            &dkg_decrypt_key,
        )
        .map_err(NoRandomnessReason::SecretShareDecryptionFailed)?;
```

**File:** crates/aptos-crypto/src/unit_tests/arkworks_upgrade.rs (L66-97)
```rust
#[test]
fn test_roundtrip_and_serialization() {
    let mut rng = test_rng();

    // Prepare test cases: generator + random points
    let mut test_cases = vec![G1Old::generator()];
    test_cases.extend((0..20).map(|_| G1Old::rand(&mut rng)));

    for p_old in test_cases {
        // Convert old → new
        let p_new = roundtrip_old_to_new::<_, G1New>(&p_old);

        // Generator check
        if p_old == G1Old::generator() {
            assert_eq!(p_new, G1New::generator());
        }

        // Roundtrip old → new → old
        let p_old_back = roundtrip_new_to_old::<_, G1Old>(&p_new);
        assert_eq!(p_old_back, p_old, "Roundtrip old → new → old failed");

        // Serialization compatibility
        let mut buf_old = Vec::new();
        p_old.serialize_compressed(&mut buf_old).unwrap();

        let mut buf_new = Vec::new();
        p_new.serialize_compressed(&mut buf_new).unwrap();

        assert_eq!(buf_old.len(), buf_new.len());
        assert_eq!(buf_old, buf_new, "Compressed serialization mismatch");
    }
}
```

**File:** crates/aptos-crypto/Cargo.toml (L99-99)
```text
arkworks-upgrade-compat-test = []
```
