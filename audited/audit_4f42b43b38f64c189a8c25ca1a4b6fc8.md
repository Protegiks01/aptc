# Audit Report

## Title
Atomic Commit Violation in StateMerkleDb Causes State Inconsistency Under I/O Failure

## Summary
The `StateMerkleDb::commit()` method lacks atomicity when committing state merkle tree updates. Shard databases are committed first in parallel, followed by the top-level metadata database. If the top-level commit fails due to I/O errors, the system is left in an inconsistent state with shards containing new nodes but metadata lacking the corresponding root hash, violating the State Consistency invariant.

## Finding Description

The `RawBatch` struct contains a `rocksdb::WriteBatch` but has no Drop guard to prevent silent data loss if dropped uncommitted. [1](#0-0) 

More critically, the `StateMerkleDb::commit()` method performs non-atomic commits across multiple databases. The implementation commits all 16 shard batches in parallel first, then commits the top-level batch containing the root hash: [2](#0-1) 

The vulnerability occurs in this sequence:

1. Shard batches are committed in parallel (with `.unwrap_or_else()` that panics on failure)
2. If all shards succeed, execution reaches `commit_top_levels()`
3. The `commit_top_levels()` method calls `write_schemas()` which can return an error: [3](#0-2) 

4. The `write_schemas()` method can fail at two points: [4](#0-3) 

If `write_opt()` fails (line 297) due to disk I/O errors, disk full conditions, or RocksDB corruption, the method returns an error. At this point:
- All 16 shard databases have been permanently committed to disk
- The metadata database does NOT contain the root node for this version
- The state merkle tree is in an inconsistent state

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." Validators cannot compute the correct root hash because the root node is missing, while shard nodes exist.

## Impact Explanation

This qualifies as **Medium Severity** under Aptos bug bounty criteria: "State inconsistencies requiring intervention."

The impact includes:
1. **Consensus divergence**: Different validators experiencing I/O failures at different times will have different state
2. **State verification failure**: Cannot verify state root for affected version as root node is missing
3. **State sync failure**: Nodes cannot sync past the inconsistent version
4. **Difficult recovery**: Requires database rollback or manual intervention to fix
5. **Merkle proof generation failure**: Cannot generate proofs for keys at the affected version

While this requires specific I/O error conditions, disk errors are not uncommon in production systems, especially under high load or disk-full scenarios.

## Likelihood Explanation

**Moderate likelihood** due to:

1. **Realistic trigger conditions**: Disk I/O errors, disk-full conditions, and filesystem corruption occur in production systems
2. **High-frequency code path**: State commits occur for every block/checkpoint
3. **No retry mechanism**: If top-level commit fails, there's no automatic rollback of shard commits
4. **Timing window**: The more shards committed, the larger the time window for top-level failure

The vulnerability manifests whenever:
- Disk space becomes full between shard and top-level commits
- I/O errors occur during top-level write
- Process is killed/crashes during the narrow window after shard commits but before top-level commit

## Recommendation

Implement atomic commit semantics using one of these approaches:

**Option 1: Two-Phase Commit**
```rust
pub(crate) fn commit(
    &self,
    version: Version,
    top_levels_batch: impl IntoRawBatch,
    batches_for_shards: Vec<impl IntoRawBatch + Send>,
) -> Result<()> {
    // First, convert all batches to RawBatch without committing
    let top_raw = top_levels_batch.into_raw_batch(self.metadata_db())?;
    let shard_raws: Vec<_> = batches_for_shards
        .into_iter()
        .enumerate()
        .map(|(id, b)| (id, b.into_raw_batch(self.db_shard(id))))
        .collect::<Result<Vec<_>>>()?;
    
    // Commit top-level first (contains root hash)
    self.state_merkle_metadata_db.write_schemas(top_raw)?;
    
    // Then commit shards (if this fails, we have root but missing shards,
    // which is recoverable via state sync)
    THREAD_MANAGER.get_io_pool().install(|| {
        shard_raws.into_par_iter()
            .for_each(|(shard_id, batch)| {
                self.db_shard(shard_id).write_schemas(batch)
                    .unwrap_or_else(|err| panic!("Failed to commit shard {shard_id}: {err}"));
            });
    });
    
    Ok(())
}
```

**Option 2: Add Drop Guard to RawBatch**
Add a `#[must_use]` attribute and implement a Drop guard that panics if uncommitted:
```rust
#[derive(Default)]
#[must_use = "RawBatch must be committed via write_schemas"]
pub struct RawBatch {
    pub inner: Option<rocksdb::WriteBatch>,
    pub stats: SampledBatchStats,
    committed: bool,
}

impl Drop for RawBatch {
    fn drop(&mut self) {
        if !self.committed && self.inner.is_some() {
            panic!("RawBatch dropped without being committed!");
        }
    }
}
```

**Preferred solution**: Commit top-level metadata first, then shards. This ensures the root hash is persisted before shard data, making partial failures recoverable.

## Proof of Concept

```rust
// Reproduction scenario (pseudocode):
// 1. Setup a validator node with limited disk space
// 2. Process blocks to fill disk near capacity
// 3. Trigger state checkpoint commit
// 4. Inject disk-full error after shard commits but before top-level commit
//
// Expected: All 16 shards committed, metadata DB lacks root for version N
// Result: State inconsistency - cannot verify state root, sync fails

#[test]
fn test_atomic_commit_violation() {
    // Create StateMerkleDb with mocked disk that fails on metadata write
    let state_db = create_test_state_merkle_db();
    
    // Create batches for version 100
    let (top_batch, shard_batches) = create_test_batches(100);
    
    // Mock: Make metadata DB write fail after shard writes succeed
    inject_io_error_on_metadata_db_after_shards();
    
    // Attempt commit
    let result = state_db.commit(100, top_batch, shard_batches);
    
    // Verify: Shards have data but metadata doesn't
    assert!(result.is_err());
    for shard_id in 0..16 {
        // Shards have committed data
        assert!(shard_has_nodes_for_version(shard_id, 100));
    }
    // Metadata lacks root node
    assert!(metadata_lacks_root_for_version(100));
    
    // This state is now inconsistent and unrecoverable without manual intervention
}
```

## Notes

This vulnerability violates Aptos Critical Invariant #4: "State transitions must be atomic and verifiable via Merkle proofs." The current implementation commits state in a non-atomic manner, creating windows where partial commits can occur. While not directly exploitable by an external attacker, this represents a critical implementation flaw that can cause validator divergence and network instability under realistic error conditions.

### Citations

**File:** storage/schemadb/src/batch.rs (L79-83)
```rust
#[derive(Default)]
pub struct RawBatch {
    pub inner: rocksdb::WriteBatch,
    pub stats: SampledBatchStats,
}
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L147-171)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        top_levels_batch: impl IntoRawBatch,
        batches_for_shards: Vec<impl IntoRawBatch + Send>,
    ) -> Result<()> {
        ensure!(
            batches_for_shards.len() == NUM_STATE_SHARDS,
            "Shard count mismatch."
        );
        THREAD_MANAGER.get_io_pool().install(|| {
            batches_for_shards
                .into_par_iter()
                .enumerate()
                .for_each(|(shard_id, batch)| {
                    self.db_shard(shard_id)
                        .write_schemas(batch)
                        .unwrap_or_else(|err| {
                            panic!("Failed to commit state merkle shard {shard_id}: {err}")
                        });
                })
        });

        self.commit_top_levels(version, top_levels_batch)
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L269-276)
```rust
    pub(crate) fn commit_top_levels(
        &self,
        version: Version,
        batch: impl IntoRawBatch,
    ) -> Result<()> {
        info!(version = version, "Committing StateMerkleDb.");
        self.state_merkle_metadata_db.write_schemas(batch)
    }
```

**File:** storage/schemadb/src/lib.rs (L289-304)
```rust
    fn write_schemas_inner(&self, batch: impl IntoRawBatch, option: &WriteOptions) -> DbResult<()> {
        let labels = [self.name.as_str()];
        let _timer = APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS.timer_with(&labels);

        let raw_batch = batch.into_raw_batch(self)?;

        let serialized_size = raw_batch.inner.size_in_bytes();
        self.inner
            .write_opt(raw_batch.inner, option)
            .into_db_res()?;

        raw_batch.stats.commit();
        APTOS_SCHEMADB_BATCH_COMMIT_BYTES.observe_with(&[&self.name], serialized_size as f64);

        Ok(())
    }
```
