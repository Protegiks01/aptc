# Audit Report

## Title
Validator Front-Running via Non-Broadcast Transaction Submission in QuorumStore Mode

## Summary
When QuorumStore is enabled, validators can submit transactions to their local mempool that are marked as `NonQualified` and are not broadcast to other validators. These transactions remain available in the proposer's local mempool and can be included in proposed blocks. By exploiting the predictable proposer election mechanism, validators can time their transaction submissions to rounds where they are the proposer, enabling front-running attacks.

## Finding Description

The vulnerability exists due to the interaction between two mechanisms:

1. **Predictable Proposer Selection**: The `ProposerElection` trait provides deterministic proposer selection for future rounds. [1](#0-0) 

   For `RotatingProposer`, the selection is completely deterministic. [2](#0-1) 

   For `LeaderReputation`, selection is pseudo-random but deterministic based on epoch, round, and root hash. [3](#0-2) 

2. **Non-Broadcast Transaction Submission**: When QuorumStore is enabled, `broadcast_within_validator_network()` returns false, causing client-submitted transactions to be marked as `TimelineState::NonQualified`. [4](#0-3) 

   Critically, `NonQualified` transactions are added to `priority_index` (making them available to consensus) but **not** to `timeline_index` (preventing broadcast to peers). [5](#0-4) 

3. **Consensus Transaction Retrieval**: The `get_batch` method used by consensus to pull transactions iterates over `priority_index`, which includes `NonQualified` transactions. [6](#0-5) 

   The iteration source confirms this uses the priority index. [7](#0-6) 

**Attack Scenario:**

1. Validator A calculates they will be proposer in round R+N
2. Validator A observes a profitable transaction T in the shared mempool (e.g., a large DEX trade)
3. Validator A submits a front-running transaction F to their local RPC endpoint
4. Transaction F is marked as `NonQualified` and stored in Validator A's local `priority_index` but NOT broadcast
5. In round R+N, Validator A becomes proposer and calls `payload_client.pull_payload()` [8](#0-7) 
6. The proposer's mempool returns transactions including the non-broadcast transaction F
7. Validator A includes F in their proposed block, ordering it before T (by using slightly higher gas price)
8. Other validators see F for the first time in the proposed block
9. F executes before T, allowing Validator A to extract MEV

## Impact Explanation

This is a **MEDIUM severity** vulnerability per Aptos bug bounty criteria for the following reasons:

- **MEV Extraction**: Allows validators to extract value from users through front-running, sandwich attacks, and other MEV strategies
- **Fairness Violation**: Breaks the fundamental fairness assumption that all validators observe transactions at approximately the same time
- **Limited Scope**: Attack is limited to rounds where the malicious validator is the proposer (1/N chance where N is validator set size)
- **No Consensus Safety Break**: Does not violate consensus safety or cause network liveness issues
- **No Direct Fund Theft**: Does not allow direct theft of funds but enables profit extraction through transaction ordering

The impact aligns with "Limited funds loss or manipulation" under Medium Severity criteria, as it allows validators to profit at users' expense through transaction ordering manipulation.

## Likelihood Explanation

The likelihood of exploitation is **HIGH** because:

1. **Low Barrier to Entry**: Any validator can exploit this vulnerability without special privileges beyond being in the active validator set
2. **Easy Detection**: Validators can trivially compute future proposer assignments using public information
3. **Quorum Store Deployment**: This vulnerability is active in production deployments using QuorumStore (the recommended configuration)
4. **Economic Incentive**: MEV extraction provides direct financial incentives for exploitation
5. **No Detection Mechanism**: There is no mechanism to detect that a transaction was not properly broadcast before inclusion

The only limiting factor is that validators can only exploit this during rounds where they are the proposer, but with sufficient transactions to front-run, the expected value remains positive.

## Recommendation

Implement transaction broadcast validation to ensure all transactions included in proposals have been properly broadcast or are part of certified QuorumStore batches. Specifically:

1. **Remove NonQualified Priority Index Inclusion**: Modify `process_ready_transaction` to only add transactions to `priority_index` if they are eligible for broadcast (`TimelineState::NotReady`) or if they are part of signed QuorumStore batches.

2. **Add Broadcast Verification**: When QuorumStore is enabled, only allow transactions that:
   - Are part of ProofOfStore certified batches, OR
   - Have been observed in sufficient QuorumStore batch broadcasts

3. **Alternative Fix**: Require that `get_batch` only returns transactions that have been in the local mempool for a minimum duration (e.g., 1 second) to ensure they had time to propagate through the network.

**Code Fix Example:**

```rust
// In mempool/src/core_mempool/transaction_store.rs
fn process_ready_transaction(
    &mut self,
    address: &AccountAddress,
    txn_replay_protector: ReplayProtector,
) -> bool {
    if let Some(txns) = self.transactions.get_mut(address) {
        if let Some(txn) = txns.get_mut(&txn_replay_protector) {
            let sender_bucket = sender_bucket(address, self.num_sender_buckets);
            
            // Only add to priority_index if transaction is broadcast-eligible
            // or has been in mempool for minimum duration
            let ready_for_consensus = txn.timeline_state != TimelineState::NonQualified 
                || txn.insertion_info.insertion_time.elapsed().unwrap_or(Duration::ZERO) 
                   >= Duration::from_secs(1);
            
            if ready_for_consensus {
                let ready_for_quorum_store = !self.priority_index.contains(txn);
                self.priority_index.insert(txn);
                // ... rest of the function
            }
        }
    }
    false
}
```

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_validator_front_running() {
    // Setup: Create a validator node with QuorumStore enabled
    let mut config = NodeConfig::default();
    config.consensus.quorum_store_enabled = true;
    let validator = create_validator_node(config);
    
    // Step 1: Validator calculates they will be proposer in round 10
    let current_round = validator.consensus.current_round();
    let target_round = current_round + 10;
    let proposer = validator.consensus.proposer_election
        .get_valid_proposer(target_round);
    assert_eq!(proposer, validator.author);
    
    // Step 2: Validator observes profitable transaction in mempool
    let victim_tx = create_dex_swap_transaction(
        user_account,
        amount = 1000000,
        gas_price = 100
    );
    broadcast_transaction_to_network(victim_tx);
    
    // Step 3: Validator submits front-running transaction to LOCAL mempool only
    let frontrun_tx = create_dex_swap_transaction(
        validator_account,
        amount = 999999,
        gas_price = 101  // Slightly higher gas
    );
    validator.mempool.submit_transaction_local(frontrun_tx);
    
    // Step 4: Verify frontrun_tx is NonQualified and not broadcast
    let txn_state = validator.mempool.get_timeline_state(&frontrun_tx.hash());
    assert_eq!(txn_state, TimelineState::NonQualified);
    assert!(!was_broadcast_to_peers(frontrun_tx.hash()));
    
    // Step 5: Advance to target round
    advance_to_round(target_round);
    
    // Step 6: Validator proposes block
    let proposal = validator.consensus.generate_proposal(target_round).await;
    
    // Step 7: Verify frontrun_tx is included and ordered before victim_tx
    assert!(proposal.payload.contains(&frontrun_tx));
    assert!(proposal.payload.contains(&victim_tx));
    let frontrun_idx = proposal.payload.iter()
        .position(|tx| tx.hash() == frontrun_tx.hash()).unwrap();
    let victim_idx = proposal.payload.iter()
        .position(|tx| tx.hash() == victim_tx.hash()).unwrap();
    assert!(frontrun_idx < victim_idx, "Front-running transaction not ordered first");
    
    // Step 8: Other validators receive proposal with unseen transaction
    let peer_validator = get_peer_validator();
    assert!(!peer_validator.mempool.contains(&frontrun_tx.hash()),
        "Peer validator never saw the front-running transaction");
}
```

## Notes

This vulnerability is inherent in the design decision to disable mempool broadcasting when QuorumStore is enabled, combined with the ability to predict proposer selection. The root cause is that `NonQualified` transactions are treated as valid for consensus inclusion despite never being broadcast to peers.

The issue is more severe in networks with rotating proposer election or reputation-based election where proposer assignments can be predicted multiple rounds in advance, giving validators ample time to observe profitable transactions and prepare front-running attacks.

### Citations

**File:** consensus/src/liveness/proposer_election.rs (L10-36)
```rust
pub trait ProposerElection {
    /// If a given author is a valid candidate for being a proposer, generate the info,
    /// otherwise return None.
    /// Note that this function is synchronous.
    fn is_valid_proposer(&self, author: Author, round: Round) -> bool {
        self.get_valid_proposer(round) == author
    }

    /// Return the valid proposer for a given round (this information can be
    /// used by e.g., voters for choosing the destinations for sending their votes to).
    fn get_valid_proposer(&self, round: Round) -> Author;

    /// Return the chain health: a ratio of voting power participating in the consensus.
    fn get_voting_power_participation_ratio(&self, _round: Round) -> f64 {
        1.0
    }

    fn get_valid_proposer_and_voting_power_participation_ratio(
        &self,
        round: Round,
    ) -> (Author, f64) {
        (
            self.get_valid_proposer(round),
            self.get_voting_power_participation_ratio(round),
        )
    }
}
```

**File:** consensus/src/liveness/rotating_proposer_election.rs (L35-40)
```rust
impl ProposerElection for RotatingProposer {
    fn get_valid_proposer(&self, round: Round) -> Author {
        self.proposers
            [((round / u64::from(self.contiguous_rounds)) % self.proposers.len() as u64) as usize]
    }
}
```

**File:** consensus/src/liveness/leader_reputation.rs (L695-739)
```rust
impl ProposerElection for LeaderReputation {
    fn get_valid_proposer_and_voting_power_participation_ratio(
        &self,
        round: Round,
    ) -> (Author, VotingPowerRatio) {
        let target_round = round.saturating_sub(self.exclude_round);
        let (sliding_window, root_hash) = self.backend.get_block_metadata(self.epoch, target_round);
        let voting_power_participation_ratio =
            self.compute_chain_health_and_add_metrics(&sliding_window, round);
        let mut weights =
            self.heuristic
                .get_weights(self.epoch, &self.epoch_to_proposers, &sliding_window);
        let proposers = &self.epoch_to_proposers[&self.epoch];
        assert_eq!(weights.len(), proposers.len());

        // Multiply weights by voting power:
        let stake_weights: Vec<u128> = weights
            .iter_mut()
            .enumerate()
            .map(|(i, w)| *w as u128 * self.voting_powers[i] as u128)
            .collect();

        let state = if self.use_root_hash {
            [
                root_hash.to_vec(),
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        } else {
            [
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        };

        let chosen_index = choose_index(stake_weights, state);
        (proposers[chosen_index], voting_power_participation_ratio)
    }

    fn get_valid_proposer(&self, round: Round) -> Author {
        self.get_valid_proposer_and_voting_power_participation_ratio(round)
            .0
    }
```

**File:** mempool/src/shared_mempool/tasks.rs (L140-146)
```rust
    let ineligible_for_broadcast =
        smp.network_interface.is_validator() && !smp.broadcast_within_validator_network();
    let timeline_state = if ineligible_for_broadcast {
        TimelineState::NonQualified
    } else {
        TimelineState::NotReady
    };
```

**File:** mempool/src/core_mempool/transaction_store.rs (L547-596)
```rust
    fn process_ready_transaction(
        &mut self,
        address: &AccountAddress,
        txn_replay_protector: ReplayProtector,
    ) -> bool {
        if let Some(txns) = self.transactions.get_mut(address) {
            if let Some(txn) = txns.get_mut(&txn_replay_protector) {
                let sender_bucket = sender_bucket(address, self.num_sender_buckets);
                let ready_for_quorum_store = !self.priority_index.contains(txn);

                self.priority_index.insert(txn);

                // If timeline_state is `NonQualified`, then the transaction is never added to the timeline_index,
                // and never broadcasted to the shared mempool.
                let ready_for_mempool_broadcast = txn.timeline_state == TimelineState::NotReady;
                if ready_for_mempool_broadcast {
                    self.timeline_index
                        .get_mut(&sender_bucket)
                        .unwrap()
                        .insert(txn);
                }

                if ready_for_quorum_store {
                    let bucket = self
                        .timeline_index
                        .get(&sender_bucket)
                        .unwrap()
                        .get_bucket(txn.ranking_score);
                    let bucket = format!("{}_{}", sender_bucket, bucket);

                    Self::log_ready_transaction(
                        txn.ranking_score,
                        bucket.as_str(),
                        &mut txn.insertion_info,
                        ready_for_mempool_broadcast,
                        txn.priority_of_sender
                            .clone()
                            .map_or_else(|| "Unknown".to_string(), |priority| priority.to_string())
                            .as_str(),
                    );
                }
                // Remove txn from parking lot after it has been promoted to
                // priority_index / timeline_index, i.e., txn status is ready.
                self.parking_lot_index.remove(txn);

                return true;
            }
        }
        false
    }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L1008-1010)
```rust
    pub(crate) fn iter_queue(&self) -> PriorityQueueIter<'_> {
        self.priority_index.iter()
    }
```

**File:** mempool/src/core_mempool/mempool.rs (L425-507)
```rust
    pub(crate) fn get_batch(
        &self,
        max_txns: u64,
        max_bytes: u64,
        return_non_full: bool,
        exclude_transactions: BTreeMap<TransactionSummary, TransactionInProgress>,
    ) -> Vec<SignedTransaction> {
        let start_time = Instant::now();
        let exclude_size = exclude_transactions.len();
        let mut inserted = HashSet::new();

        let gas_end_time = start_time.elapsed();

        let mut result = vec![];
        // Helper DS. Helps to mitigate scenarios where account submits several transactions
        // with increasing gas price (e.g. user submits transactions with sequence number 1, 2
        // and gas_price 1, 10 respectively)
        // Later txn has higher gas price and will be observed first in priority index iterator,
        // but can't be executed before first txn. Once observed, such txn will be saved in
        // `skipped` DS and rechecked once it's ancestor becomes available
        let mut skipped = HashSet::new();
        let mut total_bytes = 0;
        let mut txn_walked = 0usize;
        // iterate over the queue of transactions based on gas price
        'main: for txn in self.transactions.iter_queue() {
            txn_walked += 1;
            let txn_ptr = TxnPointer::from(txn);

            // TODO: removed gas upgraded logic. double check if it's needed
            if exclude_transactions.contains_key(&txn_ptr) {
                continue;
            }
            let txn_replay_protector = txn.replay_protector;
            match txn_replay_protector {
                ReplayProtector::SequenceNumber(txn_seq) => {
                    let txn_in_sequence = txn_seq > 0
                        && Self::txn_was_chosen(
                            txn.address,
                            txn_seq - 1,
                            &inserted,
                            &exclude_transactions,
                        );
                    let account_sequence_number =
                        self.transactions.get_account_sequence_number(&txn.address);
                    // include transaction if it's "next" for given account or
                    // we've already sent its ancestor to Consensus.
                    if txn_in_sequence || account_sequence_number == Some(&txn_seq) {
                        inserted.insert((txn.address, txn_replay_protector));
                        result.push((txn.address, txn_replay_protector));
                        if (result.len() as u64) == max_txns {
                            break;
                        }
                        // check if we can now include some transactions
                        // that were skipped before for given account
                        let (skipped_txn_sender, mut skipped_txn_seq_num) =
                            (txn.address, txn_seq + 1);
                        while skipped.remove(&(skipped_txn_sender, skipped_txn_seq_num)) {
                            inserted.insert((
                                skipped_txn_sender,
                                ReplayProtector::SequenceNumber(skipped_txn_seq_num),
                            ));
                            result.push((
                                skipped_txn_sender,
                                ReplayProtector::SequenceNumber(skipped_txn_seq_num),
                            ));
                            if (result.len() as u64) == max_txns {
                                break 'main;
                            }
                            skipped_txn_seq_num += 1;
                        }
                    } else {
                        skipped.insert((txn.address, txn_seq));
                    }
                },
                ReplayProtector::Nonce(_) => {
                    inserted.insert((txn.address, txn_replay_protector));
                    result.push((txn.address, txn_replay_protector));
                    if (result.len() as u64) == max_txns {
                        break;
                    }
                },
            };
        }
```

**File:** consensus/src/liveness/proposal_generator.rs (L652-672)
```rust
        let (validator_txns, mut payload) = self
            .payload_client
            .pull_payload(
                PayloadPullParameters {
                    max_poll_time: self.quorum_store_poll_time.saturating_sub(proposal_delay),
                    max_txns: max_block_txns,
                    max_txns_after_filtering: max_block_txns_after_filtering,
                    soft_max_txns_after_filtering: max_txns_from_block_to_execute
                        .unwrap_or(max_block_txns_after_filtering),
                    max_inline_txns: self.max_inline_txns,
                    maybe_optqs_payload_pull_params,
                    user_txn_filter: payload_filter,
                    pending_ordering,
                    pending_uncommitted_blocks: pending_blocks.len(),
                    recent_max_fill_fraction: max_fill_fraction,
                    block_timestamp: timestamp,
                },
                validator_txn_filter,
            )
            .await
            .context("Fail to retrieve payload")?;
```
