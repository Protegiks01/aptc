# Audit Report

## Title
Insufficient Fallback Peers for Proof Batch Fetching in OptQuorumStore Payloads Causes Network Sync Availability Issues

## Summary
When `process_optqs_payload()` processes proof batches with `additional_peers_to_request = None`, only ProofOfStore signers and the block author are used as responders for batch fetching. Block voters are never included for proof batches (hardcoded on line 525), creating an asymmetry compared to opt_batches. This causes availability issues when syncing nodes attempt to fetch batches but ProofOfStore signers are unavailable, even though block voters have the data. [1](#0-0) 

## Finding Description

The vulnerability stems from an asymmetry in peer selection for batch fetching in the OptQuorumStore payload type:

**For opt_batches:** The `block_signers` parameter is properly passed through: [2](#0-1) 

**For proof_with_data batches:** `None` is always hardcoded, ignoring block_signers: [1](#0-0) 

In `process_optqs_payload()`, when `additional_peers_to_request` is `None`, only the block author and batch signers are used as responders: [3](#0-2) 

For ProofOfStore batches, `signers()` returns the multi-signature signers (typically 2/3+ validators): [4](#0-3) 

**Attack Scenario:**

1. Block proposer includes ProofOfStore batches signed by validator Set A (2/3+ voting power)
2. Validator Set B (different validators, also 2/3+) vote for and commit the block
3. Set B validators prefetch batches during voting and store them locally
4. A syncing node (fullnode or lagging validator) needs to execute this block
5. In `materialize_block()`, if the QC future times out or arrives late, the fallback path executes: [5](#0-4) 

6. `get_transactions(block, None)` is called, passing `None` for block_voters
7. The batch requester only has access to Set A validators (ProofOfStore signers) + block author
8. If many Set A validators are offline/unresponsive, batch fetching fails after exhausting retries: [6](#0-5) 

9. Set B validators (who have the data) are never contacted, causing `ExecutorError::CouldNotGetData`

The retry mechanism provides 10 attempts by default, contacting 5 peers per attempt: [7](#0-6) 

However, if the responders list contains mostly offline validators, all retries will fail.

## Impact Explanation

**Severity: Medium** - This issue causes availability problems that impact network synchronization:

1. **Syncing nodes affected:** Fullnodes, lagging validators, restarted validators, and any node that didn't participate in the original block voting
2. **Failure mode:** Batch fetching fails with `ExecutorError::CouldNotGetData`, preventing block execution
3. **Network impact:** Slows down or prevents network synchronization during validator churn or network issues
4. **No consensus safety violation:** Validators who voted on the block can still execute (they have batches locally from prefetch)

This matches **Medium Severity** per Aptos Bug Bounty criteria: "State inconsistencies requiring intervention" - syncing nodes cannot catch up without manual intervention or waiting for ProofOfStore signers to come back online.

The issue is exacerbated during:
- Validator set changes/epoch transitions
- Network partitions affecting ProofOfStore signers
- Validator restarts or maintenance windows
- Geographic concentration of ProofOfStore signers

## Likelihood Explanation

**Likelihood: Medium-High**

**Triggering conditions:**
1. ProofOfStore signers have significant overlap with offline/unresponsive validators (natural during validator churn)
2. Syncing node calls `materialize_block()` without QC available yet (happens regularly during sync)
3. The `tokio::select!` races between QC arrival and timeout - timeout can win even if QC is available

**Frequency factors:**
- Validator churn happens regularly during epoch transitions
- Network latency variations mean QC timeout path is taken frequently
- The hardcoded `None` means this affects ALL proof batch fetching for syncing nodes
- No fallback mechanism exists to contact block voters

**Real-world scenarios:**
- Geographic network partitions
- Cloud provider outages affecting subset of validators
- Coordinated validator maintenance
- New fullnodes joining the network

The issue is not theoretical - it will manifest in production environments with validator diversity and normal network conditions.

## Recommendation

**Fix:** Pass `block_signers` (or equivalent) to `process_optqs_payload()` for proof batches, consistent with opt_batches:

```rust
// In get_transactions() around line 520-527:
let proof_batch_txns = process_optqs_payload(
    opt_qs_payload.proof_with_data(),
    self.batch_reader.clone(),
    block,
    &self.ordered_authors,
    block_signers.as_ref(),  // FIX: Pass block_signers instead of None
)
.await?;
```

**Rationale:**
1. Block voters validated batch availability and likely have the batches cached
2. Creates symmetry with opt_batches processing
3. Increases available responder pool without security compromise
4. Block voters are already verified through QC validation

**Additional enhancement:** Consider also passing `block_signers` to `prefetch_helper()` for proof batches in `prefetch_payload_data()`: [8](#0-7) 

Change line 284 from `None` to `Some(author)` to include block author during prefetch as well.

## Proof of Concept

**Reproduction Steps:**

1. Set up test environment with two validator sets A and B
2. Create ProofOfStore batches with signatures from Set A (minimum 2/3+1 validators)
3. Have Set B validators vote on and commit a block containing these batches
4. Simulate Set A validators going offline (drop their network connections)
5. Start a new syncing node that needs to fetch this block
6. Ensure the QC future times out in `materialize_block()` by adding network delay
7. Observe batch request failures in logs with counter increments:
   - `SENT_BATCH_REQUEST_RETRY_COUNT` incrementing 10 times (retry limit)
   - `RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT` incrementing
8. Observe final error: `ExecutorError::CouldNotGetData`
9. Note that Set B validators are never contacted despite having the data

**Expected behavior:** The syncing node should successfully fetch batches from Set B validators who voted for the block.

**Actual behavior:** The syncing node only contacts Set A validators (ProofOfStore signers) and fails to fetch batches, causing sync failure.

**Rust test outline:**
```rust
#[tokio::test]
async fn test_proof_batch_fetch_without_block_signers() {
    // Setup: Create ProofOfStore with Set A signers
    // Setup: Create block voted by Set B validators  
    // Setup: Make Set A unavailable
    // Execute: Call get_transactions(block, None)
    // Assert: Batch fetch fails even though Set B has data
    // Assert: RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT incremented
}
```

## Notes

This vulnerability represents a design oversight rather than malicious exploitation. The asymmetry between opt_batches and proof_batches handling suggests the hardcoded `None` on line 525 was not intentional. The fix is straightforward and aligns with the existing pattern for opt_batches, improving network resilience without introducing new attack surfaces.

### Citations

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L281-287)
```rust
                prefetch_helper(
                    p.proof_with_data(),
                    self.batch_reader.clone(),
                    None,
                    timestamp,
                    &self.ordered_authors,
                )
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L512-519)
```rust
                let opt_batch_txns = process_optqs_payload(
                    opt_qs_payload.opt_batches(),
                    self.batch_reader.clone(),
                    block,
                    &self.ordered_authors,
                    block_signers.as_ref(),
                )
                .await?;
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L520-527)
```rust
                let proof_batch_txns = process_optqs_payload(
                    opt_qs_payload.proof_with_data(),
                    self.batch_reader.clone(),
                    block,
                    &self.ordered_authors,
                    None,
                )
                .await?;
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L601-629)
```rust
async fn process_optqs_payload<T: TDataInfo>(
    data_ptr: &BatchPointer<T>,
    batch_reader: Arc<dyn BatchReader>,
    block: &Block,
    ordered_authors: &[PeerId],
    additional_peers_to_request: Option<&BitVec>,
) -> ExecutorResult<Vec<SignedTransaction>> {
    let mut signers = Vec::new();
    if let Some(peers) = additional_peers_to_request {
        for i in peers.iter_ones() {
            if let Some(author) = ordered_authors.get(i) {
                signers.push(*author);
            }
        }
    }
    if let Some(author) = block.author() {
        signers.push(author);
    }

    let batches_and_responders = data_ptr
        .batch_summary
        .iter()
        .map(|summary| {
            let mut signers = signers.clone();
            signers.append(&mut summary.signers(ordered_authors));

            (summary.info().clone(), signers)
        })
        .collect();
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L697-699)
```rust
    fn signers(&self, ordered_authors: &[PeerId]) -> Vec<PeerId> {
        self.shuffled_signers(ordered_authors)
    }
```

**File:** consensus/src/block_preparer.rs (L54-63)
```rust
        let (txns, max_txns_from_block_to_execute, block_gas_limit) = tokio::select! {
                // Poll the block qc future until a QC is received. Ignore None outcomes.
                Some(qc) = block_qc_fut => {
                    let block_voters = Some(qc.ledger_info().get_voters_bitvec().clone());
                    self.payload_manager.get_transactions(block, block_voters).await
                },
                result = self.payload_manager.get_transactions(block, None) => {
                   result
                }
        }?;
```

**File:** consensus/src/quorum_store/batch_requester.rs (L101-180)
```rust
    pub(crate) async fn request_batch(
        &self,
        digest: HashValue,
        expiration: u64,
        responders: Arc<Mutex<BTreeSet<PeerId>>>,
        mut subscriber_rx: oneshot::Receiver<PersistedValue<BatchInfoExt>>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let validator_verifier = self.validator_verifier.clone();
        let mut request_state = BatchRequesterState::new(responders, self.retry_limit);
        let network_sender = self.network_sender.clone();
        let request_num_peers = self.request_num_peers;
        let my_peer_id = self.my_peer_id;
        let epoch = self.epoch;
        let retry_interval = Duration::from_millis(self.retry_interval_ms as u64);
        let rpc_timeout = Duration::from_millis(self.rpc_timeout_ms as u64);

        monitor!("batch_request", {
            let mut interval = time::interval(retry_interval);
            let mut futures = FuturesUnordered::new();
            let request = BatchRequest::new(my_peer_id, epoch, digest);
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
                    },
                    Some(response) = futures.next() => {
                        match response {
                            Ok(BatchResponse::Batch(batch)) => {
                                counters::RECEIVED_BATCH_RESPONSE_COUNT.inc();
                                let payload = batch.into_transactions();
                                return Ok(payload);
                            }
                            // Short-circuit if the chain has moved beyond expiration
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
                            }
                            Ok(BatchResponse::BatchV2(_)) => {
                                error!("Batch V2 response is not supported");
                            }
                            Err(e) => {
                                counters::RECEIVED_BATCH_RESPONSE_ERROR_COUNT.inc();
                                debug!("QS: batch request error, digest:{}, error:{:?}", digest, e);
                            }
                        }
                    },
                    result = &mut subscriber_rx => {
                        match result {
                            Ok(persisted_value) => {
                                counters::RECEIVED_BATCH_FROM_SUBSCRIPTION_COUNT.inc();
                                let (_, maybe_payload) = persisted_value.unpack();
                                return Ok(maybe_payload.expect("persisted value must exist"));
                            }
                            Err(err) => {
                                debug!("channel closed: {}", err);
                            }
                        };
                    },
                }
            }
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
        })
    }
```

**File:** config/src/config/quorum_store_config.rs (L127-129)
```rust
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
```
