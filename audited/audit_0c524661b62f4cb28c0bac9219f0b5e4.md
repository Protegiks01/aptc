# Audit Report

## Title
Division by Zero in Rotating Proposer Election Causes Total Network Liveness Failure

## Summary
A critical vulnerability exists in the consensus layer where governance can set `contiguous_rounds=0` in the on-chain consensus configuration, causing all validator nodes to panic with division-by-zero when determining the next block proposer. This results in complete and permanent network halt requiring a hard fork to recover.

## Finding Description
The vulnerability stems from missing validation of the `contiguous_rounds` parameter in both the Move governance contract and the Rust consensus implementation.

**Attack Vector:**
1. An on-chain governance proposal sets a consensus configuration containing `ProposerElectionType::RotatingProposer(0)` or `ProposerElectionType::FixedProposer(0)` where the `contiguous_rounds` parameter is 0
2. The Move contract only validates that config bytes are non-empty, not the structural validity [1](#0-0) 
3. When the next epoch begins, the configuration is deserialized successfully (0 is a valid `u32` value) [2](#0-1) 
4. The `create_proposer_election()` function creates a `RotatingProposer` instance with the malicious config [3](#0-2) 
5. The `RotatingProposer::new()` constructor performs no validation on `contiguous_rounds` [4](#0-3) 
6. When consensus attempts to determine the proposer for any round, `get_valid_proposer()` performs division by zero: `round / u64::from(self.contiguous_rounds)` [5](#0-4) 
7. The panic propagates to all validators simultaneously, halting the entire network

**Invariant Violation:**
This breaks the fundamental consensus liveness guarantee - the network must always be able to propose and commit new blocks under honest majority assumptions.

## Impact Explanation
**Severity: CRITICAL** - Total loss of liveness/network availability (up to $1,000,000 per Aptos bug bounty)

- **Complete Network Halt:** All validator nodes crash simultaneously when attempting to determine the block proposer
- **Non-Recoverable:** The panic occurs in the core consensus loop, preventing any block production
- **Requires Hard Fork:** Recovery necessitates a coordinated network upgrade with corrected configuration
- **Affects All Validators:** Every validator node in the network experiences the same panic
- **Permanent Freezing of Funds:** Users cannot transfer funds or execute transactions until recovery

## Likelihood Explanation
**Likelihood: MEDIUM**

While this requires a governance proposal to pass, which needs significant stake/voting power, the attack is feasible because:

1. **No Technical Barriers:** The malicious config is syntactically valid BCS-encoded data
2. **Human Error Risk:** Could occur accidentally during legitimate config updates if tooling doesn't validate
3. **Governance Process:** Aptos governance has passed numerous configuration changes; a malicious or erroneous proposal could succeed
4. **No Runtime Detection:** The vulnerability only manifests after epoch transition, making testing difficult

The attack does NOT require:
- Validator private key compromise
- Byzantine validator collusion
- Network-level attacks

## Recommendation
Implement validation at multiple layers:

**1. Rust-side validation in `RotatingProposer::new()`:**
```rust
pub fn new(proposers: Vec<Author>, contiguous_rounds: u32) -> Self {
    assert!(
        contiguous_rounds > 0,
        "contiguous_rounds must be greater than 0"
    );
    assert!(
        !proposers.is_empty(),
        "proposers list cannot be empty"
    );
    Self {
        proposers,
        contiguous_rounds,
    }
}
```

**2. Move-side validation with native function:**
Implement a native function `validate_consensus_config_internal(config_bytes: vector<u8>): bool` that deserializes and validates the config structure before allowing governance to set it. Update the Move contract:
```move
public fun set_for_next_epoch(account: &signer, config: vector<u8>) {
    system_addresses::assert_aptos_framework(account);
    assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
    assert!(validate_consensus_config_internal(config), error::invalid_argument(EINVALID_CONFIG));
    std::config_buffer::upsert<ConsensusConfig>(ConsensusConfig {config});
}
```

**3. Add validation during deserialization:**
Implement a `validate()` method on `OnChainConsensusConfig` that checks all invariants.

## Proof of Concept
```rust
#[test]
#[should_panic(expected = "attempt to divide by zero")]
fn test_division_by_zero_with_contiguous_rounds_zero() {
    use crate::liveness::{
        proposer_election::ProposerElection,
        rotating_proposer_election::RotatingProposer,
    };
    use aptos_types::account_address::AccountAddress;

    // Create RotatingProposer with contiguous_rounds=0 (malicious config)
    let proposers = vec![
        AccountAddress::random(),
        AccountAddress::random(),
    ];
    let pe = RotatingProposer::new(proposers, 0);

    // Attempt to get proposer for round 1 - this will panic with division by zero
    pe.get_valid_proposer(1);
}
```

To test the full attack path through governance:
```rust
// This would be a Move integration test showing governance setting malicious config:
// 1. Create a governance proposal with ConsensusConfig containing RotatingProposer(0)
// 2. Vote to pass the proposal
// 3. Trigger epoch change
// 4. Observe panic when consensus attempts to determine next proposer
```

## Notes
- The vulnerability affects both `ProposerElectionType::RotatingProposer(0)` and `ProposerElectionType::FixedProposer(0)` variants, as both use the same `RotatingProposer` implementation internally
- Test files show only non-zero values (1, 3) are used in practice, confirming 0 is not an intended valid value [6](#0-5) 
- The same vulnerability pattern could exist for other on-chain config parameters that lack proper validation
- This is a defense-in-depth issue: validation should occur at serialization (Move), deserialization (Rust), and usage (constructor) layers

### Citations

**File:** aptos-move/framework/aptos-framework/sources/configs/consensus_config.move (L52-56)
```text
    public fun set_for_next_epoch(account: &signer, config: vector<u8>) {
        system_addresses::assert_aptos_framework(account);
        assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
        std::config_buffer::upsert<ConsensusConfig>(ConsensusConfig {config});
    }
```

**File:** consensus/src/epoch_manager.rs (L286-298)
```rust
    /// Create a proposer election handler based on proposers
    fn create_proposer_election(
        &self,
        epoch_state: &EpochState,
        onchain_config: &OnChainConsensusConfig,
    ) -> Arc<dyn ProposerElection + Send + Sync> {
        let proposers = epoch_state
            .verifier
            .get_ordered_account_addresses_iter()
            .collect::<Vec<_>>();
        match &onchain_config.proposer_election_type() {
            ProposerElectionType::RotatingProposer(contiguous_rounds) => {
                Arc::new(RotatingProposer::new(proposers, *contiguous_rounds))
```

**File:** consensus/src/epoch_manager.rs (L1178-1201)
```rust
        let onchain_consensus_config: anyhow::Result<OnChainConsensusConfig> = payload.get();
        let onchain_execution_config: anyhow::Result<OnChainExecutionConfig> = payload.get();
        let onchain_randomness_config_seq_num: anyhow::Result<RandomnessConfigSeqNum> =
            payload.get();
        let randomness_config_move_struct: anyhow::Result<RandomnessConfigMoveStruct> =
            payload.get();
        let onchain_jwk_consensus_config: anyhow::Result<OnChainJWKConsensusConfig> = payload.get();
        let dkg_state = payload.get::<DKGState>();

        if let Err(error) = &onchain_consensus_config {
            warn!("Failed to read on-chain consensus config {}", error);
        }

        if let Err(error) = &onchain_execution_config {
            warn!("Failed to read on-chain execution config {}", error);
        }

        if let Err(error) = &randomness_config_move_struct {
            warn!("Failed to read on-chain randomness config {}", error);
        }

        self.epoch_state = Some(epoch_state.clone());

        let consensus_config = onchain_consensus_config.unwrap_or_default();
```

**File:** consensus/src/liveness/rotating_proposer_election.rs (L25-32)
```rust
impl RotatingProposer {
    /// With only one proposer in the vector, it behaves the same as a fixed proposer strategy.
    pub fn new(proposers: Vec<Author>, contiguous_rounds: u32) -> Self {
        Self {
            proposers,
            contiguous_rounds,
        }
    }
```

**File:** consensus/src/liveness/rotating_proposer_election.rs (L35-39)
```rust
impl ProposerElection for RotatingProposer {
    fn get_valid_proposer(&self, round: Round) -> Author {
        self.proposers
            [((round / u64::from(self.contiguous_rounds)) % self.proposers.len() as u64) as usize]
    }
```

**File:** consensus/src/liveness/rotating_proposer_test.rs (L9-25)
```rust
#[test]
fn test_rotating_proposer() {
    let chosen_author = AccountAddress::random();
    let another_author = AccountAddress::random();
    let proposers = vec![chosen_author, another_author];
    let pe = RotatingProposer::new(proposers, 1);

    // Send a proposal from both chosen author and another author, the only winning proposals
    // follow the round-robin rotation.

    assert!(!pe.is_valid_proposer(chosen_author, 1));
    assert!(pe.is_valid_proposer(another_author, 1),);
    assert!(pe.is_valid_proposer(chosen_author, 2));
    assert!(!pe.is_valid_proposer(another_author, 2));
    assert_eq!(pe.get_valid_proposer(1), another_author);
    assert_eq!(pe.get_valid_proposer(2), chosen_author);
}
```
