# Audit Report

## Title
Indexer Memory Exhaustion via Unbounded previous_block_votes_bitvec JSON Conversion

## Summary
The indexer's `from_transaction()` function performs unbounded JSON conversion of `previous_block_votes_bitvec` without size validation, allowing memory exhaustion attacks that crash indexer services and cause unavailability.

## Finding Description

The vulnerability exists in the indexer's processing of BlockMetadataTransaction data. The `previous_block_votes_bitvec` field stores validator voting information as a `Vec<u8>`. While the BitVec data structure used in consensus enforces an 8KB limit (MAX_BUCKETS = 8192), this constraint is not enforced during BCS deserialization or indexer processing. [1](#0-0) 

The JSON conversion uses `serde_json::to_value()` which allocates memory proportional to the vector size. A 100MB Vec<u8> would result in approximately 300MB+ of JSON string allocation (each byte becomes a number in a JSON array with commas and brackets).

The root cause is that BlockMetadata's BCS deserialization uses `serde_bytes` for direct Vec<u8> deserialization without enforcing BitVec size constraints: [2](#0-1) 

While consensus normally creates BlockMetadata using BitVec (which has the 8KB limit), BCS deserialization bypasses this: [3](#0-2) 

The block validation in consensus checks payload and validator transaction sizes but not BlockMetadata field sizes: [4](#0-3) 

A Byzantine validator (within the < 1/3 Byzantine tolerance of AptosBFT) could construct a BlockMetadata with an arbitrarily large previous_block_votes_bitvec by directly calling `BlockMetadata::new()` with a crafted Vec<u8>, bypassing the normal BitVec construction path used in consensus.

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria.

This qualifies as "State inconsistencies requiring intervention" and service unavailability:
- **Indexer Service Unavailability**: Memory exhaustion crashes the indexer process, preventing API queries and blockchain data access
- **Degraded User Experience**: Applications relying on indexer APIs become non-functional
- **Operational Intervention Required**: Manual restart and potential data cleanup needed
- **No Direct Fund Loss**: Does not affect consensus, execution, or asset security
- **Limited Blast Radius**: Affects indexer infrastructure, not validator consensus

The impact is constrained because:
1. Does not affect consensus safety or liveness
2. Does not enable fund theft or manipulation  
3. Can be mitigated by restarting indexer services
4. Does not corrupt on-chain state

## Likelihood Explanation

**Likelihood: Low to Medium**

Factors increasing likelihood:
- Byzantine validators (up to 1/3) are within AptosBFT threat model
- No validation prevents oversized previous_block_votes_bitvec in block processing
- Exploit only requires constructing one malicious block
- JSON conversion happens automatically on every block metadata transaction

Factors decreasing likelihood:
- Requires compromised/malicious validator (trusted role)
- Network layer may have implicit message size limits
- Malicious behavior would be detectable by monitoring
- Attack provides limited benefit to attacker (DoS only, no theft)

The attack complexity is low once validator access is obtained, but validator compromise itself is the main barrier.

## Recommendation

Implement size validation at multiple layers:

**1. Indexer Layer (Defense in Depth):**
```rust
pub fn from_transaction(txn: &APIBlockMetadataTransaction, block_height: i64) -> Self {
    let txn_version = txn.info.version.0 as i64;
    
    // Validate previous_block_votes_bitvec size
    const MAX_VOTES_BITVEC_BYTES: usize = 8192; // Match BitVec MAX_BUCKETS
    if txn.previous_block_votes_bitvec.len() > MAX_VOTES_BITVEC_BYTES {
        panic!("previous_block_votes_bitvec exceeds maximum size: {} > {}",
               txn.previous_block_votes_bitvec.len(), MAX_VOTES_BITVEC_BYTES);
    }
    
    Self {
        version: txn_version,
        block_height,
        id: txn.id.to_string(),
        epoch: txn.epoch.0 as i64,
        round: txn.round.0 as i64,
        proposer: standardize_address(&txn.proposer.inner().to_hex_literal()),
        failed_proposer_indices: serde_json::to_value(&txn.failed_proposer_indices).unwrap(),
        previous_block_votes_bitvec: serde_json::to_value(&txn.previous_block_votes_bitvec)
            .unwrap(),
        timestamp: parse_timestamp(txn.timestamp.0, txn_version),
    }
}
```

**2. BlockMetadata Deserialization Validation:**
Add custom deserialization to enforce size limits: [5](#0-4) 

**3. Block Validation in Consensus:**
Add explicit field size checks when processing block proposals to reject blocks with oversized metadata fields before they enter the execution pipeline.

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_oversized_previous_block_votes_bitvec_memory_exhaustion() {
    use aptos_types::block_metadata::BlockMetadata;
    use aptos_crypto::HashValue;
    use aptos_types::account_address::AccountAddress;
    
    // Malicious validator constructs BlockMetadata with 100MB Vec<u8>
    let malicious_votes_bitvec = vec![0u8; 100 * 1024 * 1024]; // 100MB
    
    let block_metadata = BlockMetadata::new(
        HashValue::random(),
        1, // epoch
        1, // round
        AccountAddress::random(),
        malicious_votes_bitvec.clone(),
        vec![],
        1000000,
    );
    
    // Serialize to BCS (simulating storage/transmission)
    let bcs_bytes = bcs::to_bytes(&block_metadata).unwrap();
    assert!(bcs_bytes.len() > 100 * 1024 * 1024);
    
    // Deserialize (simulating reading from storage)
    let deserialized: BlockMetadata = bcs::from_bytes(&bcs_bytes).unwrap();
    assert_eq!(deserialized.previous_block_votes_bitvec().len(), 100 * 1024 * 1024);
    
    // JSON conversion (simulating indexer processing)
    // This will allocate ~300MB+ causing memory exhaustion
    let json_result = serde_json::to_value(deserialized.previous_block_votes_bitvec());
    
    // In production, this would exhaust memory and crash the indexer
    // Memory usage: ~300MB for JSON string representation
    assert!(json_result.is_ok());
}
```

## Notes

This vulnerability breaks the **Resource Limits** invariant (#9) which states: "All operations must respect gas, storage, and computational limits." The indexer lacks resource limits on JSON conversion operations, allowing unbounded memory allocation.

The issue is exacerbated by the fact that `previous_block_votes_bitvec` is automatically processed for every BlockMetadataTransaction without any size checks or rate limiting at the indexer layer.

### Citations

**File:** crates/indexer/src/models/block_metadata_transactions.rs (L66-67)
```rust
            previous_block_votes_bitvec: serde_json::to_value(&txn.previous_block_votes_bitvec)
                .unwrap(),
```

**File:** types/src/block_metadata.rs (L19-29)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct BlockMetadata {
    id: HashValue,
    epoch: u64,
    round: u64,
    proposer: AccountAddress,
    #[serde(with = "serde_bytes")]
    previous_block_votes_bitvec: Vec<u8>,
    failed_proposer_indices: Vec<u32>,
    timestamp_usecs: u64,
}
```

**File:** crates/aptos-bitvec/src/lib.rs (L18-20)
```rust
// Every u8 is used as a bucket of 8 bits. Total max buckets = 65536 / 8 = 8192.
const BUCKET_SIZE: usize = 8;
const MAX_BUCKETS: usize = 8192;
```

**File:** consensus/src/round_manager.rs (L1187-1193)
```rust
        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );
```
