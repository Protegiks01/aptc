# Audit Report

## Title
Validator Network Address Mismatch Vulnerability Causing Complete Connectivity Loss

## Summary
The `UpdateValidatorNetworkAddresses::execute()` function allows mixing `validator_host` and `validator_network_public_key` from different input sources (command line vs config file), creating mismatched host-key pairs that cause permanent validator connectivity loss through NoiseIK handshake failures.

## Finding Description

The vulnerability exists in how validator network addresses are constructed during updates. [1](#0-0) 

The `get_network_configs()` method independently resolves `validator_network_public_key` and `validator_host` with fallback logic that prioritizes command-line arguments over config file values. [2](#0-1) [3](#0-2) 

**Attack Scenario:**
1. Operator has config file with `validator_host=192.168.1.1:6180` and `validator_network_public_key=KeyA`
2. The actual validator node at that host possesses the private key for KeyA
3. Operator updates the network key via: `aptos node update-validator-network-addresses --validator-network-public-key KeyB --operator-config-file config.yaml`
4. Since `--validator-host` is not provided, the code uses the host from the config file
5. Result: NetworkAddress becomes `192.168.1.1:6180` with `KeyB` embedded

The mismatched NetworkAddress is stored on-chain through `stake_update_network_and_fullnode_addresses`. [4](#0-3) [5](#0-4) 

The `as_network_address()` method embeds the public key into the NetworkAddress as a NoiseIK protocol component. [6](#0-5) 

The on-chain ValidatorConfig stores these network addresses as BCS-serialized byte vectors. [7](#0-6) 

**Why This Causes Complete Connectivity Loss:**

When other validators attempt to connect, they initiate a NoiseIK handshake with the expected public key (KeyB) from the NetworkAddress. [8](#0-7) 

The prologue sent by the client includes the expected remote public key. [9](#0-8) 

On the server side, the actual validator node at 192.168.1.1:6180 receives the handshake and validates that the expected public key matches its actual public key. [10](#0-9) 

Since the client expects KeyB but the server has KeyA, the validation fails with `ClientExpectingDifferentPubkey` error, aborting the connection. The validator becomes completely unreachable, unable to participate in consensus.

## Impact Explanation

**Severity: HIGH** (up to $50,000 per Aptos Bug Bounty)

This vulnerability causes **significant protocol violations** and **validator node unavailability**:

1. **Consensus Disruption**: An unreachable validator cannot participate in AptosBFT consensus, reducing voting power and potentially affecting liveness if multiple validators are affected
2. **Network Partition**: The affected validator is permanently isolated until the next epoch when corrected addresses take effect
3. **Stake at Risk**: The validator accumulates failed proposals, affecting performance metrics and rewards
4. **No Recovery Within Epoch**: The misconfiguration persists until epoch boundary, with no way to immediately recover connectivity

The impact meets HIGH severity criteria as it causes validator node unavailability and significant protocol violations affecting consensus participation.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This vulnerability is **highly likely to occur** in practice:

1. **Common Operator Workflow**: When rotating network keys, operators naturally provide only `--validator-network-public-key` assuming the host remains unchanged
2. **No Validation**: The CLI accepts mismatched pairs without warning
3. **Silent Failure**: The transaction succeeds on-chain; connectivity failure only manifests at epoch boundary
4. **Accidental Triggering**: Legitimate operators can trigger this through simple command-line mistakes
5. **Malicious Use**: An attacker with compromised operator credentials can intentionally brick validators

The vulnerability requires operator-level access but is trivially exploitable with a single CLI command and represents a realistic operational error pattern.

## Recommendation

Implement atomic validation ensuring `validator_host` and `validator_network_public_key` originate from the same source. Modify `get_network_configs()` to enforce source consistency:

```rust
fn get_network_configs<'a>(
    &'a self,
    operator_config: &'a Option<OperatorConfiguration>,
) -> CliTypedResult<(...)> {
    // Check if mixing sources
    let using_cli_key = self.validator_network_public_key.is_some();
    let using_cli_host = self.validator_host.is_some();
    let using_config = operator_config.is_some();
    
    // Enforce: both from CLI, both from config, or neither
    if using_cli_key != using_cli_host && using_config {
        return Err(CliError::CommandArgumentError(
            "validator_host and validator_network_public_key must be specified together. \
             Provide both via command line or both via config file, not mixed.".to_string()
        ));
    }
    
    // Continue with existing fallback logic...
}
```

Additionally, add a warning when the pair differs from the config file:
```rust
if let Some(config) = operator_config {
    if using_cli_key && config.validator_network_public_key != validator_network_public_key {
        eprintln!("WARNING: Using different validator_network_public_key than config file. \
                   Ensure validator_host also matches the new key.");
    }
}
```

The same validation should apply to `full_node_host` and `full_node_network_public_key` pairs.

## Proof of Concept

```rust
// Reproduction steps (conceptual, as actual PoC requires full node setup)

// 1. Setup: Create operator config with initial network addresses
let config = OperatorConfiguration {
    validator_host: HostAndPort::from_str("192.168.1.1:6180").unwrap(),
    validator_network_public_key: x25519::PrivateKey::generate(&mut rng).public_key(),
    // ... other fields
};

// 2. Simulate update with only new public key (triggering the vulnerability)
let update_args = ValidatorNetworkAddressesArgs {
    validator_network_public_key: Some(new_different_key), // NEW KEY
    validator_host: None, // NOT PROVIDED - will fallback to config
    full_node_network_public_key: None,
    full_node_host: None,
};

// 3. Call get_network_configs - this will create mismatched pair
let (key, _, host, _) = update_args.get_network_configs(&Some(config))?;

// 4. Construct NetworkAddress - embeds MISMATCHED key with old host
let network_address = host.as_network_address(key)?;

// 5. Result: NetworkAddress points to 192.168.1.1:6180 but expects new_different_key
// When other validators connect, NoiseIK handshake will fail because:
// - Client sends prologue with new_different_key as expected remote key
// - Server at 192.168.1.1:6180 has original key's private key
// - Server validates: expected_key != actual_key -> HANDSHAKE FAILS

// Expected error at connection time:
// NoiseHandshakeError::ClientExpectingDifferentPubkey(peer_id, expected_hex, actual_hex)
```

**Testing Command Sequence:**
```bash
# Setup with config file containing KeyA and HostA
aptos init --network testnet

# Update ONLY the network key (vulnerability trigger)
aptos node update-validator-network-addresses \
  --validator-network-public-key 0xNEW_KEY_B_HEX \
  --operator-config-file operator.yaml \
  --profile validator-operator

# Result: Transaction succeeds, but validator becomes unreachable at next epoch
# Other validators cannot connect due to NoiseIK handshake failures
```

## Notes

This vulnerability also affects the `InitializeValidator` command [11](#0-10) , which uses the same `get_network_configs()` method, allowing initial validator setup with mismatched pairs.

The fullnode address pairs have partial protection [12](#0-11)  requiring both or neither, but this check should be extended to validator addresses as well.

### Citations

**File:** crates/aptos/src/node/mod.rs (L218-228)
```rust
        let validator_network_public_key =
            if let Some(public_key) = self.validator_network_public_key {
                public_key
            } else if let Some(operator_config) = operator_config {
                operator_config.validator_network_public_key
            } else {
                return Err(CliError::CommandArgumentError(
                    "Must provide either --operator-config-file or --validator-network-public-key"
                        .to_string(),
                ));
            };
```

**File:** crates/aptos/src/node/mod.rs (L239-247)
```rust
        let validator_host = if let Some(ref host) = self.validator_host {
            host
        } else if let Some(operator_config) = operator_config {
            &operator_config.validator_host
        } else {
            return Err(CliError::CommandArgumentError(
                "Must provide either --operator-config-file or --validator-host".to_string(),
            ));
        };
```

**File:** crates/aptos/src/node/mod.rs (L619-628)
```rust
        let (
            validator_network_public_key,
            full_node_network_public_key,
            validator_host,
            full_node_host,
        ) = self
            .validator_network_addresses_args
            .get_network_configs(&operator_config)?;
        let validator_network_addresses =
            vec![validator_host.as_network_address(validator_network_public_key)?];
```

**File:** crates/aptos/src/node/mod.rs (L1117-1124)
```rust
        let (
            validator_network_public_key,
            full_node_network_public_key,
            validator_host,
            full_node_host,
        ) = self
            .validator_network_addresses_args
            .get_network_configs(&validator_config)?;
```

**File:** crates/aptos/src/node/mod.rs (L1125-1126)
```rust
        let validator_network_addresses =
            vec![validator_host.as_network_address(validator_network_public_key)?];
```

**File:** crates/aptos/src/node/mod.rs (L1127-1137)
```rust
        let full_node_network_addresses =
            match (full_node_host.as_ref(), full_node_network_public_key) {
                (Some(host), Some(public_key)) => vec![host.as_network_address(public_key)?],
                (None, None) => vec![],
                _ => {
                    return Err(CliError::CommandArgumentError(
                        "If specifying fullnode addresses, both host and public key are required."
                            .to_string(),
                    ))
                },
            };
```

**File:** crates/aptos/src/node/mod.rs (L1139-1145)
```rust
        self.txn_options
            .submit_transaction(aptos_stdlib::stake_update_network_and_fullnode_addresses(
                address,
                // BCS encode, so that we can hide the original type
                bcs::to_bytes(&validator_network_addresses)?,
                bcs::to_bytes(&full_node_network_addresses)?,
            ))
```

**File:** crates/aptos-genesis/src/config.rs (L293-314)
```rust
    pub fn as_network_address(&self, key: x25519::PublicKey) -> anyhow::Result<NetworkAddress> {
        let host = self.host.to_string();

        // Since DnsName supports IPs as well, let's properly fix what the type is
        let host_protocol = if let Ok(ip) = Ipv4Addr::from_str(&host) {
            Protocol::Ip4(ip)
        } else if let Ok(ip) = Ipv6Addr::from_str(&host) {
            Protocol::Ip6(ip)
        } else {
            Protocol::Dns(self.host.clone())
        };
        let port_protocol = Protocol::Tcp(self.port);
        let noise_protocol = Protocol::NoiseIK(key);
        let handshake_protocol = Protocol::Handshake(HANDSHAKE_VERSION);

        Ok(NetworkAddress::try_from(vec![
            host_protocol,
            port_protocol,
            noise_protocol,
            handshake_protocol,
        ])?)
    }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L955-995)
```text
    public entry fun update_network_and_fullnode_addresses(
        operator: &signer,
        pool_address: address,
        new_network_addresses: vector<u8>,
        new_fullnode_addresses: vector<u8>,
    ) acquires StakePool, ValidatorConfig {
        check_stake_permission(operator);
        assert_reconfig_not_in_progress();
        assert_stake_pool_exists(pool_address);
        let stake_pool = borrow_global_mut<StakePool>(pool_address);
        assert!(signer::address_of(operator) == stake_pool.operator_address, error::unauthenticated(ENOT_OPERATOR));
        assert!(exists<ValidatorConfig>(pool_address), error::not_found(EVALIDATOR_CONFIG));
        let validator_info = borrow_global_mut<ValidatorConfig>(pool_address);
        let old_network_addresses = validator_info.network_addresses;
        validator_info.network_addresses = new_network_addresses;
        let old_fullnode_addresses = validator_info.fullnode_addresses;
        validator_info.fullnode_addresses = new_fullnode_addresses;

        if (std::features::module_event_migration_enabled()) {
            event::emit(
                UpdateNetworkAndFullnodeAddresses {
                    pool_address,
                    old_network_addresses,
                    new_network_addresses,
                    old_fullnode_addresses,
                    new_fullnode_addresses,
                },
            );
        } else {
            event::emit_event(
                &mut stake_pool.update_network_and_fullnode_addresses_events,
                UpdateNetworkAndFullnodeAddressesEvent {
                    pool_address,
                    old_network_addresses,
                    new_network_addresses,
                    old_fullnode_addresses,
                    new_fullnode_addresses,
                },
            );
        };
    }
```

**File:** network/framework/src/noise/handshake.rs (L183-218)
```rust
    pub async fn upgrade_outbound<TSocket, F>(
        &self,
        mut socket: TSocket,
        remote_peer_id: PeerId,
        remote_public_key: x25519::PublicKey,
        time_provider: F,
    ) -> Result<(NoiseStream<TSocket>, PeerRole), NoiseHandshakeError>
    where
        TSocket: AsyncRead + AsyncWrite + Debug + Unpin,
        F: Fn() -> [u8; AntiReplayTimestamps::TIMESTAMP_SIZE],
    {
        // buffer to hold prologue + first noise handshake message
        let mut client_message = [0; Self::CLIENT_MESSAGE_SIZE];

        // craft prologue = self_peer_id | expected_public_key
        client_message[..PeerId::LENGTH].copy_from_slice(self.network_context.peer_id().as_ref());
        client_message[PeerId::LENGTH..Self::PROLOGUE_SIZE]
            .copy_from_slice(remote_public_key.as_slice());

        let (prologue_msg, client_noise_msg) = client_message.split_at_mut(Self::PROLOGUE_SIZE);

        // craft 8-byte payload as current timestamp (in milliseconds)
        let payload = time_provider();

        // craft first handshake message  (-> e, es, s, ss)
        let mut rng = rand::rngs::OsRng;
        let initiator_state = self
            .noise_config
            .initiate_connection(
                &mut rng,
                prologue_msg,
                remote_public_key,
                Some(&payload),
                client_noise_msg,
            )
            .map_err(NoiseHandshakeError::BuildClientHandshakeMessageFailed)?;
```

**File:** network/framework/src/noise/handshake.rs (L349-357)
```rust
        // verify that this is indeed our public key
        let actual_public_key = self.noise_config.public_key();
        if self_expected_public_key != actual_public_key.as_slice() {
            return Err(NoiseHandshakeError::ClientExpectingDifferentPubkey(
                remote_peer_short,
                hex::encode(self_expected_public_key),
                hex::encode(actual_public_key.as_slice()),
            ));
        }
```
