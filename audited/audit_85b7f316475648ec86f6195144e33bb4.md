# Audit Report

## Title
Race Condition in Resource Group Initialization Causes Non-Deterministic Parallel Execution Failures

## Summary
A race condition exists between `group_sizes` and `group_tags` initialization in `VersionedGroupData::set_raw_base_values()`, allowing concurrent write operations to trigger code invariant errors during parallel execution. This forces fallback to sequential execution, creating a performance DoS vector and non-deterministic execution behavior.

## Finding Description

The vulnerability occurs in the parallel execution path (BlockSTM) when resource groups are lazily initialized. The initialization process creates two separate data structures non-atomically: [1](#0-0) [2](#0-1) 

Between these two operations, there's a critical window where `group_sizes` exists but `group_tags` does not. The read path only checks `group_sizes` to determine initialization: [3](#0-2) [4](#0-3) 

However, the write path (specifically `write_v2()`) calls `data_write_impl()` which requires `group_tags` to exist: [5](#0-4) [6](#0-5) 

**Exploitation Path:**

1. Attacker submits block with transactions T1 and T2 accessing resource group G (never accessed before in block)
2. **Thread 1** (T1 initialization): Enters `set_raw_base_values(G)`, creates `group_sizes[G]` entry
3. **Thread 2** (T2 read): Calls `fetch_tagged_data_and_record_dependency(G, tag)`, sees `group_sizes[G]` exists, considers group initialized
4. **Thread 2** (T2 write): Later writes via `write_v2(G, ...)` → `data_write_impl()` → checks `group_tags[G]` → **None!**
5. Returns code invariant error, halting parallel execution [7](#0-6) 

This triggers fallback to sequential execution: [8](#0-7) 

## Impact Explanation

**High Severity** per Aptos bug bounty criteria: "Validator node slowdowns"

The vulnerability forces validators to fall back from parallel to sequential execution, causing significant performance degradation:

- Parallel execution throughput: ~N transactions concurrently (N = concurrency_level)
- Sequential execution throughput: 1 transaction at a time
- Performance degradation: ~N× slower block execution

The default configuration enables fallback, preventing consensus failures but allowing performance attacks: [9](#0-8) 

**Security Impacts:**
1. **Performance DoS**: Attackers force sequential execution across all validators
2. **Non-deterministic behavior**: Same block executes differently (parallel vs sequential) based on timing
3. **Resource waste**: Computational resources wasted on failed parallel execution
4. **Code invariant violation**: The system explicitly treats this as a bug that shouldn't occur

## Likelihood Explanation

**High Likelihood** for the following reasons:

1. **Low attacker complexity**: Simply submit transactions accessing new resource groups
2. **No special privileges required**: Any transaction sender can trigger this
3. **Reproducible with sufficient attempts**: Race window is small but non-zero; attackers can submit multiple blocks to increase hit probability
4. **Natural occurrence**: Can happen without malicious intent when legitimate transactions access new groups concurrently
5. **Parallel execution is common**: Most validators run with concurrency_level > 1

The race window exists between DashMap operations on separate data structures (`group_sizes` and `group_tags`), with no cross-map synchronization.

## Recommendation

**Fix: Atomic initialization of both `group_sizes` and `group_tags`**

Restructure initialization to create both data structures atomically before releasing any locks:

```rust
pub fn set_raw_base_values(
    &self,
    group_key: K,
    base_values: Vec<(T, V)>,
) -> anyhow::Result<()> {
    // First, prepare group_tags entries while computing size
    let mut tags_to_insert = HashSet::new();
    let group_size = group_size_as_sum::<T>(
        base_values
            .iter()
            .inspect(|(tag, _)| { tags_to_insert.insert(tag.clone()); })
            .flat_map(|(tag, value)| value.bytes().map(|b| (tag.clone(), b.len()))),
    )?;
    
    // Atomically initialize group_tags FIRST
    let mut superset_tags = self.group_tags.entry(group_key.clone()).or_default();
    superset_tags.extend(tags_to_insert);
    
    // Then initialize group_sizes
    let mut group_sizes = self.group_sizes.entry(group_key.clone()).or_default();
    if let Vacant(entry) = group_sizes.size_entries.entry(ShiftedTxnIndex::zero_idx()) {
        entry.insert(SizeEntry::new(SizeAndDependencies::from_size(group_size)));
        
        for (tag, value) in base_values.into_iter() {
            self.values.set_base_value(
                (group_key.clone(), tag),
                ValueWithLayout::RawFromStorage(Arc::new(value)),
            );
        }
    }
    
    Ok(())
}
```

**Alternative: Check both maps in write path**

Modify `data_write_impl()` to check both `group_sizes` and `group_tags` consistently:

```rust
// Check both maps for initialization
if !self.group_sizes.contains_key(group_key) {
    return Err(code_invariant_error("Group (sizes) must be initialized to write to"));
}
let superset_tags = self.group_tags.get(group_key).ok_or_else(|| {
    code_invariant_error("Group (tags) must be initialized to write to")
})?;
```

## Proof of Concept

**Conceptual PoC** (actual implementation requires BlockSTM test framework):

```rust
// Rust test demonstrating the race condition
#[test]
fn test_group_initialization_race() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let group_data = Arc::new(VersionedGroupData::empty());
    let group_key = KeyType(b"/group/race_test".to_vec());
    let barrier = Arc::new(Barrier::new(2));
    
    // Thread 1: Initialize group
    let gd1 = group_data.clone();
    let gk1 = group_key.clone();
    let b1 = barrier.clone();
    let t1 = thread::spawn(move || {
        b1.wait(); // Sync start
        gd1.set_raw_base_values(gk1, vec![(1, TestValue::creation_with_len(10))])
    });
    
    // Thread 2: Write to group (after seeing group_sizes exists)
    let gd2 = group_data.clone();
    let gk2 = group_key.clone();
    let b2 = barrier.clone();
    let t2 = thread::spawn(move || {
        b2.wait(); // Sync start
        // Small delay to hit race window
        std::thread::sleep(std::time::Duration::from_micros(1));
        gd2.write_v2(
            gk2,
            1, // txn_idx
            0, // incarnation
            vec![(2, (TestValue::creation_with_len(20), None))],
            ResourceGroupSize::zero(),
            HashSet::new()
        )
    });
    
    let r1 = t1.join().unwrap();
    let r2 = t2.join().unwrap();
    
    // Race condition: T2 may hit code_invariant_error
    // if it executes between T1's group_sizes and group_tags creation
    assert!(r1.is_ok());
    // r2 may be Err(PanicError::CodeInvariantError)
}
```

**Notes**

This vulnerability represents a **code quality and performance security issue** rather than a direct consensus safety violation. The fallback mechanism prevents consensus failures in the default configuration, but the issue still qualifies as High severity under "Validator node slowdowns" criteria due to forced sequential execution across the network.

The developers explicitly marked this as a code invariant error, indicating it violates expected system guarantees. The TODO comment suggests planned refactoring: [10](#0-9) 

Until fixed, validators remain vulnerable to performance degradation attacks, and the non-deterministic execution path creates operational complexity and potential for future issues if fallback behavior changes.

### Citations

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L155-155)
```rust
        let mut group_sizes = self.group_sizes.entry(group_key.clone()).or_default();
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L175-175)
```rust
            let mut superset_tags = self.group_tags.entry(group_key.clone()).or_default();
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L271-271)
```rust
            self.data_write_impl::<true>(&group_key, txn_idx, incarnation, values, prev_tags)?;
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L282-283)
```rust
            // TODO(BlockSTMv2): when we refactor MVHashMap and group initialization logic,
            // also revisit and address the read-before-write assumption.
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L429-429)
```rust
        let initialized = self.group_sizes.contains_key(group_key);
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L452-452)
```rust
        let initialized = self.group_sizes.contains_key(group_key);
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L630-633)
```rust
            let superset_tags = self.group_tags.get(group_key).ok_or_else(|| {
                // Due to read-before-write.
                code_invariant_error("Group (tags) must be initialized to write to")
            })?;
```

**File:** aptos-move/block-executor/src/executor.rs (L1789-1799)
```rust
                        if let PanicOr::CodeInvariantError(err_msg) = err {
                            alert!(
                                "[BlockSTMv2] worker loop: CodeInvariantError({:?})",
                                err_msg
                            );
                        }
                        shared_maybe_error.store(true, Ordering::SeqCst);

                        // Make sure to halt the scheduler if it hasn't already been halted.
                        scheduler.halt();
                    }
```

**File:** aptos-move/block-executor/src/executor.rs (L2576-2596)
```rust
            // If parallel gave us result, return it
            if let Ok(output) = parallel_result {
                return Ok(output);
            }

            if !self.config.local.allow_fallback {
                panic!("Parallel execution failed and fallback is not allowed");
            }

            // All logs from the parallel execution should be cleared and not reported.
            // Clear by re-initializing the speculative logs.
            init_speculative_logs(signature_verified_block.num_txns() + 1);

            // Flush all caches to re-run from the "clean" state.
            module_cache_manager_guard
                .environment()
                .runtime_environment()
                .flush_all_caches();
            module_cache_manager_guard.module_cache_mut().flush();

            info!("parallel execution requiring fallback");
```

**File:** types/src/block_executor/config.rs (L75-76)
```rust
            allow_fallback: true,
            discard_failed_blocks: false,
```
