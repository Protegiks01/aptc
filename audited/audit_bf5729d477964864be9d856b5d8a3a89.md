# Audit Report

## Title
Memory Exhaustion via Malformed Compressed Response Decompression Size Claims

## Summary
A malicious storage service peer can exploit the LZ4 decompression logic in Aptos state sync to cause excessive memory allocations on receiving nodes by sending compressed responses with inflated decompressed size claims. This enables a resource exhaustion attack with minimal bandwidth cost (100 bytes network traffic forces 62 MiB memory allocation), affecting validator and fullnode synchronization capabilities.

## Finding Description

The vulnerability exists in the `decompress()` function in the Aptos compression library, which is used by the storage service response handling mechanism. The decompression logic allocates memory based on an attacker-controlled size field in the LZ4 header **before** validating that the compressed data actually decompresses to that size. [1](#0-0) 

The `get_decompressed_size()` function reads the claimed decompressed size from the first 4 bytes of the compressed data and only validates that it doesn't exceed `max_size` (MAX_APPLICATION_MESSAGE_SIZE ≈ 62 MiB). It does not validate that the claimed size is reasonable relative to the actual compressed payload size. [2](#0-1) 

The MAX_APPLICATION_MESSAGE_SIZE is calculated as approximately 62 MiB: [3](#0-2) 

When `StorageServiceResponse::get_data_response()` processes a compressed response, it calls this decompression logic: [4](#0-3) 

The attack flow:
1. Malicious peer sends compressed response with 100 bytes of data
2. First 4 bytes claim decompressed size is 62 MiB
3. `decompress()` allocates 62 MiB buffer at line 108 (before validation)
4. Decompression attempt fails at line 111, but memory was already allocated
5. Error triggers peer scoring penalty, but memory allocation already occurred

With the default `MAX_CONCURRENT_REQUESTS` of 6 for fullnodes (or 12 for validators/VFNs), a single malicious peer can force concurrent allocations of 372 MiB (fullnodes) or 744 MiB (validators): [5](#0-4) [6](#0-5) 

Decompression failures are classified as `ErrorType::NotUseful` (not `Malicious`), applying a 0.95 multiplier to peer scores rather than 0.8: [7](#0-6) [8](#0-7) [9](#0-8) 

With a starting score of 50.0 and ignore threshold of 25.0, approximately 14 failures are needed before the peer is ignored (50.0 × 0.95^14 ≈ 24.3), allowing ~84 total 62 MiB allocations (~5.2 GB for fullnodes, ~10.4 GB for validators) before mitigation.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty category "Validator Node Slowdowns" because:

1. **Amplification Factor**: 620,000x amplification (100 bytes network → 62 MiB memory allocation)
2. **Validator Impact**: Validators use 12 concurrent requests (744 MiB per malicious peer) making them more vulnerable than fullnodes
3. **Resource Exhaustion**: Repeated large memory allocations cause memory pressure, fragmentation, and can trigger OOM conditions on memory-constrained nodes
4. **State Sync Disruption**: Prevents new validators from bootstrapping and recovering validators from rejoining, reducing effective validator set capacity and affecting network consensus participation
5. **Delayed Mitigation**: ~14 failures (84-168 allocations depending on node type) before peer is ignored
6. **Multiple Attackers**: Multiple colluding Sybil peers can amplify the attack beyond single-peer limits

While this does not directly compromise consensus safety or enable fund theft, it significantly degrades node availability and can prevent validators from participating in consensus after downtime, which does affect network security and liveness.

## Likelihood Explanation

This vulnerability is **highly likely** to be exploited because:

1. **Trivial Execution**: Attacker only needs to modify 4 bytes in the LZ4 compression header
2. **No Privileged Access**: Any network peer can act as a storage service provider in the p2p network
3. **Low Detection Risk**: Initially appears as normal decompression failures
4. **Minimal Cost**: Attacker sends ~100 bytes to force 62 MiB allocation  
5. **Automated Attack**: Can be easily scripted and combined with Sybil attacks

The attack requires only basic understanding of the LZ4 compression format and can be executed by any network participant without special privileges or stake requirements.

## Recommendation

Add validation to ensure the claimed decompressed size is reasonable relative to the compressed data size before allocating memory:

```rust
fn get_decompressed_size(
    compressed_data: &CompressedData,
    max_size: usize,
) -> Result<usize, Error> {
    // Existing validation
    if compressed_data.len() < 4 {
        return Err(DecompressionError(...));
    }
    
    let size = parse_size_from_header(compressed_data);
    if size < 0 || size > max_size {
        return Err(DecompressionError(...));
    }
    
    // NEW: Validate claimed size is reasonable vs compressed size
    // LZ4 compression ratio rarely exceeds 10:1 for legitimate data
    let compressed_size = compressed_data.len() - 4; // Exclude header
    let max_reasonable_size = compressed_size.saturating_mul(10);
    if size > max_reasonable_size {
        return Err(DecompressionError(format!(
            "Claimed decompressed size {} exceeds reasonable ratio vs compressed size {}",
            size, compressed_size
        )));
    }
    
    Ok(size as usize)
}
```

Alternatively, use streaming decompression that doesn't require upfront allocation, or classify repeated decompression failures from a peer as `Malicious` rather than `NotUseful` for faster peer banning.

## Proof of Concept

```rust
use aptos_compression::decompress;
use aptos_compression::client::CompressionClient;
use aptos_config::config::MAX_APPLICATION_MESSAGE_SIZE;

#[test]
fn test_memory_exhaustion_via_malformed_size() {
    // Create a tiny compressed payload (100 bytes)
    let mut malformed_compressed = vec![0u8; 100];
    
    // Set first 4 bytes to claim 62 MiB decompressed size (little-endian i32)
    let claimed_size = MAX_APPLICATION_MESSAGE_SIZE as i32;
    malformed_compressed[0] = (claimed_size & 0xFF) as u8;
    malformed_compressed[1] = ((claimed_size >> 8) & 0xFF) as u8;
    malformed_compressed[2] = ((claimed_size >> 16) & 0xFF) as u8;
    malformed_compressed[3] = ((claimed_size >> 24) & 0xFF) as u8;
    
    // Attempt decompression - this will allocate 62 MiB before failing
    let result = decompress(
        &malformed_compressed,
        CompressionClient::StateSync,
        MAX_APPLICATION_MESSAGE_SIZE,
    );
    
    // Decompression fails, but memory was already allocated
    assert!(result.is_err());
    
    // An attacker can repeat this with multiple concurrent requests
    // to force 372 MiB (fullnodes) or 744 MiB (validators) of allocations
}
```

**Notes**

This vulnerability exploits a specific protocol implementation flaw in the LZ4 decompression logic used by the storage service. It is distinct from generic network DoS attacks because it leverages a memory allocation vulnerability that trusts attacker-controlled size fields without validation. The impact on state synchronization directly affects validator operations when recovering from downtime, making this a legitimate "Validator Node Slowdowns" issue under the High severity category.

### Citations

**File:** crates/aptos-compression/src/lib.rs (L92-121)
```rust
pub fn decompress(
    compressed_data: &CompressedData,
    client: CompressionClient,
    max_size: usize,
) -> Result<Vec<u8>, Error> {
    // Start the decompression timer
    let start_time = Instant::now();

    // Check size of the data and initialize raw_data
    let decompressed_size = match get_decompressed_size(compressed_data, max_size) {
        Ok(size) => size,
        Err(error) => {
            let error_string = format!("Failed to get decompressed size: {}", error);
            return create_decompression_error(&client, error_string);
        },
    };
    let mut raw_data = vec![0u8; decompressed_size];

    // Decompress the data
    if let Err(error) = lz4::block::decompress_to_buffer(compressed_data, None, &mut raw_data) {
        let error_string = format!("Failed to decompress the data: {}", error);
        return create_decompression_error(&client, error_string);
    };

    // Stop the timer and update the metrics
    metrics::observe_decompression_operation_time(&client, start_time);
    metrics::update_decompression_metrics(&client, compressed_data, &raw_data);

    Ok(raw_data)
}
```

**File:** crates/aptos-compression/src/lib.rs (L150-183)
```rust
fn get_decompressed_size(
    compressed_data: &CompressedData,
    max_size: usize,
) -> Result<usize, Error> {
    // Ensure that the compressed data is at least 4 bytes long
    if compressed_data.len() < 4 {
        return Err(DecompressionError(format!(
            "Compressed data must be at least 4 bytes long! Got: {}",
            compressed_data.len()
        )));
    }

    // Parse the size prefix
    let size = (compressed_data[0] as i32)
        | ((compressed_data[1] as i32) << 8)
        | ((compressed_data[2] as i32) << 16)
        | ((compressed_data[3] as i32) << 24);
    if size < 0 {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer must not be negative! Got: {}",
            size
        )));
    }

    // Ensure that the size is not greater than the max size limit
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
    }

    Ok(size)
```

**File:** config/src/config/network_config.rs (L47-50)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** state-sync/storage-service/types/src/responses.rs (L97-111)
```rust
    pub fn get_data_response(&self) -> Result<DataResponse, Error> {
        match self {
            StorageServiceResponse::CompressedResponse(_, compressed_data) => {
                let raw_data = aptos_compression::decompress(
                    compressed_data,
                    CompressionClient::StateSync,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )?;
                let data_response = bcs::from_bytes::<DataResponse>(&raw_data)
                    .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
                Ok(data_response)
            },
            StorageServiceResponse::RawResponse(data_response) => Ok(data_response.clone()),
        }
    }
```

**File:** config/src/config/state_sync_config.rs (L29-31)
```rust
// The maximum number of concurrent requests to send
const MAX_CONCURRENT_REQUESTS: u64 = 6;
const MAX_CONCURRENT_STATE_REQUESTS: u64 = 6;
```

**File:** config/src/config/state_sync_config.rs (L589-596)
```rust
        // Double the aggression of the pre-fetcher for validators and VFNs
        let mut modified_config = false;
        if node_type.is_validator() || node_type.is_validator_fullnode() {
            // Double transaction prefetching
            if local_stream_config_yaml["max_concurrent_requests"].is_null() {
                data_streaming_service_config.max_concurrent_requests = MAX_CONCURRENT_REQUESTS * 2;
                modified_config = true;
            }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L54-62)
```rust
impl From<ResponseError> for ErrorType {
    fn from(error: ResponseError) -> Self {
        match error {
            ResponseError::InvalidData | ResponseError::InvalidPayloadDataType => {
                ErrorType::NotUseful
            },
            ResponseError::ProofVerificationError => ErrorType::Malicious,
        }
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L168-174)
```rust
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```
