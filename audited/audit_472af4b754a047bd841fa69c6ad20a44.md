# Audit Report

## Title
VaultStorage Token Renewal Race Condition Enables Consensus Node Crash via Authentication Failure

## Summary
The `VaultStorage::client()` method implements automatic token renewal using non-atomic operations with `Ordering::Relaxed` semantics, creating a race condition where concurrent access can cause authentication token expiration during critical consensus operations. When token expiration occurs, the consensus safety rules panic the entire validator node, causing consensus liveness failures.

## Finding Description

The vulnerability exists in the token renewal mechanism of `VaultStorage` which is used by consensus `SafetyRules` for persistent storage of critical data including consensus private keys and safety state. [1](#0-0) 

The `client()` method performs a check-then-act pattern that is not atomic:

1. **Non-atomic check**: Loads `next_renewal` with `Ordering::Relaxed` 
2. **Race window**: Multiple threads can simultaneously determine renewal is needed
3. **Concurrent renewals**: Multiple threads call `renew_token_self()` concurrently
4. **State inconsistency**: Updates to `next_renewal` are not synchronized

When token expiration occurs, Vault returns HTTP 403 which is converted to `PermissionDenied`: [2](#0-1) 

This error propagates to consensus safety rules where it triggers an intentional panic: [3](#0-2) 

**Attack Path:**

VaultStorage is used during critical consensus operations:
- Reading consensus private keys during epoch initialization [4](#0-3) 

- Reading/writing SafetyData during voting operations [5](#0-4) 

These operations take `&self` and call `client()` which has the race condition: [6](#0-5) 

**Failure Modes:**

1. **Multiple concurrent renewals**: Threads race to renew, wasting resources and potentially causing Vault rate limiting
2. **Renewal failure â†’ eventual expiration**: If renewal fails but is not retried (error is only logged), token expires and subsequent operations panic the node
3. **Memory ordering issues**: `Ordering::Relaxed` provides no synchronization guarantees, allowing cores to see stale `next_renewal` values

## Impact Explanation

**High Severity** - This vulnerability causes validator node crashes:

- **Consensus Liveness Impact**: When a validator's SafetyRules panics due to token expiration, that validator cannot participate in consensus (cannot vote, sign proposals, or sign timeouts)
- **Multi-validator Impact**: If multiple validators hit this issue simultaneously (e.g., if all configured tokens expire around the same time), consensus liveness could be severely degraded
- **No Graceful Recovery**: The panic is intentional fail-fast behavior with no recovery path except operator intervention to renew tokens and restart the process

This maps to **High Severity** per the Aptos bug bounty program: "Validator node slowdowns, API crashes, Significant protocol violations"

## Likelihood Explanation

**Medium-High Likelihood** in production environments:

1. **Natural occurrence**: Network latency, Vault server load, or temporary connectivity issues can cause renewal delays or failures
2. **Configuration-dependent**: Only affects deployments using VaultStorage with token renewal enabled (`renew_ttl_secs` configured)
3. **Time-based trigger**: Token expiration is time-dependent and will eventually occur if renewals consistently fail
4. **No attacker required**: This is primarily a reliability issue that manifests under normal operational conditions

The race condition itself occurs whenever VaultStorage operations happen close to renewal time, though the safety margin (TTL/2) reduces the window significantly.

## Recommendation

Replace the non-atomic renewal check with an atomic compare-exchange operation: [1](#0-0) 

**Recommended Fix:**

```rust
fn client(&self) -> &Client {
    if let Some(ttl_secs) = self.renew_ttl_secs {
        let now = self.time_service.now_secs();
        let current_next_renewal = self.next_renewal.load(Ordering::Acquire);
        
        if now >= current_next_renewal {
            // Use compare_exchange to ensure only one thread performs renewal
            // Set to far future to act as a lock
            match self.next_renewal.compare_exchange(
                current_next_renewal,
                u64::MAX,
                Ordering::AcqRel,
                Ordering::Acquire
            ) {
                Ok(_) => {
                    // We won the race - perform the renewal
                    let result = self.client.renew_token_self(Some(ttl_secs));
                    let new_next_renewal = match result {
                        Ok(ttl) => now + (ttl as u64) / 2,
                        Err(e) => {
                            aptos_logger::error!("Unable to renew lease: {}. Will retry in 60s", e);
                            now + 60  // Retry renewal in 60 seconds
                        }
                    };
                    self.next_renewal.store(new_next_renewal, Ordering::Release);
                },
                Err(_) => {
                    // Another thread is handling renewal, wait briefly and recheck
                    std::thread::sleep(std::time::Duration::from_millis(100));
                }
            }
        }
    }
    &self.client
}
```

Additional improvements:
1. Use stronger memory ordering (`Acquire`/`Release`) for proper synchronization
2. Implement retry logic when renewal fails instead of just logging
3. Consider adding metrics for renewal failures
4. Add exponential backoff for retry attempts

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    #[test]
    fn test_concurrent_renewal_race() {
        // Setup VaultStorage with short TTL
        let vault = Arc::new(VaultStorage::new(
            "http://localhost:8200".to_string(),
            "test-token".to_string(),
            None,
            Some(10), // 10 second TTL
            false,
            None,
            None,
        ));
        
        // Set next_renewal to past time to trigger renewal
        vault.next_renewal.store(0, Ordering::Relaxed);
        
        let barrier = Arc::new(Barrier::new(10));
        let mut handles = vec![];
        
        // Spawn 10 threads that all try to access client() simultaneously
        for _ in 0..10 {
            let vault_clone = Arc::clone(&vault);
            let barrier_clone = Arc::clone(&barrier);
            
            let handle = thread::spawn(move || {
                barrier_clone.wait(); // Synchronize start
                
                // All threads call client() at the same time
                let _ = vault_clone.client();
            });
            
            handles.push(handle);
        }
        
        for handle in handles {
            handle.join().unwrap();
        }
        
        // If vulnerable, multiple renewal requests would have been sent
        // In production, this could exhaust rate limits or cause inconsistencies
    }
}
```

**Notes:**
- The PoC demonstrates concurrent access to the renewal mechanism
- In production, this would manifest as multiple renewal requests to Vault when validators perform operations near renewal time
- The actual token expiration scenario requires a full Vault setup with real token TTLs and network conditions that cause renewal delays

### Citations

**File:** secure/storage/src/vault.rs (L68-84)
```rust
    // Made into an accessor so we can get auto-renewal
    fn client(&self) -> &Client {
        if self.renew_ttl_secs.is_some() {
            let now = self.time_service.now_secs();
            let next_renewal = self.next_renewal.load(Ordering::Relaxed);
            if now >= next_renewal {
                let result = self.client.renew_token_self(self.renew_ttl_secs);
                if let Ok(ttl) = result {
                    let next_renewal = now + (ttl as u64) / 2;
                    self.next_renewal.store(next_renewal, Ordering::Relaxed);
                } else if let Err(e) = result {
                    aptos_logger::error!("Unable to renew lease: {}", e.to_string());
                }
            }
        }
        &self.client
    }
```

**File:** secure/storage/src/vault.rs (L155-165)
```rust
    fn get<T: DeserializeOwned>(&self, key: &str) -> Result<GetResponse<T>, Error> {
        let secret = key;
        let key = self.unnamespaced(key);
        let resp = self.client().read_secret(secret, key)?;
        let last_update = DateTime::parse_from_rfc3339(&resp.creation_time)?.timestamp() as u64;
        let value: T = serde_json::from_value(resp.value)?;
        self.secret_versions
            .write()
            .insert(key.to_string(), resp.version);
        Ok(GetResponse { last_update, value })
    }
```

**File:** secure/storage/src/error.rs (L56-64)
```rust
impl From<aptos_vault_client::Error> for Error {
    fn from(error: aptos_vault_client::Error) -> Self {
        match error {
            aptos_vault_client::Error::NotFound(_, key) => Self::KeyNotSet(key),
            aptos_vault_client::Error::HttpError(403, _, _) => Self::PermissionDenied,
            _ => Self::InternalError(format!("{}", error)),
        }
    }
}
```

**File:** consensus/safety-rules/src/error.rs (L78-99)
```rust
impl From<aptos_secure_storage::Error> for Error {
    fn from(error: aptos_secure_storage::Error) -> Self {
        match error {
            aptos_secure_storage::Error::PermissionDenied => {
                // If a storage error is thrown that indicates a permission failure, we
                // want to panic immediately to alert an operator that something has gone
                // wrong. For example, this error is thrown when a storage (e.g., vault)
                // token has expired, so it makes sense to fail fast and require a token
                // renewal!
                panic!(
                    "A permission error was thrown: {:?}. Maybe the storage token needs to be renewed?",
                    error
                );
            },
            aptos_secure_storage::Error::KeyVersionNotFound(_, _)
            | aptos_secure_storage::Error::KeyNotSet(_) => {
                Self::SecureStorageMissingDataError(error.to_string())
            },
            _ => Self::SecureStorageUnexpectedError(error.to_string()),
        }
    }
}
```

**File:** consensus/safety-rules/src/safety_rules.rs (L324-337)
```rust
                } else {
                    // Try to export the consensus key directly from storage.
                    match self.persistent_storage.consensus_sk_by_pk(expected_key) {
                        Ok(consensus_key) => {
                            self.validator_signer =
                                Some(ValidatorSigner::new(author, Arc::new(consensus_key)));
                            Ok(())
                        },
                        Err(Error::SecureStorageMissingDataError(error)) => {
                            Err(Error::ValidatorKeyNotFound(error))
                        },
                        Err(error) => Err(error),
                    }
                }
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L134-148)
```rust
    pub fn safety_data(&mut self) -> Result<SafetyData, Error> {
        if !self.enable_cached_safety_data {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            return self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
        }

        if let Some(cached_safety_data) = self.cached_safety_data.clone() {
            Ok(cached_safety_data)
        } else {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            let safety_data: SafetyData = self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
            self.cached_safety_data = Some(safety_data.clone());
            Ok(safety_data)
        }
    }
```
