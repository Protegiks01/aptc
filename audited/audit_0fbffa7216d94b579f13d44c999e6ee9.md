# Audit Report

## Title
Redis Cache Corruption via Concurrent Cache Worker Instances with No Distributed Locking

## Summary
The indexer gRPC cache worker lacks any distributed locking or instance coordination mechanism. When multiple cache worker instances are accidentally started with the same configuration, they concurrently write to the same Redis keys with last-write-wins semantics, creating a race condition that can corrupt the cache with inconsistent transaction data if the instances receive different data from their fullnode sources.

## Finding Description

The cache worker implementation has no safeguards against concurrent instance execution. The vulnerability manifests through the following code paths:

**1. No Instance Coordination** [1](#0-0) 

The worker's `run()` function starts immediately without any distributed lock check. Each instance independently connects to Redis and begins streaming transactions from the fullnode.

**2. Concurrent Redis Writes Without Protection** [2](#0-1) 

The `update_cache_transactions` method uses Redis pipelining for batch writes, but each SET operation has no coordination between instances. Multiple instances writing the same version keys will result in last-write-wins behavior with no conflict detection.

**3. Out-of-Order Chunk Processing** [3](#0-2) 

The code explicitly acknowledges that data chunks may arrive out of order, and async task spawning means writes complete in arbitrary order.

**4. Async Task Spawning Creates Race Windows** [4](#0-3) 

Each transaction chunk is processed in a separate spawned task that independently writes to Redis. When multiple instances run, their tasks interleave arbitrarily.

**5. Latest Version Update Has Overlap Detection But No Transaction Protection** [5](#0-4) 

The Lua script for updating `latest_version` detects overlaps and gaps, but this only protects the version pointer, not the individual transaction data writes that happen earlier.

**Attack Scenario:**

1. Operator accidentally starts two cache worker instances with identical configuration
2. Both instances query file store for starting version (e.g., 1000)
3. If `fullnode_grpc_address` points to a load balancer with multiple backend fullnodes experiencing brief sync lag, instances may receive slightly different transaction data
4. Instance A spawns Task-A1 to write versions [1000-1499]
5. Instance B spawns Task-B1 to write versions [1000-1499]  
6. Instance A spawns Task-A2 to write versions [1500-1999]
7. Instance B spawns Task-B2 to write versions [1500-1999]
8. Tasks complete in arbitrary order: Task-A1 → Task-B2 → Task-A2 → Task-B1
9. Redis cache now contains: versions [1000-1499] from Instance B (last write), versions [1500-1999] from Instance A
10. If the fullnodes served different data due to sync lag, the cache contains mixed, inconsistent transaction data
11. Clients reading from the cache receive corrupted transaction data, breaking data integrity

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria:

- **API Malfunctions**: The indexer data service reads from this corrupted cache and serves incorrect transaction data to API clients, breaking the integrity of the indexing infrastructure
- **State Inconsistencies**: The cached transaction data no longer matches the canonical blockchain state, causing indexers to process incorrect information
- **Operational Impact**: Requires manual intervention to clear cache and restart with proper safeguards

While this doesn't directly affect consensus or validator operations, it corrupts the indexing infrastructure that applications depend on for blockchain data access.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability requires:
1. **Operator error**: Accidentally starting multiple instances (e.g., Kubernetes deployment misconfiguration, manual error during maintenance)
2. **Infrastructure setup**: Fullnode URL being a load balancer to multiple backends (common in production deployments)
3. **Timing condition**: Backend fullnodes having brief sync lag or inconsistencies

While requiring multiple conditions, this scenario is realistic in production environments where:
- Orchestration systems may spawn duplicate pods during deployments
- High-availability setups use load-balanced fullnode endpoints
- Network partitions or sync delays can cause temporary fullnode inconsistencies

## Recommendation

Implement distributed locking using Redis SETNX to ensure only one cache worker instance runs at a time:

**Fix in `worker.rs`:**

```rust
const CACHE_WORKER_LOCK_KEY: &str = "cache_worker_instance_lock";
const LOCK_TTL_SECONDS: u64 = 30;
const LOCK_REFRESH_INTERVAL_SECONDS: u64 = 10;

impl Worker {
    pub async fn run(&mut self) -> Result<()> {
        loop {
            let mut conn = self.redis_client.get_tokio_connection_manager().await?;
            
            // Try to acquire distributed lock
            let lock_acquired: bool = redis::cmd("SET")
                .arg(CACHE_WORKER_LOCK_KEY)
                .arg(std::process::id().to_string())
                .arg("NX")
                .arg("EX")
                .arg(LOCK_TTL_SECONDS)
                .query_async(&mut conn)
                .await?;
            
            if !lock_acquired {
                bail!("Another cache worker instance is already running. Exiting to prevent cache corruption.");
            }
            
            // Spawn lock refresh task
            let lock_refresh_task = tokio::spawn(refresh_lock(
                self.redis_client.clone(),
                LOCK_REFRESH_INTERVAL_SECONDS
            ));
            
            // Existing worker logic...
            let result = self.run_worker_loop().await;
            
            // Cleanup lock on exit
            lock_refresh_task.abort();
            let _: () = redis::cmd("DEL")
                .arg(CACHE_WORKER_LOCK_KEY)
                .query_async(&mut conn)
                .await?;
            
            result?;
        }
    }
}

async fn refresh_lock(redis_client: redis::Client, interval_seconds: u64) -> Result<()> {
    let mut interval = tokio::time::interval(Duration::from_secs(interval_seconds));
    loop {
        interval.tick().await;
        let mut conn = redis_client.get_tokio_connection_manager().await?;
        let _: () = redis::cmd("EXPIRE")
            .arg(CACHE_WORKER_LOCK_KEY)
            .arg(LOCK_TTL_SECONDS)
            .query_async(&mut conn)
            .await?;
    }
}
```

## Proof of Concept

**Rust Test Scenario:**

```rust
#[tokio::test]
async fn test_concurrent_cache_workers_corruption() {
    // Setup: Redis instance and mock fullnode
    let redis_client = redis::Client::open("redis://127.0.0.1:6379").unwrap();
    let fullnode_url = Url::parse("http://localhost:50051").unwrap();
    
    // Create two worker instances with identical config
    let worker1 = Worker::new(
        fullnode_url.clone(),
        RedisUrl("redis://127.0.0.1:6379".to_string()),
        file_store_config.clone(),
        false,
    ).await.unwrap();
    
    let worker2 = Worker::new(
        fullnode_url.clone(),
        RedisUrl("redis://127.0.0.1:6379".to_string()),
        file_store_config.clone(),
        false,
    ).await.unwrap();
    
    // Simulate concurrent execution
    let handle1 = tokio::spawn(async move { worker1.run().await });
    let handle2 = tokio::spawn(async move { worker2.run().await });
    
    // Allow workers to process same batch concurrently
    tokio::time::sleep(Duration::from_secs(5)).await;
    
    // Verify: Check Redis for potential corruption
    let mut conn = redis_client.get_tokio_connection_manager().await.unwrap();
    let latest_version: u64 = conn.get("latest_version").await.unwrap();
    
    // Read transaction at version X from cache
    let txn_data_1: Vec<u8> = conn.get(format!("{}", latest_version - 100)).await.unwrap();
    
    // If workers wrote different data, subsequent reads may be inconsistent
    // Expected: Only one worker should be allowed to run (with locking fix)
    
    handle1.abort();
    handle2.abort();
}
```

## Notes

The vulnerability is confined to the indexer infrastructure and does not affect consensus, validator operations, or the core blockchain protocol. However, corrupted cache data compromises the integrity of dependent systems (indexers, APIs, analytics tools) that rely on accurate transaction data. The fix requires minimal changes and should be implemented before production deployments where multiple instances could inadvertently run concurrently.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L53-56)
```rust
pub(crate) enum GrpcDataStatus {
    /// Ok status with processed count.
    /// Each batch may contain multiple data chunks(like 1000 transactions).
    /// These data chunks may be out of order.
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L99-180)
```rust
    /// The main loop of the worker is:
    /// 1. Fetch metadata from file store; if not present, exit after 1 minute.
    /// 2. Start the streaming RPC with version from file store or 0 if not present.
    /// 3. Handle the INIT frame from TransactionsFromNodeResponse:
    ///    * If metadata is not present and cache is empty, start from 0.
    ///    * If metadata is not present and cache is not empty, crash.
    ///    * If metadata is present, start from file store version.
    /// 4. Process the streaming response.
    /// TODO: Use the ! return type when it is stable.
    /// TODO: Rewrite logic to actually conform to this description
    pub async fn run(&mut self) -> Result<()> {
        // Re-connect if lost.
        loop {
            let conn = self
                .redis_client
                .get_tokio_connection_manager()
                .await
                .context("Get redis connection failed.")?;
            let mut rpc_client = create_grpc_client(self.fullnode_grpc_address.clone()).await;

            // 1. Fetch metadata.
            let file_store_operator: Box<dyn FileStoreOperator> = self.file_store.create();
            // TODO: move chain id check somewhere around here
            // This ensures that metadata is created before we start the cache worker
            let mut starting_version = file_store_operator.get_latest_version().await;
            while starting_version.is_none() {
                starting_version = file_store_operator.get_latest_version().await;
                tracing::warn!(
                    "[Indexer Cache] File store metadata not found. Waiting for {} ms.",
                    FILE_STORE_METADATA_WAIT_MS
                );
                tokio::time::sleep(std::time::Duration::from_millis(
                    FILE_STORE_METADATA_WAIT_MS,
                ))
                .await;
            }

            // There's a guarantee at this point that starting_version is not null
            let starting_version = starting_version.unwrap();

            let file_store_metadata = file_store_operator.get_file_store_metadata().await.unwrap();

            tracing::info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Starting cache worker with version {}",
                starting_version
            );

            // 2. Start streaming RPC.
            let request = tonic::Request::new(GetTransactionsFromNodeRequest {
                starting_version: Some(starting_version),
                ..Default::default()
            });

            let response = rpc_client
                .get_transactions_from_node(request)
                .await
                .with_context(|| {
                    format!(
                        "Failed to get transactions from node at starting version {}",
                        starting_version
                    )
                })?;
            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC started."
            );
            // 3&4. Infinite streaming until error happens. Either stream ends or worker crashes.
            process_streaming_response(
                conn,
                self.cache_storage_format,
                file_store_metadata,
                response.into_inner(),
            )
            .await?;

            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC ended."
            );
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L213-275)
```rust
            let task: JoinHandle<anyhow::Result<()>> = tokio::spawn({
                let first_transaction = data
                    .transactions
                    .first()
                    .context("There were unexpectedly no transactions in the response")?;
                let first_transaction_version = first_transaction.version;
                let last_transaction = data
                    .transactions
                    .last()
                    .context("There were unexpectedly no transactions in the response")?;
                let last_transaction_version = last_transaction.version;
                let start_version = first_transaction.version;
                let first_transaction_pb_timestamp = first_transaction.timestamp;
                let last_transaction_pb_timestamp = last_transaction.timestamp;

                log_grpc_step(
                    SERVICE_TYPE,
                    IndexerGrpcStep::CacheWorkerReceivedTxns,
                    Some(start_version as i64),
                    Some(last_transaction_version as i64),
                    first_transaction_pb_timestamp.as_ref(),
                    last_transaction_pb_timestamp.as_ref(),
                    Some(data_download_duration_in_secs),
                    Some(size_in_bytes),
                    Some((last_transaction_version + 1 - first_transaction_version) as i64),
                    None,
                );

                let cache_update_start_time = std::time::Instant::now();

                async move {
                    // Push to cache.
                    match cache_operator_clone
                        .update_cache_transactions(data.transactions)
                        .await
                    {
                        Ok(_) => {
                            log_grpc_step(
                                SERVICE_TYPE,
                                IndexerGrpcStep::CacheWorkerTxnsProcessed,
                                Some(first_transaction_version as i64),
                                Some(last_transaction_version as i64),
                                first_transaction_pb_timestamp.as_ref(),
                                last_transaction_pb_timestamp.as_ref(),
                                Some(cache_update_start_time.elapsed().as_secs_f64()),
                                Some(size_in_bytes),
                                Some(
                                    (last_transaction_version + 1 - first_transaction_version)
                                        as i64,
                                ),
                                None,
                            );
                            Ok(())
                        },
                        Err(e) => {
                            ERROR_COUNT
                                .with_label_values(&["failed_to_update_cache_version"])
                                .inc();
                            bail!("Update cache with version failed: {}", e);
                        },
                    }
                }
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L39-57)
```rust
const CACHE_SCRIPT_UPDATE_LATEST_VERSION: &str = r#"
    local latest_version = redis.call("GET", KEYS[1])
    local num_of_versions = tonumber(ARGV[1])
    local current_version = tonumber(ARGV[2])
    if latest_version then
        if tonumber(latest_version) + num_of_versions < current_version then
            return 2
        elseif tonumber(latest_version) + num_of_versions == current_version then
            redis.call("SET", KEYS[1], current_version)
            return 0
        else
            redis.call("SET", KEYS[1], math.max(current_version, tonumber(latest_version)))
            return 1
        end
    else
        redis.call("SET", KEYS[1], ARGV[1])
        return 0
    end
"#;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L252-313)
```rust
    pub async fn update_cache_transactions(
        &mut self,
        transactions: Vec<Transaction>,
    ) -> anyhow::Result<()> {
        let start_version = transactions.first().unwrap().version;
        let end_version = transactions.last().unwrap().version;
        let num_transactions = transactions.len();
        let start_txn_timestamp = transactions.first().unwrap().timestamp;
        let end_txn_timestamp = transactions.last().unwrap().timestamp;
        let mut size_in_bytes = 0;
        let mut redis_pipeline = redis::pipe();
        let start_time = std::time::Instant::now();
        for transaction in transactions {
            let version = transaction.version;
            let cache_key = CacheEntry::build_key(version, self.storage_format).to_string();
            let timestamp_in_seconds = transaction.timestamp.map_or(0, |t| t.seconds as u64);
            let cache_entry: CacheEntry =
                CacheEntry::from_transaction(transaction, self.storage_format);
            let bytes = cache_entry.into_inner();
            size_in_bytes += bytes.len();
            redis_pipeline
                .cmd("SET")
                .arg(cache_key)
                .arg(bytes)
                .arg("EX")
                .arg(get_ttl_in_seconds(timestamp_in_seconds))
                .ignore();
            // Actively evict the expired cache. This is to avoid using Redis
            // eviction policy, which is probabilistic-based and may evict the
            // cache that is still needed.
            if version >= CACHE_SIZE_EVICTION_LOWER_BOUND {
                let key = CacheEntry::build_key(
                    version - CACHE_SIZE_EVICTION_LOWER_BOUND,
                    self.storage_format,
                )
                .to_string();
                redis_pipeline.cmd("DEL").arg(key).ignore();
            }
        }
        // Note: this method is and should be only used by `cache_worker`.
        let service_type = "cache_worker";
        log_grpc_step(
            service_type,
            IndexerGrpcStep::CacheWorkerTxnEncoded,
            Some(start_version as i64),
            Some(end_version as i64),
            start_txn_timestamp.as_ref(),
            end_txn_timestamp.as_ref(),
            Some(start_time.elapsed().as_secs_f64()),
            Some(size_in_bytes),
            Some(num_transactions as i64),
            None,
        );

        let redis_result: RedisResult<()> =
            redis_pipeline.query_async::<_, _>(&mut self.conn).await;

        match redis_result {
            Ok(_) => Ok(()),
            Err(err) => Err(err.into()),
        }
    }
```
