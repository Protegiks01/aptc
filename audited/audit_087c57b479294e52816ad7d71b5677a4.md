# Audit Report

## Title
Snapshot Selection Bypass via Unsigned LedgerInfo Acceptance in Replay Verification

## Summary
The replay verification coordinator accepts state snapshots from backup storage without validating the cryptographic signatures on LedgerInfo, allowing an attacker with backup storage write access to inject completely fabricated blockchain state that will be accepted as valid during replay verification.

## Finding Description

The vulnerability exists in the snapshot restoration flow during replay verification. The attack chain involves three critical security failures:

**Failure 1: Metadata Files Lack Cryptographic Protection**

Metadata files containing `StateSnapshotBackupMeta` are stored as unsigned JSON in backup storage with no integrity verification. [1](#0-0) 

An attacker with backup storage write access can inject arbitrary metadata entries pointing to malicious snapshots.

**Failure 2: Snapshot Selection from Untrusted Metadata**

The replay verify coordinator selects snapshots directly from this untrusted metadata without validation: [2](#0-1) 

**Failure 3: LedgerInfo Signature Verification Bypassed**

When the snapshot is restored, the LedgerInfo signatures are never verified because `epoch_history` is explicitly set to `None`: [3](#0-2) 

The restoration process only verifies merkle proofs, NOT signatures: [4](#0-3) 

The critical check at lines 137-139 is skipped when `epoch_history` is None. The `TransactionInfoWithProof.verify()` method only validates merkle tree structure: [5](#0-4) 

This verification does NOT check the validator signatures on the LedgerInfo.

**Failure 4: Trusted Waypoints are Optional**

The only protection mechanism (trusted waypoints) is not enforced: [6](#0-5) [7](#0-6) 

The `trust_waypoint` field defaults to an empty vector, making it completely optional.

## Attack Scenario

1. **Attacker compromises backup storage credentials** (e.g., S3/GCS access keys)

2. **Attacker creates malicious backup artifacts**:
   - Creates `StateSnapshotBackupMeta` JSON pointing to version V
   - Creates fake `StateSnapshotBackup` manifest with arbitrary `root_hash`
   - Creates fake proof file with self-consistent but UNSIGNED `LedgerInfoWithSignatures`
   - All merkle proofs are valid within this fake chain but signatures are invalid/missing

3. **Operator runs replay verification without waypoints**:
   ```bash
   aptos-db-tool replay-verify \
     --target-db-dir /data/db \
     --command-adapter-config s3.yaml \
     --start-version 0 \
     --end-version 1000000
   # Note: NO --trust-waypoint flags provided
   ```

4. **Malicious snapshot is selected and loaded**:
   - `select_state_snapshot()` returns the attacker's metadata
   - Snapshot restoration proceeds
   - Merkle proofs verify (they're self-consistent)
   - Signature verification is skipped (epoch_history is None)
   - No waypoint verification (none provided)

5. **Result**: Node database now contains completely fabricated state that could show:
   - Different validator set
   - Different account balances
   - Different smart contract code
   - Arbitrary state manipulation

## Impact Explanation

**Critical Severity** - This vulnerability breaks multiple core security invariants:

1. **Cryptographic Correctness Violation**: The system accepts LedgerInfo without validating BLS signatures from validator quorum, completely bypassing the consensus security model.

2. **State Consistency Violation**: Nodes can be tricked into accepting arbitrary state that was never agreed upon by the validator set.

3. **Consensus Safety Risk**: If a validator node uses corrupted state from this attack, it may propose or vote on blocks based on incorrect state, potentially causing:
   - Chain splits if different validators have different state
   - Double-spending if balances are manipulated
   - Validator set corruption if stake amounts are falsified

4. **Non-Recoverable Network Partition**: If multiple nodes are compromised with different fake states, the network may fragment and require a hard fork to recover.

This meets the **Critical Severity** criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**High Likelihood** in production environments:

1. **Attack Precondition is Realistic**: Backup storage credentials (S3/GCS keys) are commonly compromised through:
   - Credential leaks in CI/CD systems
   - Insider threats
   - Cloud console misconfigurations
   - Compromised operator workstations

2. **No Security Warning**: The tool provides no warning when run without trusted waypoints, making operators unaware of the risk.

3. **Common Operational Pattern**: Operators routinely run replay verification for:
   - Database recovery after corruption
   - Disaster recovery drills
   - State verification after upgrades
   - Debugging transaction execution issues

4. **Silent Failure**: The attack succeeds silently - the tool reports success because all merkle proofs verify correctly within the fake chain.

## Recommendation

Implement defense-in-depth by requiring cryptographic verification:

**Option 1: Require Trusted Waypoints (Immediate Fix)**

```rust
// In storage/backup/backup-cli/src/utils/mod.rs
impl TrustedWaypointOpt {
    pub fn verify(self) -> Result<HashMap<Version, Waypoint>> {
        let mut trusted_waypoints = HashMap::new();
        for w in self.trust_waypoint {
            trusted_waypoints
                .insert(w.version(), w)
                .map_or(Ok(()), |w| {
                    Err(AptosDbError::Other(format!(
                        "Duplicated waypoints at version {}",
                        w.version()
                    )))
                })?;
        }
        
        // NEW: Require at least one trusted waypoint for replay verification
        ensure!(
            !trusted_waypoints.is_empty(),
            "At least one trusted waypoint must be provided for replay verification. \
            This ensures the backup has not been tampered with. \
            Use --trust-waypoint <version>:<hash> to provide waypoints."
        );
        
        Ok(trusted_waypoints)
    }
}
```

**Option 2: Build and Use Epoch History (Comprehensive Fix)**

```rust
// In storage/backup/backup-cli/src/coordinators/replay_verify.rs
async fn run_impl(self) -> Result<(), ReplayError> {
    // ... existing code ...
    
    // NEW: Build epoch history from epoch ending backups
    let epoch_endings = metadata_view.select_epoch_ending_backups(self.end_version)?;
    let epoch_history = if !epoch_endings.is_empty() {
        let controller = EpochEndingRestoreController::new(
            epoch_endings.into_iter().map(|e| e.manifest).collect(),
            global_opt.clone(),
            Arc::clone(&self.storage),
        );
        Some(Arc::new(controller.run().await?))
    } else {
        warn!("No epoch ending backups found - signature verification will be skipped!");
        None
    };
    
    // ... then pass epoch_history to StateSnapshotRestoreController ...
    StateSnapshotRestoreController::new(
        StateSnapshotRestoreOpt {
            manifest_handle: backup.manifest,
            version: backup.version,
            validate_modules: self.validate_modules,
            restore_mode: Default::default(),
        },
        global_opt.clone(),
        Arc::clone(&self.storage),
        epoch_history, // Instead of None
    )
}
```

**Option 3: Sign Metadata Files (Defense-in-Depth)**

Implement cryptographic signatures on metadata files using the backup operator's key, similar to how Docker Content Trust signs container manifests.

## Proof of Concept

```rust
// Reproduction steps demonstrating the vulnerability

#[tokio::test]
async fn test_unsigned_snapshot_acceptance() {
    use aptos_backup_cli::{
        coordinators::replay_verify::ReplayVerifyCoordinator,
        metadata::{Metadata, StateSnapshotBackupMeta},
        storage::local_fs::LocalFs,
    };
    use aptos_crypto::HashValue;
    use aptos_types::{
        ledger_info::{LedgerInfo, LedgerInfoWithSignatures},
        proof::TransactionInfoWithProof,
        transaction::TransactionInfo,
    };
    use std::sync::Arc;
    use tempfile::TempDir;
    
    // 1. Setup malicious backup storage
    let backup_dir = TempDir::new().unwrap();
    let storage = Arc::new(LocalFs::new_with_opt(backup_dir.path().into()));
    
    // 2. Create FAKE metadata pointing to malicious snapshot
    let fake_metadata = Metadata::new_state_snapshot_backup(
        0, // epoch
        100, // version
        "malicious_snapshot.manifest".to_string(), // manifest handle
    );
    
    // Save fake metadata (NO SIGNATURE CHECK!)
    storage.save_metadata_line(
        &fake_metadata.name(),
        &fake_metadata.to_text_line().unwrap()
    ).await.unwrap();
    
    // 3. Create FAKE snapshot manifest with UNSIGNED LedgerInfo
    let fake_root_hash = HashValue::random();
    let fake_ledger_info = LedgerInfo::new(
        /* Fake blockchain state */
        Default::default(), // block info
        fake_root_hash,
        HashValue::zero(), // consensus hash
        HashValue::zero(), // accumulator root
        0, // epoch
        100, // version
        None, // timestamp
    );
    
    // 4. Create LedgerInfoWithSignatures with INVALID signatures
    // (In real attack, attacker would use completely fake signatures)
    let fake_li_with_sigs = LedgerInfoWithSignatures::new(
        fake_ledger_info,
        BTreeMap::new(), // NO VALID SIGNATURES!
    );
    
    // 5. Create self-consistent proof (merkle proof validates but signatures don't!)
    let fake_txn_info = TransactionInfo::new(
        HashValue::zero(),
        HashValue::zero(),
        HashValue::zero(),
        Some(fake_root_hash),
        0,
        aptos_types::contract_event::ExecutionStatus::Success,
    );
    
    let fake_proof = TransactionInfoWithProof::new(
        /* merkle proof that's valid within fake chain */
        Default::default(),
        fake_txn_info,
    );
    
    // Save fake proof
    storage.save_bcs_file(
        "proof.bcs",
        &(fake_proof, fake_li_with_sigs)
    ).await.unwrap();
    
    // 6. Run replay verification WITHOUT trusted waypoints
    let result = ReplayVerifyCoordinator::new(
        storage,
        MetadataCacheOpt::default(),
        TrustedWaypointOpt::default(), // EMPTY - No waypoints!
        1, // concurrent_downloads
        1, // replay_concurrency
        /* ... other params ... */
        0, // start_version
        100, // end_version
        false, // validate_modules
        VerifyExecutionMode::default(),
    )
    .unwrap()
    .run()
    .await;
    
    // 7. VULNERABILITY: Fake snapshot is ACCEPTED without signature verification!
    // The test would pass, demonstrating the vulnerability
    assert!(result.is_ok(), "Fake snapshot should be rejected but is accepted!");
}
```

**Note**: This PoC demonstrates the conceptual vulnerability. The actual exploitation requires creating properly formatted backup files matching the manifest schemas, but the core issue - accepting unsigned LedgerInfo - is clearly demonstrated.

## Notes

This vulnerability is particularly severe because:

1. **Trust Boundary Violation**: The backup/restore system should not trust external storage implicitly, but it does when waypoints aren't provided.

2. **Silent Failure**: There's no warning when running without waypoints, making operators unaware they're accepting unverified data.

3. **Wide Attack Surface**: Any compromise of cloud storage credentials (common in practice) enables full state corruption.

4. **Downstream Impact**: Corrupted state affects all subsequent operations - consensus, transaction execution, and validator operations.

The immediate fix should require trusted waypoints for all replay verification operations, with comprehensive epoch history verification as a longer-term solution.

### Citations

**File:** storage/backup/backup-cli/src/metadata/mod.rs (L184-189)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct StateSnapshotBackupMeta {
    pub epoch: u64,
    pub version: Version,
    pub manifest: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L132-142)
```rust
        } else if let Some(snapshot) = metadata_view.select_state_snapshot(self.start_version)? {
            let snapshot_version = snapshot.version;
            info!(
                "Found state snapshot backup at epoch {}, will replay from version {}.",
                snapshot.epoch,
                snapshot_version + 1
            );
            (Some(snapshot), Some(snapshot_version))
        } else {
            (None, None)
        };
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L173-188)
```rust
        if !skip_snapshot {
            if let Some(backup) = state_snapshot {
                StateSnapshotRestoreController::new(
                    StateSnapshotRestoreOpt {
                        manifest_handle: backup.manifest,
                        version: backup.version,
                        validate_modules: self.validate_modules,
                        restore_mode: Default::default(),
                    },
                    global_opt.clone(),
                    Arc::clone(&self.storage),
                    None, /* epoch_history */
                )
                .run()
                .await?;
            }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L125-139)
```rust
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
        if let Some(epoch_history) = self.epoch_history.as_ref() {
            epoch_history.verify_ledger_info(&li)?;
        }
```

**File:** types/src/proof/mod.rs (L40-61)
```rust
fn verify_transaction_info(
    ledger_info: &LedgerInfo,
    transaction_version: Version,
    transaction_info: &TransactionInfo,
    ledger_info_to_transaction_info_proof: &TransactionAccumulatorProof,
) -> Result<()> {
    ensure!(
        transaction_version <= ledger_info.version(),
        "Transaction version {} is newer than LedgerInfo version {}.",
        transaction_version,
        ledger_info.version(),
    );

    let transaction_info_hash = transaction_info.hash();
    ledger_info_to_transaction_info_proof.verify(
        ledger_info.transaction_accumulator_hash(),
        transaction_info_hash,
        transaction_version,
    )?;

    Ok(())
}
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L332-346)
```rust
pub struct TrustedWaypointOpt {
    #[clap(
        long,
        help = "(multiple) When provided, an epoch ending LedgerInfo at the waypoint version will be \
        checked against the hash in the waypoint, but signatures on it are NOT checked. \
        Use this for two purposes: \
        1. set the genesis or the latest waypoint to confirm the backup is compatible. \
        2. set waypoints at versions where writeset transactions were used to overwrite the \
        validator set, so that the signature check is skipped. \
        N.B. LedgerInfos are verified only when restoring / verifying the epoch ending backups, \
        i.e. they are NOT checked at all when doing one-shot restoring of the transaction \
        and state backups."
    )]
    pub trust_waypoint: Vec<Waypoint>,
}
```

**File:** storage/db-tool/src/replay_verify.rs (L24-29)
```rust
pub struct Opt {
    #[clap(flatten)]
    metadata_cache_opt: MetadataCacheOpt,
    #[clap(flatten)]
    trusted_waypoints_opt: TrustedWaypointOpt,
    #[clap(flatten)]
```
