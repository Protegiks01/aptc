# Audit Report

## Title
Unbounded Batch Creation During Pruner Initialization Can Cause Memory Exhaustion and Node Startup Failure

## Summary
If the `TransactionAuxiliaryDataPrunerProgress` metadata is reset to 0 (as opposed to being lost/deleted), the pruner initialization will attempt to create a single unbounded batch containing delete operations for all versions from 0 to the current ledger progress, potentially causing out-of-memory crashes or severe startup delays.

## Finding Description

The `TransactionAuxiliaryDataPruner::new()` function performs a "catch-up" operation during initialization to synchronize the sub-pruner with the main ledger metadata pruner. [1](#0-0) 

The initialization follows this flow:

1. **Progress Retrieval**: Calls `get_or_initialize_subpruner_progress()` which returns either the existing progress value or initializes it to `metadata_progress` if the key doesn't exist. [2](#0-1) 

2. **Catch-up Pruning**: Immediately calls `myself.prune(progress, metadata_progress)` without any batching logic.

3. **Unbounded Batch Creation**: The `prune()` method creates a single `SchemaBatch` and iterates through all versions from `current_progress` to `target_version`, adding delete operations. [3](#0-2) 

**Critical Distinction**: When metadata is **lost** (doesn't exist), `get_or_initialize_subpruner_progress()` initializes it to `metadata_progress`, resulting in `prune(metadata_progress, metadata_progress)` which is a no-op. However, when metadata is **reset to 0** (key exists with value 0), it returns 0, resulting in `prune(0, metadata_progress)`.

**Vulnerability Trigger**: If `metadata_progress` is 10 million versions and the progress is reset to 0, the initialization will:
- Create a single `SchemaBatch`
- Iterate 10 million times adding delete operations
- Each delete operation adds ~100-200 bytes to the batch
- Total memory usage: ~1-2 GB minimum for the batch alone
- Processing time: potentially hours on production nodes

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**Severity: Medium** (State inconsistencies requiring intervention)

**Impact on Affected Nodes**:
1. **Memory Exhaustion**: Nodes with large ledger histories (100M+ versions) could exceed available memory during initialization, causing OOM crashes
2. **Startup Failure**: Even without OOM, batch creation and write operations could take hours, effectively preventing node startup
3. **Operational Disruption**: All nodes experiencing this condition would fail to initialize properly, requiring manual intervention

**Scope**: This issue affects all ledger sub-pruners that follow the same initialization pattern: [4](#0-3) 

- `EventStorePruner` [5](#0-4) 
- `TransactionInfoPruner` [6](#0-5) 
- `TransactionAuxiliaryDataPruner` (primary focus)
- `PersistedAuxiliaryInfoPruner`, `TransactionAccumulatorPruner`, `TransactionPruner`, `WriteSetPruner`

**Why Not Higher Severity**: This doesn't cause consensus violations, fund loss, or network-wide failures. It's a node availability issue requiring specific trigger conditions.

## Likelihood Explanation

**Likelihood: Low to Medium**

**Trigger Scenarios**:
1. **Schema Migration Bug**: If a database schema migration inadvertently resets pruner progress counters to 0 while preserving `metadata_progress`
2. **Enum Deserialization Issues**: If `DbMetadataKey` enum variants are reordered in a future version, BCS deserialization could map existing values incorrectly [7](#0-6) 
3. **Database Corruption**: Storage corruption that zeros out metadata values while leaving keys intact
4. **Manual Operator Error**: During database maintenance or troubleshooting, an operator might manually reset counters

**Likelihood Factors**:
- **Low**: Requires specific metadata corruption pattern (reset to 0, not deletion)
- **Medium**: Multiple pruners share the same vulnerable pattern, increasing attack surface
- **Increasing**: As ledger grows to billions of versions, memory impact becomes more severe

**Historical Context**: The `LedgerMetadataPruner` has explicit fallback logic for missing progress, suggesting schema migration compatibility is a known concern. [8](#0-7) 

## Recommendation

Implement batched catch-up logic in sub-pruner initialization to prevent unbounded batch creation:

```rust
pub(in crate::pruner) fn new(
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        ledger_db.transaction_auxiliary_data_db_raw(),
        &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
        metadata_progress,
    )?;

    let myself = TransactionAuxiliaryDataPruner { ledger_db };

    // CRITICAL FIX: Add validation and batched catch-up
    if progress > metadata_progress {
        return Err(AptosDbError::Other(format!(
            "TransactionAuxiliaryDataPrunerProgress ({}) ahead of metadata ({}))",
            progress, metadata_progress
        )));
    }

    const MAX_CATCHUP_BATCH_SIZE: u64 = 10_000;
    let mut current = progress;
    
    info!(
        progress = progress,
        metadata_progress = metadata_progress,
        gap = metadata_progress - progress,
        "Catching up TransactionAuxiliaryDataPruner with batching."
    );

    while current < metadata_progress {
        let target = std::cmp::min(current + MAX_CATCHUP_BATCH_SIZE, metadata_progress);
        myself.prune(current, target)?;
        current = target;
        
        if (current - progress) % 100_000 == 0 {
            info!(
                progress = current,
                metadata_progress = metadata_progress,
                "Catch-up progress..."
            );
        }
    }

    Ok(myself)
}
```

**Additional Safeguards**:
1. Add progress validation: `if progress > metadata_progress` â†’ error (indicates corruption)
2. Log warnings when catch-up gap exceeds threshold (e.g., 1M versions)
3. Consider adding `max_catchup_gap` configuration parameter to abort on excessive gaps

## Proof of Concept

```rust
#[test]
fn test_pruner_metadata_reset_oom() {
    use tempfile::TempDir;
    use aptos_schemadb::DB;
    
    // Setup: Create database with large metadata_progress
    let tmpdir = TempDir::new().unwrap();
    let db = DB::open(&tmpdir.path(), "test_db", &[]).unwrap();
    
    let large_progress: Version = 10_000_000; // 10M versions
    
    // Simulate corrupted state: progress exists but is 0
    db.put::<DbMetadataSchema>(
        &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
        &DbMetadataValue::Version(0)
    ).unwrap();
    
    // This will attempt to create batch with 10M delete operations
    // Expected: OOM or severe performance degradation
    let ledger_db = Arc::new(LedgerDb::new(tmpdir.path()).unwrap());
    
    let start = std::time::Instant::now();
    let result = TransactionAuxiliaryDataPruner::new(
        ledger_db,
        large_progress
    );
    let duration = start.elapsed();
    
    // Demonstrates the issue:
    // - With 10M versions: ~1-2 GB memory allocation
    // - Processing time: seconds to minutes depending on hardware
    // - With 100M versions: likely OOM crash
    
    println!("Initialization took: {:?}", duration);
    println!("Memory impact: ~{} MB estimated", large_progress * 150 / 1_000_000);
    
    assert!(duration.as_secs() > 1, "Should take significant time for large gap");
}

#[test]
fn test_pruner_metadata_lost_safe() {
    use tempfile::TempDir;
    
    let tmpdir = TempDir::new().unwrap();
    let db = DB::open(&tmpdir.path(), "test_db", &[]).unwrap();
    
    let metadata_progress: Version = 10_000_000;
    
    // Metadata doesn't exist (lost, not reset)
    // get_or_initialize_subpruner_progress will initialize to metadata_progress
    
    let ledger_db = Arc::new(LedgerDb::new(tmpdir.path()).unwrap());
    
    let start = std::time::Instant::now();
    let result = TransactionAuxiliaryDataPruner::new(
        ledger_db,
        metadata_progress
    );
    let duration = start.elapsed();
    
    // Should complete instantly (no-op: prune(10M, 10M))
    assert!(result.is_ok());
    assert!(duration.as_millis() < 100, "Should be near-instant");
}
```

## Notes

This vulnerability demonstrates a **defensive programming failure** where the initialization code trusts metadata values without validation or batching safeguards. While the regular pruning operation implements proper batching, [9](#0-8)  the initialization path bypasses these protections.

The issue is systemic across all sub-pruners, indicating a pattern that should be addressed in the `DBSubPruner` trait or initialization utility functions to prevent similar vulnerabilities in future pruner implementations.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_auxiliary_data_pruner.rs (L39-59)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_auxiliary_data_db_raw(),
            &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionAuxiliaryDataPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionAuxiliaryDataPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```

**File:** storage/aptosdb/src/ledger_db/transaction_auxiliary_data_db.rs (L74-79)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<TransactionAuxiliaryDataSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L62-92)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning ledger data."
            );
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning ledger data is done.");
        }

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L138-171)
```rust
        let event_store_pruner = Box::new(EventStorePruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db.clone(),
        )?);
        let persisted_auxiliary_info_pruner = Box::new(PersistedAuxiliaryInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_accumulator_pruner = Box::new(TransactionAccumulatorPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_auxiliary_data_pruner = Box::new(TransactionAuxiliaryDataPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_info_pruner = Box::new(TransactionInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_pruner = Box::new(TransactionPruner::new(
            Arc::clone(&transaction_store),
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db,
        )?);
        let write_set_pruner = Box::new(WriteSetPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L85-109)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_info_pruner.rs (L37-58)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_info_db_raw(),
            &DbMetadataKey::TransactionInfoPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionInfoPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionInfoPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
}
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L47-72)
```rust
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub enum DbMetadataKey {
    LedgerPrunerProgress,
    StateMerklePrunerProgress,
    EpochEndingStateMerklePrunerProgress,
    StateKvPrunerProgress,
    StateSnapshotKvRestoreProgress(Version),
    LedgerCommitProgress,
    StateKvCommitProgress,
    OverallCommitProgress,
    StateKvShardCommitProgress(ShardId),
    StateMerkleCommitProgress,
    StateMerkleShardCommitProgress(ShardId),
    EventPrunerProgress,
    TransactionAccumulatorPrunerProgress,
    TransactionInfoPrunerProgress,
    TransactionPrunerProgress,
    WriteSetPrunerProgress,
    StateMerkleShardPrunerProgress(ShardId),
    EpochEndingStateMerkleShardPrunerProgress(ShardId),
    StateKvShardPrunerProgress(ShardId),
    StateMerkleShardRestoreProgress(ShardId, Version),
    TransactionAuxiliaryDataPrunerProgress,
    PersistedAuxiliaryInfoPrunerProgress,
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_metadata_pruner.rs (L19-40)
```rust
    pub(in crate::pruner) fn new(ledger_metadata_db: Arc<DB>) -> Result<Self> {
        if let Some(v) =
            ledger_metadata_db.get::<DbMetadataSchema>(&DbMetadataKey::LedgerPrunerProgress)?
        {
            v.expect_version();
        } else {
            // NOTE: I **think** all db should have the LedgerPrunerProgress. Have a fallback path
            // here in case the database was super old before we introducing this progress counter.
            let mut iter = ledger_metadata_db.iter::<VersionDataSchema>()?;
            iter.seek_to_first();
            let version = match iter.next().transpose()? {
                Some((version, _)) => version,
                None => 0,
            };
            ledger_metadata_db.put::<DbMetadataSchema>(
                &DbMetadataKey::LedgerPrunerProgress,
                &DbMetadataValue::Version(version),
            )?;
        }

        Ok(LedgerMetadataPruner { ledger_metadata_db })
    }
```
