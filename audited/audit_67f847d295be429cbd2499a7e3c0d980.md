# Audit Report

## Title
Indexer File Checker Lacks LZ4 Format Validation, Allowing Corrupted Files to Pass Verification

## Summary
The indexer-grpc file checker compares transaction files from two GCS buckets using raw byte comparison without validating the LZ4 compression format. [1](#0-0)  This allows corrupted or malformed LZ4 files to pass verification if both buckets contain identically corrupted data, leading to service crashes when downstream consumers attempt to decompress these files.

## Finding Description

The file checker's `run()` function downloads transaction files from two buckets and performs only raw byte comparison: [2](#0-1) 

The `download_raw_file` function returns raw bytes without any format validation: [3](#0-2) 

However, when downstream services (indexer-grpc-data-service-v2) attempt to serve these files, they must decompress them using `FileEntry::into_transactions_in_storage()`: [4](#0-3) 

The decompression operation uses `.expect()` which panics on invalid LZ4 headers or corrupted compression data: [5](#0-4) 

**Attack Scenario:**
1. A bug in the file uploader or storage corruption causes invalid LZ4 files to be written to both buckets
2. The file checker downloads both files and compares raw bytes
3. Since both files are identically corrupted, the comparison passes (line 79: `if existing_file != new_file`)
4. The checker logs "File is verified" and continues
5. When the indexer-grpc-data-service-v2 attempts to serve these transactions to clients, the service crashes with "Lz4 decompression failed" or "proto deserialization failed"
6. The data service becomes unavailable, affecting all consumers (wallets, explorers, analytics tools)

## Impact Explanation

This qualifies as **High Severity** under "API crashes" criteria. The indexer-grpc-data-service-v2 is a critical API that serves historical transaction data to ecosystem participants. [6](#0-5) 

When corrupted files pass verification:
- The data service crashes when attempting to decompress files
- Historical transaction data becomes unavailable to all consumers
- Requires manual intervention to identify and replace corrupted files
- Service outage affects wallets, block explorers, and other dependent services

## Likelihood Explanation

**Likelihood: Medium**

This can occur through:
1. **Uploader bugs**: A bug in the file store uploader that generates invalid LZ4 format
2. **Storage corruption**: GCS bucket corruption affecting multiple objects
3. **Concurrent writes**: Race conditions in upload logic creating partial/corrupted files
4. **Migration errors**: During bucket migrations, corrupted files could be replicated

The file checker's purpose is to prevent such scenarios during bucket migrations, but it fails to perform semantic validation.

## Recommendation

Add format validation before comparison. The file checker should attempt to decompress and decode files to verify they are valid LZ4CompressedProto format:

```rust
// In processor.rs run() function, after line 78:
let existing_file = existing_file.unwrap();
let new_file = new_file.unwrap();

// Validate both files can be decompressed and decoded
let validation_result = tokio::task::spawn_blocking({
    let existing = existing_file.clone();
    let new = new_file.clone();
    move || {
        // Attempt to decompress and decode both files
        let _ = FileEntry::new(existing, StorageFormat::Lz4CompressedProto)
            .into_transactions_in_storage();
        let _ = FileEntry::new(new, StorageFormat::Lz4CompressedProto)
            .into_transactions_in_storage();
        Ok::<(), anyhow::Error>(())
    }
}).await;

if let Err(e) = validation_result {
    tracing::error!(
        file_name = file_name.as_str(),
        error = ?e,
        "File format validation failed - files are corrupted"
    );
    FILE_DIFF_COUNTER.inc();
    tokio::time::sleep(tokio::time::Duration::from_secs(120)).await;
    panic!("File format validation failed: {}", file_name);
}

// Then perform byte comparison
if existing_file != new_file {
    // existing comparison logic...
}
```

## Proof of Concept

```rust
// test_corrupted_file_validation.rs
use aptos_indexer_grpc_utils::compression_util::{FileEntry, StorageFormat};

#[tokio::test]
async fn test_corrupted_lz4_file_passes_byte_comparison() {
    // Create corrupted LZ4 data (invalid magic number)
    let corrupted_data = vec![0xFF, 0xFF, 0xFF, 0xFF, 0x00, 0x00];
    
    // Simulate file checker comparing two identical corrupted files
    let file1 = corrupted_data.clone();
    let file2 = corrupted_data.clone();
    
    // Byte comparison passes
    assert_eq!(file1, file2, "Byte comparison should pass for identical corrupted files");
    
    // But decompression fails
    let result = std::panic::catch_unwind(|| {
        FileEntry::new(file1, StorageFormat::Lz4CompressedProto)
            .into_transactions_in_storage()
    });
    
    assert!(result.is_err(), "Decompression should panic on corrupted data");
    println!("âœ“ Corrupted files pass byte comparison but fail decompression");
}
```

## Notes

This vulnerability is specific to the indexer-grpc infrastructure and does not directly affect consensus or core blockchain operations. However, it represents a failure in the data integrity verification layer that the file checker is explicitly designed to provide. The impact is limited to API availability rather than blockchain security, but meets the High severity threshold for API service disruption.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-file-checker/src/processor.rs (L58-87)
```rust
            let existing_file =
                download_raw_file(&client, &self.existing_bucket_name, &file_name).await?;
            let new_file = download_raw_file(&client, &self.new_bucket_name, &file_name).await?;
            if existing_file.is_none() || new_file.is_none() {
                let bucket_name = if existing_file.is_none() {
                    &self.existing_bucket_name
                } else {
                    &self.new_bucket_name
                };
                tracing::info!(
                    bucket_name = bucket_name,
                    file_name = file_name.as_str(),
                    "Transaction file is not found in one of the buckets."
                );
                // Wait for the next file to be uploaded.
                tokio::time::sleep(tokio::time::Duration::from_secs(30)).await;
                continue;
            }
            // Compare the files.
            let existing_file = existing_file.unwrap();
            let new_file = new_file.unwrap();
            if existing_file != new_file {
                // Files are different.
                tracing::error!("Files are different: {}", file_name);
                FILE_DIFF_COUNTER.inc();

                // Sleep for a while to allow metrics to be updated.
                tokio::time::sleep(tokio::time::Duration::from_secs(120)).await;
                panic!("Files are different: {}", file_name);
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-checker/src/processor.rs (L166-186)
```rust
async fn download_raw_file(
    client: &Client,
    bucket_name: &str,
    file_name: &str,
) -> Result<Option<Vec<u8>>> {
    let file = client.object().download(bucket_name, file_name).await;
    match file {
        Ok(file) => Ok(Some(file)),
        Err(cloud_storage::Error::Other(err)) => {
            if err.contains("No such object: ") {
                Ok(None)
            } else {
                anyhow::bail!(
                    "[Indexer File] Error happens when downloading transaction file. {}",
                    err
                );
            }
        },
        Err(e) => Err(e.into()),
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator_v2/file_store_reader.rs (L234-237)
```rust
        let transactions_in_storage = tokio::task::spawn_blocking(move || {
            FileEntry::new(bytes, StorageFormat::Lz4CompressedProto).into_transactions_in_storage()
        })
        .await?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L264-271)
```rust
            FileEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                TransactionsInStorage::decode(decompressed.as_slice())
                    .expect("proto deserialization failed.")
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L169-180)
```rust
            tokio::spawn(async move {
                file_store_reader
                    .get_transaction_batch(
                        next_version,
                        /*retries=*/ 3,
                        /*max_files=*/ None,
                        filter,
                        Some(ending_version),
                        tx,
                    )
                    .await;
            });
```
