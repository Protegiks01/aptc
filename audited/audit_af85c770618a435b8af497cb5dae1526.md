# Audit Report

## Title
DoS Vulnerability in DKG Sigma Protocol Verification Due to Unchecked Iterator Consumption

## Summary
A panic-inducing vulnerability exists in the DKG sigma protocol's MSM (Multi-Scalar Multiplication) verification logic. When verifying proofs during DKG transcript validation, the `merge_msm_terms` function uses `.unwrap()` on iterator operations without validating that the prover's commitment structure matches the expected statement structure. A malicious validator can craft a DKG transcript with mismatched proof elements, causing honest validators to panic and crash during verification.

## Finding Description
The vulnerability exists in the sigma protocol verification framework used by the DKG system. During DKG transcript verification, the system validates a Signature of Knowledge (SoK) proof that demonstrates correct encryption of shares. This verification process constructs MSM terms by combining elements from both the prover's commitment and the public statement. [1](#0-0) 

The `merge_msm_terms` function has a critical flaw in how it handles the prover's first message (commitment) and the public statement: [2](#0-1) 

**The Attack Path:**

1. The function determines `number_of_beta_powers` based solely on `statement.into_iter().count()` (line 120 in `msm_terms_for_verify`)
2. It creates `affine_points` by zipping `prover_first_message` and `statement` iterators (lines 153-158)
3. The zip operation stops at the shorter iterator, so `affine_points.len() = 2 * min(prover_first_message.count(), statement.count())`
4. The loop at line 163 iterates `min(msm_terms.len(), powers_of_beta.len())` times
5. Each iteration consumes 2 elements from `affine_iter` via `.unwrap()` (lines 173-174)

**Exploitation Scenario:**

If `prover_first_message.count() < statement.count()`:
- `affine_iter` has `2 * prover_first_message.count()` elements
- `powers_of_beta` has `statement.count()` elements  
- The loop tries to run `min(msm_terms.len(), statement.count())` times
- When `affine_iter` runs out of elements, `.unwrap()` panics

A malicious validator can exploit this during DKG ceremonies by:
1. Crafting a DKG transcript with a SoK proof where the `FirstProofItem::Commitment` structure has fewer elements than the corresponding statement derived from the transcript's public data
2. Submitting this malformed transcript during the DKG aggregation phase
3. When honest validators attempt to verify this transcript, they reach the vulnerable code path [3](#0-2) 

The verification is triggered during transcript validation, which occurs when validators process DKG contributions from peers. The panic causes the validator node to crash, disrupting the DKG ceremony.

## Impact Explanation
This vulnerability constitutes a **High Severity** issue under the Aptos bug bounty program criteria:

- **Validator node crashes**: A single malicious validator can cause honest validators to panic and terminate, fitting the "Validator node slowdowns" (or outright crashes) category
- **DKG ceremony disruption**: The DKG ceremony is critical for generating shared randomness and validator set configuration. Repeated attacks could prevent the network from completing epoch transitions
- **State inconsistencies**: Failed DKG ceremonies require manual intervention to restore network progress

The impact is amplified because:
- DKG runs during epoch transitions, a critical network operation
- The attack requires no stake threshold - any validator can exploit this
- Detection is straightforward (node crashes), but recovery requires restarting validators and potentially manual intervention
- Repeated attacks could delay or prevent epoch transitions entirely

## Likelihood Explanation
**Likelihood: High**

The attack is highly likely to succeed because:

1. **Low barrier to entry**: Any participant in the DKG ceremony can submit a malformed transcript. No special privileges or majority stake required.

2. **Easy to craft**: The attacker simply needs to create a transcript with a `SharingProof` where the nested `Commitment` structure has mismatched element counts. Since BCS deserialization doesn't validate semantic correctness, only structural validity, malformed proofs can be deserialized successfully.

3. **Guaranteed trigger**: Once the malformed transcript reaches the verification code path, the panic is deterministic - there's no randomness or race condition involved.

4. **Difficult to prevent**: The vulnerability exists in core cryptographic verification logic that must process untrusted input from peer validators.

## Recommendation
Implement proper error handling instead of using `.unwrap()`. The function should validate that iterators have sufficient elements before consuming them:

```rust
fn merge_msm_terms(
    msm_terms: Vec<Self::MsmInput>,
    prover_first_message: &Self::Codomain,
    statement: &Self::Codomain,
    powers_of_beta: &[C::ScalarField],
    c: C::ScalarField,
) -> anyhow::Result<Self::MsmInput>  // Change return type to Result
{
    let mut final_basis = Vec::new();
    let mut final_scalars = Vec::new();

    // Validate lengths upfront
    let prover_msg_count = prover_first_message.clone().into_iter().count();
    let statement_count = statement.clone().into_iter().count();
    
    if prover_msg_count != statement_count {
        anyhow::bail!(
            "Prover commitment length ({}) does not match statement length ({})",
            prover_msg_count,
            statement_count
        );
    }
    
    if msm_terms.len() != powers_of_beta.len() {
        anyhow::bail!(
            "MSM terms length ({}) does not match beta powers length ({})",
            msm_terms.len(),
            powers_of_beta.len()
        );
    }

    let mut all_points_to_normalize = Vec::new();
    for (A, P) in prover_first_message.clone().into_iter()
        .zip(statement.clone().into_iter())
    {
        all_points_to_normalize.push(A);
        all_points_to_normalize.push(P);
    }

    let affine_points = C::normalize_batch(&all_points_to_normalize);
    let mut affine_iter = affine_points.into_iter();

    for (term, beta_power) in msm_terms.into_iter().zip(powers_of_beta) {
        let mut bases = term.bases().to_vec();
        let mut scalars = term.scalars().to_vec();

        for scalar in scalars.iter_mut() {
            *scalar *= beta_power;
        }

        // Use pattern matching instead of unwrap
        let A = affine_iter.next().ok_or_else(|| 
            anyhow::anyhow!("Insufficient elements in affine iterator for prover message"))?;
        let P = affine_iter.next().ok_or_else(|| 
            anyhow::anyhow!("Insufficient elements in affine iterator for statement"))?;
        
        bases.push(A);
        bases.push(P);

        scalars.push(- (*beta_power));
        scalars.push(-c * beta_power);

        final_basis.extend(bases);
        final_scalars.extend(scalars);
    }

    Self::MsmInput::new(final_basis, final_scalars)
}
```

Additionally, update the MSM evaluation in `msm.rs` to properly propagate errors: [4](#0-3) 

Change line 117 from:
```rust
let msm_result = C::msm(&final_bases, &final_scalars).expect("Could not compute batch MSM");
```

To:
```rust
let msm_result = C::msm(&final_bases, &final_scalars)
    .map_err(|e| anyhow::anyhow!("MSM computation failed: {:?}", e))?;
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_dos_vulnerability {
    use super::*;
    use ark_bls12_381::{Bls12_381, G1Projective};
    use crate::sigma_protocol::{
        traits::{FirstProofItem, Proof},
        homomorphism::tuple::TupleCodomainShape,
    };
    
    #[test]
    #[should_panic(expected = "called `Option::unwrap()` on a `None` value")]
    fn test_mismatched_proof_commitment_causes_panic() {
        // Create a minimal homomorphism setup
        // (Details would depend on the specific homomorphism implementation)
        
        // Create a statement with N elements
        let statement = create_statement_with_n_elements(5);
        
        // Create a malicious proof where the commitment has fewer elements
        let malicious_commitment = create_commitment_with_n_elements(3); // Less than 5
        
        let malicious_proof = Proof {
            first_proof_item: FirstProofItem::Commitment(malicious_commitment),
            z: create_valid_witness(),
        };
        
        // This should panic when merge_msm_terms tries to consume
        // more elements from affine_iter than are available
        let result = hom.verify(&statement, &malicious_proof, &context);
        
        // This line should never be reached
        assert!(result.is_err());
    }
}
```

**Notes:**
- The vulnerability is in the core sigma protocol verification framework used across the DKG system
- Multiple `expect()` calls exist in the codebase that should be replaced with proper error handling
- The fix requires changing function signatures to return `Result<>` types and propagating errors appropriately
- Validators should implement additional input validation on deserialized transcripts before verification to detect anomalies early

### Citations

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L102-133)
```rust
    // Returns the MSM terms that `verify()` needs
    #[allow(non_snake_case)]
    fn msm_terms_for_verify<Ct: Serialize, H>(
        &self,
        public_statement: &Self::Codomain,
        proof: &Proof<C::ScalarField, H>,
        cntxt: &Ct,
    ) -> Self::MsmInput
    where
        H: homomorphism::Trait<Domain = Self::Domain, Codomain = Self::Codomain>, // Need this because the lifetime was changed
    {
        let prover_first_message = match &proof.first_proof_item {
            FirstProofItem::Commitment(A) => A,
            FirstProofItem::Challenge(_) => {
                panic!("Missing implementation - expected commitment, not challenge")
            },
        };

        let number_of_beta_powers = public_statement.clone().into_iter().count(); // TODO: maybe pass the into_iter version in merge_msm_terms?

        let (c, powers_of_beta) = self.compute_verifier_challenges(public_statement, prover_first_message, cntxt, number_of_beta_powers);

        let msm_terms_for_prover_response = self.msm_terms(&proof.z);

        Self::merge_msm_terms(
            msm_terms_for_prover_response.into_iter().collect(),
            prover_first_message,
            public_statement,
            &powers_of_beta,
            c,
        )
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L139-184)
```rust
    fn merge_msm_terms(
        msm_terms: Vec<Self::MsmInput>,
        prover_first_message: &Self::Codomain,
        statement: &Self::Codomain,
        powers_of_beta: &[C::ScalarField],
        c: C::ScalarField,
    ) -> Self::MsmInput
    {
        let mut final_basis = Vec::new();
        let mut final_scalars = Vec::new();

        // Collect all projective points to batch normalize
        // TODO: remove this stuff... we may assume things are deserialised and hence essentially affine, so into_affine() should do
        let mut all_points_to_normalize = Vec::new();
        for (A, P) in prover_first_message.clone().into_iter()
            .zip(statement.clone().into_iter())
        {
            all_points_to_normalize.push(A);
            all_points_to_normalize.push(P);
        }

        let affine_points = C::normalize_batch(&all_points_to_normalize);
        let mut affine_iter = affine_points.into_iter();

        for (term, beta_power) in msm_terms.into_iter().zip(powers_of_beta) {
            let mut bases = term.bases().to_vec();
            let mut scalars = term.scalars().to_vec();

            // Multiply scalars by βᶦ
            for scalar in scalars.iter_mut() {
                *scalar *= beta_power;
            }

            // Add prover + statement contributions
            bases.push(affine_iter.next().unwrap()); // this is the element `A` from the prover's first message
            bases.push(affine_iter.next().unwrap()); // this is the element `P` from the statement, but we'll need `P^c`

            scalars.push(- (*beta_power));
            scalars.push(-c * beta_power);

            final_basis.extend(bases);
            final_scalars.extend(scalars);
        }

        Self::MsmInput::new(final_basis, final_scalars).expect("Something went wrong constructing MSM input")
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L514-529)
```rust
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    TupleCodomainShape(
                        self.sharing_proof.range_proof_commitment.clone(),
                        chunked_elgamal::WeightedCodomainShape {
                            chunks: self.subtrs.Cs.clone(),
                            randomness: self.subtrs.Rs.clone(),
                        },
                    ),
                    chunked_scalar_mul::CodomainShape(self.subtrs.Vs.clone()),
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```

**File:** crates/aptos-crypto/src/arkworks/msm.rs (L98-121)
```rust
pub fn verify_msm_terms_with_start<C: CurveGroup>(
    msm_terms: Vec<MsmInput<C::Affine, C::ScalarField>>,
    mut final_bases: Vec<C::Affine>,
    mut final_scalars: Vec<C::ScalarField>,
    powers_of_beta: Vec<C::ScalarField>,
) -> anyhow::Result<()> {
    assert_eq!(msm_terms.len(), powers_of_beta.len());

    for (term, beta_power) in msm_terms.into_iter().zip(powers_of_beta) {
        let mut scalars = term.scalars().to_vec();

        for scalar in scalars.iter_mut() {
            *scalar *= beta_power;
        }

        final_bases.extend(term.bases());
        final_scalars.extend(scalars);
    }

    let msm_result = C::msm(&final_bases, &final_scalars).expect("Could not compute batch MSM");
    ensure!(msm_result == C::ZERO);

    Ok(())
}
```
