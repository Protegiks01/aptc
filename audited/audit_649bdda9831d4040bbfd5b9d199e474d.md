# Audit Report

## Title
Partial Batch Failure in Account Creation Due to Fixed Retry Limit

## Summary
The `create_accounts_command` function uses `RestApiReliableTransactionSubmitter` with a hardcoded retry limit of 6, which can cause partial batch failures where some accounts are successfully created on-chain while others fail, leaving the system in an inconsistent state that requires manual intervention. [1](#0-0) 

## Finding Description
The vulnerability lies in the interaction between parallel transaction submission and fixed retry limits. When `create_accounts_command` invokes `bulk_create_accounts`, accounts are created in batches using `RestApiReliableTransactionSubmitter` with a maximum of 6 retries per transaction. [2](#0-1) 

The `execute_transactions_with_counter` method uses `join_all` to submit all transactions in a batch in parallel. Each transaction independently retries up to 6 times via `submit_check_and_retry`. [3](#0-2) 

The critical issue occurs when:
1. Multiple account creation transactions are submitted in parallel
2. Some transactions succeed within 6 retries
3. Other transactions exhaust all 6 retries due to network issues, node unavailability, or transient failures
4. The final fallback check at lines 142-158 also fails for the problematic transactions
5. The `collect::<Result<Vec<()>, anyhow::Error>>()` call fails the entire batch operation
6. **However, the successful transactions are already committed on-chain**

This breaks the **State Consistency** invariant, which requires that state transitions be atomic. The batch operation appears to fail from the caller's perspective, but some accounts were actually created, leaving the system in a partially completed state. [4](#0-3) 

The `create_and_fund_new_accounts` function processes accounts in batches, and any failure in `execute_transactions_with_counter` causes the entire batch to fail, even though some transactions succeeded.

## Impact Explanation
This qualifies as **Medium Severity** under the Aptos bug bounty program category of "State inconsistencies requiring intervention":

1. **Operational Impact**: Users receive an error indicating batch failure, but cannot determine which accounts were successfully created without manual blockchain inspection
2. **Resource Wastage**: Gas fees are spent on successfully created accounts that may not be tracked by the calling system
3. **Automation Failures**: Automated systems expecting atomic batch operations may enter inconsistent states
4. **Recovery Complexity**: Manual intervention is required to identify which accounts exist and retry only the failed ones

The retry limit of 6 prevents eventual consistency because transactions that could succeed with more time/retries are permanently failed, while others in the same batch succeed.

## Likelihood Explanation
This issue has **moderate to high likelihood** in production environments:

1. **Network Variability**: In distributed blockchain networks, intermittent network issues, node failures, or load balancing can cause some API endpoints to be temporarily unavailable while others remain accessible
2. **Load Conditions**: During high load periods, some transactions may timeout while others complete within the retry window
3. **Node Heterogeneity**: Different REST API nodes may have varying performance characteristics, causing inconsistent success rates across parallel transactions
4. **Account-Specific Issues**: Some accounts may encounter transient issues (e.g., sequence number conflicts) that resolve differently across retries

The issue becomes more probable as batch size increases and during periods of network instability.

## Recommendation

**Option 1: Increase Retry Limit and Make Configurable**
```rust
pub async fn create_accounts_command(
    cluster_args: &ClusterArgs,
    create_accounts_args: &CreateAccountsArgs,
) -> Result<()> {
    // ... existing code ...
    
    // Use higher retry limit for account creation (e.g., 20 retries)
    let max_retries = create_accounts_args.max_retries.unwrap_or(20);
    let retry_interval = create_accounts_args.retry_interval
        .unwrap_or(Duration::from_secs(10));
    
    bulk_create_accounts(
        coin_source_account,
        &RestApiReliableTransactionSubmitter::new(
            rest_clients, 
            max_retries,  // Configurable, higher default
            retry_interval
        ),
        // ... rest of parameters ...
    )
    .await?;
    
    Ok(())
}
```

**Option 2: Implement Partial Success Tracking**
Modify `execute_transactions_with_counter` to track which transactions succeeded and return detailed results:

```rust
pub struct BatchResult {
    pub successful: Vec<usize>,  // indices of successful transactions
    pub failed: Vec<(usize, anyhow::Error)>,  // indices and errors
}

async fn execute_transactions_with_counter(
    &self,
    txns: &[SignedTransaction],
    counters: &CounterState,
) -> Result<BatchResult> {
    let run_seed: u64 = thread_rng().r#gen();
    let results: Vec<_> = join_all(
        txns.iter()
            .enumerate()
            .map(|(idx, txn)| async move {
                (idx, self.submit_check_and_retry(txn, counters, run_seed).await)
            }),
    )
    .await;
    
    let mut successful = Vec::new();
    let mut failed = Vec::new();
    
    for (idx, result) in results {
        match result {
            Ok(()) => successful.push(idx),
            Err(e) => failed.push((idx, e)),
        }
    }
    
    Ok(BatchResult { successful, failed })
}
```

Then handle partial failures appropriately at the calling level, with options to retry only failed accounts.

## Proof of Concept

```rust
#[tokio::test]
async fn test_partial_batch_failure() {
    // Setup: Create a cluster with some unreliable nodes
    let mut cluster = create_test_cluster(3).await;
    
    // Make one node slow/unreliable to cause timeouts
    cluster.nodes[2].set_artificial_delay(Duration::from_secs(100));
    
    let rest_clients: Vec<RestClient> = cluster.nodes
        .iter()
        .map(|n| n.rest_client())
        .collect();
    
    // Create submitter with low retry count to trigger issue
    let submitter = RestApiReliableTransactionSubmitter::new(
        rest_clients,
        2,  // Very low retry count to trigger failure
        Duration::from_secs(5)
    );
    
    // Prepare batch of 10 account creation transactions
    let source_account = cluster.load_coin_source_account().await.unwrap();
    let txn_factory = TransactionFactory::new(cluster.chain_id);
    
    let accounts: Vec<_> = (0..10)
        .map(|_| LocalAccount::generate(&mut rand::thread_rng()))
        .collect();
    
    let txns: Vec<_> = accounts
        .iter()
        .map(|acc| {
            create_and_fund_account_request(
                Arc::new(source_account.clone()),
                1_000_000,
                acc.address(),
                &txn_factory
            )
        })
        .collect();
    
    // Execute batch - this should fail
    let counter_state = submitter.create_counter_state();
    let result = submitter
        .execute_transactions_with_counter(&txns, &counter_state)
        .await;
    
    // Verify: Operation failed
    assert!(result.is_err(), "Batch operation should fail");
    
    // But check on-chain: Some accounts were actually created
    let mut created_count = 0;
    for account in &accounts {
        if let Ok(seq) = cluster.nodes[0]
            .rest_client()
            .get_account_sequence_number(account.address())
            .await {
            if *seq.inner() > 0 {
                created_count += 1;
            }
        }
    }
    
    // VULNERABILITY: Some accounts created despite batch failure
    assert!(
        created_count > 0 && created_count < 10,
        "Partial batch success detected: {} out of 10 accounts created, \
         but operation reported failure",
        created_count
    );
    
    println!(
        "Vulnerability confirmed: {} accounts created on-chain \
         despite batch operation returning error",
        created_count
    );
}
```

## Notes

This vulnerability demonstrates a violation of the atomicity property expected from batch operations. While individual transaction consistency is maintained on the blockchain, the batch-level operation semantics create operational complexity and potential for system state confusion. The issue is exacerbated by the fixed retry limit, which prevents the system from achieving eventual consistency that would be possible with more persistent retry behavior or asynchronous retry mechanisms.

### Citations

**File:** crates/transaction-emitter-lib/src/wrappers.rs (L251-251)
```rust
        &RestApiReliableTransactionSubmitter::new(rest_clients, 6, Duration::from_secs(10)),
```

**File:** crates/transaction-emitter-lib/src/emitter/transaction_executor.rs (L54-159)
```rust
    async fn submit_check_and_retry(
        &self,
        txn: &SignedTransaction,
        counters: &CounterState,
        run_seed: u64,
    ) -> Result<()> {
        for i in 0..self.max_retries {
            sample!(
                SampleRate::Duration(Duration::from_secs(60)),
                debug!(
                    "Running reliable/retriable fetching, current state: {}",
                    counters.show_detailed()
                )
            );

            // All transactions from the same sender, need to be submitted to the same client
            // in the same retry round, so that they are not placed in parking lot.
            // Do so by selecting a client via seeded random selection.
            let seed = [
                i.to_le_bytes().to_vec(),
                run_seed.to_le_bytes().to_vec(),
                txn.sender().to_vec(),
            ]
            .concat();
            let mut seeded_rng = StdRng::from_seed(*aptos_crypto::HashValue::sha3_256_of(&seed));
            let rest_client = self.random_rest_client_from_rng(&mut seeded_rng);
            let mut failed_submit = false;
            let mut failed_wait = false;
            let result = submit_and_check(
                rest_client,
                txn,
                self.retry_after,
                i == 0,
                &mut failed_submit,
                &mut failed_wait,
            )
            .await;

            if failed_submit {
                counters.submit_failures[i.min(counters.submit_failures.len() - 1)]
                    .fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                if !counters.by_client.is_empty() {
                    counters
                        .by_client
                        .get(&rest_client.path_prefix_string())
                        .map(|(_, submit_failures, _)| {
                            submit_failures.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                        });
                }
            }
            if failed_wait {
                counters.wait_failures[i.min(counters.wait_failures.len() - 1)]
                    .fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                if !counters.by_client.is_empty() {
                    counters
                        .by_client
                        .get(&rest_client.path_prefix_string())
                        .map(|(_, _, wait_failures)| {
                            wait_failures.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                        });
                }
            }

            match result {
                Ok(()) => {
                    counters
                        .successes
                        .fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                    if !counters.by_client.is_empty() {
                        counters
                            .by_client
                            .get(&rest_client.path_prefix_string())
                            .map(|(successes, _, _)| {
                                successes.fetch_add(1, std::sync::atomic::Ordering::Relaxed)
                            });
                    }
                    return Ok(());
                },
                Err(err) => {
                    // TODO: we should have a better way to decide if a failure is retryable
                    if format!("{}", err).contains("SEQUENCE_NUMBER_TOO_OLD") {
                        break;
                    }
                },
            }
        }

        // if submission timeouts, it might still get committed:
        let onchain_info = self
            .random_rest_client()
            .wait_for_signed_transaction_bcs(txn)
            .await?
            .into_inner()
            .info;
        if !onchain_info.status().is_success() {
            anyhow::bail!(
                "Transaction failed execution with {:?}",
                onchain_info.status()
            );
        }

        counters
            .successes
            .fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        Ok(())
    }
```

**File:** crates/transaction-emitter-lib/src/emitter/transaction_executor.rs (L325-348)
```rust
    async fn execute_transactions_with_counter(
        &self,
        txns: &[SignedTransaction],
        counters: &CounterState,
    ) -> Result<()> {
        let run_seed: u64 = thread_rng().r#gen();

        join_all(
            txns.iter()
                .map(|txn| self.submit_check_and_retry(txn, counters, run_seed)),
        )
        .await
        .into_iter()
        .collect::<Result<Vec<()>, anyhow::Error>>()
        .with_context(|| {
            format!(
                "Tried executing {} txns, request counters: {:?}",
                txns.len(),
                counters.show_detailed()
            )
        })?;

        Ok(())
    }
```

**File:** crates/transaction-emitter-lib/src/emitter/account_minter.rs (L471-509)
```rust
async fn create_and_fund_new_accounts(
    source_account: Arc<LocalAccount>,
    accounts: Vec<Arc<LocalAccount>>,
    coins_per_new_account: u64,
    max_num_accounts_per_batch: usize,
    txn_executor: &dyn ReliableTransactionSubmitter,
    txn_factory: &TransactionFactory,
    counters: &CounterState,
) -> Result<()> {
    let accounts_by_batch = accounts
        .chunks(max_num_accounts_per_batch)
        .map(|chunk| chunk.to_vec())
        .collect::<Vec<_>>();
    let source_address = source_account.address();
    for (batch_index, batch) in accounts_by_batch.into_iter().enumerate() {
        let creation_requests: Vec<_> = batch
            .iter()
            .map(|account| {
                create_and_fund_account_request(
                    source_account.clone(),
                    coins_per_new_account,
                    account.address(),
                    txn_factory,
                )
            })
            .collect();

        txn_executor
            .execute_transactions_with_counter(&creation_requests, counters)
            .await
            .with_context(|| {
                format!(
                    "Account {} couldn't mint batch {}",
                    source_address, batch_index
                )
            })?;
    }
    Ok(())
}
```
