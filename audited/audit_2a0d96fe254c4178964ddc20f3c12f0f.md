# Audit Report

## Title
Premature Garbage Collection of Notification Mappings Allows Malicious Peers to Evade Reputation System

## Summary
The `garbage_collect_notification_response_map()` function removes notification ID mappings when the map exceeds `max_notification_id_mappings` (default: 300). When clients process notifications slowly (e.g., during complex proof verification), they may attempt to provide feedback for notifications whose mappings have already been garbage collected. This causes `handle_notification_feedback()` to fail silently, preventing malicious peers from being penalized through the peer reputation system. [1](#0-0) 

## Finding Description

The data streaming service maintains a mapping between notification IDs and response contexts in `notifications_to_responses`. This mapping is critical for the peer reputation system because it allows the service to identify which peer sent bad data when feedback is received. [2](#0-1) 

When a notification is sent to a client, the notification ID and response context are inserted into this map: [3](#0-2) 

The garbage collection function removes the oldest entries when the map size exceeds the configured limit: [4](#0-3) 

When feedback is provided, the system looks up the notification ID in the map to retrieve the response context and penalize the responsible peer: [5](#0-4) 

If the notification ID is not found (because it was garbage collected), the function returns an error and the peer is never penalized: [6](#0-5) 

The peer reputation system relies on `notify_bad_response()` to decrease malicious peer scores: [7](#0-6) 

**Attack Scenario:**
1. Malicious peer sends invalid data (e.g., incorrect proof) in notification #1-#50
2. Client receives these notifications but verification is slow (cryptographic proof checking, state application)
3. Stream continues sending valid notifications #51-#350 to avoid immediate detection
4. Garbage collection triggers at notification #301, removing mappings for notifications #1-#50
5. Client finishes verifying notifications #1-#50, detects they are invalid
6. Client terminates stream with feedback for notification #1
7. `handle_notification_feedback()` fails: "Response context missing for notification ID: 1"
8. Malicious peer's score is not decreased, avoids being banned
9. Attacker can repeat this pattern to continuously serve bad data without punishment

## Impact Explanation

This vulnerability breaks the **peer reputation system**, a critical security mechanism for maintaining network health in Aptos state synchronization. The impact includes:

1. **Malicious Peer Persistence**: Attackers can systematically evade punishment by exploiting the garbage collection window, allowing them to remain in the network despite serving invalid data
2. **Resource Exhaustion**: Honest nodes waste CPU/memory verifying invalid proofs and data that cannot be reported
3. **State Sync Degradation**: Without effective peer reputation, the network's ability to identify and deprioritize bad peers is compromised
4. **Denial of Service Vector**: An attacker could slow down state synchronization across the network by flooding it with invalid data that cannot be properly reported

This qualifies as **High Severity** per the Aptos bug bounty program as it constitutes a "significant protocol violation" - the peer reputation system is a core security protocol for network health. [8](#0-7) 

## Likelihood Explanation

This vulnerability is **highly likely** to be exploitable in real-world scenarios:

1. **Common Conditions**: During initial synchronization or catching up from behind, nodes frequently receive hundreds of notifications rapidly while performing computationally expensive verification
2. **Low Attacker Requirements**: Any peer can send invalid data; no special privileges required
3. **Configuration Makes Exploitation Easier**: Default `max_notification_id_mappings` of 300 is relatively small compared to typical sync workloads
4. **No Rate Limiting**: The streaming service doesn't rate-limit notification generation, making it easy to exceed 300 notifications before early ones are verified [9](#0-8) 

## Recommendation

**Solution 1: Defer Garbage Collection Until Feedback Window Expires**

Modify `garbage_collect_notification_response_map()` to only remove entries that are both old (based on age) AND exceed the limit:

```rust
fn garbage_collect_notification_response_map(&mut self) -> Result<(), Error> {
    let max_notification_id_mappings = self.streaming_service_config.max_notification_id_mappings;
    let max_notification_age_ms = 60_000; // 60 seconds
    let current_time = self.time_service.now();
    
    // First, remove expired entries
    let mut expired_keys = vec![];
    for (notification_id, response_context) in &self.notifications_to_responses {
        let age_ms = current_time.duration_since(response_context.creation_time).as_millis();
        if age_ms > max_notification_age_ms as u128 {
            expired_keys.push(*notification_id);
        }
    }
    for key in &expired_keys {
        self.notifications_to_responses.remove(key);
    }
    
    // Then, if still over limit, remove oldest
    let map_length = self.notifications_to_responses.len() as u64;
    if map_length > max_notification_id_mappings {
        // ... existing logic ...
    }
    Ok(())
}
```

**Solution 2: Increase Default Limit**

Increase `max_notification_id_mappings` to a much larger value (e.g., 10,000) to make exploitation impractical while maintaining memory bounds.

**Solution 3: Store Minimal Context for Expired Entries**

Keep a lightweight cache of recently garbage-collected notification IDs mapped to peer identifiers only, allowing delayed feedback to still penalize the correct peer. [10](#0-9) 

## Proof of Concept

```rust
#[tokio::test]
async fn test_garbage_collection_prevents_peer_penalization() {
    use crate::tests::utils::MockAptosDataClient;
    use aptos_config::config::{AptosDataClientConfig, DataStreamingServiceConfig};
    
    // Create config with small notification limit to trigger GC quickly
    let mut streaming_config = DataStreamingServiceConfig::default();
    streaming_config.max_notification_id_mappings = 10; // Small limit for testing
    
    // Create a data stream
    let (mut data_stream, mut stream_listener) = create_transaction_stream(
        AptosDataClientConfig::default(),
        streaming_config,
        0,
        1000,
    );
    
    // Initialize and send enough notifications to trigger garbage collection
    let global_data_summary = create_global_data_summary(1);
    initialize_data_requests(&mut data_stream, &global_data_summary);
    
    let mut first_notification_id = None;
    let mut notifications_sent = 0;
    
    // Send 15 notifications (exceeds limit of 10)
    while notifications_sent < 15 {
        set_transaction_response_at_queue_head(&mut data_stream);
        process_data_responses(&mut data_stream, &global_data_summary).await;
        
        if let Ok(notification) = timeout(Duration::from_millis(100), stream_listener.next()).await {
            if let Some(notification) = notification {
                if first_notification_id.is_none() {
                    first_notification_id = Some(notification.notification_id);
                }
                notifications_sent += 1;
            }
        }
    }
    
    // Verify garbage collection occurred
    let (_, sent_notifications) = data_stream.get_sent_requests_and_notifications();
    assert!(sent_notifications.len() <= 10);
    
    // Try to provide feedback for the first notification (should be garbage collected)
    let first_id = first_notification_id.unwrap();
    let result = data_stream.handle_notification_feedback(
        &first_id,
        &NotificationFeedback::InvalidPayloadData,
    );
    
    // This should fail with "Response context missing"
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Response context missing"));
    
    // The malicious peer is NOT penalized because notify_bad_response was never called
}
```

## Notes

While true notification ID reuse (same ID assigned to different notifications) requires u64 overflow and is unrealistic, the premature garbage collection issue is a **real, exploitable vulnerability** that undermines the peer reputation system's security guarantees. [11](#0-10)

### Citations

**File:** state-sync/data-streaming-service/src/data_stream.rs (L96-96)
```rust
    notifications_to_responses: BTreeMap<NotificationId, ResponseContext>,
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L250-263)
```rust
        let response_context = self
            .notifications_to_responses
            .get(notification_id)
            .ok_or_else(|| {
                Error::UnexpectedErrorEncountered(format!(
                    "Response context missing for notification ID: {:?}",
                    notification_id
                ))
            })?;
        let response_error = extract_response_error(notification_feedback)?;
        self.notify_bad_response(response_context, response_error);

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L746-764)
```rust
    /// Notifies the Aptos data client of a bad client response
    fn notify_bad_response(
        &self,
        response_context: &ResponseContext,
        response_error: ResponseError,
    ) {
        let response_id = response_context.id;
        info!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .message(&format!(
                "Notifying the data client of a bad response. Response id: {:?}, error: {:?}",
                response_id, response_error
            )));

        response_context
            .response_callback
            .notify_bad_response(response_error);
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L792-793)
```rust
            self.insert_notification_response_mapping(notification_id, response_context)?;

```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L813-831)
```rust
    fn insert_notification_response_mapping(
        &mut self,
        notification_id: NotificationId,
        response_context: ResponseContext,
    ) -> Result<(), Error> {
        if let Some(response_context) = self
            .notifications_to_responses
            .insert(notification_id, response_context)
        {
            Err(Error::UnexpectedErrorEncountered(format!(
                "Duplicate sent notification ID found! \
                 Notification ID: {:?}, \
                 previous Response context: {:?}",
                notification_id, response_context
            )))
        } else {
            self.garbage_collect_notification_response_map()
        }
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L833-862)
```rust
    fn garbage_collect_notification_response_map(&mut self) -> Result<(), Error> {
        let max_notification_id_mappings =
            self.streaming_service_config.max_notification_id_mappings;
        let map_length = self.notifications_to_responses.len() as u64;
        if map_length > max_notification_id_mappings {
            let num_entries_to_remove = map_length
                .checked_sub(max_notification_id_mappings)
                .ok_or_else(|| {
                    Error::IntegerOverflow("Number of entries to remove has overflown!".into())
                })?;

            // Collect all the keys that need to removed. Note: BTreeMap keys
            // are sorted, so we'll remove the lowest notification IDs. These
            // will be the oldest notifications.
            let mut all_keys = self.notifications_to_responses.keys();
            let mut keys_to_remove = vec![];
            for _ in 0..num_entries_to_remove {
                if let Some(key_to_remove) = all_keys.next() {
                    keys_to_remove.push(*key_to_remove);
                }
            }

            // Remove the keys
            for key_to_remove in &keys_to_remove {
                self.notifications_to_responses.remove(key_to_remove);
            }
        }

        Ok(())
    }
```

**File:** config/src/config/state_sync_config.rs (L241-244)
```rust
    /// Maximum number of notification ID to response context mappings held in
    /// memory. Once the number grows beyond this value, garbage collection occurs.
    pub max_notification_id_mappings: u64,

```

**File:** config/src/config/state_sync_config.rs (L265-280)
```rust
impl Default for DataStreamingServiceConfig {
    fn default() -> Self {
        Self {
            dynamic_prefetching: DynamicPrefetchingConfig::default(),
            enable_subscription_streaming: false,
            global_summary_refresh_interval_ms: 50,
            max_concurrent_requests: MAX_CONCURRENT_REQUESTS,
            max_concurrent_state_requests: MAX_CONCURRENT_STATE_REQUESTS,
            max_data_stream_channel_sizes: 50,
            max_notification_id_mappings: 300,
            max_num_consecutive_subscriptions: 45, // At ~3 blocks per second, this should last ~15 seconds
            max_pending_requests: 50,
            max_request_retry: 5,
            max_subscription_stream_lag_secs: 10, // 10 seconds
            progress_check_interval_ms: 50,
        }
```

**File:** state-sync/aptos-data-client/src/interface.rs (L210-230)
```rust
#[derive(Debug)]
pub struct ResponseContext {
    /// The time at which this response context was created
    pub creation_time: Instant,
    /// A unique identifier for this request/response pair. Intended mostly for
    /// debugging.
    pub id: ResponseId,
    /// A callback for notifying the data-client source about an error with this
    /// response.
    pub response_callback: Box<dyn ResponseCallback>,
}

impl ResponseContext {
    pub fn new(id: ResponseId, response_callback: Box<dyn ResponseCallback>) -> Self {
        Self {
            creation_time: Instant::now(),
            id,
            response_callback,
        }
    }
}
```

**File:** crates/aptos-id-generator/src/lib.rs (L71-77)
```rust
impl IdGenerator<u64> for U64IdGenerator {
    /// Retrieves the next ID, wrapping on overflow
    #[inline]
    fn next(&self) -> u64 {
        self.inner.fetch_add(1, Ordering::Relaxed)
    }
}
```
