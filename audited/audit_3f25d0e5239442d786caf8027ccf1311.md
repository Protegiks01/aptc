# Audit Report

## Title
Database Schema Mismatch Causes Incomplete Deletion of V2 Batches Leading to Unbounded Database Growth

## Summary
The `update_certified_timestamp` method in the batch store only deletes expired batches from the V1 database schema, failing to delete V2 batches from the separate V2 column family. When `enable_batch_v2` configuration is enabled, this causes permanent accumulation of expired V2 batches, leading to unbounded storage growth and validator node performance degradation.

## Finding Description
The Aptos consensus layer uses a QuorumStore to manage transaction batches with two separate database schemas stored in distinct column families:
- V1: `BatchSchema` using "batch" column family storing `PersistedValue<BatchInfo>`
- V2: `BatchV2Schema` using "batch_v2" column family storing `PersistedValue<BatchInfoExt>` [1](#0-0) [2](#0-1) 

On every block commit, the payload manager calls `update_certified_timestamp` on the batch reader: [3](#0-2) 

This method clears expired batches from the in-memory cache via `clear_expired_payload`, then attempts to delete them from the database: [4](#0-3) 

**The Critical Bug**: Line 536 calls `self.db.delete_batches(expired_keys)`, which only deletes from the V1 "batch" column family: [5](#0-4) 

However, when V2 batches are enabled via the `enable_batch_v2` configuration flag, batches are stored in the separate "batch_v2" column family: [6](#0-5) 

The V2 deletion method `delete_batches_v2` exists but is never called during normal operation cleanup: [7](#0-6) 

**Execution Flow**:
1. Block commits trigger `notify_commit` â†’ `update_certified_timestamp`
2. `clear_expired_payload` removes expired V2 batches from in-memory cache
3. `delete_batches` deletes only from V1 "batch" column family
4. V2 batches remain permanently in "batch_v2" column family
5. Process repeats every block commit, accumulating undeletable V2 batches

**Invariant Violations**:
- Storage management invariant: expired batches must be completely removed from persistent storage
- Resource bounds invariant: database growth must be bounded by cleanup mechanisms

## Impact Explanation
This qualifies as **High Severity** under Aptos bug bounty criteria for "Validator Node Slowdowns":

**Unbounded Storage Growth**: V2 batches accumulate permanently without any cleanup mechanism, causing:
- Continuous database size increase proportional to consensus activity
- Increased disk I/O overhead during database operations
- Slower node restart times as cache repopulation must read all accumulated batches

**Performance Degradation**: The `populate_cache_and_gc_expired_batches_v2` method loads ALL V2 batches from storage on restart: [8](#0-7) 

Expired V2 batches that should have been deleted will be unnecessarily processed, causing:
- Memory pressure from loading expired batches
- CPU overhead from expiration checking
- Quota management inconsistencies

**Consensus Participation Impact**: Validator slowdowns affect consensus performance, block processing times, and network health.

## Likelihood Explanation
**Likelihood: High (conditional on configuration)**

The vulnerability triggers automatically and continuously when `enable_batch_v2` is enabled:
- Frequency: Every block commit (multiple times per second)
- Accumulation: Permanent, with no cleanup mechanism
- Impact Growth: Linear with consensus activity over time

The `enable_batch_v2` configuration flag is a supported production feature: [9](#0-8) [10](#0-9) 

While currently disabled by default, this is a legitimate operational configuration that validator operators may enable. The bug represents a logic error in the codebase that breaks a core feature.

## Recommendation
Modify `update_certified_timestamp` to delete from both V1 and V2 schemas based on batch type:

```rust
pub fn update_certified_timestamp(&self, certified_time: u64) {
    trace!("QS: batch reader updating time {:?}", certified_time);
    self.last_certified_time
        .fetch_max(certified_time, Ordering::SeqCst);

    let expired_keys = self.clear_expired_payload(certified_time);
    
    // Separate expired keys by batch version
    let (v1_keys, v2_keys): (Vec<_>, Vec<_>) = expired_keys.into_iter()
        .partition(|key| {
            self.db_cache.get(key)
                .map(|v| !v.batch_info().is_v2())
                .unwrap_or(true)
        });
    
    // Delete from appropriate schemas
    if !v1_keys.is_empty() {
        if let Err(e) = self.db.delete_batches(v1_keys) {
            debug!("Error deleting V1 batches: {:?}", e)
        }
    }
    
    if !v2_keys.is_empty() {
        if let Err(e) = self.db.delete_batches_v2(v2_keys) {
            debug!("Error deleting V2 batches: {:?}", e)
        }
    }
}
```

Alternatively, track batch versions separately in the cache to avoid lookup overhead.

**Additional Fix Required**: Line 241 in `gc_previous_epoch_batches_from_db_v2` has the same bug and should call `delete_batches_v2` instead of `delete_batches`.

## Proof of Concept
This vulnerability can be demonstrated by:

1. Enabling V2 batches in node configuration:
```toml
[consensus.quorum_store_config]
enable_batch_v2 = true
```

2. Running the validator node normally, allowing blocks to commit

3. Monitoring database growth over time:
```bash
# Check batch_v2 column family size
du -sh /path/to/quorumstoreDB/batch_v2/
```

4. Verifying V2 batches accumulate without deletion by checking batch count after expiration time passes:
```rust
#[test]
fn test_v2_batch_deletion_bug() {
    let db = Arc::new(QuorumStoreDB::new(temp_dir));
    let batch_store = BatchStore::new(/*enable v2*/);
    
    // Create and persist V2 batch
    let batch_v2 = create_test_batch_v2(expiration_time);
    batch_store.save(&batch_v2);
    
    // Advance time past expiration
    batch_store.update_certified_timestamp(expiration_time + 1000);
    
    // Bug: V2 batch still exists in database
    assert!(db.get_batch_v2(&batch_v2.digest()).unwrap().is_some());
    // Expected: should be None after deletion
}
```

The test demonstrates that V2 batches persist in the database even after `update_certified_timestamp` is called with a timestamp beyond their expiration time.

## Notes
There is an additional instance of the same bug at line 241 where `gc_previous_epoch_batches_from_db_v2` calls `delete_batches` instead of `delete_batches_v2`, though this affects only epoch transitions rather than continuous operation.

### Citations

**File:** consensus/src/quorum_store/schema.rs (L14-26)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";

#[derive(Debug)]
pub(crate) struct BatchSchema;

impl Schema for BatchSchema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfo>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_CF_NAME;
}
```

**File:** consensus/src/quorum_store/schema.rs (L48-56)
```rust
#[derive(Debug)]
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L168-170)
```rust
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>) {
        self.batch_reader
            .update_certified_timestamp(block_timestamp);
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L488-513)
```rust
    fn persist_inner(
        &self,
        batch_info: BatchInfoExt,
        persist_request: PersistedValue<BatchInfoExt>,
    ) -> Option<SignedBatchInfo<BatchInfoExt>> {
        assert!(
            &batch_info == persist_request.batch_info(),
            "Provided batch info doesn't match persist request batch info"
        );
        match self.save(&persist_request) {
            Ok(needs_db) => {
                trace!("QS: sign digest {}", persist_request.digest());
                if needs_db {
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-539)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L93-101)
```rust
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L123-131)
```rust
    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** config/src/config/quorum_store_config.rs (L102-103)
```rust
    pub enable_batch_v2: bool,
}
```

**File:** config/src/config/quorum_store_config.rs (L144-144)
```rust
            enable_batch_v2: false,
```
