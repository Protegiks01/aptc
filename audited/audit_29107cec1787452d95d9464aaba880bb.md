# Audit Report

## Title
Consensus Split Vulnerability Due to Non-Deterministic Trace Replay Configuration

## Summary
The `async_runtime_checks` configuration flag is a per-node setting that enables/disables trace replay validation during block execution. Validators with different configurations will diverge when trace replay fails, causing an irrecoverable chain split where some validators accept a block while others reject it.

## Finding Description

The Aptos block executor implements an optional "async runtime checks" feature that performs trace replay to validate type safety after transaction execution. However, this feature has a critical design flaw that violates the fundamental consensus invariant that all validators must produce identical results for identical blocks.

**The core issue:**

The `async_runtime_checks` flag is configured per-node in the execution configuration [1](#0-0) , with a default value of `false` [2](#0-1) . This flag is set from the node configuration during initialization [3](#0-2) , and stored in a global static variable [4](#0-3)  that can differ between validators.

When a validator has `async_runtime_checks: true`, the block executor performs trace replay during the `materialize_txn_commit` phase [5](#0-4) . If trace replay fails, the validator returns a `PanicError::CodeInvariantError` [6](#0-5) , causing block execution to fail.

However, validators with `async_runtime_checks: false` skip trace replay entirely and will successfully execute the same block. This creates a consensus split where:

1. Validators with async checks **enabled** reject the block (trace replay failure)
2. Validators with async checks **disabled** accept the block (no trace replay performed)

The flag is read from the Environment during block execution [7](#0-6) , which gets it from the global configuration [8](#0-7) .

**Attack scenario:**

An attacker can craft a transaction that:
- Executes successfully in the Move VM
- Produces a valid state transition  
- But triggers a bug or edge case in the TypeChecker replay logic

This transaction will cause validators with async checks to reject the block, while validators without async checks accept it, resulting in a permanent chain fork.

## Impact Explanation

This is **Critical Severity** per the Aptos bug bounty criteria:

1. **Consensus/Safety Violation**: Breaks the fundamental invariant that all validators must produce identical state roots for identical blocks. Different validators will commit different blocks based solely on their local configuration.

2. **Non-Recoverable Network Partition**: Once the chain splits, it cannot recover automatically. The network fragments into two incompatible chains, requiring manual intervention or a hard fork to resolve.

3. **Affects All Validators**: Any validator with a configuration different from the majority will diverge from the canonical chain, potentially affecting a significant portion of the network.

4. **Easily Triggered**: The vulnerability doesn't require Byzantine validators or insider access - just configuration mismatches that are explicitly allowed by the system design.

The metric `TRACE_REPLAY_SECONDS` tracks this operation [9](#0-8) , confirming that trace replay is a post-commit validation step that can fail asynchronously.

## Likelihood Explanation

**High Likelihood:**

1. **Configuration Mismatch is Expected**: The per-node configuration explicitly allows validators to have different settings, with no consensus-level enforcement.

2. **Default is Disabled**: With the default being `false`, many validators will not enable this feature, creating a natural configuration split.

3. **No Safeguards**: There are no checks to ensure all validators have matching configurations, no warnings when configurations differ, and no consensus-level validation of this setting.

4. **Silent Divergence**: When a validator crashes during trace replay or encounters a replay error, it silently rejects the block while others accept it. The error is only logged locally [10](#0-9) .

5. **Bug in Type Checker**: Any bug or edge case in the trace replay TypeChecker implementation would trigger this vulnerability across all validators with async checks enabled.

## Recommendation

**Immediate Fix:**

Make `async_runtime_checks` a consensus parameter stored on-chain rather than a per-node configuration. All validators must use the same value determined by on-chain governance.

**Implementation:**

1. Add `async_runtime_checks` to the `Features` on-chain configuration
2. Remove it from the per-node `ExecutionConfig`
3. Read the value from on-chain state during Environment initialization
4. Ensure the value is part of the environment hash so different configurations create different environments

**Code changes needed:**

In `aptos-move/aptos-vm-environment/src/environment.rs`, replace the global config read with an on-chain feature flag check:

```rust
// Instead of: async_runtime_checks_enabled: get_async_runtime_checks(),
// Use on-chain feature flag:
async_runtime_checks_enabled: features.is_async_runtime_checks_enabled(),
```

Add the feature flag to `aptos-types/src/on_chain_config/aptos_features.rs` and ensure it's properly gated through governance.

**Alternative Mitigation:**

If async runtime checks must remain optional, ensure they are used only for monitoring/alerting and never cause execution to fail. Convert trace replay failures to warnings logged to metrics rather than returning errors that cause block rejection.

## Proof of Concept

**Setup:**

1. Configure Validator A with `async_runtime_checks: true`
2. Configure Validator B with `async_runtime_checks: false`

**Trigger Transaction:**

Submit a Move transaction that causes the TypeChecker to fail during trace replay (e.g., exploiting a bug in type checking, resource exhaustion, or edge case in bytecode interpretation).

**Expected Result:**

- Validator A: Block execution fails with `PanicError::CodeInvariantError` during trace replay, block rejected
- Validator B: Block execution succeeds (no trace replay), block accepted
- Network: Chain split occurs - two incompatible blockchain states

**Verification:**

Monitor the `TRACE_REPLAY_SECONDS` metric on both validators and check block commitment status. Validator A will show trace replay attempts and subsequent failures, while Validator B will show no trace replay activity and successful block commits.

## Notes

The trace replay mechanism was designed as an optimization to defer paranoid type checks from speculative execution to post-commit time [11](#0-10) . However, by making it a per-node configuration that can cause execution failures, it became a consensus-breaking feature.

The vulnerability is particularly insidious because the feature is described as "async" checks, suggesting they are informational or monitoring-only, when in fact they are mandatory validation steps that cause execution to fail if enabled.

### Citations

**File:** config/src/config/execution_config.rs (L59-59)
```rust
    pub async_runtime_checks: bool,
```

**File:** config/src/config/execution_config.rs (L94-94)
```rust
            async_runtime_checks: false,
```

**File:** aptos-node/src/utils.rs (L56-56)
```rust
    set_async_runtime_checks(node_config.execution.async_runtime_checks);
```

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L30-35)
```rust
/// Controls when additional checks (such as paranoid type checks) are performed. If set to true,
/// the trace may be collected during execution and Block-STM may perform the checks during post
/// commit processing once (instead of for every speculative execution). Note that there are other
/// factors that influence if checks are done async, such as block size, available workers, etc. If
/// not set - always performs the checks in-place at runtime.
static ASYNC_RUNTIME_CHECKS: OnceCell<bool> = OnceCell::new();
```

**File:** aptos-move/block-executor/src/executor.rs (L1234-1241)
```rust
        if environment.async_runtime_checks_enabled() && !trace.is_empty() {
            // Note that the trace may be empty (if block was small and executor decides not to
            // collect the trace and replay, or if the VM decides it is not profitable to do this
            // check for this particular transaction), so we check it in advance.
            let result = {
                counters::update_txn_trace_counters(&trace);
                let _timer = TRACE_REPLAY_SECONDS.start_timer();
                TypeChecker::new(&latest_view).replay(&trace)
```

**File:** aptos-move/block-executor/src/executor.rs (L1247-1257)
```rust
            if let Err(err) = result {
                alert!(
                    "Runtime type check failed during replay of transaction {}: {:?}",
                    txn_idx,
                    err
                );
                return Err(PanicError::CodeInvariantError(format!(
                    "Sequential fallback on type check failure for transaction {}: {:?}",
                    txn_idx, err
                )));
            }
```

**File:** aptos-move/aptos-vm-environment/src/environment.rs (L141-143)
```rust
    pub fn async_runtime_checks_enabled(&self) -> bool {
        self.0.async_runtime_checks_enabled
    }
```

**File:** aptos-move/aptos-vm-environment/src/environment.rs (L316-316)
```rust
            async_runtime_checks_enabled: get_async_runtime_checks(),
```

**File:** aptos-move/block-executor/src/counters.rs (L172-181)
```rust
pub static TRACE_REPLAY_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    register_histogram!(
        // metric name
        "user_txn_trace_replay_seconds",
        // metric description
        "The time spent when replaying trace for async paranoid checks",
        time_buckets(),
    )
    .unwrap()
});
```
