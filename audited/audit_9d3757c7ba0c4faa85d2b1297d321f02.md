# Audit Report

## Title
Unbounded Memory Exhaustion in BatchGenerator TimeExpirations Heap Enables Validator DoS

## Summary
The `TimeExpirations::add_item()` function in `consensus/src/quorum_store/utils.rs` has no bound on the `BinaryHeap` size. Malicious validators can exploit this by sending batches with unique batch IDs faster than they expire, causing unbounded heap growth that exhausts memory, crashes validators, and can trigger network partition.

## Finding Description

The vulnerability exists in the quorum store batch handling system where remote batches from validators are tracked in an unbounded `BinaryHeap`. [1](#0-0) 

The `TimeExpirations` structure uses a `BinaryHeap` to track expiration times, and the `add_item()` method simply pushes entries without any capacity check or size limit.

When a validator receives batches from remote peers, the processing flow is:

1. **Network Reception**: `BatchCoordinator::handle_batches_msg()` receives batches from the network [2](#0-1) 

2. **Command Forwarding**: Each batch is sent to `BatchGenerator` via `RemoteBatch` command BEFORE quota validation [3](#0-2) 

Note the TODO comment at line 230 acknowledging this ordering issue.

3. **Heap Insertion**: `BatchGenerator::insert_batch()` adds entries to `batch_expirations` heap [4](#0-3) 

The entry is added to the heap at line 169-170 regardless of whether subsequent persistence succeeds.

4. **Expiration Based on Block Commits**: Entries are only removed when blocks are certified [5](#0-4) 

The critical issue is that expiration depends on `block_timestamp` from committed blocks. If the network experiences consensus delays or liveness issues, batches accumulate in the heap without being cleaned up.

**Attack Vector**:
- A malicious validator (Byzantine actor within the threat model) sends batches with unique `batch_id` values
- Each batch with a unique ID bypasses the duplicate check at line 130-132
- Default batch quota limits (300,000 per peer) apply to `BatchStore` persistence, NOT to the `batch_expirations` heap [6](#0-5) 

- With remote batch expiry of 500ms but potential block delays of 5-10+ seconds during network stress, the accumulation window increases 10-20x
- Multiple colluding Byzantine validators can amplify the attack

**Memory Calculation**:
- Each heap entry: ~56 bytes (32-byte `PeerId` + 8-byte `BatchId` + heap overhead)
- To exhaust 1GB: ~18 million entries
- With 10 Byzantine validators sending 1,000 batches/sec each during a 30-minute liveness failure: 10 × 1,000 × 1,800 = 18 million entries ✓

## Impact Explanation

This vulnerability has **HIGH severity** impact:

1. **Validator Node Crash**: Memory exhaustion causes OOM crashes, taking validators offline
2. **Network Partition Risk**: If multiple validators crash simultaneously, the network may lose liveness or safety (< 2/3 honest validators)
3. **Resource Limits Violation**: Breaks invariant #9 requiring operations to respect memory constraints
4. **Availability Impact**: Aligns with "Validator node slowdowns" and "Significant protocol violations" in HIGH severity category

While not reaching CRITICAL (which requires permanent network damage), this enables a practical DoS attack during network stress.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

**Attacker Requirements**:
- Must be a validator (Byzantine actor within 1/3 fault tolerance model) ✓
- Can generate unique batch IDs at will ✓
- Needs network delays or liveness issues to amplify effect ✓

**Realistic Scenarios**:
- Network congestion naturally delays block commits (common in high-load periods)
- Consensus delays from slow validators or network partitions
- Deliberate liveness attack combined with memory exhaustion

**Ease of Exploitation**:
- Simple to implement: send batches with incrementing IDs
- No special privileges beyond being in validator set
- Amplified by multiple colluding validators

## Recommendation

Add a bounded capacity to `TimeExpirations` with configurable limits:

```rust
pub(crate) struct TimeExpirations<I: Ord> {
    expiries: BinaryHeap<(Reverse<u64>, I)>,
    max_capacity: usize,
}

impl<I: Ord + Hash> TimeExpirations<I> {
    pub(crate) fn new(max_capacity: usize) -> Self {
        Self {
            expiries: BinaryHeap::new(),
            max_capacity,
        }
    }

    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) -> Result<(), anyhow::Error> {
        if self.expiries.len() >= self.max_capacity {
            bail!("TimeExpirations capacity exceeded: {}", self.max_capacity);
        }
        self.expiries.push((Reverse(expiry_time), item));
        Ok(())
    }
}
```

Configure appropriate limits in `QuorumStoreConfig`:
```rust
pub struct QuorumStoreConfig {
    // ...
    pub max_batch_expirations_per_validator: usize, // e.g., 100,000
}
```

Additionally, consider:
1. Enforcing quota check BEFORE adding to `batch_expirations` (addressing the TODO at line 230)
2. Adding periodic cleanup based on wall-clock time as a backup to block-timestamp-based expiration
3. Implementing per-peer limits on pending batches

## Proof of Concept

```rust
// Rust test demonstrating heap growth
#[test]
fn test_unbounded_batch_expirations() {
    use crate::quorum_store::utils::TimeExpirations;
    use aptos_types::{PeerId, account_address::AccountAddress};
    
    let mut expirations = TimeExpirations::new();
    let peer_id = PeerId::from(AccountAddress::random());
    
    // Simulate malicious validator sending batches with unique IDs
    let num_batches = 1_000_000; // 1 million batches
    for i in 0..num_batches {
        let batch_id = i.into();
        let expiry = 1_000_000 + 500_000; // 500ms from now
        expirations.add_item((peer_id, batch_id), expiry);
    }
    
    // Heap now contains 1 million entries (~56 MB)
    // No bound prevents this from growing to GB levels
    // If blocks don't commit, expire() never removes entries
    
    // Simulate no block commits (liveness failure)
    let block_timestamp = 1_000_000; // Stays at old timestamp
    let expired = expirations.expire(block_timestamp);
    assert!(expired.is_empty()); // Nothing expires!
    
    // Memory grows unbounded until OOM crash
}
```

This vulnerability breaks the Resource Limits invariant and enables practical DoS attacks against validator nodes, warranting immediate remediation with bounded data structures and proper quota enforcement ordering.

### Citations

**File:** consensus/src/quorum_store/utils.rs (L60-73)
```rust
pub(crate) struct TimeExpirations<I: Ord> {
    expiries: BinaryHeap<(Reverse<u64>, I)>,
}

impl<I: Ord + Hash> TimeExpirations<I> {
    pub(crate) fn new() -> Self {
        Self {
            expiries: BinaryHeap::new(),
        }
    }

    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) {
        self.expiries.push((Reverse(expiry_time), item));
    }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L173-245)
```rust
    pub(crate) async fn handle_batches_msg(
        &mut self,
        author: PeerId,
        batches: Vec<Batch<BatchInfoExt>>,
    ) {
        if let Err(e) = self.ensure_max_limits(&batches) {
            error!("Batch from {}: {}", author, e);
            counters::RECEIVED_BATCH_MAX_LIMIT_FAILED.inc();
            return;
        }

        let Some(batch) = batches.first() else {
            error!("Empty batch received from {}", author.short_str().as_str());
            return;
        };

        // Filter the transactions in the batches. If any transaction is rejected,
        // the message will be dropped, and all batches will be rejected.
        if self.transaction_filter_config.is_enabled() {
            let transaction_filter = &self.transaction_filter_config.batch_transaction_filter();
            for batch in batches.iter() {
                for transaction in batch.txns() {
                    if !transaction_filter.allows_transaction(
                        batch.batch_info().batch_id(),
                        batch.author(),
                        batch.digest(),
                        transaction,
                    ) {
                        error!(
                            "Transaction {}, in batch {}, from {}, was rejected by the filter. Dropping {} batches!",
                            transaction.committed_hash(),
                            batch.batch_info().batch_id(),
                            author.short_str().as_str(),
                            batches.len()
                        );
                        counters::RECEIVED_BATCH_REJECTED_BY_FILTER.inc();
                        return;
                    }
                }
            }
        }

        let approx_created_ts_usecs = batch
            .info()
            .expiration()
            .saturating_sub(self.batch_expiry_gap_when_init_usecs);

        if approx_created_ts_usecs > 0 {
            observe_batch(
                approx_created_ts_usecs,
                batch.author(),
                BatchStage::RECEIVED,
            );
        }

        let mut persist_requests = vec![];
        for batch in batches.into_iter() {
            // TODO: maybe don't message batch generator if the persist is unsuccessful?
            if let Err(e) = self
                .sender_to_batch_generator
                .send(BatchGeneratorCommand::RemoteBatch(batch.clone()))
                .await
            {
                warn!("Failed to send batch to batch generator: {}", e);
            }
            persist_requests.push(batch.into());
        }
        counters::RECEIVED_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        if author != self.my_peer_id {
            counters::RECEIVED_REMOTE_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        }
        self.persist_and_send_digests(persist_requests, approx_created_ts_usecs);
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L123-171)
```rust
    fn insert_batch(
        &mut self,
        author: PeerId,
        batch_id: BatchId,
        txns: Vec<SignedTransaction>,
        expiry_time_usecs: u64,
    ) {
        if self.batches_in_progress.contains_key(&(author, batch_id)) {
            return;
        }

        let txns_in_progress: Vec<_> = txns
            .par_iter()
            .with_min_len(optimal_min_len(txns.len(), 32))
            .map(|txn| {
                (
                    TransactionSummary::new(
                        txn.sender(),
                        txn.replay_protector(),
                        txn.committed_hash(),
                    ),
                    TransactionInProgress::new(txn.gas_unit_price()),
                )
            })
            .collect();

        let mut txns = vec![];
        for (summary, info) in txns_in_progress {
            let txn_info = self
                .txns_in_progress_sorted
                .entry(summary)
                .or_insert_with(|| TransactionInProgress::new(info.gas_unit_price));
            txn_info.increment();
            txn_info.gas_unit_price = info.gas_unit_price.max(txn_info.gas_unit_price);
            txns.push(summary);
        }
        let updated_expiry_time_usecs = self
            .batches_in_progress
            .get(&(author, batch_id))
            .map_or(expiry_time_usecs, |batch_in_progress| {
                expiry_time_usecs.max(batch_in_progress.expiry_time_usecs)
            });
        self.batches_in_progress.insert(
            (author, batch_id),
            BatchInProgress::new(txns, updated_expiry_time_usecs),
        );
        self.batch_expirations
            .add_item((author, batch_id), updated_expiry_time_usecs);
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L534-552)
```rust
                            // Cleans up all batches that expire in timestamp <= block_timestamp. This is
                            // safe since clean request must occur only after execution result is certified.
                            for (author, batch_id) in self.batch_expirations.expire(block_timestamp) {
                                if let Some(batch_in_progress) = self.batches_in_progress.get(&(author, batch_id)) {
                                    // If there is an identical batch with higher expiry time, re-insert it.
                                    if batch_in_progress.expiry_time_usecs > block_timestamp {
                                        self.batch_expirations.add_item((author, batch_id), batch_in_progress.expiry_time_usecs);
                                        continue;
                                    }
                                }
                                if self.remove_batch_in_progress(author, batch_id) {
                                    counters::BATCH_IN_PROGRESS_EXPIRED.inc();
                                    debug!(
                                        "QS: logical time based expiration batch w. id {} from batches_in_progress, new size {}",
                                        batch_id,
                                        self.batches_in_progress.len(),
                                    );
                                }
                            }
```

**File:** config/src/config/quorum_store_config.rs (L132-135)
```rust
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
```
