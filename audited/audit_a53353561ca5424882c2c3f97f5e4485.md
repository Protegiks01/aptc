# Audit Report

## Title
API Contract Violation in bootstrap_indexer() Causes Silent Node Crashes on Indexer Failures

## Summary
The `bootstrap_indexer()` function returns `Result<Option<Runtime>>` suggesting it can report failures, but it always returns `Ok()` even when spawning a task that contains multiple `panic!()` calls. When these panics occur, the global panic handler crashes the entire node instead of allowing graceful degradation. The dropped JoinHandle prevents error detection or recovery.

## Finding Description

The API contract violation occurs across three levels:

**Level 1: Function Contract Violation**

The `bootstrap_indexer()` function in `aptos-node/src/indexer.rs` wraps the underlying `bootstrap()` function: [1](#0-0) 

The underlying implementation in `crates/indexer/src/runtime.rs` **always returns `Some(Ok(runtime))`** when the indexer is enabled, regardless of whether initialization will succeed: [2](#0-1) 

**Level 2: Silent Task Failure**

The spawned async task has multiple explicit `panic!()` calls that can trigger during normal operation:

1. Database connection pool creation failure: [3](#0-2) 

2. Tailer instantiation failure: [4](#0-3) 

3. Starting version retrieval failure: [5](#0-4) 

4. Transaction batch processing failure: [6](#0-5) 

5. Transaction commit errors: [7](#0-6) 

6. Database update failures: [8](#0-7) 

**Level 3: Whole-Node Crash**

The global panic handler installed during node startup converts any panic into a process exit: [9](#0-8) 

The crash handler implementation shows this exits the entire process: [10](#0-9) 

**Attack Scenario:**

When a node operator enables the indexer feature and the postgres database becomes unavailable (connection timeout, authentication failure, disk full, constraint violation, etc.), the sequence is:

1. `bootstrap_indexer()` returns `Ok(Some(runtime))` — caller assumes success
2. The spawned task attempts postgres connection and panics
3. Global panic handler catches it and calls `process::exit(12)`
4. **Entire node crashes** instead of just the indexer failing gracefully

The calling code in `services.rs` has no way to detect or prevent this: [11](#0-10) 

The runtime is stored in `AptosHandle` with other optional runtimes, but it's treated as successfully initialized: [12](#0-11) 

## Impact Explanation

**Severity: High** per Aptos Bug Bounty categories — "API crashes"

**Impact:**
- **Availability Loss**: When the indexer encounters any postgres error (connection failure, disk full, constraint violation), the entire node crashes rather than degrading gracefully
- **Silent Failures**: The `Ok()` return value masks impending failures, providing no opportunity for error handling
- **No Recovery Path**: The dropped JoinHandle prevents monitoring task health or implementing retry logic
- **Operational Disruption**: Node operators lose the ability to run nodes with indexer enabled if postgres has any issues

While the indexer itself only writes to an external postgres database (not blockchain state), the crash affects the entire node including consensus participation for validators, making this a **High severity availability issue**.

## Likelihood Explanation

**Likelihood: Medium to High**

**Triggering Conditions:**
- Postgres connection failures (network issues, authentication, misconfiguration)
- Database constraint violations (schema mismatches)
- Disk space exhaustion on postgres server
- Database corruption or migration failures
- Resource exhaustion (connection limits, memory)

These are **common operational scenarios** that occur regularly in production environments. The indexer feature is optional but when enabled, any postgres instability crashes the node.

**Attacker Influence:**
While external attackers cannot directly access postgres, the following scenarios enable exploitation:
- If postgres is exposed (misconfiguration), attackers could force connection failures
- Resource exhaustion attacks on postgres infrastructure
- In multi-tenant environments, other postgres users could cause constraint violations

## Recommendation

**Fix 1: Return JoinHandle for Monitoring**

Modify the function signature to return the JoinHandle, allowing callers to monitor task health:

```rust
pub fn bootstrap(
    config: &NodeConfig,
    chain_id: ChainId,
    db: Arc<dyn DbReader>,
    mp_sender: MempoolClientSender,
) -> Option<anyhow::Result<(Runtime, tokio::task::JoinHandle<()>)>> {
    if !config.indexer.enabled {
        return None;
    }

    let runtime = aptos_runtimes::spawn_named_runtime("indexer".into(), None);
    let indexer_config = config.indexer.clone();
    let node_config = config.clone();

    let handle = runtime.spawn(async move {
        let context = Arc::new(Context::new(chain_id, db, mp_sender, node_config, None));
        run_forever(indexer_config, context).await;
    });

    Some(Ok((runtime, handle)))
}
```

**Fix 2: Replace panic!() with Error Propagation**

Replace all `panic!()` calls with proper error handling that logs errors and allows graceful shutdown:

```rust
// Instead of:
let conn_pool = new_db_pool(db_uri).expect("Failed to create connection pool");

// Use:
let conn_pool = match new_db_pool(db_uri) {
    Ok(pool) => pool,
    Err(e) => {
        error!("Failed to create connection pool: {:?}. Indexer will not start.", e);
        return; // Exit task gracefully
    }
};
```

**Fix 3: Add Health Check Mechanism**

Implement a health check that the main node can query:

```rust
pub struct IndexerHealth {
    pub is_running: Arc<AtomicBool>,
    pub last_error: Arc<Mutex<Option<String>>>,
}
```

## Proof of Concept

**Reproduction Steps:**

1. Enable the indexer in node configuration:
```yaml
indexer:
  enabled: true
  postgres_uri: "postgresql://invalid_host:5432/indexer"
  processor: "default_processor"
```

2. Start the node with the configuration above

3. Observe the node startup sequence:
   - `bootstrap_indexer()` returns `Ok(Some(runtime))`
   - Node continues initialization, all services start successfully
   - The spawned indexer task attempts to connect to postgres
   - Connection fails, triggering `panic!` at line 124 of runtime.rs
   - Global panic handler catches it and calls `process::exit(12)`
   - **Entire node crashes** with exit code 12

**Expected Behavior:**
- `bootstrap_indexer()` should return `Err()` if postgres connection fails during initialization
- OR the task should handle postgres errors gracefully without panicking
- OR the panic should be caught and logged without crashing the entire node

**Actual Behavior:**
- Function returns `Ok()` suggesting success
- Task panics on postgres connection failure
- Entire node process exits with code 12

**Test Implementation:**

```rust
#[tokio::test]
async fn test_indexer_panic_crashes_node() {
    // This test demonstrates the vulnerability
    // Setup a node config with invalid postgres URI
    let mut config = NodeConfig::default();
    config.indexer.enabled = true;
    config.indexer.postgres_uri = Some("postgresql://invalid:5432/db".to_string());
    
    // Setup crash handler to catch the exit
    // (In real scenario, this would crash the entire process)
    
    // Call bootstrap_indexer
    let result = bootstrap_indexer(&config, ChainId::test(), Arc::new(MockDbReader), mock_sender());
    
    // Function returns Ok, suggesting success
    assert!(result.is_ok());
    assert!(result.unwrap().is_some());
    
    // But the spawned task will panic and crash the node
    // (Cannot be tested directly without allowing process exit)
}
```

## Notes

This vulnerability specifically affects nodes with `indexer.enabled = true` in their configuration. The indexer feature is **disabled by default** [13](#0-12) , which limits the scope to nodes that explicitly enable it.

However, for nodes running the indexer (common for infrastructure providers, block explorers, and analytics platforms), this represents a critical availability risk where postgres operational issues cascade into full node crashes rather than isolated indexer failures.

The root cause is the mismatch between the function's return type `Result<Option<Runtime>>` (suggesting failable initialization) and the actual behavior (always returning `Ok()` with a task containing deferred panics).

### Citations

**File:** aptos-node/src/indexer.rs (L12-24)
```rust
pub fn bootstrap_indexer(
    node_config: &NodeConfig,
    chain_id: ChainId,
    aptos_db: Arc<dyn DbReader>,
    mp_client_sender: MempoolClientSender,
) -> Result<Option<Runtime>, anyhow::Error> {
    use aptos_indexer::runtime::bootstrap as bootstrap_indexer_stream;

    match bootstrap_indexer_stream(&node_config, chain_id, aptos_db, mp_client_sender) {
        None => Ok(None),
        Some(res) => res.map(Some),
    }
}
```

**File:** crates/indexer/src/runtime.rs (L77-104)
```rust
pub fn bootstrap(
    config: &NodeConfig,
    chain_id: ChainId,
    db: Arc<dyn DbReader>,
    mp_sender: MempoolClientSender,
) -> Option<anyhow::Result<Runtime>> {
    if !config.indexer.enabled {
        return None;
    }

    let runtime = aptos_runtimes::spawn_named_runtime("indexer".into(), None);

    let indexer_config = config.indexer.clone();
    let node_config = config.clone();

    runtime.spawn(async move {
        let context = Arc::new(Context::new(
            chain_id,
            db,
            mp_sender,
            node_config,
            None, /* table info reader */
        ));
        run_forever(indexer_config, context).await;
    });

    Some(Ok(runtime))
}
```

**File:** crates/indexer/src/runtime.rs (L124-124)
```rust
    let conn_pool = new_db_pool(db_uri).expect("Failed to create connection pool");
```

**File:** crates/indexer/src/runtime.rs (L149-150)
```rust
    let tailer = Tailer::new(context, conn_pool.clone(), processor, options)
        .expect("Failed to instantiate tailer");
```

**File:** crates/indexer/src/runtime.rs (L163-165)
```rust
    let starting_version_from_db_short = tailer
        .get_start_version(&processor_name)
        .unwrap_or_else(|e| panic!("Failed to get starting version: {:?}", e))
```

**File:** crates/indexer/src/runtime.rs (L216-219)
```rust
        let batches = match futures::future::try_join_all(tasks).await {
            Ok(res) => res,
            Err(err) => panic!("Error processing transaction batches: {:?}", err),
        };
```

**File:** crates/indexer/src/runtime.rs (L230-243)
```rust
                Some(Err(tpe)) => {
                    let (err, start_version, end_version, _) = tpe.inner();
                    error!(
                        processor_name = processor_name,
                        start_version = start_version,
                        end_version = end_version,
                        error =? err,
                        "Error processing batch!"
                    );
                    panic!(
                        "Error in '{}' while processing batch: {:?}",
                        processor_name, err
                    );
                },
```

**File:** crates/indexer/src/runtime.rs (L251-261)
```rust
        tailer
            .update_last_processed_version(&processor_name, batch_end_version)
            .unwrap_or_else(|e| {
                error!(
                    processor_name = processor_name,
                    end_version = batch_end_version,
                    error = format!("{:?}", e),
                    "Failed to update last processed version!"
                );
                panic!("Failed to update last processed version: {:?}", e);
            });
```

**File:** aptos-node/src/lib.rs (L196-215)
```rust
/// Runtime handle to ensure that all inner runtimes stay in scope
pub struct AptosHandle {
    _admin_service: AdminService,
    _api_runtime: Option<Runtime>,
    _backup_runtime: Option<Runtime>,
    _consensus_observer_runtime: Option<Runtime>,
    _consensus_publisher_runtime: Option<Runtime>,
    _consensus_runtime: Option<Runtime>,
    _dkg_runtime: Option<Runtime>,
    _indexer_grpc_runtime: Option<Runtime>,
    _indexer_runtime: Option<Runtime>,
    _indexer_table_info_runtime: Option<Runtime>,
    _jwk_consensus_runtime: Option<Runtime>,
    _mempool_runtime: Runtime,
    _network_runtimes: Vec<Runtime>,
    _peer_monitoring_service_runtime: Runtime,
    _state_sync_runtimes: StateSyncRuntimes,
    _telemetry_runtime: Option<Runtime>,
    _indexer_db_runtime: Option<Runtime>,
}
```

**File:** aptos-node/src/lib.rs (L233-234)
```rust
    // Setup panic handler
    aptos_crash_handler::setup_panic_handler();
```

**File:** crates/crash-handler/src/lib.rs (L26-57)
```rust
pub fn setup_panic_handler() {
    panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());

    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);

    // Wait till the logs have been flushed
    aptos_logger::flush();

    // Do not kill the process if the panics happened at move-bytecode-verifier.
    // This is safe because the `state::get_state()` uses a thread_local for storing states. Thus the state can only be mutated to VERIFIER by the thread that's running the bytecode verifier.
    //
    // TODO: once `can_unwind` is stable, we should assert it. See https://github.com/rust-lang/rust/issues/92988.
    if state::get_state() == VMState::VERIFIER || state::get_state() == VMState::DESERIALIZER {
        return;
    }

    // Kill the process
    process::exit(12);
```

**File:** aptos-node/src/services.rs (L124-129)
```rust
    let indexer_runtime = indexer::bootstrap_indexer(
        node_config,
        chain_id,
        db_rw.reader.clone(),
        mempool_client_sender.clone(),
    )?;
```

**File:** config/src/config/indexer_config.rs (L29-29)
```rust
    /// Alternatively can set the `INDEXER_ENABLED` env var
```
