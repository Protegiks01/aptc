# Audit Report

## Title
State Sync Minimum Response Violation Allows Oversized Data to Bypass Size Limits

## Summary
The legacy state synchronization functions in `storage.rs` return single-item responses without validating size against configured limits. When data chunking reduces to a single item that exceeds `max_network_chunk_bytes`, the server returns it anyway, violating protocol invariants and potentially causing client crashes or resource exhaustion. [1](#0-0) 

## Finding Description
The function `get_state_value_chunk_with_proof_by_size_legacy()` implements a binary search pattern to fit data within the configured `max_response_size` limit. It progressively halves the number of items requested until the response fits. However, at the minimum case when `num_state_values_to_fetch == 1`, the function returns the data **without checking its size**, implementing a "we cannot return less than a single item" policy. [2](#0-1) 

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The server explicitly bypasses its configured `max_network_chunk_bytes` limit without error or warning.

**Critical Context**: Mainnet uses this vulnerable legacy implementation because `enable_size_and_time_aware_chunking` defaults to `false` and is only enabled for non-mainnet networks: [3](#0-2) [4](#0-3) 

**State Value Size Limits**: Individual state values can reach 1 MB (enforced by gas schedule): [5](#0-4) 

However, genesis transactions and early feature versions bypass this limit using unlimited configs: [6](#0-5) 

**Systemic Pattern**: This vulnerability exists across ALL legacy chunking functions:
- Epoch ending ledger infos [7](#0-6) 
- Transactions with proof [8](#0-7) 
- Transaction outputs [9](#0-8) 

## Impact Explanation
**High Severity** - This qualifies as "API crashes" and "Significant protocol violations" under the Aptos bug bounty program:

1. **Client Resource Exhaustion**: Nodes with bandwidth-constrained configurations (small `max_network_chunk_bytes`) receive responses exceeding their limits, potentially causing:
   - Memory exhaustion if pre-allocated buffers are exceeded
   - Out-of-memory crashes
   - Deserialization failures
   - Denial of service for state synchronization

2. **Protocol Contract Violation**: The storage service explicitly promises to respect `max_network_chunk_bytes` through its configuration system, but silently violates this contract.

3. **Mainnet Exposure**: The vulnerability is ACTIVE on mainnet because the safer implementation is disabled by default.

## Likelihood Explanation
**Medium Likelihood** due to:

**Attack Prerequisites**:
- State values approaching or exceeding 1 MB must exist in blockchain state
- Victim nodes must be configured with `max_network_chunk_bytes` close to or below state value sizes
- OR state values larger than 1 MB exist from genesis/early transactions

**Realistic Scenarios**:
1. **Bandwidth-Constrained Nodes**: Operators of nodes on limited bandwidth may configure smaller chunk sizes (e.g., 100 KB - 1 MB) for efficiency
2. **Large State Values in Production**: Applications storing maximum-size data structures (e.g., large vectors, maps) can create 1 MB state values
3. **Historical Genesis Values**: If genesis transactions wrote oversized values before limits were enforced, they remain queryable

**Attacker Capabilities**: Any user can write maximum-size state values (1 MB) via normal transactions, requiring no special privileges.

## Recommendation
Implement proper size validation even for single-item responses. When a single item exceeds the limit, return an explicit error rather than silently violating the configured constraint:

```rust
fn get_state_value_chunk_with_proof_by_size_legacy(
    &self,
    version: u64,
    start_index: u64,
    end_index: u64,
    mut num_state_values_to_fetch: u64,
    max_response_size: u64,
) -> Result<StateValueChunkWithProof, Error> {
    while num_state_values_to_fetch >= 1 {
        let state_value_chunk_with_proof = self.storage.get_state_value_chunk_with_proof(
            version,
            start_index as usize,
            num_state_values_to_fetch as usize,
        )?;
        
        // Check size even for single items
        let (overflow_frame, num_bytes) =
            check_overflow_network_frame(&state_value_chunk_with_proof, max_response_size)?;
            
        if num_state_values_to_fetch == 1 {
            if overflow_frame {
                // Return explicit error when single item exceeds limit
                return Err(Error::UnexpectedErrorEncountered(format!(
                    "Single state value at version {:?}, index {:?} exceeds max response size! \
                    State value size: {:?} bytes, limit: {:?} bytes. \
                    Consider increasing max_network_chunk_bytes configuration.",
                    version, start_index, num_bytes, max_response_size
                )));
            }
            return Ok(state_value_chunk_with_proof);
        }
        
        if !overflow_frame {
            return Ok(state_value_chunk_with_proof);
        } else {
            // ... existing truncation logic ...
        }
    }
    // ... existing error case ...
}
```

**Additional Recommendations**:
1. Enable `enable_size_and_time_aware_chunking` on mainnet after thorough testing
2. Add monitoring/metrics for oversized single-item responses
3. Document size expectations in client APIs
4. Apply same fix to all affected legacy functions

## Proof of Concept
```rust
#[test]
fn test_oversized_single_state_value_bypass() {
    use aptos_storage_service_server::StorageReader;
    use aptos_config::config::StorageServiceConfig;
    
    // Setup storage with a 1MB state value
    let mut config = StorageServiceConfig::default();
    config.max_network_chunk_bytes = 100_000; // Set limit to 100KB
    config.enable_size_and_time_aware_chunking = false; // Use legacy vulnerable code
    
    let storage = create_mock_storage_with_large_state_value(1_000_000); // 1MB value
    let storage_reader = StorageReader::new(config, storage, TimeService::mock());
    
    // Request the large state value
    let result = storage_reader.get_state_value_chunk_with_proof(
        1000, // version
        0,    // start_index
        0,    // end_index (single item)
    );
    
    // Vulnerability: Function returns OK despite exceeding configured limit
    assert!(result.is_ok());
    let chunk = result.unwrap();
    let serialized_size = bcs::to_bytes(&chunk).unwrap().len();
    
    // Demonstrate protocol violation: response exceeds configured max_network_chunk_bytes
    assert!(serialized_size > config.max_network_chunk_bytes as usize,
            "Single state value bypassed size limit: {} bytes > {} bytes limit",
            serialized_size, config.max_network_chunk_bytes);
}
```

**Notes**:
- This vulnerability requires specific configuration conditions or oversized state values to be exploitable
- Default mainnet configuration (10 MiB limit) provides significant headroom over typical 1 MB values
- However, the protocol violation and lack of error handling represent a clear security issue
- Impact escalates in bandwidth-constrained environments or if larger historical state values exist

### Citations

**File:** state-sync/storage-service/server/src/storage.rs (L318-320)
```rust
            if num_ledger_infos_to_fetch == 1 {
                return Ok(epoch_change_proof); // We cannot return less than a single item
            }
```

**File:** state-sync/storage-service/server/src/storage.rs (L536-538)
```rust
            if num_transactions_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
            }
```

**File:** state-sync/storage-service/server/src/storage.rs (L758-760)
```rust
            if num_outputs_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
            }
```

**File:** state-sync/storage-service/server/src/storage.rs (L999-1032)
```rust
        while num_state_values_to_fetch >= 1 {
            let state_value_chunk_with_proof = self.storage.get_state_value_chunk_with_proof(
                version,
                start_index as usize,
                num_state_values_to_fetch as usize,
            )?;
            if num_state_values_to_fetch == 1 {
                return Ok(state_value_chunk_with_proof); // We cannot return less than a single item
            }

            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&state_value_chunk_with_proof, max_response_size)?;
            if !overflow_frame {
                return Ok(state_value_chunk_with_proof);
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::StateValueChunkWithProof(state_value_chunk_with_proof)
                        .get_label(),
                );
                let new_num_state_values_to_fetch = num_state_values_to_fetch / 2;
                debug!("The request for {:?} state values was too large (num bytes: {:?}, limit: {:?}). Retrying with {:?}.",
                    num_state_values_to_fetch, num_bytes, max_response_size, new_num_state_values_to_fetch);
                num_state_values_to_fetch = new_num_state_values_to_fetch; // Try again with half the amount of data
            }
        }

        Err(Error::UnexpectedErrorEncountered(format!(
            "Unable to serve the get_state_value_chunk_with_proof request! Version: {:?}, \
            start index: {:?}, end index: {:?}. The data cannot fit into a single network frame!",
            version, start_index, end_index
        )))
    }
```

**File:** config/src/config/state_sync_config.rs (L198-198)
```rust
            enable_size_and_time_aware_chunking: false,
```

**File:** config/src/config/state_sync_config.rs (L620-629)
```rust
        // Potentially enable size and time-aware chunking for all networks except Mainnet
        let mut modified_config = false;
        if let Some(chain_id) = chain_id {
            if ENABLE_SIZE_AND_TIME_AWARE_CHUNKING
                && !chain_id.is_mainnet()
                && local_storage_config_yaml["enable_size_and_time_aware_chunking"].is_null()
            {
                storage_service_config.enable_size_and_time_aware_chunking = true;
                modified_config = true;
            }
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L69-69)
```rust
            "max_price_per_gas_unit",
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L20-38)
```rust
    pub fn unlimited_at_gas_feature_version(gas_feature_version: u64) -> Self {
        Self::new_impl(
            gas_feature_version,
            u64::MAX,
            u64::MAX,
            u64::MAX,
            u64::MAX,
            u64::MAX,
        )
    }

    pub fn new(feature_version: u64, gas_params: &AptosGasParameters) -> Self {
        if feature_version >= 5 {
            Self::from_gas_params(feature_version, gas_params)
        } else if feature_version >= 3 {
            Self::for_feature_version_3()
        } else {
            Self::unlimited_at_gas_feature_version(feature_version)
        }
```
