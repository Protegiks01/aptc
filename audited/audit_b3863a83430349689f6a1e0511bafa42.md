# Audit Report

## Title
TOCTOU Validation Bypass in Storage Service Request Moderator Allows Unlimited Invalid Requests

## Summary
A Time-of-Check-Time-of-Use (TOCTOU) race condition in the storage service request validation allows attackers to bypass the moderator's invalid request tracking by exploiting the gap between cached validation checks and actual storage operations. Requests for pruned data pass validation using stale cache data but fail during execution with `StorageErrorEncountered` instead of `InvalidRequest`, circumventing the moderator's protection mechanism and enabling resource exhaustion attacks.

## Finding Description

The storage service implements a request moderator to protect against malicious peers sending invalid requests. The moderator validates requests against a `StorageServerSummary` cache and tracks peers that exceed invalid request thresholds, eventually ignoring them. [1](#0-0) 

The validation occurs in the `validate_request` method, which checks if the cached summary can service the request: [2](#0-1) 

When `can_service()` returns false, the moderator correctly increments the invalid request counter and returns `Error::InvalidRequest`. However, a critical TOCTOU vulnerability exists:

**The Cached Summary is Stale**: The storage server summary is cached and refreshed only every 100ms by default: [3](#0-2) 

**Fresh Check During Execution**: When the actual storage operation executes, it performs a fresh pruning check: [4](#0-3) 

This check can fail if data has been pruned since the cached validation: [5](#0-4) 

**Error Misclassification**: The `AptosDbError` from pruning is converted to `Error::StorageErrorEncountered`, not `Error::InvalidRequest`: [6](#0-5) 

**Moderator Bypass**: The handler transforms this to `StorageServiceError::InternalError`, completely bypassing moderator tracking: [7](#0-6) 

**Attack Scenario**:
1. Attacker identifies versions at the edge of the pruning window (e.g., `latest_version - prune_window`)
2. Sends `GetStateValuesWithProof` requests for those versions
3. Validation passes because cached summary (up to 100ms stale) indicates data is available
4. Storage operation fails when `error_if_state_merkle_pruned()` detects the data is actually pruned
5. Error is classified as `StorageErrorEncountered` (Internal Error) 
6. Moderator never increments invalid request counter for this peer
7. Attacker repeats indefinitely without being penalized or ignored, causing resource exhaustion

## Impact Explanation

**Critical Severity** - This vulnerability breaks the Resource Limits invariant and enables a Denial of Service attack:

- **Resource Exhaustion**: Attackers can send unlimited invalid requests without triggering the moderator's protection mechanism
- **No Peer Penalties**: The exponential backoff system (which doubles ignore time with each violation) is completely bypassed
- **Node Performance Degradation**: Each failed request still consumes CPU, I/O, and network resources to execute the storage operation before failing
- **Liveness Impact**: Under sustained attack, storage service nodes can be overwhelmed, degrading state synchronization across the network

This meets the **High Severity** criteria of "Validator node slowdowns" and "Significant protocol violations" as defined in the Aptos bug bounty program.

## Likelihood Explanation

**High Likelihood** of exploitation:

- **Easy to Identify Targets**: Pruning windows are predictable (configured in `prune_window` settings), and attackers can query the synced ledger version to calculate pruned ranges
- **Low Attack Complexity**: Requires only standard P2P network access to send storage service requests
- **No Authentication Required**: Any connected peer can exploit this
- **Persistent Window**: The 100ms cache refresh interval provides a continuous exploitation window
- **State Merkle Pruner Always Enabled**: Production nodes typically enable state pruning to manage disk space, making this universally applicable

## Recommendation

The moderator should track requests that fail due to pruned data as invalid requests. Two approaches:

**Approach 1 - Classify Pruning Errors as Invalid Requests**:

Modify the error conversion in `storage.rs` to detect pruning-related errors and convert them to `InvalidRequest`:

```rust
// In storage.rs or error.rs
impl From<aptos_storage_interface::AptosDbError> for Error {
    fn from(error: aptos_storage_interface::AptosDbError) -> Self {
        // Check if this is a pruning-related error
        let error_msg = error.to_string();
        if error_msg.contains("is pruned") || error_msg.contains("pruned") {
            Error::InvalidRequest(error_msg)
        } else {
            Error::StorageErrorEncountered(error_msg)
        }
    }
}
```

**Approach 2 - Reduce Cache Staleness**:

Reduce the cache refresh interval significantly and implement cache invalidation on pruning events:

```rust
// In state_sync_config.rs
storage_summary_refresh_interval_ms: 10, // 10ms instead of 100ms
```

And add explicit cache invalidation when pruning occurs in `StateMerklePrunerManager`.

**Approach 3 - Two-Phase Validation** (Most Robust):

Perform a lightweight fresh pruning check during validation:

```rust
// In moderator.rs validate_request()
// After can_service() check, add:
if let DataRequest::GetStateValuesWithProof(req) = &request.data_request {
    // Verify the version isn't pruned right now
    let min_readable = self.get_min_readable_state_version()?;
    if req.version < min_readable {
        // Increment invalid request counter
        // Return Error::InvalidRequest
    }
}
```

**Recommended Solution**: Implement Approach 1 for immediate mitigation, then add Approach 3 for comprehensive protection.

## Proof of Concept

```rust
// Reproduction test for state-sync/storage-service/server/src/tests/
#[tokio::test]
async fn test_pruned_data_request_bypasses_moderator() {
    // Setup storage service with pruning enabled
    let (mut mock_db, storage) = MockDbReader::new();
    let config = StorageServiceConfig {
        max_invalid_requests_per_peer: 3,
        storage_summary_refresh_interval_ms: 100,
        ..Default::default()
    };
    
    // Set up state: latest version is 1000, pruning window is 100
    // So versions < 900 are pruned
    mock_db.set_synced_version(1000);
    mock_db.set_state_pruning_window(100);
    
    // Initial cache update: summary shows states available from 900-1000
    let summary = storage.get_data_summary().unwrap();
    assert_eq!(summary.states.unwrap().lowest, 900);
    
    // Time passes, pruner runs, now versions < 950 are pruned
    mock_db.set_state_pruning_window(50); // Aggressive pruning
    // BUT cache hasn't refreshed yet (still shows 900 available)
    
    let peer_network_id = PeerNetworkId::random();
    
    // Attacker sends requests for version 920 (now pruned, but cache says available)
    let request = StorageServiceRequest {
        data_request: DataRequest::GetStateValuesWithProof(StateValuesWithProofRequest {
            version: 920,
            start_index: 0,
            end_index: 100,
        }),
        use_compression: false,
    };
    
    // Send multiple requests (more than max_invalid_requests_per_peer)
    for i in 0..10 {
        let response = handler.process_request(&peer_network_id, request.clone(), false);
        
        // Request passes validation (cached summary says OK)
        // But fails with StorageErrorEncountered (pruned data)
        assert!(matches!(response, Err(StorageServiceError::InternalError(_))));
        
        // Check moderator state - should NOT have incremented invalid request count
        let unhealthy_states = moderator.get_unhealthy_peer_states();
        let peer_state = unhealthy_states.get(&peer_network_id);
        
        // BUG: Invalid request counter remains at 0!
        assert_eq!(peer_state.map(|s| s.invalid_request_count).unwrap_or(0), 0);
        
        // Peer is NOT ignored despite sending 10 invalid requests
        assert!(!peer_state.map(|s| s.is_ignored()).unwrap_or(false));
    }
    
    // Attack succeeded: 10 invalid requests sent, peer never penalized
}
```

**Expected Behavior**: After 3 invalid requests, the peer should be marked as unhealthy and eventually ignored.

**Actual Behavior**: The peer can send unlimited requests for pruned data without penalty because errors are classified as `InternalError` instead of `InvalidRequest`.

---

## Notes

This vulnerability specifically affects state-related requests (`GetStateValuesWithProof`, `GetNumberOfStatesAtVersion`) but the same TOCTOU pattern could potentially affect transaction/output requests if similar pruning occurs on those data types. The core issue is the semantic gap between cached validation metadata and actual storage availability, combined with improper error classification that allows invalid requests to bypass the moderator's tracking system.

### Citations

**File:** state-sync/storage-service/server/src/moderator.rs (L101-112)
```rust
/// The request moderator is responsible for validating inbound storage
/// requests and ensuring that only valid (and satisfiable) requests are processed.
/// If a peer sends too many invalid requests, the moderator will mark the peer as
/// "unhealthy" and will ignore requests from that peer for some time.
pub struct RequestModerator {
    aptos_data_client_config: AptosDataClientConfig,
    cached_storage_server_summary: Arc<ArcSwap<StorageServerSummary>>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    storage_service_config: StorageServiceConfig,
    time_service: TimeService,
    unhealthy_peer_states: Arc<DashMap<PeerNetworkId, UnhealthyPeerState>>,
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L154-185)
```rust
            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }
```

**File:** config/src/config/state_sync_config.rs (L215-215)
```rust
            storage_summary_refresh_interval_ms: 100, // Optimal for <= 10 blocks per second
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L886-890)
```rust
        gauged_api("get_state_value_chunk_with_proof", || {
            self.error_if_state_merkle_pruned("State merkle", version)?;
            self.state_store
                .get_value_chunk_with_proof(version, first_index, chunk_size)
        })
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L295-301)
```rust
            bail!(
                "{} at version {} is pruned. snapshots are available at >= {}, epoch snapshots are available at >= {}",
                data_type,
                version,
                min_readable_version,
                min_readable_epoch_snapshot_version,
            )
```

**File:** state-sync/storage-service/server/src/error.rs (L43-46)
```rust
impl From<aptos_storage_interface::AptosDbError> for Error {
    fn from(error: aptos_storage_interface::AptosDbError) -> Self {
        Error::StorageErrorEncountered(error.to_string())
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L196-202)
```rust
        process_result.map_err(|error| match error {
            Error::InvalidRequest(error) => StorageServiceError::InvalidRequest(error),
            Error::TooManyInvalidRequests(error) => {
                StorageServiceError::TooManyInvalidRequests(error)
            },
            error => StorageServiceError::InternalError(error.to_string()),
        })
```
