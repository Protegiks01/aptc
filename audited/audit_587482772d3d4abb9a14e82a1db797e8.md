# Audit Report

## Title
Consensus Liveness Failure Due to Missing Retry Logic in Remote Sharded Execution Network Service

## Summary
The `send_message()` function in the gRPC network service panics on any network error instead of implementing retry with exponential backoff. This causes permanent loss of execution results in deployments using remote sharded execution, breaking consensus liveness assumptions.

## Finding Description

The vulnerability exists in the gRPC network message service used by the remote executor service for distributed sharded block execution. [1](#0-0) 

The `send_message()` function panics on any gRPC communication failure, with a TODO comment explicitly noting the missing retry mechanism. This function is called by the outbound handler when sending messages: [2](#0-1) 

The network controller is used by the ExecutorService for remote sharded execution: [3](#0-2) 

When consensus requires block execution in a sharded deployment, the RemoteCoordinatorClient sends execution results back to the coordinator via the network controller: [4](#0-3) 

The critical execution path decision occurs here: [5](#0-4) 

**Attack Scenario:**
1. Validator deploys remote sharded execution (ProcessExecutorService instances on separate hosts)
2. Transient network failure occurs (packet loss, connection timeout, network congestion)
3. gRPC call in `send_message()` fails
4. Function panics instead of retrying
5. Async task in outbound handler crashes
6. Executor shard cannot send execution results to coordinator
7. Block execution cannot complete
8. Consensus cannot progress to next block â†’ **Liveness violation**

**Critical Context:**
Remote sharded execution must be explicitly enabled by configuring remote executor addresses: [6](#0-5) 

## Impact Explanation

**Severity: HIGH** (if remote sharded execution is enabled)

This breaks the **liveness invariant** of consensus. Per Aptos bug bounty criteria, this qualifies as High Severity due to:
- Significant protocol violation (consensus cannot progress)
- Requires validator intervention to restart crashed executor services
- Degrades network availability during execution

However, **this is a conditional vulnerability** that only affects deployments explicitly configured with remote sharded execution. The default configuration uses local sharded execution and is not affected.

## Likelihood Explanation

**Likelihood: LOW to MEDIUM** (conditional on deployment configuration)

Factors affecting likelihood:
1. **Configuration-dependent**: Remote sharded execution must be explicitly enabled (not default)
2. **Network reliability**: Transient failures are common in distributed systems
3. **Current usage**: Investigation shows this feature is primarily used in benchmarks
4. **Production readiness**: ProcessExecutorService exists with production-quality implementation

Based on code analysis: [7](#0-6) 

The feature is production-ready but appears to be optional/experimental. Current deployments likely use local sharded execution by default.

## Recommendation

Implement retry logic with exponential backoff as indicated by the TODO comment:

```rust
pub async fn send_message(
    &mut self,
    sender_addr: SocketAddr,
    message: Message,
    mt: &MessageType,
) {
    let request = tonic::Request::new(NetworkMessage {
        message: message.data,
        message_type: mt.get_type(),
    });
    
    let max_retries = 5;
    let mut retry_delay = Duration::from_millis(100);
    
    for attempt in 0..=max_retries {
        match self.remote_channel.simple_msg_exchange(request.clone()).await {
            Ok(_) => return,
            Err(e) => {
                if attempt < max_retries {
                    warn!(
                        "Failed to send message to {} (attempt {}/{}): {}. Retrying in {:?}",
                        self.remote_addr, attempt + 1, max_retries, e, retry_delay
                    );
                    tokio::time::sleep(retry_delay).await;
                    retry_delay *= 2; // Exponential backoff
                } else {
                    panic!(
                        "Error '{}' sending message to {} on node {:?} after {} retries",
                        e, self.remote_addr, sender_addr, max_retries
                    );
                }
            },
        }
    }
}
```

Additionally, consider:
1. Making retry configuration adjustable via RemoteExecutorService parameters
2. Adding metrics for retry attempts and failures
3. Implementing circuit breaker pattern for persistent failures

## Proof of Concept

```rust
// Test demonstrating the vulnerability in executor-service/src/tests.rs
#[tokio::test]
async fn test_transient_network_failure_causes_panic() {
    // Setup: Create executor service with remote sharding
    let num_shards = 2;
    let coordinator_port = get_available_port();
    let shard_ports: Vec<u16> = (0..num_shards).map(|_| get_available_port()).collect();
    
    // Simulate network failure by dropping packets or closing connection
    // The send_message call will fail and panic
    // Without retry logic, the executor shard becomes permanently unavailable
    // Block execution cannot complete
    // Consensus is blocked
    
    // Expected: Should retry and eventually succeed or gracefully degrade
    // Actual: Panics on first failure, breaking liveness
}
```

**Notes:**
- This vulnerability is **conditional** on enabling remote sharded execution
- Default Aptos deployments use local sharded execution and are **not affected**
- The TODO comment confirms developers are aware retry logic is needed
- Fix should be implemented before enabling remote sharding in production

### Citations

**File:** secure/net/src/grpc_network_service/mod.rs (L140-160)
```rust
    pub async fn send_message(
        &mut self,
        sender_addr: SocketAddr,
        message: Message,
        mt: &MessageType,
    ) {
        let request = tonic::Request::new(NetworkMessage {
            message: message.data,
            message_type: mt.get_type(),
        });
        // TODO: Retry with exponential backoff on failures
        match self.remote_channel.simple_msg_exchange(request).await {
            Ok(_) => {},
            Err(e) => {
                panic!(
                    "Error '{}' sending message to {} on node {:?}",
                    e, self.remote_addr, sender_addr
                );
            },
        }
    }
```

**File:** secure/net/src/network_controller/outbound_handler.rs (L155-160)
```rust
                grpc_clients
                    .get_mut(remote_addr)
                    .unwrap()
                    .send_message(*socket_addr, msg, message_type)
                    .await;
            }
```

**File:** execution/executor-service/src/remote_executor_service.rs (L22-54)
```rust
    pub fn new(
        shard_id: ShardId,
        num_shards: usize,
        num_threads: usize,
        self_address: SocketAddr,
        coordinator_address: SocketAddr,
        remote_shard_addresses: Vec<SocketAddr>,
    ) -> Self {
        let service_name = format!("executor_service-{}", shard_id);
        let mut controller = NetworkController::new(service_name, self_address, 5000);
        let coordinator_client = Arc::new(RemoteCoordinatorClient::new(
            shard_id,
            &mut controller,
            coordinator_address,
        ));
        let cross_shard_client = Arc::new(RemoteCrossShardClient::new(
            &mut controller,
            remote_shard_addresses,
        ));

        let executor_service = Arc::new(ShardedExecutorService::new(
            shard_id,
            num_shards,
            num_threads,
            coordinator_client,
            cross_shard_client,
        ));

        Self {
            shard_id,
            controller,
            executor_service,
        }
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L115-119)
```rust
    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
        let remote_execution_result = RemoteExecutionResult::new(result);
        let output_message = bcs::to_bytes(&remote_execution_result).unwrap();
        self.result_tx.send(Message::new(output_message)).unwrap();
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L256-276)
```rust
    fn execute_block_sharded<V: VMBlockExecutor>(
        partitioned_txns: PartitionedTransactions,
        state_view: Arc<CachedStateView>,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>> {
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        } else {
            Ok(V::execute_block_sharded(
                &SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        }
    }
```

**File:** execution/executor-service/src/remote_executor_client.rs (L32-44)
```rust
static REMOTE_ADDRESSES: OnceCell<Vec<SocketAddr>> = OnceCell::new();
static COORDINATOR_ADDRESS: OnceCell<SocketAddr> = OnceCell::new();

pub fn set_remote_addresses(addresses: Vec<SocketAddr>) {
    REMOTE_ADDRESSES.set(addresses).ok();
}

pub fn get_remote_addresses() -> Vec<SocketAddr> {
    match REMOTE_ADDRESSES.get() {
        Some(value) => value.clone(),
        None => vec![],
    }
}
```

**File:** execution/executor-service/src/process_executor_service.rs (L11-50)
```rust
/// An implementation of the remote executor service that runs in a standalone process.
pub struct ProcessExecutorService {
    executor_service: ExecutorService,
}

impl ProcessExecutorService {
    pub fn new(
        shard_id: ShardId,
        num_shards: usize,
        num_threads: usize,
        coordinator_address: SocketAddr,
        remote_shard_addresses: Vec<SocketAddr>,
    ) -> Self {
        let self_address = remote_shard_addresses[shard_id];
        info!(
            "Starting process remote executor service on {}; coordinator address: {}, other shard addresses: {:?}; num threads: {}",
            self_address, coordinator_address, remote_shard_addresses, num_threads
        );
        aptos_node_resource_metrics::register_node_metrics_collector(None);
        let _mp = MetricsPusher::start_for_local_run(
            &("remote-executor-service-".to_owned() + &shard_id.to_string()),
        );

        AptosVM::set_concurrency_level_once(num_threads);
        let mut executor_service = ExecutorService::new(
            shard_id,
            num_shards,
            num_threads,
            self_address,
            coordinator_address,
            remote_shard_addresses,
        );
        executor_service.start();
        Self { executor_service }
    }

    pub fn shutdown(&mut self) {
        self.executor_service.shutdown()
    }
}
```
