# Audit Report

## Title
Graceful Shutdown Bypass via Long-Running gRPC Requests Without Forced Timeout

## Summary
The gRPC network service in `secure/net` lacks a forced shutdown timeout mechanism, allowing malicious clients to delay server shutdown indefinitely by maintaining slow or long-running requests that ignore the shutdown signal. When shutdown is triggered, the server waits for all in-flight requests to complete without any maximum grace period, enabling operational disruption during critical maintenance, upgrades, or emergency shutdowns.

## Finding Description
The `GRPCNetworkMessageServiceServerWrapper::start_async` function uses Tonic's `serve_with_shutdown` to implement graceful shutdown. [1](#0-0) 

When a shutdown signal is received via the oneshot channel, the gRPC server stops accepting new connections but waits indefinitely for all existing in-flight requests to complete. Each request has a timeout configured via `rpc_timeout_ms`, [2](#0-1)  but there is no overall shutdown timeout that would forcefully terminate requests after a maximum grace period.

The `NetworkController::shutdown` method acknowledges this issue with a TODO comment explicitly stating: "This is still not a very clean shutdown. We don't wait for the full shutdown after sending the signal." [3](#0-2) 

The shutdown method simply sends the signal without waiting for acknowledgment: [4](#0-3) 

**Attack Scenario:**
1. Attacker establishes connections to an `ExecutorService` node (which uses `NetworkController` with a 5000ms timeout) [5](#0-4) 
2. Attacker sends multiple `SimpleMsgExchange` RPC calls with intentionally slow data transmission, taking nearly the full 5000ms timeout duration
3. When node operator triggers `ExecutorService.shutdown()` [6](#0-5)  for maintenance/emergency, the gRPC server receives the signal but waits for all slow requests to complete
4. Shutdown is delayed by up to `rpc_timeout_ms` per in-flight request, with no forced termination mechanism
5. Server continues consuming resources (memory, file descriptors, CPU cycles) during this extended shutdown period

This breaks the **availability invariant** during shutdown operations, as operators cannot predictably terminate services within a reasonable timeframe.

## Impact Explanation
This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria:

- **Operational Impact**: Prevents timely shutdown during critical maintenance windows, security upgrades, or emergency responses
- **Resource Exhaustion**: Server continues holding resources (network connections, memory, thread pool workers) during delayed shutdown
- **Denial of Service**: Attackers can coordinate multiple slow requests across distributed executor shards to maximize disruption
- **No Direct Fund Loss**: Does not directly cause loss of funds or consensus violations
- **State Inconsistency Risk**: Delayed shutdowns during coordinated upgrades could lead to inconsistent state across shards requiring manual intervention

The issue affects production deployments where `ExecutorService` and other components using `NetworkController` need reliable shutdown for operational maintenance, version upgrades, or incident response.

## Likelihood Explanation
**High Likelihood** of exploitation:

- **Low Attack Complexity**: Any network peer can send RPC requests to executor services
- **No Authentication Required**: The vulnerability can be triggered by any client with network access to the service
- **Realistic Attack**: Slow network transmission is indistinguishable from legitimate slow connections
- **Existing Acknowledgment**: The TODO comment confirms developers are aware of the incomplete shutdown implementation [3](#0-2) 
- **Production Impact**: `ExecutorService` is used in distributed block execution, making it a critical operational component

The attack requires no special privileges, insider access, or validator cooperationâ€”only the ability to send network requests to the service endpoints.

## Recommendation
Implement a forced shutdown timeout mechanism with the following changes:

**1. Add shutdown timeout configuration to NetworkController:**
```rust
pub struct NetworkController {
    // ... existing fields ...
    shutdown_timeout_ms: u64,
}

impl NetworkController {
    pub fn new(service: String, listen_addr: SocketAddr, timeout_ms: u64, shutdown_timeout_ms: u64) -> Self {
        // ... existing code ...
        Self {
            // ... existing fields ...
            shutdown_timeout_ms,
        }
    }
}
```

**2. Modify shutdown to wait with timeout:**
```rust
pub fn shutdown(&mut self) {
    info!("Shutting down network controller at {}", self.listen_addr);
    
    if let Some(shutdown_signal) = self.inbound_server_shutdown_tx.take() {
        shutdown_signal.send(()).unwrap();
        
        // Wait for shutdown with timeout
        let shutdown_deadline = std::time::Instant::now() + 
            std::time::Duration::from_millis(self.shutdown_timeout_ms);
        
        while std::time::Instant::now() < shutdown_deadline {
            std::thread::sleep(std::time::Duration::from_millis(10));
            // Could check a confirmation channel here if implemented
        }
    }
    
    // Force shutdown of runtime after grace period
    self.inbound_rpc_runtime.shutdown_timeout(
        std::time::Duration::from_millis(100)
    );
    
    // ... handle outbound shutdown similarly ...
}
```

**3. Add confirmation channel pattern (optional but recommended):**
Follow the pattern used in other Aptos components where an acknowledgment channel confirms shutdown completion, with a timeout for forced termination if acknowledgment is not received.

**4. Set reasonable defaults:**
- Shutdown timeout: 2x the RPC timeout (e.g., 10000ms if RPC timeout is 5000ms)
- Force termination: After shutdown timeout expires, forcefully terminate the runtime

## Proof of Concept

```rust
// File: secure/net/tests/graceful_shutdown_attack_test.rs
use aptos_secure_net::network_controller::{Message, MessageType, NetworkController};
use std::{
    net::{IpAddr, Ipv4Addr, SocketAddr},
    thread,
    time::{Duration, Instant},
};
use crossbeam_channel::Sender;

#[test]
fn test_shutdown_delay_attack() {
    // Setup server
    let server_addr = SocketAddr::new(
        IpAddr::V4(Ipv4Addr::LOCALHOST), 
        8080
    );
    
    let mut controller = NetworkController::new(
        "test_service".to_string(),
        server_addr,
        5000, // 5 second timeout per request
    );
    
    // Register handler
    let inbound_rx = controller.create_inbound_channel("test".to_string());
    controller.start();
    
    // Attacker sends slow request
    let client_thread = thread::spawn(move || {
        let mut client = create_slow_client(server_addr);
        // Simulate slow request that takes nearly full timeout
        thread::sleep(Duration::from_millis(4900));
        client.send_message(/* ... */);
    });
    
    // Wait for request to be in-flight
    thread::sleep(Duration::from_millis(100));
    
    // Attempt shutdown
    let shutdown_start = Instant::now();
    controller.shutdown();
    let shutdown_duration = shutdown_start.elapsed();
    
    // VULNERABILITY: Shutdown takes nearly 5 seconds due to waiting for slow request
    assert!(
        shutdown_duration > Duration::from_millis(4500),
        "Shutdown should be delayed by slow request, but completed in {:?}",
        shutdown_duration
    );
    
    println!(
        "ATTACK SUCCESSFUL: Shutdown delayed for {:?} (expected ~5000ms)",
        shutdown_duration
    );
}

#[test]
fn test_multiple_slow_requests_amplify_delay() {
    // Similar test with multiple concurrent slow requests
    // demonstrating that N slow requests can delay shutdown by up to N * timeout
    // (in practice, limited by concurrent request limit)
}
```

## Notes
- The vulnerability is explicitly acknowledged in the codebase via the TODO comment [3](#0-2) 
- Similar shutdown patterns exist throughout the codebase, but most implement acknowledgment channels or timeout mechanisms
- The main.rs file demonstrates proper forced shutdown with `runtime.shutdown_timeout()` [7](#0-6)  which should be adopted for NetworkController
- This issue affects all services using NetworkController, including ExecutorService, RemoteExecutorClient, and related distributed execution components

### Citations

**File:** secure/net/src/grpc_network_service/mod.rs (L76-76)
```rust
            .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
```

**File:** secure/net/src/grpc_network_service/mod.rs (L81-84)
```rust
            .serve_with_shutdown(server_addr, async {
                server_shutdown_rx.await.ok();
                info!("Received signal to shutdown server at {:?}", server_addr);
            })
```

**File:** secure/net/src/network_controller/mod.rs (L152-154)
```rust
    // TODO: This is still not a very clean shutdown. We don't wait for the full shutdown after
    //       sending the signal. May not matter much for now because we shutdown before exiting the
    //       process. Ideally, we want to fix this.
```

**File:** secure/net/src/network_controller/mod.rs (L157-159)
```rust
        if let Some(shutdown_signal) = self.inbound_server_shutdown_tx.take() {
            shutdown_signal.send(()).unwrap();
        }
```

**File:** execution/executor-service/src/remote_executor_service.rs (L31-31)
```rust
        let mut controller = NetworkController::new(service_name, self_address, 5000);
```

**File:** execution/executor-service/src/remote_executor_service.rs (L69-71)
```rust
    pub fn shutdown(&mut self) {
        self.controller.shutdown();
    }
```

**File:** crates/aptos/src/main.rs (L32-32)
```rust
    runtime.shutdown_timeout(Duration::from_millis(50));
```
