# Audit Report

## Title
Missing Block Height Monotonicity Validation in Indexer GRPC Transaction Conversion

## Summary
The `convert_transaction()` function accepts a `block_height` parameter and directly assigns it to the output transaction without validating that block heights are monotonically increasing, potentially allowing database corruption or inconsistencies to silently propagate through the indexer system.

## Finding Description

The indexer-grpc-fullnode component processes blockchain transactions and converts them to protobuf format for downstream consumers. The vulnerability exists in how block heights are computed and validated.

**Location 1: Block Height Computation** [1](#0-0) 

The code retrieves the initial block height from the database and increments it locally when encountering block metadata transactions. This computation assumes:
- The database returns correct block heights (no corruption)
- Block metadata transactions are complete and sequential
- No race conditions during parallel batch fetching

**Location 2: Missing Validation** [2](#0-1) 

The `convert_transaction()` function receives the block_height parameter and directly assigns it to the output structure without ANY validation that:
- Block height is monotonically increasing compared to previous transactions
- Block height is consistent with the transaction version
- Block height hasn't been corrupted

**Location 3: Call Site** [3](#0-2) 

The function is called with the locally computed block height with no validation layer in between.

**Failure Scenarios:**
1. **Database Corruption**: Disk errors or crashes could corrupt stored block heights
2. **Missing Block Metadata**: If block metadata transactions are absent, block_height won't increment correctly, causing multiple blocks to share the same height
3. **State Inconsistency**: During database recovery or state sync issues, initial block heights could be incorrect

**Security Guarantee Broken:**
This violates the **State Consistency** invariant. The blockchain protocol specification defines block_height as a "strictly monotonically increasing count" [4](#0-3) , but this property is never validated during indexer conversion.

## Impact Explanation

**Severity: Medium** - State inconsistencies requiring intervention

While this doesn't directly affect consensus or cause loss of funds, it can cause significant data integrity issues:

1. **Downstream Consumer Corruption**: Block explorers, analytics systems, and other indexers consuming this data would store incorrect block heights
2. **Query Failures**: Applications querying "all transactions in block X" would receive incorrect results
3. **Analytics Degradation**: Block-level metrics (TPS, gas usage) would be computed incorrectly
4. **Silent Propagation**: The corruption spreads without detection mechanisms

The impact is Medium rather than High because:
- It doesn't directly affect validator operations or consensus
- It doesn't cause loss of funds
- It's limited to indexer/observability infrastructure
- Recovery is possible through re-indexing

However, it does cause "State inconsistencies requiring intervention" per the Medium severity criteria.

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires a triggering condition:
- Database corruption (disk errors, crashes during writes)
- Bugs in the storage layer
- Race conditions during state sync
- Hardware failures affecting the node

While these are not common in production environments, they are realistic failure modes that can occur:
- Disk corruption happens in real-world deployments
- Complex distributed systems can have edge cases
- The lack of validation means there's no defense-in-depth

The code assumes perfect database integrity, which violates defensive programming principles. Critical infrastructure should validate invariants even when reading from trusted sources.

## Recommendation

Add validation in `convert_transaction()` to verify block height monotonicity:

```rust
pub fn convert_transaction(
    transaction: &Transaction,
    block_height: u64,
    epoch: u64,
    size_info: TransactionSizeInfo,
) -> transaction::Transaction {
    // Add validation: store and check previous block height
    static LAST_BLOCK_HEIGHT: AtomicU64 = AtomicU64::new(0);
    let prev_height = LAST_BLOCK_HEIGHT.load(Ordering::Relaxed);
    
    if prev_height > 0 && block_height < prev_height {
        panic!(
            "Block height monotonicity violation: current={}, previous={}",
            block_height, prev_height
        );
    }
    
    LAST_BLOCK_HEIGHT.store(block_height, Ordering::Relaxed);
    
    // Continue with existing conversion logic...
```

Additionally, add validation in `stream_coordinator.rs` when computing block heights:

```rust
// After incrementing block_height (lines 401, 407)
if block_height <= prev_block_height {
    panic!(
        "Block height did not increase monotonically: prev={}, current={}",
        prev_block_height, block_height
    );
}
```

## Proof of Concept

**Test Scenario**: Simulate database corruption returning incorrect block heights

```rust
#[test]
#[should_panic(expected = "Block height monotonicity violation")]
fn test_block_height_validation() {
    // Setup: Create transactions with non-monotonic block heights
    let mut transactions = vec![];
    
    // Transaction 1 at block height 100
    let txn1 = create_test_transaction(version: 1000, block_height: 100);
    transactions.push(txn1);
    
    // Transaction 2 at block height 99 (INVALID - goes backwards)
    let txn2 = create_test_transaction(version: 1001, block_height: 99);
    transactions.push(txn2);
    
    // Convert transactions - should panic on monotonicity violation
    for txn in transactions {
        convert_transaction(&txn, txn.block_height, txn.epoch, size_info);
    }
}
```

**Reproduction Steps**:
1. Start an indexer-grpc-fullnode node
2. Simulate database corruption by modifying block height values in the database
3. Observe that indexer continues processing and emits transactions with incorrect block heights
4. Verify that downstream consumers receive corrupted block height data
5. Check that no errors or warnings are logged about the inconsistency

## Notes

The Aptos protocol documentation specifies that block heights must be "strictly monotonically increasing" across the blockchain. While the consensus layer validates rounds and timestamps [5](#0-4) , the indexer layer lacks equivalent validation for block heights when converting to protobuf format, creating a gap in defense-in-depth protections.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L376-409)
```rust
        let (_, _, block_event) = context
            .db
            .get_block_info_by_version(first_version)
            .unwrap_or_else(|_| {
                panic!(
                    "[Indexer Fullnode] Could not get block_info for start version {}",
                    first_version,
                )
            });
        let mut timestamp = block_event.proposed_time();
        let mut epoch = block_event.epoch();
        let mut epoch_bcs = aptos_api_types::U64::from(epoch);
        let mut block_height = block_event.height();
        let mut block_height_bcs = aptos_api_types::U64::from(block_height);

        let mut transactions = vec![];
        for (ind, raw_txn) in raw_txns.into_iter().enumerate() {
            let txn_version = raw_txn.version;
            // Do not update block_height if first block is block metadata
            if ind > 0 {
                // Update the timestamp if the next block occurs
                if let Some(txn) = raw_txn.transaction.try_as_block_metadata_ext() {
                    timestamp = txn.timestamp_usecs();
                    epoch = txn.epoch();
                    epoch_bcs = aptos_api_types::U64::from(epoch);
                    block_height += 1;
                    block_height_bcs = aptos_api_types::U64::from(block_height);
                } else if let Some(txn) = raw_txn.transaction.try_as_block_metadata() {
                    timestamp = txn.timestamp_usecs();
                    epoch = txn.epoch();
                    epoch_bcs = aptos_api_types::U64::from(epoch);
                    block_height += 1;
                    block_height_bcs = aptos_api_types::U64::from(block_height);
                }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L515-530)
```rust
    fn convert_to_pb_txns(
        api_txns: Vec<(APITransaction, TransactionSizeInfo)>,
    ) -> Vec<TransactionPB> {
        api_txns
            .into_iter()
            .map(|(txn, size_info)| {
                let info = txn.transaction_info().unwrap();
                convert_transaction(
                    &txn,
                    info.block_height.unwrap().0,
                    info.epoch.unwrap().0,
                    size_info,
                )
            })
            .collect()
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/convert.rs (L827-948)
```rust
pub fn convert_transaction(
    transaction: &Transaction,
    block_height: u64,
    epoch: u64,
    size_info: TransactionSizeInfo,
) -> transaction::Transaction {
    let mut timestamp: Option<timestamp::Timestamp> = None;

    let txn_type = match transaction {
        Transaction::UserTransaction(_) => transaction::transaction::TransactionType::User,
        Transaction::GenesisTransaction(_) => transaction::transaction::TransactionType::Genesis,
        Transaction::BlockMetadataTransaction(_) => {
            transaction::transaction::TransactionType::BlockMetadata
        },
        Transaction::StateCheckpointTransaction(_) => {
            transaction::transaction::TransactionType::StateCheckpoint
        },
        Transaction::BlockEpilogueTransaction(_) => {
            transaction::transaction::TransactionType::BlockEpilogue
        },
        Transaction::PendingTransaction(_) => panic!("PendingTransaction is not supported"),
        Transaction::ValidatorTransaction(_) => {
            transaction::transaction::TransactionType::Validator
        },
    };

    let txn_data = match &transaction {
        Transaction::UserTransaction(ut) => {
            timestamp = Some(convert_timestamp_usecs(ut.timestamp.0));
            let expiration_timestamp_secs = Some(convert_timestamp_secs(
                ut.request.expiration_timestamp_secs.0,
            ));
            transaction::transaction::TxnData::User(transaction::UserTransaction {
                request: Some(transaction::UserTransactionRequest {
                    sender: ut.request.sender.to_string(),
                    sequence_number: ut.request.sequence_number.0,
                    max_gas_amount: ut.request.max_gas_amount.0,
                    gas_unit_price: ut.request.gas_unit_price.0,
                    expiration_timestamp_secs,
                    payload: Some(convert_transaction_payload(
                        &ut.request.payload,
                        ut.request.replay_protection_nonce.map(|n| n.into()),
                    )),
                    signature: convert_transaction_signature(&ut.request.signature),
                }),
                events: convert_events(&ut.events),
            })
        },
        Transaction::GenesisTransaction(gt) => {
            let payload = match &gt.payload {
                GenesisPayload::WriteSetPayload(wsp) => convert_write_set(&wsp.write_set),
            };
            transaction::transaction::TxnData::Genesis(transaction::GenesisTransaction {
                payload: Some(payload),
                events: convert_events(&gt.events),
            })
        },
        Transaction::BlockMetadataTransaction(bm) => {
            timestamp = Some(convert_timestamp_usecs(bm.timestamp.0));
            transaction::transaction::TxnData::BlockMetadata(
                transaction::BlockMetadataTransaction {
                    id: bm.id.to_string(),
                    events: convert_events(&bm.events),
                    previous_block_votes_bitvec: bm.previous_block_votes_bitvec.clone(),
                    proposer: bm.proposer.to_string(),
                    failed_proposer_indices: bm.failed_proposer_indices.clone(),
                    round: bm.round.0,
                },
            )
        },
        Transaction::StateCheckpointTransaction(_st) => {
            transaction::transaction::TxnData::StateCheckpoint(
                transaction::StateCheckpointTransaction {},
            )
        },
        Transaction::BlockEpilogueTransaction(block_epilogue) => {
            transaction::transaction::TxnData::BlockEpilogue(
                transaction::BlockEpilogueTransaction {
                    block_end_info: block_epilogue
                        .block_end_info
                        .as_ref()
                        .map(|block_end_info| transaction::BlockEndInfo {
                            block_gas_limit_reached: block_end_info.block_gas_limit_reached,
                            block_output_limit_reached: block_end_info.block_output_limit_reached,
                            block_effective_block_gas_units: block_end_info
                                .block_effective_block_gas_units,
                            block_approx_output_size: block_end_info.block_approx_output_size,
                        }),
                },
            )
        },
        Transaction::PendingTransaction(_) => panic!("PendingTransaction not supported"),
        Transaction::ValidatorTransaction(api_validator_txn) => {
            convert_validator_transaction(api_validator_txn)
        },
    };

    transaction::Transaction {
        timestamp: Some(
            timestamp.unwrap_or_else(|| convert_timestamp_usecs(transaction.timestamp())),
        ),
        version: transaction.version().unwrap_or_else(|| {
            panic!(
                "Could not extract version from Transaction '{:?}'",
                transaction
            )
        }),
        info: Some(convert_transaction_info(
            transaction.transaction_info().unwrap_or_else(|_| {
                panic!(
                    "Could not extract transaction_info from Transaction '{:?}'",
                    transaction
                )
            }),
        )),
        epoch,
        block_height,
        r#type: txn_type as i32,
        txn_data: Some(txn_data),
        size_info: Some(size_info),
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/tests/proto_converter_tests.rs (L128-152)
```rust
    let block_mapping = HashMap::from([
        (0, 0),
        (1, 1),
        (2, 1),
        (3, 1),
        (4, 2),
        (5, 2),
        (6, 2),
        (7, 3),
        (8, 3),
    ]);

    let context = Arc::new(test_context.clone().context);

    let streamer = FullnodeDataService::new(context, 0, None);
    let converted = fetch_all_stream(streamer).await;

    assert_eq!(converted.len(), 9);
    // Making sure that version - block height mapping is correct and that version is in order
    for (i, txn) in converted.iter().enumerate() {
        assert_eq!(txn.version as usize, i);
        assert_eq!(
            txn.block_height as usize,
            *block_mapping.get(&i).unwrap() as usize
        );
```

**File:** consensus/consensus-types/src/block.rs (L469-551)
```rust
    pub fn verify_well_formed(&self) -> anyhow::Result<()> {
        ensure!(
            !self.is_genesis_block(),
            "We must not accept genesis from others"
        );
        let parent = self.quorum_cert().certified_block();
        ensure!(
            parent.round() < self.round(),
            "Block must have a greater round than parent's block"
        );
        ensure!(
            parent.epoch() == self.epoch(),
            "block's parent should be in the same epoch"
        );
        if parent.has_reconfiguration() {
            ensure!(
                self.payload().is_none_or(|p| p.is_empty()),
                "Reconfiguration suffix should not carry payload"
            );
        }

        if let Some(payload) = self.payload() {
            payload.verify_epoch(self.epoch())?;
        }

        if let Some(failed_authors) = self.block_data().failed_authors() {
            // when validating for being well formed,
            // allow for missing failed authors,
            // for whatever reason (from different max configuration, etc),
            // but don't allow anything that shouldn't be there.
            //
            // we validate the full correctness of this field in round_manager.process_proposal()
            let succ_round = self.round() + u64::from(self.is_nil_block());
            let skipped_rounds = succ_round.checked_sub(parent.round() + 1);
            ensure!(
                skipped_rounds.is_some(),
                "Block round is smaller than block's parent round"
            );
            ensure!(
                failed_authors.len() <= skipped_rounds.unwrap() as usize,
                "Block has more failed authors than missed rounds"
            );
            let mut bound = parent.round();
            for (round, _) in failed_authors {
                ensure!(
                    bound < *round && *round < succ_round,
                    "Incorrect round in failed authors"
                );
                bound = *round;
            }
        }

        if self.is_nil_block() || parent.has_reconfiguration() {
            ensure!(
                self.timestamp_usecs() == parent.timestamp_usecs(),
                "Nil/reconfig suffix block must have same timestamp as parent"
            );
        } else {
            ensure!(
                self.timestamp_usecs() > parent.timestamp_usecs(),
                "Blocks must have strictly increasing timestamps"
            );

            let current_ts = duration_since_epoch();

            // we can say that too far is 5 minutes in the future
            const TIMEBOUND: u64 = 300_000_000;
            ensure!(
                self.timestamp_usecs() <= (current_ts.as_micros() as u64).saturating_add(TIMEBOUND),
                "Blocks must not be too far in the future"
            );
        }
        ensure!(
            !self.quorum_cert().ends_epoch(),
            "Block cannot be proposed in an epoch that has ended"
        );
        debug_checked_verify_eq!(
            self.id(),
            self.block_data.hash(),
            "Block id mismatch the hash"
        );
        Ok(())
    }
```
