# Audit Report

## Title
DoS via Zero Optimal Chunk Sizes in State Sync Data Client

## Summary
Byzantine nodes can advertise optimal chunk sizes of zero for all data types, causing synchronizing nodes to generate invalid data requests in a continuous loop. This prevents nodes from syncing and causes network resource exhaustion through repeated invalid request/retry cycles.

## Finding Description

The vulnerability exists in the state sync data client's optimal chunk size calculation mechanism. Byzantine nodes can advertise `max_chunk_size = 0` in their `ProtocolMetadata`, and if they control enough peers (≥50% of non-ignored peers), the median-based calculation will set the global `OptimalChunkSizes` to zero. [1](#0-0) 

These zero chunk sizes are then used by the stream engine when creating data client requests: [2](#0-1) 

When `optimal_chunk_size = 0`, the calculation at line 2072 produces `num_items_to_fetch = 0`. This leads to:
- Line 2076-2079: `request_end_index = request_start_index - 1` (invalid range)
- Line 2091: `total_items_to_fetch` is never decremented (subtracting 0)
- Loop continues for `max_number_of_requests` iterations, each creating an invalid request

The median calculation uses all non-ignored peer values without validating minimum chunk sizes: [3](#0-2) 

When these invalid requests (with `end_index < start_index`) reach the storage service, they are rejected: [4](#0-3) 

The data stream then retries these failed requests until the retry limit is reached: [5](#0-4) 

After exhausting retries, the stream fails and likely restarts, repeating the cycle indefinitely as long as Byzantine nodes continue advertising zero chunk sizes.

## Impact Explanation

This vulnerability achieves **High severity** impact under the Aptos bug bounty program as it causes:

1. **Validator node slowdowns**: Synchronizing nodes cannot make progress, falling increasingly behind the network
2. **Network degradation**: Continuous generation of invalid requests wastes bandwidth and peer resources
3. **Bootstrapping prevention**: New nodes cannot join the network through state sync

The attack prevents nodes from catching up to the latest blockchain state, effectively creating a denial-of-service condition for any node attempting to synchronize. While existing synchronized validators continue operating, the network's ability to onboard new validators or recover failed nodes is severely compromised.

## Likelihood Explanation

**Likelihood: Medium-High**

Attack requirements:
- Attacker operates multiple full node peers (no validator privileges required)
- Must control ≥50% of non-ignored peers connected to the target node
- Peers must maintain scores above the ignore threshold (25.0) by responding correctly to non-data requests

The attack is realistic because:
1. No validation exists on advertised chunk sizes in `ProtocolMetadata`
2. The peer scoring system doesn't specifically penalize invalid chunk size advertisements
3. Byzantine nodes can maintain high scores by responding correctly to protocol version and summary requests while advertising malicious chunk sizes
4. Full node peers can freely connect to any synchronizing node

## Recommendation

Implement minimum chunk size validation in the optimal chunk size calculation:

```rust
fn calculate_optimal_chunk_sizes(
    config: &AptosDataClientConfig,
    max_epoch_chunk_sizes: Vec<u64>,
    max_state_chunk_sizes: Vec<u64>,
    max_transaction_chunk_sizes: Vec<u64>,
    max_transaction_output_chunk_size: Vec<u64>,
) -> OptimalChunkSizes {
    // Define minimum acceptable chunk sizes to prevent zero-sized requests
    const MIN_EPOCH_CHUNK_SIZE: u64 = 1;
    const MIN_STATE_CHUNK_SIZE: u64 = 1;
    const MIN_TRANSACTION_CHUNK_SIZE: u64 = 1;
    const MIN_TRANSACTION_OUTPUT_CHUNK_SIZE: u64 = 1;

    let epoch_chunk_size = median_or_max(max_epoch_chunk_sizes, config.max_epoch_chunk_size)
        .max(MIN_EPOCH_CHUNK_SIZE);
    let state_chunk_size = median_or_max(max_state_chunk_sizes, config.max_state_chunk_size)
        .max(MIN_STATE_CHUNK_SIZE);
    let transaction_chunk_size = median_or_max(
        max_transaction_chunk_sizes,
        config.max_transaction_chunk_size,
    ).max(MIN_TRANSACTION_CHUNK_SIZE);
    let transaction_output_chunk_size = median_or_max(
        max_transaction_output_chunk_size,
        config.max_transaction_output_chunk_size,
    ).max(MIN_TRANSACTION_OUTPUT_CHUNK_SIZE);

    OptimalChunkSizes {
        epoch_chunk_size,
        state_chunk_size,
        transaction_chunk_size,
        transaction_output_chunk_size,
    }
}
```

Additionally, add validation in `create_data_client_request_batch` to detect and handle zero chunk sizes:

```rust
fn create_data_client_request_batch(
    start_index: u64,
    end_index: u64,
    max_number_of_requests: u64,
    optimal_chunk_size: u64,
    stream_engine: StreamEngine,
) -> Result<Vec<DataClientRequest>, Error> {
    if start_index > end_index {
        return Ok(vec![]);
    }

    // Validate chunk size to prevent infinite loops
    if optimal_chunk_size == 0 {
        return Err(Error::UnexpectedErrorEncountered(
            "Optimal chunk size cannot be zero. This may indicate malicious peer behavior.".into()
        ));
    }
    
    // ... rest of function
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_config::config::AptosDataClientConfig;

    #[test]
    fn test_zero_chunk_size_dos() {
        // Simulate Byzantine nodes advertising zero chunk sizes
        let byzantine_chunk_sizes = vec![0u64, 0u64, 0u64];
        let honest_chunk_sizes = vec![100u64, 100u64];
        
        // Combine to get majority Byzantine
        let mut all_chunk_sizes = byzantine_chunk_sizes.clone();
        all_chunk_sizes.extend(honest_chunk_sizes);
        
        let config = AptosDataClientConfig::default();
        
        // Calculate optimal chunk sizes (will be 0 due to median)
        let optimal = calculate_optimal_chunk_sizes(
            &config,
            all_chunk_sizes.clone(),
            all_chunk_sizes.clone(),
            all_chunk_sizes.clone(),
            all_chunk_sizes,
        );
        
        // Verify that Byzantine nodes can force zero chunk sizes
        assert_eq!(optimal.epoch_chunk_size, 0);
        assert_eq!(optimal.state_chunk_size, 0);
        assert_eq!(optimal.transaction_chunk_size, 0);
        assert_eq!(optimal.transaction_output_chunk_size, 0);
        
        // Demonstrate that zero chunk size causes invalid request generation
        let stream_engine = StateStreamEngine::new(&GetAllStatesRequest {
            version: 100,
            start_index: 0,
        }).unwrap().into();
        
        let requests = create_data_client_request_batch(
            0,
            1000,
            10,
            0, // Zero chunk size from Byzantine nodes
            stream_engine,
        );
        
        // This will create invalid requests where end_index < start_index
        // Each request will fail validation at the storage service
        // The stream will retry until max_request_retry is exhausted
        // Then restart and repeat indefinitely
        assert!(requests.is_ok());
        let request_vec = requests.unwrap();
        
        // Verify multiple invalid requests are created
        assert_eq!(request_vec.len(), 10); // max_number_of_requests
        
        // Each request has end_index < start_index due to zero chunk size
        for req in request_vec {
            if let DataClientRequest::StateValuesWithProof(req) = req {
                assert!(req.end_index < req.start_index); // Invalid range
            }
        }
    }
}
```

This proof of concept demonstrates how Byzantine nodes advertising zero chunk sizes lead to the generation of invalid data requests that will fail validation, causing a continuous retry loop that prevents synchronization progress.

### Citations

**File:** state-sync/storage-service/types/src/responses.rs (L637-642)
```rust
pub struct ProtocolMetadata {
    pub max_epoch_chunk_size: u64, // The max number of epochs the server can return in a single chunk
    pub max_state_chunk_size: u64, // The max number of states the server can return in a single chunk
    pub max_transaction_chunk_size: u64, // The max number of transactions the server can return in a single chunk
    pub max_transaction_output_chunk_size: u64, // The max number of transaction outputs the server can return in a single chunk
}
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2049-2099)
```rust
fn create_data_client_request_batch(
    start_index: u64,
    end_index: u64,
    max_number_of_requests: u64,
    optimal_chunk_size: u64,
    stream_engine: StreamEngine,
) -> Result<Vec<DataClientRequest>, Error> {
    if start_index > end_index {
        return Ok(vec![]);
    }

    // Calculate the total number of items left to satisfy the stream
    let mut total_items_to_fetch = end_index
        .checked_sub(start_index)
        .and_then(|e| e.checked_add(1)) // = end_index - start_index + 1
        .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;

    // Iterate until we've requested all transactions or hit the maximum number of requests
    let mut data_client_requests = vec![];
    let mut num_requests_made = 0;
    let mut next_index_to_request = start_index;
    while total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
        // Calculate the number of items to fetch in this request
        let num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size);

        // Calculate the start and end indices for the request
        let request_start_index = next_index_to_request;
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;

        // Create the data client requests
        let data_client_request =
            create_data_client_request(request_start_index, request_end_index, &stream_engine)?;
        data_client_requests.push(data_client_request);

        // Update the local loop state
        next_index_to_request = request_end_index
            .checked_add(1)
            .ok_or_else(|| Error::IntegerOverflow("Next index to request has overflown!".into()))?;
        total_items_to_fetch = total_items_to_fetch
            .checked_sub(num_items_to_fetch)
            .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;
        num_requests_made = num_requests_made.checked_add(1).ok_or_else(|| {
            Error::IntegerOverflow("Number of payload requests has overflown!".into())
        })?;
    }

    Ok(data_client_requests)
}
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L419-456)
```rust
pub(crate) fn calculate_optimal_chunk_sizes(
    config: &AptosDataClientConfig,
    max_epoch_chunk_sizes: Vec<u64>,
    max_state_chunk_sizes: Vec<u64>,
    max_transaction_chunk_sizes: Vec<u64>,
    max_transaction_output_chunk_size: Vec<u64>,
) -> OptimalChunkSizes {
    let epoch_chunk_size = median_or_max(max_epoch_chunk_sizes, config.max_epoch_chunk_size);
    let state_chunk_size = median_or_max(max_state_chunk_sizes, config.max_state_chunk_size);
    let transaction_chunk_size = median_or_max(
        max_transaction_chunk_sizes,
        config.max_transaction_chunk_size,
    );
    let transaction_output_chunk_size = median_or_max(
        max_transaction_output_chunk_size,
        config.max_transaction_output_chunk_size,
    );

    OptimalChunkSizes {
        epoch_chunk_size,
        state_chunk_size,
        transaction_chunk_size,
        transaction_output_chunk_size,
    }
}

/// Calculates the median of the given set of values (if it exists)
/// and returns the median or the specified max value, whichever is
/// lower.
fn median_or_max<T: Ord + Copy>(mut values: Vec<T>, max_value: T) -> T {
    // Calculate median
    values.sort_unstable();
    let idx = values.len() / 2;
    let median = values.get(idx).copied();

    // Return median or max
    min(median.unwrap_or(max_value), max_value)
}
```

**File:** state-sync/storage-service/server/src/storage.rs (L1485-1494)
```rust
fn inclusive_range_len(start: u64, end: u64) -> aptos_storage_service_types::Result<u64, Error> {
    // len = end - start + 1
    let len = end.checked_sub(start).ok_or_else(|| {
        Error::InvalidRequest(format!("end ({}) must be >= start ({})", end, start))
    })?;
    let len = len
        .checked_add(1)
        .ok_or_else(|| Error::InvalidRequest(format!("end ({}) must not be u64::MAX", end)))?;
    Ok(len)
}
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L440-454)
```rust
    /// Processes any data client responses that have been received. Note: the
    /// responses must be processed in FIFO order.
    pub async fn process_data_responses(
        &mut self,
        global_data_summary: GlobalDataSummary,
    ) -> Result<(), Error> {
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
        }
```
