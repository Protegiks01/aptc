# Audit Report

## Title
Consensus Split Vulnerability via Silent Deserialization Failure in validator_txn_enabled() Native Function

## Summary
The `validator_txn_enabled()` native function silently falls back to a default configuration when deserialization fails, causing validators running different binary versions to make divergent consensus decisions during network upgrades. This violates the Deterministic Execution invariant and causes network halt.

## Finding Description

The vulnerability exists in the native function implementation where deserialization failures are silently handled: [1](#0-0) 

When deserialization fails (e.g., when an old binary encounters a new enum variant), the function returns `OnChainConsensusConfig::default()`, which has validator transactions disabled: [2](#0-1) 

The default configuration uses `ValidatorTxnConfig::default_if_missing()` which returns V0 (disabled): [3](#0-2) [4](#0-3) 

**Attack Scenario:**

During a network upgrade when a new `OnChainConsensusConfig::V6` variant is added:

1. Governance deploys V6 config bytes on-chain via `set_for_next_epoch()`, which only validates non-empty bytes: [5](#0-4) 

2. When `aptos_governance::reconfigure()` is called, it checks `validator_txn_enabled()` to determine the execution path: [6](#0-5) 

3. **Upgraded validators**: Successfully deserialize V6 → see `vtxn=enabled` → call `reconfiguration_with_dkg::try_start()`

4. **Non-upgraded validators**: Deserialization fails → fall back to default with `vtxn=disabled` → call `reconfiguration_with_dkg::finish()`

5. The two paths produce completely different state changes:

**Path A - try_start()**: Sets reconfiguration state to Active and starts DKG session: [7](#0-6) [8](#0-7) [9](#0-8) 

**Path B - finish()**: Clears DKG session, applies configs, and triggers immediate epoch change: [10](#0-9) [11](#0-10) 

6. Validators compute different state roots for the same `reconfigure()` transaction. Since AptosBFT requires 2f+1 validators to agree on the state root to form a quorum certificate, no quorum can be formed, causing permanent network halt.

## Impact Explanation

**Severity: Critical** - This meets the highest severity criteria:

- **Total Loss of Liveness/Network Availability**: When validators compute different state roots for the same block, they cannot form a quorum certificate (requiring 2f+1 agreement). The network halts completely and cannot progress without emergency intervention.

- **Deterministic Execution Violation**: Identical transactions produce different state roots depending solely on the validator's binary version, not on the transaction content or blockchain state. This breaks the fundamental consensus safety guarantee that all honest validators must compute the same result.

The impact is severe because:
1. The network completely halts - no blocks can be committed
2. The divergence affects critical reconfiguration state (StateActive vs StateInactive) and DKG session management (in_progress vs none)
3. Recovery requires coordinated emergency intervention to either roll back all validators or force-upgrade all validators
4. The failure is silent - no errors are logged, making diagnosis extremely difficult
5. Unlike Byzantine faults which require >1/3 malicious actors, this affects ALL validators behaving honestly

## Likelihood Explanation

**Likelihood: High** during network upgrades

The vulnerability triggers whenever:
1. A new `OnChainConsensusConfig` enum variant is added (standard practice during major upgrades)
2. The new config is deployed on-chain before 100% of validators have upgraded
3. A governance `reconfigure()` call is made during the mixed-version window

This is highly likely because:
- Blockchain upgrades routinely add new config versions to support new features
- Perfect synchronization of all validator upgrades across a decentralized network is practically impossible
- Network upgrades typically have a transition window of hours to days where validators run mixed versions
- The `set_for_next_epoch()` function provides zero validation that config bytes are compatible with running validators
- No runtime checks prevent deploying configs that cannot be deserialized by some validators
- The comment in the code even acknowledges the dual requirement but doesn't protect against version mismatches [12](#0-11) 

## Recommendation

Replace `unwrap_or_default()` with explicit error handling that aborts execution when deserialization fails:

```rust
pub fn validator_txn_enabled(
    context: &mut SafeNativeContext,
    _ty_args: &[Type],
    mut args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    let config_bytes = safely_pop_arg!(args, Vec<u8>);
    let config = bcs::from_bytes::<OnChainConsensusConfig>(&config_bytes)
        .map_err(|e| {
            SafeNativeError::InvariantViolation(
                format!("Failed to deserialize OnChainConsensusConfig: {}", e)
            )
        })?;
    Ok(smallvec![Value::bool(config.is_vtxn_enabled())])
}
```

Additionally, add validation in `set_for_next_epoch()` to verify the config bytes can be successfully deserialized:

```move
public fun set_for_next_epoch(account: &signer, config: vector<u8>) {
    system_addresses::assert_aptos_framework(account);
    assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
    // Validate deserialization through native function
    assert!(validator_txn_enabled_internal(config), error::invalid_argument(EINVALID_CONFIG));
    std::config_buffer::upsert<ConsensusConfig>(ConsensusConfig {config});
}
```

## Proof of Concept

A full Move test would require:
1. Simulating a network upgrade by adding a V6 variant to OnChainConsensusConfig
2. Deploying V6 config bytes on-chain
3. Having two validators (one with V6 support, one without) execute reconfigure()
4. Observing different state transitions

The technical analysis above demonstrates the vulnerability exists in the current codebase through direct code citations showing the silent fallback behavior and divergent execution paths.

### Citations

**File:** aptos-move/framework/src/natives/consensus_config.rs (L18-20)
```rust
    let config_bytes = safely_pop_arg!(args, Vec<u8>);
    let config = bcs::from_bytes::<OnChainConsensusConfig>(&config_bytes).unwrap_or_default();
    Ok(smallvec![Value::bool(config.is_vtxn_enabled())])
```

**File:** types/src/on_chain_config/consensus_config.rs (L147-149)
```rust
    pub fn default_if_missing() -> Self {
        Self::V0
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L162-167)
```rust
    pub fn enabled(&self) -> bool {
        match self {
            ValidatorTxnConfig::V0 => false,
            ValidatorTxnConfig::V1 { .. } => true,
        }
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L443-450)
```rust
impl Default for OnChainConsensusConfig {
    fn default() -> Self {
        OnChainConsensusConfig::V4 {
            alg: ConsensusAlgorithmConfig::default_if_missing(),
            vtxn: ValidatorTxnConfig::default_if_missing(),
            window_size: DEFAULT_WINDOW_SIZE,
        }
    }
```

**File:** aptos-move/framework/aptos-framework/sources/configs/consensus_config.move (L52-56)
```text
    public fun set_for_next_epoch(account: &signer, config: vector<u8>) {
        system_addresses::assert_aptos_framework(account);
        assert!(vector::length(&config) > 0, error::invalid_argument(EINVALID_CONFIG));
        std::config_buffer::upsert<ConsensusConfig>(ConsensusConfig {config});
    }
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L685-692)
```text
    public entry fun reconfigure(aptos_framework: &signer) {
        system_addresses::assert_aptos_framework(aptos_framework);
        if (consensus_config::validator_txn_enabled() && randomness_config::enabled()) {
            reconfiguration_with_dkg::try_start();
        } else {
            reconfiguration_with_dkg::finish(aptos_framework);
        }
    }
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration_with_dkg.move (L24-40)
```text
    public(friend) fun try_start() {
        let incomplete_dkg_session = dkg::incomplete_session();
        if (option::is_some(&incomplete_dkg_session)) {
            let session = option::borrow(&incomplete_dkg_session);
            if (dkg::session_dealer_epoch(session) == reconfiguration::current_epoch()) {
                return
            }
        };
        reconfiguration_state::on_reconfig_start();
        let cur_epoch = reconfiguration::current_epoch();
        dkg::start(
            cur_epoch,
            randomness_config::current(),
            stake::cur_validator_consensus_infos(),
            stake::next_validator_consensus_infos(),
        );
    }
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration_with_dkg.move (L46-61)
```text
    public(friend) fun finish(framework: &signer) {
        system_addresses::assert_aptos_framework(framework);
        dkg::try_clear_incomplete_session(framework);
        consensus_config::on_new_epoch(framework);
        execution_config::on_new_epoch(framework);
        gas_schedule::on_new_epoch(framework);
        std::version::on_new_epoch(framework);
        features::on_new_epoch(framework);
        jwk_consensus_config::on_new_epoch(framework);
        jwks::on_new_epoch(framework);
        keyless_account::on_new_epoch(framework);
        randomness_config_seqnum::on_new_epoch(framework);
        randomness_config::on_new_epoch(framework);
        randomness_api_v0_config::on_new_epoch(framework);
        reconfiguration::reconfigure();
    }
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration_state.move (L67-77)
```text
    public(friend) fun on_reconfig_start() acquires State {
        if (exists<State>(@aptos_framework)) {
            let state = borrow_global_mut<State>(@aptos_framework);
            let variant_type_name = *string::bytes(copyable_any::type_name(&state.variant));
            if (variant_type_name == b"0x1::reconfiguration_state::StateInactive") {
                state.variant = copyable_any::pack(StateActive {
                    start_time_secs: timestamp::now_seconds()
                });
            }
        };
    }
```

**File:** aptos-move/framework/aptos-framework/sources/dkg.move (L61-85)
```text
    public(friend) fun start(
        dealer_epoch: u64,
        randomness_config: RandomnessConfig,
        dealer_validator_set: vector<ValidatorConsensusInfo>,
        target_validator_set: vector<ValidatorConsensusInfo>,
    ) acquires DKGState {
        let dkg_state = borrow_global_mut<DKGState>(@aptos_framework);
        let new_session_metadata = DKGSessionMetadata {
            dealer_epoch,
            randomness_config,
            dealer_validator_set,
            target_validator_set,
        };
        let start_time_us = timestamp::now_microseconds();
        dkg_state.in_progress = std::option::some(DKGSessionState {
            metadata: new_session_metadata,
            start_time_us,
            transcript: vector[],
        });

        emit(DKGStartEvent {
            start_time_us,
            session_metadata: new_session_metadata,
        });
    }
```

**File:** aptos-move/framework/aptos-framework/sources/dkg.move (L100-106)
```text
    public fun try_clear_incomplete_session(fx: &signer) acquires DKGState {
        system_addresses::assert_aptos_framework(fx);
        if (exists<DKGState>(@aptos_framework)) {
            let dkg_state = borrow_global_mut<DKGState>(@aptos_framework);
            dkg_state.in_progress = option::none();
        }
    }
```

**File:** aptos-move/framework/aptos-framework/sources/configs/randomness_config.move (L71-74)
```text
    /// Check whether on-chain randomness main logic (e.g., `DKGManager`, `RandManager`, `BlockMetadataExt`) is enabled.
    ///
    /// NOTE: this returning true does not mean randomness will run.
    /// The feature works if and only if `consensus_config::validator_txn_enabled() && randomness_config::enabled()`.
```
