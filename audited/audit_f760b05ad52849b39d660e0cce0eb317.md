# Audit Report

## Title
Torn Reads in BlockReader Methods Allow Inconsistent State Observation During Concurrent Root Updates

## Summary
The `BlockStore` implementation allows torn reads where `BlockReader` methods can observe partially updated state during root updates. Multiple write operations in `send_for_execution` acquire separate write locks, while reader methods acquire separate read locks for each field access. This violates atomicity guarantees and can cause validators to make incorrect consensus decisions based on inconsistent state.

## Finding Description

The `BlockReader` trait methods in `BlockStore` are implemented with separate read lock acquisitions for each call, creating race conditions when roots are updated concurrently.

**Primary Issue in send_for_execution:** [1](#0-0) 

These are two separate write lock acquisitions. Between them, readers can observe `ordered_root` updated to the new value but `highest_ordered_cert` still containing the old value.

**Torn Reads in Readers:**

The `vote_back_pressure()` method acquires two separate read locks: [2](#0-1) 

Between these reads, a concurrent update can modify the roots, causing inconsistent calculations.

**Most Critical Case - pipeline_pending_latency:** [3](#0-2) 

This function reads `ordered_root()` **twice** (lines 707 and 710). If `ordered_root` is updated between these reads, the function operates on fundamentally inconsistent data:
- `ordered_root` variable contains BlockA
- `path_from_commit_root(self.ordered_root().id())` uses BlockB
- All subsequent latency calculations mix data from two different chain states

**Evidence of Known Issue:**

The developers understood atomic updates were necessary, as evidenced by the `prune_tree` test helper: [4](#0-3) 

The comment "synchronously update both root_id and commit_root_id" and single write lock acquisition prove awareness that these updates must be atomic. However, this pattern was not applied consistently to `send_for_execution`.

**Attack Scenario:**

1. Validator processes block proposals under normal load
2. Thread A calls `pipeline_pending_latency()` for proposal validation
3. Thread A reads `ordered_root = Block100` (line 707)
4. Thread B concurrently calls `send_for_execution(Block110)`:
   - Acquires first write lock, updates `ordered_root` to Block110
   - Releases lock before acquiring second lock
5. Thread A continues: reads `self.ordered_root().id()` now returns Block110 (line 710)
6. Thread A calculates `path_from_commit_root(Block110)` but has `ordered_root` variable = Block100
7. Result: Incorrect `pending_path`, `oldest_not_committed`, and all latency calculations

This incorrect latency feeds into backpressure configuration: [5](#0-4) 

Leading to incorrect limits on block size, transaction count, and proposal delays.

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **Validator node slowdowns**: Incorrect backpressure calculations can cause validators to unnecessarily throttle block production, degrading network throughput
2. **Significant protocol violations**: The State Consistency invariant requiring atomic state transitions is violated
3. **Consensus liveness impact**: The `vote_back_pressure()` torn reads can cause validators to incorrectly enter `sync_only` mode (stopping voting) or fail to enter it when needed: [6](#0-5) 

If multiple validators simultaneously experience torn reads causing incorrect sync_only decisions, consensus progress could stall.

## Likelihood Explanation

**High likelihood** under normal operation:
- Occurs naturally during concurrent block processing
- No attacker action required - triggered by normal consensus operations
- Probability increases with network load and block commit rate
- Multiple code paths exhibit the vulnerability (vote_back_pressure, pipeline_pending_latency, sync_info)

The race window exists between every write lock acquisition in `send_for_execution`, creating continuous opportunities for torn reads during active consensus.

## Recommendation

**Fix**: Acquire the write lock once and perform all related updates atomically, following the pattern already established in `prune_tree`:

```rust
pub async fn send_for_execution(
    &self,
    finality_proof: WrappedLedgerInfo,
) -> anyhow::Result<()> {
    // ... existing validation code ...
    
    let finality_proof_clone = finality_proof.clone();
    self.pending_blocks
        .lock()
        .gc(finality_proof.commit_info().round());

    // FIXED: Single write lock for atomic update
    {
        let mut inner = self.inner.write();
        inner.update_ordered_root(block_to_commit.id());
        inner.insert_ordered_cert(finality_proof_clone.clone());
    }
    
    update_counters_for_ordered_blocks(&blocks_to_commit);

    self.execution_client
        .finalize_order(blocks_to_commit, finality_proof.clone())
        .await
        .expect("Failed to persist commit");

    Ok(())
}
```

Additionally, consider adding reader methods that atomically read multiple related fields to prevent torn reads in critical paths like `vote_back_pressure()`.

## Proof of Concept

```rust
#[tokio::test]
async fn test_torn_reads_in_pipeline_latency() {
    use std::sync::Arc;
    use std::time::Duration;
    use tokio::task;
    
    // Setup: Create BlockStore with initial state
    let block_store = /* initialize BlockStore */;
    
    // Spawn concurrent tasks
    let store_clone1 = Arc::clone(&block_store);
    let store_clone2 = Arc::clone(&block_store);
    
    let reader_task = task::spawn(async move {
        // Continuously call pipeline_pending_latency
        for _ in 0..1000 {
            let latency = store_clone1.pipeline_pending_latency(Duration::from_secs(1));
            // Check for inconsistencies (would require tracking internal state)
        }
    });
    
    let writer_task = task::spawn(async move {
        // Continuously update roots
        for i in 0..100 {
            let proof = /* create finality proof for block i */;
            let _ = store_clone2.send_for_execution(proof).await;
        }
    });
    
    let _ = tokio::join!(reader_task, writer_task);
    
    // With high probability, torn reads will occur during execution
    // This can be verified by adding assertions to track when
    // ordered_root() returns different values within the same function call
}
```

**Notes**

This vulnerability represents a fundamental concurrency correctness issue in the consensus layer. While not exploitable by external attackers through crafted transactions, it can cause validators to make incorrect decisions based on inconsistent state views during normal operation. The bug manifests most clearly in `pipeline_pending_latency()` which reads `ordered_root()` twice, but affects multiple critical consensus decision points including vote backpressure and sync state calculations.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L338-341)
```rust
        self.inner.write().update_ordered_root(block_to_commit.id());
        self.inner
            .write()
            .insert_ordered_cert(finality_proof_clone.clone());
```

**File:** consensus/src/block_storage/block_store.rs (L698-699)
```rust
        let commit_round = self.commit_root().round();
        let ordered_round = self.ordered_root().round();
```

**File:** consensus/src/block_storage/block_store.rs (L707-710)
```rust
        let ordered_root = self.ordered_root();
        let commit_root = self.commit_root();
        let pending_path = self
            .path_from_commit_root(self.ordered_root().id())
```

**File:** consensus/src/block_storage/block_store.rs (L855-860)
```rust
        // synchronously update both root_id and commit_root_id
        let mut wlock = self.inner.write();
        wlock.update_ordered_root(next_root_id);
        wlock.update_commit_root(next_root_id);
        wlock.update_window_root(next_root_id);
        wlock.process_pruned_blocks(id_to_remove.clone());
```

**File:** consensus/src/liveness/proposal_generator.rs (L766-777)
```rust
        let pipeline_pending_latency = self.block_store.pipeline_pending_latency(timestamp);
        let pipeline_backpressure = self
            .pipeline_backpressure_config
            .get_backoff(pipeline_pending_latency);
        if let Some(value) = pipeline_backpressure {
            values_max_block_txns_after_filtering
                .push(value.max_sending_block_txns_after_filtering_override);
            values_max_block.push(
                self.max_block_txns
                    .compute_with_bytes(value.max_sending_block_bytes_override),
            );
            values_proposal_delay.push(Duration::from_millis(value.backpressure_proposal_delay_ms));
```

**File:** consensus/src/round_manager.rs (L1514-1517)
```rust
        ensure!(
            !self.sync_only(),
            "[RoundManager] sync_only flag is set, stop voting"
        );
```
