# Audit Report

## Title
Transaction Censorship via Malicious Batch Broadcasting in Quorum Store

## Summary
A malicious validator can systematically censor specific users' transactions by repeatedly broadcasting batches containing those transactions, causing them to be excluded from honest nodes' mempool pulls indefinitely. This breaks transaction inclusion fairness and enables sustained censorship without requiring the malicious batches to be included in blocks.

## Finding Description

The vulnerability exists in how the Quorum Store handles remote batch messages and manages the `exclude_transactions` map used for mempool pulls.

**Attack Flow:**

1. **Batch Broadcast**: A malicious validator creates `BatchMsg` containing transactions from users they wish to censor and broadcasts it to all nodes. [1](#0-0) 

2. **Verification Passes**: The batch passes verification because it only checks that the author matches the peer_id and is in the validator set - it does NOT verify that the validator actually obtained these transactions from their own mempool. [2](#0-1) 

3. **Remote Batch Processing**: All nodes receive the batch and add the transactions to `txns_in_progress_sorted` via `handle_remote_batch`. [3](#0-2) 

4. **Transaction Exclusion**: These transactions are added to `txns_in_progress_sorted`, which is cloned and passed as `exclude_transactions` to mempool pulls. [4](#0-3) 

5. **Mempool Filtering**: When mempool processes `GetBatchRequest`, it skips all transactions in `exclude_transactions`. [5](#0-4) 

6. **Sustained Censorship**: The malicious batches expire after 500ms, but the attacker can repeatedly send new batches with different `batch_id` values to maintain indefinite censorship. [6](#0-5) 

**Key Vulnerability**: The system assumes remote batches contain transactions the sending validator legitimately pulled from their own mempool. However, there is no enforcement of this assumption - validators can include arbitrary transactions in their batches without penalty. [7](#0-6) 

## Impact Explanation

**High Severity** - This qualifies as a "Significant protocol violation" under the Aptos bug bounty program:

- **Transaction Inclusion Fairness Broken**: Users' transactions can be censored indefinitely by any single malicious validator
- **No Proof of Store Required**: The attacker doesn't need to get these batches included in blocks - just broadcasting them is sufficient
- **Network-Wide Effect**: All honest nodes are affected simultaneously since batches are broadcast to all validators
- **Sustained Attack**: The 500ms expiry can be circumvented by continuously sending new batches
- **No Economic Cost**: The attacker faces no penalties for sending batches that never result in proofs of store

The attack does not require consensus collusion (>1/3 validators) - a single malicious validator can execute it.

## Likelihood Explanation

**High Likelihood**:

- **Easy to Execute**: Attacker only needs to monitor mempool gossip, collect target transactions, and broadcast batches
- **No Detection Mechanism**: No counters or alerts for validators repeatedly sending batches without proofs of store
- **No Rate Limiting**: BatchMsg verification has no rate limits or reputation penalties [8](#0-7) 

- **Low Complexity**: Attack requires standard validator operations with no special exploits
- **Realistic Scenario**: Byzantine validators are an accepted threat model in BFT consensus systems

## Recommendation

Implement the following mitigations:

1. **Batch Origin Validation**: Track which transactions each validator has in their mempool and reject batches containing transactions the sender shouldn't have access to.

2. **Proof of Store Requirement**: Modify remote batch handling to only add transactions to `txns_in_progress_sorted` after the batch obtains a valid proof of store (quorum of signatures).

3. **Rate Limiting**: Implement per-validator rate limits on batch broadcasts and track validators who repeatedly send batches without obtaining proofs.

4. **Reputation System**: Add penalties for validators whose batches consistently fail to achieve proof of store, and reduce their impact on `exclude_transactions`.

5. **Time-Based Exclusion**: Instead of excluding transactions for the full batch expiry duration, implement a shorter exclusion window that only applies after a batch achieves proof of store.

**Suggested Code Fix** (in `batch_generator.rs`):

```rust
pub(crate) fn handle_remote_batch(
    &mut self,
    author: PeerId,
    batch_id: BatchId,
    txns: Vec<SignedTransaction>,
    has_proof_of_store: bool, // Add this parameter
) {
    // Only add to txns_in_progress_sorted if batch has proof of store
    if !has_proof_of_store {
        return; // Reject batches without proof
    }
    
    let expiry_time_usecs = aptos_infallible::duration_since_epoch().as_micros() as u64
        + self.config.remote_batch_expiry_gap_when_init_usecs;
    self.insert_batch(author, batch_id, txns, expiry_time_usecs);
}
```

## Proof of Concept

```rust
// Simulated attack scenario
#[test]
fn test_transaction_censorship_attack() {
    // Setup: Create a batch generator and mempool proxy
    let mut batch_generator = create_test_batch_generator();
    
    // Step 1: Target user creates a transaction
    let target_txn = create_signed_transaction(target_user_address, seq_num);
    
    // Step 2: Malicious validator creates batch with target transaction
    let malicious_batch = Batch::new_v2(
        batch_id_1,
        vec![target_txn.clone()],
        epoch,
        expiry_time,
        malicious_validator_id,
        gas_bucket_start,
        BatchKind::Normal,
    );
    
    // Step 3: Malicious validator broadcasts batch (passes verification)
    batch_generator.handle_remote_batch(
        malicious_validator_id,
        batch_id_1,
        vec![target_txn.clone()],
    );
    
    // Step 4: Verify target transaction is in exclude_transactions
    assert!(batch_generator.txns_in_progress_sorted.contains_key(
        &TransactionSummary::new(
            target_txn.sender(),
            target_txn.replay_protector(),
            target_txn.committed_hash()
        )
    ));
    
    // Step 5: Honest node tries to pull from mempool
    let pulled_txns = mempool_proxy.pull_internal(
        max_count,
        max_bytes,
        batch_generator.txns_in_progress_sorted.clone(),
    ).await.unwrap();
    
    // Verify: Target transaction is excluded from pulled transactions
    assert!(!pulled_txns.contains(&target_txn));
    
    // Step 6: After 500ms expiry, malicious validator sends new batch
    tokio::time::sleep(Duration::from_millis(500)).await;
    let malicious_batch_2 = create_batch_with_different_id(target_txn);
    
    // Attack continues indefinitely...
}
```

## Notes

This vulnerability requires the attacker to be a validator in the active validator set, which is consistent with the Byzantine fault tolerance model (< 1/3 Byzantine validators) explicitly referenced in Aptos's critical invariants. A single Byzantine validator can execute this attack without requiring collusion. The issue fundamentally breaks the assumption that remote batches represent legitimate transaction batching by honest validators.

### Citations

**File:** consensus/src/quorum_store/types.rs (L424-461)
```rust
pub struct BatchMsg<T: TBatchInfo> {
    batches: Vec<Batch<T>>,
}

impl<T: TBatchInfo> BatchMsg<T> {
    pub fn new(batches: Vec<Batch<T>>) -> Self {
        Self { batches }
    }

    pub fn verify(
        &self,
        peer_id: PeerId,
        max_num_batches: usize,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        ensure!(!self.batches.is_empty(), "Empty message");
        ensure!(
            self.batches.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.batches.len(),
            max_num_batches
        );
        let epoch_authors = verifier.address_to_validator_index();
        for batch in self.batches.iter() {
            ensure!(
                epoch_authors.contains_key(&batch.author()),
                "Invalid author {} for batch {} in current epoch",
                batch.author(),
                batch.digest()
            );
            ensure!(
                batch.author() == peer_id,
                "Batch author doesn't match sender"
            );
            batch.verify()?
        }
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L123-171)
```rust
    fn insert_batch(
        &mut self,
        author: PeerId,
        batch_id: BatchId,
        txns: Vec<SignedTransaction>,
        expiry_time_usecs: u64,
    ) {
        if self.batches_in_progress.contains_key(&(author, batch_id)) {
            return;
        }

        let txns_in_progress: Vec<_> = txns
            .par_iter()
            .with_min_len(optimal_min_len(txns.len(), 32))
            .map(|txn| {
                (
                    TransactionSummary::new(
                        txn.sender(),
                        txn.replay_protector(),
                        txn.committed_hash(),
                    ),
                    TransactionInProgress::new(txn.gas_unit_price()),
                )
            })
            .collect();

        let mut txns = vec![];
        for (summary, info) in txns_in_progress {
            let txn_info = self
                .txns_in_progress_sorted
                .entry(summary)
                .or_insert_with(|| TransactionInProgress::new(info.gas_unit_price));
            txn_info.increment();
            txn_info.gas_unit_price = info.gas_unit_price.max(txn_info.gas_unit_price);
            txns.push(summary);
        }
        let updated_expiry_time_usecs = self
            .batches_in_progress
            .get(&(author, batch_id))
            .map_or(expiry_time_usecs, |batch_in_progress| {
                expiry_time_usecs.max(batch_in_progress.expiry_time_usecs)
            });
        self.batches_in_progress.insert(
            (author, batch_id),
            BatchInProgress::new(txns, updated_expiry_time_usecs),
        );
        self.batch_expirations
            .add_item((author, batch_id), updated_expiry_time_usecs);
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L352-360)
```rust
        let mut pulled_txns = self
            .mempool_proxy
            .pull_internal(
                max_count,
                self.config.sender_max_total_bytes as u64,
                self.txns_in_progress_sorted.clone(),
            )
            .await
            .unwrap_or_default();
```

**File:** consensus/src/quorum_store/batch_generator.rs (L392-401)
```rust
    pub(crate) fn handle_remote_batch(
        &mut self,
        author: PeerId,
        batch_id: BatchId,
        txns: Vec<SignedTransaction>,
    ) {
        let expiry_time_usecs = aptos_infallible::duration_since_epoch().as_micros() as u64
            + self.config.remote_batch_expiry_gap_when_init_usecs;
        self.insert_batch(author, batch_id, txns, expiry_time_usecs);
    }
```

**File:** mempool/src/core_mempool/mempool.rs (L454-456)
```rust
            if exclude_transactions.contains_key(&txn_ptr) {
                continue;
            }
```

**File:** config/src/config/quorum_store_config.rs (L132-132)
```rust
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
```

**File:** consensus/src/round_manager.rs (L166-173)
```rust
            UnverifiedEvent::BatchMsg(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(Box::new((*b).into()))
```
