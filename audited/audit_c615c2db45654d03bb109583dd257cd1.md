# Audit Report

## Title
Unmetered Borrow Graph Operations in Bytecode Verification Enable Validator CPU Exhaustion

## Summary
Move bytecode verification contains a metering discrepancy where `construct_canonical_state` operations execute outside the verification meter's accounting scope. This allows attackers to create modules that consume excessive validator CPU time through unmetered O(n log n) `remap_refs` operations at every basic block boundary, causing validator slowdowns during module publishing.

## Finding Description

During Move bytecode verification for module publishing, the reference safety checker maintains a borrow graph to track reference relationships. The critical metering gap occurs in the `TransferFunctions::execute` implementation for reference safety analysis.

The verification flow proceeds as follows:

1. At each bytecode instruction, `execute_inner` is called and properly meters the work using `STEP_BASE_COST`, `STEP_PER_LOCAL_COST`, and `STEP_PER_GRAPH_ITEM_COST` [1](#0-0) 

2. After `execute_inner` returns, when at the last instruction of a basic block (index == last_index), `construct_canonical_state` is called to canonicalize the abstract state [2](#0-1) 

3. The `construct_canonical_state` method builds an ID mapping and then calls `borrow_graph.remap_refs(&id_map)` to remap all references to canonical form [3](#0-2) 

4. The `remap_refs` implementation takes the entire BTreeMap, iterates through all entries, and rebuilds it via `.collect()`, which has O(n log n) complexity where n is the number of references in the graph [4](#0-3) 

**The vulnerability:** Steps 2-4 occur AFTER `execute_inner` returns, placing all this work completely outside the verification meter's scope. No meter charges are applied for the expensive BTreeMap reconstruction.

**Attack Path:**
An attacker crafts a Move module that:
- Maximizes basic blocks up to the production limit of 1024 [5](#0-4) 
- Uses reference parameters and creates many local borrows to maximize borrow graph size
- Triggers 1024 unmetered `remap_refs` operations (one per basic block boundary)
- For a borrow graph with n references, this causes 1024 × O(n log n) unmetered CPU work

With production limits allowing graphs of hundreds of references, the unmetered work represents a log(n) factor (≈7-10x for n=100-200) more computation than what the meter charges linearly.

## Impact Explanation

This qualifies as **High Severity** under the "Validator Node Slowdowns" category because:

1. **Resource Exhaustion Without Accountability**: Verification happens synchronously during module publishing on every validator. The unmetered O(n log n) operations at 1024 basic block boundaries can consume significant CPU time without corresponding meter charges, allowing attackers to exhaust validator resources below the configured meter limits.

2. **Consensus Impact**: When validators process module publishing transactions, the excessive unmetered verification work causes processing delays. This can lead to validators falling behind consensus, timeout issues, or degraded network performance.

3. **Unfair Cost Distribution**: The verification meter charges linearly (`STEP_PER_GRAPH_ITEM_COST × graph_size`) but actual work is O(n log n). This discrepancy means attackers can cause disproportionate CPU usage relative to meter costs.

**Mitigating Factors:**
- Module verification results are cached by hash in `VERIFIED_MODULES_CACHE` [6](#0-5) 
- Production meter limit is 80,000,000 units [7](#0-6) 
- Transaction size and other verification limits bound maximum complexity
- Attack requires publishing many unique module hashes to bypass caching

However, these mitigations don't eliminate the vulnerability - they only reduce its practical exploitability. The first verification of each unique module still causes unaccounted CPU exhaustion.

## Likelihood Explanation

**High likelihood** because:
- Any user can submit module publishing transactions without special privileges
- Maximizing basic blocks and reference count is straightforward within production limits
- Every validator must verify the module synchronously when first encountered
- The attack path is simple: craft module bytecode with maximum basic blocks and references
- Module publishing is a standard transaction type that must be processed

**Practical Constraints:**
- Sustained attack requires publishing many unique modules (different hashes) to avoid caching
- Module publishing has gas costs (though this is separate from verification meter costs)
- Limited by production configuration: max_basic_blocks (1024), max_per_fun_meter_units (80M)

## Recommendation

Meter the `construct_canonical_state` operation by passing the meter into it and charging for the borrow graph remapping work. Specifically:

1. Modify `construct_canonical_state` to accept a `meter: &mut impl Meter` parameter
2. Before calling `borrow_graph.remap_refs()`, add meter charges proportional to the graph size
3. Use a cost factor that accounts for the O(n log n) complexity, not just linear
4. Update the `TransferFunctions::execute` implementation to pass the meter through to `construct_canonical_state`

Example fix structure:
```rust
pub fn construct_canonical_state(&self, meter: &mut impl Meter) -> PartialVMResult<Self> {
    // ... existing id_map construction ...
    
    // Meter the remap operation with O(n log n) cost factor
    let graph_size = self.borrow_graph.graph_size();
    let remap_cost = calculate_remap_cost(graph_size); // O(n log n) factor
    meter.add(Scope::Function, remap_cost)?;
    
    let mut borrow_graph = self.borrow_graph.clone();
    borrow_graph.remap_refs(&id_map);
    
    // ... rest of canonicalization ...
}
```

## Proof of Concept

While a complete executable PoC is not provided, the attack can be demonstrated by:

1. Creating a Move module with maximum basic blocks (1024) using branching control flow
2. Adding reference parameters and local borrow operations to maximize the borrow graph size
3. Publishing the module and measuring validator verification time
4. Comparing the verification meter charges against actual CPU time consumed
5. Observing that O(n log n) work occurs 1024 times without corresponding meter charges

The vulnerability is demonstrated by the code structure itself: the call to `construct_canonical_state` occurs after `execute_inner` returns and outside any metering scope, as shown in the cited code locations.

## Notes

- The report states the meter limit is 8M, but the actual production value is 80M units - this doesn't affect the validity of the vulnerability
- The vulnerability affects the Move bytecode verifier integrated into Aptos Core under `third_party/move/`, which is in-scope for the bug bounty program
- This is a metering discrepancy issue, not a correctness bug - verification still produces correct results, but at unaccounted computational cost
- The caching mechanism (`VERIFIED_MODULES_CACHE`) significantly reduces practical exploitability but doesn't eliminate the issue for first-time module verification

### Citations

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/mod.rs (L246-252)
```rust
    meter.add(Scope::Function, STEP_BASE_COST)?;
    meter.add_items(Scope::Function, STEP_PER_LOCAL_COST, state.local_count())?;
    meter.add_items(
        Scope::Function,
        STEP_PER_GRAPH_ITEM_COST,
        state.graph_size(),
    )?;
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/mod.rs (L687-694)
```rust
    ) -> PartialVMResult<()> {
        execute_inner(self, state, bytecode, index, meter)?;
        if index == last_index {
            safe_assert!(self.stack.is_empty());
            *state = state.construct_canonical_state()
        }
        Ok(())
    }
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/abstract_state.rs (L624-651)
```rust
    pub fn construct_canonical_state(&self) -> Self {
        let mut id_map = BTreeMap::new();
        id_map.insert(self.frame_root(), self.frame_root());
        let locals = self
            .locals
            .iter()
            .enumerate()
            .map(|(local, value)| match value {
                AbstractValue::Reference(old_id) => {
                    let new_id = RefID::new(local);
                    id_map.insert(*old_id, new_id);
                    AbstractValue::Reference(new_id)
                },
                AbstractValue::NonReference => AbstractValue::NonReference,
            })
            .collect::<Vec<_>>();
        assert!(self.locals.len() == locals.len());
        let mut borrow_graph = self.borrow_graph.clone();
        borrow_graph.remap_refs(&id_map);
        let canonical_state = AbstractState {
            locals,
            borrow_graph,
            current_function: self.current_function,
            next_id: self.locals.len() + 1,
        };
        assert!(canonical_state.is_canonical());
        canonical_state
    }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L371-384)
```rust
    pub fn remap_refs(&mut self, id_map: &BTreeMap<RefID, RefID>) {
        debug_assert!(self.check_invariant());
        let _before = self.0.len();
        self.0 = std::mem::take(&mut self.0)
            .into_iter()
            .map(|(id, mut info)| {
                info.remap_refs(id_map);
                (id_map.get(&id).copied().unwrap_or(id), info)
            })
            .collect();
        let _after = self.0.len();
        debug_assert!(_before == _after);
        debug_assert!(self.check_invariant());
    }
```

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L160-160)
```rust
        max_basic_blocks: Some(1024),
```

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L175-175)
```rust
        max_per_fun_meter_units: Some(1000 * 80000),
```

**File:** third_party/move/move-vm/runtime/src/storage/verified_module_cache.rs (L1-50)
```rust
// Copyright (c) The Move Contributors
// SPDX-License-Identifier: Apache-2.0

use cfg_if::cfg_if;
use lazy_static::lazy_static;
use parking_lot::Mutex;
use std::num::NonZeroUsize;

/// Cache for already verified modules. Since loader V1 uses such a cache to not perform repeated
/// verifications, possibly even across blocks, for comparative performance we need to have it as
/// well. For now, we keep it as a separate cache to make sure there is no interference between V1
/// and V2 implementations.
pub(crate) struct VerifiedModuleCache(Mutex<lru::LruCache<[u8; 32], ()>>);

impl VerifiedModuleCache {
    /// Maximum size of the cache. When modules are cached, they can skip re-verification.
    const VERIFIED_CACHE_SIZE: NonZeroUsize = NonZeroUsize::new(100_000).unwrap();

    /// Returns new empty verified module cache.
    pub(crate) fn empty() -> Self {
        Self(Mutex::new(lru::LruCache::new(Self::VERIFIED_CACHE_SIZE)))
    }

    /// Returns true if the module hash is contained in the cache. For tests, the cache is treated
    /// as empty at all times.
    pub(crate) fn contains(&self, module_hash: &[u8; 32]) -> bool {
        // Note: need to use get to update LRU queue.
        verifier_cache_enabled() && self.0.lock().get(module_hash).is_some()
    }

    /// Inserts the hash into the cache, marking the corresponding as locally verified. For tests,
    /// entries are not added to the cache.
    pub(crate) fn put(&self, module_hash: [u8; 32]) {
        if verifier_cache_enabled() {
            let mut cache = self.0.lock();
            cache.put(module_hash, ());
        }
    }

    /// Flushes the verified modules cache.
    pub(crate) fn flush(&self) {
        self.0.lock().clear();
    }

    /// Returns the number of verified modules in the cache.
    pub(crate) fn size(&self) -> usize {
        self.0.lock().len()
    }
}

```
