# Audit Report

## Title
Non-Atomic Database Restore Operations Leave AptosDB in Unrecoverable Inconsistent State

## Summary
The `save_transactions()` function in restore_utils.rs performs two separate, non-atomic database writes to state_kv_db and ledger_db. If the process crashes or encounters errors between these writes, the database enters a permanently inconsistent state that the recovery mechanism (`sync_commit_progress`) cannot repair, requiring complete manual database restoration.

## Finding Description
The vulnerability exists in the `save_transactions()` function's commit sequence when no existing batch is provided: [1](#0-0) 

This code performs two separate database commits:
1. First commits state changes to state_kv_db (line 167-170)
2. Then commits transaction metadata and OverallCommitProgress to ledger_db (line 172)

The critical issue is that **OverallCommitProgress** is written to the ledger_db batch, not atomically with state_kv_db: [2](#0-1) 

If the process crashes, is killed, or encounters disk errors after the state_kv_db commit succeeds but before ledger_db.write_schemas() completes:
- state_kv_db contains committed state at version V
- StateKvCommitProgress is updated to V
- ledger_db does NOT contain transactions, events, or transaction_info for version V
- **OverallCommitProgress is NOT updated** (remains at V-1 or doesn't exist for fresh databases)

The recovery mechanism fails to handle this case: [3](#0-2) 

When OverallCommitProgress doesn't exist (first restore on fresh database) or is outdated, and state_kv_db has advanced beyond it, the recovery mechanism should truncate state_kv_db. However, if OverallCommitProgress is None, the function simply logs and returns: [4](#0-3) 

This violates the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." The state database contains data with no corresponding transaction history, making verification impossible.

## Impact Explanation
**Critical Severity** - This meets the Aptos Bug Bounty criteria for "State inconsistencies requiring intervention" and potentially "Non-recoverable network partition":

1. **Permanent Database Corruption**: The database enters a state where state_kv_db claims version V is committed, but ledger_db has no corresponding transactions. This inconsistency persists across restarts.

2. **Failed State Verification**: Any attempt to verify the state root will fail because transaction data is missing from the ledger database.

3. **Manual Recovery Required**: The only resolution is to completely wipe the database and restart the full restore process, potentially taking hours or days for large databases.

4. **Validator Impact**: Validators performing disaster recovery or fresh synchronization from backups could end up with corrupted databases, preventing them from participating in consensus.

5. **Node Unusability**: The node cannot properly answer queries or participate in state synchronization because internal database consistency checks will fail.

## Likelihood Explanation
**High Likelihood** in production environments:

1. **Common Occurrence**: Restore operations happen frequently during:
   - Fresh validator node setup
   - Disaster recovery scenarios
   - Database migration/upgrade
   - State synchronization from snapshots

2. **Long Exposure Window**: Large database restores can take hours, increasing the probability of:
   - Process crashes (OOM, segfaults)
   - Administrative termination (SIGKILL)
   - Disk space exhaustion mid-write
   - Power failures or hardware issues
   - Network disruptions causing process timeouts

3. **No Transaction Boundaries**: The lack of cross-database transaction coordination means any failure between the two writes results in corruption.

4. **First-Restore Vulnerability**: Fresh databases (no existing OverallCommitProgress) have zero recovery capability, making initial deployments particularly vulnerable.

## Recommendation
Implement atomic cross-database commits or add proper recovery logic:

**Option 1**: Use a two-phase commit pattern with proper rollback:
```rust
pub(crate) fn save_transactions(...) -> Result<()> {
    if let Some((ledger_db_batch, state_kv_batches, _state_kv_metadata_batch)) = existing_batch {
        // existing logic
    } else {
        // Prepare all batches but don't commit yet
        let mut ledger_db_batch = LedgerDbSchemaBatches::new();
        let mut sharded_kv_schema_batch = ...;
        
        save_transactions_impl(...)?;
        
        let last_version = first_version + txns.len() as u64 - 1;
        
        // CRITICAL: Write OverallCommitProgress BEFORE any data commits
        // This ensures recovery can always find a safe checkpoint
        let mut progress_batch = SchemaBatch::new();
        progress_batch.put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;
        ledger_db.metadata_db().write_schemas(progress_batch)?;
        
        // Now commit the actual data
        // If these fail, OverallCommitProgress is already at last_version,
        // so recovery will truncate any partial data
        state_store.state_db.state_kv_db.commit(last_version, None, sharded_kv_schema_batch)?;
        ledger_db.write_schemas(ledger_db_batch)?;
    }
    Ok(())
}
```

**Option 2**: Fix the recovery mechanism to handle missing OverallCommitProgress: [3](#0-2) 

Change to:
```rust
pub fn sync_commit_progress(...) {
    let overall_commit_progress = ledger_metadata_db
        .get_synced_version()
        .expect("DB read failed.")
        .unwrap_or(0); // Default to 0 if no progress exists
        
    // Continue with truncation logic even if it was None...
    let state_kv_commit_progress = ...;
    
    // Truncate state_kv_db back to overall_commit_progress if needed
    if state_kv_commit_progress > overall_commit_progress {
        truncate_state_kv_db(...);
    }
    // ... similar for other databases
}
```

## Proof of Concept
```rust
// Reproduction steps (pseudo-code for test)
#[test]
fn test_restore_atomicity_violation() {
    // 1. Create fresh AptosDB
    let db = AptosDB::new_for_test(temp_dir);
    let restore_handler = db.get_restore_handler();
    
    // 2. Prepare restore data
    let txns = create_test_transactions(0, 1000);
    let (persisted_aux_info, txn_infos, events, write_sets) = 
        prepare_transaction_data(&txns);
    
    // 3. Mock state_kv_db.commit() to succeed
    // 4. Mock ledger_db.write_schemas() to fail (simulate crash/disk full)
    
    let result = restore_handler.save_transactions(
        0, &txns, &persisted_aux_info, &txn_infos, &events, write_sets
    );
    
    // Simulate the failure
    assert!(result.is_err()); // ledger_db write failed
    
    // 5. Reopen database (simulates restart)
    drop(restore_handler);
    drop(db);
    let db2 = AptosDB::open(temp_dir); // sync_commit_progress runs here
    
    // 6. Check database state
    let overall_progress = db2.get_synced_version();
    let state_kv_progress = get_state_kv_commit_progress(&db2.state_kv_db);
    
    // BUG: state_kv has advanced to version 999, but overall progress is None/0
    assert_eq!(overall_progress, None); // or Some(0)
    assert_eq!(state_kv_progress, Some(999)); // INCONSISTENT!
    
    // 7. Verify no truncation occurred
    // State KV still has version 999, but ledger has nothing
    // Database is permanently corrupted
}
```

The test demonstrates that after the simulated failure, state_kv_db contains committed data that ledger_db knows nothing about, and the recovery mechanism fails to repair this inconsistency.

### Citations

**File:** storage/aptosdb/src/backup/restore_utils.rs (L164-173)
```rust
        // get the last version and commit to the state kv db
        // commit the state kv before ledger in case of failure happens
        let last_version = first_version + txns.len() as u64 - 1;
        state_store
            .state_db
            .state_kv_db
            .commit(last_version, None, sharded_kv_schema_batch)?;

        ledger_db.write_schemas(ledger_db_batch)?;
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L279-291)
```rust
    let last_version = first_version + txns.len() as u64 - 1;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L417-424)
```rust
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
```

**File:** storage/aptosdb/src/state_store/mod.rs (L499-501)
```rust
        } else {
            info!("No overall commit progress was found!");
        }
```
