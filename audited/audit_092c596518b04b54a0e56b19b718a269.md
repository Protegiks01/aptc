# Audit Report

## Title
Missing Validation in Restore Path Allows Transaction Version Gaps via Malicious Backup Data

## Summary
The backup restore functionality in `save_transactions()` lacks validation to ensure `first_version` is consecutive with existing database state, allowing malicious backup data to create gaps in the transaction sequence. This breaks the fundamental invariant that transactions must have consecutive versions.

## Finding Description

The restore path in `storage/aptosdb/src/backup/restore_utils.rs` does not validate that `first_version` is consecutive with the database's current state. Unlike the normal execution commit path which enforces this invariant, the restore path directly saves transactions without checking for gaps.

**Normal Execution Path (Protected):** [1](#0-0) 

The normal commit path validates that `chunk.first_version == next_version`, preventing gaps.

**Restore Path (Unprotected):** [2](#0-1) 

The restore handler delegates to `restore_utils::save_transactions()` without validation: [3](#0-2) 

**Attack Flow:**
1. Attacker provides malicious backup manifest with `first_version` creating a gap (e.g., DB has versions 0-99, backup claims first_version=150)
2. `confirm_or_save_frozen_subtrees()` accepts frozen subtrees for 150 leaves without validating against current DB state: [4](#0-3) 

3. Transactions are saved at non-consecutive versions: [5](#0-4) 

4. This creates permanent gaps where versions 100-149 have no transaction data, breaking the consecutive version invariant.

## Impact Explanation

**Severity: Critical** - Non-recoverable network partition requiring manual intervention

This breaks multiple critical invariants:
- **State Consistency**: Transaction sequence has gaps, violating the assumption that all validators maintain identical consecutive transaction histories
- **Proof Generation**: Operations expecting consecutive versions will fail
- **State Sync Failure**: Nodes trying to sync will fail when requesting transactions in gap ranges

The database appears healthy (commit progress advances) but critical operations fail: [6](#0-5) 

Attempting to retrieve transactions in the gap returns `NotFound` errors, causing state sync to fail.

## Likelihood Explanation

**Likelihood: Low-Medium** - Requires operational access but realistic attack vector

While this requires the node operator to restore from malicious backup data, realistic scenarios include:
- Compromised backup storage infrastructure
- Supply chain attacks on backup distribution
- Insider threats with access to restore operations

The missing validation is a clear oversight where the restore path bypasses safety checks present in normal execution.

## Recommendation

Add validation in the restore path to ensure `first_version` is consecutive with existing database state:

```rust
pub(crate) fn save_transactions(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    // ... other parameters
) -> Result<()> {
    // Add validation
    let next_expected = state_store.current_state_locked().next_version();
    ensure!(
        first_version == next_expected,
        "Restore first_version ({}) does not match next expected version ({}). \
         This would create a gap in the transaction sequence.",
        first_version,
        next_expected,
    );
    
    // ... rest of function
}
```

Additionally, validate during `confirm_or_save_frozen_subtrees()` that `num_leaves` matches the expected next version.

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[test]
fn test_restore_version_gap_vulnerability() {
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    
    // Setup: Commit transactions 0-99 normally
    for i in 0..100 {
        let chunk = create_test_chunk(i, 1);
        db.save_transactions(&chunk).unwrap();
    }
    
    // Attack: Restore from malicious backup starting at version 150
    let restore_handler = db.get_restore_handler();
    
    // This should fail but doesn't - vulnerability allows gap
    let result = restore_handler.save_transactions(
        150, // Creates gap: versions 100-149 missing!
        &create_test_transactions(10),
        &create_test_aux_info(10),
        &create_test_txn_infos(10),
        &create_test_events(10),
        create_test_write_sets(10),
    );
    
    // Vulnerability: This succeeds when it should fail
    assert!(result.is_ok()); 
    
    // Impact: Transactions in gap return NotFound
    let result = db.get_transaction_by_version(100, 160, false);
    assert!(result.is_err()); // Version 100 doesn't exist!
}
```

## Notes

This vulnerability specifically affects the backup/restore system and requires operational access. While not directly exploitable by external network attackers, it represents a significant flaw in the restore path's safety guarantees that could enable database corruption through compromised backup infrastructure.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L245-261)
```rust
    fn pre_commit_validation(&self, chunk: &ChunkToCommit) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions_validation"]);

        ensure!(!chunk.is_empty(), "chunk is empty, nothing to save.");

        let next_version = self.state_store.current_state_locked().next_version();
        // Ensure the incoming committing requests are always consecutive and the version in
        // buffered state is consistent with that in db.
        ensure!(
            chunk.first_version == next_version,
            "The first version passed in ({}), and the next version expected by db ({}) are inconsistent.",
            chunk.first_version,
            next_version,
        );

        Ok(())
    }
```

**File:** storage/aptosdb/src/backup/restore_handler.rs (L78-99)
```rust
    pub fn save_transactions(
        &self,
        first_version: Version,
        txns: &[Transaction],
        persisted_aux_info: &[PersistedAuxiliaryInfo],
        txn_infos: &[TransactionInfo],
        events: &[Vec<ContractEvent>],
        write_sets: Vec<WriteSet>,
    ) -> Result<()> {
        restore_utils::save_transactions(
            self.state_store.clone(),
            self.ledger_db.clone(),
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets,
            None,
            false,
        )
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L78-111)
```rust
pub fn confirm_or_save_frozen_subtrees(
    transaction_accumulator_db: &DB,
    num_leaves: LeafCount,
    frozen_subtrees: &[HashValue],
    existing_batch: Option<&mut SchemaBatch>,
) -> Result<()> {
    let positions: Vec<_> = FrozenSubTreeIterator::new(num_leaves).collect();
    ensure!(
        positions.len() == frozen_subtrees.len(),
        "Number of frozen subtree roots not expected. Expected: {}, actual: {}",
        positions.len(),
        frozen_subtrees.len(),
    );

    if let Some(existing_batch) = existing_batch {
        confirm_or_save_frozen_subtrees_impl(
            transaction_accumulator_db,
            frozen_subtrees,
            positions,
            existing_batch,
        )?;
    } else {
        let mut batch = SchemaBatch::new();
        confirm_or_save_frozen_subtrees_impl(
            transaction_accumulator_db,
            frozen_subtrees,
            positions,
            &mut batch,
        )?;
        transaction_accumulator_db.write_schemas(batch)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L115-176)
```rust
pub(crate) fn save_transactions(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    txns: &[Transaction],
    persisted_aux_info: &[PersistedAuxiliaryInfo],
    txn_infos: &[TransactionInfo],
    events: &[Vec<ContractEvent>],
    write_sets: Vec<WriteSet>,
    existing_batch: Option<(
        &mut LedgerDbSchemaBatches,
        &mut ShardedStateKvSchemaBatch,
        &mut SchemaBatch,
    )>,
    kv_replay: bool,
) -> Result<()> {
    if let Some((ledger_db_batch, state_kv_batches, _state_kv_metadata_batch)) = existing_batch {
        save_transactions_impl(
            state_store,
            ledger_db,
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets.as_ref(),
            ledger_db_batch,
            state_kv_batches,
            kv_replay,
        )?;
    } else {
        let mut ledger_db_batch = LedgerDbSchemaBatches::new();
        let mut sharded_kv_schema_batch = state_store
            .state_db
            .state_kv_db
            .new_sharded_native_batches();
        save_transactions_impl(
            Arc::clone(&state_store),
            Arc::clone(&ledger_db),
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets.as_ref(),
            &mut ledger_db_batch,
            &mut sharded_kv_schema_batch,
            kv_replay,
        )?;
        // get the last version and commit to the state kv db
        // commit the state kv before ledger in case of failure happens
        let last_version = first_version + txns.len() as u64 - 1;
        state_store
            .state_db
            .state_kv_db
            .commit(last_version, None, sharded_kv_schema_batch)?;

        ledger_db.write_schemas(ledger_db_batch)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L193-294)
```rust
pub(crate) fn save_transactions_impl(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    txns: &[Transaction],
    persisted_aux_info: &[PersistedAuxiliaryInfo],
    txn_infos: &[TransactionInfo],
    events: &[Vec<ContractEvent>],
    write_sets: &[WriteSet],
    ledger_db_batch: &mut LedgerDbSchemaBatches,
    state_kv_batches: &mut ShardedStateKvSchemaBatch,
    kv_replay: bool,
) -> Result<()> {
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }

    for (idx, aux_info) in persisted_aux_info.iter().enumerate() {
        PersistedAuxiliaryInfoDb::put_persisted_auxiliary_info(
            first_version + idx as Version,
            aux_info,
            &mut ledger_db_batch.persisted_auxiliary_info_db_batches,
        )?;
    }

    for (idx, txn_info) in txn_infos.iter().enumerate() {
        TransactionInfoDb::put_transaction_info(
            first_version + idx as Version,
            txn_info,
            &mut ledger_db_batch.transaction_info_db_batches,
        )?;
    }

    ledger_db
        .transaction_accumulator_db()
        .put_transaction_accumulator(
            first_version,
            txn_infos,
            &mut ledger_db_batch.transaction_accumulator_db_batches,
        )?;

    ledger_db.event_db().put_events_multiple_versions(
        first_version,
        events,
        &mut ledger_db_batch.event_db_batches,
    )?;

    if ledger_db.enable_storage_sharding() {
        for (idx, txn_events) in events.iter().enumerate() {
            for event in txn_events {
                if let Some(event_key) = event.event_key() {
                    if *event_key == new_block_event_key() {
                        LedgerMetadataDb::put_block_info(
                            first_version + idx as Version,
                            event,
                            &mut ledger_db_batch.ledger_metadata_db_batches,
                        )?;
                    }
                }
            }
        }
    }
    // insert changes in write set schema batch
    for (idx, ws) in write_sets.iter().enumerate() {
        WriteSetDb::put_write_set(
            first_version + idx as Version,
            ws,
            &mut ledger_db_batch.write_set_db_batches,
        )?;
    }

    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }

    let last_version = first_version + txns.len() as u64 - 1;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;

    Ok(())
}
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1068-1100)
```rust
    pub(super) fn get_transaction_with_proof(
        &self,
        version: Version,
        ledger_version: Version,
        fetch_events: bool,
    ) -> Result<TransactionWithProof> {
        self.error_if_ledger_pruned("Transaction", version)?;

        let proof = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_with_proof(
                version,
                ledger_version,
                self.ledger_db.transaction_accumulator_db(),
            )?;

        let transaction = self.ledger_db.transaction_db().get_transaction(version)?;

        // If events were requested, also fetch those.
        let events = if fetch_events {
            Some(self.ledger_db.event_db().get_events_by_version(version)?)
        } else {
            None
        };

        Ok(TransactionWithProof {
            version,
            transaction,
            events,
            proof,
        })
    }
```
