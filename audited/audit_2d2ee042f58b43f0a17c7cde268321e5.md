# Audit Report

## Title
Non-Atomic State Restoration Allows Usage Statistics Divergence on Crash

## Summary
During state snapshot restoration, usage statistics can diverge from actual KV data when a crash occurs between shard commits and overall progress updates. The `StateSnapshotKvRestoreProgress` metadata persists stale usage values that include rolled-back data, which are then written to the ledger database by `kv_restore.finish()`.

## Finding Description

The state snapshot restoration process writes data to multiple independent databases without atomic guarantees between them: [1](#0-0) 

The critical issue occurs in the commit sequence within `StateKvDb::commit`: [2](#0-1) 

During chunk writes, the system performs three sequential operations:
1. Commits KV data to all shards in parallel
2. Writes `StateSnapshotKvRestoreProgress` (including usage) to metadata database  
3. Writes overall `StateKvCommitProgress`

If a crash occurs after step 2 but before step 3, recovery truncates the shards based on the overall progress: [3](#0-2) 

However, the truncation only affects shard data, not the metadata database where `StateSnapshotKvRestoreProgress` resides: [4](#0-3) 

This leaves stale progress containing usage statistics for data that was rolled back. When restoration resumes, `finish()` reads this stale progress and persists the inflated usage: [5](#0-4) [6](#0-5) 

The final usage written to `VersionDataSchema` in ledger_db includes contributions from chunks whose KV data was truncated. [7](#0-6) 

## Impact Explanation

This violates the **State Consistency** invariant requiring atomic state transitions. However, the practical impact is limited:

- Usage statistics divergence does not affect consensus (all nodes experience the same issue post-crash)
- Does not enable fund theft or validator manipulation  
- Queried usage values via `get_usage()` may be inflated but don't gate critical operations
- Requires crash at specific moment during state restoration, not attacker-controllable

This qualifies as **Medium Severity** per the bug bounty criteria: "State inconsistencies requiring intervention" - manual correction may be needed to reconcile usage accounting.

## Likelihood Explanation

**Low to Medium Likelihood:**
- Requires crash during active state snapshot restoration
- Timing window is narrow (between metadata batch write and overall progress update)
- State restoration occurs during initial sync or recovery scenarios
- Not exploitable by external attackers (requires node crash, not attacker action)
- Could occur naturally through hardware failures, OOM kills, or power loss

## Recommendation

Implement atomic cleanup of `StateSnapshotKvRestoreProgress` during shard truncation, or validate progress against actual shard state on recovery:

```rust
// In truncate_state_kv_db_shards, after truncating shards:
pub(crate) fn truncate_state_kv_db_shards(
    state_kv_db: &StateKvDb,
    target_version: Version,
) -> Result<()> {
    (0..state_kv_db.hack_num_real_shards())
        .into_par_iter()
        .try_for_each(|shard_id| {
            truncate_state_kv_db_single_shard(state_kv_db, shard_id, target_version)
        })?;
    
    // Clean up stale StateSnapshotKvRestoreProgress entries
    cleanup_stale_snapshot_progress(state_kv_db, target_version)?;
    Ok(())
}

fn cleanup_stale_snapshot_progress(state_kv_db: &StateKvDb, target_version: Version) -> Result<()> {
    // Remove StateSnapshotKvRestoreProgress for versions > target_version
    // or validate/recompute progress from actual shard state
}
```

Alternatively, make the progress write atomic with the overall commit progress by including it in the same database transaction.

## Proof of Concept

This vulnerability requires orchestrating a crash at a specific moment, making a traditional PoC challenging. However, the divergence can be demonstrated through the following sequence:

```rust
// Conceptual reproduction (not executable):
// 1. Start state snapshot restoration to version V
// 2. Process chunks, writing to shards and updating StateSnapshotKvRestoreProgress
// 3. During chunk N write, after metadata batch commits but before overall progress updates:
//    - Shards contain chunk N KV data
//    - StateSnapshotKvRestoreProgress(V) has usage including chunk N
//    - StateKvCommitProgress still at chunk N-1
// 4. Simulate crash (kill -9)
// 5. On restart:
//    - truncate_state_kv_db_shards removes chunk N from shards
//    - StateSnapshotKvRestoreProgress(V) unchanged (still includes chunk N usage)
// 6. Resume restoration:
//    - finish() reads stale progress with inflated usage
//    - Writes to ledger_db: usage includes non-existent chunk N
// 7. Verify: query get_usage(V) returns value > actual KV data size
```

## Notes

While this represents a correctness issue in crash recovery, it does **not** meet the strict exploitation criteria for a high-severity vulnerability:
- Not exploitable by unprivileged attackers
- Requires crash at specific timing (not attacker-controlled)
- No direct security harm (no fund loss, consensus break, or access control bypass)
- Impact limited to accounting inconsistency

The issue violates atomicity guarantees but falls into the category of crash recovery edge cases rather than exploitable attack vectors. Manual database reconciliation may be required if this occurs in production.

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L129-135)
```rust
    pub fn finish(self) -> Result<()> {
        let progress = self.db.get_progress(self.version)?;
        self.db.kv_finish(
            self.version,
            progress.map_or(StateStorageUsage::zero(), |p| p.usage),
        )
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L260-273)
```rust
    fn finish(self) -> Result<()> {
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => self.kv_restore.lock().take().unwrap().finish()?,
            StateSnapshotRestoreMode::TreeOnly => {
                self.tree_restore.lock().take().unwrap().finish_impl()?
            },
            StateSnapshotRestoreMode::Default => {
                // for tree only mode, we also need to write the usage to DB
                self.kv_restore.lock().take().unwrap().finish()?;
                self.tree_restore.lock().take().unwrap().finish_impl()?
            },
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L164-168)
```rust
        if !readonly {
            if let Some(overall_kv_commit_progress) = get_state_kv_commit_progress(&state_kv_db)? {
                truncate_state_kv_db_shards(&state_kv_db, overall_kv_commit_progress)?;
            }
        }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-208)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L118-127)
```rust
pub(crate) fn truncate_state_kv_db_shards(
    state_kv_db: &StateKvDb,
    target_version: Version,
) -> Result<()> {
    (0..state_kv_db.hack_num_real_shards())
        .into_par_iter()
        .try_for_each(|shard_id| {
            truncate_state_kv_db_single_shard(state_kv_db, shard_id, target_version)
        })
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1281-1315)
```rust
    fn kv_finish(&self, version: Version, usage: StateStorageUsage) -> Result<()> {
        self.ledger_db.metadata_db().put_usage(version, usage)?;
        if let Some(internal_indexer_db) = self.internal_indexer_db.as_ref() {
            if version > 0 {
                let mut batch = SchemaBatch::new();
                batch.put::<InternalIndexerMetadataSchema>(
                    &MetadataKey::LatestVersion,
                    &MetadataValue::Version(version - 1),
                )?;
                if internal_indexer_db.statekeys_enabled() {
                    batch.put::<InternalIndexerMetadataSchema>(
                        &MetadataKey::StateVersion,
                        &MetadataValue::Version(version - 1),
                    )?;
                }
                if internal_indexer_db.transaction_enabled() {
                    batch.put::<InternalIndexerMetadataSchema>(
                        &MetadataKey::TransactionVersion,
                        &MetadataValue::Version(version - 1),
                    )?;
                }
                if internal_indexer_db.event_enabled() {
                    batch.put::<InternalIndexerMetadataSchema>(
                        &MetadataKey::EventVersion,
                        &MetadataValue::Version(version - 1),
                    )?;
                }
                internal_indexer_db
                    .get_inner_db_ref()
                    .write_schemas(batch)?;
            }
        }

        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L322-325)
```rust
    /// Writes the state usage to database.
    pub(crate) fn put_usage(&self, version: Version, usage: StateStorageUsage) -> Result<()> {
        self.db.put::<VersionDataSchema>(&version, &usage.into())
    }
```
