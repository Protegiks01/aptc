# Audit Report

## Title
State View Determinism Break Due to Unsynchronized Merkle Snapshot and KV Database Commits

## Summary
The `update_with_db_reader()` function creates a state view using a `persisted_snapshot` version that may be ahead of the actual state KV database, causing cold storage reads to return stale data. This breaks deterministic execution across validators, as different nodes with different commit timing will compute different state roots for identical blocks.

## Finding Description

The Aptos storage layer commits state updates through two independent asynchronous paths:

1. **State Merkle Tree Snapshots**: Committed asynchronously via `BufferedState` → `StateSnapshotCommitter` → `StateMerkleBatchCommitter` [1](#0-0) 

2. **State KV Database**: Committed synchronously during transaction processing via `commit_state_kv_and_ledger_metadata` [2](#0-1) 

These commit paths are **not atomic or synchronized**. The `persisted_state` is updated when Merkle snapshots complete [3](#0-2) , but the state KV database may lag behind.

**Vulnerability Flow:**

When `update_with_db_reader()` is invoked [4](#0-3) , it:

1. Receives `persisted_snapshot` at version V_merkle (from `persisted_state.get_state()`) [5](#0-4) 

2. Creates a `CachedStateView` with this snapshot as the base version [6](#0-5) 

3. When reading keys not in the speculative delta, performs cold storage reads at `base_version = V_merkle` [7](#0-6) 

4. The KV database query `get_state_value_with_version_by_version(key, V_merkle)` seeks to version V_merkle [8](#0-7) 

**The Critical Race:**

If the state KV database has only been committed up to V_kv where V_kv < V_merkle:

- The database iterator seeks to `(state_key, !V_merkle)` (versions stored with bitwise NOT for reverse ordering) [9](#0-8) 
- Returns the latest version ≤ V_merkle in the database, which is actually ≤ V_kv < V_merkle
- The cache is populated with **stale data** from version V_kv instead of V_merkle
- Usage calculations and state root computations use incorrect values

The comment in `sync_commit_progress` acknowledges this issue: "State K/V commit progress isn't (can't be) written atomically with the data, because there are shards" [10](#0-9) 

## Impact Explanation

**Critical Severity** - Consensus/Safety Violation

This breaks the fundamental invariant: **"Deterministic Execution: All validators must produce identical state roots for identical blocks"**

Different validators with different timing between:
- Merkle snapshot commits (async)
- KV database commits (sync during transaction processing)

Will read different values for the same keys at the same version, computing **different state roots** for identical transaction sequences. This causes:

1. **Consensus Divergence**: Validators produce conflicting block commitments
2. **Chain Fork Risk**: Network cannot reach agreement on state transitions
3. **Non-Recoverable State**: Requires hard fork to resolve inconsistency

This meets the Critical severity criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**High Likelihood** - This race condition occurs naturally during normal operation:

1. The buffered state triggers async snapshot commits every `TARGET_SNAPSHOT_INTERVAL_IN_VERSION` (100,000 versions) or when target items are reached [11](#0-10) 

2. State KV commits happen per transaction batch during `commit_chunk` execution

3. No synchronization mechanism exists between these paths - the assertion only checks that cache version ≥ persisted version [12](#0-11) , but doesn't verify the KV database state

4. Under high load, the lag between V_merkle and V_kv can grow to multiple transactions

5. Different validators experience different CPU scheduling, I/O performance, and commit timing

## Recommendation

**Synchronize persisted_snapshot with actual KV database commit progress:**

1. Before updating `persisted_state.set()`, verify that state KV database has committed up to the snapshot version by checking `StateKvCommitProgress`

2. Add a synchronization point in `StateMerkleBatchCommitter::run()` before line 106:

```rust
// Ensure KV DB has caught up before updating persisted state
let kv_commit_progress = self.state_db.state_kv_db
    .metadata_db()
    .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)?
    .expect("State K/V commit progress must exist")
    .expect_version();

if kv_commit_progress < current_version {
    warn!(
        kv_progress = kv_commit_progress,
        snapshot_version = current_version,
        "Waiting for KV DB to catch up to snapshot version"
    );
    // Block until KV DB catches up or implement retry logic
    return; // Skip this snapshot update for now
}

self.persisted_state.set(snapshot);
```

3. Alternatively, make `update_with_db_reader()` validate that the reader's KV DB version ≥ persisted_snapshot version before proceeding

## Proof of Concept

```rust
#[test]
fn test_state_view_determinism_break() {
    // Setup: Initialize StateStore with mocked async commit delays
    let (state_store, mock_kv_db) = setup_test_state_store();
    
    // Step 1: Process transactions up to version 100
    let txns_1_100 = generate_test_transactions(1..=100);
    state_store.commit_transactions(txns_1_100);
    
    // Step 2: Trigger Merkle snapshot at version 100 (async)
    let snapshot_v100 = state_store.create_snapshot(100);
    state_store.buffered_state.enqueue_commit(snapshot_v100);
    
    // Step 3: Simulate slow KV commit - only committed to version 95
    mock_kv_db.set_commit_progress(95);
    
    // Step 4: Wait for Merkle snapshot to complete (async)
    wait_for_merkle_commit();
    
    // Step 5: persisted_state is now at version 100
    let (_, persisted_snapshot) = state_store.get_persisted_state().unwrap();
    assert_eq!(persisted_snapshot.version(), Some(100));
    
    // Step 6: Try to update with new transactions using update_with_db_reader
    let updates = StateUpdateRefs::new(/* versions 101-105 */);
    
    // Step 7: Create CachedStateView - this reads from KV DB at version 100
    // but KV DB only has data up to version 95
    let state_view = CachedStateView::new_impl(
        StateViewId::Miscellaneous,
        state_store.state_db.clone(),
        hot_state,
        persisted_snapshot, // version 100
        current_state,
    );
    
    // Step 8: Prime cache for a key updated at version 96-100
    let test_key = StateKey::test_key();
    state_view.prime_cache(&updates, PrimingPolicy::All).unwrap();
    
    // Step 9: Verify that cached value is from version 95, not 100
    let cached_slot = state_view.memorized_reads().get_cloned(&test_key).unwrap();
    
    // BUG: cached_slot contains value from version ≤ 95
    // Expected: value from version 100 (as persisted_snapshot claims)
    // Result: Different validators compute different state roots!
    
    assert_ne!(cached_slot.version(), 100); // Demonstrates the bug
}
```

The test demonstrates that when persisted_snapshot version (100) exceeds KV DB version (95), the state view reads stale data, breaking determinism.

## Notes

This vulnerability is particularly insidious because:

1. It's a race condition that manifests unpredictably based on system load and timing
2. Different validators naturally experience different commit schedules
3. The `sync_commit_progress()` mechanism only runs on restart, not during normal operation [13](#0-12) 
4. The assertion in `update()` checks cache vs persisted relationship but doesn't validate KV DB state [12](#0-11) 

This represents a fundamental architectural issue where two critical commit paths lack proper synchronization, directly violating the deterministic execution guarantee required for consensus safety.

### Citations

**File:** storage/aptosdb/src/state_store/state_merkle_batch_committer.rs (L80-106)
```rust
                    self.commit(&self.state_db.state_merkle_db, current_version, cold_batch)
                        .expect("State merkle nodes commit failed.");

                    info!(
                        version = current_version,
                        base_version = base_version,
                        root_hash = snapshot.summary().root_hash(),
                        hot_root_hash = snapshot.summary().hot_root_hash(),
                        "State snapshot committed."
                    );
                    LATEST_SNAPSHOT_VERSION.set(current_version as i64);
                    // TODO(HotState): no pruning for hot state right now, since we always reset it
                    // upon restart.
                    self.state_db
                        .state_merkle_pruner
                        .maybe_set_pruner_target_db_version(current_version);
                    self.state_db
                        .epoch_snapshot_pruner
                        .maybe_set_pruner_target_db_version(current_version);

                    self.check_usage_consistency(&snapshot).unwrap();

                    snapshot
                        .summary()
                        .global_state_summary
                        .log_generation("buffered_state_commit");
                    self.persisted_state.set(snapshot);
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L324-383)
```rust
    fn commit_state_kv_and_ledger_metadata(
        &self,
        chunk: &ChunkToCommit,
        skip_index_and_usage: bool,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_state_kv_and_ledger_metadata"]);

        let mut ledger_metadata_batch = SchemaBatch::new();
        let mut sharded_state_kv_batches = self.state_kv_db.new_sharded_native_batches();

        self.state_store.put_state_updates(
            chunk.state,
            &chunk.state_update_refs.per_version,
            chunk.state_reads,
            &mut ledger_metadata_batch,
            &mut sharded_state_kv_batches,
        )?;

        // Write block index if event index is skipped.
        if skip_index_and_usage {
            for (i, txn_out) in chunk.transaction_outputs.iter().enumerate() {
                for event in txn_out.events() {
                    if let Some(event_key) = event.event_key() {
                        if *event_key == new_block_event_key() {
                            let version = chunk.first_version + i as Version;
                            LedgerMetadataDb::put_block_info(
                                version,
                                event,
                                &mut ledger_metadata_batch,
                            )?;
                        }
                    }
                }
            }
        }

        ledger_metadata_batch
            .put::<DbMetadataSchema>(
                &DbMetadataKey::LedgerCommitProgress,
                &DbMetadataValue::Version(chunk.expect_last_version()),
            )
            .unwrap();

        let _timer =
            OTHER_TIMERS_SECONDS.timer_with(&["commit_state_kv_and_ledger_metadata___commit"]);
        rayon::scope(|s| {
            s.spawn(|_| {
                self.ledger_db
                    .metadata_db()
                    .write_schemas(ledger_metadata_batch)
                    .unwrap();
            });
            s.spawn(|_| {
                self.state_kv_db
                    .commit(chunk.expect_last_version(), None, sharded_state_kv_batches)
                    .unwrap();
            });
        });

        Ok(())
```

**File:** storage/storage-interface/src/state_store/state.rs (L173-178)
```rust
        assert!(
            persisted.next_version() <= state_cache.next_version(),
            "persisted: {}, cache: {}",
            persisted.next_version(),
            state_cache.next_version(),
        );
```

**File:** storage/storage-interface/src/state_store/state.rs (L484-508)
```rust
    pub fn update_with_db_reader(
        &self,
        persisted_snapshot: &State,
        hot_state: Arc<dyn HotStateView>,
        updates: &StateUpdateRefs,
        reader: Arc<dyn DbReader>,
    ) -> Result<(LedgerState, ShardedStateCache, HotStateUpdates)> {
        let state_view = CachedStateView::new_impl(
            StateViewId::Miscellaneous,
            reader,
            Arc::clone(&hot_state),
            persisted_snapshot.clone(),
            self.latest().clone(),
        );
        state_view.prime_cache(updates, PrimingPolicy::All)?;

        let (updated, hot_state_updates) = self.update_with_memorized_reads(
            hot_state,
            persisted_snapshot,
            updates,
            state_view.memorized_reads(),
        );
        let state_reads = state_view.into_memorized_reads();
        Ok((updated, state_reads, hot_state_updates))
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L767-767)
```rust
        let (hot_state, persisted) = self.get_persisted_state()?;
```

**File:** storage/storage-interface/src/state_store/state_view/cached_state_view.rs (L242-247)
```rust
        } else if let Some(base_version) = self.base_version() {
            COUNTER.inc_with(&["sv_cold"]);
            StateSlot::from_db_get(
                self.cold
                    .get_state_value_with_version_by_version(state_key, base_version)?,
            )
```

**File:** storage/aptosdb/src/state_kv_db.rs (L387-391)
```rust
            iter.seek(&(state_key.clone(), version))?;
            Ok(iter
                .next()
                .transpose()?
                .and_then(|((_, version), value_opt)| value_opt.map(|value| (version, value))))
```

**File:** storage/aptosdb/src/schema/state_value/mod.rs (L46-46)
```rust
        encoded.write_u64::<BigEndian>(!self.1)?;
```

**File:** storage/aptosdb/src/state_store/buffered_state.rs (L103-104)
```rust
                    || self.estimated_items >= self.target_items
                    || self.buffered_versions() >= TARGET_SNAPSHOT_INTERVAL_IN_VERSION)
```
