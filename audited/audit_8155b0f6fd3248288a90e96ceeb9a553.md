# Audit Report

## Title
State Snapshot Restoration Atomicity Violation with async_commit=true

## Summary
The `async_commit=true` parameter in `StateSnapshotRestore::new()` creates a race condition where Jellyfish Merkle tree nodes can be durably committed to RocksDB before their corresponding state key-value pairs, breaking the atomicity guarantee between tree and KV storage during state restoration.

## Finding Description

When `async_commit=true` is set at line 165 in `StateSnapshotRestore::new()`, the tree write operations are spawned asynchronously on a background thread pool while KV writes execute synchronously. [1](#0-0) 

The execution flow for each chunk is:

1. Both `kv_fn` and `tree_fn` start in parallel via `IO_POOL.join()` [2](#0-1) 

2. `tree_fn` calls `wait_for_async_commit()` for the previous chunk, then spawns a new async write on the jellyfish-merkle IO_POOL and returns immediately [3](#0-2) 

3. `kv_fn` performs synchronous write via `write_kv_batch()` which commits to RocksDB [4](#0-3) 

The critical race occurs because:
- Tree nodes are written to `StateMerkleDb` via `write_node_batch()` executing on a background thread [5](#0-4) 
- Each database performs independent RocksDB WAL writes
- The background thread's tree commit can complete before the foreground thread's KV commit

**Crash Scenario:**
If the system crashes after the async tree write commits to RocksDB WAL but before the KV write commits:
- Tree contains nodes referencing state keys from chunk N
- KV storage does not contain values for chunk N
- On recovery, `previous_key_hash()` takes the minimum of tree and KV progress [6](#0-5) 
- Restoration resumes, but temporary inconsistency exists

This violates **Critical Invariant #4: State Consistency** - state transitions should be atomic and verifiable. The tree and KV represent different points in the restoration, breaking the guarantee that they are synchronized.

## Impact Explanation

**Current Impact: Medium Severity**

This issue currently affects **offline restoration only** (backup/restore operations via db-tool), as evidenced by:
- Production restoration uses `async_commit=true` [7](#0-6) 
- State sync (online operation) uses `async_commit=false` [8](#0-7) 

Impact includes:
- **State inconsistencies requiring intervention**: Crashes during restoration leave tree ahead of KV, requiring recovery logic to handle
- Potential violation of `MAX_COMMIT_PROGRESS_DIFFERENCE` checks if inconsistency grows large [9](#0-8) 
- Restoration failures if recovery logic cannot handle edge cases

**Potential Future Impact: High Severity**

A TODO comment indicates intent to enable async_commit for state sync: [10](#0-9) 

If implemented, this would enable the race during **online node operation**, causing:
- Queries during state sync hitting missing KV entries
- `AptosDbError::NotFound` errors [11](#0-10) 
- Different nodes potentially seeing different states during sync

## Likelihood Explanation

**Current: Low**
- Only affects controlled offline restoration operations
- Requires system crash at precise timing during restoration
- Recovery mechanisms partially mitigate (min-based resume, idempotent overwrites)

**Future: Medium-to-High**
- If async_commit enabled for online state sync per TODO
- Would occur during normal state sync operations
- No user intervention required for exploitation

## Recommendation

**Immediate Fix**: Add explicit synchronization to ensure KV commits complete before tree commits become durable:

```rust
pub fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
    let kv_fn = || { /* ... */ };
    let tree_fn = || { /* ... */ };
    
    match self.restore_mode {
        StateSnapshotRestoreMode::Default => {
            // Execute KV write FIRST to completion
            kv_fn()?;
            // Then execute tree write (async spawn allowed)
            tree_fn()?;
        },
        // ... other modes
    }
    Ok(())
}
```

**Long-term Solution**: Implement transactional coordination between tree and KV writes:
- Add a coordination layer that tracks pending writes
- Ensure tree nodes don't become queryable until corresponding KV entries are durable
- Consider using RocksDB transactions spanning both databases if feasible
- Add consistency verification on restoration resume

**Critical**: Before implementing the TODO at line 1146 to enable async_commit for state sync, ensure atomicity guarantees are established to prevent online inconsistencies.

## Proof of Concept

```rust
// Test demonstrating tree-ahead-of-KV inconsistency
#[test]
fn test_async_commit_race_condition() {
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;
    
    // Setup: Create StateSnapshotRestore with async_commit=true
    let (tree_db, kv_db) = setup_test_dbs();
    let restore = StateSnapshotRestore::new(
        &Arc::new(tree_db),
        &Arc::new(kv_db),
        version,
        expected_root_hash,
        true, // async_commit=true
        StateSnapshotRestoreMode::Default,
    ).unwrap();
    
    // Add chunk - tree write spawns async
    let chunk = generate_test_chunk();
    restore.add_chunk(chunk, proof).unwrap();
    
    // Simulate crash before KV completes by checking RocksDB state
    thread::sleep(Duration::from_millis(10));
    
    // Verify: tree may have committed while KV has not
    let tree_progress = get_tree_rightmost_leaf(&tree_db);
    let kv_progress = get_kv_progress(&kv_db, version);
    
    // Assert tree is ahead (demonstrating race)
    assert!(tree_progress > kv_progress, 
        "Tree committed before KV, breaking atomicity");
}
```

The vulnerability is confirmed by:
1. Tree commits occurring asynchronously on background threads
2. Independent RocksDB instances with no transactional coordination
3. Documented recovery logic assuming tree can be ahead of KV
4. TODO indicating future plans to use this mechanism online

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L160-166)
```rust
        Ok(Self {
            tree_restore: Arc::new(Mutex::new(Some(JellyfishMerkleRestore::new(
                Arc::clone(tree_store),
                version,
                expected_root_hash,
                async_commit,
            )?))),
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L196-214)
```rust
    pub fn previous_key_hash(&self) -> Result<Option<HashValue>> {
        let hash_opt = match (
            self.kv_restore
                .lock()
                .as_ref()
                .unwrap()
                .previous_key_hash()?,
            self.tree_restore
                .lock()
                .as_ref()
                .unwrap()
                .previous_key_hash(),
        ) {
            (None, hash_opt) => hash_opt,
            (hash_opt, None) => hash_opt,
            (Some(hash1), Some(hash2)) => Some(std::cmp::min(hash1, hash2)),
        };
        Ok(hash_opt)
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L249-254)
```rust
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L394-410)
```rust
        if self.async_commit {
            self.wait_for_async_commit()?;
            let (tx, rx) = channel();
            self.async_commit_result = Some(rx);

            let mut frozen_nodes = HashMap::new();
            std::mem::swap(&mut frozen_nodes, &mut self.frozen_nodes);
            let store = self.store.clone();

            IO_POOL.spawn(move || {
                let res = store.write_node_batch(&frozen_nodes);
                tx.send(res).unwrap();
            });
        } else {
            self.store.write_node_batch(&self.frozen_nodes)?;
            self.frozen_nodes.clear();
        }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L107-107)
```rust
pub const MAX_COMMIT_PROGRESS_DIFFERENCE: u64 = 1_000_000;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L319-335)
```rust
impl StateDb {
    fn expect_value_by_version(
        &self,
        state_key: &StateKey,
        version: Version,
    ) -> Result<StateValue> {
        self.get_state_value_by_version(state_key, version)
            .and_then(|opt| {
                opt.ok_or_else(|| {
                    AptosDbError::NotFound(format!(
                        "State Value is missing for key {:?} by version {}",
                        state_key, version
                    ))
                })
            })
    }
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1145-1160)
```rust
    // state sync doesn't query for the progress, but keeps its record by itself.
    // TODO: change to async comment once it does like https://github.com/aptos-labs/aptos-core/blob/159b00f3d53e4327523052c1b99dd9889bf13b03/storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs#L147 or overlap at least two chunks.
    pub fn get_snapshot_receiver(
        self: &Arc<Self>,
        version: Version,
        expected_root_hash: HashValue,
    ) -> Result<Box<dyn StateSnapshotReceiver<StateKey, StateValue>>> {
        Ok(Box::new(StateSnapshotRestore::new(
            &self.state_merkle_db,
            self,
            version,
            expected_root_hash,
            false, /* async_commit */
            StateSnapshotRestoreMode::Default,
        )?))
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1244-1279)
```rust
    fn write_kv_batch(
        &self,
        version: Version,
        node_batch: &StateValueBatch,
        progress: StateSnapshotProgress,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_writer_write_chunk"]);
        let mut batch = SchemaBatch::new();
        let mut sharded_schema_batch = self.state_kv_db.new_sharded_native_batches();

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
            &DbMetadataValue::StateSnapshotProgress(progress),
        )?;

        if self.internal_indexer_db.is_some()
            && self
                .internal_indexer_db
                .as_ref()
                .unwrap()
                .statekeys_enabled()
        {
            let keys = node_batch.keys().map(|key| key.0.clone()).collect();
            self.internal_indexer_db
                .as_ref()
                .unwrap()
                .write_keys_to_indexer_db(&keys, version, progress)?;
        }
        self.shard_state_value_batch(
            &mut sharded_schema_batch,
            node_batch,
            self.state_kv_db.enabled_sharding(),
        )?;
        self.state_kv_db
            .commit(version, Some(batch), sharded_schema_batch)
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L917-932)
```rust
impl TreeWriter<StateKey> for StateMerkleDb {
    fn write_node_batch(&self, node_batch: &NodeBatch) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["tree_writer_write_batch"]);
        // Get the top level batch and sharded batch from raw NodeBatch
        let mut top_level_batch = SchemaBatch::new();
        let mut jmt_shard_batches: Vec<SchemaBatch> = Vec::with_capacity(NUM_STATE_SHARDS);
        jmt_shard_batches.resize_with(NUM_STATE_SHARDS, SchemaBatch::new);
        node_batch.iter().try_for_each(|(node_key, node)| {
            if let Some(shard_id) = node_key.get_shard_id() {
                jmt_shard_batches[shard_id].put::<JellyfishMerkleNodeSchema>(node_key, node)
            } else {
                top_level_batch.put::<JellyfishMerkleNodeSchema>(node_key, node)
            }
        })?;
        self.commit_no_progress(top_level_batch, jmt_shard_batches)
    }
```

**File:** storage/aptosdb/src/backup/restore_handler.rs (L41-55)
```rust
    pub fn get_state_restore_receiver(
        &self,
        version: Version,
        expected_root_hash: HashValue,
        restore_mode: StateSnapshotRestoreMode,
    ) -> Result<StateSnapshotRestore<StateKey, StateValue>> {
        StateSnapshotRestore::new(
            &self.state_store.state_merkle_db,
            &self.state_store,
            version,
            expected_root_hash,
            true, /* async_commit */
            restore_mode,
        )
    }
```
