# Audit Report

## Title
Race Condition in Fast Sync State Snapshot Receiver Creation Allows Multiple Concurrent Receivers and State Corruption

## Summary
The `get_state_snapshot_receiver()` function in `FastSyncStorageWrapper` contains a race condition that allows multiple concurrent calls to successfully create snapshot receivers for the same version, leading to Jellyfish Merkle tree corruption and state inconsistency. The function unconditionally sets `fast_sync_status` to STARTED without atomically checking if a receiver was already created, violating the intended UNKNOWN → STARTED → FINISHED state machine.

## Finding Description
The vulnerability exists in the state transition logic: [1](#0-0) 

The function performs a non-atomic check-then-act operation by:
1. Acquiring the write lock on `fast_sync_status`
2. Unconditionally setting status to STARTED (even if already STARTED)
3. Releasing the lock
4. Calling the underlying database's `get_state_snapshot_receiver()`

When two threads call this concurrently, both will:
- Successfully acquire and release the lock sequentially
- Both set status to STARTED (one overwrites the other)
- Both proceed to create separate `StateSnapshotRestore` instances for the same version

Each `StateSnapshotRestore` instance maintains independent state: [2](#0-1) 

The instances independently write to the database: [3](#0-2) 

This corrupts the Jellyfish Merkle tree because both instances write conflicting node data for the same version. The status is initialized in-memory on each restart: [4](#0-3) 

After a crash during snapshot restoration, status resets to UNKNOWN while partial tree data persists in the database, creating a critical window where concurrent recovery attempts can both succeed.

## Impact Explanation
**Critical Severity** - This breaks **Invariant #4: State Consistency** as state transitions are no longer atomic and Merkle proofs become unverifiable. The impact includes:

1. **Consensus Safety Violation**: Different nodes could compute different state roots from the same snapshot data, causing chain splits
2. **Merkle Tree Corruption**: Conflicting nodes written to the same version create an invalid tree structure
3. **Non-Recoverable State**: The corrupted Merkle tree cannot be repaired without manual intervention or hardfork
4. **State Sync Failure**: Nodes attempting to sync will receive invalid proofs and fail verification

This meets Critical severity criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation
**Medium-High Likelihood** in specific scenarios:

1. **Restart/Recovery Window**: When a node crashes mid-snapshot-sync and restarts, the in-memory status resets to UNKNOWN but partial database state persists. If multiple services attempt recovery simultaneously, both succeed.

2. **Distributed Components**: The `DbReaderWriter` is Arc-wrapped and cloned across components: [5](#0-4) 

While normal operation has protection via the bootstrapper's `initialized_state_snapshot_receiver` flag: [6](#0-5) 

This flag is not enforced at the storage layer, violating defense-in-depth principles. The storage layer should be independently safe.

## Recommendation
Implement atomic compare-and-swap for the state transition:

```rust
fn get_state_snapshot_receiver(
    &self,
    version: Version,
    expected_root_hash: HashValue,
) -> Result<Box<dyn StateSnapshotReceiver<StateKey, StateValue>>> {
    // Atomic check-and-set
    {
        let mut status = self.fast_sync_status.write();
        if *status != FastSyncStatus::UNKNOWN {
            return Err(anyhow::anyhow!(
                "State snapshot receiver already initialized. Current status: {:?}",
                *status
            ));
        }
        *status = FastSyncStatus::STARTED;
    }
    
    self.get_aptos_db_write_ref()
        .get_state_snapshot_receiver(version, expected_root_hash)
}
```

Additionally, add validation in `finalize_state_snapshot` to detect corruption: [7](#0-6) 

## Proof of Concept
```rust
// PoC: Concurrent receiver creation causing state corruption
use std::sync::Arc;
use std::thread;

// Assuming FastSyncStorageWrapper is accessible
fn test_concurrent_receiver_creation() {
    let wrapper = Arc::new(/* initialized FastSyncStorageWrapper */);
    let version = 100;
    let root_hash = HashValue::zero();
    
    let wrapper1 = wrapper.clone();
    let wrapper2 = wrapper.clone();
    
    let handle1 = thread::spawn(move || {
        wrapper1.get_state_snapshot_receiver(version, root_hash)
    });
    
    let handle2 = thread::spawn(move || {
        wrapper2.get_state_snapshot_receiver(version, root_hash)
    });
    
    let receiver1 = handle1.join().unwrap().unwrap();
    let receiver2 = handle2.join().unwrap().unwrap();
    
    // Both receivers created successfully - BUG!
    // Now both will write conflicting data to the same version
    assert!(receiver1 as *const _ != receiver2 as *const _);
}
```

The test demonstrates that both threads successfully create receivers, violating the singleton invariant for state snapshot restoration at a given version.

### Citations

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L92-96)
```rust
            Ok(Either::Right(FastSyncStorageWrapper {
                temporary_db_with_genesis: Arc::new(secondary_db),
                db_for_fast_sync: Arc::new(db_main),
                fast_sync_status: Arc::new(RwLock::new(FastSyncStatus::UNKNOWN)),
            }))
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L144-152)
```rust
    fn get_state_snapshot_receiver(
        &self,
        version: Version,
        expected_root_hash: HashValue,
    ) -> Result<Box<dyn StateSnapshotReceiver<StateKey, StateValue>>> {
        *self.fast_sync_status.write() = FastSyncStatus::STARTED;
        self.get_aptos_db_write_ref()
            .get_state_snapshot_receiver(version, expected_root_hash)
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L154-170)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let status = self.get_fast_sync_status();
        assert_eq!(status, FastSyncStatus::STARTED);
        self.get_aptos_db_write_ref().finalize_state_snapshot(
            version,
            output_with_proof,
            ledger_infos,
        )?;
        let mut status = self.fast_sync_status.write();
        *status = FastSyncStatus::FINISHED;
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L145-149)
```rust
pub struct StateSnapshotRestore<K, V> {
    tree_restore: Arc<Mutex<Option<JellyfishMerkleRestore<K>>>>,
    kv_restore: Arc<Mutex<Option<StateValueRestore<K, V>>>>,
    restore_mode: StateSnapshotRestoreMode,
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1244-1279)
```rust
    fn write_kv_batch(
        &self,
        version: Version,
        node_batch: &StateValueBatch,
        progress: StateSnapshotProgress,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_writer_write_chunk"]);
        let mut batch = SchemaBatch::new();
        let mut sharded_schema_batch = self.state_kv_db.new_sharded_native_batches();

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
            &DbMetadataValue::StateSnapshotProgress(progress),
        )?;

        if self.internal_indexer_db.is_some()
            && self
                .internal_indexer_db
                .as_ref()
                .unwrap()
                .statekeys_enabled()
        {
            let keys = node_batch.keys().map(|key| key.0.clone()).collect();
            self.internal_indexer_db
                .as_ref()
                .unwrap()
                .write_keys_to_indexer_db(&keys, version, progress)?;
        }
        self.shard_state_value_batch(
            &mut sharded_schema_batch,
            node_batch,
            self.state_kv_db.enabled_sharding(),
        )?;
        self.state_kv_db
            .commit(version, Some(batch), sharded_schema_batch)
    }
```

**File:** storage/storage-interface/src/lib.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::state_store::state_view::hot_state_view::HotStateView;
use aptos_crypto::HashValue;
pub use aptos_types::indexer::indexer_db_reader::Order;
use aptos_types::{
    account_address::AccountAddress,
    account_config::NewBlockEvent,
    contract_event::{ContractEvent, EventWithVersion},
    epoch_change::EpochChangeProof,
    epoch_state::EpochState,
    event::EventKey,
    ledger_info::LedgerInfoWithSignatures,
    proof::{
        AccumulatorConsistencyProof, SparseMerkleProof, SparseMerkleProofExt,
        SparseMerkleRangeProof, TransactionAccumulatorRangeProof, TransactionAccumulatorSummary,
    },
    state_proof::StateProof,
    state_store::{
        state_key::StateKey,
        state_storage_usage::StateStorageUsage,
        state_value::{StateValue, StateValueChunkWithProof},
        table::{TableHandle, TableInfo},
    },
    transaction::{
        AccountOrderedTransactionsWithProof, IndexedTransactionSummary, PersistedAuxiliaryInfo,
        Transaction, TransactionAuxiliaryData, TransactionInfo, TransactionListWithProofV2,
        TransactionOutputListWithProofV2, TransactionToCommit, TransactionWithProof, Version,
    },
    write_set::WriteSet,
};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use thiserror::Error;

pub mod block_info;
pub mod chunk_to_commit;
pub mod errors;
mod ledger_summary;
mod metrics;
#[cfg(any(test, feature = "fuzzing"))]
pub mod mock;
pub mod state_store;

use crate::{
    chunk_to_commit::ChunkToCommit,
    state_store::{state::State, state_summary::StateSummary},
};
pub use aptos_types::block_info::BlockHeight;
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L984-1001)
```rust
        // Initialize the state value synchronizer (if not already done)
        if !self.state_value_syncer.initialized_state_snapshot_receiver {
            // Fetch all verified epoch change proofs
            let version_to_sync = ledger_info_to_sync.ledger_info().version();
            let epoch_change_proofs = if version_to_sync == GENESIS_TRANSACTION_VERSION {
                vec![ledger_info_to_sync.clone()] // Sync to genesis
            } else {
                self.verified_epoch_states.all_epoch_ending_ledger_infos() // Sync beyond genesis
            };

            // Initialize the state value synchronizer
            let _join_handle = self.storage_synchronizer.initialize_state_synchronizer(
                epoch_change_proofs,
                ledger_info_to_sync,
                transaction_output_to_sync.clone(),
            )?;
            self.state_value_syncer.initialized_state_snapshot_receiver = true;
        }
```
