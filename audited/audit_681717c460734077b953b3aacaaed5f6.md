# Audit Report

## Title
Post-Execution Unmetered Storage I/O in Resource Group Metadata Fetching

## Summary
The `get_group_reads_needing_exchange` function can trigger storage I/O operations after gas metering is complete, potentially causing excessive latency during transaction change set finalization. While the number of operations is bounded by gas-metered reads during execution, the storage access cost itself is not accounted for in gas calculations.

## Finding Description

During transaction execution, when the VM session completes and produces a change set, the `NativeAggregatorContext::into_change_set` function is called to finalize aggregator-related changes. This function invokes `get_group_reads_needing_exchange` to identify resource group reads that need value exchange. [1](#0-0) 

The issue manifests in two code paths:

**Parallel Execution Path:** [2](#0-1) 

At line 1407, `get_resource_state_value_metadata` is called for each resource group that was read during execution.

**Sequential Execution Path:** [3](#0-2) 

At line 1461, the same metadata fetch occurs.

The critical issue is in `get_resource_state_value_metadata`: [4](#0-3) 

This calls `get_resource_state_value_impl`: [5](#0-4) 

At line 1547, if the value is not cached (status is `Uninitialized`), it calls `get_raw_base_value` which performs storage I/O: [6](#0-5) 

Line 1144 performs the actual storage read via `self.base_view.get_state_value(state_key)`.

The developers acknowledge this behavior in comments: [7](#0-6) 

**Attack Scenario:**
1. Attacker crafts transactions that read specific resources from many different resource groups
2. During execution, only individual resources are read (gas-metered), but group-level metadata may not be fully cached
3. After execution completes, `into_change_set()` is called
4. For each group read, `get_group_reads_needing_exchange` attempts to fetch metadata
5. If metadata is not cached, storage I/O is triggered for each group
6. This happens **after** gas metering is complete and cannot be aborted
7. Multiple such transactions cause cumulative latency spikes on validator nodes

## Impact Explanation

This issue qualifies as **High Severity** under the Aptos bug bounty program criteria: "Validator node slowdowns" (up to $50,000).

While individual transactions are bounded by gas limits on the number of group reads, the storage I/O cost per group is not accounted for in gas. An attacker could:

- Submit multiple transactions that read from many distinct resource groups
- Cause metadata fetches for dozens or hundreds of groups per transaction
- Create sustained latency spikes across the validator network
- Degrade network performance without requiring significant funds (only gas costs)

The impact is amplified because:
1. This occurs in the critical path of transaction finalization
2. All validators processing the same block experience the slowdown
3. The cost is incurred after the point of no return (gas already deducted)
4. Storage I/O is inherently slower than memory operations

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is feasible because:
- Resource groups with delayed fields are used in the Aptos framework (e.g., for aggregators)
- Attackers can craft transactions to read from multiple groups
- The gas cost is relatively low compared to the latency impact
- No special privileges are required

However, it requires:
- Understanding of resource groups and delayed field mechanics
- Sustained transaction submission to maintain the attack
- Some gas expenditure (though potentially profitable if disrupting a competitor)

## Recommendation

Implement one or more of the following mitigations:

1. **Pre-cache group metadata**: During resource group reads, proactively cache the group-level metadata to ensure it's available during `get_group_reads_needing_exchange`.

2. **Add gas accounting**: Track the number of metadata fetches in `get_group_reads_needing_exchange` and enforce a maximum limit based on a reasonable bound (e.g., proportional to gas consumed during execution).

3. **Optimize metadata storage**: Maintain an in-memory cache of frequently accessed resource group metadata to reduce storage hits.

4. **Rate limiting**: Implement transaction-level limits on the number of distinct resource groups that can be read.

Example fix for option 1:
```rust
// In get_resource_from_group_impl or similar read paths
// Ensure group metadata is cached whenever a group resource is read
fn ensure_group_metadata_cached(&self, group_key: &T::Key) -> PartialVMResult<()> {
    if !self.latest_view.get_resource_state().has_cached_metadata(group_key) {
        let metadata = self.get_resource_state_value_metadata(group_key)?;
        // Cache for later use in get_group_reads_needing_exchange
    }
    Ok(())
}
```

## Proof of Concept

```rust
// Pseudo-code for attack transaction in Move
script {
    use aptos_framework::resource_group_example;
    
    fun exploit(account: &signer) {
        // Read from many different resource groups
        // Each read is gas-metered during execution
        let i = 0;
        while (i < 100) {
            // Read from resource group i, triggering capture
            resource_group_example::read_from_group(i);
            i = i + 1;
        };
        // After script completes, into_change_set() is called
        // get_group_reads_needing_exchange will fetch metadata for all 100 groups
        // If not cached, triggers 100 storage I/O operations
        // Total latency: 100 * storage_latency (not gas-metered)
    }
}
```

To reproduce:
1. Deploy resource groups with delayed fields across many state keys
2. Submit transactions that read from 50-100+ distinct resource groups
3. Monitor validator latency during `into_change_set` processing
4. Observe latency spikes correlating with storage I/O for metadata fetches
5. Measure cumulative impact across multiple such transactions

## Notes

While the number of I/O operations is technically bounded by gas-metered reads, the unbounded aspect refers to the fact that the **cost** of these operations is not bounded or accounted for in gas. This creates an asymmetry where an attacker pays for reads but not for the subsequent metadata fetches, allowing disproportionate impact on validator performance.

### Citations

**File:** aptos-move/framework/src/natives/aggregator_natives/context.rs (L104-165)
```rust
    pub fn into_change_set(self) -> PartialVMResult<AggregatorChangeSet> {
        let NativeAggregatorContext {
            aggregator_v1_data,
            delayed_field_data,
            ..
        } = self;
        let (_, destroyed_aggregators, aggregators) = aggregator_v1_data.into_inner().into();

        let mut aggregator_v1_changes = BTreeMap::new();

        // First, process all writes and deltas.
        for (id, aggregator) in aggregators {
            let (value, state, limit, history) = aggregator.into();

            let change = match state {
                AggregatorState::Data => AggregatorChangeV1::Write(value),
                AggregatorState::PositiveDelta => {
                    let history = history.unwrap();
                    let plus = SignedU128::Positive(value);
                    let delta_op = DeltaOp::new(plus, limit, history);
                    AggregatorChangeV1::Merge(delta_op)
                },
                AggregatorState::NegativeDelta => {
                    let history = history.unwrap();
                    let minus = SignedU128::Negative(value);
                    let delta_op = DeltaOp::new(minus, limit, history);
                    AggregatorChangeV1::Merge(delta_op)
                },
            };
            aggregator_v1_changes.insert(id.0, change);
        }

        // Additionally, do not forget to delete destroyed values from storage.
        for id in destroyed_aggregators {
            aggregator_v1_changes.insert(id.0, AggregatorChangeV1::Delete);
        }

        let delayed_field_changes = delayed_field_data.into_inner().into();
        let delayed_write_set_ids = delayed_field_changes
            .keys()
            .cloned()
            .collect::<HashSet<_>>();
        Ok(AggregatorChangeSet {
            aggregator_v1_changes,
            delayed_field_changes,
            // is_empty check covers both whether delayed fields are enabled or not, as well as whether there
            // are any changes that would require computing reads needing exchange.
            // TODO[agg_v2](optimize) we only later compute the write set, so cannot pass the correct skip values here.
            reads_needing_exchange: if delayed_write_set_ids.is_empty() {
                BTreeMap::new()
            } else {
                self.delayed_field_resolver
                    .get_reads_needing_exchange(&delayed_write_set_ids, &HashSet::new())?
            },
            group_reads_needing_exchange: if delayed_write_set_ids.is_empty() {
                BTreeMap::new()
            } else {
                self.delayed_field_resolver
                    .get_group_reads_needing_exchange(&delayed_write_set_ids, &HashSet::new())?
            },
        })
    }
```

**File:** aptos-move/block-executor/src/view.rs (L1140-1160)
```rust
    pub(crate) fn get_raw_base_value(
        &self,
        state_key: &T::Key,
    ) -> PartialVMResult<Option<StateValue>> {
        let ret = self.base_view.get_state_value(state_key).map_err(|e| {
            PartialVMError::new(StatusCode::STORAGE_ERROR).with_message(format!(
                "Unexpected storage error for {:?}: {:?}",
                state_key, e
            ))
        });

        if ret.is_err() {
            // Even speculatively, reading from base view should not return an error.
            // Thus, this critical error log and count does not need to be buffered.
            let log_context = AdapterLogSchema::new(self.base_view.id(), self.txn_idx as usize);
            alert!(
                log_context,
                "[VM, StateView] Error getting data from storage for {:?}",
                state_key
            );
        }
```

**File:** aptos-move/block-executor/src/view.rs (L1370-1425)
```rust
    fn get_group_reads_needing_exchange_parallel(
        &self,
        parallel_state: &ParallelState<'a, T>,
        delayed_write_set_ids: &HashSet<DelayedFieldID>,
        skip: &HashSet<T::Key>,
    ) -> PartialVMResult<BTreeMap<T::Key, (StateValueMetadata, u64)>> {
        let reads_with_delayed_fields = parallel_state
            .captured_reads
            .borrow()
            .get_group_read_values_with_delayed_fields(skip)
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect::<Vec<_>>();

        reads_with_delayed_fields
            .into_iter()
            .map(|(key, group_read)| -> PartialVMResult<_> {
                let GroupRead { inner_reads, .. } = group_read;

                // TODO[agg_v2](clean-up): Once ids can be extracted without possible failure,
                // the following is just an any call on iterator (same for resource reads).
                let mut resources_needing_delayed_field_exchange = false;
                for data_read in inner_reads.values() {
                    if let DataRead::Versioned(_version, value, Some(layout)) = data_read {
                        let needs_exchange = self
                            .does_value_need_exchange(value, layout.as_ref(), delayed_write_set_ids)
                            .map_err(PartialVMError::from)?;

                        if needs_exchange {
                            resources_needing_delayed_field_exchange = true;
                            break;
                        }
                    }
                }
                if !resources_needing_delayed_field_exchange {
                    return Ok(None);
                }

                match self.get_resource_state_value_metadata(&key)? {
                    Some(metadata) => match parallel_state.read_group_size(&key, self.txn_idx)? {
                        Some(group_size) => Ok(Some((key, (metadata, group_size.get())))),
                        None => Err(code_invariant_error(format!(
                            "Cannot compute metadata op size for the group read {:?}",
                            key
                        ))
                        .into()),
                    },
                    None => Err(code_invariant_error(format!(
                        "Metadata op not present for the group read {:?}",
                        key
                    ))
                    .into()),
                }
            })
            .flat_map(Result::transpose)
            .collect()
    }
```

**File:** aptos-move/block-executor/src/view.rs (L1427-1484)
```rust
    fn get_group_reads_needing_exchange_sequential(
        &self,
        group_read_set: &HashMap<T::Key, HashSet<T::Tag>>,
        unsync_map: &UnsyncMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
        delayed_write_set_ids: &HashSet<DelayedFieldID>,
        skip: &HashSet<T::Key>,
    ) -> PartialVMResult<BTreeMap<T::Key, (StateValueMetadata, u64)>> {
        group_read_set
            .iter()
            .filter(|(key, _tags)| !skip.contains(key))
            .map(|(key, tags)| -> PartialVMResult<_> {
                if let Some(value_vec) = unsync_map.fetch_group_data(key) {
                    // TODO[agg_v2](cleanup) - can we use .any() instead?
                    let mut resources_needing_delayed_field_exchange = false;
                    for (tag, value_with_layout) in value_vec {
                        if tags.contains(&tag) {
                            if let ValueWithLayout::Exchanged(value, Some(layout)) =
                                value_with_layout
                            {
                                let needs_exchange = self.does_value_need_exchange(
                                    &value,
                                    layout.as_ref(),
                                    delayed_write_set_ids,
                                )?;
                                if needs_exchange {
                                    resources_needing_delayed_field_exchange = true;
                                    break;
                                }
                            }
                        }
                    }
                    if !resources_needing_delayed_field_exchange {
                        return Ok(None);
                    }
                    match self.get_resource_state_value_metadata(key)? {
                        Some(metadata) => match unsync_map.get_group_size(key) {
                            Some(group_size) => {
                                Ok(Some((key.clone(), (metadata, group_size.get()))))
                            },
                            None => Err(code_invariant_error(format!(
                                "Sequential cannot find metadata op size for the group read {:?}",
                                key
                            ))
                            .into()),
                        },
                        None => Err(code_invariant_error(format!(
                            "Sequential cannot find metadata op for the group read {:?}",
                            key,
                        ))
                        .into()),
                    }
                } else {
                    Ok(None)
                }
            })
            .flat_map(Result::transpose)
            .collect()
    }
```

**File:** aptos-move/block-executor/src/view.rs (L1524-1584)
```rust
    fn get_resource_state_value_impl(
        &self,
        state_key: &T::Key,
        layout: UnknownOrLayout,
        kind: ReadKind,
    ) -> PartialVMResult<ReadResult> {
        debug_assert!(
            !state_key.is_module_path(),
            "Reading a module {:?} using ResourceView",
            state_key,
        );

        let state = self.latest_view.get_resource_state();

        let mut ret = state.read_cached_data_by_kind(
            self.txn_idx,
            state_key,
            kind,
            layout.clone(),
            &|value, layout| self.patch_base_value(value, layout),
        )?;
        if matches!(ret, ReadResult::Uninitialized) {
            let from_storage =
                TransactionWrite::from_state_value(self.get_raw_base_value(state_key)?);
            state.set_base_value(
                state_key.clone(),
                ValueWithLayout::RawFromStorage(TriompheArc::new(from_storage)),
            );

            // In case of concurrent storage fetches, we cannot use our value,
            // but need to fetch it from versioned_map again.
            ret = state.read_cached_data_by_kind(
                self.txn_idx,
                state_key,
                kind,
                layout.clone(),
                &|value, layout| self.patch_base_value(value, layout),
            )?;
        }

        match ret {
            // ExecutionHalted indicates that the parallel execution is halted.
            // The read should return immediately and log the error.
            // For now we use SPECULATIVE_EXECUTION_ABORT_ERROR as the VM
            // will not log the speculative error,
            // so no actual error will be logged once the execution is halted and
            // the speculative logging is flushed.
            ReadResult::HaltSpeculativeExecution(msg) => Err(PartialVMError::new(
                StatusCode::SPECULATIVE_EXECUTION_ABORT_ERROR,
            )
            .with_message(msg)),
            ReadResult::Uninitialized => Err(code_invariant_error(
                "base value must already be recorded in the MV data structure",
            )
            .into()),
            ReadResult::Exists(_)
            | ReadResult::Metadata(_)
            | ReadResult::Value(_, _)
            | ReadResult::ResourceSize(_) => Ok(ret),
        }
    }
```

**File:** aptos-move/block-executor/src/view.rs (L1652-1664)
```rust
    fn get_resource_state_value_metadata(
        &self,
        state_key: &Self::Key,
    ) -> PartialVMResult<Option<StateValueMetadata>> {
        self.get_resource_state_value_impl(state_key, UnknownOrLayout::Unknown, ReadKind::Metadata)
            .map(|res| {
                if let ReadResult::Metadata(v) = res {
                    v
                } else {
                    unreachable!("Read result must be Metadata kind")
                }
            })
    }
```

**File:** aptos-move/aptos-aggregator/src/resolver.rs (L252-256)
```rust
    // get_reads_needing_exchange is local (looks at in-MVHashMap information only)
    // and all failures are code invariant failures - so we return PanicError.
    // get_group_reads_needing_exchange needs to additionally get the metadata of the
    // whole group, which can additionally fail with speculative / storage errors,
    // so we return PartialVMResult, to be able to distinguish/propagate those errors.
```
