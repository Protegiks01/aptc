# Audit Report

## Title
Unvalidated Peer-Advertised Ledger Info Enables Synchronization Monitoring Degradation Attack

## Summary
Malicious peers can send `StorageServerSummary` messages with fabricated `synced_ledger_info` containing artificially inflated version numbers. Since these ledger infos are never cryptographically validated, they pollute the global data summary, causing honest nodes to remain perpetually in `WaitingForCatchup` state and triggering repeated subscription stream terminations. This degrades sync performance and produces misleading logs that suggest normal operation.

## Finding Description

The Aptos state sync system aggregates `StorageServerSummary` data from network peers to build a `GlobalDataSummary` that informs synchronization decisions. Each `StorageServerSummary` contains a `DataSummary` with a `synced_ledger_info` field of type `LedgerInfoWithSignatures`, which should contain valid BLS multi-signatures from the validator set. [1](#0-0) 

However, when peers send `StorageServerSummary` responses, the system accepts and stores them without validating the cryptographic signatures in the `synced_ledger_info`: [2](#0-1) [3](#0-2) [4](#0-3) 

These unvalidated summaries are aggregated into the global data summary, where `highest_synced_ledger_info()` returns the ledger info with the highest version across all non-ignored peers: [5](#0-4) [6](#0-5) 

**Attack Path:**

1. A malicious peer (validator or regular network peer) sends a `StorageServerSummary` with a fabricated `synced_ledger_info` containing version 1,000,000,000 (or any arbitrarily high number)

2. The data client stores this without validation and includes it in the global data summary

3. **Impact on Latency Monitor**: The latency monitor checks if the node has caught up by comparing `highest_synced_version + MAX_VERSION_LAG_TO_TOLERATE >= highest_advertised_version`. With the inflated advertised version, this condition fails perpetually: [7](#0-6) 

The node remains in `WaitingForCatchup` state, logging benign messages that suggest normal operation, while latency tracking never starts.

4. **Impact on Subscription Streams**: The data streaming service compares the highest response version with the highest advertised version to detect stream lag: [8](#0-7) 

With the fake high version, the calculated lag becomes enormous. If this lag persists and increases for longer than `max_subscription_stream_lag_secs`, the stream is marked as "beyond recovery": [9](#0-8) 

The subscription stream gets terminated and reset repeatedly in a loop, forcing fallback to less efficient non-subscription sync methods.

**Why the Peer Isn't Ignored:**

The peer scoring system only lowers scores when actual data requests fail proof verification. Since the fake `synced_ledger_info` itself is never requested or verified, it doesn't trigger score penalties: [10](#0-9) 

The malicious peer remains non-ignored and continues polluting the global data summary.

## Impact Explanation

This vulnerability meets **Medium Severity** criteria per the Aptos bug bounty program for the following reasons:

1. **State Inconsistencies**: The latency monitoring system enters an incorrect state that doesn't reflect reality, providing misleading operational data

2. **Performance Degradation**: Subscription streams (the preferred real-time sync method) are repeatedly terminated, forcing nodes to fall back to less efficient polling-based sync methods

3. **Monitoring Blind Spots**: Operators see logs suggesting "Waiting for the node to catch up to the latest version" which appears normal, masking the attack and delaying incident response

4. **Not Complete Liveness Failure**: Nodes can still sync via non-subscription methods with proper proof verification, preventing this from being Critical severity

5. **Affects All Connected Nodes**: Any honest node connected to the malicious peer experiences degradation

The attack does not cause fund loss, consensus violations, or complete unavailability, but does create operational challenges requiring intervention to identify and mitigate.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attacker Requirements**: Only requires network connectivity as a peer (validator or non-validator). No cryptographic keys, stake, or validator set membership needed

- **Attack Complexity**: Trivial - just send a single modified `StorageServerSummary` message with a high version number in `synced_ledger_info`

- **Detection Difficulty**: Very difficult to detect operationally since logs appear normal ("waiting for catchup")

- **Persistence**: The attack persists as long as the malicious peer remains connected and continues sending fake summaries

- **Mitigation Barriers**: No automatic defense mechanism exists - the peer won't be ignored because the fake data never fails proof verification

## Recommendation

Implement cryptographic validation of `synced_ledger_info` received from peers before accepting it into peer state. The validation should:

1. **Verify BLS Multi-Signatures**: Call `ledger_info.verify_signatures(validator_verifier)` using the appropriate epoch's validator set

2. **Validate Against Known State**: Ensure the advertised version is within reasonable bounds of locally known blockchain state

3. **Score Malicious Peers**: If signature verification fails, mark the peer as malicious and ignore future summaries

**Recommended Code Fix** (in `peer_states.rs`):

```rust
/// Updates the storage summary for the given peer
pub fn update_summary(&self, peer: PeerNetworkId, storage_summary: StorageServerSummary) {
    // Validate the synced_ledger_info if present
    if let Some(synced_ledger_info) = &storage_summary.data_summary.synced_ledger_info {
        // Get the validator verifier for the ledger info's epoch
        // (This requires access to EpochState - implementation details depend on architecture)
        if let Err(e) = validate_synced_ledger_info(synced_ledger_info) {
            warn!("Peer {} sent invalid synced_ledger_info: {:?}", peer, e);
            // Mark peer as malicious
            self.update_score_error(peer, ErrorType::Malicious);
            return;
        }
    }
    
    self.peer_to_state
        .entry(peer)
        .or_insert(PeerState::new(self.data_client_config.clone()))
        .update_storage_summary(storage_summary);
}
```

Additionally, implement sanity bounds checking in `calculate_global_data_summary()` to filter out ledger infos with suspiciously high versions relative to local state.

## Proof of Concept

```rust
// Proof of Concept: Malicious peer sends fake StorageServerSummary

use aptos_types::ledger_info::{LedgerInfo, LedgerInfoWithSignatures};
use aptos_storage_service_types::responses::{StorageServerSummary, DataSummary, ProtocolMetadata};
use aptos_crypto::bls12381;

// Step 1: Create a fake LedgerInfoWithSignatures with artificially high version
let fake_ledger_info = LedgerInfo::new(
    /* epoch */ 100,
    /* version */ 1_000_000_000, // Artificially inflated version
    /* transaction_accumulator_hash */ HashValue::zero(),
    /* state_checkpoint_hash */ HashValue::zero(),
    /* gas_used */ 0,
    /* success */ true,
    /* timestamp_usecs */ 1234567890,
    /* next_epoch_state */ None,
);

// Create fake signatures (empty - they're never validated)
let fake_signatures = bls12381::Signature::dummy_signature();
let fake_ledger_info_with_sigs = LedgerInfoWithSignatures::new(
    fake_ledger_info,
    BTreeMap::new(), // Empty signature map - never validated!
);

// Step 2: Construct malicious StorageServerSummary
let malicious_summary = StorageServerSummary {
    protocol_metadata: ProtocolMetadata::default(),
    data_summary: DataSummary {
        synced_ledger_info: Some(fake_ledger_info_with_sigs),
        epoch_ending_ledger_infos: None,
        states: None,
        transactions: None,
        transaction_outputs: None,
    },
};

// Step 3: Send this summary to honest nodes
// When received via GetStorageServerSummary request response,
// it will be stored without validation:
// data_client.update_peer_storage_summary(peer, malicious_summary);

// Step 4: This pollutes global_data_summary.advertised_data.highest_synced_ledger_info()
// causing:
// - Latency monitor stuck in WaitingForCatchup
// - Subscription streams repeatedly terminated due to "lag"

// Expected Observable Behavior:
// - Logs show: "Waiting for the node to catch up to the latest version"
// - Subscription streams fail with: "The subscription stream is beyond recovery!"
// - Sync performance degrades as node falls back to polling methods
```

**Notes:**

The vulnerability exists because the state sync system treats peer-advertised metadata (`synced_ledger_info` in storage summaries) as trusted data for making synchronization decisions, while only validating actual payload data (transactions, proofs) when fetched. This trust assumption is violated when malicious peers send fabricated metadata, creating a gap between perceived network state and reality.

### Citations

**File:** state-sync/storage-service/types/src/responses.rs (L667-686)
```rust
pub struct DataSummary {
    /// The ledger info corresponding to the highest synced version in storage.
    /// This indicates the highest version and epoch that storage can prove.
    pub synced_ledger_info: Option<LedgerInfoWithSignatures>,
    /// The range of epoch ending ledger infos in storage, e.g., if the range
    /// is [(X,Y)], it means all epoch ending ledger infos for epochs X->Y
    /// (inclusive) are held.
    pub epoch_ending_ledger_infos: Option<CompleteDataRange<Epoch>>,
    /// The range of states held in storage, e.g., if the range is
    /// [(X,Y)], it means all states are held for every version X->Y
    /// (inclusive).
    pub states: Option<CompleteDataRange<Version>>,
    /// The range of transactions held in storage, e.g., if the range is
    /// [(X,Y)], it means all transactions for versions X->Y (inclusive) are held.
    pub transactions: Option<CompleteDataRange<Version>>,
    /// The range of transaction outputs held in storage, e.g., if the range
    /// is [(X,Y)], it means all transaction outputs for versions X->Y
    /// (inclusive) are held.
    pub transaction_outputs: Option<CompleteDataRange<Version>>,
}
```

**File:** state-sync/aptos-data-client/src/poller.rs (L422-439)
```rust
        let storage_summary = match result {
            Ok(storage_summary) => storage_summary,
            Err(error) => {
                warn!(
                    (LogSchema::new(LogEntry::StorageSummaryResponse)
                        .event(LogEvent::PeerPollingError)
                        .message("Error encountered when polling peer!")
                        .error(&error)
                        .peer(&peer))
                );
                return;
            },
        };

        // Update the summary for the peer
        data_summary_poller
            .data_client
            .update_peer_storage_summary(peer, storage_summary);
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L142-160)
```rust
    /// Returns the storage summary iff the peer is not below the ignore threshold
    pub fn get_storage_summary_if_not_ignored(&self) -> Option<&StorageServerSummary> {
        if self.is_ignored() {
            None
        } else {
            self.storage_summary.as_ref()
        }
    }

    /// Returns true iff the peer is currently ignored
    fn is_ignored(&self) -> bool {
        // Only ignore peers if the config allows it
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }

        // Otherwise, ignore peers with a low score
        self.score <= IGNORE_PEER_THRESHOLD
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L176-179)
```rust
    /// Updates the storage summary for the peer
    fn update_storage_summary(&mut self, storage_summary: StorageServerSummary) {
        self.storage_summary = Some(storage_summary);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L324-330)
```rust
    /// Updates the storage summary for the given peer
    pub fn update_summary(&self, peer: PeerNetworkId, storage_summary: StorageServerSummary) {
        self.peer_to_state
            .entry(peer)
            .or_insert(PeerState::new(self.data_client_config.clone()))
            .update_storage_summary(storage_summary);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L339-408)
```rust
    pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
        // Gather all storage summaries, but exclude peers that are ignored
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();

        // If we have no peers, return an empty global summary
        if storage_summaries.is_empty() {
            return GlobalDataSummary::empty();
        }

        // Calculate the global data summary using the advertised peer data
        let mut advertised_data = AdvertisedData::empty();
        let mut max_epoch_chunk_sizes = vec![];
        let mut max_state_chunk_sizes = vec![];
        let mut max_transaction_chunk_sizes = vec![];
        let mut max_transaction_output_chunk_sizes = vec![];
        for summary in storage_summaries {
            // Collect aggregate data advertisements
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
            if let Some(transactions) = summary.data_summary.transactions {
                advertised_data.transactions.push(transactions);
            }
            if let Some(transaction_outputs) = summary.data_summary.transaction_outputs {
                advertised_data
                    .transaction_outputs
                    .push(transaction_outputs);
            }

            // Collect preferred max chunk sizes
            max_epoch_chunk_sizes.push(summary.protocol_metadata.max_epoch_chunk_size);
            max_state_chunk_sizes.push(summary.protocol_metadata.max_state_chunk_size);
            max_transaction_chunk_sizes.push(summary.protocol_metadata.max_transaction_chunk_size);
            max_transaction_output_chunk_sizes
                .push(summary.protocol_metadata.max_transaction_output_chunk_size);
        }

        // Calculate optimal chunk sizes based on the advertised data
        let optimal_chunk_sizes = calculate_optimal_chunk_sizes(
            &self.data_client_config,
            max_epoch_chunk_sizes,
            max_state_chunk_sizes,
            max_transaction_chunk_sizes,
            max_transaction_output_chunk_sizes,
        );
        GlobalDataSummary {
            advertised_data,
            optimal_chunk_sizes,
        }
    }
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L184-198)
```rust
    pub fn highest_synced_ledger_info(&self) -> Option<LedgerInfoWithSignatures> {
        let highest_synced_position = self
            .synced_ledger_infos
            .iter()
            .map(|ledger_info_with_sigs| ledger_info_with_sigs.ledger_info().version())
            .position_max();

        if let Some(highest_synced_position) = highest_synced_position {
            self.synced_ledger_infos
                .get(highest_synced_position)
                .cloned()
        } else {
            None
        }
    }
```

**File:** state-sync/aptos-data-client/src/latency_monitor.rs (L236-264)
```rust
    fn update_advertised_version_timestamps(
        &mut self,
        highest_synced_version: u64,
        highest_advertised_version: u64,
    ) {
        // Check if we're still catching up to the latest version
        if !self.caught_up_to_latest {
            if highest_synced_version + MAX_VERSION_LAG_TO_TOLERATE >= highest_advertised_version {
                info!(
                    (LogSchema::new(LogEntry::LatencyMonitor)
                        .event(LogEvent::CaughtUpToLatest)
                        .message(
                            "We've caught up to the latest version! Starting the latency monitor."
                        ))
                );
                self.caught_up_to_latest = true; // We've caught up
            } else {
                sample!(
                    SampleRate::Duration(Duration::from_secs(LATENCY_MONITOR_LOG_FREQ_SECS)),
                    info!(
                        (LogSchema::new(LogEntry::LatencyMonitor)
                            .event(LogEvent::WaitingForCatchup)
                            .message("Waiting for the node to catch up to the latest version before starting the latency monitor."))
                    );
                );

                return; // We're still catching up, so we shouldn't update the advertised version timestamps
            }
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L586-619)
```rust
        // Get the highest advertised version
        let highest_advertised_version = global_data_summary
            .advertised_data
            .highest_synced_ledger_info()
            .map(|ledger_info| ledger_info.ledger_info().version())
            .ok_or_else(|| {
                aptos_data_client::error::Error::UnexpectedErrorEncountered(
                    "The highest synced ledger info is missing from the global data summary!"
                        .into(),
                )
            })?;

        // If the stream is not lagging behind, reset the lag and return
        if highest_response_version >= highest_advertised_version {
            self.reset_subscription_stream_lag();
            return Ok(());
        }

        // Otherwise, the stream is lagging behind the advertised version.
        // Check if the stream is beyond recovery (i.e., has failed).
        let current_stream_lag =
            highest_advertised_version.saturating_sub(highest_response_version);
        if let Some(mut subscription_stream_lag) = self.subscription_stream_lag.take() {
            // Check if the stream lag is beyond recovery
            if subscription_stream_lag
                .is_beyond_recovery(self.streaming_service_config, current_stream_lag)
            {
                return Err(
                    aptos_data_client::error::Error::SubscriptionStreamIsLagging(format!(
                        "The subscription stream is beyond recovery! Current lag: {:?}, last lag: {:?},",
                        current_stream_lag, subscription_stream_lag.version_lag
                    )),
                );
            }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L967-992)
```rust
    fn is_beyond_recovery(
        &mut self,
        streaming_service_config: DataStreamingServiceConfig,
        current_stream_lag: u64,
    ) -> bool {
        // Calculate the total duration the stream has been lagging
        let current_time = self.time_service.now();
        let stream_lag_duration = current_time.duration_since(self.start_time);
        let max_stream_lag_duration =
            Duration::from_secs(streaming_service_config.max_subscription_stream_lag_secs);

        // If the lag is further behind and enough time has passed, the stream has failed
        let lag_has_increased = current_stream_lag > self.version_lag;
        let lag_duration_exceeded = stream_lag_duration >= max_stream_lag_duration;
        if lag_has_increased && lag_duration_exceeded {
            return true; // The stream is beyond recovery
        }

        // Otherwise, update the stream lag if we've caught up.
        // This will ensure the lag can only improve.
        if current_stream_lag < self.version_lag {
            self.version_lag = current_stream_lag;
        }

        false // The stream is not yet beyond recovery
    }
```
