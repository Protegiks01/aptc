# Audit Report

## Title
Silently Ignored RPC Failure in send_commit_proof() Can Cause Validator Liveness Failure

## Summary
The `send_commit_proof()` function in `consensus/src/network.rs` discards RPC failures when sending commit proofs to self, which can cause validators to permanently lose liveness and miss committed blocks when syncing under load. [1](#0-0) 

## Finding Description

When a validator syncs and receives a commit certificate for a block it has already ordered but not yet committed, the `sync_to_highest_commit_cert()` function attempts to fast-forward the block to aggregated state by sending the commit proof to itself via RPC: [2](#0-1) 

The commit proof is sent through `send_commit_proof()`, which performs an RPC to self with a 500ms timeout but silently discards any failure. The RPC goes through `send_rpc_to_self()`: [3](#0-2) 

Under high load, the buffer manager may take longer than 500ms to process the RPC request, causing a timeout. When this happens:

1. The commit proof is never delivered to the buffer manager
2. The block remains in Executed/Signed state, never advancing to Aggregated
3. The validator must collect 2f+1 individual commit votes to aggregate the block
4. However, other validators have already committed this block and moved forward
5. Those validators have removed the block from their buffers and stopped broadcasting votes for it
6. The stuck validator cannot collect the necessary votes
7. All subsequent blocks in the pipeline are blocked waiting for this block to commit
8. The validator permanently loses liveness

The buffer manager's `process_commit_message()` would advance the block to aggregated state if it received the commit decision: [4](#0-3) 

But when the RPC times out, this code is never executed. The validator has no recovery mechanism because:
- Retrying sync triggers the same timeout issue
- Other validators' rebroadcast only covers their own votes for blocks still in their buffers
- The stuck block prevents all subsequent blocks from committing [5](#0-4) 

## Impact Explanation

This is **HIGH severity** per Aptos bug bounty criteria:
- **Validator node slowdowns**: The affected validator cannot commit any blocks, causing complete loss of liveness
- **Significant protocol violations**: Breaks the liveness guarantee that honest validators should make progress
- The validator falls increasingly behind the network and may require manual intervention or state sync to recover

While this doesn't cause consensus safety violations (no double-spending or forks), it can cause individual validators to become non-functional, reducing network resilience and potentially affecting network availability if multiple validators are affected simultaneously.

## Likelihood Explanation

**Medium to High likelihood** under production conditions:

1. **Common trigger**: Validators frequently sync when recovering from network partitions or catching up after downtime
2. **Realistic timeout**: 500ms is a tight deadline when processing many blocks under load
3. **Natural occurrence**: No attacker needed - normal high-load conditions can trigger this
4. **Persistent state**: Once a validator gets stuck, it remains stuck until manual intervention
5. **Evidence**: The TODO comment at line 810 suggests developers are aware that error handling for `send_commit_proof()` is problematic

## Recommendation

**Fix 1: Retry logic with exponential backoff**
```rust
pub async fn send_commit_proof(&self, ledger_info: LedgerInfoWithSignatures) {
    fail_point!("consensus::send::commit_decision", |_| ());
    let msg = ConsensusMsg::CommitMessage(Box::new(CommitMessage::Decision(
        CommitDecision::new(ledger_info.clone()),
    )));
    
    // Retry up to 3 times with exponential backoff
    for attempt in 0..3 {
        let timeout = Duration::from_millis(500 * (1 << attempt));
        match self.send_rpc(self.author, msg.clone(), timeout).await {
            Ok(_) => return,
            Err(e) => {
                warn!(
                    attempt = attempt,
                    error = ?e,
                    "Failed to send commit proof to self, retrying..."
                );
            }
        }
    }
    error!("Failed to send commit proof to self after retries");
}
```

**Fix 2: Use direct channel send instead of RPC**

As suggested by the TODO comment, use direct message delivery through `self_sender` without requiring a response:

```rust
pub async fn send_commit_proof(&self, ledger_info: LedgerInfoWithSignatures) {
    fail_point!("consensus::send::commit_decision", |_| ());
    let msg = ConsensusMsg::CommitMessage(Box::new(CommitMessage::Decision(
        CommitDecision::new(ledger_info),
    )));
    let self_msg = Event::Message(self.author, msg);
    if let Err(e) = self.self_sender.clone().send(self_msg).await {
        error!("Failed to send commit proof to self: {:?}", e);
    }
}
```

**Fix 3: Add timeout monitoring and alerts**

Add metrics to track timeout failures and alert operators when validators are stuck.

## Proof of Concept

```rust
#[tokio::test]
async fn test_commit_proof_timeout_causes_liveness_failure() {
    // Setup: Create a validator with buffer manager under heavy load
    // 1. Start validator V with many pending blocks in execution pipeline
    // 2. Simulate V receiving a SyncInfo with commit cert for block B at round R
    // 3. Block B is already ordered in V's pipeline (between commit_root and ordered_root)
    // 4. Inject delay in buffer manager to cause >500ms processing time
    // 5. Call sync_to_highest_commit_cert() which spawns send_commit_proof()
    // 6. Verify that send_rpc_to_self() times out after 500ms
    // 7. Verify that buffer manager never receives CommitMessage::Decision
    // 8. Verify that block B remains in Executed state, never reaching Aggregated
    // 9. Verify that no progress is made on committing block B or subsequent blocks
    // 10. Verify that validator is stuck even after other validators have moved forward
    
    // Expected: Validator V permanently loses liveness and cannot commit blocks
    // Actual: With current code, this scenario causes permanent validator stall
}
```

The PoC would require creating a test harness that simulates the full consensus pipeline with timing control to trigger the timeout condition.

## Notes

The TODO comment in `buffer_manager.rs` at line 810 acknowledges this issue: `"send_commit_proof() doesn't care about the response and this should be direct send not RPC"`. This suggests the developers recognized the problematic design but haven't yet implemented the fix. The vulnerability affects validator availability and network resilience, particularly during high-load periods or network sync scenarios.

### Citations

**File:** consensus/src/network.rs (L316-332)
```rust
    pub async fn send_rpc_to_self(
        &self,
        msg: ConsensusMsg,
        timeout_duration: Duration,
    ) -> anyhow::Result<ConsensusMsg> {
        let (tx, rx) = oneshot::channel();
        let protocol = RPC[0];
        let self_msg = Event::RpcRequest(self.author, msg.clone(), RPC[0], tx);
        self.self_sender.clone().send(self_msg).await?;
        if let Ok(Ok(Ok(bytes))) = timeout(timeout_duration, rx).await {
            let response_msg =
                tokio::task::spawn_blocking(move || protocol.from_bytes(&bytes)).await??;
            Ok(response_msg)
        } else {
            bail!("self rpc failed");
        }
    }
```

**File:** consensus/src/network.rs (L540-548)
```rust
    pub async fn send_commit_proof(&self, ledger_info: LedgerInfoWithSignatures) {
        fail_point!("consensus::send::commit_decision", |_| ());
        let msg = ConsensusMsg::CommitMessage(Box::new(CommitMessage::Decision(
            CommitDecision::new(ledger_info),
        )));
        let _ = self
            .send_rpc(self.author, msg, Duration::from_millis(500))
            .await;
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L528-541)
```rust
    async fn sync_to_highest_commit_cert(
        &self,
        ledger_info: &LedgerInfoWithSignatures,
        network: Arc<NetworkSender>,
    ) {
        // if the block exists between commit root and ordered root
        if self.commit_root().round() < ledger_info.commit_info().round()
            && self.block_exists(ledger_info.commit_info().id())
            && self.ordered_root().round() >= ledger_info.commit_info().round()
        {
            let proof = ledger_info.clone();
            tokio::spawn(async move { network.send_commit_proof(proof).await });
        }
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L786-812)
```rust
            CommitMessage::Decision(commit_proof) => {
                let target_block_id = commit_proof.ledger_info().commit_info().id();
                info!(
                    "Receive commit decision {}",
                    commit_proof.ledger_info().commit_info()
                );
                let cursor = self
                    .buffer
                    .find_elem_by_key(*self.buffer.head_cursor(), target_block_id);
                if cursor.is_some() {
                    let item = self.buffer.take(&cursor);
                    let new_item = item.try_advance_to_aggregated_with_ledger_info(
                        commit_proof.ledger_info().clone(),
                    );
                    let aggregated = new_item.is_aggregated();
                    self.buffer.set(&cursor, new_item);

                    reply_ack(protocol, response_sender);
                    if aggregated {
                        return Some(target_block_id);
                    }
                } else if self.try_add_pending_commit_proof(commit_proof.into_inner()) {
                    reply_ack(protocol, response_sender);
                } else {
                    reply_nack(protocol, response_sender); // TODO: send_commit_proof() doesn't care about the response and this should be direct send not RPC
                }
            },
```

**File:** consensus/src/pipeline/buffer_manager.rs (L826-865)
```rust
    async fn rebroadcast_commit_votes_if_needed(&mut self) {
        if self.previous_commit_time.elapsed()
            < Duration::from_millis(COMMIT_VOTE_BROADCAST_INTERVAL_MS)
        {
            return;
        }
        let mut cursor = *self.buffer.head_cursor();
        let mut count = 0;
        while cursor.is_some() {
            {
                let mut item = self.buffer.take(&cursor);
                if !item.is_signed() {
                    self.buffer.set(&cursor, item);
                    break;
                }
                let signed_item = item.unwrap_signed_mut();
                let re_broadcast = match &signed_item.rb_handle {
                    None => true,
                    // Since we don't persist the votes, nodes that crashed would lose the votes even after send ack,
                    // We'll try to re-initiate the broadcast after 30s.
                    Some((start_time, _)) => {
                        start_time.elapsed()
                            >= Duration::from_millis(COMMIT_VOTE_REBROADCAST_INTERVAL_MS)
                    },
                };
                if re_broadcast {
                    let commit_vote = CommitMessage::Vote(signed_item.commit_vote.clone());
                    signed_item.rb_handle = self
                        .do_reliable_broadcast(commit_vote)
                        .map(|handle| (Instant::now(), handle));
                    count += 1;
                }
                self.buffer.set(&cursor, item);
            }
            cursor = self.buffer.get_next(&cursor);
        }
        if count > 0 {
            info!("Start reliable broadcast {} commit votes", count);
        }
    }
```
