# Audit Report

## Title
Missing Source Digest Validation Allows Package Content Tampering

## Summary
The Aptos package publishing system fails to validate that deployed bytecode matches the `source_digest` field in `PackageMetadata`. An attacker can publish a package with legitimate-looking `source_digest` metadata while deploying modified malicious bytecode, bypassing integrity checks and potentially deceiving users and dependent packages.

## Finding Description

The vulnerability exists in the package publishing flow where `source_digest` serves as metadata to verify package source integrity, but this digest is never cryptographically validated against the actual deployed bytecode.

**Attack Flow:**

1. The `extract_metadata()` function computes `source_digest` from source files (.move files): [1](#0-0) 

2. This digest is computed by hashing source files: [2](#0-1) 

3. `publish_package()` receives `PackageMetadata` (containing `source_digest`) and bytecode as **separate parameters**: [3](#0-2) 

4. The function stores metadata without validating bytecode correspondence and calls the native publishing function: [4](#0-3) 

5. The native `request_publish` creates a `PublishRequest` with NO source_digest validation: [5](#0-4) 

6. VM-level validation in `validate_publish_request` checks bytecode stability, native functions, module names, and dependencies, but NOT source_digest: [6](#0-5) 

7. Module metadata verification only validates function/struct attributes: [7](#0-6) 

**Exploitation:**
- Compile a legitimate package to obtain correct `source_digest`
- Modify compiled bytecode (change constants, function logic, add backdoors)
- Publish using original `PackageMetadata` with unmodified `source_digest` but tampered bytecode
- On-chain `PackageRegistry` now contains misleading integrity metadata

The `source_digest` field exists in `PackageMetadata` as an integrity indicator but provides no actual integrity guarantee since validation is absent throughout the entire publishing pipeline.

## Impact Explanation

**Severity: Medium**

This violates the integrity assumption that deployed packages match their advertised source digest. While not causing direct funds loss or consensus violations, it:

1. **Breaks Trust Model**: Users and tools examining `source_digest` will see legitimate-looking metadata while actual bytecode is malicious
2. **Bypasses Security Audits**: Auditors review sources matching `source_digest`, but deployed bytecode differs
3. **Dependency Chain Attack**: Packages depending on the malicious package validate `source_digest` during build but deploy against tampered bytecode
4. **State Inconsistency**: On-chain metadata misrepresents actual deployed code, requiring manual intervention to detect

This qualifies as Medium severity per Aptos bug bounty criteria: "State inconsistencies requiring intervention" - the PackageRegistry state contains integrity metadata that doesn't match reality.

## Likelihood Explanation

**Likelihood: High**

The attack is trivial to execute:
- Requires only standard package compilation tools
- No privileged access needed
- Bytecode modification can use existing Move binary format tools
- No runtime detection mechanisms exist
- Publishing flow accepts any `source_digest` value without verification

The only barrier is attacker motivation, as the attack is technically straightforward.

## Recommendation

Implement cryptographic validation that bytecode corresponds to `source_digest`:

**Option 1: Hash-based verification** (Recommended)
Add validation in `validate_publish_request` to recompile sources from metadata and compare bytecode hashes, or store bytecode hash alongside source_digest and validate both.

**Option 2: Remove misleading field**
If validation is infeasible, remove `source_digest` from `PackageMetadata` to avoid creating false security expectations.

**Option 3: Add explicit warnings**
Document that `source_digest` is unvalidated informational metadata and should not be used for security decisions.

**Immediate Fix:**
Add validation in `validate_publish_request`:

```rust
// After line 1738 in aptos_vm.rs
fn validate_source_digest(
    modules: &[CompiledModule],
    expected_digest: &str,
) -> VMResult<()> {
    // Compute hash of deployed bytecode
    let mut hasher = Sha256::new();
    for module in modules {
        let bytecode = module.serialize();
        hasher.update(&bytecode);
    }
    let actual_digest = format!("{:X}", hasher.finalize());
    
    if actual_digest != expected_digest {
        return Err(Self::metadata_validation_error(
            "bytecode does not match source_digest"
        ));
    }
    Ok(())
}
```

## Proof of Concept

```move
// File: malicious_package/sources/token.move
module publisher::token {
    use std::signer;
    
    public entry fun transfer(from: &signer, to: address, amount: u64) {
        // Legitimate source: actually transfers tokens
        transfer_internal(from, to, amount);
    }
    
    fun transfer_internal(_from: &signer, _to: address, _amount: u64) {
        // Implementation
    }
}

// ATTACK STEPS:
// 1. Compile package normally:
//    $ aptos move compile
//    This produces source_digest = "ABC123..." from sources
//
// 2. Modify compiled bytecode in build/package/bytecode_modules/token.mv:
//    - Change transfer function to redirect funds to attacker address
//    - Or insert backdoor logic
//
// 3. Publish with original PackageMetadata but modified bytecode:
//    $ aptos move publish
//    
// 4. On-chain PackageRegistry now shows:
//    - source_digest: "ABC123..." (looks legitimate)
//    - bytecode: modified/malicious version
//
// 5. Users checking source_digest see "ABC123" and trust the package
//    But deployed bytecode steals funds when transfer() is called
//
// NO VALIDATION occurs at any stage to detect the mismatch
```

**Rust Reproduction:**
```rust
// Demonstration that source_digest is never validated
#[test]
fn test_source_digest_tampering() {
    let mut package_metadata = extract_legitimate_metadata();
    let tampered_bytecode = modify_bytecode(&original_bytecode);
    
    // This succeeds despite source_digest mismatch
    let result = publish_package(
        &owner,
        package_metadata,  // Has source_digest from original sources
        tampered_bytecode  // Modified bytecode
    );
    
    assert!(result.is_ok()); // Publishes successfully!
    // source_digest stored on-chain does not match deployed bytecode
}
```

### Citations

**File:** aptos-move/framework/src/built_package.rs (L516-522)
```rust
    pub fn extract_metadata(&self) -> anyhow::Result<PackageMetadata> {
        let source_digest = self
            .package
            .compiled_package_info
            .source_digest
            .map(|s| s.to_string())
            .unwrap_or_default();
```

**File:** third_party/move/tools/move-package/src/resolution/digest.rs (L11-51)
```rust
pub fn compute_digest(paths: &[PathBuf]) -> Result<PackageDigest> {
    let mut hashed_files = Vec::new();
    let mut hash = |path: &Path| {
        let contents = std::fs::read(path)?;
        hashed_files.push(format!("{:X}", Sha256::digest(&contents)));
        Ok(())
    };
    let mut maybe_hash_file = |path: &Path| -> Result<()> {
        match path.extension() {
            Some(x) if MOVE_EXTENSION == x => hash(path),
            _ if path.ends_with(SourcePackageLayout::Manifest.path()) => hash(path),
            _ => Ok(()),
        }
    };

    for path in paths {
        if path.is_file() {
            maybe_hash_file(path)?;
        } else {
            for entry in walkdir::WalkDir::new(path)
                .follow_links(true)
                .into_iter()
                .filter_map(|e| e.ok())
            {
                if entry.file_type().is_file() {
                    maybe_hash_file(entry.path())?
                }
            }
        }
    }

    // Sort the hashed files to ensure that the order of files is always stable
    hashed_files.sort();

    let mut hasher = Sha256::new();
    for file_hash in hashed_files.into_iter() {
        hasher.update(file_hash.as_bytes());
    }

    Ok(PackageDigest::from(format!("{:X}", hasher.finalize())))
}
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L168-228)
```text
    public fun publish_package(owner: &signer, pack: PackageMetadata, code: vector<vector<u8>>) acquires PackageRegistry {
        check_code_publishing_permission(owner);
        // Disallow incompatible upgrade mode. Governance can decide later if this should be reconsidered.
        assert!(
            pack.upgrade_policy.policy > upgrade_policy_arbitrary().policy,
            error::invalid_argument(EINCOMPATIBLE_POLICY_DISABLED),
        );

        let addr = signer::address_of(owner);
        if (!exists<PackageRegistry>(addr)) {
            move_to(owner, PackageRegistry { packages: vector::empty() })
        };

        // Checks for valid dependencies to other packages
        let allowed_deps = check_dependencies(addr, &pack);

        // Check package against conflicts
        // To avoid prover compiler error on spec
        // the package need to be an immutable variable
        let module_names = get_module_names(&pack);
        let package_immutable = &borrow_global<PackageRegistry>(addr).packages;
        let len = vector::length(package_immutable);
        let index = len;
        let upgrade_number = 0;
        vector::enumerate_ref(package_immutable
        , |i, old| {
            let old: &PackageMetadata = old;
            if (old.name == pack.name) {
                upgrade_number = old.upgrade_number + 1;
                check_upgradability(old, &pack, &module_names);
                index = i;
            } else {
                check_coexistence(old, &module_names)
            };
        });

        // Assign the upgrade counter.
        pack.upgrade_number = upgrade_number;

        let packages = &mut borrow_global_mut<PackageRegistry>(addr).packages;
        // Update registry
        let policy = pack.upgrade_policy;
        if (index < len) {
            *vector::borrow_mut(packages, index) = pack
        } else {
            vector::push_back(packages, pack)
        };

        event::emit(PublishPackage {
            code_address: addr,
            is_upgrade: upgrade_number > 0
        });

        // Request publish
        if (features::code_dependency_check_enabled())
            request_publish_with_allowed_deps(addr, module_names, allowed_deps, code, policy.policy)
        else
        // The new `request_publish_with_allowed_deps` has not yet rolled out, so call downwards
        // compatible code.
            request_publish(addr, module_names, code, policy.policy)
    }
```

**File:** aptos-move/framework/src/natives/code.rs (L284-362)
```rust
fn native_request_publish(
    context: &mut SafeNativeContext,
    _ty_args: &[Type],
    mut args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    debug_assert!(matches!(args.len(), 4 | 5));
    let with_allowed_deps = args.len() == 5;

    context.charge(CODE_REQUEST_PUBLISH_BASE)?;

    let policy = safely_pop_arg!(args, u8);
    let mut code = vec![];
    for module in safely_pop_arg!(args, Vec<Value>) {
        let module_code = module.value_as::<Vec<u8>>()?;

        context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(module_code.len() as u64))?;
        code.push(module_code);
    }

    let allowed_deps = if with_allowed_deps {
        let mut allowed_deps: BTreeMap<AccountAddress, BTreeSet<String>> = BTreeMap::new();

        for dep in safely_pop_arg!(args, Vec<Value>) {
            let (account, module_name) = unpack_allowed_dep(dep)?;

            let entry = allowed_deps.entry(account);

            if let Entry::Vacant(_) = &entry {
                // TODO: Is the 32 here supposed to indicate the length of an account address in bytes?
                context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(32))?;
            }

            context
                .charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(module_name.len() as u64))?;
            entry.or_default().insert(module_name);
        }

        Some(allowed_deps)
    } else {
        None
    };

    let mut expected_modules = BTreeSet::new();
    for name in safely_pop_arg!(args, Vec<Value>) {
        let str = get_move_string(name)?;

        // TODO(Gas): fine tune the gas formula
        context.charge(CODE_REQUEST_PUBLISH_PER_BYTE * NumBytes::new(str.len() as u64))?;
        expected_modules.insert(str);
    }

    let destination = safely_pop_arg!(args, AccountAddress);

    // Add own modules to allowed deps
    let allowed_deps = allowed_deps.map(|mut allowed| {
        allowed
            .entry(destination)
            .or_default()
            .extend(expected_modules.clone());
        allowed
    });

    let code_context = context.extensions_mut().get_mut::<NativeCodeContext>();
    if code_context.requested_module_bundle.is_some() || !code_context.enabled {
        // Can't request second time or if publish requests are not allowed.
        return Err(SafeNativeError::Abort {
            abort_code: EALREADY_REQUESTED,
        });
    }
    code_context.requested_module_bundle = Some(PublishRequest {
        destination,
        bundle: ModuleBundle::new(code),
        expected_modules,
        allowed_deps,
        check_compat: policy != ARBITRARY_POLICY,
    });

    Ok(smallvec![])
}
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L1679-1738)
```rust
    /// Validate a publish request.
    fn validate_publish_request(
        &self,
        module_storage: &impl AptosModuleStorage,
        traversal_context: &mut TraversalContext,
        gas_meter: &mut impl GasMeter,
        modules: &[CompiledModule],
        mut expected_modules: BTreeSet<String>,
        allowed_deps: Option<BTreeMap<AccountAddress, BTreeSet<String>>>,
    ) -> VMResult<()> {
        self.reject_unstable_bytecode(modules)?;
        native_validation::validate_module_natives(modules)?;

        for m in modules {
            if !expected_modules.remove(m.self_id().name().as_str()) {
                return Err(Self::metadata_validation_error(&format!(
                    "unregistered module: '{}'",
                    m.self_id().name()
                )));
            }
            if let Some(allowed) = &allowed_deps {
                for dep in m.immediate_dependencies() {
                    if !allowed
                        .get(dep.address())
                        .map(|modules| {
                            modules.contains("") || modules.contains(dep.name().as_str())
                        })
                        .unwrap_or(false)
                    {
                        return Err(Self::metadata_validation_error(&format!(
                            "unregistered dependency: '{}'",
                            dep
                        )));
                    }
                }
            }
            verify_module_metadata_for_module_publishing(m, self.features())
                .map_err(|err| Self::metadata_validation_error(&err.to_string()))?;
        }

        resource_groups::validate_resource_groups(
            self.features(),
            module_storage,
            traversal_context,
            gas_meter,
            modules,
        )?;
        event_validation::validate_module_events(
            self.features(),
            module_storage,
            traversal_context,
            modules,
        )?;

        if !expected_modules.is_empty() {
            return Err(Self::metadata_validation_error(
                "not all registered modules published",
            ));
        }
        Ok(())
```

**File:** types/src/vm/module_metadata.rs (L445-517)
```rust
    if features.is_enabled(FeatureFlag::SAFER_METADATA) {
        check_module_complexity(module)?;
    }

    if features.are_resource_groups_enabled() {
        check_metadata_format(module)?;
    }
    let metadata = if let Some(metadata) = get_metadata_from_compiled_code(module) {
        metadata
    } else {
        return Ok(());
    };

    let functions = module
        .function_defs
        .iter()
        .map(|func_def| {
            let func_handle = module.function_handle_at(func_def.function);
            let name = module.identifier_at(func_handle.name);
            (name, (func_handle, func_def))
        })
        .collect::<BTreeMap<_, _>>();

    for (fun, attrs) in &metadata.fun_attributes {
        for attr in attrs {
            if attr.is_view_function() {
                is_valid_view_function(module, &functions, fun)?;
            } else if attr.is_randomness() {
                is_valid_unbiasable_function(&functions, fun)?;
            } else {
                return Err(AttributeValidationError {
                    key: fun.clone(),
                    attribute: attr.kind,
                }
                .into());
            }
        }
    }

    let structs = module
        .struct_defs
        .iter()
        .map(|struct_def| {
            let struct_handle = module.struct_handle_at(struct_def.struct_handle);
            let name = module.identifier_at(struct_handle.name);
            (name, (struct_handle, struct_def))
        })
        .collect::<BTreeMap<_, _>>();

    for (struct_, attrs) in &metadata.struct_attributes {
        for attr in attrs {
            if features.are_resource_groups_enabled() {
                if attr.is_resource_group() && attr.get_resource_group().is_some() {
                    is_valid_resource_group(&structs, struct_)?;
                    continue;
                } else if attr.is_resource_group_member()
                    && attr.get_resource_group_member().is_some()
                {
                    is_valid_resource_group_member(&structs, struct_)?;
                    continue;
                }
            }
            if features.is_module_event_enabled() && attr.is_event() {
                continue;
            }
            return Err(AttributeValidationError {
                key: struct_.clone(),
                attribute: attr.kind,
            }
            .into());
        }
    }
    Ok(())
```
