# Audit Report

## Title
EventStorePruner Integer Underflow on Database Truncation Causing Node Initialization Failure

## Summary
The `EventStorePruner` lacks bounds checking when catching up pruning progress after database truncation, leading to integer underflow that prevents node initialization. When the database is rolled back to an earlier version but `EventPrunerProgress` metadata is not reset, the pruner attempts to prune backwards, causing arithmetic underflow and initialization failure.

## Finding Description

The vulnerability occurs in the interaction between database truncation and pruner initialization:

**Step 1: Database Truncation Does Not Reset Pruner Progress**

When the database is truncated via `truncate_ledger_db`, the function updates `LedgerCommitProgress` but does NOT reset sub-pruner progress metadata keys like `EventPrunerProgress`. [1](#0-0) 

**Step 2: EventStorePruner Initialization Without Bounds Check**

When the node restarts, `EventStorePruner::new()` retrieves the old (stale) `EventPrunerProgress` value via `get_or_initialize_subpruner_progress`, then unconditionally calls `prune(progress, metadata_progress)` where `progress > metadata_progress`. [2](#0-1) 

**Step 3: Integer Underflow in prune_event_indices**

The `prune` method calls `prune_event_indices(current_progress, target_version, ...)` which calculates `(end - start) as usize`. When `end < start`, this causes integer underflow in production builds (wraps to ~`u64::MAX`). [3](#0-2) 

**Step 4: Initialization Failure**

The underflow causes `get_events_by_version_iter` to be called with an enormous `num_versions` parameter, triggering an overflow check that returns an error, preventing the node from initializing. [4](#0-3) 

**Comparison: TransactionPruner Has the Guard**

Notably, `TransactionPruner` includes an explicit bounds check that EventStorePruner lacks. [5](#0-4) 

## Impact Explanation

**High Severity** - This qualifies as "Validator node slowdowns" and "API crashes" under the High Severity category.

The vulnerability causes deterministic node initialization failure after database truncation when `EventPrunerProgress > truncation_target_version`. This affects:

- **Node Availability**: The affected node cannot restart without manual intervention
- **Recovery Operations**: Standard database recovery procedures (truncation, rollback) become unreliable
- **Operational Impact**: Requires manual metadata key reset by operators with database access

While this does not affect consensus safety or network-wide liveness (other nodes continue operating), it creates operational fragility and recovery complications for individual validator nodes.

## Likelihood Explanation

**Medium-High Likelihood**

Database truncation is triggered by:
1. Manual truncation via `aptos-db-tool truncate` command [6](#0-5) 
2. Automatic crash recovery via `StateStore::sync_commit_progress` when database components are out of sync [7](#0-6) 

The bug triggers whenever:
- Database is truncated to version X
- EventPrunerProgress metadata shows version Y where Y > X
- This is guaranteed to occur if the node was pruning normally before truncation

## Recommendation

Add a bounds check in `EventStorePruner::prune()` or `EventStorePruner::new()` to handle backwards progress gracefully:

```rust
// In EventStorePruner::new(), before calling prune:
if progress > metadata_progress {
    // Database was truncated, reset our progress
    info!(
        old_progress = progress,
        new_progress = metadata_progress,
        "EventPrunerProgress moved backwards, resetting to metadata progress"
    );
    ledger_db.event_db().write_pruner_progress(metadata_progress)?;
    return Ok(EventStorePruner {
        ledger_db,
        internal_indexer_db,
    });
}
myself.prune(progress, metadata_progress)?;
```

Alternatively, add a bounds check in the `prune` method itself:

```rust
fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
    if current_progress >= target_version {
        return Ok(()); // Nothing to prune
    }
    // ... rest of implementation
}
```

## Proof of Concept

```rust
#[test]
fn test_event_store_pruner_backwards_progress() {
    use tempfile::TempDir;
    use aptos_config::config::RocksdbConfigs;
    
    let tmpdir = TempDir::new().unwrap();
    
    // Create database and commit some transactions
    let db = AptosDB::new_for_test(&tmpdir);
    let version = 1000u64;
    // ... commit transactions up to version 1000 ...
    
    // Simulate EventPrunerProgress being set to 1000
    db.ledger_db().event_db().write_pruner_progress(1000).unwrap();
    
    drop(db);
    
    // Truncate database to version 500
    let (ledger_db, _, _, _) = AptosDB::open_dbs(
        &StorageDirPaths::from_path(&tmpdir),
        RocksdbConfigs::default(),
        None, None, false, 0, false
    ).unwrap();
    
    truncate_ledger_db(Arc::new(ledger_db.clone()), 500).unwrap();
    
    drop(ledger_db);
    
    // Try to reinitialize - this should fail with integer underflow
    let (ledger_db, _, _, _) = AptosDB::open_dbs(
        &StorageDirPaths::from_path(&tmpdir),
        RocksdbConfigs::default(),
        None, None, false, 0, false
    ).unwrap();
    
    let ledger_db = Arc::new(ledger_db);
    
    // This will panic or return error due to integer underflow
    let result = EventStorePruner::new(
        ledger_db,
        500, // metadata_progress after truncation
        None
    );
    
    assert!(result.is_err(), "EventStorePruner should fail with backwards progress");
}
```

## Notes

This vulnerability specifically affects `EventStorePruner` due to its use of arithmetic (`(end - start) as usize`) before iteration. Other sub-pruners like `TransactionInfoPruner` and `WriteSetPruner` use Rust range iterators (`begin..end`) which safely handle backwards ranges by producing empty iterators. The `TransactionPruner` explicitly includes an `ensure!` guard against this exact scenario, indicating the pattern was recognized elsewhere but not consistently applied.

### Citations

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L353-358)
```rust
    let mut progress_batch = SchemaBatch::new();
    progress_batch.put::<DbMetadataSchema>(
        &DbMetadataKey::LedgerCommitProgress,
        &DbMetadataValue::Version(start_version - 1),
    )?;
    ledger_db.metadata_db().write_schemas(progress_batch)?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L90-106)
```rust
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L100-114)
```rust
    pub(crate) fn get_events_by_version_iter(
        &self,
        start_version: Version,
        num_versions: usize,
    ) -> Result<EventsByVersionIter<'_>> {
        let mut iter = self.db.iter::<EventSchema>()?;
        iter.seek(&start_version)?;

        Ok(EventsByVersionIter::new(
            iter,
            start_version,
            start_version.checked_add(num_versions as u64).ok_or(
                AptosDbError::TooManyRequested(num_versions as u64, Version::MAX),
            )?,
        ))
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L192-202)
```rust
    pub(crate) fn prune_event_indices(
        &self,
        start: Version,
        end: Version,
        mut indices_batch: Option<&mut SchemaBatch>,
    ) -> Result<Vec<usize>> {
        let mut ret = Vec::new();

        let mut current_version = start;

        for events in self.get_events_by_version_iter(start, (end - start) as usize)? {
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L106-111)
```rust
    fn get_pruning_candidate_transactions(
        &self,
        start: Version,
        end: Version,
    ) -> Result<Vec<(Version, Transaction)>> {
        ensure!(end >= start, "{} must be >= {}", end, start);
```

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L137-142)
```rust
        StateStore::sync_commit_progress(
            Arc::clone(&ledger_db),
            Arc::clone(&state_kv_db),
            Arc::clone(&state_merkle_db),
            /*crash_if_difference_is_too_large=*/ false,
        );
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-449)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```
