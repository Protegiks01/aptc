# Audit Report

## Title
Race Condition in Hot State LRU Commit Causes Non-Atomic List Updates Visible to Concurrent Readers

## Summary
The hot state LRU doubly-linked list update operations are not atomic from the perspective of concurrent reader threads. The background Committer thread sequentially updates DashMap entries without synchronization, allowing executor threads to observe partially committed states with broken prev/next pointer chains, leading to validator node panics.

## Finding Description

The hot state management system uses a doubly-linked LRU list to track entry age for eviction. When entries are removed or reordered, multiple related StateSlot entries must be updated atomically to maintain list consistency. However, the current implementation violates this atomicity requirement.

**Architecture Flow:** [1](#0-0) 

The Committer runs in a background thread, processing state commits asynchronously. When committing, it updates the DashMap entries sequentially: [2](#0-1) 

The critical flaw is at lines 242-261 where the Committer iterates through delta entries and updates them one-by-one in the DashMap. The `committed` mutex is **not held** during these updates—it's only locked before (line 242) to create the delta and after (line 197) to update the metadata.

Meanwhile, executor threads can call `get_committed()` which clones the State metadata while holding the lock, but returns an Arc to the **same** HotStateBase being modified: [3](#0-2) 

Executor threads then create HotStateLRU instances that read from this shared HotStateBase via the HotStateView trait: [4](#0-3) 

**Race Condition Scenario:**

Consider hot state shard 0 with LRU list: A ↔ B ↔ C

1. New state evicts B, resulting in: A ↔ C (B removed)
2. Delta contains: B (cold/removed), A (A.next=C), C (C.prev=A)
3. Committer begins processing delta in HashMap iteration order
4. Committer removes B from DashMap: `self.base.shards[shard_id].remove(&B)`
5. **[RACE WINDOW]** Executor thread calls `get_committed()`
6. Executor gets old State metadata with old head/tail
7. Executor's HotStateLRU calls `get_slot()` which reads from DashMap:
   - `get_slot(C)` returns C with **C.prev=B** (not yet updated)
   - `get_slot(B)` returns **None** (already removed)
   - `get_slot(A)` may return A with **A.next=C** (updated) or old A
8. Committer continues: updates A, updates C
9. Committer commits new metadata

During step 7, if the HotStateLRU's `delete()` method processes an entry that references the removed B: [5](#0-4) 

At lines 120-122 or 132-134, if prev_key or next_key points to B (the removed entry), calling `expect_hot_slot()` will invoke: [6](#0-5) 

This **panics** because `get_slot(B)` returns None, causing `expect("Given key is expected to exist.")` to fail.

**Broken Invariant:**
This violates Critical Invariant #4: "State Consistency: State transitions must be atomic and verifiable via Merkle proofs." Concurrent readers observe non-atomic intermediate states where the doubly-linked list integrity is temporarily broken.

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria for the following reasons:

1. **Validator Node Crashes**: When the race condition triggers, the validator node panics with `expect()` failure, causing immediate process termination. This results in:
   - Loss of liveness for affected validators
   - Reduced network capacity during consensus
   - Potential consensus delays if multiple validators crash simultaneously

2. **Unpredictable Behavior**: Beyond panics, inconsistent LRU state could cause:
   - Incorrect eviction decisions (wrong entries evicted)
   - Hot state metadata corruption (num_items mismatch)
   - Potential Merkle tree inconsistencies if hot state affects state root calculation

3. **Production Impact**: While this doesn't cause fund loss or permanent state corruption (validator can restart), repeated crashes degrade network performance and validator reputation.

This meets High Severity criteria: "Validator node slowdowns" and "API crashes" with potential for "Significant protocol violations" if the inconsistency propagates to other subsystems.

## Likelihood Explanation

**Likelihood: Medium to High**

The race window is small (microseconds to milliseconds during DashMap update), but several factors increase exploitability:

1. **Frequent Occurrence**: Hot state commits happen continuously during block execution. Every state update with evictions creates opportunity for the race.

2. **Natural Triggering**: Any workload causing high hot state churn (many state key accesses) will naturally trigger frequent evictions and commits, increasing race exposure.

3. **No Attacker Requirement**: This is a pure implementation bug that can trigger during normal operation without malicious input. Validators are continuously at risk.

4. **Multi-Shard Amplification**: With 16 shards processed in parallel, the probability of hitting the race across any shard increases.

5. **Production Conditions**: High-throughput validators processing many transactions are more likely to experience this due to increased parallel execution and commit frequency.

While triggering requires precise timing, the continuous operation of validators and high transaction volumes make this a realistic production issue rather than a theoretical concern.

## Recommendation

**Immediate Fix**: Extend the `committed` lock scope to cover all DashMap updates, ensuring atomic visibility of complete state transitions.

**Modified Committer implementation:**

```rust
fn commit(&mut self, to_commit: &State) {
    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["hot_state_commit"]);
    
    let mut n_insert = 0;
    let mut n_update = 0;
    let mut n_evict = 0;

    // Lock committed for entire update to prevent concurrent reads of partial state
    let mut committed_guard = self.committed.lock();
    let delta = to_commit.make_delta(&committed_guard);
    
    for shard_id in 0..NUM_STATE_SHARDS {
        for (key, slot) in delta.shards[shard_id].iter() {
            if slot.is_hot() {
                let key_size = key.size();
                self.total_key_bytes += key_size;
                self.total_value_bytes += slot.size();
                if let Some(old_slot) = self.base.shards[shard_id].insert(key, slot) {
                    self.total_key_bytes -= key_size;
                    self.total_value_bytes -= old_slot.size();
                    n_update += 1;
                } else {
                    n_insert += 1;
                }
            } else if let Some((key, old_slot)) = self.base.shards[shard_id].remove(&key) {
                self.total_key_bytes -= key.size();
                self.total_value_bytes -= old_slot.size();
                n_evict += 1;
            }
        }
        self.heads[shard_id] = to_commit.latest_hot_key(shard_id);
        self.tails[shard_id] = to_commit.oldest_hot_key(shard_id);
        
        debug_assert!(self.validate_lru(shard_id).is_ok());
    }
    
    // Update committed State while still holding lock
    *committed_guard = to_commit.clone();
    // Lock released here
    
    COUNTER.inc_with_by(&["hot_state_insert"], n_insert);
    COUNTER.inc_with_by(&["hot_state_update"], n_update);
    COUNTER.inc_with_by(&["hot_state_evict"], n_evict);
}
```

**Alternative Fix**: Use a double-buffering approach with atomic pointer swap to publish complete states atomically, though this is more complex.

## Proof of Concept

```rust
// Reproducing race condition requires multi-threading test
// This demonstrates the vulnerability pattern

#[cfg(test)]
mod race_condition_test {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    #[test]
    #[should_panic(expected = "Given key is expected to exist")]
    fn test_concurrent_commit_and_read_race() {
        // Setup: Create HotState with entries A ↔ B ↔ C
        let config = HotStateConfig { max_items_per_shard: 10, ..Default::default() };
        let mut state = State::new_empty(config);
        
        // Insert A, B, C into shard 0 forming LRU chain
        let key_a = StateKey::new_with_shard(0, b"key_a");
        let key_b = StateKey::new_with_shard(0, b"key_b");
        let key_c = StateKey::new_with_shard(0, b"key_c");
        
        // ... setup code to create state with A ↔ B ↔ C ...
        
        let hot_state = Arc::new(HotState::new(state, config));
        let barrier = Arc::new(Barrier::new(2));
        
        // Thread 1: Committer - evicts B to create A ↔ C
        let hot_state_writer = Arc::clone(&hot_state);
        let barrier_writer = Arc::clone(&barrier);
        let writer = thread::spawn(move || {
            barrier_writer.wait();
            // Create new state that evicts B
            let new_state = create_state_without_b();
            hot_state_writer.enqueue_commit(new_state);
            // Commit happens in background thread
        });
        
        // Thread 2: Reader - tries to use hot state during commit
        let hot_state_reader = Arc::clone(&hot_state);
        let barrier_reader = Arc::clone(&barrier);
        let reader = thread::spawn(move || {
            barrier_reader.wait();
            // Small delay to hit race window
            thread::sleep(Duration::from_micros(10));
            
            let (base, state) = hot_state_reader.get_committed();
            let overlay = LayeredMap::new();
            let mut lru = HotStateLRU::new(
                NonZeroUsize::new(10).unwrap(),
                base,
                &overlay,
                state.latest_hot_key(0),
                state.oldest_hot_key(0),
                state.num_hot_items(0),
            );
            
            // Try to delete C, which has C.prev=B
            // But B might be removed from DashMap already
            // This should panic when expect_hot_slot(B) fails
            lru.delete(&key_c);
        });
        
        writer.join().unwrap();
        reader.join().unwrap(); // Should panic here
    }
}
```

**Notes:**
- The actual PoC requires proper test infrastructure to reliably trigger the race
- In production, this manifests as sporadic validator panics during high-throughput execution
- The vulnerability exists whenever the Committer processes deltas while executors read from the same DashMap
- The overlay mechanism provides partial protection, but not complete isolation when overlay is empty or incomplete

### Citations

**File:** storage/aptosdb/src/state_store/hot_state.rs (L100-105)
```rust
impl HotStateView for HotStateBase<StateKey, StateSlot> {
    fn get_state_slot(&self, state_key: &StateKey) -> Option<StateSlot> {
        let shard_id = state_key.get_shard_id();
        self.get_from_shard(shard_id, state_key).map(|v| v.clone())
    }
}
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L131-136)
```rust
    pub fn get_committed(&self) -> (Arc<dyn HotStateView>, State) {
        let state = self.committed.lock().clone();
        let base = self.base.clone();

        (base, state)
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L172-178)
```rust
impl Committer {
    fn spawn(base: Arc<HotStateBase>, committed: Arc<Mutex<State>>) -> SyncSender<State> {
        let (tx, rx) = std::sync::mpsc::sync_channel(MAX_HOT_STATE_COMMIT_BACKLOG);
        std::thread::spawn(move || Self::new(base, committed, rx).run());

        tx
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L235-275)
```rust
    fn commit(&mut self, to_commit: &State) {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["hot_state_commit"]);

        let mut n_insert = 0;
        let mut n_update = 0;
        let mut n_evict = 0;

        let delta = to_commit.make_delta(&self.committed.lock());
        for shard_id in 0..NUM_STATE_SHARDS {
            for (key, slot) in delta.shards[shard_id].iter() {
                if slot.is_hot() {
                    let key_size = key.size();
                    self.total_key_bytes += key_size;
                    self.total_value_bytes += slot.size();
                    if let Some(old_slot) = self.base.shards[shard_id].insert(key, slot) {
                        self.total_key_bytes -= key_size;
                        self.total_value_bytes -= old_slot.size();
                        n_update += 1;
                    } else {
                        n_insert += 1;
                    }
                } else if let Some((key, old_slot)) = self.base.shards[shard_id].remove(&key) {
                    self.total_key_bytes -= key.size();
                    self.total_value_bytes -= old_slot.size();
                    n_evict += 1;
                }
            }
            self.heads[shard_id] = to_commit.latest_hot_key(shard_id);
            self.tails[shard_id] = to_commit.oldest_hot_key(shard_id);
            assert_eq!(
                self.base.shards[shard_id].len(),
                to_commit.num_hot_items(shard_id)
            );

            debug_assert!(self.validate_lru(shard_id).is_ok());
        }

        COUNTER.inc_with_by(&["hot_state_insert"], n_insert);
        COUNTER.inc_with_by(&["hot_state_update"], n_update);
        COUNTER.inc_with_by(&["hot_state_evict"], n_evict);
    }
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L109-143)
```rust
    fn delete(&mut self, key: &StateKey) -> Option<StateSlot> {
        // Fetch the slot corresponding to the given key. Note that `self.pending` and
        // `self.overlay` may contain cold slots, like the ones recently evicted, and we need to
        // ignore them.
        let old_slot = match self.get_slot(key) {
            Some(slot) if slot.is_hot() => slot,
            _ => return None,
        };

        match old_slot.prev() {
            Some(prev_key) => {
                let mut prev_slot = self.expect_hot_slot(prev_key);
                prev_slot.set_next(old_slot.next().cloned());
                self.pending.insert(prev_key.clone(), prev_slot);
            },
            None => {
                // There is no newer entry. The current key was the head.
                self.head = old_slot.next().cloned();
            },
        }

        match old_slot.next() {
            Some(next_key) => {
                let mut next_slot = self.expect_hot_slot(next_key);
                next_slot.set_prev(old_slot.prev().cloned());
                self.pending.insert(next_key.clone(), next_slot);
            },
            None => {
                // There is no older entry. The current key was the tail.
                self.tail = old_slot.prev().cloned();
            },
        }

        Some(old_slot)
    }
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L157-161)
```rust
    fn expect_hot_slot(&self, key: &StateKey) -> StateSlot {
        let slot = self.get_slot(key).expect("Given key is expected to exist.");
        assert!(slot.is_hot(), "Given key is expected to be hot.");
        slot
    }
```
