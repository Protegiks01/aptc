# Audit Report

## Title
Time-Of-Check-Time-Of-Use Race Condition in State KV Pruner Target Version Management

## Summary
A TOCTOU race condition exists in `PrunerWorker::set_target_db_version()` that allows concurrent calls to violate the monotonic increase guarantee of the pruner's target version. This can cause the pruner to skip version ranges that should be pruned according to the configured pruning policy, leading to storage bloat and potential disk exhaustion.

## Finding Description

The vulnerability lies in the `set_target_db_version()` method in `storage/aptosdb/src/pruner/pruner_worker.rs`. [1](#0-0) 

This function implements a check-then-act pattern without proper synchronization:
1. **CHECK**: Line 94 reads `target_version()` to verify the new target is greater
2. **ACT**: Line 95 calls `set_target_version()` to update the target

**Race Scenario:**

When two threads concurrently call `set_target_db_version()` with different values:

1. **Thread 1**: `set_target_db_version(500)`
   - Reads `target_version()` = 100
   - Check passes: 500 > 100 ✓
   - *Context switch occurs*

2. **Thread 2**: `set_target_db_version(1500)`
   - Reads `target_version()` = 100
   - Check passes: 1500 > 100 ✓
   - Calls `set_target_version(1500)` → target = 1500

3. **Thread 1** resumes:
   - Calls `set_target_version(500)` → target = 500 (overwrites 1500!)

**Result**: The target version decreased from 1500 to 500, violating the monotonic increase invariant.

**Propagation to Pruner:**

The pruner's `prune()` method loads the target version once at the beginning: [2](#0-1) 

If the pruner's progress is between 500-1500 after the race:
- `progress >= target_version` (e.g., 1000 >= 500)
- The while loop condition `progress < target_version` is false
- Pruning stops prematurely
- Versions 501-1500 remain unpruned despite being outside the configured prune window

This occurs naturally when `StateKvPrunerManager::maybe_set_pruner_target_db_version()` is called concurrently as new blocks are committed: [3](#0-2) 

## Impact Explanation

**Severity: Medium** - State inconsistencies requiring intervention

Per Aptos bug bounty criteria, this qualifies as Medium severity because:

1. **State Inconsistency**: The pruner's internal state becomes inconsistent with the configured pruning policy, causing version ranges to remain unpruned when they should be deleted.

2. **Storage Bloat**: Unpruned state accumulates over time, consuming disk space beyond the intended retention window. In high-throughput scenarios, this can lead to significant storage growth.

3. **Operational Impact**: If left unchecked, disk exhaustion can cause:
   - Node crashes when storage is full
   - Inability to accept new blocks
   - Degraded query performance due to larger state database
   - Manual intervention required to clear disk space and reset pruner state

4. **Node Availability**: Multiple affected nodes could impact network availability if validators run out of disk space and become unable to participate in consensus.

However, this is **not Critical or High severity** because:
- No consensus safety violation occurs
- No funds are lost or stolen
- No immediate protocol failure
- Impact is gradual and recoverable through operational intervention

## Likelihood Explanation

**Likelihood: High** during normal operation

This race condition has high probability of occurrence because:

1. **Natural Concurrency**: The `maybe_set_pruner_target_db_version()` method is called from the storage commit path as new blocks are processed. In a high-throughput blockchain with blocks arriving rapidly, concurrent invocations are common.

2. **No External Trigger Required**: The race happens organically during normal blockchain operation without requiring attacker manipulation. Any workload with concurrent block commits can trigger it.

3. **Wide Race Window**: The race window spans the entire duration of reading and comparing the target version, which is not negligible given atomic operations and potential thread scheduling delays.

4. **Persistent Effect**: Once the race occurs and decreases the target, the pruner remains stuck until the target is naturally increased beyond the current progress through subsequent block commits.

However, **attacker control is limited**:
- An external attacker cannot directly call these functions
- The timing depends on internal block processing, not external inputs
- No direct exploit vector exists for malicious actors

The vulnerability represents a **code quality and robustness issue** rather than a directly exploitable security flaw.

## Recommendation

Replace the check-then-act pattern with an atomic compare-and-set operation:

```rust
pub fn set_target_db_version(&self, target_db_version: Version) {
    // Atomically update only if new target is greater
    self.inner.pruner.target_version()
        .fetch_max(target_db_version, Ordering::SeqCst);
}
```

This uses `AtomicU64::fetch_max()` which atomically ensures the target version only increases, eliminating the TOCTOU race condition.

Alternatively, if fetch_max is not available or suitable:

```rust
pub fn set_target_db_version(&self, target_db_version: Version) {
    let mut current = self.inner.pruner.target_version();
    while target_db_version > current {
        match self.inner.pruner.target_version_atomic()
            .compare_exchange(
                current,
                target_db_version,
                Ordering::SeqCst,
                Ordering::SeqCst
            ) {
            Ok(_) => break,
            Err(actual) => current = actual,
        }
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use std::thread;
    
    #[test]
    fn test_toctou_race_in_set_target_version() {
        // Create a mock pruner with initial target = 100
        let pruner = create_test_pruner_with_target(100);
        let worker = Arc::new(PrunerWorker::new(pruner, 1000, "test"));
        
        // Spawn two threads that concurrently set different targets
        let worker1 = Arc::clone(&worker);
        let worker2 = Arc::clone(&worker);
        
        let handle1 = thread::spawn(move || {
            // Thread 1 tries to set target to 500
            for _ in 0..1000 {
                worker1.set_target_db_version(500);
            }
        });
        
        let handle2 = thread::spawn(move || {
            // Thread 2 tries to set target to 1500
            for _ in 0..1000 {
                worker2.set_target_db_version(1500);
            }
        });
        
        handle1.join().unwrap();
        handle2.join().unwrap();
        
        // After the race, target should be 1500 (max of 500 and 1500)
        // But due to TOCTOU, it might be 500 (violating monotonic increase)
        let final_target = worker.inner.pruner.target_version();
        
        // This assertion will fail when the race occurs
        assert_eq!(
            final_target, 1500,
            "TOCTOU race allowed target to decrease from 1500 to {}",
            final_target
        );
    }
}
```

## Notes

While this vulnerability represents a genuine race condition that violates the intended monotonic increase invariant, it has limited practical exploitability:

1. **No Direct Attacker Control**: External attackers cannot directly trigger or manipulate the timing of this race condition. It occurs naturally during internal system operation.

2. **Gradual Impact**: The security impact is indirect and gradual (storage bloat over time), rather than immediate catastrophic failure.

3. **Operational Workaround**: Node operators can mitigate by monitoring disk usage and restarting nodes if pruner state becomes inconsistent.

The fix is straightforward using atomic operations that guarantee monotonic increase without race conditions. This issue is best classified as a **robustness bug** that should be fixed to prevent operational issues, though it does not represent a critical security vulnerability that enables direct attacks on the blockchain protocol.

### Citations

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L93-97)
```rust
    pub fn set_target_db_version(&self, target_db_version: Version) {
        if target_db_version > self.inner.pruner.target_version() {
            self.inner.pruner.set_target_version(target_db_version);
        }
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L49-56)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_pruner__prune"]);

        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_pruner_manager.rs (L128-142)
```rust
    fn set_pruner_target_db_version(&self, latest_version: Version) {
        assert!(self.pruner_worker.is_some());
        let min_readable_version = latest_version.saturating_sub(self.prune_window);
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["state_kv_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.pruner_worker
            .as_ref()
            .unwrap()
            .set_target_db_version(min_readable_version);
    }
```
