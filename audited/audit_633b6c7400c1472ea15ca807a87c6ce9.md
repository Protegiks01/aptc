# Audit Report

## Title
Peer Metadata Cache Inconsistency and Panic Due to Invalid Index Removal in Connection Event Broadcast

## Summary
The `remove_peer_metadata()` function in `network/framework/src/application/storage.rs` contains a critical partial failure vulnerability where a panic in the `broadcast()` function leaves the system in an inconsistent state. The peer is removed from the main metadata map but the cached version remains stale, and subscribers are only partially notified. Additionally, the `broadcast()` function has a latent bug where removing multiple closed subscribers causes an out-of-bounds panic due to improper use of `swap_remove()` with stale indices.

## Finding Description

The vulnerability exists in the interaction between `remove_peer_metadata()` and `broadcast()` functions: [1](#0-0) 

The critical issue is the order of operations:
1. Line 240: Peer is removed from the main `peers_and_metadata` HashMap via `entry.remove()`
2. Line 245: `broadcast()` is called to notify subscribers
3. Line 259: Cache is updated via `set_cached_peers_and_metadata()`

If `broadcast()` panics between steps 2 and 3, the cache is never updated, creating a persistent inconsistency.

The `broadcast()` function has a bug that can trigger this panic: [2](#0-1) 

When multiple subscribers have closed their channels, their indices are collected in `to_del` (lines 374-391), then `swap_remove()` is called on each index (line 393). However, `swap_remove()` changes the vector by swapping the last element into the removed position and shrinking the length. This invalidates all subsequent indices in `to_del`, causing an out-of-bounds panic.

**Example Scenario:**
- Subscribers: [Sub0, Sub1, Sub2, Sub3, Sub4] (length 5)
- Closed channels at indices: 1, 3, 4
- `to_del = [1, 3, 4]`
- After `swap_remove(1)`: [Sub0, Sub4, Sub2, Sub3] (length 4, indices shifted)
- After `swap_remove(3)`: [Sub0, Sub4, Sub2] (length 3)
- Calling `swap_remove(4)`: **PANIC - index 4 out of bounds for length 3**

The panic leaves the system in an inconsistent state:
- Main map: peer removed
- Cached map: peer still present (stale data)
- Write lock: poisoned (future lock attempts will panic)
- Subscribers: partially notified

Applications using the cached data see stale peer information. The consensus publisher specifically relies on this cache: [3](#0-2) 

The consensus publisher's garbage collection uses `get_connected_peers_and_metadata()`, which reads from the cache: [4](#0-3) 

With stale cache data, the publisher continues attempting to send consensus updates to disconnected peers, wasting resources and potentially causing consensus delays.

## Impact Explanation

This vulnerability meets **High Severity** criteria per the Aptos bug bounty program:

1. **Validator Node Slowdowns**: The consensus publisher wastes resources sending messages to disconnected peers that appear connected in the stale cache. This degrades node performance and consensus efficiency.

2. **State Inconsistencies**: The cached peer metadata diverges from actual state, violating the "State Consistency" invariant that state transitions must be atomic. Multiple network components (consensus, health checker, connectivity manager) rely on this cache.

3. **Lock Poisoning**: When the panic occurs, the `peers_and_metadata` RwLock becomes poisoned. The aptos_infallible implementation will panic on all future lock attempts: [5](#0-4) 

This causes cascading failures throughout the network layer.

4. **Partial Notification**: Subscribers receive inconsistent views - some get LostPeer notifications, others don't, leading to divergent understanding of network topology across components.

## Likelihood Explanation

**High Likelihood** - This vulnerability can be triggered during normal network operations:

1. Multiple applications subscribe to connection events (consensus publisher, health checker, connectivity manager, etc. as shown in the codebase search results).

2. Applications can close subscriptions during restarts, shutdowns, or crashes - common in distributed systems.

3. When 3+ subscriptions are closed and a peer subsequently disconnects, the bug is triggered.

4. Large validator networks with high peer churn make this scenario probable.

5. Once triggered, the inconsistent state persists until node restart, affecting all subsequent operations.

## Recommendation

Fix the `broadcast()` function to remove closed subscribers in reverse order or use a different removal strategy that doesn't invalidate indices:

```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    let mut to_del = vec![];
    for i in 0..listeners.len() {
        let dest = listeners.get_mut(i).unwrap();
        if let Err(err) = dest.try_send(event.clone()) {
            match err {
                TrySendError::Full(_) => {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(1)),
                        warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                    );
                },
                TrySendError::Closed(_) => {
                    to_del.push(i);
                },
            }
        }
    }
    // Remove in reverse order to avoid index invalidation
    for evict in to_del.into_iter().rev() {
        listeners.swap_remove(evict);
    }
}
```

Additionally, consider wrapping the `broadcast()` call in `remove_peer_metadata()` with panic catching or reordering operations to update the cache before broadcasting (though this has other trade-offs).

## Proof of Concept

```rust
#[tokio::test]
async fn test_broadcast_panic_on_multiple_closed_subscribers() {
    use std::panic;
    
    // Create the peers and metadata container
    let network_ids = vec![NetworkId::Validator];
    let peers_and_metadata = PeersAndMetadata::new(&network_ids);
    
    // Create 5 subscriptions
    let mut subs = vec![];
    for _ in 0..5 {
        subs.push(peers_and_metadata.subscribe());
    }
    
    // Close subscriptions at indices 1, 3, and 4
    subs[1].close();
    subs[3].close();
    subs[4].close();
    
    // Create and insert a peer
    let peer_id = PeerId::random();
    let peer_network_id = PeerNetworkId::new(NetworkId::Validator, peer_id);
    let connection = ConnectionMetadata::mock(peer_id);
    let connection_id = connection.connection_id;
    
    peers_and_metadata
        .insert_connection_metadata(peer_network_id, connection.clone())
        .unwrap();
    
    // Verify peer is in both maps
    let metadata_before = peers_and_metadata.get_metadata_for_peer(peer_network_id).unwrap();
    assert_eq!(metadata_before.connection_metadata.connection_id, connection_id);
    
    // Attempt to remove the peer - this should panic in broadcast()
    let result = panic::catch_unwind(panic::AssertUnwindSafe(|| {
        peers_and_metadata
            .remove_peer_metadata(peer_network_id, connection_id)
    }));
    
    assert!(result.is_err(), "Expected panic but operation succeeded");
    
    // Verify inconsistent state: peer removed from main map but cache still has it
    // Main map access will fail (lock poisoned or peer not found)
    // But cache should still show the peer
    let cached_peers = peers_and_metadata.get_connected_peers_and_metadata();
    
    // This demonstrates the vulnerability: cache shows stale data
    // In reality, the poisoned lock would prevent further operations
}
```

**Notes:**
- The actual reproduction requires proper mocking of ConnectionMetadata and handling of the poisoned lock scenario
- In production, this manifests as cascading panics and node degradation rather than a clean test failure
- The fix (reverse iteration) prevents the index invalidation issue entirely

### Citations

**File:** network/framework/src/application/storage.rs (L107-125)
```rust
    /// Returns metadata for all peers currently connected to the node
    pub fn get_connected_peers_and_metadata(
        &self,
    ) -> Result<HashMap<PeerNetworkId, PeerMetadata>, Error> {
        // Get the cached peers and metadata
        let cached_peers_and_metadata = self.cached_peers_and_metadata.load();

        // Collect all connected peers
        let mut connected_peers_and_metadata = HashMap::new();
        for (network_id, peers_and_metadata) in cached_peers_and_metadata.iter() {
            for (peer_id, peer_metadata) in peers_and_metadata.iter() {
                if peer_metadata.is_connected() {
                    let peer_network_id = PeerNetworkId::new(*network_id, *peer_id);
                    connected_peers_and_metadata.insert(peer_network_id, peer_metadata.clone());
                }
            }
        }
        Ok(connected_peers_and_metadata)
    }
```

**File:** network/framework/src/application/storage.rs (L219-262)
```rust
    pub fn remove_peer_metadata(
        &self,
        peer_network_id: PeerNetworkId,
        connection_id: ConnectionId,
    ) -> Result<PeerMetadata, Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Remove the peer metadata for the peer
        let peer_metadata = if let Entry::Occupied(entry) =
            peer_metadata_for_network.entry(peer_network_id.peer_id())
        {
            // Don't remove the peer if the connection doesn't match!
            // For now, remove the peer entirely, we could in the future
            // have multiple connections for a peer
            let active_connection_id = entry.get().connection_metadata.connection_id;
            if active_connection_id == connection_id {
                let peer_metadata = entry.remove();
                let event = ConnectionNotification::LostPeer(
                    peer_metadata.connection_metadata.clone(),
                    peer_network_id.network_id(),
                );
                self.broadcast(event);
                peer_metadata
            } else {
                return Err(Error::UnexpectedError(format!(
                    "The peer connection id did not match! Given: {:?}, found: {:?}.",
                    connection_id, active_connection_id
                )));
            }
        } else {
            // Unable to find the peer metadata for the given peer
            return Err(missing_peer_metadata_error(&peer_network_id));
        };

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        Ok(peer_metadata)
    }
```

**File:** network/framework/src/application/storage.rs (L371-395)
```rust
    fn broadcast(&self, event: ConnectionNotification) {
        let mut listeners = self.subscribers.lock();
        let mut to_del = vec![];
        for i in 0..listeners.len() {
            let dest = listeners.get_mut(i).unwrap();
            if let Err(err) = dest.try_send(event.clone()) {
                match err {
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
                    TrySendError::Closed(_) => {
                        to_del.push(i);
                    },
                }
            }
        }
        for evict in to_del.into_iter() {
            listeners.swap_remove(evict);
        }
    }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L98-127)
```rust
    /// Garbage collect inactive subscriptions by removing peers that are no longer connected
    fn garbage_collect_subscriptions(&self) {
        // Get the set of active subscribers
        let active_subscribers = self.get_active_subscribers();

        // Get the connected peers and metadata
        let peers_and_metadata = self.consensus_observer_client.get_peers_and_metadata();
        let connected_peers_and_metadata =
            match peers_and_metadata.get_connected_peers_and_metadata() {
                Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
                Err(error) => {
                    // We failed to get the connected peers and metadata
                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::UnexpectedError)
                        .message(&format!(
                            "Failed to get connected peers and metadata! Error: {:?}",
                            error
                        )));
                    return;
                },
            };

        // Identify the active subscribers that are no longer connected
        let connected_peers: HashSet<PeerNetworkId> =
            connected_peers_and_metadata.keys().cloned().collect();
        let disconnected_subscribers: HashSet<PeerNetworkId> = active_subscribers
            .difference(&connected_peers)
            .cloned()
            .collect();

```

**File:** crates/aptos-infallible/src/rwlock.rs (L25-30)
```rust
    /// lock the rwlock in write mode
    pub fn write(&self) -> RwLockWriteGuard<'_, T> {
        self.0
            .write()
            .expect("Cannot currently handle a poisoned lock")
    }
```
