# Audit Report

## Title
Cross-Shard Message Delivery Lacks Atomicity Leading to Validator Crash and Consensus Liveness Failure

## Summary
The cross-shard messaging protocol in Aptos' sharded block executor does not guarantee atomic delivery of multiple `RemoteTxnWrite` messages from the same transaction. When a transaction writes to multiple state keys required by a dependent shard, each write is sent as a separate GRPC message with no retry logic. Network failures during the message sequence cause the validator process to panic and crash, leading to consensus liveness failure if sufficient validators are affected.

## Finding Description

The cross-shard messaging protocol violates the all-or-nothing delivery guarantee through a critical design flaw in how transaction writes are communicated between shards.

**Message Sending Pattern:**

When a transaction in one shard writes to multiple state keys needed by a dependent shard, the system sends separate `RemoteTxnWrite` messages for each state key: [1](#0-0) 

Each state key generates an independent message sent through the cross-shard client interface. For the remote execution case, these become separate GRPC calls: [2](#0-1) 

**Critical Vulnerability in Network Layer:**

The GRPC network layer has NO retry logic and panics on any send failure: [3](#0-2) 

Note the explicit TODO comment acknowledging missing retry logic (line 150) and the panic on error (lines 154-157).

**Blocking Receiver:**

The dependent shard blocks indefinitely waiting for each message: [4](#0-3) 

**Attack Scenario:**

1. Remote sharded execution is enabled via configuration
2. Transaction T in Shard 0 writes K1=v1, K2=v2, K3=v3
3. All three keys are needed by dependent transaction in Shard 1
4. System sends three separate GRPC messages
5. Network partition or packet loss occurs after messages 1 and 2
6. GRPC send for message 3 fails
7. **Validator process panics and crashes** (line 154-157)
8. Validator cannot participate in consensus
9. If >1/3 validators crash due to network issues, consensus halts

**Invariant Violations:**

- **Deterministic Execution (Invariant #1)**: Different validators experiencing different network conditions cannot produce identical execution results
- **State Consistency (Invariant #4)**: Partial message delivery creates inconsistent state views across validators
- **Consensus Liveness**: Validator crashes prevent consensus participation

## Impact Explanation

This is **Critical Severity** per Aptos bug bounty criteria because it causes:

**Total loss of liveness/network availability** - If network conditions cause >1/3 of validators to crash during cross-shard message delivery, the entire blockchain halts and requires manual intervention to restart validators.

The vulnerability is integrated into the production execution path: [5](#0-4) 

When remote addresses are configured, the system uses `REMOTE_SHARDED_BLOCK_EXECUTOR` which contains this vulnerability.

## Likelihood Explanation

**HIGH likelihood** in production environments where:

1. Remote sharded execution is enabled for performance
2. Network conditions are unreliable (cloud environments, cross-datacenter)
3. High transaction throughput increases message volume

The likelihood increases with:
- Number of cross-shard dependencies
- Network latency and packet loss rates
- Number of remote shards configured

Network partitions and transient failures are common in distributed systems, making this vulnerability easily triggered during normal operations without any malicious actor.

## Recommendation

Implement atomic batching and retry logic for cross-shard messages:

**1. Batch messages per transaction:**
Group all `RemoteTxnWrite` messages for the same transaction into a single atomic message containing all writes.

**2. Add retry logic with exponential backoff:**
Replace the panic with retry logic as indicated by the TODO comment at line 150 of `secure/net/src/grpc_network_service/mod.rs`.

**3. Add message acknowledgment:**
Implement a confirmation protocol where the receiver acknowledges receipt of all messages before the sender considers the transaction committed.

**4. Add timeout handling:**
Replace indefinite blocking in `RemoteStateValue::get_value()` with timeout-based error handling that can trigger recovery procedures.

**Example fix structure:**
```rust
// In CrossShardCommitSender, batch all messages for a transaction
struct CrossShardTransactionMessages {
    txn_idx: TxnIndex,
    writes: Vec<RemoteTxnWrite>,
}

// Send atomically with retry
async fn send_with_retry(messages: CrossShardTransactionMessages, max_retries: u32) -> Result<()> {
    for attempt in 0..max_retries {
        match send_atomic_batch(messages).await {
            Ok(_) => return Ok(()),
            Err(e) if attempt < max_retries - 1 => {
                sleep(exponential_backoff(attempt)).await;
                continue;
            }
            Err(e) => return Err(e),
        }
    }
}
```

## Proof of Concept

**Setup:**
1. Configure remote sharded execution with 2 shards on separate machines
2. Enable network fault injection (iptables to drop packets)

**Reproduction Steps:**

```rust
// 1. Configure remote execution
set_remote_addresses(vec![
    SocketAddr::new(IpAddr::V4(Ipv4Addr::new(10, 0, 0, 2)), 52200),
]);
set_coordinator_address(SocketAddr::new(IpAddr::V4(Ipv4Addr::new(10, 0, 0, 1)), 52200));

// 2. Create transaction that writes multiple keys with cross-shard dependency
let txn = create_multi_write_transaction(vec![
    (state_key_1, write_op_1),  // Needed by shard 1
    (state_key_2, write_op_2),  // Needed by shard 1  
    (state_key_3, write_op_3),  // Needed by shard 1
]);

// 3. Inject network failure after 2nd message sent
// Using network fault injection tool:
// iptables -A OUTPUT -p tcp --dport 52200 -m statistic --mode nth --every 3 --packet 2 -j DROP

// 4. Execute block with sharded execution
let result = executor.execute_block_sharded(
    &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
    partitioned_txns,
    state_view,
    onchain_config,
);

// Expected result: 
// - First 2 RemoteTxnWrite messages succeed
// - Third message fails due to packet drop
// - GRPC send_message panics at line 154-157
// - Validator process crashes
// - Consensus cannot proceed if >1/3 validators crash
```

**Verification:**
Monitor validator logs for panic message matching the pattern in line 154-157, confirming the crash occurs during cross-shard message delivery when network failures are injected.

---

**Notes:**

This vulnerability is particularly concerning because:
1. It's acknowledged in code (TODO comment) but not fixed
2. It affects production consensus execution when remote sharding is enabled
3. The failure mode (process panic) is the worst possible outcome
4. No graceful degradation or recovery mechanism exists
5. Natural network conditions can trigger it without malicious actors

The fix requires fundamental protocol redesign to ensure atomicity of cross-shard message delivery, which is a critical requirement for maintaining deterministic execution across all validators.

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L114-133)
```rust
        for (state_key, write_op) in write_set.expect_write_op_iter() {
            if let Some(dependent_shard_ids) = edges.get(state_key) {
                for (dependent_shard_id, round_id) in dependent_shard_ids.iter() {
                    trace!("Sending remote update for success for shard id {:?} and txn_idx: {:?}, state_key: {:?}, dependent shard id: {:?}", self.shard_id, txn_idx, state_key, dependent_shard_id);
                    let message = RemoteTxnWriteMsg(RemoteTxnWrite::new(
                        state_key.clone(),
                        Some(write_op.clone()),
                    ));
                    if *round_id == GLOBAL_ROUND_ID {
                        self.cross_shard_client.send_global_msg(message);
                    } else {
                        self.cross_shard_client.send_cross_shard_msg(
                            *dependent_shard_id,
                            *round_id,
                            message,
                        );
                    }
                }
            }
        }
```

**File:** execution/executor-service/src/remote_cross_shard_client.rs (L55-59)
```rust
    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg) {
        let input_message = bcs::to_bytes(&msg).unwrap();
        let tx = self.message_txs[shard_id][round].lock().unwrap();
        tx.send(Message::new(input_message)).unwrap();
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L140-160)
```rust
    pub async fn send_message(
        &mut self,
        sender_addr: SocketAddr,
        message: Message,
        mt: &MessageType,
    ) {
        let request = tonic::Request::new(NetworkMessage {
            message: message.data,
            message_type: mt.get_type(),
        });
        // TODO: Retry with exponential backoff on failures
        match self.remote_channel.simple_msg_exchange(request).await {
            Ok(_) => {},
            Err(e) => {
                panic!(
                    "Error '{}' sending message to {} on node {:?}",
                    e, self.remote_addr, sender_addr
                );
            },
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/remote_state_value.rs (L29-39)
```rust
    pub fn get_value(&self) -> Option<StateValue> {
        let (lock, cvar) = &*self.value_condition;
        let mut status = lock.lock().unwrap();
        while let RemoteValueStatus::Waiting = *status {
            status = cvar.wait(status).unwrap();
        }
        match &*status {
            RemoteValueStatus::Ready(value) => value.clone(),
            RemoteValueStatus::Waiting => unreachable!(),
        }
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L256-276)
```rust
    fn execute_block_sharded<V: VMBlockExecutor>(
        partitioned_txns: PartitionedTransactions,
        state_view: Arc<CachedStateView>,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>> {
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        } else {
            Ok(V::execute_block_sharded(
                &SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        }
    }
```
