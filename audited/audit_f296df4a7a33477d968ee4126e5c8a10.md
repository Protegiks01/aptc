# Audit Report

## Title
Connection Pool Exhaustion via Unbounded Pending Proxy Protocol Upgrades

## Summary
The proxy protocol implementation in `read_header()` performs blocking `read_exact()` calls without individual timeouts, allowing an attacker to send partial headers and stall connection upgrades. Combined with the lack of limits on concurrent upgrade attempts, this enables connection pool exhaustion attacks that can prevent validators from accepting legitimate connections and degrade consensus participation.

## Finding Description

The vulnerability exists in the proxy protocol header reading logic when `enable_proxy_protocol` is configured on validator nodes. The attack exploits three architectural weaknesses:

**1. No Individual Timeout on read_exact() Calls**

The `read_header()` function performs two blocking `read_exact()` operations without individual timeouts: [1](#0-0) [2](#0-1) 

These calls will block indefinitely until all requested bytes are received or the connection closes.

**2. Only Global Upgrade Timeout Applied**

The timeout is applied to the entire `upgrade_inbound()` function (30 seconds), not to individual I/O operations: [3](#0-2) [4](#0-3) 

This means each connection can stall for up to 30 seconds waiting for proxy protocol header data.

**3. Unbounded Pending Upgrade Queue**

The `pending_inbound_connections` queue has no size limit: [5](#0-4) 

An unlimited number of connections can accumulate in the upgrade phase.

**4. Connection Limit Enforced Too Late**

The `max_inbound_connections` limit (default 100) is only enforced AFTER successful upgrade completion: [6](#0-5) [7](#0-6) 

This means the limit does not protect against attacks during the upgrade phase.

**Attack Scenario:**

1. Attacker opens many TCP connections to a validator node (e.g., 1000+ connections)
2. On each connection, sends only 10 bytes of the 16-byte proxy protocol signature [8](#0-7) 
3. Never sends the remaining 6 bytes
4. Each connection blocks in `read_exact()` waiting for completion
5. All connections accumulate in `pending_inbound_connections` for up to 30 seconds
6. System resources (file descriptors, memory, CPU) are exhausted
7. Legitimate validator connections cannot be established
8. The TCP listen backlog (256) provides minimal protection: [9](#0-8) 

The attacker can continuously open new connections as old ones timeout, maintaining sustained resource exhaustion.

## Impact Explanation

**Severity: High**

This vulnerability qualifies as **High Severity** under Aptos bug bounty criteria:
- **Validator node slowdowns**: Resource exhaustion degrades validator performance
- **Significant protocol violations**: Prevents validators from accepting connections, affecting consensus participation

**Concrete Impact:**
- Validators cannot accept new connections from peers
- Existing validators may struggle to maintain consensus quorum
- Network liveness degraded during attack
- Potential for temporary consensus stalls if multiple validators are targeted simultaneously
- System resource exhaustion (file descriptors, memory, CPU polling overhead)

This does not reach Critical severity because:
- No permanent network partition (recovers when attack stops)
- No direct fund loss or consensus safety violation
- Attack requires sustained effort and is detectable

## Likelihood Explanation

**Likelihood: High**

The attack is highly practical:
- **Low attacker requirements**: Any network peer can open TCP connections
- **No authentication needed**: Attack occurs before authentication in upgrade flow: [10](#0-9) 
- **Simple execution**: Just open connections and send partial data
- **No special resources needed**: Can be executed from commodity hardware
- **Affects production deployments**: Many validators use HAProxy with proxy protocol: [11](#0-10) 

## Recommendation

**Immediate Fix: Add timeout to read_exact() calls**

Wrap each `read_exact()` call with a short timeout (e.g., 5 seconds):

```rust
pub async fn read_header<T: AsyncRead + std::marker::Unpin>(
    original_addr: &NetworkAddress,
    stream: &mut T,
) -> io::Result<NetworkAddress> {
    use std::time::Duration;
    use tokio::time::timeout;
    
    const READ_TIMEOUT: Duration = Duration::from_secs(5);
    
    // Read header with timeout
    let mut header = [0u8; 16];
    timeout(READ_TIMEOUT, stream.read_exact(&mut header))
        .await
        .map_err(|_| io::Error::new(io::ErrorKind::TimedOut, "Proxy protocol header read timeout"))??;

    // ... validation logic ...

    // Read address bytes with timeout
    let mut address_bytes: Vec<u8> = vec![0; address_size as usize];
    timeout(READ_TIMEOUT, stream.read_exact(&mut address_bytes))
        .await
        .map_err(|_| io::Error::new(io::ErrorKind::TimedOut, "Proxy protocol address read timeout"))??;

    // ... rest of function ...
}
```

**Additional Hardening:**

1. **Limit concurrent pending upgrades**: Add configurable bound on `pending_inbound_connections` size
2. **Rate limiting**: Implement per-IP connection rate limits before upgrade phase
3. **Early connection limit check**: Reject connections before upgrade if approaching limit
4. **Monitoring**: Add metrics for pending upgrade queue size and timeout failures

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// File: network/netcore/src/transport/proxy_protocol_attack_test.rs

#[tokio::test]
async fn test_partial_header_stall_attack() {
    use tokio::net::{TcpListener, TcpStream};
    use tokio::io::AsyncWriteExt;
    use std::time::{Duration, Instant};
    
    // Start a mock validator with proxy protocol enabled
    let listener = TcpListener::bind("127.0.0.1:0").await.unwrap();
    let addr = listener.local_addr().unwrap();
    
    // Spawn task to accept connections and read proxy headers
    let validator_task = tokio::spawn(async move {
        let mut pending_upgrades = vec![];
        
        // Accept multiple connections
        for _ in 0..100 {
            if let Ok((mut stream, _)) = listener.accept().await {
                let upgrade = tokio::spawn(async move {
                    let mut header = [0u8; 16];
                    // This will block waiting for full 16 bytes
                    stream.read_exact(&mut header).await
                });
                pending_upgrades.push(upgrade);
            }
        }
        
        // All upgrades are now stuck
        pending_upgrades
    });
    
    // Attacker: Open many connections and send partial headers
    let attack_start = Instant::now();
    let mut attacker_connections = vec![];
    
    for _ in 0..100 {
        if let Ok(mut stream) = TcpStream::connect(addr).await {
            // Send only 10 bytes of 16-byte header
            stream.write_all(&[0x0D, 0x0A, 0x0D, 0x0A, 0x00, 0x0D, 0x0A, 0x51, 0x55, 0x49]).await.unwrap();
            // Never send the remaining 6 bytes
            attacker_connections.push(stream);
        }
    }
    
    // Connections are now stalled
    // In real scenario, this exhausts resources for 30 seconds
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // Verify connections are still open (not rejected immediately)
    assert!(attack_start.elapsed() < Duration::from_secs(30));
    assert_eq!(attacker_connections.len(), 100);
    
    // Clean up
    drop(attacker_connections);
    drop(validator_task);
}
```

**Notes:**

- This vulnerability is particularly severe when validators operate behind HAProxy with proxy protocol enabled
- The 30-second timeout provides a long window for resource exhaustion
- An attacker can maintain sustained pressure by continuously opening new connections
- The lack of bounds on `FuturesUnordered` means memory grows linearly with attack intensity
- Current connection limiting mechanisms do not protect the upgrade phase

### Citations

**File:** network/netcore/src/transport/proxy_protocol.rs (L56-57)
```rust
    let mut header = [0u8; 16];
    stream.read_exact(&mut header).await?;
```

**File:** network/netcore/src/transport/proxy_protocol.rs (L85-85)
```rust
    stream.read_exact(&mut address_bytes).await?;
```

**File:** network/framework/src/transport/mod.rs (L40-41)
```rust
/// A timeout for the connection to open and complete all of the upgrade steps.
pub const TRANSPORT_TIMEOUT: Duration = Duration::from_secs(30);
```

**File:** network/framework/src/transport/mod.rs (L260-261)
```rust
    let addr = if proxy_protocol_enabled {
        proxy_protocol::read_header(&addr, &mut socket)
```

**File:** network/framework/src/transport/mod.rs (L627-627)
```rust
            let fut_upgrade = timeout_io(time_service.clone(), TRANSPORT_TIMEOUT, fut_upgrade);
```

**File:** network/framework/src/peer_manager/transport.rs (L91-92)
```rust
        let mut pending_inbound_connections = FuturesUnordered::new();
        let mut pending_outbound_connections = FuturesUnordered::new();
```

**File:** network/framework/src/peer_manager/mod.rs (L375-375)
```rust
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
```

**File:** config/src/config/network_config.rs (L44-44)
```rust
pub const MAX_INBOUND_CONNECTIONS: usize = 100;
```

**File:** config/src/config/network_config.rs (L105-105)
```rust
    pub enable_proxy_protocol: bool,
```

**File:** network/netcore/src/transport/tcp.rs (L127-127)
```rust
        let listener = socket.listen(256)?;
```
