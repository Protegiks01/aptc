# Audit Report

## Title
PackageMetadata source_digest Lacks Cryptographic Binding to Published Bytecode, Enabling Code Substitution Attacks

## Summary
The `PackageMetadata.source_digest` field is stored on-chain without cryptographic verification against the actual bytecode being published. An attacker can publish malicious bytecode while claiming it corresponds to benign source code, undermining code transparency and enabling supply chain attacks against DeFi protocols, governance proposals, and on-chain applications.

## Finding Description

The Aptos package publishing system stores a `source_digest` in `PackageMetadata` to represent the hash of Move source files. However, this digest is never cryptographically verified against the actual compiled bytecode during package publication.

**Attack Flow:**

1. **Metadata Structure**: The `PackageMetadata` struct contains `source_digest` as a plain string field with no cryptographic binding to the bytecode: [1](#0-0) 

2. **Source Digest Computation**: During local compilation, `source_digest` is computed from Move source files (.move) and the manifest: [2](#0-1) 

3. **Separated Storage**: In `publish_package()`, the metadata (with source_digest) is stored in PackageRegistry BEFORE bytecode validation: [3](#0-2) 

4. **No Verification**: The bytecode publishing request is made separately without checking source_digest correspondence: [4](#0-3) 

5. **VM Validation Bypasses Check**: The VM's `validate_publish_request()` validates module structure, dependencies, and metadata format, but never computes a bytecode hash or verifies it matches the claimed source_digest: [5](#0-4) 

**Exploitation Scenario:**

An attacker compiles two packages:
- **Package A (Benign)**: Legitimate DeFi code → generates `source_digest_A`
- **Package B (Malicious)**: Backdoored code with hidden fund theft logic → generates `bytecode_B`

The attacker constructs a `PackageMetadata` with:
- `source_digest = source_digest_A` (claims to be Package A)
- `name = "TrustedDeFiProtocol"`

Then publishes via `publish_package_txn()` with:
- `metadata_serialized` containing the fake source_digest
- `code = bytecode_B` (actual malicious bytecode)

**Result**: The on-chain `PackageRegistry` shows `source_digest_A`, leading users and auditors to believe the code matches Package A's source, while `bytecode_B` executes with malicious logic. Since no verification exists between lines 207-227 in code.move or in the VM validation at lines 1680-1738 in aptos_vm.rs, both metadata and bytecode are accepted.

## Impact Explanation

**Severity: HIGH** (up to $50,000 per Aptos Bug Bounty)

This vulnerability constitutes a **significant protocol violation** affecting code authenticity guarantees:

1. **Breaks Code Transparency Invariant**: Users cannot trust that published code matches claimed sources, violating the fundamental assumption that on-chain metadata reflects actual execution behavior.

2. **Supply Chain Attack Vector**: Malicious actors can impersonate trusted packages (e.g., governance proposals, DeFi protocols) by publishing backdoored code with legitimate source digests.

3. **Governance Compromise**: Governance proposals could execute different code than what was audited, enabling covert protocol changes or fund theft.

4. **Audit Bypass**: Security auditors reviewing on-chain packages via source_digest would analyze incorrect code, failing to detect vulnerabilities in actual deployed bytecode.

5. **Wide Impact Surface**: Affects all Move modules, including:
   - DeFi protocols holding user funds
   - NFT contracts
   - On-chain governance proposals
   - Validator staking configurations

While this does not directly cause consensus splits or network downtime (hence not Critical), it enables persistent deception that could lead to fund loss and undermines trust in the entire Move ecosystem on Aptos.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attacker Requirements**: Only requires ability to call `publish_package_txn()`, which any account can do subject to gas costs.
- **Technical Complexity**: LOW - Simply requires compiling two packages separately and combining metadata from one with bytecode from another.
- **Detection Difficulty**: HIGH - Victims would need to manually decompile on-chain bytecode and compare against expected source, which is not part of standard verification workflows.
- **Exploit Persistence**: Once published, the mismatch remains permanently on-chain until upgraded.
- **No Rate Limiting**: An attacker can publish multiple malicious packages with fake source digests.

The vulnerability is trivially exploitable and highly likely to be discovered and abused by malicious actors, especially given the high-value targets in DeFi and governance.

## Recommendation

Implement cryptographic binding between `source_digest` and published bytecode:

**Option 1 - Bytecode Hash Verification (Recommended):**

Add a `bytecode_hash` field to `PackageMetadata` and verify consistency during publishing:

```rust
// In natives/code.rs PackageMetadata
pub struct PackageMetadata {
    pub name: String,
    pub upgrade_policy: UpgradePolicy,
    pub upgrade_number: u64,
    pub source_digest: String,
    pub bytecode_hash: String,  // NEW: SHA256 of all module bytecode
    // ... existing fields
}
```

In `aptos_vm.rs`, add verification in `validate_publish_request()`:

```rust
fn validate_publish_request(
    // ... existing params
    metadata: &PackageMetadata,  // NEW: pass metadata
    modules: &[CompiledModule],
    bundle: &ModuleBundle,
) -> VMResult<()> {
    // NEW: Compute hash of actual bytecode
    let mut hasher = Sha256::new();
    for blob in bundle.iter() {
        hasher.update(blob.code());
    }
    let computed_hash = format!("{:X}", hasher.finalize());
    
    // Verify against claimed hash
    if metadata.bytecode_hash != computed_hash {
        return Err(Self::metadata_validation_error(
            "bytecode hash mismatch - published code does not match metadata"
        ));
    }
    
    // ... existing validations
}
```

**Option 2 - Deterministic Build Verification:**

Store compiler version and build flags in metadata, then recompile from source_digest to verify bytecode matches. This is more complex but provides stronger guarantees.

**Option 3 - Remove source_digest:**

If verification cannot be implemented, remove the source_digest field entirely to prevent false security guarantees rather than leaving an unverified trust anchor.

## Proof of Concept

```rust
// Demonstration of exploitability (conceptual - would require full test environment)

#[test]
fn test_source_digest_mismatch_attack() {
    // Step 1: Compile benign package
    let benign_source = r#"
        module 0x1::TrustedVault {
            public fun withdraw(amount: u64) { /* safe logic */ }
        }
    "#;
    let benign_package = compile_package(benign_source);
    let benign_digest = benign_package.source_digest(); // "ABC123..."
    
    // Step 2: Compile malicious package  
    let malicious_source = r#"
        module 0x1::TrustedVault {
            public fun withdraw(amount: u64) {
                // BACKDOOR: steal all funds to attacker
                transfer_all_to(attacker_address());
            }
        }
    "#;
    let malicious_package = compile_package(malicious_source);
    let malicious_bytecode = malicious_package.extract_code();
    
    // Step 3: Create fake metadata with benign digest but malicious bytecode
    let fake_metadata = PackageMetadata {
        name: "TrustedVault".to_string(),
        source_digest: benign_digest,  // FAKE - claims benign
        // ... other fields
    };
    
    // Step 4: Publish with mismatched metadata and bytecode
    publish_package_txn(
        &attacker_signer,
        bcs::to_bytes(&fake_metadata).unwrap(),
        malicious_bytecode  // ACTUAL - is malicious
    );
    
    // RESULT: On-chain PackageRegistry shows benign source_digest
    // but execution uses malicious bytecode
    let registry = borrow_global<PackageRegistry>(VAULT_ADDRESS);
    assert!(registry.packages[0].source_digest == benign_digest);
    
    // Users trusting source_digest will be deceived
    // Actual execution steals funds via malicious bytecode
}
```

**Move Test Scenario:**

```move
#[test(attacker = @0x123, victim = @0x456)]
fun test_publish_mismatched_package(attacker: &signer, victim: &signer) {
    // Attacker creates metadata claiming digest "BENIGN_HASH"
    let fake_metadata = create_metadata(
        b"TrustedProtocol",
        b"BENIGN_HASH_FROM_AUDITED_CODE"
    );
    
    // But publishes different bytecode with backdoor
    let malicious_code = vector[
        compile_to_bytes("module 0x123::Backdoor { fun steal() {...} }")
    ];
    
    // Publish succeeds - no verification between digest and code
    code::publish_package_txn(attacker, 
        bcs::to_bytes(&fake_metadata), 
        malicious_code
    );
    
    // Verification: source_digest on-chain != actual bytecode behavior
    // Users see "BENIGN_HASH" but execution runs backdoor logic
}
```

## Notes

This vulnerability is particularly insidious because:

1. The `source_digest` field exists precisely to provide code authenticity, creating a false sense of security
2. Standard audit workflows likely assume source_digest can be trusted for verification
3. The separation between metadata storage (line 211 in code.move) and bytecode validation (line 1561 in aptos_vm.rs) with no cross-validation enables the attack
4. No existing grep searches found verification logic: `source_digest.*verify|verify.*source_digest` returned zero results

The fix requires bridging the gap between the Move-level metadata storage and VM-level bytecode validation to ensure cryptographic consistency.

### Citations

**File:** aptos-move/framework/src/natives/code.rs (L61-71)
```rust
pub struct PackageMetadata {
    pub name: String,
    pub upgrade_policy: UpgradePolicy,
    pub upgrade_number: u64,
    pub source_digest: String,
    #[serde(with = "serde_bytes")]
    pub manifest: Vec<u8>,
    pub modules: Vec<ModuleMetadata>,
    pub deps: Vec<PackageDep>,
    pub extension: Option<Any>,
}
```

**File:** third_party/move/tools/move-package/src/resolution/digest.rs (L11-51)
```rust
pub fn compute_digest(paths: &[PathBuf]) -> Result<PackageDigest> {
    let mut hashed_files = Vec::new();
    let mut hash = |path: &Path| {
        let contents = std::fs::read(path)?;
        hashed_files.push(format!("{:X}", Sha256::digest(&contents)));
        Ok(())
    };
    let mut maybe_hash_file = |path: &Path| -> Result<()> {
        match path.extension() {
            Some(x) if MOVE_EXTENSION == x => hash(path),
            _ if path.ends_with(SourcePackageLayout::Manifest.path()) => hash(path),
            _ => Ok(()),
        }
    };

    for path in paths {
        if path.is_file() {
            maybe_hash_file(path)?;
        } else {
            for entry in walkdir::WalkDir::new(path)
                .follow_links(true)
                .into_iter()
                .filter_map(|e| e.ok())
            {
                if entry.file_type().is_file() {
                    maybe_hash_file(entry.path())?
                }
            }
        }
    }

    // Sort the hashed files to ensure that the order of files is always stable
    hashed_files.sort();

    let mut hasher = Sha256::new();
    for file_hash in hashed_files.into_iter() {
        hasher.update(file_hash.as_bytes());
    }

    Ok(PackageDigest::from(format!("{:X}", hasher.finalize())))
}
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L207-214)
```text
        let packages = &mut borrow_global_mut<PackageRegistry>(addr).packages;
        // Update registry
        let policy = pack.upgrade_policy;
        if (index < len) {
            *vector::borrow_mut(packages, index) = pack
        } else {
            vector::push_back(packages, pack)
        };
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L221-227)
```text
        // Request publish
        if (features::code_dependency_check_enabled())
            request_publish_with_allowed_deps(addr, module_names, allowed_deps, code, policy.policy)
        else
        // The new `request_publish_with_allowed_deps` has not yet rolled out, so call downwards
        // compatible code.
            request_publish(addr, module_names, code, policy.policy)
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L1680-1738)
```rust
    fn validate_publish_request(
        &self,
        module_storage: &impl AptosModuleStorage,
        traversal_context: &mut TraversalContext,
        gas_meter: &mut impl GasMeter,
        modules: &[CompiledModule],
        mut expected_modules: BTreeSet<String>,
        allowed_deps: Option<BTreeMap<AccountAddress, BTreeSet<String>>>,
    ) -> VMResult<()> {
        self.reject_unstable_bytecode(modules)?;
        native_validation::validate_module_natives(modules)?;

        for m in modules {
            if !expected_modules.remove(m.self_id().name().as_str()) {
                return Err(Self::metadata_validation_error(&format!(
                    "unregistered module: '{}'",
                    m.self_id().name()
                )));
            }
            if let Some(allowed) = &allowed_deps {
                for dep in m.immediate_dependencies() {
                    if !allowed
                        .get(dep.address())
                        .map(|modules| {
                            modules.contains("") || modules.contains(dep.name().as_str())
                        })
                        .unwrap_or(false)
                    {
                        return Err(Self::metadata_validation_error(&format!(
                            "unregistered dependency: '{}'",
                            dep
                        )));
                    }
                }
            }
            verify_module_metadata_for_module_publishing(m, self.features())
                .map_err(|err| Self::metadata_validation_error(&err.to_string()))?;
        }

        resource_groups::validate_resource_groups(
            self.features(),
            module_storage,
            traversal_context,
            gas_meter,
            modules,
        )?;
        event_validation::validate_module_events(
            self.features(),
            module_storage,
            traversal_context,
            modules,
        )?;

        if !expected_modules.is_empty() {
            return Err(Self::metadata_validation_error(
                "not all registered modules published",
            ));
        }
        Ok(())
```
