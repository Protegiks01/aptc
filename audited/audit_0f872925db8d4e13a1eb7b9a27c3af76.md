# Audit Report

## Title
Orphaned Transaction Index Data Due to Internal Indexer Configuration Changes

## Summary
The `TransactionPruner::prune()` function fails to clean up `OrderedTransactionByAccountSchema` data when the `internal_indexer_db` configuration changes between node restarts, causing unbounded disk space growth from unpruned indices.

## Finding Description

The pruning logic in `TransactionPruner::prune()` determines where to delete `OrderedTransactionByAccountSchema` entries based on the runtime configuration of `internal_indexer_db`: [1](#0-0) 

The critical flaw occurs when node operators change their internal indexer configuration between restarts:

**Scenario 1: Disabling transaction indexing (`transaction_enabled: true → false`)**

Initial state with `transaction_enabled() = true`:
- Transaction data written to internal indexer DB [2](#0-1) 
- Pruning deletes from internal indexer DB (line 62 in transaction_pruner.rs)

After config change to `transaction_enabled() = false`:
- The check at line 59 fails, execution goes to else clause at line 68-71
- Pruning attempts to delete from main ledger DB batch
- **But old data remains in internal indexer DB, never pruned**

**Scenario 2: Removing internal indexer entirely (`Some → None`)**

Initial state with `internal_indexer_db = Some(...)`:
- Transaction data in internal indexer DB
- Pruning handled by lines 58-67

After config change to `internal_indexer_db = None`:
- The check at line 58 fails completely
- `prune_transaction_by_account` is never called
- **All historical data in internal indexer DB remains unpruned**

The root cause is that pruning progress is tracked separately:
- Main ledger DB progress: [3](#0-2) 
- Internal indexer DB progress: [4](#0-3) 

When configuration changes, the pruner initializes from main DB progress only: [5](#0-4) 

This fails to account for data in the other database, leaving it orphaned.

## Impact Explanation

**Severity: High** per Aptos bug bounty criteria (Validator node slowdowns)

While this does not directly violate consensus safety or cause fund loss, it represents a **High severity** operational issue:

1. **Disk Space Exhaustion**: Unpruned `OrderedTransactionByAccountSchema` indices accumulate indefinitely, eventually filling disk space
2. **Resource Limit Violation**: Breaks invariant #9 (Resource Limits) - storage must respect pruning windows
3. **Validator Degradation**: Can cause validator nodes to fail when disk space runs out, affecting network liveness
4. **Cascading Failures**: Multiple validators changing configs could reduce network capacity

The impact is limited to nodes that change their configuration, but for long-running validators with strict pruning windows, this causes unbounded growth that requires manual intervention or database migration.

## Likelihood Explanation

**Likelihood: Medium**

This occurs when:
1. Node operators change `indexer_db_config.enable_transaction` setting
2. Or operators remove internal indexer DB entirely
3. During upgrades or optimization attempts

While not automatic exploitation, it's a realistic operational scenario that:
- Can happen during routine maintenance
- Is not prevented by configuration validation [6](#0-5) 
- Affects any validator adjusting their indexer settings
- Would go unnoticed until disk space issues emerge

## Recommendation

Add migration logic to handle configuration changes by checking and pruning from both databases:

```rust
fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
    let mut batch = SchemaBatch::new();
    let candidate_transactions = 
        self.get_pruning_candidate_transactions(current_progress, target_version)?;
    
    // ... existing main DB pruning code ...
    
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::TransactionPrunerProgress,
        &DbMetadataValue::Version(target_version),
    )?;
    
    // NEW: Handle both internal indexer and main DB pruning
    if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
        if indexer_db.transaction_enabled() {
            // Prune from internal indexer DB as before
            let mut index_batch = SchemaBatch::new();
            self.transaction_store
                .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
            index_batch.put::<InternalIndexerMetadataSchema>(
                &IndexerMetadataKey::TransactionPrunerProgress,
                &IndexerMetadataValue::Version(target_version),
            )?;
            indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
        } else {
            // Prune from main DB
            self.transaction_store
                .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
        }
    } else {
        // NEW: When internal_indexer_db is None, always prune from main DB
        // This ensures data written when skip_index=false is cleaned up
        self.transaction_store
            .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
    }
    
    self.ledger_db.transaction_db().write_schemas(batch)
}
```

Additionally, add startup validation to detect orphaned data and log warnings when configuration changes are detected.

## Proof of Concept

```rust
// Test demonstrating orphaned data after config change
#[test]
fn test_config_change_orphans_data() {
    // Setup: Create DB with internal indexer enabled
    let (mut db, internal_indexer) = create_test_db_with_indexer(true); // transaction_enabled=true
    
    // Step 1: Commit transactions with indexer enabled
    for version in 0..1000 {
        let txn = create_test_signed_transaction();
        db.save_transactions(&[txn], version, None).unwrap();
    }
    
    // Step 2: Prune with indexer enabled (versions 0-500)
    db.ledger_pruner.prune(500).unwrap();
    
    // Verify: Data pruned from internal indexer DB
    assert!(internal_indexer.get_transaction_version().unwrap() == Some(500));
    
    // Step 3: Restart with transaction_enabled=false
    drop(db);
    let mut db = reopen_db_with_indexer(false); // transaction_enabled=false
    
    // Step 4: Continue committing and pruning (versions 1000-2000)
    for version in 1000..2000 {
        let txn = create_test_signed_transaction();
        db.save_transactions(&[txn], version, None).unwrap();
    }
    
    db.ledger_pruner.prune(500).unwrap(); // Try to prune more
    
    // BUG: Old data (versions 501-999) in internal indexer DB is never pruned
    // It remains there indefinitely, wasting disk space
    let orphaned_data = count_indexer_db_entries(&internal_indexer);
    assert!(orphaned_data > 0, "Orphaned data detected!");
}
```

**Notes:**
- This vulnerability requires node operator configuration changes between restarts
- It does not affect consensus or create inter-node inconsistencies
- Impact is limited to individual nodes that change their configuration
- The issue violates the storage resource limits invariant through unbounded data accumulation
- Fix requires both code changes and operational procedures to detect/migrate orphaned data

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L54-57)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L58-72)
```rust
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
```

**File:** storage/indexer/src/db_indexer.rs (L421-428)
```rust
                if self.indexer_db.transaction_enabled() {
                    if let ReplayProtector::SequenceNumber(seq_num) = signed_txn.replay_protector()
                    {
                        batch.put::<OrderedTransactionByAccountSchema>(
                            &(signed_txn.sender(), seq_num),
                            &version,
                        )?;
                    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-59)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
```

**File:** config/src/config/internal_indexer_db_config.rs (L91-99)
```rust
        // Shouldn't turn on internal indexer for db without sharding
        if !node_config.storage.rocksdb_configs.enable_storage_sharding
            && config.is_internal_indexer_db_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Don't turn on internal indexer db if DB sharding is off".into(),
            ));
        }
```
