# Audit Report

## Title
Unbounded Catch-Up Pruning During Validator Startup Causes Availability Risk

## Summary
The `TransactionAuxiliaryDataPruner::new()` initialization performs unbounded synchronous pruning when the stored progress lags behind metadata progress, which can cause excessive startup delays and cause validators to miss early consensus rounds.

## Finding Description

During validator startup, the `LedgerPruner` initialization process creates multiple sub-pruners, including `TransactionAuxiliaryDataPruner`. Each sub-pruner performs a "catch-up" prune operation to synchronize its progress with the ledger metadata progress. [1](#0-0) 

The critical issue is that when `progress` is significantly behind `metadata_progress`, the prune operation iterates over every version in the gap without any batching or limits: [2](#0-1) 

This occurs during the critical startup path where `LedgerPruner::new()` is called synchronously: [3](#0-2) [4](#0-3) 

**Contrast with normal pruning**: During regular operation, the pruner respects batch size limits: [5](#0-4) 

However, the initialization catch-up has NO such batching - it processes the entire gap in a single synchronous call.

**Scenario triggering the issue**:
1. Database metadata corruption or partial restore causes `TransactionAuxiliaryDataPrunerProgress` to be stale (e.g., 0) while `metadata_progress` is current (e.g., 10,000,000)
2. On validator startup, `get_or_initialize_subpruner_progress` returns the stale progress value
3. `prune(0, 10000000)` executes, iterating 10 million times
4. Each iteration adds a delete operation to the batch
5. Validator startup is blocked until completion
6. Validator misses early consensus rounds

This affects **all seven sub-pruners** that follow the same pattern (EventStorePruner, PersistedAuxiliaryInfoPruner, TransactionAccumulatorPruner, TransactionAuxiliaryDataPruner, TransactionInfoPruner, TransactionPruner, WriteSetPruner).

## Impact Explanation

This qualifies as **Medium** severity under the category of "State inconsistencies requiring intervention." While the impact could potentially reach "Validator node slowdowns" (High severity), the realistic scenario requires pre-existing database corruption, which limits the exploitability.

The availability impact includes:
- Validator startup delay proportional to version gap (potentially minutes)
- Missing early consensus rounds after restart
- Reduced network liveness if multiple validators affected simultaneously
- Potential cascade effects if validators restart during critical network events

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires specific conditions:
1. Database metadata corruption or inconsistency between sub-pruner progress and metadata progress
2. Validator restart while in corrupted state
3. Sufficiently large version gap (millions of versions)

These conditions can arise from:
- Partial database backups/restores during operational recovery
- Bugs in progress tracking preventing updates
- Filesystem corruption affecting specific metadata entries
- Operational errors during database migrations

While external attackers cannot directly trigger this without validator filesystem access, it represents a **design weakness** that creates availability risks during operational incidents.

## Recommendation

Implement batched catch-up pruning during initialization with the same limits used during normal pruning:

```rust
pub(in crate::pruner) fn new(
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        ledger_db.transaction_auxiliary_data_db_raw(),
        &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
        metadata_progress,
    )?;

    let myself = TransactionAuxiliaryDataPruner { ledger_db };

    // Batch the catch-up to avoid unbounded startup delays
    const CATCHUP_BATCH_SIZE: usize = 10_000;
    let mut current_progress = progress;
    
    info!(
        progress = progress,
        metadata_progress = metadata_progress,
        "Catching up TransactionAuxiliaryDataPruner."
    );
    
    while current_progress < metadata_progress {
        let batch_target = std::cmp::min(
            current_progress + CATCHUP_BATCH_SIZE as Version,
            metadata_progress
        );
        myself.prune(current_progress, batch_target)?;
        current_progress = batch_target;
    }

    Ok(myself)
}
```

Apply this pattern to all sub-pruners. Additionally, add monitoring/alerts for large progress gaps and consider graceful degradation (e.g., async catch-up with reduced consensus participation).

## Proof of Concept

```rust
// Test scenario simulating startup delay
#[test]
fn test_unbounded_catchup_delay() {
    // Setup: Create ledger_db with metadata_progress at 1,000,000
    let ledger_db = create_test_ledger_db();
    let metadata_progress = 1_000_000;
    
    // Simulate corrupted progress metadata (stored as 0)
    ledger_db.transaction_auxiliary_data_db_raw()
        .put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
            &DbMetadataValue::Version(0)
        )
        .unwrap();
    
    // Measure startup time
    let start = std::time::Instant::now();
    let pruner = TransactionAuxiliaryDataPruner::new(
        Arc::new(ledger_db),
        metadata_progress
    ).unwrap();
    let duration = start.elapsed();
    
    // With 1M version gap, expect significant delay
    println!("Startup delay: {:?}", duration);
    assert!(duration.as_secs() > 1, "Startup should be delayed with large gap");
}
```

## Notes

While this issue represents a legitimate design weakness that creates availability risks, it **does not meet the strict criteria for an exploitable security vulnerability** per the bug bounty validation checklist. Specifically:

- **Not exploitable by unprivileged attacker**: Requires database corruption or validator filesystem access
- **No clear external attack path**: Cannot be triggered by network peers or transaction senders
- **Operational issue, not security exploit**: Affects availability under corrupted state conditions

This finding should be treated as a **resilience improvement** rather than a critical security vulnerability. The recommended fix improves operational robustness and reduces availability risks during database recovery scenarios.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_auxiliary_data_pruner.rs (L39-59)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_auxiliary_data_db_raw(),
            &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionAuxiliaryDataPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionAuxiliaryDataPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_auxiliary_data_db.rs (L74-79)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<TransactionAuxiliaryDataSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L62-92)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning ledger data."
            );
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning ledger data is done.");
        }

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L152-155)
```rust
        let transaction_auxiliary_data_pruner = Box::new(TransactionAuxiliaryDataPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L146-149)
```rust
        let pruner = Arc::new(
            LedgerPruner::new(ledger_db, internal_indexer_db)
                .expect("Failed to create ledger pruner."),
        );
```
