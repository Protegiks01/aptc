# Audit Report

## Title
Indexer Cache Worker Permanent Crash Loop Due to Version Gap Detection When Cache is Reinitialized

## Summary
The `cache_setup_if_needed()` function initializes `CACHE_KEY_LATEST_VERSION` to "0" when Redis cache is empty, but this creates an unrecoverable crash loop when the file store metadata has already progressed to a higher version. The cache worker cannot update the latest version due to gap detection logic in the Lua script, causing permanent indexer service unavailability. [1](#0-0) 

## Finding Description

The vulnerability occurs through the following sequence:

**Initialization Phase:**
When the file store processor initializes, it calls `cache_setup_if_needed()` which uses Redis `SET` command with `NX` flag to initialize `CACHE_KEY_LATEST_VERSION` to the constant `CACHE_DEFAULT_LATEST_VERSION_NUMBER` ("0") if the key doesn't exist. [2](#0-1) 

**Cache Worker Processing:**
The cache worker starts processing from the file store metadata version (e.g., 1,000,000 if the blockchain has progressed). At the end of each batch, it attempts to update the cache's latest version using `update_cache_latest_version()`. [3](#0-2) 

**Gap Detection Failure:**
The Lua script that validates version updates detects a gap when the cached `latest_version` (0) plus `num_of_versions` (e.g., 1000) is far less than the `current_version` (e.g., 1,001,000). This returns status code 2 indicating a gap. [4](#0-3) 

**Error Propagation:**
When the Lua script returns 2, `update_cache_latest_version()` returns an error which propagates up through the cache worker's processing loop, causing it to exit and restart. [5](#0-4) 

**Permanent Loop:**
The outer loop in the cache worker's `run()` method will reconnect and retry, but the Redis key remains set to "0", so the gap detection fails on every attempt, creating a permanent crash loop. [6](#0-5) 

**Trigger Scenario:**
1. Blockchain has progressed to version N (e.g., 1,000,000)
2. Redis cache is cleared (maintenance, migration, or failure)
3. File store metadata still exists at version N
4. System restarts with `cache_setup_if_needed()` setting version to "0"
5. Cache worker attempts first batch update from version N
6. Gap detected: 0 + 1000 < 1,001,000
7. Worker crashes and enters infinite retry loop

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program:

- **API crashes**: The indexer data service becomes unavailable as it relies on the cache worker to populate the cache with recent transactions
- **Significant protocol violations**: The indexer service, which is critical infrastructure for blockchain data access, becomes permanently unavailable without manual intervention
- **Service degradation**: All clients depending on the indexer gRPC service (wallets, explorers, analytics platforms) lose access to real-time blockchain data

The impact affects the entire indexer infrastructure availability, not the core consensus or blockchain itself. However, indexers are critical for ecosystem functionality.

## Likelihood Explanation

**Very High Likelihood** in production environments:

1. **Operational maintenance**: Redis cache clearing is a common operational task for capacity management, debugging, or migration
2. **Redis failures**: Transient Redis failures followed by restart can trigger this state
3. **Scaling operations**: Adding new cache instances to a running system
4. **No recovery mechanism**: The system has no automatic recovery path once in this state
5. **No validation**: The initialization logic doesn't check if file store version is compatible with default cache version

This is not a theoretical bug but a design flaw that will manifest in real operational scenarios.

## Recommendation

**Solution 1: Initialize cache version from file store metadata**

Instead of always using "0" as the default, initialize `CACHE_KEY_LATEST_VERSION` to the file store metadata version:

```rust
// In processor.rs, replace cache_setup_if_needed() call:
let batch_start_version = metadata.version;

// Initialize cache with file store version instead of 0
let version_inserted: bool = redis::cmd("SET")
    .arg(CACHE_KEY_LATEST_VERSION)
    .arg(batch_start_version.to_string())
    .arg("NX")
    .query_async(&mut cache_operator.conn)
    .await?;
```

**Solution 2: Modify Lua script to handle large gaps gracefully**

Update the gap detection logic to allow initialization from any version when the cached value is 0:

```lua
local latest_version = redis.call("GET", KEYS[1])
local num_of_versions = tonumber(ARGV[1])
local current_version = tonumber(ARGV[2])
if latest_version then
    local latest = tonumber(latest_version)
    -- Allow gap if current cached version is 0 (initialization case)
    if latest == 0 then
        redis.call("SET", KEYS[1], current_version)
        return 0
    end
    -- Normal gap detection for non-zero cached versions
    if latest + num_of_versions < current_version then
        return 2
    elseif latest + num_of_versions == current_version then
        redis.call("SET", KEYS[1], current_version)
        return 0
    else
        redis.call("SET", KEYS[1], math.max(current_version, latest))
        return 1
    end
else
    redis.call("SET", KEYS[1], current_version)
    return 0
end
```

**Solution 3: Add explicit validation and error handling**

Add validation before processing to detect and handle this condition explicitly, with clear error messages for operators.

## Proof of Concept

**Reproduction Steps:**

1. Start indexer system with blockchain at version 1,000,000
2. File store metadata is created with version 1,000,000
3. Clear Redis cache: `redis-cli FLUSHALL`
4. Restart cache worker service
5. Observe crash logs:

```
[ERROR] Redis latest version update failed. The version is beyond the next expected version.
[ERROR] Failed to update the latest version in the cache
```

6. Worker enters infinite restart loop
7. Data service requests return timeouts as cache is never populated

**Verification:**
```bash
# Check Redis state
redis-cli GET latest_version
# Output: "0"

# Check file store metadata
# Shows version: 1000000

# Cache worker logs show repeated errors
kubectl logs indexer-cache-worker | grep "Version is not right"
```

The system remains in this failed state until manual intervention (either clearing the Redis key or resetting file store metadata), demonstrating the permanent service unavailability.

## Notes

This vulnerability affects **indexer service availability**, not the core Aptos blockchain consensus or validator operations. However, it represents a critical operational failure that breaks the indexer infrastructure's core invariant: continuous data availability for ecosystem participants.

The root cause is the hardcoded `CACHE_DEFAULT_LATEST_VERSION_NUMBER = "0"` constant which doesn't account for cache reinitialization scenarios when the blockchain has already progressed beyond genesis.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L32-32)
```rust
const CACHE_DEFAULT_LATEST_VERSION_NUMBER: &str = "0";
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L39-57)
```rust
const CACHE_SCRIPT_UPDATE_LATEST_VERSION: &str = r#"
    local latest_version = redis.call("GET", KEYS[1])
    local num_of_versions = tonumber(ARGV[1])
    local current_version = tonumber(ARGV[2])
    if latest_version then
        if tonumber(latest_version) + num_of_versions < current_version then
            return 2
        elseif tonumber(latest_version) + num_of_versions == current_version then
            redis.call("SET", KEYS[1], current_version)
            return 0
        else
            redis.call("SET", KEYS[1], math.max(current_version, tonumber(latest_version)))
            return 1
        end
    else
        redis.call("SET", KEYS[1], ARGV[1])
        return 0
    end
"#;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L116-122)
```rust
        let version_inserted: bool = redis::cmd("SET")
            .arg(CACHE_KEY_LATEST_VERSION)
            .arg(CACHE_DEFAULT_LATEST_VERSION_NUMBER)
            .arg("NX")
            .query_async(&mut self.conn)
            .await
            .context("Redis latest_version check failed.")?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L359-361)
```rust
            2 => {
                tracing::error!(version=version, "Redis latest version update failed. The version is beyond the next expected version.");
                Err(anyhow::anyhow!("Version is not right."))
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L109-180)
```rust
    pub async fn run(&mut self) -> Result<()> {
        // Re-connect if lost.
        loop {
            let conn = self
                .redis_client
                .get_tokio_connection_manager()
                .await
                .context("Get redis connection failed.")?;
            let mut rpc_client = create_grpc_client(self.fullnode_grpc_address.clone()).await;

            // 1. Fetch metadata.
            let file_store_operator: Box<dyn FileStoreOperator> = self.file_store.create();
            // TODO: move chain id check somewhere around here
            // This ensures that metadata is created before we start the cache worker
            let mut starting_version = file_store_operator.get_latest_version().await;
            while starting_version.is_none() {
                starting_version = file_store_operator.get_latest_version().await;
                tracing::warn!(
                    "[Indexer Cache] File store metadata not found. Waiting for {} ms.",
                    FILE_STORE_METADATA_WAIT_MS
                );
                tokio::time::sleep(std::time::Duration::from_millis(
                    FILE_STORE_METADATA_WAIT_MS,
                ))
                .await;
            }

            // There's a guarantee at this point that starting_version is not null
            let starting_version = starting_version.unwrap();

            let file_store_metadata = file_store_operator.get_file_store_metadata().await.unwrap();

            tracing::info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Starting cache worker with version {}",
                starting_version
            );

            // 2. Start streaming RPC.
            let request = tonic::Request::new(GetTransactionsFromNodeRequest {
                starting_version: Some(starting_version),
                ..Default::default()
            });

            let response = rpc_client
                .get_transactions_from_node(request)
                .await
                .with_context(|| {
                    format!(
                        "Failed to get transactions from node at starting version {}",
                        starting_version
                    )
                })?;
            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC started."
            );
            // 3&4. Infinite streaming until error happens. Either stream ends or worker crashes.
            process_streaming_response(
                conn,
                self.cache_storage_format,
                file_store_metadata,
                response.into_inner(),
            )
            .await?;

            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC ended."
            );
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L444-447)
```rust
                    cache_operator
                        .update_cache_latest_version(transaction_count, current_version)
                        .await
                        .context("Failed to update the latest version in the cache")?;
```
