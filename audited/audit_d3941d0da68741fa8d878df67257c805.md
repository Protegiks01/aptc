# Audit Report

## Title
DAG Consensus Storage Amplification Attack via Unbounded Parent Certificates

## Summary
The DAG consensus node validation logic only validates payload and validator transaction sizes but fails to validate the size of parent certificates. A malicious validator can craft nodes with excessive parent certificates (up to network message limit), causing storage to consume 3-4x more space than configured limits allow.

## Finding Description

The vulnerability exists in the DAG consensus node validation and storage flow: [1](#0-0) 

The validation function checks validator transactions and payload sizes against `max_receiving_size_per_round_bytes` (default 20 MB), but completely ignores the size of the `parents` field containing `NodeCertificate` structures. [2](#0-1) 

Each `Node` contains a `Vec<NodeCertificate>` for parents. The Node verification only checks that parents satisfy voting power requirements (2f+1 quorum): [3](#0-2) 

There is no upper limit on the number of parents. An attacker can include ALL validators as parents instead of just the minimum 2f+1 required.

Each `NodeCertificate` contains an `AggregateSignature` with a `BitVec`: [4](#0-3) [5](#0-4) 

With the maximum validator set size of 65,536: [6](#0-5) 

Each `NodeCertificate` with full `BitVec` is approximately 8,380 bytes (88 bytes metadata + 8,195 bytes BitVec + 97 bytes signature).

**Attack Scenario:**
1. Attacker crafts a Node with 20 MB payload (at the validation limit)
2. Attacker includes ~5,250 parent certificates (fitting in remaining 44 MB of 64 MB network limit)
3. Node passes validation (only checks payload: 20 MB âœ“)
4. Node is BCS-encoded and stored: [7](#0-6) 

5. Total storage consumed: 20 MB payload + 44 MB parents = **64 MB**
6. Validated size: **20 MB**
7. **Amplification: 3.2x**

## Impact Explanation

This is a **Medium severity** storage amplification attack according to Aptos bug bounty criteria:

- **Storage Exhaustion**: Validators can be forced to store 3.2x more data than configured limits
- **Node Slowdowns**: Excessive storage consumption degrades node performance (High severity element)
- **State Inconsistencies**: Storage exhaustion can cause nodes to fail, requiring manual intervention (Medium severity)
- **Resource Limit Violation**: Breaks the documented invariant: "All operations must respect gas, storage, and computational limits"

The attack is bounded by the network message limit (64 MB), preventing it from reaching Critical severity. However, sustained attacks across many rounds can exhaust node storage.

## Likelihood Explanation

**High Likelihood:**
- Any validator can execute this attack without special privileges
- No cryptographic attacks or consensus collusion required
- Attack is deterministic and repeatable
- Large validator sets (thousands of validators) increase amplification potential
- Network message limit (64 MB) is sufficiently large to enable significant amplification

The attack becomes more effective as the validator set grows larger, which is expected as the network scales.

## Recommendation

Add validation for the total BCS-encoded size of the entire Node structure before storage, or add explicit limits on parent certificate count and size:

```rust
fn validate(&self, node: Node) -> anyhow::Result<Node> {
    // ... existing validation ...
    
    // NEW: Validate parent certificates size
    let parent_certs_size = node.parents().iter()
        .map(|cert| bcs::serialized_size(cert).unwrap_or(0))
        .sum::<usize>() as u64;
    
    // NEW: Validate total node size including parents
    let total_size = txn_bytes + parent_certs_size;
    ensure!(
        total_size <= self.payload_config.max_receiving_size_per_round_bytes,
        "Total node size {} exceeds limit {}",
        total_size,
        self.payload_config.max_receiving_size_per_round_bytes
    );
    
    // Alternative: Limit number of parents
    let min_required_parents = calculate_min_parents(&self.epoch_state.verifier);
    ensure!(
        node.parents().len() <= min_required_parents * 2,
        "Excessive parent certificates: {} (max allowed: {})",
        node.parents().len(),
        min_required_parents * 2
    );
    
    // ... rest of validation ...
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod storage_amplification_attack {
    use super::*;
    use aptos_types::validator_verifier::ValidatorVerifier;
    
    #[test]
    fn test_parent_certificate_amplification() {
        // Setup: Create validator set with 10,000 validators
        let num_validators = 10_000;
        let verifier = create_test_validator_verifier(num_validators);
        
        // Step 1: Create minimal payload (1 MB)
        let payload = create_test_payload(1_000_000);
        let payload_size = payload.size();
        assert_eq!(payload_size, 1_000_000);
        
        // Step 2: Create parent certificates for ALL validators
        // (instead of just required 2f+1 = ~6,667)
        let parents = create_all_validator_parents(&verifier, 1);
        assert_eq!(parents.len(), num_validators);
        
        // Step 3: Create node
        let node = Node::new(
            1,     // epoch
            2,     // round
            author,
            timestamp,
            vec![], // validator_txns
            payload,
            parents,
            Extensions::Empty,
        );
        
        // Step 4: Node passes validation (only checks payload!)
        let validation_result = validate_node(&node, &config);
        assert!(validation_result.is_ok());
        
        // Step 5: Calculate BCS-encoded size
        let bcs_encoded = bcs::to_bytes(&node).unwrap();
        let actual_storage_size = bcs_encoded.len();
        
        // Step 6: Demonstrate amplification
        let validated_size = payload_size;
        let amplification_factor = actual_storage_size as f64 / validated_size as f64;
        
        println!("Validated size: {} MB", validated_size / 1_000_000);
        println!("Actual storage: {} MB", actual_storage_size / 1_000_000);
        println!("Amplification: {}x", amplification_factor);
        
        // With 10K validators, each parent ~8.4 KB:
        // Parents size = 10,000 * 8,400 = 84 MB
        // Total size = 1 MB + 84 MB = 85 MB
        // Amplification = 85x
        assert!(amplification_factor > 3.0, 
            "Storage amplification attack successful: {}x amplification", 
            amplification_factor);
    }
}
```

## Notes

The vulnerability is exacerbated by:
1. Large validator sets approaching the maximum (65,536 validators)
2. Lack of economic disincentives for bloated nodes
3. No monitoring or alerting for nodes with excessive parent certificates
4. BCS encoding preserves full `BitVec` sizes regardless of bit density

The fix should be implemented at the validation layer before storage occurs, as post-storage detection would still waste resources.

### Citations

**File:** consensus/src/dag/rb_handler.rs (L112-143)
```rust
    fn validate(&self, node: Node) -> anyhow::Result<Node> {
        ensure!(
            node.epoch() == self.epoch_state.epoch,
            "different epoch {}, current {}",
            node.epoch(),
            self.epoch_state.epoch
        );

        let num_vtxns = node.validator_txns().len() as u64;
        ensure!(num_vtxns <= self.vtxn_config.per_block_limit_txn_count());
        for vtxn in node.validator_txns() {
            let vtxn_type_name = vtxn.type_name();
            ensure!(
                is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                "unexpected validator transaction: {:?}",
                vtxn_type_name
            );
            vtxn.verify(self.epoch_state.verifier.as_ref())
                .context(format!("{} verification failed", vtxn_type_name))?;
        }
        let vtxn_total_bytes = node
            .validator_txns()
            .iter()
            .map(ValidatorTransaction::size_in_bytes)
            .sum::<usize>() as u64;
        ensure!(vtxn_total_bytes <= self.vtxn_config.per_block_limit_total_bytes());

        let num_txns = num_vtxns + node.payload().len() as u64;
        let txn_bytes = vtxn_total_bytes + node.payload().size() as u64;
        ensure!(num_txns <= self.payload_config.max_receiving_txns_per_round);
        ensure!(txn_bytes <= self.payload_config.max_receiving_size_per_round_bytes);

```

**File:** consensus/src/dag/types.rs (L152-159)
```rust
#[derive(Clone, Serialize, Deserialize, CryptoHasher, Debug, PartialEq)]
pub struct Node {
    metadata: NodeMetadata,
    validator_txns: Vec<ValidatorTransaction>,
    payload: Payload,
    parents: Vec<NodeCertificate>,
    extensions: Extensions,
}
```

**File:** consensus/src/dag/types.rs (L329-340)
```rust
        // Verification of the certificate is delayed until we need to fetch it
        ensure!(
            verifier
                .check_voting_power(
                    self.parents()
                        .iter()
                        .map(|parent| parent.metadata().author()),
                    true,
                )
                .is_ok(),
            "not enough parents to satisfy voting power"
        );
```

**File:** types/src/aggregate_signature.rs (L15-19)
```rust
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, CryptoHasher, BCSCryptoHash)]
pub struct AggregateSignature {
    validator_bitmask: BitVec,
    sig: Option<bls12381::Signature>,
}
```

**File:** crates/aptos-bitvec/src/lib.rs (L18-20)
```rust
// Every u8 is used as a bucket of 8 bits. Total max buckets = 65536 / 8 = 8192.
const BUCKET_SIZE: usize = 8;
const MAX_BUCKETS: usize = 8192;
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L100-100)
```text
    const MAX_VALIDATOR_SET_SIZE: u64 = 65536;
```

**File:** consensus/src/consensusdb/schema/dag/mod.rs (L35-43)
```rust
impl ValueCodec<NodeSchema> for Node {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}
```
