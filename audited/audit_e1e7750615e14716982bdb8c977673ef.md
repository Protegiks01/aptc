# Audit Report

## Title
Silent Storage Commit Failures Allow Consensus Safety Violations Through ExecutorError Dropping

## Summary
The Aptos consensus pipeline silently drops `ExecutorError` instances when blocks fail to commit to storage, allowing validators to continue consensus operations despite having divergent ledger states. This breaks consensus safety guarantees and can lead to double-spending and loss of funds.

## Finding Description

The vulnerability exists in the block commitment pipeline where storage errors are silently discarded at multiple levels:

**Critical Path 1 - Silent Discard in `wait_for_commit_ledger()`:**

The `wait_for_commit_ledger()` function explicitly ignores the result of the commit operation: [1](#0-0) 

When `commit_ledger_fut.await` returns an error (wrapped as `TaskError::InternalError` from underlying `ExecutorError`), it is completely discarded with `let _ = ...`.

**Critical Path 2 - Persisting Phase Always Returns Success:**

The persisting phase calls `wait_for_commit_ledger()` but always returns `Ok(round)` regardless of whether commits succeeded: [2](#0-1) 

**Critical Path 3 - Underlying Storage Errors Are Real:**

The actual `commit_ledger` operation can fail with `ExecutorError` when database operations fail: [3](#0-2) 

At line 388-390, the database writer's `commit_ledger` call can return storage errors that propagate as `ExecutorError`.

**Critical Path 4 - Buffer Manager Pattern Matching:**

While the buffer manager pattern matches on `Some(Ok(round))`, it would never receive errors because the persisting phase always returns success: [4](#0-3) 

**The Attack Sequence:**

1. Storage subsystem encounters an error (disk full, I/O failure, database corruption)
2. `executor.commit_ledger()` returns `Err(ExecutorError::InternalError{...})`
3. This error propagates through the pipeline as `TaskError::InternalError`
4. `wait_for_commit_ledger()` discards this error completely
5. Persisting phase returns `Ok(round)` to buffer manager
6. Buffer manager updates `highest_committed_round` and continues consensus
7. **Validator believes block is committed but data is NOT in storage**
8. If some validators successfully commit while others fail, ledger states diverge
9. Validators with failed commits continue voting on subsequent blocks
10. Network operates with inconsistent ledger states across validators

This violates the **Consensus Safety** invariant: "AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine" and the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

## Impact Explanation

**Critical Severity** - This vulnerability meets multiple critical impact criteria from the Aptos bug bounty:

1. **Consensus/Safety Violations**: The core consensus safety guarantee is broken. Validators can have divergent committed states, allowing:
   - Different validators to report different transaction outcomes for the same block
   - Clients querying different validators to see conflicting ledger states
   - Potential for double-spending if some validators commit a transaction while others don't

2. **Loss of Funds**: If a validator fails to commit blocks containing withdrawals but continues voting, those withdrawals may be accepted by the network while the validator's local state shows different balances. This can lead to:
   - Users believing transactions were successful when they weren't durably persisted
   - Validators with incomplete ledger states making incorrect state transition decisions
   - Potential for fund loss during epoch transitions or state sync operations

3. **Non-recoverable Network Partition**: Once validators have divergent committed states, recovering consensus requires manual intervention or state sync from correct validators. If a supermajority experiences storage failures, the network could reach an irrecoverable state.

The issue is particularly severe because:
- Storage failures are silent - no alerts or panics occur
- Failed validators continue participating in consensus
- The divergence compounds over time as more blocks are processed
- Detection requires manual comparison of ledger states across validators

## Likelihood Explanation

**High Likelihood** - Storage failures are common in production systems:

1. **Natural Occurrence**: Disk full conditions, I/O errors, and database corruption occur regularly in distributed systems operating at scale

2. **No Special Privileges Required**: An attacker doesn't need validator access - they just need to trigger storage conditions that cause commit failures (e.g., filling disk space through state bloat attacks)

3. **Easy to Trigger**: The fail_point infrastructure already exists in the codebase for testing commit failures: [5](#0-4) 

4. **Silent Propagation**: The error handling in the execution path logs errors but doesn't halt consensus: [6](#0-5) 

The `log_executor_error_occurred` function only logs warnings and increments counters - it doesn't prevent consensus from continuing.

5. **Realistic Scenarios**:
   - Disk space exhaustion on validator nodes
   - Database file corruption from hardware failures
   - I/O timeouts during high load
   - Race conditions in storage layer during epoch transitions

## Recommendation

**Immediate Fix**: Propagate storage commit errors to halt consensus when commits fail.

**Fix for `wait_for_commit_ledger()`:**
```rust
pub async fn wait_for_commit_ledger(&self) -> Result<(), TaskError> {
    if let Some(fut) = self.pipeline_futs() {
        fut.commit_ledger_fut.await?;
    }
    Ok(())
}
```

**Fix for Persisting Phase:**
```rust
async fn process(&self, req: PersistingRequest) -> PersistingResponse {
    let PersistingRequest {
        blocks,
        commit_ledger_info,
    } = req;

    for b in &blocks {
        if let Some(tx) = b.pipeline_tx().lock().as_mut() {
            tx.commit_proof_tx
                .take()
                .map(|tx| tx.send(commit_ledger_info.clone()));
        }
        // Propagate commit errors instead of silently dropping them
        b.wait_for_commit_ledger().await
            .map_err(|e| ExecutorError::InternalError { 
                error: format!("Commit ledger failed: {}", e) 
            })?;
    }

    let response = Ok(blocks.last().expect("Blocks can't be empty").round());
    if commit_ledger_info.ledger_info().ends_epoch() {
        self.commit_msg_tx
            .send_epoch_change(EpochChangeProof::new(vec![commit_ledger_info], false))
            .await;
    }
    response
}
```

**Fix for Buffer Manager Error Handling:**
```rust
Some(result) = self.persisting_phase_rx.next() => {
    match result {
        Ok(round) => {
            self.pending_commit_votes = self.pending_commit_votes.split_off(&(round + 1));
            self.highest_committed_round = round;
            self.pending_commit_blocks = self.pending_commit_blocks.split_off(&(round + 1));
        },
        Err(e) => {
            error!("Critical: Persisting phase failed: {:?}", e);
            log_executor_error_occurred(
                e,
                &counters::PIPELINE_DISCARDED_EXECUTOR_ERROR_COUNT,
                HashValue::zero(),
            );
            // Halt consensus - storage commit failures are unrecoverable
            panic!("Storage commit failure - cannot continue consensus safely");
        }
    }
}
```

**Additional Recommendations:**

1. Add monitoring alerts for `BUFFER_MANAGER_RECEIVED_EXECUTOR_ERROR_COUNT` and `PIPELINE_DISCARDED_EXECUTOR_ERROR_COUNT` metrics

2. Implement pre-commit storage health checks before attempting commits

3. Add explicit panic/halt on critical storage errors rather than silent continuation

4. Review all other locations where `ExecutorError` is handled to ensure critical errors are never silently dropped

## Proof of Concept

```rust
// Test demonstrating silent storage failure
#[tokio::test]
async fn test_silent_commit_failure() {
    use fail::FailScenario;
    
    // Setup consensus pipeline with real storage
    let (executor, mut buffer_manager) = setup_test_pipeline();
    
    // Enable fail point to inject storage error
    let scenario = FailScenario::setup();
    fail::cfg("executor::commit_blocks", "return").unwrap();
    
    // Create and order blocks
    let blocks = create_test_blocks(3);
    let ordered_proof = create_test_ledger_info(&blocks);
    
    // Send blocks through pipeline
    buffer_manager.process_ordered_blocks(OrderedBlocks {
        ordered_blocks: blocks.clone(),
        ordered_proof: ordered_proof.clone(),
    }).await;
    
    // Wait for execution and signing
    tokio::time::sleep(Duration::from_secs(1)).await;
    
    // Verify: Buffer manager advanced highest_committed_round
    assert!(buffer_manager.highest_committed_round > 0);
    
    // Verify: But storage does NOT contain the blocks
    let db_version = executor.db.reader.get_latest_version().unwrap();
    assert_eq!(db_version, 0); // Storage unchanged!
    
    // Verify: No panic occurred - consensus continued silently
    // This demonstrates the vulnerability: consensus thinks blocks are
    // committed but they are not in storage
    
    scenario.teardown();
}
```

**Notes:**

The vulnerability is exacerbated by the fact that execution errors in earlier phases (execution_response handling) are logged but also allow consensus to continue: [7](#0-6) 

This pattern of logging-and-continuing for critical errors creates multiple failure points where consensus safety can be violated.

### Citations

**File:** consensus/consensus-types/src/pipelined_block.rs (L562-568)
```rust
    pub async fn wait_for_commit_ledger(&self) {
        // may be aborted (e.g. by reset)
        if let Some(fut) = self.pipeline_futs() {
            // this may be cancelled
            let _ = fut.commit_ledger_fut.await;
        }
    }
```

**File:** consensus/src/pipeline/persisting_phase.rs (L59-82)
```rust
    async fn process(&self, req: PersistingRequest) -> PersistingResponse {
        let PersistingRequest {
            blocks,
            commit_ledger_info,
        } = req;

        for b in &blocks {
            if let Some(tx) = b.pipeline_tx().lock().as_mut() {
                tx.commit_proof_tx
                    .take()
                    .map(|tx| tx.send(commit_ledger_info.clone()));
            }
            b.wait_for_commit_ledger().await;
        }

        let response = Ok(blocks.last().expect("Blocks can't be empty").round());
        if commit_ledger_info.ledger_info().ends_epoch() {
            self.commit_msg_tx
                .send_epoch_change(EpochChangeProof::new(vec![commit_ledger_info], false))
                .await;
        }
        response
    }
}
```

**File:** execution/executor/src/block_executor/mod.rs (L362-395)
```rust
    fn commit_ledger(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) -> ExecutorResult<()> {
        let _timer = OTHER_TIMERS.timer_with(&["commit_ledger"]);

        let block_id = ledger_info_with_sigs.ledger_info().consensus_block_id();
        info!(
            LogSchema::new(LogEntry::BlockExecutor).block_id(block_id),
            "commit_ledger"
        );

        // Check for any potential retries
        // TODO: do we still have such retries?
        let committed_block = self.block_tree.root_block();
        if committed_block.num_persisted_transactions()?
            == ledger_info_with_sigs.ledger_info().version() + 1
        {
            return Ok(());
        }

        // Confirm the block to be committed is tracked in the tree.
        self.block_tree.get_block(block_id)?;

        fail_point!("executor::commit_blocks", |_| {
            Err(anyhow::anyhow!("Injected error in commit_blocks.").into())
        });

        let target_version = ledger_info_with_sigs.ledger_info().version();
        self.db
            .writer
            .commit_ledger(target_version, Some(&ledger_info_with_sigs), None)?;

        self.block_tree.prune(ledger_info_with_sigs.ledger_info())?;

        Ok(())
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L617-627)
```rust
        let executed_blocks = match inner {
            Ok(result) => result,
            Err(e) => {
                log_executor_error_occurred(
                    e,
                    &counters::BUFFER_MANAGER_RECEIVED_EXECUTOR_ERROR_COUNT,
                    block_id,
                );
                return;
            },
        };
```

**File:** consensus/src/pipeline/buffer_manager.rs (L968-973)
```rust
                Some(Ok(round)) = self.persisting_phase_rx.next() => {
                    // see where `need_backpressure()` is called.
                    self.pending_commit_votes = self.pending_commit_votes.split_off(&(round + 1));
                    self.highest_committed_round = round;
                    self.pending_commit_blocks = self.pending_commit_blocks.split_off(&(round + 1));
                },
```

**File:** consensus/src/counters.rs (L1184-1212)
```rust
pub fn log_executor_error_occurred(
    e: ExecutorError,
    counter: &Lazy<IntCounterVec>,
    block_id: HashValue,
) {
    match e {
        ExecutorError::CouldNotGetData => {
            counter.with_label_values(&["CouldNotGetData"]).inc();
            warn!(
                block_id = block_id,
                "Execution error - CouldNotGetData {}", block_id
            );
        },
        ExecutorError::BlockNotFound(block_id) => {
            counter.with_label_values(&["BlockNotFound"]).inc();
            warn!(
                block_id = block_id,
                "Execution error BlockNotFound {}", block_id
            );
        },
        e => {
            counter.with_label_values(&["UnexpectedError"]).inc();
            warn!(
                block_id = block_id,
                "Execution error {:?} for {}", e, block_id
            );
        },
    }
}
```
