# Audit Report

## Title
Lack of Atomic Startup and Cleanup in Network Component Initialization Leading to Partial System State

## Summary
The `NetworkBuilder::start()` function spawns network components sequentially without error handling or rollback mechanisms. If the `ConnectivityManager` or `HealthChecker` fail to start after `PeerManager` has already been spawned, the `PeerManager` continues accepting connections without proper connectivity management or health monitoring, violating system invariants about resource limits and connection policies.

## Finding Description

The `NetworkBuilder::start()` method starts network components in sequence without any transactional guarantees or cleanup on failure: [1](#0-0) 

The startup sequence is:
1. State immediately set to `STARTED` (line 253)
2. PeerManager spawned via `executor.spawn()` (line 256)  
3. ConnectivityManager spawned if present (line 263)
4. HealthChecker spawned if present (line 271)
5. Discovery listeners started (line 278-282)

Each component is spawned as an independent task. The `ConnectivityManager` builder's start method can panic: [2](#0-1) 

Additionally, the `ConnectivityManager` event loop contains `unwrap()` calls that can panic if channels are unexpectedly closed: [3](#0-2) 

**Failure Scenarios:**
1. **Builder panic**: If `ConnectivityManagerBuilder.connectivity_manager` is `None`, the `.expect()` panics, leaving PeerManager running
2. **Runtime panic**: If oneshot channel receivers are dropped before sending responses, `unwrap()` panics  
3. **Early task exit**: If the spawned task encounters an error during initialization

When `PeerManager` runs without `ConnectivityManager`:
- The PeerManager accepts connections via its listener: [4](#0-3) 

- But there is no connectivity enforcement. The ConnectivityManager is responsible for enforcing connection policies and limits, as documented in the codebase.

The `ConnectivityManager` enforces critical network policies including peer eligibility, connection limits, and disconnecting ineligible peers. Without it running, these protections are absent while the PeerManager continues accepting connections.

## Impact Explanation

**High Severity** - This issue meets the "Significant protocol violations" category per Aptos bug bounty criteria.

**Security impacts of PeerManager running without ConnectivityManager:**
- **Connection limit bypass**: The `outbound_connection_limit` configured for fullnodes is not enforced, allowing unlimited connections
- **Ineligible peer persistence**: Peers removed from the trusted set are not disconnected
- **Resource exhaustion**: Without connection limits, an attacker could open many connections to exhaust node resources (memory, file descriptors, CPU)
- **Network policy violations**: Discovery updates and peer eligibility checks are not processed

**Security impacts without HealthChecker:**
- Dead connections accumulate without cleanup
- Connection pool fills with unresponsive peers
- Network quality degrades over time

## Likelihood Explanation

**Medium likelihood** - While the condition requires a runtime failure, several realistic triggers exist:

1. **Programming bugs**: Any bug causing panic in ConnectivityManager initialization or event loop
2. **Channel lifecycle issues**: Receivers dropped before responses sent causes unwrap() panics in request handlers
3. **Resource pressure**: Under extreme resource contention, tasks may fail to initialize properly
4. **State machine violations**: Although state checks exist, concurrent access or bugs could violate assumptions

The lack of defensive programming (error handling, health checks, rollback) means any failure in component initialization results in this vulnerable state.

## Recommendation

Implement atomic startup with proper error handling and rollback:

```rust
pub fn start(&mut self) -> Result<&mut Self, NetworkError> {
    assert_eq!(self.state, State::BUILT);
    
    let executor = self.executor.as_mut().expect("Executor must exist");
    
    // Start peer manager and store handle for potential cleanup
    self.peer_manager_builder.start(executor);
    let peer_manager_started = true;
    
    // Start connectivity manager with error handling
    if let Some(conn_mgr_builder) = self.connectivity_manager_builder.as_mut() {
        if let Err(e) = conn_mgr_builder.try_start(executor) {
            // Rollback: shutdown peer manager
            if peer_manager_started {
                self.shutdown_peer_manager();
            }
            return Err(NetworkError::ConnectivityManagerStartFailed(e));
        }
    }
    
    // Start health checker with error handling
    if let Some(health_checker_builder) = self.health_checker_builder.as_mut() {
        if let Err(e) = health_checker_builder.try_start(executor) {
            // Rollback: shutdown already-started components
            self.shutdown_peer_manager();
            self.shutdown_connectivity_manager();
            return Err(NetworkError::HealthCheckerStartFailed(e));
        }
    }
    
    // Only set STARTED after all components successfully started
    self.state = State::STARTED;
    
    // Start discovery listeners
    if let Some(discovery_listeners) = self.discovery_listeners.take() {
        discovery_listeners
            .into_iter()
            .for_each(|listener| listener.start(executor))
    }
    
    Ok(self)
}
```

Additionally:
1. Change builder `start()` methods to return `Result<(), Error>` instead of void
2. Store `JoinHandle`s from `executor.spawn()` calls for health monitoring
3. Implement periodic health checks to detect failed components
4. Add graceful shutdown methods for each component

## Proof of Concept

```rust
// Reproduction: Simulate ConnectivityManager panic during start

#[tokio::test]
async fn test_partial_start_failure() {
    // Setup network builder
    let mut builder = NetworkBuilder::create(/* ... */);
    builder.build(executor);
    
    // Inject fault: Drop connectivity_manager to cause panic
    // In real scenario, this could be a runtime panic in event loop
    builder.connectivity_manager_builder
        .as_mut()
        .unwrap()
        .connectivity_manager = None;
    
    // This will panic on conn_mgr_builder.start() due to .expect()
    // but PeerManager is already running
    let result = std::panic::catch_unwind(AssertUnwindSafe(|| {
        builder.start();
    }));
    
    assert!(result.is_err()); // Panic occurred
    
    // Verify PeerManager is still accepting connections
    // while ConnectivityManager never started
    let test_peer = connect_to_peer(builder.listen_address()).await;
    assert!(test_peer.is_ok()); // Connection accepted
    
    // Verify no connection limit enforcement
    let mut connections = vec![];
    for _ in 0..1000 {  // Far beyond configured limit
        let conn = connect_to_peer(builder.listen_address()).await;
        assert!(conn.is_ok()); // All accepted without limit
        connections.push(conn.unwrap());
    }
    
    // This demonstrates resource exhaustion vulnerability
}
```

## Notes

This is an architectural vulnerability in the startup orchestration logic. While it requires a trigger condition (panic, resource exhaustion, or bug), the lack of defensive programming means the system enters an inconsistent state where critical network protections are absent. The vulnerability violates the "Resource Limits" invariant that all operations must respect configured limits, as connection limits are not enforced when ConnectivityManager fails to start while PeerManager continues running.

### Citations

**File:** network/builder/src/builder.rs (L251-284)
```rust
    pub fn start(&mut self) -> &mut Self {
        assert_eq!(self.state, State::BUILT);
        self.state = State::STARTED;

        let executor = self.executor.as_mut().expect("Executor must exist");
        self.peer_manager_builder.start(executor);
        debug!(
            NetworkSchema::new(&self.network_context),
            "{} Started peer manager", self.network_context
        );

        if let Some(conn_mgr_builder) = self.connectivity_manager_builder.as_mut() {
            conn_mgr_builder.start(executor);
            debug!(
                NetworkSchema::new(&self.network_context),
                "{} Started conn manager", self.network_context
            );
        }

        if let Some(health_checker_builder) = self.health_checker_builder.as_mut() {
            health_checker_builder.start(executor);
            debug!(
                NetworkSchema::new(&self.network_context),
                "{} Started health checker", self.network_context
            );
        }

        if let Some(discovery_listeners) = self.discovery_listeners.take() {
            discovery_listeners
                .into_iter()
                .for_each(|listener| listener.start(executor))
        }
        self
    }
```

**File:** network/framework/src/connectivity_manager/builder.rs (L68-74)
```rust
    pub fn start(&mut self, executor: &Handle) {
        let conn_mgr = self
            .connectivity_manager
            .take()
            .expect("Service Must be present");
        executor.spawn(conn_mgr.start());
    }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L875-880)
```rust
            ConnectivityRequest::GetDialQueueSize(sender) => {
                sender.send(self.dial_queue.len()).unwrap();
            },
            ConnectivityRequest::GetConnectedSize(sender) => {
                sender.send(self.connected.len()).unwrap();
            },
```

**File:** network/framework/src/peer_manager/mod.rs (L232-260)
```rust
    pub async fn start(mut self) {
        // Start listening for connections.
        info!(
            NetworkSchema::new(&self.network_context),
            "Start listening for incoming connections on {}", self.listen_addr
        );
        self.start_connection_listener();
        loop {
            ::futures::select! {
                connection_event = self.transport_notifs_rx.select_next_some() => {
                    self.handle_connection_event(connection_event);
                }
                connection_request = self.connection_reqs_rx.select_next_some() => {
                    self.handle_outbound_connection_request(connection_request).await;
                }
                request = self.requests_rx.select_next_some() => {
                    self.handle_outbound_request(request).await;
                }
                complete => {
                    break;
                }
            }
        }

        warn!(
            NetworkSchema::new(&self.network_context),
            "PeerManager actor terminated"
        );
    }
```
