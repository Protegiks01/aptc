# Audit Report

## Title
State Query Failure in TreeOnly Restore Mode: Missing KV Data Causes Inconsistent Query Responses Despite Valid Merkle Tree Structure

## Summary
In `StateSnapshotRestoreMode::TreeOnly` mode, the Jellyfish Merkle Tree structure is restored without writing the actual key-value data to `state_kv_db`. This creates a critical inconsistency where Merkle proof queries succeed (proving data exists), but state value queries fail (returning 404), violating the fundamental state consistency invariant that proofs and values must match.

## Finding Description

The state restore mechanism in Aptos supports three modes: `Default`, `KvOnly`, and `TreeOnly`. The vulnerability lies in the TreeOnly mode implementation: [1](#0-0) 

When processing state chunks in TreeOnly mode, only the tree restoration function is executed: [2](#0-1) 

The `kv_fn()` which writes actual KV data via `StateValueRestore::add_chunk()` is **never called** in TreeOnly mode. This means the state values are never written to the `state_kv_db`: [3](#0-2) 

Subsequently, when state value queries are performed, they query the `state_kv_db` directly: [4](#0-3) 

If the KV data doesn't exist (due to TreeOnly restore), the query returns `None`. The API layer interprets this as "resource not found": [5](#0-4) 

However, Merkle proof queries still work because they query the tree structure (which WAS restored): [6](#0-5) 

**Attack Scenario:**
1. Operator performs database restore from backup
2. TreeOnly restore phase completes at version V (tree structure written)
3. Process is interrupted before transaction replay phase (KV data not written)
4. Due to a bug or misconfiguration, restore-complete marker is created
5. Node starts serving queries with inconsistent state:
   - State value query for resource X → 404 "Not Found"
   - Merkle proof query for resource X → Valid proof showing resource exists
6. Clients receive contradictory information, causing application failures
7. If a validator node is in this state, it cannot properly validate transactions that depend on state reads

This breaks **Critical Invariant #4 (State Consistency)**: "State transitions must be atomic and verifiable via Merkle proofs" - specifically, the guarantee that if a Merkle proof proves data exists at a given version, querying that data must return the value, not "not found".

## Impact Explanation

**High Severity** - This qualifies as a "Significant protocol violation" under the Aptos bug bounty criteria:

1. **Query Service Degradation**: Nodes in this state cannot serve state queries correctly, returning false negatives for existing data
2. **Client Application Failures**: Applications relying on state queries receive incorrect "not found" responses, causing transaction failures and incorrect business logic
3. **Validator Impact**: If a validator enters this state, it cannot properly execute transactions that read state, potentially causing consensus disagreement or transaction failures
4. **State Inconsistency**: Creates a fundamental violation where proofs and values don't match, undermining the integrity of the state commitment scheme
5. **Difficult Detection**: The node appears healthy (tree root hash is correct, proofs validate), but is silently failing queries

While this doesn't directly cause fund loss or consensus safety violations (validators would fail to execute transactions rather than execute them incorrectly), it represents a significant protocol violation that degrades node functionality and could cascade into broader network issues.

## Likelihood Explanation

**Medium Likelihood** - This issue can occur through several realistic scenarios:

1. **Interrupted Restore**: The backup restore process uses TreeOnly mode as an intermediate step. If the process crashes or is killed after TreeOnly restore but before transaction replay completes, the node could be left in an inconsistent state.

2. **Restore Coordinator Bug**: If there's a bug in the restore coordinator logic that creates the restore-complete marker prematurely (after TreeOnly restore but before transaction replay), the node would start serving queries in an inconsistent state.

3. **Manual Configuration Error**: An operator manually using TreeOnly mode without understanding the requirement for subsequent transaction replay.

4. **Race Condition**: A timing issue where the node begins accepting queries after TreeOnly restore but before `sync_commit_progress` runs on startup to detect and fix the inconsistency.

The normal restore flow includes safeguards (transaction replay follows TreeOnly restore, sync_commit_progress on startup), but operational errors, crashes at inopportune times, or bugs in the restore orchestration could trigger this vulnerability.

## Recommendation

Implement validation checks to prevent serving queries when KV data is missing:

1. **Add KV Data Completeness Check**: Before marking a node as ready to serve queries, verify that `state_kv_commit_progress` matches or exceeds the `state_merkle_max_version`:

```rust
// In StateStore::new or during readiness checks
pub fn validate_state_consistency(&self) -> Result<()> {
    let state_kv_commit_progress = self.state_kv_db
        .metadata_db()
        .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)?
        .map(|v| v.expect_version())
        .unwrap_or(0);
    
    let state_merkle_max_version = get_max_version_in_state_merkle_db(&self.state_merkle_db)?
        .unwrap_or(0);
    
    ensure!(
        state_kv_commit_progress >= state_merkle_max_version,
        "State KV data incomplete: kv_progress={}, tree_version={}. Cannot serve queries.",
        state_kv_commit_progress,
        state_merkle_max_version
    );
    Ok(())
}
```

2. **Strengthen sync_commit_progress**: Make it more aggressive about detecting and fixing tree-ahead-of-KV inconsistencies: [7](#0-6) 

Add explicit check that tree version doesn't exceed KV commit progress by more than expected difference.

3. **TreeOnly Mode Warning**: Add documentation and runtime warnings that TreeOnly mode requires subsequent KV population and should only be used as part of a complete restore workflow.

4. **Atomic Restore Completion**: Ensure the restore-complete marker is only created after ALL phases complete (TreeOnly + transaction replay), with explicit validation.

## Proof of Concept

```rust
// Reproduction steps (pseudo-code demonstrating the vulnerability):

use aptos_db::AptosDB;
use aptos_storage_interface::{DbReader, StateSnapshotReceiver};
use aptos_types::state_store::state_key::StateKey;

#[test]
fn test_tree_only_query_failure() {
    // Setup: Initialize a fresh database
    let db = AptosDB::new_for_test(...);
    
    // Prepare state snapshot data
    let version = 100;
    let state_key = StateKey::resource(...);
    let state_value = StateValue::new(...);
    let chunk = vec![(state_key.clone(), state_value.clone())];
    let proof = SparseMerkleRangeProof::new(...);
    
    // Step 1: Perform TreeOnly restore
    let mut restore = StateSnapshotRestore::new(
        &db.state_merkle_db,
        &db.state_store,
        version,
        expected_root_hash,
        false, // async_commit
        StateSnapshotRestoreMode::TreeOnly, // TREE ONLY - no KV data written
    ).unwrap();
    
    restore.add_chunk(chunk.clone(), proof).unwrap();
    restore.finish().unwrap();
    
    // Step 2: Verify tree structure exists (proof query works)
    let tree_proof = db.get_state_proof_by_version_ext(
        &state_key.hash(),
        version,
        0,
        false
    ).unwrap();
    assert!(tree_proof.verify(expected_root_hash).is_ok()); // SUCCEEDS
    
    // Step 3: Attempt to query state value (should fail - KV data missing)
    let value_result = db.get_state_value_by_version(&state_key, version).unwrap();
    assert!(value_result.is_none()); // FAILS - returns None even though tree proves it exists!
    
    // This demonstrates the inconsistency:
    // - Merkle proof proves the data exists
    // - Value query returns "not found"
    // - Violates state consistency invariant
}
```

**Notes**

This vulnerability is particularly insidious because:
1. The node's state root hash is correct and validates properly
2. Merkle proofs are valid and verify correctly
3. But actual value queries fail, creating a "phantom state" situation
4. The normal restore workflow includes safeguards (transaction replay), but edge cases (crashes, bugs, manual operations) can bypass them
5. The `sync_commit_progress` startup check provides some protection by truncating inconsistent state, but there may be windows where queries are served before this check runs
6. This represents a fundamental violation of the state consistency guarantee that proof verification and value retrieval must be consistent

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L49-57)
```rust
#[derive(Clone, Copy, Deserialize, Serialize, PartialEq, Eq)]
pub enum StateSnapshotRestoreMode {
    /// Restore both KV and Tree by default
    Default,
    /// Only restore the state KV
    KvOnly,
    /// Only restore the state tree
    TreeOnly,
}
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L88-127)
```rust
    pub fn add_chunk(&mut self, mut chunk: Vec<(K, V)>) -> Result<()> {
        // load progress
        let progress_opt = self.db.get_progress(self.version)?;

        // skip overlaps
        if let Some(progress) = progress_opt {
            let idx = chunk
                .iter()
                .position(|(k, _v)| CryptoHash::hash(k) > progress.key_hash)
                .unwrap_or(chunk.len());
            chunk = chunk.split_off(idx);
        }

        // quit if all skipped
        if chunk.is_empty() {
            return Ok(());
        }

        // save
        let mut usage = progress_opt.map_or(StateStorageUsage::zero(), |p| p.usage);
        let (last_key, _last_value) = chunk.last().unwrap();
        let last_key_hash = CryptoHash::hash(last_key);

        // In case of TreeOnly Restore, we only restore the usage of KV without actually writing KV into DB
        for (k, v) in chunk.iter() {
            usage.add_item(k.key_size() + v.value_size());
        }

        // prepare the sharded kv batch
        let kv_batch: StateValueBatch<K, Option<V>> = chunk
            .into_iter()
            .map(|(k, v)| ((k, self.version), Some(v)))
            .collect();

        self.db.write_kv_batch(
            self.version,
            &kv_batch,
            StateSnapshotProgress::new(last_key_hash, usage),
        )
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L246-255)
```rust
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => kv_fn()?,
            StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
        }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L374-402)
```rust
    pub(crate) fn get_state_value_with_version_by_version(
        &self,
        state_key: &StateKey,
        version: Version,
    ) -> Result<Option<(Version, StateValue)>> {
        let mut read_opts = ReadOptions::default();

        // We want `None` if the state_key changes in iteration.
        read_opts.set_prefix_same_as_start(true);
        if !self.enabled_sharding() {
            let mut iter = self
                .db_shard(state_key.get_shard_id())
                .iter_with_opts::<StateValueSchema>(read_opts)?;
            iter.seek(&(state_key.clone(), version))?;
            Ok(iter
                .next()
                .transpose()?
                .and_then(|((_, version), value_opt)| value_opt.map(|value| (version, value))))
        } else {
            let mut iter = self
                .db_shard(state_key.get_shard_id())
                .iter_with_opts::<StateValueByKeyHashSchema>(read_opts)?;
            iter.seek(&(state_key.hash(), version))?;
            Ok(iter
                .next()
                .transpose()?
                .and_then(|((_, version), value_opt)| value_opt.map(|value| (version, value))))
        }
    }
```

**File:** api/src/state.rs (L289-304)
```rust
        let bytes = state_view
            .as_converter(self.context.db.clone(), self.context.indexer_reader.clone())
            .find_resource(&state_view, address, &tag)
            .context(format!(
                "Failed to query DB to check for {} at {}",
                tag.to_canonical_string(),
                address
            ))
            .map_err(|err| {
                BasicErrorWith404::internal_with_code(
                    err,
                    AptosErrorCode::InternalError,
                    &ledger_info,
                )
            })?
            .ok_or_else(|| resource_not_found(address, &tag, ledger_version, &ledger_info))?;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L184-206)
```rust
    /// Returns the proof of the given state key and version.
    fn get_state_proof_by_version_ext(
        &self,
        key_hash: &HashValue,
        version: Version,
        root_depth: usize,
        use_hot_state: bool,
    ) -> Result<SparseMerkleProofExt> {
        let db = if use_hot_state {
            if self.state_merkle_db.sharding_enabled() {
                self.hot_state_merkle_db
                    .as_ref()
                    .ok_or(AptosDbError::HotStateError)?
            } else {
                // Unsharded unit tests still rely on this.
                &self.state_merkle_db
            }
        } else {
            &self.state_merkle_db
        };
        let (_, proof) = db.get_with_proof_ext(key_hash, version, root_depth)?;
        Ok(proof)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```
