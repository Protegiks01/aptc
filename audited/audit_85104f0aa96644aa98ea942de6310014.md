# Audit Report

## Title
Silent Subscription Failure Masks Network Partition in Consensus Observer

## Summary
The `create_new_subscriptions()` function returns an empty vector without error indication when all subscription attempts fail. This silent failure masks critical network partition issues, delaying the observer's fallback to state sync and creating a false sense of operational health during network outages.

## Finding Description

The consensus observer relies on active subscriptions to peer nodes to receive consensus updates. When these subscriptions fail, the system should immediately detect and respond to the failure. However, a critical flaw exists in the error propagation path. [1](#0-0) 

The `create_new_subscriptions()` function attempts to create subscriptions but silently returns an empty vector when all attempts fail. This occurs in three scenarios:
1. When peer sorting fails (line 59)
2. When no potential peers exist (line 67)  
3. When all subscription RPC requests fail (line 110)

The function is called asynchronously from the subscription manager: [2](#0-1) 

The async task only logs a warning when fewer subscriptions are created than requested (lines 244-252), but doesn't propagate any error to the caller. This creates a dangerous scenario where:

1. **Network Partition Occurs**: All connected peers become unreachable
2. **Subscriptions Terminated**: Existing unhealthy subscriptions are terminated
3. **Silent Creation Failure**: New subscription attempts all fail, returning empty vec
4. **False Health Status**: `check_and_manage_subscriptions()` returns `Ok(())` because there are no subscriptions to check [3](#0-2) 

The function only returns an error if ALL subscriptions were terminated (line 142-149), not if creation of new subscriptions failed. This means a node can exist in a state with zero subscriptions while the system reports healthy operation.

The main consensus observer loop periodically checks progress: [4](#0-3) 

When `check_and_manage_subscriptions()` returns `Ok(())` during a partition, the system doesn't immediately enter fallback mode. Instead, it relies on the fallback manager's timeout-based detection: [5](#0-4) 

This timeout-based detection (configured via `observer_fallback_progress_threshold_ms`) creates a window where the node operates without subscriptions but believes it's healthy.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria because it creates "state inconsistencies requiring intervention":

1. **Delayed Partition Detection**: A node experiencing network partition will not immediately recognize the issue. The silent failure masks the fact that it has zero active subscriptions and cannot receive consensus updates.

2. **False Health Metrics**: Monitoring systems will show `Ok()` status from subscription management while the node is actually partitioned from the consensus network.

3. **Extended Degraded Operation**: The node operates in a degraded state until the fallback manager's timeout expires (typically several seconds to minutes), during which it cannot process consensus updates.

4. **Potential Liveness Impact**: If multiple observer nodes experience this simultaneously during a network event, it could impact the overall system's ability to propagate consensus updates efficiently.

While this doesn't directly cause consensus safety violations or fund loss, it represents a significant operational issue that can delay recovery from network partitions and mask critical infrastructure problems.

## Likelihood Explanation

**High Likelihood** - This vulnerability can be triggered by common operational scenarios:

1. **Network Partitions**: Common in distributed systems, especially during datacenter failures, routing issues, or DDoS mitigation
2. **Configuration Errors**: Firewall rules or network policies blocking consensus observer ports
3. **Peer Churn**: Rapid peer disconnections during network instability
4. **No Special Privileges Required**: Any network-level disruption can trigger this condition

The vulnerability is particularly likely during:
- Cloud provider network incidents
- Geographic network partitions
- Aggressive firewall policies
- Peer discovery failures

## Recommendation

**Solution**: Propagate subscription creation failures as errors when zero subscriptions are successfully created.

Modify `spawn_subscription_creation_task()` to track and report complete subscription creation failures:

```rust
// In subscription_manager.rs, spawn_subscription_creation_task()
let subscription_creation_task = tokio::spawn(async move {
    // ... existing code ...
    
    let new_subscriptions = subscription_utils::create_new_subscriptions(
        // ... params ...
    ).await;
    
    // ... existing code to add subscriptions ...
    
    let num_subscriptions_created = new_subscription_peers.len();
    if num_subscriptions_created < num_subscriptions_to_create {
        warn!(/* existing warning */);
        
        // NEW: If we created ZERO subscriptions when we needed some, 
        // this indicates a critical failure
        if num_subscriptions_created == 0 && num_subscriptions_to_create > 0 {
            // Mark that complete subscription failure occurred
            // This should trigger appropriate alerts/metrics
            metrics::increment_counter_without_labels(
                &metrics::OBSERVER_SUBSCRIPTION_CREATION_COMPLETE_FAILURE
            );
        }
    }
    
    // ... rest of existing code ...
});
```

Additionally, modify `check_and_manage_subscriptions()` to check for zero subscriptions:

```rust
pub async fn check_and_manage_subscriptions(&mut self) -> Result<(), Error> {
    // ... existing code ...
    
    // NEW: After spawning subscription creation, check if we have zero subscriptions
    // and should have some
    let final_subscription_peers = self.get_active_subscription_peers();
    let max_subscriptions = self.consensus_observer_config.max_concurrent_subscriptions;
    
    if final_subscription_peers.is_empty() && max_subscriptions > 0 {
        return Err(Error::SubscriptionsReset(
            "No active subscriptions and unable to create new ones".to_string()
        ));
    }
    
    // ... existing return ...
}
```

## Proof of Concept

The following test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_complete_subscription_failure_masking() {
    // Create consensus observer config
    let consensus_observer_config = ConsensusObserverConfig {
        max_concurrent_subscriptions: 2,
        ..ConsensusObserverConfig::default()
    };
    
    // Create consensus observer client with NO connected peers
    let network_ids = &[NetworkId::Validator];
    let (peers_and_metadata, consensus_observer_client, _) =
        create_consensus_observer_client(network_ids);
    
    // Create subscription manager
    let db_reader = Arc::new(MockDatabaseReader::new());
    let mut subscription_manager = SubscriptionManager::new(
        consensus_observer_client,
        consensus_observer_config,
        None,
        db_reader,
        TimeService::mock(),
    );
    
    // Verify no subscriptions exist
    assert_eq!(subscription_manager.get_active_subscription_peers().len(), 0);
    
    // Call check_and_manage_subscriptions with NO connected peers
    // This should fail but currently returns Ok(())
    let result = subscription_manager.check_and_manage_subscriptions().await;
    
    // BUG: This returns Ok(()) even though we have 0 subscriptions
    // and cannot create new ones
    assert!(result.is_ok()); // This demonstrates the vulnerability
    
    // Wait for async subscription creation to complete
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // VULNERABILITY: Still 0 subscriptions but system thinks it's healthy
    assert_eq!(subscription_manager.get_active_subscription_peers().len(), 0);
    
    // The node is now in a state where:
    // 1. It has NO active subscriptions
    // 2. check_and_manage_subscriptions() returned Ok(())
    // 3. It cannot receive consensus updates
    // 4. But the system believes it's operating normally
}
```

This test can be added to `consensus/src/consensus_observer/observer/subscription_manager.rs` test module to verify the vulnerability exists and validate the fix.

### Citations

**File:** consensus/src/consensus_observer/observer/subscription_utils.rs (L35-111)
```rust
pub async fn create_new_subscriptions(
    consensus_observer_config: ConsensusObserverConfig,
    consensus_observer_client: Arc<
        ConsensusObserverClient<NetworkClient<ConsensusObserverMessage>>,
    >,
    consensus_publisher: Option<Arc<ConsensusPublisher>>,
    db_reader: Arc<dyn DbReader>,
    time_service: TimeService,
    connected_peers_and_metadata: HashMap<PeerNetworkId, PeerMetadata>,
    num_subscriptions_to_create: usize,
    active_subscription_peers: Vec<PeerNetworkId>,
    unhealthy_subscription_peers: Vec<PeerNetworkId>,
) -> Vec<ConsensusObserverSubscription> {
    // Sort the potential peers for subscription requests
    let mut sorted_potential_peers = match sort_peers_for_subscriptions(
        connected_peers_and_metadata,
        active_subscription_peers,
        unhealthy_subscription_peers,
        consensus_publisher,
    ) {
        Some(sorted_peers) => sorted_peers,
        None => {
            error!(LogSchema::new(LogEntry::ConsensusObserver)
                .message("Failed to sort peers for subscription requests!"));
            return vec![];
        },
    };

    // Verify that we have potential peers to subscribe to
    if sorted_potential_peers.is_empty() {
        warn!(LogSchema::new(LogEntry::ConsensusObserver)
            .message("There are no potential peers to subscribe to!"));
        return vec![];
    }

    // Go through the potential peers and attempt to create new subscriptions
    let mut created_subscriptions = vec![];
    for _ in 0..num_subscriptions_to_create {
        // If there are no peers left to subscribe to, return early
        if sorted_potential_peers.is_empty() {
            info!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "There are no more potential peers to subscribe to! \
                    Num created subscriptions: {:?}",
                    created_subscriptions.len()
                ))
            );
            break;
        }

        // Attempt to create a new subscription
        let (observer_subscription, failed_subscription_peers) = create_single_subscription(
            consensus_observer_config,
            consensus_observer_client.clone(),
            db_reader.clone(),
            sorted_potential_peers.clone(),
            time_service.clone(),
        )
        .await;

        // Remove the failed peers from the sorted list
        sorted_potential_peers.retain(|peer| !failed_subscription_peers.contains(peer));

        // Process a successful subscription creation
        if let Some(observer_subscription) = observer_subscription {
            // Remove the peer from the sorted list (for the next selection)
            sorted_potential_peers
                .retain(|peer| *peer != observer_subscription.get_peer_network_id());

            // Add the newly created subscription to the subscription list
            created_subscriptions.push(observer_subscription);
        }
    }

    // Return the list of created subscriptions
    created_subscriptions
}
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L108-150)
```rust
    pub async fn check_and_manage_subscriptions(&mut self) -> Result<(), Error> {
        // Get the subscription and connected peers
        let initial_subscription_peers = self.get_active_subscription_peers();
        let connected_peers_and_metadata = self.get_connected_peers_and_metadata();

        // Terminate any unhealthy subscriptions
        let terminated_subscriptions =
            self.terminate_unhealthy_subscriptions(&connected_peers_and_metadata);

        // Check if all subscriptions were terminated
        let num_terminated_subscriptions = terminated_subscriptions.len();
        let all_subscriptions_terminated = num_terminated_subscriptions > 0
            && num_terminated_subscriptions == initial_subscription_peers.len();

        // Calculate the number of new subscriptions to create
        let remaining_subscription_peers = self.get_active_subscription_peers();
        let max_concurrent_subscriptions =
            self.consensus_observer_config.max_concurrent_subscriptions as usize;
        let num_subscriptions_to_create =
            max_concurrent_subscriptions.saturating_sub(remaining_subscription_peers.len());

        // Update the total subscription metrics
        update_total_subscription_metrics(&remaining_subscription_peers);

        // Spawn a task to create the new subscriptions (asynchronously)
        self.spawn_subscription_creation_task(
            num_subscriptions_to_create,
            remaining_subscription_peers,
            terminated_subscriptions,
            connected_peers_and_metadata,
        )
        .await;

        // Return an error if all subscriptions were terminated
        if all_subscriptions_terminated {
            Err(Error::SubscriptionsReset(format!(
                "All {:?} subscriptions were unhealthy and terminated!",
                num_terminated_subscriptions,
            )))
        } else {
            Ok(())
        }
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L208-257)
```rust
        let subscription_creation_task = tokio::spawn(async move {
            // Identify the terminated subscription peers
            let terminated_subscription_peers = terminated_subscriptions
                .iter()
                .map(|(peer, _)| *peer)
                .collect();

            // Create the new subscriptions
            let new_subscriptions = subscription_utils::create_new_subscriptions(
                consensus_observer_config,
                consensus_observer_client,
                consensus_publisher,
                db_reader,
                time_service,
                connected_peers_and_metadata,
                num_subscriptions_to_create,
                active_subscription_peers,
                terminated_subscription_peers,
            )
            .await;

            // Identify the new subscription peers
            let new_subscription_peers = new_subscriptions
                .iter()
                .map(|subscription| subscription.get_peer_network_id())
                .collect::<Vec<_>>();

            // Add the new subscriptions to the list of active subscriptions
            for subscription in new_subscriptions {
                active_observer_subscriptions
                    .lock()
                    .insert(subscription.get_peer_network_id(), subscription);
            }

            // Log a warning if we failed to create as many subscriptions as requested
            let num_subscriptions_created = new_subscription_peers.len();
            if num_subscriptions_created < num_subscriptions_to_create {
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to create the requested number of subscriptions! Number of subscriptions \
                        requested: {:?}, number of subscriptions created: {:?}.",
                        num_subscriptions_to_create,
                        num_subscriptions_created
                    ))
                );
            }

            // Update the subscription change metrics
            update_subscription_change_metrics(new_subscription_peers, terminated_subscriptions);
        });
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L168-214)
```rust
    async fn check_progress(&mut self) {
        debug!(LogSchema::new(LogEntry::ConsensusObserver)
            .message("Checking consensus observer progress!"));

        // If we've fallen back to state sync, we should wait for it to complete
        if self.state_sync_manager.in_fallback_mode() {
            info!(LogSchema::new(LogEntry::ConsensusObserver)
                .message("Waiting for state sync to complete fallback syncing!",));
            return;
        }

        // If state sync is syncing to a commit decision, we should wait for it to complete
        if self.state_sync_manager.is_syncing_to_commit() {
            info!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Waiting for state sync to reach commit decision: {:?}!",
                    self.observer_block_data.lock().root().commit_info()
                ))
            );
            return;
        }

        // Check if we need to fallback to state sync
        if let Err(error) = self.observer_fallback_manager.check_syncing_progress() {
            // Log the error and enter fallback mode
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to make syncing progress! Entering fallback mode! Error: {:?}",
                    error
                ))
            );
            self.enter_fallback_mode().await;
            return;
        }

        // Otherwise, check the health of the active subscriptions
        if let Err(error) = self
            .subscription_manager
            .check_and_manage_subscriptions()
            .await
        {
            // Log the failure and clear the pending block state
            warn!(LogSchema::new(LogEntry::ConsensusObserver)
                .message(&format!("Subscription checks failed! Error: {:?}", error)));
            self.clear_pending_block_state().await;
        }
    }
```

**File:** consensus/src/consensus_observer/observer/fallback_manager.rs (L58-116)
```rust
    pub fn check_syncing_progress(&mut self) -> Result<(), Error> {
        // If we're still within the startup period, we don't need to verify progress
        let time_now = self.time_service.now();
        let startup_period = Duration::from_millis(
            self.consensus_observer_config
                .observer_fallback_startup_period_ms,
        );
        if time_now.duration_since(self.start_time) < startup_period {
            return Ok(()); // We're still in the startup period
        }

        // Fetch the synced ledger info version from storage
        let latest_ledger_info_version =
            self.db_reader
                .get_latest_ledger_info_version()
                .map_err(|error| {
                    Error::UnexpectedError(format!(
                        "Failed to read highest synced version: {:?}",
                        error
                    ))
                })?;

        // Verify that the synced version is increasing appropriately
        self.verify_increasing_sync_versions(latest_ledger_info_version, time_now)?;

        // Verify that the sync lag is within acceptable limits
        self.verify_sync_lag_health(latest_ledger_info_version)
    }

    /// Verifies that the synced version is increasing appropriately. If not
    /// (i.e., too much time has passed without an increase), an error is returned.
    fn verify_increasing_sync_versions(
        &mut self,
        latest_ledger_info_version: Version,
        time_now: Instant,
    ) -> Result<(), Error> {
        // Verify that the synced version is increasing appropriately
        let (highest_synced_version, highest_version_timestamp) =
            self.highest_synced_version_and_time;
        if latest_ledger_info_version <= highest_synced_version {
            // The synced version hasn't increased. Check if we should enter fallback mode.
            let duration_since_highest_seen = time_now.duration_since(highest_version_timestamp);
            let fallback_threshold = Duration::from_millis(
                self.consensus_observer_config
                    .observer_fallback_progress_threshold_ms,
            );
            if duration_since_highest_seen > fallback_threshold {
                Err(Error::ObserverProgressStopped(format!(
                    "Consensus observer is not making progress! Highest synced version: {}, elapsed: {:?}",
                    highest_synced_version, duration_since_highest_seen
                )))
            } else {
                Ok(()) // We haven't passed the fallback threshold yet
            }
        } else {
            // The synced version has increased. Update the highest synced version and time.
            self.highest_synced_version_and_time = (latest_ledger_info_version, time_now);
            Ok(())
        }
```
