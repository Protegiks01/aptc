# Audit Report

## Title
Inconsistent AggregatorV1 Read Validation Between BlockSTM Versions Creates Consensus Split Risk

## Summary
The inclusion of AggregatorV1 reads in `data_reads` validation creates both double-validation in BlockSTMv2 and missed validation in BlockSTMv1. A critical invariant check that ensures aggregator values are read through the correct API is only enforced in BlockSTMv2, not in BlockSTMv1. This inconsistency violates the deterministic execution invariant and can lead to consensus splits if validators operate under different Block-STM execution modes.

## Finding Description

The codebase implements two parallel execution strategies: BlockSTMv1 and BlockSTMv2. When a transaction reads an AggregatorV1 value, it should be captured in both the `aggregator_v1_reads` HashSet and the `data_reads` HashMap. [1](#0-0) [2](#0-1) 

**The Double-Validation Issue (BlockSTMv2):**

In BlockSTMv2, aggregator v1 reads undergo validation twice:

1. **First validation** during commit hook: [3](#0-2) 

2. **Second validation** during post-commit processing: [4](#0-3) 

Both validations call `validate_data_reads` which includes AggregatorV1 reads: [5](#0-4) 

**The Missed Validation Issue (BlockSTMv1):**

A critical invariant check exists only in `validate_aggregator_v1_reads`: [6](#0-5) 

This check ensures that when a transaction writes to an aggregator, any prior reads of that aggregator must have been performed through the correct AggregatorV1 API (not the generic resource API). However, this validation is **only executed in BlockSTMv2**: [7](#0-6) 

In BlockSTMv1, `validate_and_commit_delayed_fields` is called with `is_v2 = false`, which means `validate_aggregator_v1_reads` is never invoked: [8](#0-7) 

**Exploitation Scenario:**

1. An attacker crafts a transaction that:
   - Reads an AggregatorV1 state value using the generic resource API (bypassing `capture_aggregator_v1_read`)
   - Writes to the same aggregator using the AggregatorV1 write API
   
2. The read is captured in `data_reads` but NOT in `aggregator_v1_reads`

3. Different validators produce different outcomes:
   - **BlockSTMv1 validators**: Accept the transaction (validation passes, no invariant check)
   - **BlockSTMv2 validators**: Reject the transaction (invariant check at lines 997-1006 detects violation)

4. This leads to a **consensus split** violating the deterministic execution invariant.

## Impact Explanation

**Severity: Medium (up to $10,000)**

This vulnerability qualifies as Medium severity under the Aptos bug bounty program because it creates:

1. **State inconsistencies requiring intervention**: Different validators accept/reject the same transaction, leading to divergent state roots
2. **Consensus safety violation**: Breaks the critical invariant that all validators must produce identical outputs for identical blocks

While this doesn't directly lead to fund theft or total network failure, it compromises consensus safety by allowing validators running different Block-STM modes to diverge on transaction validity. During rolling upgrades or configuration changes where validators temporarily operate under different modes, this could cause chain splits requiring manual intervention.

The impact is mitigated by:
- AggregatorV1 being legacy/deprecated functionality
- Validators likely operating under uniform configurations in production
- The attack requires deliberately crafting transactions that violate API usage patterns

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability is exploitable when:
1. Validators operate under different Block-STM execution modes (V1 vs V2)
2. An attacker can craft a transaction that reads an aggregator through the wrong API
3. The same transaction writes to that aggregator

Likelihood factors:
- **Increases during**: Rolling upgrades, configuration migrations, emergency rollbacks
- **Decreases due to**: Uniform validator configurations, deprecated AggregatorV1 usage, API access controls
- **Technical barrier**: Medium - requires understanding of internal Block-STM execution modes and aggregator semantics

## Recommendation

**Fix Option 1: Remove AggregatorV1 reads from `validate_data_reads`**

In `captured_reads.rs`, modify `validate_data_reads` to exclude aggregator v1 reads:

```rust
pub(crate) fn validate_data_reads(
    &self,
    data_map: &VersionedData<T::Key, T::Value>,
    idx_to_validate: TxnIndex,
) -> bool {
    if self.non_delayed_field_speculative_failure {
        return false;
    }
    
    // Filter out aggregator v1 reads - they are validated separately in BlockSTMv2
    let non_aggregator_reads = self.data_reads.iter()
        .filter(|(k, _)| !self.aggregator_v1_reads.contains(k));
    
    self.validate_data_reads_impl(non_aggregator_reads, data_map, idx_to_validate)
}
```

**Fix Option 2: Enforce invariant check in BlockSTMv1**

Call `validate_aggregator_v1_reads` in both BlockSTMv1 and BlockSTMv2 commit hooks, or add the check directly to `validate_data_reads`.

**Recommended: Option 1** - This eliminates double-validation and ensures consistent behavior across both execution modes.

## Proof of Concept

```rust
// Pseudo-code demonstrating the vulnerability
// This would need to be adapted to actual Aptos test framework

#[test]
fn test_aggregator_v1_validation_inconsistency() {
    // Setup: Create validators with BlockSTMv1 and BlockSTMv2
    let v1_executor = BlockExecutor::new_with_v1();
    let v2_executor = BlockExecutor::new_with_v2();
    
    // Create transaction that:
    // 1. Reads aggregator state through resource API (wrong interface)
    // 2. Writes to same aggregator through aggregator API
    let malicious_txn = create_txn_with_wrong_read_interface();
    
    // Execute on both validators
    let v1_result = v1_executor.execute_block(vec![malicious_txn.clone()]);
    let v2_result = v2_executor.execute_block(vec![malicious_txn]);
    
    // EXPECTED: Both should produce same result (accept or reject)
    // ACTUAL: V1 accepts, V2 rejects -> consensus split
    assert_eq!(v1_result.is_ok(), v2_result.is_ok(), 
        "Validation inconsistency detected!");
}
```

## Notes

- The vulnerability exists in the current codebase implementation as of the analyzed version
- AggregatorV1 is marked as legacy/deprecated, which reduces practical exploit likelihood
- The issue fundamentally stems from having different validation logic paths for the same transaction type
- Production impact depends on validator configuration uniformity and upgrade coordination practices

### Citations

**File:** aptos-move/block-executor/src/captured_reads.rs (L551-552)
```rust
    aggregator_v1_reads: HashSet<T::Key>,

```

**File:** aptos-move/block-executor/src/captured_reads.rs (L951-962)
```rust
    pub(crate) fn validate_data_reads(
        &self,
        data_map: &VersionedData<T::Key, T::Value>,
        idx_to_validate: TxnIndex,
    ) -> bool {
        if self.non_delayed_field_speculative_failure {
            return false;
        }

        // This includes AggregatorV1 reads and keeps BlockSTMv1 behavior intact.
        self.validate_data_reads_impl(self.data_reads.iter(), data_map, idx_to_validate)
    }
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L993-1006)
```rust
        if ret {
            // Additional invariant check (that AggregatorV1 reads are captured for
            // aggregator write keys). This protects against the case where aggregator v1
            // state value read was read by a wrong interface (e.g. via resource API).
            for key in aggregator_write_keys {
                if self.data_reads.contains_key(&key) && !self.aggregator_v1_reads.contains(&key) {
                    // Not assuming read-before-write here: if there was a read, it must also be
                    // captured as an aggregator_v1 read.
                    return Err(code_invariant_error(format!(
                        "Captured read at aggregator key {:?} not found among AggregatorV1 reads",
                        key
                    )));
                }
            }
```

**File:** aptos-move/block-executor/src/view.rs (L1816-1828)
```rust
        if let ViewState::Sync(parallel_state) = &self.latest_view {
            parallel_state
                .captured_reads
                .borrow_mut()
                .capture_aggregator_v1_read(state_key.clone());
        }

        // TODO[agg_v1](cleanup):
        // Integrate aggregators V1. That is, we can lift the u128 value
        // from the state item by passing the right layout here. This can
        // be useful for cross-testing the old and the new flows.
        // self.get_resource_state_value(state_key, Some(&MoveTypeLayout::U128))
        self.get_resource_state_value(state_key, None)
```

**File:** aptos-move/block-executor/src/executor.rs (L861-870)
```rust
            || (is_v2
                && !read_set.validate_aggregator_v1_reads(
                    versioned_cache.data(),
                    last_input_output
                        .modified_aggregator_v1_keys(txn_idx)
                        .ok_or_else(|| {
                            code_invariant_error("Modified aggregator v1 keys must be recorded")
                        })?,
                    txn_idx,
                )?)
```

**File:** aptos-move/block-executor/src/executor.rs (L965-975)
```rust
        if !Self::validate_and_commit_delayed_fields(
            txn_idx,
            versioned_cache,
            last_input_output,
            scheduler.is_v2(),
        )? {
            return Err(code_invariant_error(format!(
                "Delayed field validation after re-execution failed for txn {}",
                txn_idx
            )));
        }
```

**File:** aptos-move/block-executor/src/executor.rs (L1009-1014)
```rust
        if !Self::validate_and_commit_delayed_fields(
            txn_idx,
            versioned_cache,
            last_input_output,
            scheduler.is_v2(),
        )? {
```

**File:** aptos-move/block-executor/src/executor.rs (L1142-1154)
```rust
        if !Self::validate(
            txn_idx,
            last_input_output,
            shared_sync_params.global_module_cache,
            shared_sync_params.versioned_cache,
            // Module cache is not versioned (published at commit), so validation after
            // commit might observe later publishes (higher txn index) and be incorrect.
            // Hence, we skip the paranoid module validation after commit.
            // TODO(BlockSTMv2): Do the additional checking in sequential commit hook,
            // when modules have been published. Update the comment here as skipping
            // in V2 is needed for a different, code cache implementation related reason.
            true,
        ) {
```
