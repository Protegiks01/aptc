# Audit Report

## Title
Memory Exhaustion via Unbounded Discovered Peers Accumulation in ConnectivityManager

## Summary
The `ConnectivityManager` lacks bounds checking when accumulating discovered peers from multiple discovery sources, and performs full HashMap cloning on every connectivity check. If discovered peers grow to a large size, the repeated cloning and HashSet operations can exhaust validator node memory, causing crashes or severe performance degradation.

## Finding Description

The vulnerability exists in the peer discovery and selection system across two files: [1](#0-0) 

The `handle_update_discovered_peers` function processes peer updates from multiple discovery sources (OnChainValidatorSet, File, Rest, Config) and accumulates them into the `discovered_peers.peer_set` HashMap without any size limits. Each discovery source can contribute peers that accumulate in the same data structure. [2](#0-1) 

The `DiscoveredPeerSet` is defined as a simple HashMap with no capacity limits. [3](#0-2) 

In `choose_peers_to_dial`, the entire `discovered_peers.peer_set` HashMap is cloned on line 577, creating a complete copy of all peer data. This happens on every connectivity check cycle. [4](#0-3) 

The cloned peer data is then processed through multiple HashSet allocation and cloning operations in the selection logic, amplifying memory consumption.

**Attack Scenario:**

While OnChain discovery is bounded by `MAX_VALIDATOR_SET_SIZE` (65,536), nodes can be configured with File or REST discovery sources that load peer data from external sources: [5](#0-4) 

If these discovery sources are compromised or misconfigured to return millions of malicious peer IDs (e.g., via a compromised REST endpoint returning a manipulated ValidatorSet, or a maliciously crafted discovery file), all peers accumulate unbounded in `discovered_peers.peer_set`.

**Memory Exhaustion Calculation:**
- 10 million malicious peer IDs × 500 bytes/entry ≈ 5 GB
- Full HashMap clone on each connectivity check: +5 GB
- Multiple HashSet operations: +2-3 GB
- Repeated every connectivity check interval (typically seconds)
- Can exhaust available memory, triggering OOM killer or severe swapping

## Impact Explanation

This qualifies as **High Severity** under the Aptos Bug Bounty program:
- **Validator node slowdowns**: Memory pressure causes severe performance degradation
- **Node crashes**: OOM conditions can crash validator processes
- **Significant protocol violations**: Breaks the "Resource Limits" invariant - operations must respect memory constraints

The vulnerability affects validator availability and network health. While not directly causing consensus safety violations or fund loss, degraded validator performance impacts network liveness and can lead to missed blocks or reduced throughput.

## Likelihood Explanation

**Medium-to-Low Likelihood** for direct exploitation:
- Requires compromise or misconfiguration of File/REST discovery sources
- Validator operators typically use OnChain discovery (which is bounded)
- File/REST discovery requires operator-level system access or configuration control

**Higher Likelihood** scenarios:
- Misconfigured public fullnodes using REST discovery pointed at untrusted endpoints
- Supply chain attacks compromising discovery file generation systems
- Adjacent service vulnerabilities allowing file writes to discovery paths
- Insider threats or compromised validator operator systems

The vulnerability is a **design flaw** rather than an easily exploitable bug - it requires specific conditions but has serious consequences when triggered.

## Recommendation

Implement strict bounds checking on the total number of discovered peers:

```rust
// In DiscoveredPeerSet
const MAX_DISCOVERED_PEERS: usize = 100_000; // Conservative limit

// In handle_update_discovered_peers, before line 929:
fn handle_update_discovered_peers(
    &mut self,
    src: DiscoverySource,
    new_discovered_peers: PeerSet,
) {
    // Early validation
    let current_size = self.discovered_peers.read().peer_set.len();
    let new_size = current_size.saturating_add(new_discovered_peers.len());
    
    if new_size > MAX_DISCOVERED_PEERS {
        error!(
            NetworkSchema::new(&self.network_context),
            "Discovered peers exceeds maximum limit. Current: {}, Attempted: {}, Max: {}",
            current_size, new_discovered_peers.len(), MAX_DISCOVERED_PEERS
        );
        // Reject the update or apply rate limiting
        return;
    }
    
    // ... existing logic
}
```

Additional recommendations:
1. Avoid full HashMap cloning in `choose_peers_to_dial` - iterate over the read lock directly
2. Implement per-source limits to prevent any single source from dominating
3. Add monitoring/alerting for discovered peer set size
4. Consider using reference counting or `Arc<DiscoveredPeer>` to reduce clone costs

## Proof of Concept

Create a malicious discovery file with 1 million peer entries:

```yaml
# malicious_peers.yaml (excerpt - repeat 1M times)
---
"0000000000000000000000000000000000000000000000000000000000000001":
  addresses:
    - "/ip4/1.2.3.4/tcp/6180/noise-ik/0000000000000000000000000000000000000000000000000000000000000001/handshake/0"
  keys:
    - "0000000000000000000000000000000000000000000000000000000000000001"
  role: "Validator"
"0000000000000000000000000000000000000000000000000000000000000002":
  addresses:
    - "/ip4/1.2.3.5/tcp/6180/noise-ik/0000000000000000000000000000000000000000000000000000000000000002/handshake/0"
  keys:
    - "0000000000000000000000000000000000000000000000000000000000000002"
  role: "Validator"
# ... repeat with sequential peer IDs
```

Configure node to use file discovery pointing to this file. Monitor memory usage during connectivity checks - memory will grow unbounded until OOM.

Rust test to demonstrate the cloning issue:

```rust
#[test]
fn test_discovered_peers_memory_exhaustion() {
    // Create discovered peer set with 1M entries
    let mut peer_set = HashMap::new();
    for i in 0..1_000_000 {
        let peer_id = AccountAddress::from_hex_literal(&format!("0x{:064x}", i)).unwrap();
        peer_set.insert(peer_id, DiscoveredPeer::new(PeerRole::Validator));
    }
    
    let discovered_peers = Arc::new(RwLock::new(DiscoveredPeerSet { peer_set }));
    
    // Measure memory before clone
    let before = get_memory_usage();
    
    // This is what happens in choose_peers_to_dial
    let cloned = discovered_peers.read().peer_set.clone();
    
    // Measure memory after clone
    let after = get_memory_usage();
    
    // Verify significant memory increase (should be ~500MB-1GB)
    assert!(after - before > 500_000_000);
}
```

## Notes

This vulnerability represents a **resource exhaustion design flaw** rather than a logic bug. While the on-chain validator set is bounded at 65,536 validators, the accumulation of peers from multiple discovery sources without bounds checking creates an attack surface. The severity is heightened by the full HashMap cloning on every connectivity check, which amplifies the memory impact. Proper bounds checking and avoiding unnecessary clones would mitigate this issue.

### Citations

**File:** network/framework/src/connectivity_manager/mod.rs (L177-179)
```rust
struct DiscoveredPeerSet {
    peer_set: HashMap<PeerId, DiscoveredPeer>,
}
```

**File:** network/framework/src/connectivity_manager/mod.rs (L572-587)
```rust
    async fn choose_peers_to_dial(&mut self) -> Vec<(PeerId, DiscoveredPeer)> {
        // Get the eligible peers to dial
        let network_id = self.network_context.network_id();
        let role = self.network_context.role();
        let roles_to_dial = network_id.upstream_roles(&role);
        let discovered_peers = self.discovered_peers.read().peer_set.clone();
        let eligible_peers: Vec<_> = discovered_peers
            .into_iter()
            .filter(|(peer_id, peer)| {
                peer.is_eligible_to_be_dialed() // The node is eligible to dial
                    && !self.connected.contains_key(peer_id) // The node is not already connected
                    && !self.dial_queue.contains_key(peer_id) // There is no pending dial to this node
                    && roles_to_dial.contains(&peer.role) // We can dial this role
            })
            .collect();

```

**File:** network/framework/src/connectivity_manager/mod.rs (L886-940)
```rust
    fn handle_update_discovered_peers(
        &mut self,
        src: DiscoverySource,
        new_discovered_peers: PeerSet,
    ) {
        // Log the update event
        info!(
            NetworkSchema::new(&self.network_context),
            "{} Received updated list of discovered peers! Source: {:?}, num peers: {:?}",
            self.network_context,
            src,
            new_discovered_peers.len()
        );

        // Remove peers that no longer have relevant network information
        let mut keys_updated = false;
        let mut peers_to_check_remove = Vec::new();
        for (peer_id, peer) in self.discovered_peers.write().peer_set.iter_mut() {
            let new_peer = new_discovered_peers.get(peer_id);
            let check_remove = if let Some(new_peer) = new_peer {
                if new_peer.keys.is_empty() {
                    keys_updated |= peer.keys.clear_src(src);
                }
                if new_peer.addresses.is_empty() {
                    peer.addrs.clear_src(src);
                }
                new_peer.addresses.is_empty() && new_peer.keys.is_empty()
            } else {
                keys_updated |= peer.keys.clear_src(src);
                peer.addrs.clear_src(src);
                true
            };
            if check_remove {
                peers_to_check_remove.push(*peer_id);
            }
        }

        // Remove peers that no longer have state
        for peer_id in peers_to_check_remove {
            self.discovered_peers.write().remove_peer_if_empty(&peer_id);
        }

        // Make updates to the peers accordingly
        for (peer_id, discovered_peer) in new_discovered_peers {
            // Don't include ourselves, because we don't need to dial ourselves
            if peer_id == self.network_context.peer_id() {
                continue;
            }

            // Create the new `DiscoveredPeer`, role is set when a `Peer` is first discovered
            let mut discovered_peers = self.discovered_peers.write();
            let peer = discovered_peers
                .peer_set
                .entry(peer_id)
                .or_insert_with(|| DiscoveredPeer::new(discovered_peer.role));
```

**File:** network/framework/src/connectivity_manager/selection.rs (L36-88)
```rust
pub fn choose_random_peers_by_ping_latency(
    network_context: NetworkContext,
    eligible_peers: Vec<(PeerId, DiscoveredPeer)>,
    num_peers_to_choose: usize,
    discovered_peers: Arc<RwLock<DiscoveredPeerSet>>,
) -> Vec<(PeerId, DiscoveredPeer)> {
    // Get all eligible peer IDs
    let eligible_peer_ids = eligible_peers
        .iter()
        .map(|(peer_id, _)| *peer_id)
        .collect::<HashSet<_>>();

    // Identify the peer IDs that haven't been dialed recently
    let non_recently_dialed_peer_ids = eligible_peers
        .iter()
        .filter(|(_, peer)| !peer.has_dialed_recently())
        .map(|(peer_id, _)| *peer_id)
        .collect::<HashSet<_>>();

    // Choose peers (weighted by latency) from the non-recently dialed peers
    let mut selected_peer_ids = choose_peers_by_ping_latency(
        &network_context,
        &non_recently_dialed_peer_ids,
        num_peers_to_choose,
        discovered_peers.clone(),
    );

    // If not enough peers were selected, choose additional peers weighted by latency
    let num_selected_peer_ids = selected_peer_ids.len();
    if num_selected_peer_ids < num_peers_to_choose {
        // Filter out the already selected peers
        let unselected_peer_ids = get_unselected_peer_ids(&eligible_peer_ids, &selected_peer_ids);

        // Choose the remaining peers weighted by latency
        let num_remaining_peers = num_peers_to_choose.saturating_sub(num_selected_peer_ids);
        let remaining_selected_peer_ids = choose_peers_by_ping_latency(
            &network_context,
            &unselected_peer_ids,
            num_remaining_peers,
            discovered_peers.clone(),
        );

        // Extend the selected peers with the remaining peers
        selected_peer_ids.extend(remaining_selected_peer_ids);
    }

    // Extend the selected peers with random peers (if necessary)
    let selected_peer_ids =
        extend_with_random_peers(selected_peer_ids, &eligible_peer_ids, num_peers_to_choose);

    // Return the selected peers
    get_discovered_peers_for_ids(selected_peer_ids, discovered_peers)
}
```

**File:** network/builder/src/builder.rs (L372-385)
```rust
                DiscoveryMethod::File(file_discovery) => DiscoveryChangeListener::file(
                    self.network_context,
                    conn_mgr_reqs_tx.clone(),
                    file_discovery.path.as_path(),
                    Duration::from_secs(file_discovery.interval_secs),
                    self.time_service.clone(),
                ),
                DiscoveryMethod::Rest(rest_discovery) => DiscoveryChangeListener::rest(
                    self.network_context,
                    conn_mgr_reqs_tx.clone(),
                    rest_discovery.url.clone(),
                    Duration::from_secs(rest_discovery.interval_secs),
                    self.time_service.clone(),
                ),
```
