# Audit Report

## Title
Cross-Database Snapshot Inconsistency in Sharded LedgerDB Allows State Corruption

## Summary
When storage sharding is enabled, `transaction_info_db` and `transaction_accumulator_db` are separate RocksDB instances that lack atomic commit guarantees. Reads from these databases (including in `check_txn_info_hashes.rs` and production code like `get_transaction_info_with_proof`) are NOT guaranteed to see the same consistent snapshot, violating the State Consistency invariant. Process crashes during parallel writes can leave the databases permanently inconsistent.

## Finding Description

The vulnerability exists in how AptosDB handles sharded database writes and reads. When `enable_storage_sharding = true` (the production configuration), the ledger database is split into multiple separate RocksDB instances: [1](#0-0) 

Each sub-database (including `transaction_info_db` and `transaction_accumulator_db`) is opened as a completely separate RocksDB instance in different directories, opened in parallel threads.

**The Write Path Vulnerability:**

During transaction commits, writes to these separate databases happen in parallel without atomic commit guarantees: [2](#0-1) 

The TODO comment at lines 272-273 explicitly acknowledges this issue: "Write progress for each of the following databases, and handle the inconsistency at the startup time." The writes to `transaction_info_db` (line 310-313) and `transaction_accumulator_db` (line 314-318) are spawned as separate parallel threads.

These writes ultimately call separate `write_schemas` on different RocksDB instances: [3](#0-2) 

The writes are sequential, not atomic. If the process crashes between line 535 (transaction_info_db) and line 542 (transaction_accumulator_db), the databases are left in an inconsistent state.

**The Read Path Vulnerability:**

In `check_txn_info_hashes.rs`, the code reads from both databases: [4](#0-3) 

The iterator on `transaction_info_db` (lines 33-35) creates a snapshot at iterator creation time within that RocksDB instance. However, each `get()` call on `transaction_accumulator_db_raw()` (lines 40-42) reads from a completely different RocksDB instance. When sharding is enabled, there is NO guarantee these see the same consistent snapshot.

**The same pattern exists in production code:** [5](#0-4) 

This method reads from `transaction_info_db` (line 81) and `transaction_accumulator_db` (line 80) without snapshot consistency guarantees.

**Exploitation Scenario:**

1. Validator node processes transactions normally
2. During `calculate_and_commit_ledger_and_state_kv`, parallel threads write to separate databases
3. Process crashes (power failure, OOM kill, SIGKILL) after `commit_transaction_infos` completes but before `commit_transaction_accumulator` completes
4. On restart, `transaction_info_db` contains version N, but `transaction_accumulator_db` contains version N-1
5. Any code reading from both databases sees inconsistent data
6. Validators may produce different state roots, causing consensus disagreement

## Impact Explanation

**Medium to High Severity** - This meets the "State inconsistencies requiring intervention" criterion from the bug bounty program.

**Impact categories:**
- **State Consistency Violation**: Breaks invariant #4 - "State transitions must be atomic and verifiable via Merkle proofs"
- **Consensus Risk**: Validators with inconsistent data may produce different state roots for the same version, violating invariant #1 (Deterministic Execution)
- **Data Integrity**: Permanent corruption requiring manual database repair or resync from other nodes
- **Proof Generation Failures**: `get_transaction_info_with_proof` can return invalid proofs that fail verification

The developers acknowledge this issue exists (TODO comment), confirming it's a known unresolved problem.

## Likelihood Explanation

**High likelihood** - This vulnerability is triggered by any unclean shutdown:
- Power failures
- OOM killer terminating the process
- SIGKILL signals
- Kernel panics
- Hardware failures

During high transaction throughput, commits happen frequently (potentially multiple times per second), creating a large window of vulnerability. Even a 1-second crash window during a commit means the vulnerability is hit frequently in production environments.

The parallel write design guarantees that there's always a time window where one database is committed but the other isn't, making this vulnerability inevitable under crash conditions.

## Recommendation

**Immediate Fix - Add Write Progress Tracking:**

Implement the TODO mentioned in the code by adding per-database write progress markers. During startup, check all sub-databases for version consistency and roll back any partially committed data.

**Short-term Fix - Sequential Writes with Ordering:**

Modify the write path to write to `transaction_accumulator_db` BEFORE `transaction_info_db`, and record which database was written last. On recovery, use the minimum version across all databases.

**Long-term Fix - True Atomic Commits:**

Implement a write-ahead log (WAL) or two-phase commit protocol across the sharded databases:
1. Write intent log with all data to be committed
2. Commit to all databases
3. Clear intent log

On crash recovery, replay incomplete commits from the intent log.

**Alternative - Use Single RocksDB Instance:**

For critical consistency requirements, disable sharding (`enable_storage_sharding = false`) so all ledger data uses a single RocksDB instance with atomic commit guarantees: [6](#0-5) 

## Proof of Concept

**Reproduction Steps:**

1. Start an Aptos validator node with `enable_storage_sharding = true`
2. Generate high transaction load to trigger frequent commits
3. During a commit (monitor logs for "commit_transaction_infos" timing), send SIGKILL to the validator process:
   ```bash
   while true; do
     if grep -q "commit_transaction_infos" /var/log/aptos/validator.log; then
       pkill -9 aptos-node
       break
     fi
     sleep 0.1
   done
   ```
4. Restart the node
5. Run the consistency checker:
   ```bash
   aptos-db-tool check-txn-info-hashes --db-dir /opt/aptos/data
   ```
6. Observe hash mismatch errors indicating `transaction_info_db` and `transaction_accumulator_db` are at different versions

**Expected Result:** The check will fail with messages like:
```
Found mismatch: version: 12345, txn_info_hash: 0xabc..., leaf_hash: None
```

This demonstrates that the databases are in an inconsistent state with no automatic recovery mechanism.

## Notes

The vulnerability is explicitly acknowledged in the codebase via the TODO comment but remains unresolved. The issue affects not just debug tools but production code paths like `get_transaction_info_with_proof`, making it a systemic consistency problem. While not directly exploitable by external attackers, it represents a critical reliability and consensus safety issue that can be triggered by common failure scenarios.

### Citations

**File:** storage/aptosdb/src/ledger_db/mod.rs (L150-172)
```rust
        if !sharding {
            info!("Individual ledger dbs are not enabled!");
            return Ok(Self {
                ledger_metadata_db: LedgerMetadataDb::new(Arc::clone(&ledger_metadata_db)),
                event_db: EventDb::new(
                    Arc::clone(&ledger_metadata_db),
                    EventStore::new(Arc::clone(&ledger_metadata_db)),
                ),
                persisted_auxiliary_info_db: PersistedAuxiliaryInfoDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_accumulator_db: TransactionAccumulatorDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_auxiliary_data_db: TransactionAuxiliaryDataDb::new(Arc::clone(
                    &ledger_metadata_db,
                )),
                transaction_db: TransactionDb::new(Arc::clone(&ledger_metadata_db)),
                transaction_info_db: TransactionInfoDb::new(Arc::clone(&ledger_metadata_db)),
                write_set_db: WriteSetDb::new(Arc::clone(&ledger_metadata_db)),
                enable_storage_sharding: false,
            });
        }
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L173-293)
```rust

        let ledger_db_folder = db_root_path.as_ref().join(LEDGER_DB_FOLDER_NAME);

        let mut event_db = None;
        let mut persisted_auxiliary_info_db = None;
        let mut transaction_accumulator_db = None;
        let mut transaction_auxiliary_data_db = None;
        let mut transaction_db = None;
        let mut transaction_info_db = None;
        let mut write_set_db = None;
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            s.spawn(|_| {
                let event_db_raw = Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(EVENT_DB_NAME),
                        EVENT_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                );
                event_db = Some(EventDb::new(
                    event_db_raw.clone(),
                    EventStore::new(event_db_raw),
                ));
            });
            s.spawn(|_| {
                persisted_auxiliary_info_db = Some(PersistedAuxiliaryInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(PERSISTED_AUXILIARY_INFO_DB_NAME),
                        PERSISTED_AUXILIARY_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_accumulator_db = Some(TransactionAccumulatorDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_ACCUMULATOR_DB_NAME),
                        TRANSACTION_ACCUMULATOR_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_auxiliary_data_db = Some(TransactionAuxiliaryDataDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_AUXILIARY_DATA_DB_NAME),
                        TRANSACTION_AUXILIARY_DATA_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )))
            });
            s.spawn(|_| {
                transaction_db = Some(TransactionDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_DB_NAME),
                        TRANSACTION_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_info_db = Some(TransactionInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_INFO_DB_NAME),
                        TRANSACTION_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                write_set_db = Some(WriteSetDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(WRITE_SET_DB_NAME),
                        WRITE_SET_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
        });

        // TODO(grao): Handle data inconsistency.

        Ok(Self {
            ledger_metadata_db: LedgerMetadataDb::new(ledger_metadata_db),
            event_db: event_db.unwrap(),
            persisted_auxiliary_info_db: persisted_auxiliary_info_db.unwrap(),
            transaction_accumulator_db: transaction_accumulator_db.unwrap(),
            transaction_auxiliary_data_db: transaction_auxiliary_data_db.unwrap(),
            transaction_db: transaction_db.unwrap(),
            transaction_info_db: transaction_info_db.unwrap(),
            write_set_db: write_set_db.unwrap(),
            enable_storage_sharding: true,
        })
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L531-548)
```rust
    pub fn write_schemas(&self, schemas: LedgerDbSchemaBatches) -> Result<()> {
        self.write_set_db
            .write_schemas(schemas.write_set_db_batches)?;
        self.transaction_info_db
            .write_schemas(schemas.transaction_info_db_batches)?;
        self.transaction_db
            .write_schemas(schemas.transaction_db_batches)?;
        self.persisted_auxiliary_info_db
            .write_schemas(schemas.persisted_auxiliary_info_db_batches)?;
        self.event_db.write_schemas(schemas.event_db_batches)?;
        self.transaction_accumulator_db
            .write_schemas(schemas.transaction_accumulator_db_batches)?;
        self.transaction_auxiliary_data_db
            .write_schemas(schemas.transaction_auxiliary_data_db_batches)?;
        // TODO: remove this after sharding migration
        self.ledger_metadata_db
            .write_schemas(schemas.ledger_metadata_db_batches)
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L271-322)
```rust
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            // TODO(grao): Write progress for each of the following databases, and handle the
            // inconsistency at the startup time.
            //
            // TODO(grao): Consider propagating the error instead of panic, if necessary.
            s.spawn(|_| {
                self.commit_events(
                    chunk.first_version,
                    chunk.transaction_outputs,
                    skip_index_and_usage,
                )
                .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .write_set_db()
                    .commit_write_sets(chunk.first_version, chunk.transaction_outputs)
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .transaction_db()
                    .commit_transactions(
                        chunk.first_version,
                        chunk.transactions,
                        skip_index_and_usage,
                    )
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .persisted_auxiliary_info_db()
                    .commit_auxiliary_info(chunk.first_version, chunk.persisted_auxiliary_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_state_kv_and_ledger_metadata(chunk, skip_index_and_usage)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_transaction_infos(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                new_root_hash = self
                    .commit_transaction_accumulator(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
        });

        Ok(new_root_hash)
    }
```

**File:** storage/aptosdb/src/db_debugger/ledger/check_txn_info_hashes.rs (L32-52)
```rust
        println!("Checking that TransactionInfo hashes matches accumulator leaf hashes...");
        let txn_info_iter = ledger_db
            .transaction_info_db()
            .get_transaction_info_iter(self.start_version, self.num_versions)?;
        let mut version = self.start_version;
        for res in txn_info_iter {
            let txn_info = res?;
            let leaf_hash =
                ledger_db
                    .transaction_accumulator_db_raw()
                    .get::<TransactionAccumulatorSchema>(&Position::from_leaf_index(version))?;
            let txn_info_hash = txn_info.hash();

            ensure!(
                leaf_hash.as_ref() == Some(&txn_info_hash),
                "Found mismatch: version: {}, txn_info_hash: {:?}, leaf_hash: {:?}",
                version,
                txn_info_hash,
                leaf_hash,
            );

```

**File:** storage/aptosdb/src/ledger_db/transaction_info_db.rs (L72-83)
```rust
    /// Returns transaction info at `version` with proof towards root of ledger at `ledger_version`.
    pub(crate) fn get_transaction_info_with_proof(
        &self,
        version: Version,
        ledger_version: Version,
        transaction_accumulator_db: &TransactionAccumulatorDb,
    ) -> Result<TransactionInfoWithProof> {
        Ok(TransactionInfoWithProof::new(
            transaction_accumulator_db.get_transaction_proof(version, ledger_version)?,
            self.get_transaction_info(version)?,
        ))
    }
```
