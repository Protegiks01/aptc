# Audit Report

## Title
Race Condition Between Cache Eviction and File Store Fetching Causes Panic on Missing Transaction Data

## Summary
The indexer-grpc file store processor lacks protection against fetching transactions that have been evicted from Redis cache, leading to a panic when attempting to decode empty byte vectors returned for missing keys. This occurs due to a race condition where the cache worker evicts old transactions before checking if the file store processor still needs them.

## Finding Description

The vulnerability exists in the coordination between two components:

1. **File Store Processor** fetches transactions from Redis cache and uploads them to file storage [1](#0-0) 

2. **Cache Worker** actively evicts transactions older than 300,000 versions from the current head [2](#0-1) 

The issue manifests through the following sequence:

**Step 1: Missing Empty Byte Check**
The `get_transactions_with_durations` method fetches transactions via Redis `mget` but does not check if any returned values are empty byte vectors (which Redis returns for missing keys): [3](#0-2) 

**Step 2: Decoding Failure**
When a missing key returns an empty byte vector, the code attempts to decode it. For Lz4 compression (the default when compression is enabled), creating a decoder from an empty slice fails: [4](#0-3) 

**Step 3: Race Condition Timeline**
The cache worker evicts entries during transaction processing, BEFORE checking if the file store is lagging: [5](#0-4) 

This creates a race window where:
- Cache worker is at version 500,000
- File store processor is at version 200,000 (recovering from crash or lag)
- Cache worker processes a batch and evicts version 200,000 (since 500,000 - 300,000 = 200,000)
- File store processor attempts to fetch versions 200,000-200,999
- Redis returns empty byte vectors for evicted keys
- Lz4 decoder panics on `.expect()` when trying to decode empty data
- Spawned task fails, causing cascading panic: [6](#0-5) 

**Comparison with Correct Implementation**
The in-memory cache implementation correctly checks for empty values from Redis `mget`: [7](#0-6) 

However, `CacheOperator::get_transactions_with_durations` lacks this critical check.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

**Impact Category: State inconsistencies requiring intervention**
- File store processor crashes and stops uploading transaction batches to file storage (S3/GCS)
- Historical transaction data becomes unavailable for downstream indexers and analytics systems
- Creates data gaps in the file store that require manual intervention to recover
- Does not affect blockchain consensus or validator operations (isolated to indexer infrastructure)
- Requires service restart and potential re-sync to recover

**Affected Systems:**
- Indexer-grpc file store processor service
- Downstream data consumers relying on file store for historical data
- Analytics and monitoring systems depending on complete transaction history

**Not Critical/High because:**
- Does not affect consensus, validator operations, or main blockchain functionality
- Does not result in loss of funds or permanent state corruption
- Limited to data availability in auxiliary indexing infrastructure
- Core blockchain continues operating normally

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to trigger in several realistic scenarios:

1. **Service Recovery After Downtime:**
   - File store processor crashes or is stopped for maintenance
   - Upon restart, it attempts to resume from last processed version
   - If cache has advanced by > 150,000 versions during downtime, evicted data causes panic

2. **Network/Storage Latency:**
   - Slow uploads to file storage (S3/GCS timeout, network congestion)
   - File store processor lags behind cache worker
   - Once lag exceeds 300,000 versions, race condition triggers

3. **High Transaction Volume:**
   - Rapid transaction processing causes cache to advance quickly
   - File store upload speed cannot keep pace
   - Lag accumulates until eviction catches up to fetch range

4. **Initial Deployment:**
   - File store starts from version 0 on new deployment
   - Cache worker already at high version number
   - Immediate risk if cache > 300,000 versions

The 150,000 version "safety buffer" (`FILE_STORE_VERSIONS_RESERVED`) is intended to prevent this, but the race condition allows eviction to occur before the check executes, especially when:
- Multiple batch processing happens in quick succession
- Network delays cause file store status updates to lag
- Cache worker and file store processor run on separate systems with clock skew

## Recommendation

**Primary Fix: Add Empty Byte Vector Check**

Add explicit validation in `get_transactions_with_durations` before decoding:

```rust
pub async fn get_transactions_with_durations(
    &mut self,
    start_version: u64,
    transaction_count: u64,
) -> anyhow::Result<(Vec<Transaction>, f64, f64)> {
    let start_time = std::time::Instant::now();
    let versions = (start_version..start_version + transaction_count)
        .map(|e| CacheEntry::build_key(e, self.storage_format))
        .collect::<Vec<String>>();
    let encoded_transactions: Vec<Vec<u8>> = self
        .conn
        .mget(versions)
        .await
        .context("Failed to mget from Redis")?;
    
    // ADD THIS CHECK: Detect evicted/missing keys
    if encoded_transactions.iter().any(|v| v.is_empty()) {
        return Err(anyhow::anyhow!(
            "Some transactions have been evicted from cache. \
             Requested range: {}-{}, got {} entries",
            start_version,
            start_version + transaction_count - 1,
            encoded_transactions.iter().filter(|v| !v.is_empty()).count()
        ));
    }
    
    let io_duration = start_time.elapsed().as_secs_f64();
    let start_time = std::time::Instant::now();
    let mut transactions = vec![];
    for encoded_transaction in encoded_transactions {
        let cache_entry: CacheEntry = CacheEntry::new(encoded_transaction, self.storage_format);
        let transaction = cache_entry.into_transaction();
        transactions.push(transaction);
    }
    ensure!(
        transactions.len() == transaction_count as usize,
        "Failed to get all transactions from cache."
    );
    let decoding_duration = start_time.elapsed().as_secs_f64();
    Ok((transactions, io_duration, decoding_duration))
}
```

**Secondary Fix: Move Eviction Check Earlier**

In cache worker, check file store status BEFORE processing each batch instead of after:

```rust
loop {
    // Check BEFORE processing next batch
    loop {
        let file_store_version = cache_operator
            .get_file_store_latest_version()
            .await?
            .unwrap();
        if file_store_version + FILE_STORE_VERSIONS_RESERVED < current_version {
            tokio::time::sleep(std::time::Duration::from_millis(
                CACHE_WORKER_WAIT_FOR_FILE_STORE_MS,
            ))
            .await;
            tracing::warn!(
                current_version = current_version,
                file_store_version = file_store_version,
                "[Indexer Cache] File store version is behind, waiting..."
            );
            WAIT_FOR_FILE_STORE_COUNTER.inc();
        } else {
            break;
        }
    }
    
    // NOW process the batch (with eviction)
    let received = match resp_stream.next().await { ... };
    // ... rest of processing
}
```

**Tertiary Fix: Graceful Fallback in File Store Processor**

Handle cache misses gracefully instead of panicking:

```rust
let transactions = match cache_operator_clone
    .get_transactions(start_version, FILE_ENTRY_TRANSACTION_COUNT)
    .await
{
    Ok(txns) => txns,
    Err(e) if e.to_string().contains("evicted from cache") => {
        tracing::error!(
            start_version = start_version,
            "Transactions evicted from cache, falling back to fullnode fetch"
        );
        // Implement fallback to fetch from fullnode directly
        // or return error to retry later
        continue; // Skip this batch and retry
    },
    Err(e) => {
        tracing::error!(error = ?e, "Failed to get transactions");
        return Err(e);
    }
};
```

## Proof of Concept

**Scenario Setup:**
1. Deploy cache worker at version 500,000
2. Deploy file store processor starting at version 200,000
3. Observe crash when file store attempts to fetch evicted data

**Rust Test Case:**

```rust
#[tokio::test]
async fn test_evicted_transactions_cause_panic() {
    use redis_test::{MockCmd, MockRedisConnection};
    
    // Setup: Simulate cache with some keys missing (evicted)
    let start_version = 200_000_u64;
    let transaction_count = 1000_u64;
    
    // Build keys for the range
    let mut keys: Vec<String> = Vec::new();
    for v in start_version..start_version + transaction_count {
        keys.push(format!("l4:{}", v));
    }
    
    // Simulate Redis mget returning empty vectors for evicted keys
    let mut values: Vec<Vec<u8>> = Vec::new();
    for _ in 0..transaction_count {
        values.push(Vec::new()); // Empty = evicted
    }
    
    let cmds = vec![MockCmd::new(
        redis::cmd("MGET").arg(keys),
        Ok(values),
    )];
    
    let mock_connection = MockRedisConnection::new(cmds);
    let mut cache_operator = CacheOperator::new(
        mock_connection,
        StorageFormat::Lz4CompressedProto,
    );
    
    // This should fail gracefully but currently panics
    let result = cache_operator
        .get_transactions(start_version, transaction_count)
        .await;
    
    // Currently panics on: Decoder::new(&[]).expect("Lz4 decompression failed")
    // Should return: Err("Some transactions have been evicted from cache")
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .to_string()
        .contains("evicted from cache"));
}
```

**Reproduction Steps:**
1. Start cache worker at version 500,000+ with eviction enabled
2. Stop file store processor, let cache advance by 200,000+ versions
3. Restart file store processor from old checkpoint (e.g., version 200,000)
4. File store will panic when attempting to fetch evicted transactions
5. Check logs for "Lz4 decompression failed" panic message

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store/src/processor.rs (L162-166)
```rust
                    let transactions = cache_operator_clone
                        .get_transactions(start_version, FILE_ENTRY_TRANSACTION_COUNT)
                        .await
                        .unwrap();
                    let last_transaction = transactions.last().unwrap().clone();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store/src/processor.rs (L243-243)
```rust
                    Err(err) => panic!("Error processing transaction batches: {:?}", err),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L282-289)
```rust
            if version >= CACHE_SIZE_EVICTION_LOWER_BOUND {
                let key = CacheEntry::build_key(
                    version - CACHE_SIZE_EVICTION_LOWER_BOUND,
                    self.storage_format,
                )
                .to_string();
                redis_pipeline.cmd("DEL").arg(key).ignore();
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L367-395)
```rust
    pub async fn get_transactions_with_durations(
        &mut self,
        start_version: u64,
        transaction_count: u64,
    ) -> anyhow::Result<(Vec<Transaction>, f64, f64)> {
        let start_time = std::time::Instant::now();
        let versions = (start_version..start_version + transaction_count)
            .map(|e| CacheEntry::build_key(e, self.storage_format))
            .collect::<Vec<String>>();
        let encoded_transactions: Vec<Vec<u8>> = self
            .conn
            .mget(versions)
            .await
            .context("Failed to mget from Redis")?;
        let io_duration = start_time.elapsed().as_secs_f64();
        let start_time = std::time::Instant::now();
        let mut transactions = vec![];
        for encoded_transaction in encoded_transactions {
            let cache_entry: CacheEntry = CacheEntry::new(encoded_transaction, self.storage_format);
            let transaction = cache_entry.into_transaction();
            transactions.push(transaction);
        }
        ensure!(
            transactions.len() == transaction_count as usize,
            "Failed to get all transactions from cache."
        );
        let decoding_duration = start_time.elapsed().as_secs_f64();
        Ok((transactions, io_duration, decoding_duration))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L142-150)
```rust
    pub fn into_transaction(self) -> Transaction {
        match self {
            CacheEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L478-499)
```rust
        // Check if the file store isn't too far away
        loop {
            let file_store_version = cache_operator
                .get_file_store_latest_version()
                .await?
                .unwrap();
            if file_store_version + FILE_STORE_VERSIONS_RESERVED < current_version {
                tokio::time::sleep(std::time::Duration::from_millis(
                    CACHE_WORKER_WAIT_FOR_FILE_STORE_MS,
                ))
                .await;
                tracing::warn!(
                    current_version = current_version,
                    file_store_version = file_store_version,
                    "[Indexer Cache] File store version is behind current version too much."
                );
                WAIT_FOR_FILE_STORE_COUNTER.inc();
            } else {
                // File store is up to date, continue cache update.
                break;
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/in_memory_cache.rs (L357-364)
```rust
            let values = conn.mget::<Vec<String>, Vec<Vec<u8>>>(keys).await?;
            // If any of the values are empty, we return an error.
            if values.iter().any(|v| v.is_empty()) {
                return Err(anyhow::anyhow!(format!(
                    "Failed to fetch all the keys; fetch size {}",
                    values.len()
                )));
            }
```
