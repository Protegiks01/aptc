# Audit Report

## Title
State Snapshot Manifest Deserialization Resource Exhaustion via Unbounded Chunk Vector

## Summary
The state snapshot manifest deserialization in the backup-cli lacks size validation on the `chunks` vector before allocating memory. A malicious manifest with millions of `StateSnapshotChunk` entries can cause heap exhaustion and Out-of-Memory (OOM) crashes during restore operations, creating a denial-of-service condition for nodes attempting to restore from backups.

## Finding Description

The `StateSnapshotBackup` struct derives `Deserialize` for JSON deserialization without any size constraints on its `chunks` field. [1](#0-0) 

During state snapshot restoration, the manifest is loaded via `load_json_file` which performs two memory-intensive operations without validation. [2](#0-1) 

The deserialization chain has two allocation points:

1. **First allocation**: The entire manifest JSON file is read into memory using `read_to_end`, regardless of size. [3](#0-2) 

2. **Second allocation**: The JSON is deserialized into the `StateSnapshotBackup` structure, allocating the `Vec<StateSnapshotChunk>` without any size limits. [4](#0-3) 

**Attack Propagation:**

An attacker who gains access to backup storage (through misconfigured cloud buckets, compromised credentials, or insider access) can craft a malicious `manifest.json` containing millions of fake `StateSnapshotChunk` entries. Each chunk contains approximately 300+ bytes of data (two `usize` fields, two `HashValue` fields of 32 bytes each, and two `FileHandle` strings).

When a node operator initiates a restore operation pointing to this malicious manifest:
1. The entire multi-gigabyte JSON file is loaded into a `Vec<u8>` buffer
2. `serde_json` then deserializes this into the `StateSnapshotBackup` struct, allocating the massive `chunks` vector
3. The node exhausts available heap memory before any validation occurs at line 163 where `manifest.chunks.len()` is first accessed for legitimate purposes

**Example:** A manifest with 10 million chunks would result in:
- JSON file size: 3-5 GB
- In-memory Vec allocation: ~3 GB for chunks vector
- Total memory spike: 6-8 GB before any validation

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria:

- **Validator node slowdowns**: A restore operation consuming excessive memory will degrade node performance
- **API crashes**: The OOM condition will crash the backup-cli process and potentially the entire node if memory pressure is severe
- **Availability impact**: Nodes cannot restore from compromised backups, preventing recovery scenarios

The vulnerability affects the backup/restore subsystem which is critical for:
- New node bootstrapping
- Disaster recovery procedures  
- State synchronization fallback mechanisms
- Archive node operations

## Likelihood Explanation

**Likelihood: Medium**

While backup storage is expected to be trusted and controlled by node operators, several realistic scenarios enable exploitation:

1. **Cloud Storage Misconfiguration**: Public S3/GCS buckets or overly permissive IAM policies allowing unauthorized write access
2. **Credential Compromise**: Stolen backup storage credentials through phishing, insider threats, or software vulnerabilities
3. **Supply Chain Attacks**: Compromise of backup infrastructure providers or management tools
4. **Social Engineering**: Tricking operators into restoring from attacker-controlled backup sources

The attack requires no special blockchain knowledge, validator keys, or consensus participationâ€”only the ability to write malicious JSON to backup storage or convince operators to use a malicious source.

Defense-in-depth principles require validating untrusted inputs even when sources are nominally trusted, as trust boundaries can be breached through operational errors or external compromises.

## Recommendation

Implement size validation before deserializing the manifest to prevent unbounded memory allocation:

1. **Add manifest file size limit**: Validate the file size before reading it entirely into memory
2. **Add chunk count validation**: Check the array length during deserialization or immediately after
3. **Use streaming deserialization**: For large manifests, consider streaming JSON parsing instead of loading the entire file

**Proposed fix in `storage_ext.rs`:**

```rust
// Add constant
const MAX_MANIFEST_SIZE_BYTES: usize = 100 * 1024 * 1024; // 100 MB

async fn load_json_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
    let bytes = self.read_all(file_handle).await?;
    ensure!(
        bytes.len() <= MAX_MANIFEST_SIZE_BYTES,
        "Manifest file exceeds maximum allowed size: {} bytes (max: {} bytes)",
        bytes.len(),
        MAX_MANIFEST_SIZE_BYTES
    );
    Ok(serde_json::from_slice(&bytes)?)
}
```

**Additional validation in `restore.rs` after deserialization:**

```rust
const MAX_CHUNKS_PER_MANIFEST: usize = 100_000; // Reasonable limit for 1TB state with 10MB chunks

let manifest: StateSnapshotBackup = self.storage.load_json_file(&self.manifest_handle).await?;
ensure!(
    manifest.chunks.len() <= MAX_CHUNKS_PER_MANIFEST,
    "Manifest contains {} chunks, exceeding maximum of {}",
    manifest.chunks.len(),
    MAX_CHUNKS_PER_MANIFEST
);
```

## Proof of Concept

**Malicious Manifest Generation:**

```rust
// Create malicious manifest with 10 million chunks
use serde_json::json;
use std::fs::File;
use std::io::Write;

fn generate_malicious_manifest() -> std::io::Result<()> {
    let mut file = File::create("malicious_manifest.json")?;
    
    write!(file, r#"{{"version":0,"epoch":0,"root_hash":"0x0000000000000000000000000000000000000000000000000000000000000000","chunks":["#)?;
    
    for i in 0..10_000_000 {
        if i > 0 {
            write!(file, ",")?;
        }
        write!(file, r#"{{"first_idx":{},"last_idx":{},"first_key":"0x0000000000000000000000000000000000000000000000000000000000000000","last_key":"0x0000000000000000000000000000000000000000000000000000000000000000","blobs":"fake/blob/{}","proof":"fake/proof/{}"}}"#, i*1000, (i+1)*1000-1, i, i)?;
    }
    
    write!(file, r#"],"proof":"fake/proof"}}"#)?;
    Ok(())
}
```

**Trigger the vulnerability:**

```bash
# Upload malicious manifest to backup storage
# Then run restore operation
aptos-db-tool restore bootstrap-db \
    --state-manifest malicious_manifest.json \
    --state-into-version 0 \
    --target-db-dir /tmp/test_restore
    
# Expected result: Process crashes with OOM before reaching validation logic
```

## Notes

This vulnerability represents a defense-in-depth failure where the backup/restore system trusts manifest content without validation. While backup storage is nominally trusted infrastructure, operational security best practices require validating all external inputs to prevent resource exhaustion attacks. The issue is particularly concerning given that restore operations are critical for node recovery and may be performed under time pressure during incidents, when operators might be less vigilant about backup source verification.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L30-39)
```rust
#[derive(Deserialize, Serialize)]
pub struct StateSnapshotBackup {
    /// Version at which this state snapshot is taken.
    pub version: Version,
    /// Epoch in which this state snapshot is taken.
    pub epoch: u64,
    /// Hash of the state tree root.
    pub root_hash: HashValue,
    /// All account blobs in chunks.
    pub chunks: Vec<StateSnapshotChunk>,
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-124)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
```

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L24-28)
```rust
    async fn read_all(&self, file_handle: &FileHandleRef) -> Result<Vec<u8>> {
        let mut file = self.open_for_read(file_handle).await?;
        let mut bytes = Vec::new();
        file.read_to_end(&mut bytes).await?;
        Ok(bytes)
```

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L35-37)
```rust
    async fn load_json_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
        Ok(serde_json::from_slice(&self.read_all(file_handle).await?)?)
    }
```
