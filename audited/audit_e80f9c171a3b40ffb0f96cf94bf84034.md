# Audit Report

## Title
Missing Timestamp Update in Token V1 Current Tables Causes Temporal Data Inconsistency

## Summary
The indexer's token processor fails to update `last_transaction_timestamp` when updating Token V1 "current" tables (`current_collection_datas`, `current_token_datas`, `current_token_ownerships`), causing timestamp fields to become stale while version fields advance. This creates temporal inconsistencies in the indexed data.

## Finding Description

The indexer maintains "current" tables that track the latest state of NFT collections, tokens, and ownerships. When these entities are updated across multiple transactions, the database uses ON CONFLICT clauses to update existing records. [1](#0-0) 

The vulnerability exists in three affected functions:
1. `insert_current_collection_datas` - updates `last_transaction_version` but NOT `last_transaction_timestamp`
2. `insert_current_token_datas` - same issue
3. `insert_current_token_ownerships` - same issue [2](#0-1) 

The database schema confirms these tables have both fields: [3](#0-2) 

Interestingly, the Token V2 tables correctly update both fields: [4](#0-3) 

**Attack Scenario:**
1. Transaction at version 100 (timestamp T1): Collection X created
   - Database: `last_transaction_version=100, last_transaction_timestamp=T1`
2. Transaction at version 200 (timestamp T2 where T2 > T1): Collection X updated
   - ON CONFLICT triggered on `collection_data_id_hash`
   - Database: `last_transaction_version=200, last_transaction_timestamp=T1` (STALE!)

The timestamp now incorrectly points to the creation time instead of the update time.

## Impact Explanation

This qualifies as **Medium Severity** under "State inconsistencies requiring intervention" because:

1. **Data Integrity Violation**: The indexer database contains internally inconsistent state where `last_transaction_timestamp` doesn't correspond to `last_transaction_version`

2. **Query Correctness Impact**: Applications querying by timestamp receive incorrect results:
   - Time-based filters ("collections updated in last 24 hours") miss recently updated items
   - Temporal analytics calculate wrong time deltas
   - Sorting by timestamp produces incorrect ordering

3. **Requires Manual Intervention**: Fixing requires database migration to recompute all timestamps from transaction versions, affecting historical data

4. **Affects Official Infrastructure**: The indexer is critical infrastructure that applications depend on for NFT marketplace functionality, analytics, and user interfaces

While this doesn't affect blockchain consensus or on-chain state, it breaks data consistency guarantees in the official indexing layer that applications trust for correct temporal information.

## Likelihood Explanation

**Likelihood: HIGH** - This bug triggers automatically during normal NFT operations:

- Any collection that is created then later updated (supply changes, metadata updates)
- Any token that has its data modified across multiple transactions  
- Any token ownership transfer or amount change

No special privileges or attack setup required - legitimate NFT activity naturally triggers the vulnerability. The bug has likely already affected production indexer databases.

## Recommendation

Add `last_transaction_timestamp` to the UPDATE clause for all three affected functions:

**For `insert_current_collection_datas`:**
```rust
.set((
    creator_address.eq(excluded(creator_address)),
    collection_name.eq(excluded(collection_name)),
    description.eq(excluded(description)),
    metadata_uri.eq(excluded(metadata_uri)),
    supply.eq(excluded(supply)),
    maximum.eq(excluded(maximum)),
    maximum_mutable.eq(excluded(maximum_mutable)),
    uri_mutable.eq(excluded(uri_mutable)),
    description_mutable.eq(excluded(description_mutable)),
    last_transaction_version.eq(excluded(last_transaction_version)),
    last_transaction_timestamp.eq(excluded(last_transaction_timestamp)), // ADD THIS LINE
    table_handle.eq(excluded(table_handle)),
    inserted_at.eq(excluded(inserted_at)),
))
```

Apply the same fix to `insert_current_token_datas` and `insert_current_token_ownerships`.

**Database Migration Required:** After deploying the fix, run a migration to recompute all existing `last_transaction_timestamp` values from the corresponding transaction versions in the historical `collection_datas`, `token_datas`, and `token_ownerships` tables.

## Proof of Concept

```rust
// Pseudocode demonstration of the bug
// This would be implemented as an integration test with actual database

#[test]
fn test_timestamp_update_bug() {
    let mut conn = get_test_db_connection();
    
    // Transaction 1: Create collection at version 100, timestamp T1
    let collection_v1 = CurrentCollectionData {
        collection_data_id_hash: "test_collection_hash".to_string(),
        last_transaction_version: 100,
        last_transaction_timestamp: timestamp_from_microseconds(1000000), // T1
        // ... other fields
    };
    
    insert_current_collection_datas(&mut conn, &[collection_v1]);
    
    let result = query_collection(&mut conn, "test_collection_hash");
    assert_eq!(result.last_transaction_version, 100);
    assert_eq!(result.last_transaction_timestamp, timestamp_from_microseconds(1000000));
    
    // Transaction 2: Update collection at version 200, timestamp T2
    let collection_v2 = CurrentCollectionData {
        collection_data_id_hash: "test_collection_hash".to_string(),
        last_transaction_version: 200,
        last_transaction_timestamp: timestamp_from_microseconds(2000000), // T2
        supply: updated_supply, // Some field changed
        // ... other fields
    };
    
    insert_current_collection_datas(&mut conn, &[collection_v2]);
    
    let result = query_collection(&mut conn, "test_collection_hash");
    
    // BUG: Version updated but timestamp did NOT!
    assert_eq!(result.last_transaction_version, 200); // ✓ Correctly updated
    assert_eq!(result.last_transaction_timestamp, timestamp_from_microseconds(1000000)); // ✗ STILL T1, not T2!
    
    // Expected: timestamp should be 2000000 (T2)
    // Actual: timestamp remains 1000000 (T1) - TEMPORAL ANOMALY
}
```

## Notes

This bug demonstrates a temporal invariant violation where `last_transaction_timestamp` and `last_transaction_version` become desynchronized. While transaction timestamps at the consensus layer are guaranteed to be monotonically non-decreasing per block [5](#0-4) , the indexer's database layer must maintain this temporal consistency when aggregating transaction data into "current state" tables. The omission of timestamp updates breaks this guarantee for Token V1 tables while V2 tables correctly maintain it.

### Citations

**File:** crates/indexer/src/processors/token_processor.rs (L455-488)
```rust
fn insert_current_collection_datas(
    conn: &mut PgConnection,
    items_to_insert: &[CurrentCollectionData],
) -> Result<(), diesel::result::Error> {
    use schema::current_collection_datas::dsl::*;

    let chunks = get_chunks(items_to_insert.len(), CurrentCollectionData::field_count());

    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::current_collection_datas::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict(collection_data_id_hash)
                .do_update()
                .set((
                    creator_address.eq(excluded(creator_address)),
                    collection_name.eq(excluded(collection_name)),
                    description.eq(excluded(description)),
                    metadata_uri.eq(excluded(metadata_uri)),
                    supply.eq(excluded(supply)),
                    maximum.eq(excluded(maximum)),
                    maximum_mutable.eq(excluded(maximum_mutable)),
                    uri_mutable.eq(excluded(uri_mutable)),
                    description_mutable.eq(excluded(description_mutable)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    table_handle.eq(excluded(table_handle)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
            Some(" WHERE current_collection_datas.last_transaction_version <= excluded.last_transaction_version "),
        )?;
    }
    Ok(())
}
```

**File:** crates/indexer/src/processors/token_processor.rs (L688-723)
```rust
fn insert_current_collections_v2(
    conn: &mut PgConnection,
    items_to_insert: &[CurrentCollectionV2],
) -> Result<(), diesel::result::Error> {
    use schema::current_collections_v2::dsl::*;

    let chunks = get_chunks(items_to_insert.len(), CurrentCollectionV2::field_count());

    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::current_collections_v2::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict(collection_id)
                .do_update()
                .set((
                    creator_address.eq(excluded(creator_address)),
                    collection_name.eq(excluded(collection_name)),
                    description.eq(excluded(description)),
                    uri.eq(excluded(uri)),
                    current_supply.eq(excluded(current_supply)),
                    max_supply.eq(excluded(max_supply)),
                    total_minted_v2.eq(excluded(total_minted_v2)),
                    mutable_description.eq(excluded(mutable_description)),
                    mutable_uri.eq(excluded(mutable_uri)),
                    table_handle_v1.eq(excluded(table_handle_v1)),
                    token_standard.eq(excluded(token_standard)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    last_transaction_timestamp.eq(excluded(last_transaction_timestamp)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
            Some(" WHERE current_collections_v2.last_transaction_version <= excluded.last_transaction_version "),
        )?;
    }
    Ok(())
}
```

**File:** crates/indexer/src/schema.rs (L190-211)
```rust
diesel::table! {
    current_collection_datas (collection_data_id_hash) {
        #[max_length = 64]
        collection_data_id_hash -> Varchar,
        #[max_length = 66]
        creator_address -> Varchar,
        #[max_length = 128]
        collection_name -> Varchar,
        description -> Text,
        #[max_length = 512]
        metadata_uri -> Varchar,
        supply -> Numeric,
        maximum -> Numeric,
        maximum_mutable -> Bool,
        uri_mutable -> Bool,
        description_mutable -> Bool,
        last_transaction_version -> Int8,
        inserted_at -> Timestamp,
        #[max_length = 66]
        table_handle -> Varchar,
        last_transaction_timestamp -> Timestamp,
    }
```

**File:** consensus/consensus-types/src/block.rs (L521-530)
```rust
        if self.is_nil_block() || parent.has_reconfiguration() {
            ensure!(
                self.timestamp_usecs() == parent.timestamp_usecs(),
                "Nil/reconfig suffix block must have same timestamp as parent"
            );
        } else {
            ensure!(
                self.timestamp_usecs() > parent.timestamp_usecs(),
                "Blocks must have strictly increasing timestamps"
            );
```
