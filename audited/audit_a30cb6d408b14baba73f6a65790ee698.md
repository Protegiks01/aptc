# Audit Report

## Title
Unicode Normalization Vulnerability in TokenDataId Enables Token Spoofing and Phishing Attacks

## Summary
The Aptos Token Standard v1 allows collection and token names to contain Unicode characters without performing Unicode normalization. This enables attackers to create visually identical but programmatically distinct tokens using different Unicode representations (e.g., composed vs. decomposed characters), facilitating phishing attacks and marketplace confusion.

## Finding Description

The vulnerability exists in the Token Standard v1 implementation where `TokenDataId` uses `String` fields for `collection` and `name` without Unicode normalization. [1](#0-0) 

Move `String` types are UTF-8 byte vectors that undergo validation but no normalization: [2](#0-1) 

When creating a `TokenDataId`, only length validation occurs - no Unicode normalization: [3](#0-2) 

**Attack Path:**

1. **Legitimate Token Creation**: A creator establishes a collection "Café" using precomposed character é (U+00E9)
2. **Malicious Duplicate**: Attacker creates "Café" using decomposed character é (U+0065 U+0301 - 'e' + combining acute accent)
3. **Distinct Storage**: Both are stored as different keys in the `token_data` table since structural equality compares bytes: [4](#0-3) 

4. **Separate Events**: Mint events are emitted with distinct `TokenDataId` instances: [5](#0-4) 

5. **Indexer Divergence**: The indexer generates different hashes for these tokens: [6](#0-5) [7](#0-6) 

6. **Visual Confusion**: Users see identical names in UIs but interact with different on-chain entities

**Root Cause Analysis:**

The Move identifier system explicitly avoids Unicode normalization by restricting identifiers to ASCII: [8](#0-7) 

However, Move `String` values (used in `TokenDataId`) allow full UTF-8 without normalization, creating the vulnerability.

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria:

**Security Harm:**
- **Token Spoofing**: Attackers create fake tokens appearing identical to legitimate ones
- **Phishing Attacks**: Users misled into purchasing/receiving wrong tokens
- **Marketplace Confusion**: Duplicate-looking entries in NFT marketplaces
- **Potential Fund Loss**: Users trade valuable assets for worthless spoofs through social engineering

**Not Critical/High because:**
- No direct consensus violation or protocol-level exploit
- No automatic fund theft (requires user interaction)
- No validator node compromise
- State remains deterministic (validators agree on distinct byte sequences)

**Scope:**
- Affects all Token v1 collections and tokens with non-ASCII names
- Impacts indexers, explorers, wallets, and marketplaces displaying token data
- Creates trust issues in the NFT ecosystem

## Likelihood Explanation

**Likelihood: High**

**Attacker Requirements:**
- Basic knowledge of Unicode normalization forms (NFC, NFD, NFKC, NFKD)
- Ability to create collections/tokens (minimal gas costs)
- No special permissions or validator access needed

**Feasibility:**
- Unicode normalization attacks are well-documented in security literature
- Tools readily available to generate different Unicode representations
- Attack is deterministic and repeatable
- No special timing or race conditions required

**Exploitation Scenarios:**
1. **High-Value NFT Spoofing**: Attacker mimics popular collections like "Aptos Monkeys" using variant Unicode
2. **Phishing Campaigns**: Direct users to fake marketplaces showing spoofed tokens
3. **Airdrop Scams**: Send fake tokens appearing to be from legitimate projects
4. **Marketplace Manipulation**: Create confusion in search results and listings

## Recommendation

**Immediate Mitigation:**

Implement Unicode normalization (NFC form) in the `create_token_data_id` function:

```move
public fun create_token_data_id(
    creator: address,
    collection: String,
    name: String,
): TokenDataId {
    // Normalize to NFC form before validation
    let normalized_collection = unicode::normalize_nfc(collection);
    let normalized_name = unicode::normalize_nfc(name);
    
    assert!(normalized_collection.length() <= MAX_COLLECTION_NAME_LENGTH, 
            error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
    assert!(normalized_name.length() <= MAX_NFT_NAME_LENGTH, 
            error::invalid_argument(ENFT_NAME_TOO_LONG));
    
    TokenDataId { 
        creator, 
        collection: normalized_collection, 
        name: normalized_name 
    }
}
```

**Implementation Steps:**

1. Add native Unicode normalization function to Move stdlib:
   - Implement `unicode::normalize_nfc()` in Rust using `unicode-normalization` crate
   - Expose as native function to Move

2. Update collection creation to normalize names: [9](#0-8) 

3. Apply normalization consistently across:
   - Collection name validation
   - Token name validation  
   - All string-based lookups and comparisons

4. Document normalization behavior in Token Standard specification

**Alternative Approach:**

Restrict token/collection names to ASCII-only characters (like Move identifiers) to completely avoid Unicode complexity.

## Proof of Concept

```move
#[test_only]
module aptos_token::unicode_spoofing_test {
    use std::string::{Self, String};
    use std::signer;
    use aptos_token::token;
    
    #[test(creator = @0xcafe)]
    fun test_unicode_normalization_attack(creator: &signer) {
        // Setup
        let creator_addr = signer::address_of(creator);
        
        // Create legitimate collection with PRECOMPOSED character é (U+00E9)
        let legit_name = string::utf8(b"Caf\xC3\xA9");  // "Café" with é as single char
        token::create_collection(
            creator,
            legit_name,
            string::utf8(b"Legitimate café collection"),
            string::utf8(b"https://example.com"),
            0,
            vector[false, false, false]
        );
        
        // Attacker creates collection with DECOMPOSED character é (U+0065 U+0301)
        let fake_name = string::utf8(b"Cafe\xCC\x81");  // "Café" with e + combining acute
        token::create_collection(
            creator,
            fake_name,
            string::utf8(b"Fake café collection"),
            string::utf8(b"https://phishing.com"),
            0,
            vector[false, false, false]
        );
        
        // Both collections exist as distinct entities
        let legit_id = token::create_token_data_id(creator_addr, legit_name, string::utf8(b"Token1"));
        let fake_id = token::create_token_data_id(creator_addr, fake_name, string::utf8(b"Token1"));
        
        // Assertion: IDs are different despite visual similarity
        assert!(legit_id != fake_id, 0);
        
        // Both can be queried independently
        assert!(token::check_collection_exists(creator_addr, legit_name), 1);
        assert!(token::check_collection_exists(creator_addr, fake_name), 2);
        
        // Visual representation would appear identical to users:
        // "Café" vs "Café" - but they're distinct on-chain entities
    }
}
```

**Rust Verification Test:**

```rust
#[test]
fn test_unicode_normalization_produces_different_hashes() {
    use unicode_normalization::UnicodeNormalization;
    
    // Precomposed form (NFC)
    let composed = "Café";  // é as U+00E9
    
    // Decomposed form (NFD) 
    let decomposed = "Cafe\u{0301}";  // e + combining acute U+0301
    
    // Visual equality
    assert_eq!(composed.nfc().collect::<String>(), decomposed.nfc().collect::<String>());
    
    // Byte inequality (the vulnerability)
    assert_ne!(composed.as_bytes(), decomposed.as_bytes());
    
    // Different SHA256 hashes (as used by indexer)
    use sha2::{Sha256, Digest};
    let hash1 = Sha256::digest(composed.as_bytes());
    let hash2 = Sha256::digest(decomposed.as_bytes());
    assert_ne!(hash1, hash2);
    
    println!("Composed bytes: {:?}", composed.as_bytes());
    println!("Decomposed bytes: {:?}", decomposed.as_bytes());
}
```

## Notes

**Additional Context:**

1. **Determinism Preserved**: This vulnerability does NOT break consensus - all validators agree on the byte-level representation. The issue is semantic at the user/application layer.

2. **Token v2 Status**: This analysis focuses on Token Standard v1. Token v2 using the object model should be evaluated separately.

3. **Broader Implications**: Similar issues may exist in other string-based identifiers throughout the Aptos ecosystem (account names, domain names, etc.).

4. **Unicode Security**: The Unicode Consortium documents these issues in Unicode Technical Report #36 (Unicode Security Considerations).

5. **Real-World Precedent**: Similar vulnerabilities have affected DNS (IDN homograph attacks), file systems, and other blockchain systems.

### Citations

**File:** aptos-move/framework/aptos-token/sources/token.move (L177-184)
```text
    struct TokenDataId has copy, drop, store {
        /// The address of the creator, eg: 0xcafe
        creator: address,
        /// The name of collection; this is unique under the same account, eg: "Aptos Animal Collection"
        collection: String,
        /// The name of the token; this is the same as the name field of TokenData
        name: String,
    }
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1161-1170)
```text
    public fun create_collection(
        creator: &signer,
        name: String,
        description: String,
        uri: String,
        maximum: u64,
        mutate_setting: vector<bool>
    ) acquires Collections {
        assert!(name.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(uri.length() <= MAX_URI_LENGTH, error::invalid_argument(EURI_TOO_LONG));
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1282-1285)
```text
        assert!(
            !collections.token_data.contains(token_data_id),
            error::already_exists(ETOKEN_DATA_ALREADY_EXISTS),
        );
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1465-1471)
```text
            event::emit_event<MintTokenEvent>(
                &mut Collections[creator_addr].mint_token_events,
                MintTokenEvent {
                    id: token_data_id,
                    amount,
                }
            );
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1538-1546)
```text
    public fun create_token_data_id(
        creator: address,
        collection: String,
        name: String,
    ): TokenDataId {
        assert!(collection.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(name.length() <= MAX_NFT_NAME_LENGTH, error::invalid_argument(ENFT_NAME_TOO_LONG));
        TokenDataId { creator, collection, name }
    }
```

**File:** third_party/move/move-stdlib/sources/string.move (L12-21)
```text
    /// A `String` holds a sequence of bytes which is guaranteed to be in utf8 format.
    struct String has copy, drop, store {
        bytes: vector<u8>,
    }

    /// Creates a new string from a sequence of bytes. Aborts if the bytes do not represent valid utf8.
    public fun utf8(bytes: vector<u8>): String {
        assert!(internal_check_utf8(&bytes), EINVALID_UTF8);
        String{bytes}
    }
```

**File:** crates/indexer/src/models/token_models/token_utils.rs (L46-48)
```rust
    pub fn to_hash(&self) -> String {
        hash_str(&self.to_string())
    }
```

**File:** crates/indexer/src/util.rs (L19-21)
```rust
pub fn hash_str(val: &str) -> String {
    hex::encode(sha2::Sha256::digest(val.as_bytes()))
}
```

**File:** third_party/move/move-core/types/src/identifier.rs (L20-23)
```rust
//! Allowed identifiers are currently restricted to ASCII due to unresolved issues with Unicode
//! normalization. See [Rust issue #55467](https://github.com/rust-lang/rust/issues/55467) and the
//! associated RFC for some discussion. Unicode identifiers may eventually be supported once these
//! issues are worked out.
```
