# Audit Report

## Title
Health Checker State Reconstruction Failure Causes Silent Peer Monitoring Loss After Validator Restart

## Summary
When a validator crashes and restarts with more than 1000 connected peers, the health checker's state reconstruction mechanism silently drops peers beyond the 1000th peer due to a channel capacity limit. These dropped peers are never added to `health_check_data`, causing them to be permanently excluded from health monitoring until they manually disconnect and reconnect.

## Finding Description

The health checker maintains an in-memory `health_check_data` HashMap that tracks which peers to monitor for liveness. [1](#0-0) 

When a validator restarts, the health checker subscribes to connection events to reconstruct its state. The `subscribe()` method attempts to send `NewPeer` events for all currently connected peers: [2](#0-1) 

However, the channel has a fixed capacity of `NOTIFICATION_BACKLOG = 1000`: [3](#0-2) 

When there are more than 1000 connected peers, the `try_send()` call fails with `TrySendError::Full`, causing the loop to break early and log only a warning: [4](#0-3) 

The health checker only adds peers to `health_check_data` when it receives `NewPeer` events: [5](#0-4) 

When performing health checks, the checker queries `connected_peers()` which **only** returns peers from `health_check_data`, not the actual network state: [6](#0-5) 

**Attack Scenario:**
1. Validator runs with 1200 connected peers in a full-mesh validator network
2. Validator crashes and restarts
3. `subscribe()` attempts to send 1200 `NewPeer` events but channel capacity is 1000
4. After 1000 events, `try_send()` fails and the loop breaks with only a warning logged
5. Health checker receives only 1000 events, adding 1000 peers to `health_check_data`
6. The remaining 200 peers exist in `PeersAndMetadata` (still connected) but not in `health_check_data`
7. `connected_peers()` returns only 1000 peers, so the health checker never pings the missing 200
8. If any of those 200 peers become unhealthy, the validator never detects it
9. The validator maintains connections to unhealthy peers, potentially degrading consensus performance

The Aptos validator network explicitly uses full-mesh topology: [7](#0-6) 

While current mainnet has ~129 validators, the documentation states this should "scale up to a few hundred validators": [8](#0-7) 

## Impact Explanation

This is **HIGH severity** per Aptos bug bounty criteria:

1. **Validator node slowdowns**: Unhealthy peers that aren't detected can degrade consensus performance by causing timeouts, message losses, and stalled rounds.

2. **Significant protocol violations**: The health checker protocol is designed to ensure all peers are monitored. This bug silently violates that guarantee, creating a partial network view that can impact consensus liveness.

3. **Network stability degradation**: In a full-mesh network where validators depend on all connections being healthy, undetected unhealthy peers can cause cascading failures affecting multiple validators.

The issue doesn't directly cause consensus safety violations or fund loss, but significantly impacts network reliability and validator operations, qualifying as HIGH severity.

## Likelihood Explanation

**Likelihood: Medium-to-High (depending on network growth)**

Current mainnet has ~129 validators, well below the 1000 threshold. However:

1. **Network growth trajectory**: The codebase is designed for scaling to hundreds of validators, and if growth continues to 1000+, this becomes inevitable.

2. **Automatic trigger**: This is not an attack requiring malicious inputâ€”it happens automatically on any restart when peer count exceeds 1000.

3. **Silent failure**: Only a warning is logged (which may be missed in production logs), making it difficult to detect until consensus performance degrades.

4. **No recovery mechanism**: Once peers are missing, they remain unmonitored until manual reconnection occurs.

The comment in the code acknowledges this risk: [9](#0-8) 

The code sized the buffer for "100 connected peers common, 500 not unexpected" but capped it at 1000, indicating awareness of potential scale issues.

## Recommendation

**Fix 1: Use unbounded channel for initial state reconstruction**

Replace the fixed-capacity channel in `subscribe()` with an unbounded channel for the initial burst:

```rust
pub fn subscribe(&self) -> tokio::sync::mpsc::Receiver<ConnectionNotification> {
    // Use unbounded channel for initial state sync to avoid dropping peers
    let (sender, receiver) = tokio::sync::mpsc::unbounded_channel();
    let peers_and_metadata = self.peers_and_metadata.read();
    
    for (network_id, network_peers_and_metadata) in peers_and_metadata.iter() {
        for (_addr, peer_metadata) in network_peers_and_metadata.iter() {
            let event = ConnectionNotification::NewPeer(
                peer_metadata.connection_metadata.clone(),
                *network_id,
            );
            // unbounded_send cannot fail due to capacity
            if let Err(err) = sender.send(event) {
                warn!("could not send initial NewPeer on subscribe(): {:?}", err);
                break;
            }
        }
    }
    
    // Convert to bounded receiver after initial sync
    let (bounded_sender, bounded_receiver) = tokio::sync::mpsc::channel(NOTIFICATION_BACKLOG);
    tokio::spawn(async move {
        // Forward from unbounded to bounded
        while let Some(event) = receiver.recv().await {
            let _ = bounded_sender.send(event).await;
        }
    });
    
    let mut listeners = self.subscribers.lock();
    listeners.push(bounded_sender);
    bounded_receiver
}
```

**Fix 2: Reconcile health_check_data with actual network state**

Add a periodic reconciliation in the health checker to detect and add missing peers:

```rust
// In HealthChecker::start(), add a periodic reconciliation timer
let reconciliation_interval = Duration::from_secs(60);
let mut reconciliation_ticker = self.time_service.interval(reconciliation_interval);

// In the main event loop:
_ = reconciliation_ticker.select_next_some() => {
    // Get actual connected peers from PeersAndMetadata
    if let Ok(connected_peers) = self.network_interface
        .get_peers_and_metadata()
        .get_connected_peers_and_metadata()
    {
        for (peer_network_id, _) in connected_peers {
            if peer_network_id.network_id() == self_network_id {
                // Add any missing peers to health_check_data
                self.network_interface.create_peer_and_health_data(
                    peer_network_id.peer_id(),
                    self.round
                );
            }
        }
    }
}
```

**Fix 3: Make the issue detectable**

Upgrade the warning to an error and add metrics:

```rust
if let Err(err) = sender.try_send(event) {
    error!("Failed to send initial NewPeer on subscribe() - peers may be missing from health checks: {:?}", err);
    counters::HEALTH_CHECKER_MISSED_PEERS.inc();
    break 'outer;
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_health_checker_state_reconstruction_overflow() {
    use crate::{
        application::storage::PeersAndMetadata,
        peer_manager::ConnectionNotification,
        protocols::health_checker::{HealthChecker, HealthCheckNetworkInterface},
        transport::ConnectionMetadata,
    };
    use aptos_config::network_id::NetworkId;
    use std::time::Duration;
    
    // Create PeersAndMetadata with more than NOTIFICATION_BACKLOG (1000) peers
    let network_id = NetworkId::Validator;
    let peers_and_metadata = PeersAndMetadata::new(&[network_id]);
    let num_peers = 1200;
    
    // Add 1200 peers to PeersAndMetadata
    for i in 0..num_peers {
        let mut peer_id_bytes = [0u8; 32];
        peer_id_bytes[0..4].copy_from_slice(&(i as u32).to_le_bytes());
        let peer_id = PeerId::new(peer_id_bytes);
        
        let connection_metadata = ConnectionMetadata::mock(peer_id);
        peers_and_metadata.insert_connection_metadata(
            PeerNetworkId::new(network_id, peer_id),
            connection_metadata,
        ).unwrap();
    }
    
    // Subscribe to connection events (simulating health checker restart)
    let connection_events_rx = peers_and_metadata.subscribe();
    
    // Collect all received events
    let mut received_count = 0;
    let mut connection_events_rx = 
        tokio_stream::wrappers::ReceiverStream::new(connection_events_rx);
    
    while let Some(_event) = connection_events_rx.next().await {
        received_count += 1;
        // Process a limited number to avoid hanging
        if received_count >= 1100 {
            break;
        }
    }
    
    // VULNERABILITY: Only 1000 NewPeer events are received, 200 are lost
    assert!(received_count <= 1000, 
        "Expected at most 1000 events due to NOTIFICATION_BACKLOG, got {}", 
        received_count);
    
    println!("Created {} peers, but only received {} NewPeer events", 
        num_peers, received_count);
    println!("Missing {} peers that will not be health-checked!", 
        num_peers - received_count);
}
```

## Notes

This vulnerability demonstrates a critical gap between the actual network connectivity state (`PeersAndMetadata`) and the health checker's view (`health_check_data`). The silent failure mode makes it particularly dangerous as validators may run with degraded monitoring for extended periods without operator awareness. The issue becomes more severe as the Aptos network scales toward its stated goal of supporting hundreds of validators in a full-mesh topology.

### Citations

**File:** network/framework/src/protocols/health_checker/interface.rs (L40-40)
```rust
    health_check_data: RwLock<HashMap<PeerId, HealthCheckData>>,
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L59-61)
```rust
    pub fn connected_peers(&self) -> Vec<PeerId> {
        self.health_check_data.read().keys().cloned().collect()
    }
```

**File:** network/framework/src/application/storage.rs (L31-34)
```rust
// notification_backlog is how many ConnectionNotification items can be queued waiting for an app to receive them.
// Beyond this, new messages will be dropped if the app is not handling them fast enough.
// We make this big enough to fit an initial burst of _all_ the connected peers getting notified.
// Having 100 connected peers is common, 500 not unexpected
```

**File:** network/framework/src/application/storage.rs (L35-35)
```rust
const NOTIFICATION_BACKLOG: usize = 1000;
```

**File:** network/framework/src/application/storage.rs (L397-419)
```rust
    /// subscribe() returns a channel for receiving NewPeer/LostPeer events.
    /// subscribe() immediately sends all* current connections as NewPeer events.
    /// (* capped at NOTIFICATION_BACKLOG, currently 1000, use get_connected_peers() to be sure)
    pub fn subscribe(&self) -> tokio::sync::mpsc::Receiver<ConnectionNotification> {
        let (sender, receiver) = tokio::sync::mpsc::channel(NOTIFICATION_BACKLOG);
        let peers_and_metadata = self.peers_and_metadata.read();
        'outer: for (network_id, network_peers_and_metadata) in peers_and_metadata.iter() {
            for (_addr, peer_metadata) in network_peers_and_metadata.iter() {
                let event = ConnectionNotification::NewPeer(
                    peer_metadata.connection_metadata.clone(),
                    *network_id,
                );
                if let Err(err) = sender.try_send(event) {
                    warn!("could not send initial NewPeer on subscribe(): {:?}", err);
                    break 'outer;
                }
            }
        }
        // I expect the peers_and_metadata read lock to still be in effect until after listeners.push() below
        let mut listeners = self.subscribers.lock();
        listeners.push(sender);
        receiver
    }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L211-217)
```rust
                        ConnectionNotification::NewPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.create_peer_and_health_data(
                                    metadata.remote_peer_id, self.round
                                );
                            }
```

**File:** network/README.md (L33-34)
```markdown
Each member of the validator network maintains a full membership view and connects
directly to all other validators in order to maintain a full-mesh network.
```

**File:** network/README.md (L45-46)
```markdown
This approach should scale up to a few hundred validators before requiring
partial membership views, sophisticated failure detectors, or network overlays.
```
