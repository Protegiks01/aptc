# Audit Report

## Title
Database Corruption Masking in Replay Verification Tool Due to Silent Panic Recovery

## Summary
The `Verifier::new()` function in the replay-on-archive tool catches and suppresses panics when opening the database in write mode, then continues with readonly mode. If the panic was caused by database corruption, the verification proceeds against corrupted data, invalidating all verification results and masking critical data integrity issues.

## Finding Description

The vulnerability exists in the database opening logic of the replay verification tool: [1](#0-0) 

The code attempts to open the database in write mode within a `panic::catch_unwind` block. If any panic occurs (including corruption-related panics), it only logs a warning and continues by opening the database in readonly mode.

**The broken security guarantee:** The replay verification tool is designed to validate blockchain state integrity by re-executing transactions and comparing results against stored data. When database corruption exists:

1. **Source of corruption:** RocksDB can panic during write-mode opening due to WAL corruption, manifest file corruption, or LSM tree inconsistencies. [2](#0-1) 

2. **Corruption propagation:** The verification reads "expected" transaction data from the corrupted database via `BackupHandler::get_transaction_iter()`: [3](#0-2) 

3. **State corruption:** Transaction execution uses state from the same corrupted database: [4](#0-3) 

4. **False validation:** The tool compares execution results against expected values, both from the corrupted database, creating a "garbage-in, garbage-out" scenario: [5](#0-4) 

**Attack scenario:** While this tool is not directly exploitable by remote attackers, it creates a critical defense-in-depth failure:
- If database corruption occurs (through filesystem issues, hardware failures, or bugs in write paths)
- Operators run replay-on-archive to verify integrity
- The tool reports success, giving false confidence in corrupted data
- Corrupted state could propagate through state sync or backups

## Impact Explanation

This issue is classified as **High Severity** under operational tooling criteria, though it does not directly fit the standard bug bounty categories:

- **Not Network-Exploitable:** Requires existing filesystem access or pre-existing corruption
- **Defense-in-Depth Failure:** Bypasses the integrity verification mechanism designed to detect corruption
- **Operational Impact:** Node operators rely on this tool for integrity verification in production workflows [6](#0-5) 

The tool is used in critical verification workflows but is not part of the consensus or execution critical path, limiting direct security impact.

## Likelihood Explanation

**Likelihood: Medium**
- Database corruption can occur through hardware failures, filesystem issues, or software bugs
- The replay-on-archive tool is actively used in production verification workflows
- However, exploitation requires pre-existing corruption or filesystem access
- The vulnerability manifests when operators specifically run verification after corruption occurs

## Recommendation

**Immediate fix:** Propagate the write-mode open failure instead of suppressing it:

```rust
pub fn new(config: &Opt) -> Result<Self> {
    // Open in write mode to create any new DBs necessary.
    // This also validates database integrity with stricter checks.
    AptosDB::open(
        StorageDirPaths::from_path(config.db_dir.as_path()),
        false, // write mode
        NO_OP_STORAGE_PRUNER_CONFIG,
        config.rocksdb_opt.clone().into(),
        false,
        BUFFERED_STATE_TARGET_ITEMS,
        DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
        None,
        HotStateConfig::default(),
    )?;

    // Now open in readonly mode for verification
    let aptos_db = AptosDB::open(
        StorageDirPaths::from_path(config.db_dir.as_path()),
        true, // readonly
        NO_OP_STORAGE_PRUNER_CONFIG,
        config.rocksdb_opt.clone().into(),
        false,
        BUFFERED_STATE_TARGET_ITEMS,
        DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
        None,
        HotStateConfig {
            delete_on_restart: false,
            ..Default::default()
        },
    )?;
    // ... rest of initialization
}
```

Remove the `panic::catch_unwind` wrapper and let errors propagate normally. If write-mode opening fails, the tool should exit with a clear error message rather than masking the corruption.

## Proof of Concept

**Note:** This is an operational tool vulnerability, not a network-exploitable issue. A proof of concept would require:

1. Creating a corrupted RocksDB database that fails write-mode open but succeeds readonly open
2. Running the replay-on-archive tool against it
3. Observing that verification reports success despite corruption

This cannot be demonstrated through standard Move tests or network attacks, as it requires filesystem-level manipulation of the database.

**Validation Checkpoint:** âŒ This issue **does not meet** the strict validation criteria for a bug bounty submission because:
- Not exploitable by unprivileged attackers without filesystem access
- Requires pre-existing corruption or insider access
- Affects operational tooling, not the core protocol security

While this is a legitimate code quality and operational reliability issue that should be fixed, it does not qualify as a security vulnerability per the defined bounty criteria.

### Citations

**File:** storage/db-tool/src/replay_on_archive.rs (L150-183)
```rust
    pub fn new(config: &Opt) -> Result<Self> {
        // Open in write mode to create any new DBs necessary.
        {
            if let Err(e) = panic::catch_unwind(|| {
                AptosDB::open(
                    StorageDirPaths::from_path(config.db_dir.as_path()),
                    false,
                    NO_OP_STORAGE_PRUNER_CONFIG,
                    config.rocksdb_opt.clone().into(),
                    false,
                    BUFFERED_STATE_TARGET_ITEMS,
                    DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
                    None,
                    HotStateConfig::default(),
                )
            }) {
                warn!("Unable to open AptosDB in write mode: {:?}", e);
            };
        }

        let aptos_db = AptosDB::open(
            StorageDirPaths::from_path(config.db_dir.as_path()),
            true,
            NO_OP_STORAGE_PRUNER_CONFIG,
            config.rocksdb_opt.clone().into(),
            false,
            BUFFERED_STATE_TARGET_ITEMS,
            DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
            None,
            HotStateConfig {
                delete_on_restart: false,
                ..Default::default()
            },
        )?;
```

**File:** storage/db-tool/src/replay_on_archive.rs (L375-387)
```rust
        let executed_outputs = executor
            .execute_block(
                &txns_provider,
                &self
                    .arc_db
                    .state_view_at_version(current_version.checked_sub(1))?,
                BlockExecutorConfigFromOnchain::new_no_block_limit(),
                TransactionSliceMetadata::Chunk {
                    begin: *current_version,
                    end: *current_version + cur_txns.len() as u64,
                },
            )
            .map(BlockOutput::into_transaction_outputs_forced)?;
```

**File:** storage/db-tool/src/replay_on_archive.rs (L394-407)
```rust
            if let Err(err) = executed_outputs[idx].ensure_match_transaction_info(
                version,
                &expected_txn_infos[idx],
                Some(&expected_writesets[idx]),
                Some(&expected_events[idx]),
            ) {
                cur_txns.drain(0..idx + 1);
                cur_persisted_aux_info.drain(0..idx + 1);
                expected_txn_infos.drain(0..idx + 1);
                expected_events.drain(0..idx + 1);
                expected_writesets.drain(0..idx + 1);

                return Ok(Some(err));
            }
```

**File:** storage/schemadb/src/lib.rs (L389-407)
```rust
fn to_db_err(rocksdb_err: rocksdb::Error) -> AptosDbError {
    match rocksdb_err.kind() {
        ErrorKind::Incomplete => AptosDbError::RocksDbIncompleteResult(rocksdb_err.to_string()),
        ErrorKind::NotFound
        | ErrorKind::Corruption
        | ErrorKind::NotSupported
        | ErrorKind::InvalidArgument
        | ErrorKind::IOError
        | ErrorKind::MergeInProgress
        | ErrorKind::ShutdownInProgress
        | ErrorKind::TimedOut
        | ErrorKind::Aborted
        | ErrorKind::Busy
        | ErrorKind::Expired
        | ErrorKind::TryAgain
        | ErrorKind::CompactionTooLarge
        | ErrorKind::ColumnFamilyDropped
        | ErrorKind::Unknown => AptosDbError::OtherRocksDbError(rocksdb_err.to_string()),
    }
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L40-76)
```rust
    /// Gets an iterator that yields a range of transactions.
    pub fn get_transaction_iter(
        &self,
        start_version: Version,
        num_transactions: usize,
    ) -> Result<
        impl Iterator<
                Item = Result<(
                    Transaction,
                    PersistedAuxiliaryInfo,
                    TransactionInfo,
                    Vec<ContractEvent>,
                    WriteSet,
                )>,
            > + '_,
    > {
        let txn_iter = self
            .ledger_db
            .transaction_db()
            .get_transaction_iter(start_version, num_transactions)?;
        let mut txn_info_iter = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_iter(start_version, num_transactions)?;
        let mut event_vec_iter = self
            .ledger_db
            .event_db()
            .get_events_by_version_iter(start_version, num_transactions)?;
        let mut write_set_iter = self
            .ledger_db
            .write_set_db()
            .get_write_set_iter(start_version, num_transactions)?;
        let mut persisted_aux_info_iter = self
            .ledger_db
            .persisted_auxiliary_info_db()
            .get_persisted_auxiliary_info_iter(start_version, num_transactions)?;

```

**File:** testsuite/replay-verify/main.py (L1-50)
```python
import argparse
import datetime
from enum import Enum
from google.cloud import storage
import json
from kubernetes import client, config as KubernetesConfig
from kubernetes.client.rest import ApiException
import logging
import os
import sys
from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type
import time
import urllib.parse
import yaml


sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from testsuite import forge
from archive_disk_utils import (
    TESTNET_SNAPSHOT_NAME,
    MAINNET_SNAPSHOT_NAME,
    create_replay_verify_pvcs_from_existing,
    create_replay_verify_pvcs_from_snapshot,
    get_kubectl_credentials,
)

SHARDING_ENABLED = True
MAX_RETRIES = 5
RETRY_DELAY = 20  # seconds
QUERY_DELAY = 5  # seconds
TEARDOWN_DELAY = 30 * 60  # 30 minutes slack to allow for pod setup and teardown

REPLAY_CONCURRENCY_LEVEL = 1

INT64_MAX = 9_223_372_036_854_775_807


class Network(Enum):
    TESTNET = 1
    MAINNET = 2

    def __str__(self):
        return self.name.lower()

    @classmethod
    def from_string(cls, name: str):
        try:
            return cls[name.upper()]
        except KeyError:
```
