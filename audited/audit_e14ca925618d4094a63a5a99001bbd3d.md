# Audit Report

## Title
Unbounded Concurrent Connection Upgrade Tasks Leading to Async Runtime Exhaustion

## Summary
The `TransportHandler` in the network layer does not limit the number of concurrent connection upgrade operations, allowing an attacker to overwhelm the async runtime with unbounded tasks performing expensive cryptographic operations (Noise handshakes), causing validator node performance degradation.

## Finding Description

The vulnerability exists in the `TransportHandler::listen()` method which manages inbound and outbound connection upgrades. The handler uses two `FuturesUnordered` collections to track pending connection upgrades without any limit on the number of concurrent tasks: [1](#0-0) 

When new inbound connections arrive, they are immediately added to `pending_inbound_connections` without checking capacity: [2](#0-1) 

Similarly, dial requests are added to `pending_outbound_connections` without limit checking: [3](#0-2) 

Each connection upgrade involves expensive operations including Noise cryptographic handshake and protocol negotiation: [4](#0-3) 

The critical issue is that the connection limit check happens in `PeerManager::handle_new_connection_event()` AFTER the upgrade completes: [5](#0-4) 

**Attack Path:**
1. Attacker rapidly initiates many TCP connections to the validator's listening port
2. Each connection is accepted and wrapped in an upgrade future
3. All futures are pushed to `pending_inbound_connections` without limit checking
4. Each upgrade performs expensive Noise handshake concurrently
5. Only after upgrade completes does PeerManager check the connection limit
6. Rejected connections have already consumed significant CPU/memory resources

This contrasts with the RPC layer which explicitly checks limits BEFORE adding tasks: [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program ("Validator node slowdowns"). An attacker can cause:

1. **CPU Exhaustion**: Unbounded concurrent Noise handshakes consume CPU cycles for cryptographic operations
2. **Memory Exhaustion**: Each pending upgrade task allocates memory for buffers and state machines
3. **Runtime Degradation**: The async executor becomes overloaded with too many concurrent tasks
4. **Consensus Impact**: Degraded validator performance may affect block proposal/voting timing

While this doesn't directly break consensus safety, it can cause liveness issues by making validators slow to respond, potentially leading to missed rounds or reduced network throughput.

## Likelihood Explanation

**Likelihood: High**

The attack is trivial to execute:
- Requires only network access to validator listening port (publicly exposed)
- No authentication needed before upgrade starts
- No special resources or insider access required
- Can be scripted with standard networking tools

The vulnerability is always present unless operators manually configure rate limiting (which is optional and defaults to None): [7](#0-6) 

Even with rate limiting configured, it only throttles bytes, not the number of concurrent upgrade tasks.

## Recommendation

Implement a bounded limit on concurrent connection upgrades in `TransportHandler`, similar to the RPC implementation. Add a configuration parameter `max_concurrent_connection_upgrades` and check it before adding futures to the pending collections:

```rust
pub struct TransportHandler<TTransport, TSocket> {
    // ... existing fields ...
    max_concurrent_connection_upgrades: usize,
}

pub async fn listen(mut self) {
    let mut pending_inbound_connections = FuturesUnordered::new();
    let mut pending_outbound_connections = FuturesUnordered::new();

    loop {
        futures::select! {
            dial_request = self.transport_reqs_rx.select_next_some() => {
                // Check limit before adding
                if pending_outbound_connections.len() < self.max_concurrent_connection_upgrades {
                    if let Some(fut) = self.dial_peer(dial_request) {
                        pending_outbound_connections.push(fut);
                    }
                } else {
                    // Reject or queue the request
                    warn!("Outbound connection upgrade queue at capacity");
                }
            },
            inbound_connection = self.listener.select_next_some() => {
                // Check limit before adding
                if pending_inbound_connections.len() < self.max_concurrent_connection_upgrades {
                    if let Some(fut) = self.upgrade_inbound_connection(inbound_connection) {
                        pending_inbound_connections.push(fut);
                    }
                } else {
                    // Drop the connection immediately
                    warn!("Inbound connection upgrade queue at capacity");
                    counters::connections_rejected(&self.network_context, ConnectionOrigin::Inbound).inc();
                }
            },
            // ... rest of select branches ...
        }
    }
}
```

Recommended default: `max_concurrent_connection_upgrades = 100` (aligned with `MAX_INBOUND_CONNECTIONS`).

## Proof of Concept

```rust
#[tokio::test]
async fn test_unbounded_connection_upgrade_exhaustion() {
    use tokio::net::TcpStream;
    use std::time::Duration;
    
    // Start a validator node with default network config
    let validator_addr = "127.0.0.1:6180"; // Default listen address
    
    // Spawn many concurrent connection attempts
    let mut handles = vec![];
    for _ in 0..1000 {
        let addr = validator_addr.to_string();
        let handle = tokio::spawn(async move {
            // Open TCP connection but don't complete handshake
            // This keeps the upgrade future in pending_inbound_connections
            if let Ok(stream) = TcpStream::connect(&addr).await {
                // Hold connection open
                tokio::time::sleep(Duration::from_secs(30)).await;
                drop(stream);
            }
        });
        handles.push(handle);
        
        // Small delay to avoid local port exhaustion
        tokio::time::sleep(Duration::from_millis(10)).await;
    }
    
    // Monitor validator metrics
    // Expected: pending_connection_upgrades counter grows unbounded
    // Expected: CPU usage spikes from concurrent Noise handshakes
    // Expected: Memory usage increases from task allocation
    
    for handle in handles {
        let _ = handle.await;
    }
}
```

Run this test against a live validator node and observe:
1. `aptos_network_pending_connection_upgrades` metric growing unbounded
2. CPU utilization spike from concurrent cryptographic operations
3. Increased memory usage from task state allocation
4. Degraded response time for legitimate connections

**Notes**

The vulnerability breaks the Resource Limits invariant by allowing unbounded consumption of computational resources (CPU for cryptographic operations, memory for task state) without proper bounds checking. While the `PeerManager` enforces a connection limit, this check occurs too late in the pipelineâ€”after expensive upgrade operations have already been performed. The design should follow the principle established in the RPC layer where limits are enforced at task creation time, not completion time.

### Citations

**File:** network/framework/src/peer_manager/transport.rs (L90-92)
```rust
    pub async fn listen(mut self) {
        let mut pending_inbound_connections = FuturesUnordered::new();
        let mut pending_outbound_connections = FuturesUnordered::new();
```

**File:** network/framework/src/peer_manager/transport.rs (L101-104)
```rust
                dial_request = self.transport_reqs_rx.select_next_some() => {
                    if let Some(fut) = self.dial_peer(dial_request) {
                        pending_outbound_connections.push(fut);
                    }
```

**File:** network/framework/src/peer_manager/transport.rs (L106-109)
```rust
                inbound_connection = self.listener.select_next_some() => {
                    if let Some(fut) = self.upgrade_inbound_connection(inbound_connection) {
                        pending_inbound_connections.push(fut);
                    }
```

**File:** network/framework/src/transport/mod.rs (L277-293)
```rust
    let (mut socket, remote_peer_id, peer_role) =
        ctxt.noise.upgrade_inbound(socket).await.map_err(|err| {
            if err.should_security_log() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(15)),
                    warn!(
                        SecurityEvent::NoiseHandshake,
                        NetworkSchema::new(&ctxt.noise.network_context)
                            .network_address(&addr)
                            .connection_origin(&origin),
                        error = %err,
                    )
                );
            }
            let err = io::Error::other(err);
            add_pp_addr(proxy_protocol_enabled, err, &addr)
        })?;
```

**File:** network/framework/src/peer_manager/mod.rs (L352-388)
```rust
        if conn.metadata.origin == ConnectionOrigin::Inbound {
            // Everything below here is meant for unknown peers only. The role comes from
            // the Noise handshake and if it's not `Unknown` then it is trusted.
            if conn.metadata.role == PeerRole::Unknown {
                // TODO: Keep track of somewhere else to not take this hit in case of DDoS
                // Count unknown inbound connections
                let unknown_inbound_conns = self
                    .active_peers
                    .iter()
                    .filter(|(peer_id, (metadata, _))| {
                        metadata.origin == ConnectionOrigin::Inbound
                            && trusted_peers
                                .get(peer_id)
                                .is_none_or(|peer| peer.role == PeerRole::Unknown)
                    })
                    .count();

                // Reject excessive inbound connections made by unknown peers
                // We control outbound connections with Connectivity manager before we even send them
                // and we must allow connections that already exist to pass through tie breaking.
                if !self
                    .active_peers
                    .contains_key(&conn.metadata.remote_peer_id)
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .connection_metadata_with_address(&conn.metadata),
                        "{} Connection rejected due to connection limit: {}",
                        self.network_context,
                        conn.metadata
                    );
                    counters::connections_rejected(&self.network_context, conn.metadata.origin)
                        .inc();
                    self.disconnect(conn);
                    return;
                }
```

**File:** network/framework/src/protocols/rpc/mod.rs (L213-223)
```rust
        if self.inbound_rpc_tasks.len() as u32 == self.max_concurrent_inbound_rpcs {
            // Increase counter of declined requests
            counters::rpc_messages(
                network_context,
                REQUEST_LABEL,
                INBOUND_LABEL,
                DECLINED_LABEL,
            )
            .inc();
            return Err(RpcError::TooManyPending(self.max_concurrent_inbound_rpcs));
        }
```

**File:** config/src/config/network_config.rs (L158-159)
```rust
            inbound_rate_limit_config: None,
            outbound_rate_limit_config: None,
```
