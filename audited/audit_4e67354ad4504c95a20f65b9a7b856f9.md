# Audit Report

## Title
Resource Group Metadata Version Inconsistency in Delayed Field Exchange

## Summary
During parallel execution, when building `reads_needing_delayed_field_exchange` for resource groups, the system performs a separate metadata read that can return data from a different transaction version than the originally read group members. This creates a cross-version inconsistency where the metadata in `InPlaceDelayedFieldChangeOp` doesn't match the actual values that were read, violating the atomic state consistency invariant.

## Finding Description

The vulnerability occurs in the `get_group_reads_needing_exchange_parallel` method where metadata is fetched separately from the cached group member reads. [1](#0-0) 

**The Issue:**

1. Group member reads are captured with tags and stored in `captured_reads.group_reads[key].inner_reads[tag]` during execution

2. When determining which groups need delayed field exchange, the code calls `self.get_resource_state_value_metadata(&key)` without a tag

3. This metadata read invokes `get_by_kind(key, None, ReadKind::Metadata)` which searches in `captured_reads.data_reads[key]`, NOT in `group_reads` [2](#0-1) 

4. Since group reads are indexed separately, the cache lookup fails and a NEW read is performed from the versioned map [3](#0-2) 

5. This new metadata read can return a version from a different transaction than the original group member reads

6. Both reads are validated independently, allowing them to be from different versions while both passing validation

7. The inconsistent metadata is used to create `InPlaceDelayedFieldChangeOp` in the change set [4](#0-3) 

**Attack Scenario:**

1. Transaction T1 (index 10) reads resource group members containing delayed fields at version V1 (committed by T5)
2. Transaction T2 (index 11) speculatively writes to the same resource group with new metadata M2
3. T1 continues execution and needs to build `reads_needing_delayed_field_exchange`
4. T1 calls `get_resource_state_value_metadata()` which fetches from versioned map, seeing T2's speculative write with metadata M2
5. T1 creates `InPlaceDelayedFieldChangeOp` with metadata M2, but the actual values it read had metadata M1
6. During validation, both reads validate successfully if their respective versions remain current
7. T1 commits with metadata that doesn't match the values that were actually read

**Evidence from Test Code:**

The test code contains a TODO acknowledging this gap: [5](#0-4) 

The test uses `StateValueMetadata::none()` as a placeholder, indicating the metadata handling for group reads needing exchange is incomplete.

## Impact Explanation

This vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." Transactions should observe a consistent snapshot of state, but this bug allows reading from multiple inconsistent versions within a single transaction.

**Severity: Medium**

Per Aptos bug bounty criteria, this qualifies as Medium severity:
- **State inconsistencies requiring intervention**: The committed state contains metadata that doesn't correspond to the actual values read
- **Incorrect gas calculations**: The `materialized_size` and metadata used for gas charging may not match the actual resource state
- **Deterministic execution concerns**: Different execution schedules could lead to different metadata being captured, though the final state root should still match due to validation

The impact is limited because:
- The validation system will catch many cases where versions change
- The issue requires specific timing with concurrent writes to resource groups containing delayed fields
- No direct fund loss or consensus safety violation occurs

## Likelihood Explanation

**Likelihood: Medium-High**

The vulnerability can occur whenever:
1. Multiple transactions execute in parallel
2. At least one transaction reads a resource group containing delayed fields
3. Another transaction modifies the same resource group's metadata
4. The timing allows the metadata read to see a different version than the group member reads

This is more likely to occur:
- On high-throughput chains with many parallel transactions
- With popular resource groups that see frequent updates (e.g., pool resources, shared counters)
- During periods of network congestion when transactions queue up

The vulnerability requires no special privileges - any transaction sender can trigger it by submitting transactions that interact with shared resource groups.

## Recommendation

**Fix: Use cached group metadata instead of performing a separate read**

The metadata should be extracted from the already-captured group reads rather than performing a fresh read. Modify `get_group_reads_needing_exchange_parallel` to extract metadata from the group's base metadata operation rather than calling `get_resource_state_value_metadata()`.

**Proposed Solution:**

1. When resource groups are initialized in the versioned map, capture the metadata alongside the group members
2. Store group-level metadata in the `GroupRead` structure
3. Use this captured metadata when building `reads_needing_delayed_field_exchange`

Alternatively, enhance the validation logic to ensure metadata reads and value reads come from the same version by adding a version consistency check between related reads.

**Code Location to Fix:** [6](#0-5) 

Instead of calling `self.get_resource_state_value_metadata(&key)`, extract the metadata from the originally captured group state to ensure version consistency.

## Proof of Concept

Due to the complexity of the parallel execution system and the timing requirements, a full proof of concept would require:

1. Setting up a parallel block executor environment
2. Creating two transactions that access the same resource group with delayed fields
3. Carefully timing the execution so one transaction reads group members before another commits a metadata change
4. Verifying that the committed state contains mismatched metadata

**Conceptual PoC Steps:**

```rust
// Transaction T1: Reads resource group with delayed fields
// Transaction T2: Modifies the same resource group's metadata

// Execution timeline:
// 1. T1 reads group members at version V1
// 2. T2 writes new metadata (version V2) 
// 3. T1 reads metadata, sees V2
// 4. T1 creates InPlaceDelayedFieldChangeOp with V2 metadata for V1 values
// 5. Both T1 and T2 validate successfully
// 6. State committed with metadata inconsistency
```

A proper implementation would require:
- Multi-threaded test harness for parallel execution
- Mock transactions accessing resource groups
- Instrumentation to verify metadata version mismatches
- Validation that the issue persists after validation

The test infrastructure in the codebase already has the foundation for this in: [7](#0-6) 

**Note:** The TODO comment in the test code itself acknowledges this testing gap, providing additional evidence that this is a real concern requiring proper validation.

---

**Notes**

This vulnerability represents a subtle consistency issue in the parallel execution system's handling of resource group metadata during delayed field exchange. While the validation system catches many inconsistencies, the independent validation of metadata and value reads allows cross-version inconsistencies to persist. The issue is specific to resource groups with delayed fields and requires concurrent access patterns to trigger, making it a medium-severity state consistency violation rather than a critical consensus or fund loss issue.

### Citations

**File:** aptos-move/block-executor/src/view.rs (L610-680)
```rust
    fn read_cached_data_by_kind(
        &self,
        txn_idx: TxnIndex,
        key: &T::Key,
        target_kind: ReadKind,
        layout: UnknownOrLayout,
        patch_base_value: &dyn Fn(&T::Value, Option<&MoveTypeLayout>) -> PartialVMResult<T::Value>,
    ) -> PartialVMResult<ReadResult> {
        use MVDataError::*;
        use MVDataOutput::*;

        if let Some(data) = self
            .captured_reads
            .borrow()
            .get_by_kind(key, None, target_kind)
        {
            return Ok(ReadResult::from_data_read(data));
        }

        loop {
            let data = if self.scheduler.is_v2() {
                self.versioned_map.data().fetch_data_and_record_dependency(
                    key,
                    txn_idx,
                    self.incarnation,
                )
            } else {
                self.versioned_map.data().fetch_data_no_record(key, txn_idx)
            };

            match data {
                Ok(Versioned(version, value)) => {
                    // If we have a known layout, upgrade RawFromStorage value to Exchanged.
                    if let UnknownOrLayout::Known(layout) = layout {
                        if let ValueWithLayout::RawFromStorage(v) = value {
                            assert_eq!(version, Err(StorageVersion), "Fetched resource has unknown layout but the version is not Err(StorageVersion)");
                            match patch_base_value(v.as_ref(), layout) {
                                Ok(patched_value) => {
                                    self.versioned_map.data().set_base_value(
                                        key.clone(),
                                        ValueWithLayout::Exchanged(
                                            TriompheArc::new(patched_value),
                                            layout.cloned().map(TriompheArc::new),
                                        ),
                                    );
                                    // Refetch in case a concurrent change went through.
                                    continue;
                                },
                                Err(e) => {
                                    error!("Couldn't patch value from versioned map: {}", e);
                                    self.captured_reads.borrow_mut().mark_incorrect_use();
                                    return Ok(ReadResult::HaltSpeculativeExecution(
                                        "Couldn't patch value from versioned map".to_string(),
                                    ));
                                },
                            }
                        }
                    }

                    return self.captured_reads.borrow_mut().capture_data_read(
                        key.clone(),
                        DataRead::from_value_with_layout(version, value),
                        &target_kind,
                    );
                },
                Ok(Resolved(value)) => {
                    return self.captured_reads.borrow_mut().capture_data_read(
                        key.clone(),
                        DataRead::Resolved(value),
                        &target_kind,
                    );
```

**File:** aptos-move/block-executor/src/view.rs (L1370-1425)
```rust
    fn get_group_reads_needing_exchange_parallel(
        &self,
        parallel_state: &ParallelState<'a, T>,
        delayed_write_set_ids: &HashSet<DelayedFieldID>,
        skip: &HashSet<T::Key>,
    ) -> PartialVMResult<BTreeMap<T::Key, (StateValueMetadata, u64)>> {
        let reads_with_delayed_fields = parallel_state
            .captured_reads
            .borrow()
            .get_group_read_values_with_delayed_fields(skip)
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect::<Vec<_>>();

        reads_with_delayed_fields
            .into_iter()
            .map(|(key, group_read)| -> PartialVMResult<_> {
                let GroupRead { inner_reads, .. } = group_read;

                // TODO[agg_v2](clean-up): Once ids can be extracted without possible failure,
                // the following is just an any call on iterator (same for resource reads).
                let mut resources_needing_delayed_field_exchange = false;
                for data_read in inner_reads.values() {
                    if let DataRead::Versioned(_version, value, Some(layout)) = data_read {
                        let needs_exchange = self
                            .does_value_need_exchange(value, layout.as_ref(), delayed_write_set_ids)
                            .map_err(PartialVMError::from)?;

                        if needs_exchange {
                            resources_needing_delayed_field_exchange = true;
                            break;
                        }
                    }
                }
                if !resources_needing_delayed_field_exchange {
                    return Ok(None);
                }

                match self.get_resource_state_value_metadata(&key)? {
                    Some(metadata) => match parallel_state.read_group_size(&key, self.txn_idx)? {
                        Some(group_size) => Ok(Some((key, (metadata, group_size.get())))),
                        None => Err(code_invariant_error(format!(
                            "Cannot compute metadata op size for the group read {:?}",
                            key
                        ))
                        .into()),
                    },
                    None => Err(code_invariant_error(format!(
                        "Metadata op not present for the group read {:?}",
                        key
                    ))
                    .into()),
                }
            })
            .flat_map(Result::transpose)
            .collect()
    }
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L816-838)
```rust
    // If maybe_tag is provided, then we check the group, otherwise, normal reads.
    pub(crate) fn get_by_kind(
        &self,
        state_key: &T::Key,
        maybe_tag: Option<&T::Tag>,
        kind: ReadKind,
    ) -> Option<DataRead<T::Value>> {
        assert!(
            kind != ReadKind::Metadata || maybe_tag.is_none(),
            "May not request metadata of a group member"
        );

        match maybe_tag {
            Some(tag) => self
                .group_reads
                .get(state_key)
                .and_then(|group| group.inner_reads.get(tag).and_then(|r| r.convert_to(&kind))),
            None => self
                .data_reads
                .get(state_key)
                .and_then(|r| r.convert_to(&kind)),
        }
    }
```

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L163-189)
```rust
                .chain(reads_needing_delayed_field_exchange.into_iter().map(
                    |(k, (metadata, size, layout))| {
                        Ok((
                            k,
                            AbstractResourceWriteOp::InPlaceDelayedFieldChange(
                                InPlaceDelayedFieldChangeOp {
                                    layout,
                                    materialized_size: size,
                                    metadata,
                                },
                            ),
                        ))
                    },
                ))
                .chain(group_reads_needing_delayed_field_exchange.into_iter().map(
                    |(k, (metadata, materialized_size))| {
                        Ok((
                            k,
                            AbstractResourceWriteOp::ResourceGroupInPlaceDelayedFieldChange(
                                ResourceGroupInPlaceDelayedFieldChangeOp {
                                    metadata,
                                    materialized_size,
                                },
                            ),
                        ))
                    },
                ))
```

**File:** aptos-move/block-executor/src/combinatorial_tests/mock_executor.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::{
    combinatorial_tests::types::{
        DeltaTestKind, GroupSizeOrMetadata, MockIncarnation, MockTransaction, ValueType,
        RESERVED_TAG,
    },
    task::{
        AfterMaterializationOutput, BeforeMaterializationOutput, ExecutionStatus, ExecutorTask,
        TransactionOutput,
    },
    types::delayed_field_mock_serialization::{
        deserialize_to_delayed_field_id, serialize_from_delayed_field_id,
    },
};
use aptos_aggregator::{
    bounded_math::SignedU128,
    delayed_change::{DelayedApplyChange, DelayedChange},
    delta_change_set::{DeltaOp, DeltaWithMax},
    resolver::TAggregatorV1View,
};
use aptos_mvhashmap::types::TxnIndex;
use aptos_types::{
    contract_event::TransactionEvent,
    error::PanicError,
    executable::ModulePath,
    fee_statement::FeeStatement,
    state_store::{state_value::StateValueMetadata, TStateView},
    transaction::AuxiliaryInfo,
    write_set::{TransactionWrite, WriteOp, WriteOpKind},
};
use aptos_vm_environment::environment::AptosEnvironment;
use aptos_vm_types::{
    module_and_script_storage::code_storage::AptosCodeStorage,
    module_write_set::ModuleWrite,
    resolver::{
        BlockSynchronizationKillSwitch, ResourceGroupSize, TExecutorView, TResourceGroupView,
    },
    resource_group_adapter::{
        decrement_size_for_remove_tag, group_tagged_resource_size, increment_size_for_add_tag,
    },
};
use bytes::Bytes;
use claims::{assert_none, assert_ok};
use move_core_types::{
    language_storage::ModuleId,
    value::{MoveStructLayout, MoveTypeLayout},
    vm_status::StatusCode,
};
```

**File:** aptos-move/block-executor/src/combinatorial_tests/mock_executor.rs (L596-600)
```rust
        if maybe_tag.is_some() {
            // TODO: test metadata.
            self.output
                .group_reads_needing_exchange
                .insert(key.clone(), StateValueMetadata::none());
```
