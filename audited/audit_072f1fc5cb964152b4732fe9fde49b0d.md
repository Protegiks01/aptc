# Audit Report

## Title
Fast Sync State Snapshot Finalization Lacks Atomic State Updates Leading to Database Corruption and Consensus Violations

## Summary
The `finalize_state_snapshot()` function in `FastSyncStorageWrapper` fails to provide atomic state updates. When the underlying database finalization fails after partial writes, the fast sync status remains as STARTED, creating a critical read/write database split and leaving the database in a corrupted state. This violates the State Consistency invariant and can lead to consensus failures. [1](#0-0) 

## Finding Description

The vulnerability exists in the interaction between the wrapper's status management and the underlying non-atomic database operations.

**The Critical Flow:**

1. When `finalize_state_snapshot()` is called, it first asserts the status is STARTED, then delegates to the underlying AptosDB implementation. [2](#0-1) 

2. The underlying `finalize_state_snapshot()` in AptosDB performs **multiple non-atomic database writes**: [3](#0-2) 

3. These operations include:
   - **Line 155-160**: `confirm_or_save_frozen_subtrees` with `None` batch parameter, which **immediately commits** to the transaction accumulator database: [4](#0-3) 

   - **Line 223**: Commits the ledger_db_batch with `write_schemas()`
   - **Lines 225-234**: Four separate `save_min_readable_version()` calls, each performing immediate database writes: [5](#0-4) 

4. There is even a **TODO comment acknowledging this atomicity problem**: [6](#0-5) 

**The Vulnerability Trigger:**

If any operation fails after partial writes (e.g., disk I/O error at line 228), the `?` operator causes early return. The wrapper's status update never executes, leaving status as STARTED. [7](#0-6) 

**The Dangerous State:**

With status remaining STARTED:
- **Write operations** go to `db_for_fast_sync` (the main database): [8](#0-7) 

- **Read operations** go to `temporary_db_with_genesis`: [9](#0-8) 

This creates a **read/write split** where the node reads from one database while writing to another. The `db_for_fast_sync` now contains **partial, corrupted state** from the failed finalization.

**Retry Amplifies Corruption:**

When state sync retries after error notification: [10](#0-9) 

The retry calls `get_state_snapshot_receiver` again, which unconditionally sets status to STARTED (already STARTED): [11](#0-10) 

A new snapshot receiver is created on the **already-corrupted** `db_for_fast_sync`, writing new chunks on top of partial data from the failed attempt, causing cascading corruption.

## Impact Explanation

**Severity: CRITICAL** (up to $1,000,000)

This vulnerability breaks multiple critical invariants:

1. **State Consistency Violation**: The fundamental invariant "State transitions must be atomic and verifiable via Merkle proofs" is completely violated. The database contains partial, unverifiable state.

2. **Consensus/Safety Violation**: When the corrupted node computes its state root, it will produce a different hash than correctly-synced validators, causing:
   - The node to reject valid blocks from other validators
   - Other validators to reject blocks proposed by this node
   - Potential network partition if multiple nodes fail identically

3. **Non-Recoverable State**: There is no rollback mechanism. The database corruption is permanent. The node cannot recover without:
   - Manual intervention to delete corrupted databases
   - Complete re-sync from genesis or new snapshot
   - Potential hardfork if the issue affects enough validators

4. **Deterministic Execution Failure**: Validators must produce identical state roots for identical blocks. A corrupted node will compute different state roots, breaking consensus safety.

This meets the **Critical Severity** criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

This vulnerability will trigger whenever:

1. **Disk I/O failures** occur during snapshot finalization (common in cloud environments)
2. **Out of disk space** conditions during batch writes
3. **Database corruption** from underlying RocksDB issues
4. **Power failures** or system crashes mid-write
5. **Resource exhaustion** (file descriptors, memory) during pruner operations
6. **Network interruptions** causing partial downloads that pass validation

The vulnerability is **deterministic** - any failure during the multi-step finalization process will trigger it. Given that:
- Fast sync is the **primary bootstrapping method** for new nodes
- The finalization involves **7+ separate database write operations**
- Each operation can fail independently
- Cloud infrastructure commonly experiences transient failures

The probability of encountering this during production operations is **significant**.

## Recommendation

Implement **atomic state updates** with proper rollback on failure:

```rust
fn finalize_state_snapshot(
    &self,
    version: Version,
    output_with_proof: TransactionOutputListWithProofV2,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    let status = self.get_fast_sync_status();
    assert_eq!(status, FastSyncStatus::STARTED);
    
    // CRITICAL FIX: Wrap in a transaction with explicit rollback
    let result = self.get_aptos_db_write_ref().finalize_state_snapshot(
        version,
        output_with_proof,
        ledger_infos,
    );
    
    // Only update status if finalization COMPLETELY succeeded
    match result {
        Ok(()) => {
            let mut status = self.fast_sync_status.write();
            *status = FastSyncStatus::FINISHED;
            Ok(())
        },
        Err(e) => {
            // On failure, reset status and signal for database cleanup
            let mut status = self.fast_sync_status.write();
            *status = FastSyncStatus::UNKNOWN;
            
            // Clear any partial writes from db_for_fast_sync
            self.cleanup_partial_snapshot(version)?;
            
            Err(e)
        }
    }
}

fn cleanup_partial_snapshot(&self, version: Version) -> Result<()> {
    // Implement rollback of partial writes
    // Truncate db_for_fast_sync to last known good state
    // This requires adding rollback support to all write operations
    todo!("Implement database rollback mechanism")
}
```

**Additionally**, fix the underlying atomicity issue in `aptosdb_writer.rs`:

1. Include `confirm_or_save_frozen_subtrees` in the batch (as the TODO suggests)
2. Make all `save_min_readable_version` operations part of a single atomic batch
3. Implement proper transaction support with rollback across all operations
4. Add database checkpoints before finalization begins

## Proof of Concept

```rust
#[test]
fn test_finalize_state_snapshot_partial_failure() {
    use storage::fast_sync_storage_wrapper::*;
    use aptos_storage_interface::DbWriter;
    
    // Setup: Create FastSyncStorageWrapper with fast sync enabled
    let config = create_test_config_with_fast_sync();
    let wrapper = FastSyncStorageWrapper::initialize_dbs(&config, None, None)
        .unwrap()
        .right()
        .unwrap();
    
    // Step 1: Initialize snapshot receiver (sets status to STARTED)
    let version = 1000;
    let expected_root = HashValue::random();
    let receiver = wrapper.get_state_snapshot_receiver(version, expected_root).unwrap();
    
    // Verify status is STARTED
    assert_eq!(wrapper.get_fast_sync_status(), FastSyncStatus::STARTED);
    
    // Step 2: Add state chunks successfully
    receiver.add_chunk(state_chunks, proof).unwrap();
    receiver.finish_box().unwrap();
    
    // Step 3: Inject failure during finalize_state_snapshot
    // This simulates disk I/O error after confirm_or_save_frozen_subtrees succeeds
    // but before write_schemas completes
    inject_io_error_at_write_schemas();
    
    let output_with_proof = create_test_output_with_proof();
    let ledger_infos = create_test_ledger_infos();
    
    // Step 4: Call finalize_state_snapshot - it will fail partway through
    let result = wrapper.finalize_state_snapshot(version, output_with_proof.clone(), &ledger_infos);
    
    // VULNERABILITY: Status remains STARTED despite failure
    assert!(result.is_err());
    assert_eq!(wrapper.get_fast_sync_status(), FastSyncStatus::STARTED);
    
    // CRITICAL BUG: db_for_fast_sync has partial writes (frozen subtrees committed)
    // but status didn't transition to FINISHED
    
    // Step 5: Demonstrate read/write split
    let write_db = wrapper.get_aptos_db_write_ref(); // Points to db_for_fast_sync
    let read_db = wrapper.get_aptos_db_read_ref();   // Points to temporary_db_with_genesis
    
    // Write operations go to corrupted db_for_fast_sync
    // Read operations go to temporary_db_with_genesis
    assert!(std::ptr::eq(write_db, wrapper.db_for_fast_sync.as_ref()));
    assert!(std::ptr::eq(read_db, wrapper.temporary_db_with_genesis.as_ref()));
    
    // Step 6: Retry creates new snapshot on already-corrupted database
    let receiver2 = wrapper.get_state_snapshot_receiver(version, expected_root).unwrap();
    receiver2.add_chunk(state_chunks, proof).unwrap();
    
    // Now db_for_fast_sync has overlapping partial writes from both attempts
    // leading to permanent corruption
    
    // Step 7: If finalize succeeds on retry, node uses corrupted database
    clear_injected_errors();
    wrapper.finalize_state_snapshot(version, output_with_proof, &ledger_infos).unwrap();
    
    // Status is now FINISHED but database is corrupted
    assert_eq!(wrapper.get_fast_sync_status(), FastSyncStatus::FINISHED);
    
    // Step 8: Verify corruption - state root will be different from correct nodes
    let computed_root = wrapper.get_aptos_db_read_ref().get_state_root(version).unwrap();
    let expected_correct_root = compute_correct_state_root(version);
    
    // CONSENSUS VIOLATION: Different state root than other validators
    assert_ne!(computed_root, expected_correct_root);
}
```

**Notes:**
- The vulnerability is confirmed by the explicit TODO comment acknowledging the non-atomic `confirm_or_save_frozen_subtrees` operation
- Multiple database write operations can fail independently with no rollback
- The status management creates a read/write split that persists across retries
- This breaks the fundamental State Consistency invariant required for consensus safety

### Citations

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L126-132)
```rust
    pub(crate) fn get_aptos_db_read_ref(&self) -> &AptosDB {
        if self.is_fast_sync_bootstrap_finished() {
            self.db_for_fast_sync.as_ref()
        } else {
            self.temporary_db_with_genesis.as_ref()
        }
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L134-140)
```rust
    pub(crate) fn get_aptos_db_write_ref(&self) -> &AptosDB {
        if self.is_fast_sync_bootstrap_started() || self.is_fast_sync_bootstrap_finished() {
            self.db_for_fast_sync.as_ref()
        } else {
            self.temporary_db_with_genesis.as_ref()
        }
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L144-152)
```rust
    fn get_state_snapshot_receiver(
        &self,
        version: Version,
        expected_root_hash: HashValue,
    ) -> Result<Box<dyn StateSnapshotReceiver<StateKey, StateValue>>> {
        *self.fast_sync_status.write() = FastSyncStatus::STARTED;
        self.get_aptos_db_write_ref()
            .get_state_snapshot_receiver(version, expected_root_hash)
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L154-170)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let status = self.get_fast_sync_status();
        assert_eq!(status, FastSyncStatus::STARTED);
        self.get_aptos_db_write_ref().finalize_state_snapshot(
            version,
            output_with_proof,
            ledger_infos,
        )?;
        let mut status = self.fast_sync_status.write();
        *status = FastSyncStatus::FINISHED;
        Ok(())
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-241)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
            ensure!(
                num_transaction_outputs == 1,
                "Number of transaction outputs should == 1, but got: {}",
                num_transaction_outputs
            );
            ensure!(
                num_transaction_infos == 1,
                "Number of transaction infos should == 1, but got: {}",
                num_transaction_infos
            );

            // TODO(joshlind): include confirm_or_save_frozen_subtrees in the change set
            // bundle below.

            // Update the merkle accumulator using the given proof
            let frozen_subtrees = output_with_proof
                .proof
                .ledger_info_to_transaction_infos_proof
                .left_siblings();
            restore_utils::confirm_or_save_frozen_subtrees(
                self.ledger_db.transaction_accumulator_db_raw(),
                version,
                frozen_subtrees,
                None,
            )?;

            // Create a single change set for all further write operations
            let mut ledger_db_batch = LedgerDbSchemaBatches::new();
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
            // Save the target transactions, outputs, infos and events
            let (transactions, outputs): (Vec<Transaction>, Vec<TransactionOutput>) =
                output_with_proof
                    .transactions_and_outputs
                    .into_iter()
                    .unzip();
            let events = outputs
                .clone()
                .into_iter()
                .map(|output| output.events().to_vec())
                .collect::<Vec<_>>();
            let wsets: Vec<WriteSet> = outputs
                .into_iter()
                .map(|output| output.write_set().clone())
                .collect();
            let transaction_infos = output_with_proof.proof.transaction_infos;
            // We should not save the key value since the value is already recovered for this version
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;

            // Save the epoch ending ledger infos
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;

            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;

            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;

            restore_utils::update_latest_ledger_info(self.ledger_db.metadata_db(), ledger_infos)?;
            self.state_store.reset();

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L78-111)
```rust
pub fn confirm_or_save_frozen_subtrees(
    transaction_accumulator_db: &DB,
    num_leaves: LeafCount,
    frozen_subtrees: &[HashValue],
    existing_batch: Option<&mut SchemaBatch>,
) -> Result<()> {
    let positions: Vec<_> = FrozenSubTreeIterator::new(num_leaves).collect();
    ensure!(
        positions.len() == frozen_subtrees.len(),
        "Number of frozen subtree roots not expected. Expected: {}, actual: {}",
        positions.len(),
        frozen_subtrees.len(),
    );

    if let Some(existing_batch) = existing_batch {
        confirm_or_save_frozen_subtrees_impl(
            transaction_accumulator_db,
            frozen_subtrees,
            positions,
            existing_batch,
        )?;
    } else {
        let mut batch = SchemaBatch::new();
        confirm_or_save_frozen_subtrees_impl(
            transaction_accumulator_db,
            frozen_subtrees,
            positions,
            &mut batch,
        )?;
        transaction_accumulator_db.write_schemas(batch)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L47-52)
```rust
    pub(super) fn write_pruner_progress(&self, version: Version) -> Result<()> {
        self.db.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(version),
        )
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L932-952)
```rust
                            if let Err(error) = finalize_storage_and_send_commit(
                                chunk_executor,
                                &mut commit_notification_sender,
                                metadata_storage,
                                state_snapshot_receiver,
                                storage,
                                &epoch_change_proofs,
                                target_output_with_proof,
                                version,
                                &target_ledger_info,
                                last_committed_state_index,
                            )
                            .await
                            {
                                send_storage_synchronizer_error(
                                    error_notification_sender.clone(),
                                    notification_id,
                                    error,
                                )
                                .await;
                            }
```
