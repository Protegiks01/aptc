# Audit Report

## Title
LastVote Corruption Causes Unrecoverable Validator Crash and Potential Safety Violations

## Summary
When LastVote data in ConsensusDB becomes corrupted, validators panic during startup and cannot recover automatically. The panic occurs before fallback recovery mechanisms can activate, requiring manual intervention. If operators delete the corrupted data to restore liveness, validators lose equivocation protection, potentially violating consensus safety guarantees.

## Finding Description

The LastVote is a critical consensus safety mechanism that prevents validators from double-voting (equivocation) on different blocks in the same round. It is stored in ConsensusDB using the SingleEntrySchema. [1](#0-0) 

The vulnerability occurs in the recovery process during validator startup. When the `PersistentLivenessStorage::start()` method attempts to deserialize the LastVote from raw bytes, it uses `.expect()` which causes a panic if deserialization fails: [2](#0-1) 

This panic happens **before** the error handling mechanism at lines 591-594 that would gracefully fall back to `PartialRecoveryData`: [3](#0-2) 

The LastVote is essential for preventing equivocation. SafetyRules checks the cached vote to avoid signing multiple votes for the same round: [4](#0-3) 

**Exploitation Scenario:**
1. Disk corruption, bit flips, or file system errors corrupt the LastVote data in ConsensusDB
2. Validator attempts to restart
3. The `start()` method reads the corrupted bytes and attempts BCS deserialization
4. Deserialization fails, triggering the `.expect()` panic at line 528
5. Validator crashes before reaching the PartialRecoveryData fallback
6. Validator cannot restart without manual intervention

**Safety Violation Scenario:**
If operators manually delete the corrupted LastVote to restore liveness:
1. Validator loses knowledge of what it previously voted for
2. If the validator had already voted in round N for block A
3. After recovery without LastVote, it could vote in round N for block B
4. This equivocation violates consensus safety and could contribute to chain splits

## Impact Explanation

**Critical Severity** per Aptos Bug Bounty criteria:

1. **Total Loss of Liveness**: The validator cannot start and participate in consensus. This directly matches the "Total loss of liveness/network availability" category.

2. **Potential Consensus Safety Violations**: If enough validators experience this issue and operators manually delete corrupted LastVotes, multiple validators could equivocate, violating the consensus safety invariant that prevents double-spending and chain splits under < 1/3 Byzantine faults.

3. **Non-recoverable Without Manual Intervention**: The validator is stuck in a crashed state. Automated recovery is impossible because the panic occurs before error handling.

4. **Network-Wide Impact**: If multiple validators experience disk corruption (e.g., during power outages or storage failures affecting a data center), the network could lose consensus participation from multiple nodes simultaneously.

## Likelihood Explanation

**High Likelihood:**

1. **Disk Corruption is Common**: Storage corruption from bit flips, disk failures, power outages, or file system bugs occurs regularly in production systems.

2. **No Redundancy**: The LastVote has no checksums, validation, or redundant storage that would detect or prevent corruption.

3. **Single Point of Failure**: A single corrupted byte in the LastVote data causes complete validator failure.

4. **Long-Running Validators**: Validators run continuously for extended periods, increasing exposure to storage issues.

5. **Real-World Precedent**: Database corruption is a well-documented cause of node failures in distributed systems.

## Recommendation

Replace the `.expect()` calls with proper error handling that allows fallback to PartialRecoveryData:

**Fix for `persistent_liveness_storage.rs` lines 526-532:**

```rust
let last_vote = raw_data.0.and_then(|bytes| {
    match bcs::from_bytes::<Vote>(&bytes[..]) {
        Ok(vote) => Some(vote),
        Err(e) => {
            error!(error = ?e, "Failed to deserialize last vote, will use partial recovery");
            None
        }
    }
});

let highest_2chain_timeout_cert = raw_data.1.and_then(|bytes| {
    match bcs::from_bytes::<TwoChainTimeoutCertificate>(&bytes) {
        Ok(cert) => Some(cert),
        Err(e) => {
            error!(error = ?e, "Failed to deserialize highest 2-chain timeout cert, will use partial recovery");
            None
        }
    }
});
```

**Additional Recommendations:**

1. **Add Data Validation**: Store checksums alongside LastVote data to detect corruption early.

2. **Implement Redundant Storage**: Keep multiple copies of LastVote with versioning.

3. **Add Recovery Logging**: Log detailed diagnostics when corruption is detected to aid operators.

4. **Manual Recovery Documentation**: Document safe procedures for operators to handle corrupted LastVote scenarios.

5. **Automated Cleanup**: Automatically delete corrupted LastVote and enter recovery mode rather than requiring manual intervention.

## Proof of Concept

**Reproduction Steps:**

1. Start a validator node and let it vote on some blocks
2. Stop the validator
3. Corrupt the LastVote entry in ConsensusDB:
   ```bash
   # Locate ConsensusDB path (typically <data_dir>/consensus_db)
   # Use a hex editor or script to corrupt the single_entry column family
   # Specifically corrupt the entry with key 0x00 (LastVote)
   ```
4. Attempt to restart the validator
5. **Expected Result**: Validator panics with message "unable to deserialize last vote"
6. **Actual Behavior**: Validator cannot start and requires manual intervention

**Rust Test Case:**

```rust
#[test]
fn test_corrupted_last_vote_recovery() {
    use aptos_consensus::consensusdb::ConsensusDB;
    use aptos_consensus::persistent_liveness_storage::StorageWriteProxy;
    use aptos_config::config::NodeConfig;
    use tempfile::TempDir;
    
    let tmp_dir = TempDir::new().unwrap();
    let mut config = NodeConfig::default();
    config.storage.dir = tmp_dir.path().to_path_buf();
    
    // Initialize storage and save a valid vote
    let db = ConsensusDB::new(tmp_dir.path());
    let valid_vote_bytes = vec![0x01, 0x02, 0x03]; // Simplified
    db.save_vote(valid_vote_bytes).unwrap();
    
    // Corrupt the LastVote data
    let corrupted_bytes = vec![0xFF, 0xFF, 0xFF]; // Invalid BCS
    db.save_vote(corrupted_bytes).unwrap();
    
    // Attempt to start - this will panic
    let aptos_db = Arc::new(MockDbReader::new());
    let storage = StorageWriteProxy::new(&config, aptos_db);
    
    // This call will panic with "unable to deserialize last vote"
    let _result = storage.start(false, None);
    // Test demonstrates the panic prevents recovery
}
```

**Notes:**
- The panic occurs in production code, not test code
- No unprivileged attacker can directly corrupt the disk, but environmental factors (hardware failures, OS bugs) can cause corruption
- The vulnerability's severity stems from validators being unable to recover automatically from a realistic failure scenario
- The impact is amplified because operators may unknowingly create safety violations when attempting manual recovery

### Citations

**File:** consensus/src/consensusdb/schema/single_entry/mod.rs (L36-43)
```rust
#[derive(Debug, Eq, PartialEq, FromPrimitive, ToPrimitive)]
#[repr(u8)]
pub enum SingleEntryKey {
    // Used to store the last vote
    LastVote = 0,
    // Two chain timeout cert
    Highest2ChainTimeoutCert = 1,
}
```

**File:** consensus/src/persistent_liveness_storage.rs (L526-528)
```rust
        let last_vote = raw_data
            .0
            .map(|bytes| bcs::from_bytes(&bytes[..]).expect("unable to deserialize last vote"));
```

**File:** consensus/src/persistent_liveness_storage.rs (L591-594)
```rust
            Err(e) => {
                error!(error = ?e, "Failed to construct recovery data");
                LivenessStorageData::PartialRecoveryData(ledger_recovery_data)
            },
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L68-74)
```rust
        // if already voted on this round, send back the previous vote
        // note: this needs to happen after verifying the epoch as we just check the round here
        if let Some(vote) = safety_data.last_vote.clone() {
            if vote.vote_data().proposed().round() == proposed_block.round() {
                return Ok(vote);
            }
        }
```
