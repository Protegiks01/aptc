# Audit Report

## Title
Consensus Observer Liveness Failure Due to Missing Config Consistency Validation in `wait_for_epoch_start()`

## Summary
The `wait_for_epoch_start()` function in `epoch_state.rs` does not validate that `consensus_config`, `execution_config`, and `randomness_config` are internally consistent. This allows contradictory on-chain configurations to cause consensus observer nodes to fail when processing blocks, resulting in a complete liveness failure.

## Finding Description

The vulnerability exists in the consensus observer's epoch initialization flow where three on-chain configurations are extracted and used without validation of their internal consistency. [1](#0-0) 

The function extracts configs from on-chain state but performs NO validation to check if they are compatible with each other: [2](#0-1) 

These configs are then passed to `execution_client.start_epoch()` which computes `randomness_enabled` based on two of the configs: [3](#0-2) 

However, the consensus observer creates dummy randomness channels with no sender: [4](#0-3) 

The pipeline builder is configured with both `is_randomness_enabled` and `rand_check_enabled` from the configs: [5](#0-4) 

When processing blocks, the `rand_check()` function executes with these contradictory settings: [6](#0-5) 

**Attack Scenario:**
1. Malicious governance proposal sets contradictory configs:
   - `OnChainConsensusConfig::V3` or `V4` (where `rand_check_enabled()` returns `false`)
   - `is_vtxn_enabled() = true` 
   - `OnChainRandomnessConfig::V2` (randomness enabled)

2. For consensus observers:
   - `is_randomness_enabled = true && true = true`
   - `rand_check_enabled = false` (V3/V4 don't have this field)
   - No RandManager is created (rand_config passed as None)
   - Dummy `rand_rx` channel created with sender immediately dropped

3. When processing blocks:
   - `rand_check()` doesn't early return (line 700-702 check fails)
   - `rand_check_enabled && !has_randomness = false && X = false`
   - Code awaits on `rand_rx` (line 778-780)
   - Sender was dropped, so receiver immediately fails with error
   - Block execution fails with "randomness tx cancelled"
   - **Consensus observer cannot process ANY blocks**

## Impact Explanation

This is a **HIGH severity** issue per Aptos bug bounty criteria:
- **Validator node slowdowns**: Consensus observer nodes completely fail to process blocks, causing them to fall behind indefinitely
- **Significant protocol violations**: Breaks the consensus liveness invariant that nodes should be able to observe and execute valid blocks

All consensus observer nodes in the network would be affected, unable to process blocks until the contradictory configs are corrected through another governance proposal or the epoch changes with consistent configs.

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability requires:
1. Governance to pass a proposal with contradictory configs (either malicious proposal or configuration error)
2. The specific combination of V3/V4 consensus config + VTXNs enabled + randomness enabled

While this requires governance action, it's realistic because:
- Config upgrades happen during epoch transitions
- The contradiction is subtle and might not be caught in testing
- No validation exists to prevent this combination
- A malicious governance proposal could intentionally exploit this

## Recommendation

Add validation in `wait_for_epoch_start()` or `extract_on_chain_configs()` to ensure config consistency:

```rust
fn validate_config_consistency(
    consensus_config: &OnChainConsensusConfig,
    randomness_config: &OnChainRandomnessConfig,
) -> Result<(), &'static str> {
    // If randomness is enabled, rand_check must be supported (V5+) or vtxn must be disabled
    if randomness_config.randomness_enabled() && consensus_config.is_vtxn_enabled() {
        // For older config versions (V1-V4), rand_check_enabled() returns false
        // This is incompatible with randomness enabled for consensus observers
        if !consensus_config.rand_check_enabled() {
            return Err("Randomness enabled but rand_check not supported in consensus config version");
        }
    }
    Ok(())
}
```

Apply this validation before returning configs:

```rust
// In extract_on_chain_configs(), before the final return:
validate_config_consistency(&consensus_config, &onchain_randomness_config)
    .map_err(|e| error!("Config validation failed: {}", e))
    .ok();
```

Alternatively, for consensus observers specifically, override contradictory settings:

```rust
// In wait_for_epoch_start() after extracting configs:
let randomness_config = if consensus_config.is_vtxn_enabled() 
    && randomness_config.randomness_enabled() 
    && !consensus_config.rand_check_enabled() {
    // Override to disable randomness for observer if configs are contradictory
    OnChainRandomnessConfig::Off
} else {
    randomness_config
};
```

## Proof of Concept

```rust
// Reproduction steps in Rust test:

#[tokio::test]
async fn test_contradictory_configs_cause_liveness_failure() {
    // 1. Set up consensus observer with contradictory configs
    let consensus_config = OnChainConsensusConfig::V3 {
        alg: ConsensusAlgorithmConfig::JolteonV2 {
            main: ConsensusConfigV1::default(),
            quorum_store_enabled: true,
            order_vote_enabled: true,
        },
        vtxn: ValidatorTxnConfig::default_enabled(), // VTXNs ENABLED
    };
    
    let randomness_config = OnChainRandomnessConfig::V2(ConfigV2::default()); // Randomness ENABLED
    
    // V3 has rand_check_enabled() = false (field doesn't exist)
    assert!(!consensus_config.rand_check_enabled());
    assert!(consensus_config.is_vtxn_enabled());
    assert!(randomness_config.randomness_enabled());
    
    // 2. Simulate consensus observer epoch start with these configs
    // (Create observer, call wait_for_epoch_start, try to process a block)
    
    // 3. Attempt to process a block through the pipeline
    // Expected: Block processing fails with "randomness tx cancelled"
    // Result: Consensus observer cannot make progress
}
```

## Notes

This vulnerability demonstrates a critical gap in configuration validation during epoch transitions. The `wait_for_epoch_start()` function trusts that on-chain configs are internally consistent, but there is no enforcement mechanism to ensure this invariant. This allows governance (either maliciously or through error) to set contradictory configurations that break consensus observer liveness.

### Citations

**File:** consensus/src/consensus_observer/observer/epoch_state.rs (L84-127)
```rust
    pub async fn wait_for_epoch_start(
        &mut self,
        block_payloads: Arc<
            Mutex<BTreeMap<(u64, aptos_consensus_types::common::Round), BlockPayloadStatus>>,
        >,
    ) -> (
        Arc<dyn TPayloadManager>,
        OnChainConsensusConfig,
        OnChainExecutionConfig,
        OnChainRandomnessConfig,
    ) {
        // Extract the epoch state and on-chain configs
        let (epoch_state, consensus_config, execution_config, randomness_config) =
            extract_on_chain_configs(&self.node_config, &mut self.reconfig_events).await;

        // Update the local epoch state and quorum store config
        self.epoch_state = Some(epoch_state.clone());
        self.execution_pool_window_size = consensus_config.window_size();
        self.quorum_store_enabled = consensus_config.quorum_store_enabled();
        info!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "New epoch started: {:?}. Execution pool window: {:?}. Quorum store enabled: {:?}",
                epoch_state.epoch, self.execution_pool_window_size, self.quorum_store_enabled,
            ))
        );

        // Create the payload manager
        let payload_manager: Arc<dyn TPayloadManager> = if self.quorum_store_enabled {
            Arc::new(ConsensusObserverPayloadManager::new(
                block_payloads,
                self.consensus_publisher.clone(),
            ))
        } else {
            Arc::new(DirectMempoolPayloadManager {})
        };

        // Return the payload manager and on-chain configs
        (
            payload_manager,
            consensus_config,
            execution_config,
            randomness_config,
        )
    }
```

**File:** consensus/src/consensus_observer/observer/epoch_state.rs (L131-219)
```rust
async fn extract_on_chain_configs(
    node_config: &NodeConfig,
    reconfig_events: &mut ReconfigNotificationListener<DbBackedOnChainConfig>,
) -> (
    Arc<EpochState>,
    OnChainConsensusConfig,
    OnChainExecutionConfig,
    OnChainRandomnessConfig,
) {
    // Fetch the next reconfiguration notification
    let reconfig_notification = reconfig_events
        .next()
        .await
        .expect("Failed to get reconfig notification!");

    // Extract the epoch state from the reconfiguration notification
    let on_chain_configs = reconfig_notification.on_chain_configs;
    let validator_set: ValidatorSet = on_chain_configs
        .get()
        .expect("Failed to get the validator set from the on-chain configs!");
    let epoch_state = Arc::new(EpochState::new(
        on_chain_configs.epoch(),
        (&validator_set).into(),
    ));

    // Extract the consensus config (or use the default if it's missing)
    let onchain_consensus_config: anyhow::Result<OnChainConsensusConfig> = on_chain_configs.get();
    if let Err(error) = &onchain_consensus_config {
        error!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Failed to read on-chain consensus config! Error: {:?}",
                error
            ))
        );
    }
    let consensus_config = onchain_consensus_config.unwrap_or_default();

    // Extract the execution config (or use the default if it's missing)
    let onchain_execution_config: anyhow::Result<OnChainExecutionConfig> = on_chain_configs.get();
    if let Err(error) = &onchain_execution_config {
        error!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Failed to read on-chain execution config! Error: {:?}",
                error
            ))
        );
    }
    let execution_config =
        onchain_execution_config.unwrap_or_else(|_| OnChainExecutionConfig::default_if_missing());

    // Extract the randomness config sequence number (or use the default if it's missing)
    let onchain_randomness_config_seq_num: anyhow::Result<RandomnessConfigSeqNum> =
        on_chain_configs.get();
    if let Err(error) = &onchain_randomness_config_seq_num {
        warn!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Failed to read on-chain randomness config seq num! Error: {:?}",
                error
            ))
        );
    }
    let onchain_randomness_config_seq_num = onchain_randomness_config_seq_num
        .unwrap_or_else(|_| RandomnessConfigSeqNum::default_if_missing());

    // Extract the randomness config
    let onchain_randomness_config: anyhow::Result<RandomnessConfigMoveStruct> =
        on_chain_configs.get();
    if let Err(error) = &onchain_randomness_config {
        error!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Failed to read on-chain randomness config! Error: {:?}",
                error
            ))
        );
    }
    let onchain_randomness_config = OnChainRandomnessConfig::from_configs(
        node_config.randomness_override_seq_num,
        onchain_randomness_config_seq_num.seq_num,
        onchain_randomness_config.ok(),
    );

    // Return the extracted epoch state and on-chain configs
    (
        epoch_state,
        consensus_config,
        execution_config,
        onchain_randomness_config,
    )
}
```

**File:** consensus/src/pipeline/execution_client.rs (L566-567)
```rust
        let randomness_enabled = onchain_consensus_config.is_vtxn_enabled()
            && onchain_randomness_config.randomness_enabled();
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L1080-1085)
```rust
        let (_, rand_msg_rx) =
            aptos_channel::new::<AccountAddress, IncomingRandGenRequest>(QueueStyle::FIFO, 1, None);
        let (_, secret_share_msg_rx) = aptos_channel::new::<
            AccountAddress,
            IncomingSecretShareRequest,
        >(QueueStyle::FIFO, 1, None);
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L256-281)
```rust
        is_randomness_enabled: bool,
        signer: Arc<ValidatorSigner>,
        state_sync_notifier: Arc<dyn ConsensusNotificationSender>,
        payload_manager: Arc<dyn TPayloadManager>,
        txn_notifier: Arc<dyn TxnNotifier>,
        enable_pre_commit: bool,
        consensus_onchain_config: &OnChainConsensusConfig,
        persisted_auxiliary_info_version: u8,
        network_sender: Arc<NetworkSender>,
        secret_share_config: Option<SecretShareConfig>,
    ) -> Self {
        let module_cache = Arc::new(Mutex::new(None));
        Self {
            block_preparer,
            executor,
            validators,
            block_executor_onchain_config,
            is_randomness_enabled,
            signer,
            state_sync_notifier,
            payload_manager,
            txn_notifier,
            pre_commit_status: Arc::new(Mutex::new(PreCommitStatus::new(0, enable_pre_commit))),
            order_vote_enabled: consensus_onchain_config.order_vote_enabled(),
            persisted_auxiliary_info_version,
            rand_check_enabled: consensus_onchain_config.rand_check_enabled(),
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L685-783)
```rust
    async fn rand_check(
        prepare_fut: TaskFuture<PrepareResult>,
        parent_block_execute_fut: TaskFuture<ExecuteResult>,
        rand_rx: oneshot::Receiver<Option<Randomness>>,
        executor: Arc<dyn BlockExecutorTrait>,
        block: Arc<Block>,
        is_randomness_enabled: bool,
        rand_check_enabled: bool,
        module_cache: Arc<Mutex<Option<CachedModuleView<CachedStateView>>>>,
    ) -> TaskResult<RandResult> {
        let mut tracker = Tracker::start_waiting("rand_check", &block);
        parent_block_execute_fut.await?;
        let (user_txns, _) = prepare_fut.await?;

        tracker.start_working();
        if !is_randomness_enabled {
            return Ok((None, false));
        }
        let grand_parent_id = block.quorum_cert().parent_block().id();
        let parent_state_view = executor
            .state_view(block.parent_id())
            .map_err(anyhow::Error::from)?;

        let mut has_randomness = false;
        // scope to drop the lock, compiler seems not able to figure out manual drop with async point
        {
            let mut cache_guard = module_cache.lock();
            if let Some(cache_mut) = cache_guard.as_mut() {
                // flush the cache if the execution state view is not linear
                // in case of speculative executing a forked block
                let previous_state_view = cache_mut.state_view_id();
                let expected_state_view = StateViewId::BlockExecution {
                    block_id: grand_parent_id,
                };
                if previous_state_view == expected_state_view {
                    cache_mut.reset_state_view(parent_state_view);
                } else {
                    counters::RAND_BLOCK
                        .with_label_values(&["reset_cache"])
                        .inc();
                    cache_mut.reset_all(parent_state_view);
                }
            } else {
                *cache_guard = Some(CachedModuleView::new(parent_state_view));
            }
            let cache_ref = cache_guard.as_mut().expect("just set");

            for txn in user_txns.iter() {
                if let Some(txn) = txn.borrow_into_inner().try_as_signed_user_txn() {
                    if let Ok(TransactionExecutableRef::EntryFunction(entry_fn)) =
                        txn.executable_ref()
                    {
                        // use the deserialized API to avoid cloning the metadata
                        // should migrate once we move metadata into the extension and avoid cloning
                        if let Ok(Some(module)) = cache_ref.unmetered_get_deserialized_module(
                            entry_fn.module().address(),
                            entry_fn.module().name(),
                        ) {
                            if get_randomness_annotation_for_entry_function(
                                entry_fn,
                                &module.metadata,
                            )
                            .is_some()
                            {
                                has_randomness = true;
                                break;
                            }
                        }
                    }
                }
            }
        }
        let label = if has_randomness {
            "has_rand"
        } else {
            "no_rand"
        };
        counters::RAND_BLOCK.with_label_values(&[label]).inc();
        if has_randomness {
            info!(
                "[Pipeline] Block {} {} {} has randomness txn",
                block.id(),
                block.epoch(),
                block.round()
            );
        }
        drop(tracker);
        // if rand check is enabled and no txn requires randomness, we skip waiting for randomness
        let mut tracker = Tracker::start_waiting("rand_gen", &block);
        tracker.start_working();
        let maybe_rand = if rand_check_enabled && !has_randomness {
            None
        } else {
            rand_rx
                .await
                .map_err(|_| anyhow!("randomness tx cancelled"))?
        };
        Ok((Some(maybe_rand), has_randomness))
    }
```
