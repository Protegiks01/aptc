# Audit Report

## Title
Stream Replacement Vulnerability Allows Byzantine Validators to Discard Critical Consensus Messages

## Summary
The `InboundStreamBuffer::new_stream()` function contains a critical logic flaw where `Option::replace()` is called before validating whether an existing stream is in progress. This allows a Byzantine validator to intentionally send a new stream header before an existing stream completes, causing all buffered fragments (up to ~400MB) to be silently discarded. The connection remains active, enabling repeated exploitation to block critical consensus messages and potentially disrupt validator participation.

## Finding Description

The Aptos network layer uses a streaming protocol to fragment large messages (>4MiB) into smaller chunks for transmission. The `InboundStreamBuffer` manages incoming fragmented messages on a per-peer basis. [1](#0-0) 

The critical vulnerability exists in the `new_stream()` method where stream replacement logic is flawed: [2](#0-1) 

The code calls `self.stream.replace(inbound_stream)` at line 84, which **immediately installs the new stream and returns the old stream**. Only after this replacement does the code check if an old stream existed (line 84). If an old stream was present, the function returns an error, but the damage is already done - the old stream with all its buffered fragments has been discarded and the new stream is installed.

**Attack Flow**:

1. A Byzantine validator sends a large consensus message (e.g., BlockRetrievalResponse) to an honest validator
2. Stream header arrives: `request_id=1`, `num_fragments=100` (4MB × 100 = 400MB message)
3. Fragments 1-99 arrive sequentially and are buffered in memory [3](#0-2) 
4. Before fragment 100 arrives, the Byzantine validator sends a malicious second header: `request_id=2`, `num_fragments=1`
5. The `new_stream()` method executes, replacing the stream with 99 buffered fragments
6. The error "Discarding existing stream for request ID: 1" is logged [4](#0-3) 
7. The error propagates to the peer event loop where it's logged as a warning but the connection continues [5](#0-4) 
8. Fragment 100 for request_id=1 arrives but is rejected (wrong request_id expected)
9. The original 400MB consensus message is never received by the application
10. The attack can be repeated indefinitely as the peer is not disconnected

**Regarding the Original Question**: The question asks about network reordering. TCP guarantees in-order delivery [6](#0-5) , and the `MultiplexMessageStream` processes frames sequentially [7](#0-6) . However, **there is NO buffering for out-of-order messages**. If a malicious peer intentionally sends fragments before their header, they are rejected with error "No stream exists!" [8](#0-7) 

## Impact Explanation

**High Severity** per Aptos Bug Bounty criteria:

1. **Validator Node Slowdowns**: Byzantine validators can force honest validators to waste CPU cycles deserializing and buffering up to 400MB of fragments, then discard them, causing performance degradation.

2. **Significant Protocol Violations**: The streaming protocol's invariant that "one stream must complete before the next begins" is violated. The single `InboundStreamBuffer` per connection was designed to handle one stream at a time [9](#0-8) , but the bug allows streams to be preempted.

3. **Consensus Impact**: Large consensus messages (BlockRetrievalResponse, ProofOfStore batches) are commonly >4MiB and require streaming [10](#0-9) . Systematic message loss could prevent validators from:
   - Receiving block proposals
   - Receiving votes during consensus
   - Completing state synchronization
   - Retrieving historical blocks

4. **Resource Exhaustion**: Each attack cycle allocates ~400MB (max message size 64MB ÷ max frame size 4MB = 16 fragments × 4MB, but can be configured higher), deserializes fragments, buffers them, then discards them. Memory pressure and allocation churn can degrade node performance.

## Likelihood Explanation

**Highly Likely to Occur**:

1. **Attacker Requirements**: Only requires being a Byzantine validator (< 1/3 of stake is assumed). Validator networks use mutual authentication [11](#0-10) , so only other validators can connect, but Byzantine validators are assumed to exist per the BFT threat model.

2. **Easy to Exploit**: The attacker simply needs to send stream headers in rapid succession. No complex timing or state manipulation required.

3. **No Detection or Mitigation**: 
   - Errors are only logged, peer is not disconnected
   - No rate limiting on stream header reception
   - No peer reputation system at the network layer (only at application layers like state-sync)
   - The existing test actually demonstrates this behavior is expected to error but doesn't verify the side effect [12](#0-11) 

4. **Realistic Scenario**: The outbound sender sends streams sequentially due to `.await` [13](#0-12) , but a malicious peer can send messages in any order.

## Recommendation

**Immediate Fix**: Check for existing stream BEFORE calling `replace()`:

```rust
pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
    // Check if a stream already exists BEFORE replacing
    if self.stream.is_some() {
        bail!(
            "Cannot start new stream - existing stream in progress for request ID: {}",
            self.stream.as_ref().unwrap().request_id
        );
    }
    
    let inbound_stream = InboundStream::new(header, self.max_fragments)?;
    self.stream = Some(inbound_stream);
    Ok(())
}
```

**Additional Hardening**:

1. **Disconnect Malicious Peers**: On repeated stream protocol violations (fragment before header, out-of-order fragments, overlapping streams), disconnect the peer instead of just logging.

2. **Per-Request Stream Tracking**: Consider using `HashMap<RequestId, InboundStream>` to support concurrent streams per peer, or document that concurrent streams are not supported and enforce this strictly.

3. **Rate Limiting**: Implement rate limiting on stream header reception per peer to prevent rapid stream churn attacks.

## Proof of Concept

```rust
#[test]
fn test_stream_replacement_vulnerability() {
    use crate::protocols::stream::{InboundStreamBuffer, StreamHeader, StreamFragment};
    use crate::protocols::wire::messaging::v1::{DirectSendMsg, NetworkMessage};
    use crate::protocols::wire::handshake::v1::ProtocolId;
    
    let max_fragments = 100;
    let mut buffer = InboundStreamBuffer::new(max_fragments);
    
    // Start first stream with 100 fragments
    let header1 = StreamHeader {
        request_id: 1,
        num_fragments: 100,
        message: NetworkMessage::DirectSendMsg(DirectSendMsg {
            protocol_id: ProtocolId::ConsensusDirectSendBcs,
            priority: 0,
            raw_msg: vec![0; 4_000_000], // 4MB
        }),
    };
    assert!(buffer.new_stream(header1).is_ok());
    
    // Append 99 fragments (simulating ~396MB buffered)
    for i in 1..100 {
        let fragment = StreamFragment {
            request_id: 1,
            fragment_id: i,
            raw_data: vec![0; 4_000_000], // 4MB each
        };
        assert!(buffer.append_fragment(fragment).is_ok());
    }
    
    // Malicious peer sends second header BEFORE completing first stream
    let header2 = StreamHeader {
        request_id: 2,
        num_fragments: 1,
        message: NetworkMessage::DirectSendMsg(DirectSendMsg {
            protocol_id: ProtocolId::ConsensusDirectSendBcs,
            priority: 0,
            raw_msg: vec![0; 100],
        }),
    };
    
    // This returns an error BUT the stream is replaced!
    let result = buffer.new_stream(header2);
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Discarding existing stream"));
    
    // VULNERABILITY: The stream with 99 fragments is now GONE
    // Attempting to send fragment 100 for request_id=1 will fail
    let fragment100 = StreamFragment {
        request_id: 1,
        fragment_id: 100,
        raw_data: vec![0; 4_000_000],
    };
    let result = buffer.append_fragment(fragment100);
    assert!(result.is_err()); // Wrong request_id - expects 2, got 1
    
    // The original ~400MB message is permanently lost
    // Consensus/state-sync will never receive it
}
```

**Notes**:
- This vulnerability affects all network message types including critical consensus messages
- Byzantine validators under the 1/3 threshold can exploit this without detection
- The issue violates the network layer's reliability guarantee for large message delivery
- No peer reputation or disconnection mechanism exists at this layer to prevent repeated abuse

### Citations

**File:** network/framework/src/peer/mod.rs (L138-194)
```rust
    /// Inbound stream buffer
    inbound_stream: InboundStreamBuffer,
}

impl<TSocket> Peer<TSocket>
where
    TSocket: AsyncRead + AsyncWrite + Send + 'static,
{
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        network_context: NetworkContext,
        executor: Handle,
        time_service: TimeService,
        connection: Connection<TSocket>,
        connection_notifs_tx: aptos_channels::Sender<TransportNotification<TSocket>>,
        peer_reqs_rx: aptos_channel::Receiver<ProtocolId, PeerRequest>,
        upstream_handlers: Arc<
            HashMap<ProtocolId, aptos_channel::Sender<(PeerId, ProtocolId), ReceivedMessage>>,
        >,
        inbound_rpc_timeout: Duration,
        max_concurrent_inbound_rpcs: u32,
        max_concurrent_outbound_rpcs: u32,
        max_frame_size: usize,
        max_message_size: usize,
    ) -> Self {
        let Connection {
            metadata: connection_metadata,
            socket,
        } = connection;
        let remote_peer_id = connection_metadata.remote_peer_id;
        let max_fragments = max_message_size / max_frame_size;
        Self {
            network_context,
            executor,
            time_service: time_service.clone(),
            connection_metadata,
            connection: Some(socket),
            connection_notifs_tx,
            peer_reqs_rx,
            upstream_handlers,
            inbound_rpcs: InboundRpcs::new(
                network_context,
                time_service.clone(),
                remote_peer_id,
                inbound_rpc_timeout,
                max_concurrent_inbound_rpcs,
            ),
            outbound_rpcs: OutboundRpcs::new(
                network_context,
                time_service,
                remote_peer_id,
                max_concurrent_outbound_rpcs,
            ),
            state: State::Connected,
            max_frame_size,
            max_message_size,
            inbound_stream: InboundStreamBuffer::new(max_fragments),
```

**File:** network/framework/src/peer/mod.rs (L252-265)
```rust
                maybe_message = reader.next() => {
                    match maybe_message {
                        Some(message) =>  {
                            if let Err(err) = self.handle_inbound_message(message, &mut write_reqs_tx) {
                                warn!(
                                    NetworkSchema::new(&self.network_context)
                                        .connection_metadata(&self.connection_metadata),
                                    error = %err,
                                    "{} Error in handling inbound message from peer: {}, error: {}",
                                    self.network_context,
                                    remote_peer_id.short_str(),
                                    err
                                );
                            }
```

**File:** network/framework/src/peer/mod.rs (L422-425)
```rust
            while let Some(message) = write_reqs_rx.next().await {
                // either channel full would block the other one
                let result = if outbound_stream.should_stream(&message) {
                    outbound_stream.stream_message(message).await
```

**File:** network/framework/src/protocols/stream/mod.rs (L82-92)
```rust
    pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
        let inbound_stream = InboundStream::new(header, self.max_fragments)?;
        if let Some(old) = self.stream.replace(inbound_stream) {
            bail!(
                "Discarding existing stream for request ID: {}",
                old.request_id
            )
        } else {
            Ok(())
        }
    }
```

**File:** network/framework/src/protocols/stream/mod.rs (L95-112)
```rust
    pub fn append_fragment(
        &mut self,
        fragment: StreamFragment,
    ) -> anyhow::Result<Option<NetworkMessage>> {
        // Append the fragment to the existing stream
        let stream = self
            .stream
            .as_mut()
            .ok_or_else(|| anyhow::anyhow!("No stream exists!"))?;
        let stream_end = stream.append_fragment(fragment)?;

        // If the stream is complete, take it out and return the message
        if stream_end {
            Ok(Some(self.stream.take().unwrap().message))
        } else {
            Ok(None)
        }
    }
```

**File:** network/framework/src/protocols/stream/mod.rs (L164-214)
```rust
    fn append_fragment(&mut self, mut fragment: StreamFragment) -> anyhow::Result<bool> {
        // Verify the stream request ID and fragment request ID
        ensure!(
            self.request_id == fragment.request_id,
            "Stream fragment from a different request! Expected {}, got {}.",
            self.request_id,
            fragment.request_id
        );

        // Verify the fragment ID
        let fragment_id = fragment.fragment_id;
        ensure!(fragment_id > 0, "Fragment ID must be greater than zero!");
        ensure!(
            fragment_id <= self.num_fragments,
            "Fragment ID {} exceeds number of fragments {}!",
            fragment_id,
            self.num_fragments
        );

        // Verify the fragment ID is the expected next fragment
        let expected_fragment_id = self.received_fragment_id.checked_add(1).ok_or_else(|| {
            anyhow::anyhow!(
                "Current fragment ID overflowed when adding 1: {}",
                self.received_fragment_id
            )
        })?;
        ensure!(
            expected_fragment_id == fragment_id,
            "Unexpected fragment ID, expected {}, got {}!",
            expected_fragment_id,
            fragment_id
        );

        // Update the received fragment ID
        self.received_fragment_id = expected_fragment_id;

        // Append the fragment data to the message
        let raw_data = &mut fragment.raw_data;
        match &mut self.message {
            NetworkMessage::Error(_) => {
                panic!("StreamHeader for NetworkMessage::Error(_) should be rejected!")
            },
            NetworkMessage::RpcRequest(request) => request.raw_request.append(raw_data),
            NetworkMessage::RpcResponse(response) => response.raw_response.append(raw_data),
            NetworkMessage::DirectSendMsg(message) => message.raw_msg.append(raw_data),
        }

        // Return whether the stream is complete
        let is_stream_complete = self.received_fragment_id == self.num_fragments;
        Ok(is_stream_complete)
    }
```

**File:** network/framework/src/protocols/stream/mod.rs (L355-370)
```rust
    #[test]
    pub fn test_inbound_stream_buffer_new_stream() {
        // Create an inbound stream buffer
        let max_fragments = 10;
        let mut inbound_stream_buffer = InboundStreamBuffer::new(max_fragments);

        // Start a new stream
        let stream_header = create_stream_header(1, 5);
        assert!(inbound_stream_buffer.new_stream(stream_header).is_ok());

        // Attempt to start another stream without completing the first one
        let another_stream_header = create_stream_header(2, 6);
        assert!(inbound_stream_buffer
            .new_stream(another_stream_header)
            .is_err());
    }
```

**File:** network/framework/src/transport/mod.rs (L409-418)
```rust
/// The common AptosNet Transport.
///
/// The base transport layer is pluggable, so long as it provides a reliable,
/// ordered, connection-oriented, byte-stream abstraction (e.g., TCP). We currently
/// use either `MemoryTransport` or `TcpTransport` as this base layer.
///
/// Inbound and outbound connections are first established with the `base_transport`
/// and then negotiate a secure, authenticated transport layer (currently Noise
/// protocol). Finally, we negotiate common supported application protocols with
/// the `Handshake` protocol.
```

**File:** network/framework/src/protocols/wire/messaging/v1/mod.rs (L222-248)
```rust
impl<TReadSocket: AsyncRead + Unpin> Stream for MultiplexMessageStream<TReadSocket> {
    type Item = Result<MultiplexMessage, ReadError>;

    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        match self.project().framed_read.poll_next(cx) {
            Poll::Ready(Some(Ok(frame))) => {
                let frame = frame.freeze();

                match bcs::from_bytes(&frame) {
                    Ok(message) => Poll::Ready(Some(Ok(message))),
                    // Failed to deserialize the NetworkMessage
                    Err(err) => {
                        let mut frame = frame;
                        let frame_len = frame.len();
                        // Keep a few bytes from the frame for debugging
                        frame.truncate(8);
                        let err = ReadError::DeserializeError(err, frame_len, frame);
                        Poll::Ready(Some(Err(err)))
                    },
                }
            },
            Poll::Ready(Some(Err(err))) => Poll::Ready(Some(Err(ReadError::IoError(err)))),
            Poll::Ready(None) => Poll::Ready(None),
            Poll::Pending => Poll::Pending,
        }
    }
}
```

**File:** network/framework/src/constants.rs (L20-21)
```rust
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** network/framework/src/noise/handshake.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! The handshake module implements the handshake part of the protocol.
//! This module also implements additional anti-DoS mitigation,
//! by including a timestamp in each handshake initialization message.
//! Refer to the module's documentation for more information.
//! A successful handshake returns a [`NoiseStream`] which is defined in the
//! [stream] module.
//!
//! [stream]: crate::noise::stream

use crate::{
    application::storage::PeersAndMetadata,
    logging::NetworkSchema,
    noise::{error::NoiseHandshakeError, stream::NoiseStream},
};
use aptos_config::{
    config::{Peer, PeerRole},
    network_id::{NetworkContext, NetworkId},
};
use aptos_crypto::{noise, x25519};
use aptos_infallible::{duration_since_epoch, RwLock};
use aptos_logger::{error, trace};
use aptos_short_hex_str::{AsShortHexStr, ShortHexStr};
use aptos_types::PeerId;
use futures::io::{AsyncRead, AsyncReadExt, AsyncWrite, AsyncWriteExt};
use std::{collections::HashMap, convert::TryFrom as _, fmt::Debug, sync::Arc};

/// In a mutually authenticated network, a client message is accompanied with a timestamp.
/// This is in order to prevent replay attacks, where the attacker does not know the client's static key,
/// but can still replay a handshake message in order to force a peer into performing a few Diffie-Hellman key exchange operations.
///
/// Thus, to prevent replay attacks a responder will always check if the timestamp is strictly increasing,
/// effectively considering it as a stateful counter.
///
/// If the client timestamp has been seen before, or is not strictly increasing,
/// we can abort the handshake early and avoid heavy Diffie-Hellman computations.
/// If the client timestamp is valid, we store it.
#[derive(Default)]
pub struct AntiReplayTimestamps(HashMap<x25519::PublicKey, u64>);

impl AntiReplayTimestamps {
    /// The timestamp is sent as a payload, so that it is encrypted.
    /// Note that a millisecond value is a 16-byte value in rust,
    /// but as we use it to store a duration since UNIX_EPOCH we will never use more than 8 bytes.
    pub const TIMESTAMP_SIZE: usize = 8;

    /// obtain the current timestamp
    pub fn now() -> [u8; Self::TIMESTAMP_SIZE] {
```
