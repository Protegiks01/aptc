# Audit Report

## Title
Stale Timeout Certificate Pollution Preventing Legitimate TC Persistence and Propagating Across Network

## Summary
The timeout certificate (TC) cleanup logic in `persistent_liveness_storage.rs` only deletes TCs when they are `None`, allowing stale TCs with high round numbers to persist across node restarts. These stale TCs can prevent legitimate TCs from being persisted and propagate to other nodes, potentially impacting consensus liveness.

## Finding Description

The vulnerability exists in the TC cleanup logic during node recovery. When a node restarts, it loads the highest timeout certificate from the database and checks only if the TC's **epoch** matches the current epoch. [1](#0-0) 

If the epochs match, the TC is kept regardless of its round number. The cleanup at lines 578-582 only executes when the TC is `None`: [2](#0-1) 

This creates a vulnerability when:

1. A node reaches round 110 and times out, creating and persisting TC_110
2. Node crashes before committing blocks beyond round 105
3. Network continues and commits blocks up to round 105 (without the crashed node)
4. Node restarts and syncs to committed state at round 105
5. Node loads TC_110 from its database (epoch matches, so TC is kept)
6. Node begins participating from round 106 but has TC_110 in memory

The stale TC_110 now causes two critical issues:

**Issue 1: Local TC Insertion Blocking**
When the node or network tries to create a legitimate TC_106, the insertion is rejected: [3](#0-2) 

Since `106 <= 110`, the legitimate TC_106 cannot be persisted to the database.

**Issue 2: Network-Wide TC Pollution**
The stale TC_110 is broadcast to other nodes via SyncInfo messages. The SyncInfo includes TCs that have rounds higher than the highest QC: [4](#0-3) 

When other nodes receive the SyncInfo containing TC_110, they insert it into their own block stores: [5](#0-4) 

This causes the stale TC to propagate network-wide, preventing all nodes from persisting legitimate TCs with lower round numbers.

The root cause is that TC validation during recovery only checks epoch equality, not whether the TC's round is reasonable relative to the committed state: [6](#0-5) 

## Impact Explanation

This is a **Medium severity** issue per Aptos bug bounty criteria:

- **State Inconsistencies**: Legitimate timeout certificates cannot be persisted to the database, creating inconsistency between in-memory and persisted state
- **Liveness Impact**: While consensus can continue (timeouts can still be signed and broadcast), the inability to persist TCs means nodes lose timeout proofs after restarts, potentially slowing round progression
- **Recovery Issues**: After subsequent crashes, nodes cannot prove that timeouts occurred, making it harder to justify round advancement to peers
- **Network-Wide Propagation**: A single node with a stale TC can pollute the entire validator network

This doesn't directly break consensus safety (voting rules still work correctly with high-round TCs) but impacts the protocol's ability to maintain proper liveness guarantees across crashes and restarts.

## Likelihood Explanation

This vulnerability has **Medium to High likelihood** in production environments:

**Occurrence Conditions:**
- Node crashes or restarts during active consensus (common in distributed systems)
- Node has uncommitted speculative state when crash occurs (standard in optimistic protocols)
- Node's committed state is behind the highest round it reached before crash

**Attack Requirements:**
- No attacker needed - occurs naturally during normal node operation
- No Byzantine behavior required
- No network manipulation needed

The scenario is particularly likely in networks with unstable nodes or during rolling upgrades where nodes restart while consensus is actively progressing.

## Recommendation

Add round validation during TC recovery to ensure stale TCs with rounds beyond reasonable bounds are cleaned up:

```rust
// In RecoveryData::new(), after determining the epoch and root_id:
let root_round = match &root.window_root_block {
    None => root.commit_root_block.round(),
    Some(window_root_block) => window_root_block.round(),
};

highest_2chain_timeout_certificate: match highest_2chain_timeout_cert {
    Some(tc) if tc.epoch() == epoch && tc.round() >= root_round => Some(tc),
    _ => None,
},
```

This ensures that TCs are only kept if:
1. Their epoch matches the current epoch (existing check)
2. Their round is at or above the root block's round (new check)

Any TC from a "future" round that got rolled back due to uncommitted state will be set to `None` and cleaned up by the existing cleanup logic at lines 578-582.

**Alternative Fix:** Add an upper bound check allowing TCs slightly ahead of the root:
```rust
Some(tc) if tc.epoch() == epoch 
    && tc.round() >= root_round 
    && tc.round() <= root_round + MAX_TC_ROUND_DELTA => Some(tc),
```

where `MAX_TC_ROUND_DELTA` is a reasonable constant (e.g., 50 rounds) accounting for sync delays.

## Proof of Concept

```rust
// Rust integration test demonstrating the vulnerability
#[tokio::test]
async fn test_stale_tc_blocks_legitimate_tc_insertion() {
    // Setup: Node at round 110 times out
    let mut node = setup_test_node().await;
    node.advance_to_round(110).await;
    let tc_110 = node.create_and_persist_timeout_cert(110).await;
    
    // Simulate crash and rollback to committed state at round 105
    node.crash().await;
    node.restart_at_committed_round(105).await;
    
    // Verify TC_110 was loaded from database (stale)
    assert_eq!(node.block_store.highest_2chain_timeout_cert().unwrap().round(), 110);
    
    // Node participates at round 106 and times out
    node.advance_to_round(106).await;
    let tc_106 = node.create_timeout_cert(106).await;
    
    // Attempt to insert legitimate TC_106
    let result = node.block_store.insert_2chain_timeout_certificate(tc_106.clone());
    assert!(result.is_ok()); // Returns Ok but doesn't actually insert
    
    // Verify TC_106 was NOT persisted (blocked by stale TC_110)
    node.restart_at_committed_round(105).await;
    assert_eq!(node.block_store.highest_2chain_timeout_cert().unwrap().round(), 110); // Still stale TC_110
    assert_ne!(node.block_store.highest_2chain_timeout_cert().unwrap().round(), 106); // TC_106 not persisted
    
    // Verify stale TC propagates to other nodes
    let mut other_node = setup_test_node().await;
    other_node.advance_to_round(106).await;
    
    let sync_info = node.block_store.sync_info();
    assert_eq!(sync_info.highest_2chain_timeout_cert().unwrap().round(), 110);
    
    other_node.process_sync_info(&sync_info).await;
    assert_eq!(other_node.block_store.highest_2chain_timeout_cert().unwrap().round(), 110);
    
    // Other node now also cannot persist TC_106
    let result = other_node.block_store.insert_2chain_timeout_certificate(tc_106);
    assert!(result.is_ok());
    assert_eq!(other_node.block_store.highest_2chain_timeout_cert().unwrap().round(), 110); // Still 110, not 106
}
```

**Notes**

The vulnerability specifically affects the 2-chain timeout certificate mechanism which is critical for liveness in AptosBFT. While the consensus protocol can tolerate missing TCs temporarily (nodes can still vote based on QCs), persistent inability to store TCs across the network degrades the protocol's ability to make progress during periods of network instability or high latency. The fix should be applied to ensure TC state consistency across restarts and prevent stale certificate propagation.

### Citations

**File:** consensus/src/persistent_liveness_storage.rs (L386-397)
```rust
        let (root_id, epoch) = match &root.window_root_block {
            None => {
                let commit_root_id = root.commit_root_block.id();
                let epoch = root.commit_root_block.epoch();
                (commit_root_id, epoch)
            },
            Some(window_root_block) => {
                let window_start_id = window_root_block.id();
                let epoch = window_root_block.epoch();
                (window_start_id, epoch)
            },
        };
```

**File:** consensus/src/persistent_liveness_storage.rs (L414-417)
```rust
            highest_2chain_timeout_certificate: match highest_2chain_timeout_cert {
                Some(tc) if tc.epoch() == epoch => Some(tc),
                _ => None,
            },
```

**File:** consensus/src/persistent_liveness_storage.rs (L578-582)
```rust
                if initial_data.highest_2chain_timeout_certificate.is_none() {
                    self.db
                        .delete_highest_2chain_timeout_certificate()
                        .expect("unable to cleanup highest 2-chain timeout cert");
                }
```

**File:** consensus/src/block_storage/block_store.rs (L564-569)
```rust
        let cur_tc_round = self
            .highest_2chain_timeout_cert()
            .map_or(0, |tc| tc.round());
        if tc.round() <= cur_tc_round {
            return Ok(());
        }
```

**File:** consensus/consensus-types/src/sync_info.rs (L58-59)
```rust
        let highest_2chain_timeout_cert = highest_2chain_timeout_cert
            .filter(|tc| tc.round() > highest_quorum_cert.certified_block().round());
```

**File:** consensus/src/block_storage/sync_manager.rs (L169-171)
```rust
        if let Some(tc) = sync_info.highest_2chain_timeout_cert() {
            self.insert_2chain_timeout_certificate(Arc::new(tc.clone()))?;
        }
```
