# Audit Report

## Title
Randomness Not Cryptographically Bound to Block ID Enables State Divergence in Fork Scenarios

## Summary
The randomness generation system signs only `(epoch, round)` and explicitly excludes `block_id` from cryptographic commitments, creating a vulnerability where identical randomness can be validly applied to different blocks at the same round during fork scenarios, potentially causing consensus safety violations and state divergence.

## Finding Description

The `FullRandMetadata` struct contains a `block_id` field that is explicitly marked as "not used for signing": [1](#0-0) 

When randomness shares are generated and verified, only `RandMetadata` (containing `epoch` and `round`) is cryptographically signed, completely excluding the `block_id`: [2](#0-1) [3](#0-2) 

When shares are aggregated into final randomness, the output `Randomness` object only contains `RandMetadata`, not the `block_id`: [4](#0-3) 

The `RandStore` validates shares only against `RandMetadata`, not against the specific `block_id`: [5](#0-4) 

**Attack Scenario:**

1. Byzantine validators or a consensus bug causes two different blocks (Block A and Block B) to exist at the same `(epoch E, round R)` with different `block_id` values
2. Different validator nodes process different blocks first through `RandManager.process_incoming_blocks()`
3. Both groups generate randomness shares for `(E, R)` - these shares are cryptographically identical/compatible since they only sign `(epoch, round)`
4. Each group aggregates shares into the same randomness value `R`
5. Group 1 associates `R` with `block_id_A`, Group 2 associates `R` with `block_id_B`
6. When blocks are executed, they create different `BlockMetadataWithRandomness` transactions: [6](#0-5) [7](#0-6) 

7. The metadata transactions have different `id` fields but identical `randomness`, causing different state roots and violating **Invariant #1: Deterministic Execution**

## Impact Explanation

**Critical Severity** - This violates the core consensus safety guarantee:

1. **Consensus Safety Violation**: Breaks AptosBFT's fundamental property that all honest validators must agree on the same state for committed blocks
2. **State Divergence**: Different validators execute the same randomness with different block IDs, producing different state roots
3. **Non-recoverable Network Split**: Once state diverges, the network cannot recover without manual intervention or hard fork
4. **Chain Split Risk**: Different validator subsets may commit to incompatible histories

This meets the Critical severity criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Low to Medium Likelihood** in practice:

**Required Preconditions:**
- Byzantine validators proposing conflicting blocks at the same round (requires >1/3 Byzantine threshold to sustain), OR
- Consensus implementation bug allowing fork scenarios, OR  
- Network partition with inconsistent block ordering

**Mitigating Factors:**
- AptosBFT's safety rules normally prevent multiple blocks per round from getting quorum certificates
- OrderedBlocks contain `ordered_proof` (LedgerInfoWithSignatures) that commits to specific block IDs: [8](#0-7) 

**However**, the randomness system provides **zero defense-in-depth**. If any consensus edge case allows a fork, the randomness layer will amplify it into state divergence rather than detecting/preventing it.

## Recommendation

Cryptographically bind randomness shares to the specific `block_id`:

```rust
// In types/src/randomness.rs
#[derive(Clone, Serialize, Deserialize, Debug, PartialEq, Eq, Hash)]
pub struct RandMetadata {
    pub epoch: u64,
    pub round: Round,
    pub block_id: HashValue,  // ADD THIS
}

// Update FullRandMetadata construction
impl FullRandMetadata {
    pub fn new(epoch: u64, round: Round, block_id: HashValue, timestamp: u64) -> Self {
        Self {
            metadata: RandMetadata { epoch, round, block_id },  // Include block_id
            timestamp,
        }
    }
}
```

This ensures randomness shares are cryptographically tied to specific blocks, preventing reuse across forks and providing defense-in-depth against consensus bugs.

**Alternative**: Add explicit validation in `RandStore::add_rand_metadata()` to reject metadata if the round already has a different `block_id`:

```rust
fn add_metadata(&mut self, rand_config: &RandConfig, rand_metadata: FullRandMetadata) {
    match self {
        RandItem::PendingDecision { metadata, .. } => {
            ensure!(
                metadata.block_id == rand_metadata.block_id,
                "Block ID mismatch for same round: existing={:?}, new={:?}",
                metadata.block_id, rand_metadata.block_id
            );
        }
        // ... rest of logic
    }
}
```

## Proof of Concept

```rust
// Reproduction steps demonstrating the vulnerability:

// 1. Create two different blocks at the same (epoch, round)
let epoch = 10;
let round = 100;
let block_a = create_test_block(epoch, round, HashValue::random());
let block_b = create_test_block(epoch, round, HashValue::random());

// 2. Generate metadata from both blocks
let metadata_a = FullRandMetadata::from(&block_a);
let metadata_b = FullRandMetadata::from(&block_b);

// 3. Generate randomness shares - they're IDENTICAL because only (epoch, round) is signed
let share_a = Share::generate(&rand_config, metadata_a.metadata.clone());
let share_b = Share::generate(&rand_config, metadata_b.metadata.clone());

// 4. Verify shares are compatible with BOTH blocks
assert!(share_a.verify(&rand_config, &metadata_a.metadata, &author).is_ok());
assert!(share_a.verify(&rand_config, &metadata_b.metadata, &author).is_ok()); // SAME SHARE VALID FOR BOTH!

// 5. Aggregate produces identical randomness for both blocks
let randomness = Share::aggregate(shares.iter(), &rand_config, metadata_a.metadata.clone());

// 6. Different nodes execute with different block_ids but same randomness
let tx_a = block_a.new_metadata_with_randomness(&validators, Some(randomness.clone()));
let tx_b = block_b.new_metadata_with_randomness(&validators, Some(randomness.clone()));

// tx_a.id != tx_b.id but tx_a.randomness == tx_b.randomness
// This causes different execution outcomes and state divergence
```

## Notes

While this vulnerability requires specific preconditions (fork scenario) to exploit, it represents a critical design flaw in the randomness system. The cryptographic binding should include `block_id` as a defense-in-depth measure. The current implementation relies entirely on consensus correctness without providing any additional safety layer, violating security best practices.

### Citations

**File:** types/src/randomness.rs (L29-35)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, PartialEq, Eq, Hash)]
pub struct FullRandMetadata {
    pub metadata: RandMetadata,
    // not used for signing
    pub block_id: HashValue,
    pub timestamp: u64,
}
```

**File:** consensus/src/rand/rand_gen/types.rs (L52-81)
```rust
    fn verify(
        &self,
        rand_config: &RandConfig,
        rand_metadata: &RandMetadata,
        author: &Author,
    ) -> anyhow::Result<()> {
        let index = *rand_config
            .validator
            .address_to_validator_index()
            .get(author)
            .ok_or_else(|| anyhow!("Share::verify failed with unknown author"))?;
        let maybe_apk = &rand_config.keys.certified_apks[index];
        if let Some(apk) = maybe_apk.get() {
            WVUF::verify_share(
                &rand_config.vuf_pp,
                apk,
                bcs::to_bytes(&rand_metadata)
                    .map_err(|e| anyhow!("Serialization failed: {}", e))?
                    .as_slice(),
                &self.share,
            )?;
        } else {
            bail!(
                "[RandShare] No augmented public key for validator id {}, {}",
                index,
                author
            );
        }
        Ok(())
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L84-95)
```rust
    fn generate(rand_config: &RandConfig, rand_metadata: RandMetadata) -> RandShare<Self>
    where
        Self: Sized,
    {
        let share = Share {
            share: WVUF::create_share(
                &rand_config.keys.ask,
                bcs::to_bytes(&rand_metadata).unwrap().as_slice(),
            ),
        };
        RandShare::new(rand_config.author(), rand_metadata, share)
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L130-148)
```rust
        let proof = WVUF::aggregate_shares(&rand_config.wconfig, &apks_and_proofs);
        let metadata_serialized = bcs::to_bytes(&rand_metadata).map_err(|e| {
            anyhow!("Share::aggregate failed with metadata serialization error: {e}")
        })?;
        let eval = WVUF::derive_eval(
            &rand_config.wconfig,
            &rand_config.vuf_pp,
            metadata_serialized.as_slice(),
            &rand_config.get_all_certified_apk(),
            &proof,
            THREAD_MANAGER.get_exe_cpu_pool(),
        )
        .map_err(|e| anyhow!("Share::aggregate failed with WVUF derive_eval error: {e}"))?;
        debug!("WVUF derivation time: {} ms", timer.elapsed().as_millis());
        let eval_bytes = bcs::to_bytes(&eval)
            .map_err(|e| anyhow!("Share::aggregate failed with eval serialization error: {e}"))?;
        let rand_bytes = Sha3_256::digest(eval_bytes.as_slice()).to_vec();
        Ok(Randomness::new(rand_metadata, rand_bytes))
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L146-157)
```rust
            RandItem::PendingDecision {
                metadata,
                share_aggregator,
            } => {
                ensure!(
                    &metadata.metadata == share.metadata(),
                    "[RandStore] RandShare metadata from {} mismatch with block metadata!",
                    share.author(),
                );
                share_aggregator.add_share(rand_config.get_peer_weight(share.author()), share);
                Ok(())
            },
```

**File:** types/src/block_metadata_ext.rs (L23-34)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct BlockMetadataWithRandomness {
    pub id: HashValue,
    pub epoch: u64,
    pub round: u64,
    pub proposer: AccountAddress,
    #[serde(with = "serde_bytes")]
    pub previous_block_votes_bitvec: Vec<u8>,
    pub failed_proposer_indices: Vec<u32>,
    pub timestamp_usecs: u64,
    pub randomness: Option<Randomness>,
}
```

**File:** consensus/consensus-types/src/block.rs (L597-617)
```rust
    pub fn new_metadata_with_randomness(
        &self,
        validators: &[AccountAddress],
        randomness: Option<Randomness>,
    ) -> BlockMetadataExt {
        BlockMetadataExt::new_v1(
            self.id(),
            self.epoch(),
            self.round(),
            self.author().unwrap_or(AccountAddress::ZERO),
            self.previous_bitvec().into(),
            // For nil block, we use 0x0 which is convention for nil address in move.
            self.block_data()
                .failed_authors()
                .map_or(vec![], |failed_authors| {
                    Self::failed_authors_to_indices(validators, failed_authors)
                }),
            self.timestamp_usecs(),
            randomness,
        )
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L79-83)
```rust
#[derive(Clone)]
pub struct OrderedBlocks {
    pub ordered_blocks: Vec<Arc<PipelinedBlock>>,
    pub ordered_proof: LedgerInfoWithSignatures,
}
```
