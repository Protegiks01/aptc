# Audit Report

## Title
Predictable Proposer Selection Enables Strategic Manipulation in ProposerAndVoter V1 Configuration

## Summary
The deprecated `ProposerAndVoter` (V1) leader reputation configuration uses a predictable seed based solely on epoch and round numbers for weighted random proposer selection. This allows validators with knowledge of the selection algorithm to pre-compute all future proposer assignments for an entire epoch, enabling strategic behavior to maximize their proposal frequency and rewards beyond their fair share.

## Finding Description

The proposer election mechanism in Aptos uses weighted random selection to choose block proposers based on reputation and stake. However, when configured with the deprecated `LeaderReputationType::ProposerAndVoter` variant, the seed generation is deterministic and predictable. [1](#0-0) 

When `use_root_hash` is false (which occurs only for `ProposerAndVoter` V1), the state only contains the epoch and round numbers - both publicly known values. [2](#0-1) 

This predictable state is then used in the weighted selection algorithm: [3](#0-2) 

The weights are calculated based on historical performance and multiplied by voting power: [4](#0-3) [5](#0-4) 

**Attack Path:**

1. A rational validator, at the start of an epoch, has access to all public information needed for the calculation:
   - Current epoch number
   - All validator addresses and their voting powers
   - Historical performance data (from on-chain `NewBlockEvent`s)
   - The exact weight calculation algorithm

2. Since the seed is `SHA3-256(epoch || round)`, the validator can pre-compute the proposer for ANY future round by simulating the weighted selection with different round numbers.

3. Armed with this knowledge, the validator can employ strategic behaviors:
   - **Selective participation**: Only actively participate (vote, stay online) during rounds where they are selected as proposer to maximize rewards
   - **Reputation gaming**: Manipulate their historical metrics by selectively participating to maintain the optimal weight (active_weight = 1000 vs inactive_weight = 10 vs failed_weight = 1)
   - **Free-riding**: Reduce operational costs by going offline when not selected, knowing exactly when to come back online
   - **Strategic failures**: If they predict future selection probabilities will increase, they might strategically accept failures now

## Impact Explanation

This vulnerability breaks critical consensus invariants:

**Broken Invariants:**
- **Fairness of Proposer Selection**: Validators should be selected based on their actual stake and performance, not their ability to game predictions
- **Liveness Guarantee**: If many validators adopt this strategy, network liveness could degrade during predicted "unprofitable" rounds
- **Incentive Alignment**: The reputation system is designed to reward good behavior and penalize bad behavior, but predictability allows validators to game the system

**Severity Assessment - HIGH:**
- While this doesn't directly cause consensus safety violations or fund theft, it represents a significant protocol violation
- It enables unfair reward distribution, with sophisticated validators earning disproportionate rewards
- It could lead to validator node slowdowns or reduced network participation if widely adopted
- The issue undermines the entire purpose of reputation-based leader election

According to Aptos bug bounty criteria, this qualifies as **High Severity** due to "Significant protocol violations" and potential for "Validator node slowdowns" if the strategy becomes widespread.

## Likelihood Explanation

**Current Likelihood: LOW to MEDIUM**

The default configuration uses `ProposerAndVoterV2`, which includes the root hash in the seed and is secure: [6](#0-5) 

However, the vulnerability remains exploitable under these conditions:

1. **Legacy Networks**: Any Aptos network still using the deprecated V1 configuration
2. **Governance Downgrade**: If on-chain governance changes the configuration from V2 back to V1 (either accidentally or through compromise)
3. **Backwards Compatibility**: V1 remains in the codebase for backwards compatibility, creating an attack surface [7](#0-6) 

The likelihood increases with:
- Number of sophisticated validators who understand the algorithm
- Economic incentive (higher rewards make strategic behavior more attractive)
- Network maturity (validators have more time to analyze and exploit)

## Recommendation

**Immediate Actions:**

1. **Deprecate and Remove V1 Completely**: Remove support for `ProposerAndVoter` variant after ensuring all networks have migrated to V2

2. **Add Configuration Validation**: Implement on-chain checks to prevent governance from downgrading to V1:

```rust
// In consensus config validation
pub fn validate_proposer_election_type(config: &ProposerElectionType) -> Result<()> {
    match config {
        ProposerElectionType::LeaderReputation(
            LeaderReputationType::ProposerAndVoter(_)
        ) => {
            bail!("ProposerAndVoter V1 is deprecated and insecure. Use ProposerAndVoterV2 instead.")
        },
        _ => Ok(())
    }
}
```

3. **Audit Existing Networks**: Verify that all Aptos networks (mainnet, testnet, devnet) are using V2

4. **Document Security Risk**: Add explicit security warnings in the code comments explaining why V1 is insecure

**Long-term Improvements:**

1. Consider adding additional entropy sources to make V2 even more unpredictable
2. Implement monitoring to detect strategic participation patterns
3. Consider penalties for validators with suspicious participation patterns (consistently online only when selected)

## Proof of Concept

```rust
// Proof of Concept: Demonstrating predictable proposer selection in V1

use aptos_crypto::HashValue;
use aptos_types::account_address::AccountAddress;

// Simulate the vulnerable ProposerAndVoter V1 seed generation
fn generate_v1_seed(epoch: u64, round: u64) -> Vec<u8> {
    [
        epoch.to_le_bytes().to_vec(),
        round.to_le_bytes().to_vec(),
    ]
    .concat()
}

// Simulate the weighted selection algorithm
fn next_in_range(state: Vec<u8>, max: u128) -> u128 {
    let hash = HashValue::sha3_256_of(&state).to_vec();
    let mut temp = [0u8; 16];
    temp.copy_from_slice(&hash[..16]);
    u128::from_le_bytes(temp) % max
}

fn choose_index(weights: Vec<u128>, state: Vec<u8>) -> usize {
    let mut cumulative_weights = Vec::new();
    let mut total = 0u128;
    
    for w in weights {
        total += w;
        cumulative_weights.push(total);
    }
    
    let chosen = next_in_range(state, total);
    
    cumulative_weights
        .binary_search_by(|w| {
            if *w <= chosen {
                std::cmp::Ordering::Less
            } else {
                std::cmp::Ordering::Greater
            }
        })
        .unwrap_err()
}

// Demonstration: A validator can predict all future proposers
fn predict_future_proposers(
    epoch: u64,
    validators: Vec<AccountAddress>,
    weights: Vec<u128>,
    start_round: u64,
    num_rounds: u64,
) -> Vec<(u64, AccountAddress)> {
    let mut predictions = Vec::new();
    
    for round in start_round..(start_round + num_rounds) {
        let seed = generate_v1_seed(epoch, round);
        let proposer_index = choose_index(weights.clone(), seed);
        predictions.push((round, validators[proposer_index]));
    }
    
    predictions
}

#[test]
fn test_predictable_selection() {
    // Setup: 4 validators with different weights
    let validators = vec![
        AccountAddress::from_hex_literal("0x1").unwrap(),
        AccountAddress::from_hex_literal("0x2").unwrap(),
        AccountAddress::from_hex_literal("0x3").unwrap(),
        AccountAddress::from_hex_literal("0x4").unwrap(),
    ];
    
    // Weights based on stake and reputation
    // active_weight=1000, voting_power varies
    let weights = vec![
        1000 * 100, // Validator 1: 100 stake
        1000 * 200, // Validator 2: 200 stake
        1000 * 150, // Validator 3: 150 stake
        1000 * 50,  // Validator 4: 50 stake
    ];
    
    let epoch = 5;
    let start_round = 100;
    
    // Validator can predict next 1000 rounds
    let predictions = predict_future_proposers(
        epoch,
        validators.clone(),
        weights.clone(),
        start_round,
        1000,
    );
    
    // Count how many times each validator is selected
    let mut selection_counts = vec![0; validators.len()];
    for (_round, proposer) in &predictions {
        let idx = validators.iter().position(|v| v == proposer).unwrap();
        selection_counts[idx] += 1;
    }
    
    println!("Predictable selections over 1000 rounds:");
    for (i, count) in selection_counts.iter().enumerate() {
        println!("Validator {}: {} times ({}%)", 
            i + 1, count, (*count as f64 / 1000.0) * 100.0);
    }
    
    // Demonstrate that Validator 2 can now strategically participate:
    // - They know exactly which rounds they'll be selected
    // - They can go offline during other rounds
    // - This reduces costs while maintaining rewards
    
    let validator_2_rounds: Vec<u64> = predictions
        .iter()
        .filter(|(_r, p)| *p == validators[1])
        .map(|(r, _p)| *r)
        .collect();
    
    println!("\nValidator 2 only needs to be online for {} specific rounds", 
        validator_2_rounds.len());
    println!("Strategic savings: {}% operational time reduction",
        ((1000 - validator_2_rounds.len()) as f64 / 1000.0) * 100.0);
}
```

**Expected Output:**
The test demonstrates that validators can predict all future proposer selections with 100% accuracy when using ProposerAndVoter V1, enabling strategic participation that reduces operational costs while maintaining rewards.

## Notes

- The vulnerability only affects networks using the deprecated `ProposerAndVoter` (V1) configuration
- The current default and recommended configuration (`ProposerAndVoterV2`) is NOT vulnerable as it includes the unpredictable root hash in the seed
- This is a game-theoretic vulnerability that breaks fairness assumptions rather than a traditional security bug
- The issue demonstrates why unpredictable randomness is critical for fair distributed systems
- The migration path from V1 to V2 exists and has been tested in the codebase

### Citations

**File:** consensus/src/liveness/leader_reputation.rs (L541-549)
```rust
                if cur_failed_proposals * 100
                    > (cur_proposals + cur_failed_proposals) * self.failure_threshold_percent
                {
                    self.failed_weight
                } else if cur_proposals > 0 || cur_votes > 0 {
                    self.active_weight
                } else {
                    self.inactive_weight
                }
```

**File:** consensus/src/liveness/leader_reputation.rs (L710-716)
```rust
        // Multiply weights by voting power:
        let stake_weights: Vec<u128> = weights
            .iter_mut()
            .enumerate()
            .map(|(i, w)| *w as u128 * self.voting_powers[i] as u128)
            .collect();

```

**File:** consensus/src/liveness/leader_reputation.rs (L717-730)
```rust
        let state = if self.use_root_hash {
            [
                root_hash.to_vec(),
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        } else {
            [
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        };
```

**File:** types/src/on_chain_config/consensus_config.rs (L488-503)
```rust
            proposer_election_type: ProposerElectionType::LeaderReputation(
                LeaderReputationType::ProposerAndVoterV2(ProposerAndVoterConfig {
                    active_weight: 1000,
                    inactive_weight: 10,
                    failed_weight: 1,
                    failure_threshold_percent: 10, // = 10%
                    // In each round we get stastics for the single proposer
                    // and large number of validators. So the window for
                    // the proposers needs to be significantly larger
                    // to have enough useful statistics.
                    proposer_window_num_validators_multiplier: 10,
                    voter_window_num_validators_multiplier: 1,
                    weight_by_voting_power: true,
                    use_history_from_previous_epoch_max_count: 5,
                }),
            ),
```

**File:** types/src/on_chain_config/consensus_config.rs (L525-550)
```rust
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[serde(rename_all = "snake_case")]
pub enum LeaderReputationType {
    // Proposer election based on whether nodes succeeded or failed
    // their proposer election rounds, and whether they voted.
    // Version 1:
    // * use reputation window from stale end
    // * simple (predictable) seed
    ProposerAndVoter(ProposerAndVoterConfig),
    // Version 2:
    // * use reputation window from recent end
    // * unpredictable seed, based on root hash
    ProposerAndVoterV2(ProposerAndVoterConfig),
}

impl LeaderReputationType {
    pub fn use_root_hash_for_seed(&self) -> bool {
        // all versions after V1 should use root hash
        !matches!(self, Self::ProposerAndVoter(_))
    }

    pub fn use_reputation_window_from_stale_end(&self) -> bool {
        // all versions after V1 shouldn't use from stale end
        matches!(self, Self::ProposerAndVoter(_))
    }
}
```

**File:** consensus/src/liveness/proposer_election.rs (L39-69)
```rust
fn next_in_range(state: Vec<u8>, max: u128) -> u128 {
    // hash = SHA-3-256(state)
    let hash = aptos_crypto::HashValue::sha3_256_of(&state).to_vec();
    let mut temp = [0u8; 16];
    copy_slice_to_vec(&hash[..16], &mut temp).expect("next failed");
    // return hash[0..16]
    u128::from_le_bytes(temp) % max
}

// chose index randomly, with given weight distribution
pub(crate) fn choose_index(mut weights: Vec<u128>, state: Vec<u8>) -> usize {
    let mut total_weight = 0;
    // Create cumulative weights vector
    // Since we own the vector, we can safely modify it in place
    for w in &mut weights {
        total_weight = total_weight
            .checked_add(w)
            .expect("Total stake shouldn't exceed u128::MAX");
        *w = total_weight;
    }
    let chosen_weight = next_in_range(state, total_weight);
    weights
        .binary_search_by(|w| {
            if *w <= chosen_weight {
                Ordering::Less
            } else {
                Ordering::Greater
            }
        })
        .expect_err("Comparison never returns equals, so it's always guaranteed to be error")
}
```
