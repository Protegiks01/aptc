# Audit Report

## Title
State Divergence in Quorum Store Coordinator Due to Unhandled BatchGenerator Channel Failure

## Summary
The `QuorumStoreCoordinator::start()` function contains a critical state synchronization vulnerability where a panic on line 80 during `CommitNotification` handling can cause permanent state divergence between `ProofCoordinator`, `ProofManager`, and `BatchGenerator` components, leading to transaction liveness failures and unbounded memory growth. [1](#0-0) 

## Finding Description

The vulnerability exists in the sequential message-passing pattern used for `CommitNotification` events. When a block is committed, the coordinator sends notifications to three components in order:

1. **ProofCoordinator** (lines 61-64) - processes and updates internal state
2. **ProofManager** (lines 66-72) - marks batches as committed in proof queue
3. **BatchGenerator** (lines 74-80) - removes batches from in-progress tracking [2](#0-1) 

Each send operation uses `.expect()` which panics on channel failure. If the `BatchGenerator` receiver has been dropped (due to task panic, crash, or any failure), the send on line 74 fails and line 80 panics. However, at this point:

- **ProofCoordinator** has already processed the notification
- **ProofManager** has already marked batches as committed via `batch_proof_queue.mark_committed(batches)` [3](#0-2) 

- **BatchGenerator** never receives the notification, so batches remain in `batches_in_progress` and transactions stay in `txns_in_progress_sorted` [4](#0-3) 

This creates permanent state divergence where `ProofManager` believes batches are committed while `BatchGenerator` still tracks them as in-progress.

**Critical Impact**: When `BatchGenerator` pulls new transactions from mempool, it passes `txns_in_progress_sorted` as the exclusion list: [5](#0-4) 

Since committed batches were never removed from this map, their transactions are permanently excluded from future batch generation, causing transaction liveness failure.

## Impact Explanation

**High Severity** - This qualifies as "Significant protocol violations" and "State inconsistencies requiring intervention" per the Aptos bug bounty program:

1. **Transaction Liveness Failure**: Transactions in the divergent batches are permanently excluded from mempool pulls, preventing them from ever being included in new batches even though they were already committed to the blockchain

2. **Memory Leak**: The `batches_in_progress` HashMap grows unbounded as committed batches accumulate without cleanup, eventually exhausting validator memory

3. **Validator Malfunction**: The `QuorumStoreCoordinator` task crashes, disrupting the validator's consensus participation

4. **State Consistency Violation**: Breaks the critical invariant that all consensus components maintain synchronized views of batch commitment status

Unlike `BatchCoordinator` which gracefully handles channel failures with warnings: [6](#0-5) 

The coordinator uses `.expect()` causing cascading failures.

## Likelihood Explanation

**Medium-to-High Likelihood**:

The `BatchGenerator` task can terminate prematurely due to:
- Database errors during batch persistence
- Out-of-memory conditions
- Assertion failures in batch processing logic
- Any panic in the command handling loop [7](#0-6) 

Once the receiver is dropped, the next `CommitNotification` triggers the vulnerability. The shutdown sequence comment acknowledges this risk: [8](#0-7) 

However, this protection only applies during graceful shutdown, not unexpected crashes.

## Recommendation

Replace `.expect()` with graceful error handling for all three component sends:

```rust
// In QuorumStoreCoordinator::start() CommitNotification handling
if let Err(e) = self.proof_coordinator_cmd_tx
    .send(ProofCoordinatorCommand::CommitNotification(batches.clone()))
    .await
{
    error!("Failed to send CommitNotification to ProofCoordinator: {}", e);
    // Do not proceed with other components to maintain consistency
    continue;
}

if let Err(e) = self.proof_manager_cmd_tx
    .send(ProofManagerCommand::CommitNotification(
        block_timestamp,
        batches.clone(),
    ))
    .await
{
    error!("Failed to send CommitNotification to ProofManager: {}", e);
    continue;
}

if let Err(e) = self.batch_generator_cmd_tx
    .send(BatchGeneratorCommand::CommitNotification(
        block_timestamp,
        batches,
    ))
    .await
{
    error!("Failed to send CommitNotification to BatchGenerator: {}", e);
}
```

Alternatively, use an atomic transaction-like approach where all three sends are attempted first, and only committed if all succeed, or implement a rollback mechanism to undo partial state updates.

## Proof of Concept

```rust
// Rust test to demonstrate the vulnerability
#[tokio::test]
async fn test_commit_notification_divergence() {
    use tokio::sync::mpsc;
    use consensus::quorum_store::{
        batch_generator::BatchGeneratorCommand,
        proof_coordinator::ProofCoordinatorCommand,
        proof_manager::ProofManagerCommand,
        quorum_store_coordinator::{QuorumStoreCoordinator, CoordinatorCommand},
    };
    
    let (batch_gen_tx, mut batch_gen_rx) = mpsc::channel(10);
    let (proof_coord_tx, mut proof_coord_rx) = mpsc::channel(10);
    let (proof_mgr_tx, mut proof_mgr_rx) = mpsc::channel(10);
    let (coord_tx, coord_rx) = futures_channel::mpsc::channel(10);
    let (qs_msg_tx, _) = aptos_channel::new(QueueStyle::FIFO, 10, None);
    
    let coordinator = QuorumStoreCoordinator::new(
        PeerId::random(),
        batch_gen_tx,
        vec![],
        proof_coord_tx,
        proof_mgr_tx,
        qs_msg_tx,
    );
    
    // Simulate BatchGenerator crash by dropping receiver
    drop(batch_gen_rx);
    
    // Send CommitNotification
    let batches = vec![];
    coord_tx.unbounded_send(
        CoordinatorCommand::CommitNotification(1000, batches)
    ).unwrap();
    
    // Coordinator will panic on line 80 when trying to send to BatchGenerator
    // ProofCoordinator and ProofManager will have received the notification
    // but BatchGenerator will not, creating state divergence
    
    let handle = tokio::spawn(coordinator.start(coord_rx));
    
    // Verify ProofCoordinator received notification
    assert!(proof_coord_rx.recv().await.is_some());
    
    // Verify ProofManager received notification  
    assert!(proof_mgr_rx.recv().await.is_some());
    
    // Coordinator task panics and terminates
    assert!(handle.await.is_err());
}
```

**Notes**

The vulnerability demonstrates a violation of the **State Consistency** invariant: "State transitions must be atomic and verifiable." The non-atomic, sequential notification pattern allows partial state updates when component failures occur, leading to permanent divergence between critical consensus subsystems.

This issue is particularly severe because the affected transactions become permanently stuck in the exclusion list, violating transaction liveness guarantees without any recovery mechanism. The validator experiencing this bug cannot self-heal and requires manual intervention or restart to restore consistency.

### Citations

**File:** consensus/src/quorum_store/quorum_store_coordinator.rs (L61-80)
```rust
                        self.proof_coordinator_cmd_tx
                            .send(ProofCoordinatorCommand::CommitNotification(batches.clone()))
                            .await
                            .expect("Failed to send to ProofCoordinator");

                        self.proof_manager_cmd_tx
                            .send(ProofManagerCommand::CommitNotification(
                                block_timestamp,
                                batches.clone(),
                            ))
                            .await
                            .expect("Failed to send to ProofManager");

                        self.batch_generator_cmd_tx
                            .send(BatchGeneratorCommand::CommitNotification(
                                block_timestamp,
                                batches,
                            ))
                            .await
                            .expect("Failed to send to BatchGenerator");
```

**File:** consensus/src/quorum_store/quorum_store_coordinator.rs (L86-91)
```rust
                        // Note: Shutdown is done from the back of the quorum store pipeline to the
                        // front, so senders are always shutdown before receivers. This avoids sending
                        // messages through closed channels during shutdown.
                        // Oneshots that send data in the reverse order of the pipeline must assume that
                        // the receiver could be unavailable during shutdown, and resolve this without
                        // panicking.
```

**File:** consensus/src/quorum_store/proof_manager.rs (L88-100)
```rust
    pub(crate) fn handle_commit_notification(
        &mut self,
        block_timestamp: u64,
        batches: Vec<BatchInfoExt>,
    ) {
        trace!(
            "QS: got clean request from execution at block timestamp {}",
            block_timestamp
        );
        self.batch_proof_queue.mark_committed(batches);
        self.batch_proof_queue
            .handle_updated_block_timestamp(block_timestamp);
        self.update_remaining_txns_and_proofs();
```

**File:** consensus/src/quorum_store/batch_generator.rs (L352-360)
```rust
        let mut pulled_txns = self
            .mempool_proxy
            .pull_internal(
                max_count,
                self.config.sender_max_total_bytes as u64,
                self.txns_in_progress_sorted.clone(),
            )
            .await
            .unwrap_or_default();
```

**File:** consensus/src/quorum_store/batch_generator.rs (L423-577)
```rust
        loop {
            let _timer = counters::BATCH_GENERATOR_MAIN_LOOP.start_timer();

            tokio::select! {
                Some(updated_back_pressure) = back_pressure_rx.recv() => {
                    self.back_pressure = updated_back_pressure;
                },
                _ = interval.tick() => monitor!("batch_generator_handle_tick", {

                    let tick_start = Instant::now();
                    // TODO: refactor back_pressure logic into its own function
                    if self.back_pressure.txn_count {
                        // multiplicative decrease, every second
                        if back_pressure_decrease_latest.elapsed() >= back_pressure_decrease_duration {
                            back_pressure_decrease_latest = tick_start;
                            dynamic_pull_txn_per_s = std::cmp::max(
                                (dynamic_pull_txn_per_s as f64 * self.config.back_pressure.decrease_fraction) as u64,
                                self.config.back_pressure.dynamic_min_txn_per_s,
                            );
                            trace!("QS: dynamic_max_pull_txn_per_s: {}", dynamic_pull_txn_per_s);
                        }
                        counters::QS_BACKPRESSURE_TXN_COUNT.observe(1.0);
                        counters::QS_BACKPRESSURE_MAKE_STRICTER_TXN_COUNT.observe(1.0);
                        counters::QS_BACKPRESSURE_DYNAMIC_MAX.observe(dynamic_pull_txn_per_s as f64);
                    } else {
                        // additive increase, every second
                        if back_pressure_increase_latest.elapsed() >= back_pressure_increase_duration {
                            back_pressure_increase_latest = tick_start;
                            dynamic_pull_txn_per_s = std::cmp::min(
                                dynamic_pull_txn_per_s + self.config.back_pressure.additive_increase_when_no_backpressure,
                                self.config.back_pressure.dynamic_max_txn_per_s,
                            );
                            trace!("QS: dynamic_max_pull_txn_per_s: {}", dynamic_pull_txn_per_s);
                        }
                        counters::QS_BACKPRESSURE_TXN_COUNT.observe(
                            if dynamic_pull_txn_per_s < self.config.back_pressure.dynamic_max_txn_per_s { 1.0 } else { 0.0 }
                        );
                        counters::QS_BACKPRESSURE_MAKE_STRICTER_TXN_COUNT.observe(0.0);
                        counters::QS_BACKPRESSURE_DYNAMIC_MAX.observe(dynamic_pull_txn_per_s as f64);
                    }
                    if self.back_pressure.proof_count {
                        counters::QS_BACKPRESSURE_PROOF_COUNT.observe(1.0);
                    } else {
                        counters::QS_BACKPRESSURE_PROOF_COUNT.observe(0.0);
                    }
                    let since_last_non_empty_pull_ms = std::cmp::min(
                        tick_start.duration_since(last_non_empty_pull).as_millis(),
                        self.config.batch_generation_max_interval_ms as u128
                    ) as usize;
                    if (!self.back_pressure.proof_count
                        && since_last_non_empty_pull_ms >= self.config.batch_generation_min_non_empty_interval_ms)
                        || since_last_non_empty_pull_ms == self.config.batch_generation_max_interval_ms {

                        let dynamic_pull_max_txn = std::cmp::max(
                            (since_last_non_empty_pull_ms as f64 / 1000.0 * dynamic_pull_txn_per_s as f64) as u64, 1);
                        let pull_max_txn = std::cmp::min(
                            dynamic_pull_max_txn,
                            self.config.sender_max_total_txns as u64,
                        );
                        let batches = self.handle_scheduled_pull(pull_max_txn).await;
                        if !batches.is_empty() {
                            last_non_empty_pull = tick_start;

                            let persist_start = Instant::now();
                            let mut persist_requests = vec![];
                            for batch in batches.clone().into_iter() {
                                persist_requests.push(batch.into());
                            }
                            self.batch_writer.persist(persist_requests);
                            counters::BATCH_CREATION_PERSIST_LATENCY.observe_duration(persist_start.elapsed());

                            if self.config.enable_batch_v2 {
                                network_sender.broadcast_batch_msg_v2(batches).await;
                            } else {
                                let batches = batches.into_iter().map(|batch| {
                                    batch.try_into().expect("Cannot send V2 batch with flag disabled")
                                }).collect();
                                network_sender.broadcast_batch_msg(batches).await;
                            }
                        } else if tick_start.elapsed() > interval.period().checked_div(2).unwrap_or(Duration::ZERO) {
                            // If the pull takes too long, it's also accounted as a non-empty pull to avoid pulling too often.
                            last_non_empty_pull = tick_start;
                            sample!(
                                SampleRate::Duration(Duration::from_secs(1)),
                                info!(
                                    "QS: pull took a long time, {} ms",
                                    tick_start.elapsed().as_millis()
                                )
                            );
                        }
                    }
                }),
                Some(cmd) = cmd_rx.recv() => monitor!("batch_generator_handle_command", {
                    match cmd {
                        BatchGeneratorCommand::CommitNotification(block_timestamp, batches) => {
                            trace!(
                                "QS: got clean request from execution, block timestamp {}",
                                block_timestamp
                            );
                            // Block timestamp is updated asynchronously, so it may race when it enters state sync.
                            if self.latest_block_timestamp > block_timestamp {
                                continue;
                            }
                            self.latest_block_timestamp = block_timestamp;

                            for (author, batch_id) in batches.iter().map(|b| (b.author(), b.batch_id())) {
                                if self.remove_batch_in_progress(author, batch_id) {
                                    counters::BATCH_IN_PROGRESS_COMMITTED.inc();
                                }
                            }

                            // Cleans up all batches that expire in timestamp <= block_timestamp. This is
                            // safe since clean request must occur only after execution result is certified.
                            for (author, batch_id) in self.batch_expirations.expire(block_timestamp) {
                                if let Some(batch_in_progress) = self.batches_in_progress.get(&(author, batch_id)) {
                                    // If there is an identical batch with higher expiry time, re-insert it.
                                    if batch_in_progress.expiry_time_usecs > block_timestamp {
                                        self.batch_expirations.add_item((author, batch_id), batch_in_progress.expiry_time_usecs);
                                        continue;
                                    }
                                }
                                if self.remove_batch_in_progress(author, batch_id) {
                                    counters::BATCH_IN_PROGRESS_EXPIRED.inc();
                                    debug!(
                                        "QS: logical time based expiration batch w. id {} from batches_in_progress, new size {}",
                                        batch_id,
                                        self.batches_in_progress.len(),
                                    );
                                }
                            }
                        },
                        BatchGeneratorCommand::ProofExpiration(batch_ids) => {
                            for batch_id in batch_ids {
                                counters::BATCH_IN_PROGRESS_TIMEOUT.inc();
                                debug!(
                                    "QS: received timeout for proof of store, batch id = {}",
                                    batch_id
                                );
                                // Not able to gather the proof, allow transactions to be polled again.
                                self.remove_batch_in_progress(self.my_peer_id, batch_id);
                            }
                        },
                        BatchGeneratorCommand::RemoteBatch(batch) => {
                            self.handle_remote_batch(batch.author(), batch.batch_id(), batch.into_transactions());
                        },
                        BatchGeneratorCommand::Shutdown(ack_tx) => {
                            ack_tx
                                .send(())
                                .expect("Failed to send shutdown ack");
                            break;
                        },
                    }
                })
            }
        }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L231-237)
```rust
            if let Err(e) = self
                .sender_to_batch_generator
                .send(BatchGeneratorCommand::RemoteBatch(batch.clone()))
                .await
            {
                warn!("Failed to send batch to batch generator: {}", e);
            }
```
