# Audit Report

## Title
JWK Consensus Manager Transaction Pool Removal Vulnerability via Rapid Observation State Transitions

## Summary
The JWK consensus manager unconditionally restarts consensus when new observations arrive, even when a quorum-certified update is already in the validator transaction pool awaiting block inclusion. This causes premature removal of valid transactions through guard drops, enabling denial-of-service attacks on JWK updates by rapidly oscillating provider keys.

## Finding Description

The vulnerability exists in the interaction between `process_new_observation()` and the validator transaction pool lifecycle management. [1](#0-0) 

The critical flaw is at line 196 which only checks if `observed != on_chain`, without verifying the current `consensus_state`. When a validator completes consensus and reaches `Finished` state, the quorum-certified update is placed in the validator transaction pool with a `TxnGuard`: [2](#0-1) 

However, if a new observation arrives before the on-chain state updates (which requires consensus → execution → commit, taking at least one block time), the code at line 216 unconditionally overwrites the `Finished` state with a new `InProgress` state:

When `Finished` is dropped, the `vtxn_guard` is dropped. The `TxnGuard::drop()` implementation removes the transaction from the pool: [3](#0-2) 

**Attack Scenario:**
1. Attacker controls an OIDC provider's JWK endpoint
2. Publishes JWKs = [key1, key2]
3. Validators observe, reach consensus, obtain QC, place in validator txn pool (state = `Finished`)
4. Before consensus can pull the transaction, attacker publishes JWKs = [key1, key2, key3]
5. Validators observe new state, check passes (line 196), new consensus starts
6. State transitions from `Finished` to `InProgress`, dropping `vtxn_guard`
7. Original quorum-certified transaction removed from pool
8. Attacker repeats by oscillating keys rapidly
9. JWK updates never reach the blockchain

The channel back pressure (capacity 1, KLAST style) is correctly handled via the abort mechanism when tasks are replaced. However, the state transition vulnerability occurs AFTER successful consensus completion when the transaction is already in the pool. [4](#0-3) 

## Impact Explanation

This constitutes **High Severity** under Aptos bug bounty criteria for the following reasons:

1. **Significant Protocol Violations**: JWK consensus is a critical validator operation for on-chain authentication. Blocking JWK updates prevents proper OIDC integration and authentication mechanisms from functioning correctly.

2. **Validator Node Operation Impact**: Validators waste computational resources performing consensus that never materializes on-chain. This affects node efficiency and bandwidth utilization.

3. **Liveness Failure**: While not total network liveness loss, it causes persistent failure of a specific protocol subsystem (JWK updates), which could require manual intervention to resolve if an attacker maintains the attack.

4. **Low Attack Barrier**: The attacker only needs control over an OIDC provider's JWK endpoint (a legitimate service they may operate) and can trigger this through normal HTTP responses, requiring no special validator access or cryptographic capabilities.

The issue does NOT reach Critical severity because:
- No funds are at risk
- Core consensus (AptosBFT) is unaffected
- Does not cause permanent network damage
- Can be mitigated by removing the malicious OIDC provider from the supported list

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to occur under normal operations:

1. **Observation Frequency**: JWK observers poll every 10 seconds (line 122 in the file), creating frequent observation windows.

2. **Block Time vs Observation Rate**: On-chain updates require consensus (multiple seconds minimum), while observations happen every 10 seconds. This creates natural race conditions even without malicious actors.

3. **Legitimate Key Rotations**: OIDC providers legitimately rotate keys for security. A provider performing rapid key rotations (e.g., emergency response to compromise) could unintentionally trigger this.

4. **Malicious Exploitation**: An attacker with OIDC provider access can trivially trigger this by:
   - Publishing key set A
   - Waiting ~5 seconds (partial consensus completion)
   - Publishing key set B
   - Repeating indefinitely

5. **Multi-Issuer Amplification**: With multiple OIDC providers, the probability of this occurring increases as each issuer has independent observation cycles.

The attack requires only HTTP endpoint control, making it practically exploitable by:
- Malicious OIDC provider operators
- Attackers who compromise an OIDC provider's infrastructure
- Misconfigured OIDC providers with unstable key sets

## Recommendation

Add a state check in `process_new_observation()` to prevent restarting consensus when already in `Finished` state:

```rust
pub fn process_new_observation(
    &mut self,
    issuer: Issuer,
    jwks: Vec<JWKMoveStruct>,
) -> Result<()> {
    debug!(
        epoch = self.epoch_state.epoch,
        issuer = String::from_utf8(issuer.clone()).ok(),
        "Processing new observation."
    );
    let state = self.states_by_issuer.entry(issuer.clone()).or_default();
    state.observed = Some(jwks.clone());
    
    // ADD THIS CHECK: Don't restart consensus if already Finished
    if matches!(state.consensus_state, ConsensusState::Finished { .. }) {
        debug!(
            epoch = self.epoch_state.epoch,
            issuer = String::from_utf8(issuer.clone()).ok(),
            "Skipping consensus - already finished with pending txn"
        );
        return Ok(());
    }
    
    if state.observed.as_ref() != state.on_chain.as_ref().map(ProviderJWKs::jwks) {
        // ... rest of consensus start logic
    }
    Ok(())
}
```

Alternative: Implement a "staged observation" approach where new observations are queued but don't start consensus until the current `Finished` state is processed (transaction included on-chain or on-chain state updated).

## Proof of Concept

```rust
#[tokio::test]
async fn test_rapid_observation_removes_pending_txn() {
    // Setup: Create JWK manager with mock components
    let consensus_key = Arc::new(PrivateKey::generate_for_testing());
    let my_addr = AccountAddress::random();
    let epoch_state = Arc::new(create_test_epoch_state());
    let update_certifier = Arc::new(DummyUpdateCertifier::new());
    let vtxn_pool = VTxnPoolState::default();
    
    let mut manager = IssuerLevelConsensusManager::new(
        consensus_key,
        my_addr,
        epoch_state,
        update_certifier,
        vtxn_pool.clone(),
    );
    
    let issuer = b"https://example.com".to_vec();
    
    // Step 1: Initialize with on-chain state
    manager.reset_with_on_chain_state(AllProvidersJWKs {
        entries: vec![ProviderJWKs {
            issuer: issuer.clone(),
            version: 1,
            jwks: vec![create_test_jwk("key1")],
        }],
    }).unwrap();
    
    // Step 2: First observation triggers consensus
    let jwks_v2 = vec![create_test_jwk("key1"), create_test_jwk("key2")];
    manager.process_new_observation(issuer.clone(), jwks_v2.clone()).unwrap();
    
    // Step 3: Simulate consensus completion - produce QC
    let qc = create_test_quorum_certified_update(&issuer, 2, jwks_v2.clone());
    manager.process_quorum_certified_update(qc).unwrap();
    
    // Step 4: Verify transaction is in pool
    let txns = vtxn_pool.pull(
        Instant::now() + Duration::from_secs(1),
        10,
        10000,
        TransactionFilter::no_op()
    );
    assert_eq!(txns.len(), 1, "Transaction should be in pool");
    
    // Step 5: New observation before on-chain update
    let jwks_v3 = vec![create_test_jwk("key1"), create_test_jwk("key2"), create_test_jwk("key3")];
    manager.process_new_observation(issuer.clone(), jwks_v3).unwrap();
    
    // Step 6: VULNERABILITY: Transaction removed from pool!
    let txns_after = vtxn_pool.pull(
        Instant::now() + Duration::from_secs(1),
        10,
        10000,
        TransactionFilter::no_op()
    );
    assert_eq!(txns_after.len(), 0, "VULNERABILITY: Transaction was removed!");
}
```

## Notes

The vulnerability affects the issuer-level JWK consensus manager. The per-key mode manager (`jwk_manager_per_key.rs`) has similar patterns and should be reviewed for the same issue. The channel capacity (KLAST, size 1) is sufficient for preventing deadlock through the abort mechanism, but the state transition flaw occurs at a higher level in the transaction pool lifecycle management.

### Citations

**File:** crates/aptos-jwk-consensus/src/jwk_manager/mod.rs (L184-228)
```rust
    pub fn process_new_observation(
        &mut self,
        issuer: Issuer,
        jwks: Vec<JWKMoveStruct>,
    ) -> Result<()> {
        debug!(
            epoch = self.epoch_state.epoch,
            issuer = String::from_utf8(issuer.clone()).ok(),
            "Processing new observation."
        );
        let state = self.states_by_issuer.entry(issuer.clone()).or_default();
        state.observed = Some(jwks.clone());
        if state.observed.as_ref() != state.on_chain.as_ref().map(ProviderJWKs::jwks) {
            let observed = ProviderJWKs {
                issuer: issuer.clone(),
                version: state.on_chain_version() + 1,
                jwks,
            };
            let signature = self
                .consensus_key
                .sign(&observed)
                .context("process_new_observation failed with signing error")?;
            let abort_handle = self
                .update_certifier
                .start_produce(
                    self.epoch_state.clone(),
                    observed.clone(),
                    self.qc_update_tx.clone(),
                )
                .context(
                    "process_new_observation failed with update_certifier.start_produce failure",
                )?;
            state.consensus_state = ConsensusState::InProgress {
                my_proposal: ObservedUpdate {
                    author: self.my_addr,
                    observed: observed.clone(),
                    signature,
                },
                abort_handle_wrapper: QuorumCertProcessGuard::new(abort_handle),
            };
            info!("[JWK] update observed, update={:?}", observed);
        }

        Ok(())
    }
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager/mod.rs (L332-343)
```rust
        match &state.consensus_state {
            ConsensusState::InProgress { my_proposal, .. } => {
                //TODO: counters
                let txn = ValidatorTransaction::ObservedJWKUpdate(update.clone());
                let vtxn_guard =
                    self.vtxn_pool
                        .put(Topic::JWK_CONSENSUS(issuer.clone()), Arc::new(txn), None);
                state.consensus_state = ConsensusState::Finished {
                    vtxn_guard,
                    my_proposal: my_proposal.clone(),
                    quorum_certified: update.clone(),
                };
```

**File:** crates/validator-transaction-pool/src/lib.rs (L202-206)
```rust
impl Drop for TxnGuard {
    fn drop(&mut self) {
        self.pool.lock().try_delete(self.seq_num);
    }
}
```

**File:** crates/aptos-jwk-consensus/src/types.rs (L96-101)
```rust
impl Drop for QuorumCertProcessGuard {
    fn drop(&mut self) {
        let QuorumCertProcessGuard { handle } = self;
        handle.abort();
    }
}
```
