# Audit Report

## Title
Missing Rate Limiting in Aptos Rosetta API Enables Resource Exhaustion via Request Amplification

## Summary
The Aptos Rosetta API balance query endpoints lack rate limiting controls, allowing unauthenticated attackers to spam requests that amplify into multiple expensive backend operations on the underlying fullnode, potentially causing resource exhaustion and service degradation.

## Finding Description

The Rosetta API's `/account/balance` endpoint processes balance queries without any rate limiting restrictions. This vulnerability exists at multiple layers:

**1. Rosetta API Layer - No Rate Limiting**

The Rosetta API server routes are configured without rate limiting middleware: [1](#0-0) 

The middleware stack only includes CORS, logging, and error handling - no rate limiting filter is applied.

**2. Account Balance Handler - Unbounded Requests**

The balance query handler processes each request without authentication or throttling: [2](#0-1) 

**3. Request Amplification to Backend**

Each balance query triggers multiple downstream operations: [3](#0-2) 

For a single `/account/balance` request, the handler executes:
- `get_sequence_number()`: 1 REST API call to fetch account resource
- `get_base_balances()`: N view function calls (N = number of currencies, potentially many)
- `get_stake_balances()` or `get_delegation_stake_balances()`: Additional REST API calls and view functions

**4. Stake Balance Functions - High-Cost Operations**

The stake balance functions perform expensive view function calls and resource queries: [4](#0-3) [5](#0-4) 

Each of these operations requires:
- Database queries to retrieve account state at specific versions
- View function execution in the Move VM
- State tree traversals for Merkle proof verification
- BCS deserialization of on-chain data

**5. Fullnode REST API - Also Missing Rate Limiting**

The underlying fullnode REST API that Rosetta queries also lacks rate limiting middleware: [6](#0-5) 

The fullnode API middleware stack includes compression, size limits, and logging, but no rate limiting.

**6. Documentation Discrepancy**

The API documentation claims rate limiting exists, but it is not implemented: [7](#0-6) 

This documentation states "Rate limiting: 100 requests per minute by default", but code inspection confirms no such limiting exists in the implementation.

**Attack Scenario:**

1. Attacker sends thousands of concurrent requests to `/account/balance` endpoint
2. Each request amplifies into 3-10+ backend REST API calls
3. Each backend call triggers database I/O, state tree traversals, and Move VM execution
4. The amplification factor (frontend requests Ã— backend calls per request) overwhelms the fullnode
5. Legitimate requests experience delays or failures
6. If the fullnode serves other critical services, those services degrade

## Impact Explanation

This vulnerability enables **resource exhaustion** through request amplification. While the Rosetta API is an auxiliary service rather than core consensus infrastructure, the impact depends on deployment architecture:

**Service Degradation:** Unbounded requests can exhaust:
- CPU resources (Move VM execution, cryptographic operations)
- Memory (concurrent request buffers, cached state)
- Database I/O (state reads, version lookups)
- Network connections (connection pool exhaustion)

**Amplification Factor:** A single malicious request triggers multiple expensive backend operations, making this more severe than simple request flooding.

**Cascading Impact:** If the Rosetta instance shares a fullnode with other services (block explorers, indexers, validator operations), resource exhaustion affects those services as well.

**Severity Assessment:** This represents a **Medium severity** vulnerability under the Aptos Bug Bounty criteria as it causes service degradation requiring operational intervention to mitigate, though it does not directly impact consensus, funds, or state integrity. The issue breaks the **Resource Limits** invariant that "all operations must respect gas, storage, and computational limits."

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly likely to be exploited because:

1. **Trivial Exploitation:** Requires only HTTP client and network access - no authentication, special permissions, or technical sophistication
2. **No Attacker Barriers:** Rosetta endpoints are publicly accessible by design for exchange integrations
3. **Immediate Impact:** Resource exhaustion manifests immediately with sufficient request volume
4. **Low Detection:** Without rate limiting, distinguishing malicious from legitimate traffic is difficult
5. **Amplification Advantage:** Request amplification makes exploitation more efficient than simple flooding

The attack requires only basic scripting knowledge and can be executed from any network location with internet access.

## Recommendation

**Implement multi-layer rate limiting:**

**1. Add Rate Limiting Middleware to Rosetta API**

Apply rate limiting at the Rosetta route level using a token bucket or similar algorithm:

```rust
// In crates/aptos-rosetta/src/lib.rs, modify routes() function:

use aptos_rate_limiter::TokenBucketRateLimiter;

pub fn routes(
    context: RosettaContext,
) -> impl Filter<Extract = (impl Reply,), Error = Infallible> + Clone {
    // Create rate limiter: 100 requests per minute per IP
    let rate_limiter = Arc::new(TokenBucketRateLimiter::new(100, Duration::from_secs(60)));
    
    account::routes(context.clone())
        .or(block::block_route(context.clone()))
        // ... other routes ...
        .with(rate_limit_middleware(rate_limiter))  // Add rate limiting
        .with(warp::cors()...)
        .with(logger())
        .recover(handle_rejection)
}
```

**2. Add Rate Limiting to Fullnode REST API**

Implement rate limiting middleware in the fullnode API runtime: [6](#0-5) 

Insert rate limiting middleware before the route definition:

```rust
let rate_limiter = Arc::new(TokenBucketRateLimiter::new(100, Duration::from_secs(60)));

let route = Route::new()
    .at("/", poem::get(root_handler))
    .nest("/v1", ...)
    .with(cors)
    .with(rate_limit_filter(rate_limiter))  // Add this
    .with_if(config.api.compression_enabled, Compression::new())
    .with(PostSizeLimit::new(size_limit))
    // ... rest of middleware
```

**3. Configuration-Based Limits**

Make rate limits configurable via `ApiConfig`:

```rust
pub struct ApiConfig {
    // ... existing fields ...
    pub rate_limit_requests_per_minute: Option<u64>,
    pub rate_limit_per_ip: bool,
}
```

**4. Response Headers**

Include standard rate limit headers in responses:
- `X-RateLimit-Limit`
- `X-RateLimit-Remaining`
- `X-RateLimit-Reset`

Return HTTP 429 (Too Many Requests) when limits are exceeded.

**5. IP-Based and Endpoint-Specific Limits**

Implement different limits for different endpoints:
- Balance queries: 100/minute
- Transaction submission: 10/minute
- Block queries: 200/minute

Track limits per source IP address using the existing `TokenBucketRateLimiter` infrastructure: [8](#0-7) 

## Proof of Concept

```rust
// File: crates/aptos-rosetta/tests/rate_limit_poc.rs
// Proof of Concept: Resource exhaustion via unbounded balance queries

use reqwest::Client;
use std::time::{Duration, Instant};
use tokio::task::JoinSet;

#[tokio::test]
async fn test_rosetta_balance_query_no_rate_limit() {
    // Setup: Start local Rosetta server (assume running on localhost:8082)
    let base_url = "http://localhost:8082";
    let client = Client::new();
    
    // Attack: Send 1000 concurrent balance queries
    let mut join_set = JoinSet::new();
    let start = Instant::now();
    
    for i in 0..1000 {
        let client = client.clone();
        let url = format!("{}/account/balance", base_url);
        
        join_set.spawn(async move {
            let request_body = serde_json::json!({
                "network_identifier": {
                    "blockchain": "aptos",
                    "network": "testnet"
                },
                "account_identifier": {
                    "address": format!("0x{:x}", i)
                }
            });
            
            client.post(&url)
                .json(&request_body)
                .send()
                .await
        });
    }
    
    // Wait for all requests to complete
    let mut success_count = 0;
    while let Some(result) = join_set.join_next().await {
        if let Ok(Ok(response)) = result {
            if response.status().is_success() {
                success_count += 1;
            }
        }
    }
    
    let elapsed = start.elapsed();
    println!("Sent 1000 requests in {:?}", elapsed);
    println!("Success count: {}", success_count);
    
    // Expected: Without rate limiting, all 1000 requests succeed
    // This demonstrates resource exhaustion vulnerability
    // With rate limiting: Should receive 429 responses after limit exceeded
    assert!(success_count > 900, "Most requests should succeed without rate limiting");
}

// Amplification demonstration
#[tokio::test] 
async fn test_balance_query_amplification() {
    let base_url = "http://localhost:8082";
    let client = Client::new();
    
    // Single balance query with staking info triggers multiple backend calls
    let request_body = serde_json::json!({
        "network_identifier": {
            "blockchain": "aptos",
            "network": "testnet"
        },
        "account_identifier": {
            "address": "0x1",
            "sub_account": {
                "address": "stake::operator",
                "pool_address": "0xABC..."
            }
        },
        "currencies": [
            {"symbol": "APT", "decimals": 8},
            {"symbol": "USDC", "decimals": 6}
        ]
    });
    
    // This single request triggers:
    // 1. get_sequence_number() - 1 REST call
    // 2. get_base_balances() - 2 view calls (one per currency)
    // 3. get_stake_balances() - 1 REST call + 1 view call
    // Total: 5 backend operations for 1 frontend request
    
    let response = client.post(format!("{}/account/balance", base_url))
        .json(&request_body)
        .send()
        .await
        .expect("Request failed");
        
    assert!(response.status().is_success());
    
    // Multiply this by 1000 concurrent requests = 5000 backend operations
    // Without rate limiting, this amplification can overwhelm the fullnode
}
```

**Notes**

The vulnerability exists due to the complete absence of rate limiting controls at both the Rosetta API layer and the underlying fullnode REST API layer. While the fullnode API documentation claims "100 requests per minute by default," code inspection confirms this is not implemented. The `aptos-rate-limiter` crate exists in the codebase but is not integrated into either API service. The faucet service demonstrates proper rate limiting implementation using both memory-based and Redis-based checkers, which could serve as a reference for fixing this vulnerability. This issue is distinct from network-level DoS attacks as it exploits request amplification - each frontend request triggers multiple expensive backend operations including database queries, state tree traversals, and Move VM execution.

### Citations

**File:** crates/aptos-rosetta/src/lib.rs (L163-189)
```rust
/// Collection of all routes for the server
pub fn routes(
    context: RosettaContext,
) -> impl Filter<Extract = (impl Reply,), Error = Infallible> + Clone {
    account::routes(context.clone())
        .or(block::block_route(context.clone()))
        .or(construction::combine_route(context.clone()))
        .or(construction::derive_route(context.clone()))
        .or(construction::hash_route(context.clone()))
        .or(construction::metadata_route(context.clone()))
        .or(construction::parse_route(context.clone()))
        .or(construction::payloads_route(context.clone()))
        .or(construction::preprocess_route(context.clone()))
        .or(construction::submit_route(context.clone()))
        .or(network::list_route(context.clone()))
        .or(network::options_route(context.clone()))
        .or(network::status_route(context.clone()))
        .or(health_check_route(context))
        .with(
            warp::cors()
                .allow_any_origin()
                .allow_methods(vec![Method::GET, Method::POST])
                .allow_headers(vec![warp::http::header::CONTENT_TYPE]),
        )
        .with(logger())
        .recover(handle_rejection)
}
```

**File:** crates/aptos-rosetta/src/account.rs (L49-95)
```rust
async fn account_balance(
    request: AccountBalanceRequest,
    server_context: RosettaContext,
) -> ApiResult<AccountBalanceResponse> {
    debug!("/account/balance");
    trace!(
        request = ?request,
        server_context = ?server_context,
        "account_balance for [{}]",
        request.account_identifier.address
    );

    let network_identifier = request.network_identifier;

    check_network(network_identifier, &server_context)?;

    // Retrieve the block index to read
    let block_height =
        get_block_index_from_request(&server_context, request.block_identifier.clone()).await?;

    // Version to grab is the last entry in the block (balance is at end of block)
    // NOTE: In Rosetta, we always do balances by block here rather than ledger version.
    let block_info = server_context
        .block_cache()?
        .get_block_info_by_height(block_height, server_context.chain_id)
        .await?;
    let balance_version = block_info.last_version;

    // Retrieve all metadata we want to provide as an on-demand lookup
    let (sequence_number, operators, balances, lockup_expiration) = get_balances(
        &server_context,
        request.account_identifier,
        balance_version,
        request.currencies,
    )
    .await?;

    Ok(AccountBalanceResponse {
        block_identifier: block_info.block_id,
        balances,
        metadata: AccountBalanceMetadata {
            sequence_number: sequence_number.into(),
            operators,
            lockup_expiration_time_utc: aptos_rest_client::aptos_api_types::U64(lockup_expiration),
        },
    })
}
```

**File:** crates/aptos-rosetta/src/account.rs (L97-160)
```rust
/// Retrieve the balances for an account
#[allow(clippy::manual_retain)]
async fn get_balances(
    server_context: &RosettaContext,
    account: AccountIdentifier,
    version: u64,
    maybe_filter_currencies: Option<Vec<Currency>>,
) -> ApiResult<(u64, Option<Vec<AccountAddress>>, Vec<Amount>, u64)> {
    let rest_client = server_context.rest_client()?;
    let owner_address = account.account_address()?;
    let pool_address = account.pool_address()?;

    let mut balances = vec![];
    let mut lockup_expiration: u64 = 0;
    let mut maybe_operators = None;

    // Handle the things that must always happen

    // Retrieve the sequence number
    let sequence_number = get_sequence_number(&rest_client, owner_address, version).await?;

    // Filter currencies to lookup
    let currencies_to_lookup = if let Some(currencies) = maybe_filter_currencies {
        currencies.into_iter().collect()
    } else {
        server_context.currencies.clone()
    };

    // Regular account, FA and Coin
    if account.is_base_account() {
        balances =
            get_base_balances(&rest_client, owner_address, version, currencies_to_lookup).await?;
    } else if pool_address.is_some() {
        // Lookup the delegation pool, if it's provided in the account information
        // Filter appropriately, must have native coin
        if currencies_to_lookup.contains(&native_coin()) {
            (balances, lockup_expiration) = get_delegation_info(
                &rest_client,
                &account,
                owner_address,
                pool_address.unwrap(),
                version,
            )
            .await?;
        }
    } else {
        // Retrieve staking information (if it applies)
        // Only non-pool addresses, and non base accounts
        //
        // These are special cases around querying the stake amounts
        // Filter appropriately, must have native coin
        if currencies_to_lookup.contains(&native_coin()) {
            (balances, lockup_expiration, maybe_operators) =
                get_staking_info(&rest_client, &account, owner_address, version).await?;
        }
    }

    Ok((
        sequence_number,
        maybe_operators,
        balances,
        lockup_expiration,
    ))
}
```

**File:** crates/aptos-rosetta/src/types/misc.rs (L288-381)
```rust
pub async fn get_stake_balances(
    rest_client: &aptos_rest_client::Client,
    owner_account: &AccountIdentifier,
    pool_address: AccountAddress,
    version: u64,
) -> ApiResult<Option<BalanceResult>> {
    const STAKE_POOL: &str = "0x1::stake::StakePool";

    // Retreive the pool resource
    if let Ok(response) = rest_client
        .get_account_resource_at_version_bcs::<StakePool>(pool_address, STAKE_POOL, version)
        .await
    {
        let stake_pool = response.into_inner();

        // Stake isn't allowed for base accounts
        if owner_account.is_base_account() {
            return Err(ApiError::InvalidInput(Some(
                "Stake pool not supported for base account".to_string(),
            )));
        }

        // If the operator address is different, skip
        if owner_account.is_operator_stake()
            && owner_account.operator_address()? != stake_pool.operator_address
        {
            return Err(ApiError::InvalidInput(Some(
                "Stake pool not for matching operator".to_string(),
            )));
        }

        // Any stake pools that match, retrieve that.
        let mut requested_balance: Option<String> = None;
        let lockup_expiration = stake_pool.locked_until_secs;
        let owner_address = owner_account.account_address()?;
        let operator_address = stake_pool.operator_address;

        let staking_contract_amounts_response = view::<Vec<u64>>(
            rest_client,
            version,
            AccountAddress::ONE,
            ident_str!(STAKING_CONTRACT_MODULE),
            ident_str!("staking_contract_amounts"),
            vec![],
            vec![
                bcs::to_bytes(&owner_address)?,
                bcs::to_bytes(&operator_address)?,
            ],
        )
        .await?;
        let total_active_stake = staking_contract_amounts_response[0];
        let accumulated_rewards = staking_contract_amounts_response[1];
        let commission_amount = staking_contract_amounts_response[2];

        // TODO: I think all of these are off, probably need to recalculate all of them
        // see the get_staking_contract_amounts_internal function in staking_contract.move for more
        // information on why commission is only subtracted from active and total stake
        if owner_account.is_active_stake() {
            // active stake is principal and rewards (including commission) so subtract the commission
            requested_balance = Some((total_active_stake - commission_amount).to_string());
        } else if owner_account.is_pending_active_stake() {
            // pending_active cannot have commission because it is new principal
            requested_balance = Some(stake_pool.pending_active.to_string());
        } else if owner_account.is_inactive_stake() {
            // inactive will not have commission because commission has already been extracted
            requested_balance = Some(stake_pool.inactive.to_string());
        } else if owner_account.is_pending_inactive_stake() {
            // pending_inactive will not have commission because commission has already been extracted
            requested_balance = Some(stake_pool.pending_inactive.to_string());
        } else if owner_account.is_total_stake() {
            // total stake includes commission since it includes active stake, which includes commission
            requested_balance =
                Some((stake_pool.get_total_staked_amount() - commission_amount).to_string());
        } else if owner_account.is_commission() {
            requested_balance = Some(commission_amount.to_string());
        } else if owner_account.is_rewards() {
            requested_balance = Some(accumulated_rewards.to_string());
        }

        if let Some(balance) = requested_balance {
            Ok(Some(BalanceResult {
                balance: Some(Amount {
                    value: balance,
                    currency: native_coin(),
                }),
                lockup_expiration,
            }))
        } else {
            Ok(None)
        }
    } else {
        Ok(None)
    }
}
```

**File:** crates/aptos-rosetta/src/types/misc.rs (L384-435)
```rust
pub async fn get_delegation_stake_balances(
    rest_client: &aptos_rest_client::Client,
    account_identifier: &AccountIdentifier,
    owner_address: AccountAddress,
    pool_address: AccountAddress,
    version: u64,
) -> ApiResult<Option<BalanceResult>> {
    // get requested_balance
    let balances_response = rest_client
        .view(
            &ViewRequest {
                function: DELEGATION_POOL_GET_STAKE_FUNCTION.clone(),
                type_arguments: vec![],
                arguments: vec![
                    serde_json::Value::String(pool_address.to_string()),
                    serde_json::Value::String(owner_address.to_string()),
                ],
            },
            Some(version),
        )
        .await?;

    let requested_balance =
        parse_requested_balance(account_identifier, balances_response.into_inner());

    // get lockup_secs
    let lockup_secs_response = rest_client
        .view(
            &ViewRequest {
                function: STAKE_GET_LOCKUP_SECS_FUNCTION.clone(),
                type_arguments: vec![],
                arguments: vec![serde_json::Value::String(pool_address.to_string())],
            },
            Some(version),
        )
        .await?;
    let lockup_expiration = parse_lockup_expiration(lockup_secs_response.into_inner());

    if let Some(balance) = requested_balance {
        Ok(Some(BalanceResult {
            balance: Some(Amount {
                value: balance,
                currency: native_coin(),
            }),
            lockup_expiration,
        }))
    } else {
        Err(ApiError::InternalError(Some(
            "Unable to construct BalanceResult instance".to_string(),
        )))
    }
}
```

**File:** api/src/runtime.rs (L237-259)
```rust
        // Build routes for the API
        let route = Route::new()
            .at("/", poem::get(root_handler))
            .nest(
                "/v1",
                Route::new()
                    .nest("/", api_service)
                    .at("/spec.json", poem::get(spec_json))
                    .at("/spec.yaml", poem::get(spec_yaml))
                    // TODO: We add this manually outside of the OpenAPI spec for now.
                    // https://github.com/poem-web/poem/issues/364
                    .at(
                        "/set_failpoint",
                        poem::get(set_failpoints::set_failpoint_poem).data(context.clone()),
                    ),
            )
            .with(cors)
            .with_if(config.api.compression_enabled, Compression::new())
            .with(PostSizeLimit::new(size_limit))
            .with(CatchPanic::new().with_handler(panic_handler))
            // NOTE: Make sure to keep this after all the `with` middleware.
            .catch_all_error(convert_error)
            .around(middleware_log);
```

**File:** api/doc/README.md (L26-27)
```markdown
## Limitations
- Rate limiting: 100 requests per minute by default
```

**File:** crates/aptos-rate-limiter/src/rate_limit.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use aptos_infallible::{Mutex, RwLock};
use aptos_logger::debug;
use aptos_metrics_core::HistogramVec;
use std::{cmp::min, collections::HashMap, fmt::Debug, hash::Hash, sync::Arc, time::Instant};
use tokio::time::Duration;

pub type SharedBucket = Arc<Mutex<Bucket>>;

const ONE_SEC: Duration = Duration::from_secs(1);

/// A generic token bucket filter
///
/// # Terms
/// ## Key
/// A `key` is an identifier of the item being rate limited
///
/// ## Token
/// A `token` is the smallest discrete value that we want to rate limit by.  In a situation involving
/// network requests, this may represent a request or a byte.  `Tokens` are the counters for the
/// rate limiting, and when there are no `tokens` left in a `bucket`, the `key` is throttled.
///
/// ## Bucket
/// A `bucket` is the tracker of the number of `tokens`.  It has a `bucket size`, and any additional
/// tokens added to it will "spill" out of the `bucket`.  The `buckets` are filled at an `interval`
/// with a given `fill rate`.
///
/// ## Interval
/// The `interval` at which we refill *all* of the `buckets` in the token bucket filter. Configured
/// across the whole token bucket filter.
///
/// ## Fill Rate
/// The rate at which we fill a `bucket` with tokens. Configured per bucket.
///
/// ## Bucket Size
/// Maximum size of a bucket.  A bucket saturates at this size.  Configured per bucket.
///
/// # Features
/// ## Keys
/// The token bucket takes any key as long as it's hashable.  This should allow it to apply to
/// many applications that need rate limiters.
///
/// ## Bucket sizes and Rates
/// ### Defaults
/// There are defaults for bucket size and fill rate, which will apply to unknown keys.
///
/// ### Refill Interval
/// Buckets are refilled automatically at an interval.  To do this synchronously, it calculates the
```
