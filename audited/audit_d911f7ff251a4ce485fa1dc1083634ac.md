# Audit Report

## Title
Unbounded Channel Memory Exhaustion in Remote Executor Service Leading to Validator Node Crash

## Summary
The `secure/net` networking module uses unbounded crossbeam channels to handle inbound messages from remote peers via gRPC. An attacker with network access to the remote executor service can flood the gRPC endpoint with messages, causing unbounded memory growth in the channel buffer, ultimately leading to memory exhaustion and node crash.

## Finding Description

The vulnerability exists in the remote sharded block executor infrastructure used by Aptos validator nodes. When a node is configured to use remote sharded execution (via `remote_executor_addresses` configuration), it exposes a gRPC endpoint that accepts execution commands and results.

The attack flow proceeds as follows:

1. **Unbounded Channel Creation**: The `NetworkController::create_inbound_channel()` function creates unbounded crossbeam channels for receiving messages. [1](#0-0) 

2. **gRPC Endpoint Exposure**: The `GRPCNetworkMessageServiceServerWrapper` exposes a gRPC endpoint `simple_msg_exchange` that receives `NetworkMessage` requests from remote peers. [2](#0-1) 

3. **No Rate Limiting or Authentication**: The gRPC service has no authentication, authorization, or rate limiting mechanisms. It only enforces a maximum message size (80MB) and timeout. [3](#0-2) 

4. **Blocking Consumer**: The executor service consumes messages from the channel in a blocking loop. When processing blocks (especially complex ones), the consumer is slow. [4](#0-3) 

5. **Message Reception**: The coordinator client blocks on receiving execution commands from the unbounded channel. [5](#0-4) 

6. **Executor Integration**: When remote executor addresses are configured, the validator's executor uses `REMOTE_SHARDED_BLOCK_EXECUTOR` which relies on these unbounded channels. [6](#0-5) 

**Attack Scenario**:
- Attacker identifies a validator node configured with remote sharded execution
- Attacker floods the exposed gRPC endpoint with valid `NetworkMessage` requests
- Messages are queued in the unbounded channel via `handler.send(msg).unwrap()`
- The executor service processes messages slowly (especially during complex block execution)
- Channel buffer grows without bounds as messages accumulate
- Memory exhaustion occurs, triggering OOM killer or node crash

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

- **Validator node slowdowns**: As memory pressure increases, the node experiences performance degradation
- **API crashes**: Eventually leads to node crash due to memory exhaustion
- **Availability impact**: Can take down validator nodes participating in consensus if they use remote sharded execution

While this doesn't directly compromise consensus safety or cause loss of funds, it represents a remote denial-of-service attack against validator infrastructure. The severity is High rather than Critical because:
1. It only affects nodes configured with remote sharded execution (not default)
2. It impacts availability rather than consensus safety or fund security
3. Recovery is possible by restarting the node

However, if multiple validators in a network use this configuration and are simultaneously attacked, it could impact network liveness.

## Likelihood Explanation

**Likelihood: Medium to High** (conditional on deployment configuration)

**Factors increasing likelihood**:
- No authentication or authorization required - attacker only needs network access
- No rate limiting - attacker can send unlimited messages
- Unbounded channels - no backpressure mechanism exists
- Attack is straightforward - simple gRPC message flooding

**Factors decreasing likelihood**:
- Requires validator node to be configured with `remote_executor_addresses`
- Default configuration appears to use local sharded execution
- Network access to executor service may be restricted in production deployments
- Primarily designed for benchmark/testing scenarios

If remote sharded execution is deployed in production with exposed endpoints, exploitation is highly likely. The attack requires minimal sophistication and can be executed with standard gRPC client tools.

## Recommendation

Implement bounded channels with backpressure and add rate limiting:

```rust
// In network_controller/mod.rs, replace unbounded with bounded channels:
pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
    // Use bounded channel with reasonable limit (e.g., 1000 messages)
    let (inbound_sender, inbound_receiver) = bounded(1000);
    
    self.inbound_handler
        .lock()
        .unwrap()
        .register_handler(message_type, inbound_sender);
    
    inbound_receiver
}

// In grpc_network_service/mod.rs, add rate limiting per peer:
use std::collections::HashMap;
use std::time::{Duration, Instant};

struct RateLimiter {
    requests: HashMap<SocketAddr, Vec<Instant>>,
    max_requests_per_window: usize,
    window: Duration,
}

impl RateLimiter {
    fn check_rate_limit(&mut self, addr: SocketAddr) -> bool {
        let now = Instant::now();
        let requests = self.requests.entry(addr).or_insert_with(Vec::new);
        
        // Remove old requests outside the window
        requests.retain(|&time| now.duration_since(time) < self.window);
        
        if requests.len() >= self.max_requests_per_window {
            return false; // Rate limit exceeded
        }
        
        requests.push(now);
        true
    }
}

// In simple_msg_exchange, check rate limit:
async fn simple_msg_exchange(
    &self,
    request: Request<NetworkMessage>,
) -> Result<Response<Empty>, Status> {
    let remote_addr = request.remote_addr()
        .ok_or_else(|| Status::internal("No remote address"))?;
    
    if !self.rate_limiter.lock().unwrap().check_rate_limit(remote_addr) {
        return Err(Status::resource_exhausted("Rate limit exceeded"));
    }
    
    // ... rest of implementation
}
```

Additionally:
1. Add authentication via mutual TLS for remote executor connections
2. Implement connection-level rate limiting at the gRPC server level
3. Add metrics and alerts for channel queue depth
4. Consider using `try_send()` with error handling instead of `send().unwrap()`
5. Document security implications of remote sharded execution in production

## Proof of Concept

```rust
// PoC demonstrating unbounded channel flooding
// Place in secure/net/src/network_controller/mod.rs tests section

#[cfg(test)]
mod channel_flooding_poc {
    use super::*;
    use std::thread;
    use std::time::Duration;
    
    #[test]
    #[ignore] // Ignore by default as it intentionally causes OOM
    fn test_unbounded_channel_flooding() {
        let server_addr = SocketAddr::new(
            IpAddr::V4(Ipv4Addr::LOCALHOST), 
            utils::get_available_port()
        );
        
        let mut network_controller = NetworkController::new(
            "flood_test".to_string(),
            server_addr,
            5000
        );
        
        // Create inbound channel - this is UNBOUNDED
        let receiver = network_controller.create_inbound_channel("test".to_string());
        network_controller.start();
        
        // Simulate slow consumer
        let consumer_handle = thread::spawn(move || {
            loop {
                if let Ok(_msg) = receiver.recv() {
                    // Simulate slow processing (e.g., complex block execution)
                    thread::sleep(Duration::from_millis(100));
                }
            }
        });
        
        // Simulate attacker flooding the endpoint
        let attacker_handle = thread::spawn(move || {
            let rt = Runtime::new().unwrap();
            let mut client = GRPCNetworkMessageServiceClientWrapper::new(&rt, server_addr);
            
            // Flood with messages
            for i in 0..100_000 {
                rt.block_on(async {
                    client.send_message(
                        server_addr,
                        Message::new(vec![0u8; 1024 * 1024]), // 1MB message
                        &MessageType::new("test".to_string()),
                    ).await;
                });
                
                if i % 100 == 0 {
                    println!("Sent {} messages", i);
                }
            }
        });
        
        // Monitor memory usage - will observe unbounded growth
        // In real attack, node would crash with OOM
        
        attacker_handle.join().unwrap();
        // Consumer will be overwhelmed with 100k messages in queue
    }
}
```

## Notes

This vulnerability demonstrates a critical design flaw in using unbounded channels for network message handling. While crossbeam channels are efficient, using them without bounds in a network-facing context creates a trivial DoS vector. The vulnerability is conditionally exploitable based on deployment configuration, but when present, represents a serious availability risk for validator nodes.

The fix requires implementing proper resource management through bounded channels, backpressure mechanisms, and rate limiting at multiple layers (connection, peer, and message type levels).

### Citations

**File:** secure/net/src/network_controller/mod.rs (L128-137)
```rust
    pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
        let (inbound_sender, inbound_receiver) = unbounded();

        self.inbound_handler
            .lock()
            .unwrap()
            .register_handler(message_type, inbound_sender);

        inbound_receiver
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L23-23)
```rust
const MAX_MESSAGE_SIZE: usize = 1024 * 1024 * 80;
```

**File:** secure/net/src/grpc_network_service/mod.rs (L93-115)
```rust
    async fn simple_msg_exchange(
        &self,
        request: Request<NetworkMessage>,
    ) -> Result<Response<Empty>, Status> {
        let _timer = NETWORK_HANDLER_TIMER
            .with_label_values(&[&self.self_addr.to_string(), "inbound_msgs"])
            .start_timer();
        let remote_addr = request.remote_addr();
        let network_message = request.into_inner();
        let msg = Message::new(network_message.message);
        let message_type = MessageType::new(network_message.message_type);

        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L215-260)
```rust
    pub fn start(&self) {
        trace!(
            "Shard starting, shard_id={}, num_shards={}.",
            self.shard_id,
            self.num_shards
        );
        let mut num_txns = 0;
        loop {
            let command = self.coordinator_client.receive_execute_command();
            match command {
                ExecutorShardCommand::ExecuteSubBlocks(
                    state_view,
                    transactions,
                    concurrency_level_per_shard,
                    onchain_config,
                ) => {
                    num_txns += transactions.num_txns();
                    trace!(
                        "Shard {} received ExecuteBlock command of block size {} ",
                        self.shard_id,
                        num_txns
                    );
                    let exe_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "execute_block"]);
                    let ret = self.execute_block(
                        transactions,
                        state_view.as_ref(),
                        BlockExecutorConfig {
                            local: BlockExecutorLocalConfig::default_with_concurrency_level(
                                concurrency_level_per_shard,
                            ),
                            onchain: onchain_config,
                        },
                    );
                    drop(state_view);
                    drop(exe_timer);

                    let _result_tx_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "result_tx"]);
                    self.coordinator_client.send_execution_result(ret);
                },
                ExecutorShardCommand::Stop => {
                    break;
                },
            }
        }
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L80-113)
```rust
    fn receive_execute_command(&self) -> ExecutorShardCommand<RemoteStateViewClient> {
        match self.command_rx.recv() {
            Ok(message) => {
                let _rx_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx"])
                    .start_timer();
                let bcs_deser_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx_bcs_deser"])
                    .start_timer();
                let request: RemoteExecutionRequest = bcs::from_bytes(&message.data).unwrap();
                drop(bcs_deser_timer);

                match request {
                    RemoteExecutionRequest::ExecuteBlock(command) => {
                        let init_prefetch_timer = REMOTE_EXECUTOR_TIMER
                            .with_label_values(&[&self.shard_id.to_string(), "init_prefetch"])
                            .start_timer();
                        let state_keys = Self::extract_state_keys(&command);
                        self.state_view_client.init_for_block(state_keys);
                        drop(init_prefetch_timer);

                        let (sub_blocks, concurrency, onchain_config) = command.into();
                        ExecutorShardCommand::ExecuteSubBlocks(
                            self.state_view_client.clone(),
                            sub_blocks,
                            concurrency,
                            onchain_config,
                        )
                    },
                }
            },
            Err(_) => ExecutorShardCommand::Stop,
        }
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L256-276)
```rust
    fn execute_block_sharded<V: VMBlockExecutor>(
        partitioned_txns: PartitionedTransactions,
        state_view: Arc<CachedStateView>,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>> {
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        } else {
            Ok(V::execute_block_sharded(
                &SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        }
    }
```
