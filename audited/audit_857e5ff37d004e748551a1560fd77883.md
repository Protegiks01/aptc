# Audit Report

## Title
OnDiskStorage Silent Failure: Validators Operate with Inaccessible Storage Causing Unexpected Consensus Participation Failures

## Summary
The `OnDiskStorage::available()` function returns `Ok(())` without verifying actual file access, allowing validators to start and appear healthy even when storage is inaccessible. This causes silent consensus participation failures when validators attempt to sign votes, as storage read/write operations fail at runtime rather than during initialization. [1](#0-0) 

## Finding Description

The `KVStorage` trait defines `available()` as a health check that "Returns an error if the backend service is not online and available." [2](#0-1) 

During validator initialization, the safety rules manager calls `available()` and panics if storage is unavailable, ensuring validators don't start with inaccessible storage: [3](#0-2) 

However, `OnDiskStorage::available()` always returns `Ok(())` without checking whether the file can be opened, read from, or written to. This violates the contract that `available()` should verify backend availability.

During consensus participation, when a validator needs to vote on a proposal, it must:
1. Read safety data from storage to check voting rules
2. Sign the vote
3. Write updated safety data back to storage [4](#0-3) [5](#0-4) 

These operations call `OnDiskStorage::read()` and `OnDiskStorage::write()` which perform actual file I/O: [6](#0-5) 

If the storage file becomes inaccessible after initialization (due to permission changes, disk full, filesystem mounted read-only, or file deletion), these operations fail, causing vote construction to error. The error propagates through the consensus flow and is logged, but the validator continues running: [7](#0-6) 

**Attack Scenarios:**

1. **File Permission Changes**: Operator accidentally changes permissions on the storage file after validator starts
2. **Disk Full**: Disk fills up, preventing writes to storage
3. **Read-Only Filesystem**: Filesystem remounted read-only for maintenance or disaster recovery
4. **File Deletion**: Storage file accidentally deleted during operations
5. **Network Mount Failure**: If storage is on a network mount that becomes unavailable

In contrast, `VaultStorage::available()` properly validates backend availability by checking if Vault is unsealed: [8](#0-7) 

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria because it causes state inconsistencies requiring intervention:

- Validators silently fail to participate in consensus without clear indication
- Reduces effective validator set size, potentially impacting network liveness
- Operators cannot distinguish storage access failures from normal consensus validation errors in metrics
- No automatic recovery mechanism or health check to detect the condition after startup

The issue does not reach High or Critical severity because:
- It does not cause consensus safety violations or loss of funds
- It does not enable unauthorized actions by external attackers
- It requires operational failures (file permissions, disk space) to manifest
- The validator continues running and can recover if storage becomes accessible again

## Likelihood Explanation

**Likelihood: Medium**

This issue is moderately likely to occur in production environments:

- **Common in operational scenarios**: File permission errors, disk full conditions, and filesystem issues are common operational problems
- **Silent failure**: The validator appears healthy at startup even when storage will fail at runtime
- **No preventive checks**: No periodic health checks verify storage accessibility after initialization
- **Production environments**: More likely in production where multiple operators manage infrastructure, automated scripts modify permissions, or disk space is constrained

However, it requires external triggering conditions rather than being directly exploitable by network-level attackers.

## Recommendation

Implement proper storage accessibility checks in `OnDiskStorage::available()`:

```rust
fn available(&self) -> Result<(), Error> {
    // Verify file can be opened for reading
    File::open(&self.file_path)
        .map_err(|e| Error::InternalError(format!("Cannot open storage file for reading: {}", e)))?;
    
    // Verify parent directory is writable (for atomic writes via temp file)
    let parent_dir = self.file_path.parent()
        .ok_or_else(|| Error::InternalError("Storage file has no parent directory".into()))?;
    
    if !parent_dir.exists() {
        return Err(Error::InternalError(format!("Parent directory {:?} does not exist", parent_dir)));
    }
    
    // Check write permissions by attempting to create a temp file
    let test_path = parent_dir.join(".storage_health_check");
    File::create(&test_path)
        .and_then(|_| fs::remove_file(&test_path))
        .map_err(|e| Error::InternalError(format!("Cannot write to storage directory: {}", e)))?;
    
    Ok(())
}
```

**Additional Recommendations:**

1. **Periodic Health Checks**: Add periodic calls to `available()` during validator operation to detect storage issues before they cause signing failures
2. **Metrics Segregation**: Add specific metrics counters for storage access failures vs. consensus validation errors
3. **Alerting**: Emit high-priority alerts when storage operations fail
4. **Documentation**: Clearly document storage requirements and failure modes for operators

## Proof of Concept

```rust
// PoC demonstrating the vulnerability
// File: consensus/safety-rules/src/tests/storage_failure_test.rs

use aptos_secure_storage::{OnDiskStorage, KVStorage};
use aptos_temppath::TempPath;
use std::fs;

#[test]
fn test_available_does_not_detect_inaccessible_storage() {
    // Create storage file
    let temp_path = TempPath::new();
    temp_path.create_as_file().unwrap();
    let storage = OnDiskStorage::new(temp_path.path().to_path_buf());
    
    // available() returns Ok even though file exists
    assert!(storage.available().is_ok());
    
    // Make file unreadable (Unix only)
    #[cfg(unix)]
    {
        use std::os::unix::fs::PermissionsExt;
        let mut perms = fs::metadata(temp_path.path()).unwrap().permissions();
        perms.set_mode(0o000);
        fs::set_permissions(temp_path.path(), perms).unwrap();
        
        // available() still returns Ok - THIS IS THE BUG
        assert!(storage.available().is_ok());
        
        // But actual read fails
        let result: Result<_, _> = storage.get::<String>("test_key");
        assert!(result.is_err()); // Storage is actually inaccessible
    }
}

#[test]
fn test_disk_full_not_detected_by_available() {
    let temp_path = TempPath::new();
    temp_path.create_as_file().unwrap();
    let mut storage = OnDiskStorage::new(temp_path.path().to_path_buf());
    
    // available() returns Ok
    assert!(storage.available().is_ok());
    
    // If disk becomes full after this, writes will fail but available() won't detect it
    // In production, this means validator starts successfully but fails when signing
}
```

**Notes:**

This vulnerability represents a violation of the reliability guarantees expected from secure storage backends. While `VaultStorage` properly implements health checks, `OnDiskStorage` does not, creating operational blind spots where validators appear healthy but cannot fulfill their consensus duties. The issue is particularly insidious because it passes the initialization check but fails silently at runtime when critical consensus operations require storage access.

### Citations

**File:** secure/storage/src/on_disk.rs (L53-70)
```rust
    fn read(&self) -> Result<HashMap<String, Value>, Error> {
        let mut file = File::open(&self.file_path)?;
        let mut contents = String::new();
        file.read_to_string(&mut contents)?;
        if contents.is_empty() {
            return Ok(HashMap::new());
        }
        let data = serde_json::from_str(&contents)?;
        Ok(data)
    }

    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** secure/storage/src/on_disk.rs (L74-76)
```rust
    fn available(&self) -> Result<(), Error> {
        Ok(())
    }
```

**File:** secure/storage/src/kv_storage.rs (L14-15)
```rust
    /// Returns an error if the backend service is not online and available.
    fn available(&self) -> Result<(), Error>;
```

**File:** consensus/safety-rules/src/safety_rules_manager.rs (L21-26)
```rust
pub fn storage(config: &SafetyRulesConfig) -> PersistentSafetyStorage {
    let backend = &config.backend;
    let internal_storage: Storage = backend.into();
    if let Err(error) = internal_storage.available() {
        panic!("Storage is not available: {:?}", error);
    }
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L66-66)
```rust
        let mut safety_data = self.persistent_storage.safety_data()?;
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L92-92)
```rust
        self.persistent_storage.set_safety_data(safety_data)?;
```

**File:** consensus/src/round_manager.rs (L2136-2142)
```rust
                        match result {
                            Ok(_) => trace!(RoundStateLogSchema::new(round_state)),
                            Err(e) => {
                                counters::ERROR_COUNT.inc();
                                warn!(kind = error_kind(&e), RoundStateLogSchema::new(round_state), "Error: {:#}", e);
                            }
                        }
```

**File:** secure/storage/src/vault.rs (L147-153)
```rust
    fn available(&self) -> Result<(), Error> {
        if !self.client().unsealed()? {
            Err(Error::InternalError("Vault is not unsealed".into()))
        } else {
            Ok(())
        }
    }
```
