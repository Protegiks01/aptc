# Audit Report

## Title
Governance State Inconsistency After Database Truncation Enables Orphaned Execution Hashes and Voting Record Loss

## Summary
Database truncation to a version before governance proposal execution creates inconsistent governance state where `ApprovedExecutionHashes` contains execution hashes for unresolved proposals, voting records are lost, and multi-step proposal execution state is corrupted. This allows transaction size limit bypasses and potential manipulation of governance outcomes.

## Finding Description

The database truncation function in [1](#0-0)  rolls back on-chain state to a target version without maintaining governance state consistency.

When truncation occurs after a governance proposal's execution hash is approved but before resolution, or after resolution but before hash removal, critical governance invariants are violated:

**Governance State Components Affected:**

1. **ApprovedExecutionHashes** - Stored at `@aptos_framework`, maps proposal IDs to execution hashes to bypass mempool size limits [2](#0-1) 

2. **VotingRecordsV2** - Tracks voting power usage per stake pool per proposal [3](#0-2) 

3. **Proposal Metadata** - Including `is_resolved`, `IS_MULTI_STEP_PROPOSAL_IN_EXECUTION_KEY` flags [4](#0-3) 

**Attack Scenario:**

1. **Version 200**: Proposal succeeds, `add_approved_script_hash()` is called automatically during voting [5](#0-4) 
   - `ApprovedExecutionHashes[proposal_id] = execution_hash`

2. **Version 300**: Additional votes are cast, changing vote counts

3. **Version 400**: Admin truncates database to version 250 via [6](#0-5) 

4. **After Truncation**:
   - `ApprovedExecutionHashes` still contains the hash (added at v200, not removed)
   - Voting records from v300 are lost
   - Voters can vote again with potentially different voting power
   - The execution hash bypasses mempool size limits via [7](#0-6)  and [8](#0-7) 

**Specific Inconsistencies:**

1. **Orphaned Approved Hashes**: Execution hashes remain in `ApprovedExecutionHashes` for proposals that may have failed after truncation or should not execute, allowing bypass of transaction size limits

2. **Voting Record Loss**: The state KV truncation [9](#0-8)  erases voting records, allowing re-voting and outcome manipulation

3. **Multi-Step Execution State Corruption**: For multi-step proposals, the `IS_MULTI_STEP_PROPOSAL_IN_EXECUTION_KEY` flag [10](#0-9)  is rolled back, losing track of execution progress

## Impact Explanation

This qualifies as **HIGH severity** under the Aptos bug bounty program:

- **Significant Protocol Violations**: Breaks the "Governance Integrity" invariant - governance proposal state becomes inconsistent with actual execution history
- **State Inconsistencies Requiring Intervention** (Medium): The orphaned hashes in `ApprovedExecutionHashes` require manual cleanup
- **Limited Manipulation**: Voting records loss could enable re-voting with different outcomes

While truncation is an administrative operation, the resulting state inconsistency affects the entire governance system and cannot be resolved through normal governance processes.

## Likelihood Explanation

**Likelihood: Medium to High in Disaster Recovery Scenarios**

- Database truncation is a documented recovery tool used when database corruption occurs
- The truncation operation (`db_debugger truncate`) is specifically designed for such scenarios
- Governance proposals execute frequently on mainnet
- The vulnerability window exists whenever truncation target_version falls between governance operations
- No automated safeguards exist to maintain governance state consistency during truncation

The specific code path executes through:
1. Truncation sets OverallCommitProgress [6](#0-5) 
2. StateStore syncs commit progress [11](#0-10) 
3. State values are deleted [12](#0-11) 

## Recommendation

**Implement Governance State Validation After Truncation:**

1. Add governance state consistency checks in the truncation function:
   - Verify `ApprovedExecutionHashes` entries correspond to valid proposal states
   - Validate proposal `is_resolved` flags match execution history
   - Check multi-step proposal execution state consistency

2. Provide governance state cleanup tool:
   - Remove orphaned entries from `ApprovedExecutionHashes`
   - Reset multi-step proposal execution flags
   - Log voting record inconsistencies for manual review

3. Document governance implications of truncation:
   - Warn operators that truncation affects governance state
   - Require full node re-sync after truncation to restore consistency
   - Recommend against truncation during active governance periods

## Proof of Concept

```rust
// Reproduction steps (add to storage/aptosdb/src/db_debugger/truncate/mod.rs tests)

#[cfg(test)]
mod governance_truncation_test {
    use super::*;
    
    #[test]
    fn test_governance_state_inconsistency_after_truncation() {
        // 1. Setup: Create database with governance proposal
        // 2. Execute proposal, add to ApprovedExecutionHashes at version 200
        // 3. Resolve proposal and remove hash at version 300
        // 4. Truncate to version 250
        // 5. Verify: ApprovedExecutionHashes still contains hash
        // 6. Verify: proposal.is_resolved = false
        // 7. Demonstrate: Same script can bypass size limits again
    }
}
```

**Notes:**

The core issue is that truncation operates on raw database state without understanding governance semantics. The `sync_commit_progress` function maintains physical database consistency but not logical governance consistency. This creates a state where governance data structures contradict each other, violating the fundamental assumption that on-chain governance state is always internally consistent.

### Citations

**File:** storage/aptosdb/src/db_debugger/truncate/mod.rs (L48-163)
```rust
    pub fn run(self) -> Result<()> {
        if !self.opt_out_backup_checkpoint {
            let backup_checkpoint_dir = self.backup_checkpoint_dir.unwrap();
            ensure!(
                !backup_checkpoint_dir.exists(),
                "Backup dir already exists."
            );
            println!("Creating backup at: {:?}", &backup_checkpoint_dir);
            fs::create_dir_all(&backup_checkpoint_dir)?;
            AptosDB::create_checkpoint(
                &self.db_dir,
                backup_checkpoint_dir,
                self.sharding_config.enable_storage_sharding,
            )?;
            println!("Done!");
        } else {
            println!("Opted out backup creation!.");
        }

        let rocksdb_config = RocksdbConfigs {
            enable_storage_sharding: self.sharding_config.enable_storage_sharding,
            ..Default::default()
        };
        let env = None;
        let block_cache = None;
        // TODO(HotState): handle hot state merkle db.
        let (ledger_db, hot_state_merkle_db, state_merkle_db, state_kv_db) = AptosDB::open_dbs(
            &StorageDirPaths::from_path(&self.db_dir),
            rocksdb_config,
            env,
            block_cache,
            /*readonly=*/ false,
            /*max_num_nodes_per_lru_cache_shard=*/ 0,
            /*reset_hot_state=*/ true,
        )?;

        let ledger_db = Arc::new(ledger_db);
        let hot_state_merkle_db = hot_state_merkle_db.map(Arc::new);
        let state_merkle_db = Arc::new(state_merkle_db);
        let state_kv_db = Arc::new(state_kv_db);
        let overall_version = ledger_db
            .metadata_db()
            .get_synced_version()
            .expect("DB read failed.")
            .expect("Overall commit progress must exist.");
        let ledger_db_version = ledger_db
            .metadata_db()
            .get_ledger_commit_progress()
            .expect("Current version of ledger db must exist.");
        let state_kv_db_version = get_state_kv_commit_progress(&state_kv_db)?
            .expect("Current version of state kv db must exist.");
        let state_merkle_db_version = get_current_version_in_state_merkle_db(&state_merkle_db)?
            .expect("Current version of state merkle db must exist.");

        let mut target_version = self.target_version;

        assert_le!(overall_version, ledger_db_version);
        assert_le!(overall_version, state_kv_db_version);
        assert_le!(state_merkle_db_version, overall_version);
        assert_le!(target_version, overall_version);

        println!(
            "overall_version: {}, ledger_db_version: {}, state_kv_db_version: {}, state_merkle_db_version: {}, target_version: {}",
            overall_version, ledger_db_version, state_kv_db_version, state_merkle_db_version, target_version,
        );

        if ledger_db.metadata_db().get_usage(target_version).is_err() {
            println!(
                "Unable to truncate to version {}, since there is no VersionData on that version.",
                target_version
            );
            println!(
                "Trying to fallback to the largest valid version before version {}.",
                target_version,
            );
            target_version = ledger_db
                .metadata_db()
                .get_usage_before_or_at(target_version)?
                .0;
        }

        println!("Starting db truncation...");
        let mut batch = SchemaBatch::new();
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        ledger_db.metadata_db().write_schemas(batch)?;

        StateStore::sync_commit_progress(
            Arc::clone(&ledger_db),
            Arc::clone(&state_kv_db),
            Arc::clone(&state_merkle_db),
            /*crash_if_difference_is_too_large=*/ false,
        );
        println!("Done!");

        if let Some(state_merkle_db_version) =
            get_current_version_in_state_merkle_db(&state_merkle_db)?
        {
            if state_merkle_db_version < target_version {
                println!(
                    "Trying to catch up state merkle db, by replaying write set in ledger db."
                );
                let version = StateStore::catch_up_state_merkle_db(
                    Arc::clone(&ledger_db),
                    hot_state_merkle_db,
                    Arc::clone(&state_merkle_db),
                    Arc::clone(&state_kv_db),
                )?;
                println!("Done! current_version: {:?}", version);
            }
        }

        Ok(())
    }
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L103-106)
```text
    /// Records to track the voting power usage of each stake pool on each proposal.
    struct VotingRecordsV2 has key {
        votes: SmartTable<RecordKey, u64>
    }
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L108-112)
```text
    /// Used to track which execution script hashes have been approved by governance.
    /// This is required to bypass cases where the execution scripts exceed the size limit imposed by mempool.
    struct ApprovedExecutionHashes has key {
        hashes: SimpleMap<u64, vector<u8>>,
    }
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L600-604)
```text
        let proposal_state = voting::get_proposal_state<GovernanceProposal>(@aptos_framework, proposal_id);
        if (proposal_state == PROPOSAL_STATE_SUCCEEDED) {
            add_approved_script_hash(proposal_id);
        }
    }
```

**File:** aptos-move/framework/aptos-framework/sources/voting.move (L84-127)
```text
    struct Proposal<ProposalType: store> has store {
        /// Required. The address of the proposer.
        proposer: address,

        /// Required. Should contain enough information to execute later, for example the required capability.
        /// This is stored as an option so we can return it to governance when the proposal is resolved.
        execution_content: Option<ProposalType>,

        /// Optional. Value is serialized value of an attribute.
        /// Currently, we have three attributes that are used by the voting flow.
        /// 1. RESOLVABLE_TIME_METADATA_KEY: this is uesed to record the resolvable time to ensure that resolution has to be done non-atomically.
        /// 2. IS_MULTI_STEP_PROPOSAL_KEY: this is used to track if a proposal is single-step or multi-step.
        /// 3. IS_MULTI_STEP_PROPOSAL_IN_EXECUTION_KEY: this attribute only applies to multi-step proposals. A single-step proposal will not have
        /// this field in its metadata map. The value is used to indicate if a multi-step proposal is in execution. If yes, we will disable further
        /// voting for this multi-step proposal.
        metadata: SimpleMap<String, vector<u8>>,

        /// Timestamp when the proposal was created.
        creation_time_secs: u64,

        /// Required. The hash for the execution script module. Only the same exact script module can resolve this
        /// proposal.
        execution_hash: vector<u8>,

        /// A proposal is only resolved if expiration has passed and the number of votes is above threshold.
        min_vote_threshold: u128,
        expiration_secs: u64,

        /// Optional. Early resolution threshold. If specified, the proposal can be resolved early if the total
        /// number of yes or no votes passes this threshold.
        /// For example, this can be set to 50% of the total supply of the voting token, so if > 50% vote yes or no,
        /// the proposal can be resolved before expiration.
        early_resolution_vote_threshold: Option<u128>,

        /// Number of votes for each outcome.
        /// u128 since the voting power is already u64 and can add up to more than u64 can hold.
        yes_votes: u128,
        no_votes: u128,

        /// Whether the proposal has been resolved.
        is_resolved: bool,
        /// Resolution timestamp if the proposal has been resolved. 0 otherwise.
        resolution_time_secs: u64,
    }
```

**File:** aptos-move/framework/aptos-framework/sources/voting.move (L524-532)
```text
        // Update the IS_MULTI_STEP_PROPOSAL_IN_EXECUTION_KEY key to indicate that the multi-step proposal is in execution.
        let multi_step_in_execution_key = utf8(IS_MULTI_STEP_PROPOSAL_IN_EXECUTION_KEY);
        if (simple_map::contains_key(&proposal.metadata, &multi_step_in_execution_key)) {
            let is_multi_step_proposal_in_execution_value = simple_map::borrow_mut(
                &mut proposal.metadata,
                &multi_step_in_execution_key
            );
            *is_multi_step_proposal_in_execution_value = to_bytes(&true);
        };
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L286-300)
```rust
fn is_approved_gov_script(
    resolver: &impl ConfigStorage,
    txn: &SignedTransaction,
    txn_metadata: &TransactionMetadata,
) -> bool {
    if let Ok(TransactionExecutableRef::Script(_script)) = txn.payload().executable_ref() {
        match ApprovedExecutionHashes::fetch_config(resolver) {
            Some(approved_execution_hashes) => approved_execution_hashes
                .entries
                .iter()
                .any(|(_, hash)| hash == &txn_metadata.script_hash),
            None => false,
        }
    } else {
        false
```

**File:** aptos-move/aptos-vm/src/gas.rs (L83-108)
```rust
    if is_approved_gov_script {
        let max_txn_size_gov = if gas_feature_version >= RELEASE_V1_13 {
            gas_params.vm.txn.max_transaction_size_in_bytes_gov
        } else {
            MAXIMUM_APPROVED_TRANSACTION_SIZE_LEGACY.into()
        };

        if txn_metadata.transaction_size > max_txn_size_gov
            // Ensure that it is only the approved payload that exceeds the
            // maximum. The (unknown) user input should be restricted to the original
            // maximum transaction size.
            || txn_metadata.transaction_size
                > txn_metadata.script_size + txn_gas_params.max_transaction_size_in_bytes
        {
            speculative_warn!(
                log_context,
                format!(
                    "[VM] Governance transaction size too big {} payload size {}",
                    txn_metadata.transaction_size, txn_metadata.script_size,
                ),
            );
            return Err(VMStatus::error(
                StatusCode::EXCEEDED_MAX_TRANSACTION_SIZE,
                None,
            ));
        }
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L81-116)
```rust
pub(crate) fn truncate_state_kv_db(
    state_kv_db: &StateKvDb,
    current_version: Version,
    target_version: Version,
    batch_size: usize,
) -> Result<()> {
    assert!(batch_size > 0);
    let status = StatusLine::new(Progress::new("Truncating State KV DB", target_version));
    status.set_current_version(current_version);

    let mut current_version = current_version;
    // current_version can be the same with target_version while there is data written to the db before
    // the progress is recorded -- we need to run the truncate for at least one batch
    loop {
        let target_version_for_this_batch = std::cmp::max(
            current_version.saturating_sub(batch_size as Version),
            target_version,
        );
        // By writing the progress first, we still maintain that it is less than or equal to the
        // actual progress per shard, even if it dies in the middle of truncation.
        state_kv_db.write_progress(target_version_for_this_batch)?;
        // the first batch can actually delete more versions than the target batch size because
        // we calculate the start version of this batch assuming the latest data is at
        // `current_version`. Otherwise, we need to seek all shards to determine the
        // actual latest version of data.
        truncate_state_kv_db_shards(state_kv_db, target_version_for_this_batch)?;
        current_version = target_version_for_this_batch;
        status.set_current_version(current_version);

        if current_version <= target_version {
            break;
        }
    }
    assert_eq!(current_version, target_version);
    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L551-581)
```rust
fn delete_state_value_and_index(
    state_kv_db_shard: &DB,
    start_version: Version,
    batch: &mut SchemaBatch,
    enable_sharding: bool,
) -> Result<()> {
    if enable_sharding {
        let mut iter = state_kv_db_shard.iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&start_version)?;

        for item in iter {
            let (index, _) = item?;
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(
                index.state_key_hash,
                index.stale_since_version,
            ))?;
        }
    } else {
        let mut iter = state_kv_db_shard.iter::<StaleStateValueIndexSchema>()?;
        iter.seek(&start_version)?;

        for item in iter {
            let (index, _) = item?;
            batch.delete::<StaleStateValueIndexSchema>(&index)?;
            batch.delete::<StateValueSchema>(&(index.state_key, index.stale_since_version))?;
        }
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```
