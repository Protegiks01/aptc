# Audit Report

## Title
Consensus Observer Permanently Stuck in Fallback Mode Due to Missing State Cleanup on Task Failure

## Summary
The consensus observer's fallback sync mechanism fails to clean up its internal state when the sync task is aborted or fails, causing the observer to remain permanently stuck in fallback mode and unable to make progress. This results in a complete loss of liveness for the affected node.

## Finding Description

The vulnerability exists in the `sync_for_fallback()` function where the fallback sync handle is set **before** the async task completes, but is only cleared **after** the task successfully sends a completion notification. [1](#0-0) 

The critical flow is:

1. **Line 186**: `fallback_sync_handle` is set to `Some(DropGuard::new(abort_handle))` immediately when `sync_for_fallback()` is called
2. **Lines 150-161**: An async task calls `execution_client.sync_for_duration(fallback_duration).await`
3. **Lines 156-160**: If sync fails, the task returns early WITHOUT clearing the handle or sending a notification
4. **Lines 163-173**: If the task is aborted after sync succeeds but before sending the notification, the notification is never sent

In both failure scenarios, the `fallback_sync_handle` remains set, causing `in_fallback_mode()` to permanently return `true`. [2](#0-1) 

The observer's progress check mechanism then becomes permanently blocked: [3](#0-2) 

Since `in_fallback_mode()` returns `true`, the observer returns early without checking actual progress or attempting recovery. The handle is only cleared when `process_fallback_sync_notification()` is called, which requires receiving the `FallbackSyncCompleted` notification: [4](#0-3) 

But if the notification was never sent due to task failure or abortion, this cleanup never occurs, creating a permanent deadlock.

## Impact Explanation

**Severity: CRITICAL** - Total loss of liveness/network availability

This vulnerability causes a **complete and permanent loss of liveness** for the affected consensus observer node, meeting the Critical severity criteria per the Aptos bug bounty program. Once the observer enters this stuck state:

- The node cannot process any new blocks or consensus messages
- The node cannot synchronize state or make forward progress  
- The node cannot recover without manual intervention or restart
- The observer effectively becomes non-functional for the remainder of the epoch

This breaks the fundamental liveness invariant that consensus observer nodes must be able to make continuous forward progress. While consensus observers are not validators, they are critical infrastructure for light clients, wallets, and indexing services that rely on them for block data.

## Likelihood Explanation

**Likelihood: HIGH**

This issue can occur whenever:

1. **State sync failures**: Network partitions, database errors, or peer unavailability cause `sync_for_duration()` to return an error
2. **Task abortion**: The DropGuard is dropped if `sync_for_fallback()` is called again (e.g., due to race conditions or logic errors)
3. **Runtime shutdown**: Graceful shutdown sequences may abort tasks mid-execution

State sync failures are common in distributed blockchain systems due to network instability, peer churn, and database I/O issues. The error case (lines 156-160) is particularly realistic and can be triggered by any transient network or storage issue during the fallback sync operation.

## Recommendation

The `sync_for_fallback()` function must ensure cleanup occurs even when the task fails or is aborted. This can be achieved by using a guard pattern or moving the handle assignment inside the async task:

**Option 1: Cleanup on all exit paths**
```rust
pub fn sync_for_fallback(&mut self) {
    // ... existing logging and metrics ...
    
    let consensus_observer_config = self.consensus_observer_config;
    let execution_client = self.execution_client.clone();
    let sync_notification_sender = self.state_sync_notification_sender.clone();
    
    let (abort_handle, abort_registration) = AbortHandle::new_pair();
    tokio::spawn(Abortable::new(
        async move {
            metrics::set_gauge_with_label(...);
            
            let fallback_duration = Duration::from_millis(...);
            
            let latest_synced_ledger_info = match execution_client
                .clone()
                .sync_for_duration(fallback_duration)
                .await
            {
                Ok(latest_synced_ledger_info) => latest_synced_ledger_info,
                Err(error) => {
                    error!(...);
                    // Send a notification even on failure to trigger cleanup
                    // OR: Clear metrics here before returning
                    metrics::set_gauge_with_label(..., 0);
                    return;
                },
            };
            
            // Send notification
            let state_sync_notification =
                StateSyncNotification::fallback_sync_completed(latest_synced_ledger_info);
            let _ = sync_notification_sender.send(state_sync_notification);
            
            // Clear metrics
            metrics::set_gauge_with_label(..., 0);
        },
        abort_registration,
    ));
    
    self.fallback_sync_handle = Some(DropGuard::new(abort_handle));
}
```

**Option 2: Add timeout and recovery mechanism in check_progress()**
```rust
async fn check_progress(&mut self) {
    if self.state_sync_manager.in_fallback_mode() {
        // Check if fallback has been running too long
        if self.fallback_started_at.elapsed() > MAX_FALLBACK_DURATION {
            warn!("Fallback sync timeout - forcing cleanup");
            self.state_sync_manager.clear_active_fallback_sync();
            return;
        }
        
        info!("Waiting for state sync to complete fallback syncing");
        return;
    }
    // ... rest of progress checks ...
}
```

**Option 3: Ensure notification is always sent (recommended)**
```rust
// In the async task, use a guard to ensure cleanup
let cleanup_guard = scopeguard::guard((), |_| {
    metrics::set_gauge_with_label(..., 0);
    // Send a failure notification if not already sent
    let _ = sync_notification_sender.send(
        StateSyncNotification::fallback_sync_completed(
            execution_client.get_latest_ledger_info()
        )
    );
});

// ... rest of task logic ...

std::mem::forget(cleanup_guard); // Prevent double-send on success
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_fallback_sync_failure_leaves_observer_stuck() {
    use consensus::consensus_observer::observer::state_sync_manager::*;
    use consensus::pipeline::execution_client::DummyExecutionClient;
    use aptos_config::config::ConsensusObserverConfig;
    
    // Create state sync manager
    let consensus_observer_config = ConsensusObserverConfig::default();
    let (state_sync_notification_sender, mut state_sync_notification_receiver) = 
        tokio::sync::mpsc::unbounded_channel();
    
    // Create a failing execution client
    struct FailingExecutionClient;
    #[async_trait::async_trait]
    impl TExecutionClient for FailingExecutionClient {
        async fn sync_for_duration(&self, _: Duration) -> Result<LedgerInfoWithSignatures> {
            Err(anyhow::anyhow!("Simulated sync failure"))
        }
        // ... other required methods ...
    }
    
    let mut state_sync_manager = StateSyncManager::new(
        consensus_observer_config,
        Arc::new(FailingExecutionClient),
        state_sync_notification_sender,
    );
    
    // Verify initial state - not in fallback mode
    assert!(!state_sync_manager.in_fallback_mode());
    
    // Call sync_for_fallback - this will spawn a task that fails
    state_sync_manager.sync_for_fallback();
    
    // Immediately after calling, the handle is set
    assert!(state_sync_manager.in_fallback_mode());
    
    // Wait for the task to fail
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Try to receive notification - should timeout because task failed and didn't send
    let notification_result = tokio::time::timeout(
        Duration::from_millis(100),
        state_sync_notification_receiver.recv()
    ).await;
    assert!(notification_result.is_err(), "No notification should be sent on failure");
    
    // BUG: Observer is still stuck in fallback mode!
    assert!(state_sync_manager.in_fallback_mode(), 
        "VULNERABILITY: Observer remains in fallback mode after task failure");
    
    // The observer cannot recover without manual intervention
    // Subsequent calls to check_progress() will return early forever
}
```

## Notes

This vulnerability demonstrates a critical state management failure where the internal state (`fallback_sync_handle`) diverges from the actual operational state (no task running). The root cause is that state modification (setting the handle) occurs outside the async task's lifecycle, while state cleanup (clearing the handle) depends on the task's successful completion. This creates an asymmetry that leads to permanent state corruption on any failure path.

The issue affects **all** consensus observer nodes and can be triggered by common failure scenarios like network partitions or database errors, making it both high-impact and high-likelihood.

### Citations

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L100-103)
```rust
    /// Returns true iff state sync is currently executing in fallback mode
    pub fn in_fallback_mode(&self) -> bool {
        self.fallback_sync_handle.is_some()
    }
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L135-187)
```rust
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(
            async move {
                // Update the state sync metrics now that we're syncing for the fallback
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    1, // We're syncing for the fallback
                );

                // Get the fallback duration
                let fallback_duration =
                    Duration::from_millis(consensus_observer_config.observer_fallback_duration_ms);

                // Sync for the fallback duration
                let latest_synced_ledger_info = match execution_client
                    .clone()
                    .sync_for_duration(fallback_duration)
                    .await
                {
                    Ok(latest_synced_ledger_info) => latest_synced_ledger_info,
                    Err(error) => {
                        error!(LogSchema::new(LogEntry::ConsensusObserver)
                            .message(&format!("Failed to sync for fallback! Error: {:?}", error)));
                        return;
                    },
                };

                // Notify consensus observer that we've synced for the fallback
                let state_sync_notification =
                    StateSyncNotification::fallback_sync_completed(latest_synced_ledger_info);
                if let Err(error) = sync_notification_sender.send(state_sync_notification) {
                    error!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to send state sync notification for fallback! Error: {:?}",
                            error
                        ))
                    );
                }

                // Clear the state sync metrics now that we're done syncing
                metrics::set_gauge_with_label(
                    &metrics::OBSERVER_STATE_SYNC_EXECUTING,
                    metrics::STATE_SYNCING_FOR_FALLBACK,
                    0, // We're no longer syncing for the fallback
                );
            },
            abort_registration,
        ));

        // Save the sync task handle
        self.fallback_sync_handle = Some(DropGuard::new(abort_handle));
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L172-177)
```rust
        // If we've fallen back to state sync, we should wait for it to complete
        if self.state_sync_manager.in_fallback_mode() {
            info!(LogSchema::new(LogEntry::ConsensusObserver)
                .message("Waiting for state sync to complete fallback syncing!",));
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L963-964)
```rust
        // Reset the state sync manager for the synced fallback
        self.state_sync_manager.clear_active_fallback_sync();
```
