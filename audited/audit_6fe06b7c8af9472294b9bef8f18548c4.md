# Audit Report

## Title
Request Starvation in Dynamic Prefetching Causes State Sync Deadlock

## Summary
The dynamic prefetching mechanism in the data streaming service can cause complete request starvation where no new data requests are sent, preventing forward progress in state synchronization. When `max_concurrent_requests` reaches its minimum value (3) and all in-flight requests are failing/retrying, the system cannot send requests for new data ranges, causing the node to fall behind the network indefinitely.

## Finding Description

The vulnerability exists in the interaction between dynamic prefetching limits and request tracking in the data streaming service. The issue manifests when:

1. **Dynamic prefetching decreases to minimum**: After repeated request failures/timeouts, the dynamic prefetching state decreases `max_concurrent_requests` to the configured minimum value of 3. [1](#0-0) 

2. **Request slot calculation prevents new requests**: In `create_and_send_client_requests`, the number of available slots is calculated as `max_in_flight_requests - num_in_flight_requests`. [2](#0-1) 

3. **Starvation occurs**: When we have 3 requests in-flight (including retries) and `max_in_flight_requests = 3`, the calculation yields `remaining_in_flight_slots = 0`, preventing any new requests from being created. [3](#0-2) 

4. **Failed responses are not counted as complete**: The system only counts successful responses as "complete", meaning failed/timed-out requests remain in the in-flight count even after they receive error responses. [4](#0-3) 

5. **Request tracking advances prematurely**: When requests are created, `next_request_version` is immediately updated to point to the next data range, even before the requests succeed. [5](#0-4) 

This creates a deadlock scenario:
- The stream has requested versions 0-2999 (3 requests)
- All 3 requests timeout and are retried
- `next_request_version = 3000` (already advanced)
- But `remaining_in_flight_slots = 0` prevents creating requests for versions 3000+
- The stream is stuck retrying the same failed version ranges indefinitely
- No forward progress can be made until the retries succeed or max_request_retry is exceeded

**Attack scenario**: A malicious or slow peer can intentionally delay responses just below the timeout threshold, causing repeated failures that drive `max_concurrent_requests` to minimum. Once at minimum with 3 in-flight requests, no new requests can be sent, and the node cannot sync new data.

## Impact Explanation

This vulnerability has **Medium severity** impact per the Aptos bug bounty program criteria:

- **State inconsistencies requiring intervention**: Affected nodes fall behind the network and cannot sync new state, requiring manual intervention to restart the stream or adjust configuration
- **Validator node slowdowns**: Validators using this state sync mechanism will be unable to participate effectively in consensus
- **Liveness degradation**: While not complete network failure, individual nodes lose liveness in state synchronization

The impact is limited to Medium (not High/Critical) because:
- Only affects individual nodes, not the entire network
- No funds are at risk
- No consensus safety violations (only liveness)
- Recovery is possible by restarting the stream (hits max_request_retry limit)

However, in a scenario where multiple nodes are affected simultaneously (e.g., network-wide congestion or coordinated attack on multiple nodes), this could significantly degrade network performance.

## Likelihood Explanation

The likelihood of this vulnerability being triggered is **Medium to High**:

**Factors increasing likelihood:**
- Natural network conditions (congestion, packet loss) can trigger the failure path
- No malicious intent required - normal network issues can cause this
- The minimum prefetching value of 3 is quite low, easily reached after a few failures
- The decreasing step (2) is larger than the increasing step (1), making it easier to reach minimum [6](#0-5) 

**Factors decreasing likelihood:**
- Requires sustained failures to decrease prefetching to minimum
- The timeout mechanism eventually allows progress (though degraded)
- Stream terminates after max_request_retry (5) failures, forcing restart

**Attacker requirements:**
- Control over one or more network peers
- Ability to cause request delays/timeouts
- No privileged access required

## Recommendation

The vulnerability should be fixed by modifying the request slot calculation to account for failed/retried requests differently:

**Option 1**: Don't count retried failed requests against the in-flight limit
- When a request fails and is retried, mark it as a retry
- Exclude retries from `num_in_flight_requests` calculation
- This allows new requests even while retrying failed ones

**Option 2**: Implement a minimum guaranteed slot allocation
- Always reserve at least 1 slot for new requests, even when at minimum concurrency
- Modify the slot calculation to ensure `remaining_in_flight_slots >= 1` when `num_in_flight_requests < max_pending_requests`

**Option 3**: Prevent premature advancement of request tracking
- Don't update `next_request_version` until requests succeed
- Roll back request tracking on failures
- This ensures failed requests can be recreated as "new" requests

**Recommended fix** (Option 2 - minimal change):

```rust
// In create_and_send_client_requests, modify the logic to guarantee at least one slot:
fn create_and_send_client_requests(
    &mut self,
    global_data_summary: &GlobalDataSummary,
) -> Result<(), Error> {
    let num_pending_requests = self.get_num_pending_data_requests()?;
    let num_complete_pending_requests = self.get_num_complete_pending_requests()?;
    let num_in_flight_requests =
        num_pending_requests.saturating_sub(num_complete_pending_requests);

    let max_pending_requests = self.streaming_service_config.max_pending_requests;
    let max_num_requests_to_send = max_pending_requests.saturating_sub(num_pending_requests);

    if max_num_requests_to_send > 0 {
        let max_in_flight_requests = self
            .dynamic_prefetching_state
            .get_max_concurrent_requests(&self.stream_engine);

        // FIX: Ensure at least one slot is always available for new requests
        // when we haven't reached max_pending_requests
        let effective_max_in_flight = if num_in_flight_requests >= max_in_flight_requests 
            && max_num_requests_to_send > 0 {
            num_in_flight_requests + 1  // Allow one more request for forward progress
        } else {
            max_in_flight_requests
        };

        let client_requests = self.stream_engine.create_data_client_requests(
            max_num_requests_to_send,
            effective_max_in_flight,  // Use adjusted limit
            num_in_flight_requests,
            global_data_summary,
            self.notification_id_generator.clone(),
        )?;
        
        // ... rest of the function
    }
    Ok(())
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_starvation {
    use super::*;
    use crate::tests::utils::MockAptosDataClient;
    use aptos_channels::message_queues::QueueStyle;
    use aptos_config::config::{DataStreamingServiceConfig, DynamicPrefetchingConfig};
    
    #[tokio::test]
    async fn test_request_starvation_at_minimum_concurrency() {
        // Configure with minimum prefetching value of 3
        let dynamic_prefetching_config = DynamicPrefetchingConfig {
            enable_dynamic_prefetching: true,
            initial_prefetching_value: 3,
            min_prefetching_value: 3,
            max_prefetching_value: 10,
            prefetching_value_increase: 1,
            prefetching_value_decrease: 2,
            ..Default::default()
        };
        
        let mut streaming_config = DataStreamingServiceConfig::default();
        streaming_config.dynamic_prefetching = dynamic_prefetching_config;
        streaming_config.max_pending_requests = 50;
        
        // Create a mock data client that always returns timeouts
        let data_client_config = AptosDataClientConfig::default();
        let aptos_data_client = MockAptosDataClient::new(
            data_client_config, 
            false,  // Return timeouts
            false, 
            false, 
            false
        );
        
        // Create stream
        let stream_request = StreamRequest::GetAllTransactions(...);
        let (stream_update_notifier, _) = aptos_channel::new(QueueStyle::LIFO, 1, None);
        
        let (mut data_stream, _) = DataStream::new(
            data_client_config,
            streaming_config,
            1,
            &stream_request,
            stream_update_notifier,
            aptos_data_client,
            Arc::new(U64IdGenerator::new()),
            &AdvertisedData::empty(),
            TimeService::mock(),
        ).unwrap();
        
        // Initialize and send first batch of requests
        let global_data_summary = GlobalDataSummary::empty();
        data_stream.initialize_data_requests(global_data_summary.clone()).unwrap();
        
        // Simulate all 3 requests timing out
        for _ in 0..3 {
            data_stream.process_data_responses(global_data_summary.clone()).await.unwrap();
        }
        
        // At this point:
        // - max_concurrent_requests should be at minimum (3)
        // - We should have 3 in-flight requests (all retries)
        // - next_request_version is advanced
        
        // Try to create new requests
        let (sent_requests, _) = data_stream.get_sent_requests_and_notifications();
        let initial_count = sent_requests.as_ref().unwrap().len();
        
        data_stream.create_and_send_client_requests(&global_data_summary).unwrap();
        
        let final_count = sent_requests.as_ref().unwrap().len();
        
        // VULNERABILITY: No new requests should be created (starvation)
        // final_count == initial_count means no progress
        assert_eq!(final_count, initial_count, 
            "Request starvation: no new requests created despite having more data to fetch");
    }
}
```

**Notes:**
- The vulnerability requires dynamic prefetching to be enabled (default is true)
- Minimum concurrency of 3 is the default configuration
- Natural network conditions or malicious peers can trigger this scenario
- The issue affects state synchronization liveness but not consensus safety

### Citations

**File:** config/src/config/state_sync_config.rs (L319-319)
```rust
            min_prefetching_value: 3,
```

**File:** config/src/config/state_sync_config.rs (L320-321)
```rust
            prefetching_value_increase: 1,
            prefetching_value_decrease: 2,
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L283-294)
```rust
            let max_in_flight_requests = self
                .dynamic_prefetching_state
                .get_max_concurrent_requests(&self.stream_engine);

            // Create the client requests
            let client_requests = self.stream_engine.create_data_client_requests(
                max_num_requests_to_send,
                max_in_flight_requests,
                num_in_flight_requests,
                global_data_summary,
                self.notification_id_generator.clone(),
            )?;
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L881-892)
```rust
    fn get_num_complete_pending_requests(&mut self) -> Result<u64, Error> {
        let mut num_complete_pending_requests = 0;
        for sent_data_request in self.get_sent_data_requests()? {
            if let Some(client_response) = sent_data_request.lock().client_response.as_ref() {
                if client_response.is_ok() {
                    // Only count successful responses as complete. Failures will be retried
                    num_complete_pending_requests += 1;
                }
            }
        }
        Ok(num_complete_pending_requests)
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1747-1751)
```rust
    fn update_request_version(&mut self, request_end_version: Version) -> Result<(), Error> {
        self.next_request_version = request_end_version
            .checked_add(1)
            .ok_or_else(|| Error::IntegerOverflow("Next request version has overflown!".into()))?;
        Ok(())
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2036-2046)
```rust
fn calculate_num_requests_to_send(
    max_number_of_requests: u64,
    max_in_flight_requests: u64,
    num_in_flight_requests: u64,
) -> u64 {
    // Calculate the number of remaining in-flight request slots
    let remaining_in_flight_slots = max_in_flight_requests.saturating_sub(num_in_flight_requests);

    // Bound the number of requests to send by the maximum
    min(remaining_in_flight_slots, max_number_of_requests)
}
```
