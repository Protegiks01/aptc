# Audit Report

## Title
Missing Validation for connectivity_check_interval_ms Enables Node DoS and Liveness Failures

## Summary
The `connectivity_check_interval_ms` parameter in NetworkConfig lacks any bounds validation, allowing values of zero (causing immediate node crash), extremely small values (causing resource exhaustion), or extremely large values (causing network partition and liveness failures).

## Finding Description

The `connectivity_check_interval_ms` configuration parameter controls how frequently the ConnectivityManager performs critical network maintenance operations. This parameter is accepted without any validation and converted directly to a Duration. [1](#0-0) 

The parameter flows through the network builder: [2](#0-1) 

And is converted to a Duration without bounds checking: [3](#0-2) 

This Duration is then used to create an interval timer: [4](#0-3) 

The interval creation has only one guard - it panics if the period is zero: [5](#0-4) 

**Attack Scenario 1: Zero Value (Immediate Crash)**
Setting `connectivity_check_interval_ms: 0` causes the node to panic during startup with the message "period must be non-zero", resulting in immediate denial of service.

**Attack Scenario 2: Very Small Values (Resource Exhaustion)**
Setting `connectivity_check_interval_ms: 1` (1 millisecond) causes `check_connectivity()` to execute 1000 times per second. This function performs resource-intensive operations: [6](#0-5) 

Including spawning TCP connection attempts for latency pinging: [7](#0-6) [8](#0-7) 

This leads to excessive CPU usage, network traffic, and potential node slowdown or crash.

**Attack Scenario 3: Very Large Values (Liveness Failure)**
Setting `connectivity_check_interval_ms: 18446744073709551615` (u64::MAX, approximately 584 million years) effectively disables connectivity checks. The node will:
- Never detect or disconnect stale connections
- Never dial new eligible peers  
- Fail to maintain network connectivity
- Experience effective network partition

The config sanitizer performs no validation on this parameter: [9](#0-8) 

## Impact Explanation

This issue qualifies as **Medium Severity** per Aptos bug bounty criteria, potentially reaching **High Severity** depending on the attack scenario:

**High Severity** indicators present:
- **Validator node slowdowns**: Small interval values (1-100ms) cause excessive resource consumption, directly matching the "Validator node slowdowns" category
- **Significant protocol violations**: Large interval values prevent the node from maintaining proper network connectivity, violating availability guarantees

**Medium Severity** indicators present:  
- **State inconsistencies requiring intervention**: Nodes with disrupted connectivity may fall out of sync, requiring manual intervention

The zero-value crash scenario represents immediate availability loss. The small-value scenario causes resource exhaustion affecting validator performance. The large-value scenario causes network partition and consensus participation failure.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability is highly likely to manifest through:

1. **Accidental Misconfiguration** (High): Operator typos (e.g., missing a digit, adding extra zeros) during manual config editing
2. **Config Template Errors** (Medium): Incorrect default values in deployment scripts or configuration management tools  
3. **Insider Threat** (Low-Medium): Malicious operator with config file access intentionally setting malicious values

The default value is 5000ms, but during node deployment or reconfiguration, operators frequently modify networking parameters. With no validation, any typo immediately causes harm.

## Recommendation

Add bounds validation to the config sanitizer for all network timing parameters:

```rust
// In config/src/config/config_sanitizer.rs

const MIN_CONNECTIVITY_CHECK_INTERVAL_MS: u64 = 1000;  // 1 second minimum
const MAX_CONNECTIVITY_CHECK_INTERVAL_MS: u64 = 300_000; // 5 minutes maximum

fn sanitize_network_timing_configs(
    node_config: &NodeConfig,
    _node_type: NodeType,
    _chain_id: Option<ChainId>,
) -> Result<(), Error> {
    let sanitizer_name = "NetworkTimingConfigSanitizer";
    
    // Validate validator network timing
    if let Some(validator_network) = &node_config.validator_network {
        if validator_network.connectivity_check_interval_ms < MIN_CONNECTIVITY_CHECK_INTERVAL_MS {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_string(),
                format!(
                    "connectivity_check_interval_ms ({}) must be >= {}ms",
                    validator_network.connectivity_check_interval_ms,
                    MIN_CONNECTIVITY_CHECK_INTERVAL_MS
                ),
            ));
        }
        if validator_network.connectivity_check_interval_ms > MAX_CONNECTIVITY_CHECK_INTERVAL_MS {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_string(),
                format!(
                    "connectivity_check_interval_ms ({}) must be <= {}ms",
                    validator_network.connectivity_check_interval_ms,
                    MAX_CONNECTIVITY_CHECK_INTERVAL_MS
                ),
            ));
        }
    }
    
    // Validate fullnode network timing
    for fullnode_network in &node_config.full_node_networks {
        if fullnode_network.connectivity_check_interval_ms < MIN_CONNECTIVITY_CHECK_INTERVAL_MS {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_string(),
                format!(
                    "connectivity_check_interval_ms ({}) must be >= {}ms",
                    fullnode_network.connectivity_check_interval_ms,
                    MIN_CONNECTIVITY_CHECK_INTERVAL_MS
                ),
            ));
        }
        if fullnode_network.connectivity_check_interval_ms > MAX_CONNECTIVITY_CHECK_INTERVAL_MS {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_string(),
                format!(
                    "connectivity_check_interval_ms ({}) must be <= {}ms",
                    fullnode_network.connectivity_check_interval_ms,
                    MAX_CONNECTIVITY_CHECK_INTERVAL_MS
                ),
            ));
        }
    }
    
    Ok(())
}
```

Call this validation in `NodeConfig::sanitize()` alongside other sanitizers.

## Proof of Concept

**PoC 1: Zero Value Crash**
```yaml
# validator_config.yaml
validator_network:
  connectivity_check_interval_ms: 0
  # ... other config
```

Starting a node with this config will panic with:
```
thread 'main' panicked at 'assertion failed: period > ZERO_DURATION'
```

**PoC 2: Resource Exhaustion**  
```yaml
validator_network:
  connectivity_check_interval_ms: 1
```

Monitor node with `top` - CPU usage will spike to 100% with continuous connectivity check iterations.

**PoC 3: Liveness Failure**
```yaml  
validator_network:
  connectivity_check_interval_ms: 18446744073709551615
```

The node starts but never performs connectivity checks. Use network monitoring to observe that stale connections are never closed and new peers are never dialed, even after epoch changes or validator set updates.

**Notes**

While this vulnerability requires configuration file access (node operator privilege), it represents a significant defense-in-depth weakness. The lack of validation enables:
- Accidental misconfigurations causing production outages
- Simplified attack paths for compromised operator accounts  
- No safety net against human error during critical operations

Similar timing parameters (`ping_interval_ms`, `ping_timeout_ms`) also lack validation and should be addressed comprehensively.

### Citations

**File:** config/src/config/network_config.rs (L41-41)
```rust
pub const CONNECTIVITY_CHECK_INTERVAL_MS: u64 = 5000;
```

**File:** network/builder/src/builder.rs (L209-219)
```rust
        network_builder.add_connectivity_manager(
            seeds,
            peers_and_metadata,
            config.max_outbound_connections,
            config.connection_backoff_base,
            config.max_connection_delay_ms,
            config.connectivity_check_interval_ms,
            config.network_channel_size,
            config.mutual_authentication,
            config.enable_latency_aware_dialing,
        );
```

**File:** network/framework/src/connectivity_manager/builder.rs (L54-54)
```rust
                Duration::from_millis(connectivity_check_interval_ms),
```

**File:** network/framework/src/connectivity_manager/mod.rs (L415-415)
```rust
        let ticker = self.time_service.interval(self.connectivity_check_interval);
```

**File:** network/framework/src/connectivity_manager/mod.rs (L633-633)
```rust
            self.ping_eligible_peers(eligible_peers.clone()).await;
```

**File:** network/framework/src/connectivity_manager/mod.rs (L807-836)
```rust
    async fn check_connectivity<'a>(
        &'a mut self,
        pending_dials: &'a mut FuturesUnordered<BoxFuture<'static, PeerId>>,
    ) {
        trace!(
            NetworkSchema::new(&self.network_context),
            "{} Checking connectivity",
            self.network_context
        );

        // Log the eligible peers with addresses from discovery
        sample!(SampleRate::Duration(Duration::from_secs(60)), {
            info!(
                NetworkSchema::new(&self.network_context),
                discovered_peers = ?self.discovered_peers,
                "Active discovered peers"
            )
        });

        // Cancel dials to peers that are no longer eligible.
        self.cancel_stale_dials().await;
        // Disconnect from connected peers that are no longer eligible.
        self.close_stale_connections().await;
        // Dial peers which are eligible but are neither connected nor queued for dialing in the
        // future.
        self.dial_eligible_peers(pending_dials).await;

        // Update the metrics for any peer ping latencies
        self.update_ping_latency_metrics();
    }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L1159-1198)
```rust
    tokio::task::spawn_blocking(move || {
        // Extract the socket addresses from the network address
        let socket_addresses = match network_address.to_socket_addrs() {
            Ok(socket_addresses) => socket_addresses.collect::<Vec<_>>(),
            Err(error) => {
                warn!(
                    NetworkSchema::new(&network_context),
                    "Failed to resolve network address {:?}: {}", network_address, error
                );
                return;
            },
        };

        // If no socket addresses were found, log an error and return
        if socket_addresses.is_empty() {
            warn!(
                NetworkSchema::new(&network_context),
                "Peer {} does not have any socket addresses for network address {:?}!",
                peer_id.short_str(),
                network_address,
            );
            return;
        }

        // Limit the number of socket addresses we'll try to connect to
        let socket_addresses = socket_addresses
            .iter()
            .take(MAX_SOCKET_ADDRESSES_TO_PING)
            .collect::<Vec<_>>();

        // Attempt to connect to the socket addresses over TCP and time the connection
        for socket_address in socket_addresses {
            // Start the ping timer
            let start_time = Instant::now();

            // Attempt to connect to the socket address
            if let Ok(tcp_stream) = TcpStream::connect_timeout(
                socket_address,
                Duration::from_secs(MAX_CONNECTION_TIMEOUT_SECS),
            ) {
```

**File:** crates/aptos-time-service/src/interval.rs (L31-31)
```rust
        assert!(period > ZERO_DURATION, "`period` must be non-zero.");
```

**File:** config/src/config/config_sanitizer.rs (L39-70)
```rust
impl ConfigSanitizer for NodeConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // If config sanitization is disabled, don't do anything!
        if node_config.node_startup.skip_config_sanitizer {
            return Ok(());
        }

        // Sanitize all of the sub-configs
        AdminServiceConfig::sanitize(node_config, node_type, chain_id)?;
        ApiConfig::sanitize(node_config, node_type, chain_id)?;
        BaseConfig::sanitize(node_config, node_type, chain_id)?;
        ConsensusConfig::sanitize(node_config, node_type, chain_id)?;
        DagConsensusConfig::sanitize(node_config, node_type, chain_id)?;
        ExecutionConfig::sanitize(node_config, node_type, chain_id)?;
        sanitize_failpoints_config(node_config, node_type, chain_id)?;
        sanitize_fullnode_network_configs(node_config, node_type, chain_id)?;
        IndexerGrpcConfig::sanitize(node_config, node_type, chain_id)?;
        InspectionServiceConfig::sanitize(node_config, node_type, chain_id)?;
        LoggerConfig::sanitize(node_config, node_type, chain_id)?;
        MempoolConfig::sanitize(node_config, node_type, chain_id)?;
        NetbenchConfig::sanitize(node_config, node_type, chain_id)?;
        StateSyncConfig::sanitize(node_config, node_type, chain_id)?;
        StorageConfig::sanitize(node_config, node_type, chain_id)?;
        InternalIndexerDBConfig::sanitize(node_config, node_type, chain_id)?;
        sanitize_validator_network_config(node_config, node_type, chain_id)?;

        Ok(()) // All configs passed validation
    }
```
