# Audit Report

## Title
Timing Side-Channel Leaks Transaction Output Metadata via Output Reduction Count in Legacy Storage Service Implementation

## Summary
The storage service's legacy implementation of `get_transactions_or_outputs_with_proof_by_size_legacy()` performs a variable number of database calls based on the client-controlled `max_num_output_reductions` parameter and the actual size of transaction outputs. This creates an observable timing side-channel that allows external attackers to infer transaction complexity and output sizes without accessing the actual transaction data.

## Finding Description

The vulnerability exists in the legacy chunking implementation used when `enable_size_and_time_aware_chunking` is disabled (default on Mainnet). [1](#0-0) [2](#0-1) [3](#0-2) 

The handler function receives requests with client-controlled parameters: [4](#0-3) [5](#0-4) 

The legacy implementation performs iterative database queries: [6](#0-5) 

**Attack Vector:**
1. Attacker sends `GetTransactionsOrOutputsWithProof` requests for the same transaction range with varying `max_num_output_reductions` values (0, 1, 5, 10, etc.)
2. The loop iterates `num_output_reductions <= max_num_output_reductions` times, making a database call each iteration
3. Each database call to `self.storage.get_transaction_outputs()` takes measurable time
4. The number of actual iterations depends on whether outputs overflow the network frame size
5. Attacker measures response times from their perspective
6. Statistical analysis reveals how many reduction iterations occurred, inferring transaction output sizes

**Information Leaked:**
- Whether transaction outputs are large or small
- Relative complexity of transactions in a range
- Output size patterns that could correlate with transaction types (simple transfers vs. complex smart contract executions)

**Access Control Context:**
The storage service operates on public networks with `AuthenticationMode::MaybeMutual`, allowing unauthenticated peers to connect and send requests. [7](#0-6) 

## Impact Explanation

This qualifies as **Low Severity** per Aptos bug bounty criteria:
- **Category**: Minor information leak
- **No funds loss**: Transaction data remains secure
- **No consensus impact**: Does not affect validator agreement
- **No availability impact**: Does not cause node slowdowns beyond normal request processing
- **Limited information**: Only metadata about output sizes is leaked; actual transaction contents remain confidential
- **Public data**: Transaction data is already publicly accessible on-chain; only timing patterns provide additional metadata

The leaked information has minimal security value since:
1. Transaction contents are public anyway
2. Only relative size information is leaked, not content
3. Requires statistical analysis across multiple requests
4. Does not enable any further attacks on funds, consensus, or state

## Likelihood Explanation

**High likelihood of exploitation:**
- **Low skill requirement**: Simple timing measurements
- **No special access needed**: Any peer can send requests on public networks
- **Easy to execute**: Send requests with different parameters and measure response times
- **Difficult to detect**: Appears as legitimate data synchronization traffic
- **Network observable**: Client can measure round-trip times

**Limiting factors:**
- Network jitter may obscure timing differences
- Requires multiple requests for statistical significance
- Limited actionable value of leaked information
- Only affects Mainnet (testnets use new implementation without vulnerability)

## Recommendation

**Immediate Fix:** Enable size and time-aware chunking on Mainnet to use the new implementation that eliminates iterative database calls.

Modify the configuration optimizer to enable the feature on all networks: [3](#0-2) 

Change line 624 from:
```rust
&& !chain_id.is_mainnet()
```
to:
```rust
// Enable on all networks including Mainnet
```

**Alternative Fix:** Add constant-time behavior to the legacy implementation by always performing the maximum number of iterations regardless of whether data fits, then selecting the appropriate response. However, this adds unnecessary latency.

**Long-term Fix:** Deprecate the legacy implementation entirely once size and time-aware chunking is stable.

## Proof of Concept

```rust
// Timing attack PoC (conceptual - would need network setup to execute)
use std::time::Instant;

#[test]
fn test_timing_side_channel_attack() {
    // Setup: Create storage service and mock database with known transaction outputs
    // of varying sizes
    
    let peer_network_id = PeerNetworkId::random();
    let start_version = 1000;
    let end_version = 1010;
    
    // Attack: Send requests with different max_num_output_reductions
    let mut timings = vec![];
    
    for max_reductions in [0, 1, 2, 5, 10] {
        let request = StorageServiceRequest::new(
            DataRequest::GetTransactionsOrOutputsWithProof(
                TransactionsOrOutputsWithProofRequest {
                    proof_version: end_version,
                    start_version,
                    end_version,
                    include_events: false,
                    max_num_output_reductions: max_reductions,
                }
            ),
            false,
        );
        
        let start = Instant::now();
        let _response = handler.process_request(&peer_network_id, request, false);
        let duration = start.elapsed();
        
        timings.push((max_reductions, duration));
    }
    
    // Analysis: Observe timing differences
    // If outputs are large and require multiple reductions:
    // - max_reductions=0: Fast (1 DB call + fallback)
    // - max_reductions=5: Slower (multiple DB calls before fallback)
    // If outputs fit without reduction:
    // - All requests have similar timing (1 DB call)
    
    // Statistical analysis reveals transaction output characteristics
    for (max_red, duration) in timings {
        println!("max_reductions={}: {:?}", max_red, duration);
    }
}
```

## Notes

This vulnerability **only affects Mainnet** where the legacy implementation is still enabled by default. Testnets and development networks already use the new size and time-aware chunking implementation that eliminates this timing side-channel by performing at most one attempt to fetch outputs before falling back to transactions.

The new implementation avoids the vulnerability because it does not use `max_num_output_reductions` in an iterative loop: [8](#0-7) 

While this is a valid timing side-channel, the practical security impact is minimal since transaction data is public and only metadata about output sizes can be inferred.

### Citations

**File:** config/src/config/state_sync_config.rs (L14-14)
```rust
const ENABLE_SIZE_AND_TIME_AWARE_CHUNKING: bool = true;
```

**File:** config/src/config/state_sync_config.rs (L198-198)
```rust
            enable_size_and_time_aware_chunking: false,
```

**File:** config/src/config/state_sync_config.rs (L620-630)
```rust
        // Potentially enable size and time-aware chunking for all networks except Mainnet
        let mut modified_config = false;
        if let Some(chain_id) = chain_id {
            if ENABLE_SIZE_AND_TIME_AWARE_CHUNKING
                && !chain_id.is_mainnet()
                && local_storage_config_yaml["enable_size_and_time_aware_chunking"].is_null()
            {
                storage_service_config.enable_size_and_time_aware_chunking = true;
                modified_config = true;
            }
        }
```

**File:** state-sync/storage-service/types/src/requests.rs (L382-388)
```rust
pub struct TransactionsOrOutputsWithProofRequest {
    pub proof_version: u64,   // The version the proof should be relative to
    pub start_version: u64,   // The starting version of the transaction/output list
    pub end_version: u64,     // The ending version of the transaction/output list (inclusive)
    pub include_events: bool, // Whether or not to include events (if transactions are returned)
    pub max_num_output_reductions: u64, // The max num of output reductions before transactions are returned
}
```

**File:** state-sync/storage-service/server/src/handler.rs (L547-567)
```rust
    fn get_transactions_or_outputs_with_proof(
        &self,
        request: &TransactionsOrOutputsWithProofRequest,
    ) -> aptos_storage_service_types::Result<DataResponse, Error> {
        let response = self.storage.get_transactions_or_outputs_with_proof(
            request.proof_version,
            request.start_version,
            request.end_version,
            request.include_events,
            request.max_num_output_reductions,
        )?;

        Ok(DataResponse::TransactionsOrOutputsWithProof((
            response
                .transaction_list_with_proof
                .map(|t| t.consume_transaction_list_with_proof()),
            response
                .transaction_output_list_with_proof
                .map(|t| t.consume_output_list_with_proof()),
        )))
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L787-841)
```rust
    fn get_transactions_or_outputs_with_proof_by_size(
        &self,
        proof_version: u64,
        start_version: u64,
        end_version: u64,
        include_events: bool,
        max_num_output_reductions: u64,
        max_response_size: u64,
        use_size_and_time_aware_chunking: bool,
    ) -> Result<TransactionDataWithProofResponse, Error> {
        // Calculate the number of transaction outputs to fetch
        let expected_num_outputs = inclusive_range_len(start_version, end_version)?;
        let max_num_outputs = self.config.max_transaction_output_chunk_size;
        let num_outputs_to_fetch = min(expected_num_outputs, max_num_outputs);

        // If size and time-aware chunking are disabled, use the legacy implementation
        if !use_size_and_time_aware_chunking {
            return self.get_transactions_or_outputs_with_proof_by_size_legacy(
                proof_version,
                start_version,
                end_version,
                num_outputs_to_fetch,
                include_events,
                max_num_output_reductions,
                max_response_size,
            );
        }

        // Fetch the transaction outputs with proof
        let response = self.get_transaction_outputs_with_proof_by_size(
            proof_version,
            start_version,
            end_version,
            max_response_size,
            true, // This is a transaction or output request
            use_size_and_time_aware_chunking,
        )?;

        // If the request was fully satisfied (all items were fetched), return the response
        if let Some(output_list_with_proof) = response.transaction_output_list_with_proof.as_ref() {
            if num_outputs_to_fetch == output_list_with_proof.get_num_outputs() as u64 {
                return Ok(response);
            }
        }

        // Otherwise, return as many transactions as possible
        self.get_transactions_with_proof_by_size(
            proof_version,
            start_version,
            end_version,
            include_events,
            max_response_size,
            use_size_and_time_aware_chunking,
        )
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L845-897)
```rust
    fn get_transactions_or_outputs_with_proof_by_size_legacy(
        &self,
        proof_version: u64,
        start_version: u64,
        end_version: u64,
        mut num_outputs_to_fetch: u64,
        include_events: bool,
        max_num_output_reductions: u64,
        max_response_size: u64,
    ) -> Result<TransactionDataWithProofResponse, Error> {
        let mut num_output_reductions = 0;
        while num_output_reductions <= max_num_output_reductions {
            let output_list_with_proof = self.storage.get_transaction_outputs(
                start_version,
                num_outputs_to_fetch,
                proof_version,
            )?;
            let response = TransactionDataWithProofResponse {
                transaction_data_response_type: TransactionDataResponseType::TransactionOutputData,
                transaction_list_with_proof: None,
                transaction_output_list_with_proof: Some(output_list_with_proof),
            };

            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&response, max_response_size)?;

            if !overflow_frame {
                return Ok(response);
            } else if num_outputs_to_fetch == 1 {
                break; // We cannot return less than a single item. Fallback to transactions
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::TransactionDataWithProof(response).get_label(),
                );
                let new_num_outputs_to_fetch = num_outputs_to_fetch / 2;
                debug!("The request for {:?} outputs was too large (num bytes: {:?}, limit: {:?}). Current number of data reductions: {:?}",
                    num_outputs_to_fetch, num_bytes, max_response_size, num_output_reductions);
                num_outputs_to_fetch = new_num_outputs_to_fetch; // Try again with half the amount of data
                num_output_reductions += 1;
            }
        }

        // Return transactions only
        self.get_transactions_with_proof_by_size(
            proof_version,
            start_version,
            end_version,
            include_events,
            max_response_size,
            self.config.enable_size_and_time_aware_chunking,
        )
    }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L1-1)
```rust
// Copyright (c) Aptos Foundation
```
