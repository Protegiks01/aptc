# Audit Report

## Title
Batch Notification Race Condition Causes False Payload Unavailability and Consensus Performance Degradation

## Summary
The `BatchCoordinator::persist_and_send_digests` function extracts batch metadata before persistence and unconditionally sends all batches to ProofManager, including those that subsequently fail to persist. This causes ProofManager to reference non-existent batches, leading to false payload unavailability errors, incorrect validator blame, and consensus performance degradation.

## Finding Description

In the batch persistence flow, there is a critical ordering issue where batch notifications are sent to ProofManager before verifying successful persistence: [1](#0-0) 

The `batches` variable is created from ALL `persist_requests` before any persistence occurs. Subsequently, the actual persistence is attempted: [2](#0-1) 

However, the `persist()` method only returns successfully persisted batches: [3](#0-2) 

Persistence can fail when batches expire or quota limits are exceeded: [4](#0-3) 

Despite persistence failures, ALL batches (including failed ones) are sent to ProofManager: [5](#0-4) 

When ProofManager includes these non-persisted batches in optimistic proposals, payload availability checks fail because the batches don't exist in batch_store: [6](#0-5) 

The `exists()` check fails for non-persisted batches, causing validators to mark batch authors as unavailable and timeout with `PayloadUnavailable`: [7](#0-6) 

**Attack Scenario:**
1. Attacker sends batches with expirations near the current certified timestamp
2. Validators receive batches and queue them for persistence
3. Between batch metadata extraction (line 92-100) and persistence (line 103), certified_time advances
4. Batches become expired (`expiration <= last_certified_time`)
5. Persistence fails but batches are sent to ProofManager anyway
6. ProofManager includes these batches in optimistic proposals
7. Other validators' availability checks fail
8. Batch authors are incorrectly blamed as having missing payloads
9. Consensus timeouts occur with `PayloadUnavailable` reason
10. Network-wide consensus performance degrades

## Impact Explanation

This is a **High Severity** vulnerability based on Aptos bug bounty criteria:

1. **Consensus Performance Degradation**: Validators experience increased timeout rates and reduced block proposal success rates, directly impacting network throughput
2. **Incorrect Validator Scoring**: Batch authors are falsely blamed for payload unavailability, potentially affecting validator reputation and staking rewards
3. **Exploitable via Timing Attacks**: Attackers can deliberately send near-expiration batches to trigger this condition across multiple validators simultaneously
4. **State Inconsistency**: ProofManager's view of available batches diverges from BatchStore's actual persisted state

The vulnerability meets "Validator node slowdowns" and "Significant protocol violations" under High Severity criteria.

## Likelihood Explanation

**High Likelihood:**
- Race condition occurs naturally during normal operation when batches expire between metadata extraction and persistence
- Storage quota exhaustion can also trigger this condition under heavy load
- No special privileges required - any peer can send batches
- Attackers can deliberately exploit by timing batch submissions relative to certified_time updates
- Multi-node impact: same timing issue affects all validators simultaneously, amplifying the problem

## Recommendation

Fix the ordering by only sending successfully persisted batches to ProofManager:

```rust
fn persist_and_send_digests(
    &self,
    persist_requests: Vec<PersistedValue<BatchInfoExt>>,
    approx_created_ts_usecs: u64,
) {
    if persist_requests.is_empty() {
        return;
    }

    let batch_store = self.batch_store.clone();
    let network_sender = self.network_sender.clone();
    let sender_to_proof_manager = self.sender_to_proof_manager.clone();
    tokio::spawn(async move {
        let peer_id = persist_requests[0].author();
        
        // Persist first, then extract metadata only from successful batches
        let signed_batch_infos = batch_store.persist(persist_requests);
        
        if !signed_batch_infos.is_empty() {
            // Extract batch summaries only from successfully persisted batches
            let batches: Vec<_> = signed_batch_infos
                .iter()
                .map(|signed_info| {
                    // Need to get summaries from persisted values
                    // This requires tracking which batches succeeded
                })
                .collect();
            
            if approx_created_ts_usecs > 0 {
                observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
            }
            
            // Send signed batch infos to network
            if signed_batch_infos[0].is_v2() {
                network_sender
                    .send_signed_batch_info_msg_v2(signed_batch_infos, vec![peer_id])
                    .await;
            } else {
                // ... V1 handling
            }
            
            // Only send successfully persisted batches to ProofManager
            let _ = sender_to_proof_manager
                .send(ProofManagerCommand::ReceiveBatches(batches))
                .await;
        }
    });
}
```

**Alternative approach**: Modify `BatchStore::persist()` to return both signed infos and corresponding summaries for only successful batches.

## Proof of Concept

```rust
#[tokio::test]
async fn test_expired_batch_notification_race() {
    // Setup batch store with current certified time
    let current_time = 1000000;
    let batch_store = Arc::new(BatchStore::new(
        1, true, current_time, /* ... */
    ));
    
    // Create batch with expiration just after current time
    let batch_expiration = current_time + 100;
    let batch = create_test_batch(batch_expiration);
    let persist_request = PersistedValue::new(batch.info().clone(), Some(batch.txns()));
    
    // Create ProofManager channel to monitor notifications
    let (proof_manager_tx, mut proof_manager_rx) = tokio::sync::mpsc::channel(100);
    
    // Simulate certified time advancing before persist completes
    batch_store.update_certified_timestamp(current_time + 200);
    
    // Call persist_and_send_digests
    let coordinator = BatchCoordinator::new(/* ... */, proof_manager_tx, /* ... */);
    coordinator.persist_and_send_digests(vec![persist_request], 0);
    
    // Wait for ProofManager notification
    if let Some(ProofManagerCommand::ReceiveBatches(batches)) = proof_manager_rx.recv().await {
        // Batch notification was sent even though batch expired
        assert_eq!(batches.len(), 1);
        
        // Verify batch is NOT in batch_store
        assert!(batch_store.get_batch_from_local(batches[0].0.digest()).is_err());
        
        // Vulnerability confirmed: ProofManager has batch metadata
        // but BatchStore doesn't have the actual batch
    }
}
```

## Notes

This vulnerability represents a fundamental state synchronization issue where ProofManager's view of available batches can diverge from BatchStore's actual persisted state. The root cause is the premature extraction of batch metadata before validating persistence success. The fix requires ensuring only successfully persisted batches are communicated to ProofManager, maintaining consistency between these two critical consensus components.

### Citations

**File:** consensus/src/quorum_store/batch_coordinator.rs (L92-100)
```rust
            let batches = persist_requests
                .iter()
                .map(|persisted_value| {
                    (
                        persisted_value.batch_info().clone(),
                        persisted_value.summary(),
                    )
                })
                .collect();
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L103-103)
```rust
                let signed_batch_infos = batch_store.persist(persist_requests);
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L131-133)
```rust
            let _ = sender_to_proof_manager
                .send(ProofManagerCommand::ReceiveBatches(batches))
                .await;
```

**File:** consensus/src/quorum_store/batch_store.rs (L419-439)
```rust
    pub(crate) fn save(&self, value: &PersistedValue<BatchInfoExt>) -> anyhow::Result<bool> {
        let last_certified_time = self.last_certified_time();
        if value.expiration() > last_certified_time {
            fail_point!("quorum_store::save", |_| {
                // Skip caching and storing value to the db
                Ok(false)
            });
            counters::GAP_BETWEEN_BATCH_EXPIRATION_AND_CURRENT_TIME_WHEN_SAVE.observe(
                Duration::from_micros(value.expiration() - last_certified_time).as_secs_f64(),
            );

            return self.insert_to_cache(value);
        }
        counters::NUM_BATCH_EXPIRED_WHEN_SAVE.inc();
        bail!(
            "Incorrect expiration {} in epoch {}, last committed timestamp {}",
            value.expiration(),
            self.epoch(),
            last_certified_time,
        );
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L613-628)
```rust
impl BatchWriter for BatchStore {
    fn persist(
        &self,
        persist_requests: Vec<PersistedValue<BatchInfoExt>>,
    ) -> Vec<SignedBatchInfo<BatchInfoExt>> {
        let mut signed_infos = vec![];
        for persist_request in persist_requests.into_iter() {
            let batch_info = persist_request.batch_info().clone();
            if let Some(signed_info) = self.persist_inner(batch_info, persist_request.clone()) {
                self.notify_subscribers(persist_request);
                signed_infos.push(signed_info);
            }
        }
        signed_infos
    }
}
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/src/round_manager.rs (L976-978)
```rust
                if let Err(missing_authors) = self.block_store.check_payload(block.block()) {
                    RoundTimeoutReason::PayloadUnavailable { missing_authors }
                } else {
```
