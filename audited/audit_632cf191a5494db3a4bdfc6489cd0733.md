# Audit Report

## Title
Async Task Cancellation in CommandAdapter Backup Operations Can Leave Corrupted Partial Backup Files Without Rollback

## Summary
The `CommandAdapter` backup storage implementation lacks proper cleanup mechanisms when async write tasks are cancelled mid-execution. The `ChildStdinAsDataSink` wrapper lacks a `Drop` implementation to ensure child processes are properly terminated and cleaned up, allowing orphaned bash commands to continue writing partial data after task cancellation, resulting in corrupted backup files with no rollback mechanism.

## Finding Description

The vulnerability exists in the backup system's `CommandAdapter` implementation, which delegates backup operations to external bash commands. When `create_for_write()` is called, it spawns a child process and returns its stdin as an `AsyncWrite` trait object (`ChildStdinAsDataSink`). [1](#0-0) 

The critical issue is that `ChildStdinAsDataSink` has no `Drop` implementation to ensure proper cleanup: [2](#0-1) 

When an async task is cancelled (dropped) before `shutdown()` is explicitly called, several critical failures occur:

1. **File handle already returned**: The `create_for_write()` function returns the file handle immediately after reading from stdout (line 104-110), before any data is written. This handle may already be included in the backup manifest.

2. **No Drop cleanup**: When `ChildStdinAsDataSink` is dropped without `shutdown()` being called, there is no Drop implementation to ensure the child process is properly waited on and validated.

3. **Orphaned process continues**: When a `tokio::process::Child` is dropped without being awaited, the process continues running as an orphan but we lose the ability to check its exit status or ensure completion.

4. **No rollback mechanism**: The `CommandAdapterConfig` defines commands for creation and writing, but has no rollback, cleanup, or abort commands: [3](#0-2) 

**Attack Scenario:**

Backup operations have explicit timeout handling: [4](#0-3) 

When writing large backup chunks or proofs, timeouts can occur: [5](#0-4) 

If the task is cancelled between `write_all()` (line 423) and `shutdown()` (line 424), or during the `tokio::io::copy()` operation (lines 429-436):

1. The 60-second timeout expires during a long write operation
2. The `AsyncWrite` handle is dropped without `shutdown()` being called
3. The underlying bash command continues running with incomplete data
4. The file handle was already returned and may be referenced in the manifest
5. The backup file is left in a corrupted/partial state
6. No error is reported; the corruption is silent

The same issue affects transaction and epoch ending backups: [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **HIGH severity** according to the Aptos bug bounty criteria:

1. **Significant Protocol Violation**: Backups are critical infrastructure for disaster recovery. Corrupted backups violate the fundamental guarantee that backups must be consistent and restorable.

2. **State Inconsistencies Requiring Intervention**: Partial backup files can cause restoration failures, requiring manual intervention to identify and remove corrupted files.

3. **Silent Failure**: The corruption is not detected or reported, meaning operators may not discover the issue until attempting restoration during an actual disaster scenario.

4. **Cascading Impact**: Corrupted backup files referenced in manifests can cause entire backup sets to become unrestorable, potentially leading to data loss scenarios.

While this does not directly affect consensus or validator operations, it compromises the disaster recovery capabilities of the entire network, which is a critical operational requirement.

## Likelihood Explanation

This vulnerability has **MEDIUM to HIGH likelihood** of occurrence:

1. **Common Triggering Conditions**:
   - 60-second timeouts are explicitly configured and can be exceeded with large state snapshots
   - Network interruptions during backup operations to remote storage
   - Resource exhaustion causing task cancellation
   - Explicit cancellation signals (e.g., operator interrupting backup)

2. **Frequency**: Backup operations run regularly (often daily or more frequently), providing multiple opportunities for the issue to manifest.

3. **Scale Dependency**: As the Aptos network grows and state size increases, backup operations take longer, increasing the probability of timeout or cancellation.

4. **No Protection**: There are no scope guards, Drop implementations, or other safety mechanisms preventing this issue.

## Recommendation

Implement a `Drop` guard for `ChildStdinAsDataSink` that ensures proper cleanup:

```rust
impl Drop for ChildStdinAsDataSink<'_> {
    fn drop(&mut self) {
        if let Some(mut child) = self.child.take() {
            // If we're being dropped without shutdown being called,
            // kill the child process to prevent orphaned partial writes
            if let Some(child_inner) = child.child.id() {
                eprintln!("Warning: ChildStdinAsDataSink dropped without shutdown, killing child process {}", child_inner);
                let _ = child.child.start_kill();
            }
            // Note: We cannot wait for the process here since Drop is not async
            // The caller MUST call shutdown() explicitly
        }
    }
}
```

Better solution: Implement a scope guard pattern that ensures cleanup:

```rust
pub struct BackupWriteGuard<'a> {
    writer: Option<Box<dyn AsyncWrite + Send + Unpin>>,
    file_handle: FileHandle,
    _marker: std::marker::PhantomData<&'a ()>,
}

impl<'a> BackupWriteGuard<'a> {
    pub async fn new(
        storage: &dyn BackupStorage,
        backup_handle: &BackupHandleRef,
        name: &ShellSafeName,
    ) -> Result<Self> {
        let (file_handle, writer) = storage.create_for_write(backup_handle, name).await?;
        Ok(Self {
            writer: Some(writer),
            file_handle,
            _marker: std::marker::PhantomData,
        })
    }

    pub async fn write_all(&mut self, buf: &[u8]) -> Result<()> {
        self.writer.as_mut().unwrap().write_all(buf).await
    }

    pub async fn commit(mut self) -> Result<FileHandle> {
        let mut writer = self.writer.take().unwrap();
        writer.shutdown().await?;
        Ok(self.file_handle)
    }
}

impl Drop for BackupWriteGuard<'_> {
    fn drop(&mut self) {
        if self.writer.is_some() {
            eprintln!("Warning: BackupWriteGuard dropped without commit - backup file may be corrupted");
            // Ideally, we would signal to the command adapter to delete the partial file
        }
    }
}
```

Additionally, extend `CommandAdapterConfig` to support cleanup commands:

```rust
pub struct Commands {
    // ... existing fields ...
    
    /// Command to abort/cleanup a partial write
    /// input env vars:
    ///     $FILE_HANDLE
    pub abort_write: Option<String>,
}
```

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_cancellation_leaves_partial_file() {
    use std::time::Duration;
    use tokio::time::timeout;
    
    // Create a command adapter that writes to local filesystem
    let config = CommandAdapterConfig {
        commands: Commands {
            create_backup: "mkdir -p /tmp/backup_test/$BACKUP_NAME && echo $BACKUP_NAME".to_string(),
            create_for_write: "cat > /tmp/backup_test/$BACKUP_HANDLE/$FILE_NAME && echo $FILE_HANDLE".to_string(),
            // ... other commands ...
        },
        env_vars: vec![],
    };
    
    let adapter = CommandAdapter::new(config);
    let backup_handle = adapter.create_backup(&ShellSafeName::from_str("test_backup").unwrap()).await.unwrap();
    
    // Start writing a large file but cancel mid-write
    let write_task = async {
        let (file_handle, mut writer) = adapter
            .create_for_write(&backup_handle, &ShellSafeName::from_str("test_file").unwrap())
            .await
            .unwrap();
        
        // Write some data
        let large_data = vec![0u8; 10 * 1024 * 1024]; // 10MB
        writer.write_all(&large_data).await.unwrap();
        
        // Simulate timeout or cancellation - drop without shutdown
        // writer is dropped here without shutdown() being called
        std::mem::drop(writer);
        
        file_handle
    };
    
    // Cancel the task by timeout
    let result = timeout(Duration::from_millis(100), write_task).await;
    
    // The timeout will cancel the task, dropping the writer without shutdown
    assert!(result.is_err());
    
    // Check that partial file exists on filesystem
    tokio::time::sleep(Duration::from_secs(1)).await;
    let partial_file_path = "/tmp/backup_test/test_backup/test_file";
    
    // This demonstrates the vulnerability: partial file exists with incomplete data
    let metadata = std::fs::metadata(partial_file_path).unwrap();
    assert!(metadata.len() > 0 && metadata.len() < 10 * 1024 * 1024);
    
    println!("Vulnerability confirmed: Partial file exists with {} bytes", metadata.len());
}
```

## Notes

This vulnerability specifically affects the `CommandAdapter` backend used for cloud storage (S3, GCS, Azure) backups. The `LocalFs` backend may have similar issues but would need separate analysis. The root cause is the lack of cancellation-safe patterns throughout the backup write path, combined with no rollback mechanisms in the command adapter configuration.

### Citations

**File:** storage/backup/backup-cli/src/storage/command_adapter/mod.rs (L93-112)
```rust
    async fn create_for_write(
        &self,
        backup_handle: &BackupHandleRef,
        name: &ShellSafeName,
    ) -> Result<(FileHandle, Box<dyn AsyncWrite + Send + Unpin>)> {
        let mut child = self
            .cmd(&self.config.commands.create_for_write, vec![
                EnvVar::backup_handle(backup_handle.to_string()),
                EnvVar::file_name(name.as_ref()),
            ])
            .spawn()?;
        let mut file_handle = FileHandle::new();
        child
            .stdout()
            .read_to_string(&mut file_handle)
            .await
            .err_notes(backup_handle)?;
        file_handle.truncate(file_handle.trim_end().len());
        Ok((file_handle, Box::new(child.into_data_sink())))
    }
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/command.rs (L167-223)
```rust
pub(super) struct ChildStdinAsDataSink<'a> {
    child: Option<SpawnedCommand>,
    join_fut: Option<BoxFuture<'a, Result<()>>>,
}

impl ChildStdinAsDataSink<'_> {
    fn new(child: SpawnedCommand) -> Self {
        Self {
            child: Some(child),
            join_fut: None,
        }
    }
}

impl AsyncWrite for ChildStdinAsDataSink<'_> {
    fn poll_write(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        buf: &[u8],
    ) -> Poll<Result<usize, tokio::io::Error>> {
        if self.join_fut.is_some() {
            Poll::Ready(Err(tokio::io::ErrorKind::BrokenPipe.into()))
        } else {
            Pin::new(self.child.as_mut().unwrap().stdin()).poll_write(cx, buf)
        }
    }

    fn poll_flush(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), tokio::io::Error>> {
        if self.join_fut.is_some() {
            Poll::Ready(Err(tokio::io::ErrorKind::BrokenPipe.into()))
        } else {
            Pin::new(self.child.as_mut().unwrap().stdin()).poll_flush(cx)
        }
    }

    fn poll_shutdown(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), tokio::io::Error>> {
        if self.join_fut.is_none() {
            let res = Pin::new(self.child.as_mut().unwrap().stdin()).poll_shutdown(cx);
            if let Poll::Ready(Ok(_)) = res {
                // pipe shutdown successful
                self.join_fut = Some(self.child.take().unwrap().join().boxed())
            } else {
                return res;
            }
        }

        Pin::new(self.join_fut.as_mut().unwrap())
            .poll(cx)
            .map_err(tokio::io::Error::other)
    }
}
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/config.rs (L41-72)
```rust
#[derive(Clone, Default, Deserialize)]
pub struct Commands {
    /// Command line to create backup.
    /// input env vars:
    ///     $BACKUP_NAME
    /// expected output on stdout:
    ///     BackupHandle, trailing newline is trimmed
    pub create_backup: String,
    /// Command line to open a file for writing.
    /// input env vars:
    ///     $BACKUP_HANDLE returned from the previous command
    ///     $FILE_NAME
    /// stdin will be fed with byte stream.
    /// expected output on stdout:
    ///     FileHandle, trailing newline
    pub create_for_write: String,
    /// Command line to open a file for reading.
    /// input env vars:
    ///     $FILE_NAME
    /// expected stdout to stream out bytes of the file.
    pub open_for_read: String,
    /// Command line to save a line of metadata
    /// input env vars:
    ///     $FILE_NAME
    /// stdin will be fed with a line of text with a trailing newline.
    pub save_metadata_line: String,
    /// Command line to list all existing metadata file handles.
    /// expected stdout to stream out lines of file handles.
    pub list_metadata_files: String,
    /// Command line to backup one metadata file to a metadata backup folder
    pub backup_metadata_file: Option<String>,
}
```

**File:** storage/backup/backup-cli/src/utils/backup_service_client.rs (L39-84)
```rust
    const TIMEOUT_SECS: u64 = 60;

    pub fn new_with_opt(opt: BackupServiceClientOpt) -> Self {
        Self::new(opt.address)
    }

    pub fn new(address: String) -> Self {
        Self {
            address,
            client: reqwest::Client::builder()
                .no_proxy()
                .build()
                .expect("Http client should build."),
        }
    }

    async fn get(&self, endpoint: &'static str, params: &str) -> Result<impl AsyncRead + use<>> {
        let _timer = BACKUP_TIMER.timer_with(&[&format!("backup_service_client_get_{endpoint}")]);

        let url = if params.is_empty() {
            format!("{}/{}", self.address, endpoint)
        } else {
            format!("{}/{}/{}", self.address, endpoint, params)
        };
        let timeout = Duration::from_secs(Self::TIMEOUT_SECS);
        let reader = tokio::time::timeout(timeout, self.client.get(&url).send())
            .await?
            .err_notes(&url)?
            .error_for_status()
            .err_notes(&url)?
            .bytes_stream()
            .map_ok(|bytes| {
                THROUGHPUT_COUNTER.inc_with_by(&[endpoint], bytes.len() as u64);
                bytes
            })
            .map_err(futures::io::Error::other)
            .into_async_read()
            .compat();

        // Adding the timeout here instead of on the response because we do use long living
        // connections. For example, we stream the entire state snapshot in one request.
        let mut reader_with_read_timeout = TimeoutReader::new(reader);
        reader_with_read_timeout.set_timeout(Some(timeout));

        Ok(Box::pin(reader_with_read_timeout))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L404-447)
```rust
    async fn write_chunk(
        &self,
        backup_handle: &BackupHandleRef,
        chunk: Chunk,
    ) -> Result<StateSnapshotChunk> {
        let _timer = BACKUP_TIMER.timer_with(&["state_snapshot_write_chunk"]);

        let Chunk {
            bytes,
            first_idx,
            last_idx,
            first_key,
            last_key,
        } = chunk;

        let (chunk_handle, mut chunk_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_name(first_idx))
            .await?;
        chunk_file.write_all(&bytes).await?;
        chunk_file.shutdown().await?;
        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_proof_name(first_idx, last_idx))
            .await?;
        tokio::io::copy(
            &mut self
                .client
                .get_account_range_proof(last_key, self.version())
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;

        Ok(StateSnapshotChunk {
            first_idx,
            last_idx,
            first_key,
            last_key,
            blobs: chunk_handle,
            proof: proof_handle,
        })
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L149-187)
```rust
    async fn write_chunk(
        &self,
        backup_handle: &BackupHandleRef,
        chunk_bytes: &[u8],
        first_version: u64,
        last_version: u64,
    ) -> Result<TransactionChunk> {
        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(
                backup_handle,
                &Self::chunk_proof_name(first_version, last_version),
            )
            .await?;
        tokio::io::copy(
            &mut self
                .client
                .get_transaction_range_proof(first_version, last_version)
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;

        let (chunk_handle, mut chunk_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_name(first_version))
            .await?;
        chunk_file.write_all(chunk_bytes).await?;
        chunk_file.shutdown().await?;

        Ok(TransactionChunk {
            first_version,
            last_version,
            transactions: chunk_handle,
            proof: proof_handle,
            format: TransactionChunkFormat::V1,
        })
    }
```
