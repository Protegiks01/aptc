# Audit Report

## Title
Unbounded Script Cache Memory Exhaustion Can Cause Validator Node Crashes During Block Execution

## Summary
The Move VM's script cache implementations (`SyncScriptCache` and `UnsyncScriptCache`) have no maximum size limit or eviction policy, allowing unbounded memory growth during block execution. An attacker can exploit this by submitting many unique script transactions within a single block, potentially exhausting memory and causing validator node crashes.

## Finding Description

The script cache is used to store deserialized and verified Move scripts during block execution to avoid redundant processing. The cache is implemented using unbounded hash maps with no size limits: [1](#0-0) 

The cache is created fresh for each block as part of the `MVHashMap` structure: [2](#0-1) 

When a script transaction is executed, the `unmetered_deserialize_and_cache_script` function deserializes the script bytecode and inserts it into the cache without checking cache size: [3](#0-2) 

**Attack Vector:**

1. An attacker submits up to 10,000 unique script transactions (the maximum block size): [4](#0-3) 

2. Each script can be up to 64 KB (or 1 MB for governance scripts): [5](#0-4) 

3. During parallel block execution, all scripts are deserialized and cached, consuming approximately:
   - Serialized bytecode: 10,000 Ã— 64 KB = 640 MB
   - Deserialized + verified structures (estimated 2-3x overhead): 1.3-1.9 GB

4. This memory is allocated directly in Rust's heap and is NOT tracked by the Move VM's memory quota system: [6](#0-5) 

5. If memory allocation fails, Rust will panic/abort, crashing the validator node.

**Security Guarantee Broken:**

This violates the **Resource Limits invariant** (#9): "All operations must respect gas, storage, and computational limits." While gas is charged for script execution, the unbounded cache growth is not subject to any resource limit, allowing memory exhaustion beyond what gas metering controls.

## Impact Explanation

**Severity: Medium**

This qualifies as Medium severity per the Aptos bug bounty criteria for the following reasons:

1. **State inconsistencies requiring intervention**: If validator nodes crash during block execution due to OOM, they must restart and resynchronize state, causing temporary inconsistencies across the network.

2. **Limited but real impact**: While modern validators typically have sufficient RAM (32+ GB), the attack could affect:
   - Resource-constrained validator nodes
   - Nodes under memory pressure from other operations
   - Multiple concurrent blocks being processed

3. **Does not reach High severity** because it doesn't guarantee validator slowdowns or crashes (depends on hardware and memory availability), and recovery is automatic through node restart and state sync.

4. **Does not reach Critical severity** because it doesn't cause permanent consensus breaks, fund loss, or require hardforks. The impact is temporary and recoverable.

## Likelihood Explanation

**Likelihood: Low to Medium**

The attack is feasible but has significant practical barriers:

**Barriers:**
- Requires crafting 10,000 unique script bytecode sequences
- Requires paying transaction fees and gas for all 10,000 transactions
- Requires getting all transactions into a single block (requires mempool flooding or block proposer coordination)
- Modern validators typically have sufficient memory to handle 1-2 GB cache

**Enabling Factors:**
- Scripts are still enabled in Aptos (not deprecated)
- No cache size limit or eviction policy exists
- Memory allocation failures cause node crashes
- Attack targets consensus availability, not requiring validator privileges

## Recommendation

Implement a maximum cache size with an eviction policy (e.g., LRU). Modify the `ScriptCache` trait to include size limits:

```rust
// In script_cache.rs
pub trait ScriptCache {
    const MAX_CACHE_SIZE: usize = 1000; // Maximum number of cached scripts
    
    // Existing methods...
    fn insert_deserialized_script(...) -> Arc<Self::Deserialized>;
    fn insert_verified_script(...) -> Arc<Self::Verified>;
    
    // Add eviction check
    fn maybe_evict_oldest(&mut self);
}
```

Implement size checking in the insert methods:

```rust
fn insert_deserialized_script(...) -> Arc<Self::Deserialized> {
    if self.script_cache.len() >= Self::MAX_CACHE_SIZE {
        self.maybe_evict_oldest();
    }
    // ... existing insertion logic
}
```

Alternatively, use an LRU cache implementation like `lru::LruCache` instead of unbounded `HashMap`/`DashMap`.

## Proof of Concept

```rust
// Conceptual PoC (simplified for demonstration)
// In practice, would require submitting actual transactions

use move_binary_format::file_format::CompiledScript;
use sha3::{Digest, Sha3_256};

fn generate_unique_script(seed: u64) -> Vec<u8> {
    // Generate unique bytecode by varying the seed
    let mut script_bytes = vec![0xA1, 0x1C, 0xEB, 0x0B]; // Magic bytes
    script_bytes.extend_from_slice(&seed.to_le_bytes());
    // ... add minimal valid script structure
    script_bytes
}

fn demonstrate_unbounded_cache_growth() {
    let cache = SyncScriptCache::empty();
    
    // Simulate 10,000 unique scripts
    for i in 0..10_000 {
        let script_bytes = generate_unique_script(i);
        let hash = Sha3_256::digest(&script_bytes);
        
        // This will keep inserting without any size check
        cache.insert_deserialized_script(
            hash.into(),
            CompiledScript::deserialize(&script_bytes).unwrap()
        );
    }
    
    // Cache now contains 10,000 entries with no eviction
    assert_eq!(cache.num_scripts(), 10_000);
    // Memory usage: 1-2 GB with no limit
}
```

## Notes

While this vulnerability exists, practical exploitation requires significant resources (transaction fees, gas costs) and coordination (getting 10,000 unique scripts into one block). The attack impact is also temporary since the cache is released after block execution. However, the lack of any resource limit on cache size represents a real violation of the Resource Limits invariant and could cause validator availability issues under the right circumstances.

### Citations

**File:** third_party/move/move-vm/types/src/code/cache/script_cache.rs (L121-135)
```rust
pub struct SyncScriptCache<K, D, V> {
    script_cache: DashMap<K, CachePadded<Code<D, V>>>,
}

impl<K, D, V> SyncScriptCache<K, D, V>
where
    K: Eq + Hash + Clone,
    V: Deref<Target = Arc<D>>,
{
    /// Returns an empty script cache.
    pub fn empty() -> Self {
        Self {
            script_cache: DashMap::new(),
        }
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1741-1741)
```rust
        let mut versioned_cache = MVHashMap::new();
```

**File:** third_party/move/move-vm/runtime/src/storage/loader/eager.rs (L89-104)
```rust
    fn unmetered_deserialize_and_cache_script(
        &self,
        serialized_script: &[u8],
    ) -> VMResult<Arc<CompiledScript>> {
        let hash = sha3_256(serialized_script);
        Ok(match self.module_storage.get_script(&hash) {
            Some(script) => script.deserialized().clone(),
            None => {
                let deserialized_script = self
                    .runtime_environment()
                    .deserialize_into_script(serialized_script)?;
                self.module_storage
                    .insert_deserialized_script(hash, deserialized_script)
            },
        })
    }
```

**File:** config/src/config/consensus_config.rs (L23-24)
```rust
pub(crate) static MAX_RECEIVING_BLOCK_TXNS: Lazy<u64> =
    Lazy::new(|| 10000.max(2 * MAX_SENDING_BLOCK_TXNS));
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L73-81)
```rust
            max_transaction_size_in_bytes: NumBytes,
            "max_transaction_size_in_bytes",
            64 * 1024
        ],
        [
            max_transaction_size_in_bytes_gov: NumBytes,
            { RELEASE_V1_13.. => "max_transaction_size_in_bytes.gov" },
            1024 * 1024
        ],
```

**File:** aptos-move/aptos-memory-usage-tracker/src/lib.rs (L25-30)
```rust
pub trait MemoryAlgebra {
    fn new(memory_quota: AbstractValueSize, feature_version: u64) -> Self;
    fn use_heap_memory(&mut self, amount: AbstractValueSize) -> PartialVMResult<()>;
    fn release_heap_memory(&mut self, amount: AbstractValueSize);
    fn current_memory_usage(&self) -> AbstractValueSize;
}
```
