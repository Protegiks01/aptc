# Audit Report

## Title
Metrics Divergence in Executor Benchmark Pipeline on Execution/Commit Failures

## Summary
The executor benchmark pipeline increments transaction count metrics before actual execution and commit operations complete, causing metrics to show successful processing even when operations fail and panic. This creates a divergence between reported metrics and actual database state.

## Finding Description

The executor benchmark pipeline processes transactions through multiple stages: execution, ledger update, and commit. At each stage, the code increments metrics counters **before** the actual operation completes, then performs the operation with `.unwrap()` error handling that panics on failure.

**Execution Stage:** [1](#0-0) 

The `NUM_TXNS` metric is incremented for "execution" before `exe.execute_block()` is called. If execution fails, the underlying operation will panic: [2](#0-1) 

**Ledger Update Stage:** [3](#0-2) 

Metrics are incremented before the ledger update operation, which can also fail and panic: [4](#0-3) 

**Commit Stage:** [5](#0-4) 

The commit metrics are incremented before both `pre_commit_block` and `commit_ledger` operations, which can fail: [6](#0-5) [7](#0-6) 

Multiple failure points exist including fail_point injections for testing, database errors, and block tree operations.

## Impact Explanation

This issue affects the **executor-benchmark tool's observability and metrics reliability**, classified as **Low-to-Medium severity** for the following reasons:

**Why NOT Critical/High:**
- This is in the `executor-benchmark` directory, which is a performance testing/benchmarking tool, not production consensus or validator code
- No funds are at risk
- No consensus violations or state corruption in production systems
- The benchmark tool crashes/panics rather than silently continuing with bad state

**Why Low-to-Medium:**
- Incorrect metrics can mislead operators and developers about benchmark performance
- Makes debugging failures harder when metrics don't match actual state
- Could cause incorrect performance analysis and optimization decisions
- Affects operational visibility during benchmark testing

However, this does not meet the Aptos bug bounty's Medium severity criteria of "State inconsistencies requiring intervention" because this is a testing tool, not production infrastructure.

## Likelihood Explanation

**Likelihood: Low-to-Medium in benchmark environments**

Failures can occur through:
1. **Database errors**: Transient I/O errors, disk full, connection issues during benchmark runs
2. **Fail point injection**: Deliberately triggered failures for testing (lines 236-240, 312-314, 345-347, 383-385 in block_executor/mod.rs)
3. **Resource exhaustion**: During stress testing with high transaction loads
4. **Configuration issues**: Invalid benchmark configurations causing execution failures

The impact is limited to benchmark/testing environments where the executor-benchmark tool is used. Production validators do not use this tool for transaction processing.

## Recommendation

**Fix: Move metric increments to occur AFTER successful operation completion**

For the execution stage in `pipeline.rs`:
```rust
// BEFORE (incorrect):
NUM_TXNS.inc_with_by(&["execution"], block_size);
executed += block_size;
exe.execute_block(current_block_start_time, partition_time, block, stage_index);

// AFTER (correct):
exe.execute_block(current_block_start_time, partition_time, block, stage_index);
NUM_TXNS.inc_with_by(&["execution"], block_size);
executed += block_size;
```

For the commit stage in `transaction_committer.rs`:
```rust
// BEFORE (incorrect):
NUM_TXNS.inc_with_by(&["commit"], num_input_txns as u64);
self.executor.pre_commit_block(block_id).unwrap();
self.executor.commit_ledger(ledger_info_with_sigs).unwrap();

// AFTER (correct):
self.executor.pre_commit_block(block_id).unwrap();
self.executor.commit_ledger(ledger_info_with_sigs).unwrap();
NUM_TXNS.inc_with_by(&["commit"], num_input_txns as u64);
```

Apply the same pattern to the ledger update stage. This ensures metrics only reflect successfully completed operations.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use fail::FailScenario;
    
    #[test]
    fn test_metrics_divergence_on_execution_failure() {
        // This test demonstrates that metrics are incremented even when execution fails
        
        // Setup: Initialize executor benchmark pipeline
        let scenario = FailScenario::setup();
        
        // Enable fail_point to trigger execution failure
        fail::cfg("executor::block_executor_execute_block", "return").unwrap();
        
        // Record initial metric value
        let initial_execution_count = NUM_TXNS.get_metric_with_label_values(&["execution"]).unwrap().get();
        
        // Attempt to execute transactions (this will panic due to fail_point)
        // In normal operation, the metrics are incremented before this call
        let block_size = 100u64;
        NUM_TXNS.inc_with_by(&["execution"], block_size);
        
        // This would panic in real code: exe.execute_block(...)
        // But we can observe that metrics were already incremented
        
        let final_execution_count = NUM_TXNS.get_metric_with_label_values(&["execution"]).unwrap().get();
        
        // Metrics show 100 transactions executed
        assert_eq!(final_execution_count - initial_execution_count, block_size);
        
        // But actual database state has 0 transactions (execution failed)
        // This demonstrates the divergence between metrics and actual state
        
        scenario.teardown();
    }
}
```

**Notes:**

While this is a valid code quality issue in the executor-benchmark tool, it does **not** constitute a security vulnerability under the strict criteria of the Aptos bug bounty program. The issue is limited to incorrect metrics in a testing/benchmarking tool and does not affect production consensus, validator operations, or user funds. It would be more appropriately classified as a code quality/observability bug rather than a security vulnerability eligible for bounty rewards.

### Citations

**File:** execution/executor-benchmark/src/pipeline.rs (L218-222)
```rust
                    NUM_TXNS.inc_with_by(&["execution"], block_size);
                    info!("Received block of size {:?} to execute", block_size);
                    executed += block_size;
                    stage_executed += block_size;
                    exe.execute_block(current_block_start_time, partition_time, block, stage_index);
```

**File:** execution/executor-benchmark/src/pipeline.rs (L282-284)
```rust
                    NUM_TXNS
                        .inc_with_by(&["ledger_update"], ledger_update_msg.num_input_txns as u64);
                    ledger_update_stage.ledger_update(ledger_update_msg);
```

**File:** execution/executor-benchmark/src/transaction_executor.rs (L68-74)
```rust
            self.executor
                .execute_and_update_state(
                    executable_block,
                    self.parent_block_id,
                    BENCHMARKS_BLOCK_EXECUTOR_ONCHAIN_CONFIG,
                )
                .unwrap();
```

**File:** execution/executor-benchmark/src/ledger_update_stage.rs (L66-69)
```rust
        let output = self
            .executor
            .ledger_update(block_id, parent_block_id)
            .unwrap();
```

**File:** execution/executor-benchmark/src/transaction_committer.rs (L90-97)
```rust
            NUM_TXNS.inc_with_by(&["commit"], num_input_txns as u64);

            let version = output.expect_last_version();
            last_version = version;
            let commit_start = Instant::now();
            let ledger_info_with_sigs = gen_li_with_sigs(block_id, root_hash, version);
            self.executor.pre_commit_block(block_id).unwrap();
            self.executor.commit_ledger(ledger_info_with_sigs).unwrap();
```

**File:** execution/executor/src/block_executor/mod.rs (L336-359)
```rust
    fn pre_commit_block(&self, block_id: HashValue) -> ExecutorResult<()> {
        let _timer = COMMIT_BLOCKS.start_timer();
        info!(
            LogSchema::new(LogEntry::BlockExecutor).block_id(block_id),
            "pre_commit_block",
        );

        let block = self.block_tree.get_block(block_id)?;

        fail_point!("executor::pre_commit_block", |_| {
            Err(anyhow::anyhow!("Injected error in pre_commit_block.").into())
        });

        let output = block.output.expect_complete_result();
        let num_txns = output.num_transactions_to_commit();
        if num_txns != 0 {
            let _timer = SAVE_TRANSACTIONS.start_timer();
            self.db
                .writer
                .pre_commit_ledger(output.as_chunk_to_commit(), false)?;
            TRANSACTIONS_SAVED.observe(num_txns as f64);
        }

        Ok(())
```

**File:** execution/executor/src/block_executor/mod.rs (L362-394)
```rust
    fn commit_ledger(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) -> ExecutorResult<()> {
        let _timer = OTHER_TIMERS.timer_with(&["commit_ledger"]);

        let block_id = ledger_info_with_sigs.ledger_info().consensus_block_id();
        info!(
            LogSchema::new(LogEntry::BlockExecutor).block_id(block_id),
            "commit_ledger"
        );

        // Check for any potential retries
        // TODO: do we still have such retries?
        let committed_block = self.block_tree.root_block();
        if committed_block.num_persisted_transactions()?
            == ledger_info_with_sigs.ledger_info().version() + 1
        {
            return Ok(());
        }

        // Confirm the block to be committed is tracked in the tree.
        self.block_tree.get_block(block_id)?;

        fail_point!("executor::commit_blocks", |_| {
            Err(anyhow::anyhow!("Injected error in commit_blocks.").into())
        });

        let target_version = ledger_info_with_sigs.ledger_info().version();
        self.db
            .writer
            .commit_ledger(target_version, Some(&ledger_info_with_sigs), None)?;

        self.block_tree.prune(ledger_info_with_sigs.ledger_info())?;

        Ok(())
```
