# Audit Report

## Title
QuorumStoreInlineHybrid Payload Availability Check Bypass Enables Chain Halt Attack

## Summary
The `check_payload_availability()` function unconditionally returns `Ok()` for `QuorumStoreInlineHybrid` payloads without verifying that batches referenced by ProofOfStore entries are actually available locally. This allows a malicious proposer to include valid but unavailable batch proofs in blocks, causing all validators to enter an infinite retry loop during execution, halting the entire blockchain.

## Finding Description
In `consensus/src/payload_manager/quorum_store_payload_manager.rs`, the `check_payload_availability()` function handles `QuorumStoreInlineHybrid` payloads with a dangerous assumption: [1](#0-0) 

The function always returns `Ok()` based on the comment: "The payload is considered available because it contains only proofs that guarantee network availability or inlined transactions." This assumption is **incorrect**. While ProofOfStore entries have valid aggregate signatures from a quorum of validators, they only prove that validators **signed** the batch metadata in the pastâ€”not that the actual batch data is currently available.

In contrast, `OptQuorumStore` payloads properly check batch availability: [2](#0-1) 

**Attack Flow:**

1. A proposer creates a block with `QuorumStoreInlineHybrid` payload containing ProofOfStore entries for batches that existed previously but are no longer available (expired, deleted, or on network-partitioned validators).

2. The block passes verification because ProofOfStore signatures are cryptographically valid: [3](#0-2) 

3. The block passes `check_payload_availability()` because it always returns `Ok()` for this payload type.

4. In `consensus/src/round_manager.rs`, when availability check passes, nodes proceed to vote without waiting for batch data: [4](#0-3) 

5. During execution, when `materialize_block()` calls `get_transactions()`, it attempts to fetch unavailable batches: [5](#0-4) 

6. The batch fetching fails with timeout: [6](#0-5) 

7. The error propagates to `materialize_block()`, which enters an infinite retry loop: [7](#0-6) 

8. All honest validators get stuck in this retry loop (sleeping 100ms between attempts), **halting the entire blockchain indefinitely**.

**Specific Attack Scenarios:**
- **Expired Batch Reuse**: Include ProofOfStore for batches that expired and were garbage collected
- **Network Partition**: Include batches only available on isolated validators
- **Validator Crash Recovery**: Include batches from validators that crashed before disk persistence completed

## Impact Explanation
This is a **High to Critical severity** liveness vulnerability:

- **Total Loss of Network Availability**: All validators attempting to execute the block will hang indefinitely in the retry loop, completely halting block production and transaction processing.
- **Non-Recoverable Without Intervention**: The chain cannot self-recover. Requires manual intervention (rolling back the block or emergency patch).
- **Trivial to Execute**: Any validator with proposer rights can trigger this by including stale ProofOfStore entries.
- **Network-Wide Impact**: Affects all honest validators simultaneously.

Per Aptos bug bounty criteria, "Total loss of liveness/network availability" is **Critical severity** ($1M), while "Validator node slowdowns" is **High severity** ($50K). This vulnerability causes complete chain halt, qualifying as Critical.

## Likelihood Explanation
**Likelihood: High**

- **Low Attacker Requirements**: Any validator can propose malicious blocks when selected as leader. No Byzantine collusion required.
- **Natural Occurrence**: Can happen unintentionally due to timing issues (batch expiration race conditions, network delays).
- **Easy to Trigger**: Simply include ProofOfStore entries for expired/unavailable batches in a proposal.
- **No Defense**: The `check_payload_availability()` bypass means there's no protection mechanism.

## Recommendation
Implement proper batch availability checking for `QuorumStoreInlineHybrid` payloads, similar to `OptQuorumStore`:

```rust
Payload::QuorumStoreInlineHybrid(inline_batches, proofs, _)
| Payload::QuorumStoreInlineHybridV2(inline_batches, proofs, _) => {
    // Update metrics (existing code)
    update_availability_metrics(
        &self.batch_reader,
        "false",
        inline_batches.iter().map(|(batch_info, _)| batch_info),
    );
    update_availability_metrics(
        &self.batch_reader,
        "true",
        proofs.proofs.iter().map(|proof| proof.info()),
    );

    // NEW: Check proof batch availability
    let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
    for proof in &proofs.proofs {
        if self.batch_reader.exists(proof.digest()).is_none() {
            let index = *self
                .address_to_validator_index
                .get(&proof.author())
                .expect("Payload author should have been verified");
            missing_authors.set(index as u16);
        }
    }
    
    if missing_authors.all_zeros() {
        Ok(())
    } else {
        Err(missing_authors)
    }
},
```

This ensures nodes wait for unavailable batches (via `wait_for_payload()`) before voting, preventing chain halt.

## Proof of Concept

```rust
// Test in consensus/src/payload_manager/quorum_store_payload_manager.rs
#[tokio::test]
async fn test_inline_hybrid_unavailable_proof_bypass() {
    use aptos_consensus_types::{
        block::Block,
        common::{Payload, ProofWithData},
        proof_of_store::{BatchInfo, ProofOfStore},
    };
    use aptos_crypto::HashValue;
    use aptos_types::aggregate_signature::AggregateSignature;
    
    // Setup: Create mock batch reader that returns None for specific digest
    let unavailable_digest = HashValue::random();
    let batch_info = BatchInfo::new(
        PeerId::random(),
        BatchId::new(1),
        1, // epoch
        1000000, // expiration (not expired)
        unavailable_digest,
        10, // num_txns
        1000, // num_bytes
        0, // gas_bucket_start
    );
    
    // Create valid ProofOfStore (with mock signature)
    let proof = ProofOfStore::new(
        batch_info,
        AggregateSignature::empty(), // Would be valid in real scenario
    );
    
    let proof_with_data = ProofWithData::new(vec![proof]);
    let inline_batches = vec![];
    
    // Create block with QuorumStoreInlineHybrid payload
    let payload = Payload::QuorumStoreInlineHybrid(
        inline_batches,
        proof_with_data,
        None,
    );
    
    let block = Block::new_for_testing(/* with payload */);
    
    // VULNERABILITY: check_payload_availability returns Ok() 
    // even though batch is NOT available locally
    let result = payload_manager.check_payload_availability(&block);
    assert!(result.is_ok()); // Passes incorrectly!
    
    // Later during execution, get_transactions will hang/fail
    let get_txns_result = payload_manager.get_transactions(&block, None).await;
    // This will timeout or retry indefinitely in materialize_block()
    assert!(get_txns_result.is_err()); // Chain halts here
}
```

## Notes
The vulnerability exists because the code assumes "proofs guarantee network availability," but ProofOfStore only guarantees that validators **once had** the batch, not that it's **currently available**. The proper solution requires checking `batch_reader.exists()` for all proof-referenced batches before voting, matching the safer `OptQuorumStore` implementation. This prevents validators from committing to execute blocks with unavailable data, preserving chain liveness.

### Citations

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L126-163)
```rust
    async fn get_transactions_quorum_store_inline_hybrid(
        &self,
        block: &Block,
        inline_batches: &[(BatchInfo, Vec<SignedTransaction>)],
        proof_with_data: &ProofWithData,
        max_txns_to_execute: &Option<u64>,
        block_gas_limit_override: &Option<u64>,
    ) -> ExecutorResult<BlockTransactionPayload> {
        let all_transactions = {
            let mut all_txns = process_qs_payload(
                proof_with_data,
                self.batch_reader.clone(),
                block,
                &self.ordered_authors,
            )
            .await?;
            all_txns.append(
                &mut inline_batches
                    .iter()
                    // TODO: Can clone be avoided here?
                    .flat_map(|(_batch_info, txns)| txns.clone())
                    .collect(),
            );
            all_txns
        };
        let inline_batches = inline_batches
            .iter()
            .map(|(batch_info, _)| batch_info.clone())
            .collect();
        Ok(BlockTransactionPayload::new_quorum_store_inline_hybrid(
            all_transactions,
            proof_with_data.proofs.clone(),
            *max_txns_to_execute,
            *block_gas_limit_override,
            inline_batches,
            self.enable_payload_v2,
        ))
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L360-408)
```rust
            Payload::QuorumStoreInlineHybrid(inline_batches, proofs, _)
            | Payload::QuorumStoreInlineHybridV2(inline_batches, proofs, _) => {
                fn update_availability_metrics<'a>(
                    batch_reader: &Arc<dyn BatchReader>,
                    is_proof_label: &str,
                    batch_infos: impl Iterator<Item = &'a BatchInfo>,
                ) {
                    for (author, chunk) in &batch_infos.chunk_by(|info| info.author()) {
                        let (available_count, missing_count) = chunk
                            .map(|info| batch_reader.exists(info.digest()))
                            .fold((0, 0), |(available_count, missing_count), item| {
                                if item.is_some() {
                                    (available_count + 1, missing_count)
                                } else {
                                    (available_count, missing_count + 1)
                                }
                            });
                        counters::CONSENSUS_PROPOSAL_PAYLOAD_BATCH_AVAILABILITY_IN_QS
                            .with_label_values(&[
                                &author.to_hex_literal(),
                                is_proof_label,
                                "available",
                            ])
                            .inc_by(available_count as u64);
                        counters::CONSENSUS_PROPOSAL_PAYLOAD_BATCH_AVAILABILITY_IN_QS
                            .with_label_values(&[
                                &author.to_hex_literal(),
                                is_proof_label,
                                "missing",
                            ])
                            .inc_by(missing_count as u64);
                    }
                }

                update_availability_metrics(
                    &self.batch_reader,
                    "false",
                    inline_batches.iter().map(|(batch_info, _)| batch_info),
                );
                update_availability_metrics(
                    &self.batch_reader,
                    "true",
                    proofs.proofs.iter().map(|proof| proof.info()),
                );

                // The payload is considered available because it contains only proofs that guarantee network availabiliy
                // or inlined transactions.
                Ok(())
            },
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-425)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
            },
```

**File:** consensus/consensus-types/src/common.rs (L590-597)
```rust
            (true, Payload::QuorumStoreInlineHybrid(inline_batches, proof_with_data, _))
            | (true, Payload::QuorumStoreInlineHybridV2(inline_batches, proof_with_data, _)) => {
                Self::verify_with_cache(&proof_with_data.proofs, verifier, proof_cache)?;
                Self::verify_inline_batches(
                    inline_batches.iter().map(|(info, txns)| (info, txns)),
                )?;
                Ok(())
            },
```

**File:** consensus/src/round_manager.rs (L1262-1279)
```rust
        if block_store.check_payload(&proposal).is_err() {
            debug!("Payload not available locally for block: {}", proposal.id());
            counters::CONSENSUS_PROPOSAL_PAYLOAD_AVAILABILITY
                .with_label_values(&["missing"])
                .inc();
            let start_time = Instant::now();
            let deadline = self.round_state.current_round_deadline();
            let future = async move {
                (
                    block_store.wait_for_payload(&proposal, deadline).await,
                    proposal,
                    start_time,
                )
            }
            .boxed();
            self.futures.push(future);
            return Ok(());
        }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```
