# Audit Report

## Title
Missing BLS Signature Verification on CertifiedNode Database Deserialization Allows Consensus Safety Violations

## Summary
The `CertifiedNodeSchema::decode_value()` method performs BCS deserialization of `CertifiedNode` objects from the consensus database without verifying their aggregated BLS signatures. Combined with the lack of signature verification in `validate_new_node()`, this allows invalid certificates with forged signatures to be loaded into the DAG consensus system during node restart, potentially causing consensus safety violations.

## Finding Description

The vulnerability exists in the database loading path for certified nodes: [1](#0-0) 

The `decode_value()` method only performs BCS deserialization without calling `CertifiedNode::verify()` to validate the aggregated signatures. During node initialization, all certified nodes are loaded from storage: [2](#0-1) 

At line 461, `storage.get_certified_nodes()` retrieves all nodes from the database, which uses the unverified deserialization. These nodes are then added to the DAG via `add_node()` at line 474. The validation function only checks metadata: [3](#0-2) 

Critically, `validate_new_node()` never calls `CertifiedNode::verify()` to check the BLS signatures, even though this method exists: [4](#0-3) 

This breaks the cryptographic correctness invariant. In contrast, nodes received from the network ARE properly verified before acceptance: [5](#0-4) 

**Attack Scenario:**
1. Attacker gains filesystem access to validator's ConsensusDB (e.g., through compromised validator infrastructure, insider threat, or another vulnerability)
2. Attacker crafts malicious `CertifiedNode` with valid metadata but forged `AggregateSignature` that doesn't represent actual validator votes
3. Attacker injects crafted node into the `certified_node` column family
4. Upon validator restart, `DagStore::new()` loads the malicious node without signature verification
5. Invalid node enters the in-memory DAG and participates in consensus
6. Malicious node can be ordered and sent to execution, causing consensus safety violations

## Impact Explanation

This is a **Critical Severity** vulnerability under Aptos bug bounty criteria as it enables **Consensus/Safety violations**. Invalid certificates can:

- Break the consensus safety property by allowing nodes without proper quorum signatures
- Cause divergent views across validators if different nodes load different invalid certificates
- Enable forged consensus decisions that were never actually voted on by validators
- Potentially lead to non-recoverable consensus failures requiring manual intervention

The ordered nodes are sent directly to execution without re-verification: [6](#0-5) 

And forwarded to the executor: [7](#0-6) 

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires one of the following conditions:
- **Filesystem access** to validator's consensus database (requires compromised validator infrastructure or insider threat)
- **Database corruption** due to disk failures or software bugs in storage layer
- **Another vulnerability** that allows database manipulation without direct filesystem access

While the required access level is high, validator node compromises do occur in production blockchain environments, making this a realistic attack vector worthy of mitigation.

## Recommendation

Add signature verification during database deserialization. Modify `DagStore::new()` to verify signatures when loading nodes:

```rust
// In consensus/src/dag/dag_store.rs, around line 461
let mut all_nodes = storage.get_certified_nodes().unwrap_or_default();
all_nodes.sort_unstable_by_key(|(_, node)| node.round());
let mut to_prune = vec![];

// Add signature verification
for (digest, certified_node) in all_nodes {
    // Verify signatures before adding to DAG
    if let Err(e) = certified_node.verify(&epoch_state.verifier) {
        error!("Invalid signature for node from storage: {}", e);
        to_prune.push(digest);
        continue;
    }
    
    if let Err(e) = dag.add_node(certified_node) {
        debug!("Delete node after bootstrap due to {}", e);
        to_prune.push(digest);
    }
}
```

Alternatively, add verification in `decode_value()`, though this requires access to `ValidatorVerifier` which may require architectural changes to the schema layer.

## Proof of Concept

```rust
#[cfg(test)]
mod test_signature_bypass {
    use super::*;
    use aptos_crypto::HashValue;
    use aptos_types::aggregate_signature::AggregateSignature;
    
    #[test]
    fn test_invalid_signature_loaded_from_db() {
        // Setup: Create a CertifiedNode with invalid signature
        let node = create_test_node();
        let invalid_sig = AggregateSignature::empty(); // Invalid signature
        let malicious_node = CertifiedNode::new(node, invalid_sig);
        
        // Serialize to bytes (as database would store it)
        let encoded = bcs::to_bytes(&malicious_node).unwrap();
        
        // Simulate database load via decode_value
        let loaded_node = <CertifiedNode as ValueCodec<CertifiedNodeSchema>>::decode_value(&encoded).unwrap();
        
        // Verify that signature verification would fail
        let verifier = create_test_verifier();
        assert!(loaded_node.verify(&verifier).is_err());
        
        // But decode_value succeeded without verification!
        // This node could be added to DAG if validate_new_node doesn't check signatures
    }
}
```

## Notes

This vulnerability represents a defense-in-depth failure where the system relies on the assumption that database contents are always valid. While normal operation paths properly verify signatures before database writes, this protection is incomplete because:

1. Database corruption can occur naturally
2. Validator node compromises could allow direct database manipulation  
3. Software bugs in the storage layer could write invalid data

The fix is straightforward: verify cryptographic signatures when loading security-critical data from persistent storage, not just when receiving from the network.

### Citations

**File:** consensus/src/consensusdb/schema/dag/mod.rs (L88-96)
```rust
impl ValueCodec<CertifiedNodeSchema> for CertifiedNode {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}
```

**File:** consensus/src/dag/dag_store.rs (L128-164)
```rust
    fn validate_new_node(&mut self, node: &CertifiedNode) -> anyhow::Result<()> {
        ensure!(
            node.epoch() == self.epoch_state.epoch,
            "different epoch {}, current {}",
            node.epoch(),
            self.epoch_state.epoch
        );
        let author = node.metadata().author();
        let index = *self
            .author_to_index
            .get(author)
            .ok_or_else(|| anyhow!("unknown author"))?;
        let round = node.metadata().round();
        ensure!(
            round >= self.lowest_round(),
            "round too low {}, lowest in dag {}",
            round,
            self.lowest_round()
        );
        ensure!(
            round <= self.highest_round() + 1,
            "round too high {}, highest in dag {}",
            round,
            self.highest_round()
        );
        if round > self.lowest_round() {
            for parent in node.parents() {
                ensure!(self.exists(parent.metadata()), "parent not exist");
            }
        }
        let round_ref = self
            .nodes_by_round
            .entry(round)
            .or_insert_with(|| vec![None; self.author_to_index.len()]);
        ensure!(round_ref[index].is_none(), "duplicate node");
        Ok(())
    }
```

**File:** consensus/src/dag/dag_store.rs (L454-489)
```rust
    pub fn new(
        epoch_state: Arc<EpochState>,
        storage: Arc<dyn DAGStorage>,
        payload_manager: Arc<dyn TPayloadManager>,
        start_round: Round,
        window_size: u64,
    ) -> Self {
        let mut all_nodes = storage.get_certified_nodes().unwrap_or_default();
        all_nodes.sort_unstable_by_key(|(_, node)| node.round());
        let mut to_prune = vec![];
        // Reconstruct the continuous dag starting from start_round and gc unrelated nodes
        let dag = Self::new_empty(
            epoch_state,
            storage.clone(),
            payload_manager,
            start_round,
            window_size,
        );
        for (digest, certified_node) in all_nodes {
            // TODO: save the storage call in this case
            if let Err(e) = dag.add_node(certified_node) {
                debug!("Delete node after bootstrap due to {}", e);
                to_prune.push(digest);
            }
        }
        if let Err(e) = storage.delete_certified_nodes(to_prune) {
            error!("Error deleting expired nodes: {:?}", e);
        }
        if dag.read().is_empty() {
            warn!(
                "[DAG] Start with empty DAG store at {}, need state sync",
                start_round
            );
        }
        dag
    }
```

**File:** consensus/src/dag/types.rs (L438-442)
```rust
    pub fn verify(&self, verifier: &ValidatorVerifier) -> anyhow::Result<()> {
        ensure!(self.digest() == self.calculate_digest(), "invalid digest");

        Ok(verifier.verify_multi_signatures(self.metadata(), self.signatures())?)
    }
```

**File:** consensus/src/dag/dag_fetcher.rs (L330-332)
```rust
                    match FetchResponse::try_from(response).and_then(|response| {
                        response.verify(&remote_request, &self.epoch_state.verifier)
                    }) {
```

**File:** consensus/src/dag/order_rule.rs (L161-223)
```rust
    fn finalize_order(&mut self, anchor: Arc<CertifiedNode>) {
        // Check we're in the expected instance
        assert!(Self::check_parity(
            self.lowest_unordered_anchor_round,
            anchor.round(),
        ));
        let lowest_round_to_reach = anchor.round().saturating_sub(self.dag_window_size_config);

        // Ceil it to the closest unordered anchor round
        let lowest_anchor_round = std::cmp::max(
            self.lowest_unordered_anchor_round,
            lowest_round_to_reach
                + !Self::check_parity(lowest_round_to_reach, anchor.round()) as u64,
        );
        assert!(Self::check_parity(lowest_anchor_round, anchor.round()));

        let failed_authors_and_rounds: Vec<_> = (lowest_anchor_round..anchor.round())
            .step_by(2)
            .map(|failed_round| (failed_round, self.anchor_election.get_anchor(failed_round)))
            .collect();
        let parents = anchor
            .parents()
            .iter()
            .map(|cert| *cert.metadata().author())
            .collect();
        let event = CommitEvent::new(
            anchor.id(),
            parents,
            failed_authors_and_rounds
                .iter()
                .map(|(_, author)| *author)
                .collect(),
        );
        self.anchor_election.update_reputation(event);

        let mut dag_writer = self.dag.write();
        let mut ordered_nodes: Vec<_> = dag_writer
            .reachable_mut(&anchor, Some(lowest_round_to_reach))
            .map(|node_status| {
                node_status.mark_as_ordered();
                node_status.as_node().clone()
            })
            .collect();

        observe_node(anchor.timestamp(), NodeStage::AnchorOrdered);
        for node in ordered_nodes.iter().skip(1) {
            observe_node(node.timestamp(), NodeStage::NodeOrdered);
        }
        ordered_nodes.reverse();

        debug!(
            LogSchema::new(LogEvent::OrderedAnchor),
            id = anchor.id(),
            lowest_unordered_anchor_round = self.lowest_unordered_anchor_round,
            "Reached round {} with {} nodes",
            lowest_anchor_round,
            ordered_nodes.len()
        );

        self.lowest_unordered_anchor_round = anchor.round() + 1;
        self.notifier
            .send_ordered_nodes(ordered_nodes, failed_authors_and_rounds);
    }
```

**File:** consensus/src/dag/adapter.rs (L137-238)
```rust
impl OrderedNotifier for OrderedNotifierAdapter {
    fn send_ordered_nodes(
        &self,
        ordered_nodes: Vec<Arc<CertifiedNode>>,
        failed_author: Vec<(Round, Author)>,
    ) {
        let anchor = ordered_nodes
            .last()
            .expect("ordered_nodes shuld not be empty");
        let epoch = anchor.epoch();
        let round = anchor.round();
        let timestamp = anchor.metadata().timestamp();
        let author = *anchor.author();
        let mut validator_txns = vec![];
        let mut payload = Payload::empty(
            !anchor.payload().is_direct(),
            self.allow_batches_without_pos_in_proposal,
        );
        let mut node_digests = vec![];
        for node in &ordered_nodes {
            validator_txns.extend(node.validator_txns().clone());
            payload = payload.extend(node.payload().clone());
            node_digests.push(node.digest());
        }
        let parent_block_id = self.parent_block_info.read().id();
        // construct the bitvec that indicates which nodes present in the previous round in CommitEvent
        let mut parents_bitvec = BitVec::with_num_bits(self.epoch_state.verifier.len() as u16);
        for parent in anchor.parents().iter() {
            if let Some(idx) = self
                .epoch_state
                .verifier
                .address_to_validator_index()
                .get(parent.metadata().author())
            {
                parents_bitvec.set(*idx as u16);
            }
        }
        let parent_timestamp = self.parent_block_info.read().timestamp_usecs();
        let block_timestamp = timestamp.max(parent_timestamp.checked_add(1).expect("must add"));

        NUM_NODES_PER_BLOCK.observe(ordered_nodes.len() as f64);
        let rounds_between = {
            let lowest_round_node = ordered_nodes.first().map_or(0, |node| node.round());
            round.saturating_sub(lowest_round_node)
        };
        NUM_ROUNDS_PER_BLOCK.observe((rounds_between + 1) as f64);

        let block = Arc::new(PipelinedBlock::new(
            Block::new_for_dag(
                epoch,
                round,
                block_timestamp,
                validator_txns,
                payload,
                author,
                failed_author,
                parent_block_id,
                parents_bitvec,
                node_digests,
            ),
            vec![],
            StateComputeResult::new_dummy(),
        ));
        let block_info = block.block_info();
        *self.parent_block_info.write() = block_info.clone();

        self.block_ordered_ts
            .write()
            .insert(block_info.round(), Instant::now());

        observe_block(block.block().timestamp_usecs(), BlockStage::ORDERED);

        let blocks_to_send = OrderedBlocks {
            ordered_blocks: vec![block],
            ordered_proof: LedgerInfoWithSignatures::new(
                LedgerInfo::new(block_info, anchor.digest()),
                AggregateSignature::empty(),
            ),
            // TODO: this needs to be properly integrated with pipeline_builder
            // callback: Box::new(
            //     move |committed_blocks: &[Arc<PipelinedBlock>],
            //           commit_decision: LedgerInfoWithSignatures| {
            //         block_created_ts
            //             .write()
            //             .retain(|&round, _| round > commit_decision.commit_info().round());
            //         dag.commit_callback(commit_decision.commit_info().round());
            //         ledger_info_provider
            //             .write()
            //             .notify_commit_proof(commit_decision);
            //         update_counters_for_committed_blocks(committed_blocks);
            //     },
            // ),
        };
        //
        if self
            .executor_channel
            .unbounded_send(blocks_to_send)
            .is_err()
        {
            error!("[DAG] execution pipeline closed");
        }
    }
```
