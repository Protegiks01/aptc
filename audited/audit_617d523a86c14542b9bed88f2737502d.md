# Audit Report

## Title
Out-of-Bounds Panic in Network Layer Subscriber Removal Causes Validator Network Crashes and Lock Poisoning

## Summary
The `broadcast()` function in `network/framework/src/application/storage.rs` contains a critical bug where removing multiple closed subscribers causes an out-of-bounds panic due to improper use of `swap_remove()` with stale indices. This panic occurs while holding write locks, causing lock poisoning that renders the validator's network layer inoperable and requiring node restart.

## Finding Description

The vulnerability exists in the `broadcast()` function's subscriber cleanup logic: [1](#0-0) 

When multiple subscribers have closed their channels, their indices are collected in ascending order into the `to_del` vector (lines 374-391). The code then iterates through these indices and calls `swap_remove()` on each (lines 392-394). 

The critical flaw is that `swap_remove()` modifies the vector by swapping the last element into the removed position and shrinking the length, which invalidates all subsequent indices in the `to_del` vector.

**Concrete Example:**
- Initial subscribers vector: [Sub0, Sub1, Sub2, Sub3, Sub4] (length 5)
- Closed channels detected at indices: 1, 3, 4
- `to_del = [1, 3, 4]` (collected in ascending order)
- `swap_remove(1)`: Vector becomes [Sub0, Sub4, Sub2, Sub3] (length 4)
- `swap_remove(3)`: Vector becomes [Sub0, Sub4, Sub2] (length 3)
- `swap_remove(4)`: **PANIC** - index 4 is out of bounds for vector of length 3

This panic has cascading consequences because `broadcast()` is called from `remove_peer_metadata()` while holding the `peers_and_metadata` write lock: [2](#0-1) 

The write lock is acquired at line 225 and held during the `broadcast()` call at line 245. When `broadcast()` panics:

1. The panic occurs while holding TWO locks: the `peers_and_metadata` RwLock (write mode) and the `subscribers` Mutex
2. Both locks become poisoned during panic unwinding
3. The cache update at line 259 never executes, leaving stale data
4. The peer is removed from the main map but remains in the cache

The `aptos_infallible::RwLock` implementation panics on poisoned lock access: [3](#0-2) 

Any subsequent attempt to acquire these poisoned locks will panic with "Cannot currently handle a poisoned lock", causing cascading failures throughout the network layer. All network operations that require these locks (peer insertions, removals, connection state updates, metadata queries) become impossible.

The stale cache affects components like the consensus publisher that rely on cached peer data: [4](#0-3) 

## Impact Explanation

This vulnerability qualifies as **HIGH Severity** under the Aptos bug bounty program category of **"API Crashes affecting network participation"**.

**Immediate Impact:**
- **Network Layer Crash**: Out-of-bounds panic terminates the current operation
- **Lock Poisoning**: Both `peers_and_metadata` and `subscribers` locks become poisoned and unusable
- **Network Operations Failure**: All future network operations (peer management, connection handling, metadata queries) panic when attempting to acquire poisoned locks
- **Validator Network Dysfunction**: The validator cannot send/receive network messages, effectively removing it from network participation
- **Manual Recovery Required**: Node restart is required to recover from poisoned lock state

**Secondary Impact:**
- **Cache Inconsistency**: Peer removed from main map but remains in cache, causing stale data to be served
- **Partial Subscriber Notification**: Some subscribers receive LostPeer events, others don't, creating divergent views of network topology
- **Consensus Publisher Inefficiency**: Continues attempting to send to disconnected peers that appear connected in stale cache

While the validator doesn't completely halt (consensus logic may continue briefly), the inability to send/receive network messages severely degrades or eliminates its ability to participate in consensus, making this functionally equivalent to a node crash.

## Likelihood Explanation

**Medium-High Likelihood** - This bug is triggered through normal network operations:

1. **Subscriber Closure is Common**: Applications subscribe to connection events (consensus publisher, health checker, connectivity manager, etc.). These subscriptions close during:
   - Normal application restarts
   - Graceful shutdowns
   - Application crashes
   - Resource cleanup operations

2. **Multiple Closed Subscribers**: In a production validator with multiple network components, having 3+ closed subscriber channels simultaneously is realistic, especially during:
   - Coordinated component restarts
   - Node upgrades
   - Cascading failures
   - High network churn periods

3. **Peer Disconnections**: Normal network churn causes frequent peer connections and disconnections

4. **Trigger Condition**: When 3+ subscribers have closed channels AND a peer subsequently disconnects, `remove_peer_metadata()` calls `broadcast()`, triggering the bug

5. **No Mitigation**: There are no safeguards against this scenario - the code directly uses stale indices without validation

## Recommendation

Fix the `broadcast()` function to remove subscribers in reverse order or use a two-phase approach:

```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    let mut to_del = vec![];
    for i in 0..listeners.len() {
        let dest = listeners.get_mut(i).unwrap();
        if let Err(err) = dest.try_send(event.clone()) {
            match err {
                TrySendError::Full(_) => {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(1)),
                        warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                    );
                },
                TrySendError::Closed(_) => {
                    to_del.push(i);
                },
            }
        }
    }
    // Remove in reverse order to maintain valid indices
    for evict in to_del.into_iter().rev() {
        listeners.swap_remove(evict);
    }
}
```

Alternatively, use `retain()` instead:

```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    listeners.retain(|sender| {
        match sender.try_send(event.clone()) {
            Ok(_) => true,
            Err(TrySendError::Full(_)) => {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                );
                true
            },
            Err(TrySendError::Closed(_)) => false,
        }
    });
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_broadcast_panic {
    use super::*;
    use tokio::sync::mpsc;

    #[tokio::test]
    async fn test_multiple_closed_subscribers_panic() {
        let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Validator]);
        
        // Create 5 subscribers
        let mut receivers = vec![];
        for _ in 0..5 {
            let receiver = peers_and_metadata.subscribe();
            receivers.push(receiver);
        }
        
        // Drop receivers at indices 1, 3, 4 to close their channels
        drop(receivers.remove(4));  // Close index 4
        drop(receivers.remove(3));  // Close index 3  
        drop(receivers.remove(1));  // Close index 1
        
        // Trigger broadcast which should panic with out-of-bounds
        let peer_network_id = PeerNetworkId::new(NetworkId::Validator, PeerId::random());
        let connection_metadata = ConnectionMetadata::mock(peer_network_id.peer_id());
        
        // Insert peer
        peers_and_metadata.insert_connection_metadata(peer_network_id, connection_metadata.clone()).unwrap();
        
        // This removal will call broadcast() with 3 closed subscribers
        // Expected: Panic with index out of bounds
        let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
            peers_and_metadata.remove_peer_metadata(peer_network_id, connection_metadata.connection_id).unwrap();
        }));
        
        assert!(result.is_err(), "Expected panic from out-of-bounds access");
    }
}
```

**Notes:**
- The core issue is an index invalidation bug in subscriber cleanup logic, not a "slowdown" or "state inconsistency" in the blockchain sense
- The impact is a crash/panic bug affecting the network layer's availability, categorized as "API Crashes" (High Severity)
- Network metadata cache inconsistency is a secondary effect, not blockchain state corruption
- This is not a "Network DoS attack" (out of scope) but an implementation bug causing crashes during normal operations

### Citations

**File:** network/framework/src/application/storage.rs (L219-262)
```rust
    pub fn remove_peer_metadata(
        &self,
        peer_network_id: PeerNetworkId,
        connection_id: ConnectionId,
    ) -> Result<PeerMetadata, Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Remove the peer metadata for the peer
        let peer_metadata = if let Entry::Occupied(entry) =
            peer_metadata_for_network.entry(peer_network_id.peer_id())
        {
            // Don't remove the peer if the connection doesn't match!
            // For now, remove the peer entirely, we could in the future
            // have multiple connections for a peer
            let active_connection_id = entry.get().connection_metadata.connection_id;
            if active_connection_id == connection_id {
                let peer_metadata = entry.remove();
                let event = ConnectionNotification::LostPeer(
                    peer_metadata.connection_metadata.clone(),
                    peer_network_id.network_id(),
                );
                self.broadcast(event);
                peer_metadata
            } else {
                return Err(Error::UnexpectedError(format!(
                    "The peer connection id did not match! Given: {:?}, found: {:?}.",
                    connection_id, active_connection_id
                )));
            }
        } else {
            // Unable to find the peer metadata for the given peer
            return Err(missing_peer_metadata_error(&peer_network_id));
        };

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        Ok(peer_metadata)
    }
```

**File:** network/framework/src/application/storage.rs (L371-395)
```rust
    fn broadcast(&self, event: ConnectionNotification) {
        let mut listeners = self.subscribers.lock();
        let mut to_del = vec![];
        for i in 0..listeners.len() {
            let dest = listeners.get_mut(i).unwrap();
            if let Err(err) = dest.try_send(event.clone()) {
                match err {
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
                    TrySendError::Closed(_) => {
                        to_del.push(i);
                    },
                }
            }
        }
        for evict in to_del.into_iter() {
            listeners.swap_remove(evict);
        }
    }
```

**File:** crates/aptos-infallible/src/rwlock.rs (L18-30)
```rust
    /// lock the rwlock in read mode
    pub fn read(&self) -> RwLockReadGuard<'_, T> {
        self.0
            .read()
            .expect("Cannot currently handle a poisoned lock")
    }

    /// lock the rwlock in write mode
    pub fn write(&self) -> RwLockWriteGuard<'_, T> {
        self.0
            .write()
            .expect("Cannot currently handle a poisoned lock")
    }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L99-118)
```rust
    fn garbage_collect_subscriptions(&self) {
        // Get the set of active subscribers
        let active_subscribers = self.get_active_subscribers();

        // Get the connected peers and metadata
        let peers_and_metadata = self.consensus_observer_client.get_peers_and_metadata();
        let connected_peers_and_metadata =
            match peers_and_metadata.get_connected_peers_and_metadata() {
                Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
                Err(error) => {
                    // We failed to get the connected peers and metadata
                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::UnexpectedError)
                        .message(&format!(
                            "Failed to get connected peers and metadata! Error: {:?}",
                            error
                        )));
                    return;
                },
            };
```
