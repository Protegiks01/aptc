# Audit Report

## Title
MempoolMessageId Ord Implementation Violates Total Ordering Leading to Broadcast Tracking Collisions

## Summary
The `Ord` implementation for `MempoolMessageId` uses `zip` with reversed iterators, which stops at the shorter iterator's length. This violates the total ordering requirement of the `Ord` trait, causing different message IDs with matching suffix pairs to be incorrectly considered equal. This leads to BTreeMap/BTreeSet collisions that corrupt broadcast tracking state, resulting in lost ACKs, incorrect timeout detection, and transaction propagation failures. [1](#0-0) 

## Finding Description

The `Ord` trait in Rust requires that `cmp` defines a total order, meaning `a.cmp(b) == Equal` if and only if `a == b`. However, the implementation for `MempoolMessageId` violates this requirement.

The implementation iterates in reverse and uses `zip`, which stops when the shorter iterator is exhausted: [1](#0-0) 

**The Bug**: When comparing two `MempoolMessageId` instances with different vector lengths, `zip` only compares pairs up to the length of the shorter vector. If those pairs are equal, the function returns `Ordering::Equal` even though the vectors are different.

**Example**:
- Message A: `[(sender0, timeline0), (sender1, timeline1), (sender2, timeline2)]`
- Message B: `[(sender2, timeline2)]`
- After reversing: A_rev = `[(sender2, timeline2), (sender1, timeline1), (sender0, timeline0)]`, B_rev = `[(sender2, timeline2)]`
- `zip` produces: `[((sender2, timeline2), (sender2, timeline2))]`
- Comparison: Equal
- Result: **A and B are incorrectly considered equal despite being different**

**Why Different Lengths Occur in Practice**:

For non-validator nodes (VFNs and PFNs), the peer prioritization system dynamically assigns sender buckets to peers based on load balancing: [2](#0-1) 

The critical line clears and rebuilds the entire sender bucket assignment: [3](#0-2) 

This reassignment happens when:
1. Load balancing thresholds are triggered based on traffic
2. Peer priorities change due to latency fluctuations
3. Number of top peers changes

When sender bucket assignments change, subsequent broadcasts to the same peer will have different numbers of pairs in their `MempoolMessageId`.

**Exploitation Path**:

1. **Initial State**: Fullnode assigns peer P sender buckets [0, 1, 2]. Broadcast M1 is created with 9 pairs (3 sender_buckets × 3 timeline_buckets per sender).

2. **M1 Insertion**: M1 is inserted into `sent_messages` BTreeMap: [4](#0-3) 

3. **Load Balancing Triggers**: Traffic increases, peer priority update occurs, peer P is reassigned only sender bucket [2].

4. **New Broadcast**: M2 is created with only 3 pairs (1 sender_bucket × 3 timeline_buckets).

5. **Collision**: If M2's 3 pairs match the last 3 pairs of M1 (from sender_bucket 2), then `M1.cmp(M2) == Equal`.

6. **State Corruption**: When M2 is inserted into the BTreeMap, it overwrites M1 because BTreeMap uses `Ord` for key comparison: [5](#0-4) 

7. **Lost Tracking**: M1's tracking information (timestamp) is lost. When ACK arrives for M1: [6](#0-5) 

The ACK is ignored as "expired" because M1 is no longer in the map.

8. **Additional Impact**: The `std::cmp::max` comparison for selecting retry/expired messages is also affected: [7](#0-6) 

If two different message IDs compare equal, the wrong message may be selected for rebroadcast, propagating incorrect transactions.

## Impact Explanation

**Severity: Medium** (per Aptos Bug Bounty criteria)

This vulnerability causes **state inconsistencies requiring intervention**:

1. **Broadcast Tracking Corruption**: Lost message tracking leads to incorrect pending broadcast counts, affecting rate limiting logic.

2. **ACK Processing Failures**: Valid ACKs are discarded, preventing proper timeout management and backpressure signaling.

3. **Transaction Propagation Failures**: Wrong messages may be rebroadcasted, or correct messages may fail to rebroadcast, impacting network-wide transaction distribution.

4. **Resource Accounting Errors**: Incorrect pending broadcast counts affect the `max_broadcasts_per_peer` throttling mechanism: [8](#0-7) 

This is **not Critical** because:
- Does not cause direct fund loss
- Does not break consensus safety (mempool is pre-consensus)
- Does not cause permanent network partition

This **is Medium** because:
- Causes state inconsistencies in mempool broadcast tracking
- Affects transaction propagation reliability
- Impacts network liveness and transaction dissemination
- Requires no attacker action (happens during normal operation)

## Likelihood Explanation

**Likelihood: High**

This vulnerability is **highly likely** to occur in production:

1. **Automatic Trigger**: Peer prioritization updates happen automatically based on configurable intervals: [9](#0-8) 

2. **Common Conditions**: Load balancing triggers during normal traffic fluctuations on any fullnode (VFN or PFN).

3. **No Attacker Required**: This is a logic bug that manifests during normal node operation without any malicious input.

4. **Realistic Collision Probability**: When sender bucket assignments change from multiple buckets to fewer buckets, and the remaining buckets were previously included, collisions are highly probable.

5. **Production Environment**: Any Aptos fullnode using intelligent peer prioritization (`enable_intelligent_peer_prioritization: true`) is affected.

## Recommendation

**Fix the Ord implementation to properly handle vectors of different lengths**:

```rust
impl Ord for MempoolMessageId {
    fn cmp(&self, other: &MempoolMessageId) -> std::cmp::Ordering {
        // First, compare lengths - longer vectors should be greater
        match self.0.len().cmp(&other.0.len()) {
            Ordering::Equal => {
                // Same length, compare elements in reverse
                for (&self_pair, &other_pair) in self.0.iter().rev().zip(other.0.iter().rev()) {
                    let ordering = self_pair.cmp(&other_pair);
                    if ordering != Ordering::Equal {
                        return ordering;
                    }
                }
                Ordering::Equal
            }
            other_ordering => other_ordering,
        }
    }
}
```

**Alternative Fix** (if reverse iteration is required for prioritization):

```rust
impl Ord for MempoolMessageId {
    fn cmp(&self, other: &MempoolMessageId) -> std::cmp::Ordering {
        // Compare in reverse, but handle different lengths properly
        let mut self_iter = self.0.iter().rev();
        let mut other_iter = other.0.iter().rev();
        
        loop {
            match (self_iter.next(), other_iter.next()) {
                (Some(&self_pair), Some(&other_pair)) => {
                    let ordering = self_pair.cmp(&other_pair);
                    if ordering != Ordering::Equal {
                        return ordering;
                    }
                }
                (Some(_), None) => return Ordering::Greater, // self is longer
                (None, Some(_)) => return Ordering::Less,    // other is longer
                (None, None) => return Ordering::Equal,      // both exhausted
            }
        }
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use std::cmp::Ordering;
    use std::collections::BTreeMap;

    #[test]
    fn test_message_id_ordering_bug_different_lengths() {
        // Create two messages with different lengths but matching suffix
        let long_message = MempoolMessageId(vec![(0, 1), (0, 2), (5, 6)]);
        let short_message = MempoolMessageId(vec![(5, 6)]);
        
        // These should NOT be equal, but the buggy implementation considers them equal
        let ordering = long_message.cmp(&short_message);
        
        // BUG: This assertion PASSES with the current implementation (incorrectly)
        assert_eq!(ordering, Ordering::Equal);
        
        // But they are NOT actually equal
        assert_ne!(long_message, short_message);
    }

    #[test]
    fn test_btreemap_collision() {
        use std::time::SystemTime;
        
        let mut sent_messages = BTreeMap::new();
        
        // Insert long message with timestamp T1
        let long_message = MempoolMessageId(vec![(0, 1), (0, 2), (5, 6)]);
        let t1 = SystemTime::now();
        sent_messages.insert(long_message.clone(), t1);
        
        assert_eq!(sent_messages.len(), 1);
        assert!(sent_messages.contains_key(&long_message));
        
        // Insert short message with matching suffix
        let short_message = MempoolMessageId(vec![(5, 6)]);
        let t2 = SystemTime::now();
        sent_messages.insert(short_message.clone(), t2);
        
        // BUG: Map still has only 1 entry because short_message overwrote long_message
        assert_eq!(sent_messages.len(), 1);
        
        // BUG: Looking up long_message now returns the timestamp from short_message
        assert_eq!(sent_messages.get(&long_message), Some(&t2));
        
        // BUG: Original timestamp t1 is lost
        assert_ne!(sent_messages.get(&long_message), Some(&t1));
    }

    #[test]
    fn test_max_comparison_bug() {
        let long_message = MempoolMessageId(vec![(0, 1), (0, 2), (5, 6)]);
        let short_message = MempoolMessageId(vec![(5, 6)]);
        
        // When used in std::cmp::max, behavior is implementation-defined
        // because they compare equal but are different values
        let result = std::cmp::max(&long_message, &short_message);
        
        // This demonstrates the undefined behavior in message selection
        println!("Max returned: {:?}", result);
    }
}
```

**Notes**:
- The vulnerability exists in the production codebase at the specified file and line numbers
- It affects all non-validator Aptos fullnodes using peer prioritization
- The bug manifests during normal operation without requiring attacker intervention
- The fix requires modifying the `Ord` implementation to properly handle different-length vectors while maintaining the desired reverse comparison semantics

### Citations

**File:** mempool/src/shared_mempool/types.rs (L398-408)
```rust
impl Ord for MempoolMessageId {
    fn cmp(&self, other: &MempoolMessageId) -> std::cmp::Ordering {
        for (&self_pair, &other_pair) in self.0.iter().rev().zip(other.0.iter().rev()) {
            let ordering = self_pair.cmp(&other_pair);
            if ordering != Ordering::Equal {
                return ordering;
            }
        }
        Ordering::Equal
    }
}
```

**File:** mempool/src/shared_mempool/types.rs (L459-459)
```rust
    pub sent_messages: BTreeMap<MempoolMessageId, SystemTime>,
```

**File:** mempool/src/shared_mempool/priority.rs (L232-240)
```rust
        match self.last_peer_priority_update {
            None => true, // We haven't updated yet
            Some(last_update) => {
                let duration_since_update = self.time_service.now().duration_since(last_update);
                let update_interval_secs = self
                    .mempool_config
                    .shared_mempool_priority_update_interval_secs;
                duration_since_update.as_secs() > update_interval_secs
            },
```

**File:** mempool/src/shared_mempool/priority.rs (L272-432)
```rust
    fn update_sender_bucket_for_peers(
        &mut self,
        peer_monitoring_data: &HashMap<PeerNetworkId, Option<&PeerMonitoringMetadata>>,
        num_mempool_txns_received_since_peers_updated: u64,
        num_committed_txns_received_since_peers_updated: u64,
    ) {
        // TODO: If the top peer set didn't change, then don't change the Primary sender bucket assignment.
        // TODO: (Minor) If the load is low, don't do load balancing for Failover buckets.
        assert!(self.prioritized_peers.read().len() == peer_monitoring_data.len());

        // Obtain the top peers to assign the sender buckets with Primary priority
        let mut top_peers = vec![];
        let secs_elapsed_since_last_update =
            self.last_peer_priority_update.map_or(0, |last_update| {
                self.time_service
                    .now()
                    .duration_since(last_update)
                    .as_secs()
            });

        // When the node is in state sync mode, it will receive more mempool commit notifications than the actual
        // commits that happens on the blockchain during the same time period. As secs_elapsed_since_last_update is
        // local time and not the on chain time, the average_committed_traffic_observed is only a local estimate of
        // the traffic and could differ from the actual traffic observed by the blockchain. If the estimate differs
        // from the actual traffic observed on the blockchain, we could end up load balancing more or less than required.
        let average_mempool_traffic_observed = num_mempool_txns_received_since_peers_updated as f64
            / max(1, secs_elapsed_since_last_update) as f64;
        let average_committed_traffic_observed = num_committed_txns_received_since_peers_updated
            as f64
            / max(1, secs_elapsed_since_last_update) as f64;

        // Obtain the highest threshold from mempool_config.load_balancing_thresholds for which avg_mempool_traffic_threshold_in_tps exceeds average_mempool_traffic_observed
        let threshold_config = self
            .mempool_config
            .load_balancing_thresholds
            .clone()
            .into_iter()
            .rev()
            .find(|threshold_config| {
                threshold_config.avg_mempool_traffic_threshold_in_tps
                    <= max(
                        average_mempool_traffic_observed as u64,
                        average_committed_traffic_observed as u64,
                    )
            })
            .unwrap_or_default();

        let num_top_peers = max(
            1,
            min(
                self.mempool_config.num_sender_buckets,
                if self.mempool_config.enable_max_load_balancing_at_any_load {
                    u8::MAX
                } else {
                    threshold_config.max_number_of_upstream_peers
                },
            ),
        );
        info!(
            "Time elapsed since last peer update: {:?}\n
            Number of mempool transactions received since last peer update: {:?},\n
            Average mempool traffic observed: {:?},\n
            Number of committed transactions received since last peer update: {:?},\n
            Average committed traffic observed: {:?},\n
            Load balancing threshold config: {:?},\n
            Number of top peers picked: {:?}",
            secs_elapsed_since_last_update,
            num_mempool_txns_received_since_peers_updated,
            average_mempool_traffic_observed,
            num_committed_txns_received_since_peers_updated,
            average_committed_traffic_observed,
            threshold_config,
            num_top_peers
        );

        if self.node_type.is_validator_fullnode() {
            // Use the peer on the VFN network with lowest ping latency as the primary peer
            let peers_in_vfn_network = self
                .prioritized_peers
                .read()
                .iter()
                .cloned()
                .filter(|peer| peer.network_id() == NetworkId::Vfn)
                .collect::<Vec<_>>();

            if !peers_in_vfn_network.is_empty() {
                top_peers = vec![peers_in_vfn_network[0]];
            }
        }

        if top_peers.is_empty() {
            let base_ping_latency = self.prioritized_peers.read().first().and_then(|peer| {
                peer_monitoring_data
                    .get(peer)
                    .and_then(|metadata| get_peer_ping_latency(metadata))
            });

            // Extract top peers with ping latency less than base_ping_latency + 50 ms
            for peer in self.prioritized_peers.read().iter() {
                if top_peers.len() >= num_top_peers as usize {
                    break;
                }

                let ping_latency = peer_monitoring_data
                    .get(peer)
                    .and_then(|metadata| get_peer_ping_latency(metadata));

                if base_ping_latency.is_none()
                    || ping_latency.is_none()
                    || ping_latency.unwrap()
                        < base_ping_latency.unwrap()
                            + (threshold_config.latency_slack_between_top_upstream_peers as f64)
                                / 1000.0
                {
                    top_peers.push(*peer);
                }
            }
        }
        info!(
            "Identified top peers: {:?}, node_type: {:?}",
            top_peers, self.node_type
        );

        assert!(top_peers.len() <= num_top_peers as usize);
        // Top peers shouldn't be empty if prioritized_peers is not zero
        assert!(self.prioritized_peers.read().is_empty() || !top_peers.is_empty());

        self.peer_to_sender_buckets = HashMap::new();
        if !self.prioritized_peers.read().is_empty() {
            // Assign sender buckets with Primary priority
            let mut peer_index = 0;
            for bucket_index in 0..self.mempool_config.num_sender_buckets {
                self.peer_to_sender_buckets
                    .entry(*top_peers.get(peer_index).unwrap())
                    .or_default()
                    .insert(bucket_index, BroadcastPeerPriority::Primary);
                peer_index = (peer_index + 1) % top_peers.len();
            }

            // Assign sender buckets with Failover priority. Use Round Robin.
            peer_index = 0;
            let num_prioritized_peers = self.prioritized_peers.read().len();
            for _ in 0..self.mempool_config.default_failovers {
                for bucket_index in 0..self.mempool_config.num_sender_buckets {
                    // Find the first peer that already doesn't have the sender bucket, and add the bucket
                    for _ in 0..num_prioritized_peers {
                        let peer = self.prioritized_peers.read()[peer_index];
                        let sender_bucket_list =
                            self.peer_to_sender_buckets.entry(peer).or_default();
                        if let std::collections::hash_map::Entry::Vacant(e) =
                            sender_bucket_list.entry(bucket_index)
                        {
                            e.insert(BroadcastPeerPriority::Failover);
                            break;
                        }
                        peer_index = (peer_index + 1) % num_prioritized_peers;
                    }
                }
            }
        }
    }
```

**File:** mempool/src/shared_mempool/network.rs (L315-334)
```rust
        if let Some(sent_timestamp) = sync_state.broadcast_info.sent_messages.remove(&message_id) {
            let rtt = timestamp
                .duration_since(sent_timestamp)
                .expect("failed to calculate mempool broadcast RTT");

            let network_id = peer.network_id();
            counters::SHARED_MEMPOOL_BROADCAST_RTT
                .with_label_values(&[network_id.as_str()])
                .observe(rtt.as_secs_f64());

            counters::shared_mempool_pending_broadcasts(&peer).dec();
        } else {
            trace!(
                LogSchema::new(LogEntry::ReceiveACK)
                    .peer(&peer)
                    .message_id(&message_id),
                "request ID does not exist or expired"
            );
            return;
        }
```

**File:** mempool/src/shared_mempool/network.rs (L446-448)
```rust
            if pending_broadcasts >= self.mempool_config.max_broadcasts_per_peer {
                return Err(BroadcastError::TooManyPendingBroadcasts(peer));
            }
```

**File:** mempool/src/shared_mempool/network.rs (L453-453)
```rust
            match std::cmp::max(expired_message_id, retry_message_id) {
```

**File:** mempool/src/shared_mempool/network.rs (L629-633)
```rust
        state
            .broadcast_info
            .sent_messages
            .insert(message_id, send_time);
        Ok(state.broadcast_info.sent_messages.len())
```
