# Audit Report

## Title
Race Condition Between BlockExecutor State Sync and Consensus Operations Causes Validator Panics

## Summary
The `BlockExecutor` contains a Time-Of-Check-Time-Of-Use (TOCTOU) race condition where the `finish()` method (called during state synchronization) can set the internal `inner` field to `None` between the `maybe_initialize()` check and subsequent field access in concurrent consensus operations. This causes validator processes to panic with "BlockExecutor is not reset" and crash, requiring manual restart.

## Finding Description

The `BlockExecutor` struct manages its state using `inner: RwLock<Option<BlockExecutorInner<V>>>`. [1](#0-0) 

During state synchronization, the `ExecutionProxy` calls `finish()` to release memory before syncing. [2](#0-1)  The `finish()` method sets `inner` to `None` by acquiring a write lock. [3](#0-2) 

Multiple BlockExecutor methods follow a vulnerable pattern:

1. **`committed_block_id()`**: Calls `maybe_initialize()` then immediately accesses `inner` [4](#0-3) 

2. **`execute_and_update_state()`**: Same pattern after initialization check [5](#0-4) 

3. **`state_view()`**: Vulnerable to same race [6](#0-5) 

4. **`pre_commit_block()`** and **`commit_ledger()`**: Also follow this pattern [7](#0-6) 

The `maybe_initialize()` method checks if `inner` is `None` and calls `reset()` if needed, but releases the lock between the check and return. [8](#0-7) 

**The Race Condition Execution:**

Thread A (consensus pipeline via `spawn_blocking`):
- Calls a BlockExecutor method like `committed_block_id()` [9](#0-8) 
- Executes `maybe_initialize()` successfully - `inner` is `Some(...)`
- Releases read lock from `maybe_initialize()`

Thread B (state sync):
- ExecutionProxy calls `sync_to_target()` or `sync_for_duration()` [10](#0-9) 
- Acquires write lock and calls `finish()` 
- Sets `inner` to `None`
- Releases write lock

Thread A (continued):
- Acquires read lock at `self.inner.read()`
- Calls `.as_ref()` which returns `None`
- Calls `.expect("BlockExecutor is not reset")` â†’ **PANIC**
- Validator process crashes

**Lack of Synchronization:**

The `execution_lock` mutex only protects the execution phase itself, not the initialization check. [11](#0-10) [12](#0-11) 

The `write_mutex` in ExecutionProxy only serializes state sync operations, not consensus operations accessing BlockExecutor. [13](#0-12) [14](#0-13) 

## Impact Explanation

**HIGH Severity** per Aptos bug bounty program criteria:

1. **Validator Node Crashes**: The panic causes immediate validator process termination, meeting the "API crashes" and "Validator node slowdowns" criteria for HIGH severity impacts.

2. **Network Liveness Risk**: When multiple validators synchronize simultaneously (common after network partitions or during catch-up periods), multiple validators can crash concurrently, potentially affecting consensus liveness if sufficient validators are impacted.

3. **Consensus Participation Loss**: Crashed validators cannot participate in block voting or proposal, temporarily reducing network capacity until manual intervention restarts them.

4. **Natural Trigger**: This occurs during normal validator operations without requiring any malicious activity - any time a validator needs to state sync while the consensus pipeline is actively processing blocks.

The race window is narrow but real, and the consequence is severe: complete validator process termination requiring manual operator intervention to restart.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

The vulnerability triggers when three conditions align:
1. A validator falls behind and initiates state sync (frequent occurrence)
2. Consensus pipeline is concurrently processing blocks (continuous during normal operation)
3. The timing window between `maybe_initialize()` completion and `inner` access is hit

**Factors increasing likelihood:**
- State synchronization is a routine operation for validators catching up after downtime or network issues
- The consensus pipeline runs continuously through `spawn_blocking` tasks that cannot be cancelled mid-execution
- Multiple BlockExecutor methods share this vulnerable pattern, creating multiple attack surfaces
- No synchronization mechanism prevents concurrent execution of state sync and consensus operations
- Buffer manager reset occurs after `finish()` is called, leaving the race window open

The vulnerability requires no attacker involvement and occurs naturally during normal validator operations, making it particularly concerning for network reliability.

## Recommendation

Implement atomic initialization with proper synchronization to eliminate the TOCTOU race:

**Option 1: Hold read lock across initialization check and access**
```rust
fn committed_block_id(&self) -> HashValue {
    let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "committed_block_id"]);
    
    // Hold lock across both operations
    let inner_guard = self.inner.read();
    if inner_guard.is_none() {
        drop(inner_guard);
        self.reset().expect("Failed to initialize.");
        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .committed_block_id()
    } else {
        inner_guard.as_ref().unwrap().committed_block_id()
    }
}
```

**Option 2: Add coordination lock between state sync and consensus operations**
Introduce a global lock in ExecutionProxy that both state sync and consensus operations must acquire, ensuring they don't execute concurrently during critical windows.

**Option 3: Use Arc<> instead of Option<> for inner state**
Replace `RwLock<Option<BlockExecutorInner<V>>>` with `RwLock<Arc<BlockExecutorInner<V>>>` and update references atomically, preventing the None state entirely during normal operations.

## Proof of Concept

While a full PoC requires orchestrating precise timing in a multi-threaded environment, the vulnerability can be demonstrated through code inspection showing the race window exists. A stress test that repeatedly triggers state sync while consensus operations run concurrently should eventually hit the panic condition, though exact reproduction timing depends on system load and scheduling.

The core issue is architecturally sound: the TOCTOU pattern combined with `spawn_blocking` (which prevents task cancellation) and lack of synchronization between state sync and consensus operations creates a real, triggerable race condition that causes validator crashes during normal operations.

## Notes

This vulnerability affects validator availability and reliability rather than consensus safety or fund security. However, it meets HIGH severity criteria due to its impact on validator operations and potential for affecting multiple validators simultaneously during common network catch-up scenarios. The lack of malicious actor requirement and natural trigger during routine operations makes this a critical reliability issue for the Aptos network.

### Citations

**File:** execution/executor/src/block_executor/mod.rs (L49-53)
```rust
pub struct BlockExecutor<V> {
    pub db: DbReaderWriter,
    inner: RwLock<Option<BlockExecutorInner<V>>>,
    execution_lock: Mutex<()>,
}
```

**File:** execution/executor/src/block_executor/mod.rs (L67-72)
```rust
    fn maybe_initialize(&self) -> Result<()> {
        if self.inner.read().is_none() {
            self.reset()?;
        }
        Ok(())
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L79-88)
```rust
    fn committed_block_id(&self) -> HashValue {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "committed_block_id"]);

        self.maybe_initialize().expect("Failed to initialize.");
        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .committed_block_id()
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L97-113)
```rust
    fn execute_and_update_state(
        &self,
        block: ExecutableBlock,
        parent_block_id: HashValue,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "execute_and_state_checkpoint"]);

        self.maybe_initialize()?;
        // guarantee only one block being executed at a time
        let _guard = self.execution_lock.lock();
        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .execute_and_update_state(block, parent_block_id, onchain_config)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L131-149)
```rust
    fn pre_commit_block(&self, block_id: HashValue) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "pre_commit_block"]);

        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .pre_commit_block(block_id)
    }

    fn commit_ledger(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "commit_ledger"]);

        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .commit_ledger(ledger_info_with_sigs)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L151-155)
```rust
    fn finish(&self) {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "finish"]);

        *self.inner.write() = None;
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L157-160)
```rust
    fn state_view(&self, block_id: HashValue) -> ExecutorResult<CachedStateView> {
        self.maybe_initialize()?;
        self.inner.read().as_ref().unwrap().state_view(block_id)
    }
```

**File:** consensus/src/state_computer.rs (L58-58)
```rust
    write_mutex: AsyncMutex<LogicalTime>,
```

**File:** consensus/src/state_computer.rs (L136-141)
```rust
        // Grab the logical time lock
        let mut latest_logical_time = self.write_mutex.lock().await;

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by the BlockExecutor to prevent a memory leak.
        self.executor.finish();
```

**File:** consensus/src/state_computer.rs (L177-185)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        // Grab the logical time lock and calculate the target logical time
        let mut latest_logical_time = self.write_mutex.lock().await;
        let target_logical_time =
            LogicalTime::new(target.ledger_info().epoch(), target.ledger_info().round());

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by BlockExecutor to prevent a memory leak.
        self.executor.finish();
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L857-868)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(start.elapsed())
```
