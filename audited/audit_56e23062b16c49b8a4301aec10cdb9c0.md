# Audit Report

## Title
Stack Overflow Vulnerability in Backup Restore via Unlimited BCS Deserialization Depth

## Summary
The `load_bcs_file()` function in the backup-cli uses `bcs::from_bytes()` without recursion depth limits, allowing an attacker with access to backup storage to cause stack overflow by providing deeply nested BCS-encoded data. This can crash validator nodes during restore operations.

## Finding Description
The backup restoration system deserializes various Aptos data structures from backup files stored in external storage (S3, GCS, local filesystem). The `load_bcs_file()` function uses `bcs::from_bytes()` without specifying a recursion depth limit: [1](#0-0) 

This function is called during critical restore operations to deserialize transaction proofs, state snapshots, and accumulator proofs: [2](#0-1) [3](#0-2) [4](#0-3) [5](#0-4) 

In contrast, all security-sensitive contexts throughout the codebase use `bcs::from_bytes_with_limit()` with explicit depth bounds. The API layer uses a limit of 16 for user-submitted transactions: [6](#0-5) [7](#0-6) 

The network protocol layer uses limits of 32-64 depending on the protocol: [8](#0-7) [9](#0-8) 

**Attack Scenario:**
1. Attacker compromises backup storage (e.g., S3 bucket misconfiguration, stolen credentials, MITM)
2. Attacker crafts malicious BCS-encoded data with deeply nested structures (e.g., nested vectors, tuples, or enum variants)
3. Attacker replaces legitimate backup files with malicious versions
4. When a node operator performs a restore operation, the backup-cli reads the malicious file
5. `bcs::from_bytes()` recursively deserializes without depth checking
6. Stack overflow occurs, crashing the node process

This breaks the **Resource Limits** invariant (#9) which requires all operations to respect computational limits, and impacts the availability of restore operations.

## Impact Explanation
This is a **High Severity** vulnerability per Aptos bug bounty criteria:

- **Validator node crashes**: During restore operations, nodes will crash with stack overflow, requiring manual intervention
- **Denial of service on disaster recovery**: Prevents validators from recovering from backups during outages or data corruption scenarios
- **Significant protocol violation**: Backup/restore is a critical operational capability; its failure undermines network resilience

While this doesn't directly affect consensus safety or cause fund loss, it significantly impacts validator operations and network availability during recovery scenarios. The attack requires compromising backup storage, which is a realistic threat in cloud environments with misconfigured access controls.

## Likelihood Explanation
**Likelihood: Medium-High**

The vulnerability is exploitable if:
1. Attacker gains write access to backup storage (moderate difficulty - common cloud misconfigurations)
2. A node operator performs a restore operation (high likelihood during outages)
3. The malicious data is deserialized before verification (guaranteed - deserialization happens before proof verification)

The attack doesn't require:
- Validator private keys
- Network-level access
- Consensus manipulation
- Complex timing attacks

Backup storage compromise is a well-documented security concern (AWS S3 bucket leaks, GCS misconfigurations), making this a realistic attack vector.

## Recommendation
Replace all instances of `bcs::from_bytes()` in backup-cli with `bcs::from_bytes_with_limit()` using an appropriate depth limit. Based on the patterns observed in the codebase:

**Recommended fix for `storage_ext.rs`:**
```rust
async fn load_bcs_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
    // Use the same limit as network protocols for non-user data
    const BACKUP_BCS_RECURSION_LIMIT: usize = 64;
    Ok(bcs::from_bytes_with_limit(&self.read_all(file_handle).await?, BACKUP_BCS_RECURSION_LIMIT)?)
}
```

Similarly, fix the direct `bcs::from_bytes()` calls in:
- `storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs` line 262
- `storage/backup/backup-cli/src/backup_types/transaction/restore.rs` lines 121, 130
- `storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs` line 168

The limit of 64 aligns with the `RECURSION_LIMIT` constant used for trusted protocol messages: [10](#0-9) 

## Proof of Concept
```rust
// PoC demonstrating the vulnerability
// File: tests/backup_bcs_recursion_attack.rs

use bcs;
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize)]
enum DeepNested {
    Leaf(u64),
    Node(Box<DeepNested>),
}

fn create_deeply_nested_bcs(depth: usize) -> Vec<u8> {
    let mut value = DeepNested::Leaf(42);
    for _ in 0..depth {
        value = DeepNested::Node(Box::new(value));
    }
    bcs::to_bytes(&value).unwrap()
}

#[test]
#[should_panic(expected = "stack overflow")]
fn test_unlimited_bcs_deserialization() {
    // Create BCS data with nesting depth of 100000
    let malicious_bcs = create_deeply_nested_bcs(100000);
    
    // This will cause stack overflow without depth limit
    let _: DeepNested = bcs::from_bytes(&malicious_bcs).unwrap();
}

#[test]
fn test_limited_bcs_deserialization() {
    // Same data with depth limit
    let malicious_bcs = create_deeply_nested_bcs(100000);
    
    // This will safely reject with depth limit
    let result: Result<DeepNested, _> = bcs::from_bytes_with_limit(&malicious_bcs, 64);
    assert!(result.is_err()); // Should error before stack overflow
}
```

To reproduce with actual backup data:
1. Create a malicious BCS file with deeply nested structures
2. Place it in backup storage with a valid file handle
3. Run `aptos-db-tool restore` pointing to the malicious backup
4. Observe stack overflow crash during deserialization

## Notes
The vulnerability exists because backup data is treated as trusted input despite coming from potentially compromised external storage. While backup integrity is verified via cryptographic proofs (waypoints, signatures), this verification happens AFTER deserialization, allowing the attack to succeed before verification can reject the malicious data. The depth limit should be applied at deserialization time as a defense-in-depth measure.

### Citations

**File:** storage/backup/backup-cli/src/utils/storage_ext.rs (L31-33)
```rust
    async fn load_bcs_file<T: DeserializeOwned>(&self, file_handle: &FileHandleRef) -> Result<T> {
        Ok(bcs::from_bytes(&self.read_all(file_handle).await?)?)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L125-126)
```rust
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L191-192)
```rust
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L261-262)
```rust
        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L120-121)
```rust
                TransactionChunkFormat::V0 => {
                    let (txn, txn_info, events, write_set) = bcs::from_bytes(&record_bytes)?;
```

**File:** api/src/transactions.rs (L851-851)
```rust
    const MAX_SIGNED_TRANSACTION_DEPTH: usize = 16;
```

**File:** api/src/transactions.rs (L1223-1225)
```rust
                let signed_transaction: SignedTransaction =
                    bcs::from_bytes_with_limit(&data.0, Self::MAX_SIGNED_TRANSACTION_DEPTH)
                        .context("Failed to deserialize input into SignedTransaction")
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L38-39)
```rust
pub const USER_INPUT_RECURSION_LIMIT: usize = 32;
pub const RECURSION_LIMIT: usize = 64;
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L260-261)
```rust
    fn bcs_decode<T: DeserializeOwned>(&self, bytes: &[u8], limit: usize) -> anyhow::Result<T> {
        bcs::from_bytes_with_limit(bytes, limit).map_err(|e| anyhow!("{:?}", e))
```
