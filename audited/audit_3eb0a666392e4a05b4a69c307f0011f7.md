# Audit Report

## Title
Missing Root Hash Verification in State Snapshot Restoration Allows Silent State Corruption

## Summary
The state snapshot restoration process completes successfully even when the manifest is incomplete or corrupted, because `JellyfishMerkleRestore::finish_impl()` does not verify that the final computed root hash matches the `expected_root_hash`. This allows nodes to restore incomplete state while metrics report success, leading to state inconsistencies and potential consensus divergence.

## Finding Description

The vulnerability exists in the state snapshot restoration flow where the system trusts that backup manifests are complete without performing a final integrity check.

**Critical Flow Analysis:**

1. **Manifest Loading:** The restoration loads a `StateSnapshotBackup` manifest containing chunks with indices and merkle proofs. [1](#0-0) 

2. **Chunk Processing:** Each chunk is verified using `SparseMerkleRangeProof` during `add_chunk()`, which validates that the chunk is consistent with previously added data and can construct the expected root hash given left siblings (from prior chunks) and right siblings (from the proof). [2](#0-1) 

3. **Critical Gap - Missing Final Verification:** After all chunks are processed, `finish()` is called, which delegates to `finish_impl()`. This method freezes remaining nodes and writes them to storage but **NEVER verifies** that the final computed root hash matches `expected_root_hash`. [3](#0-2) 

4. **Proof of Missing Verification:** Test cases explicitly show that the caller must manually verify the root hash after finish(), demonstrating it's not done internally. [4](#0-3) 

5. **Production Code Gap:** In production state-sync flow, `finish_box()` is called followed by `finalize_state_snapshot()`, but neither performs root hash verification. [5](#0-4) 

**Attack Scenario:**

If a backup manifest is incomplete (missing final chunks) or corrupted:
- `SparseMerkleRangeProof` verification succeeds for each chunk because proofs contain right siblings representing unrestored subtrees
- The restoration completes without error
- Metrics report success based on the last processed chunk's `last_idx` [6](#0-5) 
- The database contains incomplete state with an incorrect root hash
- No error is raised despite violating the **State Consistency** invariant

**Broken Invariant:** This violates Invariant #4 (State Consistency): "State transitions must be atomic and verifiable via Merkle proofs." The system accepts an incomplete state that cannot be verified against the expected root hash.

## Impact Explanation

**Medium Severity** (up to $10,000) - State inconsistencies requiring intervention:

1. **State Corruption:** Nodes restore incomplete state, leading to divergent database states across the network
2. **Consensus Risk:** Nodes with corrupted state may produce different state roots, breaking deterministic execution
3. **Silent Failure:** The restoration reports success via metrics while the state is actually incomplete
4. **Recovery Required:** Manual intervention needed to detect and repair corrupted state

This qualifies as "State inconsistencies requiring intervention" under the Medium severity category, as affected nodes would have incorrect state requiring manual recovery.

## Likelihood Explanation

**Moderate Likelihood:**

1. **Exposure:** Any node performing state snapshot restoration from backup is vulnerable
2. **Attack Vector:** Requires either:
   - Compromised backup storage with maliciously crafted manifests
   - Backup corruption during storage/transmission
   - Malicious backup operator providing incomplete manifests
3. **No Defense:** No validation prevents this attack once manifest is loaded
4. **Detection Difficulty:** Silent failure means corruption may go undetected until consensus divergence occurs

The likelihood is moderate because it requires control over backup sources or storage, but once achieved, exploitation is trivial and undetected.

## Recommendation

**Add explicit root hash verification in `JellyfishMerkleRestore::finish_impl()`:**

```rust
pub fn finish_impl(mut self) -> Result<()> {
    self.wait_for_async_commit()?;
    
    // Deal with special cases...
    if self.partial_nodes.len() == 1 {
        // ... existing logic ...
    }
    
    self.freeze(0);
    self.store.write_node_batch(&self.frozen_nodes)?;
    
    // CRITICAL FIX: Verify final root hash matches expected
    let root_node_key = NodeKey::new_empty_path(self.version);
    let root_node = self.store.get_node(&root_node_key, "finish_verification")?;
    let actual_root_hash = root_node.hash();
    
    ensure!(
        actual_root_hash == self.expected_root_hash,
        "Root hash mismatch after restoration. Expected: {}, Actual: {}",
        self.expected_root_hash,
        actual_root_hash
    );
    
    Ok(())
}
```

**Additional safeguard in restore.rs:**

After line 228, add verification:
```rust
tokio::task::spawn_blocking(move || receiver.lock().take().unwrap().finish()).await??;

// Verify restoration completeness if in Restore mode
if !self.run_mode.is_verify() {
    let actual_root = self.run_mode.get_state_store()
        .get_root_hash(self.version)?;
    ensure!(
        actual_root == manifest.root_hash,
        "State restoration completed but root hash mismatch"
    );
}

self.run_mode.finish();
```

## Proof of Concept

**Rust test demonstrating the vulnerability:**

```rust
#[test]
fn test_incomplete_manifest_silent_failure() {
    use tempfile::TempDir;
    use aptos_types::state_store::{StateKey, StateValue};
    
    // Setup: Create complete state
    let tmp_dir1 = TempDir::new().unwrap();
    let db1 = AptosDB::new_for_test(&tmp_dir1);
    let mut state_data = HashMap::new();
    for i in 0..1000 {
        let key = StateKey::raw(&i.to_le_bytes());
        let value = StateValue::new_legacy(vec![i as u8; 32]);
        state_data.insert(key, value);
    }
    init_store(&db1.state_store, state_data.clone().into_iter());
    
    let version = 999;
    let expected_root_hash = db1.state_store.get_root_hash(version).unwrap();
    
    // Attack: Create incomplete restoration (simulate missing last chunk)
    let tmp_dir2 = TempDir::new().unwrap();
    let db2 = AptosDB::new_for_test(&tmp_dir2);
    
    let mut restore = db2.state_store
        .get_snapshot_receiver(version, expected_root_hash).unwrap();
    
    // Only restore 80% of data (simulate incomplete manifest)
    let batch_size = 100;
    let mut current_idx = 0;
    let target_idx = 800; // Stop before complete
    
    while current_idx < target_idx {
        let chunk = db1.state_store
            .get_value_chunk_with_proof(version, current_idx, batch_size)
            .unwrap();
        restore.add_chunk(chunk.raw_values, chunk.proof).unwrap();
        current_idx += batch_size;
    }
    
    // BUG: finish() succeeds despite incomplete state!
    assert!(restore.finish_box().is_ok());
    
    // Verify corruption: root hash doesn't match
    let actual_root = db2.state_store.get_root_hash(version).unwrap();
    assert_ne!(actual_root, expected_root_hash); // FAILS - should have been caught!
    
    // Verify data loss
    let actual_count = db2.state_store.get_value_count(version).unwrap();
    assert!(actual_count < 1000); // Only 800 values restored
}
```

**Notes:**
- This vulnerability allows silent state corruption through incomplete backup manifests
- The `total_chunks` variable at line 163 is indeed different from total state values (it counts chunks, not values), but the deeper issue is the missing root hash verification
- Metrics show success based on `last_idx` of processed chunks, masking the incompleteness
- Production nodes could diverge in state, causing consensus issues requiring manual intervention

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-136)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L216-225)
```rust
            leaf_idx.set(chunk.last_idx as i64);
            info!(
                chunk = chunk_idx,
                chunks_to_add = chunks_to_add,
                last_idx = chunk.last_idx,
                values_per_second = ((chunk.last_idx + 1 - start_idx) as f64
                    / start.as_ref().unwrap().elapsed().as_secs_f64())
                    as u64,
                "State chunk added.",
            );
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L336-392)
```rust
    /// Restores a chunk of states. This function will verify that the given chunk is correct
    /// using the proof and root hash, then write things to storage. If the chunk is invalid, an
    /// error will be returned and nothing will be written to storage.
    pub fn add_chunk_impl(
        &mut self,
        mut chunk: Vec<(&K, HashValue)>,
        proof: SparseMerkleRangeProof,
    ) -> Result<()> {
        if self.finished {
            info!("State snapshot restore already finished, ignoring entire chunk.");
            return Ok(());
        }

        if let Some(prev_leaf) = &self.previous_leaf {
            let skip_until = chunk
                .iter()
                .find_position(|(key, _hash)| key.hash() > *prev_leaf.account_key());
            chunk = match skip_until {
                None => {
                    info!("Skipping entire chunk.");
                    return Ok(());
                },
                Some((0, _)) => chunk,
                Some((num_to_skip, next_leaf)) => {
                    info!(
                        num_to_skip = num_to_skip,
                        next_leaf = next_leaf,
                        "Skipping leaves."
                    );
                    chunk.split_off(num_to_skip)
                },
            }
        };
        if chunk.is_empty() {
            return Ok(());
        }

        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;

```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L750-789)
```rust
    pub fn finish_impl(mut self) -> Result<()> {
        self.wait_for_async_commit()?;
        // Deal with the special case when the entire tree has a single leaf or null node.
        if self.partial_nodes.len() == 1 {
            let mut num_children = 0;
            let mut leaf = None;
            for i in 0..16 {
                if let Some(ref child_info) = self.partial_nodes[0].children[i] {
                    num_children += 1;
                    if let ChildInfo::Leaf(node) = child_info {
                        leaf = Some(node.clone());
                    }
                }
            }

            match num_children {
                0 => {
                    let node_key = NodeKey::new_empty_path(self.version);
                    assert!(self.frozen_nodes.is_empty());
                    self.frozen_nodes.insert(node_key, Node::Null);
                    self.store.write_node_batch(&self.frozen_nodes)?;
                    return Ok(());
                },
                1 => {
                    if let Some(node) = leaf {
                        let node_key = NodeKey::new_empty_path(self.version);
                        assert!(self.frozen_nodes.is_empty());
                        self.frozen_nodes.insert(node_key, node.into());
                        self.store.write_node_batch(&self.frozen_nodes)?;
                        return Ok(());
                    }
                },
                _ => (),
            }
        }

        self.freeze(0);
        self.store.write_node_batch(&self.frozen_nodes)?;
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_store/tests/mod.rs (L415-417)
```rust
        restore.finish_box().unwrap();
        let actual_root_hash = store2.get_root_hash(version).unwrap();
        prop_assert_eq!(actual_root_hash, expected_root_hash);
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1122-1136)
```rust
    // Finalize the state snapshot
    state_snapshot_receiver.finish_box().map_err(|error| {
        format!(
            "Failed to finish the state value synchronization! Error: {:?}",
            error
        )
    })?;
    storage
        .writer
        .finalize_state_snapshot(
            version,
            target_output_with_proof.clone(),
            epoch_change_proofs,
        )
        .map_err(|error| format!("Failed to finalize the state snapshot! Error: {:?}", error))?;
```
