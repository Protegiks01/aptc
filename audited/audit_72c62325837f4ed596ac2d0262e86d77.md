# Audit Report

## Title
Unbounded Message Loss in Consensus Publisher Due to Missing Subscriber Removal on Channel Backpressure

## Summary
The consensus publisher's `publish_message()` function uses a bounded channel with `try_send()` that silently drops messages when full, without any mechanism to remove problematic subscribers. This allows unbounded message loss as slow or malicious subscribers can cause persistent channel backpressure affecting all subscribers, with no automatic remediation.

## Finding Description

The vulnerability exists in the consensus observer publisher architecture where all subscribers share a single bounded channel for outbound messages. [1](#0-0) 

When consensus messages are published to active subscribers, the function iterates through all subscribers and attempts to send messages via `try_send()`: [2](#0-1) 

**Critical Issues:**

1. **Shared Channel Architecture**: All subscribers share the same bounded channel (default capacity: 1000). When N subscribers are active and a message is published, N copies are queued to the same channel. [3](#0-2) 

2. **Silent Message Drops**: When `try_send()` fails due to channel fullness, only a warning is logged. No metric is incremented to track this failure type, and critically, the subscriber remains in the `active_subscribers` set.

3. **No Subscriber Circuit Breaker**: The only subscriber removal mechanisms are explicit unsubscription requests and garbage collection for disconnected peers: [4](#0-3) 

The garbage collection only checks connectivity status, not message delivery success. There is no mechanism to remove subscribers based on repeated send failures.

**Attack Scenario:**

1. Attacker subscribes as a consensus observer (no special permissions required)
2. Attacker deliberately slows message processing or network consumption
3. Messages destined for all subscribers accumulate in the shared channel
4. Once the channel reaches capacity (1000 messages), subsequent `try_send()` calls fail
5. Critical consensus messages (OrderedBlock, CommitDecision, BlockPayload) are silently dropped
6. The slow subscriber remains active, continuing to cause backpressure
7. All other subscribers also experience message loss due to the shared channel [5](#0-4) 

**Why This is Problematic:**

The consensus publisher is called from critical consensus paths, such as when blocks are ordered: [6](#0-5) 

If validators act as publishers (which is enabled by default on validators), this creates a DoS vector where malicious observers can cause validator slowdowns by filling the shared message channel. [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program for the following reasons:

1. **Validator Node Slowdowns**: Validators with publisher enabled (default configuration) can experience operational degradation when the shared channel fills up. While `try_send()` is non-blocking, the lack of message delivery to observers and inability to identify problematic subscribers creates operational overhead.

2. **Significant Protocol Violations**: The consensus observer protocol has an implicit guarantee that subscribed observers receive consensus updates. This vulnerability breaks that guarantee - messages can be lost indefinitely without triggering subscriber removal, violating the expected reliability semantics.

3. **Resource Exhaustion via Single Malicious Actor**: A single unprivileged attacker can cause message loss for ALL subscribers by exploiting the shared channel architecture, creating a cascading availability impact.

4. **Silent Failures**: The absence of metrics for channel backpressure failures (only warning logs) means operators lack visibility into the issue until significant message loss has occurred.

## Likelihood Explanation

**Likelihood: HIGH**

1. **Low Attack Barrier**: Any peer can subscribe as a consensus observer without special permissions or stake requirements. The attack requires only:
   - Sending a Subscribe request
   - Deliberately slowing message consumption
   - No validator collusion or insider access needed

2. **Natural Triggering Conditions**: Even without malicious intent, the vulnerability can be triggered by:
   - Network congestion affecting message delivery
   - Slow observer nodes with limited resources
   - Bugs in observer message processing logic
   - High consensus throughput combined with multiple subscribers

3. **Shared Resource Amplification**: The shared channel architecture means one problematic subscriber affects all subscribers, amplifying the impact.

4. **Default Enabled on Validators**: Publishers are enabled by default on validators, making this attack surface broadly available across the network.

## Recommendation

Implement a subscriber health tracking and circuit breaker mechanism:

**1. Track Per-Subscriber Send Failures:**
```rust
// Add to ConsensusPublisher struct
subscriber_failure_counts: Arc<RwLock<HashMap<PeerNetworkId, u64>>>,
max_consecutive_failures: u64, // e.g., 100
```

**2. Increment Failure Counter and Remove Unhealthy Subscribers:**
```rust
pub fn publish_message(&self, message: ConsensusObserverDirectSend) {
    let active_subscribers = self.get_active_subscribers();
    
    for peer_network_id in &active_subscribers {
        let mut outbound_message_sender = self.outbound_message_sender.clone();
        if let Err(error) = outbound_message_sender.try_send((*peer_network_id, message.clone())) {
            warn!(...); // existing log
            
            // Track failure and remove subscriber if threshold exceeded
            let mut failures = self.subscriber_failure_counts.write();
            let count = failures.entry(*peer_network_id).or_insert(0);
            *count += 1;
            
            if *count >= self.max_consecutive_failures {
                self.remove_active_subscriber(peer_network_id);
                failures.remove(peer_network_id);
                warn!("Removed subscriber {} due to {} consecutive send failures", 
                      peer_network_id, *count);
            }
            
            // Increment metric for visibility
            metrics::increment_counter(
                &metrics::PUBLISHER_SENT_MESSAGE_ERRORS,
                "channel_full",
                peer_network_id,
            );
        } else {
            // Reset failure counter on success
            self.subscriber_failure_counts.write().remove(peer_network_id);
        }
    }
}
```

**3. Add Metric for Channel Backpressure:**
Add a dedicated metric in `metrics.rs` to track channel full errors separately from network send errors, enabling operators to detect and alert on this condition.

**Alternative Approach (More Robust):**
Consider per-subscriber channels with individual backpressure handling, though this requires more significant architectural changes.

## Proof of Concept

```rust
#[tokio::test]
async fn test_unbounded_message_loss_without_removal() {
    use tokio::time::{sleep, Duration};
    
    // Create consensus publisher with small channel for easier reproduction
    let network_id = NetworkId::Public;
    let peers_and_metadata = PeersAndMetadata::new(&[network_id]);
    let network_client = NetworkClient::new(vec![], vec![], hashmap![], peers_and_metadata.clone());
    let consensus_observer_client = Arc::new(ConsensusObserverClient::new(network_client));
    
    let mut config = ConsensusObserverConfig::default();
    config.max_network_channel_size = 10; // Small channel for testing
    
    let (consensus_publisher, mut outbound_message_receiver) = 
        ConsensusPublisher::new(config, consensus_observer_client);
    
    // Subscribe a peer
    let peer_network_id = PeerNetworkId::new(network_id, PeerId::random());
    consensus_publisher.add_active_subscriber(peer_network_id);
    
    // Verify subscriber is active
    assert_eq!(consensus_publisher.get_active_subscribers().len(), 1);
    
    // Publish messages without consuming from receiver - fill the channel
    let test_message = ConsensusObserverMessage::new_commit_decision_message(
        LedgerInfoWithSignatures::new(
            LedgerInfo::new(BlockInfo::empty(), HashValue::zero()),
            AggregateSignature::empty(),
        ),
    );
    
    // Publish enough messages to exceed channel capacity
    for _ in 0..20 {
        consensus_publisher.publish_message(test_message.clone());
    }
    
    // Wait a bit for async operations
    sleep(Duration::from_millis(100)).await;
    
    // Verify: Subscriber is STILL active despite message drops
    assert_eq!(
        consensus_publisher.get_active_subscribers().len(), 
        1,
        "Subscriber should still be active - no removal mechanism exists!"
    );
    
    // Verify: Channel is full - can only receive up to capacity messages
    let mut received_count = 0;
    while outbound_message_receiver.try_next().is_ok() {
        received_count += 1;
        if received_count > 15 {
            break; // Safety limit
        }
    }
    
    // Messages beyond channel capacity were silently dropped
    assert!(
        received_count < 20,
        "Not all messages were queued - some were dropped due to channel fullness"
    );
    
    println!("Unbounded message loss confirmed: {} messages dropped, subscriber still active", 
             20 - received_count);
}
```

## Notes

This vulnerability represents a DoS vector in the consensus observer subsystem. While it does not directly compromise consensus safety (observers are passive recipients), it creates operational risk for validator nodes acting as publishers and degrades the observer network's reliability. The shared channel architecture combined with the lack of subscriber health tracking allows a single malicious or buggy peer to cause persistent message loss affecting all subscribers.

### Citations

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L56-59)
```rust
        // Create the outbound message sender and receiver
        let max_network_channel_size = consensus_observer_config.max_network_channel_size as usize;
        let (outbound_message_sender, outbound_message_receiver) =
            mpsc::channel(max_network_channel_size);
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L99-154)
```rust
    fn garbage_collect_subscriptions(&self) {
        // Get the set of active subscribers
        let active_subscribers = self.get_active_subscribers();

        // Get the connected peers and metadata
        let peers_and_metadata = self.consensus_observer_client.get_peers_and_metadata();
        let connected_peers_and_metadata =
            match peers_and_metadata.get_connected_peers_and_metadata() {
                Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
                Err(error) => {
                    // We failed to get the connected peers and metadata
                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::UnexpectedError)
                        .message(&format!(
                            "Failed to get connected peers and metadata! Error: {:?}",
                            error
                        )));
                    return;
                },
            };

        // Identify the active subscribers that are no longer connected
        let connected_peers: HashSet<PeerNetworkId> =
            connected_peers_and_metadata.keys().cloned().collect();
        let disconnected_subscribers: HashSet<PeerNetworkId> = active_subscribers
            .difference(&connected_peers)
            .cloned()
            .collect();

        // Remove any subscriptions from peers that are no longer connected
        for peer_network_id in &disconnected_subscribers {
            self.remove_active_subscriber(peer_network_id);
            info!(LogSchema::new(LogEntry::ConsensusPublisher)
                .event(LogEvent::Subscription)
                .message(&format!(
                    "Removed peer subscription due to disconnection! Peer: {:?}",
                    peer_network_id
                )));
        }

        // Update the number of active subscribers for each network
        let active_subscribers = self.get_active_subscribers();
        for network_id in peers_and_metadata.get_registered_networks() {
            // Calculate the number of active subscribers for the network
            let num_active_subscribers = active_subscribers
                .iter()
                .filter(|peer_network_id| peer_network_id.network_id() == network_id)
                .count() as i64;

            // Update the active subscriber metric
            metrics::set_gauge(
                &metrics::PUBLISHER_NUM_ACTIVE_SUBSCRIBERS,
                &network_id,
                num_active_subscribers,
            );
        }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L212-232)
```rust
    pub fn publish_message(&self, message: ConsensusObserverDirectSend) {
        // Get the active subscribers
        let active_subscribers = self.get_active_subscribers();

        // Send the message to all active subscribers
        for peer_network_id in &active_subscribers {
            // Send the message to the outbound receiver for publishing
            let mut outbound_message_sender = self.outbound_message_sender.clone();
            if let Err(error) =
                outbound_message_sender.try_send((*peer_network_id, message.clone()))
            {
                // The message send failed
                warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::SendDirectSendMessage)
                        .message(&format!(
                            "Failed to send outbound message to the receiver for peer {:?}! Error: {:?}",
                            peer_network_id, error
                    )));
            }
        }
    }
```

**File:** config/src/config/consensus_observer_config.rs (L68-68)
```rust
            max_network_channel_size: 1000,
```

**File:** config/src/config/consensus_observer_config.rs (L112-117)
```rust
            NodeType::Validator => {
                if ENABLE_ON_VALIDATORS && !publisher_manually_set {
                    // Only enable the publisher for validators
                    consensus_observer_config.publisher_enabled = true;
                    modified_config = true;
                }
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L128-146)
```rust
/// Types of direct sends that can be sent between the consensus publisher and observer
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
pub enum ConsensusObserverDirectSend {
    OrderedBlock(OrderedBlock),
    CommitDecision(CommitDecision),
    BlockPayload(BlockPayload),
    OrderedBlockWithWindow(OrderedBlockWithWindow),
}

impl ConsensusObserverDirectSend {
    /// Returns a summary label for the direct send
    pub fn get_label(&self) -> &'static str {
        match self {
            ConsensusObserverDirectSend::OrderedBlock(_) => "ordered_block",
            ConsensusObserverDirectSend::CommitDecision(_) => "commit_decision",
            ConsensusObserverDirectSend::BlockPayload(_) => "block_payload",
            ConsensusObserverDirectSend::OrderedBlockWithWindow(_) => "ordered_block_with_window",
        }
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L400-406)
```rust
        if let Some(consensus_publisher) = &self.consensus_publisher {
            let message = ConsensusObserverMessage::new_ordered_block_message(
                ordered_blocks.clone(),
                ordered_proof.clone(),
            );
            consensus_publisher.publish_message(message);
        }
```
