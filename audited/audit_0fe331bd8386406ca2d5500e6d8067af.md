# Audit Report

## Title
Unbounded Channel Memory Exhaustion in Indexer Masked by Misleading TIMER Metrics

## Summary
The internal indexer uses an unbounded channel between batch preparation and database writes, combined with a TIMER metric that only measures batch preparation time. This allows attackers to trigger resource exhaustion by submitting high-volume transactions that overwhelm the write pipeline, while monitoring metrics incorrectly indicate healthy operation. The vulnerability breaks the Resource Limits invariant and enables denial-of-service attacks masked from detection.

## Finding Description

The indexer's `DBIndexer` component contains a critical architectural flaw in how it measures performance and handles write throughput:

**Root Cause 1: Unbounded Channel** [1](#0-0) 

The channel created here is unbounded (Rust's `mpsc::channel()` without capacity argument), allowing unlimited batches to queue without backpressure.

**Root Cause 2: Misleading Timer Scope** [2](#0-1) 

The TIMER metric starts here and measures only batch preparation (reading from main DB, processing transactions/events, creating SchemaBatch). [3](#0-2) 

The batch is sent to the unbounded channel and the function returns immediately, stopping the TIMER. The actual database write happens asynchronously in a separate thread.

**Root Cause 3: Async Write Without Monitoring** [4](#0-3) 

The actual database write occurs here in the DBCommitter thread, completely separate from where the TIMER was measured. If this write is slow or fails, the TIMER has already recorded "success."

**Attack Vector for State Keys:** [5](#0-4) 

When processing state updates, the indexer writes all created/modified state keys to StateKeysSchema. An attacker can craft transactions that create large write sets, causing:
1. Fast batch preparation (quick iteration and SchemaBatch creation)
2. Slow database writes (many keys, RocksDB write amplification, compaction triggers)
3. TIMER shows fast latencies while DBCommitter falls behind
4. Unbounded channel accumulates batches, consuming memory

**How State Corruption Is Masked:**

The validation tooling expects the indexer to track all state keys: [6](#0-5) 

If the indexer falls behind or crashes due to the unbounded queue, state keys will be missing from the internal indexer. However, operators monitoring the TIMER metric will see "healthy" fast latencies throughout the attack, masking:
- Indexer falling behind the main chain
- Memory exhaustion in progress  
- Missing state keys that will fail validation
- Impending system crash

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria

This vulnerability enables:

1. **Denial of Service**: Unbounded memory growth leads to OOM crash or severe performance degradation of the indexer service
2. **State Inconsistency**: Indexer falls behind main DB, causing API queries to return stale/incomplete data
3. **Masked Failures**: Monitoring systems relying on TIMER metrics fail to detect the attack in progress
4. **Operational Impact**: Node operators experience unexplained crashes without warning indicators

This qualifies as **"State inconsistencies requiring intervention"** under Medium severity, as the indexer is critical for API functionality and state queries. While it doesn't directly affect consensus or steal funds, it:
- Breaks the Resource Limits invariant (unbounded memory consumption)
- Causes availability issues for API clients
- Requires node restart and manual intervention
- Could mask actual state corruption from other sources

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly exploitable because:

1. **Low Attack Barrier**: Any user can submit transactions that create state updates through normal smart contract interactions
2. **No Special Access Required**: No validator privileges or insider access needed
3. **Realistic Attack Pattern**: Legitimate-looking transactions (e.g., NFT minting, token transfers) naturally create many state keys
4. **Difficult to Detect**: TIMER metrics show "healthy" operation during attack
5. **Amplification Effect**: Single transaction can create dozens of state keys, multiplying impact
6. **No Cost-Prohibitive Defense**: While transactions cost gas, the memory exhaustion impact is disproportionate

An attacker could sustain this attack by:
- Deploying contracts that create many state keys per transaction
- Submitting high-frequency transactions during network congestion
- Targeting periods when database writes are naturally slower (compaction cycles)

## Recommendation

**Immediate Fixes:**

1. **Replace unbounded channel with bounded channel:**
```rust
// In DBIndexer::new()
let (sender, receiver) = mpsc::sync_channel(100); // Add backpressure
```

2. **Add timer for actual writes in DBCommitter:**
```rust
// In DBCommitter::run()
pub fn run(&self) {
    loop {
        let batch_opt = self.receiver.recv()
            .expect("Failed to receive batch from DB Indexer");
        if let Some(batch) = batch_opt {
            let _timer = TIMER.timer_with(&["db_commit"]);
            self.db.write_schemas(batch)
                .expect("Failed to write batch to indexer db");
        } else {
            break;
        }
    }
}
```

3. **Add queue depth monitoring:**
```rust
// Add metrics for channel depth
pub static INDEXER_QUEUE_DEPTH: Lazy<IntGaugeVec> = Lazy::new(|| {
    register_int_gauge_vec!(
        "aptos_indexer_queue_depth",
        "Number of batches queued for writing",
        &["name"]
    ).unwrap()
});

// Update before send
INDEXER_QUEUE_DEPTH.with_label_values(&["pending"]).set(queue_len as i64);
```

4. **Add health check for committer thread:**
```rust
// Periodically verify committer thread is alive and processing
// Add timeout for batch processing
```

**Long-term Improvements:**
- Implement end-to-end latency tracking from batch creation to DB commit
- Add alerting for queue depth thresholds
- Consider batching strategies to reduce write amplification
- Add rate limiting for state key creation per transaction

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_indexer_queue_exhaustion() {
    // Setup indexer with monitoring
    let indexer_db = create_test_indexer_db();
    let main_db = create_test_main_db();
    let indexer = DBIndexer::new(indexer_db, main_db);
    
    // Simulate slow DB writes by adding delay in test DB implementation
    // Create transactions with large write sets
    let num_txns = 10000;
    let keys_per_txn = 100;
    
    let start_memory = get_process_memory();
    let start_time = Instant::now();
    
    // Submit transactions rapidly
    for i in 0..num_txns {
        let writeset = create_writeset_with_n_keys(keys_per_txn);
        let txn = create_transaction(writeset);
        
        // Process batch - should be fast per TIMER metric
        indexer.process_a_batch(i, i+1).unwrap();
        
        // Check TIMER shows fast latencies
        let timer_value = get_timer_metric("process_a_batch");
        assert!(timer_value < 0.1); // Sub-100ms
    }
    
    let processing_time = start_time.elapsed();
    let memory_growth = get_process_memory() - start_memory;
    
    // Verify vulnerability:
    // 1. TIMER shows fast processing
    assert!(processing_time.as_secs() < 10); // Fast batch preparation
    
    // 2. But memory has grown unboundedly (batches queued)
    assert!(memory_growth > 100_000_000); // >100MB of queued batches
    
    // 3. DBCommitter is behind (check queue depth via channel inspection)
    let pending_batches = get_channel_depth();
    assert!(pending_batches > num_txns / 2); // More than half still pending
    
    // This demonstrates: TIMER shows "healthy" but system is exhausted
}
```

**Notes:**
- The vulnerability exists in the architectural decision to use unbounded channels with async writes
- TIMER metric provides false assurance of system health
- The actual write latency is measured by a different metric (APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS) that operators may not monitor
- State snapshot restoration via `write_keys_to_indexer_db()` has no TIMER at all, creating additional blind spots
- This design breaks the Resource Limits invariant by allowing unbounded memory consumption

### Citations

**File:** storage/indexer/src/db_indexer.rs (L69-71)
```rust
                self.db
                    .write_schemas(batch)
                    .expect("Failed to write batch to indexer db");
```

**File:** storage/indexer/src/db_indexer.rs (L328-328)
```rust
        let (sender, reciver) = mpsc::channel();
```

**File:** storage/indexer/src/db_indexer.rs (L411-411)
```rust
        let _timer: aptos_metrics_core::HistogramTimer = TIMER.timer_with(&["process_a_batch"]);
```

**File:** storage/indexer/src/db_indexer.rs (L489-496)
```rust
            if self.indexer_db.statekeys_enabled() {
                writeset.write_op_iter().for_each(|(state_key, write_op)| {
                    if write_op.is_creation() || write_op.is_modification() {
                        batch
                            .put::<StateKeysSchema>(state_key, &())
                            .expect("Failed to put state keys to a batch");
                    }
                });
```

**File:** storage/indexer/src/db_indexer.rs (L546-549)
```rust
        self.sender
            .send(Some(batch))
            .map_err(|e| AptosDbError::Other(e.to_string()))?;
        Ok(version)
```

**File:** storage/aptosdb/src/db_debugger/validation.rs (L114-146)
```rust
pub fn verify_state_kvs(
    db_root_path: &Path,
    internal_db: &DB,
    target_ledger_version: u64,
) -> Result<()> {
    println!("Validating db statekeys");
    let storage_dir = StorageDirPaths::from_path(db_root_path);
    let state_kv_db =
        StateKvDb::open_sharded(&storage_dir, RocksdbConfig::default(), None, None, false)?;

    //read all statekeys from internal db and store them in mem
    let mut all_internal_keys = HashSet::new();
    let mut iter = internal_db.iter::<StateKeysSchema>()?;
    iter.seek_to_first();
    for (key_ind, state_key_res) in iter.enumerate() {
        let state_key = state_key_res?.0;
        let state_key_hash = state_key.hash();
        all_internal_keys.insert(state_key_hash);
        if key_ind % 10_000_000 == 0 {
            println!("Processed {} keys", key_ind);
        }
    }
    println!(
        "Number of state keys in internal db: {}",
        all_internal_keys.len()
    );
    for shard_id in 0..16 {
        let shard = state_kv_db.db_shard(shard_id);
        println!("Validating state_kv for shard {}", shard_id);
        verify_state_kv(shard, &all_internal_keys, target_ledger_version)?;
    }
    Ok(())
}
```
