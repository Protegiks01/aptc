# Audit Report

## Title
DKG Denial-of-Service via Unvalidated Witness Size in Sigma Protocol Verification

## Summary
The DKG (Distributed Key Generation) proof verification code performs multiple expensive clone operations on nested vector structures (`Vec<Vec<Vec<Scalar>>>`) from untrusted proof data without validating their size. A malicious validator can craft oversized witnesses in DKG transcripts to exhaust memory and CPU resources on other validators during epoch transitions, causing denial-of-service.

## Finding Description

The vulnerability exists in the sigma protocol verification path used by the DKG weighted transcript verification. When verifying a DKG transcript's Proof of Knowledge (PoK), the code performs multiple complete clones of large nested vector structures without first validating their size.

**Attack Flow:**

1. A malicious validator creates a DKG transcript with a `SharingProof` containing an oversized `HkzgWeightedElgamalWitness` in the `SoK.z` field
2. The witness contains `chunked_plaintexts: Vec<Vec<Vec<Scalar<F>>>>` with arbitrarily large dimensions
3. The transcript is broadcast to other validators and passes initial deserialization (fits within 64 MiB network limit)
4. During verification, `hom.verify()` is called which triggers `msm_terms(&proof.z)`
5. The `msm_terms` method calls projection functions that clone the entire witness structure **twice**:
   - First projection clones via `.flatten().flatten().cloned()` [1](#0-0) 
   - Second projection clones via `.clone()` [2](#0-1) 
6. These clones happen **before** any cryptographic verification that would detect the invalid witness
7. Each validator attempting to verify the malicious transcript experiences memory exhaustion and CPU starvation

**Missing Validation:**

The verification code checks `self.subtrs.Cs.len()` and `self.subtrs.Vs.len()` against expected values [3](#0-2) , but does **not** validate the `proof.z` witness size before it gets cloned during `msm_terms()` [4](#0-3) .

**Code Path:**
- `WeightedTranscript::verify()` → `hom.verify()` [5](#0-4) 
- → `Trait::verify()` → `msm_terms_for_verify()` [6](#0-5) 
- → `msm_terms(&proof.z)` [4](#0-3) 
- → `TupleHomomorphism::msm_terms()` [7](#0-6) 
- → `LiftHomomorphism::msm_terms()` (calls projection) [8](#0-7) 
- → Projection closures clone the witness [9](#0-8) 

## Impact Explanation

**Severity: Medium**

This vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

**Impact:**
- **DKG Liveness Failure**: During epoch transitions, all validators must successfully complete DKG to transition to the next epoch. A malicious validator can prevent epoch transitions by causing other validators to crash or hang during transcript verification.
- **Validator Resource Exhaustion**: Victims experience memory exhaustion (potentially 192+ MiB per malicious transcript with 2x cloning) and excessive CPU usage from allocating and copying large nested vectors.
- **State Inconsistencies**: Failed DKG prevents proper validator set updates, requiring manual intervention to restore network operation.

The vulnerability qualifies as **Medium severity** per the Aptos bug bounty criteria: "State inconsistencies requiring intervention" - failed DKG creates an inconsistent state where the network cannot progress to the next epoch.

While this doesn't directly cause consensus safety violations or fund loss, it impacts network availability during critical epoch transitions, which is a significant operational concern.

## Likelihood Explanation

**Likelihood: High**

The attack is straightforward to execute:
1. Requires only a single malicious validator (within Byzantine fault tolerance assumptions of ≤1/3 malicious validators)
2. No exploitation complexity - simply craft a transcript with oversized vectors
3. Automatically triggered during normal DKG verification flow
4. No rate limiting or resource checks prevent repeated attempts
5. Affects all validators that attempt to verify the malicious transcript

DKG occurs during every epoch transition (approximately every 2 hours on mainnet), providing regular opportunities for attack.

## Recommendation

**Solution: Add witness size validation before cloning**

Add validation in `msm_terms_for_verify()` to check the witness dimensions against expected bounds before calling `msm_terms()`: [10](#0-9) 

Insert validation after line 118 (after extracting prover_first_message):

```rust
// Validate witness dimensions before expensive cloning operations
if let Some(max_witness_size) = self.max_expected_witness_size() {
    let witness_size = proof.z.serialized_size(Compress::No);
    ensure!(
        witness_size <= max_witness_size,
        "Witness size {} exceeds maximum expected size {}",
        witness_size,
        max_witness_size
    );
}
```

For the specific DKG case, add validation in `WeightedTranscript::verify()` before the `hom.verify()` call: [11](#0-10) 

Insert validation after line 171 (after creating the homomorphism):

```rust
// Validate witness dimensions match expected DKG parameters
let witness = &self.sharing_proof.SoK.z;
ensure!(
    witness.chunked_plaintexts.len() == sc.get_total_num_players(),
    "Witness has {} player chunks, expected {}",
    witness.chunked_plaintexts.len(),
    sc.get_total_num_players()
);

let expected_chunks = num_chunks_per_scalar::<E::ScalarField>(pp.ell);
ensure!(
    witness.elgamal_randomness.len() <= sc.get_max_weight(),
    "Witness has {} randomness vectors, expected at most {}",
    witness.elgamal_randomness.len(),
    sc.get_max_weight()
);

for (i, player_chunks) in witness.chunked_plaintexts.iter().enumerate() {
    let expected_weight = sc.get_player_weight(&sc.get_player(i));
    ensure!(
        player_chunks.len() == expected_weight,
        "Player {} has {} weight chunks, expected {}",
        i,
        player_chunks.len(),
        expected_weight
    );
    
    for chunk_vec in player_chunks {
        ensure!(
            chunk_vec.len() == expected_chunks,
            "Invalid chunk size: {} instead of {}",
            chunk_vec.len(),
            expected_chunks
        );
    }
}
```

## Proof of Concept

```rust
// Proof of Concept: DKG DoS via Oversized Witness
// File: crates/aptos-dkg/tests/dos_oversized_witness.rs

use aptos_crypto::bls12381::Bls12381;
use aptos_dkg::pvss::chunky::{
    hkzg_chunked_elgamal::HkzgWeightedElgamalWitness,
    weighted_transcript::{SharingProof, Transcript},
};
use aptos_dkg::sigma_protocol::{traits::FirstProofItem, Proof};
use aptos_dkg::Scalar;
use ark_ff::UniformRand;

#[test]
fn test_oversized_witness_dos() {
    let mut rng = rand::thread_rng();
    
    // Create a malicious witness with 1000x more data than expected
    let malicious_witness = HkzgWeightedElgamalWitness {
        hkzg_randomness: Default::default(),
        // Instead of ~100 players, create 10,000
        chunked_plaintexts: (0..10_000)
            .map(|_| {
                // Instead of ~100 weight, create 1,000
                (0..1_000)
                    .map(|_| {
                        // Create 100 chunks each
                        (0..100)
                            .map(|_| Scalar(Bls12381::ScalarField::rand(&mut rng)))
                            .collect()
                    })
                    .collect()
            })
            .collect(),
        elgamal_randomness: vec![
            vec![Scalar(Bls12381::ScalarField::rand(&mut rng)); 100]; 
            10_000
        ],
    };
    
    // This witness will consume:
    // 10,000 * 1,000 * 100 * 32 bytes = 32 GB of data
    // When cloned twice, requires 96 GB of allocations
    
    let proof = Proof {
        first_proof_item: FirstProofItem::Commitment(/* ... */),
        z: malicious_witness,
    };
    
    // Measure time and memory before verification
    let start = std::time::Instant::now();
    let start_memory = /* measure memory */;
    
    // Trigger verification - this will cause excessive cloning
    // The cloning happens in the projection functions before
    // any cryptographic checks that would reject the invalid proof
    let result = /* call verify with malicious proof */;
    
    let duration = start.elapsed();
    let memory_used = /* measure memory delta */;
    
    // Demonstration: verification takes excessive time and memory
    // even though the proof is invalid
    assert!(duration.as_secs() > 10); // Takes many seconds just to clone
    assert!(memory_used > 1_000_000_000); // Uses over 1 GB
}
```

**Attack Scenario:**
1. Malicious validator creates transcript with witness containing 10,000 × 1,000 × 100 = 1 billion scalars (32 GB)
2. Serialized size: ~32 GB compressed, may fit in multiple network messages
3. Each validator attempting verification allocates 32 GB × 2 clones = 64 GB
4. With 100 validators, sustained attack exhausts cluster resources
5. DKG fails, epoch transition halts, network requires manual intervention

## Notes

The vulnerability is specific to the DKG weighted transcript verification path. The root cause is the design pattern of using projection functions within `LiftHomomorphism` that unconditionally clone witness data before validation. While this pattern is elegant for code reuse, it creates a DoS vector when applied to untrusted input.

The fix requires adding dimension validation **before** the projection functions are called, ensuring that witness sizes match the expected DKG parameters (number of players, weights, chunk counts) derived from the `SecretSharingConfig`.

Alternative mitigation: Implement lazy projection using references instead of cloning, but this requires significant refactoring of the homomorphism trait hierarchy.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/hkzg_chunked_elgamal.rs (L204-234)
```rust
            projection: |dom: &HkzgWeightedElgamalWitness<E::ScalarField>| {
                let HkzgWeightedElgamalWitness {
                    hkzg_randomness,
                    chunked_plaintexts,
                    ..
                } = dom;
                let flattened_chunked_plaintexts: Vec<Scalar<E::ScalarField>> =
                    std::iter::once(Scalar(E::ScalarField::ZERO))
                        .chain(chunked_plaintexts.iter().flatten().flatten().cloned())
                        .collect();
                univariate_hiding_kzg::Witness::<E::ScalarField> {
                    hiding_randomness: hkzg_randomness.clone(),
                    values: flattened_chunked_plaintexts,
                }
            },
        };
        // Set up the chunked_elgamal homomorphism, and use a projection map to lift it to HkzgElgamalWitness
        let lifted_chunked_elgamal = LiftedWeightedChunkedElgamal::<E::G1> {
            hom: chunked_elgamal::WeightedHomomorphism { pp, eks },
            // The projection map simply ignores the `hkzg_randomness` component
            projection: |dom: &HkzgWeightedElgamalWitness<E::ScalarField>| {
                let HkzgWeightedElgamalWitness {
                    chunked_plaintexts,
                    elgamal_randomness,
                    ..
                } = dom;
                chunked_elgamal::WeightedWitness {
                    plaintext_chunks: chunked_plaintexts.clone(),
                    plaintext_randomness: elgamal_randomness.clone(),
                }
            },
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L140-153)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L163-190)
```rust
        {
            // Verify the PoK
            let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
            let lagr_g1: &[E::G1Affine] = match &pp.pk_range_proof.ck_S.msm_basis {
                SrsBasis::Lagrange { lagr: lagr_g1 } => lagr_g1,
                SrsBasis::PowersOfTau { .. } => {
                    bail!("Expected a Lagrange basis, received powers of tau basis instead")
                },
            };
            let hom = hkzg_chunked_elgamal::WeightedHomomorphism::<E>::new(
                lagr_g1,
                pp.pk_range_proof.ck_S.xi_1,
                &pp.pp_elgamal,
                &eks_inner,
            );
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    self.sharing_proof.range_proof_commitment.clone(),
                    chunked_elgamal::WeightedCodomainShape {
                        chunks: self.subtrs.Cs.clone(),
                        randomness: self.subtrs.Rs.clone(),
                    },
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L61-65)
```rust
        let msm_terms = self.msm_terms_for_verify::<_, H>(
            public_statement,
            proof,
            cntxt,
        );
```

**File:** crates/aptos-dkg/src/sigma_protocol/traits.rs (L104-133)
```rust
    fn msm_terms_for_verify<Ct: Serialize, H>(
        &self,
        public_statement: &Self::Codomain,
        proof: &Proof<C::ScalarField, H>,
        cntxt: &Ct,
    ) -> Self::MsmInput
    where
        H: homomorphism::Trait<Domain = Self::Domain, Codomain = Self::Codomain>, // Need this because the lifetime was changed
    {
        let prover_first_message = match &proof.first_proof_item {
            FirstProofItem::Commitment(A) => A,
            FirstProofItem::Challenge(_) => {
                panic!("Missing implementation - expected commitment, not challenge")
            },
        };

        let number_of_beta_powers = public_statement.clone().into_iter().count(); // TODO: maybe pass the into_iter version in merge_msm_terms?

        let (c, powers_of_beta) = self.compute_verifier_challenges(public_statement, prover_first_message, cntxt, number_of_beta_powers);

        let msm_terms_for_prover_response = self.msm_terms(&proof.z);

        Self::merge_msm_terms(
            msm_terms_for_prover_response.into_iter().collect(),
            prover_first_message,
            public_statement,
            &powers_of_beta,
            c,
        )
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L202-206)
```rust
    fn msm_terms(&self, input: &Self::Domain) -> Self::CodomainShape<Self::MsmInput> {
        let terms1 = self.hom1.msm_terms(input);
        let terms2 = self.hom2.msm_terms(input);
        TupleCodomainShape(terms1, terms2)
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/fixed_base_msms.rs (L111-114)
```rust
    fn msm_terms(&self, input: &Self::Domain) -> Self::CodomainShape<Self::MsmInput> {
        let projected = (self.projection)(input);
        self.hom.msm_terms(&projected)
    }
```
