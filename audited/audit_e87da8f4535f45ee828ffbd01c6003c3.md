# Audit Report

## Title
Transaction Resurrection DoS: Infinite Loop of Expired Transaction Re-additions via Network Broadcast

## Summary
The mempool's `gc()` function removes expired transactions but lacks a blacklist mechanism to prevent their re-addition through network broadcasts. This allows expired transactions to be perpetually resurrected, creating an infinite loop of additions and removals that exhausts node resources.

## Finding Description

The vulnerability exists in the interaction between three mempool components:

**1. Garbage Collection removes transactions without tracking expiration history:** [1](#0-0) 

The `gc()` function calls into the transaction store's garbage collection: [2](#0-1) 

When transactions expire, they are completely removed from all indexes with no persistent record of their prior expiration.

**2. Transaction re-addition resets expiration time without checking history:** [3](#0-2) 

Each time a transaction is added via `add_txn()`, a **new** expiration time is calculated based on the current system time plus the configured timeout. There is no check to see if this transaction was previously expired and removed.

**3. Network broadcasts propagate transactions without expiration awareness:** [4](#0-3) 

The broadcast mechanism reads transactions from the timeline index without checking if they are approaching expiration or have been previously expired.

**4. Incoming transactions from peers bypass expiration history checks:** [5](#0-4) 

When processing incoming transactions from network broadcasts, the only validations are:
- Transaction filter checks
- Sequence number validation (checking if >= current on-chain sequence number)
- VM validation

There is **no check** for whether this transaction was previously expired and removed.

**Attack Scenario:**

1. Attacker submits transaction T to Node A at time T₀ with a valid sequence number
2. Node A validates and adds T with `expiration_time = T₀ + system_transaction_timeout` (e.g., 86400 seconds)
3. Node A broadcasts T to Node B
4. At T₀ + 86400s, Node A's `gc()` removes T from mempool
5. Shortly after, Node B broadcasts T back to Node A (different gc timing or retry broadcast)
6. Node A receives T from Node B:
   - Sequence number check passes (transaction not yet committed on-chain)
   - VM validation passes (transaction is still valid)
   - `add_txn()` accepts it with **NEW** `expiration_time = current_time + 86400s`
7. Transaction expires again, gets removed by gc
8. Node B or other peers re-broadcast it
9. Cycle repeats indefinitely until transaction is committed or client-specified expiration passes

The attacker can amplify this by submitting many transactions with sequence numbers that will never be committed (e.g., from accounts they don't control), causing continuous resource waste across the network.

## Impact Explanation

**Medium Severity** - This qualifies as "State inconsistencies requiring intervention" per the Aptos bug bounty program:

- **Resource Exhaustion**: Each re-addition triggers:
  - VM validation (CPU cost)
  - Index updates across multiple data structures (CPU + memory)
  - Timeline index modifications (memory allocation)
  - Network bandwidth for broadcasts
  
- **Availability Impact**: With sufficient expired transactions in the resurrection loop, nodes experience:
  - Degraded mempool performance
  - Increased latency for legitimate transaction processing
  - Memory pressure from repeatedly allocating/deallocating transaction metadata

- **Network Amplification**: Each node in the network can perpetuate the resurrection of expired transactions, creating a distributed DoS effect

The issue does NOT directly cause:
- Consensus violations (transactions are still validated correctly)
- Fund loss or theft
- Network partition requiring hardfork

Therefore, it correctly falls under **Medium** severity.

## Likelihood Explanation

**High Likelihood** of occurrence:

- **No special privileges required**: Any user can submit transactions
- **Natural network conditions trigger it**: Different nodes have different gc timing due to:
  - Clock skew
  - Different load causing gc delays
  - Retry/backoff mechanisms in broadcast protocol
  
- **Long-lived transactions common**: Transactions with 24-hour expiration (default `system_transaction_timeout_secs`) are standard, increasing the window for resurrection

- **No existing mitigation**: Code analysis shows no blacklist, bloom filter, or any mechanism to prevent re-addition

The only factors limiting exploitation are:
- Transaction must have valid sequence number not yet committed
- Client-specified expiration timestamp must not have passed

## Recommendation

Implement a time-bounded blacklist to track expired transaction hashes and reject re-addition:

```rust
// In TransactionStore struct, add:
expired_tx_blacklist: HashMap<HashValue, SystemTime>, // hash -> expiration time

// In gc() method, after removing transactions:
for key in gc_txns.iter() {
    if let Some(txn) = self.get_mempool_txn(&key.address, key.replay_protector) {
        // Add to blacklist with TTL = 2x system_transaction_timeout
        // to handle clock skew and delayed broadcasts
        self.expired_tx_blacklist.insert(
            txn.get_committed_hash(), 
            SystemTime::now() + self.system_transaction_timeout * 2
        );
    }
}

// In insert() method, before adding transaction:
let tx_hash = txn.get_committed_hash();
if let Some(blacklist_expiry) = self.expired_tx_blacklist.get(&tx_hash) {
    if SystemTime::now() < *blacklist_expiry {
        return MempoolStatus::new(MempoolStatusCode::InvalidUpdate)
            .with_message("Transaction was previously expired and is blacklisted".to_string());
    }
}

// Periodically clean blacklist in gc():
self.expired_tx_blacklist.retain(|_, expiry_time| {
    SystemTime::now() < *expiry_time
});
```

Alternative lightweight solution: Use a time-bounded Bloom filter instead of HashMap for memory efficiency, accepting small false positive rate.

## Proof of Concept

```rust
#[cfg(test)]
mod transaction_resurrection_test {
    use super::*;
    use aptos_types::{
        account_address::AccountAddress,
        transaction::{RawTransaction, SignedTransaction, Script},
        chain_id::ChainId,
    };
    use aptos_crypto::{ed25519::Ed25519PrivateKey, PrivateKey, Uniform};
    use std::time::{Duration, SystemTime};

    #[test]
    fn test_expired_transaction_resurrection() {
        // Create mempool with short timeout for testing
        let mut config = NodeConfig::default();
        config.mempool.system_transaction_timeout_secs = 1; // 1 second timeout
        let mut mempool = Mempool::new(&config);
        
        // Create a transaction
        let sender = AccountAddress::random();
        let private_key = Ed25519PrivateKey::generate_for_testing();
        let raw_txn = RawTransaction::new(
            sender,
            0, // sequence number
            TransactionPayload::Script(Script::new(vec![], vec![], vec![])),
            100000,
            1,
            u64::MAX,
            ChainId::test(),
        );
        let signed_txn = SignedTransaction::new(
            raw_txn,
            private_key.public_key(),
            private_key.sign(&raw_txn).unwrap(),
        );
        
        // Add transaction to mempool
        let status1 = mempool.add_txn(
            signed_txn.clone(),
            100,
            Some(0), // account sequence number
            TimelineState::NotReady,
            false,
            None,
            None,
        );
        assert_eq!(status1.code, MempoolStatusCode::Accepted);
        
        // Wait for expiration
        std::thread::sleep(Duration::from_secs(2));
        
        // Run garbage collection
        mempool.gc();
        
        // Verify transaction was removed
        let tx_hash = signed_txn.committed_hash();
        assert!(mempool.get_by_hash(tx_hash).is_none());
        
        // Simulate receiving the same transaction from network broadcast
        // (with updated expiration time as would happen in real scenario)
        let status2 = mempool.add_txn(
            signed_txn.clone(),
            100,
            Some(0), // account sequence number still 0 (not committed)
            TimelineState::NotReady,
            false,
            None,
            None,
        );
        
        // VULNERABILITY: Transaction is accepted again despite being previously expired
        assert_eq!(status2.code, MempoolStatusCode::Accepted);
        
        // This can repeat indefinitely, creating resource exhaustion
    }
}
```

**Notes**

This vulnerability represents a real DoS vector where the mempool's lack of expiration history tracking allows perpetual transaction resurrection. The attack is particularly insidious because it leverages normal network broadcast behavior and requires no special access or capabilities. The fix requires adding state to track recently expired transactions, with appropriate TTL management to prevent the blacklist itself from becoming a memory leak.

### Citations

**File:** mempool/src/core_mempool/mempool.rs (L332-346)
```rust
        let now = SystemTime::now();
        let expiration_time =
            aptos_infallible::duration_since_epoch_at(&now) + self.system_transaction_timeout;

        let sender = txn.sender();
        let txn_info = MempoolTransaction::new(
            txn.clone(),
            expiration_time,
            ranking_score,
            timeline_state,
            now,
            client_submitted,
            priority.clone(),
        );

```

**File:** mempool/src/core_mempool/mempool.rs (L590-593)
```rust
    pub(crate) fn gc(&mut self) {
        let now = aptos_infallible::duration_since_epoch();
        self.transactions.gc_by_system_ttl(now);
    }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L913-1006)
```rust
    fn gc(&mut self, now: Duration, by_system_ttl: bool) {
        let (metric_label, index, log_event) = if by_system_ttl {
            (
                counters::GC_SYSTEM_TTL_LABEL,
                &mut self.system_ttl_index,
                LogEvent::SystemTTLExpiration,
            )
        } else {
            (
                counters::GC_CLIENT_EXP_LABEL,
                &mut self.expiration_time_index,
                LogEvent::ClientExpiration,
            )
        };
        counters::CORE_MEMPOOL_GC_EVENT_COUNT
            .with_label_values(&[metric_label])
            .inc();

        let mut gc_txns = index.gc(now);
        // sort the expired txns by order of replay protector per account
        gc_txns.sort_by_key(|key| (key.address, key.replay_protector));
        let mut gc_iter = gc_txns.iter().peekable();

        let mut gc_txns_log = match aptos_logger::enabled!(Level::Trace) {
            true => TxnsLog::new(),
            false => TxnsLog::new_with_max(10),
        };
        while let Some(key) = gc_iter.next() {
            if let Some(txns) = self.transactions.get_mut(&key.address) {
                // If a sequence number transaction is garbage collected, then its subsequent transactions are marked as non-ready.
                // As orderless transactions (transactions with nonce) are always ready, they are not affected by this.
                if let ReplayProtector::SequenceNumber(seq_num) = key.replay_protector {
                    let park_range_start = Bound::Excluded(seq_num);
                    let park_range_end = gc_iter
                        .peek()
                        .filter(|next_key| key.address == next_key.address)
                        .map_or(Bound::Unbounded, |next_key| {
                            match next_key.replay_protector {
                                ReplayProtector::SequenceNumber(next_seq_num) => {
                                    Bound::Excluded(next_seq_num)
                                },
                                ReplayProtector::Nonce(_) => Bound::Unbounded,
                            }
                        });
                    // mark all following txns as non-ready, i.e. park them
                    for (_, t) in txns.seq_num_range_mut((park_range_start, park_range_end)) {
                        self.parking_lot_index.insert(t);
                        self.priority_index.remove(t);
                        let sender_bucket = sender_bucket(&t.get_sender(), self.num_sender_buckets);
                        self.timeline_index
                            .get_mut(&sender_bucket)
                            .unwrap_or_else(|| {
                                panic!(
                                    "Unable to get the timeline index for the sender bucket {}",
                                    sender_bucket
                                )
                            })
                            .remove(t);
                        if let TimelineState::Ready(_) = t.timeline_state {
                            t.timeline_state = TimelineState::NotReady;
                        }
                    }
                }

                if let Some(txn) = txns.remove(&key.replay_protector) {
                    let is_active = self.priority_index.contains(&txn);
                    let status = if is_active {
                        counters::GC_ACTIVE_TXN_LABEL
                    } else {
                        counters::GC_PARKED_TXN_LABEL
                    };
                    let account = txn.get_sender();
                    gc_txns_log.add_with_status(account, txn.get_replay_protector(), status);
                    if let Ok(time_delta) =
                        SystemTime::now().duration_since(txn.insertion_info.insertion_time)
                    {
                        counters::CORE_MEMPOOL_GC_LATENCY
                            .with_label_values(&[metric_label, status])
                            .observe(time_delta.as_secs_f64());
                    }

                    // remove txn
                    self.index_remove(&txn);
                }
            }
        }

        if !gc_txns_log.is_empty() {
            debug!(LogSchema::event_log(LogEntry::GCRemoveTxns, log_event).txns(gc_txns_log));
        } else {
            trace!(LogSchema::event_log(LogEntry::GCRemoveTxns, log_event).txns(gc_txns_log));
        }
        self.track_indices();
    }
```

**File:** mempool/src/shared_mempool/network.rs (L539-545)
```rust
                            let (txns, new_timeline_id) = mempool.read_timeline(
                                sender_bucket,
                                old_timeline_id,
                                max_txns,
                                before,
                                peer_priority.clone(),
                            );
```

**File:** mempool/src/shared_mempool/tasks.rs (L304-404)
```rust
pub(crate) fn process_incoming_transactions<NetworkClient, TransactionValidator>(
    smp: &SharedMempool<NetworkClient, TransactionValidator>,
    transactions: Vec<(
        SignedTransaction,
        Option<u64>,
        Option<BroadcastPeerPriority>,
    )>,
    timeline_state: TimelineState,
    client_submitted: bool,
) -> Vec<SubmissionStatusBundle>
where
    NetworkClient: NetworkClientInterface<MempoolSyncMsg>,
    TransactionValidator: TransactionValidation,
{
    // Filter out any disallowed transactions
    let mut statuses = vec![];
    let transactions =
        filter_transactions(&smp.transaction_filter_config, transactions, &mut statuses);

    // If there are no transactions left after filtering, return early
    if transactions.is_empty() {
        return statuses;
    }

    let start_storage_read = Instant::now();
    let state_view = smp
        .db
        .latest_state_checkpoint_view()
        .expect("Failed to get latest state checkpoint view.");

    // Track latency: fetching seq number
    let account_seq_numbers = IO_POOL.install(|| {
        transactions
            .par_iter()
            .map(|(t, _, _)| match t.replay_protector() {
                ReplayProtector::Nonce(_) => Ok(None),
                ReplayProtector::SequenceNumber(_) => {
                    get_account_sequence_number(&state_view, t.sender())
                        .map(Some)
                        .inspect_err(|e| {
                            error!(LogSchema::new(LogEntry::DBError).error(e));
                            counters::DB_ERROR.inc();
                        })
                },
            })
            .collect::<Vec<_>>()
    });

    // Track latency for storage read fetching sequence number
    let storage_read_latency = start_storage_read.elapsed();
    counters::PROCESS_TXN_BREAKDOWN_LATENCY
        .with_label_values(&[counters::FETCH_SEQ_NUM_LABEL])
        .observe(storage_read_latency.as_secs_f64() / transactions.len() as f64);

    let transactions: Vec<_> = transactions
        .into_iter()
        .enumerate()
        .filter_map(|(idx, (t, ready_time_at_sender, priority))| {
            if let Ok(account_sequence_num) = account_seq_numbers[idx] {
                match account_sequence_num {
                    Some(sequence_num) => {
                        if t.sequence_number() >= sequence_num {
                            return Some((t, Some(sequence_num), ready_time_at_sender, priority));
                        } else {
                            statuses.push((
                                t,
                                (
                                    MempoolStatus::new(MempoolStatusCode::VmError),
                                    Some(DiscardedVMStatus::SEQUENCE_NUMBER_TOO_OLD),
                                ),
                            ));
                        }
                    },
                    None => {
                        return Some((t, None, ready_time_at_sender, priority));
                    },
                }
            } else {
                // Failed to get account's onchain sequence number
                statuses.push((
                    t,
                    (
                        MempoolStatus::new(MempoolStatusCode::VmError),
                        Some(DiscardedVMStatus::RESOURCE_DOES_NOT_EXIST),
                    ),
                ));
            }
            None
        })
        .collect();

    validate_and_add_transactions(
        transactions,
        smp,
        timeline_state,
        &mut statuses,
        client_submitted,
    );
    notify_subscribers(SharedMempoolNotification::NewTransactions, &smp.subscribers);
    statuses
}
```
