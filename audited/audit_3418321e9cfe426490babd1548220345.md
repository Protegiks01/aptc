# Audit Report

## Title
Missing Complaint Mechanism in DKG PVSS Protocol Violates Public Verifiability Guarantees

## Summary
The Aptos DKG (Distributed Key Generation) PVSS (Publicly Verifiable Secret Sharing) implementation lacks a complaint mechanism to allow validators to prove misbehavior when they detect invalid encryption keys or dealt shares. While transcript verification occurs before decryption, there is no protocol-level mechanism for validators to demonstrate that decryption failed without revealing their private decryption keys.

## Finding Description

The DKG protocol uses a multi-phase approach where transcript verification happens before share decryption: [1](#0-0) 

The `verify()` function performs cryptographic checks including:
- Proof of Knowledge (PoK) verification (lines 164-190)
- Range proof verification (lines 193-200)  
- Low-degree test (lines 206-216)
- Multi-pairing correctness checks (lines 240-283)

However, when validators decrypt their shares, the implementation uses a hard expectation: [2](#0-1) 

The BSGS discrete log computation returns `Option<Vec<u32>>`, returning `None` when it cannot find a solution: [3](#0-2) 

**Critical Gap:** When decryption fails (BSGS returns `None`), the validator crashes via `expect()` panic. There is no mechanism to:
1. Generate a zero-knowledge proof of decryption failure
2. Submit a complaint to other validators  
3. Prove the transcript is malformed without revealing the decryption key

In the epoch manager, decryption failures are caught but only logged: [4](#0-3) [5](#0-4) 

The error handling treats decryption failure as a local validator problem rather than potential dealer misbehavior that should be publicly attributable.

## Impact Explanation

**Severity: HIGH** per Aptos bug bounty criteria - "Significant protocol violations"

This violates fundamental PVSS security guarantees:

1. **Public Verifiability Violation**: PVSS protocols require that any misbehavior be publicly provable. The current implementation only allows private detection.

2. **No Accountability**: Validators cannot prove to the network that a dealer provided invalid shares, preventing consensus on which party misbehaved.

3. **Validator Availability Impact**: The `expect()` panic crashes the validator node when BSGS fails, causing "Validator node slowdowns" (HIGH severity per bounty).

4. **DKG Liveness Degradation**: Failed validators cannot participate in consensus while others proceed with a potentially flawed DKG result.

## Likelihood Explanation

**Likelihood: Medium**

While the cryptographic verifications should prevent malformed transcripts in normal operation, several scenarios could trigger this:

1. **Implementation bugs** in the crypto libraries could allow verification to pass for invalid data
2. **Precision/rounding errors** in chunked representations could cause out-of-range values
3. **Malicious dealer exploiting edge cases** in the verification logic
4. **Hardware failures** during decryption affecting BSGS table lookups

The lack of graceful error handling (`.expect()` causing panic) means any of these scenarios result in validator crashes rather than protocol-level complaint resolution.

## Recommendation

Implement a complaint mechanism with the following components:

1. **Replace panic with error handling**:
```rust
let dealt_chunked_secret_key_share = match bsgs::dlog_vec(
    pp.pp_elgamal.G.into_group(),
    &dealt_encrypted_secret_key_share_chunks,
    &pp.table,
    pp.get_dlog_range_bound(),
) {
    Some(chunks) => chunks,
    None => {
        // Generate complaint proof instead of panicking
        return Err(DecryptionError::BsgsFailure {
            player_id: player.id,
            ciphertext_index: i,
        });
    }
};
```

2. **Add zero-knowledge complaint proof**: Similar to the `EvalProof` mechanism used for encrypted transactions: [6](#0-5) 

Implement a `DecryptionComplaintProof` that proves a validator attempted decryption correctly but failed, without revealing the decryption key.

3. **Integrate complaint handling** into the DKG transcript aggregation: [7](#0-6) 

Add complaint verification before aggregating transcripts.

## Proof of Concept

The vulnerability can be demonstrated by examining the panic path:

```rust
// In weighted_transcript.rs decrypt_own_share()
// If BSGS returns None due to invalid ciphertext:
let dealt_chunked_secret_key_share = bsgs::dlog_vec(...)
    .expect("BSGS dlog failed"); // <-- PANICS HERE

// Validator crashes without generating complaint proof
// Other validators continue with potentially invalid DKG
```

Testing scenario:
1. Deploy modified dealer that encrypts out-of-range values for specific validators
2. Transcript passes all verification checks due to implementation gaps
3. Target validators crash during `decrypt_own_share()` 
4. Network cannot determine if validators have wrong keys or dealer is malicious
5. DKG fails without proper attribution of fault

**Notes**

While the cryptographic proofs should theoretically prevent invalid transcripts, the complete absence of a complaint mechanism violates the PVSS protocol's public verifiability guarantee and creates a protocol-level vulnerability. The use of `expect()` that crashes validators rather than gracefully handling decryption failures compounds this issue, qualifying as a HIGH severity protocol violation per the bug bounty criteria.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L124-286)
```rust
    #[allow(non_snake_case)]
    fn verify<A: Serialize + Clone>(
        &self,
        sc: &Self::SecretSharingConfig,
        pp: &Self::PublicParameters,
        spks: &[Self::SigningPubKey],
        eks: &[Self::EncryptPubKey],
        sid: &A,
    ) -> anyhow::Result<()> {
        if eks.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} encryption keys, but got {}",
                sc.get_total_num_players(),
                eks.len()
            );
        }
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }

        // Initialize the **identical** PVSS SoK context
        let sok_cntxt = (
            &spks[self.dealer.id],
            sid.clone(),
            self.dealer.id,
            DST.to_vec(),
        ); // As above, this is a bit hacky... though we have access to `self` now

        {
            // Verify the PoK
            let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
            let lagr_g1: &[E::G1Affine] = match &pp.pk_range_proof.ck_S.msm_basis {
                SrsBasis::Lagrange { lagr: lagr_g1 } => lagr_g1,
                SrsBasis::PowersOfTau { .. } => {
                    bail!("Expected a Lagrange basis, received powers of tau basis instead")
                },
            };
            let hom = hkzg_chunked_elgamal::WeightedHomomorphism::<E>::new(
                lagr_g1,
                pp.pk_range_proof.ck_S.xi_1,
                &pp.pp_elgamal,
                &eks_inner,
            );
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    self.sharing_proof.range_proof_commitment.clone(),
                    chunked_elgamal::WeightedCodomainShape {
                        chunks: self.subtrs.Cs.clone(),
                        randomness: self.subtrs.Rs.clone(),
                    },
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }

            // Verify the range proof
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
        }

        let mut rng = rand::thread_rng(); // TODO: make `rng` a parameter of fn verify()?

        // Do the SCRAPE LDT
        let ldt = LowDegreeTest::random(
            &mut rng,
            sc.get_threshold_weight(),
            sc.get_total_weight() + 1,
            true,
            &sc.get_threshold_config().domain,
        ); // includes_zero is true here means it includes a commitment to f(0), which is in V[n]
        let mut Vs_flat: Vec<_> = self.subtrs.Vs.iter().flatten().cloned().collect();
        Vs_flat.push(self.subtrs.V0);
        // could add an assert_eq here with sc.get_total_weight()
        ldt.low_degree_test_group(&Vs_flat)?;

        // let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
        // let hom = hkzg_chunked_elgamal::WeightedHomomorphism::new(
        //     &pp.pk_range_proof.ck_S.lagr_g1,
        //     pp.pk_range_proof.ck_S.xi_1,
        //     &pp.pp_elgamal,
        //     &eks_inner,
        // );
        // let (sigma_bases, sigma_scalars, beta_powers) = hom.verify_msm_terms(
        //         &TupleCodomainShape(
        //             self.sharing_proof.range_proof_commitment.clone(),
        //             chunked_elgamal::WeightedCodomainShape {
        //                 chunks: self.subtrs.Cs.clone(),
        //                 randomness: self.subtrs.Rs.clone(),
        //             },
        //         ),
        //         &self.sharing_proof.SoK,
        //         &sok_cntxt,
        //     );
        // let ldt_msm_terms = ldt.ldt_msm_input(&Vs_flat)?;
        // use aptos_crypto::arkworks::msm::verify_msm_terms_with_start;
        // verify_msm_terms_with_start(ldt_msm_terms, sigma_bases, sigma_scalars, beta_powers);

        // Now compute the final MSM // TODO: merge this multi_exp with the PoK verification, as in YOLO YOSO? // TODO2: and use the iterate stuff you developed? it's being forgotten here
        let mut base_vec = Vec::new();
        let mut exp_vec = Vec::new();

        let beta = sample_field_element(&mut rng);
        let powers_of_beta = utils::powers(beta, sc.get_total_weight() + 1);

        let Cs_flat: Vec<_> = self.subtrs.Cs.iter().flatten().cloned().collect();
        assert_eq!(
            Cs_flat.len(),
            sc.get_total_weight(),
            "Number of ciphertexts does not equal number of weights"
        ); // TODO what if zero weight?
           // could add an assert_eq here with sc.get_total_weight()

        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
        }

        let weighted_Cs = E::G1::msm(&E::G1::normalize_batch(&base_vec), &exp_vec)
            .expect("Failed to compute MSM of Cs in chunky");

        let weighted_Vs = E::G2::msm(
            &E::G2::normalize_batch(&Vs_flat[..sc.get_total_weight()]), // Don't use the last entry of `Vs_flat`
            &powers_of_beta[..sc.get_total_weight()],
        )
        .expect("Failed to compute MSM of Vs in chunky");

        let res = E::multi_pairing(
            [
                weighted_Cs.into_affine(),
                *pp.get_encryption_public_params().message_base(),
            ],
            [pp.get_commitment_base(), (-weighted_Vs).into_affine()],
        ); // Making things affine here rather than converting the two bases to group elements, since that's probably what they would be converted to anyway: https://github.com/arkworks-rs/algebra/blob/c1f4f5665504154a9de2345f464b0b3da72c28ec/ec/src/models/bls12/g1.rs#L14

        if PairingOutput::<E>::ZERO != res {
            return Err(anyhow::anyhow!("Expected zero during multi-pairing check"));
        }

        Ok(())
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L357-363)
```rust
            let dealt_chunked_secret_key_share = bsgs::dlog_vec(
                pp.pp_elgamal.G.into_group(),
                &dealt_encrypted_secret_key_share_chunks,
                &pp.table,
                pp.get_dlog_range_bound(),
            )
            .expect("BSGS dlog failed");
```

**File:** crates/aptos-dkg/src/dlog/bsgs.rs (L49-67)
```rust
#[allow(non_snake_case)]
pub fn dlog_vec<C: CurveGroup>(
    G: C,
    H_vec: &[C],
    baby_table: &HashMap<Vec<u8>, u32>,
    range_limit: u32,
) -> Option<Vec<u32>> {
    let mut result = Vec::with_capacity(H_vec.len());

    for H in H_vec {
        if let Some(x) = dlog(G, *H, baby_table, range_limit) {
            result.push(x);
        } else {
            return None; // fail early if any element cannot be solved
        }
    }

    Some(result)
}
```

**File:** consensus/src/epoch_manager.rs (L1066-1072)
```rust
        let (sk, pk) = DefaultDKG::decrypt_secret_share_from_transcript(
            &dkg_pub_params,
            &transcript,
            my_index as u64,
            &dkg_decrypt_key,
        )
        .map_err(NoRandomnessReason::SecretShareDecryptionFailed)?;
```

**File:** consensus/src/epoch_manager.rs (L1989-2004)
```rust
pub enum NoRandomnessReason {
    VTxnDisabled,
    FeatureDisabled,
    DKGStateResourceMissing(anyhow::Error),
    DKGCompletedSessionResourceMissing,
    CompletedSessionTooOld,
    NotInValidatorSet,
    ErrConvertingConsensusKeyToDecryptionKey(anyhow::Error),
    TranscriptDeserializationError(bcs::Error),
    SecretShareDecryptionFailed(anyhow::Error),
    RngCreationError(rand::Error),
    RandDbNotAvailable(anyhow::Error),
    KeyPairDeserializationError(bcs::Error),
    KeyPairSerializationError(bcs::Error),
    KeyPairPersistError(anyhow::Error),
}
```

**File:** types/src/transaction/encrypted_payload.rs (L48-53)
```rust
    FailedDecryption {
        ciphertext: Ciphertext,
        extra_config: TransactionExtraConfig,
        payload_hash: HashValue,
        eval_proof: EvalProof,
    },
```

**File:** dkg/src/transcript_aggregation/mod.rs (L96-101)
```rust
        S::verify_transcript_extra(&transcript, &self.epoch_state.verifier, false, Some(sender))
            .context("extra verification failed")?;

        S::verify_transcript(&self.dkg_pub_params, &transcript).map_err(|e| {
            anyhow!("[DKG] adding peer transcript failed with trx verification failure: {e}")
        })?;
```
