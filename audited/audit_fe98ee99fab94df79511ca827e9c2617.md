# Audit Report

## Title
State Snapshot Restoration Accepts Invalid Proofs in KvOnly Mode, Bypassing Cryptographic Verification

## Summary
The `StateSnapshotRestore::add_chunk()` method accepts a `SparseMerkleRangeProof` parameter but completely ignores it when operating in `KvOnly` restore mode, allowing arbitrary state data to be written to the database without cryptographic verification against the expected Merkle root hash.

## Finding Description

The vulnerability exists in the state snapshot restoration logic where different restore modes have inconsistent security guarantees.

When `add_chunk()` is called at line 228, it receives both chunk data and a cryptographic proof: [1](#0-0) 

The method dispatches to different code paths based on `restore_mode`: [2](#0-1) 

**In KvOnly mode** (line 247), only `kv_fn()` executes, which calls `StateValueRestore::add_chunk()`. This function performs NO proof verification: [3](#0-2) 

The KV restore path simply writes data to storage without any cryptographic checks, completely ignoring the provided `SparseMerkleRangeProof` parameter.

**In contrast**, when `tree_fn()` executes (TreeOnly or Default modes), it calls `JellyfishMerkleRestore::add_chunk_impl()` which performs cryptographic verification: [4](#0-3) 

The `verify()` method at line 391 cryptographically validates that the chunk data matches the expected root hash using the proof: [5](#0-4) 

The proof verification ensures the reconstructed root hash matches the expected value: [6](#0-5) 

**KvOnly mode is used in production** during backup restoration: [7](#0-6) 

**Attack Scenario:**
1. Attacker compromises backup storage or performs MITM during restore
2. Attacker provides malicious chunk data with arbitrary/invalid proofs
3. Node operator runs restore with KvOnly mode
4. Malicious data is written to state database without verification
5. Corrupted state leads to wrong state roots and consensus divergence

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

## Impact Explanation

**Critical Severity** - This vulnerability enables state database corruption that violates fundamental blockchain security guarantees:

1. **Consensus Divergence**: Nodes restored from different (potentially malicious) backups would compute different state roots for identical blocks, breaking consensus safety.

2. **State Consistency Violation**: The core invariant that all state data must be cryptographically verifiable against Merkle roots is bypassed.

3. **Non-recoverable Network Partition**: If validator nodes restore corrupted state, they would permanently disagree on state roots, requiring manual intervention or hard fork.

4. **Defense-in-Depth Failure**: Even if backup storage is assumed trusted, cryptographic verification provides critical defense against storage compromise, insider threats, or accidental corruption.

The vulnerability meets Critical severity criteria from the bug bounty program: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Medium-to-High Likelihood** given:

1. **Common Operation**: Backup restoration is a standard disaster recovery procedure that validators must perform.

2. **Production Code Path**: KvOnly mode is explicitly used in the production restore coordinator, not just test code.

3. **Attack Surface**: Backup storage systems are high-value targets that may be compromised through:
   - Cloud storage misconfiguration
   - Supply chain attacks on backup infrastructure
   - Insider threats with storage access
   - MITM during backup transfer

4. **Silent Failure**: No validation occurs during or after KvOnly restore, so corruption goes undetected until consensus divergence appears.

5. **Inconsistent Security**: The fact that other modes verify proofs suggests this was a security requirement that was inadvertently omitted for KvOnly mode.

## Recommendation

**Enforce proof verification for ALL restore modes** to maintain defense-in-depth:

```rust
fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
    let kv_fn = || {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_add_chunk"]);
        self.kv_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk(chunk.clone())
    };

    let tree_fn = || {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["jmt_add_chunk"]);
        self.tree_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk_impl(chunk.iter().map(|(k, v)| (k, v.hash())).collect(), proof)
    };
    
    match self.restore_mode {
        StateSnapshotRestoreMode::KvOnly => {
            // SECURITY FIX: Verify proof even in KvOnly mode
            tree_fn()?; // This validates the proof cryptographically
            kv_fn()?;
        },
        StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
        StateSnapshotRestoreMode::Default => {
            let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
            r1?;
            r2?;
        },
    }

    Ok(())
}
```

Alternatively, if performance is critical and KvOnly mode needs to skip tree construction, add explicit proof verification without tree building:

1. Extract proof verification logic into a standalone function
2. Call verification in all modes before writing any data
3. Add integration tests that verify KvOnly mode rejects invalid proofs

## Proof of Concept

```rust
#[test]
fn test_kvonly_accepts_invalid_proof() {
    use aptos_types::proof::SparseMerkleRangeProof;
    
    // Setup: Create legitimate state data
    let legitimate_data = vec![
        (StateKey::raw(b"key1"), StateValue::new_legacy(b"value1".to_vec())),
        (StateKey::raw(b"key2"), StateValue::new_legacy(b"value2".to_vec())),
    ];
    
    // Attacker: Provides malicious data
    let malicious_data = vec![
        (StateKey::raw(b"key1"), StateValue::new_legacy(b"MALICIOUS".to_vec())),
        (StateKey::raw(b"key2"), StateValue::new_legacy(b"CORRUPTED".to_vec())),
    ];
    
    // Attacker: Provides completely invalid proof (wrong siblings)
    let invalid_proof = SparseMerkleRangeProof::new(vec![
        HashValue::random(),  // Wrong sibling hashes
        HashValue::random(),
    ]);
    
    let restore_db = Arc::new(MockSnapshotStore::default());
    let expected_root = HashValue::random(); // Legitimate root from manifest
    
    // Create restore in KvOnly mode
    let mut restore = StateSnapshotRestore::new(
        &restore_db,
        &restore_db,
        100, // version
        expected_root,
        false, // sync commit for testing
        StateSnapshotRestoreMode::KvOnly,
    ).unwrap();
    
    // BUG: This should FAIL but SUCCEEDS - invalid proof accepted!
    let result = restore.add_chunk(malicious_data.clone(), invalid_proof);
    assert!(result.is_ok()); // Proof verification bypassed
    
    restore.finish().unwrap();
    
    // Verify malicious data was written to database
    for (key, malicious_value) in malicious_data {
        let stored = restore_db.get_value_at_version(&(key, 100)).unwrap();
        assert_eq!(stored, malicious_value); // Corruption persisted!
    }
    
    // The state database now contains unverified, potentially malicious data
    // When tree is built later, it will have wrong root hash != expected_root
}
```

**Notes:**
- The vulnerability requires backup storage compromise or privileged access to the restore process
- However, cryptographic verification should ALWAYS be enforced as defense-in-depth
- The inconsistency between restore modes (TreeOnly verifies, KvOnly doesn't) indicates this was likely an oversight rather than intentional design
- Production usage of KvOnly mode means this code path is actively exercised and represents real attack surface

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L88-127)
```rust
    pub fn add_chunk(&mut self, mut chunk: Vec<(K, V)>) -> Result<()> {
        // load progress
        let progress_opt = self.db.get_progress(self.version)?;

        // skip overlaps
        if let Some(progress) = progress_opt {
            let idx = chunk
                .iter()
                .position(|(k, _v)| CryptoHash::hash(k) > progress.key_hash)
                .unwrap_or(chunk.len());
            chunk = chunk.split_off(idx);
        }

        // quit if all skipped
        if chunk.is_empty() {
            return Ok(());
        }

        // save
        let mut usage = progress_opt.map_or(StateStorageUsage::zero(), |p| p.usage);
        let (last_key, _last_value) = chunk.last().unwrap();
        let last_key_hash = CryptoHash::hash(last_key);

        // In case of TreeOnly Restore, we only restore the usage of KV without actually writing KV into DB
        for (k, v) in chunk.iter() {
            usage.add_item(k.key_size() + v.value_size());
        }

        // prepare the sharded kv batch
        let kv_batch: StateValueBatch<K, Option<V>> = chunk
            .into_iter()
            .map(|(k, v)| ((k, self.version), Some(v)))
            .collect();

        self.db.write_kv_batch(
            self.version,
            &kv_batch,
            StateSnapshotProgress::new(last_key_hash, usage),
        )
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L228-228)
```rust
    fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L246-255)
```rust
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => kv_fn()?,
            StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
        }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L339-391)
```rust
    pub fn add_chunk_impl(
        &mut self,
        mut chunk: Vec<(&K, HashValue)>,
        proof: SparseMerkleRangeProof,
    ) -> Result<()> {
        if self.finished {
            info!("State snapshot restore already finished, ignoring entire chunk.");
            return Ok(());
        }

        if let Some(prev_leaf) = &self.previous_leaf {
            let skip_until = chunk
                .iter()
                .find_position(|(key, _hash)| key.hash() > *prev_leaf.account_key());
            chunk = match skip_until {
                None => {
                    info!("Skipping entire chunk.");
                    return Ok(());
                },
                Some((0, _)) => chunk,
                Some((num_to_skip, next_leaf)) => {
                    info!(
                        num_to_skip = num_to_skip,
                        next_leaf = next_leaf,
                        "Skipping leaves."
                    );
                    chunk.split_off(num_to_skip)
                },
            }
        };
        if chunk.is_empty() {
            return Ok(());
        }

        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L628-697)
```rust
    fn verify(&self, proof: SparseMerkleRangeProof) -> Result<()> {
        let previous_leaf = self
            .previous_leaf
            .as_ref()
            .expect("The previous leaf must exist.");

        let previous_key = previous_leaf.account_key();
        // If we have all siblings on the path from root to `previous_key`, we should be able to
        // compute the root hash. The siblings on the right are already in the proof. Now we
        // compute the siblings on the left side, which represent all the states that have ever
        // been added.
        let mut left_siblings = vec![];

        // The following process might add some extra placeholder siblings on the left, but it is
        // nontrivial to determine when the loop should stop. So instead we just add these
        // siblings for now and get rid of them in the next step.
        let mut num_visited_right_siblings = 0;
        for (i, bit) in previous_key.iter_bits().enumerate() {
            if bit {
                // This node is a right child and there should be a sibling on the left.
                let sibling = if i >= self.partial_nodes.len() * 4 {
                    *SPARSE_MERKLE_PLACEHOLDER_HASH
                } else {
                    Self::compute_left_sibling(
                        &self.partial_nodes[i / 4],
                        previous_key.get_nibble(i / 4),
                        (3 - i % 4) as u8,
                    )
                };
                left_siblings.push(sibling);
            } else {
                // This node is a left child and there should be a sibling on the right.
                num_visited_right_siblings += 1;
            }
        }
        ensure!(
            num_visited_right_siblings >= proof.right_siblings().len(),
            "Too many right siblings in the proof.",
        );

        // Now we remove any extra placeholder siblings at the bottom. We keep removing the last
        // sibling if 1) it's a placeholder 2) it's a sibling on the left.
        for bit in previous_key.iter_bits().rev() {
            if bit {
                if *left_siblings.last().expect("This sibling must exist.")
                    == *SPARSE_MERKLE_PLACEHOLDER_HASH
                {
                    left_siblings.pop();
                } else {
                    break;
                }
            } else if num_visited_right_siblings > proof.right_siblings().len() {
                num_visited_right_siblings -= 1;
            } else {
                break;
            }
        }

        // Left siblings must use the same ordering as the right siblings in the proof
        left_siblings.reverse();

        // Verify the proof now that we have all the siblings
        proof
            .verify(
                self.expected_root_hash,
                SparseMerkleLeafNode::new(*previous_key, previous_leaf.value_hash()),
                left_siblings,
            )
            .map_err(Into::into)
    }
```

**File:** types/src/proof/definition.rs (L782-826)
```rust
    pub fn verify(
        &self,
        expected_root_hash: HashValue,
        rightmost_known_leaf: SparseMerkleLeafNode,
        left_siblings: Vec<HashValue>,
    ) -> Result<()> {
        let num_siblings = left_siblings.len() + self.right_siblings.len();
        let mut left_sibling_iter = left_siblings.iter();
        let mut right_sibling_iter = self.right_siblings().iter();

        let mut current_hash = rightmost_known_leaf.hash();
        for bit in rightmost_known_leaf
            .key()
            .iter_bits()
            .rev()
            .skip(HashValue::LENGTH_IN_BITS - num_siblings)
        {
            let (left_hash, right_hash) = if bit {
                (
                    *left_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing left sibling."))?,
                    current_hash,
                )
            } else {
                (
                    current_hash,
                    *right_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing right sibling."))?,
                )
            };
            current_hash = SparseMerkleInternalNode::new(left_hash, right_hash).hash();
        }

        ensure!(
            current_hash == expected_root_hash,
            "{}: Root hashes do not match. Actual root hash: {:x}. Expected root hash: {:x}.",
            type_name::<Self>(),
            current_hash,
            expected_root_hash,
        );

        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L247-259)
```rust
                StateSnapshotRestoreController::new(
                    StateSnapshotRestoreOpt {
                        manifest_handle: kv_snapshot.manifest,
                        version: kv_snapshot.version,
                        validate_modules: false,
                        restore_mode: StateSnapshotRestoreMode::KvOnly,
                    },
                    self.global_opt.clone(),
                    Arc::clone(&self.storage),
                    epoch_history.clone(),
                )
                .run()
                .await?;
```
