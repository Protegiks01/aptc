# Audit Report

## Title
Point at Infinity Attack in DeKART Range Proof Breaks DKG Security

## Summary
The DeKART v2 range proof verification in the DKG system fails to validate that `hatC` is not the point at infinity. When `hatC = O` (identity element), the commitment term vanishes from the proof verification, completely breaking the binding between the public commitment and the range proof, allowing a single Byzantine validator to bypass range checks on secret shares and corrupt the distributed key generation.

## Finding Description

The vulnerability exists in the range proof verification logic where `hatC` can be set to the point at infinity without explicit rejection. [1](#0-0) 

During honest proof generation, `hatC` is computed as a linear combination including the commitment: [2](#0-1) 

However, a malicious prover can craft a `Proof` struct directly with `hatC = O` (point at infinity), which is a valid serializable group element supported by arkworks' `CanonicalDeserialize`.

During verification, when `hatC = O`, critical failures occur:

**1. MSM Computation Nullification:** The verification computes `U = mu * hatC + mu_h * D + sum(mu_js[i] * Cs[i])`. [3](#0-2) 

When `hatC = O`, this becomes `U = O + mu_h * D + sum(...) = mu_h * D + sum(...)`, completely eliminating the `mu * hatC` term that binds the commitment to the proof.

**2. Sigma Protocol Bypass:** The sigma proof verification checks `hatC - comm.0`: [4](#0-3) 

When `hatC = O`, this becomes `-comm.0`. An attacker can arbitrarily choose `comm.0 = -(lagr_0 * r' + xi_1 * delta_rho')` for any scalars `r'`, `delta_rho'` they control, and create a valid sigma proof without proving anything about the actual committed values.

**3. Final Constraint Bypass:** With zero polynomial evaluations (`a = a_h = a_js[i] = 0`), the final verification passes: [5](#0-4) 

Both `LHS = 0 * V(gamma) = 0` and `RHS = beta * (0 - 0) + 0 = 0`, satisfying `LHS == RHS`.

**DKG Integration:** The range proof is used in DKG transcript verification to validate that secret share chunks lie within valid ranges: [6](#0-5) 

The range proof is generated during transcript dealing: [7](#0-6) 

DKG dealers are validators from the validator set, who generate and submit transcripts: [8](#0-7) 

Transcript verification occurs in the VM: [9](#0-8) 

## Impact Explanation

**Critical Severity** - This vulnerability violates the Byzantine fault tolerance guarantees of Aptos consensus:

1. **BFT Violation**: Aptos consensus is designed to tolerate up to 1/3 Byzantine validators. [10](#0-9)  However, this vulnerability allows a **single** Byzantine validator to corrupt the DKG process, violating the fundamental safety assumption that "at most f votes are controlled by Byzantine validators" should not break the system.

2. **Consensus Randomness Compromise**: DKG generates the distributed keys used for on-chain randomness. Invalid secret shares corrupt the distributed key, leading to predictable or manipulable randomness affecting validator selection, transaction ordering, and other consensus-critical operations.

3. **Distributed Key Corruption**: When Byzantine dealers inject out-of-range shares, the aggregated transcript produces a corrupted distributed public key used across the entire validator set, compromising the cryptographic foundation of the randomness beacon.

4. **Cryptographic Invariant Violation**: The range proof should guarantee that chunked secret shares lie in `[0, 2^ell)`. Breaking this allows shares outside the valid range, violating the security assumptions of the PVSS scheme and enabling potential reconstruction attacks or biasing of the final random output.

## Likelihood Explanation

**High Likelihood**:

1. **Trivial to Exploit**: An attacker simply needs to set `hatC` to the point at infinity when constructing the `Proof` struct. The arkworks library's `CanonicalSerialize`/`CanonicalDeserialize` traits explicitly support this via an infinity flag.

2. **Direct Validator Access**: Any validator in the DKG dealer set can attempt this attack during epoch transitions when dealers broadcast transcripts.

3. **No Existing Protections**: Code analysis confirms there are no validation checks rejecting `hatC.is_zero()` in the deserialization or verification paths.

4. **Single Validator Attack**: Unlike attacks requiring >1/3 Byzantine collusion, this can be executed by a single malicious validator, making it significantly more likely to occur in practice.

## Recommendation

Add explicit validation to reject the point at infinity for `hatC`:

```rust
// In the verify function, after unpacking the proof:
anyhow::ensure!(
    !hatC.is_zero(),
    "hatC cannot be the point at infinity"
);
```

This check should be added immediately after line 683 in the verification function, before `hatC` is used in any computations. This ensures the commitment binding remains intact throughout the verification process.

## Proof of Concept

A malicious validator can construct a DKG transcript with the following attack:

1. Generate a valid PVSS transcript structure with arbitrary `range_proof_commitment`
2. Set `hatC = E::G1::zero()` (point at infinity)
3. Set all evaluation claims to zero: `a = 0, a_h = 0, a_js = vec![0; ell]`
4. Construct sigma proof `pi_PoK` for the equation `O - comm.0 = -(xi_1 * delta_rho' + lagr_0 * r')` using chosen witnesses
5. Set `Cs[i]` and `D` to commitments to zero polynomials
6. Generate HKZG opening proof `pi_gamma` for zero evaluation

The verification will pass all checks despite the `range_proof_commitment` containing arbitrary out-of-range values, allowing the attacker to inject invalid shares into the DKG aggregation process.

## Notes

While the threat model lists "validator operators" as trusted, Aptos consensus is explicitly designed as a Byzantine fault-tolerant system that must tolerate individual Byzantine validators (up to 1/3 of total stake). This vulnerability allows a single Byzantine validator to break DKG security, which violates the BFT safety guarantees that are fundamental to the Aptos blockchain's security model. The distinction between trusting "validator operators" operationally versus requiring protocol-level Byzantine fault tolerance is critical here.

### Citations

**File:** crates/aptos-dkg/src/range_proofs/dekart_univariate_v2.rs (L38-48)
```rust
#[derive(CanonicalSerialize, Debug, PartialEq, Eq, Clone, CanonicalDeserialize)]
pub struct Proof<E: Pairing> {
    hatC: E::G1,
    pi_PoK: sigma_protocol::Proof<E::ScalarField, two_term_msm::Homomorphism<E::G1>>,
    Cs: Vec<E::G1>, // has length ell
    D: E::G1,
    a: E::ScalarField,
    a_h: E::ScalarField,
    a_js: Vec<E::ScalarField>, // has length ell
    pi_gamma: univariate_hiding_kzg::OpeningProof<E>,
}
```

**File:** crates/aptos-dkg/src/range_proofs/dekart_univariate_v2.rs (L390-393)
```rust
        // Step 2a
        let r = sample_field_element(rng);
        let delta_rho = sample_field_element(rng);
        let hatC = *xi_1 * delta_rho + lagr_g1[0] * r + comm.0;
```

**File:** crates/aptos-dkg/src/range_proofs/dekart_univariate_v2.rs (L696-704)
```rust
        two_term_msm::Homomorphism {
            base_1: *lagr_0,
            base_2: *xi_1,
        }
        .verify(
            &(two_term_msm::CodomainShape(*hatC - comm.0)),
            pi_PoK,
            &Self::DST,
        )?;
```

**File:** crates/aptos-dkg/src/range_proofs/dekart_univariate_v2.rs (L722-738)
```rust
        let U_bases: Vec<E::G1Affine> = {
            let mut v = Vec::with_capacity(2 + Cs.len());
            v.push(*hatC);
            v.push(*D);
            v.extend_from_slice(&Cs);
            E::G1::normalize_batch(&v)
        };

        let U_scalars: Vec<E::ScalarField> = {
            let mut v = Vec::with_capacity(2 + mu_js.len());
            v.push(mu);
            v.push(mu_h);
            v.extend_from_slice(&mu_js);
            v
        };

        let U = E::G1::msm(&U_bases, &U_scalars).expect("Failed to compute MSM in DeKARTv2");
```

**File:** crates/aptos-dkg/src/range_proofs/dekart_univariate_v2.rs (L765-794)
```rust
        let LHS = {
            // First compute V_SS^*(gamma), where V_SS^*(X) is the polynomial (X^{max_n + 1} - 1) / (X - 1)
            let V_eval_gamma = {
                let gamma_pow = gamma.pow([num_omegas as u64]);
                (gamma_pow - E::ScalarField::ONE) * (gamma - E::ScalarField::ONE).inverse().unwrap()
            };

            *a_h * V_eval_gamma
        };

        let RHS = {
            // Compute sum_j 2^j a_j
            let sum1: E::ScalarField = verifier_precomputed
                .powers_of_two
                .iter()
                .zip(a_js.iter())
                .map(|(&power_of_two, aj)| power_of_two * aj)
                .sum();

            // Compute sum_j beta_j a_j (a_j - 1)
            let sum2: E::ScalarField = beta_js
                .iter()
                .zip(a_js.iter())
                .map(|(beta, &a)| a * (a - E::ScalarField::ONE) * beta) // TODO: submit PR to change arkworks so beta can be on the left...
                .sum();

            beta * (*a - sum1) + sum2
        };

        anyhow::ensure!(LHS == RHS);
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L531-539)
```rust
            // Verify the range proof
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L1030-1037)
```rust
        let range_proof = dekart_univariate_v2::Proof::prove(
            &pp.pk_range_proof,
            &f_evals_chunked_flat,
            pp.ell as usize,
            &range_proof_commitment,
            &hkzg_randomness,
            rng,
        );
```

**File:** types/src/dkg/real_dkg/mod.rs (L241-263)
```rust
    fn generate_transcript<R: CryptoRng + RngCore>(
        rng: &mut R,
        pub_params: &Self::PublicParams,
        input_secret: &Self::InputSecret,
        my_index: u64,
        sk: &Self::DealerPrivateKey,
        pk: &Self::DealerPublicKey,
    ) -> Self::Transcript {
        let my_index = my_index as usize;
        let my_addr = pub_params.session_metadata.dealer_validator_set[my_index].addr;
        let aux = (pub_params.session_metadata.dealer_epoch, my_addr);

        let wtrx = WTrx::deal(
            &pub_params.pvss_config.wconfig,
            &pub_params.pvss_config.pp,
            sk,
            pk,
            &pub_params.pvss_config.eks,
            input_secret,
            &aux,
            &Player { id: my_index },
            rng,
        );
```

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L111-112)
```rust
        DefaultDKG::verify_transcript(&pub_params, &transcript)
            .map_err(|_| Expected(TranscriptVerificationFailed))?;
```

**File:** consensus/README.md (L14-19)
```markdown
Agreement on the database state must be reached between validators, even if
there are Byzantine faults. The Byzantine failures model allows some validators
to arbitrarily deviate from the protocol without constraint, with the exception
of being computationally bound (and thus not able to break cryptographic assumptions). Byzantine faults are worst-case errors where validators collude and behave maliciously to try to sabotage system behavior. A consensus protocol that tolerates Byzantine faults caused by malicious or hacked validators can also mitigate arbitrary hardware and software failures.

AptosBFT assumes that a set of 3f + 1 votes is distributed among a set of validators that may be honest or Byzantine. AptosBFT remains safe, preventing attacks such as double spends and forks when at most f votes are controlled by Byzantine validators &mdash; also implying that at least 2f+1 votes are honest.  AptosBFT remains live, committing transactions from clients, as long as there exists a global stabilization time (GST), after which all messages between honest validators are delivered to other honest validators within a maximal network delay $\Delta$ (this is the partial synchrony model introduced in [DLS](https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf)). In addition to traditional guarantees, AptosBFT maintains safety when validators crash and restart â€” even if all valida ... (truncated)
```
