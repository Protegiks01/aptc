# Audit Report

## Title
Unbounded OIDC Provider Count Enables Validator Node DoS via JWK Consensus Configuration

## Summary
The JWK consensus configuration allows an unlimited number of OIDC providers to be added through governance proposals. Each provider spawns a dedicated observer task that performs HTTP requests every 10 seconds. A malicious governance proposal with thousands of providers can cause severe resource exhaustion on all validator nodes, leading to performance degradation or node crashes.

## Finding Description

The vulnerability exists in the JWK consensus configuration system, which lacks any maximum limit on the number of OIDC providers that can be configured. This breaks the **Resource Limits** invariant that "all operations must respect gas, storage, and computational limits."

**Attack Flow:**

1. **Entry Point**: An attacker submits a governance proposal calling `jwk_consensus_config::set_for_next_epoch()` with a `ConfigV1` containing thousands of malicious OIDC provider entries. [1](#0-0) 

2. **Validation Gap**: The `new_v1()` function only validates provider name uniqueness but does NOT check the vector size: [2](#0-1) 

3. **Configuration Propagation**: At the next epoch, `start_new_epoch()` extracts all providers and passes them to the JWK consensus manager: [3](#0-2) 

4. **Observer Spawning**: The consensus manager spawns one `JWKObserver` task for **each** provider without any limit: [4](#0-3) 

5. **Resource Exhaustion**: Each observer runs continuously, making HTTP requests every 10 seconds: [5](#0-4) 

**Resource Impact per Provider:**
- 1 tokio task with stack allocation
- 2 HTTP requests per 10 seconds (OpenID config + JWK endpoint)
- Network connection overhead
- Response parsing and processing CPU cycles

With 10,000 providers: **10,000 tasks, 20,000 HTTP requests every 10 seconds per validator node**.

## Impact Explanation

**Severity: HIGH** per Aptos bug bounty criteria.

This vulnerability directly causes **"Validator node slowdowns"**, which is explicitly listed as High Severity in the bug bounty program. The impact includes:

1. **Memory Exhaustion**: Thousands of tokio tasks consuming heap and stack memory
2. **Network Saturation**: Massive concurrent HTTP connection overhead
3. **CPU Overload**: Processing thousands of responses simultaneously
4. **Liveness Degradation**: Validators may fail to participate in consensus rounds due to resource starvation
5. **Cascading Failures**: If multiple validators are affected, network liveness is severely impacted

Unlike typical network-level DoS (which is out of scope), this is a **protocol-level DoS** exploiting legitimate governance mechanisms to trigger unbounded resource allocation on all validator nodes simultaneously.

## Likelihood Explanation

**Likelihood: MEDIUM**

The attack requires:
- Governance proposal submission (requires minimum proposer stake)
- Proposal approval through voting (requires sufficient voting power)
- No technical barriers once governance approval is obtained

However:
- Governance participation is a valid attack vector per the security question
- The malicious nature of a config with thousands of providers may not be immediately obvious during voting
- Once executed, the attack affects **all** validator nodes simultaneously
- The attack persists until a corrective governance proposal is passed

## Recommendation

Implement a maximum limit on the number of OIDC providers in the `new_v1()` function. Add validation in both the Move module and Rust deserialization:

**Move Module Fix:**
```move
/// Maximum allowed OIDC providers to prevent resource exhaustion
const MAX_OIDC_PROVIDERS: u64 = 10;
/// Too many OIDC providers specified
const ETOO_MANY_PROVIDERS: u64 = 2;

public fun new_v1(oidc_providers: vector<OIDCProvider>): JWKConsensusConfig {
    let provider_count = vector::length(&oidc_providers);
    assert!(provider_count <= MAX_OIDC_PROVIDERS, error::invalid_argument(ETOO_MANY_PROVIDERS));
    
    let name_set = simple_map::new<String, u64>();
    vector::for_each_ref(&oidc_providers, |provider| {
        let provider: &OIDCProvider = provider;
        let (_, old_value) = simple_map::upsert(&mut name_set, provider.name, 0);
        if (option::is_some(&old_value)) {
            abort(error::invalid_argument(EDUPLICATE_PROVIDERS))
        }
    });
    JWKConsensusConfig {
        variant: copyable_any::pack( ConfigV1 { oidc_providers } )
    }
}
```

**Rust Validation:**
Add validation in the deserialization path as defense-in-depth: [6](#0-5) 

## Proof of Concept

**Move Test demonstrating unchecked provider creation:**

```move
#[test]
#[expected_failure] // Should fail with ETOO_MANY_PROVIDERS but currently succeeds
fun test_excessive_providers_dos() {
    use std::vector;
    use std::string::utf8;
    
    // Create 1000 providers - should be rejected but isn't
    let providers = vector::empty<OIDCProvider>();
    let i = 0;
    while (i < 1000) {
        vector::push_back(&mut providers, new_oidc_provider(
            utf8(b"Provider"),
            utf8(b"https://evil.com/config")
        ));
        i = i + 1;
    };
    
    // This currently succeeds and would cause DoS on all validators
    let config = new_v1(providers);
}
```

**Rust Reproduction Steps:**

1. Create a test that generates a `ConfigV1` with 10,000 providers
2. Simulate epoch transition by calling the consensus manager's `run()` method
3. Observe spawning of 10,000 `JWKObserver` tasks
4. Monitor resource consumption (memory, CPU, network connections)
5. Demonstrate validator node performance degradation under this load

The vulnerability is reproducible by examining the code paths shown in the citations, where no size check exists between governance proposal acceptance and observer task spawning.

## Notes

- The vulnerability affects **all** validator nodes simultaneously when the malicious configuration is applied at epoch transition
- The comment at line 63 in `jwk_consensus_config.rs` acknowledges DDoS concerns but only for CI infrastructure, not validator nodes: [7](#0-6) 
- A reasonable limit of 10-20 providers should be sufficient for legitimate use cases while preventing resource exhaustion attacks
- The fix should be implemented at the Move layer (governance enforcement) with additional Rust-side validation as defense-in-depth

### Citations

**File:** aptos-move/framework/aptos-framework/sources/configs/jwk_consensus_config.move (L62-65)
```text
    public fun set_for_next_epoch(framework: &signer, config: JWKConsensusConfig) {
        system_addresses::assert_aptos_framework(framework);
        config_buffer::upsert(config);
    }
```

**File:** aptos-move/framework/aptos-framework/sources/configs/jwk_consensus_config.move (L90-102)
```text
    public fun new_v1(oidc_providers: vector<OIDCProvider>): JWKConsensusConfig {
        let name_set = simple_map::new<String, u64>();
        vector::for_each_ref(&oidc_providers, |provider| {
            let provider: &OIDCProvider = provider;
            let (_, old_value) = simple_map::upsert(&mut name_set, provider.name, 0);
            if (option::is_some(&old_value)) {
                abort(error::invalid_argument(EDUPLICATE_PROVIDERS))
            }
        });
        JWKConsensusConfig {
            variant: copyable_any::pack( ConfigV1 { oidc_providers } )
        }
    }
```

**File:** crates/aptos-jwk-consensus/src/epoch_manager.rs (L177-186)
```rust
        let (jwk_manager_should_run, oidc_providers) = match jwk_consensus_config {
            Ok(config) => {
                let should_run =
                    config.jwk_consensus_enabled() && onchain_consensus_config.is_vtxn_enabled();
                let providers = config
                    .oidc_providers_cloned()
                    .into_iter()
                    .map(jwks::OIDCProvider::from)
                    .collect();
                (should_run, Some(SupportedOIDCProviders { providers }))
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager/mod.rs (L108-134)
```rust
        this.jwk_observers = oidc_providers
            .unwrap_or_default()
            .into_provider_vec()
            .into_iter()
            .filter_map(|provider| {
                let OIDCProvider { name, config_url } = provider;
                let maybe_issuer = String::from_utf8(name);
                let maybe_config_url = String::from_utf8(config_url);
                match (maybe_issuer, maybe_config_url) {
                    (Ok(issuer), Ok(config_url)) => Some(JWKObserver::spawn(
                        this.epoch_state.epoch,
                        this.my_addr,
                        issuer,
                        config_url,
                        Duration::from_secs(10),
                        local_observation_tx.clone(),
                    )),
                    (maybe_issuer, maybe_config_url) => {
                        warn!(
                            "unable to spawn observer, issuer={:?}, config_url={:?}",
                            maybe_issuer, maybe_config_url
                        );
                        None
                    },
                }
            })
            .collect();
```

**File:** crates/aptos-jwk-consensus/src/jwk_observer.rs (L51-90)
```rust
    async fn start(
        fetch_interval: Duration,
        my_addr: AccountAddress,
        issuer: String,
        open_id_config_url: String,
        observation_tx: aptos_channel::Sender<(), (Issuer, Vec<JWK>)>,
        close_rx: oneshot::Receiver<()>,
    ) {
        let mut interval = tokio::time::interval(fetch_interval);
        interval.set_missed_tick_behavior(MissedTickBehavior::Delay);
        let mut close_rx = close_rx.into_stream();
        let my_addr = if cfg!(feature = "smoke-test") {
            // Include self validator address in JWK request,
            // so dummy OIDC providers in smoke tests can do things like "key A for validator 1, key B for validator 2".
            Some(my_addr)
        } else {
            None
        };

        loop {
            tokio::select! {
                _ = interval.tick().fuse() => {
                    let timer = Instant::now();
                    let result = fetch_jwks(open_id_config_url.as_str(), my_addr).await;
                    debug!(issuer = issuer, "observe_result={:?}", result);
                    let secs = timer.elapsed().as_secs_f64();
                    if let Ok(mut jwks) = result {
                        OBSERVATION_SECONDS.with_label_values(&[issuer.as_str(), "ok"]).observe(secs);
                        jwks.sort();
                        let _ = observation_tx.push((), (issuer.as_bytes().to_vec(), jwks));
                    } else {
                        OBSERVATION_SECONDS.with_label_values(&[issuer.as_str(), "err"]).observe(secs);
                    }
                },
                _ = close_rx.select_next_some() => {
                    break;
                }
            }
        }
    }
```

**File:** types/src/on_chain_config/jwk_consensus_config.rs (L61-67)
```rust
    pub fn default_for_genesis() -> Self {
        // Here it is supposed to use `default_enabled()`.
        // Using an empty list instead to avoid DDoSing the CI infra or the actual providers.
        Self::V1(ConfigV1 {
            oidc_providers: vec![],
        })
    }
```

**File:** types/src/on_chain_config/jwk_consensus_config.rs (L88-98)
```rust
    fn deserialize_into_config(bytes: &[u8]) -> anyhow::Result<Self> {
        let variant = bcs::from_bytes::<MoveAny>(bytes)?;
        match variant.type_name.as_str() {
            ConfigOff::MOVE_TYPE_NAME => Ok(OnChainJWKConsensusConfig::Off),
            ConfigV1::MOVE_TYPE_NAME => {
                let config_v1 = Any::unpack::<ConfigV1>(ConfigV1::MOVE_TYPE_NAME, variant).map_err(|e|anyhow!("OnChainJWKConsensusConfig deserialization failed with ConfigV1 unpack error: {e}"))?;
                Ok(OnChainJWKConsensusConfig::V1(config_v1))
            },
            _ => Err(anyhow!("unknown variant type")),
        }
    }
```
