# Audit Report

## Title
Non-Atomic KV Replay Causes State Database Inconsistency During Restore Operations

## Summary
The `save_transactions_and_replay_kv()` function in the restore handler lacks atomic transaction guarantees across KV and ledger databases. If the KV commit succeeds but the ledger commit fails, the databases become inconsistent with KV state ahead of ledger state, and the in-memory state points to non-existent transactions. This violates the **State Consistency** invariant that state transitions must be atomic.

## Finding Description

The vulnerability exists in the restore flow where KV replay commits are not atomic with ledger commits. The execution sequence in `save_transactions` is: [1](#0-0) 

The critical flow shows:

1. **In-memory state updated prematurely**: The code explicitly acknowledges this issue with a comment noting "ideally this is set after the batches are committed" [2](#0-1) 

2. **KV commit executes first**: The state_kv_db.commit writes all 16 shards in parallel and updates `StateKvCommitProgress` [3](#0-2) 

3. **Ledger commit executes second**: The ledger_db.write_schemas writes to 8 separate databases sequentially, with progress markers written last [4](#0-3) 

**Critical Issue**: Each database write is individually atomic via RocksDB's write batch mechanism, but there is **no cross-database transaction** wrapping the KV and ledger commits together. If `state_kv_db.commit` succeeds but `ledger_db.write_schemas` fails (e.g., disk full on the 5th of 8 database writes), the result is:

- ✅ State KV data persisted for version V
- ✅ `StateKvCommitProgress` = V  
- ✅ In-memory state points to version V
- ❌ Ledger databases partially written (some have V, some don't)
- ❌ `OverallCommitProgress` = V-1 (never updated)
- ❌ `LedgerCommitProgress` = V-1 (never updated)

The node is left with KV state referencing transactions that don't fully exist in the ledger, breaking the fundamental invariant that ledger and state must be synchronized.

## Impact Explanation

**Severity: High** (State inconsistencies requiring intervention)

This vulnerability breaks the **State Consistency** invariant and can cause:

1. **Consensus Failures**: Validators may disagree on state roots if some have the inconsistent state while others don't, causing chain splits or validator penalties.

2. **State Root Mismatches**: The in-memory state cache believes version V exists, but queries for transaction data at V will fail or return partial results, causing state root calculation errors.

3. **Cascading Restore Failures**: If the restore continues after the error, subsequent batches build on corrupted state, amplifying the inconsistency.

4. **Recovery Complexity**: While the `sync_commit_progress` mechanism can recover on restart by truncating to the last consistent point, this requires node downtime and re-restoration of potentially large amounts of data. [5](#0-4) 

The recovery logic can detect and fix the inconsistency, but only after restart. During the window between failure and restart, the node operates with inconsistent state.

## Likelihood Explanation

**Likelihood: Medium**

This occurs whenever:
- Disk space exhaustion happens during the ledger write phase
- I/O errors occur on specific ledger database files
- System crashes between the two commit operations
- Resource limits (file descriptors, memory) are hit mid-write

These scenarios are realistic in production environments, especially during large state restores or snapshot synchronizations. The vulnerability is **not** exploitable by external attackers but represents a design flaw that manifests under infrastructure failures.

## Recommendation

Implement atomic commit semantics across KV and ledger databases:

**Option 1**: Move in-memory state update after both commits
```rust
// In save_transactions function (restore_utils.rs)
let ledger_state = if kv_replay {
    // Calculate but don't set yet
    let (ledger_state, _) = state_store.calculate_state_and_put_updates(
        &StateUpdateRefs::index_write_sets(...),
        &mut ledger_db_batch.ledger_metadata_db_batches,
        state_kv_batches,
    )?;
    Some(ledger_state)
} else {
    None
};

// Commit both
state_store.state_db.state_kv_db.commit(...)?;
ledger_db.write_schemas(ledger_db_batch)?;

// NOW set in-memory state after both succeed
if let Some(ledger_state) = ledger_state {
    state_store.set_state_ignoring_summary(ledger_state);
}
```

**Option 2**: Implement two-phase commit with rollback capability
```rust
// Add rollback marker before KV commit
state_kv_db.write_rollback_marker(version)?;

// Commit KV
state_kv_db.commit(version, None, sharded_state_kv_batches)?;

// Try ledger commit
match ledger_db.write_schemas(ledger_db_batch) {
    Ok(_) => {
        // Success - clear rollback marker and update state
        state_kv_db.clear_rollback_marker(version)?;
        if let Some(ledger_state) = ledger_state {
            state_store.set_state_ignoring_summary(ledger_state);
        }
    }
    Err(e) => {
        // Failure - rollback KV to previous version
        truncate_state_kv_db(&state_kv_db, version, version - 1, 1)?;
        return Err(e);
    }
}
```

**Option 3**: Write unified progress marker only after both commits succeed
The current code writes `StateKvCommitProgress` during `state_kv_db.commit` and `OverallCommitProgress` during `ledger_db.write_schemas`. Both should be written in a separate atomic operation after both commits complete.

## Proof of Concept

```rust
// Reproduction test for storage/aptosdb/src/backup/restore_utils.rs
#[test]
fn test_partial_kv_replay_failure_leaves_inconsistent_state() {
    // Setup: Create restore handler with test database
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    let restore_handler = db.get_restore_handler();
    
    // Restore some initial transactions successfully
    let (txns, aux_info, txn_infos, events, write_sets) = 
        generate_test_transactions(0, 10);
    restore_handler.save_transactions_and_replay_kv(
        0, &txns, &aux_info, &txn_infos, &events, write_sets
    ).unwrap();
    
    // Simulate partial failure: inject I/O error into ledger_db 
    // after state_kv_db.commit succeeds
    let (txns2, aux_info2, txn_infos2, events2, write_sets2) = 
        generate_test_transactions(10, 20);
    
    // Mock: Make transaction_info_db.write_schemas fail
    inject_write_failure(&db.ledger_db.transaction_info_db);
    
    // This should fail during ledger write
    let result = restore_handler.save_transactions_and_replay_kv(
        10, &txns2, &aux_info2, &txn_infos2, &events2, write_sets2
    );
    assert!(result.is_err());
    
    // BUG: Check inconsistent state
    // StateKvCommitProgress says version 19 (SUCCESS)
    let kv_progress = db.state_kv_db.metadata_db()
        .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
        .unwrap().unwrap().expect_version();
    assert_eq!(kv_progress, 19);
    
    // But OverallCommitProgress still at version 9 (FAILED)
    let overall_progress = db.ledger_db.metadata_db()
        .get_synced_version().unwrap().unwrap();
    assert_eq!(overall_progress, 9);
    
    // State inconsistency: KV has versions 10-19, ledger does not
    // In-memory state thinks version 19 exists
    // Transaction queries fail for versions 10-19
    for v in 10..20 {
        // KV query succeeds (BUG - should not exist)
        assert!(db.state_store.get_state_value_with_version(..., v).is_ok());
        
        // Ledger query fails (expected for inconsistent state)
        assert!(db.ledger_db.transaction_info_db()
            .get_transaction_info(v).is_err());
    }
}
```

**Notes**

The vulnerability is confirmed by the developer comment acknowledging the non-ideal ordering. While the `sync_commit_progress` recovery mechanism provides eventual consistency on restart, the lack of atomicity violates core database invariants and can cause immediate operational failures during restore operations. The fix requires either reordering operations to defer in-memory updates, or implementing proper two-phase commit semantics across the storage subsystems.

### Citations

**File:** storage/aptosdb/src/backup/restore_utils.rs (L115-176)
```rust
pub(crate) fn save_transactions(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    txns: &[Transaction],
    persisted_aux_info: &[PersistedAuxiliaryInfo],
    txn_infos: &[TransactionInfo],
    events: &[Vec<ContractEvent>],
    write_sets: Vec<WriteSet>,
    existing_batch: Option<(
        &mut LedgerDbSchemaBatches,
        &mut ShardedStateKvSchemaBatch,
        &mut SchemaBatch,
    )>,
    kv_replay: bool,
) -> Result<()> {
    if let Some((ledger_db_batch, state_kv_batches, _state_kv_metadata_batch)) = existing_batch {
        save_transactions_impl(
            state_store,
            ledger_db,
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets.as_ref(),
            ledger_db_batch,
            state_kv_batches,
            kv_replay,
        )?;
    } else {
        let mut ledger_db_batch = LedgerDbSchemaBatches::new();
        let mut sharded_kv_schema_batch = state_store
            .state_db
            .state_kv_db
            .new_sharded_native_batches();
        save_transactions_impl(
            Arc::clone(&state_store),
            Arc::clone(&ledger_db),
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets.as_ref(),
            &mut ledger_db_batch,
            &mut sharded_kv_schema_batch,
            kv_replay,
        )?;
        // get the last version and commit to the state kv db
        // commit the state kv before ledger in case of failure happens
        let last_version = first_version + txns.len() as u64 - 1;
        state_store
            .state_db
            .state_kv_db
            .commit(last_version, None, sharded_kv_schema_batch)?;

        ledger_db.write_schemas(ledger_db_batch)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L531-548)
```rust
    pub fn write_schemas(&self, schemas: LedgerDbSchemaBatches) -> Result<()> {
        self.write_set_db
            .write_schemas(schemas.write_set_db_batches)?;
        self.transaction_info_db
            .write_schemas(schemas.transaction_info_db_batches)?;
        self.transaction_db
            .write_schemas(schemas.transaction_db_batches)?;
        self.persisted_auxiliary_info_db
            .write_schemas(schemas.persisted_auxiliary_info_db_batches)?;
        self.event_db.write_schemas(schemas.event_db_batches)?;
        self.transaction_accumulator_db
            .write_schemas(schemas.transaction_accumulator_db_batches)?;
        self.transaction_auxiliary_data_db
            .write_schemas(schemas.transaction_auxiliary_data_db_batches)?;
        // TODO: remove this after sharding migration
        self.ledger_metadata_db
            .write_schemas(schemas.ledger_metadata_db_batches)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-502)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");

            // State K/V commit progress isn't (can't be) written atomically with the data,
            // because there are shards, so we have to attempt truncation anyway.
            info!(
                state_kv_commit_progress = state_kv_commit_progress,
                "Start state KV truncation..."
            );
            let difference = state_kv_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_state_kv_db(
                &state_kv_db,
                state_kv_commit_progress,
                overall_commit_progress,
                std::cmp::max(difference as usize, 1), /* batch_size */
            )
            .expect("Failed to truncate state K/V db.");

            let state_merkle_max_version = get_max_version_in_state_merkle_db(&state_merkle_db)
                .expect("Failed to get state merkle max version.")
                .expect("State merkle max version cannot be None.");
            if state_merkle_max_version > overall_commit_progress {
                let difference = state_merkle_max_version - overall_commit_progress;
                if crash_if_difference_is_too_large {
                    assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
                }
            }
            let state_merkle_target_version = find_tree_root_at_or_before(
                ledger_metadata_db,
                &state_merkle_db,
                overall_commit_progress,
            )
            .expect("DB read failed.")
            .unwrap_or_else(|| {
                panic!(
                    "Could not find a valid root before or at version {}, maybe it was pruned?",
                    overall_commit_progress
                )
            });
            if state_merkle_target_version < state_merkle_max_version {
                info!(
                    state_merkle_max_version = state_merkle_max_version,
                    target_version = state_merkle_target_version,
                    "Start state merkle truncation..."
                );
                truncate_state_merkle_db(&state_merkle_db, state_merkle_target_version)
                    .expect("Failed to truncate state merkle db.");
            }
        } else {
            info!("No overall commit progress was found!");
        }
    }
```
