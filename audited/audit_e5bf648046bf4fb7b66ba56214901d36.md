# Audit Report

## Title
Memory Exhaustion in Ledger Pruner Initialization Due to Unbounded Batch Deletion

## Summary
The transaction auxiliary data pruner and other sub-pruners in the ledger pruning system lack bounds checking during initialization, allowing an unbounded range of versions to be deleted in a single `SchemaBatch` before writing to the database. This can cause memory exhaustion if the catch-up range is extremely large.

## Finding Description

The vulnerability exists in the initialization path of all ledger sub-pruners. During normal pruning operations, the `LedgerPruner::prune()` function limits the range to `max_versions` (default 5,000) per batch. [1](#0-0) 

However, during initialization in `TransactionAuxiliaryDataPruner::new()`, the pruner catches up by calling `myself.prune(progress, metadata_progress)` without any range limiting. [2](#0-1) 

This calls `TransactionAuxiliaryDataDb::prune()` which iterates through the entire range, adding a delete operation to the `SchemaBatch` for each version: [3](#0-2) 

The `SchemaBatch` accumulates all deletion operations in memory as `WriteOp::Deletion { key: Vec<u8> }` entries. [4](#0-3) 

**Memory Impact Calculation:**
- Each `WriteOp::Deletion` contains an encoded key (8 bytes for Version) plus enum/vector overhead (~40-64 bytes total)
- For 1 billion versions: approximately 40-64 GB of RAM
- For 100 million versions: approximately 4-6.4 GB of RAM

**Attack Scenario:**
A malicious validator with database access could:
1. Manually modify their database to set `TransactionAuxiliaryDataPrunerProgress` to 0
2. Restart their node
3. During initialization, `get_or_initialize_subpruner_progress()` returns 0 as the stored progress [5](#0-4) 
4. The `metadata_progress` from the ledger metadata pruner reflects billions of versions on a long-running chain
5. The catch-up prune attempts to delete billions of versions in one batch
6. Memory exhaustion occurs, causing node crash

This same vulnerability affects all sub-pruners that follow the same pattern, including `TransactionInfoPruner`, `EventStorePruner`, and others.

## Impact Explanation

**Severity: High** per Aptos Bug Bounty criteria - "Validator node slowdowns" and "API crashes"

The vulnerability causes:
- **Denial of Service**: Validator node crashes due to memory exhaustion
- **Network Impact**: Affected validator becomes unavailable, reducing network resilience
- **Persistent Issue**: Node will repeatedly crash on restart unless database state is manually corrected

While this doesn't directly compromise consensus safety or cause fund loss, it significantly impacts validator availability and network health.

## Likelihood Explanation

**Likelihood: Low to Medium**

This vulnerability requires one of the following conditions:
1. **Malicious validator with database access** (Low likelihood, but possible)
2. **Bug in crash recovery** causing progress desynchronization (Medium likelihood if such bugs exist)
3. **Database corruption** leading to stale progress values (Low likelihood)

In normal operation with healthy error handling, this should not occur. However, the lack of defensive bounds checking means any scenario that causes significant progress desynchronization will trigger the issue.

**Note:** While this technically requires validator-level access to exploit maliciously, it could also occur accidentally due to software bugs, making it a legitimate reliability concern.

## Recommendation

Add bounds checking to the initialization catch-up logic to limit the range processed in a single batch:

```rust
// In TransactionAuxiliaryDataPruner::new() and similar functions
const MAX_CATCHUP_BATCH_SIZE: u64 = 10_000;

let mut current = progress;
while current < metadata_progress {
    let target = std::cmp::min(current + MAX_CATCHUP_BATCH_SIZE, metadata_progress);
    myself.prune(current, target)?;
    current = target;
}
```

This ensures that even during initialization, the pruner respects memory limits by processing the catch-up range in bounded batches.

Alternative approaches:
1. Add a size check in `SchemaBatch` that flushes when a threshold is reached
2. Validate the range before starting the prune operation and reject excessive ranges
3. Add monitoring/alerting when progress desynchronization exceeds safe thresholds

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_schemadb::{SchemaBatch, schema::Schema};
    use aptos_types::transaction::Version;
    
    #[test]
    #[should_panic(expected = "memory")]
    fn test_unbounded_prune_memory_exhaustion() {
        // This test demonstrates the memory issue
        // In a real scenario, this would cause OOM
        let mut batch = SchemaBatch::new();
        
        // Simulate a large range (use smaller number for test)
        let begin: Version = 0;
        let end: Version = 10_000_000; // 10 million for demonstration
        
        // This will accumulate 10 million delete operations in memory
        for version in begin..end {
            batch.delete::<TransactionAuxiliaryDataSchema>(&version).unwrap();
        }
        
        // Memory monitoring would show significant allocation here
        let size_estimate = std::mem::size_of::<WriteOp>() * (end - begin) as usize;
        println!("Estimated memory usage: {} MB", size_estimate / 1_024_000);
        
        // In production with billions of versions, this would exhaust memory
        assert!(size_estimate > 100_000_000); // Over 100MB for 10M versions
    }
}
```

**Notes:**
- This vulnerability exists but requires validator database access or specific bug conditions to trigger
- The code lacks defensive bounds checking in the initialization path
- Similar patterns exist across multiple pruner implementations
- The fix is straightforward: add batching to the catch-up logic

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L67-68)
```rust
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_auxiliary_data_pruner.rs (L56-56)
```rust
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/ledger_db/transaction_auxiliary_data_db.rs (L74-79)
```rust
    pub(crate) fn prune(begin: Version, end: Version, batch: &mut SchemaBatch) -> Result<()> {
        for version in begin..end {
            batch.delete::<TransactionAuxiliaryDataSchema>(&version)?;
        }
        Ok(())
    }
```

**File:** storage/schemadb/src/batch.rs (L165-172)
```rust
    fn raw_delete(&mut self, cf_name: ColumnFamilyName, key: Vec<u8>) -> DbResult<()> {
        self.rows
            .entry(cf_name)
            .or_default()
            .push(WriteOp::Deletion { key });

        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L49-52)
```rust
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
```
