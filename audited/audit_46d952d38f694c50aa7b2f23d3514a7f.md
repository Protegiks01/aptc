# Audit Report

## Title
Missing Sanitization of State Sync Chunk Size Configuration Causing Guaranteed Network Message Failures

## Summary
The `sanitize()` function in `config/src/config/state_sync_config.rs` does not validate that configured chunk byte limits (`max_network_chunk_bytes`, `max_network_chunk_bytes_v2`) stay within the network layer's hard message size limit (64 MiB). Additionally, it does not validate that these limits are reasonable relative to actual data item sizes. This allows node operators to inadvertently or maliciously configure values that guarantee state sync failures, leading to complete node unavailability.

## Finding Description

The state sync configuration defines maximum chunk sizes for network messages: [1](#0-0) 

These values are stored in configurable fields without constraints: [2](#0-1) 

The `sanitize()` implementation only validates auto-bootstrapping configuration, completely ignoring chunk size validation: [3](#0-2) 

Meanwhile, the storage service implementation allows returning single data items that exceed the configured `max_network_chunk_bytes` limit. In the size-aware chunking mode: [4](#0-3) 

In legacy mode, the same behavior occurs: [5](#0-4) 

However, the network layer enforces a hard limit on message sizes: [6](#0-5) 

And validates this during message streaming: [7](#0-6) 

**Attack Scenarios:**

1. **Configuration exceeds network limits**: Setting `max_network_chunk_bytes: 70000000` (70 MB) exceeds the network layer's 64 MiB limit, causing all large state sync responses to be rejected by the network layer.

2. **Configuration too small for data items**: Setting `max_network_chunk_bytes: 1000` (1 KB) is smaller than typical state values. The storage service returns at least one item despite exceeding the limit, which then fails network validation.

Both scenarios result in:
- Storage service creates responses based on configured limits
- Responses are sent to network layer
- Network layer rejects messages that exceed `MAX_MESSAGE_SIZE`
- State sync requests fail with errors
- Node cannot synchronize state
- Complete loss of node functionality

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program because it causes:

1. **Validator node slowdowns**: Nodes repeatedly fail state sync attempts, wasting computational resources and causing performance degradation.

2. **Significant protocol violations**: The misconfiguration violates the Resource Limits invariant that "all operations must respect gas, storage, and computational limits" by allowing network message configurations that exceed system limits.

3. **Effective node unavailability**: Nodes cannot sync state, making them unable to participate in consensus, validate transactions, or serve clients - functionally equivalent to a denial of service.

While not reaching Critical severity (no fund loss, no consensus safety violations), the impact is severe as it can render entire nodes or validator networks non-functional through simple configuration errors.

## Likelihood Explanation

The likelihood is **MEDIUM to HIGH** because:

1. **Ease of trigger**: Requires only configuration file modification, no complex attack or privileged access
2. **Honest mistakes**: Node operators unfamiliar with internal limits could easily misconfigure values
3. **No warning on startup**: Nodes start successfully with invalid configuration and only fail during state sync operations
4. **Cascading failures**: If configuration templates are distributed with invalid values, multiple nodes can be simultaneously affected
5. **Difficult diagnosis**: Failures manifest as network errors rather than configuration errors, making troubleshooting challenging

## Recommendation

Implement a `ConfigSanitizer` for `StorageServiceConfig` that validates:

1. `max_network_chunk_bytes` and `max_network_chunk_bytes_v2` do not exceed `MAX_APPLICATION_MESSAGE_SIZE`
2. These values are greater than reasonable minimums (e.g., 1 MB) to ensure at least some data items can fit
3. Chunk size configurations are reasonable relative to network limits

**Proposed fix:**

```rust
impl ConfigSanitizer for StorageServiceConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let storage_service_config = &node_config.state_sync.storage_service;

        // Import MAX_APPLICATION_MESSAGE_SIZE from network config
        use crate::config::network_config::MAX_APPLICATION_MESSAGE_SIZE;
        
        // Minimum reasonable chunk size (1 MB)
        const MIN_NETWORK_CHUNK_BYTES: u64 = 1024 * 1024;

        // Validate max_network_chunk_bytes
        if storage_service_config.max_network_chunk_bytes < MIN_NETWORK_CHUNK_BYTES {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "max_network_chunk_bytes ({}) is too small! Must be at least {} bytes",
                    storage_service_config.max_network_chunk_bytes,
                    MIN_NETWORK_CHUNK_BYTES
                ),
            ));
        }

        if storage_service_config.max_network_chunk_bytes > MAX_APPLICATION_MESSAGE_SIZE as u64 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "max_network_chunk_bytes ({}) exceeds network layer limit ({})!",
                    storage_service_config.max_network_chunk_bytes,
                    MAX_APPLICATION_MESSAGE_SIZE
                ),
            ));
        }

        // Validate max_network_chunk_bytes_v2
        if storage_service_config.max_network_chunk_bytes_v2 > MAX_APPLICATION_MESSAGE_SIZE as u64 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "max_network_chunk_bytes_v2 ({}) exceeds network layer limit ({})!",
                    storage_service_config.max_network_chunk_bytes_v2,
                    MAX_APPLICATION_MESSAGE_SIZE
                ),
            ));
        }

        Ok(())
    }
}
```

Also update `StateSyncConfig::sanitize()` to call this new sanitizer:

```rust
impl ConfigSanitizer for StateSyncConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // Sanitize the state sync driver config
        StateSyncDriverConfig::sanitize(node_config, node_type, chain_id)?;
        
        // Sanitize the storage service config
        StorageServiceConfig::sanitize(node_config, node_type, chain_id)?;
        
        Ok(())
    }
}
```

## Proof of Concept

**Step 1**: Create a node configuration file `node_config.yaml` with oversized chunk limits:

```yaml
state_sync:
  storage_service:
    max_network_chunk_bytes: 70000000  # 70 MB - exceeds 64 MiB network limit
    max_state_chunk_size: 4000
```

**Step 2**: Start an Aptos node with this configuration. The node will start successfully despite the invalid configuration.

**Step 3**: Trigger state sync by requesting state data from the node. The storage service will attempt to create responses up to 70 MB, but the network layer will reject them with an error similar to:
```
Message length 70000000 exceeds max message size 67108864!
```

**Step 4**: Observe repeated state sync failures in logs, node unable to sync state, complete loss of functionality.

**Alternative PoC with undersized limit:**

```yaml
state_sync:
  storage_service:
    max_network_chunk_bytes: 1000  # 1 KB - too small for typical state values
```

This causes the storage service to return single oversized items that still exceed 1 KB but are returned anyway due to the "always allow first item" logic, leading to guaranteed failures when typical state values exceed 1 KB.

## Notes

This vulnerability is particularly concerning because:

1. The default values (10 MiB for v1, 40 MiB for v2) are safe and within network limits, so the issue only manifests with custom configurations
2. There's no validation at configuration load time, so errors only appear during runtime state sync operations
3. The error messages from the network layer don't clearly indicate a configuration problem
4. Impact is severe but localized to misconfigured nodes (doesn't affect network-wide consensus)
5. The fix is straightforward - adding sanitization logic similar to existing patterns in the codebase

### Citations

**File:** config/src/config/state_sync_config.rs (L16-21)
```rust
// The maximum message size per state sync message
const SERVER_MAX_MESSAGE_SIZE: usize = 10 * 1024 * 1024; // 10 MiB

// The maximum message size per state sync message (for v2 data requests)
const CLIENT_MAX_MESSAGE_SIZE_V2: usize = 20 * 1024 * 1024; // 20 MiB (used for v2 data requests)
const SERVER_MAX_MESSAGE_SIZE_V2: usize = 40 * 1024 * 1024; // 40 MiB (used for v2 data requests)
```

**File:** config/src/config/state_sync_config.rs (L156-172)
```rust
pub struct StorageServiceConfig {
    /// Whether to enable size and time-aware chunking
    pub enable_size_and_time_aware_chunking: bool,
    /// Whether transaction data v2 is enabled
    pub enable_transaction_data_v2: bool,
    /// Maximum number of epoch ending ledger infos per chunk
    pub max_epoch_chunk_size: u64,
    /// Maximum number of invalid requests per peer
    pub max_invalid_requests_per_peer: u64,
    /// Maximum number of items in the lru cache before eviction
    pub max_lru_cache_size: u64,
    /// Maximum number of pending network messages
    pub max_network_channel_size: u64,
    /// Maximum number of bytes to send per network message
    pub max_network_chunk_bytes: u64,
    /// Maximum number of bytes to send per network message (for v2 data)
    pub max_network_chunk_bytes_v2: u64,
```

**File:** config/src/config/state_sync_config.rs (L487-520)
```rust
impl ConfigSanitizer for StateSyncConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // Sanitize the state sync driver config
        StateSyncDriverConfig::sanitize(node_config, node_type, chain_id)
    }
}

impl ConfigSanitizer for StateSyncDriverConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let state_sync_driver_config = &node_config.state_sync.state_sync_driver;

        // Verify that auto-bootstrapping is not enabled for
        // nodes that are fast syncing.
        let fast_sync_enabled = state_sync_driver_config.bootstrapping_mode.is_fast_sync();
        if state_sync_driver_config.enable_auto_bootstrapping && fast_sync_enabled {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Auto-bootstrapping should not be enabled for nodes that are fast syncing!"
                    .to_string(),
            ));
        }

        Ok(())
    }
}
```

**File:** state-sync/storage-service/server/src/storage.rs (L1005-1006)
```rust
            if num_state_values_to_fetch == 1 {
                return Ok(state_value_chunk_with_proof); // We cannot return less than a single item
```

**File:** state-sync/storage-service/server/src/storage.rs (L1399-1412)
```rust
    pub fn data_items_fits_in_response(
        &self,
        always_allow_first_item: bool,
        serialized_data_size: u64,
    ) -> bool {
        if always_allow_first_item && self.num_items_fetched == 0 {
            true // We always include at least one item
        } else {
            let new_serialized_data_size = self
                .serialized_data_size
                .saturating_add(serialized_data_size);
            new_serialized_data_size < self.max_response_size
        }
    }
```

**File:** config/src/config/network_config.rs (L45-50)
```rust
pub const MAX_MESSAGE_METADATA_SIZE: usize = 128 * 1024; /* 128 KiB: a buffer for metadata that might be added to messages by networking */
pub const MESSAGE_PADDING_SIZE: usize = 2 * 1024 * 1024; /* 2 MiB: a safety buffer to allow messages to get larger during serialization */
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** network/framework/src/protocols/stream/mod.rs (L266-273)
```rust
        // Verify that the message size is within limits
        let message_data_len = message.data_len();
        ensure!(
            message_data_len <= self.max_message_size,
            "Message length {} exceeds max message size {}!",
            message_data_len,
            self.max_message_size,
        );
```
