# Audit Report

## Title
Consensus Observer Payload Store Denial of Service via Far-Future Epoch Payloads

## Summary
An attacker can permanently fill the consensus observer's block payload store with unverified payloads for a far-future epoch, preventing legitimate payloads from being inserted and causing a persistent denial of service for consensus observer nodes.

## Finding Description

The consensus observer's `BlockPayloadStore` implements a bounded cache with a maximum of 150 payloads (default) or 300 payloads (test networks) to prevent unbounded memory growth. [1](#0-0) 

However, the payload insertion logic has a critical flaw: it accepts payloads for far-future epochs without validation, and these payloads are never removed by the cleanup logic.

When a `BlockPayload` message is received in `process_block_payload_message`, the system performs three checks: [2](#0-1) 

The first check only rejects payloads that are **behind** the last ordered block, not those that are far ahead. Payloads for future epochs are accepted as "unverified" since signature verification is only performed for the current epoch: [3](#0-2) 

The payload store enforces a size limit before insertion: [4](#0-3) 

The cleanup logic in `remove_blocks_for_epoch_round` uses `split_off` which **keeps** all payloads with keys greater than or equal to the specified epoch/round: [5](#0-4) 

This means payloads for future epochs are never cleaned up. Additionally, the signature verification process explicitly skips verification for future epochs: [6](#0-5) 

**Attack Scenario:**

1. Attacker sends 150 `BlockPayload` messages for epoch 1000000, rounds 0-149 (with invalid/dummy signatures and minimal transaction data)
2. Each payload passes the "out of date" check since epoch 1000000 > current epoch
3. Payloads are stored as "unverified" since signature verification is skipped for future epochs
4. The payload store reaches its maximum capacity (150/150)
5. All subsequent legitimate payloads are rejected with a warning and dropped
6. When blocks are committed at the current epoch, `remove_blocks_for_epoch_round(current_epoch, round)` only removes payloads for epochs â‰¤ current_epoch
7. The malicious payloads for epoch 1000000 remain in the store indefinitely
8. The consensus observer node cannot receive new block payloads and cannot sync with the network

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos bug bounty criteria:

- **"Validator node slowdowns"**: Validator fullnodes (VFNs) running consensus observer cannot sync, causing performance degradation
- **"Significant protocol violations"**: The consensus observer protocol is designed to enable efficient block synchronization, but this vulnerability completely breaks that functionality

The attack affects all nodes running the consensus observer (validator fullnodes and optionally public fullnodes), preventing them from receiving block payloads through the consensus observer mechanism. While nodes can fall back to state sync, this degrades network performance and violates the intended design of the consensus observer system.

This breaks **Invariant #9 (Resource Limits)**: "All operations must respect gas, storage, and computational limits" - the payload store is designed to be bounded, but an attacker can fill it with garbage data that never gets cleaned up.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attack Complexity: LOW** - The attacker only needs to send 150 network messages with payloads for a far-future epoch
- **Attacker Requirements: MINIMAL** - Any network peer can send consensus observer messages
- **Persistence: PERMANENT** - The malicious payloads remain in the store forever, requiring node restart or manual intervention
- **Detection: DIFFICULT** - The attack appears as normal consensus observer traffic until the store fills up
- **Mitigation: NONE** - No rate limiting or epoch validation prevents this attack

The attack is trivial to execute and has a permanent effect, making it a serious operational risk for consensus observer deployments.

## Recommendation

Implement epoch-based validation to reject payloads that are too far ahead of the current epoch. Add a check in `process_block_payload_message` before accepting payloads:

```rust
// Reject payloads that are too far in the future (e.g., more than 2 epochs ahead)
const MAX_FUTURE_EPOCHS: u64 = 2;
let current_epoch = self.get_epoch_state().epoch;
if block_epoch > current_epoch + MAX_FUTURE_EPOCHS {
    warn!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Rejecting block payload from far-future epoch! Block: {:?}, Current epoch: {:?}, from peer: {:?}",
            block_payload.block(), current_epoch, peer_network_id
        ))
    );
    update_metrics_for_dropped_block_payload_message(peer_network_id, &block_payload);
    return;
}
```

Additionally, implement periodic garbage collection to remove old unverified payloads:

```rust
// In BlockPayloadStore, add a method to remove stale unverified payloads
pub fn garbage_collect_stale_payloads(&mut self, current_epoch: u64) {
    let mut block_payloads = self.block_payloads.lock();
    block_payloads.retain(|&(epoch, _round), status| {
        // Keep verified payloads and recent unverified payloads
        matches!(status, BlockPayloadStatus::AvailableAndVerified(_)) 
            || epoch <= current_epoch + 2
    });
}
```

Call this garbage collection method periodically (e.g., every epoch change or during the existing garbage collection interval).

## Proof of Concept

```rust
#[tokio::test]
async fn test_far_future_epoch_payload_dos() {
    // Create a consensus observer with default config
    let consensus_observer_config = ConsensusObserverConfig::default();
    let max_pending_blocks = consensus_observer_config.max_num_pending_blocks;
    
    // Initialize observer block data
    let root = create_ledger_info(0, 0); // Current epoch 0, round 0
    let mut observer_block_data = ObserverBlockData::new_with_root(
        consensus_observer_config,
        root.clone()
    );
    
    // Attack: Fill the store with payloads for a far-future epoch
    let malicious_epoch = 1000000;
    for round in 0..max_pending_blocks {
        let block_payload = create_block_payload(malicious_epoch, round);
        observer_block_data.insert_block_payload(block_payload, false); // Unverified
    }
    
    // Verify the store is full
    let payload_count = observer_block_data.get_block_payloads().lock().len();
    assert_eq!(payload_count, max_pending_blocks as usize);
    
    // Attempt to insert a legitimate payload for current epoch
    let legitimate_payload = create_block_payload(0, 1);
    observer_block_data.insert_block_payload(legitimate_payload.clone(), true);
    
    // The legitimate payload should be rejected (store still at max)
    assert!(!observer_block_data.existing_payload_entry(&legitimate_payload));
    assert_eq!(
        observer_block_data.get_block_payloads().lock().len(),
        max_pending_blocks as usize
    );
    
    // Simulate block commitment at current epoch
    observer_block_data.handle_committed_blocks(create_ledger_info(0, 100));
    
    // Malicious payloads for epoch 1000000 should still exist
    let payload_count_after_cleanup = observer_block_data.get_block_payloads().lock().len();
    assert_eq!(payload_count_after_cleanup, max_pending_blocks as usize);
    
    // The legitimate payload still cannot be inserted
    observer_block_data.insert_block_payload(legitimate_payload.clone(), true);
    assert!(!observer_block_data.existing_payload_entry(&legitimate_payload));
    
    println!("DoS attack successful: Store filled with {} far-future payloads", 
             max_pending_blocks);
}
```

## Notes

The vulnerability exists because the system assumes payloads will eventually be committed or become stale relative to the current epoch, but it doesn't account for payloads from epochs that will never be reached. The bounded cache provides protection against unbounded growth but fails to provide protection against adversarial filling with garbage data that bypasses normal cleanup mechanisms.

### Citations

**File:** config/src/config/consensus_observer_config.rs (L72-72)
```rust
            max_num_pending_blocks: 150, // 150 blocks (sufficient for existing production networks)
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L367-380)
```rust
        let last_ordered_block = self.observer_block_data.lock().get_last_ordered_block();
        let payload_out_of_date =
            (block_epoch, block_round) <= (last_ordered_block.epoch(), last_ordered_block.round());
        let payload_exists = self
            .observer_block_data
            .lock()
            .existing_payload_entry(&block_payload);

        // If the payload is out of date or already exists, ignore it
        if payload_out_of_date || payload_exists {
            // Update the metrics for the dropped block payload
            update_metrics_for_dropped_block_payload_message(peer_network_id, &block_payload);
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L401-418)
```rust
        let verified_payload = if block_epoch == epoch_state.epoch {
            // Verify the block proof signatures
            if let Err(error) = block_payload.verify_payload_signatures(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify block payload signatures! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                        block_payload.block(), peer_network_id, error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
                return;
            }

            true // We have successfully verified the signatures
        } else {
            false // We can't verify the signatures yet
        };
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L84-95)
```rust
        // Verify that the number of payloads doesn't exceed the maximum
        let max_num_pending_blocks = self.consensus_observer_config.max_num_pending_blocks as usize;
        if self.block_payloads.lock().len() >= max_num_pending_blocks {
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Exceeded the maximum number of payloads: {:?}. Dropping block: {:?}!",
                    max_num_pending_blocks,
                    block_payload.block(),
                ))
            );
            return; // Drop the block if we've exceeded the maximum
        }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L112-119)
```rust
    pub fn remove_blocks_for_epoch_round(&self, epoch: u64, round: Round) {
        // Determine the round to split off
        let split_off_round = round.saturating_add(1);

        // Remove the blocks from the payload store
        let mut block_payloads = self.block_payloads.lock();
        *block_payloads = block_payloads.split_off(&(epoch, split_off_round));
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L228-231)
```rust
            // Check if we can break early (BtreeMaps are sorted by key)
            if epoch > current_epoch {
                break;
            }
```
