# Audit Report

## Title
Event Data Bandwidth Amplification Bypass via Single Transaction Exemption in TransactionsWithProofRequest

## Summary
The Aptos state-sync storage service allows attackers to bypass the configured `max_network_chunk_bytes` limit (10 MiB) by requesting single transactions with `include_events=true`. Both the legacy and new implementations exempt the first transaction from size validation, enabling responses that can be 10-100x larger than the intended limit, causing bandwidth exhaustion and network congestion.

## Finding Description
The storage service implements two code paths for serving `TransactionsWithProofRequest` with events:

**Legacy Implementation (Default):** [1](#0-0) 

The legacy implementation returns a single transaction without validating it against the size limit: [2](#0-1) 

The size check only occurs for `num_transactions_to_fetch > 1`: [3](#0-2) 

**New Implementation:**
Even when size-aware chunking is enabled, the first transaction is always allowed regardless of size: [4](#0-3) 

This parameter is set to `true` in the calling code: [5](#0-4) 

**Attack Vector:**
The `TransactionsWithProofRequest` struct allows clients to specify version ranges and event inclusion: [6](#0-5) 

An attacker can:
1. Identify transactions on the Aptos blockchain with extremely large events (e.g., contract deployments, large data structure emissions)
2. Send a `TransactionsWithProofRequest` with `start_version == end_version` (single transaction) and `include_events=true`
3. The server fetches the transaction with all events
4. The response bypasses the 10 MiB limit entirely, returning potentially 50 MiB, 100 MiB, or more
5. Repeat with different large transactions to exhaust bandwidth

The configured network limit is 10 MiB: [7](#0-6) [8](#0-7) 

## Impact Explanation
**Severity: HIGH** (Validator node slowdowns, API crashes, significant protocol violations)

This vulnerability enables:
- **Bandwidth Exhaustion**: A single malicious client can request multiple large transactions, consuming 10-100x more bandwidth than intended
- **Network Congestion**: Repeated requests saturate network connections between validators and full nodes
- **Validator Slowdowns**: Storage service threads become blocked serving oversized responses, degrading node performance
- **Resource Starvation**: Memory consumption for BCS serialization of large responses can cause OOM conditions

The impact aligns with "Validator node slowdowns" and "API crashes" under High Severity in the Aptos Bug Bounty program.

## Likelihood Explanation
**Likelihood: HIGH**

- **Attack Complexity: Low** - Attacker only needs to identify transactions with large events (publicly observable on-chain) and send standard RPC requests
- **No Special Privileges Required** - Any network peer can send storage service requests
- **Default Configuration Vulnerable** - Legacy implementation is the default path
- **Realistic on Mainnet** - Aptos blockchain contains transactions with large events from:
  - Smart contract deployments (large bytecode)
  - NFT minting events with embedded metadata
  - Large data structure emissions
  - Governance proposal events with extensive metadata

The attack is trivially executable and requires only knowledge of which transaction versions contain large events.

## Recommendation
Implement a hard size limit for single-item responses to prevent bandwidth amplification while maintaining the ability to serve at least minimal data:

```rust
// In get_transactions_with_proof_by_size_legacy
if num_transactions_to_fetch == 1 {
    // Still check if single item exceeds a reasonable hard limit
    let (overflow_frame, num_bytes) = check_overflow_network_frame(&response, max_response_size)?;
    if overflow_frame {
        // Define a hard limit for single items (e.g., 2x normal limit)
        const SINGLE_ITEM_HARD_LIMIT: u64 = SERVER_MAX_MESSAGE_SIZE * 2;
        if num_bytes > SINGLE_ITEM_HARD_LIMIT {
            return Err(Error::UnexpectedErrorEncountered(format!(
                "Single transaction at version {} exceeds hard limit: {} bytes (limit: {})",
                start_version, num_bytes, SINGLE_ITEM_HARD_LIMIT
            )));
        }
        warn!("Returning single transaction that exceeds normal size limit: {} bytes", num_bytes);
    }
    return Ok(response);
}
```

For the new implementation, modify `data_items_fits_in_response`:
```rust
pub fn data_items_fits_in_response(
    &self,
    always_allow_first_item: bool,
    serialized_data_size: u64,
) -> bool {
    if always_allow_first_item && self.num_items_fetched == 0 {
        // Still enforce a hard limit even for the first item
        const SINGLE_ITEM_HARD_LIMIT: u64 = SERVER_MAX_MESSAGE_SIZE * 2;
        return serialized_data_size < SINGLE_ITEM_HARD_LIMIT;
    }
    // ... rest of function
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_bandwidth_amplification_via_large_events() {
    use aptos_storage_service_server::StorageReader;
    use aptos_storage_service_types::requests::{StorageServiceRequest, TransactionsWithProofRequest};
    use aptos_config::config::StorageServiceConfig;
    
    // Setup: Mock storage with a transaction containing 50 MiB of events
    let mock_storage = setup_mock_storage_with_large_event_transaction();
    let config = StorageServiceConfig::default(); // 10 MiB limit
    let storage_reader = StorageReader::new(config, mock_storage, TimeService::mock());
    
    // Attack: Request single transaction with events
    let request = TransactionsWithProofRequest {
        proof_version: 1000,
        start_version: 500, // Transaction with 50 MiB events
        end_version: 500,   // Same version = single transaction
        include_events: true,
    };
    
    // Execute request
    let response = storage_reader.get_transactions_with_proof(
        request.proof_version,
        request.start_version,
        request.end_version,
        request.include_events,
    ).unwrap();
    
    // Verify: Response bypasses 10 MiB limit
    let serialized = bcs::to_bytes(&response).unwrap();
    let response_size = serialized.len();
    
    assert!(response_size > 50_000_000, "Response size: {} bytes", response_size);
    assert!(response_size > config.max_network_chunk_bytes * 5,
        "Amplification factor: {}x", 
        response_size / config.max_network_chunk_bytes);
    
    println!("Bandwidth amplification successful!");
    println!("Configured limit: {} MiB", config.max_network_chunk_bytes / 1024 / 1024);
    println!("Actual response: {} MiB", response_size / 1024 / 1024);
    println!("Amplification: {}x", response_size / config.max_network_chunk_bytes);
}
```

This vulnerability is a clear violation of the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The bandwidth consumption far exceeds the configured limits, enabling DoS attacks against validator nodes.

### Citations

**File:** config/src/config/state_sync_config.rs (L17-17)
```rust
const SERVER_MAX_MESSAGE_SIZE: usize = 10 * 1024 * 1024; // 10 MiB
```

**File:** config/src/config/state_sync_config.rs (L198-198)
```rust
            enable_size_and_time_aware_chunking: false,
```

**File:** config/src/config/state_sync_config.rs (L204-204)
```rust
            max_network_chunk_bytes: SERVER_MAX_MESSAGE_SIZE as u64,
```

**File:** state-sync/storage-service/server/src/storage.rs (L438-439)
```rust
                    if response_progress_tracker
                        .data_items_fits_in_response(true, total_serialized_bytes)
```

**File:** state-sync/storage-service/server/src/storage.rs (L536-537)
```rust
            if num_transactions_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
```

**File:** state-sync/storage-service/server/src/storage.rs (L540-554)
```rust
            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&response, max_response_size)?;
            if !overflow_frame {
                return Ok(response);
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::TransactionDataWithProof(response).get_label(),
                );
                let new_num_transactions_to_fetch = num_transactions_to_fetch / 2;
                debug!("The request for {:?} transactions was too large (num bytes: {:?}, limit: {:?}). Retrying with {:?}.",
                    num_transactions_to_fetch, num_bytes, max_response_size, new_num_transactions_to_fetch);
                num_transactions_to_fetch = new_num_transactions_to_fetch; // Try again with half the amount of data
            }
```

**File:** state-sync/storage-service/server/src/storage.rs (L1404-1405)
```rust
        if always_allow_first_item && self.num_items_fetched == 0 {
            true // We always include at least one item
```

**File:** state-sync/storage-service/types/src/requests.rs (L362-367)
```rust
pub struct TransactionsWithProofRequest {
    pub proof_version: u64,   // The version the proof should be relative to
    pub start_version: u64,   // The starting version of the transaction list
    pub end_version: u64,     // The ending version of the transaction list (inclusive)
    pub include_events: bool, // Whether or not to include events in the response
}
```
