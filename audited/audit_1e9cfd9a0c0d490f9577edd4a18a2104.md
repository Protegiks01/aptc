# Audit Report

## Title
Sigma Protocol Soundness Violation: Identity Element Statements Allow Trivial Proofs in DKG

## Summary
The `TupleHomomorphism` sigma protocol implementation in `aptos-dkg` lacks validation to prevent statements containing identity elements. When the public statement consists of identity elements, the verification equation degenerates, allowing an attacker to construct proofs that verify without proving knowledge of any valid witness. This breaks the soundness guarantee of the proof system and could compromise the security of the Distributed Key Generation (DKG) protocol.

## Finding Description

The `apply()` function in `TupleHomomorphism` correctly implements the mathematical properties of a group homomorphism, mapping the identity element of the domain to identity elements in both codomains. [1](#0-0) 

However, the sigma protocol verification in `PairingTupleHomomorphism` does not validate that the public statement is non-trivial (i.e., not composed entirely of identity elements). [2](#0-1) 

The verification computes MSM terms that check: `homomorphism.apply(z) - A - c*statement == 0`, where `z` is the prover's response, `A` is the commitment, `c` is the Fiat-Shamir challenge, and `statement` is the public statement. [3](#0-2) 

**When the statement contains identity elements**, the term `-c*statement` contributes nothing (since scalar multiplication with identity yields identity, and group operations with identity are no-ops). The verification equation degenerates to: `homomorphism.apply(z) - A == 0`.

An attacker can exploit this by:
1. Constructing a statement with identity elements: range_proof_commitment = identity in G1, and all ciphertexts/randomness (Cs, Rs) = identity elements
2. Sampling random `r` from the domain
3. Computing commitment `A = homomorphism.apply(r)`
4. Computing Fiat-Shamir challenge `c` (which is deterministic from the statement and A)
5. Setting response `z = r` (without using any actual witness!)
6. The verification passes: `homomorphism.apply(r) == A` (trivially true)

This breaks the **soundness property** of the Σ-protocol: the prover has not demonstrated knowledge of any witness `w` satisfying `homomorphism.apply(w) = statement`.

In the DKG context, the vulnerable verification is invoked when checking transcript validity. [4](#0-3) 

The system does not validate that ciphertexts or commitments are non-identity during transcript deserialization or verification. [5](#0-4) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program because it represents a significant protocol violation in the DKG cryptographic foundation.

**Security Impact:**
- **Cryptographic Correctness Violation**: The zero-knowledge proof system's soundness guarantee is broken
- **DKG Compromise**: If a malicious transcript with identity elements is aggregated with legitimate transcripts, it contributes zero entropy to the final DKG secret
- **Validator Security Risk**: A weakened DKG output could compromise validator key generation, affecting consensus participation

While the normal `deal()` function always generates non-trivial statements through randomness sampling, the lack of validation creates an attack surface for manually-crafted malicious transcripts. [6](#0-5) 

## Likelihood Explanation

The likelihood is **Medium** because:

**Barriers to exploitation:**
- Attacker must bypass the standard `deal()` function and craft a custom transcript
- The transcript must be accepted by the system (serialization/network layer)
- Other validation checks (range proof, low-degree test) might provide partial mitigation

**Factors increasing likelihood:**
- No validation exists anywhere in the codebase to check for identity elements in statements
- The deserialization path has no cryptographic validation
- The mathematical vulnerability is fundamental to the protocol design

The absence of any `is_identity()` or `is_zero()` checks for G1/G2 elements in the transcript verification confirms this attack surface remains unprotected.

## Recommendation

Add validation to reject statements containing identity elements before sigma protocol verification:

```rust
// In PairingTupleHomomorphism::verify()
pub fn verify<Ct: Serialize, H>(
    &self,
    public_statement: &<Self as homomorphism::Trait>::Codomain,
    proof: &Proof<H1::Scalar, H>,
    cntxt: &Ct,
) -> anyhow::Result<()>
where
    H: homomorphism::Trait<...>,
{
    // Validate statement components are not identity elements
    ensure!(
        !public_statement.0.clone().into_iter().all(|p| p.is_zero()),
        "First component of statement cannot be all identity elements"
    );
    ensure!(
        !public_statement.1.chunks.iter().flatten().all(|c| c.is_zero()),
        "Ciphertext chunks cannot be all identity elements"
    );
    ensure!(
        !public_statement.1.randomness.iter().flatten().all(|r| r.is_zero()),
        "Randomness components cannot be all identity elements"
    );
    
    // Proceed with existing verification
    let (first_msm_terms, second_msm_terms) = 
        self.msm_terms_for_verify::<_, H>(public_statement, proof, cntxt);
    // ... rest of verification
}
```

Additionally, add validation in the transcript deserialization or verification path to check for non-trivial commitments and ciphertexts.

## Proof of Concept

```rust
// Conceptual PoC demonstrating the vulnerability
#[test]
fn test_identity_statement_trivial_proof() {
    let mut rng = test_rng();
    
    // Create a homomorphism (simplified)
    let hom = create_test_tuple_homomorphism();
    
    // Construct statement with identity elements
    let identity_statement = TupleCodomainShape(
        TrivialShape(E::G1::zero()), // identity in first codomain
        WeightedCodomainShape {
            chunks: vec![vec![E::G1::zero()]], // identity ciphertexts
            randomness: vec![E::G1::zero()],   // identity randomness
        }
    );
    
    // Attacker samples random r (no real witness)
    let r = Scalar::rand(&mut rng);
    
    // Compute commitment A = hom.apply(r)
    let A = hom.apply(&r);
    
    // Compute Fiat-Shamir challenge
    let c = fiat_shamir_challenge_for_sigma_protocol(
        &context, &hom, &identity_statement, &A, &hom.dst()
    );
    
    // Set response z = r (NOT r + c*witness!)
    let z = r;
    
    // Construct "proof"
    let malicious_proof = Proof {
        first_proof_item: FirstProofItem::Commitment(A),
        z,
    };
    
    // Verification should fail but currently passes!
    let result = hom.verify(&identity_statement, &malicious_proof, &context);
    assert!(result.is_ok()); // BUG: This passes when it should fail
}
```

**Notes:**
The vulnerability exists in the mathematical protocol design where identity statements are not explicitly forbidden. The `apply()` function correctly implements homomorphism properties—mapping identity to identity is mathematically correct. However, the security issue arises from accepting such statements in the proof system without validation, allowing soundness violations.

### Citations

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L69-71)
```rust
    fn apply(&self, x: &Self::Domain) -> Self::Codomain {
        TupleCodomainShape(self.hom1.apply(x), self.hom2.apply(x))
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L299-322)
```rust
    #[allow(non_snake_case)]
    pub fn verify<Ct: Serialize, H>(
        &self,
        public_statement: &<Self as homomorphism::Trait>::Codomain,
        proof: &Proof<H1::Scalar, H>, // Would like to set &Proof<E, Self>, but that ties the lifetime of H to that of Self, but we'd like it to be eg static
        cntxt: &Ct,
    ) -> anyhow::Result<()>
    where
        H: homomorphism::Trait<
            Domain = <Self as homomorphism::Trait>::Domain,
            Codomain = <Self as homomorphism::Trait>::Codomain,
        >,
    {
        let (first_msm_terms, second_msm_terms) =
            self.msm_terms_for_verify::<_, H>(public_statement, proof, cntxt);

        let first_msm_result = H1::msm_eval(first_msm_terms);
        ensure!(first_msm_result == H1::MsmOutput::zero());

        let second_msm_result = H2::msm_eval(second_msm_terms);
        ensure!(second_msm_result == H2::MsmOutput::zero());

        Ok(())
    }
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L324-376)
```rust
    #[allow(non_snake_case)]
    fn msm_terms_for_verify<Ct: Serialize, H>(
        &self,
        public_statement: &<Self as homomorphism::Trait>::Codomain,
        proof: &Proof<H1::Scalar, H>,
        cntxt: &Ct,
    ) -> (H1::MsmInput, H2::MsmInput)
    where
        H: homomorphism::Trait<
            Domain = <Self as homomorphism::Trait>::Domain,
            Codomain = <Self as homomorphism::Trait>::Codomain,
        >, // need this?
    {
        let prover_first_message = match &proof.first_proof_item {
            FirstProofItem::Commitment(A) => A,
            FirstProofItem::Challenge(_) => {
                panic!("Missing implementation - expected commitment, not challenge")
            },
        };
        let c = fiat_shamir_challenge_for_sigma_protocol::<_, H1::Scalar, _>(
            cntxt,
            self,
            public_statement,
            &prover_first_message,
            &self.dst(),
        );

        let mut rng = ark_std::rand::thread_rng(); // TODO: make this part of the function input?
        let beta = H1::Scalar::rand(&mut rng); // verifier-specific challenge
        let len1 = public_statement.0.clone().into_iter().count(); // hmm maybe pass the into_iter version in merge_msm_terms?
        let len2 = public_statement.1.clone().into_iter().count();
        let powers_of_beta = utils::powers(beta, len1 + len2);
        let (first_powers_of_beta, second_powers_of_beta) = powers_of_beta.split_at(len1);

        let (first_msm_terms_of_response, second_msm_terms_of_response) = self.msm_terms(&proof.z);

        let first_input = H1::merge_msm_terms(
            first_msm_terms_of_response.into_iter().collect(),
            &prover_first_message.0,
            &public_statement.0,
            first_powers_of_beta,
            c,
        );
        let second_input = H2::merge_msm_terms(
            second_msm_terms_of_response.into_iter().collect(),
            &prover_first_message.1,
            &public_statement.1,
            second_powers_of_beta,
            c,
        );

        (first_input, second_input)
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L178-190)
```rust
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    self.sharing_proof.range_proof_commitment.clone(),
                    chunked_elgamal::WeightedCodomainShape {
                        chunks: self.subtrs.Cs.clone(),
                        randomness: self.subtrs.Rs.clone(),
                    },
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L443-450)
```rust
impl<E: Pairing> TryFrom<&[u8]> for Transcript<E> {
    type Error = CryptoMaterialError;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        bcs::from_bytes::<Transcript<E>>(bytes)
            .map_err(|_| CryptoMaterialError::DeserializationError)
    }
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L488-543)
```rust
    fn deal<A: Serialize + Clone, R: rand_core::RngCore + rand_core::CryptoRng>(
        sc: &Self::SecretSharingConfig,
        pp: &Self::PublicParameters,
        _ssk: &Self::SigningSecretKey,
        spk: &Self::SigningPubKey,
        eks: &[Self::EncryptPubKey],
        s: &Self::InputSecret,
        session_id: &A,
        dealer: &Player,
        rng: &mut R,
    ) -> Self {
        debug_assert_eq!(
            eks.len(),
            sc.get_total_num_players(),
            "Number of encryption keys must equal total weight"
        );

        // Initialize the PVSS SoK context
        let sok_cntxt = (spk.clone(), session_id, dealer.id, DST.to_vec()); // This is a bit hacky; also get rid of DST here and use self.dst? Would require making `self` input of `deal()`

        // Generate the Shamir secret sharing polynomial
        let mut f = vec![*s.get_secret_a()]; // constant term of polynomial
        f.extend(sample_field_elements::<E::ScalarField, _>(
            sc.get_threshold_weight() - 1,
            rng,
        )); // these are the remaining coefficients; total degree is `t - 1`, so the reconstruction threshold is `t`

        // Generate its `n` evaluations (shares) by doing an FFT over the whole domain, then truncating
        let mut f_evals = sc.get_threshold_config().domain.fft(&f);
        f_evals.truncate(sc.get_total_weight());
        debug_assert_eq!(f_evals.len(), sc.get_total_weight());

        // Encrypt the chunked shares and generate the sharing proof
        let (Cs, Rs, sharing_proof) =
            Self::encrypt_chunked_shares(&f_evals, eks, pp, sc, sok_cntxt, rng);

        // Add constant term for the `\mathbb{G}_2` commitment (we're doing this **after** the previous step
        // because we're now mutating `f_evals` by enlarging it; this is an unimportant technicality however,
        // it has no impact on computational complexity whatsoever as we could simply modify the `commit_to_scalars()`
        // function to take another input)
        f_evals.push(f[0]); // or *s.get_secret_a()

        // Commit to polynomial evaluations + constant term
        let G_2 = pp.get_commitment_base();
        let flattened_Vs = arkworks::commit_to_scalars(&G_2, &f_evals);
        debug_assert_eq!(flattened_Vs.len(), sc.get_total_weight() + 1);

        let Vs = sc.group_by_player(&flattened_Vs); // This won't use the last item in `flattened_Vs` because of `sc`
        let V0 = *flattened_Vs.last().unwrap();

        Transcript {
            dealer: *dealer,
            subtrs: Subtranscript { V0, Vs, Cs, Rs },
            sharing_proof,
        }
    }
```
