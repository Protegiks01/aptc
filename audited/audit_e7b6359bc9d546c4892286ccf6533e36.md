# Audit Report

## Title
Peer Monitoring Service Lacks Exponential Backoff on NetworkError, Enabling Resource Exhaustion DoS

## Summary
The peer monitoring service client does not implement exponential backoff when retrying failed requests after receiving `NetworkError` responses. Instead, it retries at a fixed interval regardless of consecutive failure count, and fails to disconnect peers even after repeated failures. This allows attackers to cause resource exhaustion by injecting transient network errors, forcing the monitoring client to continuously retry at full rate.

## Finding Description

When the peer monitoring service client encounters a `NetworkError`, the error handling flow is as follows:

1. **Error Creation**: Network errors are converted to `Error::NetworkError` [1](#0-0) 

2. **Error Propagation**: When `send_request_to_peer` fails, the error propagates to the request task [2](#0-1) 

3. **Failure Recording**: Each state handler (NetworkInfoState, NodeInfoState, LatencyInfoState) calls `handle_request_failure()` which increments a failure counter [3](#0-2) 

4. **No Backoff Logic**: The `RequestTracker` only checks if the fixed `request_interval_usec` has elapsed, with no exponential backoff based on failure count [4](#0-3) 

5. **Failure Counter Not Used**: While failures are tracked in `num_consecutive_request_failures`, this counter is only used for logging warnings, not for implementing backoff or peer disconnection [5](#0-4) 

6. **No Peer Disconnection**: Even when failures exceed the configured threshold (`max_latency_ping_failures`), the system only logs a warning but does not disconnect the peer (note the TODO comment) [6](#0-5) 

**Attack Scenario**: An attacker controlling a malicious peer or with the ability to inject transient network errors (packet drops, connection resets) can trigger repeated `NetworkError` responses. The monitoring client will:
- Continue retrying at the same fixed interval (default: 30s for latency, 60s for network info, 15s for node info)
- Never implement exponential backoff to reduce retry frequency
- Never disconnect the failing peer despite repeated failures
- Waste CPU, memory, and network resources processing failing requests

This contrasts with other parts of the Aptos codebase that properly implement exponential backoff, such as the connectivity manager's dial retry logic and the storage service moderator's unhealthy peer handling.

## Impact Explanation

**Medium Severity** - This vulnerability allows resource exhaustion attacks that can degrade node performance:

- **Resource Consumption**: Monitoring clients waste resources continuously sending requests to failing peers at full rate
- **Amplification Effect**: Multiple malicious peers can multiply the resource exhaustion impact
- **No Circuit Breaking**: Lack of peer disconnection means the attack continues indefinitely until manual intervention
- **DoS Potential**: On nodes monitoring many peers, this could significantly impact available resources for critical consensus operations

The impact qualifies as **Medium Severity** per Aptos bug bounty criteria as it enables "state inconsistencies requiring intervention" through resource exhaustion affecting node health monitoring and peer management.

## Likelihood Explanation

**High Likelihood**: 
- Transient network errors occur naturally in distributed systems
- An attacker can trivially inject network errors through packet manipulation
- The attack requires no special privileges - any network peer can trigger it
- Default configuration values make the issue immediately exploitable
- The vulnerability is present in all monitoring request types (latency, network info, node info)

## Recommendation

Implement exponential backoff for request retries based on consecutive failure count. Modify `RequestTracker` to:

1. **Add exponential backoff calculation**:
```rust
pub fn get_backoff_interval_usec(&self) -> u64 {
    if self.num_consecutive_request_failures == 0 {
        self.request_interval_usec
    } else {
        // Exponential backoff: interval * 2^(failures - 1), capped at max
        let backoff_multiplier = 2u64.saturating_pow(
            (self.num_consecutive_request_failures - 1).min(5) as u32
        );
        self.request_interval_usec.saturating_mul(backoff_multiplier).min(
            self.request_interval_usec * 32 // Cap at 32x original interval
        )
    }
}
```

2. **Use backoff interval in retry logic** [7](#0-6) 

3. **Implement peer disconnection** when failures exceed threshold [6](#0-5) 

4. **Add configuration** for max backoff multiplier in `PeerMonitoringServiceConfig` [8](#0-7) 

## Proof of Concept

```rust
#[tokio::test]
async fn test_network_error_no_backoff_dos() {
    use aptos_time_service::TimeService;
    use std::time::Duration;
    
    // Create request tracker with 1 second interval
    let request_interval_ms = 1000;
    let time_service = TimeService::mock();
    let mut request_tracker = RequestTracker::new(request_interval_ms, time_service.clone());
    
    let mock_time = time_service.into_mock();
    
    // Simulate 10 consecutive failures
    for i in 0..10 {
        // Mark request as started
        request_tracker.request_started();
        mock_time.advance(Duration::from_millis(100));
        
        // Mark request as completed with failure
        request_tracker.request_completed();
        request_tracker.record_response_failure();
        
        // Advance time by the interval
        mock_time.advance(Duration::from_millis(request_interval_ms + 1));
        
        // Verify that a new request is required immediately
        // (no exponential backoff is applied)
        assert!(request_tracker.new_request_required(),
                "Request should be required after failure #{}, but no backoff is applied", i + 1);
        
        // Verify failure count increases
        assert_eq!(request_tracker.get_num_consecutive_failures(), i + 1);
    }
    
    // After 10 failures, system still retries at same 1-second interval
    // Expected: Should use exponential backoff (2s, 4s, 8s, 16s, 32s...)
    // Actual: Still uses fixed 1s interval, allowing DoS
    println!("VULNERABILITY: After {} failures, still retrying at {}ms interval",
             request_tracker.get_num_consecutive_failures(),
             request_interval_ms);
}
```

This test demonstrates that after 10 consecutive failures, the system still requires new requests at the same fixed interval with no exponential backoff, enabling resource exhaustion attacks.

## Notes

This vulnerability is related to the broader issue of missing circuit breaker patterns in the peer monitoring service. While other Aptos components (connectivity manager, storage service moderator) properly implement exponential backoff using strategies from `aptos-retrier` crate or custom implementations, the peer monitoring service lacks this critical protection mechanism.

The TODO comment at [9](#0-8)  suggests this is a known gap in implementation that should be addressed.

### Citations

**File:** peer-monitoring-service/client/src/error.rs (L37-41)
```rust
impl From<aptos_network::application::error::Error> for Error {
    fn from(error: aptos_network::application::error::Error) -> Self {
        Error::NetworkError(error.to_string())
    }
}
```

**File:** peer-monitoring-service/client/src/peer_states/peer_state.rs (L124-131)
```rust
            let monitoring_service_response = match monitoring_service_response {
                Ok(monitoring_service_response) => monitoring_service_response,
                Err(error) => {
                    peer_state_value
                        .write()
                        .handle_monitoring_service_response_error(&peer_network_id, error);
                    return;
                },
```

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L160-174)
```rust
    fn handle_monitoring_service_response_error(
        &mut self,
        peer_network_id: &PeerNetworkId,
        error: Error,
    ) {
        // Handle the failure
        self.handle_request_failure();

        // Log the error
        warn!(LogSchema::new(LogEntry::NetworkInfoRequest)
            .event(LogEvent::ResponseError)
            .message("Error encountered when requesting network information from the peer!")
            .peer(peer_network_id)
            .error(&error));
    }
```

**File:** peer-monitoring-service/client/src/peer_states/request_tracker.rs (L76-90)
```rust
    pub fn new_request_required(&self) -> bool {
        // There's already an in-flight request. A new one should not be sent.
        if self.in_flight_request() {
            return false;
        }

        // Otherwise, check the last request time for freshness
        match self.last_request_time {
            Some(last_request_time) => {
                self.time_service.now()
                    > last_request_time.add(Duration::from_micros(self.request_interval_usec))
            },
            None => true, // A request should be sent immediately
        }
    }
```

**File:** peer-monitoring-service/client/src/peer_states/request_tracker.rs (L101-104)
```rust
    /// Records a failure for the request
    pub fn record_response_failure(&mut self) {
        self.num_consecutive_request_failures += 1;
    }
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L64-71)
```rust
        // TODO: If the number of ping failures is too high, disconnect from the node
        let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
        if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::TooManyPingFailures)
                .peer(peer_network_id)
                .message("Too many ping failures occurred for the peer!"));
        }
```

**File:** config/src/config/peer_monitoring_config.rs (L6-19)
```rust
#[derive(Clone, Copy, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct PeerMonitoringServiceConfig {
    pub enable_peer_monitoring_client: bool, // Whether or not to spawn the monitoring client
    pub latency_monitoring: LatencyMonitoringConfig,
    pub max_concurrent_requests: u64, // Max num of concurrent server tasks
    pub max_network_channel_size: u64, // Max num of pending network messages
    pub max_num_response_bytes: u64,  // Max num of bytes in a (serialized) response
    pub max_request_jitter_ms: u64, // Max amount of jitter (ms) that a request will be delayed for
    pub metadata_update_interval_ms: u64, // The interval (ms) between metadata updates
    pub network_monitoring: NetworkMonitoringConfig,
    pub node_monitoring: NodeMonitoringConfig,
    pub peer_monitor_interval_usec: u64, // The interval (usec) between peer monitor executions
}
```
