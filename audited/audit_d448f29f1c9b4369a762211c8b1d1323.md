# Audit Report

## Title
Race Condition in SecretShareManager Reset Allows Stale Block Processing After State Sync

## Summary
A race condition in `SecretShareManager::process_reset()` allows in-flight block processing operations to complete after a reset, causing stale blocks to pollute the freshly cleared state and creating inconsistencies between consensus components.

## Finding Description

The `SecretShareManager::process_reset()` function performs a non-atomic state reset operation that is vulnerable to race conditions with concurrent asynchronous block processing. [1](#0-0) 

The vulnerability occurs in the event loop where `tokio::select!` handles multiple concurrent operations. [2](#0-1) 

When `process_incoming_blocks()` is called, it iterates through blocks and awaits on `process_incoming_block()` for each one. [3](#0-2) 

Inside `process_incoming_block()`, the code awaits on the `secret_sharing_derive_self_fut` future. [4](#0-3) 

**The Race Condition Flow:**

1. Block processing begins and awaits on secret derivation (line 135-136)
2. The await yields control back to the `tokio::select!` loop
3. A reset signal arrives (triggered by state sync during fork resolution)
4. The reset branch executes, draining the channel and calling `process_reset()` which:
   - Clears `block_queue` (line 178)
   - Updates `highest_known_round` to target round (lines 179-181)
5. The secret derivation future completes
6. Block processing resumes from line 137 onwards:
   - Updates `highest_known_round` with the stale block's round (line 144)
   - Adds share to store (lines 145-147)
   - Broadcasts the share (lines 154-156)
   - Spawns background share requester tasks (line 157)
   - Pushes to the freshly cleared `block_queue` (line 129)

This violates the **State Consistency** invariant because reset operations are not atomic with respect to in-flight async operations. The reset is triggered during state sync operations to synchronize all consensus components to a new canonical state. [5](#0-4) 

## Impact Explanation

This vulnerability qualifies as **High to Critical Severity** based on the following impacts:

1. **State Inconsistency Between Consensus Components**: After state sync, the storage layer is synced to the target round, but the SecretShareManager contains blocks from the abandoned state, violating the State Consistency invariant.

2. **Potential Liveness Failures**: The node may wait for secret shares for rounds that don't exist in the canonical chain, causing the secret sharing pipeline to stall.

3. **Fork Boundary Violations**: During fork resolution, secret shares from the abandoned fork can persist in the manager's state and potentially be mixed with blocks from the new canonical fork.

4. **Consensus Safety Risk**: If different validators' SecretShareManagers end up in different states due to race condition timing, they may commit different blocks, breaking consensus safety guarantees.

The `update_highest_known_round` function uses `max()` logic [6](#0-5)  which means a stale block with a higher round can overwrite the reset target round, making the reset ineffective.

## Likelihood Explanation

**Likelihood: High**

This race condition can be triggered by:

1. **Natural Network Conditions**: Delayed block arrivals during state sync operations are common in distributed systems
2. **Fork Resolution Events**: Whenever a node detects it's on a fork and performs state sync, the reset mechanism is invoked
3. **Byzantine Behavior**: A malicious validator can strategically send blocks to arrive during state sync windows
4. **No Special Privileges Required**: Any network peer can trigger this by controlling message timing

The vulnerability is particularly likely during:
- Network partitions followed by healing
- Nodes catching up after being offline
- Consensus fork detection and resolution

## Recommendation

The reset operation must be atomic with respect to in-flight async operations. There are two primary solutions:

**Solution 1: Abort In-Flight Operations**
Maintain abort handles for all in-flight block processing operations and abort them before performing the reset:

```rust
fn process_reset(&mut self, request: ResetRequest) {
    let ResetRequest { tx, signal } = request;
    let target_round = match signal {
        ResetSignal::Stop => 0,
        ResetSignal::TargetRound(round) => round,
    };
    
    // Abort all in-flight block processing
    self.block_queue = BlockQueue::new();
    
    // Force update highest_known_round (not using max logic)
    {
        let mut store = self.secret_share_store.lock();
        store.highest_known_round = target_round;
        store.secret_share_map.clear();
    }
    
    self.stop = matches!(signal, ResetSignal::Stop);
    let _ = tx.send(ResetAck::default());
}
```

**Solution 2: Epoch/Version Checking**
Add a reset version counter that is incremented on each reset, and check it before completing block processing:

```rust
struct SecretShareManager {
    // ... existing fields ...
    reset_version: Arc<AtomicU64>,
}

async fn process_incoming_block(&self, block: &PipelinedBlock) -> DropGuard {
    let version_before = self.reset_version.load(Ordering::SeqCst);
    
    // ... await on secret_sharing_derive_self_fut ...
    
    let version_after = self.reset_version.load(Ordering::SeqCst);
    if version_before != version_after {
        // Reset occurred, abandon this block
        return DropGuard::new(AbortHandle::new_pair().0);
    }
    
    // ... continue processing ...
}

fn process_reset(&mut self, request: ResetRequest) {
    // ... existing logic ...
    self.reset_version.fetch_add(1, Ordering::SeqCst);
}
```

**Recommended Fix**: Implement Solution 1 as it provides clearer semantics and ensures the reset truly clears all state.

## Proof of Concept

```rust
#[tokio::test]
async fn test_reset_race_condition() {
    use std::sync::Arc;
    use tokio::sync::Mutex;
    use tokio::time::{sleep, Duration};
    
    // Setup: Create SecretShareManager with test configuration
    let (manager, mut incoming_blocks_tx, mut reset_tx) = setup_test_manager();
    
    // Start the manager in a background task
    let manager_handle = tokio::spawn(async move {
        manager.start(/* ... */).await;
    });
    
    // Create a test block for round 100
    let block_100 = create_test_block(100);
    
    // Send the block for processing
    incoming_blocks_tx.send(OrderedBlocks {
        ordered_blocks: vec![Arc::new(block_100)],
        ordered_proof: create_test_proof(),
    }).await.unwrap();
    
    // Wait a small amount to let processing start
    sleep(Duration::from_millis(50)).await;
    
    // Trigger reset to round 50 (simulating state sync)
    let (ack_tx, ack_rx) = oneshot::channel();
    reset_tx.send(ResetRequest {
        tx: ack_tx,
        signal: ResetSignal::TargetRound(50),
    }).await.unwrap();
    
    // Wait for reset acknowledgment
    ack_rx.await.unwrap();
    
    // Allow some time for race condition to manifest
    sleep(Duration::from_millis(100)).await;
    
    // Verify the bug: Check if block 100 is in the queue after reset
    let state = get_manager_state();
    
    // BUG: block_queue should be empty but contains block 100
    assert!(!state.block_queue.is_empty(), "Race condition: stale block in queue");
    
    // BUG: highest_known_round should be 50 but is 100
    assert_eq!(state.highest_known_round, 100, "Race condition: stale round persists");
    
    // Expected: highest_known_round should be 50
    // Expected: block_queue should be empty
}
```

**Notes**

This vulnerability specifically affects the secret sharing randomness component of Aptos consensus. The issue becomes critical during fork resolution scenarios where maintaining consistent state across all consensus components is essential for safety. The non-atomic nature of the reset operation combined with Rust's async/await semantics creates a window where stale state can persist after a reset operation completes.

### Citations

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L112-130)
```rust
    async fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
        let rounds: Vec<u64> = blocks.ordered_blocks.iter().map(|b| b.round()).collect();
        info!(rounds = rounds, "Processing incoming blocks.");

        let mut share_requester_handles = Vec::new();
        let mut pending_secret_key_rounds = HashSet::new();
        for block in blocks.ordered_blocks.iter() {
            let handle = self.process_incoming_block(block).await;
            share_requester_handles.push(handle);
            pending_secret_key_rounds.insert(block.round());
        }

        let queue_item = QueueItem::new(
            blocks,
            Some(share_requester_handles),
            pending_secret_key_rounds,
        );
        self.block_queue.push_back(queue_item);
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L132-158)
```rust
    async fn process_incoming_block(&self, block: &PipelinedBlock) -> DropGuard {
        let futures = block.pipeline_futs().expect("pipeline must exist");
        let self_secret_share = futures
            .secret_sharing_derive_self_fut
            .await
            .expect("Decryption share computation is expected to succeed")
            .expect("Must not be None");
        let metadata = self_secret_share.metadata().clone();

        // Now acquire lock and update store
        {
            let mut secret_share_store = self.secret_share_store.lock();
            secret_share_store.update_highest_known_round(block.round());
            secret_share_store
                .add_self_share(self_secret_share.clone())
                .expect("Add self dec share should succeed");
        }

        info!(LogSchema::new(LogEvent::BroadcastSecretShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(block.round()));
        self.network_sender.broadcast_without_self(
            SecretShareMessage::Share(self_secret_share).into_network_message(),
        );
        self.spawn_share_requester_task(metadata)
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L172-184)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.secret_share_store
            .lock()
            .update_highest_known_round(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L353-361)
```rust
        while !self.stop {
            tokio::select! {
                Some(blocks) = incoming_blocks.next() => {
                    self.process_incoming_blocks(blocks).await;
                }
                Some(reset) = reset_rx.next() => {
                    while matches!(incoming_blocks.try_next(), Ok(Some(_))) {}
                    self.process_reset(reset);
                }
```

**File:** consensus/src/pipeline/execution_client.rs (L674-692)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L233-235)
```rust
    pub fn update_highest_known_round(&mut self, round: u64) {
        self.highest_known_round = std::cmp::max(self.highest_known_round, round);
    }
```
