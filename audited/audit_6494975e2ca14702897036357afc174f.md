# Audit Report

## Title
Consensus Private Keys Exposed in Plaintext Due to Insecure OnDiskStorage Backend in Production Configuration

## Summary
The Aptos production validator Helm chart uses `OnDiskStorage` as the default secure storage backend for consensus private keys. This backend stores BLS12-381 consensus keys in unencrypted JSON files without restrictive file permissions, violating the documented requirement that OnDiskStorage "should not be used in production." An attacker who gains filesystem read access can steal consensus keys and sign malicious consensus messages, enabling consensus safety violations. [1](#0-0) 

## Finding Description

The secure storage system provides three backend implementations with vastly different security properties:

1. **VaultStorage**: Production-ready with encryption and access control [2](#0-1) 

2. **OnDiskStorage**: Explicitly documented as unsuitable for production with "no security guarantees (e.g., encryption before writing to disk)" [3](#0-2) 

3. **InMemoryStorage**: Testing-only, no persistence [4](#0-3) 

However, the production validator Helm chart defaults to OnDiskStorage: [5](#0-4) 

The consensus private key is stored via this backend without encryption: [6](#0-5) 

OnDiskStorage creates files using standard `File::create()` without setting restrictive permissions (0600) and writes keys in plain JSON: [7](#0-6) 

The configuration sanitizer only blocks `InMemoryStorage` on mainnet but allows `OnDiskStorage`: [8](#0-7) 

**Attack Path:**
1. Validator deployed with default Helm chart uses OnDiskStorage
2. Attacker gains filesystem read access via container escape, volume misconfiguration, backup access, or compromised monitoring agent
3. Attacker reads `/opt/aptos/data/secure-data.json` containing plaintext consensus keys
4. Attacker extracts BLS12-381 private key from JSON
5. Attacker signs arbitrary consensus votes, proposals, and timeouts as the compromised validator
6. With multiple compromised validators (approaching 1/3 of stake), attacker violates BFT consensus safety

## Impact Explanation

**Critical Severity**: This vulnerability enables **Consensus Safety Violations**, qualifying for Critical tier ($1M) under the Aptos bug bounty program.

With stolen consensus keys, an attacker can:
- Sign equivocating votes causing consensus disagreement
- Participate in double-signing attacks
- Break the BFT safety guarantee if enough validators are compromised
- Cause non-recoverable chain splits requiring hard forks

This directly violates the documented invariant: "Consensus Safety: AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine"

The issue affects ALL validators deployed with the default Helm chart, making it a systemic vulnerability across the validator network.

## Likelihood Explanation

**High Likelihood**: 
- Default production configuration uses the vulnerable backend
- Multiple attack vectors exist for filesystem access (container escapes, K8s misconfigurations, backup systems, monitoring agents)
- No encryption or restrictive permissions protect the key file
- Documentation explicitly warns against production use, yet production config violates this
- Sanitizer gap allows the insecure configuration on mainnet

The vulnerability requires only filesystem read access, not write access or privileged validator cooperation, making exploitation feasible for sophisticated attackers targeting validator infrastructure.

## Recommendation

**Immediate Actions:**
1. Update the production Helm chart to use VaultStorage by default
2. Extend the config sanitizer to reject OnDiskStorage on mainnet validators
3. If OnDiskStorage must be temporarily supported, implement restrictive file permissions (0600) and encryption at rest

**Code Fix for Sanitizer:**

```rust
// In config/src/config/safety_rules_config.rs, extend the sanitizer:
if let Some(chain_id) = chain_id {
    if chain_id.is_mainnet() && node_type.is_validator() {
        match &safety_rules_config.backend {
            SecureBackend::InMemoryStorage => {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "InMemoryStorage must not be used on mainnet validators!".to_string(),
                ));
            },
            SecureBackend::OnDiskStorage(_) => {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "OnDiskStorage must not be used on mainnet validators! Use Vault instead.".to_string(),
                ));
            },
            SecureBackend::Vault(_) => {}, // OK
        }
    }
}
```

**Update Helm Chart:**

```yaml
# In terraform/helm/aptos-node/files/configs/validator-base.yaml:
consensus:
  safety_rules:
    service:
      type: "local"
    backend:
      type: "vault"  # Changed from on_disk_storage
      server: "{{ .Values.vault.server }}"
      token:
        from_disk: "{{ .Values.vault.tokenPath }}"
      namespace: ~
```

## Proof of Concept

**Setup:**
1. Deploy validator using default Helm chart
2. Exec into validator container: `kubectl exec -it aptos-validator-0 -- /bin/bash`
3. Read the consensus key file: `cat /opt/aptos/data/secure-data.json`
4. Parse JSON to extract consensus private key under the "consensus" field
5. Use extracted key with Aptos crypto libraries to sign consensus messages

**Rust Reproduction:**

```rust
use aptos_crypto::bls12381::PrivateKey;
use aptos_secure_storage::{KVStorage, OnDiskStorage, Storage};
use std::path::PathBuf;

// Simulating attacker with filesystem read access
fn exploit_ondisk_storage() {
    let storage_path = PathBuf::from("/opt/aptos/data/secure-data.json");
    let storage = Storage::from(OnDiskStorage::new(storage_path));
    
    // Read consensus private key (no encryption, no access control)
    let consensus_key: PrivateKey = storage
        .get("consensus")
        .expect("Failed to steal consensus key")
        .value;
    
    println!("Stolen consensus key: {:?}", consensus_key.public_key());
    
    // Attacker can now sign arbitrary consensus messages
    // Breaking BFT safety if enough validators compromised
}
```

The vulnerability is proven by the fact that no cryptographic protection prevents an attacker with filesystem access from reading the plaintext consensus key, as documented in the codebase itself.

### Citations

**File:** secure/storage/src/on_disk.rs (L16-22)
```rust
/// OnDiskStorage represents a key value store that is persisted to the local filesystem and is
/// intended for single threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission
/// checks and simply offers a proof of concept to unblock building of applications without more
/// complex data stores. Internally, it reads and writes all data to a file, which means that it
/// must make copies of all key material which violates the code base. It violates it because
/// the anticipation is that data stores would securely handle key material. This should not be used
/// in production.
```

**File:** secure/storage/src/on_disk.rs (L64-69)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
```

**File:** secure/storage/README.md (L31-33)
```markdown
- `Vault`: The Vault secure storage implementation uses the Vault Storage Engine (an engine
offered by HashiCorp: https://www.vaultproject.io/). The Vault secure storage implementation
is the one primarily used in production environments by nodes in the blockchain.
```

**File:** secure/storage/README.md (L37-42)
```markdown
- `OnDisk`: Similar to InMemory, the OnDisk secure storage implementation provides another
useful testing implementation: an on-disk storage engine, where the storage backend is
implemented using a single file written to local disk. In a similar fashion to the in-memory
storage, on-disk should not be used in production environments as it provides no security
guarantees (e.g., encryption before writing to disk). Moreover, OnDisk storage does not
currently support concurrent data accesses.
```

**File:** secure/storage/src/in_memory.rs (L9-14)
```rust
/// InMemoryStorage represents a key value store that is purely in memory and intended for single
/// threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission checks and simply
/// is a proof of concept to unblock building of applications without more complex data stores.
/// Internally, it retains all data, which means that it must make copies of all key material which
/// violates the code base. It violates it because the anticipation is that data stores would
/// securely handle key material. This should not be used in production.
```

**File:** terraform/helm/aptos-node/files/configs/validator-base.yaml (L11-16)
```yaml
  safety_rules:
    service:
      type: "local"
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L63-81)
```rust
    fn initialize_keys_and_accounts(
        internal_store: &mut Storage,
        author: Author,
        consensus_private_key: bls12381::PrivateKey,
    ) -> Result<(), Error> {
        let result = internal_store.set(CONSENSUS_KEY, consensus_private_key);
        // Attempting to re-initialize existing storage. This can happen in environments like
        // forge. Rather than be rigid here, leave it up to the developer to detect
        // inconsistencies or why they did not reset storage between rounds. Do not repeat the
        // checks again below, because it is just too strange to have a partially configured
        // storage.
        if let Err(aptos_secure_storage::Error::KeyAlreadyExists(_)) = result {
            warn!("Attempted to re-initialize existing storage");
            return Ok(());
        }

        internal_store.set(OWNER_ACCOUNT, author)?;
        Ok(())
    }
```

**File:** config/src/config/safety_rules_config.rs (L86-96)
```rust
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }
```
