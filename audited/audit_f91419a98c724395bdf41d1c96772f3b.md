# Audit Report

## Title
Backup Service Resource Exhaustion via Unbounded Concurrent Requests with Slow Consumers

## Summary
The backup service's `BytesSender` implementation allows an attacker to exhaust node resources by making multiple concurrent requests and consuming data slowly. Each request can buffer up to 1MB (100 batches × 10KB) in memory, and slow consumption causes blocking threads to be held indefinitely. With the tokio runtime's limit of 64 blocking threads, an attacker can completely exhaust the thread pool and accumulate up to 64MB of buffered data, rendering the backup service unresponsive. [1](#0-0) 

## Finding Description
The vulnerability stems from the combination of several design choices in the backup service:

1. **Bounded Channel with Large Capacity**: Each `BytesSender` creates a tokio mpsc channel with `MAX_BATCHES=100` capacity, where each batch can be up to `TARGET_BATCH_SIZE=10KB`. [2](#0-1) 

2. **Blocking Send Behavior**: When the channel fills up, `blocking_send()` blocks the thread until space becomes available. [3](#0-2) 

3. **Limited Thread Pool**: The tokio runtime uses only 64 blocking threads for all `spawn_blocking` tasks. [4](#0-3) 

4. **No Connection Limits**: The warp-based HTTP server has no built-in connection limits, and the backup service doesn't implement any rate limiting or concurrency controls. [5](#0-4) 

5. **Per-Request Task Spawning**: Each backup request spawns a dedicated blocking task. [6](#0-5) 

**Attack Path:**

1. Attacker opens many concurrent connections (e.g., 100+) to backup endpoints like `/state_snapshot/{version}` or `/transactions/{start}/{count}`
2. For each request, `reply_with_bytes_sender` spawns a blocking task via `spawn_blocking`
3. The first 64 requests get blocking threads; subsequent requests queue up
4. Each blocking task creates a `BytesSender` and begins streaming data through the channel
5. Attacker reads data very slowly from the HTTP response streams
6. Channels fill up to 100 batches (1MB each), and `blocking_send` blocks the threads
7. All 64 blocking threads become blocked waiting for slow consumers
8. Total memory consumed: 64 threads × 1MB = 64MB minimum
9. New backup requests cannot execute because the blocking thread pool is exhausted
10. Backup service becomes completely unresponsive

This breaks **Invariant #9 (Resource Limits)**: "All operations must respect gas, storage, and computational limits." The backup service allows unbounded concurrent requests without proper resource controls.

## Impact Explanation
This is a **High severity** vulnerability per Aptos bug bounty criteria for the following reasons:

1. **API Crashes**: The backup service becomes unresponsive and unable to serve legitimate backup requests, qualifying as "API crashes" (High severity category).

2. **Fullnode Operational Impact**: The backup service typically runs on fullnodes. While this doesn't directly affect consensus, it disrupts critical disaster recovery capabilities.

3. **Resource Exhaustion**: 64 blocked threads and 64MB of memory consumption can impact other operations sharing the same runtime.

4. **Low Attack Cost**: The attack requires only standard HTTP client capabilities (slow reads) and can be executed from a single machine or small botnet.

While this is **not Critical severity** because it:
- Does not affect consensus or validator operations directly
- Does not cause loss of funds
- Does not require a hardfork to recover
- Can be mitigated by external rate limiters (HAProxy) in default deployments

The impact still qualifies as **High** due to API availability disruption on production infrastructure.

## Likelihood Explanation
**Likelihood: High**

1. **Easy to Execute**: The attack requires only basic HTTP clients capable of slow reading (e.g., curl with rate limiting, custom scripts).

2. **No Authentication Required**: The backup service has no built-in authentication mechanism. [5](#0-4) 

3. **Publicly Accessible**: Backup services on fullnodes may be exposed to allow backup clients to connect (default port 6186).

4. **No Built-in Mitigation**: The code has no connection limits, rate limiting, or concurrent request bounds at the application level.

5. **Standard DoS Technique**: "Slow loris" style attacks (slow reads) are well-known and widely used.

The main mitigating factor is that production deployments often use HAProxy with connection limits (`maxconn 500`), but:
- Not all deployments use HAProxy
- 500 concurrent connections could still cause significant resource consumption
- Standalone backup services are vulnerable

## Recommendation
Implement multiple layers of protection:

1. **Add Connection Limits**: Limit concurrent connections at the warp server level
2. **Add Concurrency Limits**: Use a semaphore to limit concurrent backup operations
3. **Reduce Channel Capacity**: Lower `MAX_BATCHES` from 100 to a smaller value (e.g., 10-20)
4. **Add Timeouts**: Implement request timeouts to prevent indefinite blocking
5. **Add Rate Limiting**: Implement per-IP rate limiting

**Example Fix** (partial - showing concurrency limiting):

```rust
// In lib.rs
use tokio::sync::Semaphore;
use std::sync::Arc;

const MAX_CONCURRENT_BACKUPS: usize = 10;

pub fn start_backup_service(address: SocketAddr, db: Arc<AptosDB>) -> Runtime {
    let backup_handler = db.get_backup_handler();
    let semaphore = Arc::new(Semaphore::new(MAX_CONCURRENT_BACKUPS));
    let routes = get_routes(backup_handler, semaphore);
    // ... rest of implementation
}

// In handlers/utils.rs
pub(super) fn reply_with_bytes_sender<F>(
    backup_handler: &BackupHandler,
    semaphore: Arc<Semaphore>,
    endpoint: &'static str,
    f: F,
) -> Box<dyn Reply>
where
    F: FnOnce(BackupHandler, &mut bytes_sender::BytesSender) -> DbResult<()> + Send + 'static,
{
    let (sender, stream) = bytes_sender::BytesSender::new(endpoint);
    
    let bh = backup_handler.clone();
    let _join_handle = tokio::task::spawn_blocking(move || {
        // Acquire permit - this will limit concurrent operations
        let _permit = semaphore.try_acquire()
            .map_err(|_| AptosDbError::Other("Too many concurrent backup requests".into()))?;
        
        let _timer = BACKUP_TIMER.timer_with(&[&format!("backup_service_bytes_sender_{}", endpoint)]);
        abort_on_error(f)(bh, sender)
    });
    
    Box::new(Response::new(Body::wrap_stream(stream)))
}
```

Additionally, reduce `MAX_BATCHES`:

```rust
// In bytes_sender.rs
impl BytesSender {
    const MAX_BATCHES: usize = 10; // Reduced from 100
    const TARGET_BATCH_SIZE: usize = 10 * 1024;
}
```

## Proof of Concept

```rust
// Add to storage/backup/backup-service/src/lib.rs in tests module

#[test]
fn test_backup_service_resource_exhaustion() {
    use std::time::Duration;
    use tokio::time::sleep;
    
    let tmpdir = TempPath::new();
    let db = Arc::new(AptosDB::new_for_test(&tmpdir));
    let port = get_available_port();
    let _rt = start_backup_service(
        SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), port),
        db,
    );
    
    // Spawn 70 concurrent slow consumers (more than MAX_BLOCKING_THREADS=64)
    let mut handles = vec![];
    for _ in 0..70 {
        let handle = std::thread::spawn(move || {
            let client = reqwest::blocking::Client::builder()
                .timeout(Duration::from_secs(300))
                .build()
                .unwrap();
            
            // Request state snapshot
            let mut response = client
                .get(format!("http://127.0.0.1:{}/state_snapshot/0", port))
                .send()
                .unwrap();
            
            // Read data very slowly (1 byte every 100ms)
            let mut buffer = [0u8; 1];
            loop {
                match response.read(&mut buffer) {
                    Ok(0) => break, // EOF
                    Ok(_) => {
                        std::thread::sleep(Duration::from_millis(100));
                    }
                    Err(_) => break,
                }
            }
        });
        handles.push(handle);
    }
    
    // Wait a bit for requests to pile up
    std::thread::sleep(Duration::from_secs(5));
    
    // Try to make a new backup request - should timeout/fail
    // because all blocking threads are exhausted
    let client = reqwest::blocking::Client::builder()
        .timeout(Duration::from_secs(10))
        .build()
        .unwrap();
    
    let result = client
        .get(format!("http://127.0.0.1:{}/db_state", port))
        .send();
    
    // This should fail or timeout due to resource exhaustion
    assert!(
        result.is_err() || result.unwrap().status().is_server_error(),
        "Backup service should be unresponsive due to resource exhaustion"
    );
}
```

**Notes:**
- This vulnerability is application-level resource exhaustion, not network-level DoS (which is out of scope)
- The attack exploits specific implementation details (bounded channels, blocking threads, lack of concurrency limits)
- Default HAProxy deployments provide partial mitigation but don't fully prevent the issue
- The backup service runs on fullnodes, not validators, limiting the blast radius
- Recovery is automatic when the attack stops (no persistent state corruption)

### Citations

**File:** storage/backup/backup-service/src/handlers/bytes_sender.rs (L22-26)
```rust
    const MAX_BATCHES: usize = 100;
    #[cfg(not(test))]
    const TARGET_BATCH_SIZE: usize = 10 * 1024;
    #[cfg(test)]
    const TARGET_BATCH_SIZE: usize = 10;
```

**File:** storage/backup/backup-service/src/handlers/bytes_sender.rs (L31-31)
```rust
        let (bytes_tx, bytes_rx) = tokio::sync::mpsc::channel(Self::MAX_BATCHES);
```

**File:** storage/backup/backup-service/src/handlers/bytes_sender.rs (L83-87)
```rust
    pub fn send_res(&self, item: BytesResult) -> DbResult<()> {
        self.bytes_tx
            .blocking_send(item)
            .map_err(|e| AptosDbError::Other(format!("Failed to send to response stream. {e}")))
    }
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** storage/backup/backup-service/src/lib.rs (L12-30)
```rust
pub fn start_backup_service(address: SocketAddr, db: Arc<AptosDB>) -> Runtime {
    let backup_handler = db.get_backup_handler();
    let routes = get_routes(backup_handler);

    let runtime = aptos_runtimes::spawn_named_runtime("backup".into(), None);

    // Ensure that we actually bind to the socket first before spawning the
    // server tasks. This helps in tests to prevent races where a client attempts
    // to make a request before the server task is actually listening on the
    // socket.
    //
    // Note: we need to enter the runtime context first to actually bind, since
    //       tokio TcpListener can only be bound inside a tokio context.
    let _guard = runtime.enter();
    let server = warp::serve(routes).bind(address);
    runtime.handle().spawn(server);
    info!("Backup service spawned.");
    runtime
}
```

**File:** storage/backup/backup-service/src/handlers/utils.rs (L46-65)
```rust
pub(super) fn reply_with_bytes_sender<F>(
    backup_handler: &BackupHandler,
    endpoint: &'static str,
    f: F,
) -> Box<dyn Reply>
where
    F: FnOnce(BackupHandler, &mut bytes_sender::BytesSender) -> DbResult<()> + Send + 'static,
{
    let (sender, stream) = bytes_sender::BytesSender::new(endpoint);

    // spawn and forget, error propagates through the `stream: TryStream<_>`
    let bh = backup_handler.clone();
    let _join_handle = tokio::task::spawn_blocking(move || {
        let _timer =
            BACKUP_TIMER.timer_with(&[&format!("backup_service_bytes_sender_{}", endpoint)]);
        abort_on_error(f)(bh, sender)
    });

    Box::new(Response::new(Body::wrap_stream(stream)))
}
```
