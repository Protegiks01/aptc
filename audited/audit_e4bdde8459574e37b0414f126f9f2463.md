# Audit Report

## Title
Infinite Retry Loop in NetworkClient Causes Validator Liveness Failure When SafetyRules Service is Unreachable

## Summary
The `NetworkClient::server()` method contains an unbounded retry loop that blocks indefinitely when attempting to connect to an unreachable remote SafetyRules service. When validators use the `Process` SafetyRules configuration, a down or unreachable SafetyRules server causes the consensus thread to block permanently, preventing the validator from participating in consensus and violating the liveness invariant.

## Finding Description

The vulnerability exists in the connection retry logic within `NetworkClient::server()`. When the client cannot connect to the remote server, it enters an infinite loop with only a 100ms sleep between attempts, never timing out or returning control to the caller. [1](#0-0) 

This NetworkClient is used by the SafetyRules remote service implementation to communicate between the consensus layer and a remote SafetyRules server: [2](#0-1) 

The RemoteClient itself contains an additional infinite retry loop in its `request()` method: [3](#0-2) 

When validators configure SafetyRules as a remote service via `SafetyRulesService::Process`: [4](#0-3) 

The consensus layer's `RoundManager` blocks when attempting to vote on blocks, as it must call the SafetyRules client to sign votes: [5](#0-4) 

**Attack Scenario:**

1. A validator on testnet/devnet configures SafetyRules with `type: "process"` and a remote `server_address`
2. An attacker causes the remote SafetyRules server to become unreachable through:
   - DoS attack on the SafetyRules server
   - Network partition between validator and SafetyRules server
   - Exploiting a crash bug in the SafetyRules server process
3. When a new block proposal arrives, `RoundManager` attempts to vote via `vote_block()`
4. The call to `safety_rules.lock().construct_and_sign_vote_two_chain()` blocks
5. The `RemoteClient::request()` method calls `process_one_message()` → `network_client.write()` → `server()`
6. `server()` enters the infinite retry loop attempting to connect
7. The consensus thread is permanently blocked, consuming CPU in a tight loop (100ms sleep intervals)
8. The validator cannot vote on any blocks, participate in consensus, or produce proposals
9. Multiple validators affected simultaneously would degrade or halt network consensus

This breaks the **liveness invariant**: validators must be able to participate in consensus to maintain network progress.

## Impact Explanation

This vulnerability qualifies as **Medium to High severity** per the Aptos bug bounty program:

**Medium Severity** ($10,000): "State inconsistencies requiring intervention" - The validator becomes completely non-functional and requires manual intervention (process restart) to recover. While individual validators can recover, if multiple validators are affected simultaneously, it creates network-wide state inconsistencies.

**High Severity** ($50,000): "Validator node slowdowns" - This is more accurately described as complete validator unavailability rather than a slowdown. If enough validators (>1/3 of stake) are affected simultaneously, the network cannot make progress, approaching "Total loss of liveness."

The impact is mitigated on mainnet by the config sanitizer that enforces `SafetyRulesService::Local`: [6](#0-5) 

However, this still affects:
- All testnet and devnet deployments using remote SafetyRules
- Custom/private Aptos deployments
- Development and testing environments

The vulnerability creates a **denial of service vector** that can be triggered by any actor capable of disrupting network connectivity or the SafetyRules service itself.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability will occur when:
1. A validator configures `SafetyRulesService::Process` (not allowed on mainnet, but possible on testnets)
2. The remote SafetyRules server becomes unreachable (accidental or malicious)

**Triggering conditions:**
- Network partition between validator and SafetyRules server
- SafetyRules server crash or resource exhaustion
- Firewall/security group misconfiguration
- Malicious DoS on the SafetyRules server endpoint
- DNS resolution failures for the server address

**Attacker requirements:**
- Ability to disrupt network connectivity or the SafetyRules service
- No validator insider access required
- No cryptographic key material needed

While mainnet validators cannot use this configuration (enforced by the sanitizer), testnets and development networks remain vulnerable. An attacker targeting a testnet could systematically take down validators using this configuration, demonstrating a proof of concept that could inform attacks on production systems if the sanitizer is ever bypassed or disabled.

## Recommendation

Implement timeout and circuit breaker mechanisms in `NetworkClient::server()`:

```rust
fn server(&mut self) -> Result<&mut NetworkStream, Error> {
    if self.stream.is_none() {
        self.increment_counter(Method::Connect, MethodResult::Query);
        info!(SecureNetLogSchema::new(
            &self.service,
            NetworkMode::Client,
            LogEvent::ConnectionAttempt,
        )
        .remote_peer(&self.server));

        let timeout = std::time::Duration::from_millis(self.timeout_ms);
        let sleeptime = time::Duration::from_millis(100);
        
        // Add maximum retry attempts and total timeout
        const MAX_RETRY_ATTEMPTS: u32 = 30; // 3 seconds with 100ms sleep
        const MAX_TOTAL_TIMEOUT: Duration = Duration::from_secs(10);
        
        let start_time = std::time::Instant::now();
        let mut attempts = 0;
        let mut stream = TcpStream::connect_timeout(&self.server, timeout);

        while let Err(err) = stream {
            attempts += 1;
            
            // Check if we've exceeded retry limits
            if attempts >= MAX_RETRY_ATTEMPTS || start_time.elapsed() >= MAX_TOTAL_TIMEOUT {
                self.increment_counter(Method::Connect, MethodResult::Failure);
                return Err(Error::NetworkError(std::io::Error::new(
                    std::io::ErrorKind::TimedOut,
                    format!("Failed to connect after {} attempts and {:?}", attempts, start_time.elapsed())
                )));
            }
            
            self.increment_counter(Method::Connect, MethodResult::Failure);
            warn!(SecureNetLogSchema::new(
                &self.service,
                NetworkMode::Client,
                LogEvent::ConnectionFailed,
            )
            .error(&err.into())
            .remote_peer(&self.server));

            thread::sleep(sleeptime);
            stream = TcpStream::connect_timeout(&self.server, timeout);
        }

        // Rest of the method unchanged
        let stream = stream?;
        stream.set_nodelay(true)?;
        self.stream = Some(NetworkStream::new(stream, self.server, self.timeout_ms));
        self.increment_counter(Method::Connect, MethodResult::Success);
        info!(SecureNetLogSchema::new(
            &self.service,
            NetworkMode::Client,
            LogEvent::ConnectionSuccessful,
        )
        .remote_peer(&self.server));
    }

    self.stream.as_mut().ok_or(Error::NoActiveStream)
}
```

Additionally, the outer retry loop in `RemoteClient::request()` should also have bounds to prevent infinite retries at that layer.

## Proof of Concept

```rust
#[cfg(test)]
mod vulnerability_poc {
    use super::*;
    use std::net::{IpAddr, Ipv4Addr, SocketAddr};
    use std::sync::{Arc, atomic::{AtomicBool, Ordering}};
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_infinite_retry_blocks_consensus() {
        // Simulate a remote SafetyRules server that is unreachable
        // Use a non-routable IP address (in TEST-NET-1 range) that will timeout
        let unreachable_addr = SocketAddr::new(
            IpAddr::V4(Ipv4Addr::new(192, 0, 2, 1)), 
            9999
        );
        
        let client = NetworkClient::new(
            "test-safety-rules".to_string(),
            unreachable_addr,
            100, // Very short timeout to speed up test
        );
        
        let blocked = Arc::new(AtomicBool::new(false));
        let blocked_clone = blocked.clone();
        
        // Spawn a thread that attempts to connect
        let handle = thread::spawn(move || {
            let mut client = client;
            blocked_clone.store(true, Ordering::SeqCst);
            // This will block forever in the current implementation
            let _ = client.read();
            blocked_clone.store(false, Ordering::SeqCst);
        });
        
        // Give the thread time to enter the retry loop
        thread::sleep(Duration::from_secs(2));
        
        // Verify the thread is still blocked
        assert!(blocked.load(Ordering::SeqCst), 
            "Thread should still be blocked in infinite retry loop");
        
        // In a real scenario, this thread would never complete
        // For the test, we need to abort it to avoid hanging the test suite
        drop(handle); // Thread will be killed when dropped
        
        println!("PoC complete: Thread remained blocked attempting to connect to unreachable server");
    }
}
```

**Notes:**

This vulnerability demonstrates a critical failure in error handling where network failures are not properly bounded. While mainnet validators are protected by configuration sanitization, the underlying code vulnerability remains and affects non-mainnet deployments. The lack of timeout and circuit breaker patterns creates a denial-of-service vector that can render validators non-functional, violating the liveness guarantees required for consensus participation.

### Citations

**File:** secure/net/src/lib.rs (L242-254)
```rust
            while let Err(err) = stream {
                self.increment_counter(Method::Connect, MethodResult::Failure);
                warn!(SecureNetLogSchema::new(
                    &self.service,
                    NetworkMode::Client,
                    LogEvent::ConnectionFailed,
                )
                .error(&err.into())
                .remote_peer(&self.server));

                thread::sleep(sleeptime);
                stream = TcpStream::connect_timeout(&self.server, timeout);
            }
```

**File:** consensus/safety-rules/src/remote_service.rs (L66-69)
```rust
    fn process_one_message(&mut self, input: &[u8]) -> Result<Vec<u8>, Error> {
        self.network_client.write(input)?;
        self.network_client.read().map_err(|e| e.into())
    }
```

**File:** consensus/safety-rules/src/remote_service.rs (L73-81)
```rust
    fn request(&mut self, input: SafetyRulesInput) -> Result<Vec<u8>, Error> {
        let input_message = serde_json::to_vec(&input)?;
        loop {
            match self.process_one_message(&input_message) {
                Err(err) => warn!("Failed to communicate with SafetyRules service: {}", err),
                Ok(value) => return Ok(value),
            }
        }
    }
```

**File:** config/src/config/safety_rules_config.rs (L98-104)
```rust
            // Verify that the safety rules service is set to local for optimal performance
            if chain_id.is_mainnet() && !safety_rules_config.service.is_local() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    format!("The safety rules service should be set to local in mainnet for optimal performance! Given config: {:?}", &safety_rules_config.service)
                ));
            }
```

**File:** config/src/config/safety_rules_config.rs (L206-216)
```rust
pub enum SafetyRulesService {
    /// This runs safety rules in the same thread as event processor
    Local,
    /// This is the production, separate service approach
    Process(RemoteService),
    /// This runs safety rules in the same thread as event processor but data is passed through the
    /// light weight RPC (serializer)
    Serializer,
    /// This creates a separate thread to run safety rules, it is similar to a fork / exec style
    Thread,
}
```

**File:** consensus/src/round_manager.rs (L1520-1523)
```rust
        let vote_result = self.safety_rules.lock().construct_and_sign_vote_two_chain(
            &vote_proposal,
            self.block_store.highest_2chain_timeout_cert().as_deref(),
        );
```
