# Audit Report

## Title
Commit Message Verification DoS via BoundedExecutor Saturation Causes Consensus Liveness Degradation

## Summary
A Byzantine validator can delay legitimate commit vote processing by flooding a victim validator's commit message verification pipeline with invalid messages. The single-threaded verification loop blocks when the BoundedExecutor reaches capacity (16 concurrent tasks), preventing reception of subsequent messages including legitimate commit votes. This can cause the victim node to miss quorum formation deadlines and degrade consensus liveness.

## Finding Description

The buffer manager's commit message verification implementation has a critical architectural flaw that enables head-of-line blocking. [1](#0-0) 

The verification loop spawns a single task that:
1. Receives commit messages from `commit_msg_rx` channel (capacity: 100)
2. Spawns verification tasks on `bounded_executor` using `.spawn().await`
3. Blocks when the executor reaches capacity

The BoundedExecutor enforces a strict concurrency limit: [2](#0-1) 

The default configuration sets this capacity to only 16 tasks: [3](#0-2) 

**Attack Scenario:**

1. A Byzantine validator sends 20+ invalid commit messages rapidly to a victim validator
2. The first 16 messages fill the bounded_executor slots, each performing expensive signature verification
3. The verification loop blocks at line 932 waiting to spawn the 17th verification task
4. **While blocked, the loop cannot call `commit_msg_rx.next().await` to receive new messages**
5. Legitimate commit votes from honest validators queue in `commit_msg_rx` (up to 100 messages)
6. Invalid signature verification is computationally expensive (BLS operations), keeping executor slots occupied
7. Legitimate commit votes experience significant delays (hundreds of milliseconds to seconds)
8. The victim node may miss quorum formation deadlines, failing to produce commit certificates

The commit message channel creation confirms the limited buffering: [4](#0-3) 

This breaks the **Consensus Liveness** invariant: nodes must process legitimate consensus messages promptly to maintain protocol progress. The pipeline consensus design requires timely commit vote aggregation to form 2f+1 quorum certificates.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty criteria for the following reasons:

1. **Validator Node Slowdowns**: The attack directly causes validators to process commit votes slowly, degrading consensus throughput and latency.

2. **Significant Protocol Violations**: Delayed commit vote processing violates the liveness guarantees of AptosBFT consensus. While safety is preserved (no equivocation or forks), liveness degradation can cause:
   - Failed quorum formation
   - Increased round timeouts
   - Reduced transaction throughput
   - Potential epoch transition delays

3. **Network-Wide Impact**: If multiple validators are simultaneously attacked, the entire network's consensus performance degrades proportionally. With sufficient coordination, an attacker controlling <1/3 stake could significantly impair network liveness.

The vulnerability does not reach Critical severity because:
- It does not cause permanent liveness loss (recovery occurs when attack stops)
- It does not violate consensus safety (no double-spending or forks)
- It does not cause fund loss or theft
- It does not require a hard fork to recover

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Must be a Byzantine validator (or compromise one validator's network identity)
- Requires < 1/3 total stake (within Byzantine fault tolerance assumptions)
- Needs moderate network bandwidth to send 20-30 messages per second

**Attack Complexity: Low**
- The attack is straightforward: send invalid commit messages rapidly
- No complex timing requirements or race conditions to exploit
- Invalid messages with malformed signatures are easy to generate
- The blocking behavior is deterministic and reliable

**Detection Difficulty: Medium**
- Attack is observable through increased verification latency metrics
- Network monitoring would show elevated commit message traffic from specific validators
- However, distinguishing malicious flooding from legitimate network congestion requires analysis

**Mitigation Barriers:**
- No per-peer rate limiting exists on commit messages
- No priority queue or fast-path rejection mechanism
- The architecture fundamentally relies on blocking spawn behavior

## Recommendation

**Immediate Fix: Replace blocking spawn with non-blocking try_spawn**

Modify the verification loop to use `try_spawn()` instead of `spawn()`, which returns an error immediately when the executor is at capacity rather than blocking:

```rust
spawn_named!("buffer manager verification", async move {
    while let Some((sender, commit_msg)) = commit_msg_rx.next().await {
        let tx = verified_commit_msg_tx.clone();
        let epoch_state_clone = epoch_state.clone();
        
        match bounded_executor.try_spawn(async move {
            match commit_msg.req.verify(sender, &epoch_state_clone.verifier) {
                Ok(_) => {
                    let _ = tx.unbounded_send(commit_msg);
                },
                Err(e) => warn!("Invalid commit message: {}", e),
            }
        }) {
            Ok(_) => {
                // Successfully spawned verification task
            },
            Err(_) => {
                // Executor at capacity - drop message and log warning
                counters::COMMIT_MSG_VERIFICATION_DROPPED.inc();
                warn!(
                    "Dropped commit message from {} due to verification backlog",
                    sender
                );
            }
        }
    }
});
```

**Additional Hardening Measures:**

1. **Per-Peer Rate Limiting**: Implement rate limiting on commit messages per validator to prevent flooding
2. **Fast-Path Validation**: Perform basic sanity checks (epoch, round bounds) before spawning verification
3. **Priority Queue**: Implement a priority queue that favors messages from validators with higher stake
4. **Increase BoundedExecutor Capacity**: Consider increasing `num_bounded_executor_tasks` from 16 to 32-64 for commit verification
5. **Separate Executor**: Use a dedicated BoundedExecutor for commit verification with higher capacity

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_commit_verification_dos() {
    // Setup: Create buffer manager with default config (16 task limit)
    let bounded_executor = BoundedExecutor::new(16, tokio::runtime::Handle::current());
    
    // Create attacker validator identity
    let attacker = create_byzantine_validator();
    
    // Create victim node's buffer manager
    let (commit_msg_tx, commit_msg_rx) = aptos_channel::new(
        QueueStyle::FIFO,
        100,
        None,
    );
    
    let buffer_manager = create_buffer_manager(
        commit_msg_rx,
        bounded_executor,
    );
    
    // Start buffer manager
    tokio::spawn(buffer_manager.start());
    
    // Attack: Send 30 invalid commit messages rapidly
    for i in 0..30 {
        let invalid_msg = create_invalid_commit_vote(
            attacker.address(),
            i, // varying rounds to avoid deduplication
        );
        commit_msg_tx.push(attacker.address(), invalid_msg).unwrap();
    }
    
    // Give verification time to process some messages
    tokio::time::sleep(Duration::from_millis(50)).await;
    
    // Send legitimate commit vote from honest validator
    let honest_validator = create_honest_validator();
    let legitimate_vote = create_valid_commit_vote(honest_validator.address());
    let sent_time = Instant::now();
    commit_msg_tx.push(honest_validator.address(), legitimate_vote).unwrap();
    
    // Measure time until legitimate vote is processed
    // Expected: Significant delay (>100ms) due to backlog
    let process_time = wait_for_commit_vote_processed().await;
    let delay = sent_time.elapsed();
    
    assert!(
        delay > Duration::from_millis(100),
        "Legitimate vote should be delayed, but took {:?}",
        delay
    );
    
    // Verify that 16+ verification tasks are running concurrently
    // causing the verification loop to block
}
```

**Notes**

The vulnerability stems from a fundamental architectural choice: using a single sequential loop with blocking spawn behavior for all commit message verification. This creates a single point of failure for DoS attacks. The BoundedExecutor's capacity limit, while necessary to prevent unbounded resource consumption, becomes an attack vector when combined with blocking spawn semantics.

The fix must balance two competing concerns:
1. Preventing unbounded executor growth (addressed by BoundedExecutor)
2. Preventing head-of-line blocking of legitimate messages (requires non-blocking spawn)

The recommended solution of using `try_spawn()` with message dropping is a pragmatic trade-off: under normal operation, the executor should have available capacity, but under attack, dropping messages is preferable to blocking legitimate traffic entirely. Additional rate limiting and prioritization mechanisms provide defense-in-depth.

### Citations

**File:** consensus/src/pipeline/buffer_manager.rs (L919-934)
```rust
        spawn_named!("buffer manager verification", async move {
            while let Some((sender, commit_msg)) = commit_msg_rx.next().await {
                let tx = verified_commit_msg_tx.clone();
                let epoch_state_clone = epoch_state.clone();
                bounded_executor
                    .spawn(async move {
                        match commit_msg.req.verify(sender, &epoch_state_clone.verifier) {
                            Ok(_) => {
                                let _ = tx.unbounded_send(commit_msg);
                            },
                            Err(e) => warn!("Invalid commit message: {}", e),
                        }
                    })
                    .await;
            }
        });
```

**File:** crates/bounded-executor/src/executor.rs (L41-52)
```rust
    /// Spawn a [`Future`] on the `BoundedExecutor`. This function is async and
    /// will block if the executor is at capacity until one of the other spawned
    /// futures completes. This function returns a [`JoinHandle`] that the caller
    /// can `.await` on for the results of the [`Future`].
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor.spawn(future_with_permit(future, permit))
    }
```

**File:** config/src/config/consensus_config.rs (L379-379)
```rust
            num_bounded_executor_tasks: 16,
```

**File:** consensus/src/pipeline/execution_client.rs (L387-392)
```rust
        let (commit_msg_tx, commit_msg_rx) =
            aptos_channel::new::<AccountAddress, (AccountAddress, IncomingCommitRequest)>(
                QueueStyle::FIFO,
                100,
                Some(&counters::BUFFER_MANAGER_MSGS),
            );
```
