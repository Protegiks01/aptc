# Audit Report

## Title
Byzantine-Induced Exponential Block Tree Traversal During Pruning Causes Validator Slowdowns

## Summary
The `find_blocks_to_prune()` function in `consensus/src/block_storage/block_tree.rs` is vulnerable to a resource exhaustion attack where Byzantine validators can craft exponentially branching block trees. When pruning occurs during block commits, validators must traverse all branches, calling `abort_pipeline()` on each block, leading to severe performance degradation and potential validator hangs.

## Finding Description

The vulnerability exists in how the consensus layer handles equivocating blocks from Byzantine proposers. While the system implements `UnequivocalProposerElection` to prevent local acceptance of multiple proposals per round, [1](#0-0) , this check is only enforced during direct proposal processing [2](#0-1) .

**Critical Bypass:** When blocks are fetched during synchronization via `fetch_quorum_cert()`, they bypass the equivocation check entirely and are inserted directly into the block tree [3](#0-2) . The insertion path only validates that the block round is newer than the ordered root [4](#0-3) , allowing multiple equivocating blocks for the same round to accumulate as children of the same parent block.

The `BlockTree::insert_block()` implementation explicitly allows multiple children per block [5](#0-4) , with only a warning when multiple blocks exist for the same round [6](#0-5) .

**Attack Execution:**

1. Byzantine proposer P creates k equivocating blocks (B₁, B₂, ..., Bₖ) for round R, all with the same parent
2. P sends different blocks to different validator subsets  
3. Each honest validator accepts the first block they receive (passes local `UnequivocalProposerElection` check)
4. Through gossip and sync operations, validators fetch missing blocks from peers
5. Synced blocks bypass equivocation checks and are inserted into the tree, creating k children for the parent
6. If Byzantine validators control consecutive rounds (or through rotation), this pattern repeats creating k^d blocks at depth d

**Pruning Traversal:** When `commit_callback()` triggers pruning [7](#0-6) , the `find_blocks_to_prune()` function performs a depth-first traversal of ALL branches [8](#0-7) . For each block, it calls `abort_pipeline()` [9](#0-8) , which aborts async execution tasks [10](#0-9) .

With exponential branching (k branches per round for d rounds = k^d blocks), the pruning operation becomes exponentially expensive, executed synchronously on the critical commit path.

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria: "Validator node slowdowns."

**Quantified Impact:**
- With k=10 equivocating blocks per round and d=10 rounds depth: 10¹⁰ blocks must be traversed
- Each block's `abort_pipeline()` call locks mutexes and aborts async tasks
- Pruning occurs during `commit_callback()` on the consensus critical path
- Validators experiencing this attack will suffer:
  - Multi-second to minute-long hangs during commits
  - Degraded consensus participation
  - Potential timeout failures and round advancement issues
  - Cascading sync issues as lagging validators fall further behind

The attack violates the **Resource Limits** invariant (#9): "All operations must respect gas, storage, and computational limits" - the pruning operation has unbounded time complexity based on attacker-controlled branching factor.

## Likelihood Explanation

**Likelihood: Medium-High**

**Requirements:**
- One or more Byzantine validators (assumed up to f < n/3 in BFT)
- Byzantine validator(s) selected as proposer through normal rotation
- Network conditions allowing block propagation and sync

**Feasibility:**
- BFT systems assume up to 1/3 Byzantine validators - this is an expected threat
- Byzantine validators will be proposers proportional to their stake/rotation frequency  
- No special network conditions required - normal sync mechanisms trigger the vulnerability
- Attack is repeatable every time a Byzantine validator is proposer
- Multiple Byzantine validators can coordinate to amplify the attack across consecutive rounds

The attack is realistic because it exploits normal protocol operations (block sync) and doesn't require violations of cryptographic assumptions or eclipse attacks.

## Recommendation

**Immediate Fix:** Enforce global equivocation prevention during block insertion, regardless of insertion source (direct proposal vs. sync).

```rust
// In BlockTree::insert_block() around line 307:
pub(super) fn insert_block(
    &mut self,
    block: PipelinedBlock,
) -> anyhow::Result<Arc<PipelinedBlock>> {
    let block_id = block.id();
    if let Some(existing_block) = self.get_block(&block_id) {
        return Ok(existing_block);
    }
    
    // NEW: Reject equivocating blocks at tree level
    if let Some(existing_round_block_id) = self.round_to_ids.get(&block.round()) {
        if *existing_round_block_id != block_id 
            && self.get_block(existing_round_block_id)
                .map_or(false, |b| b.author() == block.author()) 
        {
            bail!(
                "Rejecting equivocating block {} from author {:?} for round {} (already have {})",
                block_id,
                block.author(),
                block.round(),
                existing_round_block_id
            );
        }
    }
    
    // Existing insertion logic...
    match self.get_linkable_block_mut(&block.parent_id()) {
        Some(parent_block) => parent_block.add_child(block_id),
        None => bail!("Parent block {} not found", block.parent_id()),
    };
    // ... rest of function
}
```

**Additional Mitigations:**
1. Limit maximum children per block (e.g., 3) to cap branching factor
2. Add pruning time limits with early termination and logging
3. Track and penalize validators producing equivocating blocks via slashing

## Proof of Concept

```rust
// Consensus integration test demonstrating the attack
#[tokio::test]
async fn test_exponential_pruning_dos() {
    use consensus::block_storage::BlockStore;
    use consensus_types::block::Block;
    
    // Setup test environment with Byzantine validator
    let (mut runtime, block_store, byzantine_signer) = setup_test_consensus();
    
    // Byzantine validator creates equivocating blocks
    const BRANCHING_FACTOR: usize = 10;
    const DEPTH: usize = 5; // Results in 10^5 = 100k blocks
    
    let genesis = block_store.ordered_root();
    let mut current_parents = vec![genesis.clone()];
    
    // Build exponentially branching tree
    for round in 1..=DEPTH {
        let mut next_parents = vec![];
        for parent in &current_parents {
            // Byzantine proposer creates BRANCHING_FACTOR equivocating blocks
            for fork_id in 0..BRANCHING_FACTOR {
                let equivocating_block = Block::new_proposal(
                    /* payload */ vec![],
                    round as u64,
                    /* timestamp */ round as u64 * 1000,
                    parent.quorum_cert().clone(),
                    &byzantine_signer,
                    vec![], // failed_authors
                );
                
                // Simulate sync insertion (bypasses equivocation check)
                let inserted = block_store.insert_block(equivocating_block).await.unwrap();
                next_parents.push(inserted);
            }
        }
        current_parents = next_parents;
    }
    
    // Verify exponential growth: BRANCHING_FACTOR^DEPTH blocks
    assert_eq!(current_parents.len(), BRANCHING_FACTOR.pow(DEPTH as u32));
    
    // Trigger pruning and measure time
    let start = std::time::Instant::now();
    let leaf = current_parents[0].clone();
    
    // Create commit to trigger pruning
    let commit_qc = create_test_quorum_cert(&leaf, &validators);
    block_store.commit_callback(
        leaf.id(),
        leaf.round(),
        commit_qc,
        window_size,
    );
    
    let pruning_time = start.elapsed();
    
    // Assert pruning takes unreasonable time (demonstrates DoS)
    assert!(
        pruning_time > Duration::from_secs(5),
        "Pruning should be slow with exponential branching, took {:?}",
        pruning_time
    );
}
```

**Notes:**
- The vulnerability exploits the asymmetry between proposal validation (which checks equivocation) and sync-based insertion (which doesn't)
- The block tree data structure comment at line 326 acknowledges assuming "unequivocal proposer election" but this assumption is violated by the sync path
- The attack is within BFT threat model (Byzantine validators) but exceeds expected fault tolerance by causing liveness degradation beyond what the system should tolerate from f < n/3 Byzantine nodes

### Citations

**File:** consensus/src/liveness/unequivocal_proposer_election.rs (L46-87)
```rust
    pub fn is_valid_proposal(&self, block: &Block) -> bool {
        block.author().is_some_and(|author| {
            let valid_author = self.is_valid_proposer(author, block.round());
            if !valid_author {
                warn!(
                    SecurityEvent::InvalidConsensusProposal,
                    "Proposal is not from valid author {}, expected {} for round {} and id {}",
                    author,
                    self.get_valid_proposer(block.round()),
                    block.round(),
                    block.id()
                );

                return false;
            }
            let mut already_proposed = self.already_proposed.lock();
            // detect if the leader proposes more than once in this round
            match block.round().cmp(&already_proposed.0) {
                Ordering::Greater => {
                    already_proposed.0 = block.round();
                    already_proposed.1 = block.id();
                    true
                },
                Ordering::Equal => {
                    if already_proposed.1 != block.id() {
                        error!(
                            SecurityEvent::InvalidConsensusProposal,
                            "Multiple proposals from {} for round {}: {} and {}",
                            author,
                            block.round(),
                            already_proposed.1,
                            block.id()
                        );
                        false
                    } else {
                        true
                    }
                },
                Ordering::Less => false,
            }
        })
    }
```

**File:** consensus/src/round_manager.rs (L1195-1200)
```rust
        ensure!(
            self.proposer_election.is_valid_proposal(&proposal),
            "[RoundManager] Proposer {} for block {} is not a valid proposer for this round or created duplicate proposal",
            author,
            proposal,
        );
```

**File:** consensus/src/block_storage/sync_manager.rs (L264-269)
```rust
        while let Some(block) = pending.pop() {
            let block_qc = block.quorum_cert().clone();
            self.insert_single_quorum_cert(block_qc)?;
            self.insert_block(block).await?;
        }
        self.insert_single_quorum_cert(qc)
```

**File:** consensus/src/block_storage/block_store.rs (L416-419)
```rust
        ensure!(
            self.inner.read().ordered_root().round() < block.round(),
            "Block with old round"
        );
```

**File:** consensus/src/block_storage/block_tree.rs (L319-322)
```rust
            match self.get_linkable_block_mut(&block.parent_id()) {
                Some(parent_block) => parent_block.add_child(block_id),
                None => bail!("Parent block {} not found", block.parent_id()),
            };
```

**File:** consensus/src/block_storage/block_tree.rs (L327-335)
```rust
            if let Some(old_block_id) = self.round_to_ids.get(&arc_block.round()) {
                warn!(
                    "Multiple blocks received for round {}. Previous block id: {}",
                    arc_block.round(),
                    old_block_id
                );
            } else {
                self.round_to_ids.insert(arc_block.round(), block_id);
            }
```

**File:** consensus/src/block_storage/block_tree.rs (L405-434)
```rust
    pub(super) fn find_blocks_to_prune(
        &self,
        next_window_root_id: HashValue,
    ) -> VecDeque<HashValue> {
        // Nothing to do if this is the window root
        if next_window_root_id == self.window_root_id {
            return VecDeque::new();
        }

        let mut blocks_pruned = VecDeque::new();
        let mut blocks_to_be_pruned = vec![self.linkable_window_root()];

        while let Some(block_to_remove) = blocks_to_be_pruned.pop() {
            block_to_remove.executed_block().abort_pipeline();
            // Add the children to the blocks to be pruned (if any), but stop when it reaches the
            // new root
            for child_id in block_to_remove.children() {
                if next_window_root_id == *child_id {
                    continue;
                }
                blocks_to_be_pruned.push(
                    self.get_linkable_block(child_id)
                        .expect("Child must exist in the tree"),
                );
            }
            // Track all the block ids removed
            blocks_pruned.push_back(block_to_remove.id());
        }
        blocks_pruned
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L588-589)
```rust
        let window_root_id = self.find_window_root(block_id, window_size);
        let ids_to_remove = self.find_blocks_to_prune(window_root_id);
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L528-547)
```rust
    pub fn abort_pipeline(&self) -> Option<PipelineFutures> {
        if let Some(abort_handles) = self.pipeline_abort_handle.lock().take() {
            let mut aborted = false;
            for handle in abort_handles {
                if !handle.is_finished() {
                    handle.abort();
                    aborted = true;
                }
            }
            if aborted {
                info!(
                    "[Pipeline] Aborting pipeline for block {} {} {}",
                    self.id(),
                    self.epoch(),
                    self.round()
                );
            }
        }
        self.pipeline_futs.lock().take()
    }
```
