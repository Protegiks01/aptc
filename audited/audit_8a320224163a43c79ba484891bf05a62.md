# Audit Report

## Title
Decompression Bomb Vulnerability in Transaction Backup Restore Causes Memory Exhaustion

## Summary
The transaction backup restore system lacks size validation when decompressing and reading backup chunks, allowing an attacker who can control backup data to cause Out-of-Memory (OOM) crashes on validator/fullnode during restore operations. Memory allocation occurs before cryptographic verification, enabling resource exhaustion attacks.

## Finding Description
The Aptos backup restore system uses external decompression commands (e.g., `gzip -cd`) to read compressed backup files. When restoring transaction backups, the system reads record sizes without validation and directly allocates memory buffers of that size.

**Attack Flow:**

1. The `CommandAdapter` storage backend executes decompression commands when opening files for reading [1](#0-0) 

2. During transaction restore, `LoadedChunk::load()` opens the compressed transactions file and reads records using `read_record_bytes()` [2](#0-1) 

3. The `read_record_bytes()` function reads a 4-byte big-endian u32 size field and allocates a buffer with that exact capacity **without any size validation** [3](#0-2) 

4. This memory allocation happens **before** cryptographic verification of the backup data [4](#0-3) 

**Exploitation:**
An attacker who can inject malicious backup data can:
- Create a highly compressed file (e.g., 1MB gzip file)
- Embed a record size field claiming 4GB (u32::MAX = 4,294,967,295 bytes)
- When decompressed and read, the system attempts to allocate 4GB of memory per record
- Multiple malicious records can cause complete memory exhaustion
- The node crashes with OOM before verifying the backup's cryptographic integrity

**Security Guarantee Violated:**
This breaks the **Resource Limits** invariant (#9): "All operations must respect gas, storage, and computational limits." The backup restore process allocates unbounded memory based on untrusted input without enforcing reasonable limits.

## Impact Explanation
**Severity: HIGH** (per Aptos Bug Bounty criteria)

This vulnerability qualifies as HIGH severity under "Validator node slowdowns" and "API crashes":

1. **Node Availability Impact**: Validator or fullnode crashes during restore operations, causing service disruption
2. **Recovery Prevention**: Nodes requiring disaster recovery from backups cannot complete restoration without crashing
3. **Resource Exhaustion**: Each malicious chunk can consume up to 4GB of memory, potentially exhausting system resources completely
4. **Pre-Verification Attack**: Memory allocation occurs before cryptographic verification, bypassing security controls

While this doesn't directly cause consensus violations or fund loss, it significantly impacts network availability and node operations, particularly during critical recovery scenarios.

## Likelihood Explanation
**Likelihood: Medium**

The attack requires the attacker to control or influence backup data, which involves one of the following scenarios:

1. **Compromised Backup Storage**: If backup infrastructure (S3/GCS/Azure buckets) is compromised, attackers can inject malicious backups
2. **Supply Chain Attack**: Malicious public backups used for node bootstrapping
3. **Operator Error**: Node operators configuring restore from untrusted backup sources
4. **Storage Misconfiguration**: Public backup buckets with misconfigured write permissions [5](#0-4) 

While backup storage typically has access controls via IAM roles [6](#0-5) , misconfigurations or compromises can occur. The restore process accepts backup locations via command-line configuration, making it vulnerable to operator mistakes or compromised infrastructure.

## Recommendation

Add size validation before allocating memory in `read_record_bytes()`:

```rust
// In storage/backup/backup-cli/src/utils/read_record_bytes.rs

const MAX_RECORD_SIZE: usize = 128 * 1024 * 1024; // 128MB reasonable limit

async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
    // read record size
    let mut size_buf = BytesMut::with_capacity(4);
    self.read_full_buf_or_none(&mut size_buf).await?;
    if size_buf.is_empty() {
        return Ok(None);
    }

    // empty record
    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
    
    // ADD SIZE VALIDATION HERE
    if record_size > MAX_RECORD_SIZE {
        bail!(
            "Record size {} exceeds maximum allowed size {}",
            record_size,
            MAX_RECORD_SIZE
        );
    }
    
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }

    // read record
    let mut record_buf = BytesMut::with_capacity(record_size);
    self.read_full_buf_or_none(&mut record_buf).await?;
    if record_buf.is_empty() {
        bail!("Hit EOF when reading record.")
    }

    Ok(Some(record_buf.freeze()))
}
```

Additionally, consider:
1. Implementing streaming decompression with size tracking instead of full buffer allocation
2. Adding total decompressed size limits per backup file
3. Validating backup manifests contain reasonable size metadata before restoration begins

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// File: storage/backup/backup-cli/src/utils/read_record_bytes.rs (add to tests module)

#[test]
fn test_decompression_bomb_vulnerability() {
    use tokio::runtime::Runtime;
    
    Runtime::new().unwrap().block_on(async {
        // Create a malicious record claiming to be 4GB
        let malicious_size: u32 = 0xFFFFFFFF; // 4GB
        let size_bytes = malicious_size.to_be_bytes();
        
        // In practice, this would be in a compressed file
        // but for testing, we just need the size field
        let mut malicious_data = size_bytes.to_vec();
        
        // Attempt to read this record
        let result = malicious_data.as_slice().read_record_bytes().await;
        
        // Without the fix, this would attempt to allocate 4GB
        // With the fix, it should return an error
        match result {
            Ok(_) => panic!("Should have rejected oversized record"),
            Err(e) => {
                // Verify it failed due to size limit
                assert!(e.to_string().contains("exceeds maximum"));
            }
        }
    });
}

// Integration test demonstrating real-world impact
// This would need to be in a separate test file with proper setup
#[test]
fn test_restore_with_malicious_backup() {
    // Steps to reproduce:
    // 1. Create a compressed backup file with malicious size fields
    // 2. Configure restore to read from this backup
    // 3. Observe OOM crash during restore (before the fix)
    // 4. After fix, observe graceful error handling
}
```

**Notes:**
- The vulnerability is a **defense-in-depth** issue requiring attacker control over backup data
- While backup storage has access controls, compromises and misconfigurations can occur
- The fix is simple: validate record sizes before allocation
- This protects against both malicious attacks and corrupted backup files
- Size limits should be configurable but have reasonable defaults based on typical transaction batch sizes

### Citations

**File:** storage/backup/backup-cli/src/storage/command_adapter/sample_configs/s3.sample.yaml (L19-21)
```yaml
  open_for_read: |
    # route file handle content to stdout
    aws s3 cp "s3://$BUCKET/$SUB_DIR/$FILE_HANDLE" - | gzip -cd
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L105-112)
```rust
        let mut file = BufReader::new(storage.open_for_read(&manifest.transactions).await?);
        let mut txns = Vec::new();
        let mut persisted_aux_info = Vec::new();
        let mut txn_infos = Vec::new();
        let mut event_vecs = Vec::new();
        let mut write_sets = Vec::new();

        while let Some(record_bytes) = file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L147-154)
```rust
        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }
```

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L54-61)
```rust
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
```

**File:** terraform/fullnode/aws/backup.tf (L9-21)
```terraform
resource "aws_s3_bucket_public_access_block" "backup" {
  bucket                  = aws_s3_bucket.backup.id
  block_public_acls       = !var.enable_public_backup
  block_public_policy     = !var.enable_public_backup
  ignore_public_acls      = !var.enable_public_backup
  restrict_public_buckets = !var.enable_public_backup
}

resource "aws_s3_bucket_acl" "public-backup" {
  count  = var.enable_public_backup ? 1 : 0
  bucket = aws_s3_bucket.backup.id
  acl    = "public-read"
}
```

**File:** terraform/fullnode/aws/backup.tf (L59-79)
```terraform
data "aws_iam_policy_document" "backup" {
  statement {
    actions = [
      "s3:ListBucket",
      "s3:PutBucketAcl",
      "s3:PutObject",
      "s3:GetObject",
      "s3:GetObjectTagging",
      "s3:DeleteObject",
      "s3:DeleteObjectVersion",
      "s3:GetObjectVersion",
      "s3:GetObjectVersionTagging",
      "s3:GetObjectACL",
      "s3:PutObjectACL"
    ]
    resources = [
      "arn:aws:s3:::${aws_s3_bucket.backup.id}",
      "arn:aws:s3:::${aws_s3_bucket.backup.id}/*"
    ]
  }
}
```
