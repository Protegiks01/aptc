# Audit Report

## Title
Epoch Inconsistency in AdvertisedData Aggregation Breaks State Synchronization

## Summary
The `calculate_global_data_summary()` function in `peer_states.rs` aggregates peer data without validating epoch consistency between `epoch_ending_ledger_infos` and `synced_ledger_infos` from different peers. This allows malicious or Byzantine peers to advertise a `synced_ledger_info` at a high epoch while only providing `epoch_ending_ledger_infos` for lower epochs, causing syncing nodes to fail when attempting epoch transitions. [1](#0-0) 

## Finding Description
The vulnerability exists in the data aggregation logic where peer advertisements are combined without cross-validation. Each peer provides a `DataSummary` containing:
- `synced_ledger_info`: The highest ledger info the peer has synced
- `epoch_ending_ledger_infos`: The range of epoch ending ledger infos available [2](#0-1) 

During aggregation, the system blindly collects these fields from all peers without checking if the highest synced epoch is achievable given the available epoch ending ledger infos: [3](#0-2) 

The `AdvertisedData` then provides two independent methods that can return inconsistent results:
- `highest_epoch_ending_ledger_info()`: Returns the maximum epoch from all `epoch_ending_ledger_infos` ranges
- `highest_synced_ledger_info()`: Returns the ledger info with the highest version from all `synced_ledger_infos` [4](#0-3) 

**Attack Scenario:**
1. Honest Peer H is at epoch 5: `epoch_ending_ledger_infos = [0, 4]`, `synced_ledger_info` at epoch 5
2. Malicious Peer M advertises: `epoch_ending_ledger_infos = [0, 2]`, `synced_ledger_info` at epoch 10 (false claim)

After aggregation:
- `highest_epoch_ending_ledger_info()` returns 4
- `highest_synced_ledger_info()` returns ledger info at epoch 10

When a syncing node attempts to reach epoch 10:
- It detects an epoch change and requests epoch ending ledger infos for epochs 5-9
- But these epochs are not advertised as available (highest is 4)
- Requests fail or timeout repeatedly
- Node becomes stuck and cannot make progress [5](#0-4) 

The continuous transaction stream engine uses `highest_synced_ledger_info()` as the target but has no validation that the required epoch ending ledger infos are available: [6](#0-5) 

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty program:

1. **Validator Node Slowdowns**: Syncing nodes repeatedly attempt to fetch unavailable epoch ending ledger infos, causing timeouts and retries that severely degrade performance
2. **Bootstrap Failures**: New nodes attempting to bootstrap cannot make progress past the inconsistent epoch boundary
3. **Potential Network Partition**: If malicious peers are widely distributed, multiple nodes may become stuck, fragmenting the network

The issue does not directly cause fund loss or consensus safety violations, but significantly impacts network availability and livenessâ€”key properties for blockchain operation. It breaks the invariant that state synchronization should make consistent forward progress.

## Likelihood Explanation
**High Likelihood**:
- **Low Barrier to Entry**: Any peer in the network can advertise arbitrary `DataSummary` information
- **No Validation**: There are zero checks validating epoch consistency during aggregation
- **Natural Occurrence**: Even without malicious intent, bugs in peer storage services or network delays could cause temporarily inconsistent advertisements
- **Wide Impact**: A single malicious peer affects all nodes that include it in their peer set

The peer scoring system provides eventual mitigation after errors are detected, but the damage occurs before scores drop below the ignore threshold. [7](#0-6) 

## Recommendation
Add epoch consistency validation when aggregating `AdvertisedData`:

```rust
/// Calculates a global data summary using all known storage summaries
pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
    // ... existing code to gather storage_summaries ...
    
    // Calculate advertised data
    let mut advertised_data = AdvertisedData::empty();
    // ... existing aggregation code ...
    
    // ADDED: Validate epoch consistency
    if let (Some(highest_epoch_ending), Some(highest_synced)) = 
        (advertised_data.highest_epoch_ending_ledger_info(), 
         advertised_data.highest_synced_ledger_info()) {
        let highest_synced_epoch = highest_synced.ledger_info().epoch();
        
        // If synced epoch is higher than available epoch ending ledger infos,
        // filter out the inconsistent synced ledger info
        if highest_synced_epoch > highest_epoch_ending + 1 {
            warn!(
                "Detected epoch inconsistency: highest_synced_epoch={}, highest_epoch_ending={}", 
                highest_synced_epoch, highest_epoch_ending
            );
            advertised_data.synced_ledger_infos.retain(|li| {
                li.ledger_info().epoch() <= highest_epoch_ending + 1
            });
        }
    }
    
    GlobalDataSummary {
        advertised_data,
        optimal_chunk_sizes,
    }
}
```

Alternatively, add validation in `select_target_ledger_info()` to ensure the target epoch is achievable:

```rust
fn select_target_ledger_info(
    &self,
    advertised_data: &AdvertisedData,
) -> Result<Option<LedgerInfoWithSignatures>, Error> {
    // ... existing selection logic ...
    
    if let Some(highest_synced_ledger_info) = advertised_data.highest_synced_ledger_info() {
        let target_epoch = highest_synced_ledger_info.ledger_info().epoch();
        let (next_request_version, next_request_epoch) = self.next_request_version_and_epoch;
        
        // ADDED: Validate we can reach target epoch
        if target_epoch > next_request_epoch {
            if let Some(highest_epoch_ending) = advertised_data.highest_epoch_ending_ledger_info() {
                if target_epoch > highest_epoch_ending + 1 {
                    // Target epoch requires epoch ending ledger infos that aren't available
                    return Ok(None);
                }
            }
        }
        
        // ... rest of existing logic ...
    }
}
```

## Proof of Concept
This can be demonstrated with a Rust integration test:

```rust
#[tokio::test]
async fn test_epoch_inconsistency_in_advertised_data() {
    // Create mock storage summaries
    let honest_peer_summary = create_mock_summary(
        5, // epoch
        500, // version
        false, // ends_epoch
        Some(CompleteDataRange::new(0, 4).unwrap()) // epoch_ending_ledger_infos
    );
    
    let malicious_peer_summary = create_mock_summary(
        10, // epoch (falsely claiming epoch 10)
        2000, // version
        false, // ends_epoch
        Some(CompleteDataRange::new(0, 2).unwrap()) // only has up to epoch 2
    );
    
    // Create peer states and add both summaries
    let peer_states = PeerStates::new(Arc::new(AptosDataClientConfig::default()));
    peer_states.update_summary(honest_peer_id, honest_peer_summary);
    peer_states.update_summary(malicious_peer_id, malicious_peer_summary);
    
    // Calculate global data summary
    let global_summary = peer_states.calculate_global_data_summary();
    
    // Verify the inconsistency
    let highest_epoch_ending = global_summary.advertised_data.highest_epoch_ending_ledger_info();
    let highest_synced = global_summary.advertised_data.highest_synced_ledger_info();
    
    assert_eq!(highest_epoch_ending, Some(4));
    assert_eq!(highest_synced.unwrap().ledger_info().epoch(), 10);
    
    // This inconsistency (epoch 10 target with only epoch 4 endings available) 
    // will cause sync failures when attempting to transition through epochs 5-9
}
```

The test demonstrates that `AdvertisedData` can contain epoch-inconsistent data that will break epoch transition logic for syncing nodes.

## Notes
This vulnerability affects state synchronization, not consensus directly. However, it can cause severe availability issues and prevent new validators from joining the network, which indirectly impacts network health and decentralization. The lack of validation represents a missing defensive check in a security-critical code path handling untrusted peer data.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L143-160)
```rust
    pub fn get_storage_summary_if_not_ignored(&self) -> Option<&StorageServerSummary> {
        if self.is_ignored() {
            None
        } else {
            self.storage_summary.as_ref()
        }
    }

    /// Returns true iff the peer is currently ignored
    fn is_ignored(&self) -> bool {
        // Only ignore peers if the config allows it
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }

        // Otherwise, ignore peers with a low score
        self.score <= IGNORE_PEER_THRESHOLD
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L339-408)
```rust
    pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
        // Gather all storage summaries, but exclude peers that are ignored
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();

        // If we have no peers, return an empty global summary
        if storage_summaries.is_empty() {
            return GlobalDataSummary::empty();
        }

        // Calculate the global data summary using the advertised peer data
        let mut advertised_data = AdvertisedData::empty();
        let mut max_epoch_chunk_sizes = vec![];
        let mut max_state_chunk_sizes = vec![];
        let mut max_transaction_chunk_sizes = vec![];
        let mut max_transaction_output_chunk_sizes = vec![];
        for summary in storage_summaries {
            // Collect aggregate data advertisements
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
            if let Some(transactions) = summary.data_summary.transactions {
                advertised_data.transactions.push(transactions);
            }
            if let Some(transaction_outputs) = summary.data_summary.transaction_outputs {
                advertised_data
                    .transaction_outputs
                    .push(transaction_outputs);
            }

            // Collect preferred max chunk sizes
            max_epoch_chunk_sizes.push(summary.protocol_metadata.max_epoch_chunk_size);
            max_state_chunk_sizes.push(summary.protocol_metadata.max_state_chunk_size);
            max_transaction_chunk_sizes.push(summary.protocol_metadata.max_transaction_chunk_size);
            max_transaction_output_chunk_sizes
                .push(summary.protocol_metadata.max_transaction_output_chunk_size);
        }

        // Calculate optimal chunk sizes based on the advertised data
        let optimal_chunk_sizes = calculate_optimal_chunk_sizes(
            &self.data_client_config,
            max_epoch_chunk_sizes,
            max_state_chunk_sizes,
            max_transaction_chunk_sizes,
            max_transaction_output_chunk_sizes,
        );
        GlobalDataSummary {
            advertised_data,
            optimal_chunk_sizes,
        }
    }
```

**File:** state-sync/storage-service/types/src/responses.rs (L667-686)
```rust
pub struct DataSummary {
    /// The ledger info corresponding to the highest synced version in storage.
    /// This indicates the highest version and epoch that storage can prove.
    pub synced_ledger_info: Option<LedgerInfoWithSignatures>,
    /// The range of epoch ending ledger infos in storage, e.g., if the range
    /// is [(X,Y)], it means all epoch ending ledger infos for epochs X->Y
    /// (inclusive) are held.
    pub epoch_ending_ledger_infos: Option<CompleteDataRange<Epoch>>,
    /// The range of states held in storage, e.g., if the range is
    /// [(X,Y)], it means all states are held for every version X->Y
    /// (inclusive).
    pub states: Option<CompleteDataRange<Version>>,
    /// The range of transactions held in storage, e.g., if the range is
    /// [(X,Y)], it means all transactions for versions X->Y (inclusive) are held.
    pub transactions: Option<CompleteDataRange<Version>>,
    /// The range of transaction outputs held in storage, e.g., if the range
    /// is [(X,Y)], it means all transaction outputs for versions X->Y
    /// (inclusive) are held.
    pub transaction_outputs: Option<CompleteDataRange<Version>>,
}
```

**File:** state-sync/aptos-data-client/src/global_summary.rs (L175-198)
```rust
    /// Returns the highest epoch ending ledger info advertised in the network
    pub fn highest_epoch_ending_ledger_info(&self) -> Option<Epoch> {
        self.epoch_ending_ledger_infos
            .iter()
            .map(|epoch_range| epoch_range.highest())
            .max()
    }

    /// Returns the highest synced ledger info advertised in the network
    pub fn highest_synced_ledger_info(&self) -> Option<LedgerInfoWithSignatures> {
        let highest_synced_position = self
            .synced_ledger_infos
            .iter()
            .map(|ledger_info_with_sigs| ledger_info_with_sigs.ledger_info().version())
            .position_max();

        if let Some(highest_synced_position) = highest_synced_position {
            self.synced_ledger_infos
                .get(highest_synced_position)
                .cloned()
        } else {
            None
        }
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L498-535)
```rust
    fn select_target_ledger_info(
        &self,
        advertised_data: &AdvertisedData,
    ) -> Result<Option<LedgerInfoWithSignatures>, Error> {
        // Check if the stream has a final target ledger info
        match &self.request {
            StreamRequest::ContinuouslyStreamTransactions(request) => {
                if let Some(target) = &request.target {
                    return Ok(Some(target.clone()));
                }
            },
            StreamRequest::ContinuouslyStreamTransactionOutputs(request) => {
                if let Some(target) = &request.target {
                    return Ok(Some(target.clone()));
                }
            },
            StreamRequest::ContinuouslyStreamTransactionsOrOutputs(request) => {
                if let Some(target) = &request.target {
                    return Ok(Some(target.clone()));
                }
            },
            request => invalid_stream_request!(request),
        };

        // We don't have a final target, select the highest to make progress
        if let Some(highest_synced_ledger_info) = advertised_data.highest_synced_ledger_info() {
            let (next_request_version, _) = self.next_request_version_and_epoch;
            if next_request_version > highest_synced_ledger_info.ledger_info().version() {
                Ok(None) // We're already at the highest synced ledger info. There's no known target.
            } else {
                Ok(Some(highest_synced_ledger_info))
            }
        } else {
            Err(Error::DataIsUnavailable(
                "Unable to find the highest synced ledger info!".into(),
            ))
        }
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1187-1222)
```rust
        let (next_request_version, next_request_epoch) = self.next_request_version_and_epoch;
        if self.current_target_ledger_info.is_none() {
            // Try to select a new ledger info from the advertised data
            if let Some(target_ledger_info) =
                self.select_target_ledger_info(&global_data_summary.advertised_data)?
            {
                if target_ledger_info.ledger_info().epoch() > next_request_epoch {
                    // There was an epoch change. Request an epoch ending ledger info.
                    info!(
                        (LogSchema::new(LogEntry::AptosDataClient)
                            .event(LogEvent::Pending)
                            .message(&format!(
                                "Requested an epoch ending ledger info for epoch: {:?}",
                                next_request_epoch
                            )))
                    );
                    self.end_of_epoch_requested = true;
                    return Ok(vec![DataClientRequest::EpochEndingLedgerInfos(
                        EpochEndingLedgerInfosRequest {
                            start_epoch: next_request_epoch,
                            end_epoch: next_request_epoch,
                        },
                    )]);
                } else {
                    debug!(
                        (LogSchema::new(LogEntry::ReceivedDataResponse)
                            .event(LogEvent::Success)
                            .message(&format!(
                                "Setting new target ledger info. Version: {:?}, Epoch: {:?}",
                                target_ledger_info.ledger_info().version(),
                                target_ledger_info.ledger_info().epoch()
                            )))
                    );
                    self.current_target_ledger_info = Some(target_ledger_info);
                }
            }
```
