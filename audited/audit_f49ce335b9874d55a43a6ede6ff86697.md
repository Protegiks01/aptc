# Audit Report

## Title
Dry Run Flag Not Properly Enforced in MemoryRatelimitChecker - State Modifications Occur During Eligibility Checks

## Summary
The `MemoryRatelimitChecker::check()` function violates the `CheckerTrait` contract by modifying state during dry run mode. Specifically, when `dry_run=true`, the function still executes `clear_if_new_day()` and `get_or_insert_mut()`, which can clear the entire rate limit cache and insert new IP entries respectively. This causes users who check eligibility via the `/is_eligible` endpoint to lose quota from their daily request limit and enables cache pollution attacks.

## Finding Description

The `CheckerTrait` interface explicitly documents that when `dry_run=true`, checkers should not store anything based on the request: [1](#0-0) 

However, the `MemoryRatelimitChecker::check()` implementation violates this contract in two ways:

**Violation 1: Unconditional Cache Clearing** [2](#0-1) 

The `clear_if_new_day()` function is called unconditionally, regardless of the `dry_run` flag. This function clears the entire LRU cache and updates the atomic `current_day` counter when a new day is detected: [3](#0-2) 

**Violation 2: Unconditional IP Entry Insertion** [4](#0-3) 

The `get_or_insert_mut()` call inserts new IP addresses into the cache with an initial count of 1, even during dry runs. Only the subsequent increment operation respects the `dry_run` flag: [5](#0-4) 

**Attack Scenarios:**

1. **Quota Loss**: Users who call `/is_eligible` before `/fund` have their IP inserted with count=1. When they subsequently make actual funding requests, they effectively lose one request from their daily quota (e.g., can only make 4 real requests instead of 5 when `max_requests_per_day=5`).

2. **Cache Pollution**: An attacker can call `/is_eligible` with many different source IPs (via proxies/VPNs) to fill the LRU cache (default 1M entries), potentially evicting legitimate user entries and disrupting rate limiting.

The `/is_eligible` endpoint explicitly uses `dry_run=true`: [6](#0-5) 

For comparison, the `RedisRatelimitChecker` correctly implements dry run semantics by wrapping ALL state modifications in the `!dry_run` check: [7](#0-6) 

## Impact Explanation

**Severity: Medium (up to $10,000)**

While this is a clear contract violation with real exploitability, the impact is limited to the faucet service:

- **Scope**: Affects only testnet/devnet faucet functionality, not mainnet operations or consensus
- **Impact**: Users experience unfair rate limiting and potential service degradation
- **No consensus impact**: Does not affect blockchain consensus, validator operations, or critical infrastructure
- **Limited financial impact**: Only affects testnet token distribution (no real monetary value)

This falls under the Medium severity category as "State inconsistencies requiring intervention" - the rate limiting state becomes inconsistent between dry run and real execution modes.

## Likelihood Explanation

**Likelihood: High**

This issue will occur automatically for any user following the recommended practice of checking eligibility before requesting funds:

1. User calls `/is_eligible` to check if they qualify → IP inserted with count=1 (unintended)
2. User calls `/fund` to actually get tokens → count incremented to 2 (only 1 real request made)
3. After N-1 real funding requests, user is incorrectly rate limited

No special attacker capabilities are required - this affects normal, legitimate usage patterns. The cache pollution attack requires some resources (multiple IP addresses) but is also feasible.

## Recommendation

Move all state-modifying operations inside the `!dry_run` guard, matching the pattern used in `RedisRatelimitChecker`:

```rust
async fn check(
    &self,
    data: CheckerData,
    dry_run: bool,
) -> Result<Vec<RejectionReason>, AptosTapError> {
    // Only clear cache during non-dry-run requests
    if !dry_run {
        self.clear_if_new_day().await;
    }

    let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;
    
    // Get current count without modifying during dry run
    let current_count = if dry_run {
        *ip_to_requests_today.get(&data.source_ip).unwrap_or(&0)
    } else {
        *ip_to_requests_today.get_or_insert_mut(data.source_ip, || 0)
    };
    
    if current_count >= self.max_requests_per_day {
        return Ok(vec![RejectionReason::new(
            format!(
                "IP {} has exceeded the daily limit of {} requests",
                data.source_ip, self.max_requests_per_day
            ),
            RejectionReasonCode::UsageLimitExhausted,
        )]);
    }
    
    // Only increment during non-dry-run
    if !dry_run {
        *ip_to_requests_today.get_or_insert_mut(data.source_ip, || 0) += 1;
    }

    Ok(vec![])
}
```

Alternatively, initialize entries with count=0 instead of count=1 to avoid the off-by-one issue.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::net::IpAddr;
    use std::sync::Arc;
    use poem::http::HeaderMap;
    
    #[tokio::test]
    async fn test_dry_run_state_modification() {
        // Setup checker with max 5 requests per day
        let config = MemoryRatelimitCheckerConfig {
            max_requests_per_day: 5,
            max_entries_in_map: NonZeroUsize::new(1000).unwrap(),
        };
        let checker = MemoryRatelimitChecker::new(config);
        
        let test_ip: IpAddr = "192.168.1.100".parse().unwrap();
        let checker_data = CheckerData {
            time_request_received_secs: get_current_time_secs(),
            receiver: AccountAddress::from_hex_literal("0x1").unwrap(),
            source_ip: test_ip,
            headers: Arc::new(HeaderMap::new()),
        };
        
        // Call check with dry_run=true (simulating /is_eligible)
        let result = checker.check(checker_data.clone(), true).await;
        assert!(result.is_ok());
        assert!(result.unwrap().is_empty()); // Should pass
        
        // Verify state was modified despite dry_run=true
        let cache = checker.ip_to_requests_today.lock().await;
        let count = cache.peek(&test_ip);
        
        // BUG: IP was inserted with count=1 even though dry_run=true
        assert_eq!(count, Some(&1), "IP should not be in cache during dry run, but was inserted with count=1");
        
        drop(cache);
        
        // Now make 4 real requests
        for _ in 0..4 {
            let result = checker.check(checker_data.clone(), false).await;
            assert!(result.is_ok());
            assert!(result.unwrap().is_empty());
        }
        
        // The 5th real request should succeed (we have limit of 5)
        // But it will FAIL because dry_run already consumed one quota
        let result = checker.check(checker_data.clone(), false).await;
        
        // BUG: User only made 4 real funding requests but is now rate limited
        assert!(result.is_ok());
        let rejections = result.unwrap();
        assert!(!rejections.is_empty(), "User should still have 1 request left but was rate limited");
    }
}
```

**Notes:**

This vulnerability is specific to the `MemoryRatelimitChecker` implementation. The `RedisRatelimitChecker` correctly guards all state modifications with the `!dry_run` check and does not have this issue. The bug affects faucet services using in-memory rate limiting and can impact user experience on testnets/devnets where the faucet is used for token distribution.

### Citations

**File:** crates/aptos-faucet/core/src/checkers/mod.rs (L45-47)
```rust
    /// Returns a list of rejection reasons for the request, if any. If dry_run
    /// is set, if this Checker would store anything based on the request, it
    /// instead will not. This is useful for the is_eligible endpoint.
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L53-63)
```rust
    async fn clear_if_new_day(&self) {
        if days_since_tap_epoch(get_current_time_secs())
            > self.current_day.load(std::sync::atomic::Ordering::Relaxed)
        {
            self.current_day.store(
                days_since_tap_epoch(get_current_time_secs()),
                std::sync::atomic::Ordering::Relaxed,
            );
            self.ip_to_requests_today.lock().await.clear();
        }
    }
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L73-73)
```rust
        self.clear_if_new_day().await;
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L77-77)
```rust
        let requests_today = ip_to_requests_today.get_or_insert_mut(data.source_ip, || 1);
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L86-88)
```rust
        } else if !dry_run {
            *requests_today += 1;
        }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L143-146)
```rust
        let (checker_data, bypass, _semaphore_permit) = self
            .components
            .preprocess_request(&fund_request.0, source_ip, header_map, true)
            .await?;
```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L263-263)
```rust
        if !dry_run {
```
