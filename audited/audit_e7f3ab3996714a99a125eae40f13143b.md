# Audit Report

## Title
Database Corruption Causes Unrecoverable Node Startup Failure via Panic in TransactionPruner Initialization

## Summary
When `TransactionPruner::new()` initializes during node startup, database corruption causing the wrong `DbMetadataValue` enum variant to be stored for `TransactionPrunerProgress` triggers an `unreachable!()` panic that crashes the entire node, preventing it from starting and causing a complete availability outage.

## Finding Description

The vulnerability exists in the initialization path of the `TransactionPruner` component during node startup. The issue occurs when:

1. **Database Corruption Scenario**: The RocksDB database becomes corrupted (due to disk errors, power failures, or manual manipulation) such that the key `DbMetadataKey::TransactionPrunerProgress` contains a `DbMetadataValue::StateSnapshotProgress` variant instead of the expected `DbMetadataValue::Version` variant.

2. **Panic Trigger**: When `get_or_initialize_subpruner_progress()` retrieves this corrupted value, it calls `expect_version()` on the `DbMetadataValue`: [1](#0-0) 

3. **Unreachable Macro**: The `expect_version()` method contains an `unreachable!()` macro that panics if the value is not a `Version` variant: [2](#0-1) 

4. **Propagation Through Initialization**: This panic propagates through the entire node initialization chain:
   - `TransactionPruner::new()` is called during `LedgerPruner::new()`: [3](#0-2) 
   
   - `LedgerPruner::new()` is called with `.expect()` in `LedgerPrunerManager::init_pruner()`: [4](#0-3) 
   
   - This is invoked during `AptosDB::new_with_dbs()`: [5](#0-4) 
   
   - Which is called during node startup via `storage::initialize_database_and_checkpoints()`: [6](#0-5) 

5. **Process Termination**: The panic handler logs the crash and exits the process with code 12: [7](#0-6) 

This breaks the **availability invariant** - the node cannot recover from this condition without manual database intervention.

## Impact Explanation

**Severity: Medium** ($10,000 according to Aptos Bug Bounty criteria)

This vulnerability causes:

1. **Complete Node Unavailability**: The affected node cannot start until the database is manually repaired
2. **State Inconsistency Requiring Intervention**: Database corruption prevents normal operation and requires operator intervention
3. **Network Impact**: If multiple validator nodes are affected simultaneously (e.g., during widespread power failures), network liveness could be degraded

The severity is Medium rather than High/Critical because:
- It does NOT cause consensus violations or chain splits
- It does NOT result in loss or theft of funds
- It does NOT allow attackers to manipulate state or bypass security controls
- It requires database corruption as a precondition (not directly exploitable)
- Recovery is possible through database repair or resync

However, it qualifies as Medium because it causes "State inconsistencies requiring intervention" and creates an availability outage that cannot be automatically recovered.

## Likelihood Explanation

**Likelihood: Medium-Low**

The vulnerability requires:

1. **Database Corruption**: RocksDB database must become corrupted such that the wrong enum variant is stored for a specific metadata key. This can occur due to:
   - Hardware failures (disk corruption, bad sectors)
   - Power outages during database writes
   - Storage device failures
   - Software bugs in RocksDB or the storage layer
   - Improper database manipulation during debugging/recovery attempts

2. **Specific Corruption Pattern**: The corruption must affect the `TransactionPrunerProgress` key specifically and cause BCS deserialization to succeed but produce the wrong variant

3. **Node Restart**: The issue only manifests when the node attempts to restart after corruption occurs

While database corruption is relatively rare in production systems with proper hardware, it does happen in practice, especially in:
- Cloud environments with transient disk errors
- Validator operators running on consumer-grade hardware
- Regions with unstable power supplies
- During emergency maintenance or recovery operations

## Recommendation

Replace the panic-inducing `expect_version()` call with proper error handling that allows graceful recovery:

**Option 1: Return an Error Instead of Panicking**

Modify `get_or_initialize_subpruner_progress()` to validate the variant type and return a proper error:

```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
        match v {
            DbMetadataValue::Version(version) => Ok(version),
            _ => {
                // Log the corruption and reinitialize
                error!(
                    "Database corruption detected: wrong metadata type for {:?}. Reinitializing...",
                    progress_key
                );
                sub_db.put::<DbMetadataSchema>(
                    progress_key,
                    &DbMetadataValue::Version(metadata_progress),
                )?;
                Ok(metadata_progress)
            }
        }
    } else {
        sub_db.put::<DbMetadataSchema>(
            progress_key,
            &DbMetadataValue::Version(metadata_progress),
        )?;
        Ok(metadata_progress)
    }
}
```

**Option 2: Add a Type-Safe Wrapper**

Create a type-safe getter that returns `Result<Version>` instead of panicking:

```rust
impl DbMetadataValue {
    pub fn try_into_version(self) -> Result<Version> {
        match self {
            Self::Version(version) => Ok(version),
            _ => Err(AptosDbError::Other(format!(
                "Expected Version variant, got {:?}",
                self
            ))),
        }
    }
}
```

Then update all call sites to use `try_into_version()` instead of `expect_version()`.

## Proof of Concept

**Rust Test to Reproduce:**

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_db_indexer_schemas::metadata::StateSnapshotProgress;
    use aptos_schemadb::DB;
    use aptos_temppath::TempPath;

    #[test]
    #[should_panic(expected = "expected Version")]
    fn test_corrupted_metadata_causes_panic() {
        // Create a temporary database
        let tmpdir = TempPath::new();
        let db = DB::open(
            tmpdir.path(),
            "test_db",
            aptos_schemadb::ColumnFamilyName::new("db_metadata"),
            &aptos_schemadb::Options::default(),
        )
        .unwrap();

        // Simulate corruption: store StateSnapshotProgress instead of Version
        let corrupted_value = DbMetadataValue::StateSnapshotProgress(
            StateSnapshotProgress::default()
        );
        db.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &corrupted_value,
        )
        .unwrap();

        // This will panic when trying to initialize the pruner
        let result = get_or_initialize_subpruner_progress(
            &db,
            &DbMetadataKey::TransactionPrunerProgress,
            100,
        );

        // Test should panic before reaching here
        panic!("Should have panicked due to corrupted metadata");
    }
}
```

**Steps to Reproduce in Production:**

1. Start an Aptos node with ledger pruning enabled
2. While the node is running, use RocksDB tools to corrupt the database:
   ```bash
   # Stop the node
   # Manually modify the database to write wrong variant type
   # Use RocksDB ldb tool or direct byte manipulation
   ```
3. Restart the node
4. Observe that the node fails to start with a panic in `expect_version()`
5. Check logs for crash handler output with exit code 12

## Notes

- This issue affects all sub-pruners that use `get_or_initialize_subpruner_progress()`, not just `TransactionPruner`
- Similar patterns exist in `LedgerMetadataPruner::new()` which also uses `expect_version()` during initialization: [8](#0-7) 
- The vulnerability is only triggered when pruning is enabled in the node configuration
- Database backup and restore procedures should validate metadata types to prevent this issue
- Consider adding database integrity checks during startup before attempting to initialize pruners

### Citations

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```

**File:** storage/aptosdb/src/schema/db_metadata/mod.rs (L32-37)
```rust
    pub fn expect_version(self) -> Version {
        match self {
            Self::Version(version) => version,
            _ => unreachable!("expected Version, got {:?}", self),
        }
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L161-166)
```rust
        let transaction_pruner = Box::new(TransactionPruner::new(
            Arc::clone(&transaction_store),
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db,
        )?);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L146-149)
```rust
        let pruner = Arc::new(
            LedgerPruner::new(ledger_db, internal_indexer_db)
                .expect("Failed to create ledger pruner."),
        );
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L86-90)
```rust
        let ledger_pruner = LedgerPrunerManager::new(
            Arc::clone(&ledger_db),
            pruner_config.ledger_pruner_config,
            internal_indexer_db,
        );
```

**File:** aptos-node/src/storage.rs (L188-205)
```rust
    let instant = Instant::now();
    let (_aptos_db, db_rw, backup_service, indexer_db_opt, update_receiver) =
        bootstrap_db(node_config)?;

    // Log the duration to open storage
    debug!(
        "Storage service started in {} ms",
        instant.elapsed().as_millis()
    );

    Ok((
        db_rw,
        backup_service,
        node_config.base.waypoint.genesis_waypoint(),
        indexer_db_opt,
        update_receiver,
    ))
}
```

**File:** crates/crash-handler/src/lib.rs (L32-58)
```rust
// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());

    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);

    // Wait till the logs have been flushed
    aptos_logger::flush();

    // Do not kill the process if the panics happened at move-bytecode-verifier.
    // This is safe because the `state::get_state()` uses a thread_local for storing states. Thus the state can only be mutated to VERIFIER by the thread that's running the bytecode verifier.
    //
    // TODO: once `can_unwind` is stable, we should assert it. See https://github.com/rust-lang/rust/issues/92988.
    if state::get_state() == VMState::VERIFIER || state::get_state() == VMState::DESERIALIZER {
        return;
    }

    // Kill the process
    process::exit(12);
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_metadata_pruner.rs (L18-40)
```rust
impl LedgerMetadataPruner {
    pub(in crate::pruner) fn new(ledger_metadata_db: Arc<DB>) -> Result<Self> {
        if let Some(v) =
            ledger_metadata_db.get::<DbMetadataSchema>(&DbMetadataKey::LedgerPrunerProgress)?
        {
            v.expect_version();
        } else {
            // NOTE: I **think** all db should have the LedgerPrunerProgress. Have a fallback path
            // here in case the database was super old before we introducing this progress counter.
            let mut iter = ledger_metadata_db.iter::<VersionDataSchema>()?;
            iter.seek_to_first();
            let version = match iter.next().transpose()? {
                Some((version, _)) => version,
                None => 0,
            };
            ledger_metadata_db.put::<DbMetadataSchema>(
                &DbMetadataKey::LedgerPrunerProgress,
                &DbMetadataValue::Version(version),
            )?;
        }

        Ok(LedgerMetadataPruner { ledger_metadata_db })
    }
```
