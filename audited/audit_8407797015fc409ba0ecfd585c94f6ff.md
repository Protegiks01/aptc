# Audit Report

## Title
Batch Processing Failure Due to Single Malformed Resource in Table Info Indexer

## Summary
The `collect_table_info_from_write_op()` function in the table info indexer propagates all errors using the `?` operator, causing entire batches (up to 10,000 transactions) to fail if any single write operation encounters a recoverable error during parsing. This prevents valid table info from other transactions in the batch from being indexed and can cause node startup failures or indefinite service disruptions. [1](#0-0) 

## Finding Description

The vulnerability exists in the error handling strategy of the table info indexer. When processing write sets, the indexer iterates through each write operation and calls `collect_table_info_from_write_op()`, which can fail for various reasons:

1. **Malformed access paths** - Path conversion can fail
2. **BCS deserialization failures** - When deserializing resources or resource groups
3. **Type resolution failures** - When the annotator cannot resolve types for resources
4. **Module not found errors** - When modules referenced by resources are unavailable
5. **Type/value mismatches** - When deserializing Move values with incorrect type information

All these errors are propagated immediately with the `?` operator: [2](#0-1) [3](#0-2) [4](#0-3) [5](#0-4) 

The batch processing loop has no error isolation: [6](#0-5) 

When any single write_op fails, the entire batch fails. The underlying issues can occur in the annotation process: [7](#0-6) [8](#0-7) 

**Attack/Failure Scenarios:**

1. **Governance Transaction with Malformed Write Ops**: A governance proposal could include write operations that reference non-existent modules or contain malformed data, bypassing normal Move VM validation.

2. **Module Upgrade Timing Issues**: During module upgrades, new resources may be created before all nodes have synchronized the new module definitions, causing type resolution failures.

3. **State Sync Gaps**: During state synchronization, nodes may receive write sets before receiving the corresponding module bytecode, causing module-not-found errors.

**Impact Chain:**

During node startup in `open_indexer()`, if any batch fails, the node cannot start: [9](#0-8) 

In the table info service, there is a retry loop that keeps attempting the same failing batch indefinitely: [10](#0-9) 

The comment explicitly acknowledges this issue: "NOTE: The retry is unlikely to be helpful."

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty criteria for the following reasons:

1. **State Inconsistencies Requiring Intervention**: Valid table info from other transactions in the batch is not indexed, creating gaps in the table metadata that downstream systems depend on. This requires manual intervention to identify and skip the problematic batch.

2. **Service Availability Impact**: 
   - Node startup can fail completely during `open_indexer()`, preventing validator nodes from coming online
   - The table info service gets stuck in an infinite retry loop, consuming resources without making progress
   - Up to 10,000 transactions worth of table info can be lost per failing batch (based on BATCH_SIZE constant) [11](#0-10) 

3. **Cascading Effects**: Downstream consumers of table info (indexers, explorers, APIs) will not receive updates for tables in the affected batches, breaking data consistency guarantees.

The impact does not reach Critical or High severity because:
- It does not affect consensus or fund safety directly
- It does not cause validator node slowdowns during normal operation (only affects startup/indexer)
- No funds are at risk

## Likelihood Explanation

The likelihood of this issue occurring is **Medium**:

**Factors Increasing Likelihood:**
1. **Module Upgrades**: During network upgrades when new modules are deployed, there is a window where some nodes have the new modules while others don't, causing type resolution failures.

2. **Governance Transactions**: Governance proposals can include arbitrary write sets that bypass normal Move VM validation, potentially containing malformed data.

3. **State Sync Timing**: During rapid state synchronization or network partitions, nodes may receive write sets before receiving corresponding module bytecode.

4. **Real-World Evidence**: The existence of the retry loop with the comment "The retry is unlikely to be helpful" suggests this issue has been encountered in practice. [12](#0-11) 

**Factors Decreasing Likelihood:**
1. Normal transaction execution through the Move VM produces well-formed write operations
2. The issue requires specific timing or malformed data conditions
3. In steady-state operation with no upgrades, the likelihood is low

## Recommendation

Implement graceful error handling that isolates failures to individual write operations while allowing the rest of the batch to succeed:

**Recommended Fix:**

```rust
pub fn collect_table_info_from_write_op(
    &mut self,
    state_key: &'a StateKey,
    write_op: &'a WriteOp,
) -> Result<()> {
    // Wrap the logic in a closure to catch errors per write_op
    let result = (|| -> Result<()> {
        if let Some(bytes) = write_op.bytes() {
            match state_key.inner() {
                StateKeyInner::AccessPath(access_path) => {
                    let path: Path = (&access_path.path).try_into()?;
                    match path {
                        Path::Code(_) => (),
                        Path::Resource(struct_tag) => {
                            self.collect_table_info_from_struct(struct_tag, bytes)?
                        },
                        Path::ResourceGroup(_struct_tag) => {
                            self.collect_table_info_from_resource_group(bytes)?
                        },
                    }
                },
                StateKeyInner::TableItem { handle, .. } => {
                    self.collect_table_info_from_table_item(*handle, bytes)?
                },
                StateKeyInner::Raw(_) => (),
            }
        }
        Ok(())
    })();
    
    // Log errors but don't fail the batch
    if let Err(err) = result {
        sample!(
            SampleRate::Duration(Duration::from_secs(10)),
            aptos_logger::warn!(
                state_key = ?state_key,
                error = ?err,
                "[Indexer] Failed to collect table info from write_op, skipping"
            )
        );
        // Optionally: Track skipped write_ops in metrics
    }
    
    Ok(())
}
```

**Additional Improvements:**

1. Add metrics to track skipped write operations:
```rust
static SKIPPED_WRITE_OPS: Lazy<IntCounter> = Lazy::new(|| {
    register_int_counter!(
        "indexer_skipped_write_ops",
        "Number of write ops skipped due to parsing errors"
    ).unwrap()
});
```

2. Implement a separate logging/tracking mechanism for problematic write_ops that can be investigated later

3. Consider adding retry logic specifically for module-not-found errors with a short delay, as modules may be received shortly after write sets during state sync

## Proof of Concept

The following demonstrates how to reproduce the issue:

**Step 1: Create a test that simulates a malformed resource scenario**

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_types::{
        state_store::state_key::StateKey,
        write_set::{WriteOp, WriteSet},
        access_path::AccessPath,
    };
    
    #[test]
    fn test_batch_fails_on_single_malformed_resource() {
        // Setup indexer and annotator
        let db = /* create test DB */;
        let indexer = IndexerAsyncV2::new(db).unwrap();
        let state_view = /* create test state view */;
        let annotator = AptosValueAnnotator::new(&state_view);
        
        // Create a batch with one valid and one malformed write_op
        let valid_write_op = WriteOp::legacy_modification(vec![/* valid BCS data */]);
        let malformed_write_op = WriteOp::legacy_modification(vec![0xFF, 0xFF, 0xFF]); // Invalid BCS
        
        let valid_state_key = StateKey::access_path(AccessPath::resource_access_path(/* valid path */));
        let malformed_state_key = StateKey::access_path(AccessPath::resource_access_path(/* path with non-existent module */));
        
        let write_set = WriteSet::new(vec![
            (valid_state_key, valid_write_op),
            (malformed_state_key, malformed_write_op),
        ]);
        
        // Attempt to index - this will fail on the malformed write_op
        let result = indexer.index_with_annotator(
            &annotator,
            0,
            &[&write_set]
        );
        
        // The entire batch fails, even though one write_op was valid
        assert!(result.is_err());
        
        // Verify that the valid table info was NOT persisted
        // because the batch failed before commit
    }
}
```

**Step 2: Reproduce node startup failure**

```rust
// In aptosdb_internal.rs, during open_indexer():
// If there is a batch with a malformed resource at version 1000-2000:
// 1. Node attempts to start
// 2. open_indexer() is called
// 3. Indexer attempts to catch up from version 0 to ledger_next_version
// 4. At version 1000-2000 batch, encounters the malformed resource
// 5. index_with_annotator() returns an error
// 6. open_indexer() propagates the error with ?
// 7. Node startup fails
```

**Step 3: Reproduce infinite retry in table_info_service**

```rust
// In table_info_service.rs process_transactions():
// 1. Batch containing malformed resource is received
// 2. parse_table_info() is called
// 3. index_table_info() fails on the malformed resource
// 4. Error is logged, sleep for 5 seconds
// 5. Loop retries indefinitely with the same failing batch
// 6. Service makes no progress, gets stuck
```

## Notes

The vulnerability is exacerbated by the batch size of 10,000 transactions. A single problematic write operation in any of those 10,000 transactions causes all valid table info from the entire batch to be lost. This creates a significant data availability gap for downstream systems that depend on table metadata.

The fix should maintain backward compatibility while adding resilience to parsing errors. Consider also adding configuration options to control error handling behavior (e.g., strict mode vs. lenient mode) for different deployment scenarios.

### Citations

**File:** storage/indexer/src/db_v2.rs (L95-99)
```rust
        for write_set in write_sets {
            for (state_key, write_op) in write_set.write_op_iter() {
                table_info_parser.collect_table_info_from_write_op(state_key, write_op)?;
            }
        }
```

**File:** storage/indexer/src/db_v2.rs (L230-256)
```rust
    pub fn collect_table_info_from_write_op(
        &mut self,
        state_key: &'a StateKey,
        write_op: &'a WriteOp,
    ) -> Result<()> {
        if let Some(bytes) = write_op.bytes() {
            match state_key.inner() {
                StateKeyInner::AccessPath(access_path) => {
                    let path: Path = (&access_path.path).try_into()?;
                    match path {
                        Path::Code(_) => (),
                        Path::Resource(struct_tag) => {
                            self.collect_table_info_from_struct(struct_tag, bytes)?
                        },
                        Path::ResourceGroup(_struct_tag) => {
                            self.collect_table_info_from_resource_group(bytes)?
                        },
                    }
                },
                StateKeyInner::TableItem { handle, .. } => {
                    self.collect_table_info_from_table_item(*handle, bytes)?
                },
                StateKeyInner::Raw(_) => (),
            }
        }
        Ok(())
    }
```

**File:** storage/indexer/src/db_v2.rs (L263-267)
```rust
        let ty_tag = TypeTag::Struct(Box::new(struct_tag));
        let mut infos = vec![];
        self.annotator
            .collect_table_info(&ty_tag, bytes, &mut infos)?;
        self.process_table_infos(infos)
```

**File:** third_party/move/tools/move-resource-viewer/src/lib.rs (L692-706)
```rust
    pub fn collect_table_info(
        &self,
        ty_tag: &TypeTag,
        blob: &[u8],
        infos: &mut Vec<MoveTableInfo>,
    ) -> anyhow::Result<()> {
        let mut limit = Limiter::default();
        if !self.contains_tables(ty_tag, &mut limit)? {
            return Ok(());
        }
        let fat_ty = self.resolve_type_impl(ty_tag, &mut limit)?;
        let layout = (&fat_ty).try_into().map_err(into_vm_status)?;
        let move_value = MoveValue::simple_deserialize(blob, &layout)?;
        self.collect_table_info_from_value(&fat_ty, move_value, &mut limit, infos)
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L214-227)
```rust
            const BATCH_SIZE: Version = 10000;
            let mut next_version = indexer.next_version();
            while next_version < ledger_next_version {
                info!(next_version = next_version, "AptosDB Indexer catching up. ",);
                let end_version = std::cmp::min(ledger_next_version, next_version + BATCH_SIZE);
                let write_sets = self
                    .ledger_db
                    .write_set_db()
                    .get_write_sets(next_version, end_version)?;
                let write_sets_ref: Vec<_> = write_sets.iter().collect();
                indexer.index_with_annotator(&annotator, next_version, &write_sets_ref)?;

                next_version = end_version;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/table_info_service.rs (L329-339)
```rust
        loop {
            // NOTE: The retry is unlikely to be helpful. Put a loop here just to avoid panic and
            // allow the rest of FN functionality continue to work.
            match Self::parse_table_info(context.clone(), raw_txns, indexer_async_v2.clone()) {
                Ok(_) => break,
                Err(e) => {
                    error!(error = ?e, "Error during parse_table_info.");
                    tokio::time::sleep(Duration::from_secs(5)).await;
                },
            }
        }
```
