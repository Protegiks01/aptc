# Audit Report

## Title
Incomplete Error Handling in `reset_active_stream()` Causes Permanent State Sync Liveness Failure

## Summary
The `reset_active_stream()` function in both `ContinuousSyncer` and `Bootstrapper` components contains an error propagation bug that leaves the node in an inconsistent state when stream termination fails. This results in a permanent loss of state sync capability requiring node restart.

## Finding Description

The vulnerability exists in the `reset_active_stream()` method where error propagation prevents critical state cleanup: [1](#0-0) 

When `terminate_stream_with_feedback()` returns an error (line 531-536), the `?` operator causes an early return **before** lines 539-540 execute. This leaves `self.active_data_stream` and `self.speculative_stream_state` still set to `Some(...)` instead of being cleared to `None`.

The termination failure occurs when the DataStreamingService crashes or shuts down, causing the mpsc channel receiver to be dropped. Subsequent calls to `terminate_stream_with_feedback()` fail with `SendError`: [2](#0-1) 

The SendError is converted to `Error::UnexpectedErrorEncountered`: [3](#0-2) 

**Attack Path**:

1. DataStreamingService crashes/panics (receiver dropped)
2. An error occurs requiring stream reset (timeout, invalid data, verification failure)
3. `reset_active_stream()` is called
4. `terminate_stream_with_feedback()` fails with SendError
5. Early return leaves `active_data_stream` = `Some(...)` and `speculative_stream_state` = `Some(...)`
6. Error is logged but ignored in driver: [4](#0-3) 

7. Next iteration: `drive_progress()` checks `if self.active_data_stream.is_some()` (line 81) - **TRUE** [5](#0-4) 

8. Tries to process notifications from non-existent stream, times out repeatedly
9. Critical timeout triggers another `reset_active_stream()` call: [6](#0-5) 

10. Same failure occurs â†’ **infinite error loop**

The node cannot initialize new streams because line 94 checks require `active_data_stream` to be `None`. The streaming client is created once at node startup and never recreated: [7](#0-6) 

**The same vulnerability exists in the Bootstrapper component**: [8](#0-7) 

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

- **Validator node slowdowns**: Node permanently loses ability to sync blocks/transactions
- **Significant protocol violations**: Node falls behind network, cannot participate in consensus
- **Loss of liveness**: Core state sync functionality becomes non-operational until restart

The node enters an unrecoverable error loop where it:
- Cannot initialize new data streams (thinks stream exists)
- Cannot sync new transactions or blocks from network
- Continuously times out and fails reset attempts
- Falls progressively further behind chain state
- Requires manual node restart to recover

For validator nodes, this can lead to missing proposals, failed attestations, and potential slashing. For fullnodes, this breaks API availability and data freshness.

## Likelihood Explanation

**HIGH likelihood** - This can be triggered by realistic operational failures:

1. **Service crashes**: The DataStreamingService task could panic due to bugs, assertion failures, or unhandled errors
2. **Runtime shutdown**: Tokio runtime shutdown during maintenance or errors
3. **Resource exhaustion**: OOM conditions causing task termination
4. **Code bugs**: Any panic in the streaming service event loop

No attacker control is required - normal operational failures trigger this. The streaming service is a critical component handling network data, making crashes a realistic scenario. Once triggered, the node cannot self-recover.

## Recommendation

Implement unconditional state cleanup in `reset_active_stream()` to ensure fields are always cleared regardless of termination success:

```rust
pub async fn reset_active_stream(
    &mut self,
    notification_and_feedback: Option<NotificationAndFeedback>,
) -> Result<(), Error> {
    // Attempt to terminate the stream if it exists
    if let Some(active_data_stream) = &self.active_data_stream {
        let data_stream_id = active_data_stream.data_stream_id;
        if let Err(error) = utils::terminate_stream_with_feedback(
            &mut self.streaming_client,
            data_stream_id,
            notification_and_feedback,
        )
        .await
        {
            // Log the termination failure but continue cleanup
            warn!(LogSchema::new(LogEntry::Driver)
                .error(&error)
                .message("Failed to terminate stream, proceeding with local cleanup"));
        }
    }

    // Always clear local state, even if termination failed
    self.active_data_stream = None;
    self.speculative_stream_state = None;
    Ok(())
}
```

Apply the same fix to `Bootstrapper::reset_active_stream()` at lines 1539-1556 in `bootstrapper.rs`.

**Rationale**: Stream termination failure indicates the server-side stream is already gone or unreachable. The client must clear its local state regardless to allow recovery by initializing fresh streams. The current behavior of propagating the error prevents recovery and creates an infinite loop.

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_reset_active_stream_error_leaves_inconsistent_state() {
    // Setup: Create a continuous syncer with an active stream
    let (mut streaming_client, streaming_service_listener) = 
        new_streaming_service_client_listener_pair();
    
    // Drop the listener to simulate streaming service crash
    drop(streaming_service_listener);
    
    let mut continuous_syncer = ContinuousSyncer::new(
        driver_configuration,
        streaming_client,
        output_fallback_handler,
        storage,
        storage_synchronizer,
    );
    
    // Initialize an active stream
    continuous_syncer.active_data_stream = Some(create_test_stream());
    continuous_syncer.speculative_stream_state = Some(create_test_state());
    
    // Attempt to reset - this will fail because listener is dropped
    let result = continuous_syncer.reset_active_stream(None).await;
    
    // VULNERABILITY: Error occurs but fields remain set
    assert!(result.is_err());
    assert!(continuous_syncer.active_data_stream.is_some()); // BUG: Should be None
    assert!(continuous_syncer.speculative_stream_state.is_some()); // BUG: Should be None
    
    // Next drive_progress will think stream exists and enter error loop
    let progress_result = continuous_syncer.drive_progress(sync_request).await;
    // Node cannot initialize new stream, permanently stuck
}
```

**Notes**

This vulnerability breaks the **State Consistency** invariant - state transitions must be atomic and consistent. The partial state cleanup creates a broken invariant where the node believes it has an active stream when none exists, preventing recovery.

The issue affects both continuous syncing (post-bootstrap) and bootstrapping phases, making it a systemic problem in the state sync architecture. The fix is straightforward: always perform local cleanup regardless of remote termination success, as the local state must remain consistent with reality.

### Citations

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L76-97)
```rust
    /// Checks if the continuous syncer is able to make progress
    pub async fn drive_progress(
        &mut self,
        consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
    ) -> Result<(), Error> {
        if self.active_data_stream.is_some() {
            // We have an active data stream. Process any notifications!
            self.process_active_stream_notifications(consensus_sync_request)
                .await
        } else if self.storage_synchronizer.pending_storage_data() {
            // Wait for any pending data to be processed
            sample!(
                SampleRate::Duration(Duration::from_secs(PENDING_DATA_LOG_FREQ_SECS)),
                info!("Waiting for the storage synchronizer to handle pending data!")
            );
            Ok(())
        } else {
            // Fetch a new data stream to start streaming data
            self.initialize_active_data_stream(consensus_sync_request)
                .await
        }
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L182-198)
```rust
    /// Attempts to fetch a data notification from the active stream
    async fn fetch_next_data_notification(&mut self) -> Result<DataNotification, Error> {
        let max_stream_wait_time_ms = self.driver_configuration.config.max_stream_wait_time_ms;
        let max_num_stream_timeouts = self.driver_configuration.config.max_num_stream_timeouts;
        let result = utils::get_data_notification(
            max_stream_wait_time_ms,
            max_num_stream_timeouts,
            self.active_data_stream.as_mut(),
        )
        .await;
        if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
            // If the stream has timed out too many times, we need to reset it
            warn!("Resetting the currently active data stream due to too many timeouts!");
            self.reset_active_stream(None).await?;
        }
        result
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L524-542)
```rust
    /// Resets the currently active data stream and speculative state
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/streaming_client.rs (L460-472)
```rust
    async fn terminate_stream_with_feedback(
        &self,
        data_stream_id: DataStreamId,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        let client_request = StreamRequest::TerminateStream(TerminateStreamRequest {
            data_stream_id,
            notification_and_feedback,
        });
        // We can ignore the receiver as no data will be sent.
        let _receiver = self.send_stream_request(client_request).await?;
        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/error.rs (L47-51)
```rust
impl From<SendError> for Error {
    fn from(error: SendError) -> Self {
        Error::UnexpectedErrorEncountered(error.to_string())
    }
}
```

**File:** state-sync/state-sync-driver/src/driver.rs (L698-710)
```rust
            if let Err(error) = self
                .continuous_syncer
                .drive_progress(consensus_sync_request)
                .await
            {
                sample!(
                    SampleRate::Duration(Duration::from_secs(DRIVER_ERROR_LOG_FREQ_SECS)),
                    warn!(LogSchema::new(LogEntry::Driver)
                        .error(&error)
                        .message("Error found when driving progress of the continuous syncer!"));
                );
                metrics::increment_counter(&metrics::CONTINUOUS_SYNCER_ERRORS, error.get_label());
            }
```

**File:** aptos-node/src/state_sync.rs (L217-237)
```rust
fn setup_data_streaming_service(
    state_sync_config: StateSyncConfig,
    aptos_data_client: AptosDataClient,
) -> anyhow::Result<(StreamingServiceClient, Runtime)> {
    // Create the data streaming service
    let (streaming_service_client, streaming_service_listener) =
        new_streaming_service_client_listener_pair();
    let data_streaming_service = DataStreamingService::new(
        state_sync_config.aptos_data_client,
        state_sync_config.data_streaming_service,
        aptos_data_client,
        streaming_service_listener,
        TimeService::real(),
    );

    // Start the data streaming service
    let streaming_service_runtime = aptos_runtimes::spawn_named_runtime("stream-serv".into(), None);
    streaming_service_runtime.spawn(data_streaming_service.start_service());

    Ok((streaming_service_client, streaming_service_runtime))
}
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1539-1556)
```rust
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```
