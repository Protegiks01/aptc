Based on my comprehensive analysis of the Aptos Core codebase, this is a **VALID** security vulnerability. Here is the validated audit report:

# Audit Report

## Title
Memory Leak in RandStore Due to Lack of Garbage Collection for Incomplete Rounds

## Summary
The `RandStore` structure in Aptos consensus accumulates randomness shares for rounds that never reach the aggregation threshold without any garbage collection mechanism. This causes unbounded memory growth within an epoch, potentially leading to validator node resource exhaustion, performance degradation, and availability issues.

## Finding Description

The randomness generation system maintains a `RandStore` that tracks shares for each consensus round in two `BTreeMap` structures: `rand_map` and `fast_rand_map`. [1](#0-0) 

When blocks arrive, the `RandManager` processes incoming metadata and creates entries in these maps to aggregate randomness shares from validators. [2](#0-1) 

Each `RandItem` contains a `ShareAggregator` with a `HashMap<Author, RandShare<S>>` that accumulates shares until the threshold is reached. [3](#0-2) 

**The Critical Flaw:**

The `reset()` method only removes *future* rounds (those >= target_round) using `split_off()`, but provides no mechanism to clean up old rounds that failed to complete. [4](#0-3) 

When shares are added, they are only rejected if they exceed `FUTURE_ROUNDS_TO_ACCEPT` (200 rounds) beyond the highest known round. [5](#0-4) [6](#0-5) 

However, there is no corresponding cleanup for *old* incomplete rounds. New entries are created via `entry().or_insert_with()`, and once created, they remain indefinitely until epoch change. [7](#0-6) 

**Attack Scenario:**

1. Byzantine validators (staying under 1/3 threshold) selectively withhold randomness shares for certain rounds
2. These rounds fail to collect enough shares to reach the aggregation threshold
3. Incomplete `RandItem` entries remain in `rand_map` with partial cryptographic data (BLS signatures, metadata)
4. Over an epoch with thousands of rounds, hundreds of incomplete rounds accumulate
5. Memory consumption grows linearly with each incomplete round
6. Validator nodes experience memory pressure, performance degradation, and potentially OOM crashes

Notably, other consensus components implement garbage collection (e.g., `PendingBlocks::gc()` [8](#0-7) ), but `RandStore` lacks this protection, indicating a clear oversight.

## Impact Explanation

This qualifies as **Medium Severity** under the Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: As `rand_map` grows large, BTreeMap operations degrade in performance, affecting share aggregation and consensus operations
2. **Memory Exhaustion**: Sustained Byzantine behavior can consume significant memory (potentially hundreds of MB over long epochs)
3. **Availability Impact**: Sufficient memory pressure can lead to out-of-memory conditions, causing validator crashes and impacting network liveness

The impact is limited to within-epoch duration since `RandManager` is recreated on epoch changes, clearing all state. [9](#0-8)  However, epochs can last hours to days in production, providing substantial time for memory accumulation.

## Likelihood Explanation

**Likelihood: Medium to High**

This issue can occur through:

1. **Byzantine Behavior**: Malicious validators (under 1/3 threshold) selectively withholding shares to prevent aggregation - this is within the Aptos threat model and requires no special privileges
2. **Natural Network Conditions**: Intermittent latency or connectivity issues preventing threshold from being reached for some rounds
3. **No Economic Barriers**: The attack requires no stake beyond validator status and operates within consensus rules

The vulnerability is triggerable by any Byzantine validator subset below the 1/3 threshold, making it realistic and within the established threat model.

## Recommendation

Implement a garbage collection mechanism in `RandStore` similar to other consensus components. Add a method to periodically remove incomplete rounds that are sufficiently old (e.g., more than 1000 rounds behind the highest known round):

```rust
pub fn gc_old_rounds(&mut self, rounds_to_keep: u64) {
    if self.highest_known_round > rounds_to_keep {
        let cutoff_round = self.highest_known_round - rounds_to_keep;
        let to_remove: Vec<_> = self.rand_map
            .range(..cutoff_round)
            .map(|(r, _)| *r)
            .collect();
        for round in to_remove {
            self.rand_map.remove(&round);
        }
        if let Some(fast_map) = self.fast_rand_map.as_mut() {
            let to_remove: Vec<_> = fast_map
                .range(..cutoff_round)
                .map(|(r, _)| *r)
                .collect();
            for round in to_remove {
                fast_map.remove(&round);
            }
        }
    }
}
```

Call this method periodically (e.g., every 100 rounds) from `RandManager::start()` event loop.

## Proof of Concept

The vulnerability can be observed by monitoring memory growth during an epoch with incomplete rounds:

1. Deploy a network with validators where < 1/3 are Byzantine
2. Byzantine validators withhold shares for every 5th round
3. Monitor validator memory usage over 10,000 rounds
4. Observe linear memory growth in `RandStore` as incomplete `RandItem` entries accumulate
5. Memory is only cleared on epoch transition, not during normal operation

The absence of any `clear()`, `remove()`, or `retain()` operations on `rand_map` for old rounds confirms the leak exists in the codebase.

### Citations

**File:** consensus/src/rand/rand_gen/rand_store.rs (L18-33)
```rust
pub struct ShareAggregator<S> {
    author: Author,
    shares: HashMap<Author, RandShare<S>>,
    total_weight: u64,
    path_type: PathType,
}

impl<S: TShare> ShareAggregator<S> {
    pub fn new(author: Author, path_type: PathType) -> Self {
        Self {
            author,
            shares: HashMap::new(),
            total_weight: 0,
            path_type,
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L218-227)
```rust
pub struct RandStore<S> {
    epoch: u64,
    author: Author,
    rand_config: RandConfig,
    rand_map: BTreeMap<Round, RandItem<S>>,
    fast_rand_config: Option<RandConfig>,
    fast_rand_map: Option<BTreeMap<Round, RandItem<S>>>,
    highest_known_round: u64,
    decision_tx: Sender<Randomness>,
}
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-288)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L304-308)
```rust
                self.rand_map
                    .entry(rand_metadata.round)
                    .or_insert_with(|| RandItem::new(self.author, PathType::Slow)),
            )
        };
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L145-156)
```rust
    fn process_incoming_metadata(&self, metadata: FullRandMetadata) -> DropGuard {
        let self_share = S::generate(&self.config, metadata.metadata.clone());
        info!(LogSchema::new(LogEvent::BroadcastRandShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(metadata.round()));
        let mut rand_store = self.rand_store.lock();
        rand_store.update_highest_known_round(metadata.round());
        rand_store
            .add_share(self_share.clone(), PathType::Slow)
            .expect("Add self share should succeed");

```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/block_storage/pending_blocks.rs (L122-133)
```rust
    pub fn gc(&mut self, round: Round) {
        let mut to_remove = vec![];
        for (r, _) in self.blocks_by_round.range(..=round) {
            to_remove.push(*r);
        }
        for r in to_remove {
            self.opt_blocks_by_round.remove(&r);
            if let Some(block) = self.blocks_by_round.remove(&r) {
                self.blocks_by_hash.remove(&block.id());
            }
        }
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L240-259)
```rust
        let rand_manager = RandManager::<Share, AugmentedData>::new(
            self.author,
            epoch_state.clone(),
            signer,
            rand_config,
            fast_rand_config,
            rand_ready_block_tx,
            network_sender.clone(),
            self.rand_storage.clone(),
            self.bounded_executor.clone(),
            &self.consensus_config.rand_rb_config,
        );

        tokio::spawn(rand_manager.start(
            ordered_block_rx,
            rand_msg_rx,
            reset_rand_manager_rx,
            self.bounded_executor.clone(),
            highest_committed_round,
        ));
```
