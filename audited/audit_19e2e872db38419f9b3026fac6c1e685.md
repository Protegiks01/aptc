# Audit Report

## Title
Consensus Observer Accepts Unverified Future-Epoch Commit Decisions Leading to Invalid State Sync Targets

## Summary
The Consensus Observer component accepts `CommitDecision` messages with future epoch values without signature verification, then passes the unverified `LedgerInfoWithSignatures` to `sync_to_target()`. This allows attackers to trigger resource-wasting state synchronization attempts to invalid targets, potentially causing validator slowdowns and denial of service.

## Finding Description

The vulnerability exists in the consensus observer's commit decision processing logic. When a consensus observer receives a `CommitDecision` message, the verification logic has a critical gap for future-epoch commits: [1](#0-0) 

The verification via `verify_commit_proof()` only occurs when `commit_epoch == epoch_state.epoch`. However, when the commit decision has a future epoch (`commit_epoch > epoch_state.epoch`), the verification is completely skipped, but the code continues execution to potentially call `sync_to_commit()`: [2](#0-1) 

The `sync_to_commit()` function then invokes state sync with the unverified commit proof: [3](#0-2) 

The state sync driver receives this target but performs NO signature verification: [4](#0-3) 

The state sync layer only validates version ordering, not cryptographic signatures. Confirmation that no signature verification exists in the state-sync directory was verified through codebase analysis.

**Attack Path:**
1. Attacker (malicious consensus publisher or network peer) sends `CommitDecision` message to consensus observer
2. The commit decision contains:
   - `commit_epoch > current_epoch_state.epoch` (future epoch)
   - Invalid signatures (forged, insufficient quorum, or completely fabricated)
   - Arbitrary state root hash
3. Consensus observer processes message in `process_commit_decision_message()`
4. Verification skipped because epoch mismatch (line 468 condition false)
5. Code proceeds to line 526, calling `sync_to_commit(commit_decision, true)`
6. Unverified target passed to `execution_client.sync_to_target()`
7. State sync driver accepts target without signature validation
8. Validator wastes resources attempting to sync to invalid target

**Invariant Violated:**
- **Cryptographic Correctness**: The system must verify BLS signatures before trusting ledger information. This invariant is broken when future-epoch commit decisions bypass verification.
- **Consensus Safety**: While not a direct safety violation, accepting unverified sync targets undermines the trust model and can cause liveness issues.

## Impact Explanation

**Severity: HIGH** per Aptos bug bounty criteria

This vulnerability enables multiple high-severity impacts:

1. **Validator Node Slowdowns**: Attackers can force validators to repeatedly initiate resource-intensive state synchronization to invalid targets. Each attempt involves:
   - Memory allocation for sync state
   - Network bandwidth fetching chunks from peers  
   - CPU cycles attempting to apply transactions
   - Storage I/O during the sync process

2. **Significant Protocol Violation**: The core security principle that all `LedgerInfoWithSignatures` must be cryptographically verified before use is violated. This breaks the fundamental trust model of AptosBFT.

3. **Denial of Service Vector**: By repeatedly sending bogus future-epoch commit decisions, an attacker can:
   - Exhaust validator resources
   - Delay legitimate state synchronization
   - Degrade network-wide liveness if multiple validators are targeted

4. **State Inconsistency Risk**: The `ExecutionProxy` updates its internal `logical_time` before verifying sync success: [5](#0-4) 

If sync fails with an invalid target, the logical time has already been corrupted (line 222), potentially causing internal state tracking issues.

The impact does NOT reach Critical severity because:
- Validators won't actually commit invalid state (sync will fail during execution)
- No direct fund loss
- Not a consensus safety violation (won't cause chain splits)

However, it clearly meets HIGH severity criteria through validator slowdowns and protocol violations.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Attack Complexity**: The attacker only needs to:
   - Connect to the consensus observer network
   - Send a malformed `CommitDecision` message
   - No validator private keys required
   - No stake or governance participation needed

2. **Multiple Attack Vectors**:
   - Malicious or compromised consensus publisher
   - Network man-in-the-middle attacker
   - Any peer that can deliver messages to consensus observers

3. **No Authentication Required**: The consensus observer accepts and processes commit decisions before validation, making the attack straightforward.

4. **Repeatable**: The attack can be executed repeatedly to amplify resource exhaustion effects.

5. **Affects Critical Path**: Consensus observers are increasingly used in the Aptos network for scalability, making this a high-value target.

## Recommendation

Add signature verification for future-epoch commit decisions before initiating state sync. The fix should verify signatures against the CURRENT epoch's validator set when available, or defer the commit decision until the epoch change is processed through proper channels.

**Recommended Fix:**

In `consensus/src/consensus_observer/observer/consensus_observer.rs`, modify `process_commit_decision_message()` to handle future-epoch commits securely:

```rust
// Current code at line 466-495
if commit_epoch == epoch_state.epoch {
    // Verify the commit decision
    if let Err(error) = commit_decision.verify_commit_proof(&epoch_state) {
        // ... error handling
        return;
    }
    // ... process commit
}

// ADD THIS CHECK for future epochs:
if commit_epoch > epoch_state.epoch {
    // For future epoch commits, we cannot verify against the future validator set
    // Log a warning and defer processing until epoch change occurs naturally
    warn!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Received commit decision for future epoch: {:?}, current epoch: {:?}. \
            Deferring until epoch change is processed through proper channels.",
            commit_epoch, epoch_state.epoch
        ))
    );
    // Do NOT call sync_to_commit for unverifiable future-epoch commits
    return;
}
```

Alternatively, implement deferred verification by storing future-epoch commit decisions and verifying them after receiving the proper `EpochChangeProof` through the regular epoch transition mechanism.

## Proof of Concept

```rust
// Proof of Concept: Demonstrate unverified sync_to_target call
// This shows the vulnerable code path, not a runnable exploit

use aptos_consensus_types::common::Payload;
use aptos_types::{
    aggregate_signature::AggregateSignature,
    block_info::BlockInfo,
    ledger_info::{LedgerInfo, LedgerInfoWithSignatures},
};
use aptos_crypto::HashValue;

#[tokio::test]
async fn test_unverified_future_epoch_commit() {
    // Step 1: Create a malicious CommitDecision with future epoch
    let future_epoch = 100; // Far future epoch
    let current_epoch = 10;
    
    // Create bogus ledger info
    let malicious_block_info = BlockInfo::new(
        future_epoch,
        999, // round
        HashValue::random(), // id  
        HashValue::random(), // executed_state_id (fake state root)
        0, // version
        0, // timestamp
        None, // next_epoch_state
    );
    
    let ledger_info = LedgerInfo::new(
        malicious_block_info,
        HashValue::zero(), // consensus_data_hash
    );
    
    // Create INVALID signatures (empty signature = no quorum)
    let invalid_signatures = AggregateSignature::empty();
    let commit_proof = LedgerInfoWithSignatures::new(ledger_info, invalid_signatures);
    
    // Step 2: Consensus observer receives this commit decision
    // Because future_epoch (100) > current_epoch (10):
    // - Line 468 condition fails (commit_epoch != epoch_state.epoch)
    // - Verification at line 470 is SKIPPED
    // - Code continues to line 500-527
    // - Line 503: epoch_changed = true (because future_epoch > last_block.epoch)
    // - Line 526: sync_to_commit(commit_decision, true) is called
    
    // Step 3: sync_to_commit calls sync_to_target with UNVERIFIED commit_proof
    // Line 221 in state_sync_manager.rs:
    // execution_client.sync_to_target(commit_decision.commit_proof().clone()).await
    
    // Step 4: State sync driver accepts without signature verification
    // Only version checks in initialize_sync_target_request (lines 268-317)
    // NO call to verify_signatures() anywhere in state-sync layer
    
    // Result: Validator initiates state sync to completely invalid target
    // - Invalid signatures not detected
    // - Arbitrary state root accepted as target
    // - Resources wasted attempting to sync
    // - Can be repeated for DoS
}
```

**Attack Simulation Steps:**
1. Set up consensus observer subscribed to a malicious publisher
2. Publisher sends `CommitDecision` with epoch 1000 (future), empty signatures, random state root
3. Observer skips verification (epoch mismatch)
4. Observer calls `sync_to_target()` with unverified target
5. Monitor validator resource usage during bogus sync attempts
6. Repeat attack every few seconds to demonstrate sustained DoS
7. Observe validator performance degradation and log corruption warnings

## Notes

**Additional Context:**

The vulnerability specifically affects the Consensus Observer component, which is designed to allow validators to follow consensus without actively participating. While observers in other consensus implementations (RecoveryManager, EpochManager, DAG sync) properly verify signatures before calling sync_to_target: [6](#0-5) [7](#0-6) 

The consensus observer's future-epoch handling creates an exploitable gap. This appears to be an oversight in handling the edge case where commit decisions arrive before epoch change proofs.

The proper solution requires either:
1. Deferring future-epoch commits until epoch change is validated, OR
2. Implementing special verification logic for cross-epoch transitions

The current implementation prioritizes liveness (syncing quickly to catch up) over safety (verifying before trusting), which violates Aptos security principles.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L466-495)
```rust
        // If the commit decision is for the current epoch, verify and process it
        let epoch_state = self.get_epoch_state();
        if commit_epoch == epoch_state.epoch {
            // Verify the commit decision
            if let Err(error) = commit_decision.verify_commit_proof(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify commit decision! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                        commit_decision.proof_block_info(),
                        peer_network_id,
                        error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::COMMIT_DECISION_LABEL);
                return;
            }

            // Update the latency metrics for commit processing
            update_message_processing_latency_metrics(
                message_received_time,
                &peer_network_id,
                metrics::COMMIT_DECISION_LABEL,
            );

            // Update the pending blocks with the commit decision
            if self.process_commit_decision_for_pending_block(&commit_decision) {
                return; // The commit decision was successfully processed
            }
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L500-527)
```rust
        // Otherwise, we failed to process the commit decision. If the commit
        // is for a future epoch or round, we need to state sync.
        let last_block = self.observer_block_data.lock().get_last_ordered_block();
        let epoch_changed = commit_epoch > last_block.epoch();
        if epoch_changed || commit_round > last_block.round() {
            // If we're waiting for state sync to transition into a new epoch,
            // we should just wait and not issue a new state sync request.
            if self.state_sync_manager.is_syncing_through_epoch() {
                info!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Already waiting for state sync to reach new epoch: {:?}. Dropping commit decision: {:?}!",
                        self.observer_block_data.lock().root().commit_info(),
                        commit_decision.proof_block_info()
                    ))
                );
                return;
            }

            // Otherwise, we should start the state sync process for the commit.
            // Update the block data (to the commit decision).
            self.observer_block_data
                .lock()
                .update_blocks_for_state_sync_commit(&commit_decision);

            // Start state syncing to the commit decision
            self.state_sync_manager
                .sync_to_commit(commit_decision, epoch_changed);
        }
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L219-222)
```rust
                if let Err(error) = execution_client
                    .clone()
                    .sync_to_target(commit_decision.commit_proof().clone())
                    .await
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L261-318)
```rust
    /// Initializes the sync target request received from consensus
    pub async fn initialize_sync_target_request(
        &mut self,
        sync_target_notification: ConsensusSyncTargetNotification,
        latest_pre_committed_version: Version,
        latest_synced_ledger_info: LedgerInfoWithSignatures,
    ) -> Result<(), Error> {
        // Get the target sync version and latest committed version
        let sync_target_version = sync_target_notification
            .get_target()
            .ledger_info()
            .version();
        let latest_committed_version = latest_synced_ledger_info.ledger_info().version();

        // If the target version is old, return an error to consensus (something is wrong!)
        if sync_target_version < latest_committed_version
            || sync_target_version < latest_pre_committed_version
        {
            let error = Err(Error::OldSyncRequest(
                sync_target_version,
                latest_pre_committed_version,
                latest_committed_version,
            ));
            self.respond_to_sync_target_notification(sync_target_notification, error.clone())?;
            return error;
        }

        // If the committed version is at the target, return successfully
        if sync_target_version == latest_committed_version {
            info!(
                LogSchema::new(LogEntry::NotificationHandler).message(&format!(
                    "We're already at the requested sync target version: {} \
                (pre-committed version: {}, committed version: {})!",
                    sync_target_version, latest_pre_committed_version, latest_committed_version
                ))
            );
            let result = Ok(());
            self.respond_to_sync_target_notification(sync_target_notification, result.clone())?;
            return result;
        }

        // If the pre-committed version is already at the target, something has else gone wrong
        if sync_target_version == latest_pre_committed_version {
            let error = Err(Error::InvalidSyncRequest(
                sync_target_version,
                latest_pre_committed_version,
            ));
            self.respond_to_sync_target_notification(sync_target_notification, error.clone())?;
            return error;
        }

        // Save the request so we can notify consensus once we've hit the target
        let consensus_sync_request =
            ConsensusSyncRequest::new_with_target(sync_target_notification);
        self.consensus_sync_request = Arc::new(Mutex::new(Some(consensus_sync_request)));

        Ok(())
    }
```

**File:** consensus/src/state_computer.rs (L177-233)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        // Grab the logical time lock and calculate the target logical time
        let mut latest_logical_time = self.write_mutex.lock().await;
        let target_logical_time =
            LogicalTime::new(target.ledger_info().epoch(), target.ledger_info().round());

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by BlockExecutor to prevent a memory leak.
        self.executor.finish();

        // The pipeline phase already committed beyond the target block timestamp, just return.
        if *latest_logical_time >= target_logical_time {
            warn!(
                "State sync target {:?} is lower than already committed logical time {:?}",
                target_logical_time, *latest_logical_time
            );
            return Ok(());
        }

        // This is to update QuorumStore with the latest known commit in the system,
        // so it can set batches expiration accordingly.
        // Might be none if called in the recovery path, or between epoch stop and start.
        if let Some(inner) = self.state.read().as_ref() {
            let block_timestamp = target.commit_info().timestamp_usecs();
            inner
                .payload_manager
                .notify_commit(block_timestamp, Vec::new());
        }

        // Inject an error for fail point testing
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Invoke state sync to synchronize to the specified target. Here, the
        // ChunkExecutor will process chunks and commit to storage. However, after
        // block execution and commits, the internal state of the ChunkExecutor may
        // not be up to date. So, it is required to reset the cache of the
        // ChunkExecutor in state sync when requested to sync.
        let result = monitor!(
            "sync_to_target",
            self.state_sync_notifier.sync_to_target(target).await
        );

        // Update the latest logical time
        *latest_logical_time = target_logical_time;

        // Similarly, after state synchronization, we have to reset the cache of
        // the BlockExecutor to guarantee the latest committed state is up to date.
        self.executor.reset()?;

        // Return the result
        result.map_err(|error| {
            let anyhow_error: anyhow::Error = error.into();
            anyhow_error.into()
        })
    }
```

**File:** consensus/src/recovery_manager.rs (L84-86)
```rust
    pub async fn sync_up(&mut self, sync_info: &SyncInfo, peer: Author) -> Result<RecoveryData> {
        sync_info.verify(&self.epoch_state.verifier)?;
        ensure!(
```

**File:** consensus/src/epoch_manager.rs (L545-547)
```rust
        let ledger_info = proof
            .verify(self.epoch_state())
            .context("[EpochManager] Invalid EpochChangeProof")?;
```
