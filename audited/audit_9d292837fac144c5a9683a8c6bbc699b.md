# Audit Report

## Title
Resource Leak: Consensus Publisher Serialization Task Hangs Indefinitely After Publisher Shutdown

## Summary
When the `ConsensusPublisher::start()` loop exits, the spawned message serialization task in `spawn_message_serializer_and_sender()` remains alive indefinitely, consuming system resources. This occurs because the publisher is cloned before starting, and the original instance (wrapped in `Arc`) retains ownership of the `outbound_message_sender`, preventing the channel from closing and causing the serialization task to hang on `.collect::<()>().await`.

## Finding Description
The vulnerability exists in the initialization and lifecycle management of the `ConsensusPublisher`: [1](#0-0) 

The publisher is cloned before calling `start()`, and the original is wrapped in an `Arc` and returned. The cloned instance enters the `start()` loop: [2](#0-1) 

When the loop exits at the `else` branch (line 265-267), the cloned `ConsensusPublisher` is dropped. However, the serialization task spawned earlier continues waiting: [3](#0-2) 

The serialization task uses `.collect::<()>().await` on line 347 to consume the stream. This operation blocks until the `outbound_message_receiver` stream completes, which only happens when **all** `outbound_message_sender` instances are dropped.

**The Problem**: Each `ConsensusPublisher` instance has its own copy of `outbound_message_sender` due to the `Clone` derivation: [4](#0-3) 

When `start()` exits:
1. The **cloned** publisher is dropped
2. But the **original** publisher (in the `Arc`) remains alive
3. The original still holds its `outbound_message_sender`
4. The channel never closes
5. The serialization task hangs forever on `.collect::<()>().await`

This violates the **Resource Limits** invariant, which requires all operations to respect resource constraints.

## Impact Explanation
This is a **Medium Severity** vulnerability per the Aptos bug bounty criteria:

1. **Resource Exhaustion**: Each time the publisher is started and stopped (e.g., during node restarts, feature toggles, or testing), a tokio task remains alive indefinitely. While a single task has minimal overhead, repeated start/stop cycles cause accumulation.

2. **State Inconsistencies Requiring Intervention**: In long-running nodes with multiple restart cycles or in testing environments, the accumulation of hung tasks can degrade node performance and eventually require manual intervention or node restart.

3. **Limited Availability Impact**: The hung tasks consume tokio runtime worker slots. If enough tasks accumulate, they can starve the runtime and affect the node's ability to process new tasks, impacting availability.

The impact is limited because:
- It requires shutdown/restart cycles to accumulate
- Single instance has minimal impact
- Does not directly affect consensus safety or fund security
- Can be mitigated by node restart

However, it represents a clear resource management bug that degrades system reliability over time.

## Likelihood Explanation
**Likelihood: High**

This vulnerability triggers automatically under normal operational conditions:

1. **Guaranteed Trigger**: Occurs every time the publisher's `start()` loop exits (when `publisher_message_receiver` completes)
2. **Operational Scenarios**:
   - Node shutdown/restart cycles
   - Consensus observer feature being disabled/re-enabled
   - Network handler exits due to network events stream completion
3. **No Special Privileges Required**: Happens through normal lifecycle management, no attacker action needed
4. **Accumulation Over Time**: In environments with frequent restarts (testing, development, or operational reconfigurations), leaked tasks accumulate rapidly

## Recommendation
The fix requires ensuring the `outbound_message_sender` channel is properly closed when `start()` exits. Two approaches:

**Option 1: Drop the sender explicitly before loop exit**
```rust
// In ConsensusPublisher::start(), before the loop exits:
drop(self.outbound_message_sender);
```

**Option 2: Restructure to avoid cloning (preferred)**
Modify the initialization to not clone the publisher:

```rust
fn create_consensus_publisher(
    node_config: &NodeConfig,
    consensus_observer_client: Arc<ConsensusObserverClient<NetworkClient<ConsensusObserverMessage>>>,
    publisher_message_receiver: Receiver<(), ConsensusPublisherNetworkMessage>,
) -> (Option<Runtime>, Option<Arc<ConsensusPublisher>>) {
    if !node_config.consensus_observer.publisher_enabled {
        return (None, None);
    }

    let runtime = aptos_runtimes::spawn_named_runtime("publisher".into(), None);
    let (consensus_publisher, outbound_message_receiver) =
        ConsensusPublisher::new(node_config.consensus_observer, consensus_observer_client);
    
    let consensus_publisher_arc = Arc::new(consensus_publisher);
    
    // Clone only the Arc, not the publisher itself
    let consensus_publisher_for_start = consensus_publisher_arc.clone();
    runtime.spawn(async move {
        // Move the receivers into a scope that owns them
        consensus_publisher_for_start.start_with_owned_receiver(
            outbound_message_receiver,
            publisher_message_receiver
        ).await;
    });

    (Some(runtime), Some(consensus_publisher_arc))
}
```

And modify `start()` to take receivers by value without taking `self` by value, or create a separate method that handles the lifecycle without dropping the sender prematurely.

**Option 3: Use weak references for the serialization task**
Ensure the serialization task can detect when the publisher is dropped and exit gracefully.

## Proof of Concept
```rust
#[tokio::test]
async fn test_publisher_resource_leak() {
    use tokio::time::{sleep, Duration};
    use std::sync::Arc;
    use aptos_config::config::ConsensusObserverConfig;
    use aptos_network::application::storage::PeersAndMetadata;
    use aptos_network::application::interface::NetworkClient;
    use aptos_config::network_id::NetworkId;
    
    // Create a consensus observer client
    let network_id = NetworkId::Public;
    let peers_and_metadata = PeersAndMetadata::new(&[network_id]);
    let network_client = NetworkClient::new(vec![], vec![], hashmap![], peers_and_metadata);
    let consensus_observer_client = Arc::new(ConsensusObserverClient::new(network_client));
    
    // Create the publisher
    let (consensus_publisher, outbound_message_receiver) = 
        ConsensusPublisher::new(
            ConsensusObserverConfig::default(),
            consensus_observer_client
        );
    
    // Create a channel for network messages
    let (publisher_message_sender, publisher_message_receiver) = aptos_channel::new(
        QueueStyle::FIFO,
        100,
        None
    );
    
    // Clone and start the publisher (simulating the actual initialization)
    let publisher_clone = consensus_publisher.clone();
    let start_handle = tokio::spawn(publisher_clone.start(
        outbound_message_receiver,
        publisher_message_receiver
    ));
    
    // Allow the publisher to start
    sleep(Duration::from_millis(100)).await;
    
    // Drop the sender to trigger publisher shutdown
    drop(publisher_message_sender);
    
    // Wait for the start loop to exit
    start_handle.await.unwrap();
    
    // At this point, the serialization task should exit but won't
    // because consensus_publisher (original) still holds outbound_message_sender
    
    // The original publisher's sender keeps the channel open
    assert!(!consensus_publisher.outbound_message_sender.is_closed());
    
    // If we publish a message, it will be accepted but never processed
    // because the serialization task is waiting on a channel that will never close
    
    println!("Publisher start() exited, but serialization task is still alive");
    println!("This demonstrates the resource leak");
    
    // The test would need to verify task count or similar metrics
    // to definitively prove the leak, but the logic demonstrates the issue
}
```

**Notes**
This vulnerability represents a clear violation of proper resource lifecycle management. While the immediate impact is limited, it degrades node reliability over time and could affect long-running production validators. The fix is straightforward: ensure the channel is properly closed when the publisher's main loop exits, either by explicitly dropping the sender or restructuring the ownership model to avoid the clone that creates the resource leak.

### Citations

**File:** aptos-node/src/consensus.rs (L256-264)
```rust
    let (consensus_publisher, outbound_message_receiver) =
        ConsensusPublisher::new(node_config.consensus_observer, consensus_observer_client);

    // Start the consensus publisher
    runtime.spawn(
        consensus_publisher
            .clone()
            .start(outbound_message_receiver, publisher_message_receiver),
    );
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L30-44)
```rust
#[derive(Clone)]
pub struct ConsensusPublisher {
    // The consensus observer client to send network messages
    consensus_observer_client:
        Arc<ConsensusObserverClient<NetworkClient<ConsensusObserverMessage>>>,

    // The configuration for the consensus observer
    consensus_observer_config: ConsensusObserverConfig,

    // The set of active subscribers that have subscribed to consensus updates
    active_subscribers: Arc<RwLock<HashSet<PeerNetworkId>>>,

    // The sender for outbound network messages
    outbound_message_sender: mpsc::Sender<(PeerNetworkId, ConsensusObserverDirectSend)>,
}
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L235-274)
```rust
    pub async fn start(
        self,
        outbound_message_receiver: mpsc::Receiver<(PeerNetworkId, ConsensusObserverDirectSend)>,
        mut publisher_message_receiver: Receiver<(), ConsensusPublisherNetworkMessage>,
    ) {
        // Spawn the message serializer and sender
        spawn_message_serializer_and_sender(
            self.consensus_observer_client.clone(),
            self.consensus_observer_config,
            outbound_message_receiver,
        );

        // Create a garbage collection ticker
        let mut garbage_collection_interval = IntervalStream::new(interval(Duration::from_millis(
            self.consensus_observer_config
                .garbage_collection_interval_ms,
        )))
        .fuse();

        // Start the publisher garbage collection loop
        info!(LogSchema::new(LogEntry::ConsensusPublisher)
            .message("Starting the consensus publisher garbage collection loop!"));
        loop {
            tokio::select! {
                Some(network_message) = publisher_message_receiver.next() => {
                    self.process_network_message(network_message);
                },
                _ = garbage_collection_interval.select_next_some() => {
                    self.garbage_collect_subscriptions();
                },
                else => {
                    break; // Exit the consensus publisher loop
                }
            }
        }

        // Log the exit of the consensus publisher loop
        error!(LogSchema::new(LogEntry::ConsensusPublisher)
            .message("The consensus publisher loop exited unexpectedly!"));
    }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L279-350)
```rust
fn spawn_message_serializer_and_sender(
    consensus_observer_client: Arc<
        ConsensusObserverClient<NetworkClient<ConsensusObserverMessage>>,
    >,
    consensus_observer_config: ConsensusObserverConfig,
    outbound_message_receiver: mpsc::Receiver<(PeerNetworkId, ConsensusObserverDirectSend)>,
) {
    tokio::spawn(async move {
        // Create the message serialization task
        let consensus_observer_client_clone = consensus_observer_client.clone();
        let serialization_task =
            outbound_message_receiver.map(move |(peer_network_id, message)| {
                // Spawn a new blocking task to serialize the message
                let consensus_observer_client_clone = consensus_observer_client_clone.clone();
                tokio::task::spawn_blocking(move || {
                    let message_label = message.get_label();
                    let serialized_message = consensus_observer_client_clone
                        .serialize_message_for_peer(&peer_network_id, message);
                    (peer_network_id, serialized_message, message_label)
                })
            });

        // Execute the serialization task with in-order buffering
        let consensus_observer_client_clone = consensus_observer_client.clone();
        serialization_task
            .buffered(consensus_observer_config.max_parallel_serialization_tasks)
            .map(|serialization_result| {
                // Attempt to send the serialized message to the peer
                match serialization_result {
                    Ok((peer_network_id, serialized_message, message_label)) => {
                        match serialized_message {
                            Ok(serialized_message) => {
                                // Send the serialized message to the peer
                                if let Err(error) = consensus_observer_client_clone
                                    .send_serialized_message_to_peer(
                                        &peer_network_id,
                                        serialized_message,
                                        message_label,
                                    )
                                {
                                    // We failed to send the message
                                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                                        .event(LogEvent::SendDirectSendMessage)
                                        .message(&format!(
                                            "Failed to send message to peer: {:?}. Error: {:?}",
                                            peer_network_id, error
                                        )));
                                }
                            },
                            Err(error) => {
                                // We failed to serialize the message
                                warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                                    .event(LogEvent::SendDirectSendMessage)
                                    .message(&format!(
                                        "Failed to serialize message for peer: {:?}. Error: {:?}",
                                        peer_network_id, error
                                    )));
                            },
                        }
                    },
                    Err(error) => {
                        // We failed to spawn the serialization task
                        warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                            .event(LogEvent::SendDirectSendMessage)
                            .message(&format!("Failed to spawn the serializer task: {:?}", error)));
                    },
                }
            })
            .collect::<()>()
            .await;
    });
}
```
