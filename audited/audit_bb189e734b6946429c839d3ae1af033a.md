# Audit Report

## Title
Unverified Future Epoch Commit Decisions Cause Premature Payload Removal and Observer DoS

## Summary
A Byzantine validator can send an unverified commit decision for a future epoch to consensus observers, causing immediate removal of all current epoch block payloads without cryptographic verification. This results in loss of liveness for observer nodes (Validator Fullnodes and Public Fullnodes) that cannot execute blocks and must rely on state sync recovery.

## Finding Description

The consensus observer processes commit decision messages from subscribed peers to stay synchronized with the network. The vulnerability exists in the message processing flow where commit decisions for future epochs bypass signature verification but still trigger block payload removal.

**Attack Flow:**

1. A Byzantine validator establishes a subscription with a consensus observer [1](#0-0) 

2. The attacker sends a `CommitDecision` message with `epoch = current_epoch + 1` and `round = 0` [2](#0-1) 

3. In `process_commit_decision_message()`, the signature verification only occurs when `commit_epoch == epoch_state.epoch` (current epoch), so future epoch commits skip verification entirely [3](#0-2) 

4. Since the future epoch is ahead of the current state, the code proceeds to state sync logic and calls `update_blocks_for_state_sync_commit()` without verification [4](#0-3) 

5. This function calls `remove_blocks_for_epoch_round(commit_epoch, commit_round)` which removes payloads [5](#0-4) 

6. The `remove_blocks_for_epoch_round()` function uses `split_off()` to remove all blocks with keys less than `(epoch, round+1)`. With `epoch = current+1, round = 0`, the split point becomes `(current+1, 1)`, removing ALL blocks from the current epoch and earlier [6](#0-5) 

7. The test suite confirms this behavior: calling `remove_blocks_for_epoch_round(future_epoch, 0)` empties the entire payload store [7](#0-6) 

**Invariant Violations:**

- **Transaction Validation Invariant**: Signature verification is bypassed for future epoch commit decisions
- **Resource Limits Invariant**: No protection against malicious removal of critical resources (block payloads)
- **Liveness Guarantee**: Observer nodes lose ability to execute blocks

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under the Aptos Bug Bounty program criteria for the following reasons:

**Total Loss of Liveness**: Once payloads are removed, the observer cannot execute any blocks for the current epoch. All incoming ordered blocks will fail to execute because their payloads are missing [8](#0-7) 

**Network Availability Impact**: Consensus observers serve critical infrastructure roles:
- Validator Fullnodes (VFNs) provide API access for validators and their clients
- Public Fullnodes (PFNs) serve public API requests
- Both node types rely on consensus observer to stay synchronized [9](#0-8) 

**Recovery Challenges**: The observer attempts state sync to the fake commit proof, which will fail since the target doesn't exist on the network [10](#0-9) 

The observer remains in a broken state, unable to process blocks, until manual intervention or legitimate epoch transition occurs.

## Likelihood Explanation

**High Likelihood** of exploitation:

- **Attacker Requirements**: Only requires being a Byzantine validator with an active subscription to the target observer. Under Aptos BFT assumptions, up to 1/3 of validators can be Byzantine.

- **Attack Complexity**: Low. The attacker simply sends a single malformed `CommitDecision` message with future epoch values.

- **Detection Difficulty**: The attack appears as a legitimate epoch transition message and bypasses verification checks.

- **Broad Impact**: A single malicious validator can DoS multiple observers simultaneously by targeting all subscribed observers.

## Recommendation

Add signature verification for all commit decisions regardless of epoch, not just current epoch commits. The verification should occur before any state modifications.

**Proposed Fix:**

```rust
// In process_commit_decision_message(), around line 466
fn process_commit_decision_message(
    &mut self,
    peer_network_id: PeerNetworkId,
    message_received_time: Instant,
    commit_decision: CommitDecision,
) {
    // ... existing checks ...
    
    // ALWAYS verify commit proof before processing, regardless of epoch
    let epoch_state = self.get_epoch_state();
    if let Err(error) = commit_decision.verify_commit_proof(&epoch_state) {
        // For future epochs, attempt verification with cached future epoch states
        // or reject if no valid verification possible
        error!(/* log verification failure */);
        increment_invalid_message_counter(&peer_network_id, metrics::COMMIT_DECISION_LABEL);
        return;
    }
    
    // ... rest of processing ...
}
```

Alternatively, defer processing of future epoch commit decisions until epoch state is available for verification, rather than immediately removing payloads.

## Proof of Concept

```rust
#[test]
fn test_unverified_future_epoch_dos() {
    // Setup: Create observer at epoch 10
    let current_epoch = 10;
    let consensus_observer_config = ConsensusObserverConfig::default();
    let mut block_payload_store = BlockPayloadStore::new(consensus_observer_config);
    
    // Add 100 blocks for current epoch (10)
    let num_blocks = 100;
    let blocks = create_and_add_blocks_to_store(
        &mut block_payload_store,
        num_blocks,
        current_epoch,
        true, // verified
    );
    
    // Verify all payloads exist
    assert!(block_payload_store.all_payloads_exist(&blocks));
    assert_eq!(get_num_verified_payloads(&block_payload_store), num_blocks);
    
    // Attack: Call remove_blocks_for_epoch_round with future epoch
    let attacker_epoch = current_epoch + 1;  // Future epoch
    let attacker_round = 0;
    block_payload_store.remove_blocks_for_epoch_round(attacker_epoch, attacker_round);
    
    // Result: ALL current epoch blocks are removed
    assert!(!block_payload_store.all_payloads_exist(&blocks));
    assert_eq!(get_num_verified_payloads(&block_payload_store), 0);
    
    // Observer is now unable to execute any blocks for current epoch
    // and must wait for state sync recovery
}
```

This test demonstrates that a single call to `remove_blocks_for_epoch_round()` with a future epoch value removes all current epoch payloads, leaving the observer in a non-functional state.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L467-482)
```rust
        let epoch_state = self.get_epoch_state();
        if commit_epoch == epoch_state.epoch {
            // Verify the commit decision
            if let Err(error) = commit_decision.verify_commit_proof(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify commit decision! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                        commit_decision.proof_block_info(),
                        peer_network_id,
                        error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::COMMIT_DECISION_LABEL);
                return;
            }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L500-527)
```rust
        // Otherwise, we failed to process the commit decision. If the commit
        // is for a future epoch or round, we need to state sync.
        let last_block = self.observer_block_data.lock().get_last_ordered_block();
        let epoch_changed = commit_epoch > last_block.epoch();
        if epoch_changed || commit_round > last_block.round() {
            // If we're waiting for state sync to transition into a new epoch,
            // we should just wait and not issue a new state sync request.
            if self.state_sync_manager.is_syncing_through_epoch() {
                info!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Already waiting for state sync to reach new epoch: {:?}. Dropping commit decision: {:?}!",
                        self.observer_block_data.lock().root().commit_info(),
                        commit_decision.proof_block_info()
                    ))
                );
                return;
            }

            // Otherwise, we should start the state sync process for the commit.
            // Update the block data (to the commit decision).
            self.observer_block_data
                .lock()
                .update_blocks_for_state_sync_commit(&commit_decision);

            // Start state syncing to the commit decision
            self.state_sync_manager
                .sync_to_commit(commit_decision, epoch_changed);
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L579-594)
```rust
        if let Err(error) = self
            .subscription_manager
            .verify_message_for_subscription(peer_network_id)
        {
            // Update the rejected message counter
            increment_rejected_message_counter(&peer_network_id, &message);

            // Log the error and return
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Received message that was not from an active subscription! Error: {:?}",
                    error,
                ))
            );
            return;
        }
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L337-375)
```rust
pub struct CommitDecision {
    commit_proof: LedgerInfoWithSignatures,
}

impl CommitDecision {
    pub fn new(commit_proof: LedgerInfoWithSignatures) -> Self {
        Self { commit_proof }
    }

    /// Returns a reference to the commit proof
    pub fn commit_proof(&self) -> &LedgerInfoWithSignatures {
        &self.commit_proof
    }

    /// Returns the epoch of the commit proof
    pub fn epoch(&self) -> u64 {
        self.commit_proof.ledger_info().epoch()
    }

    /// Returns a reference to the commit proof block info
    pub fn proof_block_info(&self) -> &BlockInfo {
        self.commit_proof.commit_info()
    }

    /// Returns the round of the commit proof
    pub fn round(&self) -> Round {
        self.commit_proof.ledger_info().round()
    }

    /// Verifies the commit proof and returns an error if the proof is invalid
    pub fn verify_commit_proof(&self, epoch_state: &EpochState) -> Result<(), Error> {
        epoch_state.verify(&self.commit_proof).map_err(|error| {
            Error::InvalidMessageError(format!(
                "Failed to verify commit proof ledger info: {:?}, Error: {:?}",
                self.proof_block_info(),
                error
            ))
        })
    }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L284-286)
```rust
        // Update the block payload store
        self.block_payload_store
            .remove_blocks_for_epoch_round(commit_epoch, commit_round);
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L46-57)
```rust
    /// Returns true iff all the payloads for the given blocks
    /// are available and have been verified.
    pub fn all_payloads_exist(&self, blocks: &[Arc<PipelinedBlock>]) -> bool {
        let block_payloads = self.block_payloads.lock();
        blocks.iter().all(|block| {
            let epoch_and_round = (block.epoch(), block.round());
            matches!(
                block_payloads.get(&epoch_and_round),
                Some(BlockPayloadStatus::AvailableAndVerified(_))
            )
        })
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L111-119)
```rust
    /// Removes all blocks up to the specified epoch and round (inclusive)
    pub fn remove_blocks_for_epoch_round(&self, epoch: u64, round: Round) {
        // Determine the round to split off
        let split_off_round = round.saturating_add(1);

        // Remove the blocks from the payload store
        let mut block_payloads = self.block_payloads.lock();
        *block_payloads = block_payloads.split_off(&(epoch, split_off_round));
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L626-631)
```rust
        // Remove all the blocks for the future epoch and round
        let future_epoch = next_epoch + 1;
        block_payload_store.remove_blocks_for_epoch_round(future_epoch, 0);

        // Verify the store is now empty
        check_num_verified_payloads(&block_payload_store, 0);
```

**File:** config/src/config/consensus_observer_config.rs (L1-100)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::config::{
    config_optimizer::ConfigOptimizer, node_config_loader::NodeType, Error, NodeConfig,
};
use aptos_types::chain_id::ChainId;
use serde::{Deserialize, Serialize};
use serde_yaml::Value;

// Useful constants for enabling consensus observer on different node types
const ENABLE_ON_VALIDATORS: bool = true;
const ENABLE_ON_VALIDATOR_FULLNODES: bool = true;
const ENABLE_ON_PUBLIC_FULLNODES: bool = false;

// Maximum number of pending blocks for test networks (e.g., devnet)
const MAX_NUM_PENDING_BLOCKS_FOR_TEST_NETWORKS: u64 = 300;

#[derive(Clone, Copy, Debug, Deserialize, PartialEq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct ConsensusObserverConfig {
    /// Whether the consensus observer is enabled
    pub observer_enabled: bool,
    /// Whether the consensus publisher is enabled
    pub publisher_enabled: bool,

    /// Maximum number of pending network messages
    pub max_network_channel_size: u64,
    /// Maximum number of parallel serialization tasks for message sends
    pub max_parallel_serialization_tasks: usize,
    /// Timeout (in milliseconds) for network RPC requests
    pub network_request_timeout_ms: u64,

    /// Interval (in milliseconds) to garbage collect peer state
    pub garbage_collection_interval_ms: u64,
    /// Maximum number of blocks to keep in memory (e.g., pending blocks, ordered blocks, etc.)
    pub max_num_pending_blocks: u64,
    /// Interval (in milliseconds) to check progress of the consensus observer
    pub progress_check_interval_ms: u64,

    /// The maximum number of concurrent subscriptions
    pub max_concurrent_subscriptions: u64,
    /// Maximum timeout (in milliseconds) we'll wait for the synced version to
    /// increase before terminating the active subscription.
    pub max_subscription_sync_timeout_ms: u64,
    /// Maximum message timeout (in milliseconds) for active subscriptions
    pub max_subscription_timeout_ms: u64,
    /// Interval (in milliseconds) to check for subscription related peer changes
    pub subscription_peer_change_interval_ms: u64,
    /// Interval (in milliseconds) to refresh the subscription
    pub subscription_refresh_interval_ms: u64,

    /// Duration (in milliseconds) to require state sync to synchronize when in fallback mode
    pub observer_fallback_duration_ms: u64,
    /// Duration (in milliseconds) we'll wait on startup before considering fallback mode
    pub observer_fallback_startup_period_ms: u64,
    /// Duration (in milliseconds) we'll wait for syncing progress before entering fallback mode
    pub observer_fallback_progress_threshold_ms: u64,
    /// Duration (in milliseconds) of acceptable sync lag before entering fallback mode
    pub observer_fallback_sync_lag_threshold_ms: u64,
}

impl Default for ConsensusObserverConfig {
    fn default() -> Self {
        Self {
            observer_enabled: false,
            publisher_enabled: false,
            max_network_channel_size: 1000,
            max_parallel_serialization_tasks: num_cpus::get(), // Default to the number of CPUs
            network_request_timeout_ms: 5_000,                 // 5 seconds
            garbage_collection_interval_ms: 60_000,            // 60 seconds
            max_num_pending_blocks: 150, // 150 blocks (sufficient for existing production networks)
            progress_check_interval_ms: 5_000, // 5 seconds
            max_concurrent_subscriptions: 2, // 2 streams should be sufficient
            max_subscription_sync_timeout_ms: 15_000, // 15 seconds
            max_subscription_timeout_ms: 15_000, // 15 seconds
            subscription_peer_change_interval_ms: 180_000, // 3 minutes
            subscription_refresh_interval_ms: 600_000, // 10 minutes
            observer_fallback_duration_ms: 600_000, // 10 minutes
            observer_fallback_startup_period_ms: 60_000, // 60 seconds
            observer_fallback_progress_threshold_ms: 10_000, // 10 seconds
            observer_fallback_sync_lag_threshold_ms: 15_000, // 15 seconds
        }
    }
}

impl ConsensusObserverConfig {
    /// Returns true iff the observer or publisher is enabled
    pub fn is_observer_or_publisher_enabled(&self) -> bool {
        self.observer_enabled || self.publisher_enabled
    }
}

impl ConfigOptimizer for ConsensusObserverConfig {
    fn optimize(
        node_config: &mut NodeConfig,
        local_config_yaml: &Value,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<bool, Error> {
```

**File:** consensus/src/consensus_observer/observer/state_sync_manager.rs (L219-231)
```rust
                if let Err(error) = execution_client
                    .clone()
                    .sync_to_target(commit_decision.commit_proof().clone())
                    .await
                {
                    error!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to sync to commit decision: {:?}! Error: {:?}",
                            commit_decision, error
                        ))
                    );
                    return;
                }
```
