# Audit Report

## Title
Indexer Token Ownership Data Corruption Due to Missing Database Fallback for Table Handle Metadata

## Summary
The `TokenOwnership::from_token()` function in the indexer lacks a database fallback mechanism when `table_handle_to_owner` lookup returns `None`. This causes token ownership records to be inserted with `NULL` owner addresses, corrupting indexer data integrity. The warning logged at lines 115-120 provides insufficient diagnostic context to distinguish legitimate batch boundary scenarios from data corruption.

## Finding Description

The vulnerability exists in the token indexer's batch processing logic. When processing transactions, the indexer:

1. Builds a `table_handle_to_owner` mapping from `WriteResource` changes in the **current batch only** [1](#0-0) 

2. Uses this mapping to resolve table handle ownership when processing `WriteTableItem` changes [2](#0-1) 

3. When lookup fails (returns `None`), it only logs a warning and creates records with `NULL` owner_address [3](#0-2) 

The critical flaw is that **no database query fallback is attempted** to find the owner from previously indexed data. This contrasts with `CollectionData::from_write_table_item()`, which implements proper defensive programming with database fallback and retry logic [4](#0-3) .

The database schema allows `NULL` owner addresses [5](#0-4) , so corrupted records are successfully inserted.

**Why the warning is insufficient:**

The warning logs `transaction_version`, `table_handle`, and the entire `table_handle_to_owner` map for the current batch [6](#0-5) . However, it cannot distinguish between:
- Legitimate tables created in previous batches (batch boundary issue)
- Corrupted or invalid table handles (actual error)
- Indexer state desynchronization

An operator cannot use this warning to detect "malicious table handle injection" because table handles are deterministically generated by the Move VM [7](#0-6)  and cannot be arbitrarily chosen by attackers.

## Impact Explanation

**Medium Severity** - This qualifies as "State inconsistencies requiring intervention" per the bug bounty criteria.

While the indexer is an off-chain component and doesn't affect consensus or on-chain funds, the impact is significant:

1. **Data Integrity Corruption**: Token ownership queries return incomplete/incorrect results, breaking applications that rely on the indexer API
2. **Systematic Failure**: Every token transfer involving TokenStores created in previous batches can produce corrupted records
3. **Silent Failure**: The issue manifests as `NULL` owner addresses in legitimate data, not obvious errors
4. **No Self-Healing**: Once corrupted records are inserted, manual database intervention is required

This breaks the indexer's core invariant: accurate representation of on-chain token ownership state.

## Likelihood Explanation

**High Likelihood** - This occurs naturally during normal operations:

1. **Batch Processing Boundaries**: When a `TokenStore` resource is created in transaction N (batch 1) and a token is transferred to it in transaction N+1 (batch 2), batch 2's `table_handle_to_owner` won't contain the metadata
2. **Indexer Restarts**: If the indexer crashes and resumes from a checkpoint, historical metadata may not be available
3. **Concurrent Token Operations**: High transaction volume increases the probability of cross-batch references

The issue requires no attacker intervention - it's a design flaw that manifests during standard blockchain activity involving the Token V1 standard [8](#0-7) .

## Recommendation

Implement the same database fallback pattern used in `CollectionData`:

```rust
let maybe_table_metadata = table_handle_to_owner.get(&table_handle);
let (curr_token_ownership, owner_address, table_type) = match maybe_table_metadata {
    Some(tm) => {
        // Existing logic (lines 96-113)
    },
    None => {
        // NEW: Query database for historical metadata
        match Self::get_token_store_owner(conn, &table_handle) {
            Ok(owner) => {
                // Create proper ownership records with owner
            },
            Err(_) => {
                aptos_logger::error!(
                    transaction_version = txn_version,
                    table_handle = table_handle,
                    "Failed to resolve TokenStore owner. Database may need backfill."
                );
                return Ok(None); // Don't insert corrupted data
            }
        }
    },
};
```

Add a database query helper:
```rust
pub fn get_token_store_owner(
    conn: &mut PgPoolConnection,
    table_handle: &str,
) -> anyhow::Result<String> {
    let mut retried = 0;
    while retried < QUERY_RETRIES {
        retried += 1;
        match CurrentTokenOwnershipQuery::get_by_table_handle(conn, table_handle) {
            Ok(ownership) => return Ok(ownership.owner_address),
            Err(_) => {
                std::thread::sleep(std::time::Duration::from_millis(QUERY_RETRY_DELAY_MS));
            },
        }
    }
    Err(anyhow::anyhow!("Failed to resolve token store owner"))
}
```

This pattern matches the implementation in [9](#0-8) .

## Proof of Concept

**Setup:**
1. Create a TokenStore resource in transaction at version N
2. Process this transaction in indexer batch 1
3. Transfer a token to that TokenStore in transaction at version N+1000
4. Process this in a separate indexer batch 2 (simulating batch boundaries)

**Expected Behavior:** Token ownership record should have the correct owner address

**Actual Behavior:** Token ownership record has `NULL` owner_address, with only a warning in logs

**Reproduction Steps:**
```rust
// This would require setting up:
// 1. Aptos indexer test harness
// 2. Batch processor with separate batches
// 3. TokenStore resource creation in batch 1
// 4. Token transfer in batch 2
// 5. Verification that owner_address is NULL in database

// The complexity of reproducing this in a PoC is high because it requires
// the full indexer infrastructure, but the bug is evident from code analysis
// comparing TokenOwnership vs CollectionData implementations.
```

## Notes

**Important Clarifications:**

1. **Not a Consensus Issue**: This vulnerability affects only the off-chain indexer, not on-chain state or consensus. The blockchain state remains correct; only the indexer's database representation is corrupted.

2. **No Direct Attack Vector**: Attackers cannot inject arbitrary table handles due to deterministic generation by the Move VM [10](#0-9) . The vulnerability manifests through legitimate operations during batch boundaries.

3. **Comparison with V2**: Token V2 ownership processing has the same limitation [11](#0-10) , though burned NFT handling does implement database fallback [12](#0-11) .

4. **Operational Impact**: Applications relying on the indexer API for token ownership queries receive incomplete data, potentially breaking NFT marketplaces, wallets, and analytics tools.

The warning message provides insufficient diagnostic value because it shows only the current batch's context, making it impossible for operators to distinguish between legitimate cross-batch references and actual errors requiring intervention.

### Citations

**File:** crates/indexer/src/processors/token_processor.rs (L862-863)
```rust
        let table_handle_to_owner =
            TableMetadataForToken::get_table_handle_to_owner_from_transactions(&transactions);
```

**File:** crates/indexer/src/models/token_models/token_ownerships.rs (L88-88)
```rust
        let maybe_table_metadata = table_handle_to_owner.get(&table_handle);
```

**File:** crates/indexer/src/models/token_models/token_ownerships.rs (L114-122)
```rust
            None => {
                aptos_logger::warn!(
                    transaction_version = txn_version,
                    table_handle = table_handle,
                    "Missing table handle metadata for TokenStore. {:?}",
                    table_handle_to_owner
                );
                (None, None, None)
            },
```

**File:** crates/indexer/src/models/token_models/collection_datas.rs (L104-120)
```rust
            let maybe_creator_address = table_handle_to_owner
                .get(&standardize_address(&table_handle))
                .map(|table_metadata| table_metadata.owner_address.clone());
            let mut creator_address = match maybe_creator_address {
                Some(ca) => ca,
                None => match Self::get_collection_creator(conn, &table_handle) {
                    Ok(creator) => creator,
                    Err(_) => {
                        aptos_logger::error!(
                            transaction_version = txn_version,
                            lookup_key = &table_handle,
                            "Failed to get collection creator for table handle. You probably should backfill db."
                        );
                        return Ok(None);
                    },
                },
            };
```

**File:** crates/indexer/src/models/token_models/collection_datas.rs (L168-183)
```rust
    pub fn get_collection_creator(
        conn: &mut PgPoolConnection,
        table_handle: &str,
    ) -> anyhow::Result<String> {
        let mut retried = 0;
        while retried < QUERY_RETRIES {
            retried += 1;
            match CurrentCollectionDataQuery::get_by_table_handle(conn, table_handle) {
                Ok(current_collection_data) => return Ok(current_collection_data.creator_address),
                Err(_) => {
                    std::thread::sleep(std::time::Duration::from_millis(QUERY_RETRY_DELAY_MS));
                },
            }
        }
        Err(anyhow::anyhow!("Failed to get collection creator"))
    }
```

**File:** crates/indexer/migrations/2022-09-04-194128_add_token_data/up.sql (L32-32)
```sql
  owner_address VARCHAR(66),
```

**File:** aptos-move/framework/table-natives/src/lib.rs (L353-384)
```rust
fn native_new_table_handle(
    context: &mut SafeNativeContext,
    ty_args: &[Type],
    args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    assert_eq!(ty_args.len(), 2);
    assert!(args.is_empty());

    context.charge(NEW_TABLE_HANDLE_BASE)?;

    let table_context = context.extensions().get::<NativeTableContext>();
    let mut table_data = table_context.table_data.borrow_mut();

    // Take the transaction hash provided by the environment, combine it with the # of tables
    // produced so far, sha256 this to produce a unique handle. Given the txn hash
    // is unique, this should create a unique and deterministic global id.
    let mut digest = Sha3_256::new();
    let table_len = table_data.new_tables.len() as u32; // cast usize to u32 to ensure same length
    Digest::update(&mut digest, table_context.session_hash);
    Digest::update(&mut digest, table_len.to_be_bytes());
    let bytes = digest.finalize().to_vec();
    let handle = AccountAddress::from_bytes(&bytes[0..AccountAddress::LENGTH])
        .map_err(|_| partial_extension_error("Unable to create table handle"))?;
    let key_type = context.type_to_type_tag(&ty_args[0])?;
    let value_type = context.type_to_type_tag(&ty_args[1])?;
    assert!(table_data
        .new_tables
        .insert(TableHandle(handle), TableInfo::new(key_type, value_type))
        .is_none());

    Ok(smallvec![Value::address(handle)])
}
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L232-240)
```text
    struct TokenStore has key {
        /// the tokens owned by a token owner
        tokens: Table<TokenId, Token>,
        direct_transfer: bool,
        deposit_events: EventHandle<DepositEvent>,
        withdraw_events: EventHandle<WithdrawEvent>,
        burn_events: EventHandle<BurnTokenEvent>,
        mutate_token_property_events: EventHandle<MutateTokenPropertyMapEvent>,
    }
```

**File:** crates/indexer/src/models/token_models/v2_token_ownerships.rs (L287-305)
```rust
            let latest_nft_ownership: NFTOwnershipV2 = match prior_nft_ownership.get(token_address)
            {
                Some(inner) => inner.clone(),
                None => {
                    match CurrentTokenOwnershipV2Query::get_nft_by_token_data_id(
                        conn,
                        token_address,
                    ) {
                        Ok(nft) => nft,
                        Err(_) => {
                            aptos_logger::error!(
                                transaction_version = txn_version,
                                lookup_key = &token_address,
                                "Failed to find NFT for burned token. You probably should backfill db."
                            );
                            return Ok(None);
                        },
                    }
                },
```

**File:** crates/indexer/src/models/token_models/v2_token_ownerships.rs (L480-488)
```rust
                None => {
                    aptos_logger::warn!(
                        transaction_version = txn_version,
                        table_handle = table_handle,
                        "Missing table handle metadata for TokenStore. {:?}",
                        table_handle_to_owner
                    );
                    (None, None, None)
                },
```
