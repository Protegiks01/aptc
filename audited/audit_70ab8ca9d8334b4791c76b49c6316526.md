# Audit Report

## Title
Consensus Observer: Untrusted Timestamp in BlockPayload Enables Expired Batch Inclusion Attack

## Summary
The `BlockPayload::verify_payload_digests()` function uses an unvalidated `block_info.timestamp_usecs()` field from network messages to determine batch expiration, allowing attackers to include expired batches or exclude valid batches by manipulating the timestamp. This breaks deterministic execution guarantees and can cause consensus divergence.

## Finding Description

The consensus observer system verifies block payload digests using a timestamp that comes directly from an untrusted network message, before that timestamp is validated against the actual ordered block. [1](#0-0) 

The `verify_payload_digests()` function extracts the `block_info` directly from the received `BlockPayload` message and uses its timestamp to determine which batches are expired: [2](#0-1) 

The expiration check at this point uses the untrusted timestamp to decide whether to include or skip batches. If a batch appears expired (timestamp > expiration), it is skipped and its transactions are not consumed from the iterator.

The critical vulnerability path:

1. **Attacker sends malicious BlockPayload**: An attacker crafts a `BlockPayload` message with `block_info.timestamp_usecs = 0` (or any value less than expired batches' expiration times), along with transactions for ALL batches including expired ones.

2. **Digest verification passes**: With timestamp=0, all batches appear valid (not expired). The function reconstructs batches for ALL proofs, including expired ones, and verifies their digests successfully. [3](#0-2) 

3. **Payload stored as verified**: The malicious payload is stored in the payload store indexed by (epoch, round): [4](#0-3) 

4. **Race condition exploitation**: The observer accepts the first BlockPayload for each (epoch, round) and ignores subsequent ones: [5](#0-4) 

5. **Verification against OrderedBlock passes**: When the legitimate `OrderedBlock` arrives, it verifies that batch structure matches. The honest publisher includes ALL proof references (including expired batches) in the block payload structure: [6](#0-5) 

However, the honest publisher only includes transactions for non-expired batches (filtering happens here): [7](#0-6) 

The verification only checks that the batch proof structure matches, not the actual transactions: [8](#0-7) 

6. **Malicious transactions executed**: When the execution pipeline requests transactions, it retrieves them from the stored (malicious) payload, which includes transactions from expired batches: [9](#0-8) 

## Impact Explanation

This vulnerability breaks the **Deterministic Execution** invariant (Critical Invariant #1). Different consensus observers may execute different sets of transactions for the same block depending on which BlockPayload message they receive first:

- Observers receiving the attacker's payload first will execute transactions from expired batches
- Observers receiving the honest publisher's payload will correctly exclude expired batches
- This leads to different state roots being computed for identical blocks

This represents a **Critical Severity** issue under the Aptos bug bounty program because it enables:
- **Consensus Safety Violation**: Different nodes commit different state roots, breaking BFT consensus guarantees
- **State Divergence**: Network participants will have inconsistent views of the ledger
- **Potential Double-Spending**: Expired transactions that were already included in other blocks could be re-executed

## Likelihood Explanation

This vulnerability has **HIGH** likelihood of exploitation:

**Attacker Requirements**:
- Ability to send network messages to consensus observers (any peer can attempt this)
- Access to expired batch data from the quorum store (publicly available)
- Ability to win the race against honest publishers (requires low latency, but achievable)

**Attack Complexity**: LOW
- Simple message manipulation (change timestamp field)
- No cryptographic bypass required (signatures on proofs remain valid)
- No validator collusion needed

The attack is particularly feasible because:
1. BlockPayload messages are accepted from the first sender
2. Observers process messages as they arrive without timestamp validation
3. Batch data remains available in the network even after expiration

## Recommendation

Validate the block timestamp before using it for security-critical decisions. The fix should verify that the `BlockInfo` in the `BlockPayload` matches the actual block's timestamp when the `OrderedBlock` arrives:

**Recommended Fix**:

1. Store the `BlockInfo` from the `BlockPayload` alongside the transaction payload
2. In `verify_payloads_against_ordered_block()`, add a check that compares the stored `BlockInfo.timestamp_usecs()` with the actual block's timestamp
3. Reject payloads where timestamps don't match

```rust
// In verify_payloads_against_ordered_block()
pub fn verify_payloads_against_ordered_block(
    &mut self,
    ordered_block: &OrderedBlock,
) -> Result<(), Error> {
    for ordered_block in ordered_block.blocks() {
        let block_epoch = ordered_block.epoch();
        let block_round = ordered_block.round();
        
        match self.block_payloads.lock().entry((block_epoch, block_round)) {
            Entry::Occupied(entry) => {
                let block_payload = match entry.get() {
                    BlockPayloadStatus::AvailableAndVerified(bp) => bp,
                    BlockPayloadStatus::AvailableAndUnverified(_) => {
                        return Err(Error::InvalidMessageError(format!(
                            "Payload for epoch: {:?} and round: {:?} is unverified.",
                            block_epoch, block_round
                        )));
                    },
                };
                
                // NEW: Verify timestamp matches
                if block_payload.block().timestamp_usecs() != ordered_block.timestamp_usecs() {
                    return Err(Error::InvalidMessageError(format!(
                        "Payload timestamp mismatch! Expected: {:?}, Found: {:?}",
                        ordered_block.timestamp_usecs(),
                        block_payload.block().timestamp_usecs()
                    )));
                }
                
                // Existing verification logic...
                let transaction_payload = block_payload.transaction_payload();
                let ordered_block_payload = match ordered_block.block().payload() {
                    Some(payload) => payload,
                    None => {
                        return Err(Error::InvalidMessageError(format!(
                            "Missing block payload for epoch: {:?} and round: {:?}",
                            block_epoch, block_round
                        )));
                    },
                };
                
                transaction_payload.verify_against_ordered_payload(ordered_block_payload)?;
            },
            // ... rest of the function
        }
    }
    Ok(())
}
```

## Proof of Concept

**Attack Scenario**:

1. Wait for consensus to create a new block at timestamp `T = 1000000` containing batches [A, B, C, D]
2. Batch D has `expiration = 999000` (expired)
3. Before the honest publisher sends their BlockPayload:
   - Craft malicious BlockPayload with:
     - `block_info.timestamp_usecs = 0`
     - `epoch` and `round` matching the target block
     - `proofs` for [A, B, C, D]
     - `transactions` including all transactions from [A, B, C, D] (fetch D's transactions from quorum store)
4. Send malicious BlockPayload to target observer
5. Observer accepts it (first arrival), verifies digests (all pass with timestamp=0), stores as verified
6. Honest OrderedBlock arrives, verification passes (batch structure matches)
7. Observer executes transactions including expired batch D

**Result**: The observer executes transactions that should have been excluded, causing state divergence from nodes that received the honest payload.

## Notes

The root cause is the violation of the security principle: "validate before use". The code uses `block_info.timestamp_usecs()` for a security-critical decision (batch expiration) before validating that this timestamp matches the actual block's timestamp from the signed OrderedBlock.

The vulnerability is exacerbated by the race condition in payload acceptance, where the first BlockPayload received is trusted and subsequent ones are ignored, giving attackers an opportunity to inject malicious payloads before honest publishers.

### Citations

**File:** consensus/src/consensus_observer/network/observer_message.rs (L720-736)
```rust
    fn verify_batches(&self, expected_proofs: &[ProofOfStore<BatchInfo>]) -> Result<(), Error> {
        // Get the batches in the block transaction payload
        let payload_proofs = self.payload_proofs();
        let payload_batches: Vec<&BatchInfo> =
            payload_proofs.iter().map(|proof| proof.info()).collect();

        // Compare the expected batches against the payload batches
        let expected_batches: Vec<&BatchInfo> =
            expected_proofs.iter().map(|proof| proof.info()).collect();
        if expected_batches != payload_batches {
            return Err(Error::InvalidMessageError(format!(
                "Transaction payload failed batch verification! Expected batches {:?}, but found {:?}!",
                expected_batches, payload_batches
            )));
        }

        Ok(())
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L874-877)
```rust
    /// Verifies the block payload digests and returns an error if the data is invalid
    pub fn verify_payload_digests(&self) -> Result<(), Error> {
        // Get the block info, transactions, payload proofs and inline batches
        let block_info = self.block.clone();
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L987-998)
```rust
fn reconstruct_batch(
    block_info: &BlockInfo,
    transactions_iter: &mut IntoIter<SignedTransaction>,
    expected_batch_info: &BatchInfo,
    skip_expired_batches: bool,
) -> Result<Option<Vec<SignedTransaction>>, Error> {
    // If the batch is expired we should skip reconstruction (as the
    // transactions for the expired batch won't be sent in the payload).
    // Note: this should only be required for QS batches (not inline batches).
    if skip_expired_batches && block_info.timestamp_usecs() > expected_batch_info.expiration() {
        return Ok(None);
    }
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L1019-1038)
```rust
fn verify_batch(
    expected_batch_info: &BatchInfo,
    batch_transactions: Vec<SignedTransaction>,
) -> Result<(), Error> {
    // Calculate the batch digest
    let batch_payload = BatchPayload::new(expected_batch_info.author(), batch_transactions);
    let batch_digest = batch_payload.hash();

    // Verify the reconstructed digest against the expected digest
    let expected_digest = expected_batch_info.digest();
    if batch_digest != *expected_digest {
        return Err(Error::InvalidMessageError(format!(
            "The reconstructed batch digest does not match the expected digest! \
             Batch: {:?}, Expected digest: {:?}, Reconstructed digest: {:?}",
            expected_batch_info, expected_digest, batch_digest
        )));
    }

    Ok(())
}
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L366-380)
```rust
        // Determine if the payload is behind the last ordered block, or if it already exists
        let last_ordered_block = self.observer_block_data.lock().get_last_ordered_block();
        let payload_out_of_date =
            (block_epoch, block_round) <= (last_ordered_block.epoch(), last_ordered_block.round());
        let payload_exists = self
            .observer_block_data
            .lock()
            .existing_payload_entry(&block_payload);

        // If the payload is out of date or already exists, ignore it
        if payload_out_of_date || payload_exists {
            // Update the metrics for the dropped block payload
            update_metrics_for_dropped_block_payload_message(peer_network_id, &block_payload);
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L385-397)
```rust
        // Verify the block payload digests
        if let Err(error) = block_payload.verify_payload_digests() {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify block payload digests! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                    block_payload.block(), peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
            return;
        }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L102-106)
```rust
            if block_timestamp <= batch_info.expiration() {
                futures.push(batch_reader.get_batch(batch_info, responders.clone()));
            } else {
                debug!("QSE: skipped expired batch {}", batch_info.digest());
            }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L456-467)
```rust
            Payload::InQuorumStore(proof_with_data) => {
                let transactions = process_qs_payload(
                    proof_with_data,
                    self.batch_reader.clone(),
                    block,
                    &self.ordered_authors,
                )
                .await?;
                BlockTransactionPayload::new_in_quorum_store(
                    transactions,
                    proof_with_data.proofs.clone(),
                )
```

**File:** consensus/src/payload_manager/co_payload_manager.rs (L36-58)
```rust
    let block_payload = match block_payloads.lock().entry((block.epoch(), block.round())) {
        Entry::Occupied(mut value) => match value.get_mut() {
            BlockPayloadStatus::AvailableAndVerified(block_payload) => block_payload.clone(),
            BlockPayloadStatus::AvailableAndUnverified(_) => {
                // This shouldn't happen (the payload should already be verified)
                let error = format!(
                    "Payload data for block epoch {}, round {} is unverified!",
                    block.epoch(),
                    block.round()
                );
                return Err(InternalError { error });
            },
        },
        Entry::Vacant(_) => {
            // This shouldn't happen (the payload should already be present)
            let error = format!(
                "Missing payload data for block epoch {}, round {}!",
                block.epoch(),
                block.round()
            );
            return Err(InternalError { error });
        },
    };
```
