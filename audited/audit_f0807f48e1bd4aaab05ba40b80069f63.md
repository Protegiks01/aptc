# Audit Report

## Title
Invariant Violation: Self-Loop Prevention Relies on Debug-Only Assertions in Move Borrow Graph

## Summary
The `remap_refs` function in the move-borrow-graph can introduce self-loops in release builds because critical invariant checks use `debug_assert!` instead of `assert!`. This violates the no-self-loops invariant and causes the `unmatched_edges` function to panic when it encounters such self-loops, as its assertion at line 350 assumes self-loops cannot exist. [1](#0-0) 

## Finding Description

The borrow graph maintains a critical invariant: no reference can borrow from itself (no self-loops). This invariant is enforced through multiple mechanisms:

1. **Direct prevention during edge addition**: [2](#0-1) 

2. **Prevention during graph operations**: [3](#0-2) 

3. **Invariant checking**: [4](#0-3) 

However, the `remap_refs` function only validates these invariants using `debug_assert!`: [5](#0-4) 

In release builds, these debug assertions are compiled out, meaning self-loops can be introduced silently. The remapping process can create self-loops when:
- A reference X with ID `i` exists in the graph but is not being remapped (not in `id_map`)
- X has an outgoing edge to reference Y
- The `id_map` maps Y's ID to `i` (X's own ID)
- After remapping, X will have an edge pointing to itself

The edge remapping occurs in `BorrowEdges::remap_refs`: [6](#0-5) 

Additionally, the debug assertion checking that node count remains unchanged would fail if two nodes map to the same ID, but this is also only checked in debug mode: [7](#0-6) 

When `unmatched_edges` is subsequently called (either directly or through `leq` or `join`), it encounters the self-loop and hits an assertion that expects no self-loops to exist: [8](#0-7) 

The `join` method is used during bytecode verification for control flow joins: [9](#0-8) 

And is invoked through the abstract interpretation framework: [10](#0-9) 

## Impact Explanation

This issue constitutes a **High Severity** vulnerability under the Aptos bug bounty program criteria for "Validator node slowdowns" and "API crashes."

If exploitable, an attacker could craft Move bytecode that, when verified, triggers this condition in release-built validator nodes, causing them to panic during bytecode verification. This would:

1. **Prevent module publication**: Malicious modules would crash the verification process
2. **Cause validator node crashes**: Validators running in release mode would panic
3. **Break deterministic execution**: Different build configurations (debug vs release) would behave differently, violating the requirement that all validators produce identical results

The severity is limited to High rather than Critical because:
- It requires crafting specific bytecode patterns
- The exact exploitation path through `construct_canonical_state` is complex
- It causes availability issues rather than fund theft or consensus safety violations

## Likelihood Explanation

The likelihood is **MEDIUM** because:

**Facilitating Factors:**
- The bytecode verifier runs on every module/script submission
- Reference IDs are assigned systematically during verification: [11](#0-10) 
- Parameter references receive IDs in the reserved range [0, num_locals), making ID collisions possible during canonicalization

**Mitigating Factors:**
- Requires understanding the internal reference ID allocation scheme
- The specific conditions for self-loop creation through `construct_canonical_state` are complex
- The issue only manifests in release builds, which may be detected during testing
- Defensive programming elsewhere (like `splice_out_intermediate`) prevents most self-loop scenarios

## Recommendation

Replace all `debug_assert!` calls related to graph invariants with regular `assert!` calls to ensure they execute in release builds:

**In `graph.rs`:**
```rust
pub fn remap_refs(&mut self, id_map: &BTreeMap<RefID, RefID>) {
    assert!(self.check_invariant()); // Change from debug_assert!
    let _before = self.0.len();
    self.0 = std::mem::take(&mut self.0)
        .into_iter()
        .map(|(id, mut info)| {
            info.remap_refs(id_map);
            (id_map.get(&id).copied().unwrap_or(id), info)
        })
        .collect();
    let _after = self.0.len();
    assert!(_before == _after); // Change from debug_assert!
    assert!(self.check_invariant()); // Change from debug_assert!
}
```

**In `references.rs` and `shared.rs`:**
Change all `debug_assert!` calls to `assert!` for size consistency checks.

**Additionally**, add explicit validation in `construct_canonical_state` to ensure the constructed `id_map` does not create any ID collisions or self-loops before calling `remap_refs`.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use std::collections::BTreeMap;
    
    #[test]
    #[should_panic(expected = "assertion failed: parent_id != child_id")]
    fn test_remap_introduces_self_loop() {
        // Create a borrow graph with two nodes
        let mut graph = BorrowGraph::<(), u32>::new();
        graph.new_ref(RefID::new(0), true);
        graph.new_ref(RefID::new(5), true);
        
        // Add edge from node 0 to node 5
        graph.add_strong_borrow((), RefID::new(0), RefID::new(5));
        
        // Create id_map that maps 5 -> 0 (but doesn't map 0)
        let mut id_map = BTreeMap::new();
        id_map.insert(RefID::new(5), RefID::new(0));
        
        // In release builds, this succeeds but creates self-loop
        // In debug builds, this would panic at the debug_assert
        graph.remap_refs(&id_map);
        
        // Now try to use unmatched_edges - this WILL panic even in release
        let other = graph.clone();
        let _ = graph.unmatched_edges(&other);
    }
}
```

**Notes:**
- This vulnerability exists due to inconsistent use of assertion types for critical invariants
- The move-borrow-graph is used during Move bytecode verification, making it part of the validator's critical path
- Debug-only assertions create a discrepancy between debug and release builds, violating the deterministic execution requirement
- The specific trigger through bytecode is complex but theoretically possible given how reference IDs are allocated during verification

### Citations

**File:** third_party/move/move-borrow-graph/src/graph.rs (L188-189)
```rust
    fn add_edge(&mut self, parent_id: RefID, edge: BorrowEdge<Loc, Lbl>, child_id: RefID) {
        assert!(parent_id != child_id);
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L309-312)
```rust
        // dont add in an edge if releasing from a cycle
        if parent_id == child_id {
            return;
        }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L334-363)
```rust
    fn unmatched_edges(&self, other: &Self) -> BTreeMap<RefID, BorrowEdges<Loc, Lbl>> {
        let mut unmatched_edges = BTreeMap::new();
        for (parent_id, other_ref) in &other.0 {
            let self_ref = &self.0[parent_id];
            let self_borrowed_by = &self_ref.borrowed_by.0;
            for (child_id, other_edges) in &other_ref.borrowed_by.0 {
                for other_edge in other_edges {
                    let found_match = self_borrowed_by
                        .get(child_id)
                        .map(|parent_to_child| {
                            parent_to_child
                                .iter()
                                .any(|self_edge| self_edge.leq(other_edge))
                        })
                        .unwrap_or(false);
                    if !found_match {
                        assert!(parent_id != child_id);
                        unmatched_edges
                            .entry(*parent_id)
                            .or_insert_with(BorrowEdges::new)
                            .0
                            .entry(*child_id)
                            .or_insert_with(BorrowEdgeSet::new)
                            .insert(other_edge.clone());
                    }
                }
            }
        }
        unmatched_edges
    }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L371-384)
```rust
    pub fn remap_refs(&mut self, id_map: &BTreeMap<RefID, RefID>) {
        debug_assert!(self.check_invariant());
        let _before = self.0.len();
        self.0 = std::mem::take(&mut self.0)
            .into_iter()
            .map(|(id, mut info)| {
                info.remap_refs(id_map);
                (id_map.get(&id).copied().unwrap_or(id), info)
            })
            .collect();
        let _after = self.0.len();
        debug_assert!(_before == _after);
        debug_assert!(self.check_invariant());
    }
```

**File:** third_party/move/move-borrow-graph/src/graph.rs (L456-461)
```rust
    fn no_self_loops(&self) -> bool {
        self.0.iter().all(|(id, r)| {
            r.borrowed_by.0.keys().all(|to_id| id != to_id)
                && r.borrows_from.iter().all(|from_id| id != from_id)
        })
    }
```

**File:** third_party/move/move-borrow-graph/src/references.rs (L164-172)
```rust
    pub(crate) fn remap_refs(&mut self, id_map: &BTreeMap<RefID, RefID>) {
        let _before = self.0.len();
        self.0 = std::mem::take(&mut self.0)
            .into_iter()
            .map(|(id, edges)| (id_map.get(&id).copied().unwrap_or(id), edges))
            .collect();
        let _after = self.0.len();
        debug_assert!(_before == _after)
    }
```

**File:** third_party/move/move-borrow-graph/src/shared.rs (L6-14)
```rust
pub fn remap_set<T: Copy + Ord>(set: &mut BTreeSet<T>, id_map: &BTreeMap<T, T>) {
    let _before = set.len();
    *set = std::mem::take(set)
        .into_iter()
        .map(|x| id_map.get(&x).copied().unwrap_or(x))
        .collect();
    let _after = set.len();
    debug_assert!(_before == _after);
}
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/abstract_state.rs (L98-125)
```rust
impl AbstractState {
    /// create a new abstract state
    pub fn new(function_view: &FunctionView) -> Self {
        let num_locals = function_view.parameters().len() + function_view.locals().len();
        // ids in [0, num_locals) are reserved for constructing canonical state
        // id at num_locals is reserved for the frame root
        let next_id = num_locals + 1;
        let mut state = AbstractState {
            current_function: function_view.index(),
            locals: vec![AbstractValue::NonReference; num_locals],
            borrow_graph: BorrowGraph::new(),
            next_id,
        };

        for (param_idx, param_ty) in function_view.parameters().0.iter().enumerate() {
            if param_ty.is_reference() {
                let id = RefID::new(param_idx);
                state
                    .borrow_graph
                    .new_ref(id, param_ty.is_mutable_reference());
                state.locals[param_idx] = AbstractValue::Reference(id)
            }
        }
        state.borrow_graph.new_ref(state.frame_root(), true);

        assert!(state.is_canonical());
        state
    }
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/abstract_state.rs (L663-703)
```rust
    pub fn join_(&self, other: &Self) -> Self {
        assert!(self.current_function == other.current_function);
        assert!(self.is_canonical() && other.is_canonical());
        assert!(self.next_id == other.next_id);
        assert!(self.locals.len() == other.locals.len());
        let mut self_graph = self.borrow_graph.clone();
        let mut other_graph = other.borrow_graph.clone();
        let locals = self
            .locals
            .iter()
            .zip(&other.locals)
            .map(|(self_value, other_value)| {
                match (self_value, other_value) {
                    (AbstractValue::Reference(id), AbstractValue::NonReference) => {
                        self_graph.release(*id);
                        AbstractValue::NonReference
                    },
                    (AbstractValue::NonReference, AbstractValue::Reference(id)) => {
                        other_graph.release(*id);
                        AbstractValue::NonReference
                    },
                    // The local has a value on each side, add it to the state
                    (v1, v2) => {
                        assert!(v1 == v2);
                        *v1
                    },
                }
            })
            .collect();

        let borrow_graph = self_graph.join(&other_graph);
        let current_function = self.current_function;
        let next_id = self.next_id;

        Self {
            current_function,
            locals,
            borrow_graph,
            next_id,
        }
    }
```

**File:** third_party/move/move-bytecode-verifier/src/reference_safety/abstract_state.rs (L706-735)
```rust
impl AbstractDomain for AbstractState {
    /// attempts to join state to self and returns the result
    fn join(
        &mut self,
        state: &AbstractState,
        meter: &mut impl Meter,
    ) -> PartialVMResult<JoinResult> {
        let joined = Self::join_(self, state);
        assert!(joined.is_canonical());
        assert!(self.locals.len() == joined.locals.len());
        meter.add(Scope::Function, JOIN_BASE_COST)?;
        meter.add_items(Scope::Function, JOIN_PER_LOCAL_COST, self.locals.len())?;
        meter.add_items(
            Scope::Function,
            JOIN_PER_GRAPH_ITEM_COST,
            self.borrow_graph.graph_size(),
        )?;
        let locals_unchanged = self
            .locals
            .iter()
            .zip(&joined.locals)
            .all(|(self_value, joined_value)| self_value == joined_value);
        // locals unchanged and borrow graph covered, return unchanged
        // else mark as changed and update the state
        if locals_unchanged && self.borrow_graph.leq(&joined.borrow_graph) {
            Ok(JoinResult::Unchanged)
        } else {
            *self = joined;
            Ok(JoinResult::Changed)
        }
```
