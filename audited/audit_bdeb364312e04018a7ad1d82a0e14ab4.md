# Audit Report

## Title
Database Handle Race Condition Causing Node Panic via Concurrent Write Attempts

## Summary
Multiple services (Consensus, Consensus Observer, and State Sync) share cloned database handles pointing to the same `AptosDB` instance. The database uses `try_lock().expect()` for write coordination, which panics on concurrent access. Application-level coordination between services is insufficient, relying on boolean flag checks rather than proper mutual exclusion, creating a TOCTOU (Time-of-Check-Time-of-Use) race condition that causes node crashes.

## Finding Description

In `setup_environment_and_start_node()`, the database handle `db_rw` is shared across multiple services via `Arc::clone()`: [1](#0-0) 

This handle is then distributed to multiple services that can perform write operations: [2](#0-1) [3](#0-2) [4](#0-3) 

The `DbReaderWriter` structure shares the same underlying database instance: [5](#0-4) 

At the database level, `AptosDB` uses mutexes that **panic** on concurrent access attempts: [6](#0-5) [7](#0-6) 

The coordination mechanism relies on application-level flag checks in state sync: [8](#0-7) [9](#0-8) 

**The Vulnerability**: Two independent write paths exist:

1. **Consensus Observer Path**: Creates its own `BlockExecutor` with shared database handle: [10](#0-9) 

2. **State Sync Path**: Uses `ChunkExecutor` that can independently commit: [11](#0-10) 

The race condition occurs when:
1. State sync checks `check_if_consensus_or_observer_executing()` (returns false - no active sync request)
2. Consensus observer simultaneously initiates fallback sync or receives commit decision
3. State sync proceeds to commit via continuous syncer
4. Consensus observer also commits via execution client
5. Both reach `pre_commit_ledger` or `commit_ledger` simultaneously
6. The second caller hits `try_lock().expect()` and **panics** with "Concurrent committing detected"
7. **Node crashes**

This breaks the **State Consistency** invariant (atomic state transitions) and **Node Availability** invariant.

## Impact Explanation

This vulnerability causes **node crashes (Denial of Service)**, qualifying as **High Severity** per Aptos bug bounty criteria:
- Validator node crashes affect network availability
- Fullnode crashes impact API availability and network resilience
- No state corruption occurs (defensive panic prevents it), but availability is compromised

If exploitable conditions affect multiple nodes simultaneously (e.g., network-wide partition), this could escalate to **Critical Severity** due to widespread availability impact.

## Likelihood Explanation

**Likelihood: Medium**

The race condition can occur during:
1. **Network partitions**: Consensus observer lags, triggering fallback mode while state sync independently attempts to catch up
2. **Epoch transitions**: Coordination handover between services during epoch boundaries
3. **Node recovery**: After restart, both services attempting to synchronize simultaneously
4. **High load conditions**: Processing delays causing both services to be active

The timing window is narrow but realistic during adverse network conditions or heavy load. While not trivially exploitable by direct attacker action, the conditions naturally occur in production environments under stress.

## Recommendation

Replace the flag-based coordination with proper mutual exclusion using a shared mutex that all write paths must acquire:

**Proposed Fix**:

1. Add a shared write coordinator in the node setup:
```rust
pub struct DatabaseWriteCoordinator {
    write_lock: tokio::sync::Mutex<()>,
}

impl DatabaseWriteCoordinator {
    pub fn new() -> Arc<Self> {
        Arc::new(Self {
            write_lock: tokio::sync::Mutex::new(()),
        })
    }
    
    pub async fn acquire_write_lock(&self) -> tokio::sync::MutexGuard<'_, ()> {
        self.write_lock.lock().await
    }
}
```

2. Pass the coordinator to all services that can write (consensus, consensus observer, state sync)

3. Modify write paths to acquire the lock before calling database operations:
```rust
let _guard = write_coordinator.acquire_write_lock().await;
self.db.writer.pre_commit_ledger(chunk, sync_commit)?;
```

4. Replace the `try_lock().expect()` pattern in `AptosDB` with proper error handling:
```rust
let _lock = self.pre_commit_lock.lock()
    .map_err(|_| AptosDbError::Other("Lock poisoned".to_string()))?;
```

This ensures proper serialization of write operations across all services while allowing graceful error handling instead of panics.

## Proof of Concept

```rust
// Reproduction scenario (integration test):
// 1. Start a fullnode with consensus observer enabled
// 2. Create network partition simulation
// 3. Trigger consensus observer fallback mode
// 4. Simultaneously trigger state sync continuous syncer
// 5. Both will attempt concurrent writes
// Expected: Node panic with "Concurrent committing detected"

#[tokio::test]
async fn test_concurrent_write_race() {
    // Setup node with consensus observer
    let node_config = NodeConfig::default_for_fullnode();
    node_config.consensus_observer.observer_enabled = true;
    
    // Initialize shared database handle
    let (db_rw, _, _, _, _) = initialize_database_and_checkpoints(&mut node_config).unwrap();
    
    // Simulate consensus observer write path
    let db_clone_1 = db_rw.clone();
    let handle_1 = tokio::spawn(async move {
        // Consensus observer attempting to commit
        let executor = BlockExecutor::new(db_clone_1);
        executor.pre_commit_ledger(chunk_1, false).await
    });
    
    // Simulate state sync write path
    let db_clone_2 = db_rw.clone();
    let handle_2 = tokio::spawn(async move {
        // State sync continuous syncer attempting to commit
        let chunk_executor = ChunkExecutor::new(db_clone_2);
        chunk_executor.commit_chunk(chunk_2).await
    });
    
    // Race condition: both try to write simultaneously
    let results = tokio::join!(handle_1, handle_2);
    
    // Expected: One of them panics with "Concurrent committing detected"
    // Actual: Node crashes
}
```

## Notes

The vulnerability exists because the coordination protocol between services is enforced only through application-level checks, not proper mutual exclusion primitives. The comment in the code acknowledges this design: [12](#0-11) 

The phrase "Consensus and state sync **must** hand over" indicates an expectation, not an enforcement mechanism. The `try_lock().expect()` pattern serves as a bug detector rather than a safety mechanism, preferring to crash rather than risk state corruption. While this defensive approach prevents database corruption, it creates an availability vulnerability when the coordination protocol fails during edge cases like network partitions or epoch transitions.

### Citations

**File:** aptos-node/src/lib.rs (L704-705)
```rust
    let (db_rw, backup_service, genesis_waypoint, indexer_db_opt, update_receiver) =
        storage::initialize_database_and_checkpoints(&mut node_config)?;
```

**File:** aptos-node/src/lib.rs (L768-768)
```rust
            db_rw.clone(),
```

**File:** aptos-node/src/lib.rs (L836-836)
```rust
            db_rw.clone(),
```

**File:** aptos-node/src/lib.rs (L843-843)
```rust
        db_rw.clone(),
```

**File:** storage/storage-interface/src/lib.rs (L657-661)
```rust
#[derive(Clone)]
pub struct DbReaderWriter {
    pub reader: Arc<dyn DbReader>,
    pub writer: Arc<dyn DbWriter>,
}
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L44-53)
```rust
    fn pre_commit_ledger(&self, chunk: ChunkToCommit, sync_commit: bool) -> Result<()> {
        gauged_api("pre_commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .pre_commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-92)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
```

**File:** state-sync/state-sync-driver/src/driver.rs (L626-630)
```rust
    fn check_if_consensus_or_observer_executing(&self) -> bool {
        self.is_consensus_or_observer_enabled()
            && self.bootstrapper.is_bootstrapped()
            && !self.active_sync_request()
    }
```

**File:** state-sync/state-sync-driver/src/driver.rs (L687-690)
```rust
        // If consensus or consensus observer is executing, there's nothing to do
        if self.check_if_consensus_or_observer_executing() {
            return;
        }
```

**File:** consensus/src/consensus_provider.rs (L158-165)
```rust
        let execution_proxy = ExecutionProxy::new(
            Arc::new(BlockExecutor::<AptosVMBlockExecutor>::new(aptos_db.clone())),
            txn_notifier,
            state_sync_notifier,
            node_config.transaction_filters.execution_filter.clone(),
            node_config.consensus.enable_pre_commit,
            None,
        );
```

**File:** execution/executor/src/chunk_executor/mod.rs (L277-281)
```rust
            self.db.writer.save_transactions(
                output.as_chunk_to_commit(),
                chunk.ledger_info_opt.as_ref(),
                false, // sync_commit
            )?;
```
