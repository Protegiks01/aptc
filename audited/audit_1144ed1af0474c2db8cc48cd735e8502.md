# Audit Report

## Title
Missing Event Cryptographic Verification in Indexer Serving Path Leading to Potential False Mint Records

## Summary
Events served to indexers via the API and gRPC streaming endpoints are not cryptographically verified against their committed `event_root_hash` in `TransactionInfo`, despite the infrastructure existing to do so. While events are cryptographically authenticated during consensus via the event_root_hash → TransactionInfo → LedgerInfo chain, this authentication is not validated when retrieving events from storage to serve to external indexers, creating a trust gap where corrupted or tampered storage could produce false mint records.

## Finding Description

The Aptos blockchain correctly implements cryptographic authentication for events through a Merkle accumulator chain:

1. During execution, events are hashed and an `event_root_hash` is computed [1](#0-0) 

2. This `event_root_hash` is stored in `TransactionInfo` alongside other transaction metadata [2](#0-1) 

3. `TransactionInfo` is hashed and included in the transaction accumulator, whose root is signed by validators [3](#0-2) 

The codebase includes a verification function to validate events against their root hash: [4](#0-3) 

**However, this verification is NOT performed when serving events to indexers:**

When the indexer coordinator fetches transactions via `Context::get_transactions()`: [5](#0-4) 

It calls `consume_output_list_with_proof()` which simply unwraps the data without verification: [6](#0-5) 

The underlying `get_transaction_outputs()` reads events directly from the event database without checking they match the `event_root_hash`: [7](#0-6) 

**In contrast, state sync properly verifies events:** [8](#0-7) [9](#0-8) 

This creates an architectural inconsistency where state sync between nodes verifies event integrity cryptographically, but the indexer serving path trusts storage implicitly.

## Impact Explanation

This qualifies as **Medium Severity** under the bug bounty program ("State inconsistencies requiring intervention") because:

1. **Data Integrity Impact**: If a fullnode's storage (specifically the `event_db` in RocksDB) is corrupted or tampered with, false Mint events could be served to indexers without detection, leading to incorrect token supply records, fake NFT creation events, and manipulated market data in explorers and wallets.

2. **Trust Architecture Weakness**: External indexers and data consumers implicitly trust fullnode event data without the ability to cryptographically verify it against the blockchain's authenticated state, even though the necessary commitments exist in `TransactionInfo`.

3. **Attack Scenarios**:
   - Compromised fullnode operator modifies event storage
   - Database corruption during backup/restore operations
   - Cloud infrastructure compromise allowing filesystem access
   - Malicious data migration scripts

4. **Not Critical/High** because:
   - Requires privileged access (filesystem/database access) rather than remote exploitation
   - Does not affect consensus or validator operations
   - Does not enable direct fund theft or network partition

## Likelihood Explanation

**Moderate to Low Likelihood** due to:

**Required Conditions:**
- Attacker must gain filesystem or database access to a fullnode serving indexer data
- Requires knowledge of RocksDB format and schema structure
- Must target specific event records without breaking database consistency checks

**Mitigating Factors:**
- Most production deployments use access controls on storage
- Database tampering may trigger other integrity checks
- State sync between honest nodes would detect inconsistencies

**Realistic Scenarios:**
- Insider threat from compromised node operators
- Cloud instance compromise in shared hosting environments
- Backup/snapshot manipulation attacks
- Supply chain attacks on node infrastructure

## Recommendation

Add cryptographic verification to the indexer serving path by calling `verify()` before consuming the proof:

```rust
// In api/src/context.rs::get_transactions()
pub fn get_transactions(
    &self,
    start_version: u64,
    limit: u16,
    ledger_version: u64,
) -> Result<Vec<TransactionOnChainData>> {
    let data = self
        .db
        .get_transaction_outputs(start_version, limit as u64, ledger_version)?;
    
    // ADD VERIFICATION HERE:
    let ledger_info = self.get_latest_ledger_info()?;
    data.verify(ledger_info.ledger_info(), Some(start_version))?;
    
    // Then consume after verification
    let data = data.consume_output_list_with_proof();
    
    // ... rest of existing code
}
```

This ensures events are cryptographically verified against their committed `event_root_hash` before being served to indexers, matching the security properties of the state sync path.

**Alternative**: Provide a `get_transactions_with_verified_events()` method that explicitly performs verification, allowing indexers to opt-in to cryptographic validation.

## Proof of Concept

This vulnerability cannot be demonstrated with a traditional PoC because it requires direct storage manipulation. However, the following test demonstrates the verification gap:

```rust
// Hypothetical test showing the issue
#[test]
fn test_indexer_path_missing_event_verification() {
    // 1. Create a transaction with events and commit it
    let (transaction, events) = create_mint_transaction();
    let txn_info = commit_transaction(transaction, events.clone());
    
    // 2. Simulate storage tampering (requires direct DB access)
    let tampered_events = create_fake_mint_events();
    directly_modify_event_db(version, tampered_events);
    
    // 3. Fetch via indexer path - NO ERROR (vulnerability)
    let result = context.get_transactions(version, 1, ledger_version);
    assert!(result.is_ok()); // Tampered events are served!
    
    // 4. Fetch via state sync path - DETECTS TAMPERING
    let result = db.get_transaction_outputs(version, 1, ledger_version);
    assert!(result.verify(ledger_info, Some(version)).is_err()); // Correctly fails
}
```

The core issue is architectural: `consume_output_list_with_proof()` bypasses the verification that `verify()` would perform, creating a trust boundary violation.

## Notes

**Key Distinction**: While this requires privileged storage access (not a remote exploit), the security question specifically asks about "modified in transit or storage before reaching indexers." The missing verification represents a legitimate defense-in-depth gap where the cryptographic commitments exist but are not validated in the indexer serving path, unlike the state sync path which properly verifies event integrity.

### Citations

**File:** execution/executor/src/workflow/do_ledger_update.rs (L69-75)
```rust
                let event_hashes = txn_output
                    .events()
                    .iter()
                    .map(CryptoHash::hash)
                    .collect::<Vec<_>>();
                let event_root_hash =
                    InMemoryEventAccumulator::from_leaves(&event_hashes).root_hash();
```

**File:** types/src/transaction/mod.rs (L2025-2051)
```rust
pub struct TransactionInfoV0 {
    /// The amount of gas used.
    gas_used: u64,

    /// The vm status. If it is not `Executed`, this will provide the general error class. Execution
    /// failures and Move abort's receive more detailed information. But other errors are generally
    /// categorized with no status code or other information
    status: ExecutionStatus,

    /// The hash of this transaction.
    transaction_hash: HashValue,

    /// The root hash of Merkle Accumulator storing all events emitted during this transaction.
    event_root_hash: HashValue,

    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,

    /// The root hash of the Sparse Merkle Tree describing the world state at the end of this
    /// transaction. Depending on the protocol configuration, this can be generated periodical
    /// only, like per block.
    state_checkpoint_hash: Option<HashValue>,

    /// The hash value summarizing PersistedAuxiliaryInfo.
    auxiliary_info_hash: Option<HashValue>,
}
```

**File:** types/src/transaction/mod.rs (L2627-2643)
```rust
/// Verifies a list of events against an expected event root hash. This is done
/// by calculating the hash of the events using an event accumulator hasher.
fn verify_events_against_root_hash(
    events: &[ContractEvent],
    transaction_info: &TransactionInfo,
) -> Result<()> {
    let event_hashes: Vec<_> = events.iter().map(CryptoHash::hash).collect();
    let event_root_hash = InMemoryEventAccumulator::from_leaves(&event_hashes).root_hash();
    ensure!(
        event_root_hash == transaction_info.event_root_hash(),
        "The event root hash calculated doesn't match that carried on the \
                         transaction info! Calculated hash {:?}, transaction info hash {:?}",
        event_root_hash,
        transaction_info.event_root_hash()
    );
    Ok(())
}
```

**File:** types/src/transaction/mod.rs (L2675-2681)
```rust
    pub fn consume_output_list_with_proof(self) -> TransactionOutputListWithProof {
        match self {
            Self::TransactionOutputListWithAuxiliaryInfos(output_list_with_auxiliary_infos) => {
                output_list_with_auxiliary_infos.transaction_output_list_with_proof
            },
        }
    }
```

**File:** types/src/ledger_info.rs (L34-59)
```rust
/// This structure serves a dual purpose.
///
/// First, if this structure is signed by 2f+1 validators it signifies the state of the ledger at
/// version `version` -- it contains the transaction accumulator at that version which commits to
/// all historical transactions. This structure may be expanded to include other information that
/// is derived from that accumulator (e.g. the current time according to the time contract) to
/// reduce the number of proofs a client must get.
///
/// Second, the structure contains a `consensus_data_hash` value. This is the hash of an internal
/// data structure that represents a block that is voted on in Consensus. If 2f+1 signatures are
/// gathered on the same ledger info that represents a Quorum Certificate (QC) on the consensus
/// data.
///
/// Combining these two concepts, when a validator votes on a block, B it votes for a
/// LedgerInfo with the `version` being the latest version that will be committed if B gets 2f+1
/// votes. It sets `consensus_data_hash` to represent B so that if those 2f+1 votes are gathered a
/// QC is formed on B.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, CryptoHasher, BCSCryptoHash)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct LedgerInfo {
    commit_info: BlockInfo,

    /// Hash of consensus specific data that is opaque to all parts of the system other than
    /// consensus.
    consensus_data_hash: HashValue,
}
```

**File:** api/src/context.rs (L831-877)
```rust
    pub fn get_transactions(
        &self,
        start_version: u64,
        limit: u16,
        ledger_version: u64,
    ) -> Result<Vec<TransactionOnChainData>> {
        let data = self
            .db
            .get_transaction_outputs(start_version, limit as u64, ledger_version)?
            .consume_output_list_with_proof();

        let txn_start_version = data
            .get_first_output_version()
            .ok_or_else(|| format_err!("no start version from database"))?;
        ensure!(
            txn_start_version == start_version,
            "invalid start version from database: {} != {}",
            txn_start_version,
            start_version
        );

        let infos = data.proof.transaction_infos;
        let transactions_and_outputs = data.transactions_and_outputs;

        ensure!(
            transactions_and_outputs.len() == infos.len(),
            "invalid data size from database: {}, {}",
            transactions_and_outputs.len(),
            infos.len(),
        );

        transactions_and_outputs
            .into_iter()
            .zip(infos)
            .enumerate()
            .map(
                |(i, ((txn, txn_output), info))| -> Result<TransactionOnChainData> {
                    let version = start_version + i as u64;
                    let (write_set, events, _, _, _) = txn_output.unpack();
                    let h = self.get_accumulator_root_hash(version)?;
                    let txn: TransactionOnChainData =
                        (version, txn, info, events, h, write_set).into();
                    Ok(self.maybe_translate_v2_to_v1_events(txn))
                },
            )
            .collect()
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L394-418)
```rust
                    let txn_info = self
                        .ledger_db
                        .transaction_info_db()
                        .get_transaction_info(version)?;
                    let events = self.ledger_db.event_db().get_events_by_version(version)?;
                    let write_set = self.ledger_db.write_set_db().get_write_set(version)?;
                    let txn = self.ledger_db.transaction_db().get_transaction(version)?;
                    let auxiliary_data = self
                        .ledger_db
                        .transaction_auxiliary_data_db()
                        .get_transaction_auxiliary_data(version)?
                        .unwrap_or_default();
                    let txn_output = TransactionOutput::new(
                        write_set,
                        events,
                        txn_info.gas_used(),
                        txn_info.status().clone().into(),
                        auxiliary_data,
                    );
                    let persisted_aux_info = self
                        .ledger_db
                        .persisted_auxiliary_info_db()
                        .get_persisted_auxiliary_info(version)?
                        .unwrap_or(PersistedAuxiliaryInfo::None);
                    Ok((txn_info, (txn, txn_output), persisted_aux_info))
```

**File:** execution/executor/src/chunk_executor/mod.rs (L168-174)
```rust
        THREAD_MANAGER.get_exe_cpu_pool().install(|| {
            let _timer = CHUNK_OTHER_TIMERS.timer_with(&["apply_chunk__verify"]);
            txn_output_list_with_proof.verify(
                verified_target_li.ledger_info(),
                txn_output_list_with_proof.get_first_output_version(),
            )
        })?;
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1294-1297)
```rust
                match transaction_outputs_with_proof.verify(
                    ledger_info_to_sync.ledger_info(),
                    Some(expected_start_version),
                ) {
```
