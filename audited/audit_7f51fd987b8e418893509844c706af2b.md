# Audit Report

## Title
Infinite Loop in Internal Indexer Service Causes CPU Exhaustion When Main DB Falls Behind

## Summary
The `InternalIndexerDBService::run()` function enters an infinite tight loop that exhausts CPU resources when the internal indexer is ahead of the main database. The function fails to wait between processing attempts when `process()` returns the same version but `target_version > start_version`, causing continuous spinning without yielding.

## Finding Description

The vulnerability exists in the version progression logic of the internal indexer service's main loop. The wait condition only triggers when `target_version <= start_version`, but fails to handle the case where the indexer is ahead of the main database while still having a target version to reach. [1](#0-0) 

The critical flaw occurs when:

1. The loop receives a `target_version` greater than `start_version` (e.g., target=1005, start=1001)
2. `DBIndexer::process()` is called but returns the same `start_version` without making progress
3. The condition at line 173 evaluates to FALSE, so the loop does NOT wait
4. The loop immediately calls `process()` again with the same parameters
5. This repeats indefinitely, creating a CPU-burning tight loop

The root cause is in `DBIndexer::get_num_of_transactions()` which returns 0 when the main database is behind: [2](#0-1) 

When `version > highest_version` (line 384), the function returns 0 transactions. This causes `process_a_batch()` to complete without incrementing the version, as the iterator over 0 transactions is empty and the version increment at line 498 never executes: [3](#0-2) 

The `process()` wrapper detects no progress and breaks: [4](#0-3) 

However, this safety mechanism only prevents an infinite loop within `process()` itself. When control returns to `run()`, the loop lacks the necessary wait condition and immediately calls `process()` again.

Notably, the test function `run_with_end_version()` includes a sleep to prevent this exact issue: [5](#0-4) 

The comment at line 212 explicitly acknowledges the need to yield when no progress can be made, but this safeguard was not applied to the production `run()` function.

## Impact Explanation

This is a **High Severity** vulnerability per the Aptos bug bounty program criteria for "Validator node slowdowns". The impact includes:

1. **CPU Exhaustion**: The tight infinite loop consumes 100% of a CPU core, degrading node performance
2. **Resource Starvation**: Other critical node operations (consensus, execution, networking) may be starved of CPU resources
3. **Availability Degradation**: Node responsiveness decreases, potentially affecting block production and validation
4. **Cascading Failures**: If multiple nodes experience this simultaneously during coordinated DB restores, network performance degrades

The internal indexer is enabled by default in deployment configurations, affecting both validator and fullnode infrastructure: [6](#0-5) [7](#0-6) 

The service is spawned as a critical production component: [8](#0-7) 

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can be triggered in several realistic operational scenarios:

1. **Database Restore**: When a node restores from a backup where the internal indexer DB is from a newer backup than the main DB
2. **State Sync Issues**: During state sync, temporary inconsistencies between main DB and indexer DB can occur
3. **Database Rollback**: If the main DB undergoes a rollback due to a fork or recovery operation
4. **Fast Sync Mode**: During initial node bootstrap with fast sync enabled, race conditions between DB components

The triggering conditions are:
- `start_version > main_db_synced_version` (indexer ahead of main DB)
- `target_version > start_version` (update received indicating work to do)

These are not exotic edge cases but plausible operational scenarios encountered during node maintenance, upgrades, or network partitions requiring recovery operations.

## Recommendation

Add a wait condition in the `run()` loop when no progress is made, similar to the test function:

```rust
pub async fn run(&mut self, node_config: &NodeConfig) -> Result<()> {
    let mut start_version = self.get_start_version(node_config).await?;
    let mut target_version = self.db_indexer.main_db_reader.ensure_synced_version()?;
    let mut step_timer = std::time::Instant::now();

    loop {
        if target_version <= start_version {
            match self.update_receiver.changed().await {
                Ok(_) => {
                    (step_timer, target_version) = *self.update_receiver.borrow();
                },
                Err(e) => {
                    panic!("Failed to get update from update_receiver: {}", e);
                },
            }
        }
        let next_version = self.db_indexer.process(start_version, target_version)?;
        
        // Add this check to prevent tight loop when no progress
        if next_version == start_version {
            tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        }
        
        INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
        log_grpc_step(...);
        start_version = next_version;
    }
}
```

## Proof of Concept

The vulnerability can be demonstrated by:

1. Setting up a node with internal indexer enabled
2. Restoring the internal indexer DB from a backup at version V2
3. Restoring the main DB from an older backup at version V1 where V1 < V2
4. Sending an update with target_version > V2
5. Observing CPU usage spike to 100% on one core as the loop spins indefinitely

The exact reproduction requires access to a running node with the internal indexer enabled and the ability to perform database restore operations, which are standard operational procedures for node operators.

## Notes

This vulnerability demonstrates a resource management flaw where the indexer service assumes continuous forward progress. The existence of the sleep in the test function and the accompanying comment confirm that the developers were aware of the need to yield when waiting for the main DB to catch up, but this protection was not carried over to the production code path.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L172-183)
```rust
        loop {
            if target_version <= start_version {
                match self.update_receiver.changed().await {
                    Ok(_) => {
                        (step_timer, target_version) = *self.update_receiver.borrow();
                    },
                    Err(e) => {
                        panic!("Failed to get update from update_receiver: {}", e);
                    },
                }
            }
            let next_version = self.db_indexer.process(start_version, target_version)?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L210-214)
```rust
        while next_version < end_version {
            next_version = self.db_indexer.process(next_version, end_version)?;
            // We shouldn't stop the internal indexer so that internal indexer can catch up with the main DB
            tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        }
```

**File:** storage/indexer/src/db_indexer.rs (L382-394)
```rust
    fn get_num_of_transactions(&self, version: Version, end_version: Version) -> Result<u64> {
        let highest_version = min(self.main_db_reader.ensure_synced_version()?, end_version);
        if version > highest_version {
            // In case main db is not synced yet or recreated
            return Ok(0);
        }
        // we want to include the last transaction since the iterator interface will is right exclusive.
        let num_of_transaction = min(
            self.indexer_db.config.batch_size as u64,
            highest_version + 1 - version,
        );
        Ok(num_of_transaction)
    }
```

**File:** storage/indexer/src/db_indexer.rs (L397-407)
```rust
    pub fn process(&self, start_version: Version, end_version: Version) -> Result<Version> {
        let mut version = start_version;
        while version < end_version {
            let next_version = self.process_a_batch(version, end_version)?;
            if next_version == version {
                break;
            }
            version = next_version;
        }
        Ok(version)
    }
```

**File:** storage/indexer/src/db_indexer.rs (L410-420)
```rust
    pub fn process_a_batch(&self, start_version: Version, end_version: Version) -> Result<Version> {
        let _timer: aptos_metrics_core::HistogramTimer = TIMER.timer_with(&["process_a_batch"]);
        let mut version = start_version;
        let num_transactions = self.get_num_of_transactions(version, end_version)?;
        // This promises num_transactions should be readable from main db
        let mut db_iter = self.get_main_db_iter(version, num_transactions)?;
        let mut batch = SchemaBatch::new();
        let mut event_keys: HashSet<EventKey> = HashSet::new();
        db_iter.try_for_each(|res| {
            let (txn, events, writeset) = res?;
            if let Some(signed_txn) = txn.try_as_signed_user_txn() {
```

**File:** testsuite/forge/src/backend/k8s/helm-values/aptos-node-default-values.yaml (L12-13)
```yaml
    indexer_db_config:
      enable_event: true
```

**File:** testsuite/forge/src/backend/k8s/helm-values/aptos-node-default-values.yaml (L31-32)
```yaml
    indexer_db_config:
      enable_event: true
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/runtime.rs (L42-44)
```rust
    runtime.spawn(async move {
        indexer_service.run(&config_clone).await.unwrap();
    });
```
