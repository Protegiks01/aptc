# Audit Report

## Title
Inconsistent Batch Expiration Validation Allows Expired Inline Batches in Block Proposals

## Summary
Inline batches bypass the batch expiration validation check that is consistently applied to regular batches with proofs. This allows block proposers to include expired inline batches in payloads, potentially causing consensus splits or liveness failures when validators disagree on batch data availability.

## Finding Description

The Aptos QuorumStore implements two types of batch inclusion in block payloads:
1. **Regular batches with proofs** - batches certified via quorum store proofs
2. **Inline batches** - batches included directly in the block proposal without proofs

The critical security guarantee is that **expired batches should never be included in blocks**. However, this invariant is enforced inconsistently:

**For regular batches with proofs:**
- Expiration is checked at proof insertion time [1](#0-0) 
- Expiration is checked again during transaction processing [2](#0-1) 

**For inline batches:**
- No batch expiration check exists in `pull_batches_with_transactions()` which pulls batches for inline inclusion [3](#0-2) 
- The underlying `pull_internal()` function receives `block_timestamp` but never validates `block_timestamp <= batch.expiration()` [4](#0-3) 
- During transaction processing, inline batches bypass `request_transactions()` entirely and are directly appended [5](#0-4) 

**Attack Scenario:**
1. A batch B exists with `expiration = 1000 seconds`
2. Current block timestamp advances to `1100 seconds` (batch is expired)
3. Malicious proposer calls `pull_batches_with_transactions(block_timestamp=1100s)`
4. Since no expiration check exists, batch B is pulled and included as an inline batch
5. Proposer broadcasts block containing expired inline batch
6. Validators receive block and process inline batches
7. If the batch data has been garbage collected (after 60-second buffer), validators may fail to fetch it [6](#0-5) 
8. The batch requester checks expiration and returns an error for expired batches [7](#0-6) 
9. Different validators may succeed or fail depending on whether they still have cached data, causing inconsistent block execution

## Impact Explanation

**Severity: High** - Significant protocol violation with potential for consensus issues.

This vulnerability violates the **Deterministic Execution** invariant (#1) - validators may produce different outcomes when processing the same block depending on their local cache state. This breaks the fundamental consensus guarantee that all honest validators must agree on block execution results.

Potential impacts:
- **Consensus Split**: Validators with cached expired batch data execute successfully while others fail, leading to divergent blockchain states
- **Liveness Failure**: If sufficient validators cannot execute the block due to missing expired batch data, the chain cannot make progress
- **Protocol Invariant Violation**: The expiration mechanism exists to bound resource usage and ensure timely garbage collection; allowing expired batches undermines this design

While this requires a malicious or buggy validator proposer, the impact on network integrity is significant enough to warrant High severity classification per the bug bounty criteria for "Significant protocol violations."

## Likelihood Explanation

**Likelihood: Medium**

This can occur through:
1. **Malicious validator**: A Byzantine proposer intentionally including expired inline batches to disrupt consensus
2. **Timing bug**: A proposer with clock skew or processing delays inadvertently including batches that expire during block construction
3. **Implementation bug**: Incorrect proposer logic that doesn't properly check batch ages

The vulnerability is readily exploitable by any validator who can propose blocks (approximately 1 in N validators per round, where N is the validator set size). No additional privileges beyond being a validator are required.

The inconsistency is structural - the code paths simply don't perform the same validation - making this a persistent issue rather than a rare edge case.

## Recommendation

Add batch expiration validation in `pull_internal()` to filter out expired batches before they can be pulled for inline inclusion:

```rust
// In pull_internal(), after line 601 in the batch_iter filter_map:
let batch_iter = batches.iter().rev().filter_map(|(sort_key, info)| {
    if let Some(item) = self.items.get(&sort_key.batch_key) {
        // ADD THIS CHECK:
        // Skip batches that have expired relative to the block timestamp
        if item.info.expiration() <= block_timestamp.as_micros() as u64 {
            return None;
        }
        
        // Existing checks...
        let batch_create_ts_usecs =
            item.info.expiration() - self.batch_expiry_gap_when_init_usecs;
        // ... rest of existing logic
    }
    None
});
```

This ensures inline batches are subject to the same expiration validation as regular batches with proofs, maintaining consistency across all payload processing paths.

## Proof of Concept

```rust
// Test to demonstrate the vulnerability
#[test]
fn test_expired_inline_batch_bypass() {
    use std::time::Duration;
    
    // Setup: Create a batch proof queue with some batches
    let mut queue = /* initialize batch proof queue */;
    
    // Create a batch with expiration at T=1000
    let batch_info = BatchInfo::new(
        author,
        batch_id,
        epoch,
        1000_000_000, // expiration = 1000 seconds
        digest,
        num_txns,
        num_bytes,
        gas_bucket_start,
    );
    
    // Add batch to queue without proof (inline batch)
    queue.add_batch_without_proof(batch_info);
    
    // Advance block timestamp past expiration to T=1100
    let block_timestamp = Duration::from_secs(1100);
    
    // Pull batches for inline inclusion - this should reject expired batch but doesn't
    let (inline_batches, _, _) = queue.pull_batches_with_transactions(
        &HashSet::new(),
        max_txns,
        max_txns_after_filtering,
        soft_max_txns_after_filtering,
        true,
        block_timestamp, // T=1100, batch expired at T=1000
    );
    
    // VULNERABILITY: Expired batch is included in inline_batches
    assert!(!inline_batches.is_empty(), "Expired batch was pulled!");
    
    // In contrast, regular batches with proofs would be rejected:
    // insert_proof() checks: if proof.expiration() <= self.latest_block_timestamp
}
```

## Notes

The vulnerability exists because inline batches were designed to bypass the proof-of-store mechanism for efficiency, but this optimization inadvertently bypassed critical expiration validation. The verification logic in `reconstruct_batch()` [8](#0-7)  shows that inline batches use `skip_expired_batches=false`, meaning they cannot be skipped during reconstruction - reinforcing the expectation that inline batches should never be expired in the first place. The missing validation at pull time creates a security gap that allows this invariant to be violated.

### Citations

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L176-179)
```rust
        if proof.expiration() <= self.latest_block_timestamp {
            counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
            return;
        }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L515-559)
```rust
    pub fn pull_batches_with_transactions(
        &mut self,
        excluded_batches: &HashSet<BatchInfoExt>,
        max_txns: PayloadTxnsSize,
        max_txns_after_filtering: u64,
        soft_max_txns_after_filtering: u64,
        return_non_full: bool,
        block_timestamp: Duration,
    ) -> (
        Vec<(BatchInfoExt, Vec<SignedTransaction>)>,
        PayloadTxnsSize,
        u64,
    ) {
        let (batches, pulled_txns, unique_txns, is_full) = self.pull_batches_internal(
            excluded_batches,
            &HashSet::new(),
            max_txns,
            max_txns_after_filtering,
            soft_max_txns_after_filtering,
            return_non_full,
            block_timestamp,
            None,
        );
        let mut result = Vec::new();
        for batch in batches.into_iter() {
            if let Ok(mut persisted_value) = self.batch_store.get_batch_from_local(batch.digest()) {
                if let Some(txns) = persisted_value.take_payload() {
                    result.push((batch, txns));
                }
            } else {
                warn!(
                    "Couldn't find a batch in local storage while creating inline block: {:?}",
                    batch.digest()
                );
            }
        }

        if is_full || return_non_full {
            counters::CONSENSUS_PULL_NUM_UNIQUE_TXNS.observe_with(&["inline"], unique_txns as f64);
            counters::CONSENSUS_PULL_NUM_TXNS.observe_with(&["inline"], pulled_txns.count() as f64);
            counters::CONSENSUS_PULL_SIZE_IN_BYTES
                .observe_with(&["inline"], pulled_txns.size_in_bytes() as f64);
        }
        (result, pulled_txns, unique_txns)
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L561-624)
```rust
    fn pull_internal(
        &mut self,
        batches_without_proofs: bool,
        excluded_batches: &HashSet<BatchInfoExt>,
        exclude_authors: &HashSet<Author>,
        max_txns: PayloadTxnsSize,
        max_txns_after_filtering: u64,
        soft_max_txns_after_filtering: u64,
        return_non_full: bool,
        block_timestamp: Duration,
        min_batch_age_usecs: Option<u64>,
    ) -> (Vec<&QueueItem>, PayloadTxnsSize, u64, bool) {
        let mut result = Vec::new();
        let mut cur_unique_txns = 0;
        let mut cur_all_txns = PayloadTxnsSize::zero();
        let mut excluded_txns = 0;
        let mut full = false;
        // Set of all the excluded transactions and all the transactions included in the result
        let mut filtered_txns = HashSet::new();
        for batch_info in excluded_batches {
            let batch_key = BatchKey::from_info(batch_info);
            if let Some(txn_summaries) = self
                .items
                .get(&batch_key)
                .and_then(|item| item.txn_summaries.as_ref())
            {
                for txn_summary in txn_summaries {
                    filtered_txns.insert(*txn_summary);
                }
            }
        }

        let max_batch_creation_ts_usecs = min_batch_age_usecs
            .map(|min_age| aptos_infallible::duration_since_epoch().as_micros() as u64 - min_age);
        let mut iters = vec![];
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
        {
            let batch_iter = batches.iter().rev().filter_map(|(sort_key, info)| {
                if let Some(item) = self.items.get(&sort_key.batch_key) {
                    let batch_create_ts_usecs =
                        item.info.expiration() - self.batch_expiry_gap_when_init_usecs;

                    // Ensure that the batch was created at least `min_batch_age_usecs` ago to
                    // reduce the chance of inline fetches.
                    if max_batch_creation_ts_usecs
                        .is_some_and(|max_create_ts| batch_create_ts_usecs > max_create_ts)
                    {
                        return None;
                    }

                    if item.is_committed() {
                        return None;
                    }
                    if !(batches_without_proofs ^ item.proof.is_none()) {
                        return Some((info, item));
                    }
                }
                None
            });
            iters.push(batch_iter);
        }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L102-106)
```rust
            if block_timestamp <= batch_info.expiration() {
                futures.push(batch_reader.get_batch(batch_info, responders.clone()));
            } else {
                debug!("QSE: skipped expired batch {}", batch_info.digest());
            }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L142-148)
```rust
            all_txns.append(
                &mut inline_batches
                    .iter()
                    // TODO: Can clone be avoided here?
                    .flat_map(|(_batch_info, txns)| txns.clone())
                    .collect(),
            );
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-472)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
        let mut ret = Vec::new();
        for h in expired_digests {
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
            // No longer holding the lock on db_cache entry.
            if let Some(value) = removed_value {
                self.free_quota(value);
                ret.push(h);
            }
        }
        ret
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L145-150)
```rust
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L987-998)
```rust
fn reconstruct_batch(
    block_info: &BlockInfo,
    transactions_iter: &mut IntoIter<SignedTransaction>,
    expected_batch_info: &BatchInfo,
    skip_expired_batches: bool,
) -> Result<Option<Vec<SignedTransaction>>, Error> {
    // If the batch is expired we should skip reconstruction (as the
    // transactions for the expired batch won't be sent in the payload).
    // Note: this should only be required for QS batches (not inline batches).
    if skip_expired_batches && block_info.timestamp_usecs() > expected_batch_info.expiration() {
        return Ok(None);
    }
```
