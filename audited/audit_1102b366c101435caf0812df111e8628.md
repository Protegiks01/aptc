# Audit Report

## Title
Sparse Merkle Range Proof Key-Proof Mismatch Vulnerability in Backup/Restore System

## Summary
The backup/restore system lacks cryptographic binding between `SparseMerkleRangeProof` objects and the specific keys they were generated for. An attacker with access to the backup generation process can create proofs for arbitrary keys and associate them with mismatched chunk data, causing restore operations to fail.

## Finding Description

The vulnerability exists in the interaction between backup generation and restore verification:

**During Backup Generation:** [1](#0-0) 

The `get_account_state_range_proof()` function accepts an arbitrary `rightmost_key` parameter and passes it directly to the proof generation logic without validating that this key corresponds to any specific chunk data. [2](#0-1) 

The proof generation only validates that the key exists in the tree, but doesn't bind the proof to the specific chunk data it should authenticate.

**The Attack Vector:** [3](#0-2) 

During backup, the system:
1. Parses `last_key` from chunk data (line 415-416)
2. Requests proof via HTTP GET to `/state_range_proof/{version}/{last_key}`
3. Stores chunk data and proof separately [4](#0-3) 

The HTTP endpoint accepts any `HashValue` without validating its relationship to chunk data.

**During Restore:** [5](#0-4) 

The restore process loads chunk data and proof separately, then passes them to verification without checking they match. [6](#0-5) 

The verification uses the **actual rightmost leaf** from the chunk data, but the proof's `right_siblings` were generated for a potentially **different key's path**, causing hash reconstruction to fail.

**Root Cause:** [7](#0-6) 

The manifest stores `last_key` and `proof` as separate, unbound fields with no cryptographic commitment between them.

## Impact Explanation

This vulnerability allows **Denial of Service on backup restore operations** (Medium Severity):

- An attacker who controls backup generation or modifies backup files can provide mismatched proofs
- During restore, verification will fail when the proof's right siblings (for key Km) are used with the actual rightmost key's path bits (for key Kn â‰  Km)
- This prevents nodes from successfully restoring from backups

The impact is **NOT Critical** because:
1. State corruption is not feasible - mismatched proofs will cause verification failure, not acceptance of invalid state
2. Requires privileged access to backup infrastructure (not exploitable by unprivileged attacker)
3. Does not affect running consensus or live state synchronization

## Likelihood Explanation

**Likelihood: Low**

Exploitation requires:
1. Compromise of backup generation infrastructure, OR
2. Man-in-the-middle access to backup storage, OR  
3. Ability to distribute malicious backups to users

An unprivileged external attacker cannot directly exploit this without first compromising trusted infrastructure. However, in scenarios where users obtain backups from semi-trusted sources, this could be weaponized for targeted DoS attacks against node operators.

## Recommendation

Add cryptographic binding between proofs and chunk data:

1. **Include the rightmost key hash in the proof structure:**
```rust
pub struct SparseMerkleRangeProof {
    rightmost_key: HashValue,  // Add this field
    right_siblings: Vec<HashValue>,
}
```

2. **Validate during restore:**
```rust
// In JellyfishMerkleRestore::verify()
let actual_last_key = previous_leaf.account_key();
ensure!(
    proof.rightmost_key == *actual_last_key,
    "Proof was generated for key {:x} but chunk ends at {:x}",
    proof.rightmost_key,
    actual_last_key
);
```

3. **Update proof generation to include the key:** [2](#0-1) 

Modify `get_range_proof()` to return a proof that cryptographically commits to the rightmost key.

## Proof of Concept

```rust
#[test]
fn test_mismatched_proof_dos() {
    // Setup: Create state with keys K1, K2, K3, K4, K5
    let state_keys = vec![key1, key2, key3, key4, key5];
    
    // Attacker action: Request proof for K3 instead of K5
    let malicious_proof = backup_handler.get_account_state_range_proof(key3, version);
    
    // Store chunk with K5 as last key but K3's proof
    let chunk = create_chunk(state_keys, malicious_proof);
    
    // Restore attempt: Will fail because K3's proof doesn't match K5's path
    let result = restore_handler.add_chunk(chunk.data, chunk.proof);
    
    // Verification fails with root hash mismatch
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Root hashes do not match"));
}
```

---

**Notes:**

While this is a legitimate design flaw that should be fixed, it does not meet the strict criteria for an exploitable vulnerability because it requires privileged access to the backup infrastructure. The attacker requirement fails the "unprivileged attacker" test in the validation checklist. The issue represents a missing defense-in-depth measure rather than a directly exploitable security vulnerability in the threat model where backup infrastructure is trusted.

### Citations

**File:** storage/aptosdb/src/backup/backup_handler.rs (L165-172)
```rust
    pub fn get_account_state_range_proof(
        &self,
        rightmost_key: HashValue,
        version: Version,
    ) -> Result<SparseMerkleRangeProof> {
        self.state_store
            .get_value_range_proof(rightmost_key, version)
    }
```

**File:** storage/jellyfish-merkle/src/lib.rs (L801-824)
```rust
    pub fn get_range_proof(
        &self,
        rightmost_key_to_prove: HashValue,
        version: Version,
    ) -> Result<SparseMerkleRangeProof> {
        let (account, proof) = self.get_with_proof(rightmost_key_to_prove, version)?;
        ensure!(account.is_some(), "rightmost_key_to_prove must exist.");

        let siblings = proof
            .siblings()
            .iter()
            .zip(rightmost_key_to_prove.iter_bits())
            .filter_map(|(sibling, bit)| {
                // We only need to keep the siblings on the right.
                if !bit {
                    Some(*sibling)
                } else {
                    None
                }
            })
            .rev()
            .collect();
        Ok(SparseMerkleRangeProof::new(siblings))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/backup.rs (L404-446)
```rust
    async fn write_chunk(
        &self,
        backup_handle: &BackupHandleRef,
        chunk: Chunk,
    ) -> Result<StateSnapshotChunk> {
        let _timer = BACKUP_TIMER.timer_with(&["state_snapshot_write_chunk"]);

        let Chunk {
            bytes,
            first_idx,
            last_idx,
            first_key,
            last_key,
        } = chunk;

        let (chunk_handle, mut chunk_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_name(first_idx))
            .await?;
        chunk_file.write_all(&bytes).await?;
        chunk_file.shutdown().await?;
        let (proof_handle, mut proof_file) = self
            .storage
            .create_for_write(backup_handle, &Self::chunk_proof_name(first_idx, last_idx))
            .await?;
        tokio::io::copy(
            &mut self
                .client
                .get_account_range_proof(last_key, self.version())
                .await?,
            &mut proof_file,
        )
        .await?;
        proof_file.shutdown().await?;

        Ok(StateSnapshotChunk {
            first_idx,
            last_idx,
            first_key,
            last_key,
            blobs: chunk_handle,
            proof: proof_handle,
        })
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L35-45)
```rust
    // GET state_range_proof/<version>/<end_key>
    let bh = backup_handler.clone();
    let state_range_proof = warp::path!(Version / HashValue)
        .map(move |version, end_key| {
            reply_with_bcs_bytes(
                STATE_RANGE_PROOF,
                &bh.get_account_state_range_proof(end_key, version)?,
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L189-214)
```rust
            async move {
                tokio::spawn(async move {
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
                    Result::<_>::Ok((chunk_idx, chunk, blobs, proof))
                })
                .await?
            }
        });
        let con = self.concurrent_downloads;
        let mut futs_stream = stream::iter(futs_iter).buffered_x(con * 2, con);
        let mut start = None;
        while let Some((chunk_idx, chunk, mut blobs, proof)) = futs_stream.try_next().await? {
            start = start.or_else(|| Some(Instant::now()));
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["add_state_chunk"]);
            let receiver = receiver.clone();
            if self.validate_modules {
                blobs = tokio::task::spawn_blocking(move || {
                    Self::validate_modules(&blobs);
                    blobs
                })
                .await?;
            }
            tokio::task::spawn_blocking(move || {
                receiver.lock().as_mut().unwrap().add_chunk(blobs, proof)
            })
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L628-697)
```rust
    fn verify(&self, proof: SparseMerkleRangeProof) -> Result<()> {
        let previous_leaf = self
            .previous_leaf
            .as_ref()
            .expect("The previous leaf must exist.");

        let previous_key = previous_leaf.account_key();
        // If we have all siblings on the path from root to `previous_key`, we should be able to
        // compute the root hash. The siblings on the right are already in the proof. Now we
        // compute the siblings on the left side, which represent all the states that have ever
        // been added.
        let mut left_siblings = vec![];

        // The following process might add some extra placeholder siblings on the left, but it is
        // nontrivial to determine when the loop should stop. So instead we just add these
        // siblings for now and get rid of them in the next step.
        let mut num_visited_right_siblings = 0;
        for (i, bit) in previous_key.iter_bits().enumerate() {
            if bit {
                // This node is a right child and there should be a sibling on the left.
                let sibling = if i >= self.partial_nodes.len() * 4 {
                    *SPARSE_MERKLE_PLACEHOLDER_HASH
                } else {
                    Self::compute_left_sibling(
                        &self.partial_nodes[i / 4],
                        previous_key.get_nibble(i / 4),
                        (3 - i % 4) as u8,
                    )
                };
                left_siblings.push(sibling);
            } else {
                // This node is a left child and there should be a sibling on the right.
                num_visited_right_siblings += 1;
            }
        }
        ensure!(
            num_visited_right_siblings >= proof.right_siblings().len(),
            "Too many right siblings in the proof.",
        );

        // Now we remove any extra placeholder siblings at the bottom. We keep removing the last
        // sibling if 1) it's a placeholder 2) it's a sibling on the left.
        for bit in previous_key.iter_bits().rev() {
            if bit {
                if *left_siblings.last().expect("This sibling must exist.")
                    == *SPARSE_MERKLE_PLACEHOLDER_HASH
                {
                    left_siblings.pop();
                } else {
                    break;
                }
            } else if num_visited_right_siblings > proof.right_siblings().len() {
                num_visited_right_siblings -= 1;
            } else {
                break;
            }
        }

        // Left siblings must use the same ordering as the right siblings in the proof
        left_siblings.reverse();

        // Verify the proof now that we have all the siblings
        proof
            .verify(
                self.expected_root_hash,
                SparseMerkleLeafNode::new(*previous_key, previous_leaf.value_hash()),
                left_siblings,
            )
            .map_err(Into::into)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L9-27)
```rust
/// A chunk of a state snapshot manifest, representing accounts in the key range
/// [`first_key`, `last_key`] (right side inclusive).
#[derive(Deserialize, Serialize)]
pub struct StateSnapshotChunk {
    /// index of the first account in this chunk over all accounts.
    pub first_idx: usize,
    /// index of the last account in this chunk over all accounts.
    pub last_idx: usize,
    /// key of the first account in this chunk.
    pub first_key: HashValue,
    /// key of the last account in this chunk.
    pub last_key: HashValue,
    /// Repeated `len(record) + record` where `record` is BCS serialized tuple
    /// `(key, state_value)`
    pub blobs: FileHandle,
    /// BCS serialized `SparseMerkleRangeProof` that proves this chunk adds up to the root hash
    /// indicated in the backup (`StateSnapshotBackup::root_hash`).
    pub proof: FileHandle,
}
```
