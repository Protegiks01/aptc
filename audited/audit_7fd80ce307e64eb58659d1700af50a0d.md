# Audit Report

## Title
Execution Backpressure Desynchronization Leading to Block Space Waste and Validator Performance Degradation

## Summary
The `ExecutionBackpressureConfig` allows independent configuration of `txn_limit` and `gas_limit` backpressure mechanisms with significantly different lookback windows (18 vs 30 blocks) and metrics (median vs mean). This enables scenarios where `gas_limit` backpressure activates while `txn_limit` remains inactive, causing validators to propose large blocks (up to 1800 transactions) that execute only a small fraction of transactions before hitting the gas limit, with the remainder being skipped and requiring retry. [1](#0-0) 

## Finding Description

The vulnerability stems from the independent operation of two backpressure mechanisms with misaligned configurations:

**Configuration Discrepancy:**
- `txn_limit`: Lookback of 18 blocks, uses Percentile(0.5) median, 50ms minimum activation threshold
- `gas_limit`: Lookback of 30 blocks, uses Mean, 10ms minimum activation threshold [2](#0-1) 

**Execution Flow:**

1. Both mechanisms analyze recent block execution times independently via `get_execution_block_txn_and_gas_limit_backoff()`: [3](#0-2) 

2. In `calculate_max_block_sizes()`, if `gas_limit` activates but `txn_limit` doesn't:
   - `max_block_txns_after_filtering` remains at default 1800 (line 797-798 only pushes if Some)
   - `block_gas_limit_override` is set to reduced gas limit (line 800) [4](#0-3) 

3. The payload is pulled with high transaction count but low gas limit: [5](#0-4) 

4. During execution, `BlockGasLimitProcessor` enforces the gas limit, causing early termination: [6](#0-5) [7](#0-6) 

5. All remaining transactions are marked as skipped and filled with `skip_output`: [8](#0-7) 

**Attack Scenario:**
An attacker submits transactions with varying gas profiles across epochs to exploit the 12-block lookback window difference, creating a pattern where older expensive blocks affect the 30-block mean for `gas_limit` while recent cheaper blocks keep the 18-block median for `txn_limit` below threshold.

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria ("Validator node slowdowns"):

1. **Validator Performance Degradation**: Validators waste computational resources processing and broadcasting large blocks (1800 transactions) where 80-90% never execute
2. **Consensus Bandwidth Waste**: Network propagates blocks with ~6MB of transaction data when only ~600KB actually executes
3. **Execution Pipeline Congestion**: Unexecuted transactions create backlog in mempool requiring retry logic
4. **User Experience Impact**: Legitimate transactions experience increased latency as they're repeatedly included but skipped

The issue does NOT cause consensus safety violations or fund loss, preventing Critical severity classification.

## Likelihood Explanation

**Likelihood: Medium-High**

The vulnerability can occur through:
1. **Natural Load Patterns**: Legitimate applications submitting compute-intensive transactions can naturally trigger the desynchronization without malicious intent
2. **Attacker Exploitation**: A motivated attacker can deliberately craft transaction patterns to maintain the condition for extended periods
3. **No Special Privileges Required**: Any transaction sender can submit transactions with varying gas profiles

The 12-block difference between lookback windows provides sufficient opportunity for desynchronization to occur and persist.

## Recommendation

Implement coordination between `txn_limit` and `gas_limit` backpressure mechanisms:

**Option 1: Unified Lookback Window**
```rust
// In ExecutionBackpressureTxnLimitConfig and ExecutionBackpressureGasLimitConfig
// Ensure both use the same lookback window (e.g., max of both: 30 blocks)
pub struct ExecutionBackpressureLookbackConfig {
    pub num_blocks_to_look_at: usize, // Standardize to 30 for both
    // ... rest of config
}
```

**Option 2: Cross-Mechanism Validation**
Add validation in `get_execution_block_txn_and_gas_limit_backoff()` to ensure if one mechanism activates, the other is also checked with relaxed thresholds:

```rust
pub fn get_execution_block_txn_and_gas_limit_backoff(
    &self,
    block_execution_times: &[ExecutionSummary],
    max_block_txns: u64,
    max_block_gas_limit: Option<u64>,
) -> (Option<u64>, Option<u64>) {
    let txn_limit_backoff = self.get_execution_block_size_backoff(...);
    let gas_limit_backoff = max_block_gas_limit.and_then(|limit| 
        self.get_execution_gas_limit_backoff(...)
    );
    
    // NEW: If gas_limit activates but txn_limit doesn't, 
    // force conservative txn_limit to prevent large blocks with low gas
    if gas_limit_backoff.is_some() && txn_limit_backoff.is_none() {
        let conservative_txn_limit = estimate_txns_for_gas_limit(
            gas_limit_backoff.unwrap(), 
            block_execution_times
        );
        return (Some(conservative_txn_limit), gas_limit_backoff);
    }
    
    (txn_limit_backoff, gas_limit_backoff)
}
```

**Option 3: Gas-First Approach**
As indicated by the TODO comment, transition to gas-limit-only backpressure once execution pool is deployed, eliminating the desynchronization entirely. [9](#0-8) 

## Proof of Concept

```rust
// Test demonstrating the desynchronization scenario
#[test]
fn test_execution_backpressure_desynchronization() {
    // Setup: Create execution summaries simulating the attack pattern
    let mut execution_times = Vec::new();
    
    // Blocks 1-18: Mix of fast and moderate blocks (median stays low)
    for i in 0..18 {
        execution_times.push(ExecutionSummary {
            execution_time: Duration::from_millis(if i % 3 == 0 { 80 } else { 40 }),
            payload_len: 1000,
            to_commit: 1000,
            to_retry: 0,
            gas_used: Some(if i % 3 == 0 { 50000 } else { 10000 }),
        });
    }
    
    // Blocks 19-30: Expensive blocks (mean increases significantly)
    for _ in 18..30 {
        execution_times.push(ExecutionSummary {
            execution_time: Duration::from_millis(120),
            payload_len: 1000,
            to_commit: 1000,
            to_retry: 0,
            gas_used: Some(80000),
        });
    }
    
    let config = ExecutionBackpressureConfig {
        txn_limit: Some(ExecutionBackpressureTxnLimitConfig::default()),
        gas_limit: Some(ExecutionBackpressureGasLimitConfig::default()),
    };
    
    let backpressure = PipelineBackpressureConfig::new(vec![], Some(config));
    
    // Get backoff values
    let (txn_backoff, gas_backoff) = backpressure
        .get_execution_block_txn_and_gas_limit_backoff(
            &execution_times,
            1800, // max_block_txns
            Some(100000), // max_block_gas_limit
        );
    
    // ASSERTION: Demonstrates the vulnerability
    // txn_backoff should be None (median of last 18 blocks is acceptable)
    // gas_backoff should be Some (mean of 30 blocks exceeds target)
    assert!(txn_backoff.is_none(), 
        "txn_limit should not activate (looking at last 18 blocks with median)");
    assert!(gas_backoff.is_some(), 
        "gas_limit should activate (looking at all 30 blocks with mean)");
    
    // This creates the problematic scenario:
    // - Proposal will include 1800 transactions (no txn_limit reduction)
    // - Execution will stop early at reduced gas limit
    // - Many transactions will be skipped
    
    println!("Desynchronization detected:");
    println!("  Block will propose: 1800 transactions");
    println!("  Gas limit reduced to: {:?}", gas_backoff);
    println!("  Expected execution: ~{} transactions", 
        gas_backoff.unwrap() / 500); // Assuming avg 500 gas per txn
    println!("  Skipped transactions: ~{}", 
        1800 - (gas_backoff.unwrap() / 500));
}
```

**Notes:**
- The actual exploitation requires sustained transaction submission over 30 blocks
- The vulnerability is exacerbated during periods of variable network load
- All validators experience identical behavior (deterministic), preventing consensus splits
- The primary impact is performance degradation, not correctness violation

### Citations

**File:** config/src/config/consensus_config.rs (L150-187)
```rust
impl Default for ExecutionBackpressureTxnLimitConfig {
    fn default() -> Self {
        Self {
            lookback_config: ExecutionBackpressureLookbackConfig {
                num_blocks_to_look_at: 18,
                min_block_time_ms_to_activate: 50,
                min_blocks_to_activate: 4,
                metric: ExecutionBackpressureMetric::Percentile(0.5),
                target_block_time_ms: 90,
            },
            min_calibrated_txns_per_block: 30,
        }
    }
}

/// Execution backpressure which handles gas/s variance,
/// and adjusts gas limit to "recalibrate it" to wanted range.
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
pub struct ExecutionBackpressureGasLimitConfig {
    pub lookback_config: ExecutionBackpressureLookbackConfig,
    pub block_execution_overhead_ms: u64,
    pub min_calibrated_block_gas_limit: u64,
}

impl Default for ExecutionBackpressureGasLimitConfig {
    fn default() -> Self {
        Self {
            lookback_config: ExecutionBackpressureLookbackConfig {
                num_blocks_to_look_at: 30,
                min_block_time_ms_to_activate: 10,
                min_blocks_to_activate: 4,
                metric: ExecutionBackpressureMetric::Mean,
                target_block_time_ms: 90,
            },
            block_execution_overhead_ms: 10,
            min_calibrated_block_gas_limit: 2000,
        }
    }
```

**File:** config/src/config/consensus_config.rs (L190-194)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
pub struct ExecutionBackpressureConfig {
    pub txn_limit: Option<ExecutionBackpressureTxnLimitConfig>,
    pub gas_limit: Option<ExecutionBackpressureGasLimitConfig>,
}
```

**File:** consensus/src/liveness/proposal_generator.rs (L190-198)
```rust
    /// TODO: disable txn limit backoff and use only gas limit based backoff once execution pool is deployed.
    ///
    /// Until then, we need to compute wanted block size to create.
    /// Unfortunately, there is multiple layers where transactions are filtered.
    /// After deduping/reordering logic is applied, max_txns_to_execute limits the transactions
    /// passed to executor (`summary.payload_len` here), and then some are discarded for various
    /// reasons, which we approximate are cheaply ignored.
    /// For the rest, only `summary.to_commit` fraction of `summary.to_commit + summary.to_retry`
    /// was executed. And so assuming same discard rate, we scale `summary.payload_len` with it.
```

**File:** consensus/src/liveness/proposal_generator.rs (L347-359)
```rust
    pub fn get_execution_block_txn_and_gas_limit_backoff(
        &self,
        block_execution_times: &[ExecutionSummary],
        max_block_txns: u64,
        max_block_gas_limit: Option<u64>,
    ) -> (Option<u64>, Option<u64>) {
        let txn_limit_backoff =
            self.get_execution_block_size_backoff(block_execution_times, max_block_txns);
        let gas_limit_backoff = max_block_gas_limit.and_then(|max_block_gas_limit| {
            self.get_execution_gas_limit_backoff(block_execution_times, max_block_gas_limit)
        });
        (txn_limit_backoff, gas_limit_backoff)
    }
```

**File:** consensus/src/liveness/proposal_generator.rs (L652-672)
```rust
        let (validator_txns, mut payload) = self
            .payload_client
            .pull_payload(
                PayloadPullParameters {
                    max_poll_time: self.quorum_store_poll_time.saturating_sub(proposal_delay),
                    max_txns: max_block_txns,
                    max_txns_after_filtering: max_block_txns_after_filtering,
                    soft_max_txns_after_filtering: max_txns_from_block_to_execute
                        .unwrap_or(max_block_txns_after_filtering),
                    max_inline_txns: self.max_inline_txns,
                    maybe_optqs_payload_pull_params,
                    user_txn_filter: payload_filter,
                    pending_ordering,
                    pending_uncommitted_blocks: pending_blocks.len(),
                    recent_max_fill_fraction: max_fill_fraction,
                    block_timestamp: timestamp,
                },
                validator_txn_filter,
            )
            .await
            .context("Fail to retrieve payload")?;
```

**File:** consensus/src/liveness/proposal_generator.rs (L784-804)
```rust
        if let Some(num_blocks_to_look_at) =
            self.pipeline_backpressure_config.num_blocks_to_look_at()
        {
            let (txn_limit, gas_limit) = self
                .pipeline_backpressure_config
                .get_execution_block_txn_and_gas_limit_backoff(
                    &self
                        .block_store
                        .get_recent_block_execution_times(num_blocks_to_look_at),
                    self.max_block_txns_after_filtering,
                    self.max_block_gas_limit,
                );
            if let Some(txn_limit) = txn_limit {
                values_max_block_txns_after_filtering.push(txn_limit);
                execution_backpressure_applied = true;
            }
            block_gas_limit_override = gas_limit;
            if gas_limit.is_some() {
                execution_backpressure_applied = true;
            }
        }
```

**File:** aptos-move/block-executor/src/limit_processor.rs (L119-125)
```rust
    fn block_gas_limit(&self) -> Option<u64> {
        if self.block_gas_limit_override.is_some() {
            self.block_gas_limit_override
        } else {
            self.block_gas_limit_type.block_gas_limit()
        }
    }
```

**File:** aptos-move/block-executor/src/limit_processor.rs (L127-157)
```rust
    fn should_end_block(&mut self, mode: &str) -> bool {
        if let Some(per_block_gas_limit) = self.block_gas_limit() {
            // When the accumulated block gas of the committed txns exceeds
            // PER_BLOCK_GAS_LIMIT, early halt BlockSTM.
            let accumulated_block_gas = self.get_effective_accumulated_block_gas();
            if accumulated_block_gas >= per_block_gas_limit {
                counters::EXCEED_PER_BLOCK_GAS_LIMIT_COUNT.inc_with(&[mode]);
                info!(
                    "[BlockSTM]: execution ({}) early halted due to \
                    accumulated_block_gas {} >= PER_BLOCK_GAS_LIMIT {}",
                    mode, accumulated_block_gas, per_block_gas_limit,
                );
                return true;
            }
        }

        if let Some(per_block_output_limit) = self.block_gas_limit_type.block_output_limit() {
            let accumulated_output = self.get_accumulated_approx_output_size();
            if accumulated_output >= per_block_output_limit {
                counters::EXCEED_PER_BLOCK_OUTPUT_LIMIT_COUNT.inc_with(&[mode]);
                info!(
                    "[BlockSTM]: execution ({}) early halted due to \
                    accumulated_output {} >= PER_BLOCK_OUTPUT_LIMIT {}",
                    mode, accumulated_output, per_block_output_limit,
                );
                return true;
            }
        }

        false
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L2507-2514)
```rust
            if must_skip || block_limit_processor.should_end_block_sequential() || idx == num_txns {
                let mut has_reconfig = false;
                if let Some(last_output) = ret.last() {
                    if last_output.after_materialization()?.has_new_epoch_event() {
                        has_reconfig = true;
                    }
                }
                ret.resize_with(num_txns, E::Output::skip_output);
```
