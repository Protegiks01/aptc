# Audit Report

## Title
Memory Exhaustion via Unbounded Record Size in Backup Client Deserialization

## Summary
The `read_record_bytes()` function in the backup client allocates memory based on an untrusted u32 size field without validation before deserializing ledger info records. While the BCS deserializer itself handles malformed encoding safely, the pre-deserialization memory allocation can be exploited to cause denial of service if an attacker can control the backup service endpoint or compromise the backup service.

## Finding Description
The vulnerability exists in two layers:

**Layer 1: Unbounded Memory Allocation (Pre-BCS)** [1](#0-0) 

The `read_record_bytes()` function reads a u32 size field from the network stream and immediately allocates a buffer of that size without any bounds checking. An attacker controlling the backup service endpoint can send a size value up to 4GB (0xFFFFFFFF), causing immediate memory exhaustion.

**Layer 2: BCS Deserialization Resource Exhaustion** [2](#0-1) 

After the record bytes are read, `get_waypoint()` deserializes them using `bcs::from_bytes()`. The `LedgerInfoWithSignatures` structure contains nested unbounded vectors: [3](#0-2) 

The `ValidatorVerifier` contains an unbounded `Vec<ValidatorConsensusInfo>` with no size limit enforced during deserialization. Malformed BCS data could claim millions of validators, causing the BCS deserializer to attempt allocating gigabytes of memory.

**Exploitation Path:**
1. Attacker configures backup client to connect to malicious server OR compromises backup service [4](#0-3) 

2. Malicious endpoint returns crafted epoch ending ledger info records with:
   - Option A: Size field = 0x10000000 (256MB) causing immediate allocation failure
   - Option B: Valid size but BCS data claiming 10 million validators (1.2GB allocation)

3. Node crashes or becomes unresponsive due to memory exhaustion

**BCS Safety Analysis:**
The BCS library itself is memory-safe and returns `Result` types rather than panicking. However, it WILL attempt to allocate memory based on length prefixes in the serialized data:
- For `Vec<T>`, BCS reads a ULEB128 length and calls `Vec::with_capacity(len)`
- No built-in size limits unless using `from_bytes_with_limit()`
- Memory allocation failure can cause panic/OOM

**Partial Protection:** [5](#0-4) 

The `BitVec` type has a `MAX_BUCKETS` check in its deserializer, limiting it to 8192 bytes. However, other unbounded vectors in the data structure lack similar protections.

## Impact Explanation
**Severity: High** (per Aptos Bug Bounty: "Validator node slowdowns, API crashes")

This vulnerability can cause:
- **Validator node unavailability** during backup operations
- **Denial of service** preventing proper backup/restore functionality
- **Resource exhaustion** affecting node stability

However, this does NOT qualify as **Critical** severity because:
- No funds loss or consensus safety violation
- Requires attacker to control backup service endpoint or compromise node access
- Affects operator tools, not core consensus protocol

## Likelihood Explanation
**Likelihood: Low to Medium**

The attack requires one of the following:
1. **Node operator misconfiguration**: Pointing backup client to untrusted server (requires operator error)
2. **Backup service compromise**: Attacker gains access to backup service process (requires node access)
3. **Network position**: MITM attack on backup client connections (requires network access)

The backup service defaults to `localhost:6186` and is intended for internal use by node operators, not exposed to untrusted networks. However, the configurable nature of the endpoint address creates a potential attack surface if improperly configured.

**Mitigating factors:**
- Backup client is an operator tool, not protocol-critical
- Default configuration connects to localhost
- Requires privileged access or misconfiguration to exploit

**Aggravating factors:**
- No size validation whatsoever
- Could be chained with other vulnerabilities
- Defense-in-depth principle violated

## Recommendation
**Fix 1: Add size limit to read_record_bytes()**
```rust
const MAX_RECORD_SIZE: u32 = 10 * 1024 * 1024; // 10MB limit

async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    // ... existing code to read size_buf ...
    
    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?);
    
    // ADD SIZE CHECK
    ensure!(
        record_size <= MAX_RECORD_SIZE,
        "Record size {} exceeds maximum allowed size {}",
        record_size,
        MAX_RECORD_SIZE
    );
    
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }
    // ... rest of function ...
}
```

**Fix 2: Use size-limited BCS deserialization**
```rust
fn get_waypoint(record: &[u8], epoch: u64) -> Result<Waypoint> {
    const MAX_LEDGER_INFO_SIZE: usize = 5 * 1024 * 1024; // 5MB
    
    let li: LedgerInfoWithSignatures = 
        bcs::from_bytes_with_limit(record, MAX_LEDGER_INFO_SIZE)?;
    
    ensure!(/* ... existing validation ... */);
    Waypoint::new_epoch_boundary(li.ledger_info())
}
```

**Fix 3: Add validator count limit**
Add validation in `ValidatorVerifier::new()`:
```rust
const MAX_VALIDATORS: usize = 10_000;

pub fn new(validator_infos: Vec<ValidatorConsensusInfo>) -> Self {
    assert!(
        validator_infos.len() <= MAX_VALIDATORS,
        "Validator count {} exceeds maximum {}",
        validator_infos.len(),
        MAX_VALIDATORS
    );
    // ... existing code ...
}
```

## Proof of Concept
```rust
// PoC: Create malicious backup service response
use bytes::BytesMut;

fn create_malicious_record() -> Vec<u8> {
    let mut data = Vec::new();
    
    // Write size field claiming 256MB
    let malicious_size: u32 = 256 * 1024 * 1024;
    data.extend_from_slice(&malicious_size.to_be_bytes());
    
    // Don't need to actually send 256MB of data
    // The client will try to allocate the buffer immediately
    // causing memory exhaustion
    
    data
}

// Alternative: BCS-level attack
fn create_malicious_bcs_ledger_info() -> Vec<u8> {
    use bcs;
    
    // Create BCS data claiming huge validator set
    // BCS format: enum variant (1 byte) + fields
    let mut data = Vec::new();
    
    // LedgerInfoWithSignatures::V0 variant
    data.push(0);
    
    // ... craft BCS with length prefix claiming 10 million validators ...
    // This would cause Vec::with_capacity(10_000_000) during deserialization
    
    data
}
```

To test:
1. Stand up a malicious HTTP server serving `create_malicious_record()`
2. Configure backup client with `--backup-service-address http://malicious-server:8080`
3. Run epoch ending backup: `aptos-backup-cli backup-epoch-ending --start-epoch 0 --end-epoch 1`
4. Observe memory exhaustion and node crash

**Note**: Given the strict validation criteria and trust model considerations, this vulnerability's exploitability by a truly unprivileged attacker (without node access or configuration control) is **questionable**, as the backup client is an operator tool not exposed to untrusted parties in standard deployments.

### Citations

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-67)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
        if record_buf.is_empty() {
            bail!("Hit EOF when reading record.")
        }

        Ok(Some(record_buf.freeze()))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/backup.rs (L140-149)
```rust
    fn get_waypoint(record: &[u8], epoch: u64) -> Result<Waypoint> {
        let li: LedgerInfoWithSignatures = bcs::from_bytes(record)?;
        ensure!(
            li.ledger_info().epoch() == epoch,
            "Epoch not expected. expected: {}, actual: {}.",
            li.ledger_info().epoch(),
            epoch,
        );
        Waypoint::new_epoch_boundary(li.ledger_info())
    }
```

**File:** types/src/validator_verifier.rs (L137-161)
```rust
pub struct ValidatorVerifier {
    /// A vector of each validator's on-chain account address to its pubkeys and voting power.
    pub validator_infos: Vec<ValidatorConsensusInfo>,
    /// The minimum voting power required to achieve a quorum
    #[serde(skip)]
    quorum_voting_power: u128,
    /// Total voting power of all validators (cached from address_to_validator_info)
    #[serde(skip)]
    total_voting_power: u128,
    /// In-memory index of account address to its index in the vector, does not go through serde.
    #[serde(skip)]
    address_to_validator_index: HashMap<AccountAddress, usize>,
    /// With optimistic signature verification, we aggregate all the votes on a message and verify at once.
    /// We use this optimization for votes, order votes, commit votes, signed batch info. If the verification fails,
    /// we verify each vote individually, which is a time consuming process. These are the list of voters that have
    /// submitted bad votes that has resulted in having to verify each vote individually. Further votes by these validators
    /// will be verified individually bypassing the optimization.
    #[serde(skip)]
    #[derivative(PartialEq = "ignore")]
    pessimistic_verify_set: DashSet<AccountAddress>,
    /// This is the feature flag indicating whether the optimistic signature verification feature is enabled.
    #[serde(skip)]
    #[derivative(PartialEq = "ignore")]
    optimistic_sig_verification: bool,
}
```

**File:** storage/backup/backup-cli/src/utils/backup_service_client.rs (L22-31)
```rust
#[derive(Parser)]
pub struct BackupServiceClientOpt {
    #[clap(
        long = "backup-service-address",
        default_value = "http://localhost:6186",
        help = "Backup service address. By default a Aptos Node runs the backup service serving \
        on tcp port 6186 to localhost only."
    )]
    pub address: String,
}
```

**File:** crates/aptos-bitvec/src/lib.rs (L235-252)
```rust
impl<'de> Deserialize<'de> for BitVec {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        #[serde(rename = "BitVec")]
        struct RawData {
            #[serde(with = "serde_bytes")]
            inner: Vec<u8>,
        }
        let v = RawData::deserialize(deserializer)?.inner;
        if v.len() > MAX_BUCKETS {
            return Err(D::Error::custom(format!("BitVec too long: {}", v.len())));
        }
        Ok(BitVec { inner: v })
    }
}
```
