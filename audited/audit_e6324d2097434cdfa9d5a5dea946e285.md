# Audit Report

## Title
Timeout Timer Reset Before Message Validation Allows Malicious Validators to Bypass Subscription Timeout Mechanism

## Summary
The consensus observer's timeout mechanism can be exploited by malicious validators to maintain subscriptions indefinitely by sending invalid messages. The timeout timer is reset upon message receipt (before validation), allowing attackers to bypass timeout checks while preventing legitimate slow responses from being tolerated.

## Finding Description
The vulnerability exists in the message processing flow where subscription timeout tracking is updated before message content validation occurs.

The attack flow:

1. When a message is received, `process_network_message()` first calls `verify_message_for_subscription()` [1](#0-0) 

2. This method updates the timeout timer by calling `update_last_message_receive_time()` regardless of message validity [2](#0-1) 

3. The timeout timer update occurs in `update_last_message_receive_time()` which resets `last_message_receive_time` to the current time [3](#0-2) 

4. **Only after** the timer is reset does message validation occur, including signature verification and digest checks [4](#0-3) 

5. For example, BlockPayload messages have their digests verified and signatures checked **after** the timer reset [5](#0-4) 

6. Invalid messages are dropped, but the timer was already reset, so the subscription remains healthy

The timeout check compares elapsed time since `last_message_receive_time` against `max_subscription_timeout_ms` (default 15 seconds) [6](#0-5) 

**Attack Scenario:**
A malicious validator can:
- Establish a subscription with a consensus observer
- Send rapid invalid BlockPayload messages with incorrect digests or forged signatures
- Each invalid message resets the timeout timer before being validated
- All messages fail validation and are dropped, but subscription never times out
- Observer is stuck with a useless subscription that passes all health checks

Meanwhile, a legitimate validator sending valid but slower responses (e.g., due to network latency or computation time) would timeout based on the 15-second default threshold.

This breaks the security invariant that subscriptions should timeout if they are not providing useful (valid) consensus data.

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria:

- **Validator node slowdowns**: Observers become stuck with malicious subscriptions that provide no valid consensus data, preventing them from making progress
- **Significant protocol violations**: The timeout mechanism is designed to ensure observers maintain optimal subscriptions; this bypass defeats that protection
- **Denial of Service**: Observers cannot switch to better validators because malicious subscriptions pass health checks despite providing no useful data

The attack prevents the consensus observer from fulfilling its core function of efficiently synchronizing with the network by maintaining optimal peer subscriptions.

## Likelihood Explanation
**Likelihood: HIGH**

- **Easy to execute**: Attacker only needs to establish a subscription and send malformed messages
- **No special privileges required**: Any peer that can establish a subscription can exploit this
- **Difficult to detect**: The subscription appears healthy in all metrics except it provides no valid data
- **Affects all consensus observers**: The vulnerability exists in the core message processing logic used by all observer nodes
- **No rate limiting**: Invalid messages can be sent as rapidly as desired to ensure timer never expires

## Recommendation
Move the timeout timer update to occur **after** message validation succeeds. The timer should only be reset when messages that contribute to consensus progress are received.

**Fixed Code Structure:**

In `consensus_observer.rs`, remove the early timer reset from `verify_message_for_subscription()` and instead update it after validation passes in each message processing function:

```rust
// In process_block_payload_message, after successful verification:
if verified_payload {
    self.subscription_manager
        .update_message_receive_time(peer_network_id);
    // ... rest of processing
}

// Similar updates in process_ordered_block_message, 
// process_commit_decision_message, etc.
```

Modify `subscription_manager.rs` to separate the subscription verification from the timer update:

```rust
pub fn verify_message_for_subscription(
    &self,
    message_sender: PeerNetworkId,
) -> Result<(), Error> {
    // Only check subscription exists, don't update timer
    if self.active_observer_subscriptions.lock().contains_key(&message_sender) {
        return Ok(());
    }
    // ... error handling
}

pub fn update_message_receive_time(&mut self, peer: PeerNetworkId) {
    if let Some(subscription) = self.active_observer_subscriptions.lock().get_mut(&peer) {
        subscription.update_last_message_receive_time();
    }
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_invalid_messages_bypass_timeout() {
    // Create a consensus observer with 1 second timeout
    let consensus_observer_config = ConsensusObserverConfig {
        max_subscription_timeout_ms: 1000, // 1 second timeout
        max_subscription_sync_timeout_ms: 100_000, // Large value to isolate timeout issue
        ..ConsensusObserverConfig::default()
    };

    let time_service = TimeService::mock();
    let peer_network_id = PeerNetworkId::random();
    let mut subscription = ConsensusObserverSubscription::new(
        consensus_observer_config,
        Arc::new(MockDatabaseReader::new()),
        peer_network_id,
        time_service.clone(),
    );

    // Create a subscription manager
    let mut manager = SubscriptionManager::new(
        consensus_observer_client,
        consensus_observer_config,
        None,
        Arc::new(MockDatabaseReader::new()),
        time_service.clone(),
    );

    // Add subscription to manager
    manager.active_observer_subscriptions.lock()
        .insert(peer_network_id, subscription);

    // Simulate receiving invalid messages every 500ms
    let mock_time = time_service.into_mock();
    for i in 0..5 {
        // Advance time by 500ms (less than 1000ms timeout)
        mock_time.advance(Duration::from_millis(500));
        
        // Simulate receiving a message (timer gets reset)
        manager.verify_message_for_subscription(peer_network_id).unwrap();
        
        // In real scenario, message would fail validation here
        // But timer was already reset above
    }

    // Total elapsed time: 2500ms (should have timed out after 1000ms)
    // But subscription is still healthy because timer kept getting reset
    let peers_and_metadata = HashMap::new();
    let result = manager.check_subscription_health(
        &peers_and_metadata,
        peer_network_id,
        false
    );

    // Subscription should have timed out but doesn't due to invalid message resets
    assert!(result.is_ok(), "Subscription should have timed out but didn't");
}
```

**Notes:**
The vulnerability exists because the system assumes all messages from subscribed peers are valuable for timeout purposes, but malicious peers can send invalid messages to game this assumption. The fix ensures only messages that pass validation reset the timeout timer, properly enforcing the invariant that subscriptions must provide useful consensus data or be terminated.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L385-413)
```rust
        // Verify the block payload digests
        if let Err(error) = block_payload.verify_payload_digests() {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify block payload digests! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                    block_payload.block(), peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
            return;
        }

        // If the payload is for the current epoch, verify the proof signatures
        let epoch_state = self.get_epoch_state();
        let verified_payload = if block_epoch == epoch_state.epoch {
            // Verify the block proof signatures
            if let Err(error) = block_payload.verify_payload_signatures(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify block payload signatures! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                        block_payload.block(), peer_network_id, error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
                return;
            }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L579-581)
```rust
        if let Err(error) = self
            .subscription_manager
            .verify_message_for_subscription(peer_network_id)
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L600-632)
```rust
        match message {
            ConsensusObserverDirectSend::OrderedBlock(ordered_block) => {
                self.process_ordered_block_message(
                    peer_network_id,
                    message_received_time,
                    ordered_block,
                )
                .await;
            },
            ConsensusObserverDirectSend::CommitDecision(commit_decision) => {
                self.process_commit_decision_message(
                    peer_network_id,
                    message_received_time,
                    commit_decision,
                );
            },
            ConsensusObserverDirectSend::BlockPayload(block_payload) => {
                self.process_block_payload_message(
                    peer_network_id,
                    message_received_time,
                    block_payload,
                )
                .await;
            },
            ConsensusObserverDirectSend::OrderedBlockWithWindow(ordered_block_with_window) => {
                self.process_ordered_block_with_window_message(
                    peer_network_id,
                    message_received_time,
                    ordered_block_with_window,
                )
                .await;
            },
        }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L373-374)
```rust
            // Update the last message receive time and return early
            active_subscription.update_last_message_receive_time();
```

**File:** consensus/src/consensus_observer/observer/subscription.rs (L166-182)
```rust
    fn check_subscription_timeout(&self) -> Result<(), Error> {
        // Calculate the duration since the last message
        let time_now = self.time_service.now();
        let duration_since_last_message = time_now.duration_since(self.last_message_receive_time);

        // Check if the subscription has timed out
        if duration_since_last_message
            > Duration::from_millis(self.consensus_observer_config.max_subscription_timeout_ms)
        {
            return Err(Error::SubscriptionTimeout(format!(
                "Subscription to peer: {} has timed out! No message received for: {:?}",
                self.peer_network_id, duration_since_last_message
            )));
        }

        Ok(())
    }
```

**File:** consensus/src/consensus_observer/observer/subscription.rs (L230-232)
```rust
    pub fn update_last_message_receive_time(&mut self) {
        self.last_message_receive_time = self.time_service.now();
    }
```
