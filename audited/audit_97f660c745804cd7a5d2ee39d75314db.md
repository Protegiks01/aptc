# Audit Report

## Title
Memory Exhaustion via Unbounded Concurrent Task Spawning in Mempool Transaction Processing

## Summary
Setting `shared_mempool_max_concurrent_inbound_syncs` to `usize::MAX` allows unlimited concurrent transaction processing tasks to be spawned, leading to memory exhaustion and node crash when malicious peers flood the node with transaction broadcasts.

## Finding Description

The `shared_mempool_max_concurrent_inbound_syncs` configuration parameter controls the maximum number of concurrent worker tasks that can process incoming mempool transactions. This value is used to initialize a `BoundedExecutor` with a semaphore-based concurrency limit. [1](#0-0) 

The default value is 4 (16 for Validator Full Nodes), but the configuration has no validation to prevent setting it to extreme values like `usize::MAX`. [2](#0-1) 

The configuration sanitizer is essentially empty with a TODO comment, providing no bounds checking: [3](#0-2) 

In the mempool coordinator, this value is directly used to create the `BoundedExecutor`: [4](#0-3) 

The `BoundedExecutor` uses a Tokio `Semaphore` with the provided capacity: [5](#0-4) 

When spawning tasks, the executor acquires a permit (blocking if none available) then spawns the task: [6](#0-5) 

**The Attack Path:**

1. An attacker controls multiple malicious peers (up to the `MAX_INBOUND_CONNECTIONS` limit of 100)
2. Each peer continuously broadcasts batches of transactions to the victim node
3. For each incoming transaction broadcast message, the coordinator spawns a processing task: [7](#0-6) 

4. With `shared_mempool_max_concurrent_inbound_syncs = usize::MAX`, the semaphore permits are effectively unlimited
5. The `acquire_permit().await` call never blocks, allowing tasks to spawn without limit
6. Each task consumes significant memory during processing:
   - Transaction batch data (up to 300 transactions or ~60MB per batch)
   - Database state view objects
   - VM validation results allocated in parallel
   - Tokio task overhead and stack space [8](#0-7) 

7. Tasks accumulate faster than they complete (since validation and storage I/O are slow)
8. Memory consumption grows unbounded until the node experiences OOM and crashes

The network channel buffer (`max_network_channel_size` = 1024) and client events buffer (1024) provide minimal protection because:
- The coordinator continuously drains these channels in a tight loop
- Task spawning is nearly instantaneous (just acquiring a permit)
- The coordinator doesn't wait for tasks to complete before processing the next message
- With 100 malicious peers sending continuously, the coordinator can spawn thousands of tasks per second

## Impact Explanation

This is a **HIGH severity** vulnerability per Aptos bug bounty criteria:

1. **Validator node slowdowns**: Memory pressure causes severe performance degradation before the crash
2. **API crashes**: The node becomes unresponsive and eventually crashes due to OOM
3. **Availability impact**: Crashed nodes cannot participate in consensus, reducing network capacity

While not directly causing loss of funds or consensus safety violations, this enables a denial-of-service attack that can:
- Force validator nodes offline, reducing network decentralization
- Crash multiple nodes simultaneously if many operators use the same misconfigured value
- Disrupt API services and transaction processing

The attack requires no special privileges—any network peer can send transaction broadcasts. The cost to the attacker is minimal (just network bandwidth), while the impact on victim nodes is severe.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The vulnerability requires:
1. A node operator to explicitly set `shared_mempool_max_concurrent_inbound_syncs` to an extremely high value (like `usize::MAX`)
2. An attacker to identify such misconfigured nodes and flood them with transaction broadcasts

While setting the value to `usize::MAX` may seem unlikely, operators might:
- Misunderstand the parameter's purpose and set it high for "better performance"
- Copy misconfigured settings from untrusted sources
- Be targeted through social engineering to apply malicious configurations

The lack of configuration validation makes this easier to occur accidentally or through manipulation.

Once misconfigured, exploitation is trivial—any peer can send transaction broadcasts to trigger the vulnerability.

## Recommendation

Add strict validation to the `MempoolConfig::sanitize()` method to enforce reasonable bounds:

```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        const MAX_ALLOWED_INBOUND_SYNCS: usize = 1024; // Reasonable upper bound
        
        if self.shared_mempool_max_concurrent_inbound_syncs == 0 {
            return Err(Error::ConfigSanitizerFailed(
                "mempool".to_string(),
                "shared_mempool_max_concurrent_inbound_syncs must be greater than 0".to_string(),
            ));
        }
        
        if self.shared_mempool_max_concurrent_inbound_syncs > MAX_ALLOWED_INBOUND_SYNCS {
            return Err(Error::ConfigSanitizerFailed(
                "mempool".to_string(),
                format!(
                    "shared_mempool_max_concurrent_inbound_syncs ({}) exceeds maximum allowed value ({})",
                    self.shared_mempool_max_concurrent_inbound_syncs,
                    MAX_ALLOWED_INBOUND_SYNCS
                ),
            ));
        }
        
        Ok(())
    }
}
```

Additionally, consider implementing per-peer rate limiting on incoming transaction broadcasts to provide defense-in-depth.

## Proof of Concept

```rust
// File: mempool/src/tests/memory_exhaustion_test.rs
#[tokio::test]
#[ignore] // Run explicitly due to memory consumption
async fn test_unbounded_task_spawning_memory_exhaustion() {
    use futures::channel::mpsc;
    use std::sync::Arc;
    use tokio::runtime::Runtime;
    use aptos_bounded_executor::BoundedExecutor;
    use std::sync::atomic::{AtomicUsize, Ordering};
    
    // Create a BoundedExecutor with usize::MAX permits
    let rt = Runtime::new().unwrap();
    let executor = rt.handle().clone();
    let bounded_executor = BoundedExecutor::new(usize::MAX, executor);
    
    let task_count = Arc::new(AtomicUsize::new(0));
    let task_count_clone = task_count.clone();
    
    // Simulate malicious peer flooding with transaction batches
    for batch_id in 0..10000 {
        let count = task_count_clone.clone();
        
        // Each spawn acquires a permit (never blocks with usize::MAX)
        bounded_executor.spawn(async move {
            count.fetch_add(1, Ordering::Relaxed);
            
            // Simulate transaction processing with memory allocation
            let _large_allocation = vec![0u8; 1024 * 1024]; // 1MB per task
            
            // Simulate slow processing (DB I/O, validation)
            tokio::time::sleep(tokio::time::Duration::from_secs(10)).await;
            
            count.fetch_sub(1, Ordering::Relaxed);
        }).await;
        
        // With usize::MAX permits, we can spawn 10000 tasks nearly instantly
        // Each consuming 1MB = 10GB total memory
        if batch_id % 100 == 0 {
            println!("Spawned {} tasks, concurrent count: {}", 
                     batch_id, task_count.load(Ordering::Relaxed));
        }
    }
    
    // At this point, thousands of tasks are running concurrently
    // causing memory exhaustion
    println!("Final concurrent tasks: {}", task_count.load(Ordering::Relaxed));
    
    // In a real attack, this would cause OOM before completion
}
```

To reproduce in a live environment:
1. Modify `node.yaml` to set `mempool.shared_mempool_max_concurrent_inbound_syncs: 18446744073709551615`
2. Start the node
3. Use multiple peers to continuously send `BroadcastTransactionsRequest` messages with large transaction batches
4. Monitor memory consumption—it will grow unbounded until OOM

## Notes

This vulnerability demonstrates a critical gap in configuration validation. The `BoundedExecutor` correctly implements semaphore-based concurrency limiting, but the configuration layer allows nonsensical values that defeat the protection mechanism. Defense-in-depth requires validation at the configuration layer, not just relying on correct usage of internal primitives.

### Citations

**File:** config/src/config/mempool_config.rs (L69-69)
```rust
    pub shared_mempool_max_concurrent_inbound_syncs: usize,
```

**File:** config/src/config/mempool_config.rs (L116-116)
```rust
            shared_mempool_max_concurrent_inbound_syncs: 4,
```

**File:** config/src/config/mempool_config.rs (L176-184)
```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        Ok(()) // TODO: add reasonable verifications
    }
}
```

**File:** mempool/src/shared_mempool/coordinator.rs (L92-93)
```rust
    let workers_available = smp.config.shared_mempool_max_concurrent_inbound_syncs;
    let bounded_executor = BoundedExecutor::new(workers_available, executor.clone());
```

**File:** mempool/src/shared_mempool/coordinator.rs (L332-341)
```rust
    bounded_executor
        .spawn(tasks::process_transaction_broadcast(
            smp_clone,
            transactions,
            message_id,
            timeline_state,
            peer,
            task_start_timer,
        ))
        .await;
```

**File:** crates/bounded-executor/src/executor.rs (L25-30)
```rust
    pub fn new(capacity: usize, executor: Handle) -> Self {
        let semaphore = Arc::new(Semaphore::new(capacity));
        Self {
            semaphore,
            executor,
        }
```

**File:** crates/bounded-executor/src/executor.rs (L45-52)
```rust
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor.spawn(future_with_permit(future, permit))
    }
```

**File:** mempool/src/shared_mempool/tasks.rs (L328-333)
```rust
    let start_storage_read = Instant::now();
    let state_view = smp
        .db
        .latest_state_checkpoint_view()
        .expect("Failed to get latest state checkpoint view.");

```
