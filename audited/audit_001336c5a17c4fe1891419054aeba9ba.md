# Audit Report

## Title
Memory Exhaustion in Batch Requester Due to Unbounded Future Accumulation with Misconfigured Parameters

## Summary
The `request_batch()` function in `BatchRequester` can accumulate an unbounded number of pending RPC futures when `batch_request_num_peers` and `batch_request_retry_limit` configuration parameters are set to high values. While this creates a potential memory exhaustion vector, the vulnerability does not meet the exploitability criteria for a valid security finding as it requires validator operator misconfiguration rather than external attacker exploitation.

## Finding Description
The `request_batch()` function creates a `FuturesUnordered` collection and periodically adds new RPC request futures to it based on configuration parameters: [1](#0-0) 

The number of futures added is controlled by `BatchRequesterState::next_request_peers()`, which returns peers until `retry_limit` is exceeded: [2](#0-1) 

The total number of futures that can be added equals `retry_limit × request_num_peers`. With default configuration values: [3](#0-2) 

This results in maximum 10 × 5 = 50 futures per batch request, which is manageable. However, no validation exists to prevent extreme values: [4](#0-3) 

Multiple batch requests can execute concurrently for different digests: [5](#0-4) 

With up to 20 batches per proposal and misconfigured values (e.g., `retry_limit=100`, `request_num_peers=100`), this could theoretically accumulate 20 × 100 × 100 = 200,000 pending futures.

## Impact Explanation
This issue fails to meet **Medium Severity** criteria because:

1. **Default configuration is safe**: The default values (retry_limit=10, request_num_peers=5) result in only 50 futures per request, which is manageable.

2. **Requires operator misconfiguration**: The vulnerability only manifests when a validator operator intentionally sets extreme configuration values in their node's local config file.

3. **Not exploitable by unprivileged attackers**: External attackers cannot modify a validator's configuration parameters. While malicious peers could be slow/unresponsive to exacerbate accumulation, they cannot trigger severe memory exhaustion with default or reasonable configurations.

4. **Self-inflicted impact**: Only the misconfigured node would be affected, not the broader network.

## Likelihood Explanation
**Likelihood: Very Low**

- Requires validator operator to deviate significantly from safe defaults
- No evidence that operators commonly set extreme values
- Node-local configuration, not network-wide parameters
- Impact limited to self-inflicted service degradation

## Recommendation
Despite not meeting exploitability criteria, adding defensive validation would improve robustness:

```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let config = &node_config.consensus.quorum_store;

        // Validate batch request parameters
        let max_concurrent_futures = config.batch_request_retry_limit 
            * config.batch_request_num_peers;
        if max_concurrent_futures > 1000 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("batch_request_retry_limit ({}) * batch_request_num_peers ({}) exceeds safe limit of 1000 concurrent futures",
                    config.batch_request_retry_limit,
                    config.batch_request_num_peers
                )
            ));
        }

        // Existing validations
        Self::sanitize_send_recv_batch_limits(&sanitizer_name, config)?;
        Self::sanitize_batch_total_limits(&sanitizer_name, config)?;

        Ok(())
    }
}
```

## Proof of Concept
Not applicable - this issue requires validator operator access to modify configuration files, which is outside the scope of unprivileged attacker exploitation scenarios.

---

## Notes

**This finding does NOT constitute a valid bug bounty submission** because it fails the validation checklist requirement: "Exploitable by unprivileged attacker (no validator insider access required)."

The technical analysis confirms that:
- ✓ Memory accumulation is possible with extreme configuration values
- ✓ No validation exists in the config sanitizer for these parameters
- ✗ Default values are safe (50 futures max per request)
- ✗ Requires validator operator misconfiguration
- ✗ Cannot be triggered by external unprivileged attackers

While adding configuration validation would improve defensive robustness, the lack of validation does not constitute an exploitable security vulnerability under the Aptos bug bounty criteria, as validator operators are considered trusted actors per the trust model.

### Citations

**File:** consensus/src/quorum_store/batch_requester.rs (L40-64)
```rust
    fn next_request_peers(&mut self, num_peers: usize) -> Option<Vec<PeerId>> {
        let signers = self.signers.lock();
        if self.num_retries == 0 {
            let mut rng = rand::thread_rng();
            // make sure nodes request from the different set of nodes
            self.next_index = rng.r#gen::<usize>() % signers.len();
            counters::SENT_BATCH_REQUEST_COUNT.inc_by(num_peers as u64);
        } else {
            counters::SENT_BATCH_REQUEST_RETRY_COUNT.inc_by(num_peers as u64);
        }
        if self.num_retries < self.retry_limit {
            self.num_retries += 1;
            let ret = signers
                .iter()
                .cycle()
                .skip(self.next_index)
                .take(num_peers)
                .cloned()
                .collect();
            self.next_index = (self.next_index + num_peers) % signers.len();
            Some(ret)
        } else {
            None
        }
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L117-133)
```rust
        monitor!("batch_request", {
            let mut interval = time::interval(retry_interval);
            let mut futures = FuturesUnordered::new();
            let request = BatchRequest::new(my_peer_id, epoch, digest);
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
                    },
```

**File:** config/src/config/quorum_store_config.rs (L127-130)
```rust
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
```

**File:** config/src/config/quorum_store_config.rs (L253-271)
```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Sanitize the send/recv batch limits
        Self::sanitize_send_recv_batch_limits(
            &sanitizer_name,
            &node_config.consensus.quorum_store,
        )?;

        // Sanitize the batch total limits
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L663-720)
```rust
    fn get_or_fetch_batch(
        &self,
        batch_info: BatchInfo,
        responders: Vec<PeerId>,
    ) -> Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>> {
        let mut responders = responders.into_iter().collect();

        self.inflight_fetch_requests
            .lock()
            .entry(*batch_info.digest())
            .and_modify(|fetch_unit| {
                fetch_unit.responders.lock().append(&mut responders);
            })
            .or_insert_with(|| {
                let responders = Arc::new(Mutex::new(responders));
                let responders_clone = responders.clone();

                let inflight_requests_clone = self.inflight_fetch_requests.clone();
                let batch_store = self.batch_store.clone();
                let requester = self.batch_requester.clone();

                let fut = async move {
                    let batch_digest = *batch_info.digest();
                    defer!({
                        inflight_requests_clone.lock().remove(&batch_digest);
                    });
                    // TODO(ibalajiarun): Support V2 batch
                    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
                        Ok(value.take_payload().expect("Must have payload"))
                    } else {
                        // Quorum store metrics
                        counters::MISSED_BATCHES_COUNT.inc();
                        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
                        Ok(payload)
                    }
                }
                .boxed()
                .shared();

                tokio::spawn(fut.clone());

                BatchFetchUnit {
                    responders: responders_clone,
                    fut,
                }
            })
```
