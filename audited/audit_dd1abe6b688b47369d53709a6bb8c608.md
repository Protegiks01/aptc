# Audit Report

## Title
Arkworks FFT Domain Deserialization Does Not Validate Domain Consistency, Creating Upgrade Path Vulnerability Risk

## Summary
The `ShamirThresholdConfig` used in batch threshold encryption for consensus secret sharing does not serialize its FFT evaluation domain, instead recomputing it on deserialization. While the current arkworks 0.5.0 implementation produces deterministic domains, there is no validation mechanism to detect if a future library upgrade changes FFT domain generation, which could cause share reconstruction failures and consensus disruptions.

## Finding Description

The arkworks-based Shamir secret sharing implementation stores threshold configurations that are critical for consensus operations. The vulnerability exists in how the FFT domain is handled during serialization/deserialization: [1](#0-0) 

The `domain` field is marked with `#[serde(skip)]`, meaning it's never serialized. During deserialization, the domain is recomputed from scratch: [2](#0-1) 

This arkworks-based configuration is used in production for batch threshold encryption in consensus: [3](#0-2) [4](#0-3) 

Secret shares are generated by evaluating polynomials at FFT domain points: [5](#0-4) 

Reconstruction uses Lagrange interpolation with coefficients computed from the domain: [6](#0-5) 

The critical issue: there is **no validation** that the recomputed domain matches the original domain used when shares were created. The codebase assumes arkworks will never change `Radix2EvaluationDomain::new(n)` behavior across versions, with no defensive coding.

## Impact Explanation

**Current Status**: No active exploit exists. The current arkworks 0.5.0 implementation uses deterministic domain generation based on field constants. [7](#0-6) 

**Potential Future Impact (if arkworks changes)**:
- **High Severity**: Different validators upgrading at different times could have incompatible share reconstructions, causing consensus liveness failures
- Batch encryption decryption failures in consensus pipeline
- Inability to reconstruct secrets from previously generated shares
- Potential network partition if subset of validators cannot process transactions

However, this does **not** meet Critical severity because:
- It requires external library changes outside attacker control
- Does not enable theft/minting of funds
- Does not allow safety violations in current state
- Recovery possible through coordinated upgrades

## Likelihood Explanation

**Current Likelihood**: Very Low
- Requires future arkworks version to change FFT domain generation algorithm
- Requires Aptos team to upgrade to that version
- Arkworks maintainers are unlikely to make breaking changes to core cryptographic primitives

**Attack Vector**: None for unprivileged attackers
- Cannot be triggered without library upgrade
- Cannot be exploited by malicious transactions or validators
- Requires changes to dependency management outside blockchain protocol

This is a **latent design risk**, not an active vulnerability.

## Recommendation

Implement domain validation and versioning:

1. **Serialize domain parameters** or add version field to `ShamirThresholdConfig`:
```rust
#[derive(Debug, Clone, Copy, Serialize, PartialEq, Eq)]
pub struct ShamirThresholdConfig<F: FftField> {
    pub n: usize,
    pub t: usize,
    // Add version field
    pub domain_version: u32,
    #[serde(skip)]
    pub domain: Radix2EvaluationDomain<F>,
}
```

2. **Validate domain consistency** on deserialization:
```rust
impl<'de, F: FftField> Deserialize<'de> for ShamirThresholdConfig<F> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        // ... deserialize n, t, domain_version
        let domain = Radix2EvaluationDomain::new(n)
            .ok_or_else(|| serde::de::Error::custom(format!("Invalid domain size: {}", n)))?;
        
        // Validate domain hasn't changed from expected version
        if domain_version != EXPECTED_DOMAIN_VERSION {
            return Err(serde::de::Error::custom(
                "Incompatible FFT domain version"
            ));
        }
        
        Ok(ShamirThresholdConfig { n, t, domain_version, domain })
    }
}
```

3. **Add migration path** for future arkworks upgrades with domain changes

## Proof of Concept

This vulnerability cannot be demonstrated with a practical PoC because:
1. It requires modifying arkworks library internals
2. No current exploit path exists
3. Would require simulating future library behavior changes

**Hypothetical demonstration** (not executable):
```rust
// This would only work if arkworks changed their implementation
#[test]
fn test_domain_incompatibility_after_upgrade() {
    // Step 1: Create shares with arkworks v0.5.0
    let config_v1 = ShamirThresholdConfig::new(3, 5);
    let shares = config_v1.share(&coeffs);
    let serialized = serde_json::to_string(&config_v1).unwrap();
    
    // Step 2: Simulate arkworks v0.6.0 with different domain generation
    // (This is hypothetical - cannot actually do this)
    let config_v2: ShamirThresholdConfig = 
        serde_json::from_str(&serialized).unwrap();
    
    // Step 3: Try to reconstruct - would fail if domains differ
    let result = reconstruct(&config_v2, &shares);
    // In vulnerable scenario: result would be incorrect or error
}
```

---

**Critical Assessment**: While this is a valid engineering concern that should be addressed to prevent future issues, it **does not constitute an exploitable vulnerability** under bug bounty criteria because:
- No unprivileged attacker can trigger this
- Requires external dependency changes outside protocol control
- No current security impact exists
- Mitigation requires proactive engineering, not emergency patching

This should be tracked as a **technical debt/hardening issue** rather than a security vulnerability.

### Citations

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L42-53)
```rust
#[derive(Debug, Clone, Copy, Serialize, PartialEq, Eq)]
pub struct ShamirThresholdConfig<F: FftField> {
    /// Total number of participants (shares)
    pub n: usize,
    /// Threshold number of shares required to reconstruct the secret. Note that in
    /// MPC literature `t` usually denotes the maximal adversary threshold, so `t + 1`
    /// shares would be required to reconstruct the secret
    pub t: usize,
    /// Used for FFT-based polynomial operations. Recomputed from `n` on deserialize
    #[serde(skip)]
    pub domain: Radix2EvaluationDomain<F>,
}
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L105-123)
```rust
impl<'de, F: FftField> Deserialize<'de> for ShamirThresholdConfig<F> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct BasicFields {
            n: usize,
            t: usize,
        }

        let BasicFields { n, t } = BasicFields::deserialize(deserializer)?;

        let domain = Radix2EvaluationDomain::new(n) // Note that `new(n)` internally does `n.next_power_of_two()`
            .ok_or_else(|| serde::de::Error::custom(format!("Invalid domain size: {}", n)))?;

        Ok(ShamirThresholdConfig { n, t, domain })
    }
}
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L253-290)
```rust
    pub fn lagrange_for_subset(&self, indices: &[usize]) -> Vec<F> {
        // Step 0: check that subset is large enough
        assert!(
            indices.len() >= self.t,
            "subset size {} is smaller than threshold t={}",
            indices.len(),
            self.t
        );

        let xs_vec: Vec<F> = indices.iter().map(|i| self.domain.element(*i)).collect();

        // Step 1: compute poly w/ roots at all x in xs, compute eval at 0
        let vanishing_poly = vanishing_poly::from_roots(&xs_vec);
        let vanishing_poly_at_0 = vanishing_poly.coeffs[0]; // vanishing_poly(0) = const term

        // Step 2 (numerators): for each x in xs, divide poly eval from step 1 by (-x) using batch inversion
        let mut neg_xs: Vec<F> = xs_vec.iter().map(|&x| -x).collect();
        batch_inversion(&mut neg_xs);
        let numerators: Vec<F> = neg_xs
            .iter()
            .map(|&inv_neg_x| vanishing_poly_at_0 * inv_neg_x)
            .collect();

        // Step 3a (denominators): Compute derivative of poly from step 1, and its evaluations
        let derivative = vanishing_poly.differentiate();
        let derivative_evals = derivative.evaluate_over_domain(self.domain).evals; // TODO: with a filter perhaps we don't have to store all evals, but then batch inversion becomes a bit more tedious

        // Step 3b: Only keep the relevant evaluations, then perform a batch inversion
        let mut denominators: Vec<F> = indices.iter().map(|i| derivative_evals[*i]).collect();
        batch_inversion(&mut denominators);

        // Step 4: compute Lagrange coefficients
        numerators
            .into_iter()
            .zip(denominators)
            .map(|(numerator, denom_inv)| numerator * denom_inv)
            .collect()
    }
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L292-303)
```rust
    /// This method creates `n` shares of a secret using
    /// a `(t, n)` Shamir Secret Sharing scheme:
    /// 1. A random polynomial of degree `t-1` is given as input. We are deliberately generating
    /// it outside of this file so it won't depend on the specific version of the `rand` crate.
    /// 2. The polynomial is evaluated over the `domain` using FFT to produce all evaluations,
    ///    which are subsequently trunked.
    pub fn share(&self, coeffs: &[F]) -> Vec<ShamirShare<F>> {
        debug_assert_eq!(coeffs.len(), self.t);
        let evals = self.domain.fft(coeffs);
        (0..self.n).map(|i| self.get_player(i)).zip(evals).collect()
    }
}
```

**File:** crates/aptos-batch-encryption/src/schemes/fptx_weighted.rs (L211-227)
```rust
impl BatchThresholdEncryption for FPTXWeighted {
    type Ciphertext = StandardCiphertext;
    type DecryptionKey = BIBEDecryptionKey;
    type DecryptionKeyShare = WeightedBIBEDecryptionKeyShare;
    type Digest = Digest;
    type DigestKey = DigestKey;
    type EncryptionKey = EncryptionKey;
    type EvalProof = EvalProof;
    type EvalProofs = EvalProofs;
    type EvalProofsPromise = EvalProofsPromise;
    type Id = Id;
    type MasterSecretKeyShare = WeightedBIBEMasterSecretKeyShare;
    type PreparedCiphertext = PreparedCiphertext;
    type Round = u64;
    type SubTranscript = aptos_dkg::pvss::chunky::WeightedSubtranscript<Pairing>;
    type ThresholdConfig = aptos_crypto::weighted_config::WeightedConfigArkworks<Fr>;
    type VerificationKey = WeightedBIBEVerificationKey;
```

**File:** types/src/secret_sharing.rs (L136-146)
```rust
pub struct SecretShareConfig {
    _author: Author,
    _epoch: u64,
    validator: Arc<ValidatorVerifier>,
    digest_key: DigestKey,
    msk_share: MasterSecretKeyShare,
    verification_keys: Vec<VerificationKey>,
    config: <FPTXWeighted as BatchThresholdEncryption>::ThresholdConfig,
    encryption_key: EncryptionKey,
    weights: HashMap<Author, u64>,
}
```

**File:** Cargo.toml (L509-513)
```text
ark-ff = { version = "0.5.0", features = ["asm"] }
ark-ff-asm = { version = "0.5.0" }
ark-ff-macros = "0.5.0"
ark-groth16 = "0.5.0"
ark-poly = { version = "0.5.0", features = ["parallel"] }
```
