# Audit Report

## Title
Byzantine Peer Fragment Flooding: Unbounded Stream Header Replacement Causes Validator Resource Exhaustion

## Summary
A Byzantine peer can repeatedly send `StreamHeader` messages without completing any streams, exploiting a flaw in `InboundStreamBuffer` error handling to cause validator node slowdowns through CPU exhaustion, disk space consumption from log flooding, and connection slot starvation. The vulnerability arises because incomplete streams are replaced without disconnecting the malicious peer.

## Finding Description

The `InboundStreamBuffer` in the network streaming protocol maintains exactly one incomplete stream per connection. When a new `StreamHeader` arrives while a stream is already in progress, the buffer replaces the existing stream and returns an error, but critically **does not close the connection**. [1](#0-0) 

This error is handled in the peer event loop by logging a warning but allowing the connection to remain open: [2](#0-1) 

The stream message handling function propagates errors without triggering disconnection: [3](#0-2) 

**Attack Path:**

1. Byzantine peer establishes up to `MAX_INBOUND_CONNECTIONS` (100) connections to a validator node [4](#0-3) 

2. On each connection, the attacker sends a `StreamHeader` with `num_fragments` > 1 and up to `MAX_FRAME_SIZE` (4 MiB) of payload data [5](#0-4) 

3. Before sending any `StreamFragment` messages, the attacker immediately sends another `StreamHeader` with a different `request_id`

4. This causes the first stream to be discarded and replaced, generating an error log entry but keeping the connection alive

5. The attacker repeats steps 2-4 continuously at network speed across all 100 connections

6. **No rate limiting is applied by default** on inbound connections: [6](#0-5) [7](#0-6) 

**Broken Invariant:**
This violates the "Resource Limits" invariant: "All operations must respect gas, storage, and computational limits." The attack enables unlimited CPU consumption through forced deserialization cycles and unbounded disk usage through log file growth without any metering or rate limiting.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program criteria: "Validator node slowdowns."

**Concrete Impact:**
1. **CPU Exhaustion**: Continuous deserialization and validation of stream headers across 100 connections at network speed (potentially thousands of headers per second)
2. **Disk Space Exhaustion**: Each discarded stream generates a warning log entry. At high message rates, logs can fill disk space, causing node failure
3. **Connection Slot Starvation**: All 100 inbound connection slots occupied by malicious peer(s), preventing legitimate validators from establishing consensus connections
4. **Memory Churn**: While bounded to 400 MiB total (100 connections × 4 MiB), continuous allocation/deallocation causes memory fragmentation and garbage collection overhead

For a validator node under attack, these factors compound to significantly degrade performance during consensus rounds, potentially causing:
- Missed consensus voting deadlines
- Increased block proposal latency  
- Timeout-induced view changes in AptosBFT

## Likelihood Explanation

**Likelihood: HIGH**

The attack is trivially executable:
- **No authentication required**: Any peer can establish inbound connections to validators
- **No rate limiting by default**: The `inbound_rate_limit_config` is `None` unless explicitly configured
- **No error count threshold**: There is no mechanism to disconnect peers after repeated stream errors (unlike health check failures which have `ping_failures_tolerated`)
- **Low cost**: Attacker only needs to send headers (4 MiB each), no need to complete full message reassembly
- **High impact per connection**: With 100 connections, attacker consumes validator resources continuously

The attack requires minimal sophistication—just repeatedly sending valid `StreamHeader` protocol messages without corresponding fragments.

## Recommendation

Implement the following defenses:

1. **Enable Rate Limiting by Default**: Set `inbound_rate_limit_config` to `Some(RateLimitConfig::default())` to throttle malicious peers

2. **Track Stream Errors Per Connection**: Add an error counter to `Peer` that increments on stream replacement errors and disconnects after exceeding a threshold (similar to ping failure tracking):

```rust
// In Peer struct
stream_error_count: u32,
max_stream_errors_tolerated: u32, // e.g., 10

// In handle_inbound_stream_message
if let Err(e) = self.inbound_stream.new_stream(header) {
    self.stream_error_count += 1;
    if self.stream_error_count >= self.max_stream_errors_tolerated {
        self.shutdown(DisconnectReason::RepeatedStreamErrors);
    }
    return Err(e.into());
}

// Reset counter on successful stream completion
if let Some(message) = self.inbound_stream.append_fragment(fragment)? {
    self.stream_error_count = 0;
    // ... handle message
}
```

3. **Add DisconnectReason Variant**: [8](#0-7) 

Add `RepeatedStreamErrors` to the enum.

4. **Limit Log Volume**: Replace per-error logging with sampled logging using the existing `sample!` macro to prevent disk exhaustion: [9](#0-8) 

## Proof of Concept

```rust
#[tokio::test]
async fn test_fragment_flooding_attack() {
    // Setup: Create a peer connection with InboundStreamBuffer
    let max_fragments = 16;
    let mut inbound_stream_buffer = InboundStreamBuffer::new(max_fragments);
    
    // Attack: Repeatedly send headers without completing streams
    for i in 0..1000 {
        let header = StreamHeader {
            request_id: i,
            num_fragments: 10,
            message: NetworkMessage::DirectSendMsg(DirectSendMsg {
                protocol_id: ConsensusRpcBcs,
                priority: 0,
                raw_msg: vec![0u8; 4 * 1024 * 1024], // 4 MiB payload
            }),
        };
        
        // Each call after the first will return an error but replace the stream
        let result = inbound_stream_buffer.new_stream(header);
        
        if i > 0 {
            // Verify error is returned but stream is replaced
            assert!(result.is_err());
            assert!(result.unwrap_err().to_string().contains("Discarding existing stream"));
        }
        
        // Verify the stream buffer still holds a stream (not closed)
        assert!(inbound_stream_buffer.stream.is_some());
    }
    
    // Result: 1000 stream allocations/deallocations occurred
    // In a real attack across 100 connections, this would cause significant
    // CPU usage and generate 100,000 log entries
}
```

**Notes:**
- The default network configuration lacks inbound rate limiting, making this attack feasible at scale
- Unlike health check ping failures (which have a tolerance threshold), stream errors have no disconnect mechanism
- The streaming protocol assumes peers will complete streams they initiate, but Byzantine peers can violate this assumption without penalty
- Memory consumption is bounded by connection limits, but CPU and disk resources remain vulnerable

### Citations

**File:** network/framework/src/protocols/stream/mod.rs (L82-92)
```rust
    pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
        let inbound_stream = InboundStream::new(header, self.max_fragments)?;
        if let Some(old) = self.stream.replace(inbound_stream) {
            bail!(
                "Discarding existing stream for request ID: {}",
                old.request_id
            )
        } else {
            Ok(())
        }
    }
```

**File:** network/framework/src/peer/mod.rs (L74-81)
```rust
#[derive(Clone, Copy, Debug, PartialEq, Eq, Serialize)]
pub enum DisconnectReason {
    ConnectionClosed, // The connection was gracefully closed (e.g., by the peer)
    InputOutputError, // An I/O error occurred on the connection (e.g., when reading messages)
    NetworkHealthCheckFailure, // The connection failed the network health check (e.g., pings)
    RequestedByPeerManager, // The peer manager requested the connection to be closed
    StaleConnection,  // The connection is stale (e.g., when a validator leaves the validator set)
}
```

**File:** network/framework/src/peer/mod.rs (L254-265)
```rust
                        Some(message) =>  {
                            if let Err(err) = self.handle_inbound_message(message, &mut write_reqs_tx) {
                                warn!(
                                    NetworkSchema::new(&self.network_context)
                                        .connection_metadata(&self.connection_metadata),
                                    error = %err,
                                    "{} Error in handling inbound message from peer: {}, error: {}",
                                    self.network_context,
                                    remote_peer_id.short_str(),
                                    err
                                );
                            }
```

**File:** network/framework/src/peer/mod.rs (L543-558)
```rust
    fn handle_inbound_stream_message(
        &mut self,
        message: StreamMessage,
    ) -> Result<(), PeerManagerError> {
        match message {
            StreamMessage::Header(header) => {
                self.inbound_stream.new_stream(header)?;
            },
            StreamMessage::Fragment(fragment) => {
                if let Some(message) = self.inbound_stream.append_fragment(fragment)? {
                    self.handle_inbound_network_message(message)?;
                }
            },
        }
        Ok(())
    }
```

**File:** network/framework/src/peer/mod.rs (L649-660)
```rust
                    sample!(
                        SampleRate::Duration(Duration::from_secs(10)),
                        warn!(
                            NetworkSchema::new(&self.network_context)
                                .connection_metadata(&self.connection_metadata),
                            error = %e,
                            "[sampled] Failed to send outbound rpc request for protocol {} to peer: {}. Error: {}",
                            protocol_id,
                            self.remote_peer_id().short_str(),
                            e,
                        )
                    );
```

**File:** config/src/config/network_config.rs (L44-44)
```rust
pub const MAX_INBOUND_CONNECTIONS: usize = 100;
```

**File:** config/src/config/network_config.rs (L49-49)
```rust
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
```

**File:** config/src/config/network_config.rs (L117-119)
```rust
    pub inbound_rate_limit_config: Option<RateLimitConfig>,
    /// Outbound rate limiting configuration, if not specified, no rate limiting
    pub outbound_rate_limit_config: Option<RateLimitConfig>,
```

**File:** config/src/config/network_config.rs (L158-158)
```rust
            inbound_rate_limit_config: None,
```
