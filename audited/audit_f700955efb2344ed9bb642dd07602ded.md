# Audit Report

## Title
UTF-8 Truncation Panic in Token URI Processing Causes Indexer Denial of Service

## Summary
The indexer's `truncate_str` utility function incorrectly truncates UTF-8 strings at byte boundaries rather than character boundaries, causing a panic when multi-byte UTF-8 characters (emojis, CJK characters, etc.) straddle the 512-byte truncation point for token URIs. This allows any user to create tokens that crash the indexer, causing denial of service for API services and block explorers.

## Finding Description

The vulnerability exists in the token data processing pipeline where URIs are truncated before database insertion: [1](#0-0) 

The `get_uri_trunc()` function is called to truncate URIs: [2](#0-1) 

This calls the `truncate_str` utility function with `URI_LENGTH = 512`: [3](#0-2) 

The critical flaw is that `String::truncate()` operates on **byte indices**, not character boundaries. According to Rust documentation, `String::truncate()` **panics** if the index does not lie on a UTF-8 character boundary.

**Attack Path:**
1. Attacker creates a token on-chain with a carefully crafted URI containing multi-byte UTF-8 characters
2. The URI is designed to be >512 bytes with a multi-byte character (e.g., 4-byte emoji) starting at byte position 510, 511, or 512
3. Move's String validation allows this (valid UTF-8): [4](#0-3) 
4. When the indexer processes this transaction, it attempts to truncate at byte 512
5. The truncation splits the multi-byte character, triggering a panic
6. The indexer thread crashes, preventing further transaction indexing

**Example Attack:**
- URI = 510 Ã— 'a' + 'ðŸ”¥' (4-byte emoji at bytes 510-513)  
- Total: 514 bytes
- `truncate(512)` attempts to cut at byte 512 (inside the emoji)
- Result: **PANIC** - "attempt to truncate on non-char boundary"

The database schema confirms URIs have a 512-byte limit: [5](#0-4) 

**Additional Issue - Null Bytes:**
PostgreSQL TEXT columns reject null bytes, but Move's String allows them (valid UTF-8). While the indexer has retry logic with null byte cleaning, the first insertion attempt always fails: [6](#0-5) 

This causes performance degradation but is handled by the retry mechanism.

## Impact Explanation

**Severity: HIGH**

Per the Aptos bug bounty program, this qualifies as **High Severity: "API crashes"** (up to $50,000).

**Impact:**
- Complete denial of service for the indexer
- Block explorers cannot display transaction data
- Wallet applications lose access to token metadata
- Analytics and monitoring tools fail
- API endpoints become unavailable

The indexer is critical infrastructure for the Aptos ecosystem. While it doesn't affect consensus directly, it provides essential query services that applications depend on.

**Scope:**
- Affects all indexer instances processing token transactions
- Requires no special privileges to exploit
- Attack is deterministic and repeatable
- Low cost (only gas fees to create a token)

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Easy to exploit**: Any user can create tokens with arbitrary URI values
2. **No special permissions required**: Only needs ability to call token creation functions
3. **Deterministic**: Attack reliably crashes the indexer
4. **Low cost**: Minimal gas fees (token creation cost only)
5. **High visibility**: Token standards are well-documented and widely used
6. **Malicious or accidental**: Could be triggered intentionally or by legitimate users with non-ASCII URIs

The Move framework validates UTF-8 but doesn't restrict string length or character composition, making this attack surface readily available.

## Recommendation

**Fix the `truncate_str` function to respect UTF-8 character boundaries:**

```rust
pub fn truncate_str(val: &str, max_bytes: usize) -> String {
    if val.len() <= max_bytes {
        return val.to_string();
    }
    
    // Find the nearest character boundary at or before max_bytes
    let mut truncate_point = max_bytes;
    while truncate_point > 0 && !val.is_char_boundary(truncate_point) {
        truncate_point -= 1;
    }
    
    val[..truncate_point].to_string()
}
```

**Additional recommendations:**
1. Apply null byte cleaning **before** the first insertion attempt to avoid retry overhead
2. Add input validation at token creation to enforce reasonable URI length limits
3. Add integration tests with multi-byte UTF-8 characters at boundary positions
4. Consider adding database constraints or preprocessing to handle edge cases

## Proof of Concept

**Move test to create malicious token:**

```move
#[test(creator = @0x123)]
public fun test_create_token_with_boundary_splitting_uri(creator: &signer) {
    // Create URI with 510 ASCII chars + 4-byte emoji at position 510
    let base_uri = b"";
    let i = 0;
    while (i < 510) {
        vector::append(&mut base_uri, b"a");
        i = i + 1;
    };
    // Append 4-byte emoji (will be at bytes 510-513)
    vector::append(&mut base_uri, b"\xF0\x9F\x94\xA5"); // ðŸ”¥ emoji
    
    let collection_name = string::utf8(b"Test Collection");
    let token_name = string::utf8(b"Malicious Token");
    let uri_string = string::utf8(base_uri);
    
    // Create token - this succeeds on-chain
    token::create_token_script(
        creator,
        collection_name,
        token_name,
        string::utf8(b"Description"),
        1,
        1,
        uri_string, // This URI will crash the indexer
        creator,
        100,
        0,
        vector[false, false, false, false, false],
        vector[],
        vector[],
        vector[],
    );
    // Token created successfully on-chain
    // But indexer will PANIC when processing this transaction
}
```

**Rust reproduction:**

```rust
#[test]
#[should_panic(expected = "attempt to truncate on non-char boundary")]
fn test_truncate_str_panic() {
    let mut uri = "a".repeat(510);
    uri.push_str("ðŸ”¥"); // 4-byte emoji at position 510-513
    
    // This will panic
    let truncated = truncate_str(&uri, 512);
}
```

## Notes

While this vulnerability affects the indexer (an off-chain component) rather than consensus, it still meets High Severity criteria due to API service disruption. The indexer is essential infrastructure for ecosystem applications, and its failure significantly impacts user experience and application functionality.

### Citations

**File:** crates/indexer/src/models/token_models/token_datas.rs (L103-103)
```rust
                let metadata_uri = token_data.get_uri_trunc();
```

**File:** crates/indexer/src/models/token_models/token_utils.rs (L145-147)
```rust
    pub fn get_uri_trunc(&self) -> String {
        truncate_str(&self.uri, URI_LENGTH)
    }
```

**File:** crates/indexer/src/util.rs (L23-27)
```rust
pub fn truncate_str(val: &str, max_chars: usize) -> String {
    let mut trunc = val.to_string();
    trunc.truncate(max_chars);
    trunc
}
```

**File:** aptos-move/framework/move-stdlib/src/natives/string.rs (L37-55)
```rust
fn native_check_utf8(
    context: &mut SafeNativeContext,
    _ty_args: &[Type],
    mut args: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    debug_assert!(args.len() == 1);
    let s_arg = safely_pop_arg!(args, VectorRef);
    let s_ref = s_arg.as_bytes_ref();

    context.charge(
        STRING_CHECK_UTF8_BASE
            + STRING_CHECK_UTF8_PER_BYTE * NumBytes::new(s_ref.as_slice().len() as u64),
    )?;

    let ok = std::str::from_utf8(s_ref.as_slice()).is_ok();
    // TODO: extensible native cost tables

    Ok(smallvec![Value::bool(ok)])
}
```

**File:** crates/indexer/src/schema.rs (L762-763)
```rust
        #[max_length = 512]
        metadata_uri -> Varchar,
```

**File:** crates/indexer/src/processors/token_processor.rs (L234-234)
```rust
                let token_datas = clean_data_for_db(token_datas, true);
```
