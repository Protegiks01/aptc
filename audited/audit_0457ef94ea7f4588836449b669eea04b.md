# Audit Report

## Title
Missing Chunk Count Validation in DKG Secret Reconstruction Enables Malicious Dealer to Corrupt Shared Secrets

## Summary
The `le_chunks_to_scalar()` function in the DKG chunk reconstruction module does not validate that the number of chunks matches the expected count for the given `num_bits` parameter. This allows a malicious DKG dealer to create transcripts with incorrect per-share chunk counts that pass verification but cause all validators to reconstruct corrupted secret shares, breaking the DKG protocol.

## Finding Description

The vulnerability exists in the chunk-to-scalar reconstruction function used during DKG decryption: [1](#0-0) 

This function accepts any number of chunks and reconstructs a scalar value by computing `sum(chunk_i * base^i)` where `base = 2^num_bits`. It validates the `num_bits` parameter but **does not validate that `chunks.len()` matches the expected chunk count**.

The expected chunk count for a field element should be: [2](#0-1) 

For BLS12-381 Fr field (255 bits), with `ell=8`, this would be 32 chunks; with `ell=16`, 16 chunks; with `ell=32`, 8 chunks; with `ell=64`, 4 chunks.

**Attack Path:**

1. During DKG dealing, a malicious dealer calls the standard `deal()` function which properly chunks shares: [3](#0-2) 

2. The dealer then manipulates the `Cs` ciphertext structure in the transcript before broadcasting, providing incorrect chunk counts per share while maintaining the correct **total** chunk count.

3. When validators verify the transcript, the range proof only validates the total number of chunks: [4](#0-3) 

This checks `sc.get_total_weight() * num_chunks_per_scalar == total_chunks`, but not the per-share structure.

4. The proof-of-knowledge verification also passes because it operates on whatever chunk structure is provided: [5](#0-4) 

5. The homomorphism MSM terms are computed using `le_chunks_to_scalar` without validation: [6](#0-5) 

6. When honest validators decrypt their shares, they call `le_chunks_to_scalar` with the malformed chunks: [7](#0-6) 

7. Each validator reconstructs an **incorrect** secret share because:
   - If fewer chunks than expected: missing high-order bits result in smaller value
   - If more chunks than expected: extra high-order bits result in larger value

8. During threshold reconstruction, the corrupted shares produce an **incorrect shared secret**, completely breaking DKG security.

## Impact Explanation

This vulnerability represents a **High Severity** issue under the Aptos bug bounty criteria:

- **Significant Protocol Violation**: The DKG (Distributed Key Generation) protocol is fundamental to validator consensus security. If DKG can be corrupted by a single malicious dealer, the entire validator key generation mechanism is compromised.

- **Consensus Security Impact**: DKG-generated keys are used for validator operations and consensus participation. Corrupted keys could lead to consensus failures or security breaches.

- **Byzantine Fault Tolerance Violation**: While BFT systems assume up to 1/3 Byzantine validators, the protocol should include sufficient validation to prevent a single malicious participant from corrupting the entire DKG output. This vulnerability allows one dealer to break DKG for all participants.

## Likelihood Explanation

**Likelihood: Medium-High**

- **Attacker Requirements**: Requires one malicious validator acting as a DKG dealer. While validators are generally trusted, Byzantine fault tolerance explicitly assumes some fraction may be malicious.

- **Complexity**: The attack is straightforward to execute - simply modify the chunk structure in the transcript after generation but before broadcasting.

- **Detection**: The malformed transcript passes all current verification checks, making the attack undetectable until DKG reconstruction fails or produces incorrect results.

- **Frequency**: Occurs whenever DKG is executed (epoch changes, validator set updates), which happens regularly in production networks.

## Recommendation

Add explicit validation in `le_chunks_to_scalar()` to verify the chunk count matches the expected value:

```rust
pub fn le_chunks_to_scalar<F: PrimeField>(num_bits: u8, chunks: &[F]) -> F {
    assert!(
        num_bits.is_multiple_of(8) && num_bits > 0 && num_bits <= 64,
        "Invalid chunk size"
    );
    
    // Add chunk count validation
    let expected_chunks = F::MODULUS_BIT_SIZE.div_ceil(num_bits as u32);
    assert_eq!(
        chunks.len(),
        expected_chunks as usize,
        "Invalid chunk count: expected {}, got {}",
        expected_chunks,
        chunks.len()
    );

    let base = F::from(1u128 << num_bits);
    let mut acc = F::zero();
    let mut multiplier = F::one();

    for &chunk in chunks {
        acc += chunk * multiplier;
        multiplier *= base;
    }

    acc
}
```

Additionally, add explicit validation during transcript verification to check the structure of `Cs`:

```rust
// In verify() function, after line 487
for i in 0..sc.get_total_num_players() {
    let expected_chunks = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;
    for j in 0..self.subtrs.Cs[i].len() {
        if self.subtrs.Cs[i][j].len() != expected_chunks {
            bail!(
                "Invalid chunk count for player {} share {}: expected {}, got {}",
                i, j, expected_chunks, self.subtrs.Cs[i][j].len()
            );
        }
    }
}
```

## Proof of Concept

```rust
#[test]
fn test_chunk_count_mismatch_vulnerability() {
    use ark_bls12_381::Fr;
    use crate::pvss::chunky::chunks::{le_chunks_to_scalar, scalar_to_le_chunks};
    
    let num_bits: u8 = 16;
    let original = Fr::from(0x123456789ABCDEFu64);
    
    // Correct chunking produces expected number of chunks
    let correct_chunks = scalar_to_le_chunks(num_bits, &original);
    let expected_count = Fr::MODULUS_BIT_SIZE.div_ceil(num_bits as u32) as usize;
    assert_eq!(correct_chunks.len(), expected_count);
    
    // Reconstruction with correct chunks works
    let reconstructed = le_chunks_to_scalar(num_bits, &correct_chunks);
    assert_eq!(original, reconstructed);
    
    // VULNERABILITY: Using wrong number of chunks succeeds but produces wrong value
    let malicious_chunks = &correct_chunks[0..expected_count-2]; // Drop last 2 chunks
    let corrupted = le_chunks_to_scalar(num_bits, malicious_chunks);
    
    // The corrupted value is different - this breaks DKG!
    assert_ne!(original, corrupted);
    println!("Original: {:?}", original);
    println!("Corrupted: {:?}", corrupted);
    
    // Extra chunks also corrupt the value
    let mut extra_chunks = correct_chunks.clone();
    extra_chunks.push(Fr::from(0x1234u64));
    extra_chunks.push(Fr::from(0x5678u64));
    let corrupted_extra = le_chunks_to_scalar(num_bits, &extra_chunks);
    
    assert_ne!(original, corrupted_extra);
    println!("Corrupted (extra): {:?}", corrupted_extra);
}
```

## Notes

While this vulnerability requires a malicious validator/dealer to exploit, it represents a critical flaw in the DKG protocol implementation. Byzantine fault-tolerant systems must include sufficient validation to prevent single malicious actors from corrupting protocol execution. The absence of chunk count validation allows malformed transcripts to pass verification and corrupt the entire DKG output for all participants, violating fundamental security properties of the distributed key generation mechanism.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/chunks.rs (L32-48)
```rust
pub fn le_chunks_to_scalar<F: PrimeField>(num_bits: u8, chunks: &[F]) -> F {
    assert!(
        num_bits.is_multiple_of(8) && num_bits > 0 && num_bits <= 64, // TODO: so make num_bits a u8?
        "Invalid chunk size"
    );

    let base = F::from(1u128 << num_bits); // need u128 in the case where `num_bits` is 64, because of `chunk * multiplier`
    let mut acc = F::zero();
    let mut multiplier = F::one();

    for &chunk in chunks {
        acc += chunk * multiplier;
        multiplier *= base;
    }

    acc
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L300-302)
```rust
pub fn num_chunks_per_scalar<F: PrimeField>(ell: u8) -> u32 {
    F::MODULUS_BIT_SIZE.div_ceil(ell as u32) // Maybe add `as usize` here?
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L514-529)
```rust
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    TupleCodomainShape(
                        self.sharing_proof.range_proof_commitment.clone(),
                        chunked_elgamal::WeightedCodomainShape {
                            chunks: self.subtrs.Cs.clone(),
                            randomness: self.subtrs.Rs.clone(),
                        },
                    ),
                    chunked_scalar_mul::CodomainShape(self.subtrs.Vs.clone()),
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L532-539)
```rust
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L884-885)
```rust
            let dealt_secret_key_share =
                chunks::le_chunks_to_scalar(pp.ell, &dealt_chunked_secret_key_share_fr);
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L971-974)
```rust
        let f_evals_chunked: Vec<Vec<E::ScalarField>> = f_evals
            .iter()
            .map(|f_eval| chunks::scalar_to_le_chunks(pp.ell, f_eval))
            .collect();
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_scalar_mul.rs (L106-109)
```rust
                        scalars: vec![le_chunks_to_scalar(
                            self.ell,
                            &Scalar::slice_as_inner(chunks),
                        )],
```
