# Audit Report

## Title
Channel Blocking in Commit Path Causes Loss of Liveness When Indexer Service Fails

## Summary
The `commit_ledger` function in AptosDB has a critical ordering flaw where it commits data to disk before notifying subscribers. When the internal indexer service crashes or its receiver is dropped, the notification send fails and causes the entire commit operation to return an error, even though the data has already been permanently written to the database. This leads to loss of liveness as the node believes commits are failing when they are actually succeeding.

## Finding Description

The vulnerability exists in the commit path of AptosDB. The critical issue is a violation of atomicity in the `commit_ledger` function: [1](#0-0) 

The commit process occurs in this order:
1. **Line 107**: Database schemas are written to disk - the commit is **permanent and irreversible**
2. **Line 110**: `post_commit` is called, which includes notifying subscribers

In the `post_commit` function, if a version update subscriber has been registered, the code attempts to send a notification through a tokio watch channel: [2](#0-1) 

The subscriber is registered via: [3](#0-2) 

The receiver side is used by the Internal Indexer DB Service: [4](#0-3) 

**The Critical Flaw**: When the indexer service panics (which it does at line 179 when `changed().await` fails, or at lines 115-158 for various version mismatch conditions), the receiver is dropped. Tokio's `watch::Sender::send()` returns `SendError` when all receivers have been dropped. This error is propagated with `?` in the `post_commit` function, causing `commit_ledger` to return an error **after the data has already been committed to disk**.

The consensus pipeline treats this as a commit failure: [5](#0-4) 

This creates a state inconsistency where:
- The database has the committed transaction
- The consensus layer believes the commit failed
- The node stops processing subsequent blocks (loss of liveness)

## Impact Explanation

This is a **HIGH severity** vulnerability per Aptos bug bounty criteria for the following reasons:

1. **Loss of Liveness**: Once triggered, the node cannot commit any further blocks. Every commit attempt fails in `post_commit` even though data is being written to disk. This completely halts block processing.

2. **State Inconsistency**: The database state diverges from the consensus layer's view. The DB shows transactions as committed (OverallCommitProgress is updated), but the consensus pipeline receives errors and may attempt retries or enter error states.

3. **Violates Atomicity Invariant**: The commit operation violates the fundamental invariant that "State transitions must be atomic and verifiable." A commit either fully succeeds or fully fails - there should be no intermediate state.

4. **Potential Validator Divergence**: In a multi-validator setup, if some validators have their indexer crash while others don't, they could diverge in their processing, potentially affecting consensus safety.

This maps to "Validator node slowdowns" or "Significant protocol violations" in the HIGH severity category.

## Likelihood Explanation

**Likelihood: HIGH**

The vulnerability is highly likely to occur because:

1. **Multiple Panic Points**: The Internal Indexer DB Service has numerous panic conditions: [6](#0-5) 

2. **No Error Recovery**: The indexer service uses `.unwrap()` and `panic!` instead of graceful error handling: [7](#0-6) 

3. **Common Triggers**: Version mismatches between different indexer components, database corruption, resource exhaustion, or configuration errors can all trigger the panic conditions.

4. **No Defensive Coding**: The commit path has no error recovery or fallback if the send fails.

## Recommendation

**Fix**: Make the subscriber notification non-critical and handle send failures gracefully. The notification is for the indexer's benefit and should not block the critical commit path.

Recommended code change in `storage/aptosdb/src/db/aptosdb_writer.rs`:

```rust
// In post_commit function, replace lines 618-624 with:
if let Some(update_sender) = &self.update_subscriber {
    // Best-effort notification - don't fail commit if send fails
    if let Err(e) = update_sender.send((Instant::now(), version)) {
        // Log the error but don't propagate it
        warn!(
            "Failed to send update to subscriber (receiver likely dropped): {}. \
            This is non-critical - commit succeeded.",
            e
        );
    }
}
```

**Alternative Fix**: Move the subscriber notification before the commit, or make it completely asynchronous and detached from the commit success path.

**Additional Recommendations**:
1. Replace panic! calls in the indexer service with graceful error handling
2. Add monitoring/alerting when the indexer service crashes
3. Implement automatic restart mechanisms for the indexer service
4. Add circuit breaker pattern - disable subscriber if it fails repeatedly

## Proof of Concept

**Reproduction Steps**:

1. **Setup**: Start an Aptos node with internal indexer enabled in the configuration.

2. **Trigger Indexer Panic**: Cause a version mismatch by:
   - Manually corrupting the indexer DB to report a different version than expected
   - Or trigger any of the panic conditions in `get_start_version()`

3. **Observe Failure**: 
   - The indexer service panics and the async task exits
   - The receiver is dropped
   - Next commit attempt executes successfully up to line 107 (data written to disk)
   - Line 110 `post_commit` is called
   - Line 619-623 `send()` returns `SendError`
   - Commit returns error to consensus
   - Node halts block processing

**Rust Test Reproduction**:

```rust
#[tokio::test]
async fn test_commit_fails_when_subscriber_dropped() {
    // Create AptosDB and set up subscriber
    let (sender, receiver) = tokio::sync::watch::channel((Instant::now(), 0u64));
    let mut db = setup_test_db();
    db.add_version_update_subscriber(sender).unwrap();
    
    // Drop the receiver to simulate indexer crash
    drop(receiver);
    
    // Attempt to commit - should fail in post_commit even though data is written
    let chunk = create_test_chunk();
    db.pre_commit_ledger(chunk.clone(), false).unwrap();
    
    let result = db.commit_ledger(0, None, Some(chunk));
    
    // This should fail with SendError, demonstrating the bug
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("Failed to send update to subscriber"));
    
    // But the data is actually committed in the DB (inconsistent state)
    assert_eq!(db.ledger_db.metadata_db().get_synced_version().unwrap(), Some(0));
}
```

## Notes

This vulnerability exists only when the internal indexer is enabled and a subscriber is registered. When the indexer is disabled, the subscriber is None and the problematic code path is not executed. However, the internal indexer is a standard feature in production Aptos nodes, making this a realistic production vulnerability.

The root cause is the violation of the principle that optional, non-critical operations (like indexer notifications) should never block critical paths (like transaction commits). The fix should ensure that the commit path remains robust even when auxiliary services fail.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L618-624)
```rust
            if let Some(update_sender) = &self.update_subscriber {
                update_sender
                    .send((Instant::now(), version))
                    .map_err(|err| {
                        AptosDbError::Other(format!("Failed to send update to subscriber: {}", err))
                    })?;
            }
```

**File:** storage/aptosdb/src/db/mod.rs (L158-164)
```rust
    pub fn add_version_update_subscriber(
        &mut self,
        sender: Sender<(Instant, Version)>,
    ) -> Result<()> {
        self.update_subscriber = Some(sender);
        Ok(())
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L114-162)
```rust
            if start_version != state_start_version {
                panic!("Cannot start state indexer because the progress doesn't match.");
            }
        }

        if node_config.indexer_db_config.enable_transaction() {
            let transaction_start_version = self
                .db_indexer
                .indexer_db
                .get_transaction_version()?
                .map_or(0, |v| v + 1);
            if start_version != transaction_start_version {
                panic!("Cannot start transaction indexer because the progress doesn't match.");
            }
        }

        if node_config.indexer_db_config.enable_event() {
            let event_start_version = self
                .db_indexer
                .indexer_db
                .get_event_version()?
                .map_or(0, |v| v + 1);
            if start_version != event_start_version {
                panic!("Cannot start event indexer because the progress doesn't match.");
            }
        }

        if node_config.indexer_db_config.enable_event_v2_translation() {
            let event_v2_translation_start_version = self
                .db_indexer
                .indexer_db
                .get_event_v2_translation_version()?
                .map_or(0, |v| v + 1);
            if node_config
                .indexer_db_config
                .event_v2_translation_ignores_below_version()
                < start_version
                && start_version != event_v2_translation_start_version
            {
                panic!(
                    "Cannot start event v2 translation indexer because the progress doesn't match. \
                    start_version: {}, event_v2_translation_start_version: {}",
                    start_version, event_v2_translation_start_version
                );
            }
            if !node_config.indexer_db_config.enable_event() {
                panic!("Cannot start event v2 translation indexer because event indexer is not enabled.");
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L167-199)
```rust
    pub async fn run(&mut self, node_config: &NodeConfig) -> Result<()> {
        let mut start_version = self.get_start_version(node_config).await?;
        let mut target_version = self.db_indexer.main_db_reader.ensure_synced_version()?;
        let mut step_timer = std::time::Instant::now();

        loop {
            if target_version <= start_version {
                match self.update_receiver.changed().await {
                    Ok(_) => {
                        (step_timer, target_version) = *self.update_receiver.borrow();
                    },
                    Err(e) => {
                        panic!("Failed to get update from update_receiver: {}", e);
                    },
                }
            }
            let next_version = self.db_indexer.process(start_version, target_version)?;
            INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::InternalIndexerDBProcessed,
                Some(start_version as i64),
                Some(next_version as i64),
                None,
                None,
                Some(step_timer.elapsed().as_secs_f64()),
                None,
                Some((next_version - start_version) as i64),
                None,
            );
            start_version = next_version;
        }
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1079-1106)
```rust
    async fn commit_ledger(
        pre_commit_fut: TaskFuture<PreCommitResult>,
        commit_proof_fut: TaskFuture<LedgerInfoWithSignatures>,
        parent_block_commit_fut: TaskFuture<CommitLedgerResult>,
        executor: Arc<dyn BlockExecutorTrait>,
        block: Arc<Block>,
    ) -> TaskResult<CommitLedgerResult> {
        let mut tracker = Tracker::start_waiting("commit_ledger", &block);
        parent_block_commit_fut.await?;
        pre_commit_fut.await?;
        let ledger_info_with_sigs = commit_proof_fut.await?;

        // it's committed as prefix
        if ledger_info_with_sigs.commit_info().id() != block.id() {
            return Ok(None);
        }

        tracker.start_working();
        let ledger_info_with_sigs_clone = ledger_info_with_sigs.clone();
        tokio::task::spawn_blocking(move || {
            executor
                .commit_ledger(ledger_info_with_sigs_clone)
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(Some(ledger_info_with_sigs))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/runtime.rs (L42-44)
```rust
    runtime.spawn(async move {
        indexer_service.run(&config_clone).await.unwrap();
    });
```
