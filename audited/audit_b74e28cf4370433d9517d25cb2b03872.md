# Audit Report

## Title
Lock Contention in Telemetry Service Validator Cache Update Blocks Authentication Requests

## Summary
The `update_for_chain()` function in the telemetry service holds exclusive write locks on validator and VFN caches while performing CPU-intensive BCS deserialization and network address parsing for all validators in the set. This blocks all concurrent cache read operations, including authentication requests and JWT validation, causing potential request timeouts during high traffic periods.

## Finding Description

The vulnerability exists in the validator cache update mechanism. The code flow is: [1](#0-0) 

These write locks are acquired and then held during expensive parsing operations: [2](#0-1) 

The parsing operations include:
1. **BCS deserialization** via `validator_network_addresses()` and `fullnode_network_addresses()` which call `bcs::from_bytes()`: [3](#0-2) 

2. **Network address validation and parsing** for each validator in the set
3. **Error logging** which may involve I/O operations
4. **Collection operations** with filter_map iterating through all validators

During this time, all read operations are blocked because `RwLock` write locks are exclusive: [4](#0-3) 

Critical read operations that are blocked include:

**Authentication requests** that need to verify peer identity: [5](#0-4) 

**JWT validation** on every authenticated request: [6](#0-5) 

With validator sets potentially containing hundreds of validators (up to 65,536 theoretically allowed), and each validator having multiple network addresses to parse, the lock hold duration can accumulate to tens of milliseconds. During peak traffic when many validators are authenticating and submitting telemetry data, this creates a synchronization bottleneck.

## Impact Explanation

This issue qualifies as **Medium severity** per the Aptos bug bounty criteria:

1. **Service Degradation**: The telemetry service is critical infrastructure for monitoring validator health and network operations. Authentication failures cascade to:
   - Validators unable to send metrics/logs
   - Monitoring gaps that could hide attacks or issues
   - Retry storms from failed authentication attempts

2. **Availability Impact**: While not a total service outage, periodic blocking during cache updates (every 300 seconds per the configuration) creates predictable windows of degraded availability: [7](#0-6) 

3. **Cascading Effects**: During high load, the brief lock contention can trigger:
   - Request timeout cascades
   - Connection pool exhaustion from retries
   - Reduced observability during critical periods

While this doesn't directly impact consensus or fund security, it degrades critical operational infrastructure, fitting the "state inconsistencies requiring intervention" category at Medium severity.

## Likelihood Explanation

**Likelihood: High**

This issue occurs automatically during normal operations:
1. Cache updates happen every 5 minutes (configurable)
2. No attacker action required - it's an inherent design flaw
3. Impact increases with:
   - Number of validators in the set
   - Complexity of network addresses
   - Concurrent authentication request load
   - Slower CPU/system performance

The issue is deterministic and reproducible on every cache update cycle.

## Recommendation

**Fix**: Parse data structures BEFORE acquiring write locks, then acquire locks only for the final atomic swap:

```rust
async fn update_for_chain(
    &self,
    chain_name: &ChainCommonName,
    url: &str,
) -> Result<(), ValidatorCacheUpdateError> {
    // ... REST API call remains the same (lines 91-102) ...
    
    let (peer_addrs, state) = response.into_parts();
    let chain_id = ChainId::new(state.chain_id);
    
    // PARSE DATA WITHOUT HOLDING LOCKS
    let validator_peers: PeerSet = peer_addrs
        .clone()
        .into_iter()
        .filter_map(|validator_info| -> Option<(PeerId, Peer)> {
            validator_info
                .config()
                .validator_network_addresses()
                .map(|addresses| {
                    (
                        *validator_info.account_address(),
                        Peer::from_addrs(PeerRole::Validator, addresses),
                    )
                })
                .map_err(|err| {
                    error!("unable to parse validator network address: {}", err)
                })
                .ok()
        })
        .collect();

    let vfn_peers: PeerSet = peer_addrs
        .into_iter()
        .filter_map(|validator_info| -> Option<(PeerId, Peer)> {
            validator_info
                .config()
                .fullnode_network_addresses()
                .map(|addresses| {
                    (
                        *validator_info.account_address(),
                        Peer::from_addrs(PeerRole::ValidatorFullNode, addresses),
                    )
                })
                .map_err(|err| {
                    error!("unable to parse fullnode network address: {}", err)
                })
                .ok()
        })
        .collect();
    
    // Validation before lock acquisition
    let validator_count = validator_peers.len();
    let vfn_count = vfn_peers.len();
    let has_validators = !validator_peers.is_empty();
    let has_vfns = !vfn_peers.is_empty();
    
    let result = if !has_validators && !has_vfns {
        Err(ValidatorCacheUpdateError::BothPeerSetEmpty)
    } else if !has_validators {
        Err(ValidatorCacheUpdateError::ValidatorSetEmpty)
    } else if !has_vfns {
        Err(ValidatorCacheUpdateError::VfnSetEmpty)
    } else {
        Ok(())
    };
    
    // ACQUIRE LOCKS ONLY FOR ATOMIC UPDATE
    let mut validator_cache = self.validators.write();
    let mut vfn_cache = self.validator_fullnodes.write();
    
    // Fast swap - locks held for minimal time
    if has_validators {
        validator_cache.insert(chain_id, (state.epoch, validator_peers));
        VALIDATOR_CACHE_SIZE
            .with_label_values(&[&chain_id.to_string(), ValidatorCachePeerType::Validator.as_str()])
            .set(validator_count as i64);
    }
    
    if has_vfns {
        vfn_cache.insert(chain_id, (state.epoch, vfn_peers));
        VALIDATOR_CACHE_SIZE
            .with_label_values(&[&chain_id.to_string(), ValidatorCachePeerType::ValidatorFullnode.as_str()])
            .set(vfn_count as i64);
    }
    
    if has_validators || has_vfns {
        let now_unix = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();
        VALIDATOR_CACHE_LAST_UPDATE_TIMESTAMP
            .with_label_values(&[&chain_id.to_string()])
            .set(now_unix as i64);
    }
    
    result
}
```

This reduces lock hold time from O(n Ã— parse_time) to O(1) for the map insertion.

## Proof of Concept

```rust
#[cfg(test)]
mod lock_contention_test {
    use super::*;
    use std::sync::{Arc, atomic::{AtomicBool, AtomicUsize, Ordering}};
    use std::thread;
    use std::time::{Duration, Instant};
    
    #[test]
    fn test_write_lock_blocks_readers() {
        let cache = Arc::new(RwLock::new(HashMap::<ChainId, (u64, PeerSet)>::new()));
        let blocked_reads = Arc::new(AtomicUsize::new(0));
        let write_held = Arc::new(AtomicBool::new(false));
        
        // Simulate cache update holding write lock
        let cache_clone = cache.clone();
        let write_held_clone = write_held.clone();
        let writer = thread::spawn(move || {
            let mut writer = cache_clone.write();
            write_held_clone.store(true, Ordering::SeqCst);
            
            // Simulate slow parsing (BCS deserialization of 100 validators)
            thread::sleep(Duration::from_millis(50));
            
            writer.insert(ChainId::new(1), (10, HashMap::new()));
            write_held_clone.store(false, Ordering::SeqCst);
        });
        
        // Wait for writer to acquire lock
        while !write_held.load(Ordering::SeqCst) {
            thread::sleep(Duration::from_micros(100));
        }
        
        // Spawn 10 concurrent readers (simulating authentication requests)
        let mut readers = vec![];
        for _ in 0..10 {
            let cache_clone = cache.clone();
            let blocked_clone = blocked_reads.clone();
            let reader = thread::spawn(move || {
                let start = Instant::now();
                let _reader = cache_clone.read();
                let duration = start.elapsed();
                
                // If read was delayed > 10ms, it was blocked by writer
                if duration.as_millis() > 10 {
                    blocked_clone.fetch_add(1, Ordering::SeqCst);
                }
            });
            readers.push(reader);
        }
        
        writer.join().unwrap();
        for reader in readers {
            reader.join().unwrap();
        }
        
        // All readers should have been blocked
        assert_eq!(blocked_reads.load(Ordering::SeqCst), 10,
            "All authentication requests should be blocked during cache update");
    }
}
```

## Notes

This is a classic lock contention anti-pattern in concurrent systems. The fix is standard practice: minimize critical section duration by performing expensive operations outside locks. The telemetry service's availability depends on this fix, especially as validator sets grow larger.

### Citations

**File:** crates/aptos-telemetry-service/src/validator_cache.rs (L104-105)
```rust
        let mut validator_cache = self.validators.write();
        let mut vfn_cache = self.validator_fullnodes.write();
```

**File:** crates/aptos-telemetry-service/src/validator_cache.rs (L107-150)
```rust
        let validator_peers: PeerSet = peer_addrs
            .clone()
            .into_iter()
            .filter_map(|validator_info| -> Option<(PeerId, Peer)> {
                validator_info
                    .config()
                    .validator_network_addresses()
                    .map(|addresses| {
                        (
                            *validator_info.account_address(),
                            Peer::from_addrs(PeerRole::Validator, addresses),
                        )
                    })
                    .map_err(|err| {
                        error!(
                            "unable to parse validator network address for validator info {} for chain name {}: {}",
                            validator_info, chain_name, err
                        )
                    })
                    .ok()
            })
            .collect();

        let vfn_peers: PeerSet = peer_addrs
            .into_iter()
            .filter_map(|validator_info| -> Option<(PeerId, Peer)> {
                validator_info
                    .config()
                    .fullnode_network_addresses()
                    .map(|addresses| {
                        (
                            *validator_info.account_address(),
                            Peer::from_addrs(PeerRole::ValidatorFullNode, addresses),
                        )
                    })
                    .map_err(|err| {
                        error!(
                            "unable to parse fullnode network address for validator info {} in chain name {}: {}",
                            validator_info, chain_name, err
                        );
                    })
                    .ok()
            })
            .collect();
```

**File:** types/src/validator_config.rs (L60-66)
```rust
    pub fn fullnode_network_addresses(&self) -> Result<Vec<NetworkAddress>, bcs::Error> {
        bcs::from_bytes(&self.fullnode_network_addresses)
    }

    pub fn validator_network_addresses(&self) -> Result<Vec<NetworkAddress>, bcs::Error> {
        bcs::from_bytes(&self.validator_network_addresses)
    }
```

**File:** crates/aptos-infallible/src/rwlock.rs (L18-30)
```rust
    /// lock the rwlock in read mode
    pub fn read(&self) -> RwLockReadGuard<'_, T> {
        self.0
            .read()
            .expect("Cannot currently handle a poisoned lock")
    }

    /// lock the rwlock in write mode
    pub fn write(&self) -> RwLockWriteGuard<'_, T> {
        self.0
            .write()
            .expect("Cannot currently handle a poisoned lock")
    }
```

**File:** crates/aptos-telemetry-service/src/auth.rs (L72-114)
```rust
    let (epoch, peer_role) = match cache.read().get(&body.chain_id) {
        Some((epoch, peer_set)) => {
            match peer_set.get(&body.peer_id) {
                Some(peer) => {
                    let remote_public_key = &remote_public_key;
                    if !peer.keys.contains(remote_public_key) {
                        warn!("peer found in peer set but public_key is not found. request body: {}, role_type: {}, peer_id: {}, received public_key: {}", body.chain_id, body.role_type, body.peer_id, remote_public_key);
                        return Err(reject::custom(ServiceError::forbidden(
                            ServiceErrorCode::AuthError(
                                AuthError::PeerPublicKeyNotFound,
                                body.chain_id,
                            ),
                        )));
                    }
                    Ok((*epoch, peer.role))
                },
                None => {
                    // if not, verify that their peerid is constructed correctly from their public key
                    let derived_remote_peer_id =
                        aptos_types::account_address::from_identity_public_key(remote_public_key);
                    if derived_remote_peer_id != body.peer_id {
                        return Err(reject::custom(ServiceError::forbidden(
                            ServiceErrorCode::AuthError(
                                AuthError::PublicKeyMismatch,
                                body.chain_id,
                            ),
                        )));
                    } else {
                        Ok((*epoch, PeerRole::Unknown))
                    }
                },
            }
        },
        None => {
            warn!(
                "Validator set unavailable for Chain ID {}. Rejecting request.",
                body.chain_id
            );
            Err(reject::custom(ServiceError::unauthorized(
                ServiceErrorCode::AuthError(AuthError::ValidatorSetUnavailable, body.chain_id),
            )))
        },
    }?;
```

**File:** crates/aptos-telemetry-service/src/jwt_auth.rs (L57-64)
```rust
    let current_epoch = match context.peers().validators().read().get(&claims.chain_id) {
        Some(info) => info.0,
        None => {
            return Err(reject::custom(ServiceError::unauthorized(
                JwtAuthError::ExpiredAuthToken.into(),
            )));
        },
    };
```

**File:** crates/aptos-telemetry-service/e2e-test/telemetry-config.yaml (L14-14)
```yaml
update_interval: 300
```
