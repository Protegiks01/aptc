# Audit Report

## Title
Panic in Epoch Ending Restore Due to Version Filtering Bypass in Manifest Verification

## Summary
The epoch ending restore process can panic when processing a valid manifest where all ledger infos have versions exceeding the target_version. The manifest verification does not validate version compatibility, and the restore logic uses `expect()` assuming non-empty results without ensuring this invariant is maintained after target_version filtering.

## Finding Description

The vulnerability exists in the epoch ending restore workflow where manifest verification and version filtering are disconnected, allowing a panic to occur through legitimate code paths.

**Manifest Verification (Insufficient)**:
The `EpochEndingBackup::verify()` method validates manifest structure but does not check version compatibility with target_version: [1](#0-0) 

The verification ensures chunks are non-empty and epoch ranges are valid, but makes no assertions about actual ledger info versions relative to any target.

**Version Filtering During Restore**:
During `preheat_impl()`, ledger infos are filtered based on target_version: [2](#0-1) 

When the first ledger info in the first chunk has `version > target_version`, the loop breaks immediately without adding any items to `ledger_infos`, leaving it empty.

**Panic Location**:
The `run_impl()` method unconditionally calls `expect()` on the potentially empty vector: [3](#0-2) 

Additionally, a second panic exists at: [4](#0-3) 

**Attack Vector**:
The one-shot restore path bypasses metadata view filtering that would normally prevent this: [5](#0-4) 

The user directly provides `manifest_handle` and `target_version` via CLI, with no validation that the manifest contains epochs compatible with the target.

**How Attack Propagates**:
1. Attacker crafts or provides manifest with structurally valid data (passes `verify()`)
2. All epochs in manifest have versions > user's specified target_version
3. Node operator runs: `db-tool restore oneoff epoch-ending --epoch-ending-manifest <manifest> --target-version <low_version>`
4. Manifest loads and passes verification
5. All ledger infos get filtered out during preheat due to version check
6. `ledger_infos` vector remains empty
7. Process panics at line 216 with misleading message: "Epoch ending backup can't be empty"

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

- **Denial of Service**: The restore process crashes with a panic, preventing node restoration
- **State Inconsistencies Requiring Intervention**: The crashed restore leaves the system in an incomplete state requiring manual debugging and alternative backup selection
- **Misleading Error Messaging**: The error message "Epoch ending backup can't be empty" doesn't indicate the actual problem (version incompatibility), making debugging difficult

The impact is limited because:
- Only affects restore operations, not running nodes
- Does not cause fund loss or consensus violations
- Operator can recover by using compatible backups
- Does not affect network-wide operations

However, it prevents critical node recovery operations and could be exploited by:
- Malicious backup providers distributing incompatible backups
- Man-in-the-middle attacks modifying backup manifests
- Social engineering attacks tricking operators into using wrong backups

## Likelihood Explanation

**Likelihood: Medium to High**

The vulnerability can be triggered through several realistic scenarios:

1. **User Error**: Node operator accidentally selects a backup from future epochs when trying to restore to an earlier version
2. **Untrusted Backup Sources**: Operators using third-party or community backup sources may encounter crafted manifests
3. **Backup Storage Compromise**: If backup storage is compromised, attacker can replace manifests with incompatible versions
4. **Configuration Mistakes**: Misconfigured automation scripts might pass wrong target_version values

The attack requires:
- Node operator to initiate a restore (common during node setup or recovery)
- Access to provide manifest file path (standard CLI operation)
- Knowledge of appropriate target_version values (documented in backup metadata)

The panic is **deterministic** - once conditions are met, the crash is guaranteed. The vulnerability is **easily exploitable** through normal CLI operations without requiring code execution or privileged access.

## Recommendation

**Immediate Fix**: Replace `expect()` with proper error handling and validate version compatibility during manifest verification.

**Recommended Changes**:

1. Add version range validation during manifest verification or loading:
```rust
// In preheat_impl(), after loading manifest:
ensure!(
    !ledger_infos.is_empty(),
    "No epoch endings found compatible with target version {}. \
    Manifest contains epochs starting at version {} which exceeds target.",
    self.target_version,
    manifest.chunks.first().map(|c| c.first_epoch).unwrap_or(0)
);
```

2. Replace `expect()` with proper error handling:
```rust
// In run_impl(), replace line 213-216:
let first_li = preheat_data
    .ledger_infos
    .first()
    .ok_or_else(|| anyhow!(
        "No epoch endings restored. The backup manifest contains epochs \
        that all exceed the target version {}. Please select a backup \
        containing earlier epochs or increase the target version.",
        self.controller.target_version
    ))?;
```

3. Add early validation in `EpochEndingBackup::verify()` to check if any chunks could match a given target (requires passing target_version as parameter).

4. Consider adding a pre-flight check before restore that validates version compatibility between manifest and target_version.

## Proof of Concept

```rust
// Test demonstrating the panic
#[tokio::test]
async fn test_epoch_ending_restore_panic_on_version_mismatch() {
    use aptos_backup_cli::{
        backup_types::epoch_ending::{
            manifest::{EpochEndingBackup, EpochEndingChunk},
            restore::{EpochEndingRestoreController, EpochEndingRestoreOpt},
        },
        storage::local_fs::LocalFs,
        utils::{GlobalRestoreOptions, RestoreRunMode},
    };
    use aptos_types::{ledger_info::LedgerInfoWithSignatures, waypoint::Waypoint};
    use std::{collections::HashMap, path::PathBuf, sync::Arc};
    use tempfile::TempDir;

    // Setup: Create manifest with epochs at high versions (e.g., version 1000000)
    // Set target_version to low value (e.g., version 100)
    let temp_dir = TempDir::new().unwrap();
    let storage = Arc::new(LocalFs::new(temp_dir.path().to_path_buf()));
    
    // Create manifest with high-version epochs
    let manifest = EpochEndingBackup {
        first_epoch: 100,
        last_epoch: 100,
        waypoints: vec![
            Waypoint::new_epoch_boundary(&create_ledger_info_at_version(1000000, 100))
                .unwrap()
        ],
        chunks: vec![EpochEndingChunk {
            first_epoch: 100,
            last_epoch: 100,
            ledger_infos: "chunk_file".into(),
        }],
    };
    
    // Save manifest and create chunk file with high-version ledger info
    // ...
    
    let controller = EpochEndingRestoreController::new(
        EpochEndingRestoreOpt {
            manifest_handle: "manifest.json".into(),
        },
        GlobalRestoreOptions {
            target_version: 100, // Much lower than ledger info versions
            trusted_waypoints: Arc::new(HashMap::new()),
            run_mode: Arc::new(RestoreRunMode::Verify),
            concurrent_downloads: 1,
            replay_concurrency_level: 1,
        },
        storage,
    );
    
    // This will panic with "Epoch ending backup can't be empty"
    let result = controller.run(None).await;
    
    // Expected: Should return error instead of panicking
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("target version"));
}
```

The test creates a manifest with ledger infos at version 1,000,000+ but sets target_version to 100. When restore runs, all ledger infos are filtered out, causing the panic at line 216.

## Notes

- The vulnerability is present in both one-shot restore (via db-tool) and potentially in coordinator-based restore if manifest selection is bypassed
- The coordinated restore path has additional filtering via `select_epoch_ending_backups()` that provides some protection: [6](#0-5) 
- However, the one-shot path directly accepts user-provided manifests without this protection: [7](#0-6) 
- The issue demonstrates insufficient defense-in-depth: even if manifest passes structural verification, runtime invariants must be explicitly validated rather than assumed via `expect()`

### Citations

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/manifest.rs (L29-68)
```rust
    pub fn verify(&self) -> Result<()> {
        // check number of waypoints
        ensure!(
            self.first_epoch <= self.last_epoch
                && self.last_epoch - self.first_epoch + 1 == self.waypoints.len() as u64,
            "Malformed manifest. first epoch: {}, last epoch {}, num waypoints {}",
            self.first_epoch,
            self.last_epoch,
            self.waypoints.len(),
        );

        // check chunk ranges
        ensure!(!self.chunks.is_empty(), "No chunks.");
        let mut next_epoch = self.first_epoch;
        for chunk in &self.chunks {
            ensure!(
                chunk.first_epoch == next_epoch,
                "Chunk ranges not continuous. Expected first epoch: {}, actual: {}.",
                next_epoch,
                chunk.first_epoch,
            );
            ensure!(
                chunk.last_epoch >= chunk.first_epoch,
                "Chunk range invalid. [{}, {}]",
                chunk.first_epoch,
                chunk.last_epoch,
            );
            next_epoch = chunk.last_epoch + 1;
        }

        // check last epoch in chunk matches manifest
        ensure!(
            next_epoch - 1 == self.last_epoch, // okay to -1 because chunks is not empty.
            "Last epoch in chunks: {}, in manifest: {}",
            next_epoch - 1,
            self.last_epoch,
        );

        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L28-32)
```rust
#[derive(Parser)]
pub struct EpochEndingRestoreOpt {
    #[clap(long = "epoch-ending-manifest")]
    pub manifest_handle: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L91-111)
```rust
        let mut past_target = false;
        for chunk in &manifest.chunks {
            if past_target {
                break;
            }

            let lis = self.read_chunk(&chunk.ledger_infos).await?;
            ensure!(
                chunk.first_epoch + lis.len() as u64 == chunk.last_epoch + 1,
                "Number of items in chunks doesn't match that in manifest. \
                first_epoch: {}, last_epoch: {}, items in chunk: {}",
                chunk.first_epoch,
                chunk.last_epoch,
                lis.len(),
            );

            for li in lis {
                if li.ledger_info().version() > self.target_version {
                    past_target = true;
                    break;
                }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L213-216)
```rust
        let first_li = preheat_data
            .ledger_infos
            .first()
            .expect("Epoch ending backup can't be empty.");
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L242-246)
```rust
        let last_li = preheat_data
            .ledger_infos
            .last()
            .expect("Verified not empty.")
            .ledger_info();
```

**File:** storage/db-tool/src/restore.rs (L70-82)
```rust
                    Oneoff::EpochEnding {
                        storage,
                        opt,
                        global,
                    } => {
                        EpochEndingRestoreController::new(
                            opt,
                            global.try_into()?,
                            storage.init_storage().await?,
                        )
                        .run(None)
                        .await?;
                    },
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L171-196)
```rust
    pub fn select_epoch_ending_backups(
        &self,
        target_version: Version,
    ) -> Result<Vec<EpochEndingBackupMeta>> {
        // This can be more flexible, but for now we assume and check backups are continuous in
        // range (which is always true when we backup from a single backup coordinator)
        let mut next_epoch = 0;
        let mut res = Vec::new();
        for backup in self.epoch_ending_backups.iter().sorted() {
            if backup.first_version > target_version {
                break;
            }

            ensure!(
                backup.first_epoch == next_epoch,
                "Epoch ending backup ranges not continuous, expecting epoch {}, got {}.",
                next_epoch,
                backup.first_epoch,
            );
            res.push(backup.clone());

            next_epoch = backup.last_epoch + 1;
        }

        Ok(res)
    }
```
