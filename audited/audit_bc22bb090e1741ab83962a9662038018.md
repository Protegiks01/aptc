# Audit Report

## Title
Missing Validation of WriteSetPrunerProgress Leading to Unrecoverable Node Failure During State Restoration

## Summary
The `WriteSetPrunerProgress` metadata is not validated against the latest state snapshot version during database initialization. If this progress value is corrupted or manipulated to prune write sets between a snapshot and the current ledger version, the node becomes unable to start, breaking the ability to replay transactions and verify state transitions.

## Finding Description

The Aptos storage layer uses state snapshots and write set replay to reconstruct the current state during node initialization. The `StateStore::create_buffered_state_from_latest_snapshot()` function retrieves write sets from the latest snapshot version to the current synced version to replay state changes. [1](#0-0) 

This function directly calls `get_write_sets()` without any protection against pruned data: [2](#0-1) 

The function will fail with "Write set missing for version X" if any write set in the range has been pruned.

Meanwhile, `WriteSetPruner` prunes write sets based solely on the `WriteSetPrunerProgress` metadata value: [3](#0-2) 

The pruner progress initialization lacks validation to ensure it doesn't exceed the latest snapshot version: [4](#0-3) 

**Attack Scenario:**
1. Node has snapshot at version 99,900,000 and current version 100,000,000
2. `WriteSetPrunerProgress` becomes corrupted or set to 99,950,000 (via database corruption, backup restore issue, or pruning bug)
3. Write sets from versions 99,900,001 to 99,950,000 are pruned
4. Node restarts and attempts state restoration
5. `create_buffered_state_from_latest_snapshot()` tries to fetch write sets [99,900,001, 100,000,000]
6. Call fails because write sets [99,900,001, 99,950,000] are missing
7. Node initialization panics with "buffered state creation failed": [5](#0-4) 

**Broken Invariants:**
- **State Consistency**: Cannot replay transactions to verify state transitions
- **Node Availability**: Node cannot start and participate in consensus
- **Recovery Capability**: No automatic recovery mechanism exists

## Impact Explanation

This vulnerability is rated **High Severity** because:

1. **Validator Node Unavailability**: Affected nodes cannot start, causing loss of liveness for that validator
2. **Protocol Violation**: Breaks the guarantee that nodes can always replay and verify state transitions from snapshots
3. **Manual Intervention Required**: Recovery requires either database restoration from backup or manual database repair

While this doesn't cause immediate network-wide consensus failure (requires affecting multiple validators), it violates the critical property that state must always be recoverable from snapshots plus write sets.

The impact is limited compared to Critical severity because:
- Requires database corruption or a separate bug to trigger
- Affects individual nodes rather than the entire network
- No direct fund loss or consensus safety violation

## Likelihood Explanation

**Medium Likelihood** due to:

**Triggering Conditions:**
- Database corruption during crash or disk failure
- Bug in pruning logic that sets incorrect progress
- Issues during backup/restore operations
- Race conditions in pruner initialization

**Mitigating Factors:**
- Requires specific corruption of `WriteSetPrunerProgress` metadata
- Atomic writes reduce but don't eliminate corruption risk
- Typically requires validator operator intervention to corrupt

However, the lack of defensive validation means any corruption or bug affecting this metadata value will cause unrecoverable failure.

## Recommendation

Add validation during pruner initialization and state restoration:

**1. Validate pruner progress against snapshot version during initialization:**

```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
    max_safe_progress: Option<Version>, // New parameter
) -> Result<Version> {
    let progress = if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
        v.expect_version()
    } else {
        sub_db.put::<DbMetadataSchema>(
            progress_key,
            &DbMetadataValue::Version(metadata_progress),
        )?;
        metadata_progress
    };
    
    // Validate progress is not ahead of safe limit
    if let Some(max_progress) = max_safe_progress {
        ensure!(
            progress <= max_progress,
            "Pruner progress {} exceeds safe limit {}. Database corruption detected.",
            progress,
            max_progress
        );
    }
    
    Ok(progress)
}
```

**2. Check min_readable_version before fetching write sets:**

```rust
fn create_buffered_state_from_latest_snapshot(...) -> Result<BufferedState> {
    // ... existing code ...
    
    if snapshot_next_version < num_transactions {
        // Add validation before fetching write sets
        let min_readable_version = state_db.ledger_db
            .metadata_db()
            .get_pruner_progress()
            .unwrap_or(0);
            
        ensure!(
            snapshot_next_version >= min_readable_version,
            "Cannot replay write sets: snapshot at {} is before min readable version {}",
            snapshot_next_version,
            min_readable_version
        );
        
        let write_sets = state_db
            .ledger_db
            .write_set_db()
            .get_write_sets(snapshot_next_version, num_transactions)?;
        // ... rest of replay logic ...
    }
}
```

**3. Add recovery mechanism to detect and reset corrupted pruner progress.**

## Proof of Concept

The following demonstrates the vulnerability cannot be directly tested without database manipulation, confirming it requires corruption/bug to trigger:

```rust
// This PoC shows the code path but cannot be executed without database corruption
#[test]
#[should_panic(expected = "Write set missing for version")]
fn test_writeset_pruner_corruption_breaks_recovery() {
    // 1. Setup: Create DB with transactions and snapshot
    let tmp_dir = TempPath::new();
    let db = AptosDB::new_for_test(&tmp_dir);
    
    // Commit 200,000 transactions
    commit_transactions(&db, 200_000);
    
    // Force snapshot at version 100,000
    db.state_store.force_snapshot_at_version(100_000).unwrap();
    
    // 2. Simulate corruption: Manually set WriteSetPrunerProgress to 150,000
    // (This would require direct database manipulation which we cannot do in tests)
    // In reality: Corrupt the metadata key WriteSetPrunerProgress = 150,000
    
    // 3. Close and reopen DB - this should panic because write sets
    // 100,001 to 150,000 are pruned but needed for replay
    drop(db);
    
    // This will panic with "Write set missing for version 100001"
    let db = AptosDB::open(&tmp_dir, false, NO_OP_STORAGE_PRUNER_CONFIG, 
                           RocksdbConfigs::default(), false, 1000, 1000)
        .expect("buffered state creation failed");
}
```

**Notes:**
- The actual vulnerability requires database-level manipulation or a separate bug in pruning logic to trigger
- The PoC demonstrates the code path but cannot execute without database corruption
- Real exploitation would occur through backup restore issues, disk corruption, or pruning bugs

### Citations

**File:** storage/aptosdb/src/state_store/mod.rs (L384-395)
```rust
        } else {
            Self::create_buffered_state_from_latest_snapshot(
                &state_db,
                buffered_state_target_items,
                hack_for_tests,
                /*check_max_versions_after_snapshot=*/ true,
                current_state.clone(),
                persisted_state.clone(),
                hot_state_config,
            )
            .expect("buffered state creation failed.")
        };
```

**File:** storage/aptosdb/src/state_store/mod.rs (L651-654)
```rust
            let write_sets = state_db
                .ledger_db
                .write_set_db()
                .get_write_sets(snapshot_next_version, num_transactions)?;
```

**File:** storage/aptosdb/src/ledger_db/write_set_db.rs (L77-110)
```rust
    pub(crate) fn get_write_sets(
        &self,
        begin_version: Version,
        end_version: Version,
    ) -> Result<Vec<WriteSet>> {
        if begin_version == end_version {
            return Ok(Vec::new());
        }
        ensure!(
            begin_version < end_version,
            "begin_version {} >= end_version {}",
            begin_version,
            end_version
        );

        let mut iter = self.db.iter::<WriteSetSchema>()?;
        iter.seek(&begin_version)?;

        let mut ret = Vec::with_capacity((end_version - begin_version) as usize);
        for current_version in begin_version..end_version {
            let (version, write_set) = iter.next().transpose()?.ok_or_else(|| {
                AptosDbError::NotFound(format!("Write set missing for version {}", current_version))
            })?;
            ensure!(
                version == current_version,
                "Write set missing for version {}, got version {}",
                current_version,
                version,
            );
            ret.push(write_set);
        }

        Ok(ret)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/write_set_pruner.rs (L25-33)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        WriteSetDb::prune(current_progress, target_version, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::WriteSetPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        self.ledger_db.write_set_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```
