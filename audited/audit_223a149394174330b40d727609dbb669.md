# Audit Report

## Title
Block Retrieval Accept Uncommitted Blocks Leading to Resource Exhaustion

## Summary
The `BlockRetrievalResponse::verify()` function validates block signatures and chain consistency but does not verify whether blocks have achieved 3-chain commitment according to AptosBFT's finality rules. This allows malicious validators to distribute uncommitted blocks from abandoned forks, causing honest nodes to waste resources on blocks that will eventually be pruned.

## Finding Description

The vulnerability exists in the block retrieval verification flow: [1](#0-0) 

The `verify()` function only performs three checks:
1. Block signature validation
2. Well-formedness validation  
3. Chain consistency (blocks form a valid chain)

**Critically missing**: No verification that blocks have achieved 3-chain commitment as defined in AptosBFT. [2](#0-1) 

When a peer requests blocks, the responder uses `process_block_retrieval_inner()` which retrieves ANY blocks from its BlockStore: [3](#0-2) 

This function returns blocks without checking commitment status - it simply iterates through the BlockStore and returns whatever blocks exist.

The only protection is a round-based check that prevents fetching blocks older than `ordered_root`: [4](#0-3) 

**Attack Scenario**:
1. During normal operation or network partitions, temporary forks occur with valid QuorumCertificates (2f+1 signatures)
2. Byzantine validator retains QCs from abandoned forks that never achieved 3-chain commitment
3. Attacker sends SyncInfo messages containing these QCs to honest validators
4. Honest nodes verify QC round >= ordered_root, pass the check
5. Honest nodes fetch the block chain via `retrieve_blocks_in_range()`: [5](#0-4) 

6. Retrieved blocks pass `verify()` (valid signatures, well-formed)
7. Blocks are inserted into BlockStore and consume resources
8. Blocks never commit (no 3-chain) and eventually get pruned: [6](#0-5) 

9. Attacker repeats with different abandoned QCs

## Impact Explanation

**High Severity** - Validator Node Slowdowns (per Aptos Bug Bounty):

- **Network Bandwidth Exhaustion**: Nodes repeatedly fetch uncommitted blocks from peers
- **Storage Pressure**: BlockStore fills with blocks that will be pruned, triggering unnecessary database writes
- **CPU Overhead**: Signature verification, block validation, and tree structure updates for blocks that provide no value
- **Consensus Delays**: Resources diverted from processing legitimate blocks slows down consensus progress

Unlike normal fork handling (temporary, resolves quickly), this attack allows Byzantine validators to repeatedly trigger resource waste by replaying old QCs from abandoned forks. The round check only prevents ancient blocks, but uncommitted blocks from recent forks (round >= ordered_root) bypass this protection.

## Likelihood Explanation

**Medium-High Likelihood**:

**Requirements for attack**:
- Byzantine validator with < f stake (doesn't need majority)
- Collection of abandoned QCs from previous forks (naturally occurs during normal operation)
- Ability to send SyncInfo messages to target nodes (standard P2P protocol)

**Why this works**:
- BFT consensus naturally produces temporary forks during network delays
- QCs from these forks remain cryptographically valid indefinitely
- No rate limiting on block retrieval requests in the verification logic
- No time-to-live or commitment status checks on QCs

The attack complexity is LOW - simply replaying stored QCs. Unlike attacks requiring 2f+1 collusion, a single Byzantine validator can execute this by replaying legitimately-obtained QCs from forks that lost consensus.

## Recommendation

Add commitment verification to the block retrieval response validation:

```rust
pub fn verify(
    &self,
    retrieval_request: BlockRetrievalRequest,
    sig_verifier: &ValidatorVerifier,
    ordered_root_round: Round,  // Add parameter
    commit_root_round: Round,   // Add parameter
) -> anyhow::Result<()> {
    self.verify_inner(&retrieval_request)?;

    self.blocks
        .iter()
        .try_fold(retrieval_request.block_id(), |expected_id, block| {
            block.validate_signature(sig_verifier)?;
            block.verify_well_formed()?;
            
            // NEW: Reject blocks too far ahead of commit root
            ensure!(
                block.round() <= commit_root_round.saturating_add(MAX_UNCOMMITTED_BLOCK_DISTANCE),
                "Block round {} exceeds acceptable distance from commit_root {}",
                block.round(),
                commit_root_round
            );
            
            ensure!(
                block.id() == expected_id,
                "blocks doesn't form a chain: expect {}, get {}",
                expected_id,
                block.id()
            );
            Ok(block.parent_id())
        })
        .map(|_| ())
}
```

Additionally, add QC age validation in sync_manager.rs:

```rust
pub fn need_fetch_for_quorum_cert(&self, qc: &QuorumCert) -> NeedFetchResult {
    if qc.certified_block().round() < self.ordered_root().round() {
        return NeedFetchResult::QCRoundBeforeRoot;
    }
    
    // NEW: Reject QCs too far ahead without commitment proof
    const MAX_AHEAD_ROUNDS: u64 = 100;
    if qc.certified_block().round() > self.ordered_root().round() + MAX_AHEAD_ROUNDS {
        return NeedFetchResult::QCRoundBeforeRoot;
    }
    
    // ... rest of checks
}
```

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[tokio::test]
async fn test_uncommitted_block_retrieval_attack() {
    // Setup: Create validator network with Byzantine node
    let (mut playground, network) = NetworkPlayground::new();
    let byzantine_validator = playground.add_validator();
    let honest_validator = playground.add_validator();
    
    // Byzantine validator creates fork blocks at rounds 100-102
    let fork_blocks = create_fork_chain(&byzantine_validator, 100, 3);
    
    // Fork gets QC at round 100 but never commits (no 3-chain)
    let fork_qc = create_qc_for_block(&fork_blocks[0], &validators);
    
    // Main chain commits different blocks at rounds 100-102
    let main_chain = create_main_chain(&honest_validator, 100, 3);
    commit_blocks(&main_chain); // These achieve 3-chain commitment
    
    // ATTACK: Byzantine validator sends SyncInfo with abandoned fork QC
    let malicious_sync_info = SyncInfo::new(
        fork_qc.clone(),  // QC from abandoned fork
        main_chain[2].quorum_cert().clone(),
        None
    );
    
    // Honest validator processes SyncInfo
    honest_validator.process_sync_info(malicious_sync_info).await;
    
    // VULNERABILITY: Honest validator fetches fork blocks
    assert_eq!(
        honest_validator.block_store.get_block(fork_blocks[0].id()),
        Some(fork_blocks[0].clone())
    );
    
    // Fork blocks never commit, get pruned later
    // But resources were wasted fetching and storing them
    
    // Attacker can repeat with different abandoned QCs
    // No rate limiting prevents this
}
```

**Notes**:
- This vulnerability violates the **Resource Limits** invariant by allowing unbounded resource consumption through repeatedly distributed uncommitted blocks
- The attack is practical because abandoned QCs naturally accumulate during normal consensus operation
- Single Byzantine validator can execute attack without requiring 2f+1 collusion
- Current implementation prioritizes availability over resource protection in the block retrieval path

### Citations

**File:** consensus/consensus-types/src/block_retrieval.rs (L260-281)
```rust
    pub fn verify(
        &self,
        retrieval_request: BlockRetrievalRequest,
        sig_verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        self.verify_inner(&retrieval_request)?;

        self.blocks
            .iter()
            .try_fold(retrieval_request.block_id(), |expected_id, block| {
                block.validate_signature(sig_verifier)?;
                block.verify_well_formed()?;
                ensure!(
                    block.id() == expected_id,
                    "blocks doesn't form a chain: expect {}, get {}",
                    expected_id,
                    block.id()
                );
                Ok(block.parent_id())
            })
            .map(|_| ())
    }
```

**File:** consensus/README.md (L25-25)
```markdown
A block is committed when a contiguous 3-chain commit rule is met. A block at round k is committed if it has a quorum certificate and is confirmed by two more blocks and quorum certificates at rounds k + 1 and k + 2. The commit rule eventually allows honest validators to commit a block. AptosBFT guarantees that all honest validators will eventually commit the block (and proceeding sequence of blocks linked from it). Once a sequence of blocks has committed, the state resulting from executing their transactions can be persisted and forms a replicated database.
```

**File:** consensus/src/block_storage/sync_manager.rs (L97-111)
```rust
    pub fn need_fetch_for_quorum_cert(&self, qc: &QuorumCert) -> NeedFetchResult {
        if qc.certified_block().round() < self.ordered_root().round() {
            return NeedFetchResult::QCRoundBeforeRoot;
        }
        if self
            .get_quorum_cert_for_block(qc.certified_block().id())
            .is_some()
        {
            return NeedFetchResult::QCAlreadyExist;
        }
        if self.block_exists(qc.certified_block().id()) {
            return NeedFetchResult::QCBlockExist;
        }
        NeedFetchResult::NeedFetch
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L543-591)
```rust
    pub async fn process_block_retrieval_inner(
        &self,
        request: &BlockRetrievalRequest,
    ) -> Box<BlockRetrievalResponse> {
        let mut blocks = vec![];
        let mut status = BlockRetrievalStatus::Succeeded;
        let mut id = request.block_id();

        match &request {
            BlockRetrievalRequest::V1(req) => {
                while (blocks.len() as u64) < req.num_blocks() {
                    if let Some(executed_block) = self.get_block(id) {
                        blocks.push(executed_block.block().clone());
                        if req.match_target_id(id) {
                            status = BlockRetrievalStatus::SucceededWithTarget;
                            break;
                        }
                        id = executed_block.parent_id();
                    } else {
                        status = BlockRetrievalStatus::NotEnoughBlocks;
                        break;
                    }
                }
            },
            BlockRetrievalRequest::V2(req) => {
                while (blocks.len() as u64) < req.num_blocks() {
                    if let Some(executed_block) = self.get_block(id) {
                        if !executed_block.block().is_genesis_block() {
                            blocks.push(executed_block.block().clone());
                        }
                        if req.is_window_start_block(executed_block.block()) {
                            status = BlockRetrievalStatus::SucceededWithTarget;
                            break;
                        }
                        id = executed_block.parent_id();
                    } else {
                        status = BlockRetrievalStatus::NotEnoughBlocks;
                        break;
                    }
                }
            },
        }

        if blocks.is_empty() {
            status = BlockRetrievalStatus::IdNotFound;
        }

        Box::new(BlockRetrievalResponse::new(status, blocks))
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L901-916)
```rust
    async fn retrieve_blocks_in_range(
        &mut self,
        initial_block_id: HashValue,
        num_blocks: u64,
        target_block_retrieval_payload: TargetBlockRetrieval,
        peers: Vec<AccountAddress>,
    ) -> anyhow::Result<Vec<Block>> {
        BLOCKS_FETCHED_FROM_NETWORK_IN_BLOCK_RETRIEVER.inc_by(num_blocks);
        self.retrieve_blocks(
            initial_block_id,
            target_block_retrieval_payload,
            peers,
            num_blocks,
        )
        .await
    }
```

**File:** consensus/src/block_storage/block_store.rs (L843-862)
```rust
    pub(crate) fn prune_tree(&self, next_root_id: HashValue) -> VecDeque<HashValue> {
        let id_to_remove = self.inner.read().find_blocks_to_prune(next_root_id);
        if let Err(e) = self
            .storage
            .prune_tree(id_to_remove.clone().into_iter().collect())
        {
            // it's fine to fail here, as long as the commit succeeds, the next restart will clean
            // up dangling blocks, and we need to prune the tree to keep the root consistent with
            // executor.
            warn!(error = ?e, "fail to delete block");
        }

        // synchronously update both root_id and commit_root_id
        let mut wlock = self.inner.write();
        wlock.update_ordered_root(next_root_id);
        wlock.update_commit_root(next_root_id);
        wlock.update_window_root(next_root_id);
        wlock.process_pruned_blocks(id_to_remove.clone());
        id_to_remove
    }
```
