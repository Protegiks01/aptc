# Audit Report

## Title
Stream Header Interleaving Allows Denial-of-Service via Incomplete Stream Discarding

## Summary
The network protocol's `InboundStreamBuffer` maintains only a single active stream per peer connection. When a new stream header arrives while a previous stream is incomplete, the implementation unconditionally discards the in-progress stream and replaces it with the new one. This allows a malicious peer to prevent legitimate large messages (including consensus blocks and state sync data) from ever completing by repeatedly sending new stream headers, causing a denial-of-service condition.

## Finding Description

The `MultiplexMessage` enum allows arbitrary interleaving of `NetworkMessage` and `StreamMessage` variants. [1](#0-0) 

Each peer connection maintains a single `InboundStreamBuffer` that can only track one active stream at a time. [2](#0-1) 

When a new `StreamMessage::Header` arrives, the `new_stream()` method unconditionally replaces any existing stream using `Option::replace()`, which installs the new stream before checking if an old stream existed. [3](#0-2) 

The critical flaw is that `self.stream.replace(inbound_stream)` immediately overwrites the existing stream with the new one, then checks if there was an old stream to return an error. Even though an error is returned ("Discarding existing stream for request ID: {}"), the state mutation has already occurred—the old stream is permanently lost and the new stream is active.

When this error propagates up through `handle_inbound_stream_message`, it is only logged as a warning and the connection continues processing messages normally. [4](#0-3) 

The error handling in the main event loop does not disconnect the peer when stream errors occur. [5](#0-4) 

**Attack Scenario:**
1. Malicious peer sends `StreamMessage::Header(request_id=1, num_fragments=255)` for a large message
2. Victim node creates an `InboundStream` and begins buffering fragments
3. Attacker sends `StreamMessage::Fragment(request_id=1, fragment_id=1)` 
4. Before the stream completes, attacker sends `StreamMessage::Header(request_id=2, num_fragments=255)`
5. The first stream is discarded, all buffered data is lost
6. Attacker repeats steps 3-5 indefinitely

This prevents any large messages from ever completing delivery. Since consensus blocks, state sync chunks, and other critical protocol messages may exceed the frame size and require streaming, this can disrupt network operations.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program criteria:
- **State inconsistencies requiring intervention**: Continuous disruption of large message delivery can prevent consensus messages from propagating, potentially causing validator nodes to fall behind or stall
- **Validator node slowdowns**: Continuous processing and discarding of incomplete streams wastes CPU and memory resources
- **Limited protocol availability**: While not causing total network failure, this can degrade network functionality by preventing large messages from being delivered

The impact is limited to Medium rather than High/Critical because:
- Small messages (below max frame size) are unaffected and delivered normally
- The attack requires continuous sending of malicious headers to maintain the DoS
- It doesn't cause permanent state corruption or fund loss
- The attack is per-connection, requiring the attacker to maintain connections to target nodes

However, this could escalate in impact if critical consensus or state sync operations rely on streamed messages, potentially causing validators to fall out of sync.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly likely to be exploitable because:

1. **Low attacker requirements**: Any network peer can send arbitrary `MultiplexMessage` variants without special authentication
2. **Simple attack execution**: The attacker only needs to send stream headers repeatedly—no complex timing or state manipulation required
3. **No rate limiting**: There are no apparent per-peer rate limits on stream header frequency [4](#0-3) 
4. **Error handling doesn't disconnect**: The connection remains open after discarding streams, allowing the attack to continue indefinitely
5. **Deterministic behavior**: The vulnerability is in the core logic, not a race condition or timing-dependent bug

The attack can be executed with basic network access and requires minimal resources from the attacker while consuming victim resources processing and discarding incomplete streams.

## Recommendation

**Short-term fix**: Track incomplete stream metadata and reject new stream headers when one is in progress:

```rust
pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
    // Reject new stream if one is already in progress
    if self.stream.is_some() {
        bail!(
            "Cannot start new stream (request ID: {}) while stream is in progress",
            header.request_id
        );
    }
    
    let inbound_stream = InboundStream::new(header, self.max_fragments)?;
    self.stream = Some(inbound_stream);
    Ok(())
}
```

**Medium-term fix**: Add connection health monitoring that disconnects peers exhibiting malicious patterns:
- Track number of discarded/failed streams per peer
- Implement exponential backoff or connection termination after repeated violations
- Add metrics to monitor stream completion rates

**Long-term fix**: Support multiple concurrent streams per connection:
- Maintain a `HashMap<u32, InboundStream>` keyed by `request_id`
- Add maximum concurrent streams limit (e.g., 10 per peer)
- Implement stream timeout and cleanup mechanisms
- Add per-peer memory limits for buffered stream data

## Proof of Concept

```rust
// Add to network/framework/src/protocols/stream/mod.rs tests
#[test]
fn test_stream_header_interleaving_dos() {
    use crate::protocols::wire::messaging::v1::{DirectSendMsg, NetworkMessage};
    use crate::protocols::wire::handshake::v1::ProtocolId::ConsensusRpcBcs;
    
    // Create an inbound stream buffer
    let max_fragments = 10;
    let mut inbound_stream_buffer = InboundStreamBuffer::new(max_fragments);
    
    // Start first stream with 5 fragments
    let stream_header_1 = StreamHeader {
        request_id: 1,
        num_fragments: 5,
        message: NetworkMessage::DirectSendMsg(DirectSendMsg {
            protocol_id: ConsensusRpcBcs,
            priority: 0,
            raw_msg: vec![0xAA; 100], // Some data
        }),
    };
    assert!(inbound_stream_buffer.new_stream(stream_header_1).is_ok());
    
    // Send first fragment
    let fragment_1 = StreamFragment {
        request_id: 1,
        fragment_id: 1,
        raw_data: vec![0x01; 50],
    };
    assert!(inbound_stream_buffer.append_fragment(fragment_1).is_ok());
    
    // Attacker sends new stream header BEFORE completing first stream
    let stream_header_2 = StreamHeader {
        request_id: 2,
        num_fragments: 3,
        message: NetworkMessage::DirectSendMsg(DirectSendMsg {
            protocol_id: ConsensusRpcBcs,
            priority: 0,
            raw_msg: vec![0xBB; 100],
        }),
    };
    
    // This should fail but currently succeeds in discarding the first stream
    let result = inbound_stream_buffer.new_stream(stream_header_2);
    
    // BUG: The result is Err, but stream 1 has been discarded!
    assert!(result.is_err());
    
    // Try to continue first stream - this will fail because it was discarded
    let fragment_2 = StreamFragment {
        request_id: 1,
        fragment_id: 2,
        raw_data: vec![0x02; 50],
    };
    
    // This fails because request_id 1 stream no longer exists
    let append_result = inbound_stream_buffer.append_fragment(fragment_2);
    assert!(append_result.is_err()); // Proves first stream was lost
    
    // Demonstrates the DoS: first stream can never complete
    // Attacker can repeat this pattern to prevent any large message delivery
}
```

**Notes**

The vulnerability exists because `Option::replace()` performs the replacement before returning the old value, making the state mutation unavoidable even when an error is returned. The current implementation treats stream header arrival as a signal to unconditionally reset the stream buffer, rather than protecting in-progress streams. This is a design flaw in the state machine, not a race condition or edge case.

While regular `NetworkMessage` variants can interleave freely with stream fragments without issues, multiple `StreamMessage::Header` variants cannot safely interleave due to the single-stream-per-peer limitation. The fix requires either rejecting new headers when a stream is active, or supporting multiple concurrent streams with proper resource limits.

### Citations

**File:** network/framework/src/protocols/wire/messaging/v1/mod.rs (L47-52)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Deserialize, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub enum MultiplexMessage {
    Message(NetworkMessage),
    Stream(StreamMessage),
}
```

**File:** network/framework/src/peer/mod.rs (L138-140)
```rust
    /// Inbound stream buffer
    inbound_stream: InboundStreamBuffer,
}
```

**File:** network/framework/src/peer/mod.rs (L250-270)
```rust
                // Handle a new inbound MultiplexMessage that we've just read off
                // the wire from the remote peer.
                maybe_message = reader.next() => {
                    match maybe_message {
                        Some(message) =>  {
                            if let Err(err) = self.handle_inbound_message(message, &mut write_reqs_tx) {
                                warn!(
                                    NetworkSchema::new(&self.network_context)
                                        .connection_metadata(&self.connection_metadata),
                                    error = %err,
                                    "{} Error in handling inbound message from peer: {}, error: {}",
                                    self.network_context,
                                    remote_peer_id.short_str(),
                                    err
                                );
                            }
                        },
                        // The socket was gracefully closed by the remote peer.
                        None => self.shutdown(DisconnectReason::ConnectionClosed),
                    }
                },
```

**File:** network/framework/src/peer/mod.rs (L543-558)
```rust
    fn handle_inbound_stream_message(
        &mut self,
        message: StreamMessage,
    ) -> Result<(), PeerManagerError> {
        match message {
            StreamMessage::Header(header) => {
                self.inbound_stream.new_stream(header)?;
            },
            StreamMessage::Fragment(fragment) => {
                if let Some(message) = self.inbound_stream.append_fragment(fragment)? {
                    self.handle_inbound_network_message(message)?;
                }
            },
        }
        Ok(())
    }
```

**File:** network/framework/src/protocols/stream/mod.rs (L82-92)
```rust
    pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
        let inbound_stream = InboundStream::new(header, self.max_fragments)?;
        if let Some(old) = self.stream.replace(inbound_stream) {
            bail!(
                "Discarding existing stream for request ID: {}",
                old.request_id
            )
        } else {
            Ok(())
        }
    }
```
