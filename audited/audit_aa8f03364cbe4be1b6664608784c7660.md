# Audit Report

## Title
Missing Schema Migration Logic Causes Consensus Liveness Failure During Randomness Storage Upgrades

## Summary
The randomness generation storage system lacks schema migration logic, causing BCS deserialization failures to be silently ignored during validator restarts. When `AugmentedData` schema changes during upgrades, validators lose their persisted certified augmentation data, preventing them from processing blocks until they regenerate and broadcast new data, potentially causing network-wide liveness failures.

## Finding Description

The randomness generation system stores `AugmentedData` and `CertifiedAugData` using BCS serialization in RocksDB. The schema is defined without any migration logic: [1](#0-0) 

The `AugmentedData` struct contains fields that have evolved over time: [2](#0-1) 

When validators restart, the `RandDb::get_all()` method silently discards deserialization errors: [3](#0-2) 

During `AugDataStore` initialization, these silent failures result in empty state: [4](#0-3) 

The critical consensus impact occurs because validators only process blocks when they have their certified augmentation data: [5](#0-4) 

**Attack Scenario:**
1. Protocol upgrade changes `AugmentedData` schema (e.g., adding/removing fields like `fast_delta`)
2. BCS cannot deserialize old-format data into new struct (BCS is not forward/backward compatible)
3. Validators restart with new code
4. `filter_map` silently drops all deserialization errors
5. `get_all_certified_aug_data().unwrap_or_default()` returns empty vector
6. `my_certified_aug_data_exists()` returns false
7. Validators cannot process incoming blocks (line 380 guard fails)
8. Validators must regenerate and broadcast aug_data to form quorum
9. If many validators restart simultaneously during coordinated upgrade, they cannot form 2/3+ quorum to create certified_aug_data
10. Network experiences consensus liveness failure

## Impact Explanation

**High Severity** - This vulnerability can cause:
- **Validator node liveness failures**: Individual validators cannot process blocks after restart
- **Network-wide consensus disruption**: If enough validators (>1/3) are affected simultaneously during coordinated upgrades, the network cannot form quorum to certify augmentation data
- **Prolonged downtime**: Recovery requires manual intervention and coordination among validators

This meets the High severity criteria per Aptos bug bounty: "Validator node slowdowns" and "Significant protocol violations". While it doesn't cause permanent state corruption, it violates the consensus liveness invariant and can halt block processing network-wide.

## Likelihood Explanation

**High Likelihood** - This will occur during any protocol upgrade that modifies the `AugmentedData`, `CertifiedAugData`, or related type structures. The evidence shows this has already happened:
- The `fast_delta: Option<Delta>` field was added to `AugmentedData`, demonstrating schema evolution
- No migration code exists to handle such changes
- The silent error handling guarantees data loss on incompatible schema changes

The likelihood increases because:
- Schema evolution is a normal part of protocol development
- Coordinated upgrades are common (validators upgrade together at epoch boundaries)
- The failure is silent and non-obvious, making it difficult to detect until validators restart

## Recommendation

Implement explicit schema versioning and migration logic:

1. **Add version field to schemas:**
```rust
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct AugmentedDataV2 {
    version: u64,  // Add version field
    delta: Delta,
    fast_delta: Option<Delta>,
}
```

2. **Implement migration logic in get_all():**
```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    let results: Vec<_> = iter
        .filter_map(|e| match e {
            Ok((k, v)) => Some((k, v)),
            Err(e) => {
                // Log deserialization errors instead of silently ignoring
                error!("Failed to deserialize entry: {:?}", e);
                // Attempt migration from old format
                // ...
                None
            }
        })
        .collect();
    
    // If any errors occurred, return error instead of partial data
    Ok(results)
}
```

3. **Better alternative - Fail loudly on deserialization errors:**
```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    iter.collect::<Result<Vec<_>, _>>()  // Propagate errors instead of filtering
}
```

4. **Handle migration in AugDataStore::new():**
```rust
pub fn new(...) -> Self {
    let all_data = match db.get_all_aug_data() {
        Ok(data) => data,
        Err(e) => {
            error!("[AugDataStore] Failed to load aug_data, attempting migration: {:?}", e);
            // Implement migration or fail with clear error
            panic!("Cannot start without valid aug_data - manual intervention required");
        }
    };
    // ... rest of initialization
}
```

## Proof of Concept

```rust
// Reproduction steps:

// 1. Start validator with AugmentedData v1 (without fast_delta field)
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct AugmentedDataV1 {
    delta: Delta,
}

// Validator creates and stores certified_aug_data
let aug_data = AugData::new(epoch, author, AugmentedDataV1 { delta });
db.save_certified_aug_data(&certified_aug_data)?;

// 2. Upgrade code to AugmentedData v2 (with fast_delta field)
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct AugmentedDataV2 {
    delta: Delta,
    fast_delta: Option<Delta>,  // New field
}

// 3. Restart validator
// BCS deserialization of old data fails:
// bcs::from_bytes::<AugData<AugmentedDataV2>>(old_bytes) => Err(...)

// 4. Error is silently ignored in filter_map
// get_all_certified_aug_data() returns empty vec

// 5. Validator initialization:
let aug_data_store = AugDataStore::new(...);
// aug_data_store.certified_data is empty
// my_certified_aug_data_exists() returns false

// 6. Validator cannot process blocks:
// Line 380 guard fails: if self.aug_data_store.my_certified_aug_data_exists()
// Validator is stuck until it regenerates aug_data through network broadcast

// To reproduce:
// - Modify AugmentedData struct in types.rs
// - Build and deploy to validators
// - Restart validators
// - Observe that they cannot process blocks
// - Check logs for silent deserialization failures
```

**Notes:**
This vulnerability specifically affects the randomness generation subsystem during schema upgrades. The root cause is the combination of: (1) BCS's lack of forward/backward compatibility, (2) silent error handling in `filter_map`, and (3) the consensus-critical dependency on `my_certified_aug_data_exists()`. The fix requires implementing proper schema versioning, migration logic, and failing loudly on deserialization errors rather than silently discarding data.

### Citations

**File:** consensus/src/rand/rand_gen/storage/schema.rs (L36-96)
```rust
pub(crate) const AUG_DATA_CF_NAME: ColumnFamilyName = "aug_data";
#[derive(Debug)]
pub struct AugDataSchema<D>(PhantomData<D>);

impl<D: TAugmentedData> Schema for AugDataSchema<D> {
    type Key = AugDataId;
    type Value = AugData<D>;

    const COLUMN_FAMILY_NAME: ColumnFamilyName = AUG_DATA_CF_NAME;
}

impl<D: TAugmentedData> KeyCodec<AugDataSchema<D>> for AugDataId {
    fn encode_key(&self) -> anyhow::Result<Vec<u8>> {
        Ok(bcs::to_bytes(self)?)
    }

    fn decode_key(data: &[u8]) -> anyhow::Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

impl<D: TAugmentedData> ValueCodec<AugDataSchema<D>> for AugData<D> {
    fn encode_value(&self) -> anyhow::Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> anyhow::Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

pub(crate) const CERTIFIED_AUG_DATA_CF_NAME: ColumnFamilyName = "certified_aug_data";
#[derive(Debug)]
pub struct CertifiedAugDataSchema<D>(PhantomData<D>);

impl<D: TAugmentedData> Schema for CertifiedAugDataSchema<D> {
    type Key = AugDataId;
    type Value = CertifiedAugData<D>;

    const COLUMN_FAMILY_NAME: ColumnFamilyName = CERTIFIED_AUG_DATA_CF_NAME;
}

impl<D: TAugmentedData> KeyCodec<CertifiedAugDataSchema<D>> for AugDataId {
    fn encode_key(&self) -> anyhow::Result<Vec<u8>> {
        Ok(bcs::to_bytes(self)?)
    }

    fn decode_key(data: &[u8]) -> anyhow::Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

impl<D: TAugmentedData> ValueCodec<CertifiedAugDataSchema<D>> for CertifiedAugData<D> {
    fn encode_value(&self) -> anyhow::Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> anyhow::Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}
```

**File:** consensus/src/rand/rand_gen/types.rs (L45-49)
```rust
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct AugmentedData {
    delta: Delta,
    fast_delta: Option<Delta>,
}
```

**File:** consensus/src/rand/rand_gen/storage/db.rs (L73-82)
```rust
    fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter
            .filter_map(|e| match e {
                Ok((k, v)) => Some((k, v)),
                Err(_) => None,
            })
            .collect::<Vec<(S::Key, S::Value)>>())
    }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L51-65)
```rust
        let all_data = db.get_all_aug_data().unwrap_or_default();
        let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
        if let Err(e) = db.remove_aug_data(to_remove) {
            error!("[AugDataStore] failed to remove aug data: {:?}", e);
        }

        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L378-382)
```rust
        while !self.stop {
            tokio::select! {
                Some(blocks) = incoming_blocks.next(), if self.aug_data_store.my_certified_aug_data_exists() => {
                    self.process_incoming_blocks(blocks);
                }
```
