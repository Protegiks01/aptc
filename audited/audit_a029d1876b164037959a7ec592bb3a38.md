# Audit Report

## Title
Atomic Violation in State Merkle Tree Restore Leading to Unrecoverable Database Corruption

## Summary
The state restore mechanism performs non-atomic sequential writes across 16 database shards. When an I/O error, crash, or disk space exhaustion occurs during these writes, some shards are permanently committed while others remain unwritten, creating an unrecoverable inconsistent Merkle tree state that requires manual database deletion and restart.

## Finding Description

This vulnerability exists in the state snapshot restoration flow where frozen Merkle tree nodes are written to 16 sharded databases sequentially without transactional coordination.

**Vulnerable Code Flow:**

1. **Async Commit Initiation**: When `async_commit` is enabled, `add_chunk_impl()` spawns an asynchronous write operation [1](#0-0) 

2. **Sequential Non-Atomic Shard Writes**: The `write_node_batch()` method splits nodes across shards based on the first nibble of their path [2](#0-1)  and calls `commit_no_progress()` which writes to 16 shards sequentially in a loop [3](#0-2) 

3. **No Atomicity Guarantee**: Each `write_schemas()` call is individually atomic per RocksDB, but the sequence of 17 writes (16 shards + metadata) has NO transaction coordinator. [4](#0-3) 

4. **Incomplete Error Handling**: Errors are propagated through a channel after partial writes are durably committed [5](#0-4) 

**Attack Scenario:**

1. Validator performs state restore with async_commit enabled [6](#0-5) 
2. `commit_no_progress()` begins writing shards 0, 1, 2... sequentially
3. At shard N, an I/O error occurs (disk full, hardware failure, process crash)
4. **Shards 0 through N-1 are permanently committed** (RocksDB durability guarantees)
5. Shards N through 15 are never written
6. Database contains partial Merkle tree with missing nodes

**Why Recovery Fails:**

The crash recovery mechanism `recover_partial_nodes()` assumes consistent storage [7](#0-6) . It scans existing nodes and walks up from the rightmost leaf. With partial shard writes:
- Some child nodes exist (in written shards 0 to N-1)
- Sibling nodes at the same level are missing (in unwritten shards N+1 to 15)  
- Parent nodes may or may not exist based on shard assignment (determined by first nibble) [8](#0-7) 
- The reconstruction produces a structurally invalid tree

The `StateStore::reset()` method only recreates in-memory state from disk, it does NOT clean up corrupted data [9](#0-8) 

## Impact Explanation

**Medium Severity** - This qualifies as "State inconsistencies requiring manual intervention" per Aptos Bug Bounty criteria:

1. **Non-Recoverable Database Corruption**: The partial commit creates permanently corrupted storage with no automatic recovery mechanism. The database contains some nodes but not others, violating tree structure invariants.

2. **Requires Manual Intervention**: Affected validators must:
   - Detect the corruption (restore fails verification)
   - Manually delete all state merkle data (`rm -rf` database directories)
   - Restart state restore from scratch
   - This could take hours to days depending on state size

3. **Operational Impact**: Any validator performing state restore is vulnerable during:
   - Initial node setup and synchronization
   - Disaster recovery scenarios
   - State snapshot operations

4. **Potential Consensus Risk**: If multiple validators hit this bug at different points during restore, they could end up with different corrupted states, potentially causing consensus disagreement once they resume operation.

This does NOT qualify as Critical because it does not enable fund theft, does not cause permanent network halts, and does not directly break consensus (only affects validators in restore mode).

## Likelihood Explanation

**Moderate to High Likelihood:**

1. **Realistic Triggers**:
   - Disk space exhaustion during large state snapshot sync (multi-GB writes)
   - Storage hardware I/O errors or failures
   - Process crashes during write operations
   - Network storage (NFS/SAN) disconnections
   - Out-of-memory conditions during intensive I/O

2. **Wide Attack Surface**:
   - Any validator performing initial sync from genesis or snapshot
   - Validators recovering from crashes or data corruption
   - Regular state backup/restore operations

3. **No Protection Mechanisms**:
   - No retry logic in the write path
   - No two-phase commit or transaction coordinator
   - No integrity verification after writes complete
   - Progress tracking explicitly disabled by design (`commit_no_progress`)

4. **Production Frequency**: State restore is performed regularly in production environments during node onboarding, upgrades, and disaster recovery scenarios.

## Recommendation

Implement atomic cross-shard writes using one of these approaches:

**Option 1: Two-Phase Commit**
```rust
pub(crate) fn commit_no_progress(
    &self,
    top_level_batch: SchemaBatch,
    batches_for_shards: Vec<SchemaBatch>,
) -> Result<()> {
    // Phase 1: Prepare - write to all shards with sync disabled
    for (shard_id, batch) in batches_for_shards.iter().enumerate() {
        self.state_merkle_db_shards[shard_id].write_schemas_relaxed(batch.clone())?;
    }
    self.state_merkle_metadata_db.write_schemas_relaxed(top_level_batch.clone())?;
    
    // Phase 2: Commit - sync all writes atomically
    for shard_id in 0..NUM_STATE_SHARDS {
        self.state_merkle_db_shards[shard_id].sync()?;
    }
    self.state_merkle_metadata_db.sync()?;
    
    Ok(())
}
```

**Option 2: Write-Ahead Log**
- Log the intended write operation before executing
- If crash occurs, replay or rollback based on log
- Delete log entry only after all shards committed

**Option 3: Versioned Snapshots**
- Write to new version-tagged database instances
- Atomically swap to new version only after all writes succeed
- Keep old version for rollback

## Proof of Concept

```rust
#[test]
fn test_partial_shard_write_corruption() {
    use storage::jellyfish_merkle::restore::JellyfishMerkleRestore;
    use storage::state_merkle_db::StateMerkleDb;
    
    // Setup: Create state merkle DB with sharding enabled
    let tmpdir = TempPath::new();
    let db = StateMerkleDb::new(&tmpdir);
    let restore = JellyfishMerkleRestore::new(
        Arc::new(db),
        0, // version
        HashValue::random(),
        true, // async_commit enabled
    ).unwrap();
    
    // Simulate partial write by injecting I/O error at shard 3
    // (This would require fault injection in the test environment)
    let chunk = generate_test_state_chunk(1000);
    let proof = generate_valid_proof(&chunk);
    
    // Attempt to add chunk - will fail at shard 3
    let result = restore.add_chunk(chunk, proof);
    assert!(result.is_err());
    
    // Verify corruption: Some shards have data, others don't
    // Subsequent restore attempts will fail with inconsistent tree
    let restore2 = JellyfishMerkleRestore::new(
        Arc::new(db),
        0,
        HashValue::random(),
        false,
    );
    
    // This will fail because recover_partial_nodes finds inconsistent state
    assert!(restore2.is_err() || !restore2.unwrap().verify_consistent());
}
```

**Notes:**
- This vulnerability requires actual I/O failures to trigger, which can be simulated using fault injection frameworks
- The corrupted state persists across process restarts
- Manual database deletion is the only recovery path currently available

### Citations

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L267-334)
```rust
    fn recover_partial_nodes(
        store: &dyn TreeReader<K>,
        version: Version,
        rightmost_leaf_node_key: NodeKey,
    ) -> Result<Vec<InternalInfo<K>>> {
        ensure!(
            !rightmost_leaf_node_key.nibble_path().is_empty(),
            "Root node would not be written until entire restoration process has completed \
             successfully.",
        );

        // Start from the parent of the rightmost leaf. If this internal node exists in storage, it
        // is not a partial node. Go to the parent node and repeat until we see a node that does
        // not exist. This node and all its ancestors will be the partial nodes.
        let mut node_key = rightmost_leaf_node_key.gen_parent_node_key();
        while store.get_node_option(&node_key, "restore")?.is_some() {
            node_key = node_key.gen_parent_node_key();
        }

        // Next we reconstruct all the partial nodes up to the root node, starting from the bottom.
        // For all of them, we scan all its possible child positions and see if there is one at
        // each position. If the node is not the bottom one, there is additionally a partial node
        // child at the position `previous_child_index`.
        let mut partial_nodes = vec![];
        // Initialize `previous_child_index` to `None` for the first iteration of the loop so the
        // code below treats it differently.
        let mut previous_child_index = None;

        loop {
            let mut internal_info = InternalInfo::new_empty(node_key.clone());

            for i in 0..previous_child_index.unwrap_or(16) {
                let child_node_key = node_key.gen_child_node_key(version, (i as u8).into());
                if let Some(node) = store.get_node_option(&child_node_key, "restore")? {
                    let child_info = match node {
                        Node::Internal(internal_node) => ChildInfo::Internal {
                            hash: Some(internal_node.hash()),
                            leaf_count: Some(internal_node.leaf_count()),
                        },
                        Node::Leaf(leaf_node) => ChildInfo::Leaf(leaf_node),
                        Node::Null => unreachable!("Child cannot be Null"),
                    };
                    internal_info.set_child(i, child_info);
                }
            }

            // If this is not the lowest partial node, it will have a partial node child at
            // `previous_child_index`. Set the hash of this child to `None` because it is a
            // partial node and we do not know its hash yet. For the lowest partial node, we just
            // find all its known children from storage in the loop above.
            if let Some(index) = previous_child_index {
                internal_info.set_child(index, ChildInfo::Internal {
                    hash: None,
                    leaf_count: None,
                });
            }

            partial_nodes.push(internal_info);
            if node_key.nibble_path().is_empty() {
                break;
            }
            previous_child_index = node_key.nibble_path().last().map(|x| u8::from(x) as usize);
            node_key = node_key.gen_parent_node_key();
        }

        partial_nodes.reverse();
        Ok(partial_nodes)
    }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L394-410)
```rust
        if self.async_commit {
            self.wait_for_async_commit()?;
            let (tx, rx) = channel();
            self.async_commit_result = Some(rx);

            let mut frozen_nodes = HashMap::new();
            std::mem::swap(&mut frozen_nodes, &mut self.frozen_nodes);
            let store = self.store.clone();

            IO_POOL.spawn(move || {
                let res = store.write_node_batch(&frozen_nodes);
                tx.send(res).unwrap();
            });
        } else {
            self.store.write_node_batch(&self.frozen_nodes)?;
            self.frozen_nodes.clear();
        }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L741-746)
```rust
    pub fn wait_for_async_commit(&mut self) -> Result<()> {
        if let Some(rx) = self.async_commit_result.take() {
            rx.recv()??;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L174-190)
```rust
    pub(crate) fn commit_no_progress(
        &self,
        top_level_batch: SchemaBatch,
        batches_for_shards: Vec<SchemaBatch>,
    ) -> Result<()> {
        ensure!(
            batches_for_shards.len() == NUM_STATE_SHARDS,
            "Shard count mismatch."
        );
        let mut batches = batches_for_shards.into_iter();
        for shard_id in 0..NUM_STATE_SHARDS {
            let state_merkle_batch = batches.next().unwrap();
            self.state_merkle_db_shards[shard_id].write_schemas(state_merkle_batch)?;
        }

        self.state_merkle_metadata_db.write_schemas(top_level_batch)
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L918-932)
```rust
    fn write_node_batch(&self, node_batch: &NodeBatch) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["tree_writer_write_batch"]);
        // Get the top level batch and sharded batch from raw NodeBatch
        let mut top_level_batch = SchemaBatch::new();
        let mut jmt_shard_batches: Vec<SchemaBatch> = Vec::with_capacity(NUM_STATE_SHARDS);
        jmt_shard_batches.resize_with(NUM_STATE_SHARDS, SchemaBatch::new);
        node_batch.iter().try_for_each(|(node_key, node)| {
            if let Some(shard_id) = node_key.get_shard_id() {
                jmt_shard_batches[shard_id].put::<JellyfishMerkleNodeSchema>(node_key, node)
            } else {
                top_level_batch.put::<JellyfishMerkleNodeSchema>(node_key, node)
            }
        })?;
        self.commit_no_progress(top_level_batch, jmt_shard_batches)
    }
```

**File:** storage/schemadb/src/lib.rs (L289-309)
```rust
    fn write_schemas_inner(&self, batch: impl IntoRawBatch, option: &WriteOptions) -> DbResult<()> {
        let labels = [self.name.as_str()];
        let _timer = APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS.timer_with(&labels);

        let raw_batch = batch.into_raw_batch(self)?;

        let serialized_size = raw_batch.inner.size_in_bytes();
        self.inner
            .write_opt(raw_batch.inner, option)
            .into_db_res()?;

        raw_batch.stats.commit();
        APTOS_SCHEMADB_BATCH_COMMIT_BYTES.observe_with(&[&self.name], serialized_size as f64);

        Ok(())
    }

    /// Writes a group of records wrapped in a [`SchemaBatch`].
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }
```

**File:** storage/aptosdb/src/backup/restore_handler.rs (L41-55)
```rust
    pub fn get_state_restore_receiver(
        &self,
        version: Version,
        expected_root_hash: HashValue,
        restore_mode: StateSnapshotRestoreMode,
    ) -> Result<StateSnapshotRestore<StateKey, StateValue>> {
        StateSnapshotRestore::new(
            &self.state_store.state_merkle_db,
            &self.state_store,
            version,
            expected_root_hash,
            true, /* async_commit */
            restore_mode,
        )
    }
```

**File:** types/src/nibble/nibble_path/mod.rs (L222-225)
```rust
    // Returns the shard_id of the NibblePath, or None if it is root.
    pub fn get_shard_id(&self) -> Option<usize> {
        if self.num_nibbles() > 0 {
            Some(usize::from(self.get_nibble(0)))
```

**File:** storage/aptosdb/src/state_store/mod.rs (L707-719)
```rust
    pub fn reset(&self) {
        self.buffered_state.lock().quit();
        *self.buffered_state.lock() = Self::create_buffered_state_from_latest_snapshot(
            &self.state_db,
            self.buffered_state_target_items,
            false,
            true,
            self.current_state.clone(),
            self.persisted_state.clone(),
            self.hot_state_config,
        )
        .expect("buffered state creation failed.");
    }
```
