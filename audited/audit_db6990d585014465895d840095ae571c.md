# Audit Report

## Title
Dependency Merge Order Violation in `remove_v2` Causes Validator Node Crashes

## Summary
The `remove_v2` method in `versioned_group_data.rs` incorrectly assumes that dependencies can be merged with a strict ordering constraint when migrating them from a removed entry to a lower-indexed entry. This assumption is violated in BlockSTM's speculative execution model due to transaction re-executions, causing a `PanicError` that crashes validator nodes when fallback is disabled.

## Finding Description

The vulnerability exists in the dependency migration logic when removing resource group size entries: [1](#0-0) 

The code calls `extend_with_higher_dependencies` which enforces an invariant that all dependencies in the target entry (next_lower_entry) must have strictly lower transaction indices than all dependencies in the source (removed_size_deps): [2](#0-1) 

However, this invariant is **violated** due to BlockSTM's re-execution model. Dependencies are registered when transactions read from entries, and the transaction index performing the read (not the entry's index) is what gets recorded: [3](#0-2) 

**Attack Scenario:**

1. Entry at index 5 exists with size S1
2. Entry at index 10 is created with size S1  
3. Transaction 12 reads size, finds entry 10, registers dependency {12: inc0} in entry 10
4. Transaction 10 aborts (e.g., due to dependency failure), `remove_v2` is called
5. Dependencies {12: inc0} are successfully merged into entry 5 (check passes: no deps yet)
6. Transaction 10 re-executes (inc 1), creates new entry at index 10 with size S1
7. Transaction 9 reads size, finds entry 10, registers dependency {9: inc0} in entry 10
8. Transaction 10 aborts again, `remove_v2` is called
9. **BUG TRIGGERS**: Try to merge {9: inc0} into entry 5 which has {12: inc0}
10. Check fails: `highest_dep_idx in {12} = 12 should be < lowest in {9} = 9`
11. `extend_with_higher_dependencies` returns `PanicError::CodeInvariantError`

The error propagates through the execution stack: [4](#0-3) 

And if fallback is disabled, the validator **panics**: [5](#0-4) 

## Impact Explanation

**Severity: CRITICAL**

This vulnerability meets the Critical severity criteria under "Total loss of liveness/network availability":

1. **Validator Node Crashes**: When `allow_fallback` is disabled (typical in production for performance), triggering this bug causes a panic that crashes the validator node
2. **Consensus Liveness Impact**: If multiple validators can be triggered to crash simultaneously through carefully crafted transaction patterns, it could cause consensus liveness failures
3. **Deterministic Execution Violation**: Different validators may crash at different times based on timing, violating the deterministic execution invariant
4. **Network Availability**: Repeated crashes of validator nodes reduces network availability and could enable other attacks

The bug is in production code used by BlockSTMv2, which is deployed on mainnet: [6](#0-5) 

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The vulnerability can be triggered when:
1. BlockSTMv2 is enabled (production setting)
2. Transactions cause specific abort/re-execution patterns involving resource groups
3. Multiple transactions read the same resource group size at different execution points
4. Transaction re-executions occur in a specific order

While requiring specific conditions, these conditions naturally arise in BlockSTM's normal operation:
- Transaction aborts are common during speculative execution
- Resource group operations are used throughout the Aptos Framework
- Re-execution with incremented incarnations is standard BlockSTM behavior

An attacker could increase likelihood by:
- Submitting transactions that intentionally conflict on resource groups
- Creating read-write patterns that maximize re-execution probability
- Targeting heavily-used resource groups to affect multiple validators

## Recommendation

Replace `extend_with_higher_dependencies` with the regular `extend` method, as the ordering invariant does not hold in this context:

```rust
// In versioned_group_data.rs, line 396-400:
if next_lower_entry.value.size == removed_size_entry.value.size {
    next_lower_entry
        .value
        .dependencies
        .lock()
        .extend(std::mem::take(&mut removed_size_deps)); // Changed from extend_with_higher_dependencies
}
```

The regular `extend` method correctly handles dependency merging by keeping the latest incarnation for each transaction index without enforcing ordering constraints: [7](#0-6) 

## Proof of Concept

```rust
#[test]
fn test_dependency_ordering_violation_on_remove() {
    use aptos_move::mvhashmap::versioned_group_data::VersionedGroupData;
    use aptos_move::mvhashmap::types::{KeyType, TestValue};
    use aptos_vm_types::resolver::ResourceGroupSize;
    use std::collections::HashSet;

    let group_key = KeyType(b"/test/group".to_vec());
    let tag = 0usize;
    let group_data = VersionedGroupData::<KeyType<Vec<u8>>, usize, TestValue>::empty();
    
    // Initialize group
    group_data.set_raw_base_values(group_key.clone(), vec![]).unwrap();
    
    let size = ResourceGroupSize::Combined {
        num_tagged_resources: 1,
        all_tagged_resources_size: 100,
    };
    
    // Step 1: Create entry at index 5
    group_data.write_v2(
        group_key.clone(),
        5,  // txn_idx
        0,  // incarnation
        vec![(tag, (TestValue::creation_with_len(1), None))],
        size,
        HashSet::new(),
    ).unwrap();
    
    // Step 2: Create entry at index 10
    group_data.write_v2(
        group_key.clone(),
        10, // txn_idx
        0,  // incarnation  
        vec![(tag, (TestValue::creation_with_len(1), None))],
        size,
        HashSet::new(),
    ).unwrap();
    
    // Step 3: Txn 12 reads, creates dependency on entry 10
    group_data.get_group_size_and_record_dependency(&group_key, 12, 0).unwrap();
    
    // Step 4: Remove entry 10 (txn 10 aborts), dependencies migrate to entry 5
    group_data.remove_v2(&group_key, 10, HashSet::from([&tag])).unwrap();
    
    // Step 5: Re-create entry 10 (txn 10 re-executes with inc 1)
    group_data.write_v2(
        group_key.clone(),
        10,
        1,  // incremented incarnation
        vec![(tag, (TestValue::creation_with_len(1), None))],
        size,
        HashSet::new(),
    ).unwrap();
    
    // Step 6: Txn 9 reads, creates dependency on entry 10  
    group_data.get_group_size_and_record_dependency(&group_key, 9, 0).unwrap();
    
    // Step 7: Remove entry 10 again - THIS TRIGGERS THE BUG
    // Entry 5 has dependency {12: inc0}, trying to merge {9: inc0}
    // extend_with_higher_dependencies will fail: 12 >= 9
    let result = group_data.remove_v2(&group_key, 10, HashSet::from([&tag]));
    
    // This will return PanicError in vulnerable code
    assert!(result.is_err(), "Expected PanicError due to dependency ordering violation");
}
```

**Notes:**
- This bug only affects BlockSTMv2, not the original BlockSTM implementation
- The vulnerability is in production code path used when `blockstm_v2` is enabled
- The fix is simple and maintains correctness while removing the invalid ordering constraint
- Even with fallback enabled, sequential execution may encounter the same issue if transaction ordering is preserved

### Citations

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L395-401)
```rust
            if next_lower_entry.value.size == removed_size_entry.value.size {
                next_lower_entry
                    .value
                    .dependencies
                    .lock()
                    .extend_with_higher_dependencies(std::mem::take(&mut removed_size_deps))?;
            }
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L485-497)
```rust
    pub fn get_group_size_and_record_dependency(
        &self,
        group_key: &K,
        txn_idx: TxnIndex,
        incarnation: Incarnation,
    ) -> Result<ResourceGroupSize, MVGroupError> {
        match self.group_sizes.get(group_key) {
            Some(g) => {
                Self::get_latest_entry(&g.size_entries, txn_idx, ReadPosition::BeforeCurrentTxn)
                    .map_or(Err(MVGroupError::Uninitialized), |(_, size)| {
                        // TODO(BlockSTMv2): convert to PanicErrors after MVHashMap refactoring.
                        assert_ok!(size.value.dependencies.lock().insert(txn_idx, incarnation));
                        Ok(size.value.size)
```

**File:** aptos-move/mvhashmap/src/registered_dependencies.rs (L96-98)
```rust
    pub(crate) fn extend(&mut self, other: BTreeMap<TxnIndex, Incarnation>) {
        Self::extend_impl(&mut self.dependencies, other);
    }
```

**File:** aptos-move/mvhashmap/src/registered_dependencies.rs (L104-117)
```rust
    pub(crate) fn extend_with_higher_dependencies(
        &mut self,
        other: BTreeMap<TxnIndex, Incarnation>,
    ) -> Result<(), PanicError> {
        let dependencies = &mut self.dependencies;
        if let Some((highest_dep_idx, _)) = dependencies.last_key_value() {
            // Highest dependency in self should be strictly less than other dependencies.
            check_lowest_dependency_idx(&other, *highest_dep_idx)?;
        }

        Self::extend_impl(dependencies, other);

        Ok(())
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1778-1799)
```rust
                    if let Err(err) = self.worker_loop_v2(
                        &executor,
                        signature_verified_block,
                        environment,
                        *worker_id,
                        num_workers,
                        &scheduler,
                        &shared_sync_params,
                    ) {
                        // If there are multiple errors, they all get logged: FatalVMError is
                        // logged at construction, below we log CodeInvariantErrors.
                        if let PanicOr::CodeInvariantError(err_msg) = err {
                            alert!(
                                "[BlockSTMv2] worker loop: CodeInvariantError({:?})",
                                err_msg
                            );
                        }
                        shared_maybe_error.store(true, Ordering::SeqCst);

                        // Make sure to halt the scheduler if it hasn't already been halted.
                        scheduler.halt();
                    }
```

**File:** aptos-move/block-executor/src/executor.rs (L2558-2565)
```rust
            let parallel_result = if self.config.local.blockstm_v2 {
                BLOCKSTM_VERSION_NUMBER.set(2);
                self.execute_transactions_parallel_v2(
                    signature_verified_block,
                    base_view,
                    transaction_slice_metadata,
                    module_cache_manager_guard,
                )
```

**File:** aptos-move/block-executor/src/executor.rs (L2581-2583)
```rust
            if !self.config.local.allow_fallback {
                panic!("Parallel execution failed and fallback is not allowed");
            }
```
