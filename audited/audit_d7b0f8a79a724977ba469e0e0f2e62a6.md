# Audit Report

## Title
Consensus Liveness Failure via Unvalidated Block Author Transaction Filters

## Summary
The `BlockTransactionFilterConfig::new()` constructor accepts arbitrary `BlockTransactionFilter` configurations without validating consensus compatibility. This allows individual validator nodes to configure filters that reject all transactions from specific block authors, causing execution divergence across validators and preventing quorum certificate formation, resulting in total network liveness failure.

## Finding Description

The vulnerability exists in the lack of validation when creating block transaction filter configurations. The `BlockTransactionFilterConfig::new()` constructor accepts any `BlockTransactionFilter` without checking for consensus-incompatible rules: [1](#0-0) 

The `BlockTransactionFilter` supports matching on block authors via `BlockMatcher::Author(address)`, which can be used to create deny rules targeting specific validators: [2](#0-1) 

This breaks the **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks."

**Attack Flow:**

1. Validator V1 loads a malicious/misconfigured filter that denies all transactions from blocks authored by validator V2:
   ```yaml
   consensus_filter:
     filter_enabled: true
     block_transaction_filter:
       block_transaction_rules:
         - Deny:
             - Block:
                 Author: "0x<V2_address>"
   ```

2. When V2 proposes a block with transactions [T1, T2, T3], the filter is applied during block preparation before execution: [3](#0-2) 

3. V1 executes an empty transaction set (all filtered out), while other validators execute [T1, T2, T3].

4. During block insertion and execution, V1 computes a different state root: [4](#0-3) 

5. Validators create votes containing their execution results in the LedgerInfo, which includes the `executed_state_id` (state root) in BlockInfo: [5](#0-4) 

6. Votes are aggregated by LedgerInfo hash. Different state roots produce different hashes, preventing vote aggregation: [6](#0-5) 

7. If f+1 validators have incompatible filters causing different execution results, no quorum (2f+1) can form on any single state root, causing **total liveness failure**.

The test suite demonstrates that block author filtering is an intended feature: [7](#0-6) 

## Impact Explanation

**Critical Severity** - Total loss of liveness/network availability.

If f+1 validators adopt different consensus filters (even through accidental misconfiguration rather than malice), the network cannot form quorum certificates because validators compute different state roots for the same blocks. This results in complete network halt requiring manual intervention to align validator configurations.

Even a single validator with author-based filtering causes degraded liveness when that validator fails to participate in consensus rounds for blocks from targeted authors, reducing the effective validator set size and increasing the risk of falling below quorum thresholds during partial network partitions.

This meets the Critical severity criteria: "Total loss of liveness/network availability" and "Non-recoverable network partition (requires hardfork)" if divergent states are committed.

## Likelihood Explanation

**Medium-to-High Likelihood** depending on threat model:

**Accidental Misconfiguration:** Validator operators could unintentionally deploy divergent filter configurations during routine maintenance, especially if configs are managed independently per validator without coordination.

**Intentional Attack (requires validator access):** An attacker with access to f+1 validator configurations (through supply chain attacks, compromised operators, or social engineering) could deploy incompatible filters to halt the network.

The lack of any validation or warning in the constructor makes this easy to trigger accidentally. The code explicitly supports block author filtering with test coverage, indicating this is considered a valid use case without safety guardrails.

## Recommendation

Add validation to `BlockTransactionFilterConfig::new()` to prevent consensus-incompatible configurations:

```rust
impl BlockTransactionFilterConfig {
    pub fn new(filter_enabled: bool, block_transaction_filter: BlockTransactionFilter) -> Result<Self, String> {
        // Validate that filters don't create consensus incompatibility
        if filter_enabled && block_transaction_filter.uses_block_author_matching() {
            return Err(
                "Block author-based transaction filters can cause consensus divergence. \
                 All validators must use identical consensus filters to maintain network liveness."
                    .to_string(),
            );
        }
        
        Ok(Self {
            filter_enabled,
            block_transaction_filter,
        })
    }
}
```

Add a method to detect problematic filter patterns:

```rust
impl BlockTransactionFilter {
    pub fn uses_block_author_matching(&self) -> bool {
        self.block_transaction_rules.iter().any(|rule| {
            let matchers = match rule {
                BlockTransactionRule::Allow(m) | BlockTransactionRule::Deny(m) => m,
            };
            matchers.iter().any(|m| matches!(
                m,
                BlockTransactionMatcher::Block(BlockMatcher::Author(_))
            ))
        })
    }
}
```

Additionally:
1. Add runtime monitoring to detect when validators execute blocks with different transaction sets
2. Document that consensus filters MUST be identical across all validators
3. Provide tooling to validate filter configuration consistency before deployment

## Proof of Concept

The existing smoke test demonstrates the vulnerability mechanism. Modify it to show consensus failure with divergent configs:

```rust
#[tokio::test]
async fn test_consensus_divergence_with_author_filter() {
    // Create swarm with 4 validators
    let mut swarm = SwarmBuilder::new_local(4).with_aptos().build().await;
    
    // Configure validator 0 and 1 to filter transactions from validator 2's blocks
    let validator_2_address = swarm.validators().nth(2).unwrap().peer_id();
    swarm.validators_mut().nth(0).unwrap()
        .config_mut()
        .transaction_filters
        .consensus_filter = BlockTransactionFilterConfig::new(
            true,
            BlockTransactionFilter::empty().add_block_author_filter(false, validator_2_address)
        );
    
    // When validator 2 proposes blocks, validators 0 and 1 execute differently
    // This causes vote aggregation to fail and consensus stalls
    // Test would show that blocks from validator 2 don't get QCs
}
```

The vulnerability is demonstrated by the fact that `BlockTransactionFilterConfig::new()` accepts this configuration without error, and the filter will be applied during consensus execution, causing the divergence described above.

### Citations

**File:** config/src/config/transaction_filters_config.rs (L98-103)
```rust
    pub fn new(filter_enabled: bool, block_transaction_filter: BlockTransactionFilter) -> Self {
        Self {
            filter_enabled,
            block_transaction_filter,
        }
    }
```

**File:** crates/aptos-transaction-filters/src/block_transaction_filter.rs (L250-260)
```rust
/// A matcher that defines the criteria for matching blocks
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
pub enum BlockMatcher {
    All,                            // Matches any block
    Author(AccountAddress),         // Matches blocks proposed by the specified author
    BlockId(HashValue),             // Matches blocks with the specified ID
    BlockEpochGreaterThan(u64),     // Matches blocks with epochs greater than the specified value
    BlockEpochLessThan(u64),        // Matches blocks with epochs less than the specified value
    BlockTimeStampGreaterThan(u64), // Matches blocks with timestamps greater than the specified value
    BlockTimeStampLessThan(u64),    // Matches blocks with timestamps less than the specified value
}
```

**File:** consensus/src/block_preparer.rs (L122-146)
```rust
/// Filters transactions in a block based on the filter configuration
fn filter_block_transactions(
    txn_filter_config: Arc<BlockTransactionFilterConfig>,
    block_id: HashValue,
    block_author: Option<AccountAddress>,
    block_epoch: u64,
    block_timestamp_usecs: u64,
    txns: Vec<SignedTransaction>,
) -> Vec<SignedTransaction> {
    // If the transaction filter is disabled, return early
    if !txn_filter_config.is_enabled() {
        return txns;
    }

    // Otherwise, filter the transactions
    txn_filter_config
        .block_transaction_filter()
        .filter_block_transactions(
            block_id,
            block_author,
            block_epoch,
            block_timestamp_usecs,
            txns,
        )
}
```

**File:** consensus/src/round_manager.rs (L1500-1527)
```rust
    async fn vote_block(&mut self, proposed_block: Block) -> anyhow::Result<Vote> {
        let block_arc = self
            .block_store
            .insert_block(proposed_block)
            .await
            .context("[RoundManager] Failed to execute_and_insert the block")?;

        // Short circuit if already voted.
        ensure!(
            self.round_state.vote_sent().is_none(),
            "[RoundManager] Already vote on this round {}",
            self.round_state.current_round()
        );

        ensure!(
            !self.sync_only(),
            "[RoundManager] sync_only flag is set, stop voting"
        );

        let vote_proposal = block_arc.vote_proposal();
        let vote_result = self.safety_rules.lock().construct_and_sign_vote_two_chain(
            &vote_proposal,
            self.block_store.highest_2chain_timeout_cert().as_deref(),
        );
        let vote = vote_result.context(format!(
            "[RoundManager] SafetyRules Rejected {}",
            block_arc.block()
        ))?;
```

**File:** types/src/block_info.rs (L29-44)
```rust
pub struct BlockInfo {
    /// The epoch to which the block belongs.
    epoch: u64,
    /// The consensus protocol is executed in rounds, which monotonically increase per epoch.
    round: Round,
    /// The identifier (hash) of the block.
    id: HashValue,
    /// The accumulator root hash after executing this block.
    executed_state_id: HashValue,
    /// The version of the latest transaction after executing this block.
    version: Version,
    /// The timestamp this block was proposed by a proposer.
    timestamp_usecs: u64,
    /// An optional field containing the next epoch info
    next_epoch_state: Option<EpochState>,
}
```

**File:** consensus/src/pending_votes.rs (L281-329)
```rust
        let li_digest = vote.ledger_info().hash();

        //
        // 1. Has the author already voted for this round?
        //

        if let Some((previously_seen_vote, previous_li_digest)) =
            self.author_to_vote.get(&vote.author())
        {
            // is it the same vote?
            if &li_digest == previous_li_digest {
                // we've already seen an equivalent vote before
                let new_timeout_vote = vote.is_timeout() && !previously_seen_vote.is_timeout();
                if !new_timeout_vote {
                    // it's not a new timeout vote
                    return VoteReceptionResult::DuplicateVote;
                }
            } else {
                // we have seen a different vote for the same round
                error!(
                    SecurityEvent::ConsensusEquivocatingVote,
                    remote_peer = vote.author(),
                    vote = vote,
                    previous_vote = previously_seen_vote
                );

                return VoteReceptionResult::EquivocateVote;
            }
        }

        //
        // 2. Store new vote (or update, in case it's a new timeout vote)
        //

        self.author_to_vote
            .insert(vote.author(), (vote.clone(), li_digest));

        //
        // 3. Let's check if we can create a QC
        //

        let len = self.li_digest_to_votes.len() + 1;
        // obtain the ledger info with signatures associated to the vote's ledger info
        let (hash_index, status) = self.li_digest_to_votes.entry(li_digest).or_insert_with(|| {
            (
                len,
                VoteStatus::NotEnoughVotes(SignatureAggregator::new(vote.ledger_info().clone())),
            )
        });
```

**File:** crates/aptos-transaction-filters/src/tests/block_transaction_filter_config.rs (L121-168)
```rust
        // Create a malicious block author (where blocks are not allowed)
        let malicious_block_author = AccountAddress::random();

        // Create a filter that denies transactions based on multiple criteria
        let transactions = utils::create_entry_function_transactions(use_new_txn_payload_format);
        let block_transaction_filter_string = format!(
            r#"
            block_transaction_rules:
                - Deny:
                    - Transaction:
                        Sender: "{}"
                    - Transaction:
                        ModuleAddress: "0000000000000000000000000000000000000000000000000000000000000000"
                    - Block:
                        BlockId: "{}"
                - Deny:
                    - Transaction:
                        Sender: "{}"
                    - Transaction:
                        EntryFunction:
                            - "0000000000000000000000000000000000000000000000000000000000000001"
                            - entry
                            - check
                    - Block:
                        BlockId: "{}"
                - Deny:
                    - Transaction:
                        Sender: "{}"
                    - Block:
                        BlockId: "0000000000000000000000000000000000000000000000000000000000000000"
                - Deny:
                    - Block:
                        Author: "{}"
                - Deny:
                    - Block:
                        BlockEpochLessThan: {}
                - Allow:
                    - Transaction:
                        All
          "#,
            transactions[0].sender().to_standard_string(),
            block_id.to_hex(),
            transactions[1].sender().to_standard_string(),
            block_id.to_hex(),
            transactions[2].sender().to_standard_string(),
            malicious_block_author,
            block_epoch,
        );
```
