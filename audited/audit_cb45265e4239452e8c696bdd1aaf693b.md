# Audit Report

## Title
State Sync Accepts Corrupted Intermediate State Checkpoint Hashes in Multi-Block Chunks

## Summary
During state synchronization, when a chunk contains multiple blocks with state checkpoints, only the final checkpoint hash is validated against the locally computed state root. Intermediate checkpoint hashes are accepted without validation, allowing corrupted state metadata to be persisted in the database.

## Finding Description
The vulnerability exists in the state checkpoint validation logic during state sync when transaction outputs are applied without re-execution. The issue manifests when state sync receives chunks containing multiple blocks: [1](#0-0) 

When `known_state_checkpoints` is provided (which occurs during state sync), the validation only checks if the **last** checkpoint hash matches the locally computed state root. This happens because:

1. State sync receives a chunk with multiple blocks (e.g., blocks at transaction indices 99, 199, 299)
2. The chunk executor applies transaction outputs and updates the state tree incrementally
3. `StateUpdateRefs` is constructed with all checkpoint indices tracked in `all_checkpoint_indices`: [2](#0-1) 

4. However, only `last_checkpoint_index` (the final one) is used for validation, while `all_checkpoint_versions` containing all checkpoints is stored but not validated: [3](#0-2) 

5. The `for_last_checkpoint` field contains state updates up to and including only the **last** checkpoint, not intermediate ones, so intermediate state roots are never computed or validated

6. When `enqueue_chunk_by_transaction_outputs` is called during state sync (which applies outputs without re-execution): [4](#0-3) 

The system calls the chunk executor which eventually validates only the last checkpoint in `update_ledger`: [5](#0-4) 

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs" because state checkpoint hashes (which serve as Merkle root proofs) are not verified to match the actual state.

**Attack Scenario:**
1. A malicious or buggy state sync peer sends a chunk containing blocks 1000-1002
2. Block 1000 ends at index 99 with **corrupted** state checkpoint hash A
3. Block 1001 ends at index 199 with **corrupted** state checkpoint hash B  
4. Block 2002 ends at index 299 with **correct** state checkpoint hash C
5. Validation only checks: `known[299] == state_summary.last_checkpoint().root_hash()` âœ“
6. Hashes A and B are never validated but are stored in the transaction_infos table
7. These corrupted hashes can propagate to other nodes during state sync or be used in API responses

## Impact Explanation
This is a **Medium to High Severity** vulnerability as it violates state integrity guarantees:

- **State inconsistencies requiring intervention**: Incorrect state checkpoint hashes in the database represent corrupted metadata that doesn't match the actual state. While the actual state data remains correct, the proof metadata is corrupted.
  
- **Propagation risk**: Other nodes syncing from an affected node may receive these corrupted checkpoint hashes, spreading the inconsistency across the network.

- **State snapshot sync attacks**: State snapshot synchronization relies on checkpoint hashes as trusted roots. Corrupted hashes could cause state snapshot sync to fail or accept incorrect state: [6](#0-5) 

This meets the Medium Severity criteria of "State inconsistencies requiring intervention" and potentially High Severity if it enables broader attacks on state sync integrity.

## Likelihood Explanation
**Likelihood: Medium**

The vulnerability is triggered whenever:
- State sync receives chunks with multiple blocks (common during catch-up)
- Transaction outputs are applied without re-execution (the default state sync path)
- The source peer (malicious or buggy) provides incorrect checkpoint hashes

While this requires either a malicious peer or a bug in the block production logic, state sync regularly processes multi-block chunks, making this exploitable in practice. The test suite confirms multi-block chunks are expected: [7](#0-6) 

## Recommendation
Validate **all** state checkpoint hashes, not just the last one. The fix should compute intermediate state roots and verify each checkpoint hash:

```rust
fn get_state_checkpoint_hashes(
    execution_output: &ExecutionOutput,
    known_state_checkpoints: Option<Vec<Option<HashValue>>>,
    state_summary: &LedgerStateSummary,
) -> Result<Vec<Option<HashValue>>> {
    let num_txns = execution_output.to_commit.len();
    let state_update_refs = execution_output.to_commit.state_update_refs();
    let all_checkpoint_indices = state_update_refs.all_checkpoint_versions();

    if let Some(known) = known_state_checkpoints {
        ensure!(known.len() == num_txns, "Bad number of known hashes");
        
        // Validate ALL checkpoint hashes, not just the last one
        if !all_checkpoint_indices.is_empty() {
            // For each checkpoint, compute the state root at that point
            // and validate against the known checkpoint hash
            // This requires computing intermediate state roots, not just the final one
            
            // Simplified validation (full implementation needs incremental state computation):
            for &checkpoint_idx in all_checkpoint_indices {
                if let Some(known_hash) = known[checkpoint_idx] {
                    // Compute state root at this checkpoint and validate
                    // This requires refactoring to compute intermediate roots
                    ensure!(
                        /* computed_root_at_checkpoint == known_hash */,
                        "State checkpoint hash mismatch at index {}", checkpoint_idx
                    );
                }
            }
        }
        
        Ok(known)
    } else {
        // ... existing code for local execution ...
    }
}
```

Alternatively, force re-execution for multi-block chunks to ensure all checkpoints are validated through full execution.

## Proof of Concept
```rust
// Test case demonstrating the vulnerability
#[tokio::test]
async fn test_multi_block_checkpoint_validation() {
    // Setup: Create a chunk with 3 blocks
    let mut transactions = vec![];
    let mut outputs = vec![];
    
    // Block 1: transactions 0-99, checkpoint at 99
    for i in 0..100 {
        transactions.push(create_dummy_transaction(i));
        outputs.push(create_dummy_output());
    }
    transactions[99] = Transaction::StateCheckpoint(HashValue::zero());
    
    // Block 2: transactions 100-199, checkpoint at 199  
    for i in 100..200 {
        transactions.push(create_dummy_transaction(i));
        outputs.push(create_dummy_output());
    }
    transactions[199] = Transaction::StateCheckpoint(HashValue::zero());
    
    // Block 3: transactions 200-299, checkpoint at 299
    for i in 200..300 {
        transactions.push(create_dummy_transaction(i));
        outputs.push(create_dummy_output());
    }
    transactions[299] = Transaction::StateCheckpoint(HashValue::zero());
    
    // Create TransactionOutputListWithProofV2 with CORRUPTED checkpoint hashes
    let mut txn_infos = vec![];
    for i in 0..300 {
        let mut info = create_transaction_info(i);
        
        // Corrupt checkpoint hashes for blocks 1 and 2
        if i == 99 || i == 199 {
            info.state_checkpoint_hash = Some(HashValue::random()); // CORRUPTED!
        } else if i == 299 {
            info.state_checkpoint_hash = Some(compute_correct_hash()); // Correct
        }
        
        txn_infos.push(info);
    }
    
    let proof = create_proof_with_infos(txn_infos);
    let outputs_with_proof = TransactionOutputListWithProofV2::new(outputs, proof);
    
    // Apply the chunk - this should REJECT corrupted intermediate checkpoints
    // but currently ACCEPTS them!
    let result = chunk_executor.enqueue_chunk_by_transaction_outputs(
        outputs_with_proof,
        &verified_target_li,
        None,
    );
    
    // Bug: This succeeds even with corrupted checkpoint hashes at indices 99, 199
    assert!(result.is_ok()); // Currently passes - THIS IS THE BUG
    
    // The database now contains corrupted checkpoint hashes that don't match
    // the actual state at those versions
}
```

## Notes
The vulnerability is subtle because:
1. Transaction accumulator proofs ARE validated correctly
2. The final checkpoint hash IS validated  
3. The actual state data is correct (outputs are applied properly)
4. Only the intermediate checkpoint hash **metadata** is corrupted

However, this metadata corruption can propagate and undermine state sync integrity guarantees.

### Citations

**File:** execution/executor/src/workflow/do_state_checkpoint.rs (L44-89)
```rust
    fn get_state_checkpoint_hashes(
        execution_output: &ExecutionOutput,
        known_state_checkpoints: Option<Vec<Option<HashValue>>>,
        state_summary: &LedgerStateSummary,
    ) -> Result<Vec<Option<HashValue>>> {
        let _timer = OTHER_TIMERS.timer_with(&["get_state_checkpoint_hashes"]);

        let num_txns = execution_output.to_commit.len();
        let last_checkpoint_index = execution_output
            .to_commit
            .state_update_refs()
            .last_inner_checkpoint_index();

        if let Some(known) = known_state_checkpoints {
            ensure!(
                known.len() == num_txns,
                "Bad number of known hashes. {} vs {}",
                known.len(),
                num_txns
            );
            if let Some(idx) = last_checkpoint_index {
                ensure!(
                    known[idx] == Some(state_summary.last_checkpoint().root_hash()),
                    "Root hash mismatch with known hashes passed in. {:?} vs {:?}",
                    known[idx],
                    Some(&state_summary.last_checkpoint().root_hash()),
                );
            }

            Ok(known)
        } else {
            if !execution_output.is_block {
                // We should enter this branch only in test.
                execution_output.to_commit.ensure_at_most_one_checkpoint()?;
            }

            let mut out = vec![None; num_txns];

            if let Some(index) = last_checkpoint_index {
                out[index] = Some(state_summary.last_checkpoint().root_hash());
            }

            Ok(out)
        }
    }
}
```

**File:** storage/storage-interface/src/state_store/state_update_refs.rs (L120-134)
```rust
#[derive(Debug)]
pub struct StateUpdateRefs<'kv> {
    pub per_version: PerVersionStateUpdateRefs<'kv>,
    all_checkpoint_versions: Vec<Version>,
    /// Updates from the beginning of the block/chunk to the last checkpoint (if it exists).
    for_last_checkpoint: Option<(PerVersionStateUpdateRefs<'kv>, BatchedStateUpdateRefs<'kv>)>,
    /// Updates from the version after last checkpoint to last version (`None` if the last version
    /// is a checkpoint, e.g. in a regular block).
    for_latest: Option<(PerVersionStateUpdateRefs<'kv>, BatchedStateUpdateRefs<'kv>)>,
}

impl<'kv> StateUpdateRefs<'kv> {
    pub(crate) fn all_checkpoint_versions(&self) -> &[Version] {
        &self.all_checkpoint_versions
    }
```

**File:** storage/storage-interface/src/state_store/state_update_refs.rs (L168-229)
```rust
    pub fn index<
        UpdateIter: IntoIterator<Item = (&'kv StateKey, &'kv BaseStateOp)>,
        VersionIter: IntoIterator<Item = UpdateIter>,
    >(
        first_version: Version,
        updates_by_version: VersionIter,
        num_versions: usize,
        all_checkpoint_indices: Vec<usize>,
    ) -> Self {
        if num_versions == 0 {
            return Self {
                per_version: PerVersionStateUpdateRefs::new_empty(first_version),
                all_checkpoint_versions: vec![],
                for_last_checkpoint: None,
                for_latest: None,
            };
        }

        let mut updates_by_version = updates_by_version.into_iter();
        let mut num_versions_for_last_checkpoint = 0;
        let last_checkpoint_index = all_checkpoint_indices.last().copied();

        let for_last_checkpoint = last_checkpoint_index.map(|index| {
            num_versions_for_last_checkpoint = index + 1;
            let per_version = PerVersionStateUpdateRefs::index(
                first_version,
                updates_by_version
                    .by_ref()
                    .take(num_versions_for_last_checkpoint),
                num_versions_for_last_checkpoint,
            );
            let batched = Self::batch_updates(&per_version);
            (per_version, batched)
        });

        let for_latest = match last_checkpoint_index {
            Some(index) if index + 1 == num_versions => None,
            _ => {
                assert!(num_versions_for_last_checkpoint < num_versions);
                let per_version = PerVersionStateUpdateRefs::index(
                    first_version + num_versions_for_last_checkpoint as Version,
                    updates_by_version,
                    num_versions - num_versions_for_last_checkpoint,
                );
                let batched = Self::batch_updates(&per_version);
                Some((per_version, batched))
            },
        };

        Self {
            per_version: Self::concat_per_version_updates(
                for_last_checkpoint.as_ref().map(|x| &x.0),
                for_latest.as_ref().map(|x| &x.0),
            ),
            all_checkpoint_versions: all_checkpoint_indices
                .into_iter()
                .map(|index| first_version + index as Version)
                .collect(),
            for_last_checkpoint,
            for_latest,
        }
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L842-861)
```rust
) -> JoinHandle<()> {
    // Create a state snapshot receiver
    let receiver = async move {
        // Get the target version and expected root hash
        let version = target_ledger_info.ledger_info().version();
        let expected_root_hash = target_output_with_proof
            .get_output_list_with_proof()
            .proof
            .transaction_infos
            .first()
            .expect("Target transaction info should exist!")
            .ensure_state_checkpoint_hash()
            .expect("Must be at state checkpoint.");

        // Create the snapshot receiver
        let mut state_snapshot_receiver = storage
            .writer
            .get_state_snapshot_receiver(version, expected_root_hash)
            .expect("Failed to initialize the state snapshot receiver!");

```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L986-1021)
```rust
async fn apply_output_chunk<ChunkExecutor: ChunkExecutorTrait + 'static>(
    chunk_executor: Arc<ChunkExecutor>,
    outputs_with_proof: TransactionOutputListWithProofV2,
    target_ledger_info: LedgerInfoWithSignatures,
    end_of_epoch_ledger_info: Option<LedgerInfoWithSignatures>,
) -> anyhow::Result<()> {
    // Apply the output chunk
    let num_outputs = outputs_with_proof.get_num_outputs();
    let result = tokio::task::spawn_blocking(move || {
        chunk_executor.enqueue_chunk_by_transaction_outputs(
            outputs_with_proof,
            &target_ledger_info,
            end_of_epoch_ledger_info.as_ref(),
        )
    })
    .await
    .expect("Spawn_blocking(apply_output_chunk) failed!");

    // Update the logs and metrics if the chunk was applied successfully
    if result.is_ok() {
        // Log the application event
        info!(
            LogSchema::new(LogEntry::StorageSynchronizer).message(&format!(
                "Applied a new transaction output chunk! Transaction total: {:?}.",
                num_outputs
            ))
        );

        // Update the chunk metrics
        let operation_label =
            metrics::StorageSynchronizerOperations::AppliedTransactionOutputs.get_label();
        update_synchronizer_chunk_metrics(num_outputs, operation_label);
    }

    result
}
```

**File:** execution/executor/src/chunk_executor/mod.rs (L336-392)
```rust
    pub fn update_ledger(&self) -> Result<()> {
        let _timer = CHUNK_OTHER_TIMERS.timer_with(&["chunk_update_ledger_total"]);

        let (parent_state_summary, parent_accumulator, chunk) =
            self.commit_queue.lock().next_chunk_to_update_ledger()?;
        let ChunkToUpdateLedger {
            output,
            chunk_verifier,
        } = chunk;

        let state_checkpoint_output = DoStateCheckpoint::run(
            &output.execution_output,
            &parent_state_summary,
            &ProvableStateSummary::new_persisted(self.db.reader.as_ref())?,
            Some(
                chunk_verifier
                    .transaction_infos()
                    .iter()
                    .map(|t| t.state_checkpoint_hash())
                    .collect_vec(),
            ),
        )?;

        let ledger_update_output = DoLedgerUpdate::run(
            &output.execution_output,
            &state_checkpoint_output,
            parent_accumulator.clone(),
        )?;

        chunk_verifier.verify_chunk_result(&parent_accumulator, &ledger_update_output)?;

        let ledger_info_opt = chunk_verifier.maybe_select_chunk_ending_ledger_info(
            &ledger_update_output,
            output.execution_output.next_epoch_state.as_ref(),
        )?;
        output.set_state_checkpoint_output(state_checkpoint_output);
        output.set_ledger_update_output(ledger_update_output);

        let first_version = output.execution_output.first_version;
        let num_txns = output.execution_output.num_transactions_to_commit();
        let executed_chunk = ExecutedChunk {
            output,
            ledger_info_opt,
        };

        self.commit_queue
            .lock()
            .save_ledger_update_output(executed_chunk)?;

        info!(
            LogSchema::new(LogEntry::ChunkExecutor)
                .first_version_in_request(Some(first_version))
                .num_txns_in_request(num_txns),
            "Calculated ledger update!",
        );
        Ok(())
    }
```

**File:** execution/executor-types/src/transactions_with_output.rs (L368-396)
```rust
    fn test_chunk_with_ckpts_no_reconfig() {
        let txns = vec![
            dummy_txn(),
            ckpt_txn(),
            dummy_txn(),
            ckpt_txn(),
            dummy_txn(),
        ];
        let outputs = vec![
            default_output(),
            default_output(),
            default_output(),
            default_output(),
            default_output(),
        ];
        let aux_infos = vec![
            default_aux_info(),
            default_aux_info(),
            default_aux_info(),
            default_aux_info(),
            default_aux_info(),
        ];
        let txn_with_outputs = TransactionsWithOutput::new(txns, outputs, aux_infos);

        let (all_ckpt_indices, is_reconfig) =
            TransactionsToKeep::get_all_checkpoint_indices(&txn_with_outputs, false);
        assert_eq!(all_ckpt_indices, vec![1, 3]);
        assert!(!is_reconfig);
    }
```
