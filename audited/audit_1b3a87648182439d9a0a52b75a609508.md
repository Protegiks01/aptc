# Audit Report

## Title
Incarnation Read Race Condition in BlockSTMv2 Causes Node Crash and Potential Consensus Violation

## Summary
The `incarnation()` function in `scheduler_status.rs` returns the current incarnation under lock but releases the lock immediately, creating a Time-of-Check-Time-of-Use (TOCTOU) vulnerability. In `scheduler_v2.rs::start_commit()`, this function is called three times to validate and commit a transaction. Between the validation check and the final read, another thread can abort the transaction and increment its incarnation, causing the committer to use a mismatched incarnation number. This leads to either an immediate node crash via invariant violation or potential commitment of an invalidated transaction. [1](#0-0) 

## Finding Description

The vulnerability exists in the transaction commit flow of the BlockSTMv2 parallel executor. The critical code path is in `start_commit()`: [2](#0-1) [3](#0-2) 

**The Race Condition:**

1. **Line 616**: Thread A (committer) reads `incarnation = N` for a transaction in `Executed(N)` state
2. **Line 617**: Verifies transaction is executed
3. **Line 633**: Validates using `incarnation = N` (checks if commit is blocked)
4. **Line 644**: Double-checks that incarnation is still `N` (passes)
5. **RACE WINDOW**: Between lines 644-675, Thread B (executor) can:
   - Call `start_abort(txn_idx, N)` (succeeds)
   - Call `finish_abort(txn_idx, N, false)` (transitions to `PendingScheduling(N+1)`)
   - Incarnation is now `N+1`, but Thread A hasn't detected this yet
6. **Line 675**: Thread A reads `incarnation = N+1` and returns it
7. Thread A proceeds to commit, believing it validated incarnation `N+1`, but it actually validated incarnation `N`

**Impact Path 1: Node Crash**

The mismatched incarnation causes an invariant violation during validation. When `prepare_and_queue_commit_ready_txn` attempts to validate with the stale incarnation: [4](#0-3) 

If delayed field validation fails, it calls `abort_pre_final_reexecution` with incarnation `N+1`: [5](#0-4) 

This calls `direct_abort(txn_idx, N+1, true)` with `start_next_incarnation=true`: [6](#0-5) 

Since incarnation `N+1` was already created by Thread B's abort, `start_abort(txn_idx, N+1)` returns `false`: [7](#0-6) 

With `start_next_incarnation=true` but `start_abort` returning false, `direct_abort` returns a `PanicError`, **crashing the node**.

**Impact Path 2: Consensus Violation**

If incarnation `N+1` hasn't been executed yet when validation occurs, the read-set will have `blockstm_v2_incarnation = N`, but we're trying to validate incarnation `N+1`. This also triggers an invariant error and node crash.

Alternatively, if incarnation `N+1` executes before commit completes, we commit a transaction that was validated as incarnation `N` (which was invalidated) but is being committed as incarnation `N+1` (which may not have been properly validated through the commit flow), potentially violating the **Deterministic Execution** invariant.

## Impact Explanation

**HIGH Severity** - This vulnerability causes:

1. **Validator Node Crash**: The PanicError from the invariant violation crashes the validator node, matching the "API crashes" category in the High Severity tier ($50,000)
2. **Availability Impact**: Crashed validators cannot participate in consensus, degrading network availability
3. **Non-Deterministic Behavior**: Different validators may hit the race at different times, causing inconsistent node states
4. **Potential Consensus Violation**: In rare cases, committing mismatched incarnations could lead to state divergence between validators

The issue does NOT require attacker control - it occurs naturally under high transaction throughput with conflicting reads/writes, making it a systemic reliability issue rather than an exploit.

## Likelihood Explanation

**MEDIUM-HIGH Likelihood** in production:

1. **Natural Occurrence**: The race happens during normal parallel execution when transactions have conflicting dependencies
2. **Narrow Window**: The race window (lines 644-675) is small but traversed for every commit
3. **High Throughput Amplification**: With many workers and thousands of transactions per block, the probability increases significantly
4. **No Special Conditions Required**: Any transaction abort during commit can trigger this
5. **Deterministic Crash**: Once the race occurs, the node crash is deterministic (not transient)

The developers clearly anticipated TOCTOU issues (evidenced by the double-check at line 644), but missed that the final incarnation read at line 675 occurs after the check, reopening the race window.

## Recommendation

**Fix**: Hold the lock across the entire validation-to-commit sequence, or perform all three incarnation reads atomically under a single lock acquisition:

```rust
pub(crate) fn start_commit(&self) -> Result<Option<(TxnIndex, Incarnation)>, PanicError> {
    let next_to_commit_idx = self.next_to_commit_idx.load(Ordering::Relaxed);
    
    if self.is_halted() || next_to_commit_idx == self.num_txns {
        return Ok(None);
    }
    
    // Acquire lock once and hold it for all validation logic
    let status_guard = self.txn_statuses.statuses[next_to_commit_idx as usize]
        .status_with_incarnation.lock();
    
    let incarnation = status_guard.incarnation();
    
    if !status_guard.is_executed() {
        return Ok(None);
    }
    
    // Release lock only after we've committed to this incarnation
    drop(status_guard);
    
    // ... rest of validation using the locked incarnation ...
    
    if self.cold_validation_requirements.is_commit_blocked(next_to_commit_idx, incarnation) {
        return Ok(None);
    }
    
    // Mark as committed and increment counter
    // ... existing code ...
    
    return Ok(Some((next_to_commit_idx, incarnation)));
}
```

Alternatively, make `start_commit` return the incarnation from a single atomic read-and-mark-as-committing operation, eliminating the multiple read issue entirely.

## Proof of Concept

```rust
// Multi-threaded race condition test
#[test]
fn test_incarnation_race_in_start_commit() {
    use std::sync::Arc;
    use std::thread;
    
    let num_txns = 10;
    let scheduler = Arc::new(SchedulerV2::new(num_txns, 4));
    let statuses = Arc::clone(&scheduler.txn_statuses);
    
    // Setup: Transaction 5 is in Executed(0) state
    let txn_idx = 5;
    assert!(statuses.start_executing(txn_idx).unwrap().is_some());
    assert!(statuses.finish_execution(txn_idx, 0).unwrap().is_some());
    assert!(statuses.is_executed(txn_idx));
    
    // Thread 1: Attempts to commit
    let scheduler_clone1 = Arc::clone(&scheduler);
    let handle1 = thread::spawn(move || {
        // This will read incarnation multiple times
        // If race occurs, may return mismatched incarnation
        scheduler_clone1.start_commit()
    });
    
    // Thread 2: Aborts the transaction in the race window
    let scheduler_clone2 = Arc::clone(&scheduler);
    let handle2 = thread::spawn(move || {
        // Abort incarnation 0, creating incarnation 1
        scheduler_clone2.direct_abort(txn_idx, 0, false)
    });
    
    let commit_result = handle1.join().unwrap();
    let abort_result = handle2.join().unwrap();
    
    // If race occurred, commit_result may have incarnation 1
    // but validation was done for incarnation 0
    // Subsequent commit operations will panic
    if let Ok(Some((idx, incarnation))) = commit_result {
        assert_eq!(idx, txn_idx);
        // This incarnation may not match what was validated!
        // Attempting to use it for commit will cause panic
    }
}
```

## Notes

The developers were clearly aware of TOCTOU risks, as evidenced by the double-check at line 644. However, they missed that reading the incarnation again at line 675 (after the validation) reopens the race window. The fix requires either holding the lock longer or restructuring the commit flow to be atomic.

This vulnerability affects the core parallel execution engine and impacts all validators running BlockSTMv2. It represents a fundamental concurrency bug that can cause node crashes under normal operating conditions.

### Citations

**File:** aptos-move/block-executor/src/scheduler_status.rs (L531-553)
```rust
    pub(crate) fn start_abort(
        &self,
        txn_idx: TxnIndex,
        incarnation: Incarnation,
    ) -> Result<bool, PanicError> {
        let prev_value = self.statuses[txn_idx as usize]
            .next_incarnation_to_abort
            .fetch_max(incarnation + 1, Ordering::Relaxed);
        match incarnation.cmp(&prev_value) {
            cmp::Ordering::Less => Ok(false),
            cmp::Ordering::Equal => {
                // Increment the counter and clear speculative logs (from the aborted execution).
                counters::SPECULATIVE_ABORT_COUNT.inc();
                clear_speculative_txn_logs(txn_idx as usize);

                Ok(true)
            },
            cmp::Ordering::Greater => Err(code_invariant_error(format!(
                "Try abort incarnation {} > self.next_incarnation_to_abort = {}",
                incarnation, prev_value,
            ))),
        }
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L772-777)
```rust
    pub(crate) fn incarnation(&self, txn_idx: TxnIndex) -> Incarnation {
        self.statuses[txn_idx as usize]
            .status_with_incarnation
            .lock()
            .incarnation()
    }
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L616-646)
```rust
        let incarnation = self.txn_statuses.incarnation(next_to_commit_idx);
        if self.txn_statuses.is_executed(next_to_commit_idx) {
            self.commit_marker_invariant_check(next_to_commit_idx)?;

            // All prior transactions are committed and the latest incarnation of the transaction
            // at next_to_commit_idx has finished but has not been aborted. If any of its reads was
            // incorrect, it would have been invalidated by the respective transaction's last
            // (committed) (re-)execution, and led to an abort in the corresponding finish execution
            // (which, inductively, must occur before the transaction is committed). Hence, it
            // must also be safe to commit the current transaction.
            //
            // The only exception is if there are unsatisfied cold validation requirements,
            // blocking the commit. These may not yet be scheduled for validation, or deferred
            // until after the txn finished execution, whereby deferral happens before txn status
            // becomes Executed, while validation and unblocking happens after.
            if self
                .cold_validation_requirements
                .is_commit_blocked(next_to_commit_idx, incarnation)
            {
                // May not commit a txn with an unsatisfied validation requirement. This will be
                // more rare than !is_executed in the common case, hence the order of checks.
                return Ok(None);
            }
            // The check might have passed after the validation requirement has been fulfilled.
            // Yet, if validation failed, the status would be aborted before removing the block,
            // which would increase the incarnation number. It is also important to note that
            // blocking happens during sequential commit hook, while holding the lock (which is
            // also held here), hence before the call of this method.
            if incarnation != self.txn_statuses.incarnation(next_to_commit_idx) {
                return Ok(None);
            }
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L673-676)
```rust
            return Ok(Some((
                next_to_commit_idx,
                self.txn_statuses.incarnation(next_to_commit_idx),
            )));
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L996-1016)
```rust
    pub(crate) fn direct_abort(
        &self,
        txn_idx: TxnIndex,
        incarnation: Incarnation,
        start_next_incarnation: bool,
    ) -> Result<bool, PanicError> {
        if self.txn_statuses.start_abort(txn_idx, incarnation)? {
            self.txn_statuses
                .finish_abort(txn_idx, incarnation, start_next_incarnation)?;
            return Ok(true);
        }

        if start_next_incarnation {
            return Err(code_invariant_error(format!(
                "SchedulerV2: self-abort with start_next_incarnation failed for {} {}",
                txn_idx, incarnation
            )));
        }

        Ok(false)
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1018-1023)
```rust
            scheduler.abort_pre_final_reexecution::<T, E>(
                txn_idx,
                incarnation,
                last_input_output,
                versioned_cache,
            )?;
```

**File:** aptos-move/block-executor/src/scheduler_wrapper.rs (L106-128)
```rust
    pub(crate) fn abort_pre_final_reexecution<T, E>(
        &self,
        txn_idx: TxnIndex,
        incarnation: Incarnation,
        last_input_output: &TxnLastInputOutput<T, E::Output>,
        versioned_cache: &MVHashMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
    ) -> Result<(), PanicError>
    where
        T: BlockExecutableTransaction,
        E: ExecutorTask<Txn = T>,
    {
        match self {
            SchedulerWrapper::V1(_, _) => {
                // Updating the scheduler state not required as the execute method invoked
                // in [executor::execute_txn_after_commit] does not take in the scheduler.
                update_transaction_on_abort::<T, E>(txn_idx, last_input_output, versioned_cache);
            },
            SchedulerWrapper::V2(scheduler, _) => {
                scheduler.direct_abort(txn_idx, incarnation, true)?;
            },
        }
        Ok(())
    }
```
