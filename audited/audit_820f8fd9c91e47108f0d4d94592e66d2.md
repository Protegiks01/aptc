# Audit Report

## Title
Health Checker Failure Detection Bypass via LIFO Queue and Unconditional Failure Reset

## Summary
The health checker uses a LIFO queue for network events and unconditionally resets peer failure counters when processing incoming Ping requests, without validating round numbers. A malicious peer can exploit this by flooding the victim with Ping requests while refusing to respond to the victim's outbound health checks, preventing the victim from detecting the peer as unhealthy and disconnecting.

## Finding Description

The health checker implements bidirectional health monitoring where both outbound Pings (sent by this node) and inbound Pings (received from peers) are used to assess peer health. However, there's a critical asymmetry in how failures are tracked:

**Outbound Health Check Path (Round-Aware):** [1](#0-0) 

When an outbound Ping fails, `increment_peer_round_failure()` only increments the failure counter if the stored round is less than or equal to the current round. [2](#0-1) 

When an outbound Ping succeeds, `reset_peer_round_state()` resets failures and updates the round, but only if the new round is newer.

**Inbound Health Check Path (NOT Round-Aware):** [3](#0-2) 

When processing an incoming Ping request, the health checker calls `reset_peer_failures()`: [4](#0-3) 

This function unconditionally sets failures to 0 **without checking or updating round numbers**.

**LIFO Queue Amplification:** [5](#0-4) 

The health checker is the only major network service using LIFO queue style. With LIFO: [6](#0-5) 

Newest messages are retrieved first, allowing attackers to continuously push new Pings to the front of the queue.

**Attack Scenario:**

1. Malicious Peer B connects to Honest Node A
2. Node A starts sending periodic Pings to B every 10 seconds (default `PING_INTERVAL_MS`)
3. Peer B intentionally does not respond to Node A's Pings (saves resources)
4. Node A increments failure counter for B (requires 3 failures by default to disconnect)
5. Before reaching 3 failures, Peer B floods Node A with 50-100 Ping requests
6. Due to LIFO queue, these new Pings are processed immediately
7. Each processed Ping calls `reset_peer_failures(B)`, setting failures back to 0
8. Node A never accumulates enough failures to disconnect Peer B
9. Peer B repeats this pattern, staying connected while being unresponsive

This breaks the network health monitoring invariant: **peers that don't respond to health checks should be disconnected**.

## Impact Explanation

**High Severity** (per Aptos bug bounty criteria):

1. **Significant Protocol Violation**: The health checker's core invariant is violated - unresponsive peers cannot be detected and disconnected
2. **Validator Node Degradation**: Malicious peers can occupy connection slots while being unresponsive, degrading network performance
3. **Eclipse Attack Facilitation**: An attacker can fill a victim's connection slots with unresponsive peers, isolating the node from the network
4. **Network Partition Risk**: During network stress, legitimate peers might appear unresponsive while malicious peers flood health checks, causing incorrect disconnections of honest peers

The vulnerability affects all Aptos nodes (validators and fullnodes) as the health checker is a core network component.

## Likelihood Explanation

**Likelihood: High**

1. **Easy to Execute**: Any peer can send Ping requests as part of normal protocol behavior
2. **Low Resource Requirements**: Sending periodic Ping floods requires minimal bandwidth compared to responding to health checks
3. **No Special Access Needed**: No validator privileges or cryptographic material required
4. **Immediate Benefit**: Malicious peers can stay connected indefinitely while saving resources
5. **Difficult to Detect**: Ping requests appear as legitimate health check traffic

Default configuration parameters make this exploitable: [7](#0-6) 

With 10-second ping intervals and 3 failures tolerated, an attacker only needs to send a burst of Pings every 20-30 seconds to prevent disconnection.

## Recommendation

**Fix 1: Add Round Checking to Inbound Ping Handling**

Modify `reset_peer_failures()` to check round numbers similar to how `reset_peer_round_state()` works:

```rust
/// Resets the number of peer failures for the given peer and updates the round.
/// Only resets if the incoming ping is from a current or newer round.
pub fn reset_peer_failures(&mut self, peer_id: PeerId, round: u64) {
    if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
        // Only reset failures if this ping is from current or newer round
        if round >= health_check_data.round {
            health_check_data.failures = 0;
            // Optionally update round to prevent old pings from resetting
            health_check_data.round = round;
        }
    }
}
```

However, incoming Pings don't carry round information in the current protocol.

**Fix 2: Remove Unconditional Failure Reset (Recommended)**

Remove the automatic failure reset on incoming Pings, or make it a separate "bidirectional health" metric that doesn't interfere with outbound health check failure detection:

```rust
fn handle_ping_request(
    &mut self,
    peer_id: PeerId,
    ping: Ping,
    protocol: ProtocolId,
    res_tx: oneshot::Sender<Result<Bytes, RpcError>>,
) {
    // ... existing code ...
    
    // REMOVE THIS LINE:
    // self.network_interface.reset_peer_failures(peer_id);
    
    // Only track that we received an inbound ping for metrics/monitoring
    // Do NOT reset outbound health check failures
    
    let _ = res_tx.send(Ok(message.into()));
}
```

**Fix 3: Change LIFO to FIFO**

Change the queue style to FIFO to match all other network services:

```rust
let network_service_config = NetworkServiceConfig::new(
    direct_send_protocols,
    rpc_protocols,
    aptos_channel::Config::new(NETWORK_CHANNEL_SIZE)
        .queue_style(QueueStyle::FIFO)  // Changed from LIFO
        .counters(&counters::PENDING_HEALTH_CHECKER_NETWORK_EVENTS),
);
```

This prevents attackers from continuously pushing new messages to the front of the queue.

**Recommended: Combine Fix 2 and Fix 3** for complete protection.

## Proof of Concept

```rust
#[tokio::test]
async fn test_health_check_bypass_via_ping_flood() {
    use crate::protocols::health_checker::*;
    use aptos_time_service::TimeService;
    
    // Setup health checker with default config
    let ping_interval = Duration::from_secs(10);
    let ping_timeout = Duration::from_secs(20);
    let ping_failures_tolerated = 3;
    
    let (mut harness, mut health_checker) = TestHarness::new_permissive(ping_failures_tolerated);
    let malicious_peer = PeerId::random();
    
    // Connect malicious peer
    harness.connect_peer(malicious_peer).await;
    
    // Advance to round 1, health checker sends ping
    harness.trigger_ping().await;
    let (ping1, _) = harness.expect_ping().await;
    // Malicious peer does NOT respond - let it timeout
    
    // Advance to round 2
    harness.trigger_ping().await;
    let (ping2, _) = harness.expect_ping().await;
    // Malicious peer does NOT respond - let it timeout
    // Failure count should be 2 now
    
    // Before round 3, malicious peer floods with 50 Pings
    for _ in 0..50 {
        harness.send_ping_from_peer(malicious_peer).await;
    }
    
    // Process the inbound pings (LIFO: newest first)
    // Each one calls reset_peer_failures(), setting failures to 0
    harness.process_inbound_pings().await;
    
    // Advance to round 3
    harness.trigger_ping().await;
    let (ping3, _) = harness.expect_ping().await;
    // Malicious peer does NOT respond
    
    // Verify that peer is NOT disconnected despite 3+ failed outbound pings
    // because the inbound ping flood reset the failure counter
    assert!(harness.is_peer_connected(malicious_peer));
    
    // Expected: peer should have been disconnected after 3 failures
    // Actual: peer remains connected because failures were reset
}
```

The test demonstrates that a malicious peer can bypass health check failure detection by flooding with inbound Ping requests that reset the failure counter, preventing disconnection despite failing to respond to outbound health checks.

**Notes**

This vulnerability uniquely affects the health checker because:
1. It's the only major network service using LIFO queue (all others use FIFO)
2. The `reset_peer_failures()` function lacks round number validation
3. The bidirectional health check design allows inbound Pings to override outbound failure detection

The combination of LIFO queueing and unconditional failure reset creates an exploitable attack vector for malicious peers to remain connected while being unresponsive to health checks, potentially leading to network degradation, eclipse attacks, and connection slot exhaustion.

### Citations

**File:** network/framework/src/protocols/health_checker/interface.rs (L108-116)
```rust
    /// Increments the number of failures for the specified round.
    /// If the round is in the past, nothing is done.
    pub fn increment_peer_round_failure(&mut self, peer_id: PeerId, round: u64) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            if health_check_data.round <= round {
                health_check_data.failures += 1;
            }
        }
    }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L118-124)
```rust
    /// Resets the number of peer failures for the given peer.
    /// If the peer is not found, nothing is done.
    pub fn reset_peer_failures(&mut self, peer_id: PeerId) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            health_check_data.failures = 0;
        }
    }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L126-135)
```rust
    /// Resets the state if the given round is newer than the
    /// currently stored round. Otherwise, nothing is done.
    pub fn reset_peer_round_state(&mut self, peer_id: PeerId, round: u64) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            if round > health_check_data.round {
                health_check_data.round = round;
                health_check_data.failures = 0;
            }
        }
    }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L71-77)
```rust
    let network_service_config = NetworkServiceConfig::new(
        direct_send_protocols,
        rpc_protocols,
        aptos_channel::Config::new(NETWORK_CHANNEL_SIZE)
            .queue_style(QueueStyle::LIFO)
            .counters(&counters::PENDING_HEALTH_CHECKER_NETWORK_EVENTS),
    );
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L277-306)
```rust
    fn handle_ping_request(
        &mut self,
        peer_id: PeerId,
        ping: Ping,
        protocol: ProtocolId,
        res_tx: oneshot::Sender<Result<Bytes, RpcError>>,
    ) {
        let message = match protocol.to_bytes(&HealthCheckerMsg::Pong(Pong(ping.0))) {
            Ok(msg) => msg,
            Err(e) => {
                warn!(
                    NetworkSchema::new(&self.network_context),
                    error = ?e,
                    "{} Unable to serialize pong response: {}", self.network_context, e
                );
                return;
            },
        };
        trace!(
            NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
            "{} Sending Pong response to peer: {} with nonce: {}",
            self.network_context,
            peer_id.short_str(),
            ping.0,
        );
        // Record Ingress HC here and reset failures.
        self.network_interface.reset_peer_failures(peer_id);

        let _ = res_tx.send(Ok(message.into()));
    }
```

**File:** crates/channel/src/message_queues.rs (L96-107)
```rust
    fn pop_from_key_queue(&mut self, key: &K) -> (Option<T>, bool) {
        if let Some(q) = self.per_key_queue.get_mut(key) {
            // Extract message from the key's queue
            let retval = match self.queue_style {
                QueueStyle::FIFO | QueueStyle::KLAST => q.pop_front(),
                QueueStyle::LIFO => q.pop_back(),
            };
            (retval, q.is_empty())
        } else {
            (None, true)
        }
    }
```

**File:** config/src/config/network_config.rs (L38-40)
```rust
pub const PING_INTERVAL_MS: u64 = 10_000;
pub const PING_TIMEOUT_MS: u64 = 20_000;
pub const PING_FAILURES_TOLERATED: u64 = 3;
```
