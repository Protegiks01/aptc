# Audit Report

## Title
Infinite Loop Vulnerability in Data Streaming Service Due to Zero-Length Chunk Sizes

## Summary
The data streaming service can enter an infinite loop when zero-length optimal chunk sizes are used, causing nodes to repeatedly generate invalid data requests without making progress. The vulnerability stems from missing validation of zero chunk sizes combined with flawed error handling that fails to increment failure counters, preventing automatic stream termination.

## Finding Description

The vulnerability exists in the state synchronization data streaming service and manifests through the following execution path:

**Root Cause:** The `DataStreamingService` initializes with an empty `GlobalDataSummary` that sets all optimal chunk sizes to 0. [1](#0-0) 

**Validation Bypass:** When fetching a global data summary, empty summaries skip chunk size validation entirely, allowing zero values to propagate into the system. [2](#0-1) 

**Stream Creation Without Validation:** When creating a new stream, the service refreshes the global data summary but does not validate chunk sizes before creating the stream. [3](#0-2) 

**Invalid Request Generation:** When creating data client requests with zero chunk sizes, the function calculates `num_items_to_fetch = min(total_items, optimal_chunk_size) = 0`. For state streams starting at index 0, this triggers an integer underflow: `request_end_index = 0 + 0 - 1` causes a checked subtraction failure. [4](#0-3) 

**Empty Response Detection:** For responses with empty data, validation logic correctly detects this and returns `AptosDataClientResponseIsInvalid` errors. [5](#0-4) 

**Critical Flaw - No Failure Counter Increment:** When `transform_client_response_into_notification` returns an error, it propagates through `send_data_notification_to_client` without reaching the code that resets the failure counter. The error occurs in the successful data client response path, so `resend_data_client_request` (which increments `request_failure_count`) is never called. [6](#0-5) 

The `resend_data_client_request` function that increments the failure counter is only called from error handling paths that this bug bypasses. [7](#0-6) 

**No Stream Termination:** Errors are caught in the progress checker and logged, but the stream remains active in the data streams map. [8](#0-7) 

**Infinite Loop:** The stream termination check requires `request_failure_count >= max_request_retry` (default 5), but since the counter is never incremented, termination never occurs. [9](#0-8) [10](#0-9) 

## Impact Explanation

**Severity: Medium (up to $10,000)**

This vulnerability causes state inconsistencies requiring manual intervention, falling under the Medium severity category for "Limited Protocol Violations" with temporary liveness issues:

1. **Node Synchronization Failure:** Affected nodes cannot sync blockchain state, preventing participation in consensus or API serving
2. **Resource Waste:** Continuous error processing consumes CPU and memory resources
3. **Manual Intervention Required:** Only recovery is node restart or waiting for valid peer advertisements

While this creates a liveness failure, it does not cause fund loss, consensus safety violations, or permanent network halt, justifying Medium rather than Critical severity.

## Likelihood Explanation

**Likelihood: High**

The vulnerability can be triggered through realistic scenarios:

1. **Node Startup Race Condition:** Nodes starting before sufficient peers connect naturally use empty global data summaries with zero chunk sizes
2. **Malicious Peer Attack:** The optimal chunk size calculation uses median aggregation across peer advertisements. If â‰¥50% of connected peers advertise zero chunk sizes, the median becomes zero, triggering the vulnerability. [11](#0-10) 

No validation prevents peers from advertising zero chunk sizes, and no special privileges are required since any network peer can participate.

## Recommendation

Implement the following mitigations:

1. **Add Chunk Size Validation:** Reject zero chunk sizes in `verify_optimal_chunk_sizes()` and during peer advertisement processing
2. **Fix Error Handling:** Ensure `request_failure_count` is incremented when `send_data_notification_to_client` fails, not just when data client errors occur
3. **Add Stream Health Checks:** Detect streams making no progress (no state updates) over time and terminate them automatically
4. **Validate on Stream Creation:** Check chunk sizes are non-zero before creating streams in `process_new_stream_request()`

## Proof of Concept

To reproduce:
1. Start an Aptos node with no peer connections
2. Request a state sync stream (e.g., via continuous transaction outputs API)
3. The stream will be created with zero chunk sizes from the empty global data summary
4. Observe repeated `IntegerOverflow` or `AptosDataClientResponseIsInvalid` errors in logs
5. Verify the stream never terminates and `request_failure_count` remains 0
6. Node requires restart to recover

## Notes

This is a protocol-level validation bug, not a network DoS attack. The vulnerability exists in the validation logic that should reject zero chunk sizes and the error handling that should properly count and respond to failures. The fact that malicious peers can trigger it does not make it a "Network DoS" - it's a missing input validation issue that affects node liveness.

### Citations

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L106-106)
```rust
            global_data_summary: Arc::new(ArcSwap::new(Arc::new(GlobalDataSummary::empty()))),
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L265-284)
```rust
        // Refresh the cached global data summary
        refresh_global_data_summary(
            self.aptos_data_client.clone(),
            self.global_data_summary.clone(),
        );

        // Create a new data stream
        let stream_id = self.stream_id_generator.next();
        let advertised_data = self.get_global_data_summary().advertised_data.clone();
        let (data_stream, stream_listener) = DataStream::new(
            self.data_client_config,
            self.streaming_service_config,
            stream_id,
            &request_message.stream_request,
            stream_update_notifier,
            self.aptos_data_client.clone(),
            self.notification_id_generator.clone(),
            &advertised_data,
            self.time_service.clone(),
        )?;
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L313-332)
```rust
            if let Err(error) = self.update_progress_of_data_stream(data_stream_id).await {
                if matches!(error, Error::NoDataToFetch(_)) {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(NO_DATA_TO_FETCH_LOG_FREQ_SECS)),
                        info!(LogSchema::new(LogEntry::CheckStreamProgress)
                            .stream_id(*data_stream_id)
                            .event(LogEvent::Pending)
                            .error(&error))
                    );
                } else {
                    metrics::increment_counter(
                        &metrics::CHECK_STREAM_PROGRESS_ERROR,
                        error.get_label(),
                    );
                    warn!(LogSchema::new(LogEntry::CheckStreamProgress)
                        .stream_id(*data_stream_id)
                        .event(LogEvent::Error)
                        .error(&error));
                }
            }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L463-471)
```rust
    if global_data_summary.is_empty() {
        sample!(
            SampleRate::Duration(Duration::from_secs(GLOBAL_DATA_REFRESH_LOG_FREQ_SECS)),
            info!(LogSchema::new(LogEntry::RefreshGlobalData)
                .message("Latest global data summary is empty."))
        );
    } else {
        verify_optimal_chunk_sizes(&global_data_summary.optimal_chunk_sizes)?;
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L322-327)
```rust
                        if state_values_with_proof.raw_values.is_empty() {
                            return Err(Error::AptosDataClientResponseIsInvalid(format!(
                                "Received an empty state values response! Request: {:?}",
                                client_request
                            )));
                        }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2070-2079)
```rust
    while total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
        // Calculate the number of items to fetch in this request
        let num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size);

        // Calculate the start and end indices for the request
        let request_start_index = next_index_to_request;
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-453)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L729-744)
```rust
    fn resend_data_client_request(
        &mut self,
        data_client_request: &DataClientRequest,
    ) -> Result<(), Error> {
        // Increment the number of client failures for this request
        self.request_failure_count += 1;

        // Resend the client request
        let pending_client_response = self.send_client_request(true, data_client_request.clone());

        // Push the pending response to the head of the sent requests queue
        self.get_sent_data_requests()?
            .push_front(pending_client_response);

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L775-807)
```rust
        if let Some(data_notification) = self
            .stream_engine
            .transform_client_response_into_notification(
                data_client_request,
                response_payload,
                self.notification_id_generator.clone(),
            )?
        {
            // Update the metrics for the data notification send latency
            metrics::observe_duration(
                &metrics::DATA_NOTIFICATION_SEND_LATENCY,
                data_client_request.get_label(),
                response_context.creation_time,
            );

            // Save the response context for this notification ID
            let notification_id = data_notification.notification_id;
            self.insert_notification_response_mapping(notification_id, response_context)?;

            // Send the notification along the stream
            trace!(
                (LogSchema::new(LogEntry::StreamNotification)
                    .stream_id(self.data_stream_id)
                    .event(LogEvent::Success)
                    .message(&format!(
                        "Sent a single stream notification! Notification ID: {:?}",
                        notification_id
                    )))
            );
            self.send_data_notification(data_notification).await?;

            // Reset the failure count. We've sent a notification and can move on.
            self.request_failure_count = 0;
```

**File:** config/src/config/state_sync_config.rs (L277-277)
```rust
            max_request_retry: 5,
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L448-456)
```rust
fn median_or_max<T: Ord + Copy>(mut values: Vec<T>, max_value: T) -> T {
    // Calculate median
    values.sort_unstable();
    let idx = values.len() / 2;
    let median = values.get(idx).copied();

    // Return median or max
    min(median.unwrap_or(max_value), max_value)
}
```
