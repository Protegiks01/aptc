# Audit Report

## Title
StateKeysSchema Deletion Tracking Gap Enables Permanent API Performance Degradation Attack

## Summary
The `StateKeysSchema` indexer only tracks state key creations and modifications but never removes deleted keys, allowing attackers to permanently degrade API query performance by creating and deleting large numbers of resources. This creates a storage bloat and DoS vector affecting all future queries to the targeted account.

## Finding Description

The internal indexer maintains a `StateKeysSchema` that maps state keys to empty values for fast prefix-based lookups. When processing transactions, this schema is only populated for creation and modification operations, explicitly excluding deletions: [1](#0-0) 

This means deleted state keys remain in the index permanently, as there is no pruning or deletion mechanism for `StateKeysSchema`.

When DB sharding is enabled, the API's `get_resources_by_pagination` and `get_modules_by_pagination` endpoints use `PrefixedStateValueIterator`, which relies on `StateKeysSchema` to enumerate all state keys matching an account prefix: [2](#0-1) 

The iterator implementation enumerates ALL keys from `StateKeysSchema` (including deleted ones) and attempts to fetch their values from the main database: [3](#0-2) 

For each deleted key, `get_state_value_by_version` returns `None` at line 67, causing the iterator to skip it and continue. However, this means the iterator must:
1. Read each deleted key from the index
2. Perform a database lookup via `get_state_value_by_version`
3. Skip the result when None is returned
4. Continue to the next key

**Attack Scenario:**
1. Attacker creates a Move module that creates 8,192 distinct resources per transaction (the maximum allowed by `max_write_ops_per_transaction`): [4](#0-3) 

2. Attacker executes 122 transactions to create ~1 million resources under their account
3. Attacker deletes all resources in subsequent transactions
4. All 1 million deleted keys remain in `StateKeysSchema` permanently
5. When anyone queries the account's resources via `/accounts/{address}/resources`, the iterator must process all 1 million deleted keys before returning results

The pagination limit only applies AFTER filtering deleted keys: [5](#0-4) 

This means even requesting a single page of 100 resources requires scanning through all deleted keys first.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos Bug Bounty program criteria for the following reasons:

1. **API Performance Degradation**: Queries to affected accounts become extremely slow, proportional to the number of deleted keys. With 1 million deleted keys, each query performs 1 million unnecessary database lookups.

2. **Storage Bloat**: The indexer database grows indefinitely with deleted keys that can never be removed, as no pruning mechanism exists: [1](#0-0) 

3. **Availability Impact**: While not a total loss of availability, it significantly degrades service quality and could cause timeouts for affected endpoints, meeting the "State inconsistencies requiring intervention" category.

4. **Permanent Effect**: Unlike temporary DoS attacks, this creates permanent performance degradation that persists across all future queries and node restarts.

The maximum page size for account resources is 9,999, but this limit doesn't protect against the underlying issue: [6](#0-5) 

## Likelihood Explanation

This attack is **highly likely** to occur because:

1. **Low Attacker Cost**: Creating and deleting resources costs gas, but an attacker with moderate funds can create millions of deleted keys. The attack is one-time with permanent effects.

2. **No Special Privileges Required**: Any account can create resources under their own address using standard Move operations.

3. **No Detection/Prevention**: There are no rate limits, detection mechanisms, or cleanup processes for this attack pattern.

4. **Wide Attack Surface**: Affects all nodes with DB sharding enabled when serving API requests for the targeted account.

5. **Amplification Factor**: One-time attack cost creates permanent query degradation for all future users.

## Recommendation

Implement deletion tracking in `StateKeysSchema` by modifying the indexer to remove deleted keys from the index:

```rust
// In storage/indexer/src/db_indexer.rs, modify the state key indexing logic:

if self.indexer_db.statekeys_enabled() {
    writeset.write_op_iter().for_each(|(state_key, write_op)| {
        if write_op.is_creation() || write_op.is_modification() {
            batch
                .put::<StateKeysSchema>(state_key, &())
                .expect("Failed to put state keys to a batch");
        } else if write_op.is_deletion() {
            // NEW: Remove deleted keys from the index
            batch
                .delete::<StateKeysSchema>(state_key)
                .expect("Failed to delete state key from batch");
        }
    });
}
```

Additionally, implement a one-time migration to clean up existing deleted keys from the index by:
1. Iterating through all keys in `StateKeysSchema`
2. Checking if each key exists in the current state
3. Removing keys that no longer exist

This ensures both forward correctness and cleans up historical pollution.

## Proof of Concept

```move
// File: sources/deletion_attack.move
module attacker::deletion_attack {
    use std::signer;
    use std::vector;

    struct Resource0 has key { value: u64 }
    struct Resource1 has key { value: u64 }
    // ... Define Resource2 through Resource8191 similarly
    // (In practice, would use a macro or code generation)

    /// Create maximum number of resources in a single transaction
    public entry fun create_resources(account: &signer) {
        move_to(account, Resource0 { value: 0 });
        move_to(account, Resource1 { value: 1 });
        // ... Create Resource2 through Resource8191
        // This creates 8192 resources (max per transaction)
    }

    /// Delete all created resources
    public entry fun delete_resources(account: &signer) acquires Resource0, Resource1 {
        let Resource0 { value: _ } = move_from<Resource0>(signer::address_of(account));
        let Resource1 { value: _ } = move_from<Resource1>(signer::address_of(account));
        // ... Delete Resource2 through Resource8191
    }
}

// Exploit steps:
// 1. Deploy the module
// 2. Call create_resources() 122 times to create ~1M resources
// 3. Call delete_resources() 122 times to delete all resources
// 4. All 1M deleted keys remain in StateKeysSchema
// 5. Query /v1/accounts/0xATTACKER/resources to observe severe slowdown
// 6. Each query must iterate through 1M deleted keys performing DB lookups
```

The proof of concept demonstrates that an attacker can permanently degrade API performance for their own account (or any account where they can create resources). The attack cost scales with the number of deleted keys, but the performance impact is permanent and affects all future queries.

**Notes**

This vulnerability specifically affects deployments with DB sharding enabled, as indicated by the conditional logic that routes to the indexer-based iterator. The non-sharded path uses `StateValueSchema` directly and is not affected by this issue, as that schema naturally handles deletions through versioning.

### Citations

**File:** storage/indexer/src/db_indexer.rs (L489-496)
```rust
            if self.indexer_db.statekeys_enabled() {
                writeset.write_op_iter().for_each(|(state_key, write_op)| {
                    if write_op.is_creation() || write_op.is_modification() {
                        batch
                            .put::<StateKeysSchema>(state_key, &())
                            .expect("Failed to put state keys to a batch");
                    }
                });
```

**File:** api/src/context.rs (L477-496)
```rust
        let account_iter = if !db_sharding_enabled(&self.node_config) {
            Box::new(
                self.db
                    .get_prefixed_state_value_iterator(
                        &StateKeyPrefix::from(address),
                        prev_state_key,
                        version,
                    )?
                    .map(|item| item.map_err(|err| anyhow!(err.to_string()))),
            )
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| format_err!("Indexer reader doesn't exist"))?
                .get_prefixed_state_value_iterator(
                    &StateKeyPrefix::from(address),
                    prev_state_key,
                    version,
                )?
        };
```

**File:** api/src/context.rs (L502-529)
```rust
        let mut resource_iter = account_iter
            .filter_map(|res| match res {
                Ok((k, v)) => match k.inner() {
                    StateKeyInner::AccessPath(AccessPath { address: _, path }) => {
                        match Path::try_from(path.as_slice()) {
                            Ok(Path::Resource(struct_tag)) => {
                                Some(Ok((struct_tag, v.bytes().to_vec())))
                            }
                            // TODO: Consider expanding to Path::Resource
                            Ok(Path::ResourceGroup(struct_tag)) => {
                                Some(Ok((struct_tag, v.bytes().to_vec())))
                            }
                            Ok(Path::Code(_)) => None,
                            Err(e) => Some(Err(anyhow::Error::from(e))),
                        }
                    }
                    _ => {
                        error!("storage prefix scan return inconsistent key ({:?}) with expected key prefix ({:?}).", k, StateKeyPrefix::from(address));
                        Some(Err(format_err!( "storage prefix scan return inconsistent key ({:?})", k )))
                    }
                },
                Err(e) => Some(Err(e)),
            })
            .take(limit as usize + 1);
        let kvs = resource_iter
            .by_ref()
            .take(limit as usize)
            .collect::<Result<Vec<(StructTag, Vec<u8>)>>>()?;
```

**File:** storage/indexer/src/utils.rs (L49-74)
```rust
    pub fn next_impl(&mut self) -> anyhow::Result<Option<(StateKey, StateValue)>> {
        let iter = &mut self.state_keys_iter;
        if self.is_finished {
            return Ok(None);
        }
        while let Some((state_key, _)) = iter.next().transpose()? {
            if !self.key_prefix.is_prefix(&state_key)? {
                self.is_finished = true;
                return Ok(None);
            }

            match self
                .main_db
                .get_state_value_by_version(&state_key, self.desired_version)?
            {
                Some(state_value) => {
                    return Ok(Some((state_key, state_value)));
                },
                None => {
                    // state key doesn't have value before the desired version, continue to next state key
                    continue;
                },
            }
        }
        Ok(None)
    }
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L174-177)
```rust
            max_write_ops_per_transaction: NumSlots,
            { 11.. => "max_write_ops_per_transaction" },
            8192,
        ],
```

**File:** config/src/config/api_config.rs (L100-101)
```rust
const DEFAULT_MAX_ACCOUNT_RESOURCES_PAGE_SIZE: u16 = 9999;
const DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE: u16 = 9999;
```
