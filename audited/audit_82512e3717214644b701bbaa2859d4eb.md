# Audit Report

## Title
Ledger Pruner Crash Recovery Failure: Non-Atomic Progress Updates Cause Validator Startup DoS

## Summary
During fast sync operations, the ledger pruner's progress markers are written sequentially across multiple databases without atomicity. If a crash occurs mid-write, sub-pruner progress can exceed the metadata pruner progress, causing arithmetic underflow during restart. This results in validator startup failure and requires manual database intervention.

## Finding Description

The LedgerPruner system maintains separate progress markers for the metadata pruner (`LedgerPrunerProgress`) and each of seven sub-pruners (e.g., `EventPrunerProgress`, `TransactionPrunerProgress`). During fast sync completion, these progress markers are updated sequentially without atomic transaction guarantees. [1](#0-0) 

The critical ordering is: sub-database progress markers are written FIRST, and `LedgerPrunerProgress` (in `ledger_metadata_db`) is written LAST. If a crash occurs after some sub-database writes complete but before `ledger_metadata_db.write_pruner_progress()` executes, the database enters an inconsistent state where:
- Sub-pruner progress = NEW_VERSION (e.g., 1000)
- LedgerPrunerProgress = OLD_VERSION (e.g., 900)

On validator restart, `LedgerPruner::new()` initializes by reading the metadata progress: [2](#0-1) 

Each sub-pruner then attempts to "catch up" to this metadata progress: [3](#0-2) 

When `progress (1000) > metadata_progress (900)`, the catch-up logic calls `self.prune(1000, 900)` with inverted parameters. This triggers multiple failure modes:

**EventStorePruner Failure Path:**
The `prune()` method calculates `(end - start)` for the version range: [4](#0-3) 

With `start=1000` and `end=900`, the subtraction `(900 - 1000)` underflows in unsigned arithmetic, wrapping to a massive value (approximately `u64::MAX - 100`). This value is then passed to `get_events_by_version_iter()`, which performs overflow-checked addition: [5](#0-4) 

The `checked_add()` overflow returns `None`, triggering `AptosDbError::TooManyRequested`, causing validator initialization to fail.

**TransactionPruner Failure Path:**
This sub-pruner includes an explicit validation check: [6](#0-5) 

With inverted parameters, this check fails immediately with an error message, also preventing validator startup.

This violates the **State Consistency** invariant that pruner progress markers must remain synchronized and monotonically increasing.

## Impact Explanation

**Severity: Medium** (per Aptos bug bounty criteria: "State inconsistencies requiring intervention")

**Impact Breakdown:**
- **Validator Availability**: Complete denial of service for the affected validator node - it cannot restart until manual database repair
- **Network Impact**: Single validator outage does not compromise consensus (requires >2/3 validators), but reduces network resilience
- **Recovery Complexity**: Requires manual intervention to either:
  1. Reset all sub-pruner progress markers to match `LedgerPrunerProgress`
  2. Advance `LedgerPrunerProgress` to match sub-pruner progress
  3. Restore from backup
- **No Consensus Break**: Does not affect other validators or compromise blockchain integrity
- **No Fund Loss**: No direct financial impact

The issue qualifies as Medium severity because it causes state inconsistency requiring manual intervention and temporarily reduces validator availability, but does not threaten consensus safety or cause fund loss.

## Likelihood Explanation

**Likelihood: Medium-High for validators performing fast sync**

**Factors Increasing Likelihood:**
- Fast sync is a common operation for new validators joining the network or validators recovering from extended downtime
- The vulnerable window exists during every fast sync completion
- No attacker action required - occurs naturally from system crashes, power failures, or OOM kills
- Modern SSDs perform writes asynchronously, increasing crash vulnerability window

**Factors Decreasing Likelihood:**
- Requires crash at specific moment during sequential progress writes (approximately 8 sequential operations)
- Modern systems are generally stable, reducing crash frequency
- Issue only manifests during fast sync, not during normal pruning operations (where metadata pruner executes first)

**Real-World Scenario:**
A validator operator initiates fast sync to catch up to network state. During the final progress marker writes, the system experiences:
- Out-of-memory condition triggering SIGKILL
- Power failure or hardware fault
- Operating system crash
- Container orchestration system killing the pod

On restart attempt, the validator fails initialization and logs cryptic errors about invalid version ranges or overflow conditions, requiring expert intervention to diagnose and repair.

## Recommendation

**Immediate Fix: Add invariant validation in sub-pruner initialization**

Modify each sub-pruner's constructor to validate that its saved progress does not exceed the metadata progress. If it does, skip the catch-up logic:

```rust
// In event_store_pruner.rs EventStorePruner::new()
pub(in crate::pruner) fn new(
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
    internal_indexer_db: Option<InternalIndexerDB>,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        ledger_db.event_db_raw(),
        &DbMetadataKey::EventPrunerProgress,
        metadata_progress,
    )?;

    let myself = EventStorePruner {
        ledger_db,
        internal_indexer_db,
    };

    // FIX: Only catch up if progress is behind metadata_progress
    if progress < metadata_progress {
        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;
    } else if progress > metadata_progress {
        warn!(
            progress = progress,
            metadata_progress = metadata_progress,
            "EventStorePruner progress ahead of metadata progress - skipping catch-up due to crash recovery"
        );
    }

    Ok(myself)
}
```

**Long-Term Fix: Ensure atomic progress updates**

Modify `LedgerDb::write_pruner_progress()` to use a single atomic batch write:

```rust
pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
    info!("Fast sync is done, writing pruner progress {version} for all ledger sub pruners.");
    
    // Create a single batch for all progress updates
    let mut batch = SchemaBatch::new();
    
    // Add all progress markers to the same batch
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::EventPrunerProgress,
        &DbMetadataValue::Version(version),
    )?;
    // ... (repeat for all sub-pruner progress keys)
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::LedgerPrunerProgress,
        &DbMetadataValue::Version(version),
    )?;
    
    // Write atomically
    self.ledger_metadata_db.db().write_schemas(batch)?;
    
    Ok(())
}
```

## Proof of Concept

**Reproduction Steps:**

1. **Setup**: Start a validator node and initiate fast sync
2. **Crash Injection**: Use `kill -9` (SIGKILL) during the progress write phase in `write_pruner_progress()`
3. **Verify Inconsistency**: 
   ```bash
   # Check database state
   rocksdb_tool --db=<db_path>/ledger_db/metadata scan --column_family=metadata | grep Progress
   # Should show EventPrunerProgress > LedgerPrunerProgress
   ```
4. **Trigger Bug**: Restart validator
5. **Observe Failure**: Validator fails with error during `LedgerPruner::new()`:
   ```
   Error: "Too many requested: XXX exceeds maximum Version::MAX"
   or
   Error: "900 must be >= 1000"
   ```

**Automated Test Case:**

```rust
#[test]
fn test_crash_recovery_with_inconsistent_progress() {
    let tmpdir = TempPath::new();
    let mut db = AptosDB::new_for_test(&tmpdir);
    
    // Simulate fast sync completing
    // Write sub-pruner progress
    db.ledger_db.event_db().write_pruner_progress(1000).unwrap();
    db.ledger_db.transaction_db().write_pruner_progress(1000).unwrap();
    
    // Simulate crash before metadata pruner progress is written
    // LedgerPrunerProgress remains at old value (e.g., 900)
    
    // Drop and reopen DB to simulate restart
    drop(db);
    
    // This should fail during LedgerPruner initialization
    let result = std::panic::catch_unwind(|| {
        AptosDB::new_for_test(&tmpdir)
    });
    
    assert!(result.is_err(), "Expected validator initialization to fail");
}
```

## Notes

This vulnerability specifically affects the fast sync completion path where `LedgerDb::write_pruner_progress()` is called from `save_min_readable_version()`. During normal pruning operations (via `PrunerWorker`), the metadata pruner executes first, maintaining the correct ordering where `LedgerPrunerProgress >= sub_pruner_progress`.

The issue exemplifies the broader challenge of maintaining consistency across multiple independent database write operations without distributed transaction support. The recommended atomic batch approach ensures all-or-nothing semantics for progress marker updates.

### Citations

**File:** storage/aptosdb/src/ledger_db/mod.rs (L373-388)
```rust
    pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
        info!("Fast sync is done, writing pruner progress {version} for all ledger sub pruners.");
        self.event_db.write_pruner_progress(version)?;
        self.persisted_auxiliary_info_db
            .write_pruner_progress(version)?;
        self.transaction_accumulator_db
            .write_pruner_progress(version)?;
        self.transaction_auxiliary_data_db
            .write_pruner_progress(version)?;
        self.transaction_db.write_pruner_progress(version)?;
        self.transaction_info_db.write_pruner_progress(version)?;
        self.write_set_db.write_pruner_progress(version)?;
        self.ledger_metadata_db.write_pruner_progress(version)?;

        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L129-129)
```rust
        let metadata_progress = ledger_metadata_pruner.progress()?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L90-106)
```rust
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L111-113)
```rust
            start_version.checked_add(num_versions as u64).ok_or(
                AptosDbError::TooManyRequested(num_versions as u64, Version::MAX),
            )?,
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L202-202)
```rust
        for events in self.get_events_by_version_iter(start, (end - start) as usize)? {
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L111-111)
```rust
        ensure!(end >= start, "{} must be >= {}", end, start);
```
