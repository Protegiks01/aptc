# Audit Report

## Title
TOCTOU Race Condition in SafetyRules Voting with OnDiskStorage in Multi-Process Deployments

## Summary
The `guarded_construct_and_sign_vote_two_chain()` function contains a read-modify-write pattern on persistent storage without atomic guarantees when using OnDiskStorage. If multiple SafetyRules instances access the same storage file concurrently (across different processes), both can read the same `last_voted_round`, pass the voting eligibility check, and create votes for the same round, violating the single-vote-per-round guarantee and enabling equivocation.

## Finding Description

The vulnerability exists in the voting logic's interaction with persistent storage: [1](#0-0) 

The function performs:
1. **READ**: Loads `safety_data` from persistent storage (line 66)
2. **CHECK**: Verifies if already voted in this round (lines 70-74)  
3. **MODIFY**: Updates `last_voted_round` in memory (lines 77-80)
4. **WRITE**: Persists updated `safety_data` back to storage (line 92)

This is a classic TOCTOU (Time-Of-Check-Time-Of-Use) vulnerability. While in-process synchronization exists via `Arc<Mutex<>>` in RoundManager [2](#0-1)  and `Arc<RwLock<>>` in LocalClient [3](#0-2) , these only protect within a single process.

The OnDiskStorage implementation lacks file-level locking: [4](#0-3) 

The comments explicitly state it's "intended for single threads (or must be wrapped by a Arc<RwLock<>>)", but `RwLock` only works within a process, not across processes.

**Race Condition Scenario:**
- Process A: Reads safety_data (`last_voted_round = X`)
- Process B: Reads safety_data (`last_voted_round = X`)  
- Process A: Checks round Y > X ✓, updates to Y, writes back
- Process B: Checks round Y > X ✓ (still using old cached value), updates to Y, writes back
- **Result**: Both processes created and signed votes for round Y → **EQUIVOCATION**

## Impact Explanation

**Severity: CRITICAL** (per Aptos Bug Bounty criteria)

This violates **Consensus Safety** - the fundamental BFT guarantee that no validator can vote twice in the same round (equivocation). Equivocation can lead to:
- Chain splits if conflicting votes create competing forks
- Loss of consensus safety under < 1/3 Byzantine assumption
- Potential for double-spending if malicious validators exploit this

This breaks the documented invariant: "Consensus Safety: AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine"

However, **exploitation requires**:
- Multiple SafetyRules instances (different processes) configured with the same storage path
- This is NOT a standard deployment configuration
- Requires either deployment misconfiguration OR insider access to run multiple processes

## Likelihood Explanation

**Likelihood: LOW in production, but vulnerability exists in code**

Standard Aptos deployment has:
- ONE consensus process per validator node
- Each SafetyRules instance has dedicated storage
- No legitimate reason for shared storage across processes

This can occur through:
1. **Configuration error**: Admin accidentally points multiple instances to same storage path
2. **Container orchestration bug**: Shared volumes between containers  
3. **Testing/development**: Running multiple instances with same config
4. **Malicious insider**: Validator operator intentionally running multiple processes

The vulnerability is real (no file locking exists), but exploitation requires privileged access or severe misconfiguration, placing it outside the "unprivileged attacker" scope defined in the trust model.

## Recommendation

**Option 1: Add Process-Level File Locking (Preferred)**

Implement exclusive file locking for OnDiskStorage using the `fs2` crate, following the pattern used in the codebase: [5](#0-4) 

Add an exclusive lock in `OnDiskStorage::new()` that's held for the lifetime of the storage instance. This prevents multiple processes from accessing the same storage file.

**Option 2: Add Process ID Check**

Store a process ID in the storage file on initialization and verify it on each access. Panic if a different process attempts to use the same storage.

**Option 3: Use VaultStorage with CAS Enabled**

For production deployments, prefer VaultStorage with CAS (Compare-And-Swap) enabled: [6](#0-5) 

CAS provides atomic read-modify-write semantics that would cause the second concurrent write to fail, preventing equivocation (though causing the vote to fail, which is preferable to a safety violation).

## Proof of Concept

**Note**: This PoC requires running multiple processes with the same storage configuration, which is not exploitable by an external attacker but demonstrates the code-level race condition:

```rust
// Run two separate processes concurrently:
// Process 1:
use aptos_safety_rules::*;
use aptos_secure_storage::{OnDiskStorage, Storage};

fn main() {
    let storage_path = "/tmp/shared_safety_storage.json";
    let storage = Storage::from(OnDiskStorage::new(storage_path.into()));
    let mut safety_storage = PersistentSafetyStorage::new(storage, false);
    
    // Initialize with author and consensus key
    // ... initialization code ...
    
    let mut safety_rules = SafetyRules::new(safety_storage, false);
    
    // Vote on round 10
    let vote_proposal = create_vote_proposal_for_round(10);
    let vote = safety_rules.construct_and_sign_vote_two_chain(&vote_proposal, None).unwrap();
    println!("Process 1 created vote for round: {}", vote.vote_data().proposed().round());
}

// Process 2: (identical code, run simultaneously)
// Both processes can successfully create votes for round 10
// Demonstrating equivocation
```

**Expected Result**: Both processes successfully create votes for round 10, violating the single-vote-per-round guarantee.

**Actual Production Impact**: This scenario cannot occur in standard deployments without privileged access or severe misconfiguration.

---

## Notes

After thorough investigation, while the code-level race condition exists in the OnDiskStorage implementation, **this does NOT meet the "unprivileged attacker" exploitation criterion** specified in the validation checklist. The vulnerability requires:

- Ability to run multiple consensus processes on a validator node (privileged access)
- OR deployment misconfiguration causing storage sharing (operator error)

Standard Aptos deployments have proper in-process synchronization via `Mutex`/`RwLock` and run a single consensus process per validator. The lack of file-level locking in OnDiskStorage is a documented design choice based on the single-process assumption.

While the recommendation to add file-level locking would improve defense-in-depth, this is fundamentally a deployment/configuration issue rather than a vulnerability exploitable by external attackers.

### Citations

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L66-80)
```rust
        let mut safety_data = self.persistent_storage.safety_data()?;

        // if already voted on this round, send back the previous vote
        // note: this needs to happen after verifying the epoch as we just check the round here
        if let Some(vote) = safety_data.last_vote.clone() {
            if vote.vote_data().proposed().round() == proposed_block.round() {
                return Ok(vote);
            }
        }

        // Two voting rules
        self.verify_and_update_last_vote_round(
            proposed_block.block_data().round(),
            &mut safety_data,
        )?;
```

**File:** consensus/src/round_manager.rs (L309-309)
```rust
    safety_rules: Arc<Mutex<MetricsSafetyRules>>,
```

**File:** consensus/safety-rules/src/local_client.rs (L25-25)
```rust
    internal: Arc<RwLock<SafetyRules>>,
```

**File:** secure/storage/src/on_disk.rs (L16-22)
```rust
/// OnDiskStorage represents a key value store that is persisted to the local filesystem and is
/// intended for single threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission
/// checks and simply offers a proof of concept to unblock building of applications without more
/// complex data stores. Internally, it reads and writes all data to a file, which means that it
/// must make copies of all key material which violates the code base. It violates it because
/// the anticipation is that data stores would securely handle key material. This should not be used
/// in production.
```

**File:** third_party/move/tools/move-package-cache/src/file_lock.rs (L15-46)
```rust
/// A file-based lock to ensure exclusive access to certain resources.
///
/// This is used by the package cache to ensure only one process can mutate a cached repo, checkout,
/// or on-chain package at a time.
pub struct FileLock {
    file: Option<File>,
    path: PathBuf,
}

impl FileLock {
    /// Attempts to acquire an exclusive `FileLock`, with an optional alert callback.
    ///
    /// If the lock cannot be acquired within `alert_timeout`, the `alert_on_wait` callback
    /// is executed to notify the caller.
    pub async fn lock_with_alert_on_wait<P, F>(
        lock_path: P,
        alert_timeout: Duration,
        alert_on_wait: F,
    ) -> Result<Self>
    where
        P: AsRef<Path>,
        F: FnOnce(),
    {
        let lock_path = lock_path.as_ref().to_owned();

        let lock_fut = {
            let lock_path = lock_path.clone();

            task::spawn_blocking(move || -> Result<File> {
                let lock_file = File::create(&lock_path)?;
                lock_file.lock_exclusive()?;
                Ok(lock_file)
```

**File:** config/src/config/secure_backend_config.rs (L183-183)
```rust
                    config.disable_cas.map_or_else(|| true, |disable| !disable),
```
