# Audit Report

## Title
Panic on Empty Targets Vector in Secret Share Request Multicast

## Summary
The `spawn_share_requester_task()` function in the secret share manager can pass an empty targets vector to `rb.multicast()` when all validators have already provided their shares. This triggers a panic due to the `unreachable!()` macro in the reliable broadcast implementation, causing abnormal termination of the background task.

## Finding Description
When a new block is processed, each validator broadcasts its secret share and spawns a background task to request missing shares from other validators after a 300ms delay. [1](#0-0) 

If all validators' shares arrive within the 300ms window (which is the expected behavior in a well-performing network), the `targets` vector becomes empty after filtering out validators that are already in `existing_shares`. This empty vector is then passed to `rb.multicast()`. [2](#0-1) 

The `multicast()` implementation does not handle empty receivers gracefully. When no receivers are provided, the for-loop at lines 164-166 executes zero iterations, leaving both `rpc_futures` and `aggregate_futures` empty. [3](#0-2) 

In the subsequent `tokio::select!` loop, both stream arms immediately return `None` because the FuturesUnordered collections are empty, causing execution to reach the `else` branch which contains `unreachable!()`. [4](#0-3) 

This same vulnerability exists in the randomness generation code path. [5](#0-4) 

## Impact Explanation
This is a **Low Severity** issue as categorized in the Aptos bug bounty program under "Non-critical implementation bugs." The panic occurs in a spawned background task and does not affect:
- Consensus safety or liveness (shares have already been collected)
- State consistency or deterministic execution
- Validator node operation or availability
- Any critical system invariants

However, it does cause:
- Abnormal task termination with panic logs
- Wasted computational resources spawning doomed tasks
- Operational noise that complicates debugging legitimate issues
- Occurs frequently in well-performing networks (the "happy path")

## Likelihood Explanation
This issue has **HIGH likelihood** of occurring in production environments. In a network with good latency characteristics (< 100ms between validators) and a reasonable number of validators (4-10), all secret shares will typically arrive well within the 300ms delay window. This means the panic would be triggered during normal, optimal network operation for every consensus round.

## Recommendation
Add a guard check before calling multicast to skip the operation when targets is empty:

```rust
if !targets.is_empty() {
    info!(
        epoch = epoch,
        round = metadata.round,
        "[SecretShareManager] Start broadcasting share request for {}",
        targets.len(),
    );
    rb.multicast(request, aggregate_state, targets)
        .await
        .expect("Broadcast cannot fail");
    info!(
        epoch = epoch,
        round = metadata.round,
        "[SecretShareManager] Finish broadcasting share request",
    );
} else {
    info!(
        epoch = epoch,
        round = metadata.round,
        "[SecretShareManager] All shares already received, skipping request",
    );
}
```

Apply the same fix to `rand_manager.rs` at the equivalent location.

Alternatively, fix the root cause by making `multicast()` handle empty receivers gracefully by returning immediately with a successful empty aggregation.

## Proof of Concept
```rust
// Test demonstrating the panic with empty receivers
#[tokio::test]
#[should_panic(expected = "Should aggregate with all responses")]
async fn test_multicast_empty_receivers_panic() {
    use aptos_types::validator_verifier::random_validator_verifier;
    
    let (_, validator_verifier) = random_validator_verifier(4, None, false);
    let validators = validator_verifier.get_ordered_account_addresses();
    let self_author = validators[0];
    
    let sender = Arc::new(TestRBSender::<TestRBMessage>::new(HashMap::new()));
    let rb = ReliableBroadcast::new(
        self_author,
        validators.clone(),
        sender,
        FixedInterval::from_millis(10),
        TimeService::real(),
        Duration::from_millis(500),
        BoundedExecutor::new(2, Handle::current()),
    );
    
    let message = TestMessage(vec![42]);
    let aggregating = Arc::new(TestBroadcastStatus {
        threshold: 0, // No responses needed
        received: Arc::new(Mutex::new(HashSet::new())),
    });
    
    // Pass empty receivers vector - this will panic
    let empty_receivers: Vec<Author> = vec![];
    rb.multicast(message, aggregating, empty_receivers).await.unwrap();
}
```

### Citations

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L246-257)
```rust
        let task = async move {
            // TODO(ibalajiarun): Make this configurable
            tokio::time::sleep(Duration::from_millis(300)).await;
            let maybe_existing_shares = secret_share_store.lock().get_all_shares_authors(&metadata);
            if let Some(existing_shares) = maybe_existing_shares {
                let epoch = epoch_state.epoch;
                let request = RequestSecretShare::new(metadata.clone());
                let targets = epoch_state
                    .verifier
                    .get_ordered_account_addresses_iter()
                    .filter(|author| !existing_shares.contains(author))
                    .collect::<Vec<_>>();
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L264-266)
```rust
                rb.multicast(request, aggregate_state, targets)
                    .await
                    .expect("Broadcast cannot fail");
```

**File:** crates/reliable-broadcast/src/lib.rs (L164-166)
```rust
            for receiver in receivers {
                rpc_futures.push(send_message(receiver, None));
            }
```

**File:** crates/reliable-broadcast/src/lib.rs (L167-204)
```rust
            loop {
                tokio::select! {
                    Some((receiver, result)) = rpc_futures.next() => {
                        let aggregating = aggregating.clone();
                        let future = executor.spawn(async move {
                            (
                                    receiver,
                                    result
                                        .and_then(|msg| {
                                            msg.try_into().map_err(|e| anyhow::anyhow!("{:?}", e))
                                        })
                                        .and_then(|ack| aggregating.add(receiver, ack)),
                            )
                        }).await;
                        aggregate_futures.push(future);
                    },
                    Some(result) = aggregate_futures.next() => {
                        let (receiver, result) = result.expect("spawned task must succeed");
                        match result {
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
                                }
                            },
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
                        }
                    },
                    else => unreachable!("Should aggregate with all responses")
                }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L280-292)
```rust
                    .verifier
                    .get_ordered_account_addresses_iter()
                    .filter(|author| !existing_shares.contains(author))
                    .collect::<Vec<_>>();
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Start broadcasting share request for {}",
                    targets.len(),
                );
                rb.multicast(request, aggregate_state, targets)
                    .await
                    .expect("Broadcast cannot fail");
```
