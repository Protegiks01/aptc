# Audit Report

## Title
State Sync InvalidSyncRequest Error Incorrectly Rejects Legitimate Consensus Sync Requests During Pre-Commit Race Conditions

## Summary
The `InvalidSyncRequest` error validation in `state-sync-driver` incorrectly treats the case where `sync_target_version == latest_pre_committed_version` as an error condition, when this can occur legitimately due to timing races between consensus's optimistic pre-commit pipeline and state sync notification processing. This causes consensus to receive errors for valid sync requests, potentially leading to unnecessary retries, delays, or temporary liveness degradation. [1](#0-0) 

## Finding Description

The vulnerability exists in the sync target request validation logic that handles consensus notifications. When consensus requests state sync to synchronize to a target version, the validation performs three checks: [2](#0-1) [3](#0-2) [4](#0-3) 

The critical flaw is in the third check: when `sync_target_version == latest_pre_committed_version`, it returns `InvalidSyncRequest` error with the comment "something has else gone wrong". However, this condition can occur legitimately due to a race condition in the consensus pipeline.

**The Race Condition Flow:**

1. Consensus executes blocks through its pipelined execution and calls optimistic pre-commit: [5](#0-4) 

2. Meanwhile, consensus determines it needs state sync to catch up (e.g., during epoch transitions or fallback scenarios) and sends a sync target notification: [6](#0-5) 

3. The notification is processed by the state sync driver: [7](#0-6) 

4. State sync driver fetches the pre-committed version and validates: [8](#0-7) 

**TOCTOU Vulnerability:**
Between fetching `latest_pre_committed_version` (line 413) and checking it against the target (line 303 in notification_handlers.rs), the pre-committed version can change due to concurrent pre-commit operations. This creates a Time-of-Check-Time-of-Use (TOCTOU) race condition.

**Scenario Demonstrating the Issue:**

```
Time T0: pre_committed_version = 99, committed_version = 95
Time T1: Consensus pipeline begins pre-committing block 100
Time T2: Consensus sends sync_to_target(version=100) notification
Time T3: Pre-commit completes, pre_committed_version = 100
Time T4: State sync driver processes notification
        - Reads pre_committed_version = 100
        - Reads sync_target_version = 100
        - Check fails: 100 == 100 â†’ InvalidSyncRequest
Time T5: Consensus receives error and may retry or enter error handling
```

The logical inconsistency is that when `committed_version == target`, state sync correctly returns success (lines 289-300), recognizing that the target is already reached. By the same logic, when `pre_committed_version == target`, the data is already written to storage and only needs certification - the sync target notification contains the `LedgerInfoWithSignatures` needed for this certification, but instead of using it, the code returns an error.

## Impact Explanation

**Severity: High** (Validator node slowdowns / Significant protocol violations)

This vulnerability causes:

1. **Incorrect Error Propagation**: Consensus receives `InvalidSyncRequest` errors for legitimate sync requests, violating the expected protocol behavior where state sync should handle transitions between pre-committed and committed states gracefully.

2. **Potential Liveness Degradation**: When consensus receives these errors during critical operations like epoch transitions or catchup scenarios: [9](#0-8) 
   
   If the sync fails with this error, the entire fast-forward sync operation fails, potentially causing validators to be unable to catch up to the network.

3. **Retry Amplification**: Consensus may implement retry logic that repeatedly hits this race condition, causing unnecessary computational overhead and delays in achieving consensus state synchronization.

4. **State Sync Protocol Violation**: The check violates the state synchronization invariant that state sync should gracefully handle all valid transition states between pre-committed and fully committed data. The code comment "something has else gone wrong" indicates this was not an intentionally designed error case.

This meets the **High Severity** criteria: "Validator node slowdowns" and "Significant protocol violations" as it affects the critical consensus-state sync coordination path.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to trigger because:

1. **Optimistic Pre-Commit Design**: Aptos consensus uses optimistic pre-commit to improve performance, making the race window between pre-commit and sync requests common during normal operation.

2. **Natural Timing Windows**: The race can occur naturally without any attacker action during:
   - Epoch transitions when validators are catching up
   - Network partitions followed by rejoin scenarios
   - Consensus observer synchronization
   - Any scenario where consensus pipeline and state sync coordination overlap

3. **Multiple Notification Sources**: The codebase supports both consensus and consensus observer notifications, increasing the chance of concurrent requests: [10](#0-9) 

4. **Non-Atomic Check**: The pre-committed version is fetched separately from the validation check, creating a TOCTOU window that is not protected by any synchronization mechanism.

## Recommendation

**Fix Option 1: Treat Pre-Committed == Target as Success**

Change the validation logic to handle `pre_committed_version == target` similarly to how `committed_version == target` is handled:

```rust
// In notification_handlers.rs, replace lines 302-310 with:

// If the pre-committed version is already at the target, we just need to certify it
if sync_target_version == latest_pre_committed_version {
    info!(
        LogSchema::new(LogEntry::NotificationHandler).message(&format!(
            "Target version {} is already pre-committed (committed: {}). \
             Completing certification.",
            sync_target_version, latest_committed_version
        ))
    );
    
    // The target ledger info provides the certification we need
    // State sync will complete when the ledger info is applied
    let consensus_sync_request =
        ConsensusSyncRequest::new_with_target(sync_target_notification);
    self.consensus_sync_request = Arc::new(Mutex::new(Some(consensus_sync_request)));
    
    // Immediately check if we can satisfy this request
    return Ok(());
}
```

**Fix Option 2: Atomic Check-and-Set**

Alternatively, make the version check atomic by holding a lock during the entire validation and save operation, though this would impact performance.

**Fix Option 3: Remove the Check**

If the pre-committed == target case should never occur in correct operation, add defensive logging but don't treat it as a hard error - instead handle it gracefully by either returning success or proceeding with the sync request.

## Proof of Concept

```rust
// Rust test demonstrating the race condition
// File: state-sync/state-sync-driver/src/tests/notification_handlers_test.rs

#[tokio::test]
async fn test_precommit_race_invalid_sync_request() {
    // Setup: Create mock storage with pre_committed = 99, committed = 95
    let storage = Arc::new(MockDbReader::new());
    storage.set_pre_committed_version(99);
    storage.set_committed_version(95);
    
    // Create consensus notification handler
    let time_service = TimeService::mock();
    let (consensus_listener, _) = ConsensusNotificationListener::new();
    let mut handler = ConsensusNotificationHandler::new(
        consensus_listener,
        time_service
    );
    
    // Create sync target notification for version 100
    let target_li = create_ledger_info_with_sigs(100);
    let (sync_notification, _callback) = ConsensusSyncTargetNotification::new(target_li);
    
    // Simulate race: pre-commit completes before validation
    // This would happen in concurrent execution
    tokio::spawn(async move {
        tokio::time::sleep(Duration::from_micros(10)).await;
        storage.set_pre_committed_version(100); // Race!
    });
    
    tokio::time::sleep(Duration::from_micros(50)).await;
    
    // Process notification - will now see pre_committed = 100
    let result = handler.initialize_sync_target_request(
        sync_notification,
        100, // latest_pre_committed_version after race
        create_ledger_info_with_sigs(95), // committed version
    ).await;
    
    // BUG: This returns InvalidSyncRequest error even though the request is valid
    assert!(matches!(result, Err(Error::InvalidSyncRequest(100, 100))));
    
    // EXPECTED: Should return Ok(()) or handle gracefully, not error
}
```

**Notes:**
The PoC demonstrates that when the pre-committed version equals the target version due to a timing race, the code incorrectly returns an error. In production, this would cause consensus to receive errors during legitimate synchronization attempts, potentially causing validators to fail catchup operations or experience delays in state synchronization.

### Citations

**File:** state-sync/state-sync-driver/src/error.rs (L31-34)
```rust
    #[error(
        "Received an invalid sync request for version: {0}, but the pre-committed version is: {1}"
    )]
    InvalidSyncRequest(Version, Version),
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L275-286)
```rust
        // If the target version is old, return an error to consensus (something is wrong!)
        if sync_target_version < latest_committed_version
            || sync_target_version < latest_pre_committed_version
        {
            let error = Err(Error::OldSyncRequest(
                sync_target_version,
                latest_pre_committed_version,
                latest_committed_version,
            ));
            self.respond_to_sync_target_notification(sync_target_notification, error.clone())?;
            return error;
        }
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L288-300)
```rust
        // If the committed version is at the target, return successfully
        if sync_target_version == latest_committed_version {
            info!(
                LogSchema::new(LogEntry::NotificationHandler).message(&format!(
                    "We're already at the requested sync target version: {} \
                (pre-committed version: {}, committed version: {})!",
                    sync_target_version, latest_pre_committed_version, latest_committed_version
                ))
            );
            let result = Ok(());
            self.respond_to_sync_target_notification(sync_target_notification, result.clone())?;
            return result;
        }
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L302-310)
```rust
        // If the pre-committed version is already at the target, something has else gone wrong
        if sync_target_version == latest_pre_committed_version {
            let error = Err(Error::InvalidSyncRequest(
                sync_target_version,
                latest_pre_committed_version,
            ));
            self.respond_to_sync_target_notification(sync_target_notification, error.clone())?;
            return error;
        }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1035-1075)
```rust
    async fn pre_commit(
        ledger_update_fut: TaskFuture<LedgerUpdateResult>,
        parent_block_pre_commit_fut: TaskFuture<PreCommitResult>,
        order_proof_fut: TaskFuture<WrappedLedgerInfo>,
        commit_proof_fut: TaskFuture<LedgerInfoWithSignatures>,
        executor: Arc<dyn BlockExecutorTrait>,
        block: Arc<Block>,
        pre_commit_status: Arc<Mutex<PreCommitStatus>>,
    ) -> TaskResult<PreCommitResult> {
        let mut tracker = Tracker::start_waiting("pre_commit", &block);
        let (compute_result, _, _) = ledger_update_fut.await?;
        parent_block_pre_commit_fut.await?;

        order_proof_fut.await?;

        let wait_for_proof = {
            let mut status_guard = pre_commit_status.lock();
            let wait_for_proof = compute_result.has_reconfiguration() || !status_guard.is_active();
            // it's a bit ugly here, but we want to make the check and update atomic in the pre_commit case
            // to avoid race that check returns active, sync manager pauses pre_commit and round gets updated
            if !wait_for_proof {
                status_guard.update_round(block.round());
            }
            wait_for_proof
        };

        if wait_for_proof {
            commit_proof_fut.await?;
            pre_commit_status.lock().update_round(block.round());
        }

        tracker.start_working();
        tokio::task::spawn_blocking(move || {
            executor
                .pre_commit_block(block.id())
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(compute_result)
    }
```

**File:** consensus/src/state_computer.rs (L216-219)
```rust
        let result = monitor!(
            "sync_to_target",
            self.state_sync_notifier.sync_to_target(target).await
        );
```

**File:** state-sync/state-sync-driver/src/driver.rs (L407-442)
```rust
    /// Handles a consensus or consensus observer request to sync to a specified target
    async fn handle_consensus_sync_target_notification(
        &mut self,
        sync_target_notification: ConsensusSyncTargetNotification,
    ) -> Result<(), Error> {
        // Fetch the pre-committed and committed versions
        let latest_pre_committed_version =
            utils::fetch_pre_committed_version(self.storage.clone())?;
        let latest_synced_ledger_info =
            utils::fetch_latest_synced_ledger_info(self.storage.clone())?;
        let latest_committed_version = latest_synced_ledger_info.ledger_info().version();

        // Update the sync target notification logs and metrics
        info!(
            LogSchema::new(LogEntry::ConsensusNotification).message(&format!(
                "Received a consensus sync target notification! Target: {:?}. \
                Latest pre-committed version: {}. Latest committed version: {}.",
                sync_target_notification.get_target(),
                latest_pre_committed_version,
                latest_committed_version,
            ))
        );
        metrics::increment_counter(
            &metrics::DRIVER_COUNTERS,
            metrics::DRIVER_CONSENSUS_SYNC_TARGET_NOTIFICATION,
        );

        // Initialize a new sync request
        self.consensus_notification_handler
            .initialize_sync_target_request(
                sync_target_notification,
                latest_pre_committed_version,
                latest_synced_ledger_info,
            )
            .await
    }
```

**File:** state-sync/state-sync-driver/src/driver.rs (L616-623)
```rust
    /// Returns true iff this node enables consensus or consensus observer
    fn is_consensus_or_observer_enabled(&self) -> bool {
        self.driver_configuration.role == RoleType::Validator
            || self
                .driver_configuration
                .consensus_observer_config
                .observer_enabled
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L512-514)
```rust
        execution_client
            .sync_to_target(highest_commit_cert.ledger_info().clone())
            .await?;
```
