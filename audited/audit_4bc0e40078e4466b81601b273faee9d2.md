# Audit Report

## Title
Dangling Reference in BlockTree: ordered_root Can Point to Pruned Blocks After commit_callback

## Summary
The `commit_callback` function in BlockTree updates `window_root` and `commit_root` and prunes old blocks, but does not verify that `ordered_root_id` still points to an existing block after pruning. This can cause `ordered_root_id` to become a dangling reference, leading to consensus node crashes when `ordered_root()` is subsequently called.

## Finding Description

In the BlockTree implementation, three root pointers track different stages of consensus: `ordered_root_id`, `commit_root_id`, and `window_root_id`. The expected invariant is:

**`window_root.round() ≤ commit_root.round() ≤ ordered_root.round()`** [1](#0-0) 

When blocks are committed, `commit_callback` is invoked to update roots and prune old blocks: [2](#0-1) 

The function performs the following steps:
1. Calculates new `window_root_id` based on the committed block and `window_size`
2. Calls `find_blocks_to_prune(window_root_id)` to determine blocks to remove
3. Prunes blocks from storage and memory via `process_pruned_blocks`
4. Updates `window_root_id` 
5. Updates `commit_root_id` via `update_highest_commit_cert`

**Critical Issue**: `ordered_root_id` is **never checked or updated** during this process. The pruning logic in `find_blocks_to_prune` only considers the new window_root: [3](#0-2) 

The pruning traverses from the current window_root and removes all blocks except those on the path to `next_window_root_id`. If `ordered_root_id` points to a block on a different branch (in case of forks) or at a round below the new window_root, that block will be pruned.

After pruning, `process_pruned_blocks` removes blocks from `id_to_block`: [4](#0-3) 

Subsequently, any call to `ordered_root()` will fail: [5](#0-4) 

The `.expect("Root must exist")` will panic because `get_block(&ordered_root_id)` returns `None` after the block has been pruned.

**Exploitation Scenarios:**

1. **Fork Resolution**: If `ordered_root` points to a block on fork A, and later fork B is committed via `commit_callback`, the entire A branch gets pruned including the ordered_root block.

2. **State Sync Edge Cases**: During recovery or state sync, if commit decisions arrive for high-round blocks while `ordered_root` points to a lower round, the window_root advancement could prune the ordered_root block.

3. **Pipeline Delays**: In decoupled execution with significant pipeline delays, if commits happen for blocks at rounds much higher than the current ordered_root, the window calculation could result in pruning the ordered_root.

Multiple code paths call `ordered_root()`, including:
- `send_for_execution` (checking if new block round > ordered_root)
- `path_from_ordered_root` (used during block proposal)
- Various getters and state queries [6](#0-5) 

## Impact Explanation

This vulnerability causes **consensus node crashes**, fitting the **Medium Severity** category ($10,000 range):
- **State inconsistencies requiring intervention**: The node enters an invalid state where a root pointer is dangling
- **Availability impact**: Node crashes and requires restart
- **Not direct fund loss**: No immediate theft or minting
- **Not consensus safety violation**: The underlying consensus may still be correct, but node implementation fails

The impact is limited because:
- Requires specific timing or network conditions to trigger
- Node can recover by restarting and syncing
- Doesn't affect the blockchain's global consensus state
- Primarily impacts individual node availability

## Likelihood Explanation

**Moderate likelihood** during exceptional network conditions:

1. **Normal Operation**: Low likelihood - the invariant typically holds when blocks are processed in order
2. **Network Forks**: Higher likelihood - BFT consensus can have temporary forks before resolution
3. **State Sync/Recovery**: Higher likelihood - unusual block processing orders during catch-up
4. **Pipeline Edge Cases**: Possible with decoupled execution and varying block processing rates

The vulnerability is a **defensive programming failure** - even if the scenario is rare, the code should validate invariants rather than silently allowing dangling references.

## Recommendation

Add invariant validation in `commit_callback` before pruning to ensure `ordered_root` won't be pruned:

```rust
pub fn commit_callback(
    &mut self,
    storage: Arc<dyn PersistentLivenessStorage>,
    block_id: HashValue,
    block_round: Round,
    finality_proof: WrappedLedgerInfo,
    commit_decision: LedgerInfoWithSignatures,
    window_size: Option<u64>,
) {
    let window_root_id = self.find_window_root(block_id, window_size);
    
    // ADDED: Validate that ordered_root won't be pruned
    let ordered_root_round = self.ordered_root().round();
    let window_root_block = self.get_block(&window_root_id)
        .expect("Window root must exist");
    assert!(
        ordered_root_round >= window_root_block.round(),
        "Cannot prune ordered_root: ordered_root at round {}, window_root at round {}",
        ordered_root_round,
        window_root_block.round()
    );
    
    let ids_to_remove = self.find_blocks_to_prune(window_root_id);
    // ... rest of function
}
```

Alternatively, update `ordered_root` during commit_callback to maintain the invariant:

```rust
// After updating window_root and commit_root, ensure ordered_root is also advanced
if self.commit_root().round() > self.ordered_root().round() {
    self.update_ordered_root(self.commit_root_id);
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_ordered_root_dangling_reference_on_fork() {
    // Create a block tree with forks:
    //       ╭--> A1--> A2--> A3
    // Genesis
    //       ╰--> B1--> B2--> B3
    
    let window_size = Some(3u64);
    let (_, block_store, pipelined_blocks) = create_block_tree_with_forks(window_size).await;
    let [genesis, a1, a2, a3, b1, b2, _] = pipelined_blocks;
    
    // Simulate send_for_execution ordering block A3
    let a3_qc = QuorumCert::new(/* ... */);
    block_store.send_for_execution(a3_qc.into_wrapped_ledger_info()).await.unwrap();
    
    // ordered_root should now point to A3
    assert_eq!(block_store.ordered_root().id(), a3.id());
    
    // Now simulate commit_callback for B3 (different fork wins)
    let b3_commit_cert = create_commit_cert_for_block(b2.id());
    block_store.commit_callback(
        b2.id(),
        b2.round(),
        b3_commit_cert.clone(),
        b3_commit_cert.ledger_info().clone(),
        window_size,
    );
    
    // At this point, fork A (including A3) has been pruned
    // but ordered_root_id still points to A3
    
    // This call should panic with "Root must exist"
    // because A3 was pruned but ordered_root_id wasn't updated
    let _ = block_store.ordered_root(); // PANICS HERE
}
```

**Note**: The actual test implementation requires proper setup of QCs, ledger infos, and fork structures. The key point is demonstrating that after `commit_callback` prunes one fork, `ordered_root()` can panic if it pointed to the pruned branch.

### Citations

**File:** consensus/src/block_storage/block_tree.rs (L76-81)
```rust
    /// Root of the tree. This is the root of ordering phase
    ordered_root_id: HashValue,
    /// Commit Root id: this is the root of commit phase
    commit_root_id: HashValue,
    /// Window Root id: this is the first item in the [`OrderedBlockWindow`](OrderedBlockWindow)
    window_root_id: HashValue,
```

**File:** consensus/src/block_storage/block_tree.rs (L174-181)
```rust
    fn remove_block(&mut self, block_id: HashValue) {
        // Remove the block from the store
        if let Some(block) = self.id_to_block.remove(&block_id) {
            let round = block.executed_block().round();
            self.round_to_ids.remove(&round);
        };
        self.id_to_quorum_cert.remove(&block_id);
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L198-201)
```rust
    pub(super) fn ordered_root(&self) -> Arc<PipelinedBlock> {
        self.get_block(&self.ordered_root_id)
            .expect("Root must exist")
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L405-434)
```rust
    pub(super) fn find_blocks_to_prune(
        &self,
        next_window_root_id: HashValue,
    ) -> VecDeque<HashValue> {
        // Nothing to do if this is the window root
        if next_window_root_id == self.window_root_id {
            return VecDeque::new();
        }

        let mut blocks_pruned = VecDeque::new();
        let mut blocks_to_be_pruned = vec![self.linkable_window_root()];

        while let Some(block_to_remove) = blocks_to_be_pruned.pop() {
            block_to_remove.executed_block().abort_pipeline();
            // Add the children to the blocks to be pruned (if any), but stop when it reaches the
            // new root
            for child_id in block_to_remove.children() {
                if next_window_root_id == *child_id {
                    continue;
                }
                blocks_to_be_pruned.push(
                    self.get_linkable_block(child_id)
                        .expect("Child must exist in the tree"),
                );
            }
            // Track all the block ids removed
            blocks_pruned.push_back(block_to_remove.id());
        }
        blocks_pruned
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L567-600)
```rust
    pub fn commit_callback(
        &mut self,
        storage: Arc<dyn PersistentLivenessStorage>,
        block_id: HashValue,
        block_round: Round,
        finality_proof: WrappedLedgerInfo,
        commit_decision: LedgerInfoWithSignatures,
        window_size: Option<u64>,
    ) {
        let current_round = self.commit_root().round();
        let committed_round = block_round;
        let commit_proof = finality_proof
            .create_merged_with_executed_state(commit_decision)
            .expect("Inconsistent commit proof and evaluation decision, cannot commit block");

        debug!(
            LogSchema::new(LogEvent::CommitViaBlock).round(current_round),
            committed_round = committed_round,
            block_id = block_id,
        );

        let window_root_id = self.find_window_root(block_id, window_size);
        let ids_to_remove = self.find_blocks_to_prune(window_root_id);

        if let Err(e) = storage.prune_tree(ids_to_remove.clone().into_iter().collect()) {
            // it's fine to fail here, as long as the commit succeeds, the next restart will clean
            // up dangling blocks, and we need to prune the tree to keep the root consistent with
            // executor.
            warn!(error = ?e, "fail to delete block");
        }
        self.process_pruned_blocks(ids_to_remove);
        self.update_window_root(window_root_id);
        self.update_highest_commit_cert(commit_proof);
    }
```

**File:** consensus/src/block_storage/block_store.rs (L311-350)
```rust
    /// Send an ordered block id with the proof for execution, returns () on success or error
    pub async fn send_for_execution(
        &self,
        finality_proof: WrappedLedgerInfo,
    ) -> anyhow::Result<()> {
        let block_id_to_commit = finality_proof.commit_info().id();
        let block_to_commit = self
            .get_block(block_id_to_commit)
            .ok_or_else(|| format_err!("Committed block id not found"))?;

        // First make sure that this commit is new.
        ensure!(
            block_to_commit.round() > self.ordered_root().round(),
            "Committed block round lower than root"
        );

        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();

        assert!(!blocks_to_commit.is_empty());

        let finality_proof_clone = finality_proof.clone();
        self.pending_blocks
            .lock()
            .gc(finality_proof.commit_info().round());

        self.inner.write().update_ordered_root(block_to_commit.id());
        self.inner
            .write()
            .insert_ordered_cert(finality_proof_clone.clone());
        update_counters_for_ordered_blocks(&blocks_to_commit);

        self.execution_client
            .finalize_order(blocks_to_commit, finality_proof.clone())
            .await
            .expect("Failed to persist commit");

        Ok(())
    }
```
