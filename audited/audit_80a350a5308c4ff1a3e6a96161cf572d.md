# Audit Report

## Title
Integer Underflow in Replay Verification Job Generation Due to Non-Monotonic Snapshot Version Ordering

## Summary
The `gen_replay_verify_jobs` tool lacks validation to ensure that state snapshot backup metadata maintains monotonic version numbers relative to epoch ordering. When snapshots are sorted by (epoch, version) rather than version alone, and malformed metadata contains higher epochs with lower versions, the code performs unchecked subtraction that causes integer underflow, leading to incorrect replay verification job ranges.

## Finding Description

The vulnerability exists in the replay verification job generation logic. The function retrieves state snapshots and processes them to create transaction replay ranges: [1](#0-0) 

The snapshots are retrieved via `all_state_snapshots()` which returns a slice sorted by `StateSnapshotBackupMeta`'s derived `Ord` implementation: [2](#0-1) 

Since Rust's derived `Ord` compares fields lexicographically in declaration order, snapshots are sorted **first by epoch, then by version**. This is confirmed in the `MetadataView::new()` constructor: [3](#0-2) 

**The Critical Flaw**: There is no validation that epochs correlate monotonically with versions. In normal blockchain operation, higher epochs should have higher versions since both progress forward in time. However, backup metadata is loaded from external storage without validation: [4](#0-3) 

If malformed metadata contains snapshots where a higher epoch has a lower version (e.g., epoch=10 at version=500, epoch=5 at version=1000), the sorted order becomes non-monotonic by version:
- After sorting: [(epoch=5, v=1000), (epoch=10, v=500)]
- After reversing: [(epoch=10, v=500), (epoch=5, v=1000)]
- After tuple_windows: (end=500, begin=1000)

The code then performs unchecked subtraction: [5](#0-4) 

Since `Version` is `u64`: [6](#0-5) 

The operation `500 - 1000` causes integer underflow:
- **Debug builds**: Panic
- **Release builds**: Wraps to approximately `u64::MAX - 499` â‰ˆ 18446744073709551115

With the wraparound value, the condition `end.version - begin.version >= self.max_versions_per_range` is always true, causing the code to create a "partial replay" job with incorrect ranges (begin=1000, end=1000+max_versions_per_range), which extends **beyond** the actual end snapshot version.

## Impact Explanation

**Severity: HIGH**

This vulnerability affects the **availability and correctness** of backup verification operations:

1. **Debug Build Impact**: Tool crashes with panic, preventing job generation entirely
2. **Release Build Impact**: Generates incorrect replay verification ranges that:
   - Attempt to replay transactions beyond the actual snapshot version
   - Skip transactions that should be verified
   - Cause verification failures or produce incorrect results

3. **Operational Impact**:
   - Disrupts disaster recovery procedures
   - Compromises state verification integrity
   - Could lead to acceptance of incorrect blockchain state during recovery
   - Affects the CI/CD replay-verify workflow used for continuous validation

This meets **High Severity** criteria per Aptos bug bounty: "Significant protocol violations" and operational disruptions affecting critical backup/restore infrastructure. While it does not directly cause consensus violations or fund loss, it undermines the integrity of state verification, which is a critical security property for blockchain recovery.

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability can manifest through two scenarios:

1. **Malicious Injection** (Lower Probability): Attacker with write access to backup storage (S3, GCS) injects metadata files with non-monotonic epoch-version pairs. This requires compromised backup infrastructure credentials.

2. **Software Bug** (Higher Probability): A bug in the backup creation process creates inconsistent metadata. Potential causes:
   - Race conditions between multiple backup coordinators
   - Backup metadata from different chain instances mixed in same storage
   - Logic errors in snapshot creation during complex epoch transitions
   - Metadata corruption during storage operations

The lack of any validation in the metadata loading pipeline means such malformed data would be silently accepted and processed. This is particularly concerning given that: [7](#0-6) 

The tool runs in production CI/CD pipelines where failures could block critical operations.

## Recommendation

**Add validation to ensure epoch-version monotonicity in backup metadata.**

Insert validation in `MetadataView::new()` after sorting:

```rust
// After line 48 in storage/backup/backup-cli/src/metadata/view.rs
state_snapshot_backups.sort_unstable();
state_snapshot_backups.dedup();

// Add validation
for window in state_snapshot_backups.windows(2) {
    if window[0].epoch < window[1].epoch && window[0].version >= window[1].version {
        return Err(anyhow::anyhow!(
            "Invalid backup metadata: epoch {} (version {}) followed by epoch {} (version {}). \
             Higher epochs must have higher versions.",
            window[0].epoch, window[0].version, window[1].epoch, window[1].version
        ));
    }
}
```

**Alternative/Additional Fix**: Add defensive bounds checking in `gen_replay_verify_jobs.rs`:

```rust
// Before line 96
Some((end, mut begin)) => {
    if end.version < begin.version {
        return Err(anyhow::anyhow!(
            "Invalid snapshot ordering: end version {} < begin version {}. \
             Backup metadata may be corrupted.",
            end.version, begin.version
        ));
    }
    // ... rest of logic
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_snapshot_ordering {
    use super::*;
    use aptos_backup_cli::metadata::{Metadata, StateSnapshotBackupMeta};
    use aptos_backup_cli::metadata::view::MetadataView;
    use aptos_backup_cli::storage::FileHandle;
    
    #[test]
    #[should_panic(expected = "attempt to subtract with overflow")]
    fn test_non_monotonic_snapshot_underflow() {
        // Create malformed metadata with non-monotonic epoch-version pairs
        let metadata_vec = vec![
            Metadata::StateSnapshotBackup(StateSnapshotBackupMeta {
                epoch: 5,
                version: 1000,
                manifest: FileHandle::new("snapshot1".to_string()),
            }),
            Metadata::StateSnapshotBackup(StateSnapshotBackupMeta {
                epoch: 10,
                version: 500, // Higher epoch, LOWER version - malformed!
                manifest: FileHandle::new("snapshot2".to_string()),
            }),
        ];
        
        let metadata_view = MetadataView::new(metadata_vec, vec![]);
        let snapshots = metadata_view.all_state_snapshots();
        
        // After sorting by (epoch, version): [(5,1000), (10,500)]
        assert_eq!(snapshots[0].epoch, 5);
        assert_eq!(snapshots[0].version, 1000);
        assert_eq!(snapshots[1].epoch, 10);
        assert_eq!(snapshots[1].version, 500);
        
        // Simulate the logic in gen_replay_verify_jobs
        let reversed: Vec<_> = snapshots.iter().rev().collect();
        // After reverse: [(10,500), (5,1000)]
        
        let end = reversed[0];
        let begin = reversed[1];
        
        // This will panic in debug mode or wrap in release mode
        let _diff = end.version - begin.version; // 500 - 1000 = UNDERFLOW!
    }
}
```

**Notes**

The vulnerability is real and exploitable under specific conditions. While exploitation requires either compromised backup storage access or a bug in the backup process, the complete absence of validation creates a significant risk to operational integrity. The fix is straightforward: validate epoch-version monotonicity when loading backup metadata. This should be prioritized given that replay-verify operations are critical for disaster recovery and state verification in production environments.

### Citations

**File:** storage/db-tool/src/gen_replay_verify_jobs.rs (L80-92)
```rust
        let job_ranges = metadata_view
            .all_state_snapshots()
            .iter()
            .dedup_by(|a, b| a.epoch == b.epoch)
            .filter(|s| s.epoch >= global_min_epoch && s.version <= global_end_version)
            .chain(once(&fake_end))
            .collect_vec()
            .iter()
            .rev()
            .tuple_windows()
            // to simplify things, if start_version appears in the middle of a range, give up the range
            .take_while(|(_end, begin)| begin.version >= self.start_version.unwrap_or(0))
            .peekable()
```

**File:** storage/db-tool/src/gen_replay_verify_jobs.rs (L94-117)
```rust
                match it.next() {
                    Some((end, mut begin)) => {
                        if end.version - begin.version >= self.max_versions_per_range {
                            // cut big range short, this hopefully automatically skips load tests
                            let msg = if end.epoch - begin.epoch > 15 {
                                "!!! Need more snapshots !!!"
                            } else {
                                ""
                            };
                            Some((
                                true,
                                begin.version,
                                begin.version + self.max_versions_per_range - 1,
                                format!(
                                    "Partial replay epoch {} - {}, {} txns starting from version {}, another {} versions omitted, until {}. {}",
                                    begin.epoch,
                                    end.epoch - 1,
                                    self.max_versions_per_range,
                                    begin.version,
                                    end.version - begin.version - self.max_versions_per_range,
                                    end.version,
                                    msg
                                )
                            ))
```

**File:** storage/backup/backup-cli/src/metadata/mod.rs (L184-189)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct StateSnapshotBackupMeta {
    pub epoch: u64,
    pub version: Version,
    pub manifest: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L47-48)
```rust
        state_snapshot_backups.sort_unstable();
        state_snapshot_backups.dedup();
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L193-213)
```rust
    let mut metadata_vec = Vec::new();
    for h in new_remote_hashes.into_iter().chain(up_to_date_local_hashes) {
        let cached_file = cache_dir.join(h);
        metadata_vec.extend(
            OpenOptions::new()
                .read(true)
                .open(&cached_file)
                .await
                .err_notes(&cached_file)?
                .load_metadata_lines()
                .await
                .err_notes(&cached_file)?
                .into_iter(),
        )
    }
    info!(
        total_time = timer.elapsed().as_secs(),
        "Metadata cache loaded.",
    );

    Ok(MetadataView::new(metadata_vec, remote_file_handles))
```

**File:** types/src/transaction/mod.rs (L98-98)
```rust
pub type Version = u64; // Height - also used for MVCC in StateDB
```

**File:** .github/workflows/workflow-run-replay-verify.yaml (L152-160)
```yaml
          ./aptos-debugger aptos-db gen-replay-verify-jobs  \
            --metadata-cache-dir ./metadata_cache \
            --command-adapter-config ${{ inputs.BACKUP_CONFIG_TEMPLATE_PATH }} \
            --start-version ${{ inputs.HISTORY_START }} \
            --ranges-to-skip "${{ inputs.RANGES_TO_SKIP }}" \
            --max-versions-per-range ${{ inputs.MAX_VERSIONS_PER_RANGE }} \
            \
            --max-ranges-per-job 16 \
            --output-json-file jobs.json \
```
