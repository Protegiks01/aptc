# Audit Report

## Title
Indexer Race Condition: Out-of-Order Transaction Processing Causes Incorrect Staking State Due to Missing Version Filtering in Database Queries

## Summary
The Aptos indexer's parallel batch processing architecture allows later transaction batches to complete before earlier ones, causing database queries to read data from future versions when processing historical transactions. This specifically affects inactive delegator share processing in the stake indexer, where the `get_by_inactive_share_handle()` query lacks transaction version filtering, violating deterministic ordering guarantees and producing incorrect staking state.

## Finding Description
The indexer runtime spawns multiple parallel processor tasks (default: 5) that fetch and process transaction batches concurrently: [1](#0-0) 

Each task processes its batch independently and writes to the database during processing, not after collection. This creates a race condition where Batch N+1 (e.g., transactions 200-299) can finish processing and write to the database before Batch N (e.g., transactions 100-199).

When processing inactive delegator shares, if the transaction's write set doesn't contain the necessary pool mapping, the code queries the database to look up the pool address: [2](#0-1) 

The critical vulnerability is in the database query itself, which has NO version filtering: [3](#0-2) 

This query returns the first matching row regardless of transaction version. When Batch N (version 100) queries for an inactive share handle that was written by Batch N+1 (version 200), it receives data from the future, violating temporal ordering.

The `txn_version` parameter is passed through the call chain but never used to filter database reads: [4](#0-3) 

**Attack Scenario:**
1. Indexer processes transactions 100-199 (Batch A) and 200-299 (Batch B) in parallel
2. Transaction 250 creates a new delegation pool with inactive shares
3. Batch B completes first, writing pool data to `current_delegator_balances` table
4. Batch A is still processing transaction 150 which references an inactive share
5. Transaction 150's write set lacks the pool mapping, triggering a database lookup
6. The query returns the pool address from transaction 250 (from the future)
7. Transaction 150's delegator balance is indexed with incorrect pool association
8. The indexer state is now inconsistent with deterministic sequential processing

## Impact Explanation
This is a **Medium Severity** issue under the Aptos bug bounty program category "State inconsistencies requiring intervention."

**Specific Impacts:**
- **Incorrect Delegator Balances**: Delegators' inactive share balances may be associated with wrong pools
- **Broken Indexer Queries**: Applications querying the indexer for staking data receive incorrect information
- **State Divergence**: Different indexer instances processing the same blockchain may produce different results depending on timing
- **Requires Manual Intervention**: Operators must detect and reindex affected ranges to fix corruption

While this doesn't affect consensus or the underlying blockchain (the source of truth remains correct), it breaks the indexer's fundamental guarantee of deterministic state reconstruction and affects all downstream applications relying on accurate staking data.

## Likelihood Explanation
**Likelihood: HIGH**

This vulnerability triggers automatically under normal indexer operation:
- Parallel processing is enabled by default with 5 concurrent tasks
- Database upsert protections prevent old data from overwriting new data, but don't prevent reading future data
- The race window exists whenever inactive shares are processed across batch boundaries
- No attacker interaction required - this is an inherent architectural flaw

The issue occurs probabilistically based on:
- Processing speed variations between batches
- Database commit timing
- Network and I/O latency differences
- Transaction content (more likely when inactive shares span multiple batches)

## Recommendation

Add transaction version filtering to all database queries used during transaction processing. Specifically, modify the `get_by_inactive_share_handle()` query to only return records with `last_transaction_version <= current_txn_version`:

```rust
impl CurrentDelegatorBalanceQuery {
    pub fn get_by_inactive_share_handle(
        conn: &mut PgPoolConnection,
        table_handle: &str,
        max_version: i64,  // Add version parameter
    ) -> diesel::QueryResult<Self> {
        current_delegator_balances::table
            .filter(current_delegator_balances::parent_table_handle.eq(table_handle))
            .filter(current_delegator_balances::last_transaction_version.le(max_version))  // Add version filter
            .order_by(current_delegator_balances::last_transaction_version.desc())  // Get most recent
            .first::<Self>(conn)
    }
}
```

Update all call sites to pass the current transaction version: [2](#0-1) 

**Alternative Solution:** Serialize batch processing to guarantee sequential ordering, though this would sacrifice throughput.

## Proof of Concept

**Setup:**
1. Configure indexer with default parallel processing (5 tasks)
2. Ensure database is empty for clean testing
3. Create a blockchain state with:
   - Transaction 100: Creates delegation pool A
   - Transaction 150: User adds inactive shares to pool A (references inactive_share_handle_X)
   - Transaction 250: Creates delegation pool B with same inactive share structure, writing to inactive_share_handle_X

**Reproduction Steps:**

```rust
// Run the indexer with parallel processing enabled
// Monitor database queries during processing

// In delegator_balances.rs, add logging:
pub fn get_staking_pool_from_inactive_share_handle(
    conn: &mut PgPoolConnection,
    table_handle: &str,
) -> anyhow::Result<String> {
    let result = CurrentDelegatorBalanceQuery::get_by_inactive_share_handle(conn, table_handle)?;
    
    // LOG THIS
    eprintln!("Query returned version: {}, for table_handle: {}", 
              result.last_transaction_version, 
              table_handle);
    
    Ok(result.pool_address)
}

// Expected: version 150 queries should never return records with version > 150
// Actual: When batch containing txn 250 finishes first, 
//         version 150 query returns data from version 250
```

**Verification:**
Query the `current_delegator_balances` table after indexing completes. Check for records where the `last_transaction_version` doesn't match the chronological order they should have been processed in. Compare results against a sequential (non-parallel) indexer run on the same data.

## Notes

This vulnerability is specific to the indexer component and does not affect blockchain consensus or validator operations. The blockchain state itself remains correct and deterministic. However, it breaks a critical guarantee of indexer infrastructure: that reprocessing the same blockchain produces identical results regardless of timing.

The issue is exacerbated by the fact that database upsert operations include version checks (e.g., `WHERE last_transaction_version <= EXCLUDED.last_transaction_version`) which prevent data corruption from writes, creating a false sense of security that masks the read-side vulnerability.

### Citations

**File:** crates/indexer/src/runtime.rs (L209-215)
```rust
    loop {
        let mut tasks = vec![];
        for _ in 0..processor_tasks {
            let other_tailer = tailer.clone();
            let task = tokio::spawn(async move { other_tailer.process_next_batch().await });
            tasks.push(task);
        }
```

**File:** crates/indexer/src/models/stake_models/delegator_balances.rs (L298-315)
```rust
    pub fn get_staking_pool_from_inactive_share_handle(
        conn: &mut PgPoolConnection,
        table_handle: &str,
    ) -> anyhow::Result<String> {
        let mut retried = 0;
        while retried < QUERY_RETRIES {
            retried += 1;
            match CurrentDelegatorBalanceQuery::get_by_inactive_share_handle(conn, table_handle) {
                Ok(current_delegator_balance) => return Ok(current_delegator_balance.pool_address),
                Err(_) => {
                    std::thread::sleep(std::time::Duration::from_millis(QUERY_RETRY_DELAY_MS));
                },
            }
        }
        Err(anyhow::anyhow!(
            "Failed to get staking pool address from inactive share handle"
        ))
    }
```

**File:** crates/indexer/src/models/stake_models/delegator_balances.rs (L413-421)
```rust
impl CurrentDelegatorBalanceQuery {
    pub fn get_by_inactive_share_handle(
        conn: &mut PgPoolConnection,
        table_handle: &str,
    ) -> diesel::QueryResult<Self> {
        current_delegator_balances::table
            .filter(current_delegator_balances::parent_table_handle.eq(table_handle))
            .first::<Self>(conn)
    }
```

**File:** crates/indexer/src/models/stake_models/stake_utils.rs (L146-170)
```rust
    pub fn from_write_resource(
        write_resource: &WriteResource,
        txn_version: i64,
    ) -> Result<Option<Self>> {
        let type_str = format!(
            "{}::{}::{}",
            write_resource.data.typ.address,
            write_resource.data.typ.module,
            write_resource.data.typ.name
        );
        if !Self::is_resource_supported(type_str.as_str()) {
            return Ok(None);
        }
        let resource = MoveResource::from_write_resource(
            write_resource,
            0, // Placeholder, this isn't used anyway
            txn_version,
            0, // Placeholder, this isn't used anyway
        );
        Ok(Some(Self::from_resource(
            &type_str,
            resource.data.as_ref().unwrap(),
            txn_version,
        )?))
    }
```
