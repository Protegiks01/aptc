# Audit Report

## Title
State Merkle Shard Pruner Progress Regression Due to Missing Version Validation

## Summary
The `prune()` function in `StateMerkleShardPruner` lacks validation to ensure `target_version >= current_progress` before entering the pruning loop. When `target_version < current_progress`, the function regresses the shard's pruner progress metadata, violating the invariant that pruner progress should be monotonically non-decreasing. This creates persistent state inconsistency in the database.

## Finding Description

The vulnerability exists in the initialization path of `StateMerkleShardPruner`. [1](#0-0) 

When `StateMerkleShardPruner::new()` is called, it reads the shard's existing progress via `get_or_initialize_subpruner_progress` and then immediately calls `prune(progress, metadata_progress, usize::MAX)` to catch up the shard. However, there is no validation that `metadata_progress >= progress`. [2](#0-1) 

The `prune()` function does not validate the relationship between `current_progress` and `target_version` before entering the loop. When `target_version < current_progress`:

1. The call to `get_stale_node_indices()` seeks to `current_progress` but filters for indices with `stale_since_version <= target_version`
2. Since all indices from `current_progress` onwards have `stale_since_version >= current_progress > target_version`, no indices are collected
3. The function sets `done = true` and writes `target_version` as the new progress metadata
4. **This regresses the shard progress from `current_progress` to `target_version`** [3](#0-2) 

The scenario occurs when database state becomes inconsistent, such as:
- Partial database restoration (metadata DB from older backup, shard DB from newer backup)
- Database corruption where shard progress > metadata progress
- Race conditions during crash recovery

In contrast, the main pruner properly validates this condition. [4](#0-3) 

## Impact Explanation

**Medium Severity** - State inconsistencies requiring intervention.

The vulnerability causes:
1. **Pruner metadata corruption**: Progress is regressed, creating false information about what data has been pruned
2. **Operational confusion**: Metrics and monitoring report incorrect pruner state
3. **Potential state sync issues**: Nodes may request data that was already pruned, causing sync failures
4. **Persistent inconsistency**: The corrupted metadata persists across restarts until manually corrected

This does NOT cause:
- Consensus violations (consensus does not depend on pruner progress)
- Fund loss or theft
- Node crashes or liveness failures
- Direct security exploitation

The impact is limited to operational state consistency, fitting the "State inconsistencies requiring intervention" category for Medium severity.

## Likelihood Explanation

**Low to Medium Likelihood**

The vulnerability requires database state inconsistency where `shard_progress > metadata_progress`. This can occur through:

1. **Partial database restoration** - Operator restores metadata DB from an older backup while shard DBs are from a newer backup
2. **Database corruption** - File system or storage corruption creates inconsistent progress values
3. **Concurrent pruner bugs** - Other bugs that cause metadata and shard progress to drift

While these scenarios are not common in normal operation, they are realistic operational edge cases that can occur in production environments, especially during:
- Disaster recovery procedures
- Database maintenance operations
- Storage failures
- Software upgrade issues

The vulnerability is **NOT directly exploitable** by an unprivileged attacker, as it requires database state manipulation that only occurs through operational issues or system failures.

## Recommendation

Add validation at the beginning of the `prune()` function to ensure `target_version >= current_progress`:

```rust
pub(in crate::pruner) fn prune(
    &self,
    current_progress: Version,
    target_version: Version,
    max_nodes_to_prune: usize,
) -> Result<()> {
    // Validate that target_version is not less than current_progress
    if target_version < current_progress {
        info!(
            shard_id = self.shard_id,
            current_progress = current_progress,
            target_version = target_version,
            "Target version is less than current progress, skipping prune"
        );
        return Ok(());
    }
    
    loop {
        // ... existing loop logic
    }
}
```

Additionally, consider adding similar validation in `StateMerkleShardPruner::new()` to detect and log the inconsistency:

```rust
pub(in crate::pruner) fn new(
    shard_id: usize,
    db_shard: Arc<DB>,
    metadata_progress: Version,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        &db_shard,
        &S::progress_metadata_key(Some(shard_id)),
        metadata_progress,
    )?;
    
    if progress > metadata_progress {
        warn!(
            shard_id = shard_id,
            shard_progress = progress,
            metadata_progress = metadata_progress,
            "Shard progress exceeds metadata progress, possible database inconsistency detected"
        );
    }
    
    let myself = Self {
        shard_id,
        db_shard,
        _phantom: PhantomData,
    };

    // ... rest of initialization
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_schemadb::DB;

    #[test]
    fn test_prune_with_regressed_target_version() {
        // Create a temporary database
        let tmpdir = TempPath::new();
        let db = Arc::new(DB::open(
            tmpdir.path(),
            "test_db",
            &[/* schema column families */]
        ).unwrap());

        // Set shard progress to 1000
        db.put::<DbMetadataSchema>(
            &DbMetadataKey::StateMerklePrunerProgress,
            &DbMetadataValue::Version(1000)
        ).unwrap();

        // Create shard pruner with metadata_progress = 900 (< shard progress)
        let shard_pruner = StateMerkleShardPruner::<StaleNodeIndexSchema>::new(
            0,
            db.clone(),
            900  // metadata_progress < actual shard progress
        ).unwrap();

        // Read the progress after initialization
        let final_progress = db.get::<DbMetadataSchema>(
            &DbMetadataKey::StateMerklePrunerProgress
        ).unwrap().unwrap().expect_version();

        // BUG: Progress should remain at 1000 or at least not decrease
        // Instead it regresses to 900
        assert_eq!(final_progress, 900);  // This demonstrates the bug
        
        // Expected behavior: progress should remain at 1000
        // assert_eq!(final_progress, 1000);
    }
}
```

**Notes:**
- This vulnerability requires database state inconsistency to manifest
- It is not directly exploitable by unprivileged attackers
- Impact is limited to operational state consistency, not consensus or security
- The lack of validation is a defensive programming gap that should be addressed

### Citations

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L31-56)
```rust
    pub(in crate::pruner) fn new(
        shard_id: usize,
        db_shard: Arc<DB>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            &db_shard,
            &S::progress_metadata_key(Some(shard_id)),
            metadata_progress,
        )?;
        let myself = Self {
            shard_id,
            db_shard,
            _phantom: PhantomData,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up {} shard {shard_id}.",
            S::name(),
        );
        myself.prune(progress, metadata_progress, usize::MAX)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L58-100)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
        max_nodes_to_prune: usize,
    ) -> Result<()> {
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }

        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L59-95)
```rust
    fn prune(&self, batch_size: usize) -> Result<Version> {
        // TODO(grao): Consider separate pruner metrics, and have a label for pruner name.
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_merkle_pruner__prune"]);
        let mut progress = self.progress();
        let target_version = self.target_version();

        if progress >= target_version {
            return Ok(progress);
        }

        info!(
            name = S::name(),
            current_progress = progress,
            target_version = target_version,
            "Start pruning..."
        );

        while progress < target_version {
            if let Some(target_version_for_this_round) = self
                .metadata_pruner
                .maybe_prune_single_version(progress, target_version)?
            {
                self.prune_shards(progress, target_version_for_this_round, batch_size)?;
                progress = target_version_for_this_round;
                info!(name = S::name(), progress = progress);
                self.record_progress(target_version_for_this_round);
            } else {
                self.prune_shards(progress, target_version, batch_size)?;
                self.record_progress(target_version);
                break;
            }
        }

        info!(name = S::name(), progress = target_version, "Done pruning.");

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L191-217)
```rust
    pub(in crate::pruner::state_merkle_pruner) fn get_stale_node_indices(
        state_merkle_db_shard: &DB,
        start_version: Version,
        target_version: Version,
        limit: usize,
    ) -> Result<(Vec<StaleNodeIndex>, Option<Version>)> {
        let mut indices = Vec::new();
        let mut iter = state_merkle_db_shard.iter::<S>()?;
        iter.seek(&StaleNodeIndex {
            stale_since_version: start_version,
            node_key: NodeKey::new_empty_path(0),
        })?;

        let mut next_version = None;
        while indices.len() < limit {
            if let Some((index, _)) = iter.next().transpose()? {
                next_version = Some(index.stale_since_version);
                if index.stale_since_version <= target_version {
                    indices.push(index);
                    continue;
                }
            }
            break;
        }

        Ok((indices, next_version))
    }
```
