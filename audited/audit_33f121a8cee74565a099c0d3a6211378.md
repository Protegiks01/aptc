# Audit Report

## Title
Indexer Backfiller Silent Data Loss via Malicious Fullnode Status Response Injection

## Summary

The indexer backfiller's stream processing loop silently skips all `Response::Status` messages without tracking transaction receipt, allowing a malicious fullnode to send only status responses (bypassing actual transaction data) while the backfiller incorrectly marks the range as successfully backfilled, creating permanent gaps in the indexed transaction history. [1](#0-0) 

## Finding Description

The backfiller implements a gRPC stream consumer for the `GetTransactionsFromNode` RPC endpoint. According to the protocol specification, the stream should contain: [2](#0-1) 

The legitimate fullnode implementation sends `INIT` status, transaction data batches, and `BATCH_END` status markers: [3](#0-2) [4](#0-3) 

However, the backfiller's stream processing logic silently skips all status responses: [5](#0-4) 

**Critical flaw**: After the stream ends, the backfiller unconditionally increments the version counter and updates the progress file: [6](#0-5) 

The `FileStoreOperatorV2` tracks the expected next transaction version and validates sequential receipt: [7](#0-6) 

**Attack Scenario:**
1. Backfiller requests transactions [1000, 2000) with `num_transactions_per_folder = 1000`
2. Malicious fullnode responds:
   - `Response::Status(INIT)` → skipped at line 190-191
   - `Response::Status(BATCH_END)` → skipped at line 190-191  
   - Closes stream
3. The while loop exits when `stream.next().await` returns `None`
4. `FileStoreOperatorV2.version` remains at 1000 (never incremented - no transactions processed)
5. Line 207: `version += 1000` → version becomes 2000
6. Lines 212-220: Progress file updated to version 2000
7. Transactions [1000, 2000) are **permanently skipped** - next iteration starts at 2000

**Contrast with Proper Implementation:**

The cache worker correctly validates transaction receipt: [8](#0-7) [9](#0-8) 

The cache worker tracks `current_version` throughout data receipt and validates it matches `start_version + num_of_transactions` when `BATCH_END` arrives. If validation fails, it breaks with an error. The backfiller performs no such validation.

## Impact Explanation

**Medium Severity** per Aptos Bug Bounty criteria: "State inconsistencies requiring intervention"

This vulnerability causes:

1. **Data Integrity Loss**: Permanent gaps in the backfilled transaction archive. Once the progress file is updated, those versions are never re-attempted.

2. **Silent Failure**: The backfiller logs success and continues to the next range, with no error indication.

3. **Downstream Corruption**: Any indexer, analytics system, or blockchain explorer relying on the backfilled filestore will have incomplete transaction history, potentially missing:
   - User transactions
   - Contract deployments
   - State changes
   - Token transfers

4. **Operational Impact**: Requires manual intervention to detect missing ranges and re-run backfill with a trusted fullnode.

This does not directly impact consensus, funds, or liveness of the blockchain itself, but significantly compromises the integrity of the indexer ecosystem that many applications depend on.

## Likelihood Explanation

**High Likelihood** given the attack requirements:

1. **Minimal Attacker Resources**: Only requires operating a malicious fullnode that responds to `GetTransactionsFromNode` requests
2. **No Privilege Required**: Attacker does not need validator access, governance participation, or any on-chain permissions
3. **Simple Exploit**: Just send status messages without data - requires ~10 lines of code in a rogue gRPC server implementation
4. **Detection Difficulty**: Silent failure with successful logs makes detection challenging without manual data integrity audits
5. **Realistic Scenario**: Organizations running backfills might use untrusted or compromised fullnodes

## Recommendation

Add transaction count validation after stream processing completes. The fix should verify that `FileStoreOperatorV2.version` has advanced by exactly `num_transactions_per_folder` before updating the progress file:

```rust
// After line 199, before line 201:
let expected_end_version = task_version + num_transactions_per_folder;
let actual_end_version = file_store_operator.version();

if actual_end_version != expected_end_version {
    panic!(
        "Transaction count mismatch for range [{}, {}): expected version {}, got version {}",
        task_version,
        expected_end_version,
        expected_end_version,
        actual_end_version
    );
}
```

Alternative: Track and validate `BATCH_END` status messages instead of silently skipping them, similar to the cache worker implementation. This would provide both completeness checking and proper protocol adherence.

## Proof of Concept

```rust
#[tokio::test]
async fn test_malicious_fullnode_status_only_attack() {
    use aptos_protos::internal::fullnode::v1::{
        stream_status::StatusType,
        transactions_from_node_response::Response,
        StreamStatus, TransactionsFromNodeResponse,
    };
    use futures::stream;
    
    // Simulate malicious fullnode sending only status responses
    let malicious_responses = vec![
        // INIT status
        TransactionsFromNodeResponse {
            response: Some(Response::Status(StreamStatus {
                r#type: StatusType::Init as i32,
                start_version: 1000,
                end_version: None,
            })),
            chain_id: 1,
        },
        // BATCH_END status without any data
        TransactionsFromNodeResponse {
            response: Some(Response::Status(StreamStatus {
                r#type: StatusType::BatchEnd as i32,
                start_version: 1000,
                end_version: Some(1999),
            })),
            chain_id: 1,
        },
    ];
    
    let mut stream = stream::iter(malicious_responses.into_iter().map(Ok));
    let mut file_store_operator = FileStoreOperatorV2::new(
        50 * (1 << 20), // MAX_SIZE_PER_FILE
        1000,           // num_transactions_per_folder
        1000,           // starting version
        BatchMetadata::default(),
    );
    
    let (tx, _rx) = tokio::sync::mpsc::channel(10);
    
    // Process stream exactly as backfiller does
    while let Some(response_item) = stream.next().await {
        match response_item {
            Ok(r) => {
                match r.response.unwrap() {
                    Response::Data(data) => {
                        // Would process transactions here
                        for transaction in data.transactions {
                            file_store_operator
                                .buffer_and_maybe_dump_transactions_to_file(
                                    transaction,
                                    tx.clone(),
                                )
                                .await
                                .unwrap();
                        }
                    },
                    Response::Status(_) => {
                        continue; // Line 190-191: silently skip
                    },
                }
            },
            Err(_) => break,
        }
    }
    
    // Verify the vulnerability: version never incremented
    assert_eq!(
        file_store_operator.version(),
        1000,
        "FileStoreOperator version should still be 1000 (no transactions received)"
    );
    
    // But backfiller would update progress to 2000 and skip [1000, 2000) forever
    let mut version = 1000u64;
    version += 1000; // Line 207
    assert_eq!(version, 2000, "Progress file would be updated to 2000");
    
    println!("VULNERABILITY CONFIRMED:");
    println!("- Malicious fullnode sent only Status responses");
    println!("- No transaction data was processed");
    println!("- FileStoreOperator.version = 1000 (unchanged)");
    println!("- Progress file would be updated to 2000");
    println!("- Transactions [1000, 2000) are permanently lost");
}
```

## Notes

This vulnerability exists because the backfiller treats status responses as optional protocol overhead rather than as critical synchronization points. The cache worker demonstrates the correct pattern: status messages must be parsed and validated to ensure data completeness. The missing validation creates an exploitable gap where a malicious fullnode can cause silent data loss without triggering any error conditions.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-v2-file-store-backfiller/src/processor.rs (L173-199)
```rust
                        while let Some(response_item) = stream.next().await {
                            match response_item {
                                Ok(r) => {
                                    assert!(r.chain_id == chain_id);
                                    match r.response.unwrap() {
                                        Response::Data(data) => {
                                            let transactions = data.transactions;
                                            for transaction in transactions {
                                                file_store_operator
                                                    .buffer_and_maybe_dump_transactions_to_file(
                                                        transaction,
                                                        tx.clone(),
                                                    )
                                                    .await
                                                    .unwrap();
                                            }
                                        },
                                        Response::Status(_) => {
                                            continue;
                                        },
                                    }
                                },
                                Err(e) => {
                                    panic!("Error when getting transactions from fullnode: {e}.")
                                },
                            }
                        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-v2-file-store-backfiller/src/processor.rs (L207-220)
```rust
                    version += self.num_transactions_per_folder;
                }
            });

            // Update the progress file.
            let progress_file = ProgressFile {
                version,
                backfill_id: self.backfill_id,
            };
            let bytes =
                serde_json::to_vec(&progress_file).context("Failed to serialize progress file.")?;
            std::fs::write(&self.progress_file_path, &bytes)
                .context("Failed to write progress file.")?;
            info!("Progress file updated to version {}.", version,);
```

**File:** protos/proto/aptos/internal/fullnode/v1/fullnode_data.proto (L11-16)
```text
// Transaction data is transferred via 1 stream with batches until terminated.
// One stream consists:
//  StreamStatus: INIT with version x
//  loop k:
//    TransactionOutput data(size n)
//    StreamStatus: BATCH_END with version x + (k + 1) * n - 1
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L119-133)
```rust
            let init_status = get_status(StatusType::Init, starting_version, None, ledger_chain_id);
            match tx.send(Result::<_, Status>::Ok(init_status)).await {
                Ok(_) => {
                    // TODO: Add request details later
                    info!(
                        start_version = starting_version,
                        chain_id = ledger_chain_id,
                        service_type = SERVICE_TYPE,
                        "[Indexer Fullnode] Init connection"
                    );
                },
                Err(_) => {
                    panic!("[Indexer Fullnode] Unable to initialize stream");
                },
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L163-168)
```rust
                let batch_end_status = get_status(
                    StatusType::BatchEnd,
                    coordinator.current_version,
                    Some(max_version),
                    ledger_chain_id,
                );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator_v2/file_store_operator.rs (L50-58)
```rust
        ensure!(
            self.version == transaction.version,
            "Gap is found when buffering transaction, expected: {}, actual: {}",
            self.version,
            transaction.version,
        );
        self.buffer.push(transaction);
        self.buffer_size_in_bytes += size_bytes;
        self.version += 1;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L395-404)
```rust
                GrpcDataStatus::ChunkDataOk {
                    num_of_transactions,
                    task,
                } => {
                    current_version += num_of_transactions;
                    transaction_count += num_of_transactions;
                    tps_calculator.tick_now(num_of_transactions);

                    tasks_to_run.push(task);
                },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L413-443)
```rust
                GrpcDataStatus::BatchEnd {
                    start_version,
                    num_of_transactions,
                } => {
                    // Handle the data multithreading.
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
                    if current_version != start_version + num_of_transactions {
                        error!(
                            current_version = current_version,
                            actual_current_version = start_version + num_of_transactions,
                            "[Indexer Cache] End signal received with wrong version."
                        );
                        ERROR_COUNT
                            .with_label_values(&["data_end_wrong_version"])
                            .inc();
                        break;
                    }
```
