# Audit Report

## Title
Indexer Cache Worker Lacks Graceful Shutdown Leading to State Inconsistencies Requiring Manual Intervention

## Summary
The indexer-grpc-cache-worker does not implement graceful shutdown handling, causing in-progress transaction processing to be lost during abrupt termination. This can lead to cache state inconsistencies that require manual intervention or cache rebuild, particularly in scenarios involving repeated crashes or file store advancement during downtime.

## Finding Description

The cache worker's state persistence occurs only at batch boundaries, not before shutdown. The system has three critical gaps:

**1. No Signal Handling**

The server framework spawns tasks without signal handlers: [1](#0-0) 

When either task exits unexpectedly, the process immediately calls `process::exit(1)` with no cleanup opportunity.

**2. Deferred State Persistence**

Transaction processing spawns async tasks that accumulate in a vector: [2](#0-1) 

These tasks are only awaited when a `BatchEnd` signal arrives: [3](#0-2) 

The cache's `latest_version` pointer is persisted to Redis only after all tasks complete successfully at the batch boundary. If shutdown occurs mid-batch, the in-memory `current_version` is lost and `latest_version` remains at the previous batch.

**3. Restart Without Reconciliation**

On restart, the worker blindly starts from the file store version without checking cache state: [4](#0-3) 

**Failure Scenarios:**

**Scenario A: Mid-Batch Crash**
1. Cache at version 10,000 (last completed batch)
2. Processing batch 10,001-10,100, tasks spawned
3. SIGKILL/OOM before BatchEnd signal
4. Tasks partially execute (some transactions written, some not)
5. `latest_version` still shows 10,000
6. Restart from file store version 10,000
7. Re-process transactions 10,001-10,100, overwriting partial data

**Scenario B: File Store Advances During Downtime**
1. Cache at version 10,000
2. Cache worker crashes
3. File store worker continues to version 11,000
4. Cache worker restarts from 11,000
5. Attempts to update cache from 10,000 to 11,000 (gap of 1,000)
6. Atomic Lua script detects gap and returns error: [5](#0-4) 

7. Worker errors and crashes in a loop: [6](#0-5) 

**Scenario C: Repeated Crashes**
If crashes occur repeatedly before batch completion, the cache makes no forward progress, requiring manual intervention to clear and rebuild.

## Impact Explanation

This is categorized as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

While this affects the indexer cache (off-chain infrastructure), not blockchain consensus or state, it meets Medium criteria because:
- Cache can enter irrecoverable states requiring manual intervention
- Service degradation impacts users querying blockchain data
- Crash loops prevent normal operations
- Manual cache rebuild has operational costs

However, this does NOT affect:
- Blockchain consensus or validator operations
- On-chain state or transaction validity
- Fund security or asset integrity
- Core protocol safety or liveness

## Likelihood Explanation

**High likelihood** in production environments due to:
- Common operational events trigger this (OOM kills, pod evictions, node crashes, deployments)
- No mitigation exists in current code
- Kubernetes/container environments routinely send SIGTERM during rolling updates
- File store and cache worker can drift during restarts
- Once in a bad state, automatic recovery is impossible

## Recommendation

Implement graceful shutdown with signal handling:

**1. Add signal handler in main.rs:**
```rust
use tokio::signal;
use tokio_util::sync::CancellationToken;

#[tokio::main]
async fn main() -> Result<()> {
    let shutdown_token = CancellationToken::new();
    let shutdown_token_clone = shutdown_token.clone();
    
    tokio::spawn(async move {
        signal::ctrl_c().await.expect("Failed to listen for ctrl-c");
        shutdown_token_clone.cancel();
    });
    
    let args = ServerArgs::parse();
    args.run_with_shutdown::<IndexerGrpcCacheWorkerConfig>(shutdown_token).await
}
```

**2. Propagate shutdown signal to worker:**
```rust
pub async fn run(&mut self, shutdown: CancellationToken) -> Result<()> {
    loop {
        tokio::select! {
            _ = shutdown.cancelled() => {
                info!("Shutdown signal received, flushing pending work...");
                // Await all pending tasks
                join_all(tasks_to_run).await;
                // Persist final state
                cache_operator.update_cache_latest_version(...).await?;
                info!("Graceful shutdown complete");
                return Ok(());
            }
            result = process_streaming_response(...) => {
                result?;
            }
        }
    }
}
```

**3. Add restart reconciliation:**
Check cache state against file store on startup and handle gaps/overlaps appropriately, either by resetting cache or warning operators.

## Proof of Concept

```rust
// Test demonstrating state loss on abrupt termination
#[tokio::test]
async fn test_abrupt_shutdown_loses_state() {
    // Setup: Cache at version 1000
    let mut cache_op = setup_cache_with_version(1000).await;
    
    // Start processing batch 1001-1100
    let worker = Worker::new(...).await.unwrap();
    let worker_handle = tokio::spawn(async move {
        worker.run().await
    });
    
    // Wait for some transactions to be written
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Simulate abrupt shutdown (kill task)
    worker_handle.abort();
    
    // Verify: latest_version still shows 1000
    assert_eq!(cache_op.get_latest_version().await.unwrap(), Some(1000));
    
    // But some transaction data exists beyond 1000
    let tx_1050 = cache_op.get_transactions(1050, 1).await;
    assert!(tx_1050.is_ok()); // Data exists but is "invisible"
    
    // Restart worker from file store version 1000
    // Re-processes 1001-1100, wasting work
}
```

## Notes

This vulnerability is specific to the indexer infrastructure (`ecosystem/indexer-grpc/`) and does not affect core blockchain consensus, execution, or state management. It represents an operational reliability issue rather than a protocol security vulnerability. The impact is limited to indexer service availability and data consistency, not blockchain safety or fund security.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L46-77)
```rust
pub async fn run_server_with_config<C>(config: GenericConfig<C>) -> Result<()>
where
    C: RunnableConfig,
{
    let health_port = config.health_check_port;
    // Start liveness and readiness probes.
    let config_clone = config.clone();
    let task_handler = tokio::spawn(async move {
        register_probes_and_metrics_handler(config_clone, health_port).await;
        anyhow::Ok(())
    });
    let main_task_handler =
        tokio::spawn(async move { config.run().await.expect("task should exit with Ok.") });
    tokio::select! {
        res = task_handler => {
            if let Err(e) = res {
                error!("Probes and metrics handler panicked or was shutdown: {:?}", e);
                process::exit(1);
            } else {
                panic!("Probes and metrics handler exited unexpectedly");
            }
        },
        res = main_task_handler => {
            if let Err(e) = res {
                error!("Main task panicked or was shutdown: {:?}", e);
                process::exit(1);
            } else {
                panic!("Main task exited unexpectedly");
            }
        },
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L119-145)
```rust
            // 1. Fetch metadata.
            let file_store_operator: Box<dyn FileStoreOperator> = self.file_store.create();
            // TODO: move chain id check somewhere around here
            // This ensures that metadata is created before we start the cache worker
            let mut starting_version = file_store_operator.get_latest_version().await;
            while starting_version.is_none() {
                starting_version = file_store_operator.get_latest_version().await;
                tracing::warn!(
                    "[Indexer Cache] File store metadata not found. Waiting for {} ms.",
                    FILE_STORE_METADATA_WAIT_MS
                );
                tokio::time::sleep(std::time::Duration::from_millis(
                    FILE_STORE_METADATA_WAIT_MS,
                ))
                .await;
            }

            // There's a guarantee at this point that starting_version is not null
            let starting_version = starting_version.unwrap();

            let file_store_metadata = file_store_operator.get_file_store_metadata().await.unwrap();

            tracing::info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Starting cache worker with version {}",
                starting_version
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L395-403)
```rust
                GrpcDataStatus::ChunkDataOk {
                    num_of_transactions,
                    task,
                } => {
                    current_version += num_of_transactions;
                    transaction_count += num_of_transactions;
                    tps_calculator.tick_now(num_of_transactions);

                    tasks_to_run.push(task);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L413-447)
```rust
                GrpcDataStatus::BatchEnd {
                    start_version,
                    num_of_transactions,
                } => {
                    // Handle the data multithreading.
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
                    if current_version != start_version + num_of_transactions {
                        error!(
                            current_version = current_version,
                            actual_current_version = start_version + num_of_transactions,
                            "[Indexer Cache] End signal received with wrong version."
                        );
                        ERROR_COUNT
                            .with_label_values(&["data_end_wrong_version"])
                            .inc();
                        break;
                    }
                    cache_operator
                        .update_cache_latest_version(transaction_count, current_version)
                        .await
                        .context("Failed to update the latest version in the cache")?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L39-57)
```rust
const CACHE_SCRIPT_UPDATE_LATEST_VERSION: &str = r#"
    local latest_version = redis.call("GET", KEYS[1])
    local num_of_versions = tonumber(ARGV[1])
    local current_version = tonumber(ARGV[2])
    if latest_version then
        if tonumber(latest_version) + num_of_versions < current_version then
            return 2
        elseif tonumber(latest_version) + num_of_versions == current_version then
            redis.call("SET", KEYS[1], current_version)
            return 0
        else
            redis.call("SET", KEYS[1], math.max(current_version, tonumber(latest_version)))
            return 1
        end
    else
        redis.call("SET", KEYS[1], ARGV[1])
        return 0
    end
"#;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L359-364)
```rust
            2 => {
                tracing::error!(version=version, "Redis latest version update failed. The version is beyond the next expected version.");
                Err(anyhow::anyhow!("Version is not right."))
            },
            _ => Ok(()),
        }
```
