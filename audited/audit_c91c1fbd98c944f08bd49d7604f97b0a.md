# Audit Report

## Title
Race Condition in Concurrent Indexer Processing Causes Non-Atomic Updates to Indexed Blockchain State

## Summary
The Aptos indexer processes transaction batches concurrently using multiple tasks, but performs database reads outside of transaction boundaries. This creates race conditions where concurrent processors read stale data from "current" tables, leading to inconsistent historical records and potential processing failures when the same blockchain state is accessed by multiple concurrent batch processors.

## Finding Description

The indexer violates the **State Consistency** invariant by allowing non-atomic updates to indexed blockchain state through a fundamental race condition in concurrent batch processing.

### Root Cause

The indexer spawns multiple concurrent tasks (default 5, controlled by `processor_tasks` configuration) that process different transaction batches in parallel. While batches are fetched sequentially, they are processed and committed to the database concurrently and can complete in any order. [1](#0-0) 

Each concurrent task retrieves transactions and processes them by calling methods that perform **database SELECT queries outside of any transaction scope** to look up existing state:

**Critical Read #1 - Delegator Balances:** [2](#0-1) 

This function queries `current_delegator_balances` table to find the staking pool address for an inactive share handle. The SELECT happens at line 305-306: [3](#0-2) 

**Critical Read #2 - Object Ownership:** [4](#0-3) 

This function queries `current_objects` table at line 174 to retrieve object owner information: [5](#0-4) 

These SELECT queries occur **before** the database transaction begins: [6](#0-5) 

The database transaction only starts at line 91, but the data preparation (including SELECT queries) happens at lines 335-357 **before** entering the transaction.

### Race Condition Scenario

1. **Thread A** processes transactions 100-199
2. **Thread B** processes transactions 200-299  
3. Both threads execute concurrently

**Thread A** (processing transaction 150):
- Calls `Object::from_delete_resource` for object "0xABC"
- Executes SELECT on `current_objects` with READ COMMITTED isolation
- Reads: `owner = "0x1", version = 100` (current state)
- Prepares to write deletion record with owner "0x1"

**Thread B** (processing transaction 250):
- Updates object "0xABC" ownership to "0x2"
- **Commits database transaction first** (concurrent execution completes faster)
- Database now shows: `owner = "0x2", version = 250`

**Thread A continues:**
- Begins database transaction
- Writes to historical `objects` table with owner "0x1" (stale data)
- The historical table uses `on_conflict().do_nothing()` without version checking: [7](#0-6) 

**Result:** Historical `objects` table permanently records incorrect owner information based on stale data read before the transaction started.

### Database Isolation Level

The indexer uses PostgreSQL's default READ COMMITTED isolation level, confirmed in the Hasura metadata configuration. This allows each SELECT query to see different committed states, making the race condition exploitable.

## Impact Explanation

**Severity: Medium** - State inconsistencies requiring intervention (per Aptos bug bounty criteria: $10,000).

This vulnerability causes:

1. **Historical Data Corruption**: The `objects`, `delegated_staking_activities`, and similar historical tables record incorrect state based on stale reads, permanently corrupting the audit trail.

2. **Current State Inconsistencies**: While "current" tables have WHERE clause protection for version checking, the protection is insufficient:
   - Stale reads still occur and get written to historical tables
   - Failed lookups can cause processing errors (retry logic exists but may exhaust retries)
   - Race conditions create non-deterministic indexing behavior

3. **Deterministic Execution Violation**: The fundamental blockchain invariant that "all validators must produce identical state roots for identical blocks" is broken at the indexer level. Different indexer instances processing the same blockchain can produce different indexed states depending on concurrent execution timing.

4. **Downstream Impact**: Applications querying the indexer receive inconsistent data:
   - Wrong object ownership history
   - Incorrect delegator balance tracking  
   - Invalid state reconstructions
   - Failed Merkle proof verifications if based on corrupted data

This does not directly affect consensus or blockchain execution, but breaks the indexer's guarantee of providing an accurate, queryable view of blockchain state. In production systems, this requires manual intervention to identify and correct corrupted records.

## Likelihood Explanation

**Likelihood: High**

This vulnerability occurs automatically in production configurations:

- Default `processor_tasks = 5` enables concurrent processing
- Any blockchain activity involving objects or delegation pools triggers the vulnerable code paths
- The race window is significant (milliseconds to seconds per batch)
- No special attacker action required - normal blockchain operation triggers it

The retry logic with `QUERY_RETRIES` proves developers are aware of lookup failures but didn't address the root cause: [8](#0-7) 

Similar retry exists for objects: [9](#0-8) 

These retries are band-aids that don't prevent stale reads or guarantee consistency.

## Recommendation

**Solution: Perform all database reads within the transaction boundary**

1. **Move database lookups inside transactions**: Refactor code to pass necessary data through in-memory structures rather than querying during processing.

2. **Use SERIALIZABLE isolation level**: Change transaction isolation to SERIALIZABLE to detect and abort conflicting concurrent transactions:

```rust
conn.build_transaction()
    .serializable()  // Add this
    .read_write()
    .run::<_, Error, _>(|pg_conn| {
        // All operations including reads
    })
```

3. **Implement proper locking**: For "current" table lookups, use `SELECT ... FOR UPDATE` to lock rows being read:

```rust
pub fn get_by_address_for_update(
    object_address: &str,
    conn: &mut PgPoolConnection,
) -> diesel::QueryResult<Self> {
    current_objects::table
        .filter(current_objects::object_address.eq(object_address))
        .for_update()  // Add row-level locking
        .first::<Self>(conn)
}
```

4. **Serialize processing of overlapping keys**: Detect when concurrent batches might update the same keys and serialize those operations.

5. **Add validation**: After all concurrent batches complete, verify no version gaps exist in "current" tables before marking processing complete.

## Proof of Concept

To demonstrate this vulnerability:

1. Configure indexer with `processor_tasks = 5`
2. Generate transactions that:
   - Transaction at version N: Create object with address 0xABC, owner 0x1
   - Transaction at version N+100: Transfer object 0xABC to owner 0x2  
   - Transaction at version N+50: Delete object 0xABC
3. Process these transactions with concurrent batches:
   - Batch A: versions N to N+99
   - Batch B: versions N+100 to N+199
4. If Batch B completes first (updates current_objects to show owner 0x2 at version N+100), then Batch A processes the deletion at version N+50, it will query and see either:
   - Stale data (owner 0x1) if query happens before Batch B commits
   - New data (owner 0x2) if query happens after Batch B commits
5. The historical `objects` table will record the deletion with whichever owner was seen during the query, which may be incorrect for version N+50.

Query the database after processing:
```sql
-- Check for inconsistency
SELECT o.transaction_version, o.owner_address, o.is_deleted,
       co.last_transaction_version, co.owner_address 
FROM objects o
LEFT JOIN current_objects co ON o.object_address = co.object_address
WHERE o.object_address = '0xABC'
ORDER BY o.transaction_version;
```

The historical record at version N+50 may show an owner that never actually owned the object at that version, proving the race condition caused data corruption.

---

**Notes**

This vulnerability demonstrates that transaction isolation in the indexer is insufficient. While individual database transactions are atomic, the logical consistency across the entire indexing process is not guaranteed due to reads happening outside transaction boundaries. The WHERE clause protection on "current" table updates partially mitigates but doesn't prevent historical data corruption or processing failures. Production deployments of the Aptos indexer are at risk of serving inconsistent blockchain state to downstream applications.

### Citations

**File:** crates/indexer/src/runtime.rs (L210-214)
```rust
        let mut tasks = vec![];
        for _ in 0..processor_tasks {
            let other_tailer = tailer.clone();
            let task = tokio::spawn(async move { other_tailer.process_next_batch().await });
            tasks.push(task);
```

**File:** crates/indexer/src/models/stake_models/delegator_balances.rs (L298-315)
```rust
    pub fn get_staking_pool_from_inactive_share_handle(
        conn: &mut PgPoolConnection,
        table_handle: &str,
    ) -> anyhow::Result<String> {
        let mut retried = 0;
        while retried < QUERY_RETRIES {
            retried += 1;
            match CurrentDelegatorBalanceQuery::get_by_inactive_share_handle(conn, table_handle) {
                Ok(current_delegator_balance) => return Ok(current_delegator_balance.pool_address),
                Err(_) => {
                    std::thread::sleep(std::time::Duration::from_millis(QUERY_RETRY_DELAY_MS));
                },
            }
        }
        Err(anyhow::anyhow!(
            "Failed to get staking pool address from inactive share handle"
        ))
    }
```

**File:** crates/indexer/src/models/stake_models/delegator_balances.rs (L414-421)
```rust
    pub fn get_by_inactive_share_handle(
        conn: &mut PgPoolConnection,
        table_handle: &str,
    ) -> diesel::QueryResult<Self> {
        current_delegator_balances::table
            .filter(current_delegator_balances::parent_table_handle.eq(table_handle))
            .first::<Self>(conn)
    }
```

**File:** crates/indexer/src/models/v2_objects.rs (L167-192)
```rust
    fn get_object_owner(
        conn: &mut PgPoolConnection,
        object_address: &str,
    ) -> anyhow::Result<CurrentObject> {
        let mut retried = 0;
        while retried < QUERY_RETRIES {
            retried += 1;
            match CurrentObjectQuery::get_by_address(object_address, conn) {
                Ok(res) => {
                    return Ok(CurrentObject {
                        object_address: res.object_address,
                        owner_address: res.owner_address,
                        state_key_hash: res.state_key_hash,
                        allow_ungated_transfer: res.allow_ungated_transfer,
                        last_guid_creation_num: res.last_guid_creation_num,
                        last_transaction_version: res.last_transaction_version,
                        is_deleted: res.is_deleted,
                    })
                },
                Err(_) => {
                    std::thread::sleep(std::time::Duration::from_millis(QUERY_RETRY_DELAY_MS));
                },
            }
        }
        Err(anyhow::anyhow!("Failed to get object owner"))
    }
```

**File:** crates/indexer/src/models/v2_objects.rs (L195-205)
```rust
impl CurrentObjectQuery {
    /// TODO: Change this to a KV store
    pub fn get_by_address(
        object_address: &str,
        conn: &mut PgPoolConnection,
    ) -> diesel::QueryResult<Self> {
        current_objects::table
            .filter(current_objects::object_address.eq(object_address))
            .first::<Self>(conn)
    }
}
```

**File:** crates/indexer/src/processors/stake_processor.rs (L90-104)
```rust
    match conn
        .build_transaction()
        .read_write()
        .run::<_, Error, _>(|pg_conn| {
            insert_to_db_impl(
                pg_conn,
                &current_stake_pool_voters,
                &proposal_votes,
                &delegator_actvities,
                &delegator_balances,
                &delegator_pools,
                &delegator_pool_balances,
                &current_delegator_pool_balances,
            )
        }) {
```

**File:** crates/indexer/src/processors/default_processor.rs (L425-442)
```rust
fn insert_objects(
    conn: &mut PgConnection,
    items_to_insert: &[Object],
) -> Result<(), diesel::result::Error> {
    use schema::objects::dsl::*;
    let chunks = get_chunks(items_to_insert.len(), Object::field_count());
    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::objects::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((transaction_version, write_set_change_index))
                .do_nothing(),
            None,
        )?;
    }
    Ok(())
}
```
