# Audit Report

## Title
Race Condition in Subscription Stream Management Causes State Corruption and Data Loss

## Summary
A race condition exists in the storage service's subscription management system where concurrent access to the `subscriptions` DashMap can cause subscription updates to be applied to the wrong stream, resulting in state corruption, data loss, and synchronization failures for peers.

## Finding Description

The vulnerability occurs in the `handle_ready_subscriptions` function where subscription state updates are not atomic. The function performs two separate DashMap accesses with a race window between them:

1. **First access**: Removes a pending subscription request from the stream [1](#0-0) 

2. **Processing**: The subscription request is processed and data is sent to the peer (unlocked state)

3. **Second access**: Updates the stream's known version and epoch [2](#0-1) 

Between these two accesses, another thread can replace the entire subscription stream via `handle_subscription_request` when a peer starts a new subscription with a different stream ID. [3](#0-2) 

**Exploitation Timeline:**

1. Peer P has active subscription Stream ID 100 with `highest_known_version = 1000`, `next_index_to_serve = 5`
2. Thread A processes Stream 100's request at index 5, fetching 100 transactions (versions 1001-1100)
3. **Race Window**: Thread B receives new subscription from Peer P with Stream ID 200 (`known_version_at_stream_start = 2000`)
4. Thread B detects stream ID mismatch and replaces Stream 100 entirely with new Stream 200
5. Thread A continues and updates Stream 200's metadata with Stream 100's data via `update_known_version_and_epoch` [4](#0-3) 

**Result**: Stream 200 now has corrupted state:
- `highest_known_version = 2100` (should be 2000)  
- `next_index_to_serve = 1` (should be 0)
- Peer's pending request at index 0 gets rejected as "too low"
- 100 versions of blockchain data are skipped (2001-2100)

This breaks the **State Consistency** invariant as the stream metadata no longer matches the actual delivered data, and subscription state updates are not atomic.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

- **State inconsistencies requiring intervention**: Affected peers have corrupted subscription streams with incorrect version tracking, causing them to miss critical blockchain data
- **Data loss**: Peers skip transaction versions, leading to incomplete state synchronization
- **Synchronization failures**: Nodes cannot properly sync with the network, potentially falling behind or requiring manual intervention
- **No funds directly at risk**: However, nodes relying on incomplete data may make incorrect decisions

The impact is limited to the storage service layer and does not directly compromise consensus or funds, but it can cause significant operational issues for affected nodes.

## Likelihood Explanation

**High likelihood** of occurrence:

- **Natural timing**: The race window naturally occurs during normal subscription processing (no special timing required)
- **Common scenario**: Peers frequently reconnect or restart subscriptions with new stream IDs
- **No privileges needed**: Any peer can trigger this by starting a new subscription while an old one is being processed
- **Wide race window**: Processing time between the two DashMap accesses can be substantial (involves storage reads, data transformation, network sends)
- **No detection**: The corruption is silentâ€”no error is logged when the wrong stream is updated

## Recommendation

Implement atomic subscription stream updates by storing and validating the stream ID throughout the processing lifecycle:

```rust
// In handle_ready_subscriptions, capture the stream ID with the request
let subscription_request_and_known_version_and_stream_id =
    subscriptions
        .get_mut(&peer_network_id)
        .map(|mut subscription_stream_requests| {
            let stream_id = subscription_stream_requests.subscription_stream_id();
            (
                subscription_stream_requests.pop_first_pending_request(),
                subscription_stream_requests.highest_known_version,
                stream_id, // Capture stream ID
            )
        });

// Later, validate stream ID before updating
if let Some(mut subscription_stream_requests) =
    subscriptions.get_mut(&peer_network_id)
{
    // Validate the stream ID matches before updating
    if subscription_stream_requests.subscription_stream_id() == original_stream_id {
        subscription_stream_requests
            .update_known_version_and_epoch(&data_response)?;
    } else {
        // Stream was replaced, discard this update
        warn!("Stream ID changed during processing, discarding update");
    }
}
```

Alternatively, use a single atomic operation that holds the lock throughout:
- Extract request
- Process it  
- Update metadata
- All within a single `get_mut()` or `entry()` call

## Proof of Concept

```rust
use aptos_storage_service_server::subscription::{SubscriptionRequest, SubscriptionStreamRequests};
use aptos_config::network_id::{NetworkId, PeerNetworkId};
use aptos_types::PeerId;
use dashmap::DashMap;
use std::sync::Arc;
use std::thread;

#[test]
fn test_subscription_race_condition() {
    // Setup
    let subscriptions = Arc::new(DashMap::new());
    let peer = PeerNetworkId::new(NetworkId::Validator, PeerId::random());
    
    // Thread 1: Create initial subscription (Stream ID 100)
    let request_100 = create_subscription_request(100, 0, 1000, 0);
    let stream_100 = SubscriptionStreamRequests::new(request_100, time_service.clone());
    subscriptions.insert(peer, stream_100);
    
    let subs_clone = subscriptions.clone();
    let peer_clone = peer;
    
    // Thread 1: Simulate processing a ready subscription
    let handle1 = thread::spawn(move || {
        // Step 1: Pop request (releases lock)
        let (req, known_ver) = subs_clone
            .get_mut(&peer_clone)
            .map(|mut s| (s.pop_first_pending_request(), s.highest_known_version))
            .unwrap();
        
        // Simulate processing time
        thread::sleep(Duration::from_millis(10));
        
        // Step 2: Update stream (acquires lock again)
        if let Some(mut stream) = subs_clone.get_mut(&peer_clone) {
            // This will update the WRONG stream (Stream 200)!
            stream.highest_known_version += 100;
            stream.next_index_to_serve += 1;
        }
    });
    
    // Thread 2: Replace stream during processing (Stream ID 200)
    let handle2 = thread::spawn(move || {
        thread::sleep(Duration::from_millis(5)); // Hit the race window
        
        let request_200 = create_subscription_request(200, 0, 2000, 0);
        let stream_200 = SubscriptionStreamRequests::new(request_200, time_service.clone());
        subscriptions.insert(peer, stream_200); // Replaces Stream 100
    });
    
    handle1.join().unwrap();
    handle2.join().unwrap();
    
    // Verify corruption: Stream 200 has wrong version
    let stream = subscriptions.get(&peer).unwrap();
    assert_eq!(stream.subscription_stream_id(), 200);
    assert_eq!(stream.get_highest_known_version_and_epoch().0, 2100); // CORRUPTED! Should be 2000
    assert_eq!(stream.get_next_index_to_serve(), 1); // CORRUPTED! Should be 0
}
```

## Notes

This vulnerability demonstrates a critical failure in concurrent state management. The DashMap provides fine-grained locking at the entry level, but the code incorrectly assumes that the same stream will be present across two separate lock acquisitions. The lack of stream ID validation allows updates intended for one stream to corrupt a completely different stream, breaking state sync correctness for affected peers.

### Citations

**File:** state-sync/storage-service/server/src/subscription.rs (L543-557)
```rust
        // Update the highest known version
        self.highest_known_version += num_data_items as u64;

        // Update the highest known epoch if we've now hit an epoch ending ledger info
        if self.highest_known_version == target_ledger_info.ledger_info().version()
            && target_ledger_info.ledger_info().ends_epoch()
        {
            self.highest_known_epoch += 1;
        }

        // Update the next index to serve
        self.next_index_to_serve += 1;

        // Refresh the last stream update time
        self.refresh_last_stream_update_time();
```

**File:** state-sync/storage-service/server/src/subscription.rs (L659-667)
```rust
        let subscription_request_and_known_version =
            subscriptions
                .get_mut(&peer_network_id)
                .map(|mut subscription_stream_requests| {
                    (
                        subscription_stream_requests.pop_first_pending_request(),
                        subscription_stream_requests.highest_known_version,
                    )
                });
```

**File:** state-sync/storage-service/server/src/subscription.rs (L713-719)
```rust
                    // Update the stream's known version and epoch
                    if let Some(mut subscription_stream_requests) =
                        subscriptions.get_mut(&peer_network_id)
                    {
                        subscription_stream_requests
                            .update_known_version_and_epoch(&data_response)?;
                    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L308-318)
```rust
            Entry::Occupied(mut occupied_entry) => {
                // If the stream has a different ID than the request, replace the stream.
                // Otherwise, add the request to the existing stream.
                let existing_stream_id = occupied_entry.get().subscription_stream_id();
                if existing_stream_id != request_stream_id {
                    // Create a new subscription stream for the peer
                    let subscription_stream = SubscriptionStreamRequests::new(
                        subscription_request,
                        self.time_service.clone(),
                    );
                    occupied_entry.replace_entry(subscription_stream);
```
