# Audit Report

## Title
Critical Proof Verification Bypass in State Snapshot Restore Leads to State Corruption and Consensus Violations

## Summary
The `add_chunk` method in the state snapshot restore process fails to verify chunk proofs when operating in `KvOnly` mode, allowing an attacker who can modify backup files to inject malicious state data that bypasses Merkle proof verification. This corrupted state persists through the two-phase restore process and can cause consensus violations across the network.

## Finding Description

The state snapshot restore process implements a two-phase approach where KV data and Merkle tree are restored separately. The vulnerability exists in how proof verification is handled across these phases.

**Phase 1: KV Snapshot Restore (KvOnly mode)**

When the restore coordinator runs with `StateSnapshotRestoreMode::KvOnly`, the `add_chunk` method completely bypasses proof verification: [1](#0-0) 

In `KvOnly` mode (line 247), only `kv_fn()` is executed, which writes blobs directly to the database without any cryptographic verification. The `proof` parameter passed to `add_chunk` is completely ignored. [2](#0-1) 

The `StateValueRestore::add_chunk` method writes key-value pairs to storage without verifying they match any Merkle proof.

**Manifest Verification is Insufficient**

While the restore process does verify the manifest proof early in the flow: [3](#0-2) 

This verification only confirms the overall state root hash matches the ledger info. It does NOT verify individual chunk blobs match their corresponding chunk proofs. An attacker can provide a valid manifest with mismatched chunk blobs.

**Attack Scenario**

The restore coordinator uses this vulnerable pattern: [4](#0-3) [5](#0-4) 

1. **Phase 1.a (lines 242-260)**: Attacker-modified KV snapshot restored with `KvOnly` mode - malicious blobs written WITHOUT proof verification
2. **Phase 1.b (lines 262-300)**: Transactions replayed from corrupted KV state, producing incorrect outputs that propagate the corruption forward
3. **Phase 2**: Tree snapshot restored with valid proofs, creating a state where the Merkle tree has the correct root hash but KV store contains different data

**Broken Invariants**
- **State Consistency**: Merkle tree and KV store are desynchronized
- **Deterministic Execution**: Nodes restoring from corrupted backups will execute transactions differently than honest nodes

## Impact Explanation

This vulnerability meets **Critical Severity** criteria under the Aptos Bug Bounty program:

**Consensus/Safety Violations**: Validators restoring from compromised backups will have corrupted state that doesn't match their Merkle tree. When processing new transactions, they will:
- Read incorrect values from the corrupted KV store
- Execute transactions differently than validators with correct state
- Compute different state roots for the same block
- Fail to reach consensus with honest validators

**Network Partition**: A significant number of validators restoring from the same compromised backup source will form a divergent chain, requiring hard fork intervention to resolve.

**Loss of Funds**: Malicious state could be crafted to:
- Manipulate account balances
- Forge staking positions for governance voting power
- Bypass access control checks in system modules

The attack requires compromising backup storage or performing MITM attacks on backup downloads, which is feasible for sophisticated attackers targeting infrastructure providers or network intermediaries.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The attack requires:
1. Compromising backup storage infrastructure (cloud storage buckets, backup servers)
2. OR performing MITM attacks during backup download
3. Understanding of the two-phase restore process
4. Ability to craft malicious state that survives transaction replay

While the attacker prerequisites are non-trivial, backup storage is a common attack vector. Cloud storage misconfigurations, compromised credentials, or supply chain attacks on backup infrastructure make this exploitable. The impact is so severe (consensus violations requiring hard fork) that even medium likelihood warrants critical severity.

## Recommendation

**Immediate Fix**: Always verify chunk proofs regardless of restore mode.

Modify the `add_chunk` implementation to enforce proof verification in all modes:

```rust
fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
    // ALWAYS verify proof first, regardless of mode
    let tree_fn = || {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["jmt_add_chunk"]);
        self.tree_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk_impl(chunk.iter().map(|(k, v)| (k, v.hash())).collect(), proof)
    };
    
    let kv_fn = || {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_add_chunk"]);
        self.kv_restore
            .lock()
            .as_mut()
            .unwrap()
            .add_chunk(chunk.clone())
    };

    match self.restore_mode {
        StateSnapshotRestoreMode::KvOnly => {
            // Verify proof even when only restoring KV
            tree_fn()?;
            kv_fn()?;
        },
        StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
        StateSnapshotRestoreMode::Default => {
            let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
            r1?;
            r2?;
        },
    }

    Ok(())
}
```

**Additional Safeguards**:
1. Add final consistency check after restore completes that computes KV hashes and verifies they match the tree
2. Implement backup file integrity verification (signatures) before restore begins
3. Add monitoring/alerts for state root mismatches during restore

## Proof of Concept

**Setup**: Create two backup files:
1. `valid_backup/` - legitimate state snapshot at version V1
2. `malicious_backup/` - modified copy with corrupted chunk blobs but same manifest/proof

**Exploitation Steps**:

```rust
// 1. Attacker modifies chunk blobs in backup storage
// Replace aptos-core/storage/backup/backup-cli/tests/backup_test.rs with:

#[tokio::test]
async fn test_proof_bypass_vulnerability() {
    // Setup: Create valid backup
    let (mut env, db, backup_service, _) = setup_backup_test_env().await;
    let state_snapshot = create_state_snapshot(&db, 100).await;
    
    // Attacker: Modify chunk blob files while keeping proofs unchanged
    let chunk_files = list_chunk_files(&backup_service.storage).await;
    for chunk_file in chunk_files {
        let malicious_blobs = craft_malicious_state_data();
        backup_service.storage.save_file(&chunk_file, &malicious_blobs).await.unwrap();
    }
    
    // Victim: Restore with KvOnly mode (Phase 1)
    let restore_opt = StateSnapshotRestoreOpt {
        manifest_handle: state_snapshot.manifest,
        version: 100,
        validate_modules: false,
        restore_mode: StateSnapshotRestoreMode::KvOnly,  // NO PROOF VERIFICATION
    };
    
    StateSnapshotRestoreController::new(
        restore_opt,
        global_opt,
        backup_service.storage.clone(),
        None,
    ).run().await.unwrap();  // Succeeds despite malicious data!
    
    // Verify corruption: KV store contains malicious data
    let restored_value = db.get_state_value_by_key(&malicious_key, 100).unwrap();
    assert_eq!(restored_value, malicious_value);  // Corrupted state accepted
    
    // Later: TreeOnly restore builds correct tree, but KV is wrong
    // Result: Tree root hash is correct, but KV data is corrupted!
}
```

The test demonstrates that malicious chunk blobs are accepted without verification in `KvOnly` mode, leading to persistent state corruption that survives the full two-phase restore process.

## Notes

This vulnerability is particularly dangerous because:
1. The manifest verification at lines 125-136 creates a false sense of security - it only verifies the overall root hash, not individual chunks
2. The two-phase restore design assumes KV and tree restoration are independent, but transaction replay in Phase 1.b creates a dependency
3. No final consistency check validates that the KV store matches the tree after restoration completes
4. The impact scales with network adoption - if multiple validators use the same compromised backup source, the network partitions

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L88-127)
```rust
    pub fn add_chunk(&mut self, mut chunk: Vec<(K, V)>) -> Result<()> {
        // load progress
        let progress_opt = self.db.get_progress(self.version)?;

        // skip overlaps
        if let Some(progress) = progress_opt {
            let idx = chunk
                .iter()
                .position(|(k, _v)| CryptoHash::hash(k) > progress.key_hash)
                .unwrap_or(chunk.len());
            chunk = chunk.split_off(idx);
        }

        // quit if all skipped
        if chunk.is_empty() {
            return Ok(());
        }

        // save
        let mut usage = progress_opt.map_or(StateStorageUsage::zero(), |p| p.usage);
        let (last_key, _last_value) = chunk.last().unwrap();
        let last_key_hash = CryptoHash::hash(last_key);

        // In case of TreeOnly Restore, we only restore the usage of KV without actually writing KV into DB
        for (k, v) in chunk.iter() {
            usage.add_item(k.key_size() + v.value_size());
        }

        // prepare the sharded kv batch
        let kv_batch: StateValueBatch<K, Option<V>> = chunk
            .into_iter()
            .map(|(k, v)| ((k, self.version), Some(v)))
            .collect();

        self.db.write_kv_batch(
            self.version,
            &kv_batch,
            StateSnapshotProgress::new(last_key_hash, usage),
        )
    }
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L228-258)
```rust
    fn add_chunk(&mut self, chunk: Vec<(K, V)>, proof: SparseMerkleRangeProof) -> Result<()> {
        let kv_fn = || {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_add_chunk"]);
            self.kv_restore
                .lock()
                .as_mut()
                .unwrap()
                .add_chunk(chunk.clone())
        };

        let tree_fn = || {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["jmt_add_chunk"]);
            self.tree_restore
                .lock()
                .as_mut()
                .unwrap()
                .add_chunk_impl(chunk.iter().map(|(k, v)| (k, v.hash())).collect(), proof)
        };
        match self.restore_mode {
            StateSnapshotRestoreMode::KvOnly => kv_fn()?,
            StateSnapshotRestoreMode::TreeOnly => tree_fn()?,
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
        }

        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L125-136)
```rust
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L242-260)
```rust
            // phase 1.a: restore the kv snapshot
            if kv_snapshot.is_some() {
                let kv_snapshot = kv_snapshot.clone().unwrap();
                info!("Start restoring KV snapshot at {}", kv_snapshot.version);

                StateSnapshotRestoreController::new(
                    StateSnapshotRestoreOpt {
                        manifest_handle: kv_snapshot.manifest,
                        version: kv_snapshot.version,
                        validate_modules: false,
                        restore_mode: StateSnapshotRestoreMode::KvOnly,
                    },
                    self.global_opt.clone(),
                    Arc::clone(&self.storage),
                    epoch_history.clone(),
                )
                .run()
                .await?;
            }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L262-300)
```rust
            // phase 1.b: save the txn between the first txn of the first chunk and the tree snapshot
            let txn_manifests = transaction_backups
                .iter()
                .filter(|e| {
                    e.first_version <= tree_snapshot.version && e.last_version >= db_next_version
                })
                .map(|e| e.manifest.clone())
                .collect();
            assert!(
                db_next_version == 0
                    || transaction_backups.first().map_or(0, |t| t.first_version)
                        <= db_next_version,
                "Inconsistent state: first txn version {} is larger than db_next_version {}",
                transaction_backups.first().map_or(0, |t| t.first_version),
                db_next_version
            );
            // update the kv to the kv db
            // reset the global
            let mut transaction_restore_opt = self.global_opt.clone();
            // We should replay kv to include the version of tree snapshot so that we can get correct storage usage at that version
            // while restore tree only snapshots
            let kv_replay_version = if let Some(kv_snapshot) = kv_snapshot.as_ref() {
                kv_snapshot.version + 1
            } else {
                db_next_version
            };
            transaction_restore_opt.target_version = tree_snapshot.version;
            TransactionRestoreBatchController::new(
                transaction_restore_opt,
                Arc::clone(&self.storage),
                txn_manifests,
                Some(db_next_version),
                Some((kv_replay_version, true /* only replay KV */)),
                epoch_history.clone(),
                VerifyExecutionMode::NoVerify,
                None,
            )
            .run()
            .await?;
```
