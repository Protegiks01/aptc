# Audit Report

## Title
Memory-Based Rate Limiter Loses All State on Restart, Allowing Unlimited Daily Quota Bypass

## Summary
The `MemoryRatelimitChecker` in the Aptos faucet service stores all rate limit state in volatile memory with no persistence mechanism. Every service restart completely resets all IP-based rate limit counters, allowing attackers to bypass the configured `max_requests_per_day` limit by timing requests around service restarts or crashes. [1](#0-0) 

## Finding Description
The `MemoryRatelimitChecker` implements daily rate limiting using an in-memory `LruCache` data structure wrapped in a `Mutex`. The configuration explicitly specifies `max_requests_per_day`, creating a security contract that each IP address should be limited to N requests per calendar day. [2](#0-1) 

However, when the faucet service starts, the constructor creates a fresh, empty cache with zero state recovery: [3](#0-2) 

The `clear_if_new_day()` function only handles date rollovers during runtime but provides no mechanism for recovering state after a restart: [4](#0-3) 

**Attack Scenario:**
1. Attacker makes requests up to `max_requests_per_day` limit (e.g., 100 requests)
2. Attacker waits for a service restart (deployment, crash, scaling event, or configuration update)
3. All rate limit counters are reset to zero upon restart
4. Attacker makes another 100 requests successfully
5. Process repeats indefinitely

This violates the documented security guarantee of "per day" rate limiting, instead providing only "per service uptime" limiting.

The configuration system treats `MemoryRatelimit` as a valid production option alongside `RedisRatelimit`: [5](#0-4) 

## Impact Explanation
This vulnerability meets **High Severity** criteria per the Aptos bug bounty program for the following reasons:

1. **Significant Protocol Violation**: The rate limiting protocol is fundamentally broken, as the documented "daily" limit can be bypassed through service restarts.

2. **Resource Exhaustion**: Attackers can drain faucet funds by repeatedly requesting tokens around restart events, potentially causing:
   - Complete depletion of faucet resources
   - Denial of service for legitimate users
   - Unfair distribution of testnet tokens

3. **API/Service Availability**: The faucet is a critical service for testnet/devnet operations. Its compromise affects the entire developer ecosystem.

4. **Production Impact**: The faucet is deployed on production testnets (devnet, testnet) as documented: [6](#0-5) 

## Likelihood Explanation
This vulnerability has **HIGH likelihood** of exploitation because:

1. **Common Restart Events**: Production services restart regularly due to:
   - Scheduled deployments and upgrades
   - Configuration changes
   - Container orchestration scaling events
   - Crash recovery with auto-restart policies
   - Infrastructure maintenance

2. **No Special Access Required**: Any user can exploit this by simply timing requests around public maintenance windows or opportunistically after crashes.

3. **Easy Detection**: Attackers can monitor service uptime through API response patterns or public status pages.

4. **Documented Configuration Option**: The `MemoryRatelimit` checker is presented as a valid configuration option alongside Redis, with no warnings about restart behavior.

## Recommendation

**Short-term mitigation**: Add clear documentation warning that `MemoryRatelimitChecker` should only be used for local development/testing, not production deployments.

**Long-term fix**: Implement state persistence for `MemoryRatelimitChecker` or deprecate it in favor of `RedisRatelimitChecker` for all production use cases.

Example documentation fix for `memory_ratelimit.rs`:

```rust
/// Simple in-memory rate limiter for LOCAL DEVELOPMENT ONLY.
/// 
/// ⚠️  WARNING: This checker stores all state in volatile memory.
/// All rate limit counters are RESET TO ZERO on service restart.
/// DO NOT use in production - use RedisRatelimitChecker instead.
///
/// This checker tracks requests per IP with configurable daily limits,
/// but the "daily" limit is only enforced per service uptime, not per
/// calendar day. After any crash or restart, all IPs receive a fresh quota.
```

Alternatively, implement persistence using a file-based checkpoint system:

```rust
pub struct MemoryRatelimitChecker {
    pub max_requests_per_day: u32,
    pub ip_to_requests_today: Mutex<LruCache<IpAddr, u32>>,
    pub current_day: AtomicU64,
    pub checkpoint_path: Option<PathBuf>, // NEW: optional persistence
}

// Implement periodic checkpointing and recovery on startup
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_rate_limit_bypass_via_restart() {
    use std::net::IpAddr;
    use std::str::FromStr;
    use std::num::NonZeroUsize;
    
    // Create rate limiter with max 3 requests per day
    let config = MemoryRatelimitCheckerConfig {
        max_requests_per_day: 3,
        max_entries_in_map: NonZeroUsize::new(100).unwrap(),
    };
    
    let checker1 = MemoryRatelimitChecker::new(config.clone());
    let test_ip = IpAddr::from_str("192.168.1.100").unwrap();
    
    // Make 3 requests - should all succeed
    for i in 0..3 {
        let data = CheckerData {
            time_request_received_secs: 1000000,
            receiver: AccountAddress::ZERO,
            source_ip: test_ip,
            headers: Arc::new(HeaderMap::new()),
        };
        
        let result = checker1.check(data, false).await.unwrap();
        assert_eq!(result.len(), 0, "Request {} should succeed", i);
    }
    
    // 4th request should fail - rate limited
    let data = CheckerData {
        time_request_received_secs: 1000000,
        receiver: AccountAddress::ZERO,
        source_ip: test_ip,
        headers: Arc::new(HeaderMap::new()),
    };
    let result = checker1.check(data, false).await.unwrap();
    assert_eq!(result.len(), 1, "4th request should be rate limited");
    
    // SIMULATE RESTART: Create new checker instance (all state lost)
    drop(checker1);
    let checker2 = MemoryRatelimitChecker::new(config);
    
    // Make 3 MORE requests - they all succeed despite hitting limit before restart
    for i in 0..3 {
        let data = CheckerData {
            time_request_received_secs: 1000000,
            receiver: AccountAddress::ZERO,
            source_ip: test_ip,
            headers: Arc::new(HeaderMap::new()),
        };
        
        let result = checker2.check(data, false).await.unwrap();
        assert_eq!(result.len(), 0, "Request {} after restart should succeed - VULNERABILITY", i);
    }
    
    // Attacker successfully made 6 requests in the same day (3 + restart + 3)
    // instead of the configured limit of 3
}
```

**Expected behavior**: After restart, the 4th overall request should still be rejected because the IP already used its daily quota.

**Actual behavior**: After restart, the IP receives a fresh quota and can make 3 more requests, bypassing the daily limit.

## Notes

The alternative `RedisRatelimitChecker` implementation properly persists state and is not affected by this issue: [7](#0-6) 

Redis-based rate limiting uses persistent storage with TTL-based expiration, ensuring rate limits survive service restarts. Production deployments should exclusively use `RedisRatelimit` for distributed, persistent rate limiting.

### Citations

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L15-21)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct MemoryRatelimitCheckerConfig {
    pub max_requests_per_day: u32,

    #[serde(default = "MemoryRatelimitCheckerConfig::default_max_entries_in_map")]
    pub max_entries_in_map: NonZeroUsize,
}
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L31-42)
```rust
pub struct MemoryRatelimitChecker {
    pub max_requests_per_day: u32,

    /// Map of IP to how many requests they've submitted today (where the
    /// response wasn't a 500). To avoid OOMing the server, we set a limit
    /// on how many entries we have in the table.
    pub ip_to_requests_today: Mutex<LruCache<IpAddr, u32>>,

    /// Used for tracking daily ratelimit. See the comment in RedisRatelimitChecker
    /// for more information on how we track daily limits.
    pub current_day: AtomicU64,
}
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L44-51)
```rust
impl MemoryRatelimitChecker {
    pub fn new(args: MemoryRatelimitCheckerConfig) -> Self {
        Self {
            max_requests_per_day: args.max_requests_per_day,
            ip_to_requests_today: Mutex::new(LruCache::new(args.max_entries_in_map)),
            current_day: AtomicU64::new(days_since_tap_epoch(get_current_time_secs())),
        }
    }
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L53-63)
```rust
    async fn clear_if_new_day(&self) {
        if days_since_tap_epoch(get_current_time_secs())
            > self.current_day.load(std::sync::atomic::Ordering::Relaxed)
        {
            self.current_day.store(
                days_since_tap_epoch(get_current_time_secs()),
                std::sync::atomic::Ordering::Relaxed,
            );
            self.ip_to_requests_today.lock().await.clear();
        }
    }
```

**File:** crates/aptos-faucet/core/src/checkers/mod.rs (L81-107)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
#[serde(tag = "type")]
pub enum CheckerConfig {
    /// Requires that an auth token is included in the Authorization header.
    AuthToken(ListManagerConfig),

    /// Requires a legitimate Google ReCaptcha token.
    GoogleCaptcha(GoogleCaptchaCheckerConfig),

    /// Rejects requests if their IP is in a blocklisted IPrnage.
    IpBlocklist(IpRangeManagerConfig),

    /// Checkers whether a config-defined magic header kv is present.
    MagicHeader(MagicHeaderCheckerConfig),

    /// Basic in memory ratelimiter that allows a single successful request per IP.
    MemoryRatelimit(MemoryRatelimitCheckerConfig),

    /// Ratelimiter that uses Redis.
    RedisRatelimit(RedisRatelimitCheckerConfig),

    /// Rejects requests if their Referer is blocklisted.
    RefererBlocklist(ListManagerConfig),

    /// In-house captcha solution.
    TapCaptcha(TapCaptchaCheckerConfig),
}
```

**File:** crates/aptos-faucet/README.md (L31-49)
```markdown
## Running
To run the faucet, the simplest way to start is with this command:
```
cargo run -p aptos-faucet-service -- run-simple --key <private_key> --node-url <api_url> --chain-id TESTING
```

Another example, running alongside a localnet (without `--use-faucet`):
```
cargo run -p aptos -- node run-local-testnet --force-restart --assume-yes
cargo run -p aptos-faucet-service -- run-simple --key ~/.aptos/testnet/mint.key --node-url http://127.0.0.1:8080 --chain-id TESTING
```

This command lets you configure only a subset of the full functionality of the faucet. You cannot enable any checkers / bypassers, and it supports only the MintFunder. Generally it is intended for use with some kind of local swarm-based testnet or other such uses.

For running the faucet in production, you will instead want to build a configuration file and run it like this:
```
cargo run -p aptos-faucet-service -- run -c <path_to_config_file>
```

```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L114-150)
```rust
/// The RedisRatelimitChecker backend uses redis to ratelimit requests to the tap. Unlike
/// the PostgresStorage backend, it does not store full information for each
/// request. Instead, it uses counters to track limits. This is heavily inspired
/// by https://redis.com/redis-best-practices/basic-rate-limiting/.
///
/// We use a generic key (e.g. IP address or Firebase UID).
///
/// If we're not careful, it is possible for people to exceed the intended limit
/// by sending many requests simultaneously. We avoid this problem with this
/// order of operations:
///   1. Read the current value of the limit for the given key (e.g. IP / Firebase UID).
///   2. If value is greater than limit, reject.
///   3. Otherwise, increment and set TTL if necessary.
///   4. Increment returns the new value. Check if this is greater than the limit also.
///
/// Incrementing the limit is an atomic operation (meaning each client will see
/// value increment, never reading the same value), so steps 1 and 2 are not
/// actually necessary for correctness. Instead, steps 1 and 2 are just an optimization
/// to avoid incrementing the limit unnecessarily if the limit has already been
/// reached. With steps 1 and 2 we end up having more unnecessary reads when
/// they're under their limit vs more unnecessary writes when they're over their
/// limit, but we'll happily take more reads over more writes.
///
/// Note: Previously I made an attempt (d4fbf6db675e9036a967b52bf8d13e1b2566787e) at
/// doing these steps atomically, but it became very unwieldy:
///   1. Start a transaction.
///   2. Increment current value for limit for source key, set TTL if necessary.
///   3. If value is greater than limit, revert the transaction.
///
/// This second way leaves a small window for someone to slip in multiple requests,
/// therein blowing past the configured limit, but it's a very small window, so we'll
/// worry about it as a followup: https://github.com/aptos-labs/aptos-tap/issues/15.
pub struct RedisRatelimitChecker {
    args: RedisRatelimitCheckerConfig,
    db_pool: Pool,
    ratelimit_key_provider: RatelimitKeyProvider,
}
```
