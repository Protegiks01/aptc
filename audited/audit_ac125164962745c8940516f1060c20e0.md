# Audit Report

## Title
Database Atomicity Violation in Parallel Ledger Commits Allows Inconsistent State on Node Crash

## Summary
The `calculate_and_commit_ledger_and_state_kv()` function in AptosDB performs parallel writes to 7 separate databases without cross-database transactional guarantees. When storage sharding is enabled, if one database write succeeds while another fails and panics, the successful writes are permanently persisted, creating an inconsistent ledger state that can cause validator downtime and require manual intervention.

## Finding Description

The vulnerability exists in the parallel commit architecture when storage sharding is enabled. [1](#0-0) 

When processing a transaction chunk, the system spawns 7 concurrent tasks that write to separate RocksDB databases:

1. Events database (commit_events)
2. Write sets database (commit_write_sets)
3. Transactions database (commit_transactions)
4. Auxiliary info database (commit_auxiliary_info)
5. State KV & metadata (commit_state_kv_and_ledger_metadata)
6. Transaction infos database (commit_transaction_infos)
7. Transaction accumulator (commit_transaction_accumulator)

Each task uses `.unwrap()` which panics on error, and each database write uses `sync=true`, immediately persisting data to disk. [2](#0-1) 

With storage sharding enabled, these are **physically separate RocksDB instances**, not just column families within the same database. [3](#0-2) 

The critical flaw: if Task 1 completes and commits successfully, then Task 3 encounters an I/O error and panics, Task 1's write is already persisted and **cannot be rolled back**. The rayon scope will propagate the panic, crashing the node with databases in inconsistent states.

The developers acknowledge this issue: [4](#0-3) 

While a recovery mechanism exists through `sync_commit_progress`, the truncation process itself writes to multiple databases sequentially and is not atomic: [5](#0-4) 

If truncation fails partway through (e.g., subsequent disk error, power loss), the node panics during startup and cannot recover: [6](#0-5) 

## Impact Explanation

This vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

**Impact Severity: High**

Per Aptos bug bounty criteria, this qualifies as:
- **High Severity**: "Validator node slowdowns" and "Significant protocol violations"
- Potentially **Medium Severity**: "State inconsistencies requiring intervention"

Specific impacts:
1. **Validator Downtime**: Node crashes and cannot restart if recovery fails
2. **Liveness Degradation**: Affected validators cannot participate in consensus
3. **Manual Intervention Required**: Database inconsistencies may require operator intervention
4. **Network Health Impact**: If multiple validators encounter this simultaneously (e.g., during network stress), network liveness could be significantly impaired

While this doesn't directly cause consensus safety violations or fund loss (the recovery mechanism prevents state corruption from being committed to the ledger), it creates operational vulnerabilities that can impact network availability.

## Likelihood Explanation

**Likelihood: Medium to High during stress conditions**

The vulnerability triggers when:
1. Storage sharding is enabled (common in production)
2. A database write operation fails (disk I/O errors, space exhaustion, corruption)
3. The failure occurs after at least one other parallel task has completed

Scenarios that increase likelihood:
- **Disk space exhaustion**: If disk fills up during heavy transaction load, some writes may succeed before others fail
- **Hardware degradation**: Intermittent I/O errors on failing storage devices
- **Resource contention**: Under extreme load, some database operations may timeout while others succeed
- **Specific transaction patterns**: Certain transaction types may cause one database to fill faster than others

The developers' TODO comments indicate this is a known architectural issue requiring resolution, suggesting it's considered a realistic concern.

## Recommendation

Implement one of the following solutions:

**Option 1: Two-Phase Commit Protocol**
```rust
fn calculate_and_commit_ledger_and_state_kv(
    &self,
    chunk: &ChunkToCommit,
    skip_index_and_usage: bool,
) -> Result<HashValue> {
    // Phase 1: Prepare all batches in parallel
    let (events_batch, write_sets_batch, txns_batch, ...) = 
        prepare_all_batches_parallel(chunk)?;
    
    // Phase 2: Write all batches sequentially with rollback on error
    match self.commit_all_batches_atomic(
        events_batch, write_sets_batch, txns_batch, ...
    ) {
        Ok(hash) => Ok(hash),
        Err(e) => {
            self.rollback_partial_commits(chunk.first_version)?;
            Err(e)
        }
    }
}
```

**Option 2: Propagate Errors Instead of Panic**
Replace `.unwrap()` with proper error handling that aborts all tasks on first failure:
```rust
THREAD_MANAGER.get_non_exe_cpu_pool().install(|| -> Result<HashValue> {
    let results: Vec<Result<()>> = vec![
        self.commit_events(...),
        self.ledger_db.write_set_db().commit_write_sets(...),
        // ... other commits
    ].into_par_iter().collect();
    
    // Check all results before any writes
    for result in results {
        result?;
    }
    // Only commit if all preparations succeeded
    self.commit_all_prepared_batches()
})
```

**Option 3: Single-Database Atomic Batch**
Consolidate all writes into a single RocksDB WriteBatch when possible, ensuring atomicity at the database level.

## Proof of Concept

The following demonstrates the vulnerability (conceptual Rust test):

```rust
#[test]
fn test_partial_commit_on_failure() {
    let aptos_db = setup_test_db_with_sharding();
    
    // Simulate a chunk with transactions
    let chunk = create_test_chunk(version: 100, num_txns: 10);
    
    // Inject failure in one of the databases after others succeed
    aptos_db.transaction_db().inject_failure_after_write(
        version: 105,
        error: "Simulated I/O error"
    );
    
    // Attempt commit - should panic due to .unwrap()
    let result = std::panic::catch_unwind(|| {
        aptos_db.calculate_and_commit_ledger_and_state_kv(&chunk, false)
    });
    
    assert!(result.is_err(), "Should panic on write failure");
    
    // Verify inconsistent state
    let events_version = aptos_db.event_db().latest_version().unwrap();
    let txns_version = aptos_db.transaction_db().latest_version().unwrap();
    
    // Events succeeded, transactions failed
    assert_eq!(events_version, Some(109)); // Committed up to version 109
    assert_eq!(txns_version, Some(99));     // Still at version 99
    
    // This violates atomicity - databases are at different versions
    assert_ne!(events_version, txns_version, "State is inconsistent");
}
```

To reproduce in practice:
1. Enable storage sharding in node configuration
2. Fill disk to near capacity during heavy transaction processing
3. Monitor for panic logs indicating write failures
4. Observe node crash and failed restart attempts due to inconsistent database state
5. Manual database repair required

## Notes

This vulnerability is explicitly acknowledged in the codebase with TODO comments indicating the need to "handle the inconsistency at startup time" and "propagate the error instead of panic." The recovery mechanism provides partial mitigation, but the non-atomic nature of both the initial writes and the recovery truncation creates a window for permanent inconsistency requiring manual intervention. The impact on network liveness is proportional to the number of validators affected simultaneously.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L271-319)
```rust
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            // TODO(grao): Write progress for each of the following databases, and handle the
            // inconsistency at the startup time.
            //
            // TODO(grao): Consider propagating the error instead of panic, if necessary.
            s.spawn(|_| {
                self.commit_events(
                    chunk.first_version,
                    chunk.transaction_outputs,
                    skip_index_and_usage,
                )
                .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .write_set_db()
                    .commit_write_sets(chunk.first_version, chunk.transaction_outputs)
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .transaction_db()
                    .commit_transactions(
                        chunk.first_version,
                        chunk.transactions,
                        skip_index_and_usage,
                    )
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .persisted_auxiliary_info_db()
                    .commit_auxiliary_info(chunk.first_version, chunk.persisted_auxiliary_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_state_kv_and_ledger_metadata(chunk, skip_index_and_usage)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_transaction_infos(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                new_root_hash = self
                    .commit_transaction_accumulator(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
        });
```

**File:** storage/schemadb/src/lib.rs (L307-309)
```rust
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L183-279)
```rust
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            s.spawn(|_| {
                let event_db_raw = Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(EVENT_DB_NAME),
                        EVENT_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                );
                event_db = Some(EventDb::new(
                    event_db_raw.clone(),
                    EventStore::new(event_db_raw),
                ));
            });
            s.spawn(|_| {
                persisted_auxiliary_info_db = Some(PersistedAuxiliaryInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(PERSISTED_AUXILIARY_INFO_DB_NAME),
                        PERSISTED_AUXILIARY_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_accumulator_db = Some(TransactionAccumulatorDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_ACCUMULATOR_DB_NAME),
                        TRANSACTION_ACCUMULATOR_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_auxiliary_data_db = Some(TransactionAuxiliaryDataDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_AUXILIARY_DATA_DB_NAME),
                        TRANSACTION_AUXILIARY_DATA_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )))
            });
            s.spawn(|_| {
                transaction_db = Some(TransactionDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_DB_NAME),
                        TRANSACTION_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                transaction_info_db = Some(TransactionInfoDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(TRANSACTION_INFO_DB_NAME),
                        TRANSACTION_INFO_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
            s.spawn(|_| {
                write_set_db = Some(WriteSetDb::new(Arc::new(
                    Self::open_rocksdb(
                        ledger_db_folder.join(WRITE_SET_DB_NAME),
                        WRITE_SET_DB_NAME,
                        &rocksdb_configs.ledger_db_config,
                        env,
                        block_cache,
                        readonly,
                    )
                    .unwrap(),
                )));
            });
        });
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L531-548)
```rust
    pub fn write_schemas(&self, schemas: LedgerDbSchemaBatches) -> Result<()> {
        self.write_set_db
            .write_schemas(schemas.write_set_db_batches)?;
        self.transaction_info_db
            .write_schemas(schemas.transaction_info_db_batches)?;
        self.transaction_db
            .write_schemas(schemas.transaction_db_batches)?;
        self.persisted_auxiliary_info_db
            .write_schemas(schemas.persisted_auxiliary_info_db_batches)?;
        self.event_db.write_schemas(schemas.event_db_batches)?;
        self.transaction_accumulator_db
            .write_schemas(schemas.transaction_accumulator_db_batches)?;
        self.transaction_auxiliary_data_db
            .write_schemas(schemas.transaction_auxiliary_data_db_batches)?;
        // TODO: remove this after sharding migration
        self.ledger_metadata_db
            .write_schemas(schemas.ledger_metadata_db_batches)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L448-449)
```rust
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```
