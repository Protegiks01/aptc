# Audit Report

## Title
Consensus Observer Memory Exhaustion via Multiplicative Resource Limit Interaction

## Summary
The consensus observer's memory consumption can exceed available node memory due to independent, non-coordinated limits across multiple data structures. The `max_num_pending_blocks` limit applies separately to three distinct block stores, while `max_network_channel_size` applies independently to two network message channels. These limits compound multiplicatively rather than being bounded by a total memory cap, allowing combined memory usage of 10-15GB or more, causing out-of-memory (OOM) node crashes.

## Finding Description

The consensus observer system manages block data through three independent stores, each enforcing the same `max_num_pending_blocks` limit without coordination: [1](#0-0) 

Each store can independently reach maximum capacity:

1. **BlockPayloadStore** - stores transaction payloads up to the limit: [2](#0-1) 

2. **OrderedBlockStore** - stores ordered blocks up to the limit: [3](#0-2) 

3. **PendingBlockStore** - stores pending blocks up to the limit: [4](#0-3) 

Additionally, two separate network channels buffer messages independently: [5](#0-4) 

**Configuration limits:** [6](#0-5) 

**Block size limits:** [7](#0-6) 

**Memory calculation for production networks (max_num_pending_blocks = 150):**
- BlockPayloadStore: 150 payloads × 6MB = 900MB
- OrderedBlockStore: 150 blocks (Arc-shared metadata, but still significant)
- PendingBlockStore: 150 blocks (Arc-shared metadata)
- Observer channel: 1,000 messages × 6MB = 6GB
- Publisher channel: 1,000 messages × 6MB = 6GB
- **Total: ~13.8GB**

**For test networks (max_num_pending_blocks = 300):**
- Block stores: ~1.8GB
- Network channels: ~12GB
- **Total: ~13.8GB**

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The limits exist per-component but lack global memory coordination.

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:
- **Validator node slowdowns**: Excessive memory consumption causes performance degradation
- **Node crashes**: OOM conditions force validator/fullnode restarts
- **Consensus liveness risk**: Multiple simultaneous node crashes could impact network liveness
- **Availability impact**: Nodes become unavailable during OOM and restart cycles

This meets the High Severity threshold for "Validator node slowdowns" and "Significant protocol violations" when considering the cumulative impact on network stability.

## Likelihood Explanation

**High likelihood** - can occur under normal operating conditions:
- **Legitimate triggers**: High block production rate, network congestion, or temporary publisher delays naturally fill buffers
- **No malicious intent required**: The vulnerability manifests during normal high-load scenarios
- **Compounding effect**: Multiple components reaching capacity simultaneously is realistic during network stress
- **Configuration variance**: Test networks with `max_num_pending_blocks = 300` are even more susceptible

A malicious or compromised validator could deliberately trigger this by rapidly publishing large blocks, but the fundamental issue is the lack of coordinated memory limits.

## Recommendation

Implement a global memory budget that coordinates limits across all consensus observer components:

```rust
pub struct ConsensusObserverConfig {
    // ... existing fields ...
    
    /// Maximum total memory (in bytes) for all consensus observer data structures
    /// Default: 2GB for production, accounts for all stores + network buffers
    pub max_total_memory_bytes: u64,
    
    /// Existing per-component limits now act as sub-limits within the global budget
    pub max_num_pending_blocks: u64,
    pub max_network_channel_size: u64,
}

impl Default for ConsensusObserverConfig {
    fn default() -> Self {
        Self {
            // ... existing defaults ...
            max_total_memory_bytes: 2 * 1024 * 1024 * 1024, // 2GB
            max_num_pending_blocks: 150,
            max_network_channel_size: 1000,
        }
    }
}
```

Add memory tracking to `ObserverBlockData`:

```rust
pub struct ObserverBlockData {
    // ... existing fields ...
    
    // Track estimated memory usage across all stores
    estimated_memory_bytes: Arc<AtomicU64>,
    max_total_memory_bytes: u64,
}
```

Before inserting into any store, check total memory:

```rust
pub fn insert_block_payload(&mut self, block_payload: BlockPayload, verified: bool) {
    let estimated_size = estimate_payload_size(&block_payload);
    
    // Check if adding this payload would exceed global memory limit
    if self.estimated_memory_bytes.load(Ordering::Relaxed) + estimated_size 
        > self.max_total_memory_bytes {
        warn!("Global memory limit reached, dropping payload");
        return;
    }
    
    self.block_payload_store.insert_block_payload(block_payload, verified);
    self.estimated_memory_bytes.fetch_add(estimated_size, Ordering::Relaxed);
}
```

Similarly track and enforce limits for network channels and apply backpressure when approaching global memory limit.

## Proof of Concept

```rust
#[test]
fn test_memory_exhaustion_via_limit_interaction() {
    use aptos_config::config::ConsensusObserverConfig;
    use consensus::consensus_observer::observer::block_data::ObserverBlockData;
    
    // Configure with limits that compound to excessive memory
    let config = ConsensusObserverConfig {
        max_num_pending_blocks: 300, // Test network value
        max_network_channel_size: 1000,
        ..Default::default()
    };
    
    // Create observer block data
    let mut block_data = ObserverBlockData::new_with_root(
        config,
        create_test_ledger_info(),
    );
    
    // Fill all three stores to capacity with 6MB blocks
    let block_size_mb = 6;
    for i in 0..300 {
        // Create large block payload (6MB)
        let payload = create_large_payload(block_size_mb * 1024 * 1024);
        block_data.insert_block_payload(payload, true);
        
        // Create ordered block
        let ordered_block = create_test_ordered_block(i);
        block_data.insert_ordered_block(ordered_block.clone());
        
        // Create pending block
        let pending = create_test_pending_block(ordered_block);
        block_data.insert_pending_block(pending);
    }
    
    // Calculate total memory usage
    let payload_memory = 300 * 6 * 1024 * 1024; // 1.8GB
    let estimated_total = payload_memory; // Conservative estimate, ~1.8GB
    
    // Additionally, network channels can buffer 2000 messages * 6MB = 12GB
    // Total realistic worst case: ~13.8GB
    
    // This exceeds reasonable node memory limits (e.g., 8GB nodes)
    assert!(estimated_total > 1024 * 1024 * 1024, 
        "Memory usage {} exceeds 1GB, demonstrating exhaustion risk", 
        estimated_total);
}
```

**Notes:**
- The vulnerability stems from architectural design where per-component limits compound without global coordination
- This can be triggered both maliciously (compromised validator sending flood) and legitimately (network congestion, high block rate)
- The issue particularly affects test networks with higher `max_num_pending_blocks` values
- Current monitoring only tracks per-store metrics without total memory awareness
- No backpressure mechanism exists to coordinate memory usage across stores and network channels

### Citations

**File:** consensus/src/consensus_observer/observer/block_data.rs (L69-85)
```rust
    fn new_with_root(
        consensus_observer_config: ConsensusObserverConfig,
        root: LedgerInfoWithSignatures,
    ) -> Self {
        // Create the various block stores
        let block_payload_store = BlockPayloadStore::new(consensus_observer_config);
        let ordered_block_store = OrderedBlockStore::new(consensus_observer_config);
        let pending_block_store = PendingBlockStore::new(consensus_observer_config);

        // Create the observer block data
        Self {
            block_payload_store,
            ordered_block_store,
            pending_block_store,
            root,
        }
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L79-95)
```rust
    pub fn insert_block_payload(
        &mut self,
        block_payload: BlockPayload,
        verified_payload_signatures: bool,
    ) {
        // Verify that the number of payloads doesn't exceed the maximum
        let max_num_pending_blocks = self.consensus_observer_config.max_num_pending_blocks as usize;
        if self.block_payloads.lock().len() >= max_num_pending_blocks {
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Exceeded the maximum number of payloads: {:?}. Dropping block: {:?}!",
                    max_num_pending_blocks,
                    block_payload.block(),
                ))
            );
            return; // Drop the block if we've exceeded the maximum
        }
```

**File:** consensus/src/consensus_observer/observer/ordered_blocks.rs (L76-88)
```rust
    pub fn insert_ordered_block(&mut self, observed_ordered_block: ObservedOrderedBlock) {
        // Verify that the number of ordered blocks doesn't exceed the maximum
        let max_num_ordered_blocks = self.consensus_observer_config.max_num_pending_blocks as usize;
        if self.ordered_blocks.len() >= max_num_ordered_blocks {
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Exceeded the maximum number of ordered blocks: {:?}. Dropping block: {:?}.",
                    max_num_ordered_blocks,
                    observed_ordered_block.ordered_block().proof_block_info()
                ))
            );
            return; // Drop the block if we've exceeded the maximum
        }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L152-154)
```rust
        // Perform garbage collection if the store is too large
        self.garbage_collect_pending_blocks();
    }
```

**File:** consensus/src/consensus_observer/network/network_handler.rs (L93-105)
```rust
        // Create a channel for sending consensus observer messages
        let (observer_message_sender, observer_message_receiver) = aptos_channel::new(
            QueueStyle::FIFO,
            consensus_observer_config.max_network_channel_size as usize,
            None,
        );

        // Create a channel for sending consensus publisher messages
        let (publisher_message_sender, publisher_message_receiver) = aptos_channel::new(
            QueueStyle::FIFO,
            consensus_observer_config.max_network_channel_size as usize,
            None,
        );
```

**File:** config/src/config/consensus_observer_config.rs (L63-84)
```rust
impl Default for ConsensusObserverConfig {
    fn default() -> Self {
        Self {
            observer_enabled: false,
            publisher_enabled: false,
            max_network_channel_size: 1000,
            max_parallel_serialization_tasks: num_cpus::get(), // Default to the number of CPUs
            network_request_timeout_ms: 5_000,                 // 5 seconds
            garbage_collection_interval_ms: 60_000,            // 60 seconds
            max_num_pending_blocks: 150, // 150 blocks (sufficient for existing production networks)
            progress_check_interval_ms: 5_000, // 5 seconds
            max_concurrent_subscriptions: 2, // 2 streams should be sufficient
            max_subscription_sync_timeout_ms: 15_000, // 15 seconds
            max_subscription_timeout_ms: 15_000, // 15 seconds
            subscription_peer_change_interval_ms: 180_000, // 3 minutes
            subscription_refresh_interval_ms: 600_000, // 10 minutes
            observer_fallback_duration_ms: 600_000, // 10 minutes
            observer_fallback_startup_period_ms: 60_000, // 60 seconds
            observer_fallback_progress_threshold_ms: 10_000, // 10 seconds
            observer_fallback_sync_lag_threshold_ms: 15_000, // 15 seconds
        }
    }
```

**File:** config/src/config/consensus_config.rs (L220-232)
```rust
impl Default for ConsensusConfig {
    fn default() -> ConsensusConfig {
        ConsensusConfig {
            max_network_channel_size: 1024,
            max_sending_block_txns: MAX_SENDING_BLOCK_TXNS,
            max_sending_block_txns_after_filtering: MAX_SENDING_BLOCK_TXNS_AFTER_FILTERING,
            max_sending_opt_block_txns_after_filtering: MAX_SENDING_OPT_BLOCK_TXNS_AFTER_FILTERING,
            max_sending_block_bytes: 3 * 1024 * 1024, // 3MB
            max_receiving_block_txns: *MAX_RECEIVING_BLOCK_TXNS,
            max_sending_inline_txns: 100,
            max_sending_inline_bytes: 200 * 1024,       // 200 KB
            max_receiving_block_bytes: 6 * 1024 * 1024, // 6MB
            max_pruned_blocks_in_mem: 100,
```
