# Audit Report

## Title
Incomplete Replay-Verify Coverage Allows Undetected Event Corruption in Off-Chain Indexers

## Summary
The `gen_replay_verify_jobs` function creates partial verification jobs that intentionally skip large transaction ranges to optimize performance. These omitted transactions are never verified, allowing corrupted events in those ranges to remain undetected, potentially compromising off-chain indexers that rely on event data integrity.

## Finding Description
The replay-verify system is designed to detect database corruption by re-executing historical transactions and comparing outputs against stored data. However, the job generation logic contains a critical gap in coverage. [1](#0-0) 

When a transaction range exceeds `max_versions_per_range`, the system creates a "partial" job covering only the first `max_versions_per_range` transactions. The remaining transactions in that epoch range are completely omitted from verification jobs, as evidenced by the description message acknowledging "another X versions omitted."

The critical issue is that these omitted transactions are never verified by any subsequent job. The batching iterator moves to the next state snapshot range without creating additional jobs to cover the gap. [2](#0-1) 

Events are verified during replay-verify through two mechanisms:

1. **During backup load** - Events are verified against transaction info event root hashes: [3](#0-2) [4](#0-3) 

2. **During transaction replay** - Outputs are verified through re-execution: [5](#0-4) 

However, if database corruption occurs **after** the initial load (e.g., due to storage media degradation, software bugs, or hardware failures), only the replay-verify process can detect it. When transactions fall into omitted ranges, their corrupted events remain undetected.

## Impact Explanation
This qualifies as **Medium Severity** under the Aptos bug bounty criteria for "State inconsistencies requiring intervention."

Off-chain indexers depend on event data integrity to maintain accurate representations of on-chain state. If events are corrupted in omitted ranges:
- Indexers would process and propagate invalid event data
- Users relying on indexed data would receive incorrect information
- DeFi protocols, wallets, and analytics platforms could make decisions based on corrupted data
- The corruption would persist undetected until manually discovered

While this doesn't directly cause fund loss, it violates the **State Consistency** invariant that "state transitions must be atomic and verifiable."

## Likelihood Explanation
**Moderate likelihood** for the following reasons:

1. **Database corruption is rare but occurs**: Storage media degradation, software bugs during upgrades, or hardware failures can corrupt database contents
2. **Partial jobs are used in production**: The GitHub workflow actively uses `gen-replay-verify-jobs` with `MAX_VERSIONS_PER_RANGE` limits [6](#0-5) 

3. **Large ranges trigger partial jobs**: Epochs with high transaction volume (e.g., during load tests or network stress) will exceed `max_versions_per_range` and create gaps
4. **No alternative verification**: Once partial jobs omit transactions, there's no mechanism to ensure they're verified later

## Recommendation
Implement complete coverage by creating multiple jobs for large ranges instead of creating partial jobs with gaps:

```rust
// In gen_replay_verify_jobs.rs, modify the batching logic:
if end.version - begin.version >= self.max_versions_per_range {
    // Instead of creating ONE partial job, create MULTIPLE complete jobs
    let mut current = begin.version;
    let mut jobs = Vec::new();
    
    while current < end.version {
        let range_end = min(current + self.max_versions_per_range - 1, end.version - 1);
        jobs.push((
            false, // not partial since we're covering everything
            current,
            range_end,
            format!(
                "Replay epoch {} - {}, {} txns starting from version {}.",
                begin.epoch,
                end.epoch - 1,
                range_end - current + 1,
                current,
            )
        ));
        current = range_end + 1;
    }
    
    return jobs;
}
```

Additionally, add validation to ensure complete coverage:
- Track all version ranges added to jobs
- Before returning, verify there are no gaps between `start_version` and `global_end_version`
- Emit warnings or errors if gaps are detected

## Proof of Concept
```rust
// Reproduction scenario:
// 1. Create a mock state with an epoch containing 10,000,000 transactions
// 2. Set max_versions_per_range to 1,000,000  
// 3. Run gen_replay_verify_jobs
// 4. Verify that only versions 0-999,999 are in jobs
// 5. Versions 1,000,000-9,999,999 (90% of transactions) are omitted

#[test]
fn test_partial_jobs_create_coverage_gaps() {
    // Setup test with large epoch range
    let max_versions_per_range = 1_000_000;
    let epoch_start = 0;
    let epoch_end = 10_000_000;
    
    // Run gen_replay_verify_jobs
    // Expected: Multiple jobs covering 0-999,999, 1,000,000-1,999,999, etc.
    // Actual: Single partial job covering 0-999,999
    // Gap: 1,000,000-9,999,999 never verified
    
    // Simulate corruption in version 5,000,000
    // Corruption will not be detected by replay-verify
    // Off-chain indexers will process corrupted events
}
```

**Notes:**
- This vulnerability exists in the current implementation of the replay-verify job generation system
- While the partial verification appears intentional (to skip expensive load test ranges), it creates a security gap where corruption can go undetected
- The fix should maintain performance optimization while ensuring complete coverage through job splitting rather than range omission

### Citations

**File:** storage/db-tool/src/gen_replay_verify_jobs.rs (L93-142)
```rust
            .batching(|it| {
                match it.next() {
                    Some((end, mut begin)) => {
                        if end.version - begin.version >= self.max_versions_per_range {
                            // cut big range short, this hopefully automatically skips load tests
                            let msg = if end.epoch - begin.epoch > 15 {
                                "!!! Need more snapshots !!!"
                            } else {
                                ""
                            };
                            Some((
                                true,
                                begin.version,
                                begin.version + self.max_versions_per_range - 1,
                                format!(
                                    "Partial replay epoch {} - {}, {} txns starting from version {}, another {} versions omitted, until {}. {}",
                                    begin.epoch,
                                    end.epoch - 1,
                                    self.max_versions_per_range,
                                    begin.version,
                                    end.version - begin.version - self.max_versions_per_range,
                                    end.version,
                                    msg
                                )
                            ))
                        } else {
                            while let Some((_prev_end, prev_begin)) = it.peek() {
                                if end.version - prev_begin.version > self.max_versions_per_range {
                                    break;
                                }
                                begin = prev_begin;
                                let _ = it.next();
                            }
                            Some((
                                false,
                                begin.version,
                                end.version - 1,
                                format!(
                                    "Replay epoch {} - {}, {} txns starting from version {}.",
                                    begin.epoch,
                                    end.epoch - 1,
                                    end.version - begin.version,
                                    begin.version,
                                )
                            ))
                        }
                    },
                    None => None,
                }
            }).collect_vec();
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L167-167)
```rust
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
```

**File:** types/src/transaction/mod.rs (L2338-2351)
```rust
        // Verify the events if they exist.
        if let Some(event_lists) = &self.events {
            ensure!(
                event_lists.len() == self.get_num_transactions(),
                "The length of event_lists ({}) does not match the number of transactions ({}).",
                event_lists.len(),
                self.get_num_transactions(),
            );
            event_lists
                .into_par_iter()
                .zip_eq(self.proof.transaction_infos.par_iter())
                .map(|(events, txn_info)| verify_events_against_root_hash(events, txn_info))
                .collect::<Result<Vec<_>>>()?;
        }
```

**File:** execution/executor/src/chunk_executor/mod.rs (L629-650)
```rust
        for (version, txn_out, txn_info, write_set, events) in multizip((
            begin_version..end_version,
            &execution_output.to_commit.transaction_outputs,
            transaction_infos.iter(),
            write_sets.iter(),
            event_vecs.iter(),
        )) {
            if let Err(err) = txn_out.ensure_match_transaction_info(
                version,
                txn_info,
                Some(write_set),
                Some(events),
            ) {
                return if verify_execution_mode.is_lazy_quit() {
                    error!("(Not quitting right away.) {}", err);
                    verify_execution_mode.mark_seen_error();
                    Ok(version + 1)
                } else {
                    Err(err)
                };
            }
        }
```

**File:** .github/workflows/workflow-run-replay-verify.yaml (L152-160)
```yaml
          ./aptos-debugger aptos-db gen-replay-verify-jobs  \
            --metadata-cache-dir ./metadata_cache \
            --command-adapter-config ${{ inputs.BACKUP_CONFIG_TEMPLATE_PATH }} \
            --start-version ${{ inputs.HISTORY_START }} \
            --ranges-to-skip "${{ inputs.RANGES_TO_SKIP }}" \
            --max-versions-per-range ${{ inputs.MAX_VERSIONS_PER_RANGE }} \
            \
            --max-ranges-per-job 16 \
            --output-json-file jobs.json \
```
