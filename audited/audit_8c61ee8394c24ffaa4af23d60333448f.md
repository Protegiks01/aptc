# Audit Report

## Title
Unbounded Memory Growth in State KV Pruner Causes Validator Node Crashes and DoS

## Summary
The `StateKvMetadataPruner::prune()` and `StateKvShardPruner::prune()` methods accumulate all stale state value deletions within a batch into a single unbounded `SchemaBatch` before writing to the database. During high-throughput periods or sustained load, this can cause millions of delete operations to be buffered in memory, leading to out-of-memory (OOM) crashes, validator node slowdowns, and potential network-wide availability issues.

## Finding Description

The state KV pruner is responsible for removing stale state values that fall outside the configured pruning window. The pruning process operates in batches controlled by the `batch_size` configuration parameter (default: 5,000 versions). [1](#0-0) 

In the non-sharded path, the implementation iterates through all stale state value indices between `current_progress` and `target_version`, adding delete operations to a single `SchemaBatch` without any internal size limits or progress checkpointing. [2](#0-1) 

The `SchemaBatch` is simply a `HashMap` with no size constraints, allowing unbounded memory growth.

**Vulnerability Mechanism:**

1. Each state key update creates a stale index entry when the old value becomes eligible for pruning [3](#0-2) 

2. During high transaction throughput (e.g., NFT mints, airdrops, DeFi activity), thousands of state keys can be updated per version

3. With the default `batch_size` of 5,000 versions, if there are 10,000 state updates per version, the pruner attempts to buffer **50 million delete operations** in a single batch [4](#0-3) 

4. Each delete operation requires memory for the encoded key and metadata, potentially consuming gigabytes of RAM

5. Progress is only persisted **after** the entire batch completes, so a crash mid-batch loses all progress and forces re-execution

**Similar Issue in Sharded Path:**

The `StateKvShardPruner` exhibits the same vulnerability: [5](#0-4) 

**Attack Scenario:**

An attacker (or natural high load) creates sustained state updates:
1. Deploy contracts or send transactions that update many state keys
2. Continue over thousands of versions to build up stale entries
3. When pruning activates, the pruner attempts to load millions of deletions into memory
4. Validator nodes experience memory exhaustion and crash
5. If multiple validators crash simultaneously, network liveness is impacted

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria:

- **Validator node slowdowns**: Memory pressure causes degraded performance during pruning operations
- **Validator node crashes**: Out-of-memory errors force node restarts, causing temporary validator unavailability
- **Potential network liveness issues**: If many validators crash during coordinated pruning windows, the network could experience reduced block production capacity

While this doesn't directly cause consensus violations or funds loss, it represents a clear availability attack vector that can degrade network performance and reliability. The issue violates the documented invariant: **"Resource Limits: All operations must respect gas, storage, and computational limits"** - the pruner fails to respect memory limits when batching deletions.

## Likelihood Explanation

**High Likelihood** - This issue can manifest in two scenarios:

1. **Natural Occurrence**: During legitimate high-load periods (mainnet stress tests, popular NFT drops, major DeFi events), transaction throughput naturally creates many state updates. Mainnet regularly processes thousands of TPS, each touching multiple state keys.

2. **Deliberate Attack**: An adversary can intentionally trigger this by:
   - Deploying contracts that perform many state writes per transaction
   - Sustaining this activity over the pruning window
   - Waiting for stale entries to accumulate
   - Cost: Requires paying gas for transactions, but feasible for a well-resourced attacker

The vulnerability requires no privileged access and can occur during normal network operation, making it a realistic threat to validator stability.

## Recommendation

Implement internal batching and progress checkpointing within the `prune()` methods:

**Fix Strategy:**
1. Add a configurable internal batch size limit (e.g., 10,000 deletions per sub-batch)
2. Write intermediate progress checkpoints after each sub-batch
3. Flush the `SchemaBatch` when it reaches the size limit
4. Resume from the last checkpoint on failure

**Suggested Code Fix:**

```rust
pub(in crate::pruner) fn prune(
    &self,
    current_progress: Version,
    target_version: Version,
) -> Result<()> {
    const INTERNAL_BATCH_SIZE: usize = 10_000;
    let mut batch = SchemaBatch::new();
    let mut deletion_count = 0;
    let mut last_processed_version = current_progress;

    let mut iter = self
        .state_kv_db
        .metadata_db()
        .iter::<StaleStateValueIndexSchema>()?;
    iter.seek(&current_progress)?;
    
    for item in iter {
        let (index, _) = item?;
        if index.stale_since_version > target_version {
            break;
        }
        
        batch.delete::<StaleStateValueIndexSchema>(&index)?;
        batch.delete::<StateValueSchema>(&(index.state_key, index.version))?;
        deletion_count += 1;
        last_processed_version = index.stale_since_version;
        
        // Flush batch when size limit reached
        if deletion_count >= INTERNAL_BATCH_SIZE {
            batch.put::<DbMetadataSchema>(
                &DbMetadataKey::StateKvPrunerProgress,
                &DbMetadataValue::Version(last_processed_version),
            )?;
            self.state_kv_db.metadata_db().write_schemas(batch)?;
            
            // Reset for next sub-batch
            batch = SchemaBatch::new();
            deletion_count = 0;
        }
    }
    
    // Write final batch and progress
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::StateKvPrunerProgress,
        &DbMetadataValue::Version(target_version),
    )?;
    self.state_kv_db.metadata_db().write_schemas(batch)
}
```

Apply similar fixes to `StateKvShardPruner::prune()`.

## Proof of Concept

```rust
#[test]
fn test_pruner_memory_exhaustion() {
    use aptos_temppath::TempPath;
    use aptos_types::state_store::state_key::StateKey;
    use aptos_crypto::HashValue;
    
    // Setup: Create a test database with sharding disabled
    let tmpdir = TempPath::new();
    let config = RocksdbConfigs::default();
    let state_kv_db = Arc::new(StateKvDb::new(&tmpdir, config, false, 1).unwrap());
    
    // Simulate high-load scenario: Create 100,000 stale entries per version
    // across 5,000 versions = 500 million stale entries
    const ENTRIES_PER_VERSION: usize = 100_000;
    const NUM_VERSIONS: usize = 5_000;
    
    let mut batch = SchemaBatch::new();
    for version in 0..NUM_VERSIONS {
        for i in 0..ENTRIES_PER_VERSION {
            let state_key = StateKey::raw(format!("key_{}_{}", version, i).as_bytes());
            let stale_index = StaleStateValueIndex {
                stale_since_version: version as u64,
                version: version as u64,
                state_key: state_key.clone(),
            };
            
            // Add to index (simulating what happens during normal operation)
            batch.put::<StaleStateValueIndexSchema>(&stale_index, &())?;
            batch.put::<StateValueSchema>(
                &(state_key, version as u64),
                &StateValue::new_legacy(vec![0u8; 100]),
            )?;
        }
        
        // Commit every 1000 versions to avoid OOM during setup
        if version % 1000 == 0 {
            state_kv_db.metadata_db().write_schemas(batch)?;
            batch = SchemaBatch::new();
        }
    }
    state_kv_db.metadata_db().write_schemas(batch)?;
    
    // Now attempt to prune - this will try to load 500M deletions into one batch
    let pruner = StateKvMetadataPruner::new(state_kv_db);
    
    // Monitor memory usage before/after
    let mem_before = get_process_memory_usage();
    
    // This should cause excessive memory growth or OOM
    let result = pruner.prune(0, NUM_VERSIONS as u64);
    
    let mem_after = get_process_memory_usage();
    let mem_delta_gb = (mem_after - mem_before) as f64 / 1024.0 / 1024.0 / 1024.0;
    
    println!("Memory growth during pruning: {:.2} GB", mem_delta_gb);
    assert!(result.is_err() || mem_delta_gb > 5.0, 
            "Should either fail or consume excessive memory");
}
```

**Notes:**
- The PoC demonstrates that without internal batching, the pruner attempts to buffer all deletions in memory
- In production, this manifests as gradual memory growth during pruning windows
- Validators with limited RAM (common in cloud deployments) are most vulnerable
- The issue compounds when multiple pruners run concurrently (ledger, state merkle, epoch snapshot)

### Citations

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L28-73)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        if self.state_kv_db.enabled_sharding() {
            let num_shards = self.state_kv_db.num_shards();
            // NOTE: This can be done in parallel if it becomes the bottleneck.
            for shard_id in 0..num_shards {
                let mut iter = self
                    .state_kv_db
                    .db_shard(shard_id)
                    .iter::<StaleStateValueIndexByKeyHashSchema>()?;
                iter.seek(&current_progress)?;
                for item in iter {
                    let (index, _) = item?;
                    if index.stale_since_version > target_version {
                        break;
                    }
                }
            }
        } else {
            let mut iter = self
                .state_kv_db
                .metadata_db()
                .iter::<StaleStateValueIndexSchema>()?;
            iter.seek(&current_progress)?;
            for item in iter {
                let (index, _) = item?;
                if index.stale_since_version > target_version {
                    break;
                }
                batch.delete::<StaleStateValueIndexSchema>(&index)?;
                batch.delete::<StateValueSchema>(&(index.state_key, index.version))?;
            }
        }

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        self.state_kv_db.metadata_db().write_schemas(batch)
    }
```

**File:** storage/schemadb/src/batch.rs (L127-133)
```rust
/// `SchemaBatch` holds a collection of updates that can be applied to a DB atomically. The updates
/// will be applied in the order in which they are added to the `SchemaBatch`.
#[derive(Debug, Default)]
pub struct SchemaBatch {
    rows: DropHelper<HashMap<ColumnFamilyName, Vec<WriteOp>>>,
    stats: SampledBatchStats,
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L970-980)
```rust
                if old_entry.is_occupied() {
                    // The value at the old version can be pruned once the pruning window hits
                    // this `version`.
                    Self::put_state_kv_index(
                        batch,
                        enable_sharding,
                        version,
                        old_entry.expect_value_version(),
                        key,
                    )
                }
```

**File:** config/src/config/storage_config.rs (L387-395)
```rust
impl Default for LedgerPrunerConfig {
    fn default() -> Self {
        LedgerPrunerConfig {
            enable: true,
            prune_window: 90_000_000,
            batch_size: 5_000,
            user_pruning_window_offset: 200_000,
        }
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L47-72)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
            &DbMetadataValue::Version(target_version),
        )?;

        self.db_shard.write_schemas(batch)
    }
```
