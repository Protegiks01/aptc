# Audit Report

## Title
AtomicUsize Underflow in SyncMutexCache Due to Concurrent Operations on Different Cache Indices

## Summary
The `SyncMutexCache` implementation contains a race condition where concurrent operations on different cache indices can cause the global `size` counter to underflow, wrapping to an extremely large value (near `usize::MAX`). This makes the cache believe it has consumed massive memory, potentially causing denial of service through continuous eviction attempts and rejection of new entries.

## Finding Description

The vulnerability exists in the interplay between per-slot mutex locks and the global atomic size counter in `SyncMutexCache`: [1](#0-0) 

The critical issue is in the `insert_with_size()` and `evict()` functions: [2](#0-1) [3](#0-2) 

**The Race Condition:**

While operations on the **same** cache index are protected by `self.cache[index].lock()`, operations on **different** indices can execute concurrently. The problem arises because:

1. Each cache slot has its own mutex: `self.cache[index]`
2. All slots share a single global atomic counter: `self.size`
3. A thread determines "how much to subtract" while holding its slot's mutex
4. But between reading the entry and executing `fetch_sub()`, other threads operating on different indices can modify the global counter
5. `AtomicUsize::fetch_sub()` uses wrapping semantics - it will wrap on underflow

**Concrete Attack Scenario:**

Initial state:
- `cache[0]` = entry with size 100
- `cache[1]` through `cache[9]` = entries with total size 50  
- `total_size = 150`

Thread A: `insert_with_size(0, val, 200)` on index 0
Thread B-K: Concurrent evictions on indices 1-9

Timeline:
1. Thread A locks `cache[0]`, reads previous entry (size=100)
2. Threads B-K evict all entries from indices 1-9, reducing `total_size` by 50 → `total_size = 100`
3. Thread A executes `fetch_sub(100)` → `total_size = 0`
4. More evictions happen while Thread A is between operations
5. Thread A's slot gets evicted by another thread → `total_size` becomes negative, wrapping to `usize::MAX - X`

When `total_size` underflows, cache behavior becomes pathological: [4](#0-3) [5](#0-4) 

With `total_size ≈ usize::MAX`:
- Line 93: Eviction triggers on EVERY insertion
- Line 118: Eviction loop runs continuously trying to reduce the "huge" size
- The cache becomes effectively unusable

**Why This Differs from the Defensive Pattern:**

The Aptos codebase shows awareness of this issue in other locations: [6](#0-5) 

This code explicitly checks `count > current` before calling `fetch_sub()` to prevent underflow, but `SyncMutexCache` lacks this protection.

## Impact Explanation

**Current Impact: LOW to NONE**
Based on codebase analysis, `aptos-in-memory-cache` is currently only used in test code: [7](#0-6) 

No production usage was found in consensus, VM, storage, governance, or other critical Aptos components.

**Potential Impact if Used in Production: HIGH**
If this cache were deployed in validator nodes or critical services:
- **Service Degradation**: Continuous eviction attempts would consume CPU
- **Cache Denial of Service**: Cache becomes non-functional due to size overflow
- **Node Slowdown**: Performance impact on any service relying on the cache

This would qualify as **High Severity** per Aptos bug bounty criteria: "Validator node slowdowns" or "API crashes."

However, **the specific scenario described in the security question (concurrent operations on the SAME key) does NOT cause the vulnerability** because the mutex protects same-key operations. The vulnerability only manifests with concurrent operations on DIFFERENT keys/indices.

## Likelihood Explanation

**Current Likelihood: NONE** - The cache is not used in production code.

**If Deployed: MEDIUM** - Requires:
- High concurrency (multiple threads operating simultaneously)
- Specific timing where many evictions occur between an insert's read and fetch_sub
- Cache under heavy load

The race window is narrow but exploitable in high-throughput scenarios typical of blockchain validators.

## Recommendation

Add defensive checks before `fetch_sub()` operations, following the pattern established elsewhere in the codebase:

```rust
fn insert_with_size(&self, key: usize, value: T, size_in_bytes: usize) -> usize {
    let index = key % self.capacity;
    let mut lock = self.cache[index].lock();

    // Update cache size with underflow protection
    if let Some(prev) = &*lock {
        let current_size = self.size.load(Ordering::Relaxed);
        if prev.size_in_bytes > current_size {
            // Defensive: set to 0 rather than underflow
            self.size.store(0, Ordering::Relaxed);
        } else {
            self.size.fetch_sub(prev.size_in_bytes, Ordering::Relaxed);
        }
    }

    self.size.fetch_add(size_in_bytes, Ordering::Relaxed);
    *lock = Some(SizedCacheEntry {
        key,
        value,
        size_in_bytes,
    });

    index
}
```

Apply similar protection to `evict()`.

Alternatively, use stronger synchronization (e.g., a global RwLock) if the performance trade-off is acceptable.

## Proof of Concept

```rust
use aptos_in_memory_cache::caches::SyncMutexCache;
use aptos_in_memory_cache::SizedCache;
use std::sync::Arc;
use std::thread;

#[test]
fn test_size_underflow_race() {
    let cache = Arc::new(SyncMutexCache::<Vec<u8>>::with_capacity(100));
    
    // Populate cache with entries totaling 1000 bytes
    for i in 0..10 {
        cache.insert_with_size(i, vec![0u8; 100], 100);
    }
    
    assert_eq!(cache.total_size(), 1000);
    
    let cache_clone = cache.clone();
    
    // Thread that inserts large entry at index 0
    let insert_thread = thread::spawn(move || {
        for _ in 0..100 {
            cache_clone.insert_with_size(0, vec![0u8; 500], 500);
            thread::yield_now(); // Increase race window
        }
    });
    
    // Threads that evict entries from other indices
    let mut evict_threads = vec![];
    for idx in 1..10 {
        let cache_clone = cache.clone();
        evict_threads.push(thread::spawn(move || {
            for _ in 0..100 {
                cache_clone.evict(&idx);
                thread::yield_now();
            }
        }));
    }
    
    insert_thread.join().unwrap();
    for t in evict_threads {
        t.join().unwrap();
    }
    
    let final_size = cache.total_size();
    
    // If underflow occurred, size will be enormous
    if final_size > 1_000_000_000 {
        println!("UNDERFLOW DETECTED: size = {}", final_size);
        println!("This is approximately usize::MAX - {}", usize::MAX - final_size);
        panic!("Size counter underflowed!");
    }
}
```

**Note:** This PoC has a narrow race window and may require many iterations to trigger. Use thread sanitizers or add explicit delays to increase reproducibility.

---

## Notes

The security question specifically asks about "concurrent operations on the **same key**," but same-key operations are protected by the per-slot mutex and do NOT cause this vulnerability. The actual vulnerability requires concurrent operations on **different** cache indices (different keys that may hash to different slots).

Additionally, this cache implementation is currently only present in test code and has no production usage in critical Aptos components (consensus, VM, storage, governance, or staking). Therefore, while the technical race condition exists, it poses **no current security risk** to the Aptos blockchain.

If this cache were to be deployed in production services, the issue should be addressed to prevent potential service degradation and denial of service scenarios.

### Citations

**File:** crates/aptos-in-memory-cache/src/caches/sync_mutex.rs (L70-74)
```rust
pub struct SyncMutexCache<T: Send + Sync + Clone> {
    cache: Box<[CacheEntryLock<T>]>,
    capacity: usize,
    size: AtomicUsize,
}
```

**File:** crates/aptos-in-memory-cache/src/caches/sync_mutex.rs (L114-132)
```rust
    fn insert_with_size(&self, key: usize, value: T, size_in_bytes: usize) -> usize {
        let index = key % self.capacity;
        let mut lock = self.cache[index].lock();

        // Update cache size
        if let Some(prev) = &*lock {
            self.size.fetch_sub(prev.size_in_bytes, Ordering::Relaxed);
        }

        // Update cache entry
        self.size.fetch_add(size_in_bytes, Ordering::Relaxed);
        *lock = Some(SizedCacheEntry {
            key,
            value,
            size_in_bytes,
        });

        index
    }
```

**File:** crates/aptos-in-memory-cache/src/caches/sync_mutex.rs (L134-144)
```rust
    fn evict(&self, key: &usize) -> Option<CacheEntry<T>> {
        let index = *key % self.capacity;
        let mut lock = self.cache[index].lock();

        // Update the cache size and set the value at key to none
        if let Some(prev) = lock.take() {
            self.size.fetch_sub(prev.size_in_bytes, Ordering::Relaxed);
            return Some(prev);
        }
        None
    }
```

**File:** crates/aptos-in-memory-cache/tests/common/mod.rs (L90-96)
```rust
    fn insert(&self, key: usize, value: NotATransaction) {
        let size = value.get_size();
        self.cache.insert_with_size(key, value, size);
        if self.cache.total_size() >= self.metadata.eviction_trigger_size_in_bytes {
            self.eviction_start.store(key, Ordering::Relaxed);
            self.insert_notify.notify_one();
        }
```

**File:** crates/aptos-in-memory-cache/tests/common/mod.rs (L117-126)
```rust
            // Evict entries until the cache size is below the target size
            while cache.total_size() > metadata.target_size_in_bytes {
                if let Some(value) = cache.evict(&eviction_index) {
                    if value.key > watermark_value {
                        cache.insert_with_size(value.key, value.value.clone(), value.size_in_bytes);
                        break;
                    }
                }
                eviction_index = (eviction_index + 1) % metadata.capacity;
            }
```

**File:** crates/transaction-generator-lib/src/workflow_delegator.rs (L238-250)
```rust
    fn reduce_txn_count(&mut self, count: usize) {
        match self {
            StageSwitchCondition::WhenPoolBecomesEmpty(_) => {},
            StageSwitchCondition::MaxTransactions(max) => {
                let current = max.load(Ordering::Relaxed);
                if count > current {
                    max.store(0, Ordering::Relaxed);
                } else {
                    max.fetch_sub(count, Ordering::Relaxed);
                }
            },
        }
    }
```

**File:** crates/aptos-in-memory-cache/Cargo.toml (L1-5)
```text
[package]
name = "aptos-in-memory-cache"
description = "In-memory cache"
version = "0.1.0"

```
