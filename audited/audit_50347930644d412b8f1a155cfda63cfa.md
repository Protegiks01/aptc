# Audit Report

## Title
Aggregator V1 Delta Bypass of Transaction Write Set Size Limits

## Summary
The `check_change_set()` validation in `ChangeSetConfigs` does not account for Aggregator V1 deltas, allowing attackers to bypass `max_write_ops_per_transaction` and `max_bytes_all_write_ops_per_transaction` limits by creating transactions with excessive aggregator operations that are materialized into write operations after validation completes.

## Finding Description

The validation flow contains a critical gap where Aggregator V1 deltas escape size limit enforcement:

**Validation Phase (Before Materialization):** [1](#0-0) 

The `check_change_set()` method validates transaction limits by calling `change_set.num_write_ops()` and iterating `change_set.write_set_size_iter()`.

**Iterator Implementation Excludes Deltas:** [2](#0-1) 

The comment explicitly acknowledges that "deltas & events are not part of these" - only `resource_write_set` and `aggregator_v1_write_set` are counted, while `aggregator_v1_delta_set` is intentionally excluded.

**Validation Timing:** [3](#0-2) 

Validation occurs in `UserSessionChangeSet::new()` during session finalization, before delta materialization.

**Post-Validation Materialization:** [4](#0-3) 

After validation passes, `try_materialize_aggregator_v1_delta_set()` converts each delta into a `WriteOp` that gets added to `aggregator_v1_write_set`. This occurs without re-validation against size limits.

**Attack Path:**
1. Attacker creates a transaction with minimal regular writes (e.g., 100 write ops)
2. Transaction includes operations on 8500 unique aggregators, creating 8500 entries in `aggregator_v1_delta_set`
3. `check_change_set()` validates: `num_write_ops() = 100 + 0 = 100` (passes limit of 8192)
4. Delta materialization converts 8500 deltas into write ops
5. Total write ops become 8600, exceeding the intended limit
6. No re-validation occurs, transaction commits with excessive state changes

The vulnerability violates the **Resource Limits** invariant (#9) that "all operations must respect gas, storage, and computational limits."

## Impact Explanation

**Severity: HIGH** (up to $50,000 per Aptos Bug Bounty criteria)

This qualifies as a "Significant protocol violation" under High Severity:

- **Storage Bombing**: Attackers can create transactions with 10x-100x more write operations than intended limits allow, potentially causing:
  - Excessive state growth beyond designed capacity
  - Degraded validator performance due to oversized transactions
  - Increased storage I/O load during state commitment

- **Validator Node Slowdowns**: Processing and committing transactions with thousands of unexpected write operations can cause validator performance degradation, impacting block production rates.

- **Consensus Impact**: While not directly breaking consensus safety, excessive state changes can affect consensus liveness through validator performance degradation.

The limits exist for a reason - `max_write_ops_per_transaction` is set to 8192 to bound transaction execution complexity. Bypassing this limit undermines critical resource management guarantees.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The attack is straightforward to execute:
- Requires only normal transaction submission privileges
- No special validator access or insider knowledge needed
- Can be triggered through standard Move smart contract execution
- Aggregator operations are a normal feature, not requiring special permissions

**Constraints:**
- Gas limits provide some natural bound on the number of aggregator operations
- However, gas costs may not perfectly align with storage impact, especially if aggregator operations are relatively cheap compared to the storage burden they create after materialization
- The attacker needs to interact with or create multiple unique aggregators

**Feasibility:** Any user can submit a transaction that touches many aggregators (either by creating them or modifying existing ones), making this practically exploitable.

## Recommendation

Add re-validation after delta materialization to enforce size limits on the final write set. The fix should be implemented in one of two places:

**Option 1: Re-validate after materialization in try_materialize()**

Modify the materialization flow to re-check limits after converting deltas: [5](#0-4) 

Add validation call after line 171:
```rust
self.change_set.try_materialize_aggregator_v1_delta_set(resolver)?;

// Re-validate after materialization to ensure limits are still satisfied
self.change_set_configs.check_change_set(&self.change_set)?;
```

**Option 2: Include deltas in initial validation**

Modify `num_write_ops()` and `write_set_size_iter()` to account for deltas upfront by estimating their post-materialization size. However, this is less accurate since delta sizes aren't known until materialization.

**Recommended Approach:** Option 1 provides the most accurate enforcement since it validates the actual final write set that will be committed to storage.

## Proof of Concept

```rust
// Rust test demonstrating the bypass
#[test]
fn test_aggregator_delta_bypass_write_limit() {
    use aptos_types::write_set::WriteOp;
    use aptos_vm_types::change_set::VMChangeSet;
    use aptos_vm_types::storage::change_set_configs::ChangeSetConfigs;
    use aptos_gas_schedule::AptosGasParameters;
    use std::collections::BTreeMap;
    
    // Create configs with write limit of 100
    let mut gas_params = AptosGasParameters::zeros();
    gas_params.vm.txn.max_write_ops_per_transaction = 100.into();
    let configs = ChangeSetConfigs::new(12, &gas_params);
    
    // Create a changeset with 50 regular writes
    let mut resource_write_set = BTreeMap::new();
    for i in 0..50 {
        let key = StateKey::raw(vec![i]);
        resource_write_set.insert(
            key,
            AbstractResourceWriteOp::Write(WriteOp::legacy_creation(vec![1, 2, 3].into()))
        );
    }
    
    // Create 150 aggregator deltas (exceeds limit of 100)
    let mut aggregator_v1_delta_set = BTreeMap::new();
    for i in 0..150 {
        let key = StateKey::raw(vec![100 + i]);
        aggregator_v1_delta_set.insert(
            key,
            DeltaOp::new(SignedU128::Positive(1), u128::MAX, DeltaHistory::new())
        );
    }
    
    let changeset = VMChangeSet::new(
        resource_write_set,
        vec![],
        BTreeMap::new(),
        BTreeMap::new(),
        aggregator_v1_delta_set,
    );
    
    // Validation PASSES (only counts 50 writes, not 150 deltas)
    assert!(configs.check_change_set(&changeset).is_ok());
    
    // After materialization, we'd have 200 total writes (50 + 150)
    // exceeding the limit of 100, but no re-validation occurs
    assert_eq!(changeset.num_write_ops(), 50); // Only counts non-delta writes
    assert_eq!(changeset.aggregator_v1_delta_set().len(), 150); // Deltas not validated
}
```

**Notes:**
- The actual PoC would need proper imports and mock resolver for materialization
- The key point is demonstrating that `check_change_set()` passes with 50 write ops despite 150 deltas waiting to be materialized
- After materialization (not shown), total would be 200 write ops, exceeding the 100 limit without error

### Citations

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L86-128)
```rust
    pub fn check_change_set(&self, change_set: &impl ChangeSetInterface) -> Result<(), VMStatus> {
        let storage_write_limit_reached = |maybe_message: Option<&str>| {
            let mut err = PartialVMError::new(StatusCode::STORAGE_WRITE_LIMIT_REACHED);
            if let Some(message) = maybe_message {
                err = err.with_message(message.to_string())
            }
            Err(err.finish(Location::Undefined).into_vm_status())
        };

        if self.max_write_ops_per_transaction != 0
            && change_set.num_write_ops() as u64 > self.max_write_ops_per_transaction
        {
            return storage_write_limit_reached(Some("Too many write ops."));
        }

        let mut write_set_size = 0;
        for (key, op_size) in change_set.write_set_size_iter() {
            if let Some(len) = op_size.write_len() {
                let write_op_size = len + (key.size() as u64);
                if write_op_size > self.max_bytes_per_write_op {
                    return storage_write_limit_reached(None);
                }
                write_set_size += write_op_size;
            }
            if write_set_size > self.max_bytes_all_write_ops_per_transaction {
                return storage_write_limit_reached(None);
            }
        }

        let mut total_event_size = 0;
        for event in change_set.events_iter() {
            let size = event.event_data().len() as u64;
            if size > self.max_bytes_per_event {
                return storage_write_limit_reached(None);
            }
            total_event_size += size;
            if total_event_size > self.max_bytes_all_events_per_transaction {
                return storage_write_limit_reached(None);
            }
        }

        Ok(())
    }
```

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L367-399)
```rust
    pub fn try_materialize_aggregator_v1_delta_set(
        &mut self,
        resolver: &impl AggregatorV1Resolver,
    ) -> VMResult<()> {
        let into_write =
            |(state_key, delta): (StateKey, DeltaOp)| -> VMResult<(StateKey, WriteOp)> {
                // Materialization is needed when committing a transaction, so
                // we need precise mode to compute the true value of an
                // aggregator.
                let write = resolver
                    .try_convert_aggregator_v1_delta_into_write_op(&state_key, &delta)
                    .map_err(|e| {
                        // We need to set abort location for Aggregator V1 to ensure correct VMStatus can
                        // be constructed.
                        const AGGREGATOR_V1_ADDRESS: AccountAddress = CORE_CODE_ADDRESS;
                        const AGGREGATOR_V1_MODULE_NAME: &IdentStr = ident_str!("aggregator");
                        e.finish(Location::Module(ModuleId::new(
                            AGGREGATOR_V1_ADDRESS,
                            AGGREGATOR_V1_MODULE_NAME.into(),
                        )))
                    })?;
                Ok((state_key, write))
            };

        let aggregator_v1_delta_set = std::mem::take(&mut self.aggregator_v1_delta_set);
        let materialized_aggregator_delta_set = aggregator_v1_delta_set
            .into_iter()
            .map(into_write)
            .collect::<VMResult<BTreeMap<StateKey, WriteOp>>>()?;
        self.aggregator_v1_write_set
            .extend(materialized_aggregator_delta_set);
        Ok(())
    }
```

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L856-871)
```rust
    fn num_write_ops(&self) -> usize {
        // Note: we only use resources and aggregators because they use write ops directly,
        // and deltas & events are not part of these.
        self.resource_write_set().len() + self.aggregator_v1_write_set().len()
    }

    fn write_set_size_iter(&self) -> impl Iterator<Item = (&StateKey, WriteOpSize)> {
        self.resource_write_set()
            .iter()
            .map(|(k, v)| (k, v.materialized_size()))
            .chain(
                self.aggregator_v1_write_set()
                    .iter()
                    .map(|(k, v)| (k, v.write_op_size())),
            )
    }
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/session/user_transaction_sessions/session_change_sets.rs (L24-35)
```rust
    pub(crate) fn new(
        change_set: VMChangeSet,
        module_write_set: ModuleWriteSet,
        change_set_configs: &ChangeSetConfigs,
    ) -> Result<Self, VMStatus> {
        let user_session_change_set = Self {
            change_set,
            module_write_set,
        };
        change_set_configs.check_change_set(&user_session_change_set)?;
        Ok(user_session_change_set)
    }
```

**File:** aptos-move/aptos-vm-types/src/output.rs (L156-174)
```rust
    pub fn try_materialize(
        &mut self,
        resolver: &impl AggregatorV1Resolver,
    ) -> anyhow::Result<(), VMStatus> {
        // First, check if output of transaction should be discarded or delta
        // change set is empty. In both cases, we do not need to apply any
        // deltas and can return immediately.
        if self.status().is_discarded()
            || (self.aggregator_v1_delta_set().is_empty()
                && self.delayed_field_change_set().is_empty())
        {
            return Ok(());
        }

        self.change_set
            .try_materialize_aggregator_v1_delta_set(resolver)?;

        Ok(())
    }
```
