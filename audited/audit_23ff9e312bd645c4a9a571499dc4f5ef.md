# Audit Report

## Title
Panic-Based Denial of Service via Concurrent Ledger Update Race Condition in Block Pipeline

## Summary
A race condition in the consensus block pipeline allows duplicate ledger update tasks to execute concurrently for the same block, causing a panic when both tasks attempt to set the same `OnceCell` in `PartialStateComputeResult`. This crashes validator nodes and causes loss of network liveness.

## Finding Description

The vulnerability exists at the intersection of three design flaws:

**1. Non-Idempotent Pipeline Task Spawning:**
When `insert_block()` is called for a block, it spawns pipeline tasks including `ledger_update_fut`. The code comments acknowledge that `insert_block` may be called multiple times for the same block and considers it "idempotent". [1](#0-0) 

However, pipeline task spawning is NOT idempotent. If `insert_block()` is called concurrently for the same block ID by multiple threads, both create separate `PipelinedBlock` objects and call `build_for_consensus()`, which spawns independent task sets. [2](#0-1) 

**2. Ledger Update Tasks Lack Abort Handles:**
The `ledger_update_fut` is spawned without an abort handle, meaning it will NOT be cancelled when the duplicate `PipelinedBlock` is dropped. [3](#0-2) 

While other tasks have abort handles registered (via `Some(&mut abort_handles)`), ledger_update is spawned with `None`, making it unabortable. When the duplicate PipelinedBlock is dropped, its Drop implementation only aborts tasks with registered handles. [4](#0-3) 

**3. Concurrent Execution Reaches Panic-Prone Code:**
Both ledger_update tasks eventually call `BlockExecutor::ledger_update()`, which only acquires a read lock (allowing concurrent access). [5](#0-4) 

Both threads retrieve the same `Block` from the executor's block tree and obtain a reference to the same `PartialStateComputeResult`. A TOCTOU race exists at the completeness check: [6](#0-5) 

Both threads pass this check, then both attempt to set the `state_checkpoint_output` OnceCell: [7](#0-6) 

The `OnceCell::set()` method returns `Err` if the cell is already set. The `.expect()` call panics on this error, crashing the validator node.

**Attack Sequence:**

1. Attacker sends duplicate block proposals through multiple network paths or exploits natural race conditions between proposal receipt and sync
2. Two threads concurrently call `insert_block(block_X)`
3. Both pass the duplicate check before the write lock (TOCTOU)
4. Both spawn ledger_update tasks (no abort handles)
5. One PipelinedBlock gets inserted, the other is dropped (but its tasks continue)
6. Both ledger_update tasks call `executor.ledger_update(block_id_X, parent_id)`
7. Both acquire read locks on executor.inner (concurrent access allowed)
8. Both retrieve the same Block and PartialStateComputeResult
9. Both pass the incomplete result check (TOCTOU race)
10. Both call `set_state_checkpoint_output()` on the same OnceCell
11. Second call triggers panic via `.expect()`, crashing the validator

## Impact Explanation

**Severity: Critical**

This vulnerability allows an attacker to crash validator nodes, causing loss of liveness. According to Aptos bug bounty criteria, this falls under Critical Severity:
- **Total loss of liveness/network availability**: If multiple validators are crashed simultaneously, the network cannot make progress
- **Validator node crashes**: Direct impact on network availability

Each crashed validator must be manually restarted. If an attacker can continuously trigger this vulnerability, they can prevent validators from participating in consensus, potentially bringing the network to a halt if enough validators (>1/3) are affected.

The vulnerability breaks the **availability invariant** - the system should remain live and operational under Byzantine conditions, but a simple network-level race condition can cause deterministic crashes.

## Likelihood Explanation

**Likelihood: Medium-to-High**

The vulnerability is realistic and exploitable:

1. **Natural occurrence**: The code design explicitly allows concurrent `insert_block()` calls for the same block (acknowledged as "idempotent" behavior)
2. **Multiple trigger paths**: Block proposals can arrive via different paths (direct proposal, sync, network message duplication)
3. **No authentication required**: Any network peer can send block messages
4. **Deterministic crash**: Once the race is triggered, the panic is guaranteed
5. **Low complexity**: No sophisticated attack needed - simple message duplication or timing manipulation suffices

The main complexity is timing the concurrent calls, but network-level race conditions occur naturally in distributed systems, making this exploitable even without active malicious intent.

## Recommendation

**Fix 1: Register Abort Handle for Ledger Update Tasks**

Modify `build_internal()` to register abort handles for ledger_update tasks:

```rust
let ledger_update_fut = spawn_shared_fut(
    Self::ledger_update(
        rand_check_fut.clone(),
        execute_fut.clone(),
        parent.ledger_update_fut.clone(),
        self.executor.clone(),
        block.clone(),
    ),
    Some(&mut abort_handles),  // Changed from None
);
```

**Fix 2: Add Execution Lock to ledger_update**

Protect `ledger_update()` with the same execution lock used by `execute_and_update_state()`:

```rust
fn ledger_update(
    &self,
    block_id: HashValue,
    parent_block_id: HashValue,
) -> ExecutorResult<StateComputeResult> {
    let _guard = self.execution_lock.lock(); // Add this line
    // ... rest of the method
}
```

**Fix 3: Use try_insert Instead of expect**

Replace the panic-prone `.expect()` with graceful error handling:

```rust
pub fn set_state_checkpoint_output(&self, state_checkpoint_output: StateCheckpointOutput) {
    if self.state_checkpoint_output
        .set(state_checkpoint_output)
        .is_err()
    {
        // Log and return instead of panicking
        warn!("StateCheckpointOutput already set, ignoring duplicate");
    }
}
```

**Recommended approach**: Implement all three fixes for defense in depth. Fix 1 prevents orphaned tasks, Fix 2 prevents concurrent execution, and Fix 3 prevents panics even if the first two are bypassed.

## Proof of Concept

```rust
// Reproduction steps (pseudo-code for integration test)

#[tokio::test]
async fn test_concurrent_insert_block_panic() {
    // Setup: Initialize BlockStore with executor
    let block_store = setup_block_store();
    let block = create_test_block();
    
    // Attack: Spawn two concurrent insert_block calls
    let block_store_1 = block_store.clone();
    let block_1 = block.clone();
    let handle1 = tokio::spawn(async move {
        block_store_1.insert_block(block_1).await
    });
    
    let block_store_2 = block_store.clone();
    let block_2 = block.clone();
    let handle2 = tokio::spawn(async move {
        block_store_2.insert_block(block_2).await
    });
    
    // Wait for both to complete
    let _ = tokio::join!(handle1, handle2);
    
    // Expected: One task panics with "StateCheckpointOutput already set"
    // Actual: Validator node crashes
}
```

To trigger in production:
1. Deploy a malicious network peer that sends duplicate block proposals
2. Send the same block through multiple network paths simultaneously
3. Wait for the race condition to trigger
4. Observe validator panic logs containing "StateCheckpointOutput already set"

**Notes**

This is a critical availability vulnerability that can be exploited without any privileged access. The root cause is the assumption that `insert_block()` being called multiple times is safe ("idempotent"), when in reality the pipeline task spawning creates unabortable duplicate tasks that race to completion and trigger panics. The vulnerability is inherent in the current design where ledger_update tasks lack abort handles and the executor allows concurrent read access to the same block's state.

### Citations

**File:** consensus/src/round_manager.rs (L1254-1255)
```rust
        // tries to add the same block again, which is okay as `insert_block` call
        // is idempotent.
```

**File:** consensus/src/block_storage/block_store.rs (L413-437)
```rust
        if let Some(existing_block) = self.get_block(block.id()) {
            return Ok(existing_block);
        }
        ensure!(
            self.inner.read().ordered_root().round() < block.round(),
            "Block with old round"
        );

        let block_window = self
            .inner
            .read()
            .get_ordered_block_window(&block, self.window_size)?;
        let blocks = block_window.blocks();
        for block in blocks {
            if let Some(payload) = block.payload() {
                self.payload_manager.prefetch_payload_data(
                    payload,
                    block.author().expect("Payload block must have author"),
                    block.timestamp_usecs(),
                );
            }
        }

        let pipelined_block = PipelinedBlock::new_ordered(block, block_window);
        self.insert_block_inner(pipelined_block).await
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L502-511)
```rust
        let ledger_update_fut = spawn_shared_fut(
            Self::ledger_update(
                rand_check_fut.clone(),
                execute_fut.clone(),
                parent.ledger_update_fut.clone(),
                self.executor.clone(),
                block.clone(),
            ),
            None,
        );
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L528-546)
```rust
    pub fn abort_pipeline(&self) -> Option<PipelineFutures> {
        if let Some(abort_handles) = self.pipeline_abort_handle.lock().take() {
            let mut aborted = false;
            for handle in abort_handles {
                if !handle.is_finished() {
                    handle.abort();
                    aborted = true;
                }
            }
            if aborted {
                info!(
                    "[Pipeline] Aborting pipeline for block {} {} {}",
                    self.id(),
                    self.epoch(),
                    self.round()
                );
            }
        }
        self.pipeline_futs.lock().take()
```

**File:** execution/executor/src/block_executor/mod.rs (L115-128)
```rust
    fn ledger_update(
        &self,
        block_id: HashValue,
        parent_block_id: HashValue,
    ) -> ExecutorResult<StateComputeResult> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "ledger_update"]);

        self.inner
            .read()
            .as_ref()
            .ok_or_else(|| ExecutorError::InternalError {
                error: "BlockExecutor is not reset".into(),
            })?
            .ledger_update(block_id, parent_block_id)
```

**File:** execution/executor/src/block_executor/mod.rs (L291-294)
```rust
        if let Some(complete_result) = block.output.get_complete_result() {
            info!(block_id = block_id, "ledger_update already done.");
            return Ok(complete_result);
        }
```

**File:** execution/executor/src/types/partial_state_compute_result.rs (L76-80)
```rust
    pub fn set_state_checkpoint_output(&self, state_checkpoint_output: StateCheckpointOutput) {
        self.state_checkpoint_output
            .set(state_checkpoint_output)
            .expect("StateCheckpointOutput already set");
    }
```
