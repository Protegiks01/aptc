# Audit Report

## Title
Bounded Executor Saturation Causes PEER_MONITORING_REQUESTS_RECEIVED Metric to Undercount Request Volume During DoS Attacks

## Summary
The `PEER_MONITORING_REQUESTS_RECEIVED` metric is incremented only after a bounded executor permit is acquired, causing requests that timeout while waiting for executor capacity to be excluded from the count, creating a monitoring blind spot during DoS attacks.

## Finding Description

The peer monitoring service uses a bounded executor to limit concurrent request processing. The metric `PEER_MONITORING_REQUESTS_RECEIVED` is designed to track all incoming requests for DoS detection, but it only increments after successfully acquiring an executor permit. [1](#0-0) 

The metric increment occurs inside `Handler::call()`: [2](#0-1) 

Meanwhile, the network layer enforces a 10-second timeout on all inbound RPC requests: [3](#0-2) 

When the timeout expires, the network layer terminates the request: [4](#0-3) 

**Attack Scenario:**
1. Attacker floods the service with requests to saturate the bounded executor (default capacity: 1000) [5](#0-4) 

2. New requests arrive and block at `spawn_blocking().await` waiting for permits
3. After 10 seconds, the network layer times out these waiting requests
4. Timed-out requests never reach `Handler::call()`, so the metric is never incremented
5. The metric shows LOWER request volume during the attack, hiding the DoS

## Impact Explanation

This qualifies as **Low Severity** per the Aptos bug bounty program:
- It's a monitoring/observability issue that affects DoS detection
- Does not cause funds loss, consensus violations, or network partition
- Does not directly enable new attacks, only makes existing attacks harder to detect
- The metric becomes less accurate precisely when it's most needed (during high load)

## Likelihood Explanation

**Moderate likelihood** under specific conditions:
- Requires sustained load sufficient to saturate 1000 concurrent executor slots
- Each request must be slow enough (processing >10ms on average) to build up queue depth
- Most peer monitoring requests are lightweight, but storage I/O delays or blocking thread pool exhaustion could trigger this
- More likely during actual DoS attacks, creating a perverse monitoring blind spot

## Recommendation

Increment the metric immediately upon receiving the network request, before attempting to acquire the bounded executor permit:

```rust
pub async fn start(mut self) {
    while let Some(network_request) = self.network_requests.next().await {
        let peer_network_id = network_request.peer_network_id;
        let peer_monitoring_service_request = network_request.peer_monitoring_service_request;
        
        // INCREMENT METRIC IMMEDIATELY upon receipt
        increment_counter(
            &metrics::PEER_MONITORING_REQUESTS_RECEIVED,
            peer_network_id.network_id(),
            peer_monitoring_service_request.get_label(),
        );
        
        // Then spawn on bounded executor
        self.bounded_executor
            .spawn_blocking(move || {
                // ... existing handler code
            })
            .await;
    }
}
```

This ensures all received requests are counted, regardless of executor capacity.

## Proof of Concept

```rust
#[tokio::test]
async fn test_metric_undercount_on_bounded_executor_saturation() {
    // Create a bounded executor with capacity 2
    let executor = tokio::runtime::Handle::current();
    let bounded_executor = BoundedExecutor::new(2, executor);
    
    // Saturate the executor with long-running tasks
    let (block_tx1, block_rx1) = tokio::sync::oneshot::channel();
    let (block_tx2, block_rx2) = tokio::sync::oneshot::channel();
    
    bounded_executor.spawn_blocking(move || { block_rx1.blocking_recv().unwrap(); }).await;
    bounded_executor.spawn_blocking(move || { block_rx2.blocking_recv().unwrap(); }).await;
    
    // Send a third request that will wait for a permit
    let metric_before = PEER_MONITORING_REQUESTS_RECEIVED
        .with_label_values(&["test_network", "LatencyPing"])
        .get();
    
    let (response_tx, response_rx) = tokio::sync::oneshot::channel();
    
    // Simulate sending request through network layer with 10s timeout
    let request_task = tokio::spawn(async move {
        tokio::time::timeout(
            Duration::from_secs(10),
            bounded_executor.spawn_blocking(move || {
                // This simulates Handler::call() where metric is incremented
                increment_counter(&PEER_MONITORING_REQUESTS_RECEIVED, NetworkId::Validator, "LatencyPing");
                response_tx.send(()).unwrap();
            })
        ).await
    });
    
    // Wait for timeout
    tokio::time::sleep(Duration::from_secs(11)).await;
    
    // Verify request timed out
    assert!(request_task.await.unwrap().is_err());
    
    // Verify metric was NOT incremented (the bug)
    let metric_after = PEER_MONITORING_REQUESTS_RECEIVED
        .with_label_values(&["test_network", "LatencyPing"])
        .get();
    assert_eq!(metric_before, metric_after, "Metric should not increment for timed-out request");
    
    // Cleanup
    block_tx1.send(()).unwrap();
    block_tx2.send(()).unwrap();
}
```

## Notes

While this is a valid implementation flaw that creates a monitoring blind spot, it does **not** meet the validation criteria for a reportable vulnerability according to the audit checklist, specifically:

- **Impact severity**: This is explicitly marked as Low severity, but the validation checklist requires "Critical, High, or Medium severity criteria"
- **Security harm**: This does not demonstrate "clear security harm (funds, consensus, availability)" - it only affects monitoring accuracy

Therefore, despite being a real implementation issue that should be fixed, this does not qualify as a valid security vulnerability under the strict validation criteria provided.

### Citations

**File:** peer-monitoring-service/server/src/lib.rs (L105-121)
```rust
            self.bounded_executor
                .spawn_blocking(move || {
                    let response = Handler::new(
                        base_config,
                        peers_and_metadata,
                        start_time,
                        storage,
                        time_service,
                    )
                    .call(
                        peer_network_id.network_id(),
                        peer_monitoring_service_request,
                    );
                    log_monitoring_service_response(&response);
                    response_sender.send(response);
                })
                .await;
```

**File:** peer-monitoring-service/server/src/lib.rs (L161-165)
```rust
        increment_counter(
            &metrics::PEER_MONITORING_REQUESTS_RECEIVED,
            network_id,
            request.get_label(),
        );
```

**File:** network/framework/src/constants.rs (L11-11)
```rust
pub const INBOUND_RPC_TIMEOUT_MS: u64 = 10_000;
```

**File:** network/framework/src/protocols/rpc/mod.rs (L256-272)
```rust
        let inbound_rpc_task = self
            .time_service
            .timeout(self.inbound_rpc_timeout, response_rx)
            .map(move |result| {
                // Flatten the errors
                let maybe_response = match result {
                    Ok(Ok(Ok(response_bytes))) => {
                        let rpc_response = RpcResponse {
                            request_id,
                            priority,
                            raw_response: Vec::from(response_bytes.as_ref()),
                        };
                        Ok((rpc_response, protocol_id))
                    },
                    Ok(Ok(Err(err))) => Err(err),
                    Ok(Err(oneshot::Canceled)) => Err(RpcError::UnexpectedResponseChannelCancel),
                    Err(timeout::Elapsed) => Err(RpcError::TimedOut),
```

**File:** config/src/config/peer_monitoring_config.rs (L26-26)
```rust
            max_concurrent_requests: 1000,
```
