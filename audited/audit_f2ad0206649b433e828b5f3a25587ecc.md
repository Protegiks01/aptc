# Audit Report

## Title
Rate Limiting Bypass via Response Error Misclassification in Storage Service

## Summary
The storage service server's error conversion logic treats all `responses::Error` types as unexpected internal errors rather than invalid client requests, allowing malicious clients to bypass rate limiting when triggering response generation failures.

## Finding Description

The storage service implements rate limiting to protect against abusive clients by tracking invalid requests per peer. However, the error conversion implementation loses critical security context. [1](#0-0) 

This `From` trait implementation converts ALL `responses::Error` variants to `UnexpectedErrorEncountered`, regardless of the underlying cause. When these errors occur during response generation (e.g., compression failures), they flow through the handler's error mapping: [2](#0-1) 

Since `UnexpectedErrorEncountered` errors are mapped to `StorageServiceError::InternalError` (not `InvalidRequest`), they do NOT trigger the rate limiting mechanism in the request moderator: [3](#0-2) 

**Attack Scenario:**

A malicious client can exploit data size edge cases where:
1. Client requests pass initial validation (data exists in storage)
2. Server fetches and attempts to compress response data
3. Compression fails due to size constraints or data incompressibility
4. Error chain: `aptos_compression::Error` → `responses::Error::UnexpectedErrorEncountered` → `Error::UnexpectedErrorEncountered` → `StorageServiceError::InternalError`
5. No call to `increment_invalid_request_count()`, bypassing rate limiting

The compression errors originate from: [4](#0-3) 

## Impact Explanation

**HIGH Severity** - This vulnerability allows malicious peers to cause validator node slowdowns and API crashes through repeated failed requests that bypass rate limiting protections. While the storage server has chunk size limits, edge cases exist where individual data items can trigger response generation failures without being counted as invalid requests. This violates the "Resource Limits" invariant requiring all operations to respect computational and resource constraints.

## Likelihood Explanation

**HIGH** - The attack is straightforward to execute:
- No validator access required
- Client only needs network connectivity to storage service
- Automated scripts can continuously probe for size edge cases
- No rate limiting protection against this attack vector

## Recommendation

Distinguish between truly unexpected server errors and client-triggered failures. Modify the error conversion to preserve security context:

```rust
impl From<aptos_storage_service_types::responses::Error> for Error {
    fn from(error: aptos_storage_service_types::responses::Error) -> Self {
        match error {
            // Compression/serialization failures during response generation
            // should be treated as invalid requests (client asked for data
            // that cannot be properly served)
            aptos_storage_service_types::responses::Error::UnexpectedErrorEncountered(msg) 
                if msg.contains("Compressed size greater") || 
                   msg.contains("Raw data size greater") => {
                Error::InvalidRequest(format!("Response data too large: {}", msg))
            },
            // Degenerate ranges represent malformed client input
            aptos_storage_service_types::responses::Error::DegenerateRangeError => {
                Error::InvalidRequest("Invalid data range requested".to_string())
            },
            // Other errors are genuinely unexpected
            error => Error::UnexpectedErrorEncountered(error.to_string()),
        }
    }
}
```

## Proof of Concept

```rust
// Test demonstrating rate limiting bypass
#[tokio::test]
async fn test_compression_error_bypasses_rate_limiting() {
    let storage_config = StorageServiceConfig {
        max_invalid_requests_per_peer: 3,
        ..Default::default()
    };
    
    let peer_id = PeerNetworkId::new(NetworkId::Public, PeerId::random());
    
    // Send requests that trigger compression errors
    for i in 0..10 {
        let request = create_request_triggering_compression_failure();
        let response = storage_service.process_request(peer_id, request).await;
        
        // Expect InternalError, not TooManyInvalidRequests
        assert!(matches!(response, Err(StorageServiceError::InternalError(_))));
    }
    
    // Peer should have been rate limited after 3 invalid requests,
    // but compression errors don't count, so peer can continue attacking
    let moderator = storage_service.get_request_moderator();
    assert!(!moderator.is_peer_ignored(peer_id)); // VULNERABILITY: Peer not ignored!
}
```

## Notes

This vulnerability breaks the Resource Limits invariant by allowing unbounded failed request processing from malicious peers. The fix requires careful analysis of error origins to correctly classify client-triggered failures versus genuine internal errors.

### Citations

**File:** state-sync/storage-service/server/src/error.rs (L31-35)
```rust
impl From<aptos_storage_service_types::responses::Error> for Error {
    fn from(error: aptos_storage_service_types::responses::Error) -> Self {
        Error::UnexpectedErrorEncountered(error.to_string())
    }
}
```

**File:** state-sync/storage-service/server/src/handler.rs (L196-202)
```rust
        process_result.map_err(|error| match error {
            Error::InvalidRequest(error) => StorageServiceError::InvalidRequest(error),
            Error::TooManyInvalidRequests(error) => {
                StorageServiceError::TooManyInvalidRequests(error)
            },
            error => StorageServiceError::InternalError(error.to_string()),
        })
```

**File:** state-sync/storage-service/server/src/moderator.rs (L160-184)
```rust
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
```

**File:** crates/aptos-compression/src/lib.rs (L53-82)
```rust
    if raw_data.len() > max_bytes {
        let error_string = format!(
            "Raw data size greater than max bytes limit: {}, max: {}",
            raw_data.len(),
            max_bytes
        );
        return create_compression_error(&client, error_string);
    }

    // Compress the data
    let compression_mode = CompressionMode::FAST(ACCELERATION_PARAMETER);
    let compressed_data = match lz4::block::compress(&raw_data, Some(compression_mode), true) {
        Ok(compressed_data) => compressed_data,
        Err(error) => {
            let error_string = format!("Failed to compress the data: {}", error);
            return create_compression_error(&client, error_string);
        },
    };

    // Ensure that the compressed data size is not greater than the max byte
    // limit. This can happen in the case of uncompressible data, where the
    // compressed data is larger than the uncompressed data.
    if compressed_data.len() > max_bytes {
        let error_string = format!(
            "Compressed size greater than max bytes limit: {}, max: {}",
            compressed_data.len(),
            max_bytes
        );
        return create_compression_error(&client, error_string);
    }
```
