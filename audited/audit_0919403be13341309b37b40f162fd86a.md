# Audit Report

## Title
Latency-Based Peer Selection Enables Eclipse Attacks on Public Fullnodes via Malicious VFN Operators

## Summary
Public fullnodes use TCP connection latency to weight peer selection when establishing outbound connections. Malicious validator operators can manipulate this latency measurement by deploying low-latency VFN infrastructure or immediately accepting TCP connections during pings. With only 6 outbound connection slots and exponential latency weight decay, attackers can dominate all peer connections, eclipsing fullnodes from the honest network and feeding them false blockchain data.

## Finding Description

Aptos public fullnodes discover peers through on-chain discovery, retrieving VFN (Validator Full Node) addresses from the ValidatorSet. When `enable_latency_aware_dialing` is enabled, fullnodes measure TCP connection latency to each discovered VFN and use weighted selection to choose peers. [1](#0-0) 

The latency measurement is performed via TCP connection timing: [2](#0-1) 

Latency is converted to selection weight with exponential decay - the weight halves for every 25ms of latency: [3](#0-2) 

This creates a severe vulnerability: A VFN at 10ms latency receives 32x more weight than one at 100ms latency. With only 6 outbound connections allowed: [4](#0-3) 

And these outbound peers being treated as HighPriority for state synchronization: [5](#0-4) 

**Attack Path:**
1. Malicious validator operators register VFN addresses pointing to low-latency infrastructure (edge nodes, geographically distributed data centers)
2. When victim fullnode performs latency measurements, attacker VFNs immediately accept TCP connections (latency <10ms)
3. Honest VFNs in typical data centers measure 50-200ms latency
4. Due to exponential weight decay, attacker VFNs receive vastly higher selection probability
5. Victim fullnode selects all 6 outbound connections to attacker-controlled VFNs
6. State sync client treats these as HighPriority peers
7. Victim fullnode syncs blockchain data exclusively from attacker nodes
8. Attackers feed false state, censor transactions, or perform targeted consensus violations

**Broken Invariants:**
- **State Consistency**: Fullnodes can be fed inconsistent state from eclipsed peers
- **Network Diversity**: No geographic, organizational, or network diversity requirements
- **Peer Reliability**: TCP connection time is easily manipulable and doesn't reflect data reliability

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria due to "Significant protocol violations":

1. **Eclipse Attack on Fullnodes**: Complete isolation from honest network peers
2. **False Blockchain Data**: Victims receive attacker-controlled state information
3. **Transaction Censorship**: Attackers can prevent victims from seeing specific transactions
4. **Widespread Impact**: Any public fullnode using latency-aware dialing is vulnerable
5. **Data Integrity Violation**: Breaks the fundamental assumption that fullnodes can reliably sync blockchain state

While this doesn't directly impact consensus among validators, it severely compromises the security guarantees for public fullnode operators who rely on accurate blockchain state for:
- Serving user queries
- Transaction submission
- DApp backends
- Monitoring/analytics infrastructure

## Likelihood Explanation

**High Likelihood:**

1. **Low Attack Cost**: Deploying low-latency infrastructure or edge nodes is inexpensive
2. **Trivial Manipulation**: Immediately accepting TCP connections requires no sophisticated techniques
3. **Default Configuration**: Latency-aware dialing is enabled by default: [6](#0-5) 

4. **Small Attack Surface**: Only 6 outbound connections needed - a single malicious validator with distributed VFNs can execute this attack
5. **No Detection**: Victims cannot distinguish malicious low-latency peers from legitimate ones
6. **Insider Capability**: Requires validator operator access, but any compromised validator or malicious operator can execute it

**Attack Requirements:**
- Control of at least one validator (to register VFN addresses)
- Low-latency network infrastructure (~10ms response time)
- Multiple VFN endpoints (to occupy all 6 connection slots)

## Recommendation

Implement multi-layered defenses against latency manipulation:

1. **Diversity Requirements**:
   - Limit connections per validator to 1-2 (prevent single validator dominance)
   - Require geographic diversity (distribute across regions/ASNs)
   - Add organizational diversity tracking

2. **Robust Latency Measurement**:
   - Replace TCP connection time with application-level ping after connection
   - Measure sustained latency over time, not just initial connection
   - Use multiple latency samples and detect anomalies

3. **Reduce Weight Bias**:
   - Flatten the exponential curve (e.g., square root instead of halving)
   - Cap maximum weight difference (e.g., 10x instead of unlimited)
   - Add randomness to selection even with weights

4. **Peer Reputation System**:
   - Track peer reliability (successful data requests, correct state proofs)
   - Downweight peers that provide invalid data
   - Maintain long-term peer scoring

**Example Fix for Weight Calculation:**

```rust
fn convert_latency_to_weight(latency_secs: f64) -> f64 {
    if latency_secs <= 0.0 {
        return 0.0;
    }
    
    // Use square root to reduce exponential bias
    // Cap maximum weight advantage at 10x
    let weight = 1.0 / latency_secs.sqrt();
    let max_weight = 10.0;
    let min_weight = 1.0;
    
    weight.clamp(min_weight, max_weight)
}
```

**Add Validator Connection Limit:**

```rust
// In choose_peers_to_dial()
let mut peers_per_validator: HashMap<PeerId, usize> = HashMap::new();
let max_connections_per_validator = 2;

eligible_peers = eligible_peers
    .into_iter()
    .filter(|(peer_id, _)| {
        let validator_id = get_validator_for_vfn(peer_id);
        let count = peers_per_validator.entry(validator_id).or_insert(0);
        if *count < max_connections_per_validator {
            *count += 1;
            true
        } else {
            false
        }
    })
    .collect();
```

## Proof of Concept

```rust
// This PoC demonstrates the weight bias in latency-based selection

#[cfg(test)]
mod eclipse_attack_poc {
    use super::*;
    
    #[test]
    fn test_latency_weight_bias_enables_eclipse() {
        // Attacker VFNs with artificially low latency (immediate TCP accept)
        let attacker_latency_ms = 10.0;
        let attacker_latency_secs = attacker_latency_ms / 1000.0;
        
        // Honest VFNs with typical data center latency
        let honest_latency_ms = 100.0;
        let honest_latency_secs = honest_latency_ms / 1000.0;
        
        // Calculate weights using the actual function
        let attacker_weight = convert_latency_to_weight(attacker_latency_secs);
        let honest_weight = convert_latency_to_weight(honest_latency_secs);
        
        // Show the bias
        let weight_ratio = attacker_weight / honest_weight;
        println!("Attacker weight: {}", attacker_weight);
        println!("Honest weight: {}", honest_weight);
        println!("Weight ratio: {}x", weight_ratio);
        
        // With 6 attacker VFNs and 100 honest VFNs
        // Probability of selecting attacker = (6 * attacker_weight) / (6 * attacker_weight + 100 * honest_weight)
        let total_attacker_weight = 6.0 * attacker_weight;
        let total_honest_weight = 100.0 * honest_weight;
        let attacker_prob = total_attacker_weight / (total_attacker_weight + total_honest_weight);
        
        println!("Probability of selecting attacker VFN: {:.1}%", attacker_prob * 100.0);
        
        // Demonstrate that with only 6 connections, attacker will dominate
        // Expected number of attacker connections out of 6 total
        let expected_attacker_connections = 6.0 * attacker_prob;
        println!("Expected attacker connections (out of 6): {:.2}", expected_attacker_connections);
        
        // Assert the vulnerability: attackers will get >80% of connections
        assert!(attacker_prob > 0.8, "Attackers can eclipse fullnode with >80% probability");
    }
    
    #[test]
    fn test_tcp_connection_time_manipulation() {
        // Demonstrate that TCP connection time can be trivially manipulated
        use std::net::TcpListener;
        use std::time::Instant;
        
        // Attacker: Immediately accept connection
        let attacker_listener = TcpListener::bind("127.0.0.1:0").unwrap();
        let attacker_addr = attacker_listener.local_addr().unwrap();
        
        std::thread::spawn(move || {
            // Accept immediately (simulates malicious VFN)
            let (_stream, _addr) = attacker_listener.accept().unwrap();
        });
        
        let start = Instant::now();
        let _stream = TcpStream::connect_timeout(
            &attacker_addr, 
            Duration::from_secs(2)
        ).unwrap();
        let attacker_latency = start.elapsed();
        
        println!("Attacker latency: {:?}", attacker_latency);
        
        // Honest node: Natural network delay + processing
        // (Would be 50-200ms in real network conditions)
        
        // Assert: TCP connection time is easily manipulable
        assert!(attacker_latency.as_millis() < 50, 
               "Attacker can achieve <50ms latency trivially");
    }
}
```

**Notes**

This vulnerability represents a fundamental design flaw in the latency-based peer selection mechanism. While the intent was to improve performance by connecting to nearby peers, the implementation creates a severe security vulnerability that allows eclipse attacks. The exponential weight decay (halving every 25ms) massively amplifies small latency differences, making it trivial for attackers with low-latency infrastructure to dominate peer selection.

**Critical Issue**: This vulnerability requires validator operator access to register VFN addresses, which technically makes it an "insider threat" scenario. However, given that any compromised validator or malicious operator can execute this attack, and the impact affects all public fullnodes, this still represents a significant protocol-level vulnerability that should be addressed.

The fix requires reducing the latency weight bias, adding diversity requirements, and implementing reputation-based peer scoring to prevent any single entity from dominating a fullnode's peer connections.

### Citations

**File:** network/framework/src/connectivity_manager/mod.rs (L628-645)
```rust
        if selection::should_select_peers_by_latency(
            &self.network_context,
            self.enable_latency_aware_dialing,
        ) {
            // Ping the eligible peers (so that we can fetch missing ping latency information)
            self.ping_eligible_peers(eligible_peers.clone()).await;

            // Choose the peers to dial (weighted by ping latency)
            selection::choose_random_peers_by_ping_latency(
                self.network_context,
                eligible_peers,
                num_peers_to_dial,
                self.discovered_peers.clone(),
            )
        } else {
            // Choose the peers randomly
            selection::choose_peers_to_dial_randomly(eligible_peers, num_peers_to_dial)
        }
```

**File:** network/framework/src/connectivity_manager/mod.rs (L1153-1227)
```rust
fn spawn_latency_ping_task(
    network_context: NetworkContext,
    peer_id: AccountAddress,
    network_address: NetworkAddress,
    discovered_peers: Arc<RwLock<DiscoveredPeerSet>>,
) -> JoinHandle<()> {
    tokio::task::spawn_blocking(move || {
        // Extract the socket addresses from the network address
        let socket_addresses = match network_address.to_socket_addrs() {
            Ok(socket_addresses) => socket_addresses.collect::<Vec<_>>(),
            Err(error) => {
                warn!(
                    NetworkSchema::new(&network_context),
                    "Failed to resolve network address {:?}: {}", network_address, error
                );
                return;
            },
        };

        // If no socket addresses were found, log an error and return
        if socket_addresses.is_empty() {
            warn!(
                NetworkSchema::new(&network_context),
                "Peer {} does not have any socket addresses for network address {:?}!",
                peer_id.short_str(),
                network_address,
            );
            return;
        }

        // Limit the number of socket addresses we'll try to connect to
        let socket_addresses = socket_addresses
            .iter()
            .take(MAX_SOCKET_ADDRESSES_TO_PING)
            .collect::<Vec<_>>();

        // Attempt to connect to the socket addresses over TCP and time the connection
        for socket_address in socket_addresses {
            // Start the ping timer
            let start_time = Instant::now();

            // Attempt to connect to the socket address
            if let Ok(tcp_stream) = TcpStream::connect_timeout(
                socket_address,
                Duration::from_secs(MAX_CONNECTION_TIMEOUT_SECS),
            ) {
                // We connected successfully, update the peer's ping latency
                let ping_latency_secs = start_time.elapsed().as_secs_f64();
                discovered_peers
                    .write()
                    .update_ping_latency_secs(&peer_id, ping_latency_secs);

                // Attempt to terminate the TCP stream cleanly
                if let Err(error) = tcp_stream.shutdown(Shutdown::Both) {
                    warn!(
                        NetworkSchema::new(&network_context),
                        "Failed to terminate TCP stream to peer {} after pinging: {}",
                        peer_id.short_str(),
                        error
                    );
                }

                return;
            } else {
                // Log an error if we failed to connect to the socket address
                info!(
                    NetworkSchema::new(&network_context),
                    "Failed to ping peer {} at socket address {:?} after pinging",
                    peer_id.short_str(),
                    socket_address
                );
            }
        }
    })
}
```

**File:** network/framework/src/connectivity_manager/selection.rs (L148-168)
```rust
/// Converts the given latency measurement to a weight. The weight
/// is calculated as the inverse of the latency, with a scaling
/// factor to ensure that low latency peers are highly weighted.
fn convert_latency_to_weight(latency_secs: f64) -> f64 {
    // If the latency is <= 0, something has gone wrong, so return 0.
    if latency_secs <= 0.0 {
        return 0.0;
    }

    // Invert the latency to get the weight
    let mut weight = 1.0 / latency_secs;

    // For every 25ms of latency, reduce the weight by 1/2 (to
    // ensure that low latency peers are highly weighted)
    let num_reductions = (latency_secs / 0.025) as usize;
    for _ in 0..num_reductions {
        weight /= 2.0;
    }

    weight
}
```

**File:** config/src/config/network_config.rs (L43-43)
```rust
pub const MAX_FULLNODE_OUTBOUND_CONNECTIONS: usize = 6;
```

**File:** config/src/config/network_config.rs (L166-166)
```rust
            enable_latency_aware_dialing: true,
```

**File:** state-sync/aptos-data-client/src/priority.rs (L104-121)
```rust
    // Otherwise, this node is a PFN. PFNs should highly
    // prioritize trusted peers (i.e., VFNs and seed peers).
    if is_trusted_peer(peers_and_metadata.clone(), peer) {
        return PeerPriority::HighPriority;
    }

    // Outbound connections should be prioritized. This prioritizes
    // other VFNs/seed peers over regular PFNs. Inbound connections
    // are always low priority (as they are generally unreliable).
    if let Some(metadata) = utils::get_metadata_for_peer(&peers_and_metadata, *peer) {
        if metadata.get_connection_metadata().is_outbound_connection() {
            PeerPriority::HighPriority
        } else {
            PeerPriority::LowPriority
        }
    } else {
        PeerPriority::LowPriority // We don't have connection metadata
    }
```
