# Audit Report

## Title
Critical Race Condition in reset_state_store() Breaks State Consistency During Transaction Commits

## Summary
The `reset_state_store()` function in RestoreHandler does not synchronize with ongoing transaction commits, allowing it to reset the in-memory buffered state between the pre-commit and commit phases of a transaction. This creates a race condition that can cause transaction commit failures and leave the database in an inconsistent state where ledger_db contains committed data but the state_store's in-memory view is at an older version.

## Finding Description
The transaction commit process in AptosDB follows a two-phase protocol protected by separate locks: [1](#0-0) 

The commit flow executes as:
1. **Pre-commit phase** (`pre_commit_ledger`): Acquires `pre_commit_lock`, writes transaction data to ledger_db and state_kv_db, then updates the in-memory buffered_state [2](#0-1) 

2. **Commit phase** (`commit_ledger`): Acquires `commit_lock`, validates the commit range, writes `OverallCommitProgress`, and finalizes the commit [3](#0-2) 

However, `reset_state_store()` does NOT acquire either lock before resetting the state: [4](#0-3) 

The reset operation calls `StateStore::reset()` which destroys and recreates the buffered state: [5](#0-4) 

**Race Condition Scenario:**
- **Thread 1** (Transaction commit): Executes `pre_commit_ledger(version=N)` 
  - Writes transaction data to ledger_db and state_kv_db
  - Updates buffered_state to version N
  - Releases `pre_commit_lock`
  
- **Thread 2** (Restore operation): Calls `reset_state_store()`
  - Does NOT acquire `pre_commit_lock` or `commit_lock`
  - Reads `OverallCommitProgress` from DB = N-1 (not yet updated by commit_ledger)
  - Resets buffered_state to version N-1
  
- **Thread 1** (continuing): Attempts `commit_ledger(version=N)`
  - Validates commit range using `get_and_check_commit_range(N)`
  - Reads `state_store.current_state_locked().version()` = N-1 (reset by Thread 2!)
  - Validation fails: `ensure!(version_to_commit <= pre_committed_ver)` fails because N > N-1 [6](#0-5) 

**Result:** The commit fails with "Version too new to commit", but ledger_db already contains the transaction data from pre-commit. The database is now inconsistent with:
- ledger_db containing data for version N
- state_kv_db containing state for version N  
- OverallCommitProgress stuck at N-1
- buffered_state at version N-1

This violates the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

## Impact Explanation
This vulnerability meets **Medium Severity** criteria per the Aptos bug bounty program: "State inconsistencies requiring intervention."

**Concrete Impacts:**
1. **State Inconsistency**: Database components (ledger_db, state_kv_db, state_store) end up at different versions, breaking atomicity guarantees
2. **Transaction Loss**: Committed transactions can be lost if the node restarts and syncs to OverallCommitProgress
3. **Manual Recovery Required**: Operators must manually intervene to restore consistency, potentially requiring rollback or database repair
4. **Consensus Divergence Risk**: If different validator nodes experience this at different times, they may diverge in their view of committed state

The issue does not directly cause fund loss or consensus safety violations, but creates state corruption requiring operator intervention, which matches Medium severity.

## Likelihood Explanation
**Likelihood: Medium-Low**

The vulnerability requires:
1. A restore operation to be triggered (via backup-cli or restore tooling) while the node is processing transactions
2. Precise timing where `reset_state_store()` executes between `pre_commit_ledger()` and `commit_ledger()`

While the timing window is narrow, restore operations can legitimately occur on running nodes (the API provides no exclusivity guarantees), making this exploitable during:
- Database restoration from backups
- Transaction replay operations
- State synchronization procedures

Node operators performing restore operations on live nodes could trigger this accidentally. The race window exists on every transaction commit, making it probabilistically likely given sufficient transaction volume during a restore.

## Recommendation
Add synchronization to `reset_state_store()` to prevent it from executing concurrently with transaction commits. The fix should acquire both commit locks before resetting state:

```rust
// In storage/aptosdb/src/backup/restore_handler.rs
impl RestoreHandler {
    pub fn reset_state_store(&self) {
        // Acquire both locks to prevent concurrent commits
        let _pre_commit_lock = self.aptosdb.pre_commit_lock.lock()
            .expect("Failed to acquire pre_commit_lock for reset");
        let _commit_lock = self.aptosdb.commit_lock.lock()
            .expect("Failed to acquire commit_lock for reset");
        
        self.state_store.reset();
    }
}
```

However, this requires exposing the locks from AptosDB. A better architectural fix would be:

```rust
// In storage/aptosdb/src/db/mod.rs - add method to AptosDB
impl AptosDB {
    pub fn reset_state_store_synchronized(&self) {
        let _pre_commit_lock = self.pre_commit_lock.lock()
            .expect("Failed to acquire pre_commit_lock");
        let _commit_lock = self.commit_lock.lock()
            .expect("Failed to acquire commit_lock");
        self.state_store.reset();
    }
}

// In RestoreHandler, call the synchronized version
impl RestoreHandler {
    pub fn reset_state_store(&self) {
        self.aptosdb.reset_state_store_synchronized();
    }
}
```

## Proof of Concept

```rust
// Test to demonstrate the race condition
#[test]
fn test_reset_state_store_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    // Setup: Create AptosDB instance
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    let db_arc = Arc::new(db);
    
    // Commit initial transaction to version 0
    let chunk = create_test_chunk(0, 1);
    db_arc.pre_commit_ledger(chunk.clone(), false).unwrap();
    db_arc.commit_ledger(0, None, Some(chunk)).unwrap();
    
    // Setup synchronization barriers for precise timing
    let barrier1 = Arc::new(Barrier::new(2));
    let barrier2 = Arc::new(Barrier::new(2));
    
    let db_clone1 = Arc::clone(&db_arc);
    let b1_clone1 = Arc::clone(&barrier1);
    let b2_clone1 = Arc::clone(&barrier2);
    
    // Thread 1: Transaction commit
    let commit_thread = thread::spawn(move || {
        let chunk = create_test_chunk(1, 1);
        
        // Pre-commit version 1
        db_clone1.pre_commit_ledger(chunk.clone(), false).unwrap();
        
        // Signal: pre-commit done, wait for reset to interfere
        b1_clone1.wait();
        b2_clone1.wait();
        
        // Try to commit - this should fail due to version mismatch
        let result = db_clone1.commit_ledger(1, None, Some(chunk));
        result
    });
    
    let db_clone2 = Arc::clone(&db_arc);
    let b1_clone2 = Arc::clone(&barrier1);
    let b2_clone2 = Arc::clone(&barrier2);
    
    // Thread 2: Reset operation
    let reset_thread = thread::spawn(move || {
        // Wait for pre-commit to complete
        b1_clone2.wait();
        
        // Reset state store while commit is pending
        let restore_handler = db_clone2.get_restore_handler();
        restore_handler.reset_state_store();
        
        // Signal: reset done
        b2_clone2.wait();
    });
    
    // Wait for both threads
    reset_thread.join().unwrap();
    let commit_result = commit_thread.join().unwrap();
    
    // Verify: commit should fail with version mismatch error
    assert!(commit_result.is_err());
    assert!(commit_result.unwrap_err().to_string().contains("Version too new to commit"));
    
    // Verify inconsistency: ledger_db has data but OverallCommitProgress is behind
    let synced_version = db_arc.ledger_db.metadata_db().get_synced_version().unwrap();
    let current_state_version = db_arc.state_store.current_state_locked().version();
    
    // State is inconsistent: current_state was reset to 0 but commit wrote data for version 1
    assert_eq!(synced_version, Some(0)); // OverallCommitProgress not updated
    assert_eq!(current_state_version, Some(0)); // State was reset
    // But ledger_db contains transaction data for version 1 (from pre_commit)
}
```

**Notes:**
- The vulnerability exists in production code at the boundary between backup/restore operations and normal transaction processing
- This is not a theoretical issue - it can occur during legitimate restore operations on running nodes
- The fix requires careful synchronization to prevent deadlocks while ensuring atomicity
- Alternative mitigation: Document that restore operations MUST NOT be performed on nodes actively processing transactions, and add runtime checks to prevent this

### Citations

**File:** storage/aptosdb/src/db/mod.rs (L34-37)
```rust
    /// This is just to detect concurrent calls to `pre_commit_ledger()`
    pre_commit_lock: std::sync::Mutex<()>,
    /// This is just to detect concurrent calls to `commit_ledger()`
    commit_lock: std::sync::Mutex<()>,
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L44-76)
```rust
    fn pre_commit_ledger(&self, chunk: ChunkToCommit, sync_commit: bool) -> Result<()> {
        gauged_api("pre_commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .pre_commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["pre_commit_ledger"]);

            chunk
                .state_summary
                .latest()
                .global_state_summary
                .log_generation("db_save");

            self.pre_commit_validation(&chunk)?;
            let _new_root_hash =
                self.calculate_and_commit_ledger_and_state_kv(&chunk, self.skip_index_and_usage)?;

            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions__others"]);

            self.state_store.buffered_state().lock().update(
                chunk.result_ledger_state_with_summary(),
                chunk.estimated_total_state_updates(),
                sync_commit || chunk.is_reconfig,
            )?;

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L522-538)
```rust
    fn get_and_check_commit_range(&self, version_to_commit: Version) -> Result<Option<Version>> {
        let old_committed_ver = self.ledger_db.metadata_db().get_synced_version()?;
        let pre_committed_ver = self.state_store.current_state_locked().version();
        ensure!(
            old_committed_ver.is_none() || version_to_commit >= old_committed_ver.unwrap(),
            "Version too old to commit. Committed: {:?}; Trying to commit with LI: {}",
            old_committed_ver,
            version_to_commit,
        );
        ensure!(
            pre_committed_ver.is_some() && version_to_commit <= pre_committed_ver.unwrap(),
            "Version too new to commit. Pre-committed: {:?}, Trying to commit with LI: {}",
            pre_committed_ver,
            version_to_commit,
        );
        Ok(old_committed_ver)
    }
```

**File:** storage/aptosdb/src/backup/restore_handler.rs (L57-59)
```rust
    pub fn reset_state_store(&self) {
        self.state_store.reset();
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L707-719)
```rust
    pub fn reset(&self) {
        self.buffered_state.lock().quit();
        *self.buffered_state.lock() = Self::create_buffered_state_from_latest_snapshot(
            &self.state_db,
            self.buffered_state_target_items,
            false,
            true,
            self.current_state.clone(),
            self.persisted_state.clone(),
            self.hot_state_config,
        )
        .expect("buffered state creation failed.");
    }
```
