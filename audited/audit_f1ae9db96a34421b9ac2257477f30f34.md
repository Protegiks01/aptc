# Audit Report

## Title
Permanent Indexer Lag After Fast Sync Due to Missing Version Gap Handling

## Summary
The legacy `Indexer` in `storage/indexer/src/lib.rs` contains a critical version gap vulnerability that causes permanent indexer failure after fast sync operations. When a node performs fast sync, the ledger advances without updating the indexer, creating a version gap that triggers a strict ordering check failure in `index_with_annotator()`. This error is swallowed by the consensus layer, leaving the indexer permanently stuck and serving stale data to API queries.

## Finding Description

The vulnerability exists in the version continuity enforcement mechanism of the legacy Indexer. The `index_with_annotator()` function enforces strict sequential version ordering: [1](#0-0) 

This check ensures `first_version <= next_version`, erroring if the condition fails. The critical flaw emerges during fast sync operations:

**Fast Sync Path (No Indexer Update):**
During fast sync, `finalize_state_snapshot()` commits transactions to the ledger without invoking the indexer: [2](#0-1) 

This function saves transactions, updates metadata, and advances the ledger version, but contains no call to the indexer's `index()` method.

**Indexer Initialization (One-Time Catch-Up):**
The indexer's catch-up mechanism only runs during database initialization: [3](#0-2) 

This catch-up logic (lines 207-228) executes only when `open_indexer()` is called during `AptosDB::open()`. After fast sync completes, the indexer is never reopened or caught up.

**Normal Operation (Gap Triggers Failure):**
After fast sync, when normal transaction commits resume via `post_commit()`: [4](#0-3) 

The indexer is called at lines 636-658 with `first_version` calculated from the current ledger state (line 613). If the indexer is at version 0 and the ledger is at version 10000 (after fast sync), the call fails the ordering check.

**Error Handling (Failure Swallowed):**
The consensus layer's error handling swallows indexer failures: [5](#0-4) 

This `wait_and_log_error` function only logs errors as warnings, allowing the node to continue operating with a broken indexer.

**Attack/Trigger Scenario:**
1. Fresh node starts with empty database (ledger version 0, indexer version 0)
2. Node configured for fast sync: `BootstrappingMode::DownloadLatestStates`
3. Fast sync downloads state snapshot at version N (e.g., 10,000)
4. `finalize_state_snapshot()` advances ledger to version N without updating indexer
5. Indexer remains at version 0; no catch-up occurs post-fast-sync
6. First normal transaction commits at version N+1
7. `post_commit()` calls `indexer.index(first_version=N+1, ...)`
8. Check fails: `N+1 <= 0` is false
9. Error logged but swallowed; node continues operating
10. All subsequent commits fail the same check
11. Indexer permanently stuck at version 0, serving stale/empty data

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos Bug Bounty)

This vulnerability causes **significant protocol violations** through API data integrity compromise:

1. **Validator Node Degradation**: Any validator or fullnode performing fast sync with `enable_indexer=true` experiences permanent indexer lag
2. **API Data Corruption**: The indexer serves the `/accounts`, `/events`, `/transactions` API endpoints. With the indexer stuck at version 0, these endpoints return empty or stale data indefinitely
3. **dApp Service Disruption**: Applications relying on node APIs receive incorrect data, causing transaction failures, balance mismatches, and broken user experiences
4. **No Automatic Recovery**: The issue persists until manual database intervention (deleting and rebuilding the indexer database)
5. **Silent Failure**: Errors are only logged as warnings; operators may not realize the indexer is broken until users report issues

The impact meets the **High Severity** criteria for "API crashes" and "Significant protocol violations" as the indexer API becomes effectively non-functional while appearing operational.

## Likelihood Explanation

**Likelihood: High**

This vulnerability triggers under common operational conditions:

1. **Common Scenario**: Fast sync (`BootstrappingMode::DownloadLatestStates`) is the recommended bootstrapping mode for new nodes joining the network [6](#0-5) 

2. **Indexer Usage**: The `enable_indexer` flag is used in production configurations including mainnet genesis and forge testing frameworks [7](#0-6) 

3. **No Attacker Required**: This is a logic bug triggered by normal fast sync operations; no malicious actor needed
4. **Affects All Node Types**: Both validators and fullnodes performing fast sync with indexer enabled are affected
5. **Persistent Failure**: Once triggered, every subsequent commit fails the indexer update, making the issue permanent

## Recommendation

Implement a post-fast-sync catch-up mechanism that triggers when the indexer detects a version gap. Add this logic to the `FastSyncStorageWrapper`:

```rust
// In storage/aptosdb/src/fast_sync_storage_wrapper.rs
impl DbWriter for FastSyncStorageWrapper {
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let status = self.get_fast_sync_status();
        assert_eq!(status, FastSyncStatus::STARTED);
        
        // Execute original finalization
        self.get_aptos_db_write_ref().finalize_state_snapshot(
            version,
            output_with_proof,
            ledger_infos,
        )?;
        
        // NEW: Trigger indexer catch-up after fast sync
        if let Some(indexer) = &self.get_aptos_db_write_ref().indexer {
            let ledger_version = version + 1;
            let indexer_version = indexer.next_version();
            if indexer_version < ledger_version {
                info!(
                    "Catching up indexer after fast sync: {} -> {}",
                    indexer_version, ledger_version
                );
                // Trigger catch-up with batched processing
                self.get_aptos_db_write_ref()
                    .catch_up_indexer(indexer_version, ledger_version)?;
            }
        }
        
        let mut status = self.fast_sync_status.write();
        *status = FastSyncStatus::FINISHED;
        Ok(())
    }
}
```

Additionally, modify `index_with_annotator()` to handle gaps more gracefully by allowing the indexer to skip ahead:

```rust
// In storage/indexer/src/lib.rs, modify index_with_annotator:
pub fn index_with_annotator<R: StateView>(
    &self,
    annotator: &AptosValueAnnotator<R>,
    first_version: Version,
    write_sets: &[&WriteSet],
) -> Result<()> {
    let next_version = self.next_version();
    
    // Allow skipping ahead if there's a gap (e.g., from fast sync)
    if first_version > next_version {
        warn!(
            "Indexer version gap detected. Skipping from {} to {}. \
             This can happen after fast sync.",
            next_version,
            first_version
        );
        // Update next_version to first_version to close the gap
        self.next_version.store(first_version, Ordering::Relaxed);
    }
    
    let end_version = first_version + write_sets.len() as Version;
    if end_version <= self.next_version() {
        // ... rest of existing logic
    }
    // ... continue with existing implementation
}
```

## Proof of Concept

```rust
// Rust reproduction test (add to storage/aptosdb/src/db/aptosdb_test.rs)
#[test]
fn test_indexer_gap_after_fast_sync_simulation() {
    use crate::AptosDB;
    use aptos_config::config::{NodeConfig, StorageDirPaths};
    use aptos_temppath::TempPath;
    use aptos_types::transaction::{Transaction, WriteSet};
    
    // Setup: Create database with indexer enabled
    let tmp_dir = TempPath::new();
    let config = NodeConfig::default();
    
    let db = AptosDB::open(
        StorageDirPaths::from_path(&tmp_dir),
        false, // readonly
        config.storage.storage_pruner_config,
        config.storage.rocksdb_configs,
        true, // enable_indexer = true
        config.storage.buffered_state_target_items,
        config.storage.max_num_nodes_per_lru_cache_shard,
        None,
        config.storage.hot_state_config,
    ).unwrap();
    
    // Verify indexer starts at version 0
    if let Some(indexer) = &db.indexer {
        assert_eq!(indexer.next_version(), 0);
    }
    
    // Simulate fast sync: Directly finalize state at version 1000
    // without going through normal commit path
    let output_with_proof = create_mock_transaction_output_with_proof(1000);
    let ledger_infos = vec![create_mock_ledger_info(1000)];
    
    db.finalize_state_snapshot(1000, output_with_proof, &ledger_infos).unwrap();
    
    // Verify ledger advanced to version 1000
    assert_eq!(db.get_synced_version().unwrap(), Some(1000));
    
    // Verify indexer still at version 0 (the bug)
    if let Some(indexer) = &db.indexer {
        assert_eq!(indexer.next_version(), 0, "Indexer should still be at version 0");
    }
    
    // Attempt normal commit at version 1001
    let chunk = create_mock_chunk_to_commit(1001, 1);
    let result = db.pre_commit_ledger(chunk.clone(), false);
    assert!(result.is_ok());
    
    let commit_result = db.commit_ledger(1001, None, Some(chunk));
    // Commit succeeds but indexer update fails silently
    assert!(commit_result.is_ok());
    
    // Verify indexer is STILL at version 0 (permanent lag)
    if let Some(indexer) = &db.indexer {
        assert_eq!(indexer.next_version(), 0, "BUG: Indexer permanently stuck at version 0");
    }
}
```

**Notes:**
- This vulnerability affects the legacy `Indexer` (`storage/indexer/src/lib.rs`), not the newer `InternalIndexerDB` system
- The legacy indexer is marked for deprecation (line 4 comment) but remains active in production code
- Fast sync is commonly used for bootstrapping new nodes, making this a high-probability issue
- The vulnerability requires no attacker; it's triggered by normal operational patterns
- Manual remediation requires deleting and rebuilding the indexer database, causing operational disruption

### Citations

**File:** storage/indexer/src/lib.rs (L102-107)
```rust
        db_ensure!(
            first_version <= next_version,
            "Indexer expects to see continuous transaction versions. Expecting: {}, got: {}",
            next_version,
            first_version,
        );
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-241)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
            ensure!(
                num_transaction_outputs == 1,
                "Number of transaction outputs should == 1, but got: {}",
                num_transaction_outputs
            );
            ensure!(
                num_transaction_infos == 1,
                "Number of transaction infos should == 1, but got: {}",
                num_transaction_infos
            );

            // TODO(joshlind): include confirm_or_save_frozen_subtrees in the change set
            // bundle below.

            // Update the merkle accumulator using the given proof
            let frozen_subtrees = output_with_proof
                .proof
                .ledger_info_to_transaction_infos_proof
                .left_siblings();
            restore_utils::confirm_or_save_frozen_subtrees(
                self.ledger_db.transaction_accumulator_db_raw(),
                version,
                frozen_subtrees,
                None,
            )?;

            // Create a single change set for all further write operations
            let mut ledger_db_batch = LedgerDbSchemaBatches::new();
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
            // Save the target transactions, outputs, infos and events
            let (transactions, outputs): (Vec<Transaction>, Vec<TransactionOutput>) =
                output_with_proof
                    .transactions_and_outputs
                    .into_iter()
                    .unzip();
            let events = outputs
                .clone()
                .into_iter()
                .map(|output| output.events().to_vec())
                .collect::<Vec<_>>();
            let wsets: Vec<WriteSet> = outputs
                .into_iter()
                .map(|output| output.write_set().clone())
                .collect();
            let transaction_infos = output_with_proof.proof.transaction_infos;
            // We should not save the key value since the value is already recovered for this version
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;

            // Save the epoch ending ledger infos
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;

            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;

            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;

            restore_utils::update_latest_ledger_info(self.ledger_db.metadata_db(), ledger_infos)?;
            self.state_store.reset();

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L603-659)
```rust
    fn post_commit(
        &self,
        old_committed_version: Option<Version>,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        // If commit succeeds and there are at least one transaction written to the storage, we
        // will inform the pruner thread to work.
        if old_committed_version.is_none() || version > old_committed_version.unwrap() {
            let first_version = old_committed_version.map_or(0, |v| v + 1);
            let num_txns = version + 1 - first_version;

            COMMITTED_TXNS.inc_by(num_txns);
            LATEST_TXN_VERSION.set(version as i64);
            if let Some(update_sender) = &self.update_subscriber {
                update_sender
                    .send((Instant::now(), version))
                    .map_err(|err| {
                        AptosDbError::Other(format!("Failed to send update to subscriber: {}", err))
                    })?;
            }
            // Activate the ledger pruner and state kv pruner.
            // Note the state merkle pruner is activated when state snapshots are persisted
            // in their async thread.
            self.ledger_pruner
                .maybe_set_pruner_target_db_version(version);
            self.state_store
                .state_kv_pruner
                .maybe_set_pruner_target_db_version(version);

            // Note: this must happen after txns have been saved to db because types can be newly
            // created in this same chunk of transactions.
            if let Some(indexer) = &self.indexer {
                let _timer = OTHER_TIMERS_SECONDS.timer_with(&["indexer_index"]);
                // n.b. txns_to_commit can be partial, when the control was handed over from consensus to state sync
                // where state sync won't send the pre-committed part to the DB again.
                if let Some(chunk) = chunk_opt
                    && chunk.len() == num_txns as usize
                {
                    let write_sets = chunk
                        .transaction_outputs
                        .iter()
                        .map(|t| t.write_set())
                        .collect_vec();
                    indexer.index(self.state_store.clone(), first_version, &write_sets)?;
                } else {
                    let write_sets: Vec<_> = self
                        .ledger_db
                        .write_set_db()
                        .get_write_set_iter(first_version, num_txns as usize)?
                        .try_collect()?;
                    let write_set_refs = write_sets.iter().collect_vec();
                    indexer.index(self.state_store.clone(), first_version, &write_set_refs)?;
                };
            }
        }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L184-233)
```rust
        if !readonly && enable_indexer {
            myself.open_indexer(
                db_paths.default_root_path(),
                rocksdb_configs.index_db_config,
            )?;
        }

        Ok(myself)
    }

    fn open_indexer(
        &mut self,
        db_root_path: impl AsRef<Path>,
        rocksdb_config: RocksdbConfig,
    ) -> Result<()> {
        let indexer = Indexer::open(&db_root_path, rocksdb_config)?;
        let ledger_next_version = self.get_synced_version()?.map_or(0, |v| v + 1);
        info!(
            indexer_next_version = indexer.next_version(),
            ledger_next_version = ledger_next_version,
            "Opened AptosDB Indexer.",
        );

        if indexer.next_version() < ledger_next_version {
            use aptos_storage_interface::state_store::state_view::db_state_view::DbStateViewAtVersion;
            let db: Arc<dyn DbReader> = self.state_store.clone();

            let state_view = db.state_view_at_version(Some(ledger_next_version - 1))?;
            let annotator = AptosValueAnnotator::new(&state_view);

            const BATCH_SIZE: Version = 10000;
            let mut next_version = indexer.next_version();
            while next_version < ledger_next_version {
                info!(next_version = next_version, "AptosDB Indexer catching up. ",);
                let end_version = std::cmp::min(ledger_next_version, next_version + BATCH_SIZE);
                let write_sets = self
                    .ledger_db
                    .write_set_db()
                    .get_write_sets(next_version, end_version)?;
                let write_sets_ref: Vec<_> = write_sets.iter().collect();
                indexer.index_with_annotator(&annotator, next_version, &write_sets_ref)?;

                next_version = end_version;
            }
        }
        info!("AptosDB Indexer caught up.");

        self.indexer = Some(indexer);
        Ok(())
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L173-177)
```rust
async fn wait_and_log_error<T, F: Future<Output = TaskResult<T>>>(f: F, msg: String) {
    if let Err(TaskError::InternalError(e)) = f.await {
        warn!("{} failed: {}", msg, e);
    }
}
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L66-77)
```rust
        if config
            .state_sync
            .state_sync_driver
            .bootstrapping_mode
            .is_fast_sync()
            && (db_main
                .ledger_db
                .metadata_db()
                .get_synced_version()?
                .map_or(0, |v| v)
                == 0)
        {
```

**File:** config/src/config/storage_config.rs (L295-295)
```rust
    pub enable_indexer: bool,
```
