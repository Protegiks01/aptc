# Audit Report

## Title
Non-Atomic Database Updates During State Snapshot Restore Lead to Inconsistent Partial State

## Summary
During state snapshot restoration, the internal indexer database is committed before the main state KV database, violating atomicity. If the main database commit fails, the internal indexer database retains orphaned keys with progress markers that don't correspond to the actual state, leading to database inconsistency that is silently accepted on resume attempts.

## Finding Description

The state snapshot restore process updates two databases: the main state KV database and the optional internal indexer database. The vulnerability occurs in the `write_kv_batch` method where these updates are not atomic. [1](#0-0) 

The critical sequence is:

1. **Line 1267-1270**: `write_keys_to_indexer_db` is called, which immediately commits keys and progress to the internal indexer database [2](#0-1) 

2. **Line 1277-1278**: The main state KV database commit is attempted

If step 2 fails (due to disk errors, panics in shard commits, etc.), the internal indexer database has already been permanently updated while the main database has not. The failure can occur in the parallel shard commit: [3](#0-2) 

When a shard commit fails, it panics (line 196), but the internal indexer DB was already committed earlier.

On resume, the `get_progress` method checks for consistency but silently accepts the case where the internal indexer has progress but the main DB doesn't: [4](#0-3) 

Line 1340 accepts `(None, Some(_))` without error, returning the main DB progress (None), effectively ignoring that the indexer DB is ahead and contains orphaned data.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria:

- **State inconsistencies requiring intervention**: The two databases become desynchronized, with the indexer DB containing keys that don't exist in the main state DB
- **Restore process corruption**: Subsequent restore attempts proceed with incomplete progress information, potentially requiring manual database cleanup
- **Query inconsistencies**: During the inconsistency window, the internal indexer may respond to queries about state keys that don't actually exist in the committed state, potentially causing errors in dependent systems

While not directly causing fund loss or consensus violations, this breaks the **State Consistency** invariant that "state transitions must be atomic and verifiable." The orphaned indexer data can lead to operational issues requiring manual intervention to clean up the databases.

## Likelihood Explanation

The likelihood is **Medium to High**:

- **Common trigger conditions**: Any I/O error, disk full condition, or filesystem permission issue during the state KV commit will trigger this vulnerability
- **Automatic occurrence**: When internal indexer is enabled (common in production for query performance), this happens automatically during any restore failure
- **No special privileges required**: Any node operator performing state restoration can encounter this
- **Persistent effects**: The inconsistency persists across restart attempts until manually cleaned up

The TODO comment indicates awareness of the panic handling issue but not the atomicity problem with the internal indexer. [5](#0-4) 

## Recommendation

Implement atomic two-phase commit for both databases:

```rust
fn write_kv_batch(
    &self,
    version: Version,
    node_batch: &StateValueBatch,
    progress: StateSnapshotProgress,
) -> Result<()> {
    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_writer_write_chunk"]);
    let mut batch = SchemaBatch::new();
    let mut sharded_schema_batch = self.state_kv_db.new_sharded_native_batches();

    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
        &DbMetadataValue::StateSnapshotProgress(progress),
    )?;

    // Prepare indexer batch but DON'T commit yet
    let mut indexer_batch = None;
    if self.internal_indexer_db.is_some()
        && self.internal_indexer_db.as_ref().unwrap().statekeys_enabled()
    {
        let keys = node_batch.keys().map(|key| key.0.clone()).collect();
        let mut batch = SchemaBatch::new();
        for state_key in keys.iter() {
            batch.put::<StateKeysSchema>(state_key, &())?;
        }
        batch.put::<InternalIndexerMetadataSchema>(
            &MetadataKey::StateSnapshotRestoreProgress(version),
            &MetadataValue::StateSnapshotProgress(progress),
        )?;
        indexer_batch = Some(batch);
    }
    
    self.shard_state_value_batch(
        &mut sharded_schema_batch,
        node_batch,
        self.state_kv_db.enabled_sharding(),
    )?;
    
    // Commit main DB first
    self.state_kv_db.commit(version, Some(batch), sharded_schema_batch)?;
    
    // Only commit indexer DB after main DB succeeds
    if let (Some(indexer_batch), Some(internal_indexer_db)) = 
        (indexer_batch, self.internal_indexer_db.as_ref()) {
        internal_indexer_db.get_inner_db_ref().write_schemas(indexer_batch)?;
    }
    
    Ok(())
}
```

Additionally, fix the `get_progress` check to reject the inconsistent state:

```rust
match (main_db_progress, progress_opt) {
    (None, None) => (),
    (None, Some(_)) => {
        bail!(
            "Inconsistent restore progress: internal indexer db has progress but main db doesn't. \
            This indicates a previous restore failure. Manual cleanup required."
        );
    },
    // ... rest of cases
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_atomicity_violation {
    use super::*;
    use std::sync::Arc;
    
    #[test]
    fn test_indexer_orphaned_after_main_db_failure() {
        // Setup: Create state store with internal indexer enabled
        let tmpdir = tempfile::tempdir().unwrap();
        let db_path = tmpdir.path();
        let state_store = create_state_store_with_indexer(db_path);
        
        // Prepare a batch of state values
        let version = 100;
        let state_values = create_test_state_values(10);
        let progress = StateSnapshotProgress::new(HashValue::random(), StateStorageUsage::zero());
        
        // Simulate failure scenario by filling disk or forcing I/O error
        // This would cause state_kv_db.commit to fail after indexer is committed
        
        // Verify: indexer DB has the keys
        let indexer_progress = state_store.internal_indexer_db
            .as_ref().unwrap()
            .get_restore_progress(version).unwrap();
        assert!(indexer_progress.is_some());
        
        // Verify: main DB does NOT have the keys (commit failed)
        let main_progress = state_store.state_kv_db.metadata_db()
            .get::<DbMetadataSchema>(&DbMetadataKey::StateSnapshotKvRestoreProgress(version))
            .unwrap();
        assert!(main_progress.is_none());
        
        // Resume: get_progress silently accepts this inconsistency
        let resume_progress = state_store.get_progress(version).unwrap();
        assert!(resume_progress.is_none()); // Uses main DB, ignoring indexer inconsistency
        
        // This leaves orphaned keys in indexer DB with no corresponding main DB data
    }
}
```

## Notes

This vulnerability demonstrates a classic atomicity violation in distributed database operations. The fix requires ensuring both databases commit successfully before considering the operation complete, implementing proper rollback on failure, or accepting the inconsistency and implementing a cleanup mechanism during resume.

The issue is compounded by the panic-on-error approach in shard commits, which prevents proper error propagation and recovery. The combination of immediate indexer commit + deferred main DB commit + panic-based error handling creates a perfect storm for database inconsistency.

### Citations

**File:** storage/aptosdb/src/state_store/mod.rs (L1244-1279)
```rust
    fn write_kv_batch(
        &self,
        version: Version,
        node_batch: &StateValueBatch,
        progress: StateSnapshotProgress,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_value_writer_write_chunk"]);
        let mut batch = SchemaBatch::new();
        let mut sharded_schema_batch = self.state_kv_db.new_sharded_native_batches();

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateSnapshotKvRestoreProgress(version),
            &DbMetadataValue::StateSnapshotProgress(progress),
        )?;

        if self.internal_indexer_db.is_some()
            && self
                .internal_indexer_db
                .as_ref()
                .unwrap()
                .statekeys_enabled()
        {
            let keys = node_batch.keys().map(|key| key.0.clone()).collect();
            self.internal_indexer_db
                .as_ref()
                .unwrap()
                .write_keys_to_indexer_db(&keys, version, progress)?;
        }
        self.shard_state_value_batch(
            &mut sharded_schema_batch,
            node_batch,
            self.state_kv_db.enabled_sharding(),
        )?;
        self.state_kv_db
            .commit(version, Some(batch), sharded_schema_batch)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1338-1360)
```rust
            match (main_db_progress, progress_opt) {
                (None, None) => (),
                (None, Some(_)) => (),
                (Some(main_progress), Some(indexer_progress)) => {
                    if main_progress.key_hash > indexer_progress.key_hash {
                        bail!(
                            "Inconsistent restore progress between main db and internal indexer db. main db: {:?}, internal indexer db: {:?}",
                            main_progress,
                            indexer_progress,
                        );
                    }
                },
                _ => {
                    bail!(
                        "Inconsistent restore progress between main db and internal indexer db. main db: {:?}, internal indexer db: {:?}",
                        main_db_progress,
                        progress_opt,
                    );
                },
            }
        }

        Ok(main_db_progress)
```

**File:** storage/indexer/src/db_indexer.rs (L90-108)
```rust
    pub fn write_keys_to_indexer_db(
        &self,
        keys: &Vec<StateKey>,
        snapshot_version: Version,
        progress: StateSnapshotProgress,
    ) -> Result<()> {
        // add state value to internal indexer
        let mut batch = SchemaBatch::new();
        for state_key in keys {
            batch.put::<StateKeysSchema>(state_key, &())?;
        }

        batch.put::<InternalIndexerMetadataSchema>(
            &MetadataKey::StateSnapshotRestoreProgress(snapshot_version),
            &MetadataValue::StateSnapshotProgress(progress),
        )?;
        self.db.write_schemas(batch)?;
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L186-200)
```rust
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
```
