# Audit Report

## Title
Mempool Broadcast Stuck State Due to Sender Bucket Priority Changes During Pending Broadcasts (Non-Validators)

## Summary
In non-validator nodes, when sender bucket assignments change via peer priority updates while broadcasts are pending ACK, the retry/expired broadcast path returns empty transactions even though transactions exist in the mempool. This causes the peer to enter a stuck state where all subsequent broadcast attempts fail with `NoTransactions` error, blocking fresh broadcasts until the original transactions are committed. [1](#0-0) 

## Finding Description
The vulnerability occurs in the `determine_broadcast_batch()` function when processing expired or retry broadcasts for non-validator nodes. The issue manifests through the following sequence:

1. **Initial Broadcast (T0)**: A non-validator node sends a broadcast to Peer A containing transactions from sender bucket 0. The message ID is stored in `state.broadcast_info.sent_messages`. [2](#0-1) 

2. **Peer Priority Update (T1)**: The `update_prioritized_peers()` method is called (triggered by load changes or peer metadata updates), which invokes `update_sender_bucket_for_peers()` to reassign sender buckets based on load balancing. [3](#0-2) 

During this update, Peer A loses access to sender bucket 0 (reassigned to different peers or buckets). The peer is removed from `peer_to_sender_buckets` mapping for bucket 0.

3. **Broadcast Timeout/Retry (T2)**: The original broadcast times out or needs retry. The code finds the expired/retry message and attempts to reconstruct transactions. [4](#0-3) 

For non-validators, `get_sender_bucket_priority_for_peer()` is called for each sender bucket in the message. Since Peer A no longer has access to bucket 0, this returns `None`. [5](#0-4) 

The `map_or_else(Vec::new, ...)` pattern returns an empty vector, causing all transactions to be filtered out even though they still exist in the mempool timeline.

4. **Stuck State**: The function returns `BroadcastError::NoTransactions`. [6](#0-5) 

However, the message remains in tracking because the timeline is not actually empty (the filtering at lines 400-421 checks `timeline_range_of_message()`, which still contains transactions). [7](#0-6) 

5. **Fresh Broadcast Blockage**: The next broadcast attempt finds the same expired/retry message (since it wasn't cleared from tracking), prioritizes it over fresh broadcasts, and repeats the failure cycle. [8](#0-7) 

The peer remains stuck unable to receive any new transactions until the original transactions in the old sender bucket are committed and removed from the timeline.

## Impact Explanation
**Medium Severity** per Aptos bug bounty criteria:

- **State Inconsistencies**: The peer enters a stuck state where broadcast tracking shows pending messages that can never be successfully retried, creating inconsistency between actual mempool state and broadcast state.

- **Transaction Propagation Delays**: Fresh transactions in sender buckets that the peer CAN access are not broadcast because retry/expired messages take precedence. This degrades transaction propagation across the network.

- **Operational Impact**: Affects all non-validator nodes (VFNs and PFNs) during normal load-based peer priority updates. In high-load scenarios with frequent priority updates, multiple peers could enter stuck states simultaneously.

This does NOT constitute Critical or High severity because:
- No consensus violations occur (validators are unaffected)
- No fund loss or theft is possible
- Transactions will eventually propagate through other peers
- The stuck state clears when transactions commit
- Network remains operational overall

## Likelihood Explanation
**High Likelihood** - This occurs during normal operation without any malicious activity:

1. **Trigger Condition**: Peer priority updates happen automatically based on:
   - Load balancing thresholds exceeded (mempool traffic increases)
   - Peer metadata changes (ping latencies, sync lag)
   - Time-based priority refresh intervals [9](#0-8) 

2. **Timing Window**: The broadcast ACK timeout is configurable but typically several seconds, providing ample opportunity for priority updates to occur during pending broadcasts. [10](#0-9) 

3. **Affected Nodes**: All non-validator nodes using intelligent peer prioritization are vulnerable. Validators are immune because they don't use sender bucket priority filtering.

4. **Compounding Factor**: Under high load (when priority updates are most frequent), the issue becomes more severe as more peers get stuck, further degrading transaction propagation.

## Recommendation

The code should distinguish between two cases:
1. Empty timeline (transactions committed) - correctly return `NoTransactions`
2. Inaccessible timeline (peer lost sender bucket access) - should clear the message from tracking and allow fresh broadcasts

**Proposed Fix** in `determine_broadcast_batch()`:

```rust
let txns = message_id
    .decode()
    .into_iter()
    .flat_map(|(sender_bucket, start_end_pairs)| {
        if self.node_type.is_validator() {
            // Validator path unchanged
            mempool
                .timeline_range(sender_bucket, start_end_pairs)
                .into_iter()
                .map(|(txn, ready_time)| {
                    (txn, ready_time, BroadcastPeerPriority::Primary)
                })
                .collect::<Vec<_>>()
        } else {
            // Check if peer still has access to this sender bucket
            match self.prioritized_peers_state
                .get_sender_bucket_priority_for_peer(&peer, sender_bucket) {
                Some(priority) => {
                    // Peer has access - return transactions with priority
                    mempool
                        .timeline_range(sender_bucket, start_end_pairs)
                        .into_iter()
                        .map(|(txn, ready_time)| {
                            (txn, ready_time, priority.clone())
                        })
                        .collect::<Vec<_>>()
                },
                None => {
                    // Peer lost access - remove this message from tracking
                    // and return empty to skip this sender bucket
                    state.broadcast_info.sent_messages.remove(&message_id);
                    state.broadcast_info.retry_messages.remove(&message_id);
                    Vec::new()
                }
            }
        }
    })
    .collect::<Vec<_>>();

// If transactions is empty due to peer priority changes, 
// fall through to fresh broadcast instead of returning error
if txns.is_empty() && (expired_message_id.is_some() || retry_message_id.is_some()) {
    // Check if it was genuinely empty vs lost access
    // If lost access, we already removed from tracking above
    // Fall through to fresh broadcast (None case)
    None
} else {
    Some((message_id.clone(), txns, metric_label))
}
```

Alternatively, a simpler fix is to detect when `get_sender_bucket_priority_for_peer` returns `None` during retry/expired processing and immediately clear that message from tracking, then proceed to fresh broadcast path.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_config::config::{MempoolConfig, NodeType};
    use aptos_time_service::TimeService;
    
    #[tokio::test]
    async fn test_broadcast_stuck_on_priority_change() {
        // Setup non-validator node
        let mempool_config = MempoolConfig::default();
        let node_type = NodeType::PublicFullnode;
        
        // Create network interface with mocked client
        let network_client = MockNetworkClient::new();
        let mut network_interface = MempoolNetworkInterface::new(
            network_client,
            node_type,
            mempool_config.clone(),
        );
        
        // Add a peer and assign sender bucket 0
        let peer = create_test_peer();
        let peer_metadata = create_test_metadata();
        network_interface.update_peers(&hashmap! {
            peer => peer_metadata.clone()
        });
        
        // Create mempool with transactions in sender bucket 0
        let mut mempool = CoreMempool::new(&mempool_config);
        add_test_transactions(&mut mempool, /* sender_bucket */ 0, /* count */ 10);
        
        // Execute initial broadcast to peer
        let mut smp = create_shared_mempool(mempool, network_interface);
        network_interface
            .execute_broadcast(peer, false, &mut smp)
            .await
            .expect("Initial broadcast should succeed");
        
        // Verify message is in sent_messages
        let sync_states = network_interface.sync_states.read();
        let state = sync_states.get(&peer).unwrap();
        assert!(!state.broadcast_info.sent_messages.is_empty());
        let message_id = state.broadcast_info.sent_messages.keys().next().unwrap();
        
        // Update peer priorities - peer loses access to sender bucket 0
        // This simulates load-based rebalancing
        network_interface.prioritized_peers_state
            .update_prioritized_peers(
                vec![(peer, Some(&peer_metadata))],
                10000, // High mempool traffic
                5000,  // High committed traffic
            );
        
        // Verify peer lost access to sender bucket 0
        assert!(network_interface.prioritized_peers_state
            .get_sender_bucket_priority_for_peer(&peer, 0)
            .is_none());
        
        // Wait for broadcast timeout
        tokio::time::sleep(Duration::from_millis(
            mempool_config.shared_mempool_ack_timeout_ms + 100
        )).await;
        
        // Attempt next broadcast - should fail with NoTransactions
        // but message remains in tracking
        let result = network_interface
            .execute_broadcast(peer, false, &mut smp)
            .await;
        
        assert!(matches!(result, Err(BroadcastError::NoTransactions(_))));
        
        // Verify message is STILL in sent_messages (stuck state)
        let sync_states = network_interface.sync_states.read();
        let state = sync_states.get(&peer).unwrap();
        assert!(state.broadcast_info.sent_messages.contains_key(&message_id),
            "Message should still be tracked, creating stuck state");
        
        // Verify subsequent broadcasts continue to fail
        for _ in 0..5 {
            let result = network_interface
                .execute_broadcast(peer, false, &mut smp)
                .await;
            assert!(matches!(result, Err(BroadcastError::NoTransactions(_))),
                "Peer remains stuck in retry loop");
        }
        
        // Verify fresh transactions in OTHER sender buckets cannot be broadcast
        add_test_transactions(&mut smp.mempool.lock(), /* sender_bucket */ 1, /* count */ 5);
        
        // These transactions won't propagate because expired message takes precedence
        let result = network_interface
            .execute_broadcast(peer, false, &mut smp)
            .await;
        assert!(matches!(result, Err(BroadcastError::NoTransactions(_))),
            "Fresh broadcasts are blocked by stuck retry message");
    }
}
```

## Notes
- This vulnerability only affects non-validator nodes (VFNs and PFNs) because validators don't use sender bucket priority filtering
- The issue becomes more severe under high load when peer priority updates are frequent
- The stuck state clears when the transactions in the original sender bucket are committed, making this a transient but recurring issue
- Multiple peers can be affected simultaneously during load spikes, significantly degrading transaction propagation network-wide
- The root cause is the inability to distinguish between "timeline empty because transactions committed" vs "timeline inaccessible because peer lost sender bucket access"

### Citations

**File:** mempool/src/shared_mempool/network.rs (L400-421)
```rust
        state.broadcast_info.sent_messages = state
            .broadcast_info
            .sent_messages
            .clone()
            .into_iter()
            .filter(|(message_id, _batch)| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeMap<MempoolMessageId, SystemTime>>();
        state.broadcast_info.retry_messages = state
            .broadcast_info
            .retry_messages
            .clone()
            .into_iter()
            .filter(|message_id| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeSet<MempoolMessageId>>();
```

**File:** mempool/src/shared_mempool/network.rs (L432-434)
```rust
            let deadline = sent_time.add(Duration::from_millis(
                self.mempool_config.shared_mempool_ack_timeout_ms,
            ));
```

**File:** mempool/src/shared_mempool/network.rs (L452-490)
```rust
        let (message_id, transactions, metric_label) =
            match std::cmp::max(expired_message_id, retry_message_id) {
                Some(message_id) => {
                    let metric_label = if Some(message_id) == expired_message_id {
                        Some(counters::EXPIRED_BROADCAST_LABEL)
                    } else {
                        Some(counters::RETRY_BROADCAST_LABEL)
                    };

                    let txns = message_id
                        .decode()
                        .into_iter()
                        .flat_map(|(sender_bucket, start_end_pairs)| {
                            if self.node_type.is_validator() {
                                mempool
                                    .timeline_range(sender_bucket, start_end_pairs)
                                    .into_iter()
                                    .map(|(txn, ready_time)| {
                                        (txn, ready_time, BroadcastPeerPriority::Primary)
                                    })
                                    .collect::<Vec<_>>()
                            } else {
                                self.prioritized_peers_state
                                    .get_sender_bucket_priority_for_peer(&peer, sender_bucket)
                                    .map_or_else(Vec::new, |priority| {
                                        mempool
                                            .timeline_range(sender_bucket, start_end_pairs)
                                            .into_iter()
                                            .map(|(txn, ready_time)| {
                                                (txn, ready_time, priority.clone())
                                            })
                                            .collect::<Vec<_>>()
                                    })
                            }
                        })
                        .collect::<Vec<_>>();
                    (message_id.clone(), txns, metric_label)
                },
                None => {
```

**File:** mempool/src/shared_mempool/network.rs (L565-567)
```rust
        if transactions.is_empty() {
            return Err(BroadcastError::NoTransactions(peer));
        }
```

**File:** mempool/src/shared_mempool/network.rs (L629-633)
```rust
        state
            .broadcast_info
            .sent_messages
            .insert(message_id, send_time);
        Ok(state.broadcast_info.sent_messages.len())
```

**File:** mempool/src/shared_mempool/priority.rs (L205-213)
```rust
    pub fn get_sender_bucket_priority_for_peer(
        &self,
        peer: &PeerNetworkId,
        sender_bucket: MempoolSenderBucket,
    ) -> Option<BroadcastPeerPriority> {
        self.peer_to_sender_buckets
            .get(peer)
            .and_then(|buckets| buckets.get(&sender_bucket).cloned())
    }
```

**File:** mempool/src/shared_mempool/priority.rs (L216-242)
```rust
    pub fn ready_for_update(&self, peers_changed: bool) -> bool {
        // If intelligent peer prioritization is disabled, we should only
        // update the prioritized peers if the peers have changed.
        if !self.mempool_config.enable_intelligent_peer_prioritization {
            return peers_changed;
        }

        // Otherwise, we should update the prioritized peers if the peers have changed
        // or if we haven't observed ping latencies for all peers yet. This is useful
        // because latencies are only populated some time after the peer connects, so
        // we should continuously reprioritize until latencies are observed for all peers.
        if peers_changed || !self.observed_all_ping_latencies {
            return true;
        }

        // Otherwise, we should only update if enough time has passed since the last update
        match self.last_peer_priority_update {
            None => true, // We haven't updated yet
            Some(last_update) => {
                let duration_since_update = self.time_service.now().duration_since(last_update);
                let update_interval_secs = self
                    .mempool_config
                    .shared_mempool_priority_update_interval_secs;
                duration_since_update.as_secs() > update_interval_secs
            },
        }
    }
```

**File:** mempool/src/shared_mempool/priority.rs (L272-432)
```rust
    fn update_sender_bucket_for_peers(
        &mut self,
        peer_monitoring_data: &HashMap<PeerNetworkId, Option<&PeerMonitoringMetadata>>,
        num_mempool_txns_received_since_peers_updated: u64,
        num_committed_txns_received_since_peers_updated: u64,
    ) {
        // TODO: If the top peer set didn't change, then don't change the Primary sender bucket assignment.
        // TODO: (Minor) If the load is low, don't do load balancing for Failover buckets.
        assert!(self.prioritized_peers.read().len() == peer_monitoring_data.len());

        // Obtain the top peers to assign the sender buckets with Primary priority
        let mut top_peers = vec![];
        let secs_elapsed_since_last_update =
            self.last_peer_priority_update.map_or(0, |last_update| {
                self.time_service
                    .now()
                    .duration_since(last_update)
                    .as_secs()
            });

        // When the node is in state sync mode, it will receive more mempool commit notifications than the actual
        // commits that happens on the blockchain during the same time period. As secs_elapsed_since_last_update is
        // local time and not the on chain time, the average_committed_traffic_observed is only a local estimate of
        // the traffic and could differ from the actual traffic observed by the blockchain. If the estimate differs
        // from the actual traffic observed on the blockchain, we could end up load balancing more or less than required.
        let average_mempool_traffic_observed = num_mempool_txns_received_since_peers_updated as f64
            / max(1, secs_elapsed_since_last_update) as f64;
        let average_committed_traffic_observed = num_committed_txns_received_since_peers_updated
            as f64
            / max(1, secs_elapsed_since_last_update) as f64;

        // Obtain the highest threshold from mempool_config.load_balancing_thresholds for which avg_mempool_traffic_threshold_in_tps exceeds average_mempool_traffic_observed
        let threshold_config = self
            .mempool_config
            .load_balancing_thresholds
            .clone()
            .into_iter()
            .rev()
            .find(|threshold_config| {
                threshold_config.avg_mempool_traffic_threshold_in_tps
                    <= max(
                        average_mempool_traffic_observed as u64,
                        average_committed_traffic_observed as u64,
                    )
            })
            .unwrap_or_default();

        let num_top_peers = max(
            1,
            min(
                self.mempool_config.num_sender_buckets,
                if self.mempool_config.enable_max_load_balancing_at_any_load {
                    u8::MAX
                } else {
                    threshold_config.max_number_of_upstream_peers
                },
            ),
        );
        info!(
            "Time elapsed since last peer update: {:?}\n
            Number of mempool transactions received since last peer update: {:?},\n
            Average mempool traffic observed: {:?},\n
            Number of committed transactions received since last peer update: {:?},\n
            Average committed traffic observed: {:?},\n
            Load balancing threshold config: {:?},\n
            Number of top peers picked: {:?}",
            secs_elapsed_since_last_update,
            num_mempool_txns_received_since_peers_updated,
            average_mempool_traffic_observed,
            num_committed_txns_received_since_peers_updated,
            average_committed_traffic_observed,
            threshold_config,
            num_top_peers
        );

        if self.node_type.is_validator_fullnode() {
            // Use the peer on the VFN network with lowest ping latency as the primary peer
            let peers_in_vfn_network = self
                .prioritized_peers
                .read()
                .iter()
                .cloned()
                .filter(|peer| peer.network_id() == NetworkId::Vfn)
                .collect::<Vec<_>>();

            if !peers_in_vfn_network.is_empty() {
                top_peers = vec![peers_in_vfn_network[0]];
            }
        }

        if top_peers.is_empty() {
            let base_ping_latency = self.prioritized_peers.read().first().and_then(|peer| {
                peer_monitoring_data
                    .get(peer)
                    .and_then(|metadata| get_peer_ping_latency(metadata))
            });

            // Extract top peers with ping latency less than base_ping_latency + 50 ms
            for peer in self.prioritized_peers.read().iter() {
                if top_peers.len() >= num_top_peers as usize {
                    break;
                }

                let ping_latency = peer_monitoring_data
                    .get(peer)
                    .and_then(|metadata| get_peer_ping_latency(metadata));

                if base_ping_latency.is_none()
                    || ping_latency.is_none()
                    || ping_latency.unwrap()
                        < base_ping_latency.unwrap()
                            + (threshold_config.latency_slack_between_top_upstream_peers as f64)
                                / 1000.0
                {
                    top_peers.push(*peer);
                }
            }
        }
        info!(
            "Identified top peers: {:?}, node_type: {:?}",
            top_peers, self.node_type
        );

        assert!(top_peers.len() <= num_top_peers as usize);
        // Top peers shouldn't be empty if prioritized_peers is not zero
        assert!(self.prioritized_peers.read().is_empty() || !top_peers.is_empty());

        self.peer_to_sender_buckets = HashMap::new();
        if !self.prioritized_peers.read().is_empty() {
            // Assign sender buckets with Primary priority
            let mut peer_index = 0;
            for bucket_index in 0..self.mempool_config.num_sender_buckets {
                self.peer_to_sender_buckets
                    .entry(*top_peers.get(peer_index).unwrap())
                    .or_default()
                    .insert(bucket_index, BroadcastPeerPriority::Primary);
                peer_index = (peer_index + 1) % top_peers.len();
            }

            // Assign sender buckets with Failover priority. Use Round Robin.
            peer_index = 0;
            let num_prioritized_peers = self.prioritized_peers.read().len();
            for _ in 0..self.mempool_config.default_failovers {
                for bucket_index in 0..self.mempool_config.num_sender_buckets {
                    // Find the first peer that already doesn't have the sender bucket, and add the bucket
                    for _ in 0..num_prioritized_peers {
                        let peer = self.prioritized_peers.read()[peer_index];
                        let sender_bucket_list =
                            self.peer_to_sender_buckets.entry(peer).or_default();
                        if let std::collections::hash_map::Entry::Vacant(e) =
                            sender_bucket_list.entry(bucket_index)
                        {
                            e.insert(BroadcastPeerPriority::Failover);
                            break;
                        }
                        peer_index = (peer_index + 1) % num_prioritized_peers;
                    }
                }
            }
        }
    }
```
