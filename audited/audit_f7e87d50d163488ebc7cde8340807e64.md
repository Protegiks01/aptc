# Audit Report

## Title
Race Condition in Consensus Observer: Blocks Can Become Stuck as Pending When Payloads Arrive Between Check and Insertion

## Summary
A time-of-check-time-of-use (TOCTOU) race condition exists in `process_ordered_block_message()` where block payloads can arrive between checking `all_payloads_exist()` and inserting the block into the pending store, causing blocks to be incorrectly marked as pending despite having all required payloads available. [1](#0-0) 

## Finding Description
The vulnerability occurs in the consensus observer's ordered block processing logic. When an ordered block message arrives:

1. The code checks if all payloads exist for the block (acquires lock, checks, releases lock)
2. If payloads don't exist, the block should be inserted into the pending block store
3. **Race window**: Between releasing the lock after the check and acquiring it again for insertion, another thread can receive and insert the required payloads
4. The first thread proceeds to insert the block as "pending" even though payloads now exist [2](#0-1) 

When payloads arrive, they trigger `order_ready_pending_block()` to process any pending blocks that are now ready: [3](#0-2) 

However, if the pending block is inserted AFTER the payload processing completes, the block remains stuck in the pending store indefinitely. The block will only be processed when:
- Another payload for a higher round arrives (could be delayed)
- Subscription changes trigger `clear_pending_block_state()`
- Progress check detects stalling and triggers state sync [4](#0-3) 

This violates the critical invariant that blocks with all available payloads should be processed immediately, not queued indefinitely.

## Impact Explanation
This qualifies as **High Severity** under the Aptos bug bounty program due to:

1. **Validator node slowdowns**: The consensus observer falls behind the network as blocks are stuck pending instead of being processed immediately
2. **Significant protocol violations**: The observer fails to maintain consensus state synchronization, violating the deterministic execution invariant

The observer node will experience:
- Increased block processing latency (blocks delayed until next payload or timeout)
- Potential accumulation of stuck blocks if the race occurs repeatedly
- Eventual fallback to state sync, adding network overhead
- Degraded reliability as an observer node during the stuck period

While this doesn't directly cause fund loss or consensus safety violations, it significantly degrades the observer node's ability to track chain state, affecting dependent services and APIs.

## Likelihood Explanation
The race condition is **moderately likely** to occur in production:

- **High network concurrency**: In active consensus with frequent block and payload messages, the race window is frequently exposed
- **Async execution**: The use of async/await creates natural interleaving points where locks are released
- **No synchronization**: The check at line 706 and insertion at lines 710-712 use separate lock acquisitions with no transaction-level atomicity
- **Exploitability**: An attacker controlling network timing can intentionally send payloads immediately after ordered blocks to trigger the race

The race is timing-dependent but becomes more likely under high message load or when an attacker can control message delivery order.

## Recommendation
Implement atomic check-and-insert logic by holding the lock across both operations:

```rust
// Proposed fix: Hold lock for atomic check-and-insert
let should_process = {
    let mut block_data = self.observer_block_data.lock();
    if block_data.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
        // Payloads exist, will process outside lock
        true
    } else {
        // Payloads don't exist, insert as pending atomically
        block_data.insert_pending_block(pending_block_with_metadata.clone());
        false
    }
};

if should_process {
    self.process_ordered_block(pending_block_with_metadata).await;
}
```

Alternatively, add a re-check inside `insert_pending_block()` to verify payloads still don't exist before actually inserting.

## Proof of Concept

```rust
// Reproduction scenario (conceptual - would need full test harness):
// 
// Thread 1 (Ordered Block Handler):
//   1. Receives OrderedBlock for epoch=E, round=R
//   2. Calls all_payloads_exist() -> returns FALSE
//   3. Lock released
//   [RACE WINDOW]
//   
// Thread 2 (Payload Handler):
//   4. Receives BlockPayload for epoch=E, round=R  
//   5. Inserts payload into store
//   6. Calls order_ready_pending_block(E, R)
//   7. No pending blocks found (not inserted yet)
//   8. Returns
//
// Thread 1 (continued):
//   9. Calls insert_pending_block()
//   10. Block now stuck as pending despite payloads existing
//   
// Result: Block remains in pending_block_store indefinitely
// until another payload arrives or timeout triggers state sync
```

**Notes**

While the security question specifically asked about "payloads be removed", the actual exploitable race involves payloads **arriving** (not being removed) between the check and insertion. The check happens when payloads don't exist (FALSE branch), so there are no payloads to remove at that point. The vulnerability is that payloads can appear during the race window, causing inconsistent state where a block is marked pending despite having all required data.

The opposite race (payloads removed in TRUE branch) also exists but has lower impact since blocks are simply dropped with error logging rather than becoming stuck indefinitely. [5](#0-4)

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L156-165)
```rust
    /// Returns true iff all payloads exist for the given blocks
    fn all_payloads_exist(&self, blocks: &[Arc<PipelinedBlock>]) -> bool {
        // If quorum store is disabled, all payloads exist (they're already in the blocks)
        if !self.observer_epoch_state.is_quorum_store_enabled() {
            return true;
        }

        // Otherwise, check if all the payloads exist in the payload store
        self.observer_block_data.lock().all_payloads_exist(blocks)
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L427-438)
```rust
        // Update the payload store with the payload
        self.observer_block_data
            .lock()
            .insert_block_payload(block_payload, verified_payload);

        // Check if there are blocks that were missing payloads but are
        // now ready because of the new payload. Note: this should only
        // be done if the payload has been verified correctly.
        if verified_payload {
            self.order_ready_pending_block(block_epoch, block_round)
                .await;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L706-713)
```rust
        if self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        } else {
            self.observer_block_data
                .lock()
                .insert_pending_block(pending_block_with_metadata);
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L754-771)
```rust
        // Verify the block payloads against the ordered block
        if let Err(error) = self
            .observer_block_data
            .lock()
            .verify_payloads_against_ordered_block(&ordered_block)
        {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify block payloads against ordered block! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                    ordered_block.proof_block_info(),
                    peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L197-228)
```rust
    /// Removes and returns the block from the store that is now ready
    /// to be processed (after the new payload has been received).
    // TODO: identify how this will work with execution pool blocks!
    pub fn remove_ready_block(
        &mut self,
        received_payload_epoch: u64,
        received_payload_round: Round,
        block_payload_store: &mut BlockPayloadStore,
    ) -> Option<Arc<PendingBlockWithMetadata>> {
        // Calculate the round at which to split the blocks
        let split_round = received_payload_round.saturating_add(1);

        // Split the blocks at the epoch and round
        let mut blocks_at_higher_rounds = self
            .blocks_without_payloads
            .split_off(&(received_payload_epoch, split_round));

        // Check if the last block is ready (this should be the only ready block).
        // Any earlier blocks are considered out-of-date and will be dropped.
        let mut ready_block = None;
        if let Some((epoch_and_round, pending_block)) = self.blocks_without_payloads.pop_last() {
            // If all payloads exist for the block, then the block is ready
            if block_payload_store.all_payloads_exist(pending_block.ordered_block().blocks()) {
                ready_block = Some(pending_block);
            } else {
                // Otherwise, check if we're still waiting for higher payloads for the block
                let last_pending_block_round = pending_block.ordered_block().last_block().round();
                if last_pending_block_round > received_payload_round {
                    blocks_at_higher_rounds.insert(epoch_and_round, pending_block);
                }
            }
        }
```
