# Audit Report

## Title
ChunkCommitQueue Memory Leak Due to Unmonitored VecDeque Growth on Update Ledger Failures

## Summary
The `ChunkCommitQueue` in the executor maintains two unbounded `VecDeque` structures (`to_commit` and `to_update_ledger`) without any monitoring or alerting mechanisms to detect queue growth. When the `update_ledger()` operation fails after retrieving a chunk, the chunk remains in the queue as `None`, blocking all subsequent processing while new chunks continue to accumulate, leading to unbounded memory growth and eventual node crash.

## Finding Description

The `ChunkCommitQueue` structure manages a two-stage pipeline for processing transaction chunks: [1](#0-0) 

These VecDeques are unbounded with no capacity limits. The critical vulnerability occurs in the following sequence:

1. **Normal Flow**: When `update_ledger()` is called, it retrieves a chunk using `next_chunk_to_update_ledger()`: [2](#0-1) 

2. **Chunk Retrieval**: The `next_chunk_to_update_ledger()` method uses `.take()` to extract the chunk, setting the entry to `None`: [3](#0-2) 

3. **Error Scenario**: If any operation in `update_ledger()` fails (state checkpoint, ledger update, verification), the function returns an error and `save_ledger_update_output()` is never called. The `None` entry remains in the queue.

4. **Pipeline Blockage**: Subsequent calls to `next_chunk_to_update_ledger()` will fail with "Next chunk to update ledger has already been processed" because the front entry is `None`: [4](#0-3) 

5. **Unbounded Growth**: Meanwhile, new chunks continue to be enqueued via `enqueue_for_ledger_update()`: [5](#0-4) 

6. **No Monitoring**: The `is_empty()` method exists but is never checked for operational monitoring: [6](#0-5) 

The only monitoring in place tracks the `pending_data_chunks` counter which monitors items in the *communication channels* between stages, not the actual VecDeque sizes: [7](#0-6) 

The channel backpressure monitoring only covers inter-stage communication: [8](#0-7) 

Existing alerts only detect if state sync stops making progress, but provide no early warning before memory exhaustion: [9](#0-8) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty criteria:

**High Severity Impact** (up to $50,000):
- **Validator node slowdowns**: As memory consumption grows, the node experiences progressive performance degradation
- Eventual node crash requiring manual intervention and restart

**Medium Severity Impact** (up to $10,000):
- **State inconsistencies requiring intervention**: The stuck pipeline requires operator intervention to reset the chunk executor
- Memory exhaustion could cause the validator to fall out of sync, affecting network participation

The vulnerability does not directly cause fund loss, consensus safety violations, or permanent network partitions (Critical severity), but it significantly degrades node availability and requires manual recovery.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can be triggered by:

1. **Transient Errors**: Network timeouts, temporary storage issues, or verification failures during `update_ledger()` operations
2. **State Checkpoint Failures**: Errors in Jellyfish Merkle tree operations during state checkpoint computation
3. **Verification Failures**: Chunk verification mismatches due to corrupted data or implementation bugs

The vulnerability is realistic because:
- The state sync pipeline processes high volumes of data continuously
- Any transient error that occurs after `next_chunk_to_update_ledger()` but before `save_ledger_update_output()` triggers the leak
- No recovery mechanism exists to clean up the stuck queue state
- The error handling only sends error notifications without cleaning up queue state: [10](#0-9) 

## Recommendation

**Immediate Fixes:**

1. **Add Queue Size Monitoring**: Export metrics for `to_commit.len()` and `to_update_ledger.len()`:

```rust
// In chunk_commit_queue.rs
pub(crate) fn queue_sizes(&self) -> (usize, usize) {
    (self.to_commit.len(), self.to_update_ledger.len())
}

// In mod.rs, add metrics
pub fn update_queue_metrics(&self) {
    let (to_commit_len, to_update_len) = self.commit_queue.lock().queue_sizes();
    metrics::set_gauge(&CHUNK_QUEUE_DEPTH, "to_commit", to_commit_len as u64);
    metrics::set_gauge(&CHUNK_QUEUE_DEPTH, "to_update_ledger", to_update_len as u64);
}
```

2. **Add Alerting**: Create Prometheus alerts for queue depth exceeding thresholds:

```yaml
- alert: ChunkExecutor queue depth exceeds threshold
  expr: aptos_chunk_executor_queue_depth > 100
  for: 5m
  labels:
    severity: warning
    summary: "ChunkExecutor queue is growing unbounded"
```

3. **Add Cleanup on Error**: Modify error handling to remove stuck entries:

```rust
// In next_chunk_to_update_ledger, track whether chunk was taken
// In error path of update_ledger, call a cleanup method:
fn cleanup_failed_update(&mut self) -> Result<()> {
    ensure!(!self.to_update_ledger.is_empty(), "to_update_ledger is empty.");
    if self.to_update_ledger.front().unwrap().is_none() {
        self.to_update_ledger.pop_front();
    }
    Ok(())
}
```

4. **Add Bounded Queues**: Implement capacity limits on VecDeques to prevent unbounded growth:

```rust
const MAX_QUEUE_SIZE: usize = 1000;

pub(crate) fn enqueue_for_ledger_update(&mut self, chunk: ChunkToUpdateLedger) -> Result<()> {
    ensure!(
        self.to_update_ledger.len() < MAX_QUEUE_SIZE,
        "to_update_ledger queue exceeded maximum capacity"
    );
    // ... rest of implementation
}
```

## Proof of Concept

```rust
#[test]
fn test_queue_leak_on_update_ledger_failure() {
    use std::sync::Arc;
    
    // Setup executor with mock DB
    let db = create_test_db();
    let executor = ChunkExecutor::<MockVM>::new(db.clone());
    executor.reset().unwrap();
    
    // Enqueue multiple chunks
    for i in 0..10 {
        let chunk = create_test_chunk(i);
        executor.enqueue_chunk_by_execution(chunk, &ledger_info, None).unwrap();
    }
    
    // Simulate update_ledger failure by injecting error
    // (In real scenario, this could be triggered by network/storage issues)
    fail::cfg("executor::update_ledger", "return(error)").unwrap();
    
    // Attempt to update ledger - this will fail and leave chunk in stuck state
    let result = executor.update_ledger();
    assert!(result.is_err());
    
    // Try to process next chunk - this will fail because queue is stuck
    let result2 = executor.update_ledger();
    assert!(result2.is_err());
    assert!(result2.unwrap_err().to_string().contains("already been processed"));
    
    // Meanwhile, new chunks continue to accumulate
    for i in 10..100 {
        let chunk = create_test_chunk(i);
        executor.enqueue_chunk_by_execution(chunk, &ledger_info, None).unwrap();
    }
    
    // Queue has grown unbounded with no monitoring or recovery
    // In production, this continues until OOM
    assert!(!executor.is_empty()); // This check is never performed in production!
}
```

**Notes**

The vulnerability stems from a design flaw where the two-stage pipeline uses optimistic locking (`.take()` to mark as processing) without proper error recovery. The `is_empty()` method was likely intended for monitoring but was never integrated into the operational monitoring stack. The existing metrics only track channel backpressure, not the actual queue state within `ChunkCommitQueue`, creating a blind spot where memory can grow unbounded without detection until the node crashes.

### Citations

**File:** execution/executor/src/chunk_executor/chunk_commit_queue.rs (L39-46)
```rust
pub struct ChunkCommitQueue {
    /// Notice that latest_state and latest_txn_accumulator are at different versions.
    latest_state: LedgerState,
    latest_state_summary: LedgerStateSummary,
    latest_txn_accumulator: Arc<InMemoryTransactionAccumulator>,
    to_commit: VecDeque<Option<ExecutedChunk>>,
    to_update_ledger: VecDeque<Option<ChunkToUpdateLedger>>,
}
```

**File:** execution/executor/src/chunk_executor/chunk_commit_queue.rs (L73-83)
```rust
    pub(crate) fn enqueue_for_ledger_update(
        &mut self,
        chunk_to_update_ledger: ChunkToUpdateLedger,
    ) -> Result<()> {
        let _timer = CHUNK_OTHER_TIMERS.timer_with(&["enqueue_for_ledger_update"]);

        self.latest_state = chunk_to_update_ledger.output.result_state().clone();
        self.to_update_ledger
            .push_back(Some(chunk_to_update_ledger));
        Ok(())
    }
```

**File:** execution/executor/src/chunk_executor/chunk_commit_queue.rs (L85-104)
```rust
    pub(crate) fn next_chunk_to_update_ledger(
        &mut self,
    ) -> Result<(
        LedgerStateSummary,
        Arc<InMemoryTransactionAccumulator>,
        ChunkToUpdateLedger,
    )> {
        let chunk_opt = self
            .to_update_ledger
            .front_mut()
            .ok_or_else(|| anyhow!("No chunk to update ledger."))?;
        let chunk = chunk_opt
            .take()
            .ok_or_else(|| anyhow!("Next chunk to update ledger has already been processed."))?;
        Ok((
            self.latest_state_summary.clone(),
            self.latest_txn_accumulator.clone(),
            chunk,
        ))
    }
```

**File:** execution/executor/src/chunk_executor/chunk_commit_queue.rs (L154-156)
```rust
    pub(crate) fn is_empty(&self) -> bool {
        self.to_commit.is_empty() && self.to_update_ledger.is_empty()
    }
```

**File:** execution/executor/src/chunk_executor/mod.rs (L336-344)
```rust
    pub fn update_ledger(&self) -> Result<()> {
        let _timer = CHUNK_OTHER_TIMERS.timer_with(&["chunk_update_ledger_total"]);

        let (parent_state_summary, parent_accumulator, chunk) =
            self.commit_queue.lock().next_chunk_to_update_ledger()?;
        let ChunkToUpdateLedger {
            output,
            chunk_verifier,
        } = chunk;
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L408-410)
```rust
    fn pending_storage_data(&self) -> bool {
        load_pending_data_chunks(self.pending_data_chunks.clone()) > 0
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L671-681)
```rust
                Err(error) => {
                    // Send an error notification to the driver (we failed to update the ledger)
                    let error = format!("Failed to update the ledger! Error: {:?}", error);
                    handle_storage_synchronizer_error(
                        notification_metadata,
                        error,
                        &error_notification_sender,
                        &pending_data_chunks,
                    )
                    .await;
                },
```

**File:** state-sync/state-sync-driver/src/metrics.rs (L221-230)
```rust
/// Gauges for tracking the storage synchronizer pipeline channel backpressure
pub static STORAGE_SYNCHRONIZER_PIPELINE_CHANNEL_BACKPRESSURE: Lazy<IntGaugeVec> =
    Lazy::new(|| {
        register_int_gauge_vec!(
            "aptos_state_sync_storage_synchronizer_pipeline_channel_backpressure",
            "Gauges for tracking the storage synchronizer pipeline channel backpressure",
            &["channel"]
        )
        .unwrap()
    });
```

**File:** terraform/helm/monitoring/files/rules/alerts.yml (L29-35)
```yaml
  - alert: State sync is not making progress
    expr: rate(aptos_state_sync_version{type="synced"}[5m]) == 0 OR absent(aptos_state_sync_version{type="synced"})
    for: 5m
    labels:
      severity: error
      summary: "State sync is not making progress (i.e., the synced version is not increasing!)"
    annotations:
```
