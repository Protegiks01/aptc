# Audit Report

## Title
DKG Transcript Deserialization Memory Exhaustion DoS via Malicious Vec Length Prefixes

## Summary
A validator node can be crashed via Out-of-Memory (OOM) error by sending a malicious DKG transcript containing inflated vector length prefixes in BCS-serialized data. The vulnerability lies in unchecked memory allocation during deserialization of `pvss::das::WeightedTranscript` structures, allowing an attacker to claim billions of elements in Vec fields while providing minimal actual data.

## Finding Description

The DKG (Distributed Key Generation) system deserializes PVSS transcripts received from peer validators without validating the sizes of internal vector structures before memory allocation. During epoch transitions, validators exchange `DKGTranscript` messages containing BCS-serialized transcript data. [1](#0-0) 

The deserialization occurs before any validation checks. The production DKG uses `pvss::das::WeightedTranscript` which contains multiple vector fields: [2](#0-1) 

When BCS deserializes these vectors, it:
1. Reads the ULEB128-encoded length prefix (e.g., claiming 100 million elements in just ~5 bytes)
2. Allocates memory via `Vec::with_capacity(length)` 
3. Attempts to deserialize each element

An attacker can craft `transcript_bytes` where the BCS encoding claims massive vector sizes without providing corresponding data. For example:
- Claim `R: Vec<G1Projective>` has 100 million elements
- Claim `V: Vec<G1Projective>` has 100 million elements  
- Claim `C: Vec<G1Projective>` has 100 million elements

With G1Projective requiring ~96 bytes in memory each (uncompressed), this attempts to allocate ~28.8 GB before deserializing any actual points. The allocation fails, causing OOM panic and validator node crash.

**Attack Flow:**
1. Malicious/compromised validator crafts DKGTranscript with inflated length prefixes
2. Sends `DKGMessage::TranscriptResponse` to target validators during DKG phase
3. Target validators call `TranscriptAggregationState::add()`
4. Deserialization triggers massive allocations
5. OOM crash kills validator nodes
6. Network liveness degraded if multiple validators targeted

**Broken Invariants:**
- **Resource Limits**: "All operations must respect gas, storage, and computational limits" - violated by unbounded memory allocation
- **Network availability** - validator crashes reduce network liveness

Note: While the security question specifically asked about `TupleCodomainShape` in `tuple.rs`, that code path is only used in non-production "chunky" PVSS schemes. The same fundamental vulnerability exists in the production DAS PVSS implementation with simpler `Vec<CurvePoint>` structures, which is what I'm reporting here as the actual exploitable issue.

## Impact Explanation

This is **High Severity** per Aptos bug bounty criteria:
- **Validator node slowdowns/crashes** - explicitly listed as High severity
- **Network liveness impact** - if multiple validators crash during DKG, the network cannot complete epoch transition
- **Consensus availability** - degraded validator participation affects consensus performance

The impact does not reach Critical because:
- No funds are at risk
- Validators can restart after OOM crash
- Network can recover once malicious transcripts are rejected
- Does not cause permanent state corruption or safety violations

However, repeated attacks during each epoch transition could create sustained availability issues.

## Likelihood Explanation

**High Likelihood:**
- DKG runs during every epoch transition (approximately every 2 hours in production)
- Any validator can participate in DKG transcript exchange
- Crafting the malicious payload is trivial (just modify BCS length prefixes)
- No cryptographic operations needed - pure data manipulation
- Attack succeeds on first attempt
- Validators automatically process received transcripts

**Attacker Requirements:**
- Must be part of validator set (or compromise a validator node)
- No additional privileges needed beyond validator participation
- No collusion required

The system is designed to tolerate Byzantine validators (up to 1/3), so assuming a malicious validator is within the threat model.

## Recommendation

Implement size validation before deserialization, similar to the protection in Move VM transaction argument validation: [3](#0-2) 

**Recommended Fix:**

```rust
// In dkg/src/transcript_aggregation/mod.rs, line ~88:

// Add size validation before deserialization
const MAX_TRANSCRIPT_BYTES: usize = 10_000_000; // 10 MB reasonable limit
ensure!(
    transcript_bytes.len() <= MAX_TRANSCRIPT_BYTES,
    "[DKG] transcript_bytes too large: {} bytes exceeds limit of {}",
    transcript_bytes.len(),
    MAX_TRANSCRIPT_BYTES
);

// Additionally, consider streaming deserialization with element count limits
// or use try_reserve pattern instead of direct Vec allocation
let transcript = bcs::from_bytes(transcript_bytes.as_slice()).map_err(|e| {
    anyhow!("[DKG] adding peer transcript failed with trx deserialization error: {e}")
})?;
```

Additionally, consider implementing size limits in the BCS deserialization path for Vec types, using `try_reserve()` instead of `with_capacity()` to catch allocation failures gracefully.

## Proof of Concept

```rust
// Rust PoC demonstrating the vulnerability

use bcs;
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
struct MaliciousTranscript {
    // Claim this vec has billions of elements
    fake_large_vec: Vec<u64>,
}

fn create_malicious_transcript_bytes() -> Vec<u8> {
    // Manually craft BCS with inflated length
    let mut bytes = Vec::new();
    
    // ULEB128 encoding of 1 billion (0x3B9ACA00)
    // This encodes the length prefix claiming 1 billion elements
    bytes.extend_from_slice(&[0x80, 0x94, 0xEB, 0xDC, 0x03]);
    
    // Provide no actual data - deserialization will try to allocate
    // for 1 billion u64s (8 GB) before discovering missing data
    
    bytes
}

fn exploit() {
    let malicious_bytes = create_malicious_transcript_bytes();
    
    // This will attempt to allocate 8 GB and likely OOM
    let result: Result<MaliciousTranscript, _> = bcs::from_bytes(&malicious_bytes);
    
    match result {
        Ok(_) => println!("Unexpectedly succeeded"),
        Err(e) => println!("Failed (likely after OOM): {:?}", e),
    }
}

// To actually exploit in Aptos DKG:
// 1. Create a valid DKGTranscript wrapper with malicious transcript_bytes
// 2. Send via DKGMessage::TranscriptResponse during DKG phase  
// 3. Target validator will OOM when deserializing in TranscriptAggregationState::add()
```

**Notes**

While the specific `TupleCodomainShape` mentioned in the security question is present in the codebase [4](#0-3) , it is only used in non-production "chunky" PVSS schemes [5](#0-4) . The production DKG implementation uses the DAS PVSS scheme [6](#0-5)  which has the same fundamental vulnerability but in simpler vector structures. This report focuses on the actual exploitable issue in production code rather than the unused code path mentioned in the question.

### Citations

**File:** dkg/src/transcript_aggregation/mod.rs (L88-90)
```rust
        let transcript = bcs::from_bytes(transcript_bytes.as_slice()).map_err(|e| {
            anyhow!("[DKG] adding peer transcript failed with trx deserialization error: {e}")
        })?;
```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L50-72)
```rust
pub struct Transcript {
    /// Proofs-of-knowledge (PoKs) for the dealt secret committed in $c = g_2^{p(0)}$.
    /// Since the transcript could have been aggregated from other transcripts with their own
    /// committed secrets in $c_i = g_2^{p_i(0)}$, this is a vector of PoKs for all these $c_i$'s
    /// such that $\prod_i c_i = c$.
    ///
    /// Also contains BLS signatures from each player $i$ on that player's contribution $c_i$, the
    /// player ID $i$ and auxiliary information `aux[i]` provided during dealing.
    soks: Vec<SoK<G1Projective>>,
    /// Commitment to encryption randomness $g_1^{r_j} \in G_1, \forall j \in [W]$
    R: Vec<G1Projective>,
    /// Same as $R$ except uses $g_2$.
    R_hat: Vec<G2Projective>,
    /// First $W$ elements are commitments to the evaluations of $p(X)$: $g_1^{p(\omega^i)}$,
    /// where $i \in [W]$. Last element is $g_1^{p(0)}$ (i.e., the dealt public key).
    V: Vec<G1Projective>,
    /// Same as $V$ except uses $g_2$.
    V_hat: Vec<G2Projective>,
    /// ElGamal encryption of the $j$th share of player $i$:
    /// i.e., $C[s_i+j-1] = h_1^{p(\omega^{s_i + j - 1})} ek_i^{r_j}, \forall i \in [n], j \in [w_i]$.
    /// We sometimes denote $C[s_i+j-1]$ by C_{i, j}.
    C: Vec<G1Projective>,
}
```

**File:** aptos-move/aptos-vm/src/verifier/transaction_arg_validation.rs (L546-571)
```rust
fn read_n_bytes(n: usize, src: &mut Cursor<&[u8]>, dest: &mut Vec<u8>) -> Result<(), VMStatus> {
    let deserialization_error = |msg: &str| -> VMStatus {
        VMStatus::error(
            StatusCode::FAILED_TO_DESERIALIZE_ARGUMENT,
            Some(msg.to_string()),
        )
    };
    let len = dest.len();

    // It is safer to limit the length under some big (but still reasonable
    // number).
    const MAX_NUM_BYTES: usize = 1_000_000;
    if len.checked_add(n).is_none_or(|s| s > MAX_NUM_BYTES) {
        return Err(deserialization_error(&format!(
            "Couldn't read bytes: maximum limit of {} bytes exceeded",
            MAX_NUM_BYTES
        )));
    }

    // Ensure we have enough capacity for resizing.
    dest.try_reserve(len + n)
        .map_err(|e| deserialization_error(&format!("Couldn't read bytes: {}", e)))?;
    dest.resize(len + n, 0);
    src.read_exact(&mut dest[len..])
        .map_err(|_| deserialization_error("Couldn't read bytes"))
}
```

**File:** crates/aptos-dkg/src/sigma_protocol/homomorphism/tuple.rs (L122-130)
```rust
    fn deserialize_with_mode<R: Read>(
        mut reader: R,
        compress: Compress,
        validate: ark_serialize::Validate,
    ) -> Result<Self, SerializationError> {
        let a = A::deserialize_with_mode(&mut reader, compress, validate)?;
        let b = B::deserialize_with_mode(&mut reader, compress, validate)?;
        Ok(Self(a, b))
    }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcriptv2.rs (L515-524)
```rust
                &TupleCodomainShape(
                    TupleCodomainShape(
                        self.sharing_proof.range_proof_commitment.clone(),
                        chunked_elgamal::WeightedCodomainShape {
                            chunks: self.subtrs.Cs.clone(),
                            randomness: self.subtrs.Rs.clone(),
                        },
                    ),
                    chunked_scalar_mul::CodomainShape(self.subtrs.Vs.clone()),
                ),
```

**File:** types/src/dkg/real_dkg/mod.rs (L38-38)
```rust
pub type WTrx = pvss::das::WeightedTranscript;
```
