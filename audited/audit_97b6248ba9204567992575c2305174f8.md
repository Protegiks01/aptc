# Audit Report

## Title
Integer Underflow in MixedPayloadClient Causes Consensus Node Crash or Filtering Bypass

## Summary
The `MixedPayloadClient::pull_payload()` function contains an unchecked integer subtraction that causes u64 underflow when backpressure mechanisms reduce `max_txns_after_filtering` below the number of validator transactions pulled. This leads to consensus node crashes in debug builds or bypassing of transaction filtering limits in release builds.

## Finding Description

The vulnerability exists in the production payload client code where validator transactions are pulled first, then their count is subtracted from the remaining user transaction limit without bounds checking. [1](#0-0) 

**Vulnerability Trigger Conditions:**

1. **Backpressure mechanisms independently reduce transaction limits**: The `calculate_max_block_sizes()` function applies multiple backpressure mechanisms. At extreme pipeline latency (6000ms), `max_sending_block_txns_after_filtering_override` is reduced to 5. [2](#0-1) 

2. **Floor protection clamps to minimum**: The minimum floor `MIN_BLOCK_TXNS_AFTER_FILTERING` is set to 100 (50 * 2). [3](#0-2)  This floor is applied in `calculate_max_block_sizes()` to prevent overly aggressive backpressure. [4](#0-3) 

3. **Validator transactions constrained separately**: Validator transactions are pulled with limit `min(params.max_txns.count(), validator_txn_config.per_block_limit_txn_count())`. [5](#0-4)  The `max_txns.count()` is proportionally reduced when bytes are reduced via `compute_with_bytes()`, [6](#0-5)  but can still remain significantly higher than the clamped `max_txns_after_filtering`.

4. **Unchecked subtraction**: Line 94 uses standard u64 subtraction (not `saturating_sub`) which will panic in debug builds or wrap in release builds.

**Attack Scenario:**
- Pipeline latency reaches 6000ms, reducing `max_txns_after_filtering` to 5 (clamped to 100)
- `max_txns.count()` is proportionally reduced from ~5000 to ~1665 (3MBâ†’1MB reduction)
- Governance has configured `per_block_limit_txn_count` to 200 (default is 2)
- Validator pool returns 200 transactions (respecting the min(1665, 200) = 200 limit)
- Line 94: `100 - 200` = **u64 UNDERFLOW**

**Default Configuration Safety**: The default `per_block_limit_txn_count` is 2, [7](#0-6)  making the default configuration safe. However, this value can be changed via on-chain governance to any u64 value without validation constraints. [8](#0-7) 

## Impact Explanation

**HIGH Severity** - This vulnerability affects consensus availability:

**Debug Builds (Development/Testing):**
- u64 subtraction underflow causes panic at runtime
- Immediate consensus node crash
- Complete loss of individual validator availability
- Aligns with **HIGH severity: Validator Node Crashes** category

**Release Builds (Production):**
- Integer wraps to `u64::MAX - (validator_txns.len() - max_txns_after_filtering - 1)`
- Example: `100 - 200 = 18,446,744,073,709,551,516`
- User payload client receives artificially inflated limit
- Bypasses backpressure protections, potentially causing:
  - Oversized blocks leading to execution timeouts
  - Consensus inconsistency if different validators have different runtime builds
- Could escalate to **CRITICAL** if it causes consensus safety violations

## Likelihood Explanation

**LOW-MEDIUM Likelihood** (report overstates as "High"):

**Preconditions Required:**
1. **Extreme backpressure activation**: 6000ms pipeline latency or severe chain health degradation. While possible during network stress, the system has 7 backpressure levels designed to prevent reaching this extreme. [9](#0-8) 

2. **Governance misconfiguration**: Requires governance to increase `per_block_limit_txn_count` from default of 2 to >100. There is no technical validation preventing this, [10](#0-9)  but it requires deliberate governance action.

3. **Sufficient validator transactions**: Validator pool must have enough transactions to reach the limit.

**Mitigating Factors:**
- Default configuration is safe (per_block_limit_txn_count = 2)
- Requires both extreme conditions AND governance misconfiguration
- No malicious attacker can directly trigger this

## Recommendation

Replace unchecked subtraction with saturating subtraction:

```rust
user_txn_pull_params.max_txns_after_filtering = 
    max_txns_after_filtering.saturating_sub(validator_txns.len() as u64);
user_txn_pull_params.soft_max_txns_after_filtering = 
    soft_max_txns_after_filtering.saturating_sub(validator_txns.len() as u64);
```

Additionally, add validation constraints when setting `per_block_limit_txn_count` via governance to ensure it doesn't exceed safe thresholds relative to `min_max_txns_in_block_after_filtering_from_backpressure`.

## Proof of Concept

This can be demonstrated through a Rust unit test that:
1. Configures `ValidatorTxnConfig` with `per_block_limit_txn_count = 200`
2. Creates `PayloadPullParameters` with `max_txns_after_filtering = 100`
3. Mocks validator pool to return 200 transactions
4. Calls `MixedPayloadClient::pull_payload()`
5. In debug build: observes panic; in release build: observes wrapped value

The test would require modifying `consensus/src/payload_client/mixed.rs` test module to add this scenario.

## Notes

**Severity Clarification**: While the report claims "Critical," this is more accurately **HIGH severity** under the Aptos bug bounty framework as it causes validator node crashes but requires specific configuration. The default-safe nature and governance requirement lower the effective severity from Critical to High.

**Likelihood Correction**: The report's "High Likelihood" claim is overstated. The actual likelihood is LOW-MEDIUM because it requires both extreme operational stress AND non-default governance configuration. The vulnerability is real but not easily triggered in practice.

**Root Cause**: This is a defensive programming issue where the code assumes validator transaction count will always be less than `max_txns_after_filtering`, but the constraints are enforced by different mechanisms that can diverge under edge cases.

### Citations

**File:** consensus/src/payload_client/mixed.rs (L69-72)
```rust
                min(
                    params.max_txns.count(),
                    self.validator_txn_config.per_block_limit_txn_count(),
                ),
```

**File:** consensus/src/payload_client/mixed.rs (L94-94)
```rust
        user_txn_pull_params.max_txns_after_filtering -= validator_txns.len() as u64;
```

**File:** config/src/config/consensus_config.rs (L28-28)
```rust
const MIN_BLOCK_TXNS_AFTER_FILTERING: u64 = DEFEAULT_MAX_BATCH_TXNS as u64 * 2;
```

**File:** config/src/config/consensus_config.rs (L263-319)
```rust
            pipeline_backpressure: vec![
                PipelineBackpressureValues {
                    // pipeline_latency looks how long has the oldest block still in pipeline
                    // been in the pipeline.
                    // Block enters the pipeline after consensus orders it, and leaves the
                    // pipeline once quorum on execution result among validators has been reached
                    // (so-(badly)-called "commit certificate"), meaning 2f+1 validators have finished execution.
                    back_pressure_pipeline_latency_limit_ms: 1200,
                    max_sending_block_txns_after_filtering_override:
                        MAX_SENDING_BLOCK_TXNS_AFTER_FILTERING,
                    max_sending_block_bytes_override: 5 * 1024 * 1024,
                    backpressure_proposal_delay_ms: 50,
                },
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 1500,
                    max_sending_block_txns_after_filtering_override:
                        MAX_SENDING_BLOCK_TXNS_AFTER_FILTERING,
                    max_sending_block_bytes_override: 5 * 1024 * 1024,
                    backpressure_proposal_delay_ms: 100,
                },
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 1900,
                    max_sending_block_txns_after_filtering_override:
                        MAX_SENDING_BLOCK_TXNS_AFTER_FILTERING,
                    max_sending_block_bytes_override: 5 * 1024 * 1024,
                    backpressure_proposal_delay_ms: 200,
                },
                // with execution backpressure, only later start reducing block size
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 2500,
                    max_sending_block_txns_after_filtering_override: 1000,
                    max_sending_block_bytes_override: MIN_BLOCK_BYTES_OVERRIDE,
                    backpressure_proposal_delay_ms: 300,
                },
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 3500,
                    max_sending_block_txns_after_filtering_override: 200,
                    max_sending_block_bytes_override: MIN_BLOCK_BYTES_OVERRIDE,
                    backpressure_proposal_delay_ms: 300,
                },
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 4500,
                    max_sending_block_txns_after_filtering_override: 30,
                    max_sending_block_bytes_override: MIN_BLOCK_BYTES_OVERRIDE,
                    backpressure_proposal_delay_ms: 300,
                },
                PipelineBackpressureValues {
                    back_pressure_pipeline_latency_limit_ms: 6000,
                    // in practice, latencies and delay make it such that ~2 blocks/s is max,
                    // meaning that most aggressively we limit to ~10 TPS
                    // For transactions that are more expensive than that, we should
                    // instead rely on max gas per block to limit latency.
                    max_sending_block_txns_after_filtering_override: 5,
                    max_sending_block_bytes_override: MIN_BLOCK_BYTES_OVERRIDE,
                    backpressure_proposal_delay_ms: 300,
                },
            ],
```

**File:** consensus/src/liveness/proposal_generator.rs (L827-837)
```rust
        let (max_block_txns_after_filtering, max_txns_from_block_to_execute) = if self
            .min_max_txns_in_block_after_filtering_from_backpressure
            > max_block_txns_after_filtering
        {
            (
                self.min_max_txns_in_block_after_filtering_from_backpressure,
                Some(max_block_txns_after_filtering),
            )
        } else {
            (max_block_txns_after_filtering, None)
        };
```

**File:** consensus/consensus-types/src/utils.rs (L94-104)
```rust
    pub fn compute_with_bytes(&self, new_size_in_bytes: u64) -> PayloadTxnsSize {
        let new_count = if self.bytes > 0 {
            let factor = new_size_in_bytes as f64 / self.bytes as f64;
            max((self.count as f64 * factor) as u64, 1u64)
        } else {
            // If bytes is zero, then count is zero. In this case, set the new
            // count to be the same as bytes.
            new_size_in_bytes
        };
        PayloadTxnsSize::new_normalized(new_count, new_size_in_bytes)
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L125-125)
```rust
const VTXN_CONFIG_PER_BLOCK_LIMIT_TXN_COUNT_DEFAULT: u64 = 2;
```

**File:** types/src/on_chain_config/consensus_config.rs (L128-136)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
pub enum ValidatorTxnConfig {
    /// Disabled. In Jolteon, it also means to not use `BlockType::ProposalExt`.
    V0,
    /// Enabled. Per-block vtxn count and their total bytes are limited.
    V1 {
        per_block_limit_txn_count: u64,
        per_block_limit_total_bytes: u64,
    },
```

**File:** types/src/on_chain_config/consensus_config.rs (L309-317)
```rust
    pub fn effective_validator_txn_config(&self) -> ValidatorTxnConfig {
        match self {
            OnChainConsensusConfig::V1(_) | OnChainConsensusConfig::V2(_) => {
                ValidatorTxnConfig::default_disabled()
            },
            OnChainConsensusConfig::V3 { vtxn, .. }
            | OnChainConsensusConfig::V4 { vtxn, .. }
            | OnChainConsensusConfig::V5 { vtxn, .. } => vtxn.clone(),
        }
```
