# Audit Report

## Title
Message Type Confusion in Quorum Store V2 Protocol Causes Consensus State Inconsistencies

## Summary
The network routing layer in `NetworkTask::start()` does not handle Quorum Store V2 message types (`BatchMsgV2`, `SignedBatchInfoMsgV2`, `ProofOfStoreMsgV2`), causing these messages to be silently dropped when received. This creates state inconsistencies between validators with different `enable_batch_v2` configurations, potentially causing consensus liveness failures and breaking the quorum store protocol.

## Finding Description

The Aptos consensus layer supports two versions of quorum store messages: V1 (using `BatchInfo`) and V2 (using `BatchInfoExt`). The `enable_batch_v2` configuration flag in `QuorumStoreConfig` determines which version a validator uses. [1](#0-0) 

When `enable_batch_v2` is enabled, validators broadcast V2 messages: [2](#0-1) 

However, the network message routing layer in `NetworkTask::start()` only handles V1 message variants: [3](#0-2) 

The V2 message variants (`ConsensusMsg::BatchMsgV2`, `ConsensusMsg::SignedBatchInfoMsgV2`, `ConsensusMsg::ProofOfStoreMsgV2`) are **not included** in this match pattern. They fall through to the default case which logs a warning and drops the message: [4](#0-3) 

Additionally, the `check_epoch()` function in `EpochManager` also excludes V2 messages from its accepted message types: [5](#0-4) 

This causes V2 messages to be rejected as "Unexpected messages" if they somehow bypass the network layer.

**Attack Scenario:**

1. Validator A enables `enable_batch_v2 = true` in its configuration
2. Validator A creates batches using `BatchInfoExt` and broadcasts them via `ConsensusMsg::BatchMsgV2`
3. Validator B receives the `BatchMsgV2` message
4. The message does not match any pattern in `NetworkTask::start()` and falls through to the default case
5. The message is dropped with warning "Unexpected direct send msg"
6. Validator B's quorum store never receives Validator A's batch
7. Validator B cannot sign Validator A's batch to form a proof of store
8. If Validator A is the proposer and includes its batches in proposals, other validators lack the batch data
9. This causes consensus state inconsistencies and potential liveness failures

This breaks the **State Consistency** invariant (all validators must maintain consistent views of available batches) and the **Consensus Safety** invariant (validators may disagree on available transaction batches).

## Impact Explanation

**HIGH Severity** - This vulnerability qualifies as:

1. **"Significant protocol violations"** - The quorum store protocol fundamentally breaks when V2 messages are silently dropped. Validators cannot coordinate on batch creation and proof of store formation.

2. **"State inconsistencies requiring intervention"** - Validators with different `enable_batch_v2` settings will have divergent views of available batches, requiring manual intervention to resolve.

3. **Consensus liveness impact** - If a proposer sends V2 batches but other validators drop them, those validators cannot verify the proposal's batch references, potentially stalling consensus.

4. **Silent failure mode** - Messages are dropped with only a warning log, making this difficult to diagnose in production.

The impact is particularly severe during feature rollouts when validators may have mixed configurations.

## Likelihood Explanation

**HIGH Likelihood:**

1. **Trivial to trigger** - Any validator operator can set `enable_batch_v2 = true` in their configuration file
2. **No malicious intent required** - This is a legitimate configuration option intended for feature rollout
3. **Realistic scenario** - During staged rollouts, some validators will enable V2 while others haven't yet
4. **Default configuration vulnerability** - The V2 infrastructure exists in the codebase but routing was not updated
5. **No validation or compatibility checks** - There are no checks to ensure all validators use compatible message versions

The likelihood increases as the V2 feature is promoted or tested in testnet/mainnet environments.

## Recommendation

Update the network routing logic to handle V2 message types. In `consensus/src/network.rs`, modify the `NetworkTask::start()` method to include V2 variants:

```rust
// In NetworkTask::start() method, line 822-830
match msg {
    quorum_store_msg @ (ConsensusMsg::SignedBatchInfo(_)
    | ConsensusMsg::BatchMsg(_)
    | ConsensusMsg::ProofOfStoreMsg(_)
    | ConsensusMsg::SignedBatchInfoMsgV2(_)    // ADD THIS
    | ConsensusMsg::BatchMsgV2(_)              // ADD THIS
    | ConsensusMsg::ProofOfStoreMsgV2(_)) => { // ADD THIS
        Self::push_msg(
            peer_id,
            quorum_store_msg,
            &self.quorum_store_messages_tx,
        );
    },
    // ... rest of match arms
}
```

Similarly, update `consensus/src/epoch_manager.rs` in the `check_epoch()` method:

```rust
// In check_epoch() method, line 1632-1644
match msg {
    ConsensusMsg::ProposalMsg(_)
    | ConsensusMsg::OptProposalMsg(_)
    | ConsensusMsg::SyncInfo(_)
    | ConsensusMsg::VoteMsg(_)
    | ConsensusMsg::RoundTimeoutMsg(_)
    | ConsensusMsg::OrderVoteMsg(_)
    | ConsensusMsg::CommitVoteMsg(_)
    | ConsensusMsg::CommitDecisionMsg(_)
    | ConsensusMsg::BatchMsg(_)
    | ConsensusMsg::BatchRequestMsg(_)
    | ConsensusMsg::SignedBatchInfo(_)
    | ConsensusMsg::ProofOfStoreMsg(_)
    | ConsensusMsg::BatchMsgV2(_)              // ADD THIS
    | ConsensusMsg::SignedBatchInfoMsgV2(_)    // ADD THIS
    | ConsensusMsg::ProofOfStoreMsgV2(_) => {  // ADD THIS
        let event: UnverifiedEvent = msg.into();
        // ... rest of logic
    },
    // ... rest of match arms
}
```

The conversion and verification infrastructure already exists in the `UnverifiedEvent::verify()` method, which properly handles both V1 and V2 messages and converts them to a unified `VerifiedEvent` format: [6](#0-5) 

## Proof of Concept

**Reproduction Steps:**

1. **Setup two validator nodes:**
   - Node A: Set `enable_batch_v2 = true` in `QuorumStoreConfig`
   - Node B: Set `enable_batch_v2 = false` (default)

2. **Start both nodes and connect them**

3. **Trigger batch generation on Node A:**
   - Submit transactions to Node A's mempool
   - Wait for batch generation interval (25ms default)
   - Node A will call `broadcast_batch_msg_v2()` which sends `ConsensusMsg::BatchMsgV2`

4. **Observe on Node B:**
   - Check logs for: `"Unexpected direct send msg"` from peer = Node A
   - Verify the message was not pushed to `quorum_store_messages_tx` channel
   - Verify Node B's quorum store coordinator never receives the batch

5. **Verify consensus impact:**
   - If Node A is the proposer and includes its batch in a proposal
   - Node B will fail to verify the proposal due to missing batch data
   - This can cause proposal rejection or consensus stall

**Integration Test Pseudocode:**

```rust
#[tokio::test]
async fn test_v2_message_dropped() {
    // Create two test validators
    let mut node_a_config = ConsensusConfig::default();
    node_a_config.quorum_store.enable_batch_v2 = true;
    
    let mut node_b_config = ConsensusConfig::default();
    node_b_config.quorum_store.enable_batch_v2 = false;
    
    let (node_a, _) = start_test_validator(node_a_config);
    let (node_b, qs_rx) = start_test_validator_with_qs_channel(node_b_config);
    
    // Send V2 batch from node A to node B
    let batch = create_test_batch_v2();
    let msg = ConsensusMsg::BatchMsgV2(Box::new(BatchMsg::new(vec![batch])));
    node_a.network_sender.send_to(node_b.peer_id, msg).unwrap();
    
    // Wait and verify node B never receives the batch in quorum store
    tokio::time::sleep(Duration::from_millis(100)).await;
    assert!(qs_rx.try_recv().is_err(), "V2 message should be dropped");
    
    // Verify warning was logged
    assert_logs_contain("Unexpected direct send msg");
}
```

This vulnerability poses a **HIGH severity risk** to consensus safety and liveness, particularly during feature rollouts or configuration changes.

## Notes

The root cause is that while the V2 message infrastructure was added to support extended batch information (including encrypted batches via `BatchKind`), the network routing layer was not updated to handle these new message types. This creates a silent failure mode where validators with different feature flag settings cannot communicate properly about batches, leading to state inconsistencies and potential consensus failures.

### Citations

**File:** config/src/config/quorum_store_config.rs (L102-102)
```rust
    pub enable_batch_v2: bool,
```

**File:** consensus/src/quorum_store/batch_generator.rs (L494-495)
```rust
                            if self.config.enable_batch_v2 {
                                network_sender.broadcast_batch_msg_v2(batches).await;
```

**File:** consensus/src/network.rs (L823-830)
```rust
                        quorum_store_msg @ (ConsensusMsg::SignedBatchInfo(_)
                        | ConsensusMsg::BatchMsg(_)
                        | ConsensusMsg::ProofOfStoreMsg(_)) => {
                            Self::push_msg(
                                peer_id,
                                quorum_store_msg,
                                &self.quorum_store_messages_tx,
                            );
```

**File:** consensus/src/network.rs (L937-940)
```rust
                        _ => {
                            warn!(remote_peer = peer_id, "Unexpected direct send msg");
                            continue;
                        },
```

**File:** consensus/src/epoch_manager.rs (L1632-1644)
```rust
        match msg {
            ConsensusMsg::ProposalMsg(_)
            | ConsensusMsg::OptProposalMsg(_)
            | ConsensusMsg::SyncInfo(_)
            | ConsensusMsg::VoteMsg(_)
            | ConsensusMsg::RoundTimeoutMsg(_)
            | ConsensusMsg::OrderVoteMsg(_)
            | ConsensusMsg::CommitVoteMsg(_)
            | ConsensusMsg::CommitDecisionMsg(_)
            | ConsensusMsg::BatchMsg(_)
            | ConsensusMsg::BatchRequestMsg(_)
            | ConsensusMsg::SignedBatchInfo(_)
            | ConsensusMsg::ProofOfStoreMsg(_) => {
```

**File:** consensus/src/round_manager.rs (L166-229)
```rust
            UnverifiedEvent::BatchMsg(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(Box::new((*b).into()))
            },
            UnverifiedEvent::BatchMsgV2(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(b)
            },
            UnverifiedEvent::SignedBatchInfo(sd) => {
                if !self_message {
                    sd.verify(
                        peer_id,
                        max_num_batches,
                        max_batch_expiry_gap_usecs,
                        validator,
                    )?;
                    counters::VERIFY_MSG
                        .with_label_values(&["signed_batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::SignedBatchInfo(Box::new((*sd).into()))
            },
            UnverifiedEvent::SignedBatchInfoMsgV2(sd) => {
                if !self_message {
                    sd.verify(
                        peer_id,
                        max_num_batches,
                        max_batch_expiry_gap_usecs,
                        validator,
                    )?;
                    counters::VERIFY_MSG
                        .with_label_values(&["signed_batch_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::SignedBatchInfo(sd)
            },
            UnverifiedEvent::ProofOfStoreMsg(p) => {
                if !self_message {
                    p.verify(max_num_batches, validator, proof_cache)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["proof_of_store"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::ProofOfStoreMsg(Box::new((*p).into()))
            },
            UnverifiedEvent::ProofOfStoreMsgV2(p) => {
                if !self_message {
                    p.verify(max_num_batches, validator, proof_cache)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["proof_of_store_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::ProofOfStoreMsg(p)
            },
```
