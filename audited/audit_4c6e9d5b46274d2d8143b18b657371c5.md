# Audit Report

## Title
Metadata Cache Corruption Causes Persistent Restore Failures Without Recovery Mechanism

## Summary
The backup metadata cache system lacks content verification and automatic recovery mechanisms. When cached files become corrupted (due to filesystem issues, permission errors, or incomplete writes), the system treats them as valid based solely on filename matching, leading to persistent failures in restore/backup operations that require manual intervention to resolve.

## Finding Description

The `sync_and_load` function in the metadata cache system assumes cached files are valid if their filenames match remote file hashes, without performing any content verification. [1](#0-0) 

The synchronization logic identifies three categories of files:
- Stale files (in cache but not remote) - deleted
- New files (remote but not in cache) - downloaded  
- Up-to-date files (in both cache and remote) - used directly without verification [2](#0-1) 

When listing local cache files, the system silently filters out unreadable entries but corrupted files that are still listable remain in the cache: [3](#0-2) 

During the loading phase, "up_to_date" files are opened and parsed without any fallback mechanism. If a file is corrupted, the operation fails immediately: [4](#0-3) 

The `load_metadata_lines` function can fail on I/O errors, invalid UTF-8, or malformed JSON, with errors propagating up: [5](#0-4) 

In the restore coordinator, metadata loading failure causes the entire restore operation to fail: [6](#0-5) 

**Exploitation Scenario:**
1. Cache file becomes corrupted (filesystem corruption, crash during write, permission changes)
2. File retains correct filename (hash) but contains invalid content
3. On next run, file is treated as "up_to_date" and not re-downloaded
4. Loading fails when attempting to parse corrupted content
5. Operation terminates with error
6. Subsequent runs encounter the same corrupted file, creating a persistent failure loop
7. Manual intervention required to delete cache directory or specific file

## Impact Explanation

This qualifies as **Medium severity** under the Aptos bug bounty criteria: "State inconsistencies requiring intervention."

While this does not directly affect consensus or running validators, it creates operational disruption:
- Validators cannot restore from backups during disaster recovery
- Backup verification operations fail repeatedly
- No automatic recovery path exists
- Requires manual filesystem intervention by operators
- Could delay validator recovery in time-sensitive scenarios

However, this does NOT constitute a higher severity because:
- No funds are at risk
- Consensus safety/liveness is not affected
- Running validators continue to operate normally
- Only affects backup/restore tooling operations
- Workaround exists (manual cache deletion)

## Likelihood Explanation

**Moderate likelihood** due to:

**Contributing factors:**
- Filesystem corruption from hardware failures
- Incomplete writes from system crashes or power loss
- Permission changes from system administration
- Disk space exhaustion causing truncated writes
- Concurrent access issues on shared filesystems

**Mitigating factors:**
- Requires persistent cache directory usage (via `--metadata-cache-dir` flag)
- Default behavior uses temporary directories that are cleaned on restart
- Documentation encourages persistent cache for performance: [7](#0-6) 

The issue becomes critical in production environments where operators use persistent caches to avoid re-downloading metadata on every run.

## Recommendation

Implement content verification and automatic recovery mechanisms:

**1. Add checksum validation:**
```rust
// Store checksums alongside cached files or verify content hash
async fn verify_cached_file(path: &Path, expected_hash: &str) -> Result<bool> {
    // Compute content hash and compare with filename/metadata
    // Return false if mismatch, triggering re-download
}
```

**2. Implement automatic re-download on load failure:**
```rust
for h in new_remote_hashes.into_iter().chain(up_to_date_local_hashes) {
    let cached_file = cache_dir.join(h);
    let metadata_result = OpenOptions::new()
        .read(true)
        .open(&cached_file)
        .await
        .err_notes(&cached_file)
        .and_then(|mut file| file.load_metadata_lines().await);
    
    match metadata_result {
        Ok(metadata) => metadata_vec.extend(metadata.into_iter()),
        Err(e) => {
            warn!(file = ?cached_file, error = %e, "Cached file corrupted, re-downloading");
            // Delete corrupted file
            let _ = remove_file(&cached_file).await;
            // Re-download from remote
            if let Some(file_handle) = remote_file_handle_by_hash.get(h) {
                download_and_load(storage.as_ref(), file_handle, &cached_file).await?;
            }
        }
    }
}
```

**3. Add cache validation on startup:**
```rust
// Before sync, validate existing cached files
// Remove any that fail basic integrity checks
```

## Proof of Concept

```rust
// Test case demonstrating the vulnerability
#[tokio::test]
async fn test_corrupted_cache_persistent_failure() {
    use std::fs;
    use tempfile::TempDir;
    
    // Setup: Create cache directory and remote storage
    let cache_dir = TempDir::new().unwrap();
    let cache_opt = MetadataCacheOpt::new(Some(cache_dir.path()));
    let storage = create_test_backup_storage(); // Mock storage
    
    // Step 1: Normal operation - download and cache metadata
    let result = sync_and_load(&cache_opt, storage.clone(), 4).await;
    assert!(result.is_ok());
    
    // Step 2: Simulate corruption - corrupt a cached file
    let cached_files: Vec<_> = fs::read_dir(cache_opt.cache_dir())
        .unwrap()
        .filter_map(|e| e.ok())
        .collect();
    assert!(!cached_files.is_empty());
    
    let target_file = cached_files[0].path();
    fs::write(&target_file, b"CORRUPTED_INVALID_JSON{{{").unwrap();
    
    // Step 3: Attempt reload - should fail
    let result = sync_and_load(&cache_opt, storage.clone(), 4).await;
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("JSON") 
            || result.unwrap_err().to_string().contains("parse"));
    
    // Step 4: Retry - fails again (persistent failure)
    let result2 = sync_and_load(&cache_opt, storage.clone(), 4).await;
    assert!(result2.is_err());
    
    // Step 5: Manual intervention required
    fs::remove_file(&target_file).unwrap();
    let result3 = sync_and_load(&cache_opt, storage, 4).await;
    assert!(result3.is_ok());
}
```

## Notes

This vulnerability specifically affects operators using persistent metadata cache directories (via `--metadata-cache-dir` flag) for performance optimization. The issue creates operational overhead and potential recovery delays but does not compromise blockchain consensus, state integrity, or fund security. The lack of automatic recovery mechanisms transforms transient filesystem issues into persistent operational failures requiring manual intervention.

### Citations

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L28-38)
```rust
pub struct MetadataCacheOpt {
    #[clap(
        long = "metadata-cache-dir",
        value_parser,
        help = "Metadata cache dir. If specified and shared across runs, \
        metadata files in cache won't be downloaded again from backup source, speeding up tool \
        boot up significantly. Cache content can be messed up if used across the devnet, \
        the testnet and the mainnet, hence it [Defaults to temporary dir]."
    )]
    dir: Option<PathBuf>,
}
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L101-112)
```rust
    let local_hashes_vec: Vec<String> = ReadDirStream::new(dir)
        .filter_map(|entry| match entry {
            Ok(e) => {
                let path = e.path();
                let file_name = path.file_name()?.to_str()?;
                Some(file_name.to_string())
            },
            Err(_) => None,
        })
        .collect()
        .await;
    let local_hashes: HashSet<_> = local_hashes_vec.into_iter().collect();
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L133-141)
```rust
    let stale_local_hashes = local_hashes.difference(&remote_hashes);
    let new_remote_hashes = remote_hashes.difference(&local_hashes).collect::<Vec<_>>();
    let up_to_date_local_hashes = local_hashes.intersection(&remote_hashes);

    for h in stale_local_hashes {
        let file = cache_dir.join(h);
        remove_file(&file).await.err_notes(&file)?;
        info!(file_name = h, "Deleted stale metadata file in cache.");
    }
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L194-207)
```rust
    for h in new_remote_hashes.into_iter().chain(up_to_date_local_hashes) {
        let cached_file = cache_dir.join(h);
        metadata_vec.extend(
            OpenOptions::new()
                .read(true)
                .open(&cached_file)
                .await
                .err_notes(&cached_file)?
                .load_metadata_lines()
                .await
                .err_notes(&cached_file)?
                .into_iter(),
        )
    }
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L237-246)
```rust
    async fn load_metadata_lines(&mut self) -> Result<Vec<Metadata>> {
        let mut buf = String::new();
        self.read_to_string(&mut buf)
            .await
            .err_notes((file!(), line!(), &buf))?;
        Ok(buf
            .lines()
            .map(serde_json::from_str::<Metadata>)
            .collect::<Result<_, serde_json::error::Error>>()?)
    }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L117-122)
```rust
        let metadata_view = metadata::cache::sync_and_load(
            &self.metadata_cache_opt,
            Arc::clone(&self.storage),
            self.global_opt.concurrent_downloads,
        )
        .await?;
```
