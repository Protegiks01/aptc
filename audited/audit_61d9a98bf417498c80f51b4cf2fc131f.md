# Audit Report

## Title
Indexer gRPC Chunk Size Bypass Vulnerability Causing Downstream Processor Failures

## Summary
The `chunk_transactions()` function in the indexer-grpc-utils can bypass the 15MB chunk size limit by placing oversized transactions (>15MB) into chunks by themselves, violating the design assumption that downstream systems can handle at most 15MB chunks. This can cause indexer API failures and downstream processor crashes when processing legitimate governance transactions with large events and write operations.

## Finding Description

The vulnerability exists in the chunking logic that processes blockchain transactions for the indexer gRPC data service: [1](#0-0) 

The function's logic at line 153 checks `!chunk.is_empty()` before deciding whether to flush the current chunk. This means if a single transaction's encoded size exceeds `chunk_size` (15MB), it will still be added to an empty chunk, creating an oversized chunk that violates the intended limit.

The MESSAGE_SIZE_LIMIT is explicitly defined as 15MB with documentation stating "By default the downstream can receive up to 15MB": [2](#0-1) 

**How the vulnerability manifests:**

Aptos enforces the following gas parameter limits for transactions: [3](#0-2) [4](#0-3) [5](#0-4) 

A legitimate governance transaction can have:
- Transaction data: up to 1MB (max_transaction_size_in_bytes_gov)
- Events: up to 10MB (max_bytes_all_events_per_transaction)  
- Write operations: up to 10MB (max_bytes_all_write_ops_per_transaction)
- **Total protobuf encoding: potentially 21MB+**

When the indexer data service processes such a transaction, it calls `chunk_transactions()` with MESSAGE_SIZE_LIMIT: [6](#0-5) 

The resulting chunk containing a single 21MB transaction exceeds the 15MB limit and is sent to downstream processors without validation: [7](#0-6) 

This breaks the documented invariant that downstream systems expect maximum 15MB chunks, potentially causing:
- Memory allocation failures in processors with 15MB buffers
- Timeout errors in systems using 15MB-based timeout calculations  
- Database insertion failures with column size constraints
- Indexer API unavailability and crashes

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Indexer state becomes inconsistent when processors fail to handle oversized chunks, requiring manual intervention to restart/fix processors
- **API crashes**: Matches High severity criteria of "API crashes" - the indexer gRPC API and downstream processors can crash when receiving >15MB chunks

The vulnerability affects indexer infrastructure availability, which is critical for:
- External applications querying transaction data
- Analytics platforms processing blockchain events
- Ecosystem monitoring tools
- Third-party indexer implementations

While it doesn't directly affect consensus or on-chain funds, it causes denial-of-service on the indexer infrastructure layer, impacting the ecosystem's ability to observe and process blockchain data.

## Likelihood Explanation

**Likelihood: Medium**

Exploitation occurs when:
1. A governance transaction executes with near-maximum events (approaching 10MB) and write operations (approaching 10MB)
2. The transaction gets committed to the blockchain through normal governance process
3. The indexer processes this transaction

This doesn't require malicious intent - legitimate governance operations like:
- Framework upgrades with extensive module updates
- Large-scale configuration changes
- Batch operations processing many state updates

could naturally generate sufficient events and write operations to exceed 15MB when encoded as protobuf.

While governance transactions are less frequent than regular transactions, the impact is guaranteed once such a transaction exists on-chain. The indexer will fail repeatedly when processing that block range until the issue is fixed.

## Recommendation

**Fix 1: Enforce hard limit validation**

Add validation to reject or split transactions that exceed MESSAGE_SIZE_LIMIT even as single chunks:

```rust
pub fn chunk_transactions(
    transactions: Vec<Transaction>,
    chunk_size: usize,
) -> Vec<Vec<Transaction>> {
    let mut chunked_transactions = vec![];
    let mut chunk = vec![];
    let mut current_size = 0;

    for transaction in transactions {
        let txn_size = transaction.encoded_len();
        
        // Validate that single transaction doesn't exceed limit
        if txn_size > chunk_size {
            tracing::error!(
                "Transaction version {} size {} exceeds chunk_size limit {}",
                transaction.version,
                txn_size,
                chunk_size
            );
            // Option 1: Skip (with logging)
            // Option 2: Return error
            // Option 3: Use separate oversized chunk path
            continue;
        }
        
        if !chunk.is_empty() && current_size + txn_size > chunk_size {
            chunked_transactions.push(chunk);
            chunk = vec![];
            current_size = 0;
        }
        current_size += txn_size;
        chunk.push(transaction);
    }
    if !chunk.is_empty() {
        chunked_transactions.push(chunk);
    }
    chunked_transactions
}
```

**Fix 2: Increase MESSAGE_SIZE_LIMIT**

Align MESSAGE_SIZE_LIMIT with realistic maximum transaction sizes:

```rust
// Update to account for max governance transaction + events + write ops
pub const MESSAGE_SIZE_LIMIT: usize = 1024 * 1024 * 25; // 25MB
```

This matches the approach in data-service-v2: [8](#0-7) 

**Fix 3: Document and enforce contract**

Update downstream processors to explicitly handle variable-sized chunks up to the actual maximum, or add chunk size validation at the gRPC layer to fail fast rather than propagating oversized messages.

## Proof of Concept

**Test scenario:**

```rust
#[cfg(test)]
mod test_chunk_size_bypass {
    use super::*;
    use aptos_protos::transaction::v1::{Transaction, TransactionInfo, WriteSetChange, Event};
    use aptos_protos::util::timestamp::Timestamp;

    #[test]
    fn test_oversized_transaction_bypasses_chunk_limit() {
        // Create a transaction that simulates a governance txn with large events/write ops
        let mut large_transaction = Transaction {
            version: 1,
            timestamp: Some(Timestamp {
                seconds: 1,
                nanos: 0,
            }),
            info: Some(TransactionInfo {
                // Add large write set changes (simulating 10MB)
                changes: vec![WriteSetChange::default(); 100000],
                ..Default::default()
            }),
            // Add large events (simulating 10MB)  
            events: vec![Event::default(); 100000],
            ..Transaction::default()
        };
        
        let transactions = vec![large_transaction.clone()];
        let chunk_size = 15 * 1024 * 1024; // 15MB
        
        let chunks = chunk_transactions(transactions, chunk_size);
        
        // Verify that an oversized transaction creates a chunk by itself
        assert_eq!(chunks.len(), 1);
        assert_eq!(chunks[0].len(), 1);
        
        // Calculate actual size
        let actual_size = chunks[0][0].encoded_len();
        
        // VULNERABILITY: The chunk size exceeds the limit
        assert!(
            actual_size > chunk_size,
            "Chunk size {} exceeds limit {} - vulnerability confirmed",
            actual_size,
            chunk_size
        );
        
        println!("VULNERABILITY: Transaction of size {} placed in chunk exceeding {} limit", 
                 actual_size, chunk_size);
    }
}
```

**Notes:**

The indexed protobuf Transaction type includes all execution artifacts (events, write ops, transaction info) which can legitimately exceed 15MB for governance transactions operating at maximum gas parameters. The chunk_transactions() function's bypass mechanism violates the documented 15MB design assumption, creating a mismatch between producer (data service) and consumer (downstream processors) expectations that leads to indexer infrastructure failures.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L141-165)
```rust
/// Chunk transactions into chunks with chunk size less than or equal to chunk_size.
/// If a single transaction is larger than chunk_size, it will be put into a chunk by itself.
pub fn chunk_transactions(
    transactions: Vec<Transaction>,
    chunk_size: usize,
) -> Vec<Vec<Transaction>> {
    let mut chunked_transactions = vec![];
    let mut chunk = vec![];
    let mut current_size = 0;

    for transaction in transactions {
        // Only add the chunk when it's empty.
        if !chunk.is_empty() && current_size + transaction.encoded_len() > chunk_size {
            chunked_transactions.push(chunk);
            chunk = vec![];
            current_size = 0;
        }
        current_size += transaction.encoded_len();
        chunk.push(transaction);
    }
    if !chunk.is_empty() {
        chunked_transactions.push(chunk);
    }
    chunked_transactions
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L18-19)
```rust
// Limit the message size to 15MB. By default the downstream can receive up to 15MB.
pub const MESSAGE_SIZE_LIMIT: usize = 1024 * 1024 * 15;
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L73-81)
```rust
            max_transaction_size_in_bytes: NumBytes,
            "max_transaction_size_in_bytes",
            64 * 1024
        ],
        [
            max_transaction_size_in_bytes_gov: NumBytes,
            { RELEASE_V1_13.. => "max_transaction_size_in_bytes.gov" },
            1024 * 1024
        ],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L154-162)
```rust
            max_bytes_per_write_op: NumBytes,
            { 5.. => "max_bytes_per_write_op" },
            1 << 20, // a single state item is 1MB max
        ],
        [
            max_bytes_all_write_ops_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_write_ops_per_transaction" },
            10 << 20, // all write ops from a single transaction are 10MB max
        ],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L164-172)
```rust
            max_bytes_per_event: NumBytes,
            { 5.. => "max_bytes_per_event" },
            1 << 20, // a single event is 1MB max
        ],
        [
            max_bytes_all_events_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_events_per_transaction"},
            10 << 20, // all events from a single transaction are 10MB max
        ],
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L674-691)
```rust
fn get_transactions_responses_builder(
    transactions: Vec<Transaction>,
    chain_id: u32,
    txns_to_strip_filter: &BooleanTransactionFilter,
) -> (Vec<TransactionsResponse>, usize) {
    let (stripped_transactions, num_stripped) =
        strip_transactions(transactions, txns_to_strip_filter);
    let chunks = chunk_transactions(stripped_transactions, MESSAGE_SIZE_LIMIT);
    let responses = chunks
        .into_iter()
        .map(|chunk| TransactionsResponse {
            chain_id: Some(chain_id as u64),
            transactions: chunk,
            processed_range: None,
        })
        .collect();
    (responses, num_stripped)
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L862-887)
```rust
    for resp_item in resp_items {
        let send_start_time = Instant::now();
        let response_size = resp_item.encoded_len();
        let num_of_transactions = resp_item.transactions.len();
        let start_version = resp_item.transactions.first().unwrap().version;
        let end_version = resp_item.transactions.last().unwrap().version;
        let start_version_txn_timestamp = resp_item
            .transactions
            .first()
            .unwrap()
            .timestamp
            .as_ref()
            .unwrap();
        let end_version_txn_timestamp = resp_item
            .transactions
            .last()
            .unwrap()
            .timestamp
            .as_ref()
            .unwrap();

        tx.send_timeout(
            Result::<TransactionsResponse, Status>::Ok(resp_item.clone()),
            RESPONSE_CHANNEL_SEND_TIMEOUT,
        )
        .await?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```
