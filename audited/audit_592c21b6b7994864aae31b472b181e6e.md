# Audit Report

## Title
Chain ID Validation Missing in LocalFileStoreOperator Metadata Updates Enabling Cross-Chain Data Corruption

## Summary
The `update_file_store_metadata_internal()` function in the LocalFileStoreOperator allows the chain_id to be changed in subsequent calls without validation, enabling catastrophic mixing of transaction data from different blockchain networks (e.g., mainnet and testnet) within the same file store directory.

## Finding Description

The vulnerability exists in the indexer-grpc file store operator implementation. The `update_file_store_metadata_internal()` function creates and writes metadata with a provided chain_id parameter without validating whether this chain_id matches any previously stored value. [1](#0-0) 

This function is called from `upload_transaction_batch()` for periodic metadata updates, bypassing the chain_id validation that exists in `update_file_store_metadata_with_timeout()`: [2](#0-1) 

The validation in `update_file_store_metadata_with_timeout()` only checks chain_id when metadata already exists, but doesn't protect against the periodic updates in `upload_transaction_batch()`: [3](#0-2) 

**Attack Scenario:**

1. Processor A (mainnet, chain_id=1) uploads transactions to directory `/data/filestore/`
2. Metadata file `/data/filestore/metadata.json` is created with chain_id=1
3. Transaction files for mainnet are written (versions 0-999999)
4. Metadata file gets corrupted/deleted due to disk error or operator mistake
5. Operator misconfigures Processor B (testnet, chain_id=2) to point to same directory
6. Processor B finds no metadata (line 65), creates new metadata with chain_id=2
7. Processor B uploads testnet transactions (versions 1000000+)
8. Periodic metadata updates continue overwriting with chain_id=2
9. File store now contains MIXED mainnet and testnet transaction files
10. Data service validates metadata chain_id=2, serves mixed data to clients

The data service performs chain_id validation but only checks that metadata matches Redis cache, not that individual transaction files match their expected chain: [4](#0-3) 

Individual Transaction objects in the protobuf definition do NOT contain chain_id information - only Block-level metadata contains it: [5](#0-4) 

This means there's no way to detect or filter out transactions from the wrong chain once they're mixed in the file store.

## Impact Explanation

This vulnerability qualifies as **High Severity** based on the "Significant protocol violations" category, or **Medium Severity** based on "State inconsistencies requiring intervention."

**Concrete Impact:**
- Indexers, block explorers, and wallets relying on this data feed receive corrupted transaction information
- Users querying testnet data receive mixed mainnet/testnet transactions, all labeled with testnet chain_id
- Transaction version numbers become unreliable as chains have different version sequences  
- Historical data becomes permanently corrupted and untrustworthy
- Requires manual intervention to identify and separate mixed chain data
- Could lead to incorrect balance displays, wrong transaction history, or failed transaction submissions if applications make decisions based on corrupted indexer data

While this doesn't directly compromise on-chain funds or consensus, it breaks critical data integrity guarantees for the entire indexer infrastructure that many applications depend on.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability requires specific conditions but is realistically exploitable:

**Triggering Conditions:**
1. Metadata file deletion/corruption (disk failures, filesystem errors, manual operator mistakes)
2. Operator misconfiguration pointing different chain processors to same directory
3. Sequential processor deployment without proper cleanup

**Mitigating Factors:**
- Processor initialization includes chain_id validation (processor.rs lines 84, 121)
- Normal operation uses fixed chain_id per processor instance
- Requires operator error or system failure

**Realistic Scenarios:**
- Disaster recovery: restored from backup with missing metadata
- Infrastructure migration: copying transaction files but not metadata
- Dev/staging environments: reusing directories across different chains
- Kubernetes pod restarts with misconfigured persistent volumes

The Processor safeguards reduce but don't eliminate risk because they can't detect if the *files* themselves are from a different chain than the metadata.

## Recommendation

Add chain_id validation in `update_file_store_metadata_internal()` to prevent overwriting metadata with a different chain_id:

```rust
async fn update_file_store_metadata_internal(
    &mut self,
    chain_id: u64,
    version: u64,
) -> anyhow::Result<()> {
    // Read existing metadata if it exists and validate chain_id
    let metadata_path = self.path.join(METADATA_FILE_NAME);
    if let Ok(existing_bytes) = tokio::fs::read(&metadata_path).await {
        if let Ok(existing_metadata) = serde_json::from_slice::<FileStoreMetadata>(&existing_bytes) {
            anyhow::ensure!(
                existing_metadata.chain_id == chain_id,
                "Cannot change chain_id from {} to {}. This would cause data corruption.",
                existing_metadata.chain_id,
                chain_id
            );
        }
    }
    
    let metadata = FileStoreMetadata::new(chain_id, version, self.storage_format);
    info!(
        "Updating metadata file {} @ version {}",
        metadata_path.display(),
        version
    );
    match tokio::fs::write(metadata_path, serde_json::to_vec(&metadata).unwrap()).await {
        Ok(_) => {
            self.latest_metadata_update_timestamp = Some(std::time::Instant::now());
            Ok(())
        },
        Err(err) => Err(anyhow::Error::from(err)),
    }
}
```

**Additional Hardening:**
1. Add chain_id to transaction file names to enable verification: `txns_chain1_000000000.bin`
2. Include chain_id in FileEntry structure for validation during reads
3. Add operator documentation warning about directory isolation per chain
4. Implement integrity check tool to scan for mixed-chain data

## Proof of Concept

```rust
// Reproduction steps (pseudo-code):

// Step 1: Initialize LocalFileStoreOperator for mainnet
let mut operator_mainnet = LocalFileStoreOperator::new(
    PathBuf::from("/tmp/filestore"), 
    false
);

// Step 2: Upload mainnet transactions
let mainnet_txns = vec![/* mainnet transactions */];
operator_mainnet.upload_transaction_batch(1, mainnet_txns).await.unwrap();
// This creates metadata.json with chain_id=1

// Step 3: Simulate metadata deletion
tokio::fs::remove_file("/tmp/filestore/metadata.json").await.unwrap();

// Step 4: Create new operator for testnet pointing to SAME directory
let mut operator_testnet = LocalFileStoreOperator::new(
    PathBuf::from("/tmp/filestore"),
    false  
);

// Step 5: Upload testnet transactions - NO ERROR!
let testnet_txns = vec![/* testnet transactions */];
operator_testnet.upload_transaction_batch(2, testnet_txns).await.unwrap();
// This creates new metadata.json with chain_id=2

// Step 6: Verify corruption
let metadata = operator_testnet.get_file_store_metadata().await.unwrap();
assert_eq!(metadata.chain_id, 2); // Says testnet

// But directory contains BOTH mainnet and testnet files!
// /tmp/filestore/000000000.bin (mainnet)
// /tmp/filestore/001000000.bin (testnet)
// Both will be served as chain_id=2 by data service
```

**Expected Result:** The `upload_transaction_batch()` call in Step 5 should fail with "Chain ID mismatch" error.

**Actual Result:** The operation succeeds, creating mixed-chain data corruption.

## Notes

While this vulnerability is in the indexer infrastructure layer rather than core consensus, it represents a significant data integrity issue. The indexer-grpc system is a critical component of the Aptos ecosystem that many applications depend on for transaction history, balance queries, and blockchain state information. Corrupted indexer data can propagate incorrect information throughout the ecosystem, potentially causing cascading failures in dependent applications.

The fix is straightforward and should be implemented immediately to prevent operational incidents during disaster recovery or infrastructure migrations.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/local.rs (L94-124)
```rust
    async fn update_file_store_metadata_with_timeout(
        &mut self,
        expected_chain_id: u64,
        _version: u64,
    ) -> anyhow::Result<()> {
        let metadata_path = self.path.join(METADATA_FILE_NAME);
        match tokio::fs::read(metadata_path).await {
            Ok(metadata) => {
                let metadata: FileStoreMetadata =
                    serde_json::from_slice(&metadata).expect("Expected metadata to be valid JSON.");
                anyhow::ensure!(metadata.chain_id == expected_chain_id, "Chain ID mismatch.");
                Ok(())
            },
            Err(err) => {
                if err.kind() == std::io::ErrorKind::NotFound {
                    // If the metadata is not found, it means the file store is empty.
                    info!("File store is empty. Creating metadata file.");
                    self.update_file_store_metadata_internal(expected_chain_id, 0)
                        .await
                        .expect("[Indexer File] Update metadata failed.");
                    Ok(())
                } else {
                    // If not in write mode, the metadata must exist.
                    Err(anyhow::Error::msg(format!(
                        "Metadata not found or file store operator is not in write mode. {}",
                        err
                    )))
                }
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/local.rs (L126-146)
```rust
    async fn update_file_store_metadata_internal(
        &mut self,
        chain_id: u64,
        version: u64,
    ) -> anyhow::Result<()> {
        let metadata = FileStoreMetadata::new(chain_id, version, self.storage_format);
        // If the metadata is not updated, the indexer will be restarted.
        let metadata_path = self.path.join(METADATA_FILE_NAME);
        info!(
            "Updating metadata file {} @ version {}",
            metadata_path.display(),
            version
        );
        match tokio::fs::write(metadata_path, serde_json::to_vec(&metadata).unwrap()).await {
            Ok(_) => {
                self.latest_metadata_update_timestamp = Some(std::time::Instant::now());
                Ok(())
            },
            Err(err) => Err(anyhow::Error::from(err)),
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/local.rs (L206-219)
```rust
        if let Some(ts) = self.latest_metadata_update_timestamp {
            // a periodic metadata update
            if (std::time::Instant::now() - ts).as_secs() > FILE_STORE_UPDATE_FREQUENCY_SECS {
                self.update_file_store_metadata_internal(
                    chain_id,
                    start_version + batch_size as u64,
                )
                .await?;
            }
        } else {
            // the first metadata update
            self.update_file_store_metadata_internal(chain_id, start_version + batch_size as u64)
                .await?;
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L414-463)
```rust
    // Validate chain id
    let mut metadata = file_store_operator.get_file_store_metadata().await;
    while metadata.is_none() {
        metadata = file_store_operator.get_file_store_metadata().await;
        tracing::warn!(
            "[File worker] File store metadata not found. Waiting for {} ms.",
            FILE_STORE_METADATA_WAIT_MS
        );
        tokio::time::sleep(std::time::Duration::from_millis(
            FILE_STORE_METADATA_WAIT_MS,
        ))
        .await;
    }

    let metadata_chain_id = metadata.unwrap().chain_id;

    // Validate redis chain id. Must be present by the time it gets here
    let chain_id = match cache_operator.get_chain_id().await {
        Ok(chain_id) => chain_id.unwrap(),
        Err(e) => {
            ERROR_COUNT
                .with_label_values(&["redis_get_chain_id_failed"])
                .inc();
            // Connection will be dropped anyway, so we ignore the error here.
            let _result = tx
                .send_timeout(
                    Err(Status::unavailable(
                        "[Data Service] Cannot get the chain id from redis; please retry.",
                    )),
                    RESPONSE_CHANNEL_SEND_TIMEOUT,
                )
                .await;
            error!(
                error = e.to_string(),
                "[Data Service] Failed to get chain id from redis."
            );
            return;
        },
    };

    if metadata_chain_id != chain_id {
        let _result = tx
            .send_timeout(
                Err(Status::unavailable("[Data Service] Chain ID mismatch.")),
                RESPONSE_CHANNEL_SEND_TIMEOUT,
            )
            .await;
        error!("[Data Service] Chain ID mismatch.",);
        return;
    }
```

**File:** protos/proto/aptos/transaction/v1/transaction.proto (L31-45)
```text
  // Chain ID informs us which chain we're trying to index, this is important to ensure that we're not mixing chains within a single pipeline.
  uint32 chain_id = 4;
}

// Transaction as it happened on the chain, there are 4 types of transactions:
// - User Transaction: a user initiated transaction to interact with the chain
// - Block Metadata Transaction: transactions generated by the chain to group together transactions forming a "block"
// - Block Epilogue / State Checkpoint Transaction: transactions generated by the chain to end the group transactions forming a bloc
// - Genesis Transaction: the first transaction of the chain, with all core contract and validator information baked in
message Transaction {
  aptos.util.timestamp.Timestamp timestamp = 1;
  uint64 version = 2 [jstype = JS_STRING];
  TransactionInfo info = 3;
  uint64 epoch = 4 [jstype = JS_STRING];
  uint64 block_height = 5 [jstype = JS_STRING];
```
