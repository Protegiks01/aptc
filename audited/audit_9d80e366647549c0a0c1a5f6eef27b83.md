# Audit Report

## Title
Error Log Flooding Enables Security Event Suppression in Peer Monitoring Service

## Summary
The peer monitoring service logs all errors without rate limiting, allowing attackers to flood the bounded logging channel (capacity: 10,000 entries) and cause subsequent critical security errors to be silently dropped. This enables attackers to mask real security incidents by generating high volumes of benign errors.

## Finding Description

The peer monitoring service error handling contains a critical flaw where unsampled error logging can suppress security-critical events.

**Vulnerability Flow:**

1. When the peer monitoring service processes requests and encounters errors, it logs each error without rate limiting: [1](#0-0) 

2. The logger uses a bounded channel with fixed capacity: [2](#0-1) 

3. When the channel is full, logs are silently dropped with only a metric increment: [3](#0-2) 

4. The service can process up to 1,000 concurrent requests: [4](#0-3) 

**Attack Scenario:**

1. Attacker connects from multiple peers (network layer allows 100 concurrent RPCs per peer)
2. Sends requests that trigger storage errors or unexpected network errors
3. With 1,000 concurrent requests generating errors repeatedly, the logging channel fills
4. Once the 10,000-entry channel is full, subsequent critical errors (consensus issues, Byzantine behavior, storage corruption) are dropped
5. Alert fires only after 5 minutes of sustained log drops: [5](#0-4) 

**Contrast with Other Services:**

Other critical components use sampled logging to prevent this exact issue: [6](#0-5) 

However, the peer monitoring service does not apply this pattern to its error logging.

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria for "Significant protocol violations" because:

1. **Security Visibility Loss**: Critical security events (consensus violations, Byzantine behavior, storage anomalies) can be suppressed for the 5-minute alert window
2. **Attack Masking**: Attackers can use error flooding as a precursor to hide evidence of real attacks (consensus manipulation, state corruption attempts)
3. **Incident Response Degradation**: During the suppression period, operators lose visibility into security-critical events, severely hampering incident detection and response
4. **Multi-Stage Attack Enabler**: This can be chained with other attacks where the attacker wants to suppress evidence of their activities

The vulnerability breaks the invariant that security-critical errors are always logged and observable, which is fundamental to Byzantine fault detection and incident response in distributed consensus systems.

## Likelihood Explanation

**Likelihood: High**

1. **No Privilege Required**: Any network peer can send requests to the peer monitoring service
2. **Easy to Execute**: Attacker simply needs to send requests that trigger errors (storage errors, malformed requests, or requests during high load)
3. **Multiple Attack Vectors**: 
   - Send `GetNodeInformation` requests that trigger storage read errors
   - Send requests during state sync when storage is under load
   - Coordinate from multiple peers to amplify effect
4. **Realistic Conditions**: The attack succeeds when error generation rate exceeds logging processing rate (easily achievable with 1,000 concurrent requests across multiple peers)

## Recommendation

Implement rate-limited error logging using the existing `sample!` macro infrastructure:

```rust
// In peer-monitoring-service/server/src/lib.rs, line 193-195
// Replace unsampled error!() with sampled version:

sample!(
    SampleRate::Duration(Duration::from_secs(10)),
    error!(LogSchema::new(LogEntry::PeerMonitoringServiceError)
        .error(&error)
        .request(&request))
);
```

Additional mitigations:

1. **Per-peer error rate limiting**: Track error rates per peer and temporarily throttle peers generating excessive errors
2. **Priority logging**: Ensure critical errors (storage corruption, consensus issues) are written to a separate high-priority channel
3. **Reduce alert delay**: Lower the 5-minute alert threshold for log drops to enable faster incident response
4. **Error type tracking**: Implement metrics to track which error types are being dropped

## Proof of Concept

```rust
// Reproduction steps for peer-monitoring-service error flooding

use std::time::Duration;
use tokio::task::JoinSet;

#[tokio::test]
async fn test_error_log_flooding() {
    // Setup: Initialize peer monitoring service with normal configuration
    // (max_concurrent_requests = 1000, channel_size = 10000)
    
    let mut tasks = JoinSet::new();
    
    // Simulate 1000 concurrent peers sending requests that trigger errors
    for peer_id in 0..1000 {
        tasks.spawn(async move {
            // Send GetNodeInformation requests repeatedly
            // These will trigger storage errors if storage is under load
            // or can trigger UnexpectedErrorEncountered from network issues
            loop {
                send_monitoring_request(peer_id).await;
                // Generate ~100 errors per second per peer
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
        });
    }
    
    // Monitor STRUCT_LOG_QUEUE_ERROR_COUNT metric
    // Expected: Metric starts incrementing as channel fills
    // Expected: After channel fills (10k entries), subsequent critical
    //           errors from consensus/storage are silently dropped
    
    // Verify: Send a known critical error (e.g., consensus safety violation)
    // Result: Error log is dropped, not visible in logs
    // Result: Alert fires after 5 minutes, but damage is done
}
```

The PoC demonstrates that sustained error generation from multiple peers will fill the logging channel, causing subsequent critical security errors to be lost during the suppression window.

## Notes

This vulnerability is particularly concerning because:

1. **Byzantine Fault Detection**: In a BFT consensus system, error logging is critical for detecting Byzantine behavior. Suppressing these logs undermines the security model.

2. **Existing Infrastructure**: The codebase already has the `sample!` macro infrastructure specifically designed to prevent log flooding, but it's not applied to peer monitoring service errors.

3. **Alert Limitations**: While monitoring exists, the 5-minute delay and "warning" severity mean operators may not respond immediately, giving attackers a significant window to operate undetected.

4. **Cascading Effects**: If the logging suppression allows consensus issues or storage corruption to go undetected, the impact could escalate to Critical severity (consensus safety violations, data loss).

### Citations

**File:** peer-monitoring-service/server/src/lib.rs (L186-195)
```rust
            Err(error) => {
                // Log the error and update the counters
                increment_counter(
                    &metrics::PEER_MONITORING_ERRORS_ENCOUNTERED,
                    network_id,
                    error.get_label(),
                );
                error!(LogSchema::new(LogEntry::PeerMonitoringServiceError)
                    .error(&error)
                    .request(&request));
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L44-44)
```rust
pub const CHANNEL_SIZE: usize = 10000;
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L556-563)
```rust
        if let Some(sender) = &self.sender {
            if sender
                .try_send(LoggerServiceEvent::LogEntry(entry))
                .is_err()
            {
                STRUCT_LOG_QUEUE_ERROR_COUNT.inc();
            }
        }
```

**File:** config/src/config/peer_monitoring_config.rs (L26-26)
```rust
            max_concurrent_requests: 1000,
```

**File:** terraform/helm/monitoring/files/rules/alerts.yml (L156-161)
```yaml
  - alert: Logs Being Dropped
    expr: 1 < (rate(aptos_struct_log_queue_error[1m]) + rate(aptos_struct_log_send_error[1m]))
    for: 5m
    labels:
      severity: warning
      summary: "Logs being dropped"
```

**File:** crates/aptos-logger/src/sample.rs (L11-23)
```rust
/// The rate at which a `sample!` macro will run it's given function
#[derive(Debug)]
pub enum SampleRate {
    /// Only sample a single time during a window of time. This rate only has a resolution in
    /// seconds.
    Duration(Duration),
    /// Sample based on the frequency of the event. The provided u64 is the inverse of the
    /// frequency (1/x), for example Frequency(2) means that 1 out of every 2 events will be
    /// sampled (1/2).
    Frequency(u64),
    /// Always Sample
    Always,
}
```
