# Audit Report

## Title
ValidatorTransaction Deduplication Bypass Enabling Block Execution Failure via Duplicate DKG Transactions

## Summary
The `dedup()` function in the consensus layer only processes `SignedTransaction` (user transactions) and does not deduplicate `ValidatorTransaction` instances. A malicious or buggy block proposer can include duplicate DKG (Distributed Key Generation) `ValidatorTransaction` entries in a single block, which pass consensus validation but cause fatal execution failures, potentially disrupting consensus liveness. [1](#0-0) 

## Finding Description

**The Deduplication Bypass:**

The `dedup()` function exclusively operates on `Vec<SignedTransaction>`, which represents only user transactions. ValidatorTransactions (including DKG results and JWK updates) bypass this deduplication mechanism entirely: [2](#0-1) 

**Block Structure with Separate Transaction Types:**

Blocks combine three transaction types in order: BlockMetadata, ValidatorTransactions, and SignedTransactions (user transactions). Only the SignedTransactions undergo deduplication: [3](#0-2) 

**Missing Duplicate Validation:**

During proposal validation, `process_proposal()` verifies each ValidatorTransaction individually but lacks duplicate detection within a single proposal: [4](#0-3) 

**Execution Failure Mechanism:**

When a duplicate DKG ValidatorTransaction executes:
1. The first instance completes successfully, marking the DKG session as finished
2. The second instance attempts to finish an already-completed DKG session
3. The Move function `dkg::finish()` aborts with `EDKG_NOT_IN_PROGRESS`: [5](#0-4) 

This abort is NOT classified as an "Expected" failure in the Rust handler, causing it to propagate as an unexpected error: [6](#0-5) 

**Fatal Block Execution Failure:**

The unexpected error becomes a `FatalVMError` that halts block execution: [7](#0-6) [8](#0-7) [9](#0-8) 

## Impact Explanation

**Severity: High**

This vulnerability meets the **High Severity** criteria per Aptos Bug Bounty:
- **"Significant protocol violations"**: Blocks that pass consensus validation fail during execution
- **"Validator node slowdowns"**: Repeated invalid blocks cause wasted computation and potential liveness degradation

**Specific Impacts:**
1. **Consensus Liveness Risk**: Blocks voted on and accepted fail to execute, wasting validator resources
2. **Chain Progress Disruption**: If multiple validators (intentionally or due to bugs) produce such blocks, chain progress slows
3. **Deterministic Execution Violation**: The critical invariant that "all validators must produce identical state roots for identical blocks" is compromised when blocks fail unexpectedly
4. **Resource Waste**: Validators expend computational resources on blocks that cannot complete execution

**Not Critical because:**
- Does not cause permanent network partition
- Does not enable fund theft or minting
- Requires attacker to be selected as proposer (probabilistic, not guaranteed)
- Can be recovered through normal round progression

## Likelihood Explanation

**Likelihood: Medium**

**Attack Requirements:**
- Attacker must be a validator in the active validator set
- Must be selected as block proposer for a round (probability = 1/validator_count)
- Must have access to a valid DKG transcript (only during DKG phases, which are infrequent)
- No collusion with other validators required

**Exploitation Complexity: Low**
- Attack is trivial to execute once conditions are met
- Simply duplicate a ValidatorTransaction in the block proposal
- No complex timing or state manipulation required

**Real-World Scenarios:**
1. **Malicious Validator**: Intentionally disrupts consensus by proposing invalid blocks
2. **Buggy Implementation**: Faulty proposal logic accidentally includes duplicates
3. **Coordinated Attack**: Multiple compromised validators repeatedly produce invalid blocks to degrade liveness

The vulnerability is MORE likely to manifest accidentally (buggy code) than from intentional exploitation, which increases its practical risk.

## Recommendation

**Immediate Fix: Add ValidatorTransaction Deduplication**

Add duplicate detection for ValidatorTransactions during proposal validation in `round_manager.rs`:

```rust
// In process_proposal(), after line 1136, add:
if let Some(vtxns) = proposal.validator_txns() {
    let mut seen_vtxn_hashes = HashSet::new();
    for vtxn in vtxns {
        let vtxn_hash = vtxn.hash();
        ensure!(
            seen_vtxn_hashes.insert(vtxn_hash),
            "Duplicate ValidatorTransaction detected in proposal: hash={}",
            vtxn_hash
        );
    }
}
```

**Alternative: Classify DKG Abort as Expected**

Extend the `ExpectedFailure` enum in `dkg.rs` to include the DKG-not-in-progress case:

```rust
enum ExpectedFailure {
    EpochNotCurrent = 0x10001,
    TranscriptDeserializationFailed = 0x10002,
    TranscriptVerificationFailed = 0x10003,
    DKGNotInProgress = 0x10004,  // Add this
    MissingResourceDKGState = 0x30001,
    MissingResourceInprogressDKGSession = 0x30002,
    MissingResourceConfiguration = 0x30003,
}
```

Then add handling to check for this error code before calling the Move function.

**Recommended Approach: Both**

Implement both fixes for defense-in-depth:
1. Prevent duplicate ValidatorTransactions at consensus validation (primary defense)
2. Gracefully handle duplicate DKG executions at VM level (secondary defense)

## Proof of Concept

**Rust Test (Consensus Layer):**

```rust
#[tokio::test]
async fn test_duplicate_validator_transaction_in_proposal() {
    // Setup test environment with validators
    let mut test_harness = TestHarness::new();
    
    // Create a valid DKG transcript
    let dkg_transcript = DKGTranscript {
        metadata: DKGTranscriptMetadata {
            epoch: test_harness.current_epoch(),
            author: test_harness.validator_address(0),
        },
        transcript_bytes: vec![/* valid transcript data */],
    };
    
    let validator_txn = ValidatorTransaction::DKGResult(dkg_transcript.clone());
    
    // Create proposal with DUPLICATE ValidatorTransaction
    let proposal = test_harness.create_proposal_ext(
        vec![validator_txn.clone(), validator_txn.clone()],  // DUPLICATE!
        vec![/* user transactions */],
    );
    
    // Proposal passes validation (current bug)
    assert!(test_harness.round_manager.process_proposal(proposal).await.is_ok());
    
    // But execution FAILS with FatalVMError
    let execution_result = test_harness.executor.execute_block(proposal.id()).await;
    assert!(matches!(
        execution_result.unwrap_err(),
        BlockExecutionError::FatalVMError(_)
    ));
}
```

**Move Test (VM Layer):**

```move
#[test(framework = @aptos_framework)]
#[expected_failure(abort_code = 0x30002, location = aptos_framework::dkg)]
fun test_duplicate_dkg_finish_aborts(framework: &signer) {
    // Initialize DKG state
    dkg::initialize(framework);
    
    // Start a DKG session
    dkg::start(1, /* config */, /* validators */);
    
    // Finish DKG successfully
    dkg::finish(vector[/* transcript bytes */]);
    
    // Attempt to finish AGAIN - should abort with EDKG_NOT_IN_PROGRESS
    dkg::finish(vector[/* same transcript */]);  // ABORTS HERE
}
```

**Notes**

The vulnerability stems from an architectural asymmetry: user transactions undergo comprehensive deduplication through the `dedup()` function (using hash+authenticator pairs), while ValidatorTransactions completely bypass this mechanism. This creates a validation gap where duplicate ValidatorTransactions can enter blocks despite being semantically invalid.

The issue is particularly severe for DKG transactions because the Move-level error (`EDKG_NOT_IN_PROGRESS`) is not classified as an "Expected" failure in the Rust VM wrapper, causing it to propagate as a fatal error rather than being gracefully discarded. In contrast, duplicate JWK transactions fail with `IncorrectVersion`, which IS an expected failure and gets discarded without halting execution.

This vulnerability highlights the importance of uniform transaction validation across all transaction types, especially for system-level transactions that should never fail during execution.

### Citations

**File:** consensus/src/txn_hash_and_authenticator_deduper.rs (L39-94)
```rust
    fn dedup(&self, transactions: Vec<SignedTransaction>) -> Vec<SignedTransaction> {
        let _timer = TXN_DEDUP_SECONDS.start_timer();
        let mut seen = HashMap::new();
        let mut is_possible_duplicate = false;
        let mut possible_duplicates = vec![false; transactions.len()];
        for (i, txn) in transactions.iter().enumerate() {
            match seen.get(&(txn.sender(), txn.replay_protector())) {
                None => {
                    seen.insert((txn.sender(), txn.replay_protector()), i);
                },
                Some(first_index) => {
                    is_possible_duplicate = true;
                    possible_duplicates[*first_index] = true;
                    possible_duplicates[i] = true;
                },
            }
        }
        if !is_possible_duplicate {
            TXN_DEDUP_FILTERED.observe(0 as f64);
            return transactions;
        }

        let num_txns = transactions.len();

        let hash_and_authenticators: Vec<_> = possible_duplicates
            .into_par_iter()
            .zip(&transactions)
            .with_min_len(optimal_min_len(num_txns, 48))
            .map(|(need_hash, txn)| match need_hash {
                true => Some((txn.committed_hash(), txn.authenticator())),
                false => None,
            })
            .collect();

        // TODO: Possibly parallelize. See struct comment.
        let mut seen_hashes = HashSet::new();
        let mut num_duplicates: usize = 0;
        let filtered: Vec<_> = hash_and_authenticators
            .into_iter()
            .zip(transactions)
            .filter_map(|(maybe_hash, txn)| match maybe_hash {
                None => Some(txn),
                Some(hash_and_authenticator) => {
                    if seen_hashes.insert(hash_and_authenticator) {
                        Some(txn)
                    } else {
                        num_duplicates += 1;
                        None
                    }
                },
            })
            .collect();

        TXN_DEDUP_FILTERED.observe(num_duplicates as f64);
        filtered
    }
```

**File:** consensus/src/block_preparer.rs (L71-119)
```rust
    pub async fn prepare_block(
        &self,
        block: &Block,
        txns: Vec<SignedTransaction>,
        max_txns_from_block_to_execute: Option<u64>,
        block_gas_limit: Option<u64>,
    ) -> (Vec<SignedTransaction>, Option<u64>) {
        let start_time = Instant::now();

        let txn_filter_config = self.txn_filter_config.clone();
        let txn_deduper = self.txn_deduper.clone();
        let txn_shuffler = self.txn_shuffler.clone();

        let block_id = block.id();
        let block_author = block.author();
        let block_epoch = block.epoch();
        let block_timestamp_usecs = block.timestamp_usecs();

        // Transaction filtering, deduplication and shuffling are CPU intensive tasks, so we run them in a blocking task.
        let result = tokio::task::spawn_blocking(move || {
            let filtered_txns = filter_block_transactions(
                txn_filter_config,
                block_id,
                block_author,
                block_epoch,
                block_timestamp_usecs,
                txns,
            );
            let deduped_txns = txn_deduper.dedup(filtered_txns);
            let mut shuffled_txns = {
                let _timer = TXN_SHUFFLE_SECONDS.start_timer();

                txn_shuffler.shuffle(deduped_txns)
            };

            if let Some(max_txns_from_block_to_execute) = max_txns_from_block_to_execute {
                shuffled_txns.truncate(max_txns_from_block_to_execute as usize);
            }
            TXNS_IN_BLOCK
                .with_label_values(&["after_filter"])
                .observe(shuffled_txns.len() as f64);
            MAX_TXNS_FROM_BLOCK_TO_EXECUTE.observe(shuffled_txns.len() as f64);
            shuffled_txns
        })
        .await
        .expect("Failed to spawn blocking task for transaction generation");
        counters::BLOCK_PREPARER_LATENCY.observe_duration(start_time.elapsed());
        (result, block_gas_limit)
    }
```

**File:** consensus/consensus-types/src/block.rs (L553-566)
```rust
    pub fn combine_to_input_transactions(
        validator_txns: Vec<ValidatorTransaction>,
        txns: Vec<SignedTransaction>,
        metadata: BlockMetadataExt,
    ) -> Vec<Transaction> {
        once(Transaction::from(metadata))
            .chain(
                validator_txns
                    .into_iter()
                    .map(Transaction::ValidatorTransaction),
            )
            .chain(txns.into_iter().map(Transaction::UserTransaction))
            .collect()
    }
```

**File:** consensus/src/round_manager.rs (L1126-1177)
```rust
        if let Some(vtxns) = proposal.validator_txns() {
            for vtxn in vtxns {
                let vtxn_type_name = vtxn.type_name();
                ensure!(
                    is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                    "unexpected validator txn: {:?}",
                    vtxn_type_name
                );
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
            }
        }

        let (num_validator_txns, validator_txns_total_bytes): (usize, usize) =
            proposal.validator_txns().map_or((0, 0), |txns| {
                txns.iter().fold((0, 0), |(count_acc, size_acc), txn| {
                    (count_acc + 1, size_acc + txn.size_in_bytes())
                })
            });

        let num_validator_txns = num_validator_txns as u64;
        let validator_txns_total_bytes = validator_txns_total_bytes as u64;
        let vtxn_count_limit = self.vtxn_config.per_block_limit_txn_count();
        let vtxn_bytes_limit = self.vtxn_config.per_block_limit_total_bytes();
        let author_hex = author.to_hex();
        PROPOSED_VTXN_COUNT
            .with_label_values(&[&author_hex])
            .inc_by(num_validator_txns);
        PROPOSED_VTXN_BYTES
            .with_label_values(&[&author_hex])
            .inc_by(validator_txns_total_bytes);
        info!(
            vtxn_count_limit = vtxn_count_limit,
            vtxn_count_proposed = num_validator_txns,
            vtxn_bytes_limit = vtxn_bytes_limit,
            vtxn_bytes_proposed = validator_txns_total_bytes,
            proposer = author_hex,
            "Summarizing proposed validator txns."
        );

        ensure!(
            num_validator_txns <= vtxn_count_limit,
            "process_proposal failed with per-block vtxn count limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_txn_count(),
            num_validator_txns
        );
        ensure!(
            validator_txns_total_bytes <= vtxn_bytes_limit,
            "process_proposal failed with per-block vtxn bytes limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_total_bytes(),
            validator_txns_total_bytes
        );
```

**File:** aptos-move/framework/aptos-framework/sources/dkg.move (L90-97)
```text
    public(friend) fun finish(transcript: vector<u8>) acquires DKGState {
        let dkg_state = borrow_global_mut<DKGState>(@aptos_framework);
        assert!(option::is_some(&dkg_state.in_progress), error::invalid_state(EDKG_NOT_IN_PROGRESS));
        let session = option::extract(&mut dkg_state.in_progress);
        session.transcript = transcript;
        dkg_state.last_completed = option::some(session);
        dkg_state.in_progress = option::none();
    }
```

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L34-49)
```rust
enum ExpectedFailure {
    // Move equivalent: `errors::invalid_argument(*)`
    EpochNotCurrent = 0x10001,
    TranscriptDeserializationFailed = 0x10002,
    TranscriptVerificationFailed = 0x10003,

    // Move equivalent: `errors::invalid_state(*)`
    MissingResourceDKGState = 0x30001,
    MissingResourceInprogressDKGSession = 0x30002,
    MissingResourceConfiguration = 0x30003,
}

enum ExecutionFailure {
    Expected(ExpectedFailure),
    Unexpected(VMStatus),
}
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L3025-3034)
```rust
            Transaction::ValidatorTransaction(txn) => {
                let (vm_status, output) = self.process_validator_transaction(
                    resolver,
                    code_storage,
                    // TODO: Remove this clone operation
                    txn.clone(),
                    log_context,
                )?;
                (vm_status, output)
            },
```

**File:** aptos-move/aptos-vm/src/block_executor/vm_wrapper.rs (L99-115)
```rust
            // execute_single_transaction only returns an error when transactions that should never fail
            // (BlockMetadataTransaction and GenesisTransaction) return an error themselves.
            Err(err) => {
                if err.status_code() == StatusCode::SPECULATIVE_EXECUTION_ABORT_ERROR {
                    ExecutionStatus::SpeculativeExecutionAbortError(
                        err.message().cloned().unwrap_or_default(),
                    )
                } else if err.status_code()
                    == StatusCode::DELAYED_FIELD_OR_BLOCKSTM_CODE_INVARIANT_ERROR
                {
                    ExecutionStatus::DelayedFieldsCodeInvariantError(
                        err.message().cloned().unwrap_or_default(),
                    )
                } else {
                    ExecutionStatus::Abort(err)
                }
            },
```

**File:** aptos-move/block-executor/src/executor.rs (L2237-2248)
```rust
                ExecutionStatus::Abort(err) => {
                    if let Some(commit_hook) = &self.transaction_commit_hook {
                        commit_hook.on_execution_aborted(idx as TxnIndex);
                    }
                    error!(
                        "Sequential execution FatalVMError by transaction {}",
                        idx as TxnIndex
                    );
                    // Record the status indicating the unrecoverable VM failure.
                    return Err(SequentialBlockExecutionError::ErrorToReturn(
                        BlockExecutionError::FatalVMError(err),
                    ));
```
