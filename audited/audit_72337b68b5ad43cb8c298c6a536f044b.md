# Audit Report

## Title
Race Condition in BatchV2Schema Persistence Causes Cache-Database Inconsistency in Quorum Store

## Summary
Two consensus threads can simultaneously persist the same `BatchInfoExt` entry with different data (e.g., different expiration times), causing a race condition where the database write order is non-deterministic. This results in cache-database inconsistency where the in-memory cache contains newer data while the persistent database contains stale data, breaking state consistency guarantees. [1](#0-0) 

## Finding Description

The vulnerability exists in the batch persistence flow where cache updates and database writes are not atomic. The critical code path is:

1. **Cache Update Phase**: Thread acquires DashMap entry lock in `insert_to_cache`, updates cache, releases lock [2](#0-1) 

2. **Database Write Phase**: After lock release, thread writes to database without synchronization [3](#0-2) 

The database write uses `write_schemas_relaxed` which provides no conflict detection: [4](#0-3) 

**Attack Scenario:**

When a batch with digest X is received from multiple sources with different expiration times:

**Timeline T1:** Thread A receives batch (digest X, expiration 100)
**Timeline T2:** Thread B receives batch (digest X, expiration 200)

**Timeline T3:** Thread A acquires lock, inserts cache entry (exp 100), releases lock, returns Ok(true)
**Timeline T4:** Thread B acquires lock, sees entry with exp 100 < 200, replaces cache entry (exp 200), releases lock, returns Ok(true)
**Timeline T5:** Thread B writes to DB (exp 200)
**Timeline T6:** Thread A writes to DB (exp 100) - **OVERWRITES Thread B's newer write**

**Result:** Cache contains exp 200, Database contains exp 100

This violates the cache comparison logic in `insert_to_cache` which only checks cache state, not database state: [5](#0-4) 

Multiple code paths can trigger concurrent persistence:
- Network batch reception via `BatchCoordinator::handle_batches_msg` [6](#0-5) 
  
- Batch fetching via `BatchReaderImpl::get_or_fetch_batch` [7](#0-6) 

## Impact Explanation

**Severity: Medium** - State inconsistencies requiring intervention

This vulnerability causes:

1. **Immediate Impact**: Cache-database inconsistency during runtime. If the cache entry is evicted and later read from disk (PersistedOnly mode), stale data is returned: [8](#0-7) 

2. **Post-Restart Impact**: After node restart, `populate_cache_and_gc_expired_batches_v2` loads stale data from database into cache, permanently losing the newer entry: [9](#0-8) 

3. **Consensus Impact**: Batch expiration affects consensus decisions. Using stale expiration times can cause premature batch expiration, leading to:
   - Incorrect batch availability decisions
   - Potential consensus liveness issues if critical batches are incorrectly marked as expired
   - Non-deterministic validator behavior depending on cache vs. database reads

This meets **Medium Severity** criteria: "State inconsistencies requiring intervention"

## Likelihood Explanation

**Likelihood: Medium-High**

This occurs when:
1. Same batch digest is received from multiple network sources concurrently (common in distributed consensus)
2. Batches have different expiration times (happens during batch expiration extension)
3. Both threads complete cache update and proceed to database write with non-deterministic ordering

The test suite explicitly tests concurrent save operations with the same digest, indicating this is a recognized concurrent access pattern: [10](#0-9) 

However, the test only validates cache behavior, not cache-database consistency.

## Recommendation

Introduce atomic cache-database writes with proper synchronization. Two approaches:

**Option 1: Database-level synchronization with version checks**

Add a version/timestamp field to `PersistedValue` and use conditional writes:

```rust
fn persist_inner(
    &self,
    batch_info: BatchInfoExt,
    persist_request: PersistedValue<BatchInfoExt>,
) -> Option<SignedBatchInfo<BatchInfoExt>> {
    let digest = *persist_request.digest();
    
    // Single atomic operation holding lock for both cache and DB
    let needs_db = {
        let mut cache_entry = self.db_cache.entry(digest);
        match cache_entry {
            Occupied(mut entry) if entry.get().expiration() >= persist_request.expiration() => {
                return None; // Existing entry is newer or equal
            },
            _ => {
                // Update cache and return true to indicate DB write needed
                cache_entry.or_insert(persist_request.clone());
                true
            }
        }
    };
    
    if needs_db {
        // Only write to DB if we successfully updated cache
        // AND verify DB state before writing
        if let Ok(Some(existing)) = self.db.get_batch_v2(&digest) {
            if existing.expiration() >= persist_request.expiration() {
                // DB already has newer entry, skip write
                return self.generate_signed_batch_info(batch_info).ok();
            }
        }
        self.db.save_batch_v2(persist_request).expect("Could not write to DB");
    }
    
    self.generate_signed_batch_info(batch_info).ok()
}
```

**Option 2: Use Mutex for digest-level write serialization**

Maintain a `DashMap<HashValue, Arc<Mutex<()>>>` to serialize all writes for the same digest:

```rust
struct BatchStore {
    // ... existing fields ...
    write_locks: DashMap<HashValue, Arc<Mutex<()>>>,
}

fn persist_inner(
    &self,
    batch_info: BatchInfoExt,
    persist_request: PersistedValue<BatchInfoExt>,
) -> Option<SignedBatchInfo<BatchInfoExt>> {
    let digest = *persist_request.digest();
    let lock = self.write_locks.entry(digest)
        .or_insert_with(|| Arc::new(Mutex::new(())))
        .clone();
    
    let _guard = lock.lock();
    // Now cache update and DB write are serialized
    match self.save(&persist_request) {
        Ok(true) => {
            self.db.save_batch_v2(persist_request).expect("Could not write to DB");
        },
        _ => {}
    }
    
    self.generate_signed_batch_info(batch_info).ok()
}
```

## Proof of Concept

```rust
#[tokio::test(flavor = "multi_thread")]
async fn test_concurrent_persist_cache_db_inconsistency() {
    use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
    use std::sync::Arc;
    use tokio::task::spawn_blocking;
    
    let temp_dir = tempfile::tempdir().unwrap();
    let db = Arc::new(QuorumStoreDB::new(&temp_dir));
    let batch_store = Arc::new(BatchStore::new(
        1, // epoch
        true, // is_new_epoch
        0, // last_certified_time
        db.clone(),
        100_000, // memory_quota
        1_000_000, // db_quota
        1000, // batch_quota
        ValidatorSigner::random(None),
        60_000_000, // expiration_buffer
    ));
    
    let digest = HashValue::random();
    
    // Create two batches with same digest but different expirations
    let batch_old = create_persisted_value(&digest, 100); // expiration 100
    let batch_new = create_persisted_value(&digest, 200); // expiration 200
    
    let batch_store_clone1 = batch_store.clone();
    let batch_store_clone2 = batch_store.clone();
    let batch_old_clone = batch_old.clone();
    let batch_new_clone = batch_new.clone();
    
    let start_flag = Arc::new(AtomicUsize::new(0));
    let start_clone1 = start_flag.clone();
    let start_clone2 = start_flag.clone();
    
    // Thread 1: persist old batch
    let handle1 = spawn_blocking(move || {
        while start_clone1.load(Ordering::Acquire) == 0 {}
        batch_store_clone1.persist(vec![batch_old_clone]);
    });
    
    // Thread 2: persist new batch
    let handle2 = spawn_blocking(move || {
        while start_clone2.load(Ordering::Acquire) == 0 {}
        batch_store_clone2.persist(vec![batch_new_clone]);
    });
    
    // Start both threads simultaneously
    start_flag.store(1, Ordering::Release);
    
    handle1.await.unwrap();
    handle2.await.unwrap();
    
    // Small delay to ensure DB writes complete
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    // Check cache and DB state
    let cache_value = batch_store.get_batch_from_local(&digest).unwrap();
    let db_value = db.get_batch_v2(&digest).unwrap().unwrap();
    
    println!("Cache expiration: {}", cache_value.expiration());
    println!("DB expiration: {}", db_value.expiration());
    
    // This assertion will sometimes FAIL, demonstrating the race condition
    // Cache should have the newer expiration (200)
    // But DB might have the older expiration (100) if Thread 1's write happened last
    assert_eq!(
        cache_value.expiration(),
        db_value.expiration(),
        "Cache-DB inconsistency detected! Cache: {}, DB: {}",
        cache_value.expiration(),
        db_value.expiration()
    );
}
```

Run this test multiple times with `cargo test --release -- --test-threads=1 test_concurrent_persist_cache_db_inconsistency` to observe non-deterministic failures proving the race condition.

## Notes

The vulnerability is confirmed by examining the actual database write mechanism which uses `write_schemas_relaxed` without any optimistic locking or version checking: [11](#0-10) 

The RocksDB writes are atomic per batch but provide no cross-thread synchronization for the same key, allowing the last writer to win without conflict detection.

### Citations

**File:** consensus/src/quorum_store/schema.rs (L49-56)
```rust
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L488-528)
```rust
    fn persist_inner(
        &self,
        batch_info: BatchInfoExt,
        persist_request: PersistedValue<BatchInfoExt>,
    ) -> Option<SignedBatchInfo<BatchInfoExt>> {
        assert!(
            &batch_info == persist_request.batch_info(),
            "Provided batch info doesn't match persist request batch info"
        );
        match self.save(&persist_request) {
            Ok(needs_db) => {
                trace!("QS: sign digest {}", persist_request.digest());
                if needs_db {
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
                }
                if !batch_info.is_v2() {
                    self.generate_signed_batch_info(batch_info.info().clone())
                        .ok()
                        .map(|inner| inner.into())
                } else {
                    self.generate_signed_batch_info(batch_info).ok()
                }
            },
            Err(e) => {
                debug!("QS: failed to store to cache {:?}", e);
                None
            },
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L545-569)
```rust
    fn get_batch_from_db(
        &self,
        digest: &HashValue,
        is_v2: bool,
    ) -> ExecutorResult<PersistedValue<BatchInfoExt>> {
        counters::GET_BATCH_FROM_DB_COUNT.inc();

        if is_v2 {
            match self.db.get_batch_v2(digest) {
                Ok(Some(value)) => Ok(value),
                Ok(None) | Err(_) => {
                    warn!("Could not get batch from db");
                    Err(ExecutorError::CouldNotGetData)
                },
            }
        } else {
            match self.db.get_batch(digest) {
                Ok(Some(value)) => Ok(value.into()),
                Ok(None) | Err(_) => {
                    warn!("Could not get batch from db");
                    Err(ExecutorError::CouldNotGetData)
                },
            }
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L684-710)
```rust
                let fut = async move {
                    let batch_digest = *batch_info.digest();
                    defer!({
                        inflight_requests_clone.lock().remove(&batch_digest);
                    });
                    // TODO(ibalajiarun): Support V2 batch
                    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
                        Ok(value.take_payload().expect("Must have payload"))
                    } else {
                        // Quorum store metrics
                        counters::MISSED_BATCHES_COUNT.inc();
                        let subscriber_rx = batch_store.subscribe(*batch_info.digest());
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
                        Ok(payload)
                    }
                }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L83-89)
```rust
    pub fn put<S: Schema>(&self, key: &S::Key, value: &S::Value) -> Result<(), DbError> {
        // Not necessary to use a batch, but we'd like a central place to bump counters.
        let mut batch = self.db.new_native_batch();
        batch.put::<S>(key, value)?;
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L78-135)
```rust
    fn persist_and_send_digests(
        &self,
        persist_requests: Vec<PersistedValue<BatchInfoExt>>,
        approx_created_ts_usecs: u64,
    ) {
        if persist_requests.is_empty() {
            return;
        }

        let batch_store = self.batch_store.clone();
        let network_sender = self.network_sender.clone();
        let sender_to_proof_manager = self.sender_to_proof_manager.clone();
        tokio::spawn(async move {
            let peer_id = persist_requests[0].author();
            let batches = persist_requests
                .iter()
                .map(|persisted_value| {
                    (
                        persisted_value.batch_info().clone(),
                        persisted_value.summary(),
                    )
                })
                .collect();

            if persist_requests[0].batch_info().is_v2() {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    network_sender
                        .send_signed_batch_info_msg_v2(signed_batch_infos, vec![peer_id])
                        .await;
                }
            } else {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    assert!(!signed_batch_infos
                        .first()
                        .expect("must not be empty")
                        .is_v2());
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    let signed_batch_infos = signed_batch_infos
                        .into_iter()
                        .map(|sbi| sbi.try_into().expect("Batch must be V1 batch"))
                        .collect();
                    network_sender
                        .send_signed_batch_info_msg(signed_batch_infos, vec![peer_id])
                        .await;
                }
            }
            let _ = sender_to_proof_manager
                .send(ProofManagerCommand::ReceiveBatches(batches))
                .await;
        });
    }
```

**File:** consensus/src/quorum_store/tests/batch_store_test.rs (L91-184)
```rust
#[tokio::test(flavor = "multi_thread")]
async fn test_extend_expiration_vs_save() {
    let num_experiments = 2000;
    let batch_store = batch_store_for_test(2001);

    let batch_store_clone1 = batch_store.clone();
    let batch_store_clone2 = batch_store.clone();

    let digests: Vec<HashValue> = (0..num_experiments).map(|_| HashValue::random()).collect();
    let later_exp_values: Vec<PersistedValue<BatchInfoExt>> = (0..num_experiments)
        .map(|i| {
            // Pre-insert some of them.
            if i % 2 == 0 {
                assert_ok!(batch_store.save(&request_for_test(
                    &digests[i],
                    i as u64 + 30,
                    1,
                    None
                )));
            }

            request_for_test(&digests[i], i as u64 + 40, 1, None)
        })
        .collect();

    // Marshal threads to start at the same time.
    let start_flag = Arc::new(AtomicUsize::new(0));
    let start_clone1 = start_flag.clone();
    let start_clone2 = start_flag.clone();

    let save_error = Arc::new(AtomicBool::new(false));
    let save_error_clone1 = save_error.clone();
    let save_error_clone2 = save_error.clone();

    // Thread that extends expiration by saving.
    spawn_blocking(move || {
        for (i, later_exp_value) in later_exp_values.into_iter().enumerate() {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone1.load(Ordering::Acquire);
                if flag_val == 3 * i + 1 || flag_val == 3 * i + 2 {
                    break;
                }
            }

            if batch_store_clone1.save(&later_exp_value).is_err() {
                // Save in a separate flag and break so test doesn't hang.
                save_error_clone1.store(true, Ordering::Release);
                break;
            }
            start_clone1.fetch_add(1, Ordering::Relaxed);
        }
    });

    // Thread that expires.
    spawn_blocking(move || {
        for i in 0..num_experiments {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone2.load(Ordering::Acquire);
                if flag_val == 3 * i + 1
                    || flag_val == 3 * i + 2
                    || save_error_clone2.load(Ordering::Acquire)
                {
                    break;
                }
            }

            batch_store_clone2.update_certified_timestamp(i as u64 + 30);
            start_clone2.fetch_add(1, Ordering::Relaxed);
        }
    });

    for (i, &digest) in digests.iter().enumerate().take(num_experiments) {
        // Set the conditions for experiment (both threads waiting).
        while start_flag.load(Ordering::Acquire) % 3 != 0 {
            assert!(!save_error.load(Ordering::Acquire));
        }

        if i % 2 == 1 {
            assert_ok!(batch_store.save(&request_for_test(&digest, i as u64 + 30, 1, None)));
        }

        // Unleash the threads.
        start_flag.fetch_add(1, Ordering::Relaxed);
    }
    // Finish the experiment
    while start_flag.load(Ordering::Acquire) % 3 != 0 {}

    // Expire everything, call for higher times as well.
    for i in 35..50 {
        batch_store.update_certified_timestamp((i + num_experiments) as u64);
    }
}
```

**File:** storage/schemadb/src/lib.rs (L316-318)
```rust
    pub fn write_schemas_relaxed(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &WriteOptions::default())
    }
```
