# Audit Report

## Title
Missing Validator Set Non-Empty Invariant in on_new_epoch Enables Network Halt via Minimum Stake Threshold

## Summary
The `on_new_epoch()` function in the Aptos staking framework lacks a critical validation check to ensure at least one validator remains active after epoch transition. While `leave_validator_set()` explicitly prevents the last validator from leaving, `on_new_epoch()` can filter out all validators if they drop below the minimum stake threshold, resulting in an empty `active_validators` vector that propagates through the network layer as an empty `PeerSet`, causing complete network halt.

## Finding Description

The vulnerability exists in the validator set state transition logic during epoch changes. The attack exploits a **boundary condition validation gap** between two different code paths that modify the validator set:

**Protected Path**: When validators manually leave via `leave_validator_set()`: [1](#0-0) 

This function contains an explicit assertion ensuring `active_validators` never becomes empty.

**Unprotected Path**: When validators are automatically filtered during `on_new_epoch()`: [2](#0-1) 

This critical epoch transition function filters validators based on minimum stake requirements but **lacks any check** to ensure at least one validator remains. The filtering logic iterates through all validators, and if ALL validators have `voting_power < minimum_stake`, the `next_epoch_validators` vector remains empty, which is then directly assigned to `active_validators`.

**Propagation Through Network Layer**:

When the empty `ValidatorSet` is processed by the network discovery system: [3](#0-2) 

The `extract_validator_set_updates()` function iterates over the empty `ValidatorSet` and returns an empty `PeerSet`, which is then sent to the connectivity manager.

**Consensus Layer Impact**:

The validator consensus info extraction: [4](#0-3) 

With zero active and pending_inactive validators, this function returns an empty `vector<ValidatorConsensusInfo>`, and the `ValidatorVerifier` is created with zero quorum: [5](#0-4) 

**Attack Scenario**:

1. **Governance Attack**: Malicious governance proposal increases `minimum_stake` to a value higher than all current validators' stakes
2. **Epoch Transition**: `on_new_epoch()` is called at the next epoch boundary
3. **Validator Filtering**: Lines 1391-1397 filter out ALL validators as none meet the new minimum
4. **Empty Set Assignment**: Line 1401 assigns empty vector to `active_validators`
5. **Network Discovery**: `extract_validator_set_updates()` returns empty `PeerSet`
6. **Connectivity Loss**: ConnectivityManager has no peers to dial, all connections drop
7. **Consensus Halt**: No validators can produce blocks, network freezes completely

**Invariant Violation**: This breaks the **liveness guarantee** - the network must always be able to produce blocks and reach consensus. With zero validators, the system enters an unrecoverable halted state.

## Impact Explanation

**Critical Severity** - This vulnerability meets the highest severity criteria per the Aptos Bug Bounty program:

- **Total loss of liveness/network availability**: The entire blockchain network halts and cannot process any transactions
- **Non-recoverable network partition (requires hardfork)**: Recovery would require manual intervention using genesis transactions and coordinated hard fork, as demonstrated in the test scenarios [6](#0-5) 

**Affected Components**:
- All validator nodes (cannot produce blocks)
- All fullnodes (cannot sync state)
- All users (cannot submit transactions)
- All dApps (complete service disruption)

The network would be completely frozen until a coordinated hard fork recovery process is executed by core developers.

## Likelihood Explanation

**Likelihood: Low-Medium** 

While the code vulnerability is real and the impact is critical, successful exploitation requires **privileged access or coordinated action**:

**Governance Attack Path** (More Likely):
- Attacker needs significant voting power to pass malicious governance proposal
- Requires social engineering or compromise of major validators
- Governance system may have safeguards against extreme parameter changes
- However, if successful, execution is automatic at next epoch

**Mass Slashing Path** (Less Likely):
- Requires widespread validator misbehavior or network instability
- Natural slashing is designed to be gradual and proportional
- All validators dropping below minimum simultaneously is extremely unlikely

**Key Risk Factors**:
- No runtime check prevents the condition
- Formal specification lacks the required invariant [7](#0-6) 
- Defensive programming inconsistency (protected in one path, not the other)

## Recommendation

Add an explicit validation check in `on_new_epoch()` to enforce the minimum validator invariant:

**In `stake.move`, after line 1401**:
```move
validator_set.active_validators = next_epoch_validators;
// Add this check:
assert!(
    vector::length(&validator_set.active_validators) > 0, 
    error::invalid_state(ELAST_VALIDATOR)
);
validator_set.total_voting_power = total_voting_power;
```

**Additional Safeguards**:

1. **Governance Parameter Validation**: Add checks when updating `minimum_stake` via governance to ensure it won't invalidate all current validators:

```move
public fun update_minimum_stake(new_minimum: u64) {
    let validator_set = borrow_global<ValidatorSet>(@aptos_framework);
    let max_current_stake = calculate_max_validator_stake(validator_set);
    assert!(new_minimum <= max_current_stake, error::invalid_argument(ESTAKE_TOO_HIGH));
    // ... proceed with update
}
```

2. **Formal Specification Update**: Add explicit invariant to `stake.spec.move`:
```move
spec on_new_epoch {
    ensures len(global<ValidatorSet>(@aptos_framework).active_validators) > 0;
}
```

## Proof of Concept

```move
#[test_only]
module aptos_framework::stake_empty_validator_set_test {
    use aptos_framework::stake;
    use aptos_framework::staking_config;
    use std::vector;
    
    #[test(aptos_framework = @aptos_framework)]
    #[expected_failure(abort_code = stake::ELAST_VALIDATOR)]
    fun test_on_new_epoch_prevents_empty_validator_set(
        aptos_framework: &signer
    ) {
        // Setup: Initialize network with validators
        stake::initialize_for_test(aptos_framework);
        
        // Create validators with 100 coins each
        let validators = create_test_validators(5, 100);
        stake::add_validators_for_test(validators);
        
        // Attack: Governance increases minimum stake to 1000
        // This is higher than any validator's current stake
        staking_config::update_required_stake_for_test(1000, 10000);
        
        // Trigger: Call on_new_epoch
        // Expected: Should abort with ELAST_VALIDATOR
        // Actual (without fix): Succeeds with empty active_validators
        stake::on_new_epoch();
        
        // Verify: This line should never be reached
        let validator_set = stake::get_validator_set();
        assert!(vector::length(&validator_set.active_validators) == 0, 0);
        // Network is now halted - no validators to produce blocks
    }
}
```

## Notes

**Key Evidence of Vulnerability**:

1. **Code Asymmetry**: The explicit protection in `leave_validator_set()` proves the developers recognized the importance of the non-empty invariant, but failed to apply it consistently to `on_new_epoch()`

2. **ValidatorVerifier Design**: The consensus layer is designed to handle empty validator sets (quorum=0) without panicking, which means the system won't crash but will simply halt silently [8](#0-7) 

3. **Network Layer Confirmation**: The network discovery layer will successfully process an empty validator set and return empty peer sets [9](#0-8) 

4. **Formal Verification Gap**: The specification explicitly states `on_new_epoch` should never abort but doesn't ensure non-empty validator set [10](#0-9) 

This is a **critical defensive programming oversight** that violates the liveness invariant of the Aptos blockchain.

### Citations

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L1255-1255)
```text
            assert!(vector::length(&validator_set.active_validators) > 0, error::invalid_state(ELAST_VALIDATOR));
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L1372-1402)
```text
        let next_epoch_validators = vector::empty();
        let (minimum_stake, _) = staking_config::get_required_stake(&config);
        let vlen = vector::length(&validator_set.active_validators);
        let total_voting_power = 0;
        let i = 0;
        while ({
            spec {
                invariant spec_validators_are_initialized(next_epoch_validators);
                invariant i <= vlen;
            };
            i < vlen
        }) {
            let old_validator_info = vector::borrow_mut(&mut validator_set.active_validators, i);
            let pool_address = old_validator_info.addr;
            let validator_config = borrow_global<ValidatorConfig>(pool_address);
            let stake_pool = borrow_global<StakePool>(pool_address);
            let new_validator_info = generate_validator_info(pool_address, stake_pool, *validator_config);

            // A validator needs at least the min stake required to join the validator set.
            if (new_validator_info.voting_power >= minimum_stake) {
                spec {
                    assume total_voting_power + new_validator_info.voting_power <= MAX_U128;
                };
                total_voting_power = total_voting_power + (new_validator_info.voting_power as u128);
                vector::push_back(&mut next_epoch_validators, new_validator_info);
            };
            i = i + 1;
        };

        validator_set.active_validators = next_epoch_validators;
        validator_set.total_voting_power = total_voting_power;
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L1572-1594)
```text
    fun validator_consensus_infos_from_validator_set(validator_set: &ValidatorSet): vector<ValidatorConsensusInfo> {
        let validator_consensus_infos = vector[];

        let num_active = vector::length(&validator_set.active_validators);
        let num_pending_inactive = vector::length(&validator_set.pending_inactive);
        spec {
            assume num_active + num_pending_inactive <= MAX_U64;
        };
        let total = num_active + num_pending_inactive;

        // Pre-fill the return value with dummy values.
        let idx = 0;
        while ({
            spec {
                invariant idx <= len(validator_set.active_validators) + len(validator_set.pending_inactive);
                invariant len(validator_consensus_infos) == idx;
                invariant len(validator_consensus_infos) <= len(validator_set.active_validators) + len(validator_set.pending_inactive);
            };
            idx < total
        }) {
            vector::push_back(&mut validator_consensus_infos, validator_consensus_info::default());
            idx = idx + 1;
        };
```

**File:** network/discovery/src/validator_set.rs (L108-150)
```rust
pub(crate) fn extract_validator_set_updates(
    network_context: NetworkContext,
    node_set: ValidatorSet,
) -> PeerSet {
    let is_validator = network_context.network_id().is_validator_network();

    // Decode addresses while ignoring bad addresses
    node_set
        .into_iter()
        .map(|info| {
            let peer_id = *info.account_address();
            let config = info.into_config();

            let addrs = if is_validator {
                config
                    .validator_network_addresses()
                    .map_err(anyhow::Error::from)
            } else {
                config
                    .fullnode_network_addresses()
                    .map_err(anyhow::Error::from)
            }
            .map_err(|err| {
                inc_by_with_context(&DISCOVERY_COUNTS, &network_context, "read_failure", 1);

                warn!(
                    NetworkSchema::new(&network_context),
                    "OnChainDiscovery: Failed to parse any network address: peer: {}, err: {}",
                    peer_id,
                    err
                )
            })
            .unwrap_or_default();

            let peer_role = if is_validator {
                PeerRole::Validator
            } else {
                PeerRole::ValidatorFullNode
            };
            (peer_id, Peer::from_addrs(peer_role, addrs))
        })
        .collect()
}
```

**File:** types/src/validator_verifier.rs (L206-214)
```rust
    pub fn new(validator_infos: Vec<ValidatorConsensusInfo>) -> Self {
        let total_voting_power = sum_voting_power(&validator_infos);
        let quorum_voting_power = if validator_infos.is_empty() {
            0
        } else {
            total_voting_power * 2 / 3 + 1
        };
        Self::build_index(validator_infos, quorum_voting_power, total_voting_power)
    }
```

**File:** testsuite/smoke-test/src/genesis.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::{
    smoke_test_environment::SwarmBuilder,
    storage::{db_backup, db_restore},
    utils::{
        check_create_mint_transfer_node, create_test_accounts, execute_transactions,
        execute_transactions_and_wait, swarm_utils::insert_waypoint, MAX_CATCH_UP_WAIT_SECS,
        MAX_CONNECTIVITY_WAIT_SECS, MAX_HEALTHY_WAIT_SECS,
    },
    workspace_builder,
    workspace_builder::workspace_root,
};
use anyhow::anyhow;
use aptos_config::{
    config::{AdminServiceConfig, InitialSafetyRulesConfig, NodeConfig},
    network_id::NetworkId,
};
use aptos_forge::{
    get_highest_synced_version, get_highest_synced_version_and_epoch,
    wait_for_all_nodes_to_catchup, LocalNode, LocalSwarm, Node, NodeExt, SwarmExt, Validator,
};
use aptos_temppath::TempPath;
use aptos_types::{transaction::Transaction, waypoint::Waypoint};
use move_core_types::language_storage::CORE_CODE_ADDRESS;
use regex::Regex;
use reqwest::Client;
use std::{
    fs,
    path::PathBuf,
    process::Command,
    str::FromStr,
    time::{Duration, Instant},
};

#[ignore] // TODO(joshlind): revisit the flakes once we update state sync to handle forks automatically.
#[tokio::test]
/// This test verifies:
/// 1. The behaviour of the consensus sync_only mode (to emulate a network halt).
/// 2. The flow of a genesis write-set transaction for fullnodes (after the validators have forked).
///
/// The test does the following:
/// 1. Start a 4 node validator network, including 2 VFNs.
/// 2. Use consensus `sync_only` mode to force all nodes to stop at the same version (i.e., emulate a halt).
/// 3. Use the aptos CLI to generate a genesis transaction that removes the last validator from the set.
/// 4. Use the aptos-debugger to manually apply the genesis transaction to all remaining validators.
/// 5. Verify that the network is able to resume consensus and that the last validator is no longer in the set.
/// 6. Use the aptos-debugger to manually apply the genesis transaction to all VFNs.
/// 7. Verify that the VFNs are able to sync with the rest of the network.
```

**File:** aptos-move/framework/aptos-framework/sources/stake.spec.move (L453-465)
```text
    spec on_new_epoch {
        pragma verify = false; // TODO: set because of timeout (property proved).
        pragma disable_invariants_in_body;
        // The following resource requirement cannot be discharged by the global
        // invariants because this function is called during genesis.
        include ResourceRequirement;
        include GetReconfigStartTimeRequirement;
        include staking_config::StakingRewardsConfigRequirement;
        include aptos_framework::aptos_coin::ExistsAptosCoin;
        // This function should never abort.
        /// [high-level-req-4]
        aborts_if false;
    }
```
