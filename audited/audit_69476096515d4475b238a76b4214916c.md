# Audit Report

## Title
Duplicate Transaction Undercounting Vulnerability Allows Byzantine Validators to Flood Consensus with Undetected Duplicates

## Summary
The `KNOWN_DUPLICATE_TXNS_WHEN_PULL` metric in the quorum store severely undercounts duplicate transactions when batch summaries are missing, allowing Byzantine validators to include many duplicate transactions in consensus blocks without proper detection. The duplicate counting logic in `pull_internal` fails to track transactions from batches without summaries in the `filtered_txns` HashSet, causing each such batch to count its transactions as unique even when they are duplicates.

## Finding Description

The vulnerability exists in the `pull_internal` function where batches are selected for consensus block proposals. [1](#0-0) 

When a batch has a proof but no `txn_summaries`, the code assumes all transactions in the batch are unique and adds `batch.num_txns()` to `cur_unique_txns`. Critically, it does NOT insert any transaction summaries into the `filtered_txns` HashSet that tracks which transactions have already been seen.

This breaks the duplicate detection invariant in two ways:

**1. Metric Undercounting:** The `KNOWN_DUPLICATE_TXNS_WHEN_PULL` metric is calculated as: [2](#0-1) 

When `unique_txns` is overcounted due to the bug, this metric severely undercounts actual duplicates.

**2. Backpressure Miscalculation:** The `remaining_txns_without_duplicates` function also exhibits the same flaw: [3](#0-2) 

It counts transactions from batches without summaries as unique, affecting backpressure calculations used to throttle batch creation.

**Attack Scenario:**

1. Byzantine validator creates Batch A with transactions [T1, T2, T3] and Batch B with the same transactions [T1, T2, T3]
2. Validator collects valid quorum signatures for both batches (requires cooperation from honest validators who sign the batch digests)
3. Validator broadcasts the proofs to the network via: [4](#0-3) 

4. Validator delays or withholds batch summaries from being sent via: [5](#0-4) 

5. When consensus pulls batches, both batches pass the filter check: [6](#0-5) 

6. Without `txn_summaries`, both batches are counted as having 3 unique transactions each
7. `cur_unique_txns` = 6 (should be 3), `all_txns.count()` = 6
8. `KNOWN_DUPLICATE_TXNS_WHEN_PULL` = 6 - 6 = 0 duplicates (should be 3)

This violates the **State Consistency** invariant by creating inconsistent views of duplicate transaction counts across validators, and the **Resource Limits** invariant by allowing excessive duplicate transactions to consume network and consensus resources.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program for the following reasons:

1. **Significant Protocol Violation**: The quorum store protocol is designed to detect and report duplicate transactions. This bug allows duplicates to pass through consensus undetected by the primary monitoring metric, violating the protocol's transparency guarantees.

2. **Validator Node Slowdowns**: Byzantine validators can flood the network with duplicate transactions that consume:
   - Network bandwidth transmitting duplicate data
   - Consensus overhead agreeing on blocks with duplicates
   - CPU/memory in the execution-time deduplication process

3. **Monitoring Bypass**: The bug provides cover for Byzantine behavior by making duplicate transaction spam invisible to observability systems that rely on the `KNOWN_DUPLICATE_TXNS_WHEN_PULL` metric.

4. **Backpressure Manipulation**: Incorrect unique transaction counts affect when backpressure is applied to batch creation, potentially causing premature throttling or allowing queue exhaustion.

While execution-time deduplication prevents duplicate execution, the resource waste and monitoring bypass constitute a significant protocol violation that impacts network health and validator performance.

## Likelihood Explanation

**Likelihood: High**

This vulnerability can occur in two scenarios:

1. **Deliberate Exploitation**: Any validator can deliberately withhold batch summaries after obtaining valid proofs, requiring no special privileges beyond being a validator. The attack is feasible because:
   - Proofs arrive through a separate network path from batch summaries
   - There is no validation requiring summaries to exist before pulling batches
   - Multiple batches can easily contain overlapping transactions

2. **Natural Occurrence**: Network delays or packet loss can cause proofs to arrive before batch summaries, triggering this bug naturally without malicious intent.

The code paths show no checks preventing batches without summaries from being pulled: [7](#0-6) 

## Recommendation

Implement one of the following fixes:

**Option 1: Require Transaction Summaries** (Recommended)
Modify `pull_internal` to skip batches that lack transaction summaries:

```rust
if let Some(ref txn_summaries) = item.txn_summaries {
    // existing logic for calculating unique_txns
} else {
    // Skip batches without summaries to prevent inaccurate duplicate counting
    return true; // continue iteration
}
```

**Option 2: Fetch Missing Summaries**
When `txn_summaries` is None, fetch the actual transactions from `batch_store` and compute summaries on-demand:

```rust
let txn_summaries = match &item.txn_summaries {
    Some(summaries) => summaries,
    None => {
        // Fetch from batch_store and compute summaries
        // This adds latency but ensures accurate counting
    }
};
```

**Option 3: Conservative Duplicate Tracking**
When summaries are missing, assume maximum duplicates and track the batch separately:

```rust
} else {
    // No summaries available - mark as potentially all duplicates
    cur_unique_txns += 0; // assume all could be duplicates
    warn!("Pulling batch without summaries, duplicate count may be inaccurate");
}
```

Additionally, add validation to reject or deprioritize batches without summaries in the pull logic.

## Proof of Concept

```rust
#[test]
fn test_duplicate_undercount_without_summaries() {
    use crate::quorum_store::batch_proof_queue::BatchProofQueue;
    use crate::quorum_store::batch_store::BatchStore;
    use aptos_consensus_types::proof_of_store::{BatchInfoExt, ProofOfStore};
    use aptos_types::PeerId;
    use std::sync::Arc;

    let my_peer_id = PeerId::random();
    let batch_store = Arc::new(BatchStore::new(/* params */));
    let mut queue = BatchProofQueue::new(my_peer_id, batch_store, 100_000_000);

    // Create two batches with identical transactions
    let txns = vec![/* create test transactions T1, T2, T3 */];
    
    // Create Batch A and Batch B with same transactions
    let batch_a = create_test_batch(my_peer_id, txns.clone(), 1);
    let batch_b = create_test_batch(my_peer_id, txns.clone(), 2);
    
    // Create valid proofs for both batches (with quorum signatures)
    let proof_a = create_test_proof(batch_a.clone());
    let proof_b = create_test_proof(batch_b.clone());
    
    // Insert proofs WITHOUT transaction summaries
    queue.insert_proof(proof_a);
    queue.insert_proof(proof_b);
    
    // Pull batches for consensus
    let (proofs, all_txns, unique_txns, _) = queue.pull_proofs(
        &HashSet::new(),
        PayloadTxnsSize::new(10000, 1_000_000),
        10000,
        10000,
        true,
        Duration::from_secs(1000),
    );
    
    // BUG: unique_txns will be 6 instead of 3
    // KNOWN_DUPLICATE_TXNS_WHEN_PULL will be 6 - 6 = 0 instead of 3
    assert_eq!(proofs.len(), 2); // both batches pulled
    assert_eq!(unique_txns, 6); // BUG: counted as unique
    assert_eq!(all_txns.count(), 6);
    
    // The metric would report 0 duplicates when there are actually 3
    let reported_duplicates = all_txns.count() - unique_txns;
    assert_eq!(reported_duplicates, 0); // WRONG: should be 3
}
```

**Notes:**
- This vulnerability affects consensus performance and monitoring accuracy
- Byzantine validators can exploit this to hide duplicate transaction spam
- The bug occurs whenever batches have proofs but lack transaction summaries
- Execution-time deduplication provides a safety net but doesn't prevent resource waste
- The issue impacts both the `KNOWN_DUPLICATE_TXNS_WHEN_PULL` metric and backpressure calculations

### Citations

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L143-172)
```rust
    fn remaining_txns_without_duplicates(&self) -> u64 {
        // txn_summary_num_occurrences counts all the unexpired and uncommitted proofs that have txn summaries
        // in batch_summaries.
        let mut remaining_txns = self.txn_summary_num_occurrences.len() as u64;

        // For the unexpired and uncommitted proofs that don't have transaction summaries in batch_summaries,
        // we need to add the proof.num_txns() to the remaining_txns.
        remaining_txns += self
            .author_to_batches
            .values()
            .map(|batches| {
                batches
                    .keys()
                    .map(|batch_sort_key| {
                        if let Some(item) = self.items.get(&batch_sort_key.batch_key) {
                            if item.txn_summaries.is_none() {
                                if let Some(ref proof) = item.proof {
                                    // The batch has a proof but not txn summaries
                                    return proof.num_txns();
                                }
                            }
                        }
                        0
                    })
                    .sum::<u64>()
            })
            .sum::<u64>();

        remaining_txns
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L444-445)
```rust
            counters::KNOWN_DUPLICATE_TXNS_WHEN_PULL
                .observe((all_txns.count().saturating_sub(unique_txns)) as f64);
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L601-622)
```rust
            let batch_iter = batches.iter().rev().filter_map(|(sort_key, info)| {
                if let Some(item) = self.items.get(&sort_key.batch_key) {
                    let batch_create_ts_usecs =
                        item.info.expiration() - self.batch_expiry_gap_when_init_usecs;

                    // Ensure that the batch was created at least `min_batch_age_usecs` ago to
                    // reduce the chance of inline fetches.
                    if max_batch_creation_ts_usecs
                        .is_some_and(|max_create_ts| batch_create_ts_usecs > max_create_ts)
                    {
                        return None;
                    }

                    if item.is_committed() {
                        return None;
                    }
                    if !(batches_without_proofs ^ item.proof.is_none()) {
                        return Some((info, item));
                    }
                }
                None
            });
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L661-673)
```rust
                        cur_unique_txns +=
                            item.txn_summaries
                                .as_ref()
                                .map_or(batch.num_txns(), |summaries| {
                                    summaries
                                        .iter()
                                        .filter(|summary| {
                                            filtered_txns.insert(**summary)
                                                && block_timestamp.as_secs()
                                                    < summary.expiration_timestamp_secs
                                        })
                                        .count() as u64
                                });
```

**File:** consensus/src/quorum_store/proof_manager.rs (L65-70)
```rust
    pub(crate) fn receive_proofs(&mut self, proofs: Vec<ProofOfStore<BatchInfoExt>>) {
        for proof in proofs.into_iter() {
            self.batch_proof_queue.insert_proof(proof);
        }
        self.update_remaining_txns_and_proofs();
    }
```

**File:** consensus/src/quorum_store/proof_manager.rs (L80-86)
```rust
    pub(crate) fn receive_batches(
        &mut self,
        batch_summaries: Vec<(BatchInfoExt, Vec<TxnSummaryWithExpiration>)>,
    ) {
        self.batch_proof_queue.insert_batches(batch_summaries);
        self.update_remaining_txns_and_proofs();
    }
```
