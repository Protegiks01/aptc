# Audit Report

## Title
Backend Switching Enables Consensus Safety Violation Through SafetyData Reset

## Summary
When a validator operator switches the secure storage backend (e.g., from OnDiskStorage to Vault) and restarts the node, the SafetyRules initialization logic unconditionally resets the `last_voted_round` to 0, even if the validator has already participated in later rounds of the current epoch. This enables equivocation (double-voting), violating the fundamental consensus safety guarantee of AptosBFT.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Backend Initialization Logic** [1](#0-0) 

When a validator switches storage backends (e.g., OnDiskStorage → Vault), the `storage()` function checks if the new backend contains validator identity data by calling `storage.author().is_ok()`. If the new backend is empty (returns `KeyNotSet` error), and an `initial_safety_rules_config` is provided, the system calls `PersistentSafetyStorage::initialize()` to set up the new backend.

2. **Unconditional SafetyData Reset** [2](#0-1) 

The `initialize()` function unconditionally creates fresh SafetyData with epoch=1 and last_voted_round=0, regardless of the validator's actual participation history. This wipes out critical safety information that prevents equivocation.

3. **Epoch Advancement Without Historical Check** [3](#0-2) 

When SafetyRules is initialized via `guarded_initialize()` with an `EpochChangeProof`, if the stored epoch (1) is less than the proof's epoch (e.g., 10), the code takes the `Ordering::Less` branch and resets SafetyData to the new epoch with `last_voted_round=0`. There is no check to verify whether the validator has already voted in that epoch.

**Attack Scenario:**

1. Validator is active in epoch 10, has voted in rounds 1-500
2. Operator switches from OnDiskStorage to Vault backend and restarts
3. New Vault storage is empty; system calls `initialize()` → creates SafetyData{epoch: 1, last_voted_round: 0}
4. Consensus calls `initialize(&proof)` with EpochChangeProof for epoch 10
5. Code compares epoch 1 < 10, resets to SafetyData{epoch: 10, last_voted_round: 0}
6. Validator can now vote again on rounds 1-500 in epoch 10
7. **Result: Equivocation - validator has signed two different votes for the same round**

**Invariant Violated:**

The critical consensus safety rule enforced by `verify_and_update_last_vote_round()` [4](#0-3)  requires that a validator can only vote once per round. By resetting `last_voted_round`, this invariant is violated, enabling double-voting attacks.

## Impact Explanation

**Severity: CRITICAL**

This vulnerability directly violates the **Consensus Safety** invariant: "AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine validators."

Equivocation (double-voting) is the most fundamental consensus safety violation in BFT protocols. When a validator signs two conflicting votes for the same round, it can lead to:

1. **Chain Forks**: Different validators may commit different blocks at the same height
2. **Double-Spending**: Transactions can be committed on one fork and different transactions on another
3. **Loss of BFT Guarantees**: The system can no longer guarantee safety even with < 1/3 Byzantine validators

This meets the **Critical Severity** criteria per the Aptos bug bounty program: "Consensus/Safety violations" warranting up to $1,000,000.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This vulnerability can be triggered through legitimate operational procedures:

1. **Routine Operations**: Validator operators commonly migrate from less secure backends (OnDisk) to more secure ones (Vault) as part of security hardening
2. **Configuration Management**: The `initial_safety_rules_config` parameter is required for production deployments (enforced for mainnet) [5](#0-4) 
3. **No Warning**: The system provides no warning that switching backends will reset safety data
4. **Restart Scenario**: This can occur whenever a validator restarts with a different backend configuration

The vulnerability does not require malicious intent - it's a footgun that honest operators can trigger during routine maintenance.

## Recommendation

**Immediate Fix:** Preserve SafetyData During Backend Migration

The system must preserve and validate SafetyData when initializing a new storage backend. Recommended approach:

1. **Refuse Initialization if Current Epoch Mismatch:**

Modify `safety_rules_manager.rs` to detect if the waypoint indicates a later epoch than the default initialization:

```rust
pub fn storage(config: &SafetyRulesConfig) -> PersistentSafetyStorage {
    let backend = &config.backend;
    let internal_storage: Storage = backend.into();
    
    // ... existing availability check ...
    
    if let Some(test_config) = &config.test {
        // ... test initialization unchanged ...
    } else {
        let storage = PersistentSafetyStorage::new(internal_storage, config.enable_cached_safety_data);
        
        if storage.author().is_ok() {
            storage
        } else if !matches!(config.initial_safety_rules_config, InitialSafetyRulesConfig::None) {
            let waypoint = config.initial_safety_rules_config.waypoint();
            
            // CRITICAL CHECK: Refuse initialization if waypoint indicates we should 
            // be beyond epoch 1
            if waypoint.version() > 0 {
                panic!(
                    "Cannot initialize new storage backend with waypoint from version {}. \
                    This indicates the validator has already participated in consensus. \
                    To prevent safety violations, you must manually migrate SafetyData from \
                    the previous backend or use a genesis waypoint.",
                    waypoint.version()
                );
            }
            
            // ... rest of initialization ...
        } else {
            panic!("Safety rules storage is not initialized...")
        }
    }
}
```

2. **Provide Migration Tool:**

Create a dedicated migration utility that:
- Reads SafetyData from the old backend
- Validates consistency
- Writes to the new backend atomically
- Verifies the migration before allowing validator restart

3. **Add Configuration Validation:**

Add a sanity check in `PersistentSafetyStorage::initialize()`:

```rust
pub fn initialize(..., waypoint: Waypoint, ...) -> Self {
    // Validate that we're initializing at genesis
    if waypoint.version() > 0 {
        panic!("Cannot initialize storage with non-genesis waypoint");
    }
    // ... rest of initialization ...
}
```

## Proof of Concept

**Reproduction Steps:**

1. **Setup Initial State:**
```bash
# Start validator with OnDiskStorage in epoch 10, participate in consensus
# File: validator_config.yaml
consensus:
  safety_rules:
    backend:
      type: on_disk_storage
      path: /data/safety_storage.json
```

2. **Simulate Voting Activity:**
```rust
// The validator votes on blocks in rounds 1-500 of epoch 10
// This updates safety_storage.json with:
// SafetyData { epoch: 10, last_voted_round: 500, ... }
```

3. **Switch Backend:**
```bash
# Operator changes config to Vault
# File: validator_config.yaml
consensus:
  safety_rules:
    backend:
      type: vault
      server: "https://vault.example.com"
      token: { from_config: "hvs.xxxxx" }
    initial_safety_rules_config:
      from_file:
        identity_blob_path: /keys/validator_identity.yaml
        waypoint: { from_config: "0:..." }  # Waypoint from epoch 10
```

4. **Restart Validator:**
```bash
# Validator restarts, storage() function is called
# New Vault backend is empty
# storage.author().is_ok() returns false
# PersistentSafetyStorage::initialize() is called
# SafetyData reset to {epoch: 1, last_voted_round: 0}
```

5. **Consensus Initialization:**
```rust
// guarded_initialize() called with EpochChangeProof for epoch 10
// Compares: current_epoch (1) < proof_epoch (10)
// Resets SafetyData to {epoch: 10, last_voted_round: 0}
```

6. **Equivocation Enabled:**
```rust
// Validator can now vote on round 250 (which it already voted on)
// verify_and_update_last_vote_round(250) checks:
//   250 > 0 (current last_voted_round) ✓ PASSES
// Validator signs vote for round 250
// SAFETY VIOLATION: Validator has now signed TWO votes for round 250
```

## Notes

This vulnerability highlights a critical gap in the SafetyRules storage migration strategy. While backend switching is a legitimate operational requirement (e.g., migrating from OnDisk to Vault for improved security), the current implementation provides no safeguards against losing critical safety state.

The issue is particularly concerning because:
- It can occur during routine operations by honest operators
- There are no warnings or checks in place
- The configuration sanitizer only prevents InMemoryStorage on mainnet, not migration issues [6](#0-5) 
- Once equivocation occurs, the damage is permanent - the validator has signed conflicting messages

The recommended fix prevents unsafe migrations while maintaining operational flexibility through proper migration tooling.

### Citations

**File:** consensus/safety-rules/src/safety_rules_manager.rs (L44-77)
```rust
    } else {
        let storage =
            PersistentSafetyStorage::new(internal_storage, config.enable_cached_safety_data);

        let mut storage = if storage.author().is_ok() {
            storage
        } else if !matches!(
            config.initial_safety_rules_config,
            InitialSafetyRulesConfig::None
        ) {
            let identity_blob = config
                .initial_safety_rules_config
                .identity_blob()
                .expect("No identity blob in initial safety rules config");
            let waypoint = config.initial_safety_rules_config.waypoint();

            let backend = &config.backend;
            let internal_storage: Storage = backend.into();
            PersistentSafetyStorage::initialize(
                internal_storage,
                identity_blob
                    .account_address
                    .expect("AccountAddress needed for safety rules"),
                identity_blob
                    .consensus_private_key
                    .expect("Consensus key needed for safety rules"),
                waypoint,
                config.enable_cached_safety_data,
            )
        } else {
            panic!(
                "Safety rules storage is not initialized, provide an initial safety rules config"
            )
        };
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L33-60)
```rust
    pub fn initialize(
        mut internal_store: Storage,
        author: Author,
        consensus_private_key: bls12381::PrivateKey,
        waypoint: Waypoint,
        enable_cached_safety_data: bool,
    ) -> Self {
        // Initialize the keys and accounts
        Self::initialize_keys_and_accounts(&mut internal_store, author, consensus_private_key)
            .expect("Unable to initialize keys and accounts in storage");

        // Create the new persistent safety storage
        let safety_data = SafetyData::new(1, 0, 0, 0, None, 0);
        let mut persisent_safety_storage = Self {
            enable_cached_safety_data,
            cached_safety_data: Some(safety_data.clone()),
            internal_store,
        };

        // Initialize the safety data and waypoint
        persisent_safety_storage
            .set_safety_data(safety_data)
            .expect("Unable to initialize safety data");
        persisent_safety_storage
            .set_waypoint(&waypoint)
            .expect("Unable to initialize waypoint");

        persisent_safety_storage
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```

**File:** consensus/safety-rules/src/safety_rules.rs (L283-310)
```rust
        let current_epoch = self.persistent_storage.safety_data()?.epoch;
        match current_epoch.cmp(&epoch_state.epoch) {
            Ordering::Greater => {
                // waypoint is not up to the current epoch.
                return Err(Error::WaypointOutOfDate(
                    waypoint.version(),
                    new_waypoint.version(),
                    current_epoch,
                    epoch_state.epoch,
                ));
            },
            Ordering::Less => {
                // start new epoch
                self.persistent_storage.set_safety_data(SafetyData::new(
                    epoch_state.epoch,
                    0,
                    0,
                    0,
                    None,
                    0,
                ))?;

                info!(SafetyLogSchema::new(LogEntry::Epoch, LogEvent::Update)
                    .epoch(epoch_state.epoch));
            },
            Ordering::Equal => (),
        };
        self.epoch_state = Some(epoch_state.clone());
```

**File:** config/src/config/safety_rules_config.rs (L71-116)
```rust
impl ConfigSanitizer for SafetyRulesConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let safety_rules_config = &node_config.consensus.safety_rules;

        // If the node is not a validator, there's nothing to be done
        if !node_type.is_validator() {
            return Ok(());
        }

        if let Some(chain_id) = chain_id {
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }

            // Verify that the safety rules service is set to local for optimal performance
            if chain_id.is_mainnet() && !safety_rules_config.service.is_local() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    format!("The safety rules service should be set to local in mainnet for optimal performance! Given config: {:?}", &safety_rules_config.service)
                ));
            }

            // Verify that the safety rules test config is not enabled in mainnet
            if chain_id.is_mainnet() && safety_rules_config.test.is_some() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The safety rules test config should not be used in mainnet!".to_string(),
                ));
            }
        }

        Ok(())
    }
```
