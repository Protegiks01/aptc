# Audit Report

## Title
Race Condition in Parallel Ledger Pruner Allows Transaction Info to Reference Deleted Accumulator Nodes

## Summary
The LedgerPruner executes TransactionAccumulatorPruner and TransactionInfoPruner in parallel without ordering guarantees, creating a window where transaction info records exist but their corresponding accumulator nodes have been deleted. This violates the database consistency invariant and can cause backup operations and API calls to fail with "position does not exist" errors.

## Finding Description

The LedgerPruner orchestrates multiple sub-pruners that delete different types of ledger data. The pruning sequence is: [1](#0-0) 

The LedgerMetadataPruner runs sequentially first, but then all remaining sub-pruners execute **in parallel** using `par_iter()`. This includes both TransactionAccumulatorPruner and TransactionInfoPruner, which are instantiated in this order: [2](#0-1) 

However, vector ordering does not guarantee execution order in parallel iteration. The critical dependency is that **transaction proofs require both components**: [3](#0-2) 

When building a proof, the system must read accumulator node positions from storage: [4](#0-3) 

If the position doesn't exist (because TransactionAccumulatorPruner already deleted it), this returns an error. Meanwhile, TransactionInfoPruner may not have completed yet, leaving the transaction info record in the database.

**Attack Vector:**

The BackupHandler exposes `get_state_root_proof()` as an HTTP endpoint without pruning protection: [5](#0-4) 

Unlike the main read path which checks `error_if_ledger_pruned()`: [6](#0-5) 

The backup handler calls `get_transaction_info_with_proof()` directly without validation: [7](#0-6) 

**Race Condition Timeline:**

1. Pruning initiated for versions [X, Y)
2. Both TransactionAccumulatorPruner and TransactionInfoPruner start in parallel
3. TransactionAccumulatorPruner completes first, deletes accumulator nodes for version V
4. Backup service calls `/state_root_proof/V` 
5. System finds TransactionInfo for V (still exists)
6. System attempts to build proof, reads accumulator via `HashReader::get(position)`
7. Error: "position does not exist" - accumulator nodes already deleted
8. Later: TransactionInfoPruner completes, deletes TransactionInfo for V

## Impact Explanation

This issue constitutes a **High severity** finding per Aptos bug bounty criteria:

1. **State Consistency Violation** - Critical Invariant #4 states "State transitions must be atomic and verifiable via Merkle proofs." This race condition creates a window where transaction info exists but cannot be verified via proofs, violating atomicity of the pruning operation.

2. **API Crashes** - Backup service HTTP requests fail with database errors during pruning windows, matching the High severity criterion "API crashes."

3. **Significant Protocol Violation** - The database maintains an implicit invariant: "If a TransactionInfo exists, a proof for it must be generateable." This race condition breaks that invariant in a non-deterministic manner.

The impact is NOT Critical because:
- No funds are at risk
- No consensus violations occur (pruning happens post-consensus)
- The inconsistency is temporary (resolves when TransactionInfoPruner completes)
- No permanent data corruption occurs

However, the operational impact is significant: backup operations fail unpredictably during pruning windows, requiring retries and potentially causing cascading failures in backup infrastructure.

## Likelihood Explanation

**Likelihood: Medium-High**

This race condition will occur whenever:
1. Ledger pruning is active (common in production nodes)
2. Backup operations are running concurrently (common for archival nodes)
3. Thread scheduling causes TransactionAccumulatorPruner to complete before TransactionInfoPruner (non-deterministic but probable given Rayon's work-stealing scheduler)

The timing window is narrow (milliseconds to seconds depending on batch size) but the frequency is high - every pruning cycle creates the opportunity. With default pruning configurations running periodically, this represents a recurring operational risk.

The likelihood increases with:
- Larger pruning batch sizes (longer parallel execution window)
- Higher system load (more thread scheduling variability)
- More frequent backup operations

## Recommendation

**Fix 1: Enforce Pruning Order (Preferred)**

Separate accumulator-dependent pruners from independent ones. Execute TransactionInfoPruner before TransactionAccumulatorPruner to ensure dependent data is deleted first:

```rust
// In ledger_pruner/mod.rs, prune() method
self.ledger_metadata_pruner
    .prune(progress, current_batch_target_version)?;

// First prune data structures that depend on accumulator
let accumulator_dependent_pruners = vec![
    &transaction_info_pruner,
    // other pruners that need accumulator for proofs
];

THREAD_MANAGER.get_background_pool().install(|| {
    accumulator_dependent_pruners.par_iter().try_for_each(|sub_pruner| {
        sub_pruner.prune(progress, current_batch_target_version)
            .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
    })
})?;

// Then prune the accumulator itself
transaction_accumulator_pruner.prune(progress, current_batch_target_version)?;

// Finally prune independent data structures in parallel
THREAD_MANAGER.get_background_pool().install(|| {
    other_sub_pruners.par_iter().try_for_each(...)
})?;
```

**Fix 2: Add Pruning Protection to BackupHandler**

Add `error_if_ledger_pruned` checks to backup endpoints:

```rust
// In backup_handler.rs
pub fn get_state_root_proof(
    &self,
    version: Version,
) -> Result<(TransactionInfoWithProof, LedgerInfoWithSignatures)> {
    // Add pruning protection
    self.error_if_ledger_pruned("StateRootProof", version)?;
    
    let ledger_metadata_db = self.ledger_db.metadata_db();
    // ... rest of implementation
}
```

## Proof of Concept

Due to the non-deterministic nature of thread scheduling, a deterministic PoC is challenging. However, the issue can be demonstrated with stress testing:

```rust
#[test]
fn test_parallel_pruner_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let tmp_dir = TempPath::new();
    let aptos_db = AptosDB::new_for_test(&tmp_dir);
    
    // Setup: Create 1000 transactions with infos
    let num_txns = 1000;
    // ... populate database ...
    
    // Enable aggressive pruning
    let pruner = LedgerPrunerManager::new(
        Arc::clone(&aptos_db.ledger_db),
        LedgerPrunerConfig {
            enable: true,
            prune_window: 0,
            batch_size: 100,
            user_pruning_window_offset: 0,
        },
    );
    
    // Start pruning in background
    let pruner_clone = Arc::new(pruner);
    let barrier = Arc::new(Barrier::new(2));
    
    let barrier_clone = barrier.clone();
    let db_clone = aptos_db.clone();
    let pruner_handle = thread::spawn(move || {
        barrier_clone.wait();
        pruner_clone.wake_and_wait_pruner(500).unwrap();
    });
    
    // Concurrently attempt to get transaction proofs
    let backup_handle = thread::spawn(move || {
        barrier.wait();
        thread::sleep(Duration::from_millis(10)); // Small delay to hit pruning window
        
        for v in 0..100 {
            match db_clone.ledger_db.transaction_info_db()
                .get_transaction_info_with_proof(
                    v,
                    500,
                    db_clone.ledger_db.transaction_accumulator_db()
                ) {
                Ok(_) => {},
                Err(e) => {
                    // Race condition hit if error contains "does not exist"
                    if e.to_string().contains("does not exist") {
                        println!("Race condition detected at version {}: {}", v, e);
                        return true;
                    }
                }
            }
        }
        false
    });
    
    pruner_handle.join().unwrap();
    let race_detected = backup_handle.join().unwrap();
    
    assert!(race_detected, "Race condition should be detectable under stress");
}
```

## Notes

The existing test suite verifies post-pruning correctness but does not test concurrent access during the pruning window itself: [8](#0-7) 

The test calls `wake_and_wait_pruner()` which **waits** for completion, missing the intermediate race condition window. This indicates the issue was not previously considered during test design.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L75-84)
```rust
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L147-160)
```rust
        let transaction_accumulator_pruner = Box::new(TransactionAccumulatorPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_auxiliary_data_pruner = Box::new(TransactionAuxiliaryDataPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_info_pruner = Box::new(TransactionInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
```

**File:** storage/aptosdb/src/ledger_db/transaction_info_db.rs (L73-83)
```rust
    pub(crate) fn get_transaction_info_with_proof(
        &self,
        version: Version,
        ledger_version: Version,
        transaction_accumulator_db: &TransactionAccumulatorDb,
    ) -> Result<TransactionInfoWithProof> {
        Ok(TransactionInfoWithProof::new(
            transaction_accumulator_db.get_transaction_proof(version, ledger_version)?,
            self.get_transaction_info(version)?,
        ))
    }
```

**File:** storage/aptosdb/src/ledger_db/transaction_accumulator_db.rs (L195-201)
```rust
impl HashReader for TransactionAccumulatorDb {
    fn get(&self, position: Position) -> Result<HashValue, anyhow::Error> {
        self.db
            .get::<TransactionAccumulatorSchema>(&position)?
            .ok_or_else(|| anyhow!("{} does not exist.", position))
    }
}
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L81-88)
```rust
    // GET state_root_proof/<version>
    let bh = backup_handler.clone();
    let state_root_proof = warp::path!(Version)
        .map(move |version| {
            reply_with_bcs_bytes(STATE_ROOT_PROOF, &bh.get_state_root_proof(version)?)
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L1068-1083)
```rust
    pub(super) fn get_transaction_with_proof(
        &self,
        version: Version,
        ledger_version: Version,
        fetch_events: bool,
    ) -> Result<TransactionWithProof> {
        self.error_if_ledger_pruned("Transaction", version)?;

        let proof = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_with_proof(
                version,
                ledger_version,
                self.ledger_db.transaction_accumulator_db(),
            )?;
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L186-205)
```rust
    /// Gets the proof of the state root at specified version.
    /// N.B. the `LedgerInfo` returned will always be in the same epoch of the version.
    pub fn get_state_root_proof(
        &self,
        version: Version,
    ) -> Result<(TransactionInfoWithProof, LedgerInfoWithSignatures)> {
        let ledger_metadata_db = self.ledger_db.metadata_db();
        let epoch = ledger_metadata_db.get_epoch(version)?;
        let ledger_info = ledger_metadata_db.get_latest_ledger_info_in_epoch(epoch)?;
        let txn_info = self
            .ledger_db
            .transaction_info_db()
            .get_transaction_info_with_proof(
                version,
                ledger_info.ledger_info().version(),
                self.ledger_db.transaction_accumulator_db(),
            )?;

        Ok((txn_info, ledger_info))
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/test.rs (L143-146)
```rust
                assert!(ledger_store
                    .get_transaction_proof(j as u64, ledger_version)
                    .is_err());
            }
```
