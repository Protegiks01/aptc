# Audit Report

## Title
Non-Deterministic Cache Flush Causes Consensus Failure Through Divergent Type Identity

## Summary
The interner flush mechanism in the Move VM can cause validators to disagree on transaction execution results due to non-deterministic cache size thresholds, leading to consensus failure. When validators flush their interned module ID and struct name caches at different blocks, the same struct types receive different internal indices, causing type equality comparisons to fail and producing divergent state roots for identical transactions.

## Finding Description

The vulnerability occurs in the cache management system where flush decisions are based on non-deterministic local state rather than consensus-driven conditions.

**Root Cause Chain:**

1. **Non-Deterministic Flush Decision**: The `check_ready()` function flushes caches when size thresholds are exceeded based on local cache state. [1](#0-0) 

2. **Cache State Divergence**: Different validators accumulate different numbers of interned entries over time due to transaction ordering variations, network delays, restarts, or other non-deterministic factors. The `RuntimeEnvironment` with shared `InternedModuleIdPool` persists across blocks. [2](#0-1) 

3. **Index Invalidation on Flush**: When flush is called, all mappings in the interner are cleared, and subsequent interning starts from index 0. [3](#0-2) 

4. **InternedModuleId Used in Identity**: `InternedModuleId` derives `Hash`, `Eq`, and `Ord`, making it participate in equality and ordering comparisons. [4](#0-3) 

5. **StructIdentifier Includes InternedModuleId**: The `StructIdentifier` type contains `interned_module_id` as a field and derives comparison traits, meaning two `StructIdentifier` instances with the same module and name but different interned IDs are considered UNEQUAL. [5](#0-4) 

6. **StructIdentifier as BTreeMap Key**: `StructIdentifier` is used as a key in a `BTreeMap` within the `StructNameIndexMap`, causing different interned module IDs to be treated as different keys. [6](#0-5) 

7. **Type Contains StructNameIndex**: The `Type` enum, which derives equality and hashing traits, contains `StructNameIndex` values that were created from the divergent `StructIdentifier` keys. [7](#0-6) 

**Attack Scenario:**

```
Initial State:
- Validator A has accumulated 95 interned module IDs over previous blocks
- Validator B has accumulated 105 interned module IDs (different history)
- Configuration: max_interned_module_ids = 100

Block N Execution:
Before execution, check_ready() is called:
- Validator A: 95 < 100 → NO FLUSH, keeps existing indices
- Validator B: 105 > 100 → FLUSH, clears all indices

During execution of identical transactions:
- Both intern ModuleId "0x1::coin"
  - Validator A: InternedModuleId(95) [continuing]
  - Validator B: InternedModuleId(0) [fresh after flush]

- Both create StructIdentifier for "Coin"
  - Validator A: StructIdentifier { module: 0x1::coin, interned_module_id: (95), name: "Coin" }
  - Validator B: StructIdentifier { module: 0x1::coin, interned_module_id: (0), name: "Coin" }

- Both map StructIdentifier to StructNameIndex via BTreeMap lookup
  - StructIdentifier(95) != StructIdentifier(0) [different keys!]
  - Validator A assigns StructNameIndex(X)
  - Validator B assigns StructNameIndex(Y), where X ≠ Y

- Both create Type::Struct for Coin
  - Validator A: Type::Struct { idx: X, ... }
  - Validator B: Type::Struct { idx: Y, ... }

- Type comparisons during execution (type checking, generic instantiation, etc.)
  - Type_A != Type_B (because X ≠ Y)
  - Different execution paths taken
  - Different state roots produced
  - CONSENSUS FAILURE
```

This breaks the **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks."

## Impact Explanation

**Critical Severity** - This vulnerability causes a consensus safety violation meeting the highest severity criteria:

1. **Consensus/Safety Violation**: Validators executing identical transactions produce different state roots, violating Byzantine Fault Tolerance assumptions. This can cause:
   - Chain splits requiring manual intervention
   - Inability to form quorums for subsequent blocks
   - Network partition requiring hardfork to resolve

2. **Non-Recoverable Without Hardfork**: Once validators diverge on state roots, they cannot reconcile without coordinated manual intervention, potentially requiring a hardfork to resynchronize.

3. **Affects All Transactions**: Any transaction that involves struct types (which is virtually all Move transactions) can trigger divergent execution once cache states have diverged.

The vulnerability satisfies multiple Critical Severity criteria from the Aptos bug bounty: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)."

## Likelihood Explanation

**HIGH Likelihood**:

1. **Natural Occurrence**: Cache divergence happens naturally over time without any attacker action. Different validators will have different transaction histories due to:
   - Network propagation delays
   - Node restarts at different times
   - Different transaction orderings in blocks
   - Varying load patterns

2. **Threshold Trigger**: The default configuration uses fixed thresholds (e.g., `max_interned_module_ids`). As the network operates, validators will naturally reach these thresholds at different blocks.

3. **No Attacker Control Required**: This is a passive vulnerability that manifests from normal network operation. No malicious transaction crafting or validator collusion is needed.

4. **Continuous Risk**: Once any two validators have divergent cache states, every subsequent block has a risk of causing consensus failure if struct types are involved (which they always are in Move).

## Recommendation

**Immediate Fix**: Make flush decisions deterministic across all validators by tying them to consensus-observable state rather than local cache size.

**Option 1 - Flush at Block Boundaries (Preferred):**
```rust
// In check_ready()
// Replace threshold-based flushing with epoch/block-based deterministic flushing

// Option A: Flush at epoch boundaries
if transaction_slice_metadata.block_id() % BLOCKS_PER_EPOCH == 0 {
    runtime_environment.flush_all_caches();
    self.module_cache.flush();
}

// Option B: Never flush mid-execution, only between blocks
// Ensure all validators flush at the same block number based on on-chain state
let on_chain_flush_height = state_view.get_flush_height(); // deterministic
if transaction_slice_metadata.block_id() == on_chain_flush_height {
    runtime_environment.flush_all_caches();
    self.module_cache.flush();
}
```

**Option 2 - Remove InternedModuleId from Identity:**
Modify `StructIdentifier` to not include `interned_module_id` in equality/ordering comparisons:
```rust
// Use manual trait implementations instead of derive
impl PartialEq for StructIdentifier {
    fn eq(&self, other: &Self) -> bool {
        self.module == other.module && self.name == other.name
        // Exclude interned_module_id from comparison
    }
}

impl Ord for StructIdentifier {
    fn cmp(&self, other: &Self) -> Ordering {
        (&self.module, &self.name).cmp(&(&other.module, &other.name))
        // Exclude interned_module_id from ordering
    }
}
```

**Option 3 - Synchronize Flush State:**
Include flush generation counters in block metadata that all validators must agree on, ensuring synchronized flush operations.

**Recommended Approach**: Option 1 (deterministic block-based flushing) is the safest and maintains the optimization benefits while ensuring consensus.

## Proof of Concept

```rust
// Reproduction steps (pseudo-Rust test):

#[test]
fn test_consensus_divergence_on_flush() {
    // Setup two validators with different cache states
    let validator_a = setup_validator_with_cache_size(95); // below threshold
    let validator_b = setup_validator_with_cache_size(105); // above threshold
    
    let config = BlockExecutorModuleCacheLocalConfig {
        max_interned_module_ids: 100,
        ..Default::default()
    };
    
    // Create identical block with transaction using struct type
    let block = create_block_with_struct_transaction("0x1::coin::Coin");
    
    // Execute on both validators
    let state_a = validator_a.execute_block(&block, &config);
    let state_b = validator_b.execute_block(&block, &config);
    
    // Validators produce different state roots for identical transactions
    assert_ne!(state_a.state_root(), state_b.state_root());
    // ^ This assertion passes, demonstrating consensus failure
}

// Detailed reproduction:
// 1. Start two validator nodes with RuntimeEnvironment instances
// 2. On validator A, intern 95 module IDs through prior block execution
// 3. On validator B, intern 105 module IDs through different transaction history
// 4. Present both validators with identical block containing coin transfer
// 5. Before execution, check_ready() triggers:
//    - Validator A: no flush (95 < 100)
//    - Validator B: flush (105 > 100)
// 6. During execution, both intern ModuleId "0x1::coin":
//    - Validator A: InternedModuleId(95)
//    - Validator B: InternedModuleId(0)
// 7. Type comparisons produce different results
// 8. State roots diverge → consensus failure
```

**Notes:**
- The vulnerability is subtle because it requires understanding the complete chain from cache thresholds through interner indices to type identity
- The flush warning in the code acknowledges danger but doesn't prevent non-deterministic flushing [8](#0-7) 
- The real-world trigger is natural cache divergence over time, not attacker-crafted inputs

### Citations

**File:** aptos-move/block-executor/src/code_cache_global_manager.rs (L162-166)
```rust
        if num_interned_module_ids > config.max_interned_module_ids {
            runtime_environment.module_id_pool().flush();
            runtime_environment.struct_name_index_map().flush();
            self.module_cache.flush();
        }
```

**File:** third_party/move/move-vm/runtime/src/storage/environment.rs (L69-74)
```rust
    /// Pool of interned type representations. Same lifetime as struct index map.
    interned_ty_pool: Arc<InternedTypePool>,

    /// Pool of interned module ids.
    interned_module_id_pool: Arc<InternedModuleIdPool>,
}
```

**File:** third_party/move/move-vm/types/src/interner.rs (L66-71)
```rust
    fn flush(&mut self) {
        self.map.clear();
        self.vec.clear();
        self.buffer.clear();
        self.pool.clear();
    }
```

**File:** third_party/move/move-vm/types/src/interner.rs (L192-199)
```rust
    /// Flushes the interner, clearing all interned values.
    ///
    /// This is a DANGEROUS operation as it invalidates all current references to the interned
    /// values, conceptually.
    ///
    /// The caller needs to make sure there are no more active references when calling `flush`.
    /// As we currently return indices as opposed to actual references, this means to not compare
    /// indices across flushes.
```

**File:** third_party/move/move-vm/types/src/module_id_interner.rs (L7-8)
```rust
#[derive(Debug, PartialEq, Eq, PartialOrd, Ord, Hash, Clone, Copy)]
pub struct InternedModuleId(usize);
```

**File:** third_party/move/move-vm/types/src/loaded_data/runtime_types.rs (L262-267)
```rust
#[derive(Debug, Clone, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct StructIdentifier {
    module: ModuleId,
    interned_module_id: InternedModuleId,
    name: Identifier,
}
```

**File:** third_party/move/move-vm/types/src/loaded_data/runtime_types.rs (L296-313)
```rust
#[derive(Debug, Clone, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub enum Type {
    Bool,
    U8,
    U64,
    U128,
    Address,
    Signer,
    Vector(TriompheArc<Type>),
    Struct {
        idx: StructNameIndex,
        ability: AbilityInfo,
    },
    StructInstantiation {
        idx: StructNameIndex,
        ty_args: TriompheArc<Vec<Type>>,
        ability: AbilityInfo,
    },
```

**File:** third_party/move/move-vm/types/src/loaded_data/struct_name_indexing.rs (L41-49)
```rust
struct IndexMap<T: Clone + Ord> {
    forward_map: BTreeMap<T, u32>,
    backward_map: Vec<Arc<T>>,
}

/// A data structure to cache struct identifiers (address, module name, struct name) and use
/// indices instead, to save on the memory consumption and avoid unnecessary cloning. It
/// guarantees that the same struct name identifier always corresponds to a unique index.
pub struct StructNameIndexMap(RwLock<IndexMap<StructIdentifier>>);
```
