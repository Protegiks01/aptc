# Audit Report

## Title
EventPrunerProgress Divergence Leading to Permanent Dangling Index Corruption

## Summary
The EventStorePruner maintains separate progress metadata in main and indexer databases. Database truncation operations systematically skip cleaning up indexer indices, creating dangling pointers that cause permanent API query failures when db_sharding is enabled.

## Finding Description

The system violates state consistency through a critical flaw in the database truncation path:

**Core Issue: Truncation Ignores Indexer Indices**

The `delete_event_data` function explicitly skips cleaning up indexer DB indices during truncation: [1](#0-0) 

The code passes `None` for `indices_batch` with a TODO comment acknowledging the missing cleanup. This function is called during database synchronization at startup when `sync_commit_progress` detects inconsistencies: [2](#0-1) [3](#0-2) 

When `prune_event_indices` receives `None` for `indices_batch`, it skips the index deletion loop: [4](#0-3) 

**Non-Atomic Progress Updates**

EventStorePruner writes progress to two databases sequentially: [5](#0-4) 

If a crash occurs between line 78 and 80, the indexer DB has newer progress than main DB.

**One-Directional Conflict Resolution**

On restart, EventStorePruner only reads progress from the main database: [6](#0-5) 

The catch-up prune at line 106 only moves forward, never cleaning up stale indexer indices.

**Exploitation via Query Failures**

When `db_sharding_enabled` is true, queries route to the indexer: [7](#0-6) 

The indexer retrieves indices from indexer DB, then fetches events from main DB: [8](#0-7) 

If dangling indices exist, `get_event_by_version_and_index` fails with NotFound: [9](#0-8) 

## Impact Explanation

**Medium Severity** - This meets the "Limited Protocol Violations" category:

1. **State Inconsistencies**: EventPrunerProgress metadata diverges between databases, requiring manual intervention to resolve
2. **Data Availability Loss**: Event queries fail with "Event X of Txn Y not found" errors for affected ranges when using db_sharding
3. **Persistent Corruption**: The divergence is permanent because the pruner never retroactively cleans up stale indices

The impact is limited to nodes with `enable_storage_sharding=true` (default configuration) and only affects event query APIs, not consensus or fund safety.

## Likelihood Explanation

**Medium Likelihood** - This occurs when:

1. Database synchronization detects inconsistencies (uncommitted data after crash)
2. `sync_commit_progress` truncates ledger DB back to overall commit progress
3. Events are deleted from main DB but indices remain in indexer DB
4. Subsequent queries encounter the dangling indices

The truncation path is guaranteed to skip indexer cleanup (evidenced by TODO comment), but requires specific preconditions (database inconsistency requiring truncation).

## Recommendation

Modify `delete_event_data` to accept and use an indexer DB reference for cleaning up indices:

```rust
fn delete_event_data(
    ledger_db: &LedgerDb,
    start_version: Version,
    batch: &mut SchemaBatch,
    indexer_db: Option<&InternalIndexerDB>, // Add parameter
) -> Result<()> {
    if let Some(latest_version) = ledger_db.event_db().latest_version()? {
        if latest_version >= start_version {
            let mut indexer_batch = indexer_db.map(|_| SchemaBatch::new());
            let indices_batch = indexer_batch.as_mut();
            
            let num_events_per_version = ledger_db.event_db().prune_event_indices(
                start_version,
                latest_version + 1,
                indices_batch, // Pass actual batch
            )?;
            
            if let Some(ib) = indexer_batch {
                indexer_db.unwrap().get_inner_db_ref().write_schemas(ib)?;
            }
            
            ledger_db.event_db().prune_events(
                num_events_per_version,
                start_version,
                latest_version + 1,
                batch,
            )?;
        }
    }
    Ok(())
}
```

## Proof of Concept

A complete PoC would require:
1. Setting up node with `enable_storage_sharding=true`
2. Triggering database inconsistency (e.g., forced shutdown during commit)
3. Restarting node to invoke `sync_commit_progress`
4. Querying events in the truncated range
5. Observing NotFound errors

The TODO comment at line 537 and the explicit `None` parameter at line 538 provide direct evidence this cleanup path is incomplete.

## Notes

This is a storage layer consistency bug affecting data availability when database sharding is enabled. While the report claimed "High Severity - API Crashes", the actual impact is more accurately "Medium Severity - Limited Protocol Violations" as it causes query failures rather than process crashes, and only affects event availability without compromising consensus or fund safety. The vulnerability is valid and documented by the development team (TODO comment), requiring proper remediation.

### Citations

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L535-538)
```rust
                // Assuming same data will be overwritten into indices, we don't bother to deal
                // with the existence or placement of indices
                // TODO: prune data from internal indices
                None,
```

**File:** storage/aptosdb/src/state_store/mod.rs (L354-359)
```rust
            Self::sync_commit_progress(
                Arc::clone(&ledger_db),
                Arc::clone(&state_kv_db),
                Arc::clone(&state_merkle_db),
                /*crash_if_difference_is_too_large=*/ true,
            );
```

**File:** storage/aptosdb/src/state_store/mod.rs (L448-449)
```rust
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L206-217)
```rust
            if let Some(ref mut batch) = indices_batch {
                for event in events {
                    if let ContractEvent::V1(v1) = event {
                        batch.delete::<EventByKeySchema>(&(*v1.key(), v1.sequence_number()))?;
                        batch.delete::<EventByVersionSchema>(&(
                            *v1.key(),
                            current_version,
                            v1.sequence_number(),
                        ))?;
                    }
                }
            }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L71-80)
```rust
        if let Some(mut indexer_batch) = indexer_batch {
            indexer_batch.put::<InternalIndexerMetadataSchema>(
                &IndexerMetadataKey::EventPrunerProgress,
                &IndexerMetadataValue::Version(target_version),
            )?;
            self.expect_indexer_db()
                .get_inner_db_ref()
                .write_schemas(indexer_batch)?;
        }
        self.ledger_db.event_db().write_schemas(batch)
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L90-106)
```rust
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;
```

**File:** api/src/context.rs (L1096-1104)
```rust
        let mut res = if !db_sharding_enabled(&self.node_config) {
            self.db
                .get_events(event_key, start, order, limit as u64, ledger_version)?
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| anyhow!("Internal indexer reader doesn't exist"))?
                .get_events(event_key, start, order, limit as u64, ledger_version)?
        };
```

**File:** storage/indexer/src/db_indexer.rs (L671-697)
```rust
        let mut event_indices = self.indexer_db.lookup_events_by_key(
            event_key,
            first_seq,
            real_limit,
            ledger_version,
        )?;

        // When descending, it's possible that user is asking for something beyond the latest
        // sequence number, in which case we will consider it a bad request and return an empty
        // list.
        // For example, if the latest sequence number is 100, and the caller is asking for 110 to
        // 90, we will get 90 to 100 from the index lookup above. Seeing that the last item
        // is 100 instead of 110 tells us 110 is out of bound.
        if order == Order::Descending {
            if let Some((seq_num, _, _)) = event_indices.last() {
                if *seq_num < cursor {
                    event_indices = Vec::new();
                }
            }
        }

        let mut events_with_version = event_indices
            .into_iter()
            .map(|(seq, ver, idx)| {
                let event = match self
                    .main_db_reader
                    .get_event_by_version_and_index(ver, idx)?
```

**File:** storage/aptosdb/src/event_store/mod.rs (L42-50)
```rust
    pub fn get_event_by_version_and_index(
        &self,
        version: Version,
        index: u64,
    ) -> Result<ContractEvent> {
        self.event_db
            .get::<EventSchema>(&(version, index))?
            .ok_or_else(|| AptosDbError::NotFound(format!("Event {} of Txn {}", index, version)))
    }
```
