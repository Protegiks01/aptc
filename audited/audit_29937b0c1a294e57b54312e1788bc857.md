# Audit Report

## Title
Inadequate Default RAM Requirement Creates Memory Exhaustion Risk for Minimally-Compliant Validators

## Summary
The default 31 GB RAM minimum requirement specified in the hardware checker is insufficient to accommodate the default storage configurations, creating a critical gap where minimally-compliant validators are vulnerable to memory exhaustion under normal operational load, potentially leading to consensus liveness failures.

## Finding Description

The hardware checker enforces a minimum RAM requirement of 31 GB: [1](#0-0) 

However, the default storage configuration allocates 24 GB solely for the RocksDB block cache: [2](#0-1) 

Additional mandatory memory consumers include:
- JMT node cache: ~2 GB (as documented): [3](#0-2) 

- Module cache: 1 GB default: [4](#0-3) 

This totals **~27 GB** for caches alone, leaving only **4 GB** for:
- OS kernel and system processes
- Parallel transaction execution (with concurrency up to num_cpus)
- RocksDB write buffers
- Network buffers and consensus state
- Application runtime overhead

The per-transaction memory quota is 10 million abstract value size units: [5](#0-4) 

With parallel execution potentially running on 30+ threads (based on CPU cores), and each transaction capable of consuming significant memory through write operations (up to 10 MB per transaction for writes and events): [6](#0-5) 

Under adversarial conditions where multiple memory-intensive transactions execute concurrently, validators operating at exactly 31 GB RAM will experience memory pressure and potential OOM crashes.

**Critical Configuration Gap:** The node checker validates hardware meets the 31 GB minimum but performs no validation that configured cache sizes are compatible with available memory. The default configuration assumes significantly more RAM is available: [7](#0-6) 

## Impact Explanation

This issue qualifies as **Medium Severity** under the Aptos bug bounty program because it can cause:

1. **Validator Liveness Failures**: Nodes operating at the stated minimum (31 GB) will crash under load, requiring restarts and causing temporary unavailability
2. **Consensus Degradation**: If multiple minimally-compliant validators crash simultaneously due to OOM, consensus performance degrades
3. **State Inconsistencies Requiring Intervention**: OOM crashes during block execution can leave validators in inconsistent states requiring manual recovery

While production deployments use 60 GiB RAM (as shown in the Kubernetes configurations): [8](#0-7) 

The discrepancy between the stated minimum (31 GB) and actual requirements creates a false sense of security for operators attempting to run cost-optimized validators.

## Likelihood Explanation

**Likelihood: Medium-High** for operators following minimum requirements:

1. **Operators Trust Minimum Requirements**: Validator operators rely on documented minimums for hardware provisioning
2. **Default Configurations Are Used**: Most operators use default configurations without deep understanding of memory allocation
3. **No Runtime Validation**: The system does not detect or warn about insufficient memory for configured cache sizes
4. **Natural Load Triggers Issue**: No adversarial behavior required - normal high-load periods will trigger OOM

The attack vector is straightforward: submit many concurrent transactions that maximize memory usage through large write sets and complex state operations. With 30+ parallel executions possible, each consuming memory for:
- Transaction execution state
- Write buffers (up to 10 MB)
- Event buffers (up to 10 MB)
- VM stack and local variables

The remaining 4 GB becomes insufficient under load.

## Recommendation

**Immediate Fix:** Increase the minimum RAM requirement to realistically accommodate default configurations:

```rust
fn default_min_ram_gb() -> u64 {
    64  // Changed from 31 to account for default cache sizes + operational overhead
}
```

**Comprehensive Solution:**

1. **Add Configuration Validation**: Implement a check that validates total configured cache sizes against available RAM:

```rust
pub fn validate_memory_config(
    available_ram_gb: u64,
    config: &StorageConfig,
    module_cache_size_bytes: usize,
) -> Result<(), String> {
    let block_cache_gb = config.rocksdb_configs.shared_block_cache_size / (1 << 30);
    let jmt_cache_gb = 2; // Approximate based on DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD
    let module_cache_gb = module_cache_size_bytes / (1 << 30);
    let required_minimum = block_cache_gb + jmt_cache_gb + module_cache_gb + 10; // 10 GB operational overhead
    
    if available_ram_gb < required_minimum {
        return Err(format!(
            "Insufficient RAM: {} GB available, but {} GB required for current configuration",
            available_ram_gb, required_minimum
        ));
    }
    Ok(())
}
```

2. **Auto-Scale Cache Sizes**: Implement dynamic cache sizing based on detected RAM
3. **Update Documentation**: Clearly document the relationship between cache configurations and RAM requirements, specifying 64 GB as the recommended minimum for default configurations

## Proof of Concept

**Test Setup:**
1. Configure a validator with exactly 31 GB RAM
2. Use default storage configurations (24 GB block cache)
3. Generate high-concurrency workload with memory-intensive transactions

**Expected Result:** Memory exhaustion and node crash under load

**Rust Test Outline:**
```rust
#[test]
fn test_memory_exhaustion_with_minimal_ram() {
    // This test demonstrates the incompatibility between minimum RAM
    // requirement and default cache configurations
    
    const MIN_RAM_GB: u64 = 31;
    const DEFAULT_BLOCK_CACHE_GB: u64 = 24;
    const JMT_CACHE_GB: u64 = 2;
    const MODULE_CACHE_GB: u64 = 1;
    const OS_OVERHEAD_GB: u64 = 2;
    
    let total_cache_requirement = DEFAULT_BLOCK_CACHE_GB + JMT_CACHE_GB + MODULE_CACHE_GB;
    let available_for_operations = MIN_RAM_GB.saturating_sub(total_cache_requirement + OS_OVERHEAD_GB);
    
    // With only 2 GB remaining for parallel execution, buffers, and runtime,
    // the system will experience memory pressure under load
    assert!(
        available_for_operations < 5,
        "Insufficient memory for operational needs: only {} GB available after caches",
        available_for_operations
    );
    
    // Simulate concurrent transactions
    let concurrency_level = 30;  // Typical for 30-core systems
    let max_memory_per_txn_mb = 20; // Write buffer + event buffer
    let concurrent_memory_mb = concurrency_level * max_memory_per_txn_mb;
    let concurrent_memory_gb = concurrent_memory_mb / 1024;
    
    // This will exceed available operational memory
    assert!(
        concurrent_memory_gb > available_for_operations,
        "Concurrent transaction memory ({} GB) exceeds available ({} GB)",
        concurrent_memory_gb, available_for_operations
    );
}
```

**Notes:**
- The vulnerability is configuration-based rather than code logic
- Production deployments are unaffected as they use 60+ GiB
- Impact is limited to operators who strictly follow the stated 31 GB minimum
- Fix requires updating documentation and minimum requirements to reflect actual operational needs

### Citations

**File:** ecosystem/node-checker/src/checker/hardware.rs (L44-46)
```rust
    fn default_min_ram_gb() -> u64 {
        31
    }
```

**File:** config/src/config/storage_config.rs (L24-25)
```rust
// Lru cache will consume about 2G RAM based on this default value.
pub const DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD: usize = 1 << 13;
```

**File:** config/src/config/storage_config.rs (L206-237)
```rust
    /// The size of the single block cache shared by all the DB instances in `AptosDB`.
    pub shared_block_cache_size: usize,
}

impl RocksdbConfigs {
    /// Default block cache size is 24GB.
    pub const DEFAULT_BLOCK_CACHE_SIZE: usize = 24 * (1 << 30);
}

fn default_to_true() -> bool {
    true
}

impl Default for RocksdbConfigs {
    fn default() -> Self {
        Self {
            ledger_db_config: RocksdbConfig::default(),
            state_merkle_db_config: RocksdbConfig::default(),
            state_kv_db_config: RocksdbConfig {
                bloom_filter_bits: Some(10.0),
                bloom_before_level: Some(2),
                ..Default::default()
            },
            index_db_config: RocksdbConfig {
                max_open_files: 1000,
                ..Default::default()
            },
            enable_storage_sharding: true,
            high_priority_background_threads: 4,
            low_priority_background_threads: 2,
            shared_block_cache_size: Self::DEFAULT_BLOCK_CACHE_SIZE,
        }
```

**File:** types/src/block_executor/config.rs (L35-37)
```rust
            // Use 1Gb for now, should be large enough to cache all mainnet modules (at the time
            // of writing this comment, 13.11.24).
            max_module_cache_size_in_bytes: 1024 * 1024 * 1024,
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L142-142)
```rust
        [memory_quota: AbstractValueSize, { 1.. => "memory_quota" }, 10_000_000],
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L159-162)
```rust
            max_bytes_all_write_ops_per_transaction: NumBytes,
            { 5.. => "max_bytes_all_write_ops_per_transaction" },
            10 << 20, // all write ops from a single transaction are 10MB max
        ],
```

**File:** terraform/helm/aptos-node/values.yaml (L69-75)
```yaml
  resources:
    limits:
      cpu: 30
      memory: 60Gi
    requests:
      cpu: 30
      memory: 60Gi
```
