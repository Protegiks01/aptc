# Audit Report

## Title
Sub-Pruner Desynchronization Causing Node Restart Failure

## Summary
The LedgerPruner executes sub-pruners in parallel without cross-pruner transaction atomicity. When one sub-pruner fails after others have succeeded, the system enters a desynchronized state. On node restart, if the failed sub-pruner cannot complete catch-up pruning, the node panics during initialization, causing a permanent denial of service until manual database repair.

## Finding Description

The LedgerPruner coordinates multiple sub-pruners (TransactionAuxiliaryDataPruner, TransactionInfoPruner, EventStorePruner, and others) to prune historical ledger data. The pruning process has a critical design flaw: [1](#0-0) 

The LedgerMetadataPruner runs first and commits its changes (updating `LedgerPrunerProgress`), then all sub-pruners execute in parallel using `par_iter()`. Each sub-pruner independently commits its own batch: [2](#0-1) 

**The vulnerability occurs in this sequence:**

1. `LedgerMetadataPruner.prune()` succeeds and commits, updating `LedgerPrunerProgress` to version V
2. Sub-pruners execute in parallel:
   - `TransactionAuxiliaryDataPruner` succeeds, deletes data, updates its progress to V, commits
   - `TransactionInfoPruner` fails due to disk I/O error, does NOT commit, progress remains at old value
   - Other sub-pruners may succeed or fail
3. The `try_for_each()` returns an error, preventing the overall progress update
4. The pruner worker retries, but if the failure is permanent (disk corruption), retries continue indefinitely

**On node restart,** sub-pruners attempt catch-up during initialization: [3](#0-2) [4](#0-3) 

Each sub-pruner reads `metadata_progress` and performs catch-up pruning if its own progress lags. If the catch-up prune fails (permanent corruption), the constructor returns an error, which propagates up: [5](#0-4) 

The node **panics** with "Failed to create ledger pruner", preventing startup.

**Regarding the specific question about referential integrity:** The scenario "auxiliary data is deleted but transaction info remains" does NOT cause referential integrity violations because auxiliary data is optional: [6](#0-5) 

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:
- **Validator node slowdowns**: Node cannot restart, causing complete unavailability
- **Significant protocol violations**: Breaks availability invariant that nodes should recover from failures

The impact affects:
- Single validator node availability (if only one node experiences the corruption)
- Network liveness (if multiple validators are affected simultaneously)
- Requires manual database repair or restoration from backup

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability triggers when:
1. A sub-pruner fails during parallel execution (disk I/O errors, corruption)
2. The failure is permanent (not transient)
3. Node attempts to restart

Natural triggers include:
- Disk hardware failures
- Filesystem corruption
- Storage full conditions causing write failures
- Database schema corruption in specific column families

While not directly exploitable by unprivileged attackers, the fragility makes production deployments vulnerable to operational failures.

## Recommendation

**Solution 1: Implement Two-Phase Commit for Sub-Pruners**

Modify the pruning process to use two-phase commit:
1. All sub-pruners prepare their batches (phase 1)
2. Only if ALL succeed, commit all batches atomically (phase 2)
3. Update `LedgerPrunerProgress` only after all commits succeed

**Solution 2: Graceful Degradation on Restart**

Modify initialization to handle catch-up failures gracefully:
- Log catch-up failures but continue initialization
- Disable pruning if sub-pruners are desynchronized
- Allow node to start and serve queries while marking pruner as degraded
- Provide manual repair commands for operators

**Solution 3: Add Progress Validation**

Before running sub-pruners, validate that all sub-pruner progress values match `metadata_progress`. If desynchronization is detected, perform sequential catch-up before allowing parallel execution.

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[test]
fn test_subpruner_desync_causes_restart_failure() {
    // 1. Initialize AptosDB with pruning enabled
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    
    // 2. Commit transactions up to version 10000
    commit_test_transactions(&db, 10000);
    
    // 3. Simulate sub-pruner failure during parallel execution
    // by corrupting TransactionInfo column family
    corrupt_transaction_info_db(&db);
    
    // 4. Trigger pruning - some sub-pruners succeed, TransactionInfoPruner fails
    db.set_pruner_target_version(5000);
    wait_for_pruner_error(&db);
    
    // 5. Verify desynchronized state:
    // - LedgerPrunerProgress = 5000
    // - TransactionAuxiliaryDataPrunerProgress = 5000
    // - TransactionInfoPrunerProgress = 0 (failed to update)
    
    // 6. Close and reopen database (simulating restart)
    drop(db);
    
    // 7. This should PANIC with "Failed to create ledger pruner"
    // because TransactionInfoPruner catch-up will fail
    let result = std::panic::catch_unwind(|| {
        AptosDB::new_for_test(&tmpdir)
    });
    
    assert!(result.is_err(), "Node should panic on restart");
}
```

## Notes

The specific question asks whether auxiliary data deletion while transaction data remains causes "referential integrity issues." The answer is **no** - this scenario is handled gracefully because `TransactionAuxiliaryData` is designed to be optional and defaults to `None` when missing.

However, the underlying synchronization mechanism has a critical flaw: parallel sub-pruner execution without atomic coordination creates fragile state that causes node restart failures when any sub-pruner experiences permanent errors. This represents a significant availability vulnerability requiring manual intervention.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L75-84)
```rust
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_auxiliary_data_pruner.rs (L25-35)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        TransactionAuxiliaryDataDb::prune(current_progress, target_version, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        self.ledger_db
            .transaction_auxiliary_data_db()
            .write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_auxiliary_data_pruner.rs (L39-59)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_auxiliary_data_db_raw(),
            &DbMetadataKey::TransactionAuxiliaryDataPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionAuxiliaryDataPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionAuxiliaryDataPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_info_pruner.rs (L36-57)
```rust
impl TransactionInfoPruner {
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_info_db_raw(),
            &DbMetadataKey::TransactionInfoPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionInfoPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionInfoPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L146-149)
```rust
        let pruner = Arc::new(
            LedgerPruner::new(ledger_db, internal_indexer_db)
                .expect("Failed to create ledger pruner."),
        );
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L401-405)
```rust
                    let auxiliary_data = self
                        .ledger_db
                        .transaction_auxiliary_data_db()
                        .get_transaction_auxiliary_data(version)?
                        .unwrap_or_default();
```
