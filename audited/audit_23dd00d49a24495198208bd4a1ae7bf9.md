# Audit Report

## Title
Consensus Determinism Violation Through Unconstrained Block Partitioner Configuration

## Summary
The block partitioner configuration (`PrePartitionerConfig`) and number of execution shards (`NUM_EXECUTION_SHARD`) are local per-node settings that are not enforced through on-chain consensus configuration. If sharded block execution were enabled in the consensus pipeline, different validators could use different partitioning strategies, leading to different transaction execution orderings and breaking the deterministic execution invariant required for consensus safety.

## Finding Description

The Aptos execution layer supports sharded block execution through the `PartitionerV2` system, which uses a configurable `PrePartitionerConfig` to determine how transactions are divided across shards. However, this configuration is **not part of the on-chain consensus configuration** that must be identical across all validators. [1](#0-0) 

The `BlockExecutorConfigFromOnchain` structure is explicitly documented as "required to be the same across all nodes" but contains only gas-related parameters, not partitioner configuration.

Multiple `PrePartitionerConfig` implementations exist with different behaviors: [2](#0-1) 

The two main implementations are:
1. **UniformPartitioner**: Deterministically divides transactions evenly across shards
2. **ConnectedComponentPartitioner**: Uses union-find to group conflicting transactions with a configurable `load_imbalance_tolerance` parameter [3](#0-2) 

The number of execution shards is also a local configuration: [4](#0-3) [5](#0-4) 

**Critical Issue**: When sharded execution is used, transaction outputs are aggregated based on `(round, shard_id)` ordering: [6](#0-5) 

If two validators partition the same block differently, they will:
1. Assign transactions to different `(round, shard_id)` tuples
2. Produce different final transaction orderings
3. Generate different state roots
4. Break consensus determinism

**Current Mitigation**: The consensus pipeline currently creates all blocks as `ExecutableTransactions::Unsharded`, preventing this vulnerability from manifesting: [7](#0-6) 

However, the execution infrastructure fully supports sharded execution: [8](#0-7) 

## Impact Explanation

**Severity: Critical (if sharded execution enabled) / Currently Mitigated**

This would qualify as **Critical Severity** under Aptos Bug Bounty rules as it breaks consensus safety - a fundamental requirement for blockchain security. Specifically:

- **Consensus/Safety violations**: Different validators would compute different state roots for identical blocks, causing chain splits
- **Deterministic Execution Invariant Violation**: Violates the core invariant that "all validators must produce identical state roots for identical blocks"

The impact would be:
- Complete consensus failure requiring emergency intervention
- Potential chain split into multiple incompatible forks
- Loss of network liveness until all validators align on identical configuration
- Requires hard fork or coordinated validator reconfiguration to resolve

However, **this vulnerability is currently latent** because consensus does not use sharded execution. The issue would only manifest if:
1. Future development enables sharded execution in consensus, AND
2. Validators are deployed with different partitioner configurations

## Likelihood Explanation

**Current Likelihood: None (sharded execution not used in consensus)**
**Future Likelihood (if enabled): High**

Currently, this vulnerability **cannot be exploited** because:
- Consensus pipeline creates only `Unsharded` blocks
- The sharded execution path is only exercised in benchmarks

If sharded execution were enabled in consensus, the likelihood would be **HIGH** because:
- No validation exists to ensure validators use identical configurations
- Different validator operators might choose different optimizations
- The `default_pre_partitioner_config()` could be overridden per-node
- No on-chain enforcement mechanism exists

**Important Note**: This is NOT exploitable by an unprivileged external attacker. It requires validators to be misconfigured, which is a deployment/operational issue rather than a code-level exploit.

## Recommendation

**Immediate Actions:**
1. Add explicit documentation warning against enabling sharded execution in consensus without proper configuration management
2. Add runtime assertions that fail if sharded blocks are created in consensus paths

**Long-term Solution (if sharded execution is to be enabled):**
1. Add partitioner configuration to `BlockExecutorConfigFromOnchain`:

```rust
pub struct BlockExecutorConfigFromOnchain {
    pub block_gas_limit_type: BlockGasLimitType,
    enable_per_block_gas_limit: bool,
    per_block_gas_limit: Option<u64>,
    gas_price_to_burn: Option<u64>,
    // NEW: Enforce consistent partitioner configuration
    pub num_execution_shards: usize,
    pub pre_partitioner_type: PrePartitionerType,  // enum: Uniform, ConnectedComponent
    pub load_imbalance_tolerance: Option<f32>,  // for ConnectedComponent
}
```

2. Read partitioner configuration from on-chain config instead of local static variables
3. Add consensus-level validation that all validators use identical partitioner settings
4. Implement on-chain governance for partitioner configuration changes

## Proof of Concept

**Note**: A full PoC cannot be provided because this vulnerability requires:
1. Modifying consensus code to enable sharded execution (changing line 860 in `consensus/src/pipeline/pipeline_builder.rs`)
2. Running multiple validator nodes with different configurations
3. Observing consensus divergence

**Conceptual PoC Steps:**

1. Modify consensus to create sharded blocks:
```rust
// In consensus/src/pipeline/pipeline_builder.rs
let partitioner = PartitionerV2Config::default().build();
let analyzed_txns = txns.into_iter().map(|t| t.into()).collect();
let partitioned = partitioner.partition(analyzed_txns, NUM_SHARDS);
let block = (block.id(), ExecutableTransactions::Sharded(partitioned), vec![]).into();
```

2. Configure Validator A with:
```rust
AptosVM::set_num_shards_once(4);
// Using ConnectedComponentPartitioner with load_imbalance_tolerance=2.0
```

3. Configure Validator B with:
```rust
AptosVM::set_num_shards_once(4);
// Using UniformPartitioner
```

4. Submit identical block to both validators
5. Observe different state roots due to different aggregation orders

**Expected Result**: Validators A and B would produce different state roots for the same block, breaking consensus.

---

**Notes**

This is classified as a **latent design vulnerability** rather than an actively exploitable bug. The current consensus implementation prevents exploitation by not using sharded execution. However, the lack of configuration enforcement creates a significant risk if sharded execution is enabled in future releases without proper safeguards.

The vulnerability demonstrates the importance of ensuring all consensus-critical configurations are enforced through on-chain mechanisms rather than relying on operator discipline to maintain identical node configurations.

### Citations

**File:** types/src/block_executor/config.rs (L82-90)
```rust
/// Configuration from on-chain configuration, that is
/// required to be the same across all nodes.
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct BlockExecutorConfigFromOnchain {
    pub block_gas_limit_type: BlockGasLimitType,
    enable_per_block_gas_limit: bool,
    per_block_gas_limit: Option<u64>,
    gas_price_to_burn: Option<u64>,
}
```

**File:** execution/block-partitioner/src/pre_partition/mod.rs (L44-51)
```rust
pub trait PrePartitionerConfig: Debug {
    fn build(&self) -> Box<dyn PrePartitioner>;
}

/// Create a default `PrePartitionerConfig`.
pub fn default_pre_partitioner_config() -> Box<dyn PrePartitionerConfig> {
    Box::<ConnectedComponentPartitionerConfig>::default()
}
```

**File:** execution/block-partitioner/src/pre_partition/connected_component/config.rs (L8-23)
```rust
#[derive(Clone, Debug)]
pub struct ConnectedComponentPartitionerConfig {
    /// If the size a connected component is larger than `load_imbalance_tolerance * block_size / num_shards`,
    /// this component will be broken up into smaller ones.
    ///
    /// See the comments of `aptos_block_partitioner::pre_partition::connected_component::ConnectedComponentPartitioner` for more details.
    pub load_imbalance_tolerance: f32,
}

impl Default for ConnectedComponentPartitionerConfig {
    fn default() -> Self {
        ConnectedComponentPartitionerConfig {
            load_imbalance_tolerance: 2.0,
        }
    }
}
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L162-162)
```rust
static NUM_EXECUTION_SHARD: OnceCell<usize> = OnceCell::new();
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L457-468)
```rust
    pub fn set_num_shards_once(mut num_shards: usize) {
        num_shards = max(num_shards, 1);
        // Only the first call succeeds, due to OnceCell semantics.
        NUM_EXECUTION_SHARD.set(num_shards).ok();
    }

    pub fn get_num_shards() -> usize {
        match NUM_EXECUTION_SHARD.get() {
            Some(num_shards) => *num_shards,
            None => 1,
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/mod.rs (L98-110)
```rust
        let num_rounds = sharded_output[0].len();
        let mut aggregated_results = vec![];
        let mut ordered_results = vec![vec![]; num_executor_shards * num_rounds];
        // Append the output from individual shards in the round order
        for (shard_id, results_from_shard) in sharded_output.into_iter().enumerate() {
            for (round, result) in results_from_shard.into_iter().enumerate() {
                ordered_results[round * num_executor_shards + shard_id] = result;
            }
        }

        for result in ordered_results.into_iter() {
            aggregated_results.extend(result);
        }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L856-868)
```rust
        let start = Instant::now();
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(start.elapsed())
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L68-89)
```rust
        let out = match transactions {
            ExecutableTransactions::Unsharded(txns) => {
                Self::by_transaction_execution_unsharded::<V>(
                    executor,
                    txns,
                    auxiliary_infos,
                    parent_state,
                    state_view,
                    onchain_config,
                    transaction_slice_metadata,
                )?
            },
            // TODO: Execution with auxiliary info is yet to be supported properly here for sharded transactions
            ExecutableTransactions::Sharded(txns) => Self::by_transaction_execution_sharded::<V>(
                txns,
                auxiliary_infos,
                parent_state,
                state_view,
                onchain_config,
                transaction_slice_metadata.append_state_checkpoint_to_block(),
            )?,
        };
```
