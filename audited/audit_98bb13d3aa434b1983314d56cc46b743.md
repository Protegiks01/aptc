# Audit Report

## Title
Missing Validation in `batch_get_encoded_proto_data` Allows Corrupted Transaction Data from Partial Cache Misses

## Summary
The `batch_get_encoded_proto_data` function in the indexer-grpc cache operator lacks critical validation to ensure all requested transactions are retrieved from Redis. Unlike similar functions that validate the returned transaction count, this function directly returns potentially incomplete data when `mget()` encounters missing keys due to TTL expiration, active eviction, or race conditions. This leads to service crashes or corrupted transaction data being served to indexer clients.

## Finding Description

The vulnerability exists in the `batch_get_encoded_proto_data` function which performs three critical operations:

1. Calls `check_cache_coverage_status` to verify the requested version is within the cache window
2. Calls Redis `mget()` to fetch multiple transaction keys
3. Returns the raw results without validation [1](#0-0) 

The critical flaw is at lines 330-331 where `mget()` results are returned without checking if all requested transactions were successfully retrieved.

**Comparison with Protected Functions:**

The codebase contains two other functions using `mget()` that DO include proper validation:

`batch_get_encoded_proto_data_with_length`: [2](#0-1) 

`get_transactions_with_durations`: [3](#0-2) 

Both functions validate that `transactions.len() == transaction_count`, ensuring all requested data was retrieved.

**When Partial Cache Misses Occur:**

The cache system uses TTL-based expiration and active eviction: [4](#0-3) 

Partial misses can occur due to:
1. **TTL expiration**: Each entry has timestamp-based TTL (line 277), causing individual keys to expire at different times
2. **Active eviction**: Keys older than `CACHE_SIZE_EVICTION_LOWER_BOUND` (300,000 versions) are actively deleted (lines 282-288)
3. **Race conditions**: Between `check_cache_coverage_status` checking the cache window and `mget()` fetching keys, some entries may be evicted
4. **Redis memory pressure**: Redis may evict keys independently of the application's logic

**The Coverage Check Weakness:** [5](#0-4) 

This function only verifies the requested version is within the theoretical cache window (`latest_version - CACHE_SIZE_ESTIMATION` to `latest_version`). It does NOT verify that all individual keys in that range actually exist in Redis.

**Exploitation Flow:**

1. Indexer client requests transactions starting at version 1,000,000
2. `check_cache_coverage_status` returns `CacheHit(1000)` because latest_version is 1,250,000
3. `batch_get_encoded_proto_data` calls `mget()` for keys 1,000,000 to 1,000,999
4. Due to TTL expiration, keys 1,000,500-1,000,600 are missing (100 keys expired)
5. Redis `mget()` returns nil for missing keys
6. The rust-redis crate handles nil values by either:
   - Skipping them (returning 900 items instead of 1000)
   - Converting to empty `Vec<u8>` (returning 1000 items with 100 empty)
7. **No validation catches this** - the function returns corrupted data
8. Downstream processing attempts deserialization: [6](#0-5) 

9. Empty byte arrays cause panics in `CacheEntry::into_transaction()`: [7](#0-6) 

10. The service crashes with "base64 decoding failed" or "proto deserialization failed"
11. OR if fewer items are returned, wrong transaction versions are associated with wrong data, causing data corruption

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **API crashes**: The indexer-grpc data service crashes when attempting to deserialize empty or corrupted byte arrays, causing service unavailability for all clients
2. **Data corruption**: If partial data is successfully deserialized, clients receive incorrect transaction history with mismatched versions
3. **Cascading failures**: Applications relying on the indexer for transaction data may make incorrect decisions based on corrupted data

While this does not affect core consensus or validator operations (the indexer is an auxiliary service), it represents a significant protocol violation in the indexer-grpc service that can cause service-wide outages.

## Likelihood Explanation

**High Likelihood**:

1. **TTL expiration is guaranteed**: Every cache entry has a timestamp-based TTL, ensuring eventual expiration
2. **Race conditions are common**: The time gap between coverage checks and data fetching creates a natural race window
3. **Active eviction is continuous**: As new blocks are added, old keys are automatically deleted
4. **No attacker required**: This occurs during normal operation under load
5. **Affects high-traffic scenarios**: Popular version ranges near the eviction boundary are most susceptible

The issue will manifest frequently in production environments, especially during:
- High query load when cache is near capacity
- Historical data queries near the eviction boundary
- Network latency causing delays between coverage check and mget

## Recommendation

Add the same validation present in the other two `mget()`-using functions. Replace the vulnerable function with:

```rust
pub async fn batch_get_encoded_proto_data(
    &mut self,
    start_version: u64,
) -> anyhow::Result<CacheBatchGetStatus> {
    let cache_coverage_status = self.check_cache_coverage_status(start_version).await;
    match cache_coverage_status {
        Ok(CacheCoverageStatus::CacheHit(v)) => {
            let versions = (start_version..start_version + v)
                .map(|e| CacheEntry::build_key(e, self.storage_format))
                .collect::<Vec<String>>();
            let encoded_transactions: Vec<Vec<u8>> = self
                .conn
                .mget(versions)
                .await
                .context("Failed to mget from Redis")?;
            
            // ADDED VALIDATION
            if encoded_transactions.len() != v as usize {
                // Some keys are missing - treat as cache evicted
                return Ok(CacheBatchGetStatus::EvictedFromCache);
            }
            
            Ok(CacheBatchGetStatus::Ok(encoded_transactions))
        },
        Ok(CacheCoverageStatus::CacheEvicted) => Ok(CacheBatchGetStatus::EvictedFromCache),
        Ok(CacheCoverageStatus::DataNotReady) => Ok(CacheBatchGetStatus::NotReady),
        Err(err) => Err(err),
    }
}
```

**Alternative approach**: Use `Vec<Option<Vec<u8>>>` as the return type from `mget()` to explicitly handle missing keys, then return `EvictedFromCache` if any are `None`.

## Proof of Concept

```rust
#[cfg(test)]
mod test_partial_cache_miss {
    use super::*;
    use redis_test::{MockCmd, MockRedisConnection};

    #[tokio::test]
    async fn test_batch_get_with_partial_cache_miss() {
        // Simulate scenario: request 10 keys, but only 7 exist
        // Keys 1000, 1001, 1002 exist
        // Keys 1003, 1004 missing (nil)
        // Keys 1005, 1006, 1007, 1008, 1009 exist
        
        // Mock check_cache_coverage_status returning CacheHit(10)
        let latest_version_cmd = MockCmd::new(
            redis::cmd("GET").arg(CACHE_KEY_LATEST_VERSION),
            Ok("1500")
        );
        
        // Mock mget returning only 7 items (redis crate skips nils)
        let mget_keys: Vec<String> = (1000..1010)
            .map(|v| CacheEntry::build_key(v, StorageFormat::Lz4CompressedProto))
            .collect();
        
        // Simulate 7 valid items (with 2 missing in the middle)
        let valid_transaction_bytes = vec![
            vec![1, 2, 3], // 1000
            vec![4, 5, 6], // 1001
            vec![7, 8, 9], // 1002
            // 1003 missing
            // 1004 missing
            vec![10, 11, 12], // 1005
            vec![13, 14, 15], // 1006
            vec![16, 17, 18], // 1007
            vec![19, 20, 21], // 1008
        ];
        
        let mget_cmd = MockCmd::new(
            redis::cmd("MGET").arg(mget_keys),
            Ok(valid_transaction_bytes.clone())
        );
        
        let mock_connection = MockRedisConnection::new(vec![
            latest_version_cmd,
            mget_cmd,
        ]);
        
        let mut cache_operator = CacheOperator::new(
            mock_connection,
            StorageFormat::Lz4CompressedProto
        );
        
        // This should detect the mismatch and return EvictedFromCache
        // But currently it returns Ok with only 7 transactions
        let result = cache_operator.batch_get_encoded_proto_data(1000).await;
        
        match result {
            Ok(CacheBatchGetStatus::Ok(txns)) => {
                // VULNERABILITY: Function returns partial data
                assert_eq!(txns.len(), 7); // Only 7 instead of expected 10
                // Downstream code expects 10, gets 7 - CRASH or CORRUPTION
                panic!("Vulnerability: Partial cache miss not detected!");
            },
            Ok(CacheBatchGetStatus::EvictedFromCache) => {
                // CORRECT: Should fallback to file store
                println!("Correctly handled partial miss");
            },
            _ => panic!("Unexpected result"),
        }
    }
}
```

**Notes:**
- This vulnerability is specific to the indexer-grpc auxiliary service, not the core blockchain consensus/validator infrastructure
- The indexer does not participate in consensus, block production, or state commitment
- However, it represents a critical reliability issue for the indexer API that serves blockchain data to applications
- The fix is straightforward: add the same validation that already exists in similar functions in the same file

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L193-219)
```rust
    pub async fn check_cache_coverage_status(
        &mut self,
        requested_version: u64,
    ) -> anyhow::Result<CacheCoverageStatus> {
        let latest_version: u64 = match self
            .conn
            .get::<&str, String>(CACHE_KEY_LATEST_VERSION)
            .await
        {
            Ok(v) => v
                .parse::<u64>()
                .expect("Redis latest_version is not a number."),
            Err(err) => return Err(err.into()),
        };

        if requested_version >= latest_version {
            Ok(CacheCoverageStatus::DataNotReady)
        } else if requested_version + CACHE_SIZE_ESTIMATION < latest_version {
            Ok(CacheCoverageStatus::CacheEvicted)
        } else {
            // TODO: rewrite this logic to surface this max fetch size better
            Ok(CacheCoverageStatus::CacheHit(std::cmp::min(
                latest_version - requested_version,
                FILE_ENTRY_TRANSACTION_COUNT,
            )))
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L244-247)
```rust
        ensure!(
            transactions.len() == transaction_count as usize,
            "Failed to get all transactions from cache."
        );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L272-289)
```rust
            redis_pipeline
                .cmd("SET")
                .arg(cache_key)
                .arg(bytes)
                .arg("EX")
                .arg(get_ttl_in_seconds(timestamp_in_seconds))
                .ignore();
            // Actively evict the expired cache. This is to avoid using Redis
            // eviction policy, which is probabilistic-based and may evict the
            // cache that is still needed.
            if version >= CACHE_SIZE_EVICTION_LOWER_BOUND {
                let key = CacheEntry::build_key(
                    version - CACHE_SIZE_EVICTION_LOWER_BOUND,
                    self.storage_format,
                )
                .to_string();
                redis_pipeline.cmd("DEL").arg(key).ignore();
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L320-337)
```rust
    pub async fn batch_get_encoded_proto_data(
        &mut self,
        start_version: u64,
    ) -> anyhow::Result<CacheBatchGetStatus> {
        let cache_coverage_status = self.check_cache_coverage_status(start_version).await;
        match cache_coverage_status {
            Ok(CacheCoverageStatus::CacheHit(v)) => {
                let versions = (start_version..start_version + v)
                    .map(|e| CacheEntry::build_key(e, self.storage_format))
                    .collect::<Vec<String>>();
                let encoded_transactions: Vec<Vec<u8>> = self.conn.mget(versions).await?;
                Ok(CacheBatchGetStatus::Ok(encoded_transactions))
            },
            Ok(CacheCoverageStatus::CacheEvicted) => Ok(CacheBatchGetStatus::EvictedFromCache),
            Ok(CacheCoverageStatus::DataNotReady) => Ok(CacheBatchGetStatus::NotReady),
            Err(err) => Err(err),
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L389-392)
```rust
        ensure!(
            transactions.len() == transaction_count as usize,
            "Failed to get all transactions from cache."
        );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L694-709)
```rust
async fn deserialize_cached_transactions(
    transactions: Vec<Vec<u8>>,
    storage_format: StorageFormat,
) -> anyhow::Result<Vec<Transaction>> {
    let task = tokio::task::spawn_blocking(move || {
        transactions
            .into_iter()
            .map(|transaction| {
                let cache_entry = CacheEntry::new(transaction, storage_format);
                cache_entry.into_transaction()
            })
            .collect::<Vec<Transaction>>()
    })
    .await;
    task.context("Transaction bytes to CacheEntry deserialization task failed")
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L142-157)
```rust
    pub fn into_transaction(self) -> Transaction {
        match self {
            CacheEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
            },
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
            },
        }
    }
```
