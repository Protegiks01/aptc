# Audit Report

## Title
Memory Exhaustion DoS via Malicious CommitVotes with Oversized EpochState

## Summary
A malicious validator can exhaust memory on consensus nodes by creating CommitVotes containing LedgerInfo structures with artificially inflated `next_epoch_state` fields. The `pending_commit_votes` cache accepts votes for up to 100 future rounds with no validation of the LedgerInfo content size, allowing memory consumption of multiple gigabytes per malicious validator.

## Finding Description

The vulnerability exists in the `try_add_pending_commit_vote` function in BufferManager, which caches incoming CommitVotes without validating the size or content of the embedded LedgerInfo structures. [1](#0-0) 

The function only validates:
1. That the round is within `max_pending_rounds_in_commit_vote_cache` (default 100) of `highest_committed_round`
2. That the vote hasn't already been committed [2](#0-1) 

CommitVote signature verification only checks cryptographic validity, not content: [3](#0-2) 

**Attack Path:**

1. Malicious validator crafts a LedgerInfo with `next_epoch_state` containing a ValidatorVerifier with hundreds of thousands of fake validators [4](#0-3) [5](#0-4) 

2. Each ValidatorConsensusInfo is ~136 bytes: [6](#0-5) 

3. Network accepts messages up to 64 MiB: [7](#0-6) 

4. Attacker sends votes for all 100 cached rounds, each up to 64 MiB
5. Cache stores: `BTreeMap<Round, HashMap<AccountAddress, CommitVote>>` [8](#0-7) 

6. Total memory consumption: **100 rounds × 64 MiB = 6.4 GB per malicious validator**
7. With 10 malicious validators (well within 1/3 Byzantine assumption): **64 GB total**

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:
- **Validator node slowdowns**: Memory exhaustion causes OS swapping, severely degrading consensus performance
- **Potential node crashes**: Out-of-memory (OOM) kills can take validators offline
- **Network liveness impact**: If enough validators are affected, consensus could stall

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The pending_commit_votes cache has no size limits beyond round count.

## Likelihood Explanation

**High Likelihood:**
- Requires only a single compromised/malicious validator (standard in Byzantine fault model)
- Attack is trivial to execute - just craft and send oversized votes
- No rate limiting or content validation exists
- Attack can be sustained as long as consensus doesn't advance past the 100-round window
- During network issues or high load when consensus slows, attack window increases

## Recommendation

Implement strict validation of CommitVote content before caching:

```rust
fn try_add_pending_commit_vote(&mut self, vote: CommitVote) -> bool {
    // Add size validation
    const MAX_COMMIT_VOTE_SIZE: usize = 1024 * 1024; // 1 MiB limit
    
    let serialized_size = bcs::serialized_size(&vote).unwrap_or(usize::MAX);
    if serialized_size > MAX_COMMIT_VOTE_SIZE {
        warn!(
            "CommitVote from {:?} exceeds size limit: {} bytes",
            vote.author(),
            serialized_size
        );
        return false;
    }
    
    // Validate next_epoch_state validator count
    if let Some(next_epoch_state) = vote.ledger_info().commit_info().next_epoch_state() {
        const MAX_VALIDATORS_IN_VOTE: usize = 500;
        let validator_count = next_epoch_state.verifier.validator_infos.len();
        if validator_count > MAX_VALIDATORS_IN_VOTE {
            warn!(
                "CommitVote from {:?} has excessive validator count: {}",
                vote.author(),
                validator_count
            );
            return false;
        }
    }
    
    // Existing round checks...
    let block_id = vote.commit_info().id();
    let round = vote.commit_info().round();
    
    if round <= self.highest_committed_round {
        true
    } else if round > self.highest_committed_round
        && self.highest_committed_round + self.max_pending_rounds_in_commit_vote_cache > round
    {
        self.pending_commit_votes
            .entry(round)
            .or_default()
            .insert(vote.author(), vote);
        true
    } else {
        debug!(
            round = round,
            highest_committed_round = self.highest_committed_round,
            block_id = block_id,
            "Received a commit vote not in the next 100 rounds, ignored."
        );
        false
    }
}
```

Additionally, add total cache size monitoring:
```rust
// Add to BufferManager struct
pending_commit_votes_total_size: usize,
const MAX_PENDING_COMMIT_VOTES_TOTAL_SIZE: usize = 100 * 1024 * 1024; // 100 MiB total
```

## Proof of Concept

```rust
#[test]
fn test_memory_exhaustion_via_oversized_commit_votes() {
    use aptos_types::validator_verifier::{ValidatorVerifier, ValidatorConsensusInfo};
    use aptos_crypto::bls12381::PublicKey;
    use aptos_types::account_address::AccountAddress;
    
    // Create a malicious LedgerInfo with 100,000 fake validators
    let mut fake_validators = Vec::new();
    for i in 0..100_000 {
        let addr = AccountAddress::from_hex_literal(&format!("0x{:064x}", i)).unwrap();
        let pubkey = PublicKey::dummy_key();
        fake_validators.push(ValidatorConsensusInfo::new(addr, pubkey, 1));
    }
    
    let fake_verifier = ValidatorVerifier::new(fake_validators);
    let fake_epoch_state = EpochState::new(1, fake_verifier);
    
    // Create BlockInfo with this oversized epoch state
    let block_info = BlockInfo::new(
        1,
        100, // future round
        HashValue::random(),
        HashValue::random(),
        0,
        0,
        Some(fake_epoch_state),
    );
    
    let ledger_info = LedgerInfo::new(block_info, HashValue::zero());
    
    // Create and sign CommitVote
    let validator_signer = ValidatorSigner::random(None);
    let vote = CommitVote::new(validator_signer.author(), ledger_info, &validator_signer).unwrap();
    
    // Verify the vote is enormous
    let size = bcs::serialized_size(&vote).unwrap();
    assert!(size > 10_000_000); // Over 10 MiB
    
    // Attacker would send 100 such votes (one per round) 
    // Total memory: 100 × 10+ MiB = 1+ GB per malicious validator
}
```

**Notes:**
This vulnerability exploits the lack of content validation in the CommitVote caching mechanism. While signature verification ensures votes are from valid validators, it doesn't prevent malicious validators from crafting votes with artificially large data structures that serve no legitimate consensus purpose. The fix requires both size limits and semantic validation of vote contents.

### Citations

**File:** consensus/src/pipeline/buffer_manager.rs (L170-170)
```rust
    pending_commit_votes: BTreeMap<Round, HashMap<AccountAddress, CommitVote>>,
```

**File:** consensus/src/pipeline/buffer_manager.rs (L335-361)
```rust
    fn try_add_pending_commit_vote(&mut self, vote: CommitVote) -> bool {
        let block_id = vote.commit_info().id();
        let round = vote.commit_info().round();

        // Don't need to store commit vote if we have already committed up to that round
        if round <= self.highest_committed_round {
            true
        } else
        // Store the commit vote only if it is for one of the next 100 rounds.
        if round > self.highest_committed_round
            && self.highest_committed_round + self.max_pending_rounds_in_commit_vote_cache > round
        {
            self.pending_commit_votes
                .entry(round)
                .or_default()
                .insert(vote.author(), vote);
            true
        } else {
            debug!(
                round = round,
                highest_committed_round = self.highest_committed_round,
                block_id = block_id,
                "Received a commit vote not in the next 100 rounds, ignored."
            );
            false
        }
    }
```

**File:** config/src/config/consensus_config.rs (L381-381)
```rust
            max_pending_rounds_in_commit_vote_cache: 100,
```

**File:** consensus/consensus-types/src/pipeline/commit_vote.rs (L103-113)
```rust
    pub fn verify(&self, sender: Author, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        ensure!(
            self.author() == sender,
            "Commit vote author {:?} doesn't match with the sender {:?}",
            self.author(),
            sender
        );
        validator
            .optimistic_verify(self.author(), &self.ledger_info, &self.signature)
            .context("Failed to verify Commit Vote")
    }
```

**File:** types/src/ledger_info.rs (L53-59)
```rust
pub struct LedgerInfo {
    commit_info: BlockInfo,

    /// Hash of consensus specific data that is opaque to all parts of the system other than
    /// consensus.
    consensus_data_hash: HashValue,
}
```

**File:** types/src/block_info.rs (L29-44)
```rust
pub struct BlockInfo {
    /// The epoch to which the block belongs.
    epoch: u64,
    /// The consensus protocol is executed in rounds, which monotonically increase per epoch.
    round: Round,
    /// The identifier (hash) of the block.
    id: HashValue,
    /// The accumulator root hash after executing this block.
    executed_state_id: HashValue,
    /// The version of the latest transaction after executing this block.
    version: Version,
    /// The timestamp this block was proposed by a proposer.
    timestamp_usecs: u64,
    /// An optional field containing the next epoch info
    next_epoch_state: Option<EpochState>,
}
```

**File:** types/src/validator_verifier.rs (L72-76)
```rust
pub struct ValidatorConsensusInfo {
    pub address: AccountAddress,
    pub public_key: PublicKey,
    pub voting_power: u64,
}
```

**File:** config/src/config/network_config.rs (L50-50)
```rust
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```
