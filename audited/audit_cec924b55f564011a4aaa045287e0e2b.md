# Audit Report

## Title
Non-Atomic State Update During KV-Only Restore Causing Database Inconsistency

## Summary
The `replay_kv()` function in the transaction restore path updates in-memory state structures with `CORRUPTION_SENTINEL` values before database commits complete, violating atomicity guarantees. If commits fail partially, the database is left in an inconsistent state that can cause node crashes or require manual intervention.

## Finding Description

The vulnerability exists in the KV-only restore flow where state updates are performed non-atomically: [1](#0-0) 

At line 568, `force_state_version_for_kv_restore` is called with `first_version.checked_sub(1)`, which immediately updates in-memory state structures through: [2](#0-1) 

This calls: [3](#0-2) 

Which then invokes: [4](#0-3) 

The critical issue is that `set_state_ignoring_summary` sets both hot and global sparse Merkle trees to use `CORRUPTION_SENTINEL` values: [5](#0-4) 

More critically, during transaction saving in KV replay mode, the in-memory state is updated BEFORE disk commits: [6](#0-5) 

The comment at line 275 acknowledges this: "n.b. ideally this is set after the batches are committed". The actual commits happen later: [7](#0-6) 

**Atomicity Violation:** If `state_kv_db.commit()` succeeds but `ledger_db.write_schemas()` fails (disk full, I/O error, process crash), the state KV database is committed while the ledger database is not, and in-memory state structures contain `CORRUPTION_SENTINEL` values.

Additionally, the crash recovery mechanism is bypassed during restore: [8](#0-7) 

When `empty_buffered_state_for_restore=true`, `sync_commit_progress` is not called, so the normal crash recovery cannot detect or fix the inconsistency.

Future state operations will panic due to corruption sentinel validation: [9](#0-8) 

## Impact Explanation

**Severity: Medium** (up to $10,000)

This breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs."

However, after careful analysis, this issue has **limited exploitability**:

1. **Administrative Operation Only**: The restore functionality is triggered by node operators using backup-cli, not by external attackers
2. **Requires Specific Failure Conditions**: Manifests only when disk I/O fails or process crashes at a precise moment during commit
3. **Trust Model Limitation**: Node operators are considered trusted actors per the threat model
4. **No Direct Funds/Consensus Impact**: Does not directly cause fund loss or consensus violations

The impact is primarily:
- **State inconsistencies requiring intervention** (aligns with Medium severity criteria)
- Node availability issues if corruption sentinels trigger assertion panics
- Operational burden requiring manual database repair or re-restore

## Likelihood Explanation

**Likelihood: Low-Medium**

The vulnerability requires:
1. Operator initiating a KV-only restore operation (administrative action)
2. System crash, disk failure, or I/O error occurring at a specific point between two sequential database commits
3. The timing window is narrow but realistic in production environments with hardware failures

While the code path is reachable during legitimate restore operations, it requires failure conditions that are outside normal operation. The issue is more likely to manifest as an operational reliability problem than an exploitable attack vector.

## Recommendation

Implement atomic commit semantics by deferring in-memory state updates until after all database commits succeed:

1. **Modify save_transactions_impl** to return the calculated ledger state instead of immediately setting it
2. **Commit databases first**, then update in-memory state only on success
3. **Add transaction-style rollback** if any commit fails
4. **Enable crash recovery during restore** by not bypassing sync_commit_progress

Pseudocode fix for restore_utils.rs:
```
// Calculate state but don't set yet
let ledger_state_to_set = if kv_replay && ... {
    let (ledger_state, _) = state_store.calculate_state_and_put_updates(...)?;
    Some(ledger_state)
} else {
    None
};

// Commit databases
state_kv_db.commit(...)?;
ledger_db.write_schemas(...)?;

// Only update in-memory state after successful commits
if let Some(ledger_state) = ledger_state_to_set {
    state_store.set_state_ignoring_summary(ledger_state);
}
```

## Proof of Concept

**Note:** This issue manifests during operational restore procedures with specific failure conditions, making a traditional PoC challenging without modifying the codebase to inject faults.

Reproduction requires:
1. Initiate KV-only restore with backup-cli
2. Simulate disk failure or process kill between lines 170-172 of restore_utils.rs
3. Observe state KV committed but ledger uncommitted
4. Attempt to restart node and observe panic from corruption sentinel

Due to the administrative nature of the operation and requirement for specific failure injection, this is more appropriately classified as a **reliability/correctness issue** rather than an exploitable security vulnerability under the bug bounty program's strict criteria.

---

## Notes

Upon rigorous validation against the bug bounty criteria, this issue **does not fully qualify** as an exploitable security vulnerability because:

- It requires **operator-level access** to trigger (administrative restore operation)
- It cannot be exploited by **unprivileged external attackers**
- It manifests under **specific failure conditions** (crash/disk errors) not controllable by attackers
- The trust model considers node operators as **trusted actors**

While this is a legitimate engineering concern affecting database consistency and node reliability, it does not meet the "exploitable by unprivileged attacker" criterion required by the bug bounty program.

**Recommendation:** Address as an operational reliability improvement rather than a security vulnerability.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L568-568)
```rust
        restore_handler.force_state_version_for_kv_restore(first_version.checked_sub(1))?;
```

**File:** storage/aptosdb/src/backup/restore_handler.rs (L101-103)
```rust
    pub fn force_state_version_for_kv_restore(&self, version: Option<Version>) -> Result<()> {
        self.state_store.init_state_ignoring_summary(version)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L353-360)
```rust
        if !hack_for_tests && !empty_buffered_state_for_restore {
            Self::sync_commit_progress(
                Arc::clone(&ledger_db),
                Arc::clone(&state_kv_db),
                Arc::clone(&state_merkle_db),
                /*crash_if_difference_is_too_large=*/ true,
            );
        }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1199-1206)
```rust
    pub fn init_state_ignoring_summary(&self, version: Option<Version>) -> Result<()> {
        let usage = self.get_usage(version)?;
        let state = State::new_at_version(version, usage, HotStateConfig::default());
        let ledger_state = LedgerState::new(state.clone(), state);
        self.set_state_ignoring_summary(ledger_state);

        Ok(())
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1208-1239)
```rust
    pub fn set_state_ignoring_summary(&self, ledger_state: LedgerState) {
        let hot_smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let last_checkpoint_summary = StateSummary::new_at_version(
            ledger_state.last_checkpoint().version(),
            hot_smt.clone(),
            smt.clone(),
            HotStateConfig::default(),
        );
        let summary = StateSummary::new_at_version(
            ledger_state.version(),
            hot_smt,
            smt,
            HotStateConfig::default(),
        );

        let last_checkpoint = StateWithSummary::new(
            ledger_state.last_checkpoint().clone(),
            last_checkpoint_summary.clone(),
        );
        let latest = StateWithSummary::new(ledger_state.latest().clone(), summary);
        let current = LedgerStateWithSummary::from_latest_and_last_checkpoint(
            latest,
            last_checkpoint.clone(),
        );

        self.persisted_state.hack_reset(last_checkpoint.clone());
        *self.current_state_locked() = current;
        self.buffered_state
            .lock()
            .force_last_snapshot(last_checkpoint);
    }
```

**File:** crates/aptos-crypto/src/hash.rs (L684-685)
```rust
pub static CORRUPTION_SENTINEL: Lazy<HashValue> =
    Lazy::new(|| create_literal_hash("CORRUPTION_SENTINEL"));
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L164-173)
```rust
        // get the last version and commit to the state kv db
        // commit the state kv before ledger in case of failure happens
        let last_version = first_version + txns.len() as u64 - 1;
        state_store
            .state_db
            .state_kv_db
            .commit(last_version, None, sharded_kv_schema_batch)?;

        ledger_db.write_schemas(ledger_db_batch)?;
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```

**File:** storage/storage-interface/src/state_store/state_summary.rs (L92-93)
```rust
        assert_ne!(self.hot_state_summary.root_hash(), *CORRUPTION_SENTINEL);
        assert_ne!(self.global_state_summary.root_hash(), *CORRUPTION_SENTINEL);
```
