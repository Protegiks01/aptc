# Audit Report

## Title
Race Condition in Resource Group Initialization Can Trigger Code Invariant Errors and Force Sequential Execution Fallback

## Summary
A race condition exists between resource group initialization (`set_raw_base_values`) and concurrent writes (`write_v2`) in the MVHashMap parallel execution system. When transactions execute in parallel, a write to a resource group can occur during the initialization window, triggering `code_invariant_error` that forces fallback to sequential execution or crashes the validator depending on configuration.

## Finding Description

The vulnerability stems from non-atomic initialization of resource group data structures in `versioned_group_data.rs`. The initialization process creates two separate DashMap entries: [1](#0-0) [2](#0-1) 

These operations are not atomic, creating a race window. The `write_v2` function assumes both structures are initialized, checking `group_tags` first via `data_write_impl`: [3](#0-2) [4](#0-3) 

Then checking `group_sizes`: [5](#0-4) 

**Attack Scenario:**
1. Transaction i reads from a new resource group G, triggering initialization in `initialize_mvhashmap_base_group_contents`
2. Initialization creates `group_sizes` entry but hasn't yet created `group_tags` entry
3. Transaction j (where j > i) executes in parallel and attempts `write_v2` to group G
4. The `data_write_impl` call tries to access `group_tags` before it exists
5. `code_invariant_error` is triggered

The code relies on a "read-before-write" assumption documented at: [6](#0-5) 

However, in BlockSTM's speculative parallel execution, this assumption can be violated due to the race condition during the initialization window (between lines 155 and 175).

## Impact Explanation

**Production Impact (High Severity):**
The production configuration hardcodes `allow_fallback: true`: [7](#0-6) 

When the error propagates through the execution stack, the system falls back to sequential execution: [8](#0-7) 

This results in:
- Forced sequential execution instead of parallel execution
- Significant performance degradation (loss of parallelism benefits)
- Potential DoS vector if repeatedly triggered
- Validator slowdown affecting network throughput

**Alternative Configuration Impact (Critical Severity):**
If `allow_fallback` were set to `false`, the system would panic: [9](#0-8) 

This categorizes as **High Severity** per the bug bounty criteria: "Validator node slowdowns" with potential for repeated exploitation.

## Likelihood Explanation

**High Likelihood:**
1. BlockSTM parallel execution is enabled by default
2. The race window exists during every first access to a new resource group
3. Higher probability under load when many transactions execute concurrently
4. The initialization involves non-trivial computation (size calculation, serialization), widening the race window
5. An attacker could intentionally craft transactions to maximize the race probability

**Triggering Conditions:**
- Transaction i reads from a resource group (triggering initialization)
- Transaction j writes to the same group while initialization is in progress
- Timing must hit the window between lines 155 and 175 of `set_raw_base_values`

## Recommendation

**Fix: Atomic Group Initialization**

Modify `set_raw_base_values` to initialize both `group_sizes` and `group_tags` atomically before releasing any locks. One approach:

```rust
pub fn set_raw_base_values(
    &self,
    group_key: K,
    base_values: Vec<(T, V)>,
) -> anyhow::Result<()> {
    // Create both entries atomically by acquiring both locks together
    // or using a single initialization flag
    let mut group_sizes = self.group_sizes.entry(group_key.clone()).or_default();
    let mut group_tags = self.group_tags.entry(group_key.clone()).or_default();
    
    if let Vacant(entry) = group_sizes.size_entries.entry(ShiftedTxnIndex::zero_idx()) {
        let group_size = group_size_as_sum::<T>(
            base_values
                .iter()
                .flat_map(|(tag, value)| value.bytes().map(|b| (tag.clone(), b.len()))),
        )
        .map_err(|e| {
            anyhow!(
                "Tag serialization error in resource group at {:?}: {:?}",
                group_key.clone(),
                e
            )
        })?;

        entry.insert(SizeEntry::new(SizeAndDependencies::from_size(group_size)));
        
        // Now both locks are held - populate tags
        for (tag, value) in base_values.into_iter() {
            group_tags.insert(tag.clone());
            self.values.set_base_value(
                (group_key.clone(), tag),
                ValueWithLayout::RawFromStorage(Arc::new(value)),
            );
        }
    }
    
    Ok(())
}
```

Alternatively, use a single initialization flag or ensure writes cannot proceed until initialization completes.

## Proof of Concept

This vulnerability requires a multi-threaded race condition test. The following conceptual PoC demonstrates the issue:

```rust
#[test]
fn test_race_condition_group_initialization() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let group_data = Arc::new(VersionedGroupData::<KeyType, usize, TestValue>::empty());
    let group_key = KeyType(b"/group/race".to_vec());
    let barrier = Arc::new(Barrier::new(2));
    
    // Thread 1: Initialize group (slow operation)
    let group_data_1 = group_data.clone();
    let barrier_1 = barrier.clone();
    let key_1 = group_key.clone();
    let handle1 = thread::spawn(move || {
        barrier_1.wait(); // Synchronize start
        let base_values = vec![
            (1, TestValue::creation_with_len(100)), // Large value to slow down
            // ... many more values to increase initialization time
        ];
        group_data_1.set_raw_base_values(key_1, base_values)
    });
    
    // Thread 2: Attempt concurrent write
    let group_data_2 = group_data.clone();
    let barrier_2 = barrier.clone();
    let key_2 = group_key.clone();
    let handle2 = thread::spawn(move || {
        barrier_2.wait(); // Synchronize start
        std::thread::sleep(std::time::Duration::from_micros(10)); // Small delay to hit race window
        // This should trigger code_invariant_error if it executes
        // between group_sizes creation and group_tags creation
        group_data_2.write_v2(
            key_2,
            5,
            1,
            vec![(2, (TestValue::creation_with_len(1), None))],
            ResourceGroupSize::Combined { num_tagged_resources: 1, all_tagged_resources_size: 10 },
            HashSet::new(),
        )
    });
    
    let _ = handle1.join();
    let result2 = handle2.join();
    
    // If race condition occurs, result2 will be Err(PanicError::CodeInvariantError)
    // With allow_fallback=true, this causes sequential execution fallback
    // With allow_fallback=false, this would panic the validator
}
```

## Notes

While the production configuration mitigates validator crashes through `allow_fallback=true`, this remains a **valid High Severity vulnerability** because:

1. **Violates Code Invariant**: The race breaks the fundamental "read-before-write" assumption
2. **Performance DoS**: Can be repeatedly exploited to force sequential execution, degrading validator performance
3. **Configuration-Dependent Severity**: Under different configurations, this becomes Critical (validator crash)
4. **Architectural Flaw**: The non-atomic initialization pattern is inherently unsafe in concurrent execution

The issue should be fixed regardless of the fallback mitigation, as relying on fallback to sequential execution defeats the purpose of BlockSTM's parallel execution optimization and creates an exploitable performance degradation vector.

### Citations

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L155-155)
```rust
        let mut group_sizes = self.group_sizes.entry(group_key.clone()).or_default();
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L175-175)
```rust
            let mut superset_tags = self.group_tags.entry(group_key.clone()).or_default();
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L270-271)
```rust
        let (_, mut invalidated_dependencies) =
            self.data_write_impl::<true>(&group_key, txn_idx, incarnation, values, prev_tags)?;
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L275-285)
```rust
        let mut group_sizes = self.group_sizes.get_mut(&group_key).ok_or_else(|| {
            // Currently, we rely on read-before-write to make sure the group would have
            // been initialized, which would have created an entry in group_sizes. Group
            // being initialized sets up data-structures, such as superset_tags, which
            // is used in write_v2, hence the code invariant error. Note that in read API
            // (fetch_tagged_data) we return Uninitialized / TagNotFound errors, because
            // currently that is a part of expected initialization flow.
            // TODO(BlockSTMv2): when we refactor MVHashMap and group initialization logic,
            // also revisit and address the read-before-write assumption.
            code_invariant_error("Group (sizes) must be initialized to write to")
        })?;
```

**File:** aptos-move/mvhashmap/src/versioned_group_data.rs (L630-633)
```rust
            let superset_tags = self.group_tags.get(group_key).ok_or_else(|| {
                // Due to read-before-write.
                code_invariant_error("Group (tags) must be initialized to write to")
            })?;
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L3114-3114)
```rust
                allow_fallback: true,
```

**File:** aptos-move/block-executor/src/executor.rs (L2576-2597)
```rust
            // If parallel gave us result, return it
            if let Ok(output) = parallel_result {
                return Ok(output);
            }

            if !self.config.local.allow_fallback {
                panic!("Parallel execution failed and fallback is not allowed");
            }

            // All logs from the parallel execution should be cleared and not reported.
            // Clear by re-initializing the speculative logs.
            init_speculative_logs(signature_verified_block.num_txns() + 1);

            // Flush all caches to re-run from the "clean" state.
            module_cache_manager_guard
                .environment()
                .runtime_environment()
                .flush_all_caches();
            module_cache_manager_guard.module_cache_mut().flush();

            info!("parallel execution requiring fallback");
        }
```
