# Audit Report

## Title
Storage Quota Bypass via Metadata Overhead in Quorum Store Batch Persistence

## Summary
The Quorum Store's `QuotaManager` tracks storage quota based only on batch payload size (`num_bytes`), but the actual database writes include additional metadata overhead. This allows malicious validators to exceed storage quota limits by 10-30% through intentionally crafted small batches, potentially causing storage exhaustion on validator nodes.

## Finding Description
The vulnerability exists in the quota accounting mechanism of the Quorum Store batch persistence system. When a batch is persisted, the system performs two size-related operations that are misaligned:

1. **Quota Tracking** (payload only): [1](#0-0) 
   The `update_quota()` call uses `value.num_bytes()` which returns only the payload size.

2. **Actual Database Write** (payload + metadata): [2](#0-1) 
   The database writes the full `PersistedValue<BatchInfoExt>` structure.

The `PersistedValue` structure includes: [3](#0-2) 

When serialized using BCS: [4](#0-3) 

The `BatchInfoExt` metadata adds approximately 120-150 bytes per batch: [5](#0-4) 

**Attack Scenario:**
1. Malicious validator creates many small batches (e.g., 1-2 transactions, ~500-1000 bytes each)
2. Each batch passes quota validation: [6](#0-5) 
3. Quota check uses only payload size, but disk write includes ~130 bytes metadata overhead
4. For 1KB batches: overhead is ~13%; for 500-byte batches: overhead is ~26%
5. With default limits (300,000 batch quota, 300MB db_quota):
   - Expected storage: 300MB
   - Actual storage: 340-390MB (13-30% overflow)
6. Across 100 malicious validators: 4-9GB unexpected storage per node

The size limits are checked before persistence: [7](#0-6) 

However, these checks only validate `batch.num_bytes()` which doesn't include the metadata overhead that gets written to disk.

## Impact Explanation
This issue qualifies as **Medium severity** approaching **High severity**:

**Medium Severity** criteria met:
- State inconsistency requiring intervention (quota tracking vs actual storage)
- Limited resource exhaustion (bounded at 10-30% overflow)

**Approaching High** because it could cause:
- Validator node slowdowns if disk approaches capacity
- Potential node crashes on validators with limited storage headroom
- Denial of service through coordinated storage exhaustion attempts

The impact is bounded by the `batch_quota` limit (300,000 batches) and batch expiration mechanisms, preventing complete unbounded storage exhaustion. However, with multiple malicious validators, the aggregate overflow could be several GB per node, which is significant for validators with tight storage constraints.

## Likelihood Explanation
**Likelihood: Medium-High**

Requirements for exploitation:
- Attacker must be a validator (can create and broadcast batches)
- Must intentionally craft small batches to maximize overhead percentage
- Would be detectable through monitoring ()

However:
- No minimum batch size validation exists
- Attack is straightforward once validator access obtained
- Can be sustained until batch quota exhausted
- Multiple validators can coordinate to amplify impact

## Recommendation
Modify the quota tracking to account for the full serialized size of `PersistedValue`, not just the payload:

```rust
// In batch_store.rs, insert_to_cache method
pub(crate) fn insert_to_cache(
    &self,
    value: &PersistedValue<BatchInfoExt>,
) -> anyhow::Result<bool> {
    // ... existing code ...
    
    // Calculate actual serialized size instead of just payload size
    let actual_size = bcs::serialized_size(value)
        .context("Failed to calculate serialized size")?;
    
    let value_to_be_stored = if self
        .peer_quota
        .entry(author)
        .or_insert(QuotaManager::new(
            self.db_quota,
            self.memory_quota,
            self.batch_quota,
        ))
        .update_quota(actual_size)?  // Use actual_size instead of value.num_bytes()
        == StorageMode::PersistedOnly
    {
        PersistedValue::new(value.batch_info().clone(), None)
    } else {
        value.clone()
    };
    
    // ... rest of existing code ...
}
```

Additionally, consider implementing a minimum batch size threshold to discourage creation of inefficiently small batches.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::transaction::SignedTransaction;
    
    #[test]
    fn test_quota_accounting_mismatch() {
        // Create batch store with limited quota
        let batch_store = batch_store_for_test(1000, 10000, 1000);
        
        // Create many small batches to maximize overhead
        let mut total_payload_size = 0;
        let mut total_actual_size = 0;
        
        for i in 0..100 {
            // Create a small batch with 1 transaction (~500 bytes)
            let txn = create_test_transaction(500);
            let batch_payload = BatchPayload::new(peer_id, vec![txn]);
            let payload_size = batch_payload.num_bytes();
            
            let batch_info = BatchInfoExt::new_v2(
                peer_id,
                BatchId::new_for_test(i),
                epoch,
                expiration,
                batch_payload.hash(),
                1,
                payload_size as u64,
                0,
                BatchKind::PersistedData,
            );
            
            let persisted_value = PersistedValue::new(
                batch_info,
                Some(batch_payload.into_transactions()),
            );
            
            // Calculate sizes
            total_payload_size += payload_size;
            let actual_size = bcs::serialized_size(&persisted_value).unwrap();
            total_actual_size += actual_size;
            
            // Insert to cache (quota tracked by payload_size only)
            batch_store.insert_to_cache(&persisted_value).unwrap();
        }
        
        // Verify mismatch
        let overhead_percentage = 
            ((total_actual_size - total_payload_size) as f64 / total_payload_size as f64) * 100.0;
        
        println!("Total payload size tracked in quota: {} bytes", total_payload_size);
        println!("Total actual serialized size on disk: {} bytes", total_actual_size);
        println!("Overhead: {:.2}%", overhead_percentage);
        
        // Assert that overhead is significant for small batches
        assert!(overhead_percentage > 10.0, 
            "Expected >10% overhead for small batches, got {:.2}%", 
            overhead_percentage);
    }
}
```

## Notes
While this vulnerability allows quota bypass, the impact is bounded by the `batch_quota` limit and batch expiration mechanisms. The issue is most severe when exploited by multiple coordinated malicious validators against nodes with limited storage capacity. Monitoring systems would likely detect the unusual pattern of many small batches before complete storage exhaustion occurs.

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L64-84)
```rust
    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L391-391)
```rust
                .update_quota(value.num_bytes() as usize)?
```

**File:** consensus/src/quorum_store/batch_store.rs (L505-512)
```rust
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
```

**File:** consensus/src/quorum_store/types.rs (L21-25)
```rust
#[derive(Clone, Eq, Deserialize, Serialize, PartialEq, Debug)]
pub struct PersistedValue<T> {
    info: T,
    maybe_payload: Option<Vec<SignedTransaction>>,
}
```

**File:** consensus/src/quorum_store/schema.rs (L68-71)
```rust
impl ValueCodec<BatchV2Schema> for PersistedValue<BatchInfoExt> {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L46-58)
```rust
#[derive(
    Clone, Debug, Deserialize, Serialize, CryptoHasher, BCSCryptoHash, PartialEq, Eq, Hash,
)]
pub struct BatchInfo {
    author: PeerId,
    batch_id: BatchId,
    epoch: u64,
    expiration: u64,
    digest: HashValue,
    num_txns: u64,
    num_bytes: u64,
    gas_bucket_start: u64,
}
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L137-171)
```rust
    fn ensure_max_limits(&self, batches: &[Batch<BatchInfoExt>]) -> anyhow::Result<()> {
        let mut total_txns = 0;
        let mut total_bytes = 0;
        for batch in batches.iter() {
            ensure!(
                batch.num_txns() <= self.max_batch_txns,
                "Exceeds batch txn limit {} > {}",
                batch.num_txns(),
                self.max_batch_txns,
            );
            ensure!(
                batch.num_bytes() <= self.max_batch_bytes,
                "Exceeds batch bytes limit {} > {}",
                batch.num_bytes(),
                self.max_batch_bytes,
            );

            total_txns += batch.num_txns();
            total_bytes += batch.num_bytes();
        }
        ensure!(
            total_txns <= self.max_total_txns,
            "Exceeds total txn limit {} > {}",
            total_txns,
            self.max_total_txns,
        );
        ensure!(
            total_bytes <= self.max_total_bytes,
            "Exceeds total bytes limit: {} > {}",
            total_bytes,
            self.max_total_bytes,
        );

        Ok(())
    }
```
