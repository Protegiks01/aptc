# Audit Report

## Title
Accumulator Proof Size Not Accounted in Response Size Limit - State Sync Response Overflow Vulnerability

## Summary
The `get_transactions_with_proof_by_size()` function in the storage service server implements size-aware chunking to respect `max_response_size` limits. However, it fails to account for the `accumulator_range_proof` size when building responses, allowing the final serialized response to exceed the configured limit by up to ~4KB. This can cause state sync failures, node slowdowns, and network protocol violations. [1](#0-0) 

## Finding Description

The new size-aware chunking implementation iterates through transactions and checks individual item sizes against the response limit. At lines 422-431, it serializes four data components:
- `transaction`
- `info` (TransactionInfo)
- `events`
- `persisted_auxiliary_info` [2](#0-1) 

The code sums these sizes and validates against `max_response_size`. However, **after the collection loop completes**, the function fetches an `accumulator_range_proof` from storage: [3](#0-2) 

This proof contains two vectors of hash values (`left_siblings` and `right_siblings`), each potentially containing up to 63 HashValues (32 bytes each): [4](#0-3) 

The maximum proof size is approximately 4,032 bytes (2 × 63 × 32), plus BCS encoding overhead. **This size is never validated against the `max_response_size` limit.**

The legacy implementation correctly validates the complete response: [5](#0-4) 

The legacy code fetches the complete response (including proof), then calls `check_overflow_network_frame()` to validate the total size. The new implementation omits this critical final validation step.

**Exploitation Path:**
1. Client requests transaction data with a `max_response_size` of 10KB
2. Size-aware chunking accumulates ~9.5KB of transaction data (within limit)
3. Loop completes, accumulator proof of ~3KB is fetched
4. Final response is ~12.5KB - **exceeding the 10KB limit by 2.5KB**
5. No validation catches this overflow
6. Oversized response is sent to the network layer

The same vulnerability exists in `get_transaction_outputs_with_proof_by_size()`: [6](#0-5) 

## Impact Explanation

**High Severity** per Aptos Bug Bounty criteria:

1. **Validator node slowdowns**: Oversized responses can cause increased memory usage, serialization overhead, and network congestion on serving nodes.

2. **API crashes**: Receiving nodes may have strict size limits that cause deserialization failures or connection drops when responses exceed expected sizes.

3. **Significant protocol violations**: The storage service protocol specifies `max_response_size` limits that are contractually violated, breaking client expectations and configuration guarantees.

4. **State sync disruption**: Newly syncing nodes or nodes catching up after downtime may repeatedly fail to sync if responses consistently exceed limits, leading to sync loops and inability to join the network.

5. **Resource exhaustion**: If multiple clients request data simultaneously, oversized responses consume more network bandwidth and memory than provisioned, potentially causing cascading failures.

The network layer has a `MAX_FRAME_SIZE` of 4 MiB: [7](#0-6) 

While oversized responses under 4 MiB may still transmit, they violate the configured `max_response_size` which is typically set to much smaller values (hundreds of KB to few MB) for operational reasons.

## Likelihood Explanation

**High Likelihood:**

1. **Automatic occurrence**: No attacker action required - this happens naturally during normal state sync operations when transaction data approaches the size limit.

2. **Common scenarios**: 
   - Large transaction batches with substantial event data
   - Deep accumulator trees requiring many proof siblings
   - Tightly configured size limits

3. **Affected code paths**: Both `get_transactions_with_proof_by_size()` and `get_transaction_outputs_with_proof_by_size()` are primary state sync endpoints used extensively by syncing nodes.

4. **Configuration-dependent**: More likely when `enable_size_and_time_aware_chunking` is enabled (which is the newer, preferred implementation). [8](#0-7) 

## Recommendation

Add a final size validation step after constructing the complete response, similar to the legacy implementation. The fix should serialize the final response and verify it doesn't exceed `max_response_size`:

```rust
// After creating the transaction_list_with_proof_v2 response (line 504)
let response = TransactionDataWithProofResponse {
    transaction_data_response_type: TransactionDataResponseType::TransactionData,
    transaction_list_with_proof: Some(transaction_list_with_proof_v2),
    transaction_output_list_with_proof: None,
};

// Add final size validation
let (overflow_frame, num_bytes) = 
    check_overflow_network_frame(&response, max_response_size)?;
if overflow_frame && transactions.len() > 1 {
    // Response exceeded limit - retry with fewer transactions
    // Log truncation and recurse with reduced chunk size
    return self.get_transactions_with_proof_by_size(
        proof_version,
        start_version,
        end_version,
        include_events,
        max_response_size,
        use_size_and_time_aware_chunking,
    );
}

Ok(response)
```

Alternatively, pre-calculate and account for the expected proof size before the collection loop, using an estimated maximum proof size based on the transaction range depth.

Apply the same fix to `get_transaction_outputs_with_proof_by_size()` at line 733.

## Proof of Concept

```rust
#[tokio::test]
async fn test_accumulator_proof_size_overflow() {
    use crate::tests::{mock, utils};
    use aptos_config::config::StorageServiceConfig;
    use aptos_types::proof::TransactionAccumulatorRangeProof;
    use aptos_crypto::HashValue;
    
    // Create a scenario where transaction data + proof exceeds limit
    let start_version = 0;
    let num_transactions = 10;
    let end_version = start_version + num_transactions - 1;
    let proof_version = end_version;
    
    // Create large transactions and events
    let mut transaction_list = vec![];
    let mut events_list = vec![];
    for _ in 0..num_transactions {
        transaction_list.push(utils::create_large_transaction());
        events_list.push(vec![utils::create_large_event(); 20]);
    }
    
    // Create a large accumulator proof with maximum siblings
    let max_siblings = 63; // MAX_ACCUMULATOR_PROOF_DEPTH
    let left_siblings: Vec<HashValue> = (0..max_siblings)
        .map(|_| HashValue::random())
        .collect();
    let right_siblings: Vec<HashValue> = (0..max_siblings)
        .map(|_| HashValue::random())
        .collect();
    let large_proof = TransactionAccumulatorRangeProof::new(
        left_siblings,
        right_siblings,
    );
    
    // Set a tight size limit
    let max_response_size = 10_000; // 10KB
    
    let mut db_reader = mock::create_mock_db_reader();
    // Mock the storage to return our test data
    utils::expect_get_transactions_with_large_proof(
        &mut db_reader,
        start_version,
        num_transactions,
        proof_version,
        transaction_list,
        events_list,
        large_proof,
    );
    
    let mut storage_config = StorageServiceConfig::default();
    storage_config.enable_size_and_time_aware_chunking = true;
    
    let storage_reader = StorageReader::new(
        storage_config,
        Arc::new(db_reader),
        TimeService::mock(),
    );
    
    // Call get_transactions_with_proof_by_size
    let response = storage_reader.get_transactions_with_proof(
        proof_version,
        start_version,
        end_version,
        true, // include_events
    ).unwrap();
    
    // Serialize the response to check actual size
    let serialized = bcs::to_bytes(&response).unwrap();
    let actual_size = serialized.len();
    
    // Vulnerability: actual_size exceeds max_response_size
    assert!(
        actual_size > max_response_size,
        "Response size {} exceeds limit {} - vulnerability confirmed",
        actual_size,
        max_response_size
    );
}
```

This PoC demonstrates that when transaction data approaches the size limit and a substantial accumulator proof is added, the final response exceeds the configured `max_response_size`, confirming the vulnerability.

---

**Notes:**

This vulnerability directly breaks the **Resource Limits** invariant (operations must respect size limits) and represents a significant protocol violation in the state sync system. The issue affects core state synchronization functionality and could impact network-wide sync operations, warranting High severity classification.

### Citations

**File:** state-sync/storage-service/server/src/storage.rs (L361-370)
```rust
        // If size and time-aware chunking are disabled, use the legacy implementation
        if !use_size_and_time_aware_chunking {
            return self.get_transactions_with_proof_by_size_legacy(
                proof_version,
                start_version,
                end_version,
                num_transactions_to_fetch,
                include_events,
                max_response_size,
            );
```

**File:** state-sync/storage-service/server/src/storage.rs (L422-431)
```rust
                    let num_transaction_bytes = get_num_serialized_bytes(&transaction)
                        .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
                    let num_info_bytes = get_num_serialized_bytes(&info)
                        .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
                    let num_events_bytes = get_num_serialized_bytes(&events)
                        .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?;
                    let num_auxiliary_info_bytes =
                        get_num_serialized_bytes(&persisted_auxiliary_info).map_err(|error| {
                            Error::UnexpectedErrorEncountered(error.to_string())
                        })?;
```

**File:** state-sync/storage-service/server/src/storage.rs (L434-446)
```rust
                    let total_serialized_bytes = num_transaction_bytes
                        + num_info_bytes
                        + num_events_bytes
                        + num_auxiliary_info_bytes;
                    if response_progress_tracker
                        .data_items_fits_in_response(true, total_serialized_bytes)
                    {
                        transactions.push(transaction);
                        transaction_infos.push(info);
                        transaction_events.push(events);
                        persisted_auxiliary_infos.push(persisted_auxiliary_info);

                        response_progress_tracker.add_data_item(total_serialized_bytes);
```

**File:** state-sync/storage-service/server/src/storage.rs (L474-478)
```rust
        let accumulator_range_proof = self.storage.get_transaction_accumulator_range_proof(
            start_version,
            transactions.len() as u64,
            proof_version,
        )?;
```

**File:** state-sync/storage-service/server/src/storage.rs (L525-542)
```rust
            let transaction_list_with_proof = self.storage.get_transactions(
                start_version,
                num_transactions_to_fetch,
                proof_version,
                include_events,
            )?;
            let response = TransactionDataWithProofResponse {
                transaction_data_response_type: TransactionDataResponseType::TransactionData,
                transaction_list_with_proof: Some(transaction_list_with_proof),
                transaction_output_list_with_proof: None,
            };
            if num_transactions_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
            }

            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&response, max_response_size)?;
```

**File:** state-sync/storage-service/server/src/storage.rs (L700-708)
```rust
        let accumulator_range_proof = if num_fetched_outputs == 0 {
            AccumulatorRangeProof::new_empty() // Return an empty proof if no outputs were fetched
        } else {
            self.storage.get_transaction_accumulator_range_proof(
                start_version,
                num_fetched_outputs as u64,
                proof_version,
            )?
        };
```

**File:** types/src/proof/definition.rs (L576-586)
```rust
pub struct AccumulatorRangeProof<H> {
    /// The siblings on the left of the path from the first leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    left_siblings: Vec<HashValue>,

    /// The sliblings on the right of the path from the last leaf to the root. Siblings are ordered
    /// from the bottom level to the root level.
    right_siblings: Vec<HashValue>,

    phantom: PhantomData<H>,
}
```

**File:** config/src/config/network_config.rs (L49-49)
```rust
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
```
