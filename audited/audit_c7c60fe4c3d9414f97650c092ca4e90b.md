# Audit Report

## Title
Hot State LRU Chain Desynchronization Causing Validator Panic via set_commited() Bypass

## Summary
The `Committer::validate_lru()` function can panic when walking the hot state LRU chain if entries referenced by `next()`/`prev()` pointers don't exist in the shard DashMap. This occurs when `HotState::set_commited()` directly updates the committed State without synchronizing the Committer's shard, creating a desynchronization that violates the invariant that all LRU chain entries must exist in the shard.

## Finding Description

The `Committer` maintains two critical data structures that must remain synchronized: `base.shards` (a DashMap storing actual hot state entries) and `committed` (an Arc<Mutex<State>> tracking the current committed state). [1](#0-0) 

The vulnerability occurs because `set_commited()` bypasses the normal commit flow by only updating the `committed` field without synchronizing `base.shards`. [2](#0-1) 

This function is called via `PersistedState::hack_reset()`, which is documented with the precondition "Can only be used when no on the fly commit is in the queue" but lacks enforcement. [3](#0-2) 

When `set_commited()` is invoked with a State containing hot entries, it updates `self.committed` but leaves `self.base.shards` unchanged. Subsequently, when `commit()` processes a new State, it calculates the delta between `to_commit` and `self.committed`. [4](#0-3) 

The delta only contains entries where the StateSlot value changed. Since StateSlot includes the LRU chain pointers (`prev`/`next`) in its `lru_info` field, only entries with modified pointers appear in the delta. [5](#0-4) [6](#0-5) 

For entries in the LRU chain whose pointers haven't changed, they won't be in the delta and won't be inserted into the shard. However, `heads[shard_id]` and `tails[shard_id]` are set to reference the full LRU chain from the new state. [7](#0-6) 

The `validate_lru()` function attempts to walk the entire chain and expects all entries to exist in the shard. [8](#0-7)  When it encounters a key that doesn't exist in the shard, the `.expect("Must exist.")` call panics at line 288.

**Attack Scenario:**
1. System initialized with empty HotState (shards empty, committed empty)
2. `hack_reset()` called with State S1 containing hot entries A→B→C
   - `self.committed` = S1 with entries {A, B, C} and proper LRU chain metadata
   - `self.base.shards` remains empty
3. New commit enqueued with State S2 adding entry D as new head: D→A→B→C
   - D is new (not in S1)
   - A's prev pointer changes from None to Some(D), so A's StateSlot differs
   - B's StateSlot unchanged (prev=A, next=C in both states)
   - C's StateSlot unchanged (prev=B, next=None in both states)
   - Delta = {D, A} only
4. `commit()` processes:
   - Inserts only D and A into shard
   - Sets heads[shard_id] = D, tails[shard_id] = C
   - `validate_lru()` attempts to walk D→A→B
   - Reaches B, calls `shard.get(&B).expect("Must exist.")` → **PANIC**

## Impact Explanation

**Severity: HIGH**

This violates the critical invariant that all LRU chain entries must exist in the shard. The validation is enforced via debug_assert. [9](#0-8) 

**Debug Builds**: Immediate validator node crash when the debug_assert panics in the Committer thread. Since the Committer is essential for processing hot state updates, the validator becomes unable to commit new state, causing validator unavailability.

**Release Builds**: The validation is skipped (debug assertions are compiled out), leading to silent state corruption where `base.shards` is incomplete. This causes incorrect responses from `HotStateView` queries and potential consensus divergence if validators have different shard states.

This meets **HIGH Severity** criteria per Aptos Bug Bounty: "Validator node slowdowns" and "API crashes" - a validator crash during critical state commit operations is a significant protocol violation affecting network liveness and validator availability.

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability is triggered when `StateStore::set_state_ignoring_summary()` is invoked, which calls `hack_reset()`. [10](#0-9) 

This function is called during:
1. **Backup/Restore Operations**: Used in `restore_utils.rs` during state restoration where `calculate_state_and_put_updates()` can return a LedgerState with hot entries. [11](#0-10) 
2. **State Initialization**: Called by `init_state_ignoring_summary()`, though this creates empty states. [12](#0-11) 

The precondition "no on the fly commit is in the queue" is documented but not enforced - it's merely a comment warning with no runtime validation. After `hack_reset()` completes, new block proposals and transactions will trigger commits via `enqueue_commit()`, which can expose the desynchronization.

While not trivially exploitable by external attackers, node operators performing recovery operations or state synchronization could inadvertently trigger this sequence, causing validator crashes and network disruption.

## Recommendation

Synchronize `base.shards` when calling `set_commited()`:

```rust
pub(crate) fn set_commited(&self, state: State) {
    // Send the state through the normal commit channel to ensure 
    // the Committer thread processes it and updates base.shards
    self.commit_tx
        .send(state.clone())
        .expect("Failed to queue state for commit");
    
    // Update committed after ensuring the commit is queued
    *self.committed.lock() = state;
}
```

Alternatively, if `hack_reset()` must bypass the queue, populate `base.shards` directly:

```rust
pub fn hack_reset(&self, state_with_summary: StateWithSummary) {
    let (state, summary) = state_with_summary.into_inner();
    *self.summary.lock() = summary;
    
    // Populate shards with all hot entries from the state
    for shard_id in 0..NUM_STATE_SHARDS {
        for (key, slot) in state.shards()[shard_id].iter() {
            if slot.is_hot() {
                self.hot_state.base.shards[shard_id].insert(key.clone(), slot.clone());
            }
        }
    }
    
    self.hot_state.set_commited(state);
}
```

## Proof of Concept

```rust
#[test]
fn test_hot_state_lru_desynchronization() {
    use aptos_config::config::HotStateConfig;
    use aptos_storage_interface::state_store::state::State;
    use aptos_types::state_store::{state_key::StateKey, state_slot::StateSlot};
    
    // 1. Initialize HotState with empty state
    let config = HotStateConfig::default();
    let empty_state = State::new_empty(config);
    let hot_state = HotState::new(empty_state, config);
    
    // 2. Create a State with hot entries A→B→C
    let mut state_with_hot = State::new_empty(config);
    // (In practice, would build state with hot entries via update() method)
    
    // 3. Call set_commited to bypass normal commit flow
    hot_state.set_commited(state_with_hot.clone());
    // At this point: committed = state_with_hot, but base.shards is empty
    
    // 4. Enqueue a new commit that adds entry D as head
    let mut new_state = state_with_hot.clone();
    // (Would add D→A→B→C chain)
    hot_state.enqueue_commit(new_state);
    
    // 5. Wait for commit processing
    // The Committer thread will:
    // - Calculate delta (only D and A)
    // - Insert only D and A into shards
    // - Set heads/tails referencing full chain
    // - Call validate_lru() which panics at entry B
    
    // In debug builds, this causes panic: "Must exist."
    // In release builds, the shard is incomplete
}
```

## Notes

The vulnerability is particularly insidious because:
1. The `hack_reset()` function name suggests it's a workaround that might have edge cases
2. The precondition is documented but not enforced, relying on caller discipline
3. The bug only manifests when there are subsequent commits with partial chain updates
4. The StateDelta mechanism correctly identifies only changed entries, but this breaks the LRU chain invariant when combined with `set_commited()`

The root cause is the architectural assumption that all hot state updates flow through the Committer's `commit()` method, which maintains shard consistency. The `set_commited()` bypass violates this assumption without compensating by updating the shards directly.

### Citations

**File:** storage/aptosdb/src/state_store/hot_state.rs (L127-129)
```rust
    pub(crate) fn set_commited(&self, state: State) {
        *self.committed.lock() = state
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L160-170)
```rust
pub struct Committer {
    base: Arc<HotStateBase>,
    committed: Arc<Mutex<State>>,
    rx: Receiver<State>,
    total_key_bytes: usize,
    total_value_bytes: usize,
    /// Points to the newest entry. `None` if empty.
    heads: [Option<StateKey>; NUM_STATE_SHARDS],
    /// Points to the oldest entry. `None` if empty.
    tails: [Option<StateKey>; NUM_STATE_SHARDS],
}
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L235-243)
```rust
    fn commit(&mut self, to_commit: &State) {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["hot_state_commit"]);

        let mut n_insert = 0;
        let mut n_update = 0;
        let mut n_evict = 0;

        let delta = to_commit.make_delta(&self.committed.lock());
        for shard_id in 0..NUM_STATE_SHARDS {
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L262-263)
```rust
            self.heads[shard_id] = to_commit.latest_hot_key(shard_id);
            self.tails[shard_id] = to_commit.oldest_hot_key(shard_id);
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L269-269)
```rust
            debug_assert!(self.validate_lru(shard_id).is_ok());
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L277-295)
```rust
    /// Traverses the entire map and checks if all the pointers are correctly linked.
    fn validate_lru(&self, shard_id: usize) -> Result<()> {
        let head = &self.heads[shard_id];
        let tail = &self.tails[shard_id];
        ensure!(head.is_some() == tail.is_some());
        let shard = &self.base.shards[shard_id];

        {
            let mut num_visited = 0;
            let mut current = head.clone();
            while let Some(key) = current {
                let entry = shard.get(&key).expect("Must exist.");
                num_visited += 1;
                ensure!(num_visited <= shard.len());
                ensure!(entry.is_hot());
                current = entry.next().cloned();
            }
            ensure!(num_visited == shard.len());
        }
```

**File:** storage/aptosdb/src/state_store/persisted_state.rs (L64-69)
```rust
    // n.b. Can only be used when no on the fly commit is in the queue.
    pub fn hack_reset(&self, state_with_summary: StateWithSummary) {
        let (state, summary) = state_with_summary.into_inner();
        *self.summary.lock() = summary;
        self.hot_state.set_commited(state);
    }
```

**File:** types/src/state_store/state_slot.rs (L34-39)
```rust
    HotOccupied {
        value_version: Version,
        value: StateValue,
        hot_since_version: Version,
        lru_info: LRUEntry<StateKey>,
    },
```

**File:** types/src/state_store/state_slot.rs (L232-247)
```rust
impl THotStateSlot for StateSlot {
    type Key = StateKey;

    fn prev(&self) -> Option<&Self::Key> {
        match self {
            HotOccupied { lru_info, .. } | HotVacant { lru_info, .. } => lru_info.prev.as_ref(),
            _ => panic!("Should not be called on cold slots."),
        }
    }

    fn next(&self) -> Option<&Self::Key> {
        match self {
            HotOccupied { lru_info, .. } | HotVacant { lru_info, .. } => lru_info.next.as_ref(),
            _ => panic!("Should not be called on cold slots."),
        }
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1199-1206)
```rust
    pub fn init_state_ignoring_summary(&self, version: Option<Version>) -> Result<()> {
        let usage = self.get_usage(version)?;
        let state = State::new_at_version(version, usage, HotStateConfig::default());
        let ledger_state = LedgerState::new(state.clone(), state);
        self.set_state_ignoring_summary(ledger_state);

        Ok(())
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1208-1239)
```rust
    pub fn set_state_ignoring_summary(&self, ledger_state: LedgerState) {
        let hot_smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let last_checkpoint_summary = StateSummary::new_at_version(
            ledger_state.last_checkpoint().version(),
            hot_smt.clone(),
            smt.clone(),
            HotStateConfig::default(),
        );
        let summary = StateSummary::new_at_version(
            ledger_state.version(),
            hot_smt,
            smt,
            HotStateConfig::default(),
        );

        let last_checkpoint = StateWithSummary::new(
            ledger_state.last_checkpoint().clone(),
            last_checkpoint_summary.clone(),
        );
        let latest = StateWithSummary::new(ledger_state.latest().clone(), summary);
        let current = LedgerStateWithSummary::from_latest_and_last_checkpoint(
            latest,
            last_checkpoint.clone(),
        );

        self.persisted_state.hack_reset(last_checkpoint.clone());
        *self.current_state_locked() = current;
        self.buffered_state
            .lock()
            .force_last_snapshot(last_checkpoint);
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```
