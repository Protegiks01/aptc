# Audit Report

## Title
Faucet Rate Limiting State Pollution via `is_eligible` Dry Run Bypass in MemoryRatelimitChecker

## Summary
The `MemoryRatelimitChecker` in the Aptos faucet incorrectly handles the `dry_run` parameter, causing state pollution in the rate limiting cache when the `is_eligible` endpoint is called. The `get_or_insert_mut` operation inserts IP addresses into the LRU cache before checking the `dry_run` flag, allowing attackers to pollute the rate limiting database and bypass daily request limits.

## Finding Description

The vulnerability exists in the `MemoryRatelimitChecker::check()` method. When `preprocess_request()` is called with `dry_run=true` (via the `is_eligible` endpoint), the checker is supposed to avoid modifying persistent state per the `CheckerTrait` documentation. [1](#0-0) 

However, the implementation violates this contract: [2](#0-1) 

**The Bug:**
At line 77, `get_or_insert_mut(data.source_ip, || 1)` unconditionally inserts the IP address with value 1 into the LRU cache if it doesn't exist, **regardless of the `dry_run` flag**. The dry_run check only occurs later at line 86 to prevent incrementing, but the insertion has already happened.

**Attack Flow:**

1. Attacker calls `POST /is_eligible` endpoint (which sets `dry_run=true`) [3](#0-2) 

2. `preprocess_request()` is called with `dry_run=true` [4](#0-3) 

3. The checker's `check()` method is invoked with `dry_run=true` [5](#0-4) 

4. IP is inserted into cache with value 1, even though no actual funding occurred

**Exploitation Scenarios:**

**Scenario 1 - Off-by-One Counter Pollution:**
- Attacker calls `is_eligible` from IP X (not in cache)
- IP X is inserted with count=1 
- Later, IP X makes a legitimate funding request
- Counter shows 2 after first real request (should be 1)
- User reaches limit one request early

**Scenario 2 - LRU Cache Eviction Attack:**
- MemoryRatelimitChecker uses LRU cache with configurable size limit (default 1M entries) [6](#0-5) 

- Attacker floods `is_eligible` with requests from different IPs
- Each request inserts that IP into the cache
- When cache is full, oldest entries are evicted
- Legitimate rate-limited IPs get evicted, resetting their counters
- Those IPs can now make new requests beyond their daily limit

**Scenario 3 - Targeted Reset:**
- Attacker identifies rate-limited IPs (their own or coordinated attack)
- Floods cache with dummy IPs via `is_eligible`
- Forces eviction of target IPs
- Target IPs can now bypass rate limits

**Contrast with RedisRatelimitChecker:**
The Redis implementation correctly handles `dry_run`: [7](#0-6) 

Redis only performs read operations until the `dry_run` check at line 263, and only increments the counter if `!dry_run`.

## Impact Explanation

**Severity: Medium to High**

This vulnerability allows bypassing faucet rate limiting mechanisms, which can result in:

1. **Limited Funds Loss** (Medium): Attackers can drain faucet funds faster than intended by bypassing daily limits through cache pollution
2. **API Service Degradation** (High): Cache pollution attacks can degrade faucet service for legitimate users by evicting their rate limiting data
3. **Resource Exhaustion**: Filling the LRU cache with dummy entries wastes memory

Per Aptos bug bounty criteria:
- **Medium Severity** ($10,000): "Limited funds loss or manipulation" - faucet funds can be manipulated through rate limit bypass
- **High Severity** ($50,000): "API crashes" / "Significant protocol violations" - if cache pollution causes service degradation

The faucet is an auxiliary service, not core blockchain infrastructure, so this does not affect consensus, Move VM, or state management. However, it undermines the security guarantees of the faucet rate limiting system.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is:
- **Easy to exploit**: Requires only HTTP requests to a public endpoint
- **Low barrier**: No authentication or special access needed
- **Automatable**: Can be scripted to run continuously
- **Scalable**: Attackers with botnets/proxies can rotate IPs easily
- **Subtle**: Victims may not notice gradual counter inflation

The attack is already possible if MemoryRatelimitChecker is deployed in production faucets.

## Recommendation

**Fix the MemoryRatelimitChecker to respect the `dry_run` flag:**

```rust
async fn check(
    &self,
    data: CheckerData,
    dry_run: bool,
) -> Result<Vec<RejectionReason>, AptosTapError> {
    self.clear_if_new_day().await;

    let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;

    // FIX: Only insert/modify cache if not dry_run
    if dry_run {
        // Read-only check during dry run
        let requests_today = ip_to_requests_today.peek(&data.source_ip).unwrap_or(&0);
        if *requests_today >= self.max_requests_per_day {
            return Ok(vec![RejectionReason::new(
                format!(
                    "IP {} has exceeded the daily limit of {} requests",
                    data.source_ip, self.max_requests_per_day
                ),
                RejectionReasonCode::UsageLimitExhausted,
            )]);
        }
    } else {
        // Normal path: insert and increment
        let requests_today = ip_to_requests_today.get_or_insert_mut(data.source_ip, || 1);
        if *requests_today >= self.max_requests_per_day {
            return Ok(vec![RejectionReason::new(
                format!(
                    "IP {} has exceeded the daily limit of {} requests",
                    data.source_ip, self.max_requests_per_day
                ),
                RejectionReasonCode::UsageLimitExhausted,
            )]);
        }
        *requests_today += 1;
    }

    Ok(vec![])
}
```

**Key changes:**
1. Use `peek()` for read-only access during dry_run (doesn't modify cache)
2. Only call `get_or_insert_mut()` when `!dry_run`
3. Separate logic paths ensure no state modification during dry runs

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use std::net::IpAddr;
    use std::str::FromStr;
    use poem::http::HeaderMap;
    use std::sync::Arc;
    
    #[tokio::test]
    async fn test_dry_run_state_pollution() {
        // Create checker with max 5 requests per day
        let config = MemoryRatelimitCheckerConfig {
            max_requests_per_day: 5,
            max_entries_in_map: NonZeroUsize::new(100).unwrap(),
        };
        let checker = MemoryRatelimitChecker::new(config);
        
        let test_ip = IpAddr::from_str("1.2.3.4").unwrap();
        let checker_data = CheckerData {
            receiver: AccountAddress::from_hex_literal("0x1").unwrap(),
            source_ip: test_ip,
            headers: Arc::new(HeaderMap::new()),
            time_request_received_secs: get_current_time_secs(),
        };
        
        // Call check with dry_run=true (simulating is_eligible)
        let result = checker.check(checker_data.clone(), true).await.unwrap();
        assert!(result.is_empty(), "Should not reject on first dry run");
        
        // BUG: Check if IP was inserted into cache during dry_run
        let cache = checker.ip_to_requests_today.lock().await;
        let count = cache.peek(&test_ip);
        
        // VULNERABILITY: IP should NOT be in cache after dry_run, but it is!
        assert!(count.is_some(), "BUG: IP was inserted during dry_run");
        assert_eq!(*count.unwrap(), 1, "BUG: IP has count 1 after dry_run");
        
        drop(cache);
        
        // Now make a real funding request (dry_run=false)
        let result = checker.check(checker_data.clone(), false).await.unwrap();
        assert!(result.is_empty(), "Should not reject on first real request");
        
        // Check counter after real request
        let cache = checker.ip_to_requests_today.lock().await;
        let count = cache.peek(&test_ip).unwrap();
        
        // VULNERABILITY: Counter is 2, but only 1 real request was made!
        assert_eq!(*count, 2, "BUG: Counter is 2 after 1 real request + 1 dry run");
        
        println!("VULNERABILITY CONFIRMED:");
        println!("- dry_run call inserted IP with count=1");
        println!("- Real funding request incremented to count=2");
        println!("- User will hit rate limit 1 request early");
    }
    
    #[tokio::test]
    async fn test_cache_eviction_attack() {
        // Create small cache to demonstrate eviction
        let config = MemoryRatelimitCheckerConfig {
            max_requests_per_day: 5,
            max_entries_in_map: NonZeroUsize::new(3).unwrap(), // Small cache
        };
        let checker = MemoryRatelimitChecker::new(config);
        
        // Insert legitimate IP that has hit rate limit
        let legit_ip = IpAddr::from_str("10.0.0.1").unwrap();
        let legit_data = CheckerData {
            receiver: AccountAddress::from_hex_literal("0x1").unwrap(),
            source_ip: legit_ip,
            headers: Arc::new(HeaderMap::new()),
            time_request_received_secs: get_current_time_secs(),
        };
        
        // Exhaust limit for legitimate IP
        for _ in 0..5 {
            checker.check(legit_data.clone(), false).await.unwrap();
        }
        
        // Verify IP is rate limited
        let result = checker.check(legit_data.clone(), false).await.unwrap();
        assert!(!result.is_empty(), "Legitimate IP should be rate limited");
        
        // ATTACK: Flood with dry_run requests from different IPs
        for i in 1..=5 {
            let attack_ip = IpAddr::from_str(&format!("20.0.0.{}", i)).unwrap();
            let attack_data = CheckerData {
                receiver: AccountAddress::from_hex_literal("0x1").unwrap(),
                source_ip: attack_ip,
                headers: Arc::new(HeaderMap::new()),
                time_request_received_secs: get_current_time_secs(),
            };
            // Use is_eligible (dry_run=true) to pollute cache
            checker.check(attack_data, true).await.unwrap();
        }
        
        // VULNERABILITY: Legitimate IP was evicted from LRU cache
        let cache = checker.ip_to_requests_today.lock().await;
        let legit_count = cache.peek(&legit_ip);
        
        if legit_count.is_none() {
            println!("CACHE EVICTION ATTACK SUCCESSFUL:");
            println!("- Legitimate rate-limited IP was evicted");
            println!("- Attacker can now make requests from that IP again");
            println!("- Rate limiting has been bypassed");
        }
        
        drop(cache);
        
        // Legitimate IP can now make requests again (rate limit bypassed!)
        let result = checker.check(legit_data.clone(), false).await.unwrap();
        // This may or may not be empty depending on eviction, but demonstrates the issue
        println!("After eviction attack, rate limit check result: {:?}", result);
    }
}
```

**Notes:**
- This vulnerability only affects `MemoryRatelimitChecker`, not `RedisRatelimitChecker` which correctly handles dry_run
- The `is_eligible` endpoint never calls `complete()` on checkers, so the state pollution persists
- Attackers can exploit this with simple HTTP requests to a public endpoint
- The fix requires using read-only operations (`peek()`) during dry_run checks

### Citations

**File:** crates/aptos-faucet/core/src/checkers/mod.rs (L45-47)
```rust
    /// Returns a list of rejection reasons for the request, if any. If dry_run
    /// is set, if this Checker would store anything based on the request, it
    /// instead will not. This is useful for the is_eligible endpoint.
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L31-42)
```rust
pub struct MemoryRatelimitChecker {
    pub max_requests_per_day: u32,

    /// Map of IP to how many requests they've submitted today (where the
    /// response wasn't a 500). To avoid OOMing the server, we set a limit
    /// on how many entries we have in the table.
    pub ip_to_requests_today: Mutex<LruCache<IpAddr, u32>>,

    /// Used for tracking daily ratelimit. See the comment in RedisRatelimitChecker
    /// for more information on how we track daily limits.
    pub current_day: AtomicU64,
}
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L68-91)
```rust
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        self.clear_if_new_day().await;

        let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;

        let requests_today = ip_to_requests_today.get_or_insert_mut(data.source_ip, || 1);
        if *requests_today >= self.max_requests_per_day {
            return Ok(vec![RejectionReason::new(
                format!(
                    "IP {} has exceeded the daily limit of {} requests",
                    data.source_ip, self.max_requests_per_day
                ),
                RejectionReasonCode::UsageLimitExhausted,
            )]);
        } else if !dry_run {
            *requests_today += 1;
        }

        Ok(vec![])
    }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L133-166)
```rust
    async fn is_eligible(
        &self,
        fund_request: Json<FundRequest>,
        asset: poem_openapi::param::Query<Option<String>>,
        // This automagically uses FromRequest to get this data from the request.
        // It takes into things like X-Forwarded-IP and X-Real-IP.
        source_ip: RealIp,
        // Same thing, this uses FromRequest.
        header_map: &HeaderMap,
    ) -> poem::Result<(), AptosTapErrorResponse> {
        let (checker_data, bypass, _semaphore_permit) = self
            .components
            .preprocess_request(&fund_request.0, source_ip, header_map, true)
            .await?;

        if bypass {
            return Ok(());
        }

        // Call Funder.fund with `check_only` set, meaning it only does the
        // initial set of checks without actually submitting any transactions
        // to fund the account. Pass asset directly, funder will use its configured default if None.
        self.components
            .funder
            .fund(
                fund_request.amount,
                checker_data.receiver,
                asset.0,
                true,
                bypass,
            )
            .await?;

        Ok(())
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L197-203)
```rust
    async fn preprocess_request(
        &self,
        fund_request: &FundRequest,
        source_ip: RealIp,
        header_map: &HeaderMap,
        dry_run: bool,
    ) -> poem::Result<(CheckerData, bool, Option<SemaphorePermit<'_>>), AptosTapError> {
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L264-266)
```rust
            rejection_reasons.extend(checker.check(checker_data.clone(), dry_run).await.map_err(
                |e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError),
            )?);
```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L226-263)
```rust
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        let mut conn = self
            .get_redis_connection()
            .await
            .map_err(|e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::StorageError))?;

        // Generate a key corresponding to this identifier and the current day.
        let key_prefix = self.ratelimit_key_provider.ratelimit_key_prefix();
        let key_value = self
            .ratelimit_key_provider
            .ratelimit_key_value(&data)
            .await?;
        let (key, seconds_until_next_day) =
            self.get_key_and_secs_until_next_day(key_prefix, &key_value);

        // Get the value for the key, indicating how many non-500 requests we have
        // serviced for it today.
        let limit_value: Option<i64> = conn.get(&key).await.map_err(|e| {
            AptosTapError::new_with_error_code(
                format!("Failed to get value for redis key {}: {}", key, e),
                AptosTapErrorCode::StorageError,
            )
        })?;

        // If the limit value is greater than what we allow per day, signal that we
        // should reject this request.
        if let Some(rejection_reason) = self.check_limit_value(limit_value, seconds_until_next_day)
        {
            return Ok(vec![rejection_reason]);
        }

        // Atomically increment the counter for the given key, creating it and setting
        // the expiration time if it doesn't already exist.
        if !dry_run {
```
