# Audit Report

## Title
Unvalidated Timestamp Manipulation in IndexerGRPC Enables Service Disruption and Incorrect Routing

## Summary
The `StreamProgressSampleProto` struct accepts timestamps without validation, allowing malicious data services to send far future or past timestamp values via `HeartbeatRequest` messages. This causes incorrect progress tracking, division-by-zero errors in throughput calculations, and manipulation of service staleness checks that can lead to denial of service through incorrect service routing.

## Finding Description

The indexer gRPC system uses `StreamProgressSampleProto` messages to track stream progress and calculate throughput metrics. These messages contain a `timestamp` field that is never validated when received through the `HeartbeatRequest` endpoint. [1](#0-0) 

When a data service sends a heartbeat, the `GrpcManagerService` receives it without authentication or validation: [2](#0-1) 

The handler passes the data to `MetadataManager` which stores it without any timestamp validation: [3](#0-2) 

This stored data is then used in two critical ways:

**1. Service Staleness Determination**: The `is_stale_timestamp` function determines if a service should be removed from the active pool: [4](#0-3) 

**Attack Scenario 1 - Service Persistence**: If an attacker sends a far future timestamp (e.g., year 9999), the `saturating_sub` operation returns 0 staleness, preventing the service from ever being marked as unreachable even if it's actually down.

**Attack Scenario 2 - Service Removal**: If an attacker controls a legitimate data service and sends far past timestamps (e.g., year 1970 or negative values for pre-1970), the service gets immediately marked as stale and removed from the active pool: [5](#0-4) 

**2. Throughput Calculations**: The status page uses these timestamps to calculate transactions per second and bytes per second: [6](#0-5) 

**Attack Scenario 3 - Division by Zero**: If an attacker sends multiple samples with identical timestamps, `time_diff` becomes 0, leading to division by zero when calculating `tps` and `bps`, causing the status page to crash or display NaN/Infinity values.

**Attack Scenario 4 - Incorrect Service Selection**: The manager uses timestamp staleness to select which services to route requests to. Manipulated timestamps cause incorrect routing, directing clients to dead services or away from healthy ones. [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per the Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: The metadata manager's service registry becomes corrupted, requiring manual intervention to restore correct routing
- **API crashes**: The status page can crash due to division by zero or invalid timestamp parsing
- Incorrect service routing degrades indexer API availability and reliability

While this does not affect consensus, execution, or blockchain state directly, the indexer gRPC infrastructure is critical for external applications and monitoring tools that depend on reliable transaction data access.

## Likelihood Explanation

**Likelihood: High**

The attack requires:
1. Ability to send gRPC messages to the manager (any registered data service can do this)
2. Crafting a `HeartbeatRequest` with manipulated timestamps (trivial with standard protobuf libraries)
3. No authentication or authorization checks exist

Any compromised or malicious data service can exploit this immediately. The attack is:
- **Easy to execute**: Simple protobuf message construction
- **Hard to detect**: Appears as normal heartbeat traffic
- **Persistent**: Manipulated data stays in the system until services are restarted

## Recommendation

Add timestamp validation in the `handle_live_data_service_info` and `handle_historical_data_service_info` functions:

```rust
fn validate_timestamp(timestamp: &Timestamp) -> bool {
    // Timestamp seconds must be reasonable (between 2020 and 2100 for current use)
    const MIN_TIMESTAMP_SECS: i64 = 1577836800; // 2020-01-01
    const MAX_TIMESTAMP_SECS: i64 = 4102444800; // 2100-01-01
    
    if timestamp.seconds < MIN_TIMESTAMP_SECS || timestamp.seconds > MAX_TIMESTAMP_SECS {
        return false;
    }
    
    // Nanos must be in valid range
    if timestamp.nanos < 0 || timestamp.nanos > 999_999_999 {
        return false;
    }
    
    true
}

fn handle_live_data_service_info(
    &self,
    address: GrpcAddress,
    mut info: LiveDataServiceInfo,
) -> Result<()> {
    // Validate timestamp before processing
    if let Some(ref timestamp) = info.timestamp {
        if !validate_timestamp(timestamp) {
            bail!("Invalid timestamp in heartbeat: {:?}", timestamp);
        }
    }
    
    // Validate timestamps in stream progress samples
    if let Some(ref stream_info) = info.stream_info {
        for active_stream in &stream_info.active_streams {
            if let Some(ref progress) = active_stream.progress {
                for sample in &progress.samples {
                    if let Some(ref ts) = sample.timestamp {
                        if !validate_timestamp(ts) {
                            bail!("Invalid timestamp in stream sample: {:?}", ts);
                        }
                    }
                }
            }
        }
    }
    
    // Rest of existing logic...
}
```

Additionally, add safe division in `get_throughput_from_samples`:

```rust
if time_diff < 0.001 {  // Minimum 1ms difference
    return "Insufficient data".to_string();
}
```

## Proof of Concept

```rust
// PoC: Send malicious HeartbeatRequest with far future timestamp
use aptos_protos::indexer::v1::{
    HeartbeatRequest, ServiceInfo, LiveDataServiceInfo,
    StreamInfo, ActiveStream, StreamProgress, StreamProgressSampleProto,
    service_info::Info,
};
use aptos_protos::util::timestamp::Timestamp;

#[tokio::test]
async fn test_timestamp_manipulation_attack() {
    // Create malicious timestamp (far future: year 9999)
    let far_future_timestamp = Timestamp {
        seconds: 253402300799, // 9999-12-31 23:59:59
        nanos: 0,
    };
    
    // Create stream progress with manipulated timestamps
    let malicious_samples = vec![
        StreamProgressSampleProto {
            timestamp: Some(far_future_timestamp),
            version: 1000,
            size_bytes: 50000,
        },
    ];
    
    let active_stream = ActiveStream {
        id: "malicious_stream".to_string(),
        start_time: Some(far_future_timestamp),
        start_version: 0,
        end_version: None,
        progress: Some(StreamProgress {
            samples: malicious_samples,
        }),
    };
    
    let service_info = ServiceInfo {
        address: Some("http://malicious-service:50051".to_string()),
        info: Some(Info::LiveDataServiceInfo(LiveDataServiceInfo {
            chain_id: 1,
            timestamp: Some(far_future_timestamp),
            known_latest_version: Some(1000),
            stream_info: Some(StreamInfo {
                active_streams: vec![active_stream],
            }),
            min_servable_version: Some(0),
        })),
    };
    
    let request = HeartbeatRequest {
        service_info: Some(service_info),
    };
    
    // Send this request to the GrpcManager - it will be accepted without validation
    // Result: The service will never be marked as stale due to far future timestamp
    // The status page will fail to calculate throughput correctly
}
```

**Notes**

This vulnerability is limited to the indexer gRPC infrastructure and does not affect core blockchain consensus, execution, or state. However, it represents a significant availability and reliability issue for applications depending on the indexer API. The lack of input validation on timestamp fields is a clear violation of defensive programming principles and enables multiple attack vectors including service disruption, incorrect routing, and monitoring system corruption.

### Citations

**File:** protos/rust/src/pb/aptos.indexer.v1.rs (L160-167)
```rust
pub struct StreamProgressSampleProto {
    #[prost(message, optional, tag="1")]
    pub timestamp: ::core::option::Option<super::super::util::timestamp::Timestamp>,
    #[prost(uint64, tag="2")]
    pub version: u64,
    #[prost(uint64, tag="3")]
    pub size_bytes: u64,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/service.rs (L71-88)
```rust
    fn pick_live_data_service(&self, starting_version: u64) -> Option<String> {
        let mut candidates = vec![];
        for candidate in self.metadata_manager.get_live_data_services_info() {
            if let Some(info) = candidate.1.back().as_ref() {
                // TODO(grao): Handle the case when the requested starting version is beyond the
                // latest version.
                if info.min_servable_version.is_none()
                    || starting_version < info.min_servable_version.unwrap()
                {
                    continue;
                }
                let num_active_streams = info.stream_info.as_ref().unwrap().active_streams.len();
                candidates.push((candidate.0, num_active_streams));
            }
        }

        Self::pick_data_service_from_candidate(candidates)
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/service.rs (L110-127)
```rust
    async fn heartbeat(
        &self,
        request: Request<HeartbeatRequest>,
    ) -> Result<Response<HeartbeatResponse>, Status> {
        let request = request.into_inner();
        if let Some(service_info) = request.service_info {
            if let Some(address) = service_info.address {
                if let Some(info) = service_info.info {
                    return self
                        .handle_heartbeat(address, info)
                        .await
                        .map_err(|e| Status::internal(format!("Error handling heartbeat: {e}")));
                }
            }
        }

        Err(Status::invalid_argument("Bad request."))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L167-173)
```rust
    fn is_stale_timestamp(timestamp: Timestamp, threshold: Duration) -> bool {
        let timestamp_since_epoch = Duration::new(timestamp.seconds as u64, timestamp.nanos as u32);
        let now_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
        let staleness = now_since_epoch.saturating_sub(timestamp_since_epoch);

        staleness >= threshold
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L217-228)
```rust
                for kv in &self.live_data_services {
                    let (address, live_data_service) = kv.pair();
                    let unreachable = live_data_service.recent_states.back().is_some_and(|s| {
                        Self::is_stale_timestamp(
                            s.timestamp.unwrap_or_default(),
                            Duration::from_secs(60),
                        )
                    });
                    if unreachable {
                        unreachable_live_data_services.push(address.clone());
                        continue;
                    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L489-508)
```rust
    fn handle_live_data_service_info(
        &self,
        address: GrpcAddress,
        mut info: LiveDataServiceInfo,
    ) -> Result<()> {
        let mut entry = self
            .live_data_services
            .entry(address.clone())
            .or_insert(LiveDataService::new(address));
        if info.stream_info.is_none() {
            info.stream_info = Some(StreamInfo {
                active_streams: vec![],
            });
        }
        entry.value_mut().recent_states.push_back(info);
        if entry.value().recent_states.len() > MAX_NUM_OF_STATES_TO_KEEP {
            entry.value_mut().recent_states.pop_front();
        }

        Ok(())
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/status_page/mod.rs (L85-117)
```rust
pub fn get_throughput_from_samples(
    progress: Option<&StreamProgress>,
    duration: Duration,
) -> String {
    if let Some(progress) = progress {
        let now = SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .unwrap()
            .as_secs_f64();
        let index = progress.samples.partition_point(|p| {
            let diff = now - timestamp_to_unixtime(p.timestamp.as_ref().unwrap());
            diff > duration.as_secs_f64()
        });

        // Need 2 sample points for calculation.
        // TODO(grao): Consider doing interpolation here.
        if index + 1 < progress.samples.len() {
            let sample_a = progress.samples[index];
            let sample_b = progress.samples.last().unwrap();
            let time_diff = timestamp_to_unixtime(sample_b.timestamp.as_ref().unwrap())
                - timestamp_to_unixtime(sample_a.timestamp.as_ref().unwrap());
            let tps = (sample_b.version - sample_a.version) as f64 / time_diff;
            let bps = (sample_b.size_bytes - sample_a.size_bytes) as f64 / time_diff;
            return format!(
                "{} tps, {} / s",
                tps as u64,
                bytesize::to_string(bps as u64, /*si_prefix=*/ false)
            );
        }
    }

    "No data".to_string()
}
```
