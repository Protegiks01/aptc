Audit Report

## Title
Missing State Commitment (Merkle Tree Root) Verification in `replay_on_archive.rs::execute_and_verify` Enables State Corruption to Go Undetected

## Summary
The `execute_and_verify()` function in `storage/db-tool/src/replay_on_archive.rs` only validates transaction-level outputs (such as write sets, events, and gas usage) and does not verify the state root commitment (`state_checkpoint_hash`) for each transaction or chunk. This omission allows inconsistencies in the global state Merkle tree (e.g., Jellyfish Merkle Tree) to go undetected during archive/database replay, potentially enabling latent corruption or non-determinism in state computation without detection by the tool.

## Finding Description
`execute_and_verify()` calls `execute_block()` and checks transaction output fields (status, gas, writeset, event root), but it does NOT verify that the resulting `state_checkpoint_hash` (Merkle root commitment to the entire state after a transaction or chunk) matches what is present on-chain. As a result, if the Jellyfish Merkle Tree is incorrectly updated due to a bug, or if state sync has caused corruption in the database, this tool would falsely report the data as valid so long as the transaction outputs are correct.

This leads to a severe break in the core invariant that state transitions must be provably correct and that the resulting state root must match for all honest nodes. If a critical bug or state divergence exists, incident responders or operators using this replay tool would not detect the error, leading to long-term undetected state corruption or dangerous recovery attempts from an inconsistent node.

## Impact Explanation
**Severity:** High (per bounty rubric: "Significant protocol violations," "state inconsistencies requiring intervention")
- Silent database corruption or non-deterministic state computation can propagate as the replay tool is often used for verification after failures, state sync, or during forensics/incident response.
- Could allow broken consensus invariants (divergent state roots) to propagate under the illusion of correctness.
- Undetected Merkle root errors facilitate state proof failures and prevent correct node restoration, potentially requiring non-soft-fork interventions.

## Likelihood Explanation
Moderate to High in a real-world incident:
- While this is not directly triggerable by a remote attacker (affecting only local or archive verification), it is a critical blind spot for correct node operation and disaster recovery.
- Bugs in Merkle computation, non-deterministic state storage, or unreported state sync issues become invisible.
- Node operators, auditors, and core maintainers would have a false sense of trust in replay results, rendering detection of some critical classes of bugs impossible.

## Recommendation
- Extend `execute_and_verify()` to also recompute the state root commitment for each corresponding `state_checkpoint_hash` and compare it against the on-chain values (as available from `TransactionInfo`).
- For every transaction with a checkpoint, independently compute the Jellyfish Merkle root after applying the write set in the same order and cross-check against on-chain data. If a mismatch is detected, raise a clear error.
- Add explicit documentation to clarify the coverage and guarantees of the replay tool.

## Proof of Concept
1. Introduce a bug in the Merkle tree code such that `state_checkpoint_hash` is incorrectly calculated, while the write sets and events remain correct.
2. Use the db-tool with the current `execute_and_verify()` on an affected node.
3. Observe that the tool reports all transactions as valid despite divergent state roots.

**No code reproduction is necessary as the current implementation clearly omits any check on `state_checkpoint_hash`.** [1](#0-0) 

---

## Notes
- The current implementation of `execute_and_verify()` only checks transaction outputs using `ensure_match_transaction_info`, which compares status, gas, write set hash, and event root hashâ€”but NOT the state root/Merkle tree commitment (`state_checkpoint_hash`) present in `TransactionInfo` (which is optional but crucial for integrity at checkpoints). This is a clear and complete gap in replay coverage.
- No other code path or indirect action in this tool triggers state checkpoint hash verification.
- This is not a direct consensus vulnerability or remote exploit, but is a critical tool-level flaw with high impact on recovery/fork detection, integrity validation, and post-incident response. [2](#0-1) [3](#0-2) 
<|diff_marker|> ADD A1000

### Citations

**File:** storage/db-tool/src/replay_on_archive.rs (L351-417)
```rust
    fn execute_and_verify(
        &self,
        executor: &AptosVMBlockExecutor,
        current_version: &mut Version,
        cur_txns: &mut Vec<Transaction>,
        cur_persisted_aux_info: &mut Vec<PersistedAuxiliaryInfo>,
        expected_txn_infos: &mut Vec<TransactionInfo>,
        expected_events: &mut Vec<Vec<ContractEvent>>,
        expected_writesets: &mut Vec<WriteSet>,
    ) -> Result<Option<Error>> {
        if cur_txns.is_empty() {
            return Ok(None);
        }
        let txns = cur_txns
            .iter()
            .map(|txn| SignatureVerifiedTransaction::from(txn.clone()))
            .collect::<Vec<_>>();
        let txns_provider = DefaultTxnProvider::new(
            txns,
            cur_persisted_aux_info
                .iter()
                .map(|info| AuxiliaryInfo::new(*info, None))
                .collect(),
        );
        let executed_outputs = executor
            .execute_block(
                &txns_provider,
                &self
                    .arc_db
                    .state_view_at_version(current_version.checked_sub(1))?,
                BlockExecutorConfigFromOnchain::new_no_block_limit(),
                TransactionSliceMetadata::Chunk {
                    begin: *current_version,
                    end: *current_version + cur_txns.len() as u64,
                },
            )
            .map(BlockOutput::into_transaction_outputs_forced)?;
        assert_eq!(executed_outputs.len(), cur_txns.len());

        for idx in 0..cur_txns.len() {
            let version = *current_version;
            *current_version += 1;

            if let Err(err) = executed_outputs[idx].ensure_match_transaction_info(
                version,
                &expected_txn_infos[idx],
                Some(&expected_writesets[idx]),
                Some(&expected_events[idx]),
            ) {
                cur_txns.drain(0..idx + 1);
                cur_persisted_aux_info.drain(0..idx + 1);
                expected_txn_infos.drain(0..idx + 1);
                expected_events.drain(0..idx + 1);
                expected_writesets.drain(0..idx + 1);

                return Ok(Some(err));
            }
        }

        cur_txns.clear();
        cur_persisted_aux_info.clear();
        expected_txn_infos.clear();
        expected_events.clear();
        expected_writesets.clear();

        Ok(None)
    }
```

**File:** types/src/transaction/mod.rs (L1869-1928)
```rust
    pub fn ensure_match_transaction_info(
        &self,
        version: Version,
        txn_info: &TransactionInfo,
        expected_write_set: Option<&WriteSet>,
        expected_events: Option<&[ContractEvent]>,
    ) -> Result<()> {
        const ERR_MSG: &str = "TransactionOutput does not match TransactionInfo";

        let expected_txn_status: TransactionStatus = txn_info.status().clone().into();
        ensure!(
            self.status() == &expected_txn_status,
            "{}: version:{}, status:{:?}, auxiliary data:{:?}, expected:{:?}",
            ERR_MSG,
            version,
            self.status(),
            self.auxiliary_data(),
            expected_txn_status,
        );

        ensure!(
            self.gas_used() == txn_info.gas_used(),
            "{}: version:{}, gas_used:{:?}, expected:{:?}",
            ERR_MSG,
            version,
            self.gas_used(),
            txn_info.gas_used(),
        );

        let write_set_hash = CryptoHash::hash(self.write_set());
        ensure!(
            write_set_hash == txn_info.state_change_hash(),
            "{}: version:{}, write_set_hash:{:?}, expected:{:?}, write_set: {:?}, expected(if known): {:?}",
            ERR_MSG,
            version,
            write_set_hash,
            txn_info.state_change_hash(),
            self.write_set,
            expected_write_set,
        );

        let event_hashes = self
            .events()
            .iter()
            .map(CryptoHash::hash)
            .collect::<Vec<_>>();
        let event_root_hash = InMemoryEventAccumulator::from_leaves(&event_hashes).root_hash;
        ensure!(
            event_root_hash == txn_info.event_root_hash(),
            "{}: version:{}, event_root_hash:{:?}, expected:{:?}, events: {:?}, expected(if known): {:?}",
            ERR_MSG,
            version,
            event_root_hash,
            txn_info.event_root_hash(),
            self.events(),
            expected_events,
        );

        Ok(())
    }
```

**File:** types/src/transaction/mod.rs (L2025-2110)
```rust
pub struct TransactionInfoV0 {
    /// The amount of gas used.
    gas_used: u64,

    /// The vm status. If it is not `Executed`, this will provide the general error class. Execution
    /// failures and Move abort's receive more detailed information. But other errors are generally
    /// categorized with no status code or other information
    status: ExecutionStatus,

    /// The hash of this transaction.
    transaction_hash: HashValue,

    /// The root hash of Merkle Accumulator storing all events emitted during this transaction.
    event_root_hash: HashValue,

    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,

    /// The root hash of the Sparse Merkle Tree describing the world state at the end of this
    /// transaction. Depending on the protocol configuration, this can be generated periodical
    /// only, like per block.
    state_checkpoint_hash: Option<HashValue>,

    /// The hash value summarizing PersistedAuxiliaryInfo.
    auxiliary_info_hash: Option<HashValue>,
}

impl TransactionInfoV0 {
    pub fn new(
        transaction_hash: HashValue,
        state_change_hash: HashValue,
        event_root_hash: HashValue,
        state_checkpoint_hash: Option<HashValue>,
        gas_used: u64,
        status: ExecutionStatus,
        auxiliary_info_hash: Option<HashValue>,
    ) -> Self {
        Self {
            gas_used,
            status,
            transaction_hash,
            event_root_hash,
            state_change_hash,
            state_checkpoint_hash,
            auxiliary_info_hash,
        }
    }

    pub fn transaction_hash(&self) -> HashValue {
        self.transaction_hash
    }

    pub fn state_change_hash(&self) -> HashValue {
        self.state_change_hash
    }

    pub fn has_state_checkpoint_hash(&self) -> bool {
        self.state_checkpoint_hash().is_some()
    }

    pub fn state_checkpoint_hash(&self) -> Option<HashValue> {
        self.state_checkpoint_hash
    }

    pub fn auxiliary_info_hash(&self) -> Option<HashValue> {
        self.auxiliary_info_hash
    }

    pub fn ensure_state_checkpoint_hash(&self) -> Result<HashValue> {
        self.state_checkpoint_hash
            .ok_or_else(|| format_err!("State checkpoint hash not present in TransactionInfo"))
    }

    pub fn event_root_hash(&self) -> HashValue {
        self.event_root_hash
    }

    pub fn gas_used(&self) -> u64 {
        self.gas_used
    }

    pub fn status(&self) -> &ExecutionStatus {
        &self.status
    }
}
```
