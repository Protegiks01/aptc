# Audit Report

## Title
Race Condition Between Pruner and Internal Indexer Causes Permanent Data Loss

## Summary
A critical race condition exists between the ledger pruner's target version calculation and the internal indexer's asynchronous processing. The pruner calculates its target based solely on `latest_version - prune_window` without checking the internal indexer's progress, allowing it to delete data before the indexer has processed it, resulting in permanent data loss.

## Finding Description

The vulnerability stems from a lack of coordination between two asynchronous components:

**1. Pruner Target Setting (Synchronous):**
When transactions are committed, the pruner target is immediately set in `aptosdb_writer.rs`: [1](#0-0) 

The target calculation in `ledger_pruner_manager.rs` is: [2](#0-1) 

This calculation uses `latest_version - prune_window` without checking the internal indexer's progress (EventVersion, TransactionVersion, or LatestVersion metadata).

**2. Internal Indexer Processing (Asynchronous):**
The internal indexer runs in a separate async task and receives notifications via a watch channel: [3](#0-2) 

The indexer processes data asynchronously: [4](#0-3) 

**The Race Condition:**

1. Main DB commits transactions to version V
2. Update notification sent to internal indexer service (async, non-blocking)
3. Pruner target immediately set to `V - prune_window` 
4. If internal indexer is at version I where `I < V - prune_window`, the pruner will delete versions `[min_readable, V - prune_window)` 
5. Internal indexer loses access to versions `[I, V - prune_window)` permanently
6. The indexer tracks its own progress separately: [5](#0-4) 

But this progress is **never checked** by the pruner before setting targets.

**Attack Scenario:**
- Main DB at version 100,000
- Internal indexer at version 50,000 (lagging due to load)
- Prune window: 10,000
- New transactions committed to version 100,001
- Pruner target set to 90,001 (`100,001 - 10,000`)
- Pruner deletes versions < 90,001
- Internal indexer permanently loses versions 50,000-90,000

The indexer's metadata keys (EventVersion, TransactionVersion, StateVersion) track what has been indexed, but the pruner never consults these before pruning: [6](#0-5) 

## Impact Explanation

**Critical Severity** - This vulnerability causes permanent, irrecoverable data loss:

1. **Data Loss**: Events, transactions, and state keys indexed by the internal indexer are permanently deleted before indexing completes
2. **API Functionality Degradation**: APIs relying on the internal indexer (account transactions, event queries) return incomplete data
3. **Non-recoverable**: Once pruned, data cannot be recovered without full blockchain resync
4. **State Consistency Violation**: The system violates the invariant that all data should be properly indexed before pruning

This meets the "Non-recoverable network partition (requires hardfork)" or "State inconsistencies requiring intervention" criteria, warranting Critical/High severity classification.

## Likelihood Explanation

**High Likelihood:**

1. **Natural Occurrence**: The internal indexer can lag behind the main DB during:
   - High transaction throughput periods
   - CPU/I/O resource contention  
   - Batch processing delays
   - Node restart/recovery

2. **No Protection**: There is no mechanism preventing the race:
   - No synchronization between pruner and indexer
   - No checks of indexer progress before pruning
   - Pruner operates independently based solely on main DB version

3. **Default Configuration**: Many production nodes enable both pruning and internal indexer, making this scenario common

4. **Exploitable**: An attacker can deliberately cause the indexer to lag by:
   - Submitting transaction bursts to increase indexer processing time
   - Creating resource contention
   - Exploiting any indexer performance bottleneck

## Recommendation

Add indexer progress validation before setting pruner targets:

```rust
// In ledger_pruner_manager.rs
fn set_pruner_target_db_version(&self, latest_version: Version) {
    assert!(self.pruner_worker.is_some());
    
    // NEW: Get minimum indexer progress
    let mut min_indexer_version = latest_version;
    if let Some(indexer_db) = &self.internal_indexer_db {
        if let Ok(Some(event_version)) = indexer_db.get_event_version() {
            min_indexer_version = min_indexer_version.min(event_version);
        }
        if let Ok(Some(txn_version)) = indexer_db.get_transaction_version() {
            min_indexer_version = min_indexer_version.min(txn_version);
        }
        if let Ok(Some(state_version)) = indexer_db.get_state_version() {
            min_indexer_version = min_indexer_version.min(state_version);
        }
    }
    
    // Calculate min_readable_version considering indexer progress
    let target_based_on_prune_window = latest_version.saturating_sub(self.prune_window);
    let min_readable_version = target_based_on_prune_window.min(min_indexer_version);
    
    self.min_readable_version.store(min_readable_version, Ordering::SeqCst);
    PRUNER_VERSIONS
        .with_label_values(&["ledger_pruner", "min_readable"])
        .set(min_readable_version as i64);
    self.pruner_worker.as_ref().unwrap().set_target_db_version(min_readable_version);
}
```

Additionally, add the internal_indexer_db reference to LedgerPrunerManager:

```rust
pub(crate) struct LedgerPrunerManager {
    ledger_db: Arc<LedgerDb>,
    prune_window: Version,
    pruner_worker: Option<PrunerWorker>,
    pruning_batch_size: usize,
    latest_version: Arc<Mutex<Version>>,
    user_pruning_window_offset: u64,
    min_readable_version: AtomicVersion,
    internal_indexer_db: Option<InternalIndexerDB>, // NEW
}
```

## Proof of Concept

```rust
// Reproduction steps for Rust integration test

#[test]
fn test_pruner_indexer_race_condition() {
    // 1. Initialize AptosDB with internal indexer and small prune window
    let config = NodeConfig {
        storage: StorageConfig {
            pruner_config: PrunerConfig {
                ledger_pruner_config: LedgerPrunerConfig {
                    enable: true,
                    prune_window: 1000, // Small window
                    batch_size: 100,
                    ..Default::default()
                },
                ..Default::default()
            },
            ..Default::default()
        },
        indexer_db_config: InternalIndexerDBConfig {
            enable_event: true,
            enable_transaction: true,
            enable_statekeys: true,
            batch_size: 10, // Small batch to slow indexer
            ..Default::default()
        },
        ..Default::default()
    };
    
    let (db, indexer_service) = setup_db_with_indexer(config);
    
    // 2. Commit initial transactions (0-5000)
    for i in 0..5000 {
        commit_transaction(&db, i);
    }
    
    // 3. Pause indexer processing (simulate lag)
    indexer_service.pause();
    
    // 4. Get indexer current version (should be ~5000)
    let indexer_version = indexer_service.get_persisted_version().unwrap();
    assert_eq!(indexer_version, 4999);
    
    // 5. Commit many more transactions to trigger pruning
    for i in 5000..12000 {
        commit_transaction(&db, i);
    }
    
    // 6. Pruner target should now be ~11000 (12000 - 1000)
    // This is > indexer_version (4999)
    
    // 7. Wait for pruner to run
    std::thread::sleep(Duration::from_secs(2));
    
    // 8. Resume indexer
    indexer_service.resume();
    
    // 9. Indexer tries to process from 5000 onwards
    // But data from 5000-10000 has been pruned!
    let result = indexer_service.process_to_version(10000);
    
    // 10. Verify data loss occurred
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("pruned"));
    
    // Indexer permanently lost versions 5000-10000
}
```

**Notes:**
- This vulnerability occurs in production when indexer lags due to load or resource constraints
- No attacker privilege required - can be triggered naturally or through transaction spam
- Permanent data loss requires full node resync to recover
- Critical impact on any services depending on internal indexer data (APIs, analytics, etc.)

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L618-623)
```rust
            if let Some(update_sender) = &self.update_subscriber {
                update_sender
                    .send((Instant::now(), version))
                    .map_err(|err| {
                        AptosDbError::Other(format!("Failed to send update to subscriber: {}", err))
                    })?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L628-629)
```rust
            self.ledger_pruner
                .maybe_set_pruner_target_db_version(version);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L162-176)
```rust
    fn set_pruner_target_db_version(&self, latest_version: Version) {
        assert!(self.pruner_worker.is_some());
        let min_readable_version = latest_version.saturating_sub(self.prune_window);
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["ledger_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.pruner_worker
            .as_ref()
            .unwrap()
            .set_target_db_version(min_readable_version);
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L167-199)
```rust
    pub async fn run(&mut self, node_config: &NodeConfig) -> Result<()> {
        let mut start_version = self.get_start_version(node_config).await?;
        let mut target_version = self.db_indexer.main_db_reader.ensure_synced_version()?;
        let mut step_timer = std::time::Instant::now();

        loop {
            if target_version <= start_version {
                match self.update_receiver.changed().await {
                    Ok(_) => {
                        (step_timer, target_version) = *self.update_receiver.borrow();
                    },
                    Err(e) => {
                        panic!("Failed to get update from update_receiver: {}", e);
                    },
                }
            }
            let next_version = self.db_indexer.process(start_version, target_version)?;
            INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::InternalIndexerDBProcessed,
                Some(start_version as i64),
                Some(next_version as i64),
                None,
                None,
                Some(step_timer.elapsed().as_secs_f64()),
                None,
                Some((next_version - start_version) as i64),
                None,
            );
            start_version = next_version;
        }
    }
```

**File:** storage/indexer/src/db_indexer.rs (L110-124)
```rust
    pub fn get_persisted_version(&self) -> Result<Option<Version>> {
        self.get_version(&MetadataKey::LatestVersion)
    }

    pub fn get_event_version(&self) -> Result<Option<Version>> {
        self.get_version(&MetadataKey::EventVersion)
    }

    pub fn get_state_version(&self) -> Result<Option<Version>> {
        self.get_version(&MetadataKey::StateVersion)
    }

    pub fn get_transaction_version(&self) -> Result<Option<Version>> {
        self.get_version(&MetadataKey::TransactionVersion)
    }
```

**File:** storage/indexer_schemas/src/metadata.rs (L31-42)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize, Hash, PartialOrd, Ord)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub enum MetadataKey {
    LatestVersion,
    EventPrunerProgress,
    TransactionPrunerProgress,
    StateSnapshotRestoreProgress(Version),
    EventVersion,
    StateVersion,
    TransactionVersion,
    EventV2TranslationVersion,
}
```
