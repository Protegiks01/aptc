# Audit Report

## Title
Missing Future Timestamp Validation in Peer Monitoring Service Allows Malicious Peers to Gain Priority

## Summary
The `check_peer_metadata_health` function in the mempool peer prioritization logic fails to validate that peer-reported `ledger_timestamp_usecs` values are not in the future. This allows malicious peers to send future timestamps and be incorrectly marked as "healthy," gaining priority for mempool transaction broadcasting.

## Finding Description

The peer monitoring service allows nodes to query each other's sync status via `NodeInformationResponse`, which includes a `ledger_timestamp_usecs` field representing the blockchain's ledger timestamp. [1](#0-0) 

This timestamp is retrieved from storage on the server side: [2](#0-1) 

The mempool uses this timestamp to determine peer health via `check_peer_metadata_health`: [3](#0-2) 

The validation only checks if the peer is too far **behind** (stale) using `current_timestamp_usecs.saturating_sub(peer_ledger_timestamp_usecs) < max_sync_lag_usecs`. When `peer_ledger_timestamp_usecs` is in the future, `saturating_sub` underflows to 0, and the check incorrectly passes.

In contrast, the consensus layer properly validates both past and future timestamps: [4](#0-3) 

**Attack Scenario:**
1. Attacker runs a malicious peer node
2. When responding to `GetNodeInformation` requests, the attacker's node returns `ledger_timestamp_usecs = current_time + 1_year`
3. The `check_peer_metadata_health` function incorrectly marks this peer as healthy
4. The malicious peer gains priority in `compare_peer_health`: [5](#0-4) 
5. The attacker's peer is prioritized for mempool transaction broadcasting, enabling selective censorship or transaction delay attacks

## Impact Explanation
This is a **Low Severity** issue per Aptos bug bounty criteria. It affects peer prioritization in mempool but does not:
- Cause loss of funds
- Violate consensus safety
- Cause network partition or liveness loss
- Corrupt state

The impact is limited to allowing malicious peers to gain unfair priority in transaction propagation, potentially enabling selective transaction censorship or delays.

## Likelihood Explanation
**Likelihood: High**
- Any peer can exploit this without special privileges
- Exploitation requires only sending a modified response (trivial technical complexity)
- No detection mechanism exists
- The attack succeeds 100% of the time

## Recommendation

Add future timestamp validation similar to the consensus layer:

```rust
fn check_peer_metadata_health(
    mempool_config: &MempoolConfig,
    time_service: &TimeService,
    monitoring_metadata: &Option<&PeerMonitoringMetadata>,
) -> bool {
    monitoring_metadata
        .and_then(|metadata| {
            metadata
                .latest_node_info_response
                .as_ref()
                .map(|node_information_response| {
                    let peer_ledger_timestamp_usecs =
                        node_information_response.ledger_timestamp_usecs;
                    let current_timestamp_usecs = get_timestamp_now_usecs(time_service);
                    
                    let max_sync_lag_secs =
                        mempool_config.max_sync_lag_before_unhealthy_secs as u64;
                    let max_sync_lag_usecs = max_sync_lag_secs * MICROS_PER_SECOND;
                    
                    // Check peer is not too far behind
                    let is_not_stale = current_timestamp_usecs
                        .saturating_sub(peer_ledger_timestamp_usecs)
                        < max_sync_lag_usecs;
                    
                    // Check peer is not too far ahead (add future bound check)
                    const FUTURE_TIMEBOUND: u64 = 300_000_000; // 5 minutes in microseconds
                    let is_not_future = peer_ledger_timestamp_usecs 
                        <= current_timestamp_usecs.saturating_add(FUTURE_TIMEBOUND);
                    
                    is_not_stale && is_not_future
                })
        })
        .unwrap_or(false)
}
```

## Proof of Concept

```rust
#[test]
fn test_future_timestamp_not_healthy() {
    use aptos_peer_monitoring_service_types::{
        response::NodeInformationResponse,
        PeerMonitoringMetadata,
    };
    use std::time::Duration;
    
    // Create mempool config
    let mempool_config = MempoolConfig {
        max_sync_lag_before_unhealthy_secs: 10,
        ..MempoolConfig::default()
    };
    
    // Create time service
    let time_service = TimeService::mock();
    let current_time_usecs = time_service.now_unix_time().as_micros() as u64;
    
    // Create metadata with future timestamp (1 year ahead)
    let future_timestamp_usecs = current_time_usecs + (365 * 24 * 3600 * 1_000_000);
    let mut monitoring_metadata = PeerMonitoringMetadata::default();
    monitoring_metadata.latest_node_info_response = Some(NodeInformationResponse {
        build_information: Default::default(),
        highest_synced_epoch: 100,
        highest_synced_version: 1000,
        ledger_timestamp_usecs: future_timestamp_usecs,
        lowest_available_version: 0,
        uptime: Duration::from_secs(3600),
    });
    
    // Verify peer is incorrectly marked as healthy (BUG)
    let is_healthy = check_peer_metadata_health(
        &mempool_config,
        &time_service,
        &Some(&monitoring_metadata),
    );
    
    // This should be false but is currently true due to the bug
    assert!(is_healthy); // BUG: Future timestamp passes validation
}
```

## Notes
This vulnerability is categorized as **Low Severity** and does not meet the threshold for Critical, High, or Medium severity findings in the Aptos bug bounty program. While it represents a valid implementation bug with a clear attack path, its impact is limited to mempool peer prioritization and does not affect core security properties like consensus safety, deterministic execution, or state integrity.

### Citations

**File:** peer-monitoring-service/types/src/response.rs (L93-102)
```rust
/// A response for the node information request
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct NodeInformationResponse {
    pub build_information: BTreeMap<String, String>, // The build information of the node
    pub highest_synced_epoch: u64,                   // The highest synced epoch of the node
    pub highest_synced_version: u64,                 // The highest synced version of the node
    pub ledger_timestamp_usecs: u64, // The latest timestamp of the blockchain (in microseconds)
    pub lowest_available_version: u64, // The lowest stored version of the node (in storage)
    pub uptime: Duration,            // The amount of time the peer has been running
}
```

**File:** peer-monitoring-service/server/src/lib.rs (L259-280)
```rust
    fn get_node_information(&self) -> Result<PeerMonitoringServiceResponse, Error> {
        // Get the node information
        let build_information = aptos_build_info::get_build_information();
        let current_time: Instant = self.time_service.now();
        let uptime = current_time.duration_since(self.start_time);
        let (highest_synced_epoch, highest_synced_version) =
            self.storage.get_highest_synced_epoch_and_version()?;
        let ledger_timestamp_usecs = self.storage.get_ledger_timestamp_usecs()?;
        let lowest_available_version = self.storage.get_lowest_available_version()?;

        // Create and return the response
        let node_information_response = NodeInformationResponse {
            build_information,
            highest_synced_epoch,
            highest_synced_version,
            ledger_timestamp_usecs,
            lowest_available_version,
            uptime,
        };
        Ok(PeerMonitoringServiceResponse::NodeInformation(
            node_information_response,
        ))
```

**File:** mempool/src/shared_mempool/priority.rs (L562-589)
```rust
fn check_peer_metadata_health(
    mempool_config: &MempoolConfig,
    time_service: &TimeService,
    monitoring_metadata: &Option<&PeerMonitoringMetadata>,
) -> bool {
    monitoring_metadata
        .and_then(|metadata| {
            metadata
                .latest_node_info_response
                .as_ref()
                .map(|node_information_response| {
                    // Get the peer's ledger timestamp and the current timestamp
                    let peer_ledger_timestamp_usecs =
                        node_information_response.ledger_timestamp_usecs;
                    let current_timestamp_usecs = get_timestamp_now_usecs(time_service);

                    // Calculate the max sync lag before the peer is considered unhealthy (in microseconds)
                    let max_sync_lag_secs =
                        mempool_config.max_sync_lag_before_unhealthy_secs as u64;
                    let max_sync_lag_usecs = max_sync_lag_secs * MICROS_PER_SECOND;

                    // Determine if the peer is healthy
                    current_timestamp_usecs.saturating_sub(peer_ledger_timestamp_usecs)
                        < max_sync_lag_usecs
                })
        })
        .unwrap_or(false) // If metadata is missing, consider the peer unhealthy
}
```

**File:** mempool/src/shared_mempool/priority.rs (L591-611)
```rust
/// Compares the health of the given peer monitoring metadata. Healthy
/// peers are prioritized over unhealthy peers, or peers missing metadata.
fn compare_peer_health(
    mempool_config: &MempoolConfig,
    time_service: &TimeService,
    monitoring_metadata_a: &Option<&PeerMonitoringMetadata>,
    monitoring_metadata_b: &Option<&PeerMonitoringMetadata>,
) -> Ordering {
    // Check the health of the peer monitoring metadata
    let is_healthy_a =
        check_peer_metadata_health(mempool_config, time_service, monitoring_metadata_a);
    let is_healthy_b =
        check_peer_metadata_health(mempool_config, time_service, monitoring_metadata_b);

    // Compare the health statuses
    match (is_healthy_a, is_healthy_b) {
        (true, false) => Ordering::Greater, // A is healthy, B is unhealthy
        (false, true) => Ordering::Less,    // A is unhealthy, B is healthy
        _ => Ordering::Equal,               // Both are healthy or unhealthy
    }
}
```

**File:** consensus/consensus-types/src/block.rs (L532-539)
```rust
            let current_ts = duration_since_epoch();

            // we can say that too far is 5 minutes in the future
            const TIMEBOUND: u64 = 300_000_000;
            ensure!(
                self.timestamp_usecs() <= (current_ts.as_micros() as u64).saturating_add(TIMEBOUND),
                "Blocks must not be too far in the future"
            );
```
