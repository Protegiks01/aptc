# Audit Report

## Title
State Sync DoS via Malicious Minimal Chunk Size Advertisement

## Summary
The `verify_optimal_chunk_sizes()` function only validates that chunk sizes are not zero, but does not enforce a minimum threshold. Malicious peers can advertise chunk sizes of 1 (or other extremely small values), causing victim nodes to make thousands of network requests instead of a handful, resulting in severe state synchronization performance degradation and effective denial of service.

## Finding Description

The vulnerability exists in the state synchronization subsystem's chunk size validation and optimal chunk size calculation logic.

**Attack Flow:**

1. **Malicious Chunk Size Advertisement**: An attacker configures malicious nodes with minimal chunk sizes (e.g., `max_state_chunk_size: 1`) in their `StorageServiceConfig`. [1](#0-0) 

2. **Median Calculation**: When a victim node connects to peers, it collects chunk sizes from all peers and calculates the median using `calculate_optimal_chunk_sizes()`. [2](#0-1) 

3. **Vulnerable Median Logic**: The `median_or_max()` function has no minimum threshold—it sorts values and picks the middle one. With only one peer, it uses that peer's value (`idx = values.len() / 2 = 0`). With three peers advertising [1, 1, 4000], the median becomes 1. [3](#0-2) 

4. **Insufficient Validation**: The `verify_optimal_chunk_sizes()` function only checks for zero, allowing chunk size of 1 to pass validation. [4](#0-3) 

5. **Excessive Request Generation**: When syncing data, `create_data_client_request_batch()` uses the optimal chunk size to determine items per request: `num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size)`. With `optimal_chunk_size = 1`, each request fetches only 1 item. [5](#0-4) 

6. **Performance Degradation**: Syncing 10,000 transactions requires 10,000 requests instead of ~4 requests (with normal chunk size of 3000). Although only 6 concurrent requests are allowed by default, this still requires ~1,667 request rounds, each with network latency, cryptographic verification, and processing overhead. [6](#0-5) 

**Broken Invariant**: This violates the "Resource Limits" invariant—all operations must respect computational limits. The attack causes excessive network requests that waste bandwidth, CPU, and time.

## Impact Explanation

**Severity: Medium to High**

This qualifies as **Medium Severity** per the Aptos bug bounty program:
- Causes significant state synchronization performance degradation
- Prevents nodes from efficiently catching up with the blockchain
- Can render new nodes unable to join the network if sustained
- Does not directly cause fund loss or consensus breaks
- Requires some network control but is easily executable

The impact escalates to **High Severity** in scenarios where:
- The attacker controls enough peers to consistently influence the median (easier during network bootstrap or in sparse networks)
- Validator nodes are affected, causing "Validator node slowdowns" as specified in High Severity criteria
- The attack prevents critical infrastructure nodes from syncing

**Quantified Impact:**
- Normal sync: 10,000 items = ~4 requests × 100ms = ~400ms
- Malicious sync: 10,000 items = 10,000 requests ÷ 6 concurrent = 1,667 rounds × 100ms = ~167 seconds
- **Performance degradation: ~417x slower**

## Likelihood Explanation

**Likelihood: Medium**

**Favorable Conditions for Attack:**
- New nodes bootstrapping with few initial peers (high probability of influence)
- Networks with sparse connectivity or small peer sets
- No cryptographic bypass required—just config modification
- Trivial to execute: modify `StorageServiceConfig` and connect to network
- No special privileges needed

**Mitigating Factors:**
- In well-connected networks with many honest peers, median remains reasonable
- Requires attacker to control >50% of victim's peer connections for sustained effect
- Victim can potentially mitigate by manually adding honest peer connections
- Does not persist across restarts if peer set changes

**Realistic Attack Scenario:**
An attacker spins up multiple nodes with `max_*_chunk_size: 1`, connects to target victims (especially new nodes during initial sync), and the victims' state sync becomes extremely slow, preventing them from catching up to the chain tip.

## Recommendation

**Add minimum chunk size validation** at two critical points:

1. **Config-level validation** in `ConfigSanitizer` for `StorageServiceConfig`:

```rust
impl ConfigSanitizer for StorageServiceConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let config = &node_config.state_sync.storage_service;
        
        // Define minimum acceptable chunk sizes
        const MIN_EPOCH_CHUNK_SIZE: u64 = 10;
        const MIN_STATE_CHUNK_SIZE: u64 = 100;
        const MIN_TRANSACTION_CHUNK_SIZE: u64 = 100;
        const MIN_TRANSACTION_OUTPUT_CHUNK_SIZE: u64 = 100;
        
        if config.max_epoch_chunk_size < MIN_EPOCH_CHUNK_SIZE {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!("max_epoch_chunk_size must be at least {}", MIN_EPOCH_CHUNK_SIZE),
            ));
        }
        // Repeat for other chunk size fields...
        
        Ok(())
    }
}
```

2. **Runtime validation** in `verify_optimal_chunk_sizes()`:

```rust
fn verify_optimal_chunk_sizes(optimal_chunk_sizes: &OptimalChunkSizes) -> Result<(), Error> {
    const MIN_CHUNK_SIZE: u64 = 100;
    
    if optimal_chunk_sizes.state_chunk_size == 0
        || optimal_chunk_sizes.epoch_chunk_size == 0
        || optimal_chunk_sizes.transaction_chunk_size == 0
        || optimal_chunk_sizes.transaction_output_chunk_size == 0
    {
        Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Found at least one optimal chunk size of zero: {:?}",
            optimal_chunk_sizes
        )))
    } else if optimal_chunk_sizes.state_chunk_size < MIN_CHUNK_SIZE
        || optimal_chunk_sizes.epoch_chunk_size < MIN_CHUNK_SIZE
        || optimal_chunk_sizes.transaction_chunk_size < MIN_CHUNK_SIZE
        || optimal_chunk_sizes.transaction_output_chunk_size < MIN_CHUNK_SIZE
    {
        Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Found at least one optimal chunk size below minimum threshold {}: {:?}",
            MIN_CHUNK_SIZE, optimal_chunk_sizes
        )))
    } else {
        Ok(())
    }
}
```

**Alternative/Additional Defense:** Modify `median_or_max()` to enforce a minimum value:

```rust
fn median_or_max<T: Ord + Copy>(mut values: Vec<T>, max_value: T) -> T {
    values.sort_unstable();
    let idx = values.len() / 2;
    let median = values.get(idx).copied();
    let result = min(median.unwrap_or(max_value), max_value);
    
    // Enforce minimum threshold (e.g., 10% of max_value or absolute minimum)
    max(result, max_value / 10)
}
```

## Proof of Concept

**Rust Test Demonstrating the Vulnerability:**

```rust
#[cfg(test)]
mod malicious_chunk_size_test {
    use super::*;
    use aptos_config::config::AptosDataClientConfig;
    use state_sync::aptos_data_client::peer_states::calculate_optimal_chunk_sizes;

    #[test]
    fn test_malicious_minimal_chunk_sizes() {
        let config = AptosDataClientConfig::default();
        
        // Scenario 1: Single malicious peer advertising chunk size of 1
        let malicious_chunks = vec![1u64];
        let result = calculate_optimal_chunk_sizes(
            &config,
            malicious_chunks.clone(),
            malicious_chunks.clone(),
            malicious_chunks.clone(),
            malicious_chunks.clone(),
        );
        
        // The result will be 1, which passes the zero check but causes DoS
        assert_eq!(result.state_chunk_size, 1);
        assert_eq!(result.transaction_chunk_size, 1);
        
        // Scenario 2: Three peers, two malicious
        let mixed_chunks = vec![1u64, 1u64, 4000u64];
        let result = calculate_optimal_chunk_sizes(
            &config,
            mixed_chunks.clone(),
            mixed_chunks.clone(),
            mixed_chunks.clone(),
            mixed_chunks.clone(),
        );
        
        // Median of [1, 1, 4000] is 1 (index 1 after sorting)
        assert_eq!(result.state_chunk_size, 1);
        
        // Now test that verify_optimal_chunk_sizes incorrectly accepts this
        let verification_result = verify_optimal_chunk_sizes(&result);
        assert!(verification_result.is_ok()); // BUG: Should reject chunk size of 1!
        
        // Demonstrate the DoS impact
        let items_to_sync = 10000u64;
        let normal_chunk_size = 3000u64;
        let malicious_chunk_size = 1u64;
        
        let normal_requests = (items_to_sync + normal_chunk_size - 1) / normal_chunk_size;
        let malicious_requests = (items_to_sync + malicious_chunk_size - 1) / malicious_chunk_size;
        
        println!("Normal sync: {} requests", normal_requests); // ~4 requests
        println!("Malicious sync: {} requests", malicious_requests); // 10,000 requests
        assert_eq!(malicious_requests / normal_requests, 2500); // 2500x more requests!
    }
}
```

**Steps to Reproduce:**

1. Set up a test network with one honest node and one malicious node
2. Configure malicious node's `StorageServiceConfig` with `max_state_chunk_size: 1`
3. Start both nodes and establish peer connection
4. Monitor the honest node's state sync performance
5. Observe that the honest node makes thousands of tiny requests, causing extreme slowdown
6. Measure sync time: normal (seconds) vs. malicious (minutes/hours)

### Citations

**File:** state-sync/storage-service/server/src/lib.rs (L530-535)
```rust
    let new_protocol_metadata = ProtocolMetadata {
        max_epoch_chunk_size: storage_config.max_epoch_chunk_size,
        max_transaction_chunk_size: storage_config.max_transaction_chunk_size,
        max_state_chunk_size: storage_config.max_state_chunk_size,
        max_transaction_output_chunk_size: storage_config.max_transaction_output_chunk_size,
    };
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L419-443)
```rust
pub(crate) fn calculate_optimal_chunk_sizes(
    config: &AptosDataClientConfig,
    max_epoch_chunk_sizes: Vec<u64>,
    max_state_chunk_sizes: Vec<u64>,
    max_transaction_chunk_sizes: Vec<u64>,
    max_transaction_output_chunk_size: Vec<u64>,
) -> OptimalChunkSizes {
    let epoch_chunk_size = median_or_max(max_epoch_chunk_sizes, config.max_epoch_chunk_size);
    let state_chunk_size = median_or_max(max_state_chunk_sizes, config.max_state_chunk_size);
    let transaction_chunk_size = median_or_max(
        max_transaction_chunk_sizes,
        config.max_transaction_chunk_size,
    );
    let transaction_output_chunk_size = median_or_max(
        max_transaction_output_chunk_size,
        config.max_transaction_output_chunk_size,
    );

    OptimalChunkSizes {
        epoch_chunk_size,
        state_chunk_size,
        transaction_chunk_size,
        transaction_output_chunk_size,
    }
}
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L448-456)
```rust
fn median_or_max<T: Ord + Copy>(mut values: Vec<T>, max_value: T) -> T {
    // Calculate median
    values.sort_unstable();
    let idx = values.len() / 2;
    let median = values.get(idx).copied();

    // Return median or max
    min(median.unwrap_or(max_value), max_value)
}
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L478-491)
```rust
fn verify_optimal_chunk_sizes(optimal_chunk_sizes: &OptimalChunkSizes) -> Result<(), Error> {
    if optimal_chunk_sizes.state_chunk_size == 0
        || optimal_chunk_sizes.epoch_chunk_size == 0
        || optimal_chunk_sizes.transaction_chunk_size == 0
        || optimal_chunk_sizes.transaction_output_chunk_size == 0
    {
        Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Found at least one optimal chunk size of zero: {:?}",
            optimal_chunk_sizes
        )))
    } else {
        Ok(())
    }
}
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2049-2099)
```rust
fn create_data_client_request_batch(
    start_index: u64,
    end_index: u64,
    max_number_of_requests: u64,
    optimal_chunk_size: u64,
    stream_engine: StreamEngine,
) -> Result<Vec<DataClientRequest>, Error> {
    if start_index > end_index {
        return Ok(vec![]);
    }

    // Calculate the total number of items left to satisfy the stream
    let mut total_items_to_fetch = end_index
        .checked_sub(start_index)
        .and_then(|e| e.checked_add(1)) // = end_index - start_index + 1
        .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;

    // Iterate until we've requested all transactions or hit the maximum number of requests
    let mut data_client_requests = vec![];
    let mut num_requests_made = 0;
    let mut next_index_to_request = start_index;
    while total_items_to_fetch > 0 && num_requests_made < max_number_of_requests {
        // Calculate the number of items to fetch in this request
        let num_items_to_fetch = cmp::min(total_items_to_fetch, optimal_chunk_size);

        // Calculate the start and end indices for the request
        let request_start_index = next_index_to_request;
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;

        // Create the data client requests
        let data_client_request =
            create_data_client_request(request_start_index, request_end_index, &stream_engine)?;
        data_client_requests.push(data_client_request);

        // Update the local loop state
        next_index_to_request = request_end_index
            .checked_add(1)
            .ok_or_else(|| Error::IntegerOverflow("Next index to request has overflown!".into()))?;
        total_items_to_fetch = total_items_to_fetch
            .checked_sub(num_items_to_fetch)
            .ok_or_else(|| Error::IntegerOverflow("Total items to fetch has overflown!".into()))?;
        num_requests_made = num_requests_made.checked_add(1).ok_or_else(|| {
            Error::IntegerOverflow("Number of payload requests has overflown!".into())
        })?;
    }

    Ok(data_client_requests)
}
```

**File:** config/src/config/state_sync_config.rs (L29-31)
```rust
// The maximum number of concurrent requests to send
const MAX_CONCURRENT_REQUESTS: u64 = 6;
const MAX_CONCURRENT_STATE_REQUESTS: u64 = 6;
```
