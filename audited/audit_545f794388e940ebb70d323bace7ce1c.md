# Audit Report

## Title
Cache-Database Inconsistency in BatchStore Due to TOCTOU Race Condition in Concurrent Persist Operations

## Summary
The `BatchStore` implementation in the quorum store consensus component contains a Time-of-Check-Time-of-Use (TOCTOU) race condition that allows concurrent persist operations for the same batch digest with different expirations to create cache-database inconsistencies. This can lead to premature batch expiration and node-specific liveness degradation after restarts.

## Finding Description

The vulnerability exists in the `BatchCoordinator` and `BatchStore` interaction where concurrent batch persistence operations are not properly synchronized:

**Root Cause - Non-Atomic Check-Then-Act Pattern:** [1](#0-0) 

The `persist_and_send_digests` method spawns independent tokio tasks for each persist operation without synchronization. Each task calls `batch_store.persist()` concurrently. [2](#0-1) 

In `persist_inner`, the critical section (cache update via `insert_to_cache`) and the database write are not atomic. The DashMap entry lock is released BEFORE the database write occurs.

**Attack Vector - Digest Without Expiration Binding:** [3](#0-2) 

The batch digest is computed only from `author` and `txns` fields. The expiration field in `BatchInfo` is NOT included in the digest calculation, allowing the same payload to be sent with different expirations. [4](#0-3) 

The `Batch::verify()` method validates payload hash matches the digest, but does NOT verify the expiration field is bound to the payload.

**Race Condition Execution Flow:**

1. **Thread 1** receives batch with digest `D`, expiration `T1`:
   - Acquires `db_cache[D]` lock via DashMap
   - Inserts `(D, T1, payload)` into cache
   - Releases lock
   - Returns `needs_db = true`
   - **About to write to database...**

2. **Thread 2** receives same digest `D`, expiration `T2 > T1`:
   - Acquires `db_cache[D]` lock
   - Sees existing entry with `T1`, replaces with `T2` (line 401 in batch_store.rs)
   - Releases lock
   - Returns `needs_db = true`
   - **Writes `(D, T2)` to database**

3. **Thread 1** continues:
   - **Writes `(D, T1)` to database, overwriting Thread 2's write**

**Result:** Cache contains `T2`, database contains `T1`.

**Exploitation Path:**

A Byzantine validator can trigger this by:
1. Creating batch `B` with digest `D` and payload `P`
2. Sending to victim validator `V` with expiration `T1`
3. Immediately sending same digest `D`, payload `P` with expiration `T2 > T1`
4. Both messages processed concurrently by `BatchCoordinator`
5. Race condition causes cache-DB divergence
6. When `V` restarts, loads stale `T1` from database: [5](#0-4) 

7. Batch expires at `T1` instead of `T2`, potentially before consensus uses it
8. Validator `V` cannot execute blocks containing this batch, causing node-specific liveness failure

**Invariant Violations:**

- **State Consistency Invariant**: "State transitions must be atomic and verifiable" - the cache and database states diverge
- **Deterministic Execution Invariant**: Different nodes may have different batch expiration times, leading to non-deterministic behavior after restarts

## Impact Explanation

This vulnerability qualifies as **HIGH severity** per Aptos Bug Bounty criteria:

1. **Validator Node Slowdowns** - When a batch expires prematurely due to stale database data after restart, the validator cannot execute blocks containing that batch and must either re-fetch from peers (slowdown) or state-sync (major slowdown).

2. **Significant Protocol Violations** - The cache-database inconsistency violates the fundamental assumption that persistent state matches in-memory state. This is a critical correctness property for consensus systems.

3. **Node-Specific Liveness Degradation** - Affected validators may fall behind consensus if they repeatedly fail to execute blocks due to missing/expired batches, requiring manual intervention or state synchronization.

The vulnerability does not directly cause consensus safety violations (chain splits), but creates a denial-of-service vector against individual validators through state corruption.

## Likelihood Explanation

**Likelihood: MEDIUM**

**Requirements for exploitation:**
- Attacker must be a validator in the active validator set (Byzantine validator assumption)
- Attacker must send the same batch payload with different expiration metadata
- Race condition must occur with precise timing (both threads in persist window simultaneously)
- Victim node must restart to load stale data from database

**Feasibility:**
- Byzantine validators are part of the threat model (up to 1/3 can be malicious)
- Attacker can send batches with arbitrary expiration values (no upper bound validation)
- Concurrent processing in `BatchCoordinator` makes race conditions likely under load
- Node restarts occur regularly for upgrades, crashes, or maintenance

**Mitigating factors:**
- Requires multiple attempts to reliably trigger the race
- Impact only manifests after victim node restart
- Victim can recover through state sync or re-fetching batches

Despite the requirements, this is a realistic attack path that a motivated Byzantine validator could exploit to degrade specific validators' performance.

## Recommendation

**Fix 1: Atomic Cache-DB Updates**

Move the database write inside the critical section protected by the DashMap entry lock, OR use a separate per-digest mutex to serialize all operations on the same digest:

```rust
// In BatchStore
persist_locks: DashMap<HashValue, Arc<Mutex<()>>>,

fn persist_inner(&self, batch_info: BatchInfoExt, persist_request: PersistedValue<BatchInfoExt>) -> Option<SignedBatchInfo<BatchInfoExt>> {
    let digest = *persist_request.digest();
    let lock = self.persist_locks.entry(digest)
        .or_insert_with(|| Arc::new(Mutex::new(())))
        .clone();
    
    let _guard = lock.lock(); // Hold lock across cache AND db operations
    
    match self.save(&persist_request) {
        Ok(needs_db) => {
            if needs_db {
                // DB write now happens under lock
                if !batch_info.is_v2() {
                    self.db.save_batch(persist_request.try_into().expect("Must be a V1 batch")).expect("Could not write to DB");
                } else {
                    self.db.save_batch_v2(persist_request).expect("Could not write to DB")
                }
            }
            // Generate signature...
        },
        Err(e) => { /* ... */ }
    }
}
```

**Fix 2: Validate Expiration Uniqueness**

Prevent the same digest from being persisted with different expirations by tracking the canonical expiration:

```rust
// In insert_to_cache, enforce strict equality for existing entries:
if let Occupied(entry) = &cache_entry {
    match entry.get().expiration().cmp(&expiration_time) {
        Ordering::Equal => return Ok(false),
        Ordering::Greater | Ordering::Less => {
            // Reject mismatched expirations for same digest
            bail!("Expiration mismatch for digest {}: existing {}, new {}", 
                  digest, entry.get().expiration(), expiration_time);
        }
    }
}
```

**Fix 3: Include Expiration in Digest (Protocol Change)**

Modify the `BatchPayload` to include expiration in the hash calculation, making it impossible to have the same digest with different expirations. This requires a protocol upgrade.

**Recommended approach:** Implement Fix 1 (atomic operations) as it directly addresses the race condition with minimal protocol impact.

## Proof of Concept

```rust
#[tokio::test]
async fn test_concurrent_persist_race_condition() {
    use std::sync::Arc;
    use tokio::task::JoinSet;
    use consensus::quorum_store::batch_store::BatchStore;
    use consensus::quorum_store::types::PersistedValue;
    use aptos_crypto::HashValue;
    
    // Setup BatchStore with mock DB
    let batch_store = Arc::new(create_test_batch_store());
    
    // Create same payload digest with different expirations
    let digest = HashValue::random();
    let author = PeerId::random();
    let payload = vec![create_test_transaction()];
    
    let batch_info_t1 = create_batch_info(digest, 1000, author); // exp: 1000
    let batch_info_t2 = create_batch_info(digest, 2000, author); // exp: 2000
    
    let persist_req_t1 = PersistedValue::new(batch_info_t1.into(), Some(payload.clone()));
    let persist_req_t2 = PersistedValue::new(batch_info_t2.into(), Some(payload.clone()));
    
    // Spawn concurrent persist operations
    let store_clone_1 = batch_store.clone();
    let store_clone_2 = batch_store.clone();
    
    let mut set = JoinSet::new();
    
    set.spawn(async move {
        store_clone_1.persist(vec![persist_req_t1])
    });
    
    set.spawn(async move {
        store_clone_2.persist(vec![persist_req_t2])
    });
    
    // Wait for both to complete
    while let Some(_) = set.join_next().await {}
    
    // Check cache vs DB state
    let cache_value = batch_store.get_batch_from_local(&digest).unwrap();
    let db_value = batch_store.db.get_batch_v2(&digest).unwrap().unwrap();
    
    println!("Cache expiration: {}", cache_value.expiration());
    println!("DB expiration: {}", db_value.expiration());
    
    // Race condition: cache and DB may have different expirations!
    assert_ne!(cache_value.expiration(), db_value.expiration(),
               "Race condition detected: cache-DB inconsistency");
}
```

**Notes**

This vulnerability demonstrates a classic TOCTOU race condition where the check (cache update with DashMap lock) and the act (database write) are not atomic. While the individual operations are thread-safe (DashMap for cache, RocksDB for database), the combination creates a window where concurrent operations on the same digest can interleave incorrectly.

The attack requires a Byzantine validator to exploit, but the Aptos consensus protocol is designed to tolerate Byzantine validators (up to 1/3). Therefore, the protocol implementation should be resilient to Byzantine validators sending inconsistent batch metadata, which this implementation is not.

The vulnerability is particularly insidious because it only manifests after node restarts when stale data is loaded from the database, making it difficult to detect and debug in production environments.

### Citations

**File:** consensus/src/quorum_store/batch_coordinator.rs (L78-135)
```rust
    fn persist_and_send_digests(
        &self,
        persist_requests: Vec<PersistedValue<BatchInfoExt>>,
        approx_created_ts_usecs: u64,
    ) {
        if persist_requests.is_empty() {
            return;
        }

        let batch_store = self.batch_store.clone();
        let network_sender = self.network_sender.clone();
        let sender_to_proof_manager = self.sender_to_proof_manager.clone();
        tokio::spawn(async move {
            let peer_id = persist_requests[0].author();
            let batches = persist_requests
                .iter()
                .map(|persisted_value| {
                    (
                        persisted_value.batch_info().clone(),
                        persisted_value.summary(),
                    )
                })
                .collect();

            if persist_requests[0].batch_info().is_v2() {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    network_sender
                        .send_signed_batch_info_msg_v2(signed_batch_infos, vec![peer_id])
                        .await;
                }
            } else {
                let signed_batch_infos = batch_store.persist(persist_requests);
                if !signed_batch_infos.is_empty() {
                    assert!(!signed_batch_infos
                        .first()
                        .expect("must not be empty")
                        .is_v2());
                    if approx_created_ts_usecs > 0 {
                        observe_batch(approx_created_ts_usecs, peer_id, BatchStage::SIGNED);
                    }
                    let signed_batch_infos = signed_batch_infos
                        .into_iter()
                        .map(|sbi| sbi.try_into().expect("Batch must be V1 batch"))
                        .collect();
                    network_sender
                        .send_signed_batch_info_msg(signed_batch_infos, vec![peer_id])
                        .await;
                }
            }
            let _ = sender_to_proof_manager
                .send(ProofManagerCommand::ReceiveBatches(batches))
                .await;
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L488-528)
```rust
    fn persist_inner(
        &self,
        batch_info: BatchInfoExt,
        persist_request: PersistedValue<BatchInfoExt>,
    ) -> Option<SignedBatchInfo<BatchInfoExt>> {
        assert!(
            &batch_info == persist_request.batch_info(),
            "Provided batch info doesn't match persist request batch info"
        );
        match self.save(&persist_request) {
            Ok(needs_db) => {
                trace!("QS: sign digest {}", persist_request.digest());
                if needs_db {
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
                }
                if !batch_info.is_v2() {
                    self.generate_signed_batch_info(batch_info.info().clone())
                        .ok()
                        .map(|inner| inner.into())
                } else {
                    self.generate_signed_batch_info(batch_info).ok()
                }
            },
            Err(e) => {
                debug!("QS: failed to store to cache {:?}", e);
                None
            },
        }
    }
```

**File:** consensus/consensus-types/src/common.rs (L707-725)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, CryptoHasher)]
pub struct BatchPayload {
    author: PeerId,
    txns: Vec<SignedTransaction>,
    #[serde(skip)]
    num_bytes: OnceCell<usize>,
}

impl CryptoHash for BatchPayload {
    type Hasher = BatchPayloadHasher;

    fn hash(&self) -> HashValue {
        let mut state = Self::Hasher::new();
        let bytes = bcs::to_bytes(&self).expect("Unable to serialize batch payload");
        self.num_bytes.get_or_init(|| bytes.len());
        state.update(&bytes);
        state.finish()
    }
}
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```
