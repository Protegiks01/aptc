# Audit Report

## Title
TOCTOU Race Condition in ChunkExecutor::with_inner() Leading to False Positive Node Panics

## Summary
The `with_inner()` function in the ChunkExecutor exhibits a Time-of-Check to Time-of-Use (TOCTOU) race condition. The `has_pending_pre_commit` flag is read atomically before executing the inner function, but the flag's value can change during execution by concurrent threads, leading to incorrect panic decisions based on stale data. This causes unnecessary node crashes during normal state synchronization operations. [1](#0-0) 

## Finding Description
The vulnerability exists in the error handling logic of `with_inner()`. The function reads `has_pending_pre_commit` at the beginning (line 96), then executes the provided closure `f(inner)`. If an error occurs, it checks the **stale** value of `has_pending_pre_commit` to decide whether to panic (lines 98-103).

The ChunkExecutor is designed to be accessed concurrently by multiple tasks in the state synchronization pipeline: [2](#0-1) 

Three concurrent tasks share the same `Arc<ChunkExecutor>`:
1. **Executor task** - calls `enqueue_chunk_by_execution()` or `enqueue_chunk_by_transaction_outputs()`
2. **Ledger updater task** - calls `update_ledger()`
3. **Committer task** - calls `commit_chunk()`

All these methods use `with_inner()` which acquires only a **read lock**, allowing concurrent execution. [3](#0-2) 

The race occurs when:
1. **Thread A** (executor) calls `enqueue_chunk_by_execution()` → `with_inner()`
2. Thread A reads `has_pending_pre_commit = true` (line 96)
3. **Thread B** (committer) concurrently calls `commit_chunk()` → `with_inner()` 
4. Thread B successfully commits and sets `has_pending_pre_commit = false` (line 397)
5. Thread A's `enqueue_chunk()` encounters an error (e.g., version mismatch)
6. Thread A panics based on the **stale** `has_pending_pre_commit = true` value from step 2

This results in a **false positive panic** - the node crashes even though the pre-committed ledger has been successfully committed and the state is actually safe. [4](#0-3) [5](#0-4) 

## Impact Explanation
This vulnerability causes **unnecessary node crashes** during normal state synchronization operations, qualifying as **High Severity** per Aptos bug bounty criteria: "Validator node slowdowns" and "API crashes".

The impact includes:
- **Availability degradation**: Validator nodes panic unnecessarily during state sync, reducing network stability
- **Service disruption**: The crashed node must restart and resync, causing temporary unavailability
- **Potential DoS vector**: An attacker could craft transaction chunks that trigger errors during concurrent commit operations, intentionally triggering the race condition to crash nodes

While this doesn't cause consensus violations or loss of funds (not Critical severity), it significantly impacts node reliability and could be weaponized to disrupt network operations.

## Likelihood Explanation
This race condition has a **high likelihood** of occurring in production:

1. **Concurrent design by intent**: The storage synchronizer explicitly spawns three concurrent tasks that share the same ChunkExecutor, making concurrent access the normal operation mode

2. **Large timing window**: The race window extends for the entire duration of `f(inner)` execution, which can be substantial (executing transactions, validating chunks, etc.)

3. **Frequent operations**: State sync operations involving chunk execution and commits happen continuously during node synchronization

4. **Read lock contention**: Both operations only require read locks, so there's no mutual exclusion preventing the race

The race is not theoretical - it can occur during normal operations without any attacker intervention, though an attacker could increase the likelihood by timing chunk submissions to coincide with commit operations.

## Recommendation
Implement proper synchronization by re-checking the `has_pending_pre_commit` flag **after** the error occurs, when making the panic decision:

```rust
fn with_inner<F, T>(&self, f: F) -> Result<T>
where
    F: FnOnce(&ChunkExecutorInner<V>) -> Result<T>,
{
    let locked = self.inner.read();
    let inner = locked.as_ref().expect("not reset");

    f(inner).map_err(|error| {
        // Re-check the flag AFTER the error to avoid TOCTOU race
        let has_pending_pre_commit = inner.has_pending_pre_commit.load(Ordering::Acquire);
        if has_pending_pre_commit {
            panic!(
                "Hit error with pending pre-committed ledger, panicking. {:?}",
                error,
            );
        }
        error
    })
}
```

Alternatively, use a write lock for operations that modify `has_pending_pre_commit`, or upgrade to a write lock before the panic decision to ensure atomicity.

## Proof of Concept
```rust
#[cfg(test)]
mod toctou_race_test {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    #[test]
    #[should_panic(expected = "Hit error with pending pre-committed ledger")]
    fn test_toctou_race_false_positive_panic() {
        // Setup: Create ChunkExecutor with pre-committed state
        let db = /* initialize test DB with pre-committed transactions */;
        let executor = Arc::new(ChunkExecutor::<MockVM>::new(db));
        
        // Barrier to synchronize threads for maximum race likelihood
        let barrier = Arc::new(Barrier::new(2));
        
        // Thread A: Execute chunk that will error
        let executor_a = executor.clone();
        let barrier_a = barrier.clone();
        let handle_a = thread::spawn(move || {
            barrier_a.wait(); // Synchronize start
            // This will call with_inner() and see has_pending_pre_commit = true
            // Then take a long time in enqueue_chunk()
            executor_a.enqueue_chunk_by_execution(
                bad_chunk, // Chunk that causes version mismatch error
                &ledger_info,
                None
            )
        });
        
        // Thread B: Commit chunk successfully
        let executor_b = executor.clone();
        let barrier_b = barrier.clone();
        let handle_b = thread::spawn(move || {
            barrier_b.wait(); // Synchronize start
            thread::sleep(Duration::from_millis(10)); // Let Thread A read flag first
            // This commits successfully and sets has_pending_pre_commit = false
            executor_b.commit_chunk()
        });
        
        // Thread B completes successfully
        assert!(handle_b.join().unwrap().is_ok());
        
        // Thread A panics with stale flag value even though commit succeeded
        // This demonstrates the false positive panic
        handle_a.join().unwrap_err(); // Should panic unnecessarily
    }
}
```

**Notes**:
- The race condition is inherent in the current design where `has_pending_pre_commit` is checked before function execution but used after
- All three concurrent tasks (executor, ledger_updater, committer) in the storage synchronizer can trigger this race
- The window for the race is significant (entire duration of chunk processing)
- This affects node availability but does not compromise consensus safety or cause data corruption
- The fix requires either re-checking the flag after errors or using proper locking to ensure atomicity between the check and the use

### Citations

**File:** execution/executor/src/chunk_executor/mod.rs (L89-106)
```rust
    fn with_inner<F, T>(&self, f: F) -> Result<T>
    where
        F: FnOnce(&ChunkExecutorInner<V>) -> Result<T>,
    {
        let locked = self.inner.read();
        let inner = locked.as_ref().expect("not reset");

        let has_pending_pre_commit = inner.has_pending_pre_commit.load(Ordering::Acquire);
        f(inner).map_err(|error| {
            if has_pending_pre_commit {
                panic!(
                    "Hit error with pending pre-committed ledger, panicking. {:?}",
                    error,
                );
            }
            error
        })
    }
```

**File:** execution/executor/src/chunk_executor/mod.rs (L394-409)
```rust
    fn commit_chunk(&self) -> Result<ChunkCommitNotification> {
        let _timer = COMMIT_CHUNK.start_timer();
        let executed_chunk = self.commit_chunk_impl()?;
        self.has_pending_pre_commit.store(false, Ordering::Release);

        let commit_notification = {
            let _timer =
                CHUNK_OTHER_TIMERS.timer_with(&["commit_chunk__into_chunk_commit_notification"]);
            executed_chunk
                .output
                .expect_complete_result()
                .make_chunk_commit_notification()
        };

        Ok(commit_notification)
    }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L234-262)
```rust
        let executor_handle = spawn_executor(
            chunk_executor.clone(),
            error_notification_sender.clone(),
            executor_listener,
            ledger_updater_notifier,
            pending_data_chunks.clone(),
            runtime.clone(),
        );

        // Spawn the ledger updater that updates the ledger in storage
        let ledger_updater_handle = spawn_ledger_updater(
            chunk_executor.clone(),
            error_notification_sender.clone(),
            ledger_updater_listener,
            committer_notifier,
            pending_data_chunks.clone(),
            runtime.clone(),
        );

        // Spawn the committer that commits executed (but pending) chunks
        let committer_handle = spawn_committer(
            chunk_executor.clone(),
            error_notification_sender.clone(),
            committer_listener,
            commit_post_processor_notifier,
            pending_data_chunks.clone(),
            runtime.clone(),
            storage.reader.clone(),
        );
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1026-1064)
```rust
async fn execute_transaction_chunk<ChunkExecutor: ChunkExecutorTrait + 'static>(
    chunk_executor: Arc<ChunkExecutor>,
    transactions_with_proof: TransactionListWithProofV2,
    target_ledger_info: LedgerInfoWithSignatures,
    end_of_epoch_ledger_info: Option<LedgerInfoWithSignatures>,
) -> anyhow::Result<()> {
    // Execute the transaction chunk
    let num_transactions = transactions_with_proof
        .get_transaction_list_with_proof()
        .transactions
        .len();
    let result = tokio::task::spawn_blocking(move || {
        chunk_executor.enqueue_chunk_by_execution(
            transactions_with_proof,
            &target_ledger_info,
            end_of_epoch_ledger_info.as_ref(),
        )
    })
    .await
    .expect("Spawn_blocking(execute_transaction_chunk) failed!");

    // Update the logs and metrics if the chunk was executed successfully
    if result.is_ok() {
        // Log the execution event
        info!(
            LogSchema::new(LogEntry::StorageSynchronizer).message(&format!(
                "Executed a new transaction chunk! Transaction total: {:?}.",
                num_transactions
            ))
        );

        // Update the chunk metrics
        let operation_label =
            metrics::StorageSynchronizerOperations::ExecutedTransactions.get_label();
        update_synchronizer_chunk_metrics(num_transactions, operation_label);
    }

    result
}
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1094-1100)
```rust
async fn commit_chunk<ChunkExecutor: ChunkExecutorTrait + 'static>(
    chunk_executor: Arc<ChunkExecutor>,
) -> anyhow::Result<ChunkCommitNotification> {
    tokio::task::spawn_blocking(move || chunk_executor.commit_chunk())
        .await
        .expect("Spawn_blocking(commit_chunk) failed!")
}
```
