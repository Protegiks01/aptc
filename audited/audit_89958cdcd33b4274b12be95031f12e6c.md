# Audit Report

## Title
Memory Exhaustion via Unbounded Module ABI Parsing in REST API

## Summary
The REST API endpoint `/accounts/{address}/modules` deserializes and parses the ABI for every module on every request without caching, rate limiting, or memory constraints. An attacker can publish maximum-sized modules and trigger concurrent API requests that each deserialize up to 60GB of bytecode, causing Out-Of-Memory (OOM) errors and API crashes.

## Finding Description

The vulnerability exists in the `Account::modules()` function which processes module retrieval requests for the REST API. The security guarantee broken is **Resource Limits** - specifically that "all operations must respect gas, storage, and computational limits."

### Attack Flow:

**Step 1: Module Size Limits**
Aptos production configuration sets no limits on module definitions: [1](#0-0) 

Individual modules can be up to ~6MB due to transaction size limits: [2](#0-1) 

**Step 2: High Pagination Limit**
The API allows requesting up to 9,999 modules per request: [3](#0-2) 

**Step 3: Unbounded Deserialization**
When JSON format is requested, the API deserializes ALL modules without caching: [4](#0-3) 

Each module creates a new `MoveModuleBytecode` instance and calls `try_parse_abi()`: [5](#0-4) 

The `try_parse_abi()` always deserializes because `abi` is `None` for newly created instances - there is no cross-request caching.

**Step 4: Memory Amplification**
`CompiledModule::deserialize()` loads the entire bytecode into memory and creates complex in-memory data structures that can exceed the raw bytecode size.

**Step 5: Limited Concurrency Control**
The API uses `api_spawn_blocking` which is limited to 64 concurrent blocking threads: [6](#0-5) 

However, there is **no rate limiting** on the REST API endpoints: [7](#0-6) 

### Attack Scenario:
1. Attacker publishes maximum-sized modules to an account (one-time storage cost)
2. Attacker sends multiple concurrent requests: `GET /v1/accounts/{address}/modules?limit=9999`
3. Each request deserializes up to 9,999 × 6MB = ~60GB of bytecode in spawn_blocking tasks
4. With multiple concurrent requests (no rate limiting), memory usage compounds
5. Node exhausts available memory and crashes (OOM) or becomes severely degraded

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos Bug Bounty program criteria:

- **"API crashes"**: The OOM condition causes the REST API service to crash or become unresponsive
- **"Validator node slowdowns"**: If the API runs on validator nodes, memory exhaustion degrades block processing performance

The attack is denial-of-service against the REST API, affecting all clients relying on the API for blockchain interaction. While it doesn't directly compromise consensus or funds, it violates the **Resource Limits** invariant and impacts network availability.

## Likelihood Explanation

**High Likelihood:**
- **Low attack cost**: Attacker pays one-time storage fees to publish large modules
- **Zero ongoing cost**: API requests are free after initial module publication
- **No authentication required**: Public REST API endpoints are accessible to anyone
- **No rate limiting**: Attacker can send unlimited concurrent requests
- **Practical exploitability**: 
  - Creating 100 modules of 6MB each = 600MB (feasible with chunked publishing)
  - Single request processing 100 × 6MB = 600MB deserialization
  - 10 concurrent requests = 6GB memory pressure
  - 64 concurrent requests (thread pool limit) = 38.4GB memory pressure

## Recommendation

Implement multiple defense layers:

**1. Add Module ABI Caching**
Cache parsed ABIs globally with LRU eviction:
```rust
// In Context struct
abi_cache: Arc<Mutex<LruCache<(Address, Identifier), Arc<MoveModule>>>>

// In modules() function
if let Some(cached_abi) = context.abi_cache.lock().get(&(address, module_name)) {
    // Use cached ABI
} else {
    // Parse and cache
    let abi = parse_abi(bytecode)?;
    context.abi_cache.lock().insert((address, module_name), Arc::new(abi));
}
```

**2. Reduce Default Pagination Limit**
Lower `DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE` from 9999 to 100: [3](#0-2) 

**3. Implement Rate Limiting**
Add per-IP rate limiting to the API middleware in runtime.rs similar to the faucet service.

**4. Add Memory-Aware Processing**
Implement streaming or chunked ABI parsing that respects memory budgets.

**5. Set Production Module Limits**
Consider setting non-None values for `max_struct_definitions` and `max_function_definitions` in production config to cap module complexity.

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[tokio::test]
async fn test_module_oom_attack() {
    // Setup: Create test node with API
    let mut test_context = new_test_context();
    let client = test_context.client();
    
    // Step 1: Publish large modules
    const MODULE_SIZE: usize = 5_000_000; // ~5MB
    const MODULE_COUNT: usize = 100;
    
    let attacker = test_context.create_account().await;
    
    for i in 0..MODULE_COUNT {
        let large_module = generate_large_module(MODULE_SIZE, i);
        client.publish_module(attacker.address(), large_module)
            .await
            .unwrap();
    }
    
    // Step 2: Launch concurrent API requests
    let mut handles = vec![];
    for _ in 0..10 {
        let client = client.clone();
        let addr = attacker.address();
        handles.push(tokio::spawn(async move {
            // Request all modules with JSON format (triggers ABI parsing)
            client.get_account_modules(addr)
                .await
        }));
    }
    
    // Step 3: Monitor memory usage
    let start_mem = get_process_memory();
    let results = futures::future::join_all(handles).await;
    let peak_mem = get_process_memory();
    
    // Expect: Memory spike of multiple GB
    assert!(peak_mem - start_mem > 5_000_000_000); // 5GB increase
    
    // Expect: Some requests fail or timeout
    assert!(results.iter().any(|r| r.is_err() || r.as_ref().unwrap().is_err()));
}

fn generate_large_module(target_size: usize, index: usize) -> Vec<u8> {
    // Generate Move module with large constant pool or many functions
    // to reach target_size when compiled
    // Implementation details omitted for brevity
}
```

**Notes:**
- The vulnerability is exacerbated by the fact that once modules are published on-chain, querying them via API is "free" for the attacker
- The issue affects all nodes running the REST API service
- BCS format responses are not affected (they skip ABI parsing), only JSON responses
- The 64 blocking thread limit provides some protection but is insufficient against determined attackers with multiple source IPs

### Citations

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L168-171)
```rust
        max_struct_definitions: None,
        max_struct_variants: None,
        max_fields_in_struct: None,
        max_function_definitions: None,
```

**File:** aptos-move/e2e-testsuite/src/tests/verify_txn.rs (L30-30)
```rust
pub const MAX_TRANSACTION_SIZE_IN_BYTES: u64 = 6 * 1024 * 1024;
```

**File:** config/src/config/api_config.rs (L101-101)
```rust
const DEFAULT_MAX_ACCOUNT_MODULES_PAGE_SIZE: u16 = 9999;
```

**File:** api/src/accounts.rs (L547-559)
```rust
                for (_, module) in modules {
                    converted_modules.push(
                        MoveModuleBytecode::new(module.clone())
                            .try_parse_abi()
                            .context("Failed to parse move module ABI")
                            .map_err(|err| {
                                BasicErrorWith404::internal_with_code(
                                    err,
                                    AptosErrorCode::InternalError,
                                    &self.latest_ledger_info,
                                )
                            })?,
                    );
```

**File:** api/types/src/move_types.rs (L1338-1348)
```rust
    pub fn try_parse_abi(mut self) -> anyhow::Result<Self> {
        if self.abi.is_none() {
            // Ignore error, because it is possible a transaction module payload contains
            // invalid bytecode.
            // So we ignore the error and output bytecode without abi.
            if let Ok(module) = CompiledModule::deserialize(self.bytecode.inner()) {
                self.abi = Some(module.try_into()?);
            }
        }
        Ok(self)
    }
```

**File:** api/src/context.rs (L1644-1656)
```rust
/// the case of an error when joining the task converts it into a 500.
pub async fn api_spawn_blocking<F, T, E>(func: F) -> Result<T, E>
where
    F: FnOnce() -> Result<T, E> + Send + 'static,
    T: Send + 'static,
    E: InternalError + Send + 'static,
{
    tokio::task::spawn_blocking(func)
        .await
        .map_err(|err| E::internal_with_code_no_info(err, AptosErrorCode::InternalError))?
}

#[derive(Schema)]
```

**File:** api/src/runtime.rs (L230-259)
```rust
        let cors = Cors::new()
            // To allow browsers to use cookies (for cookie-based sticky
            // routing in the LB) we must enable this:
            // https://stackoverflow.com/a/24689738/3846032
            .allow_credentials(true)
            .allow_methods(vec![Method::GET, Method::POST]);

        // Build routes for the API
        let route = Route::new()
            .at("/", poem::get(root_handler))
            .nest(
                "/v1",
                Route::new()
                    .nest("/", api_service)
                    .at("/spec.json", poem::get(spec_json))
                    .at("/spec.yaml", poem::get(spec_yaml))
                    // TODO: We add this manually outside of the OpenAPI spec for now.
                    // https://github.com/poem-web/poem/issues/364
                    .at(
                        "/set_failpoint",
                        poem::get(set_failpoints::set_failpoint_poem).data(context.clone()),
                    ),
            )
            .with(cors)
            .with_if(config.api.compression_enabled, Compression::new())
            .with(PostSizeLimit::new(size_limit))
            .with(CatchPanic::new().with_handler(panic_handler))
            // NOTE: Make sure to keep this after all the `with` middleware.
            .catch_all_error(convert_error)
            .around(middleware_log);
```
