# Audit Report

## Title
Missing Root Hash Verification in State Snapshot Restore Allows Silent State Corruption

## Summary
The `JellyfishMerkleRestore::finish_impl()` function does not verify the final root hash against the expected value, allowing incomplete or corrupted state snapshots to be written to storage without detection. When chunks are processed out of order (via custom backup tooling or implementation bugs), earlier chunks are silently skipped, resulting in incomplete state that passes the restore process but breaks state consistency invariants.

## Finding Description

The `BackupServiceClient.get_state_snapshot_chunk()` client function is a simple HTTP GET wrapper that retrieves state snapshot chunks by index without enforcing any ordering constraints. [1](#0-0) 

While the standard backup flow uses `buffered_x` to preserve sequential ordering, custom backup tooling or bugs in the ordering logic could cause chunks to be retrieved or processed out of order. When this occurs during restore, the `JellyfishMerkleRestore::add_chunk_impl()` function silently skips out-of-order chunks rather than failing: [2](#0-1) 

The skip logic returns `Ok(())` without error when an entire chunk's keys are less than or equal to the previous leaf, which occurs when later chunks are processed before earlier chunks. This is intended for resumption after crashes, but enables silent data loss when chunks are genuinely out of order.

More critically, after all chunks are processed, `finish_impl()` freezes remaining nodes and writes them to storage WITHOUT verifying that the final root hash matches the expected value: [3](#0-2) 

The `expected_root_hash` field is stored during initialization but never checked in `finish_impl()`. In contrast, the test code explicitly verifies this: [4](#0-3) 

**Attack Scenario:**
1. Organization develops custom backup tooling that calls `get_state_snapshot_chunk()` with concurrent requests
2. Due to incorrect synchronization, chunks are downloaded in wrong order (e.g., [200-300], [100-200], [0-100])
3. During backup, chunks are written to files in this wrong order
4. During restore, chunk [200-300] is processed successfully
5. Chunks [100-200] and [0-100] are silently skipped (all keys < 300)
6. `finish_impl()` writes the incomplete tree (only keys 200-300) without verification
7. Node starts with corrupted state, fails to sync with network, causes consensus participation failures

## Impact Explanation

This vulnerability breaks Critical Invariant #4: "State Consistency: State transitions must be atomic and verifiable via Merkle proofs" and Invariant #1: "Deterministic Execution: All validators must produce identical state roots for identical blocks."

**Severity Assessment: MEDIUM to HIGH**

Per the Aptos bug bounty criteria:
- **Medium Severity**: "State inconsistencies requiring intervention" - A node restored from corrupted backup would have incomplete state requiring manual investigation and re-restoration
- **High Severity**: "Significant protocol violations" - If multiple nodes use the same corrupted backup, they could temporarily split from the network, though consensus safety is preserved since they represent a minority

The impact depends on detection timing:
- If detected before consensus participation: Requires manual intervention (MEDIUM)
- If node joins consensus before detection: Could cause temporary network instability (HIGH)

## Likelihood Explanation

**Likelihood: MEDIUM**

This vulnerability requires one of the following conditions:
1. **Custom backup tooling** (MOST LIKELY): Organizations often develop custom backup scripts for operational needs. If developers don't understand the ordering requirement or implement incorrect concurrency control, corrupted backups result.
2. **Bug in buffered_x**: The standard flow uses `buffered_x` which has property-based tests, but these aren't exhaustive. A rare race condition could cause ordering violations.
3. **Backup service bug**: The service could return wrong chunks for requested indices due to implementation errors.
4. **Backup file corruption**: Manual or malicious modification of backup files after creation.

The most realistic scenario is custom tooling (#1), which is common in production environments where organizations need specialized backup workflows, disaster recovery procedures, or compliance requirements.

## Recommendation

Add root hash verification to `finish_impl()` before writing the final tree to storage:

```rust
pub fn finish_impl(mut self) -> Result<()> {
    self.wait_for_async_commit()?;
    
    // ... existing special case handling ...
    
    self.freeze(0);
    
    // ADDED: Verify root hash before writing
    let root_node_key = NodeKey::new_empty_path(self.version);
    let root_node = self.frozen_nodes.get(&root_node_key)
        .ok_or_else(|| anyhow!("Root node not found after freeze"))?;
    let actual_root_hash = root_node.hash();
    ensure!(
        actual_root_hash == self.expected_root_hash,
        "State snapshot restore failed: actual root hash {} does not match expected {}. \
         This indicates chunks were processed out of order or the restore is incomplete.",
        actual_root_hash,
        self.expected_root_hash
    );
    
    self.store.write_node_batch(&self.frozen_nodes)?;
    Ok(())
}
```

Additionally, consider adding a warning in `get_state_snapshot_chunk()` documentation about ordering requirements, and providing a reference implementation showing proper use of `buffered_x` for custom tooling.

## Proof of Concept

```rust
#[test]
fn test_out_of_order_chunks_not_detected() {
    // Setup mock storage and create initial tree with keys 0-299
    let db = Arc::new(MockTreeStore::default());
    let mut tree = JellyfishMerkleTree::new(&db);
    let version = 0;
    
    // Insert 300 keys
    let mut kvs = vec![];
    for i in 0u64..300 {
        let key = HashValue::sha3_256_of(&i.to_le_bytes());
        let value = HashValue::sha3_256_of(&(i + 1000).to_le_bytes());
        kvs.push((key, value));
    }
    kvs.sort_by_key(|(k, _)| *k);
    
    let (_root_hash, batch) = tree.put_value_set(kvs.clone(), version).unwrap();
    db.write_tree_update_batch(batch).unwrap();
    let expected_root_hash = tree.get_root_hash(version).unwrap();
    
    // Start restore
    let restore_db = Arc::new(MockTreeStore::default());
    let mut restore = JellyfishMerkleRestore::new(
        restore_db.clone(),
        version,
        expected_root_hash,
        false,
    ).unwrap();
    
    // Process chunks OUT OF ORDER: [200-299], [100-199], [0-99]
    // Chunk 1: keys 200-299 (processed first - WRONG ORDER)
    let chunk1: Vec<_> = kvs[200..300].iter()
        .map(|(k, v)| (k, *v)).collect();
    let proof1 = tree.get_range_proof(chunk1.last().unwrap().0, version).unwrap();
    restore.add_chunk_impl(chunk1, proof1).unwrap();
    
    // Chunk 2: keys 100-199 (will be SKIPPED - keys < 200)
    let chunk2: Vec<_> = kvs[100..200].iter()
        .map(|(k, v)| (k, *v)).collect();
    let proof2 = tree.get_range_proof(chunk2.last().unwrap().0, version).unwrap();
    restore.add_chunk_impl(chunk2, proof2).unwrap();  // Silently skipped!
    
    // Chunk 3: keys 0-99 (will be SKIPPED - keys < 200)
    let chunk3: Vec<_> = kvs[0..100].iter()
        .map(|(k, v)| (k, *v)).collect();
    let proof3 = tree.get_range_proof(chunk3.last().unwrap().0, version).unwrap();
    restore.add_chunk_impl(chunk3, proof3).unwrap();  // Silently skipped!
    
    // Finish succeeds WITHOUT detecting incomplete state
    restore.finish_impl().unwrap();  // Should fail but doesn't!
    
    // Verify corruption: actual root hash differs from expected
    let restored_tree = JellyfishMerkleTree::new(&restore_db);
    let actual_root_hash = restored_tree.get_root_hash(version).unwrap();
    
    assert_ne!(
        actual_root_hash, 
        expected_root_hash,
        "Root hash should differ due to missing keys, but no error was raised!"
    );
}
```

This proof of concept demonstrates that processing chunks out of order results in an incomplete tree being written to storage, with the root hash verification missing to catch this corruption.

## Notes

This vulnerability represents a defense-in-depth failure where the system relies entirely on correct ordering in the backup flow without verifying the final result. While the standard implementation uses `buffered_x` for ordering guarantees, the lack of verification allows bugs in custom tooling, implementation errors, or edge cases to silently corrupt state. The explicit root hash verification in test code but not production code suggests this was an oversight rather than an intentional design decision.

### Citations

**File:** storage/backup/backup-cli/src/utils/backup_service_client.rs (L113-124)
```rust
    pub async fn get_state_snapshot_chunk(
        &self,
        version: Version,
        start_idx: usize,
        limit: usize,
    ) -> Result<impl AsyncRead + use<>> {
        self.get(
            "state_snapshot_chunk",
            &format!("{}/{}/{}", version, start_idx, limit),
        )
        .await
    }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L349-368)
```rust
        if let Some(prev_leaf) = &self.previous_leaf {
            let skip_until = chunk
                .iter()
                .find_position(|(key, _hash)| key.hash() > *prev_leaf.account_key());
            chunk = match skip_until {
                None => {
                    info!("Skipping entire chunk.");
                    return Ok(());
                },
                Some((0, _)) => chunk,
                Some((num_to_skip, next_leaf)) => {
                    info!(
                        num_to_skip = num_to_skip,
                        next_leaf = next_leaf,
                        "Skipping leaves."
                    );
                    chunk.split_off(num_to_skip)
                },
            }
        };
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L748-789)
```rust
    /// Finishes the restoration process. This tells the code that there is no more state,
    /// otherwise we can not freeze the rightmost leaf and its ancestors.
    pub fn finish_impl(mut self) -> Result<()> {
        self.wait_for_async_commit()?;
        // Deal with the special case when the entire tree has a single leaf or null node.
        if self.partial_nodes.len() == 1 {
            let mut num_children = 0;
            let mut leaf = None;
            for i in 0..16 {
                if let Some(ref child_info) = self.partial_nodes[0].children[i] {
                    num_children += 1;
                    if let ChildInfo::Leaf(node) = child_info {
                        leaf = Some(node.clone());
                    }
                }
            }

            match num_children {
                0 => {
                    let node_key = NodeKey::new_empty_path(self.version);
                    assert!(self.frozen_nodes.is_empty());
                    self.frozen_nodes.insert(node_key, Node::Null);
                    self.store.write_node_batch(&self.frozen_nodes)?;
                    return Ok(());
                },
                1 => {
                    if let Some(node) = leaf {
                        let node_key = NodeKey::new_empty_path(self.version);
                        assert!(self.frozen_nodes.is_empty());
                        self.frozen_nodes.insert(node_key, node.into());
                        self.store.write_node_batch(&self.frozen_nodes)?;
                        return Ok(());
                    }
                },
                _ => (),
            }
        }

        self.freeze(0);
        self.store.write_node_batch(&self.frozen_nodes)?;
        Ok(())
    }
```

**File:** storage/aptosdb/src/state_restore/restore_test.rs (L251-252)
```rust
    let actual_root_hash = tree.get_root_hash(version).unwrap();
    assert_eq!(actual_root_hash, expected_root_hash);
```
