# Audit Report

## Title
Premature Cache Eviction in Indexer Data Service Causes Immediate Loss of Freshly Written Transaction Data

## Summary
The `DataManager::update_data()` function contains a critical ordering bug where the eviction loop can immediately evict transaction data that was just written in the same function call. When a large batch of transactions exceeds the size limit, the eviction process starts from an updated `start_version` that points into the range of newly written data, causing up to 99% of freshly fetched transactions to be evicted before they can be served to clients. [1](#0-0) 

## Finding Description
The vulnerability exists in the sequencing of operations within `update_data()`. The function performs these operations in order:

1. **Write Phase** (lines 75-87): New transactions are written to the circular buffer, overwriting old data
2. **Window Update** (lines 89-93): `start_version` is advanced to maintain the sliding window constraint
3. **Size Update** (lines 104-105): Total cache size is recalculated  
4. **Eviction Phase** (lines 107-117): If size limit exceeded, evict data starting from the UPDATED `start_version` [2](#0-1) 

The critical flaw is at line 92, where `start_version` is updated to `end_version - num_slots` to maintain the circular buffer constraint. This moves `start_version` forward into the range of data that was just written. Subsequently, when eviction triggers at line 110, it uses this NEW `start_version` value and begins evicting from the modulo position, which now contains freshly written data. [3](#0-2) 

**Concrete Exploitation Scenario:**

Initial State:
- `num_slots = 1,000`, `size_limit_bytes = 10MB`
- Cache contains versions [0, 1,000) with small transactions (10KB each) = 10MB total
- `start_version = 0`, `end_version = 1,000`

Trigger: Fetch large batch
- FetchManager retrieves versions [1,000, 2,000) containing 1,000 transactions of 1MB each = 1GB total [4](#0-3) 

Execution Flow:
1. Lines 75-87: Write all 1,000 transactions to slots [0, 999], `size_increased = 1GB`, `size_decreased = 10MB`
2. Line 92: Since `0 + 1,000 < 2,000`, update `self.start_version = 2,000 - 1,000 = 1,000`
3. Line 105: `total_size = 10MB + 1GB - 10MB = 1GB`
4. Line 107: `1GB >= 10MB` triggers eviction
5. Lines 110-115: Evict from slot `1,000 % 1,000 = 0` â†’ This is version 1,000 (just written!)
6. Loop continues evicting versions 1,000, 1,001, 1,002... until reaching 10MB threshold
7. Approximately 990 transactions evicted, `start_version` becomes ~1,990

Result: Only versions [1,990, 2,000) remain servable. Versions [1,000, 1,990) were written then immediately evicted. [5](#0-4) 

When clients request data in the lost range, they receive "Requested data is too old" errors with no recovery mechanism. [6](#0-5) 

## Impact Explanation
This vulnerability causes severe data availability degradation in the Indexer gRPC Data Service. While this is not a consensus-critical component, it represents a **High Severity** issue under the category "API crashes / Significant protocol violations" because:

1. **Service Degradation**: The indexer API fails to serve data that was successfully fetched, violating the protocol expectation that recently retrieved blockchain data should be available
2. **Client Impact**: Applications relying on the indexer receive repeated "data too old" errors for recent versions, causing application failures
3. **No Recovery Path**: Once evicted, the data cannot be recovered from cache and clients must fall back to slower historical data service or fail entirely
4. **Realistic Trigger**: Large transactions (common in complex smart contracts, NFT minting, governance proposals) naturally trigger this condition

The default configuration has `size_limit_bytes = 10GB` and `num_slots = 5,000,000`, making this exploitable when large transaction batches arrive. [7](#0-6) 

## Likelihood Explanation
**High Likelihood** - This bug triggers automatically during normal operations when:
- Transaction batches contain large transactions (governance proposals, complex smart contract executions, large data storage)
- Cache is near capacity
- FetchManager retrieves a full batch from upstream

No attacker action required - legitimate blockchain activity naturally causes this condition. The bug manifests whenever `size_increased - size_decreased` causes total size to exceed the limit after window adjustment.

## Recommendation
Reorder operations to perform eviction BEFORE updating the sliding window, or track the range of newly written data and exclude it from eviction:

**Option 1: Evict Before Window Update**
```rust
// After writing new data (line 87)
// Perform eviction BEFORE updating start_version
if self.total_size >= self.size_limit_bytes {
    while self.total_size >= self.eviction_target {
        if let Some(transaction) = 
            self.data[self.start_version as usize % self.num_slots].take() 
        {
            self.total_size -= transaction.encoded_len();
            drop(transaction);
        }
        self.start_version += 1;
    }
}

// THEN update window for newly written data
if end_version > self.end_version {
    self.end_version = end_version;
    if self.start_version + (self.num_slots as u64) < end_version {
        self.start_version = self.start_version.max(end_version - self.num_slots as u64);
    }
}
```

**Option 2: Protect Newly Written Range**
```rust
let newly_written_start = start_version;
let newly_written_end = end_version;

// In eviction loop, skip newly written range
while self.total_size >= self.eviction_target {
    if self.start_version >= newly_written_start && 
       self.start_version < newly_written_end {
        break; // Don't evict data written in this call
    }
    // ... rest of eviction logic
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_protos::transaction::v1::Transaction;

    #[test]
    fn test_premature_eviction_vulnerability() {
        // Setup: Small cache with small transactions
        let num_slots = 1000;
        let size_limit_bytes = 10 * 1024 * 1024; // 10MB
        let mut manager = DataManager::new(1000, num_slots, size_limit_bytes);
        
        // Fill cache with small transactions (10KB each)
        let small_txns: Vec<Transaction> = (0..1000)
            .map(|_| create_transaction_of_size(10 * 1024))
            .collect();
        manager.update_data(0, small_txns);
        
        assert_eq!(manager.start_version, 0);
        assert_eq!(manager.end_version, 1000);
        
        // Trigger vulnerability: Large batch of 1MB transactions
        let large_txns: Vec<Transaction> = (0..1000)
            .map(|_| create_transaction_of_size(1024 * 1024))
            .collect();
        
        manager.update_data(1000, large_txns);
        
        // BUG: start_version should be 1000, but after eviction
        // it has advanced far beyond, evicting freshly written data
        assert!(manager.start_version > 1000, 
            "start_version {} should be > 1000 after eviction", 
            manager.start_version);
        
        // Most of the newly written data [1000, 2000) is now inaccessible
        let accessible_count = (manager.start_version..manager.end_version).count();
        assert!(accessible_count < 100, 
            "Only {} transactions accessible out of 1000 written",
            accessible_count);
        
        // Verify that get_data returns None for evicted versions
        assert!(manager.get_data(1000).is_none(), 
            "Version 1000 should be evicted but is still accessible");
    }
    
    fn create_transaction_of_size(size: usize) -> Transaction {
        // Helper to create transaction of specific size
        Transaction {
            version: 0,
            // Fill with data to reach desired size
            ..Default::default()
        }
    }
}
```

**Notes:**
- This vulnerability exists in the indexer gRPC data service, which provides transaction data to external consumers
- While not consensus-critical, it severely impacts the reliability and availability of the indexer API
- The bug is triggered by normal blockchain operations involving large transactions, not malicious activity
- Impact is limited to data availability within the indexer cache, not blockchain state or consensus

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L89-93)
```rust
        if end_version > self.end_version {
            self.end_version = end_version;
            if self.start_version + (self.num_slots as u64) < end_version {
                self.start_version = end_version - self.num_slots as u64;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L107-117)
```rust
        if self.total_size >= self.size_limit_bytes {
            while self.total_size >= self.eviction_target {
                if let Some(transaction) =
                    self.data[self.start_version as usize % self.num_slots].take()
                {
                    self.total_size -= transaction.encoded_len();
                    drop(transaction);
                }
                self.start_version += 1;
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L48-64)
```rust
    async fn fetch_and_update_cache(
        data_client: Arc<DataClient>,
        data_manager: Arc<RwLock<DataManager>>,
        version: u64,
    ) -> usize {
        let transactions = data_client.fetch_transactions(version).await;
        let len = transactions.len();

        if len > 0 {
            data_manager
                .write()
                .await
                .update_data(version, transactions);
        }

        len
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L68-71)
```rust
            trace!("Getting data from cache, requested_version: {starting_version}, oldest available version: {}.", data_manager.start_version);
            if starting_version < data_manager.start_version {
                return None;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L226-232)
```rust
                let err = Err(Status::not_found("Requested data is too old."));
                info!(stream_id = id, "Client error: {err:?}.");
                let _ = response_sender.send(err).await;
                COUNTER
                    .with_label_values(&["terminate_requested_data_too_old"])
                    .inc();
                break;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L67-73)
```rust
    fn default_num_slots() -> usize {
        5_000_000
    }

    fn default_size_limit_bytes() -> usize {
        10_000_000_000
    }
```
