# Audit Report

## Title
Unbounded String Accumulation in Move Parser Enables API Memory Exhaustion Attack

## Summary
The Move type parser in `parser.rs` accumulates characters into strings without length validation, allowing attackers to exhaust API server memory by sending malicious type tags with extremely long identifiers through the `/view` REST API endpoint.

## Finding Description

The `next_token()` function in the Move parser accumulates characters into dynamically-sized strings without checking length constraints before semantic validation. Multiple token types suffer from this issue: [1](#0-0) 

The parser accumulates identifier characters unbounded. Similarly, hex addresses and other token types have unbounded accumulation: [2](#0-1) 

The vulnerability is exposed through the public REST API `/view` endpoint, which deserializes `MoveType` from JSON strings: [3](#0-2) 

This deserialization process calls the parser without pre-validating string lengths. The API accepts `ViewRequest` containing type arguments: [4](#0-3) 

**Attack Path:**
1. Attacker sends POST `/view` with JSON payload containing extremely long identifiers in type arguments
2. JSON deserialization triggers `MoveType::from_str()` 
3. Parser's `next_token()` accumulates millions of characters into heap-allocated strings
4. Memory allocation occurs BEFORE semantic validation
5. Move's identifier validation has no length limits: [5](#0-4) 

**Example Malicious Payload:**
```json
{
  "function": "0x1::coin::balance",
  "type_arguments": ["0x1::aaaaaaaaaa...(7MB of 'a')...aaa::Type"],
  "arguments": []
}
```

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." While gas limits apply to execution, parsing happens pre-execution without resource bounds.

## Impact Explanation

**Severity: Medium to High**

An attacker can exhaust API server memory through concurrent requests, causing API unresponsiveness or crashes. Each request can contain identifiers up to the content-length limit (default 8 MB): [6](#0-5) 

With 100 concurrent requests each allocating ~8 MB during parsing, the attack consumes 800+ MB before validation, potentially triggering out-of-memory conditions.

This qualifies as **High Severity** under the bug bounty criteria: "API crashes" and potentially "Validator node slowdowns" if API services run on validator infrastructure.

## Likelihood Explanation

**High likelihood** - The attack is trivial to execute:
- Public endpoint requires no authentication
- Payload construction is straightforward
- No rate limiting on parsing operations
- Works against default configurations

The only limiting factor is the content-length restriction, but this still permits multi-megabyte allocations per request.

## Recommendation

Add length validation during tokenization before string accumulation:

```rust
// In next_token() for identifiers:
c if c.is_ascii_alphabetic() => {
    let mut r = String::new();
    r.push(c);
    const MAX_IDENTIFIER_LENGTH: usize = 255;
    for c in it {
        if identifier::is_valid_identifier_char(c) {
            if r.len() >= MAX_IDENTIFIER_LENGTH {
                bail!("Identifier exceeds maximum length of {}", MAX_IDENTIFIER_LENGTH);
            }
            r.push(c);
        } else {
            break;
        }
    }
    let len = r.len();
    (name_token(r), len)
}

// Similar limits for addresses (64 hex chars + "0x" = 66 max)
// and other token types
```

Additionally, enforce identifier length limits in the validation layer:

```rust
// In identifier.rs
pub const MAX_IDENTIFIER_LENGTH: usize = 255;

pub const fn is_valid(s: &str) -> bool {
    if s.len() > MAX_IDENTIFIER_LENGTH {
        return false;
    }
    // ... existing validation
}
```

## Proof of Concept

```rust
// Reproduction test - add to api/src/tests/view_function_test.rs
#[tokio::test]
async fn test_long_identifier_memory_exhaustion() {
    let context = new_test_context();
    
    // Create malicious type tag with 5MB identifier
    let long_identifier = "a".repeat(5_000_000);
    let malicious_type = format!("0x1::{}::Type", long_identifier);
    
    let request = ViewRequest {
        function: EntryFunctionId::from_str("0x1::coin::balance").unwrap(),
        type_arguments: vec![MoveType::from_str(&malicious_type).unwrap()],
        arguments: vec![],
    };
    
    // This will allocate 5MB+ during parsing
    // Multiple concurrent requests would exhaust memory
    let result = view_function(&context, request).await;
    
    // Should fail with validation error, not OOM
    assert!(result.is_err());
}
```

**Notes**

While a content-length limit exists, it doesn't prevent per-field abuse. The parser allocates memory proportional to input size before validating semantic constraints. This creates an asymmetry where small requests can trigger large allocations, violating the principle of proportional resource consumption. The issue is particularly concerning because legitimate Move identifiers should never approach megabyte sizes - the lack of early bounds checking represents a defense-in-depth failure.

### Citations

**File:** third_party/move/move-core/types/src/parser.rs (L119-136)
```rust
            '0' if it.peek() == Some(&'x') || it.peek() == Some(&'X') => {
                it.next().unwrap();
                match it.next() {
                    Some(c) if c.is_ascii_hexdigit() => {
                        let mut r = String::new();
                        r.push('0');
                        r.push('x');
                        r.push(c);
                        for c in it {
                            if c.is_ascii_hexdigit() {
                                r.push(c);
                            } else {
                                break;
                            }
                        }
                        let len = r.len();
                        (Token::Address(r), len)
                    },
```

**File:** third_party/move/move-core/types/src/parser.rs (L180-192)
```rust
            c if c.is_ascii_alphabetic() => {
                let mut r = String::new();
                r.push(c);
                for c in it {
                    if identifier::is_valid_identifier_char(c) {
                        r.push(c);
                    } else {
                        break;
                    }
                }
                let len = r.len();
                (name_token(r), len)
            },
```

**File:** api/types/src/move_types.rs (L813-832)
```rust
impl FromStr for MoveType {
    type Err = anyhow::Error;

    fn from_str(mut s: &str) -> Result<Self, Self::Err> {
        let mut is_ref = false;
        let mut is_mut = false;
        if s.starts_with('&') {
            s = &s[1..];
            is_ref = true;
        }
        if is_ref && s.starts_with("mut ") {
            s = &s[4..];
            is_mut = true;
        }
        // Previously this would just crap out, but this meant the API could
        // return a serialized version of an object and not be able to
        // deserialize it using that same object.
        let inner = match parse_type_tag(s) {
            Ok(inner) => (&inner).into(),
            Err(_e) => MoveType::Unparsable(s.to_string()),
```

**File:** api/types/src/view.rs (L13-21)
```rust
/// View request for the Move View Function API
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, Object)]
pub struct ViewRequest {
    pub function: EntryFunctionId,
    /// Type arguments of the function
    pub type_arguments: Vec<MoveType>,
    /// Arguments of the function
    pub arguments: Vec<serde_json::Value>,
}
```

**File:** third_party/move/move-core/types/src/identifier.rs (L82-94)
```rust
pub const fn is_valid(s: &str) -> bool {
    // Rust const fn's don't currently support slicing or indexing &str's, so we
    // have to operate on the underlying byte slice. This is not a problem as
    // valid identifiers are (currently) ASCII-only.
    let b = s.as_bytes();
    match b {
        b"<SELF>" => true,
        [b'<', b'S', b'E', b'L', b'F', b'>', b'_', ..] if b.len() > 7 => all_bytes_numeric(b, 7),
        [b'a'..=b'z', ..] | [b'A'..=b'Z', ..] => all_bytes_valid(b, 1),
        [b'_', ..] | [b'$', ..] if b.len() > 1 => all_bytes_valid(b, 1),
        _ => false,
    }
}
```

**File:** config/src/config/api_config.rs (L97-97)
```rust
const DEFAULT_REQUEST_CONTENT_LENGTH_LIMIT: u64 = 8 * 1024 * 1024; // 8 MB
```
