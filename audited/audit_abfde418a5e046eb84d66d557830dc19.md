# Audit Report

## Title
Indexer State Inconsistency: Token Deletions Fail to Update Current State When Table Metadata is Missing

## Summary
When tokens are deleted in a transaction batch that doesn't contain the TokenStore resource metadata, the indexer creates historical records but fails to update the current state table, causing permanent inconsistency between `token_ownerships` (historical) and `current_token_ownerships` (current state).

## Finding Description

The Aptos indexer maintains two database tables for token ownership tracking:
- `token_ownerships`: Historical record of all ownership changes
- `current_token_ownerships`: Latest state snapshot (upsert-based)

When processing token deletions via `DeleteTableItem`, the system relies on `table_handle_to_owner` mapping built from `WriteResource` changes in the **current batch only**. [1](#0-0) 

For token deletions, the code path is:

1. `Token::from_delete_table_item()` is called for the deletion [2](#0-1) 

2. This calls `TokenOwnership::from_token()` with `amount = BigDecimal::zero()` [3](#0-2) 

3. If `table_handle_to_owner` lookup returns `None` (metadata missing), the function logs a warning and returns `curr_token_ownership = None` [4](#0-3) 

4. The historical `TokenOwnership` is still created with `owner_address = None` and `amount = 0`, but `CurrentTokenOwnership` is `None`

5. During database insertion, `insert_current_token_ownerships()` is never called with a deletion record [5](#0-4) 

6. The existing row in `current_token_ownerships` remains unchanged, showing stale ownership data

**Exploitation Scenario:**

1. Batch N: User creates/receives token â†’ `current_token_ownerships` shows `{owner: Alice, amount: 1}`
2. Batch M (M > N): User burns token, but batch M contains no `WriteResource` for Alice's TokenStore (only `DeleteTableItem`)
3. `table_handle_to_owner` built from batch M doesn't contain the mapping
4. Historical table gets `{owner: null, amount: 0}` (deletion recorded but incomplete)
5. Current table still shows `{owner: Alice, amount: 1}` (NOT updated)
6. On-chain state is correct (token deleted), but indexer shows incorrect ownership

This breaks the indexer's core invariant: **current state tables must accurately reflect the latest on-chain state**.

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Affected Systems:**
- Indexer database queries return incorrect current ownership data
- Applications/wallets querying the indexer API receive stale data
- Users may see tokens they no longer own
- Requires database manual correction or re-indexing from genesis

**No Impact On:**
- Consensus (indexer is off-chain)
- On-chain state (blockchain state is correct)
- Fund security (actual ownership is enforced on-chain)

The severity is Medium rather than Low because this is a systematic bug affecting data integrity that requires operational intervention, not just a minor information leak.

## Likelihood Explanation

**High Likelihood:**

This bug triggers whenever:
1. Token deletion occurs in a batch separate from TokenStore resource writes
2. Common in normal operations where users burn/transfer tokens without other TokenStore modifications

**Frequency:** Expected to occur regularly in production as:
- Batches process multiple transactions from different users
- Token deletions don't always coincide with TokenStore writes in the same batch
- The indexer processes ~1000s of transactions per batch

**Affected Users:** Any token holder performing burns, transfers, or offers that result in `DeleteTableItem` operations.

## Recommendation

**Solution 1: Persistent Metadata Cache (Recommended)**

Query the database for missing table handle metadata instead of relying solely on current batch:

```rust
// In TokenOwnership::from_token()
let maybe_table_metadata = table_handle_to_owner.get(&table_handle)
    .or_else(|| {
        // Fallback: query database for previous owner
        query_table_handle_owner_from_db(conn, &table_handle, txn_version)
    });
```

**Solution 2: Zero-Amount Deletion Record**

When metadata is missing, still create `CurrentTokenOwnership` with `amount = 0` to record the deletion:

```rust
None => {
    aptos_logger::warn!(/* ... */);
    // Create deletion record even without full metadata
    let curr_token_ownership = Some(CurrentTokenOwnership {
        token_data_id_hash: token.token_data_id_hash.clone(),
        property_version: token.property_version.clone(),
        owner_address: "0x0".to_string(), // Placeholder or query from DB
        amount: BigDecimal::zero(),
        // ... other fields
    });
    (curr_token_ownership, None, None)
}
```

**Solution 3: Multi-Pass Processing**

Build `table_handle_to_owner` from the entire transaction history, not just the current batch, by querying existing TokenStore resources in the database before processing.

## Proof of Concept

```rust
#[cfg(test)]
mod test_token_deletion_bug {
    use super::*;
    
    #[test]
    fn test_deletion_without_metadata_causes_state_inconsistency() {
        // Setup: Create token in batch 1
        let batch1_transactions = vec![/* create TokenStore with token */];
        let table_handle_to_owner_batch1 = TableMetadataForToken::get_table_handle_to_owner_from_transactions(&batch1_transactions);
        
        // Process batch 1 - creates current_token_ownerships entry
        let (_, _, _, _, current_ownerships_1, _, _, _) = Token::from_transaction(
            &batch1_transactions[0],
            &table_handle_to_owner_batch1,
            &mut conn,
        );
        
        // Verify: current_token_ownerships shows ownership with amount=1
        assert_eq!(current_ownerships_1.len(), 1);
        let ownership = current_ownerships_1.values().next().unwrap();
        assert_eq!(ownership.amount, BigDecimal::from(1));
        assert_eq!(ownership.owner_address, "0xalice");
        
        // Act: Delete token in batch 2 WITHOUT TokenStore WriteResource
        let batch2_transactions = vec![/* DeleteTableItem only */];
        let table_handle_to_owner_batch2 = TableMetadataForToken::get_table_handle_to_owner_from_transactions(&batch2_transactions);
        
        // Process batch 2 - should update current_token_ownerships
        let (_, _, _, _, current_ownerships_2, _, _, _) = Token::from_transaction(
            &batch2_transactions[0],
            &table_handle_to_owner_batch2, // Missing metadata!
            &mut conn,
        );
        
        // BUG: current_ownerships_2 is EMPTY (no update created)
        assert_eq!(current_ownerships_2.len(), 0);
        
        // Result: Database still shows old ownership
        // This is the vulnerability - current state is stale
    }
}
```

**Notes:**
- This is an indexer-specific bug that doesn't affect blockchain consensus or on-chain state
- The vulnerability causes data integrity issues for off-chain queries
- Systematic occurrence makes it a reliable medium-severity issue requiring operational fixes

### Citations

**File:** crates/indexer/src/models/token_models/tokens.rs (L293-344)
```rust
    pub fn from_delete_table_item(
        table_item: &APIDeleteTableItem,
        txn_version: i64,
        txn_timestamp: chrono::NaiveDateTime,
        table_handle_to_owner: &TableHandleToOwner,
    ) -> anyhow::Result<Option<(Self, Option<TokenOwnership>, Option<CurrentTokenOwnership>)>> {
        let table_item_data = table_item.data.as_ref().unwrap();

        let maybe_token_id = match TokenWriteSet::from_table_item_type(
            table_item_data.key_type.as_str(),
            &table_item_data.key,
            txn_version,
        )? {
            Some(TokenWriteSet::TokenId(inner)) => Some(inner),
            _ => None,
        };

        if let Some(token_id) = maybe_token_id {
            let token_data_id = token_id.token_data_id;
            let collection_data_id_hash = token_data_id.get_collection_data_id_hash();
            let token_data_id_hash = token_data_id.to_hash();
            let collection_name = token_data_id.get_collection_trunc();
            let name = token_data_id.get_name_trunc();

            let token = Self {
                collection_data_id_hash,
                token_data_id_hash,
                creator_address: standardize_address(&token_data_id.creator),
                collection_name,
                name,
                property_version: token_id.property_version,
                transaction_version: txn_version,
                token_properties: serde_json::Value::Null,
                transaction_timestamp: txn_timestamp,
            };
            let (token_ownership, current_token_ownership) = TokenOwnership::from_token(
                &token,
                table_item_data.key_type.as_str(),
                &table_item_data.key,
                BigDecimal::zero(),
                table_item.handle.to_string(),
                table_handle_to_owner,
            )?
            .map(|(token_ownership, current_token_ownership)| {
                (Some(token_ownership), current_token_ownership)
            })
            .unwrap_or((None, None));
            Ok(Some((token, token_ownership, current_token_ownership)))
        } else {
            Ok(None)
        }
    }
```

**File:** crates/indexer/src/models/token_models/tokens.rs (L350-373)
```rust
    pub fn get_table_handle_to_owner_from_transactions(
        transactions: &[APITransaction],
    ) -> TableHandleToOwner {
        let mut table_handle_to_owner: TableHandleToOwner = HashMap::new();
        // Do a first pass to get all the table metadata in the batch.
        for transaction in transactions {
            if let APITransaction::UserTransaction(user_txn) = transaction {
                let txn_version = user_txn.info.version.0 as i64;
                for wsc in &user_txn.info.changes {
                    if let APIWriteSetChange::WriteResource(write_resource) = wsc {
                        let maybe_map = TableMetadataForToken::get_table_handle_to_owner(
                            write_resource,
                            txn_version,
                        )
                        .unwrap();
                        if let Some(map) = maybe_map {
                            table_handle_to_owner.extend(map);
                        }
                    }
                }
            }
        }
        table_handle_to_owner
    }
```

**File:** crates/indexer/src/models/token_models/token_ownerships.rs (L66-142)
```rust
    pub fn from_token(
        token: &Token,
        table_item_key_type: &str,
        table_item_key: &Value,
        amount: BigDecimal,
        table_handle: String,
        table_handle_to_owner: &TableHandleToOwner,
    ) -> anyhow::Result<Option<(Self, Option<CurrentTokenOwnership>)>> {
        let txn_version = token.transaction_version;
        let maybe_token_id = match TokenWriteSet::from_table_item_type(
            table_item_key_type,
            table_item_key,
            txn_version,
        )? {
            Some(TokenWriteSet::TokenId(inner)) => Some(inner),
            _ => None,
        };
        // Return early if table key is not token id
        if maybe_token_id.is_none() {
            return Ok(None);
        }
        let table_handle = standardize_address(&table_handle);
        let maybe_table_metadata = table_handle_to_owner.get(&table_handle);
        // Return early if table type is not tokenstore
        if let Some(tm) = maybe_table_metadata {
            if tm.table_type != "0x3::token::TokenStore" {
                return Ok(None);
            }
        }
        let (curr_token_ownership, owner_address, table_type) = match maybe_table_metadata {
            Some(tm) => (
                Some(CurrentTokenOwnership {
                    collection_data_id_hash: token.collection_data_id_hash.clone(),
                    token_data_id_hash: token.token_data_id_hash.clone(),
                    property_version: token.property_version.clone(),
                    owner_address: standardize_address(&tm.owner_address),
                    creator_address: standardize_address(&token.creator_address.clone()),
                    collection_name: token.collection_name.clone(),
                    name: token.name.clone(),
                    amount: amount.clone(),
                    token_properties: token.token_properties.clone(),
                    last_transaction_version: txn_version,
                    table_type: tm.table_type.clone(),
                    last_transaction_timestamp: token.transaction_timestamp,
                }),
                Some(standardize_address(&tm.owner_address)),
                Some(tm.table_type.clone()),
            ),
            None => {
                aptos_logger::warn!(
                    transaction_version = txn_version,
                    table_handle = table_handle,
                    "Missing table handle metadata for TokenStore. {:?}",
                    table_handle_to_owner
                );
                (None, None, None)
            },
        };

        Ok(Some((
            Self {
                collection_data_id_hash: token.collection_data_id_hash.clone(),
                token_data_id_hash: token.token_data_id_hash.clone(),
                property_version: token.property_version.clone(),
                owner_address: owner_address.map(|s| standardize_address(&s)),
                creator_address: standardize_address(&token.creator_address),
                collection_name: token.collection_name.clone(),
                name: token.name.clone(),
                amount,
                table_type,
                transaction_version: token.transaction_version,
                table_handle,
                transaction_timestamp: token.transaction_timestamp,
            },
            curr_token_ownership,
        )))
    }
```

**File:** crates/indexer/src/processors/token_processor.rs (L380-410)
```rust
fn insert_current_token_ownerships(
    conn: &mut PgConnection,
    items_to_insert: &[CurrentTokenOwnership],
) -> Result<(), diesel::result::Error> {
    use schema::current_token_ownerships::dsl::*;

    let chunks = get_chunks(items_to_insert.len(), CurrentTokenOwnership::field_count());

    for (start_ind, end_ind) in chunks {
        execute_with_better_error(
            conn,
            diesel::insert_into(schema::current_token_ownerships::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict((token_data_id_hash, property_version, owner_address))
                .do_update()
                .set((
                    creator_address.eq(excluded(creator_address)),
                    collection_name.eq(excluded(collection_name)),
                    name.eq(excluded(name)),
                    amount.eq(excluded(amount)),
                    token_properties.eq(excluded(token_properties)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    collection_data_id_hash.eq(excluded(collection_data_id_hash)),
                    table_type.eq(excluded(table_type)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
            Some(" WHERE current_token_ownerships.last_transaction_version <= excluded.last_transaction_version "),
        )?;
    }
    Ok(())
}
```
