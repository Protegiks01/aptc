# Audit Report

## Title
Consensus Observer Pending Block Store Pollution During Commit Sync Error Recovery

## Summary
The consensus observer's error recovery mechanism for invalid commit sync notifications fails to clean up the pending block store, allowing stale pending blocks to accumulate across repeated error-recovery cycles. This eventually causes the observer to hit the `max_num_pending_blocks` limit and drop legitimate blocks, breaking observer functionality.

## Finding Description

The consensus observer maintains three block stores in `ObserverBlockData`: payload store, ordered block store, and pending block store. When state sync completes with an invalid notification (epoch/round ahead of current block data root), the error recovery path only clears the state sync manager handle but fails to clean up the pending block store. [1](#0-0) 

This error path only calls `clear_active_commit_sync()` without cleaning up block data stores. In contrast, when `update_blocks_for_state_sync_commit()` is invoked for a new commit decision, it only clears the payload and ordered block stores, but not the pending block store: [2](#0-1) 

The correct cleanup behavior is demonstrated in `clear_block_data()` which clears all three stores: [3](#0-2) 

**Attack Scenario:**

1. Observer receives commit decision CD1 for (epoch E1, round R1)
2. Pending blocks accumulate in the pending block store while waiting for payloads
3. Observer's block data root is at (epoch E0, round R0) where (E0, R0) < (E1, R1)
4. State sync starts syncing to (E1, R1)
5. Meanwhile, commit decision CD2 arrives for (epoch E2, round R2) where (E0, R0) < (E2, R2) < (E1, R1)
6. `update_blocks_for_state_sync_commit(CD2)` is called, updating root to (E2, R2) and clearing payloads/ordered blocks but NOT pending blocks
7. State sync for (E1, R1) completes and sends notification
8. Notification validation fails: (E1, R1) > (E2, R2)
9. Error path clears only state sync handle, leaving stale pending blocks in the store
10. Repeat this cycle during network instability or catch-up scenarios
11. Pending blocks accumulate until hitting `max_num_pending_blocks` limit
12. New legitimate pending blocks are dropped, breaking observer functionality [4](#0-3) 

## Impact Explanation

This is a **Medium severity** vulnerability per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Impact:**
- Observer nodes gradually accumulate stale pending blocks across error-recovery cycles
- Once `max_num_pending_blocks` limit is reached, new legitimate blocks are silently dropped
- Observer becomes unable to process new consensus blocks, losing synchronization
- Requires manual intervention (observer restart) to clear accumulated pollution
- Affects observer network health and reliability during periods of network instability

The vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." The observer's internal state becomes polluted with stale blocks that are never cleaned up.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is triggered by natural network conditions rather than requiring active exploitation:

- **Network delays** causing commit decisions to arrive out of order
- **Observer catch-up** scenarios where the observer is synchronizing from behind
- **Epoch transitions** where commit decisions for different epochs overlap
- **Chain reorganizations** in edge cases

The race condition occurs when:
1. State sync is in progress for commit C1
2. A newer commit C2 with lower epoch/round arrives and updates block data
3. State sync for C1 completes, triggering the error path

This can happen repeatedly during periods of network instability or when observers are catching up, causing cumulative pollution over time.

## Recommendation

The error recovery path at line 1021 should clean up the pending block store along with clearing the state sync handle. The fix should mirror the successful fallback completion path:

```rust
if (synced_epoch, synced_round) > (block_data_epoch, block_data_root) {
    // Log the error
    error!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Received invalid commit sync notification for epoch: {}, round: {}! Current root: {:?}",
            synced_epoch, synced_round, block_data_root
        ))
    );
    
    // Clear ALL pending block state, not just the sync handle
    self.clear_pending_block_state().await;
    
    // Clear the state sync manager handle
    self.state_sync_manager.clear_active_commit_sync();
    
    return;
}
```

Alternatively, modify `update_blocks_for_state_sync_commit()` to also clear the pending block store:

```rust
pub fn update_blocks_for_state_sync_commit(&mut self, commit_decision: &CommitDecision) {
    let commit_proof = commit_decision.commit_proof();
    let commit_epoch = commit_decision.epoch();
    let commit_round = commit_decision.round();

    self.update_root(commit_proof.clone());
    
    self.block_payload_store
        .remove_blocks_for_epoch_round(commit_epoch, commit_round);
    
    self.ordered_block_store
        .remove_blocks_for_commit(commit_proof);
    
    // ADD: Clear pending blocks as well
    self.pending_block_store.clear_missing_blocks();
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_commit_sync_error_pollutes_pending_blocks() {
    // Setup consensus observer with mocked components
    let (observer, block_data) = setup_test_observer();
    let max_pending = observer.consensus_observer_config.max_num_pending_blocks;
    
    // Simulate the pollution scenario multiple times
    for cycle in 0..10 {
        // Add pending blocks to the store
        for i in 0..5 {
            let pending_block = create_pending_block(cycle * 100 + i);
            block_data.lock().insert_pending_block(pending_block);
        }
        
        // Simulate commit decision arriving, triggering state sync
        let commit_decision_1 = create_commit_decision(100 + cycle, 50 + cycle);
        
        // Update block data to a newer commit (triggering the race)
        let commit_decision_2 = create_commit_decision(100 + cycle, 40 + cycle);
        block_data.lock().update_blocks_for_state_sync_commit(&commit_decision_2);
        
        // State sync completes for the older commit, triggering error path
        let notification = StateSyncNotification::CommitSyncCompleted(
            commit_decision_1.commit_proof().clone()
        );
        observer.process_state_sync_notification(notification).await;
        
        // Verify pending blocks were NOT cleared (pollution accumulates)
        let pending_count = block_data.lock()
            .pending_block_store
            .blocks_without_payloads
            .len();
        
        assert!(pending_count > 0, "Cycle {}: Pending blocks should accumulate", cycle);
    }
    
    // Verify that we've accumulated pollution
    let final_pending_count = block_data.lock()
        .pending_block_store
        .blocks_without_payloads
        .len();
    
    assert!(
        final_pending_count >= max_pending,
        "Should have hit max pending blocks limit due to pollution"
    );
    
    // Verify new blocks are being dropped
    let new_block = create_pending_block(999);
    let initial_count = block_data.lock()
        .pending_block_store
        .blocks_without_payloads
        .len();
    
    block_data.lock().insert_pending_block(new_block);
    
    let final_count = block_data.lock()
        .pending_block_store
        .blocks_without_payloads
        .len();
    
    // New block should be dropped if at limit
    assert_eq!(
        initial_count, final_count,
        "New legitimate blocks are being dropped due to pollution"
    );
}
```

## Notes

This vulnerability also affects the fallback manager's `start_time` field which is never reset after recovery, but that is a less severe issue. The `reset_syncing_progress()` function only updates `highest_synced_version_and_time` but not `start_time`: [5](#0-4) 

This causes the startup grace period to only apply once during the observer's lifetime, making it more aggressive in detecting progress issues after the first recovery cycle. While less critical, this should also be addressed by resetting `start_time` in the `reset_syncing_progress()` function.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L1012-1023)
```rust
        // If the commit sync notification is ahead the block data root, something has gone wrong!
        if (synced_epoch, synced_round) > (block_data_epoch, block_data_round) {
            // Log the error, reset the state sync manager and return early
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Received invalid commit sync notification for epoch: {}, round: {}! Current root: {:?}",
                    synced_epoch, synced_round, block_data_root
                ))
            );
            self.state_sync_manager.clear_active_commit_sync();
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L92-105)
```rust
    /// Clears all block data and returns the root ledger info
    pub fn clear_block_data(&mut self) -> LedgerInfoWithSignatures {
        // Clear the payload store
        self.block_payload_store.clear_all_payloads();

        // Clear the ordered blocks
        self.ordered_block_store.clear_all_ordered_blocks();

        // Clear the pending blocks
        self.pending_block_store.clear_missing_blocks();

        // Return the root ledger info
        self.root()
    }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L273-291)
```rust
    /// Updates the block data for the given commit decision
    /// that will be used by state sync to catch us up.
    pub fn update_blocks_for_state_sync_commit(&mut self, commit_decision: &CommitDecision) {
        // Get the commit proof, epoch and round
        let commit_proof = commit_decision.commit_proof();
        let commit_epoch = commit_decision.epoch();
        let commit_round = commit_decision.round();

        // Update the root
        self.update_root(commit_proof.clone());

        // Update the block payload store
        self.block_payload_store
            .remove_blocks_for_epoch_round(commit_epoch, commit_round);

        // Update the ordered block store
        self.ordered_block_store
            .remove_blocks_for_commit(commit_proof);
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L158-195)
```rust
    fn garbage_collect_pending_blocks(&mut self) {
        // Verify that both stores have the same number of entries.
        // If not, log an error as this should never happen.
        let num_pending_blocks = self.blocks_without_payloads.len() as u64;
        let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
        if num_pending_blocks != num_pending_blocks_by_hash {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "The pending block stores have different numbers of entries: {} and {} (by hash)",
                    num_pending_blocks, num_pending_blocks_by_hash
                ))
            );
        }

        // Calculate the number of blocks to remove
        let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
        let num_blocks_to_remove = num_pending_blocks.saturating_sub(max_pending_blocks);

        // Remove the oldest blocks if the store is too large
        for _ in 0..num_blocks_to_remove {
            if let Some((oldest_epoch_round, pending_block)) =
                self.blocks_without_payloads.pop_first()
            {
                // Log a warning message for the removed block
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "The pending block store is too large: {:?} blocks. Removing the block for the oldest epoch and round: {:?}",
                        num_pending_blocks, oldest_epoch_round
                    ))
                );

                // Remove the block from the hash store
                let first_block = pending_block.ordered_block().first_block();
                self.blocks_without_payloads_by_hash
                    .remove(&first_block.id());
            }
        }
    }
```

**File:** consensus/src/consensus_observer/observer/fallback_manager.rs (L156-164)
```rust
    /// Resets the syncing progress to the latest synced ledger info and current time
    pub fn reset_syncing_progress(&mut self, latest_synced_ledger_info: &LedgerInfoWithSignatures) {
        // Get the current time and highest synced version
        let time_now = self.time_service.now();
        let highest_synced_version = latest_synced_ledger_info.ledger_info().version();

        // Update the highest synced version and time
        self.highest_synced_version_and_time = (highest_synced_version, time_now);
    }
```
