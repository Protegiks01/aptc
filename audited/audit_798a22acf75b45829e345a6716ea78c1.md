# Audit Report

## Title
RandStore Corruption Causes Node Crashes and Consensus Liveness Failures via Premature Aggregation

## Summary
Corruption in the `RandStore`'s internal state can cause `ShareAggregateState::add()` to behave incorrectly, leading to validator node crashes or permanent consensus liveness failures. Specifically, if the `total_weight` field in a `ShareAggregator` becomes corrupted to exceed the aggregation threshold, it triggers premature randomness aggregation that can either panic the node or permanently block randomness generation for a round.

## Finding Description

The vulnerability stems from how `ShareAggregateState::add()` delegates share processing to `RandStore::add_share()`, which in turn uses `ShareAggregator::try_aggregate()` to determine when sufficient shares have been collected. [1](#0-0) 

The critical flaw exists in the aggregation logic where the threshold check occurs before validation: [2](#0-1) 

**Attack Scenario 1: Node Crash**

If `RandStore` corruption causes:
- A `ShareAggregator`'s `total_weight` field to be >= threshold
- The shares HashMap does not contain the self-share

Then when `try_aggregate()` executes, it proceeds to extract the self-share which is expected to exist, causing a panic: [3](#0-2) 

This `.expect()` call crashes the validator node immediately.

**Attack Scenario 2: Permanent Liveness Failure**

If `total_weight` is corrupted to exceed the threshold but self-share exists:

1. `try_aggregate()` proceeds with aggregation (threshold check passes)
2. It spawns an async task to compute randomness
3. **Immediately** returns `Either::Right(self_share)` regardless of whether aggregation will succeed
4. The `RandItem` transitions to `Decided` state: [4](#0-3) 

5. The async aggregation task may fail if there are insufficient valid shares
6. Failures are only logged as warnings with no recovery mechanism: [5](#0-4) 

7. Once in `Decided` state, all future shares are silently ignored: [6](#0-5) 

8. Randomness for this round is never produced, but the system believes it's complete
9. Consensus stalls waiting for randomness that will never arrive

**Corruption Vectors:**

The `RandStore` can become corrupted through:
- **Epoch field corruption**: Wrong epoch causes all legitimate shares to be rejected
- **highest_known_round corruption**: If set too low, valid shares are rejected as "from future round"
- **Premature Decided state**: Shares are silently ignored while appearing to succeed
- **total_weight corruption**: Triggers the critical premature aggregation flows described above [7](#0-6) 

## Impact Explanation

This is a **Critical Severity** vulnerability (up to $1,000,000 per Aptos Bug Bounty):

1. **Validator Node Crash**: Node panic causes immediate validator unavailability, reducing network capacity
2. **Total Loss of Liveness**: If randomness for a round is permanently blocked, all validators waiting for that randomness cannot proceed with consensus, causing complete network halt
3. **Non-recoverable without Manual Intervention**: Once a `RandItem` transitions to `Decided` state without actually producing randomness, no automatic recovery exists

This breaks the **Consensus Safety and Liveness** invariant - the network cannot make progress if randomness generation fails, directly violating the AptosBFT consensus requirements.

## Likelihood Explanation

**Moderate to High Likelihood**:

- RandStore state corruption could occur through memory corruption bugs, race conditions, or logic errors in state management
- The `reset()` method modifies RandStore state and could introduce inconsistencies under edge cases
- No validation exists to detect corrupted `total_weight` values before aggregation proceeds
- The vulnerability is deterministic once corruption exists - any subsequent share addition triggers the issue
- Multiple code paths modify RandStore without comprehensive state validation [8](#0-7) 

## Recommendation

Implement defensive validation before aggregation:

```rust
pub fn try_aggregate(
    self,
    rand_config: &RandConfig,
    rand_metadata: FullRandMetadata,
    decision_tx: Sender<Randomness>,
) -> Either<Self, RandShare<S>> {
    // ADDED: Validate total_weight matches actual shares before proceeding
    let actual_weight: u64 = self.shares
        .keys()
        .map(|author| rand_config.get_peer_weight(author))
        .sum();
    
    if actual_weight != self.total_weight {
        warn!(
            "Corrupted ShareAggregator detected: total_weight={}, actual={}. Recalculating.",
            self.total_weight, actual_weight
        );
        self.total_weight = actual_weight;
    }
    
    if self.total_weight < rand_config.threshold() {
        return Either::Left(self);
    }
    
    // ADDED: Validate self-share exists before proceeding
    let self_share = match self.get_self_share() {
        Some(share) => share,
        None => {
            error!("Cannot aggregate without self share");
            return Either::Left(self);
        }
    };
    
    // ... rest of aggregation logic
}
```

Additionally, implement state validation in `RandStore::add_share()`:

```rust
pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
    ensure!(
        share.metadata().epoch == self.epoch,
        "Share from different epoch"
    );
    
    // ADDED: Validate epoch hasn't been corrupted
    ensure!(
        self.epoch > 0,
        "Corrupted RandStore: invalid epoch"
    );
    
    ensure!(
        share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
        "Share from future round"
    );
    
    // ... rest of logic
}
```

## Proof of Concept

```rust
#[test]
fn test_corrupted_total_weight_causes_premature_aggregation() {
    use crate::rand::rand_gen::{
        rand_store::{RandItem, ShareAggregator},
        types::{MockShare, PathType, RandConfig},
    };
    
    let author = Author::from_str("0x1").unwrap();
    let mut aggr = ShareAggregator::new(author, PathType::Slow);
    
    // Add only 2 shares with weight 1 each
    aggr.add_share(1, create_share_for_round(1, 1, Author::from_str("0x2").unwrap()));
    aggr.add_share(1, create_share_for_round(1, 1, Author::from_str("0x3").unwrap()));
    
    // Corrupt total_weight to exceed threshold
    // In real scenario this would be 100+ to exceed typical threshold
    aggr.total_weight = 1000; 
    
    // Create RandItem with corrupted aggregator
    let mut item = RandItem::PendingDecision {
        metadata: FullRandMetadata::new(1, 1, HashValue::zero(), 1700000000),
        share_aggregator: aggr,
    };
    
    let rand_config = create_test_rand_config();
    let (tx, _rx) = unbounded();
    
    // This should NOT aggregate with only 2 shares, but will due to corrupted total_weight
    item.try_aggregate(&rand_config, tx);
    
    // Verify it incorrectly transitioned to Decided state
    assert!(item.has_decision(), "Premature aggregation occurred due to corrupted total_weight");
    
    // Further shares will now be silently ignored
    let result = item.add_share(
        create_share_for_round(1, 1, Author::from_str("0x4").unwrap()),
        &rand_config
    );
    assert!(result.is_ok(), "Share accepted but silently ignored");
}

#[test]
#[should_panic(expected = "Aggregated item should have self share")]
fn test_missing_self_share_causes_panic() {
    let author = Author::from_str("0x1").unwrap();
    let mut aggr = ShareAggregator::new(author, PathType::Slow);
    
    // Add shares from other validators, but NOT self
    aggr.add_share(1, create_share_for_round(1, 1, Author::from_str("0x2").unwrap()));
    
    // Corrupt total_weight to trigger aggregation
    aggr.total_weight = 1000;
    
    let (tx, _rx) = unbounded();
    let metadata = FullRandMetadata::new(1, 1, HashValue::zero(), 1700000000);
    
    // This will panic because self-share doesn't exist
    let _ = aggr.try_aggregate(&create_test_rand_config(), metadata, tx);
}
```

## Notes

The vulnerability is particularly severe because:

1. There is no validation that `total_weight` accurately reflects the actual sum of share weights before aggregation
2. The async nature of the aggregation task means state transitions happen before validation completes
3. The `Decided` state is permanent - there's no mechanism to retry or recover
4. Multiple components share access to `RandStore` through `Arc<Mutex<>>`, creating opportunities for state corruption through race conditions or logic errors in the `reset()` flow

### Citations

**File:** consensus/src/rand/rand_gen/reliable_broadcast_state.rs (L131-151)
```rust
    fn add(&self, peer: Author, share: Self::Response) -> anyhow::Result<Option<()>> {
        ensure!(share.author() == &peer, "Author does not match");
        ensure!(
            share.metadata() == &self.rand_metadata,
            "Metadata does not match: local {:?}, received {:?}",
            self.rand_metadata,
            share.metadata()
        );
        share.verify(&self.rand_config)?;
        info!(LogSchema::new(LogEvent::ReceiveReactiveRandShare)
            .epoch(share.epoch())
            .round(share.metadata().round)
            .remote_peer(*share.author()));
        let mut store = self.rand_store.lock();
        let aggregated = if store.add_share(share, PathType::Slow)? {
            Some(())
        } else {
            None
        };
        Ok(aggregated)
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L41-89)
```rust
    pub fn try_aggregate(
        self,
        rand_config: &RandConfig,
        rand_metadata: FullRandMetadata,
        decision_tx: Sender<Randomness>,
    ) -> Either<Self, RandShare<S>> {
        if self.total_weight < rand_config.threshold() {
            return Either::Left(self);
        }
        match self.path_type {
            PathType::Fast => {
                observe_block(
                    rand_metadata.timestamp,
                    BlockStage::RAND_ADD_ENOUGH_SHARE_FAST,
                );
            },
            PathType::Slow => {
                observe_block(
                    rand_metadata.timestamp,
                    BlockStage::RAND_ADD_ENOUGH_SHARE_SLOW,
                );
            },
        }

        let rand_config = rand_config.clone();
        let self_share = self
            .get_self_share()
            .expect("Aggregated item should have self share");
        tokio::task::spawn_blocking(move || {
            let maybe_randomness = S::aggregate(
                self.shares.values(),
                &rand_config,
                rand_metadata.metadata.clone(),
            );
            match maybe_randomness {
                Ok(randomness) => {
                    let _ = decision_tx.unbounded_send(randomness);
                },
                Err(e) => {
                    warn!(
                        epoch = rand_metadata.metadata.epoch,
                        round = rand_metadata.metadata.round,
                        "Aggregation error: {e}"
                    );
                },
            }
        });
        Either::Right(self_share)
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L140-160)
```rust
    fn add_share(&mut self, share: RandShare<S>, rand_config: &RandConfig) -> anyhow::Result<()> {
        match self {
            RandItem::PendingMetadata(aggr) => {
                aggr.add_share(rand_config.get_peer_weight(share.author()), share);
                Ok(())
            },
            RandItem::PendingDecision {
                metadata,
                share_aggregator,
            } => {
                ensure!(
                    &metadata.metadata == share.metadata(),
                    "[RandStore] RandShare metadata from {} mismatch with block metadata!",
                    share.author(),
                );
                share_aggregator.add_share(rand_config.get_peer_weight(share.author()), share);
                Ok(())
            },
            RandItem::Decided { .. } => Ok(()),
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L162-178)
```rust
    fn try_aggregate(&mut self, rand_config: &RandConfig, decision_tx: Sender<Randomness>) {
        let item = std::mem::replace(self, Self::new(Author::ONE, PathType::Slow));
        let new_item = match item {
            RandItem::PendingDecision {
                share_aggregator,
                metadata,
            } => match share_aggregator.try_aggregate(rand_config, metadata.clone(), decision_tx) {
                Either::Left(share_aggregator) => Self::PendingDecision {
                    metadata,
                    share_aggregator,
                },
                Either::Right(self_share) => Self::Decided { self_share },
            },
            item @ (RandItem::Decided { .. } | RandItem::PendingMetadata(_)) => item,
        };
        let _ = std::mem::replace(self, new_item);
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-313)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
        let rand_metadata = share.metadata().clone();

        let (rand_config, rand_item) = if path == PathType::Fast {
            match (self.fast_rand_config.as_ref(), self.fast_rand_map.as_mut()) {
                (Some(fast_rand_config), Some(fast_rand_map)) => (
                    fast_rand_config,
                    fast_rand_map
                        .entry(rand_metadata.round)
                        .or_insert_with(|| RandItem::new(self.author, path)),
                ),
                _ => anyhow::bail!("Fast path not enabled"),
            }
        } else {
            (
                &self.rand_config,
                self.rand_map
                    .entry(rand_metadata.round)
                    .or_insert_with(|| RandItem::new(self.author, PathType::Slow)),
            )
        };

        rand_item.add_share(share, rand_config)?;
        rand_item.try_aggregate(rand_config, self.decision_tx.clone());
        Ok(rand_item.has_decision())
    }
```
