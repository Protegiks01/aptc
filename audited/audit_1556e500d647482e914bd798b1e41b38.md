# Audit Report

## Title
Race Condition in Hot State LRU Metadata Causes Validator Node Panic

## Summary
A Time-of-Check-Time-of-Use (TOCTOU) race condition exists between the background Committer thread updating `HotStateBase` and execution threads using stale LRU metadata. When execution threads access hot state keys that were evicted after metadata was captured but before use, `HotStateLRU::expect_hot_slot()` panics, causing validator node crashes.

## Finding Description

The vulnerability occurs in the hot state management system due to a lack of atomicity between reading state metadata and accessing the underlying hot state storage.

**Root Cause - Non-Atomic State Access:**

When `get_committed()` is called, it locks and clones the `State` object containing hot state metadata (head/tail pointers, item counts), then returns an Arc reference to the live `HotStateBase`. [1](#0-0) 

However, the Committer thread asynchronously updates both components in separate steps: first it modifies the `HotStateBase` DashMap by inserting/evicting entries, then it locks and updates the committed `State` with new metadata. [2](#0-1) 

The critical race window exists between when `Committer::commit()` finishes updating the HotStateBase (line 196) and when it updates the committed State (line 197).

**Race Manifestation During Execution:**

During block execution, `State::update()` creates `HotStateLRU` instances initialized with metadata from the parent state (which may now be stale) but configured to query the live `persisted_hot_state` (HotStateBase). [3](#0-2) 

The LRU chain traversal code assumes all keys referenced in the metadata exist in the hot state. When deleting entries during eviction, the code retrieves prev/next pointers from the current slot and immediately expects those keys to exist. [4](#0-3) 

The `expect_hot_slot()` function queries for a key and panics if not found. [5](#0-4) 

**Attack Scenario:**

1. Block execution at version V creates state with hot_metadata: tail=K_Z (where K_Z.prev=K_Y)
2. Execution thread A calls `get_persisted_state()` which invokes `get_committed()`, receiving stale State metadata and HotStateBase reference
3. Concurrently, Committer thread commits a new state that evicts K_Y from HotStateBase via DashMap operations
4. Thread A proceeds with `State::update()`, creating HotStateLRU with stale tail=K_Z
5. During `maybe_evict()`, the code calls `delete(K_Z)` [6](#0-5) 
6. `delete()` successfully fetches K_Z slot (containing prev=K_Y)
7. It calls `expect_hot_slot(K_Y)` to update the previous node
8. `get_slot(K_Y)` checks pending, overlay, then queries HotStateBase [7](#0-6) 
9. K_Y was evicted from HotStateBase → returns None
10. `expect()` panics with "Given key is expected to exist"

This breaks the **Deterministic Execution** invariant because identical blocks can either execute successfully or panic depending on race timing, violating blockchain consensus requirements.

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria:

**Validator Node Crashes (High)**: The panic causes the validator process to terminate during block execution, requiring process restart. While individual validator crashes don't immediately halt consensus (< 1/3 threshold), this affects network reliability. [8](#0-7) 

**Significant Protocol Violation**: Breaks the deterministic execution invariant - identical blocks should produce identical results, but here the outcome depends on concurrent thread timing. This is a fundamental violation of blockchain state machine semantics.

**Execution API Impact**: When execution threads panic, the block execution API becomes unavailable, preventing transaction processing until node restart.

Under high transaction load with multiple concurrent block executions and active Committer processing, the race window widens significantly. If multiple validators encounter this simultaneously, it could temporarily impact consensus liveness.

## Likelihood Explanation

**Moderate to High likelihood** under production conditions:

**Constant Race Window**: The race condition exists during every block execution whenever the Committer is actively processing commits. The execution path through `State::update()` → `maybe_evict()` → `delete()` → `expect_hot_slot()` is exercised on every checkpoint. [9](#0-8) 

**Natural Triggering**: No special attacker capabilities are required - the race occurs naturally under normal system operation with concurrent execution and commit activities.

**Load-Dependent**: High transaction throughput increases the frequency of both execution operations and Committer updates, widening the temporal race window. The `max_items_per_shard` capacity limit (default 250k items) triggers frequent evictions in active systems.

**Attacker Influence**: While not directly controllable, attackers can increase transaction submission rates to elevate system load, thereby increasing the probability of race condition occurrence.

## Recommendation

Implement atomic state snapshot acquisition by protecting both metadata and hot state queries under the same critical section, or use version-stamped snapshots:

**Option 1 - Extended Lock Scope:**
Extend the lock in `get_committed()` to cover the entire state access period, though this may impact concurrency.

**Option 2 - Snapshot Versioning (Recommended):**
Add version numbers to State and HotStateBase, verify they match during LRU operations, and retry on version mismatch:

```rust
pub fn get_committed(&self) -> (Arc<dyn HotStateView>, State, u64) {
    let guard = self.committed.lock();
    let version = self.state_version.load(Ordering::SeqCst);
    let state = guard.clone();
    let base = self.base.clone();
    drop(guard);
    (base, state, version)
}
```

In `HotStateLRU::expect_hot_slot()`, validate the snapshot version before panicking, and propagate a retry signal if versions diverged.

**Option 3 - Defensive Programming:**
Convert `expect_hot_slot()` to return `Result` instead of panicking, handle missing keys gracefully by reconstructing LRU chain from remaining entries.

## Proof of Concept

The following conceptual race can be demonstrated with a stress test that runs concurrent block executions while the Committer actively processes state updates. The panic will manifest under sufficient load:

```rust
// Stress test showing race condition
#[test]
fn test_hot_state_lru_race_condition() {
    // Setup: Create hot state with items near capacity
    // Thread 1: Start block execution calling get_committed()
    // Thread 2: Trigger Committer to evict items
    // Thread 1: Proceed with State::update() and maybe_evict()
    // Expected: Panic in expect_hot_slot() when accessing evicted key
    
    // This requires timing coordination to hit the race window,
    // but occurs naturally under production load conditions
}
```

A full reproduction requires instrumentation to force the race window, but the vulnerability exists in the production code path as demonstrated by the code analysis above.

## Notes

The vulnerability is particularly concerning because:

1. **Production Impact**: Affects the critical block execution path used by all validators
2. **Silent Failure**: No warning before panic, making debugging difficult
3. **Cascading Risk**: If multiple validators hit this race simultaneously during high load, it could temporarily impact network liveness
4. **Non-Determinism**: Violates fundamental blockchain invariant that execution must be deterministic

The hot state LRU system is a performance optimization, but this race condition introduces a reliability vulnerability. The fix should maintain performance while ensuring atomic consistency between metadata and storage access.

### Citations

**File:** storage/aptosdb/src/state_store/hot_state.rs (L131-136)
```rust
    pub fn get_committed(&self) -> (Arc<dyn HotStateView>, State) {
        let state = self.committed.lock().clone();
        let base = self.base.clone();

        (base, state)
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L192-205)
```rust
    fn run(&mut self) {
        info!("HotState committer thread started.");

        while let Some(to_commit) = self.next_to_commit() {
            self.commit(&to_commit);
            *self.committed.lock() = to_commit;

            GAUGE.set_with(&["hot_state_items"], self.base.len() as i64);
            GAUGE.set_with(&["hot_state_key_bytes"], self.total_key_bytes as i64);
            GAUGE.set_with(&["hot_state_value_bytes"], self.total_value_bytes as i64);
        }

        info!("HotState committer quitting.");
    }
```

**File:** storage/storage-interface/src/state_store/state.rs (L156-281)
```rust
    fn update(
        &self,
        persisted_hot_state: Arc<dyn HotStateView>,
        persisted: &State,
        batched_updates: &BatchedStateUpdateRefs,
        per_version_updates: &PerVersionStateUpdateRefs,
        all_checkpoint_versions: &[Version],
        state_cache: &ShardedStateCache,
    ) -> (Self, [HotStateShardUpdates; NUM_STATE_SHARDS]) {
        let _timer = TIMER.timer_with(&["state__update"]);

        // 1. The update batch must begin at self.next_version().
        assert_eq!(self.next_version(), batched_updates.first_version);
        assert_eq!(self.next_version(), per_version_updates.first_version);
        // 2. The cache must be at a version equal or newer than `persisted`, otherwise
        //    updates between the cached version and the persisted version are potentially
        //    missed during the usage calculation.
        assert!(
            persisted.next_version() <= state_cache.next_version(),
            "persisted: {}, cache: {}",
            persisted.next_version(),
            state_cache.next_version(),
        );
        // 3. `self` must be at a version equal or newer than the cache, because we assume
        //    it is overlaid on top of the cache.
        assert!(self.next_version() >= state_cache.next_version());

        let overlay = self.make_delta(persisted);
        let (((shards, new_metadata), usage_delta_per_shard), hot_state_updates): (
            ((Vec<_>, Vec<_>), Vec<_>),
            Vec<_>,
        ) = (
            state_cache.shards.as_slice(),
            overlay.shards.as_slice(),
            self.hot_state_metadata.as_slice(),
            batched_updates.shards.as_slice(),
            per_version_updates.shards.as_slice(),
        )
            .into_par_iter()
            .map(
                |(cache, overlay, hot_metadata, batched_updates, per_version)| {
                    let mut lru = HotStateLRU::new(
                        NonZeroUsize::new(self.hot_state_config.max_items_per_shard).unwrap(),
                        Arc::clone(&persisted_hot_state),
                        overlay,
                        hot_metadata.latest.clone(),
                        hot_metadata.oldest.clone(),
                        hot_metadata.num_items,
                    );
                    let mut all_updates = per_version.iter();
                    let mut insertions = HashMap::new();
                    let mut evictions = HashSet::new();
                    for ckpt_version in all_checkpoint_versions {
                        for (key, update) in
                            all_updates.take_while_ref(|(_k, u)| u.version <= *ckpt_version)
                        {
                            evictions.remove(*key);
                            if let Some(hot_state_value) = Self::apply_one_update(
                                &mut lru,
                                overlay,
                                cache,
                                key,
                                update,
                                self.hot_state_config.refresh_interval_versions,
                            ) {
                                insertions.insert((*key).clone(), hot_state_value);
                            }
                        }
                        // Only evict at the checkpoints.
                        evictions.extend(lru.maybe_evict().into_iter().map(|(key, slot)| {
                            insertions.remove(&key);
                            assert!(slot.is_hot());
                            key
                        }));
                    }
                    for (key, update) in all_updates {
                        evictions.remove(*key);
                        if let Some(hot_state_value) = Self::apply_one_update(
                            &mut lru,
                            overlay,
                            cache,
                            key,
                            update,
                            self.hot_state_config.refresh_interval_versions,
                        ) {
                            insertions.insert((*key).clone(), hot_state_value);
                        }
                    }

                    let (new_items, new_head, new_tail, new_num_items) = lru.into_updates();
                    let new_items = new_items.into_iter().collect_vec();

                    // TODO(aldenhu): change interface to take iter of ref
                    let new_layer = overlay.new_layer(&new_items);
                    let new_metadata = HotStateMetadata {
                        latest: new_head,
                        oldest: new_tail,
                        num_items: new_num_items,
                    };
                    let new_usage = Self::usage_delta_for_shard(cache, overlay, batched_updates);
                    (
                        ((new_layer, new_metadata), new_usage),
                        HotStateShardUpdates::new(insertions, evictions),
                    )
                },
            )
            .unzip();
        let shards = Arc::new(shards.try_into().expect("Known to be 16 shards."));
        let new_metadata = new_metadata.try_into().expect("Known to be 16 shards.");
        let usage = self.update_usage(usage_delta_per_shard);
        let hot_state_updates = hot_state_updates
            .try_into()
            .expect("Known to be 16 shards.");

        // TODO(HotState): extract and pass new hot state onchain config if needed.
        (
            State::new_with_updates(
                batched_updates.last_version(),
                shards,
                new_metadata,
                usage,
                self.hot_state_config,
            ),
            hot_state_updates,
        )
    }
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L118-123)
```rust
        match old_slot.prev() {
            Some(prev_key) => {
                let mut prev_slot = self.expect_hot_slot(prev_key);
                prev_slot.set_next(old_slot.next().cloned());
                self.pending.insert(prev_key.clone(), prev_slot);
            },
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L145-155)
```rust
    pub(crate) fn get_slot(&self, key: &StateKey) -> Option<StateSlot> {
        if let Some(slot) = self.pending.get(key) {
            return Some(slot.clone());
        }

        if let Some(slot) = self.overlay.get(key) {
            return Some(slot);
        }

        self.committed.get_state_slot(key)
    }
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L157-161)
```rust
    fn expect_hot_slot(&self, key: &StateKey) -> StateSlot {
        let slot = self.get_slot(key).expect("Given key is expected to exist.");
        assert!(slot.is_hot(), "Given key is expected to be hot.");
        slot
    }
```
