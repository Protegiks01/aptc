# Audit Report

## Title
Memory Exhaustion DoS via Oversized Transaction Filters in Indexer gRPC Service

## Summary
The Aptos indexer gRPC service is vulnerable to memory exhaustion attacks due to a mismatch between gRPC message size limits (256 MB) and transaction filter validation limits (10 KB). An attacker can send `LogicalAndFilters` with millions of filter entries that are deserialized into memory before validation occurs, causing out-of-memory crashes when multiple concurrent malicious requests are sent.

## Finding Description

The vulnerability exists in the transaction filter handling logic of the indexer gRPC service. The flow is as follows:

1. The gRPC service is configured with a maximum decoding message size of 256 MB. [1](#0-0) 

2. When a client sends a `GetTransactionsRequest` with a `transaction_filter` field, the tonic/prost framework automatically deserializes the entire protobuf message from wire format into Rust structures before any application-level validation occurs.

3. The filter validation only happens after deserialization is complete. [2](#0-1) 

4. The validation checks if the filter's encoded length exceeds 10,000 bytes (the configured limit). [3](#0-2) [4](#0-3) 

5. However, by this point, memory has already been allocated for all filter entries during deserialization.

An attacker can exploit this by:
- Crafting a `LogicalAndFilters` message with millions of minimal filter entries [5](#0-4) 
- Each entry can be a minimal `BooleanTransactionFilter` (e.g., 15-20 bytes encoded)
- Total encoded size of 50-200 MB (well under the 256 MB gRPC limit)
- Sending multiple concurrent requests to exhaust available memory

Additionally, the recursive filter processing bypasses size validation for nested filters by passing `None` for `max_filter_size`. [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program criteria for "API crashes."

**Impact**:
- **Availability**: The indexer gRPC service can be crashed via OOM, disrupting blockchain data access
- **Service Disruption**: Indexer downtime affects all applications relying on transaction data
- **Resource Exhaustion**: Server memory is exhausted by malicious requests, potentially affecting other services

The indexer service is critical infrastructure for the Aptos ecosystem, as it provides transaction data to wallets, explorers, and dApps. A crash of this service impacts the entire ecosystem's ability to monitor and interact with the blockchain.

## Likelihood Explanation

**Likelihood: High**

The attack is easy to execute:
1. **No Authentication Required**: The gRPC endpoint accepts requests from any client
2. **Simple Exploit**: Standard protobuf libraries can generate the malicious message
3. **Low Barrier**: Attacker only needs to craft a valid protobuf message and send concurrent requests
4. **No Special Privileges**: No validator access or special permissions required

The attack can be automated and executed repeatedly to maintain service disruption.

## Recommendation

**Immediate Fix**: Align gRPC message size limits with filter validation limits:

```rust
// In ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs
// Change from 256 MB to a reasonable limit for requests
pub(crate) const MAX_REQUEST_MESSAGE_SIZE: usize = 1 * (1 << 20); // 1 MB
pub(crate) const MAX_RESPONSE_MESSAGE_SIZE: usize = 256 * (1 << 20); // 256 MB

// Apply different limits for requests vs responses
let wrapper_service_raw =
    aptos_protos::indexer::v1::raw_data_server::RawDataServer::from_arc(wrapper.clone())
        .send_compressed(CompressionEncoding::Zstd)
        .accept_compressed(CompressionEncoding::Gzip)
        .max_decoding_message_size(MAX_REQUEST_MESSAGE_SIZE) // Limit incoming requests
        .max_encoding_message_size(MAX_RESPONSE_MESSAGE_SIZE); // Allow large responses
```

**Better Long-term Fix**: Implement size validation during deserialization by adding a custom protobuf decoder that checks message size before allocating memory, or validate filter size before processing nested structures:

```rust
// In ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs
impl TryFrom<aptos_protos::indexer::v1::LogicalAndFilters> for LogicalAnd {
    type Error = anyhow::Error;

    fn try_from(proto_filter: aptos_protos::indexer::v1::LogicalAndFilters) -> Result<Self> {
        // Add early size check
        ensure!(
            proto_filter.filters.len() <= 1000,
            "Too many filters in LogicalAnd: {}",
            proto_filter.filters.len()
        );
        
        Ok(Self {
            and: proto_filter
                .filters
                .into_iter()
                // Pass the max_filter_size down to nested filters
                .map(|f| BooleanTransactionFilter::new_from_proto(f, Some(10_000)))
                .collect::<Result<_>>()?,
        })
    }
}
```

## Proof of Concept

```rust
// PoC: Generate a malicious GetTransactionsRequest with oversized filter
use aptos_protos::indexer::v1::*;
use prost::Message;

fn create_malicious_filter(num_entries: usize) -> BooleanTransactionFilter {
    let mut filters = Vec::with_capacity(num_entries);
    
    // Create millions of minimal filter entries
    for _ in 0..num_entries {
        filters.push(BooleanTransactionFilter {
            filter: Some(boolean_transaction_filter::Filter::ApiFilter(
                ApiFilter {
                    filter: Some(api_filter::Filter::TransactionRootFilter(
                        TransactionRootFilter {
                            success: None,
                            transaction_type: None,
                        }
                    ))
                }
            ))
        });
    }
    
    BooleanTransactionFilter {
        filter: Some(boolean_transaction_filter::Filter::LogicalAnd(
            LogicalAndFilters { filters }
        ))
    }
}

fn main() {
    // Create filter with 2 million entries
    let malicious_filter = create_malicious_filter(2_000_000);
    
    let request = GetTransactionsRequest {
        starting_version: Some(0),
        transactions_count: None,
        batch_size: None,
        transaction_filter: Some(malicious_filter),
    };
    
    // Encode to verify size
    let encoded_size = request.encoded_len();
    println!("Encoded request size: {} bytes ({} MB)", 
             encoded_size, encoded_size / (1024 * 1024));
    
    // Send multiple concurrent requests to the indexer gRPC endpoint
    // Each request will allocate hundreds of MB during deserialization
    // With 10+ concurrent requests, this will cause OOM
}
```

**Notes**:
- The vulnerability affects all indexer gRPC services (live, historical, and fullnode data services)
- The issue is not present in the core consensus or Move VM components, so blockchain consensus safety is not impacted
- The fix requires updating configuration values and adding additional validation logic
- This represents a Resource Limits invariant violation (invariant #9 in the specification)

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L98-115)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["live_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
                    }
                } else {
                    None
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L21-21)
```rust
pub const DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES: usize = 10_000;
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L98-106)
```rust
        if let Some(max_filter_size) = max_filter_size {
            ensure!(
                proto_filter.encoded_len() <= max_filter_size,
                format!(
                    "Filter is too complicated. Max size: {} bytes, Actual size: {} bytes",
                    max_filter_size,
                    proto_filter.encoded_len()
                )
            );
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L265-277)
```rust
impl TryFrom<aptos_protos::indexer::v1::LogicalAndFilters> for LogicalAnd {
    type Error = anyhow::Error;

    fn try_from(proto_filter: aptos_protos::indexer::v1::LogicalAndFilters) -> Result<Self> {
        Ok(Self {
            and: proto_filter
                .filters
                .into_iter()
                .map(|f| BooleanTransactionFilter::new_from_proto(f, None))
                .collect::<Result<_>>()?,
        })
    }
}
```

**File:** protos/rust/src/pb/aptos.indexer.v1.rs (L8-11)
```rust
pub struct LogicalAndFilters {
    #[prost(message, repeated, tag="1")]
    pub filters: ::prost::alloc::vec::Vec<BooleanTransactionFilter>,
}
```
