# Audit Report

## Title
Non-Atomic Safety Rules Configuration Loading Enables Persistent Inconsistent Validator State

## Summary
The safety rules configuration loading process lacks atomicity when performing multi-step storage initialization and identity blob loading. IO errors during initialization can create persistent partial configuration states where critical safety data (CONSENSUS_KEY, OWNER_ACCOUNT, SAFETY_DATA, WAYPOINT) are inconsistently written, causing validators to enter unrecoverable states that prevent consensus participation.

## Finding Description

The vulnerability exists in the safety rules initialization code path with three distinct failure modes:

**Failure Mode 1: Partial Key/Account Initialization with Re-initialization Detection Bug** [1](#0-0) 

The `initialize_keys_and_accounts()` function performs two sequential write operations without atomicity. If CONSENSUS_KEY is set but OWNER_ACCOUNT write fails due to IO error, the storage enters partial state. On subsequent restart, the KeyAlreadyExists check causes early return without setting OWNER_ACCOUNT, permanently leaving storage in inconsistent state.

**Failure Mode 2: Non-Atomic Multi-Field Initialization** [2](#0-1) 

The `initialize()` method performs four sequential storage operations: keys/accounts, then safety_data, then waypoint. Each operation is individually atomic but the sequence is not. If IO error occurs after keys are set but before safety_data or waypoint, the validator has partially initialized storage.

**Failure Mode 3: Silent Overriding Identity Blob Load Failures** [3](#0-2) 

The overriding identity blobs loading uses `unwrap_or_default()` which silently converts IO errors to empty vector. If IO errors occur when reading overriding identity blob files, those keys are never loaded into storage. Additionally, individual key write failures are only logged as warnings but don't prevent initialization completion.

**Attack Path:**

1. Validator starts with OnDiskStorage backend and identity blob configuration
2. During first initialization, IO error occurs (disk full, permission denied, filesystem corruption) after CONSENSUS_KEY is written
3. `initialize_keys_and_accounts()` returns error, initialization panics: "Unable to initialize keys and accounts in storage"
4. Validator crashes, operator restarts
5. On restart, `storage.author()` fails (OWNER_ACCOUNT not set), triggering re-initialization path
6. Re-initialization attempts to set CONSENSUS_KEY, receives KeyAlreadyExists error
7. Function returns `Ok()` early without setting OWNER_ACCOUNT (line 76)
8. Continues to set SAFETY_DATA and WAYPOINT
9. Storage now has: CONSENSUS_KEY (from run 1), SAFETY_DATA (from run 2), WAYPOINT (from run 2), but **missing OWNER_ACCOUNT**
10. When SafetyRules attempts to operate, calls to `persistent_storage.author()` fail
11. Validator cannot participate in consensus [4](#0-3) 

The OnDiskStorage backend performs write-to-temp-then-rename for individual `set()` operations (atomic per operation), but provides no transaction/batch mechanism for multiple operations.

## Impact Explanation

**High Severity** - Significant Protocol Violations and Validator Node Failures

This vulnerability causes:

1. **Validator Liveness Failure**: Validators with partial configuration cannot participate in consensus. Calls to `persistent_storage.author()` during vote construction or proposal signing fail, preventing block validation.

2. **Network Availability Impact**: If multiple validators encounter this issue during deployment or disk issues, network could lose sufficient validator participation for consensus, impacting liveness.

3. **Inconsistent Security State**: Validators operate with mismatched keys and authors, violating the safety guarantee that each validator's identity is internally consistent.

4. **Silent Key Rotation Failures**: Missing overriding keys prevent validators from signing with expected rotated keys during epoch transitions, causing exclusion from validator set.

This meets "High Severity" criteria: "Validator node slowdowns" and "Significant protocol violations" per the Aptos bug bounty program.

## Likelihood Explanation

**High Likelihood** in production environments:

- IO errors are common: disk full conditions, filesystem corruption, NFS mount issues, permission problems
- The vulnerability creates **persistent** state that survives restarts - operators cannot easily recover
- The re-initialization logic exacerbates the issue by silently accepting partial state
- Overriding identity blob loading failures are completely silent (`unwrap_or_default()`), making detection impossible without deep inspection
- No validation checks detect the inconsistent state before attempting consensus operations

Once triggered, the validator remains in broken state until manual intervention (storage reset and reconfiguration).

## Recommendation

Implement atomic configuration loading with validation and rollback:

```rust
// In persistent_safety_storage.rs
fn initialize_keys_and_accounts(
    internal_store: &mut Storage,
    author: Author,
    consensus_private_key: bls12381::PrivateKey,
) -> Result<(), Error> {
    // Check if BOTH keys exist for re-initialization detection
    let consensus_exists = internal_store.get::<bls12381::PrivateKey>(CONSENSUS_KEY).is_ok();
    let owner_exists = internal_store.get::<Author>(OWNER_ACCOUNT).is_ok();
    
    if consensus_exists && owner_exists {
        warn!("Attempted to re-initialize existing storage");
        return Ok(());
    } else if consensus_exists || owner_exists {
        // Partial state detected - clear and reinitialize
        return Err(Error::SecureStorageUnexpectedError(
            "Partial initialization detected. Storage must be reset.".to_string()
        ));
    }
    
    internal_store.set(CONSENSUS_KEY, consensus_private_key)?;
    internal_store.set(OWNER_ACCOUNT, author)?;
    Ok(())
}

pub fn initialize(...) -> Self {
    // Validate storage is completely empty or completely initialized before proceeding
    let is_initialized = internal_store.get::<bls12381::PrivateKey>(CONSENSUS_KEY).is_ok()
        && internal_store.get::<Author>(OWNER_ACCOUNT).is_ok()
        && internal_store.get::<SafetyData>(SAFETY_DATA).is_ok()
        && internal_store.get::<Waypoint>(WAYPOINT).is_ok();
    
    if is_initialized {
        return Self::new(internal_store, enable_cached_safety_data);
    }
    
    // Perform initialization with explicit error handling
    // ... existing code with better error propagation
}
```

```rust
// In safety_rules_manager.rs
for blob in config
    .initial_safety_rules_config
    .overriding_identity_blobs()
    .map_err(|e| panic!("Failed to load overriding identity blobs: {}", e))? // Don't silently ignore!
{
    if let Some(sk) = blob.consensus_private_key {
        let pk_hex = hex::encode(PublicKey::from(&sk).to_bytes());
        let storage_key = format!("{}_{}", CONSENSUS_KEY, pk_hex);
        storage.internal_store().set(storage_key.as_str(), sk)
            .expect(&format!("Failed to set overriding key {}", storage_key)); // Fail fast, don't warn
    }
}
```

Additionally, implement storage validation on startup to detect and reject partial configurations.

## Proof of Concept

```rust
#[cfg(test)]
mod test_non_atomic_initialization {
    use super::*;
    use aptos_crypto::bls12381;
    use aptos_secure_storage::{InMemoryStorage, Storage};
    use aptos_types::{account_address::AccountAddress, waypoint::Waypoint};
    use std::sync::{Arc, Mutex};
    
    // Mock storage that fails after first write
    struct FailingAfterFirstWriteStorage {
        inner: Arc<Mutex<InMemoryStorage>>,
        write_count: Arc<Mutex<usize>>,
    }
    
    impl FailingAfterFirstWriteStorage {
        fn new() -> Self {
            Self {
                inner: Arc::new(Mutex::new(InMemoryStorage::new())),
                write_count: Arc::new(Mutex::new(0)),
            }
        }
        
        fn into_storage(self) -> Storage {
            // In real PoC, implement custom KVStorage trait
            // that intercepts set() calls and fails after first write
            Storage::from(InMemoryStorage::new())
        }
    }
    
    #[test]
    #[should_panic(expected = "Unable to initialize keys and accounts in storage")]
    fn test_partial_initialization_on_io_error() {
        let author = AccountAddress::random();
        let consensus_key = bls12381::PrivateKey::generate_for_testing();
        let waypoint = Waypoint::default();
        
        // Simulate IO error during OWNER_ACCOUNT write
        // This would require custom Storage implementation
        // that fails on second set() call
        
        let storage = FailingAfterFirstWriteStorage::new().into_storage();
        
        // This should panic, leaving CONSENSUS_KEY written but not OWNER_ACCOUNT
        let _result = PersistentSafetyStorage::initialize(
            storage,
            author,
            consensus_key,
            waypoint,
            true,
        );
    }
    
    #[test]
    fn test_reinitialization_with_partial_state() {
        // Step 1: Create storage with only CONSENSUS_KEY set (simulating partial failure)
        let mut storage = InMemoryStorage::new();
        let author = AccountAddress::random();
        let consensus_key = bls12381::PrivateKey::generate_for_testing();
        
        storage.set(CONSENSUS_KEY, consensus_key.clone()).unwrap();
        // OWNER_ACCOUNT is NOT set - partial state
        
        // Step 2: Attempt re-initialization
        let storage = Storage::from(storage);
        let waypoint = Waypoint::default();
        
        // This will succeed but leave OWNER_ACCOUNT unset due to KeyAlreadyExists early return
        let mut persistent_storage = PersistentSafetyStorage::initialize(
            storage,
            author,
            consensus_key,
            waypoint,
            true,
        );
        
        // Step 3: Verify storage is inconsistent - author() will fail
        let result = persistent_storage.author();
        assert!(result.is_err(), "Storage should be inconsistent but initialization succeeded");
    }
}
```

**Notes:**

The vulnerability fundamentally stems from the lack of transactional semantics in the secure storage abstraction layer. The `KVStorage` trait provides only individual `get()` and `set()` operations without batch/transaction support. While individual file writes use atomic rename operations, multi-field initialization sequences are not atomic at the application level.

The issue is particularly severe because the re-initialization detection logic (`KeyAlreadyExists` check) creates a one-way door into inconsistent state. Once CONSENSUS_KEY is written but OWNER_ACCOUNT fails, future initialization attempts will always succeed without completing the configuration.

The silent failure of overriding identity blob loading (`unwrap_or_default()`) compounds the problem by making key rotation failures invisible to operators and monitoring systems.

### Citations

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L33-61)
```rust
    pub fn initialize(
        mut internal_store: Storage,
        author: Author,
        consensus_private_key: bls12381::PrivateKey,
        waypoint: Waypoint,
        enable_cached_safety_data: bool,
    ) -> Self {
        // Initialize the keys and accounts
        Self::initialize_keys_and_accounts(&mut internal_store, author, consensus_private_key)
            .expect("Unable to initialize keys and accounts in storage");

        // Create the new persistent safety storage
        let safety_data = SafetyData::new(1, 0, 0, 0, None, 0);
        let mut persisent_safety_storage = Self {
            enable_cached_safety_data,
            cached_safety_data: Some(safety_data.clone()),
            internal_store,
        };

        // Initialize the safety data and waypoint
        persisent_safety_storage
            .set_safety_data(safety_data)
            .expect("Unable to initialize safety data");
        persisent_safety_storage
            .set_waypoint(&waypoint)
            .expect("Unable to initialize waypoint");

        persisent_safety_storage
    }
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L63-81)
```rust
    fn initialize_keys_and_accounts(
        internal_store: &mut Storage,
        author: Author,
        consensus_private_key: bls12381::PrivateKey,
    ) -> Result<(), Error> {
        let result = internal_store.set(CONSENSUS_KEY, consensus_private_key);
        // Attempting to re-initialize existing storage. This can happen in environments like
        // forge. Rather than be rigid here, leave it up to the developer to detect
        // inconsistencies or why they did not reset storage between rounds. Do not repeat the
        // checks again below, because it is just too strange to have a partially configured
        // storage.
        if let Err(aptos_secure_storage::Error::KeyAlreadyExists(_)) = result {
            warn!("Attempted to re-initialize existing storage");
            return Ok(());
        }

        internal_store.set(OWNER_ACCOUNT, author)?;
        Ok(())
    }
```

**File:** consensus/safety-rules/src/safety_rules_manager.rs (L79-99)
```rust
        // Ensuring all the overriding consensus keys are in the storage.
        let timer = Instant::now();
        for blob in config
            .initial_safety_rules_config
            .overriding_identity_blobs()
            .unwrap_or_default()
        {
            if let Some(sk) = blob.consensus_private_key {
                let pk_hex = hex::encode(PublicKey::from(&sk).to_bytes());
                let storage_key = format!("{}_{}", CONSENSUS_KEY, pk_hex);
                match storage.internal_store().set(storage_key.as_str(), sk) {
                    Ok(_) => {
                        info!("Setting {storage_key} succeeded.");
                    },
                    Err(e) => {
                        warn!("Setting {storage_key} failed with internal store set error: {e}");
                    },
                }
            }
        }
        info!("Overriding key work time: {:?}", timer.elapsed());
```

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```
