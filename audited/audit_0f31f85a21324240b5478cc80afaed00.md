# Audit Report

## Title
BlockEpilogue Transaction Replay During State Sync Re-Execution Causes Double Fee Distribution

## Summary
When nodes synchronize using `ExecuteTransactionsFromGenesis` or `ExecuteTransactions` modes, BlockEpilogue transactions stored in the database are re-executed, causing transaction fees to be double-counted. This leads to unauthorized APT minting, consensus divergence between nodes using different sync methods, and violation of the Deterministic Execution invariant.

## Finding Description

The Aptos blockchain appends BlockEpilogue transactions at the end of blocks to distribute transaction fees to validators. [1](#0-0) 

During normal block execution, the block executor generates a BlockEpilogue transaction when `TransactionSliceMetadata::append_state_checkpoint_to_block()` returns a block ID. [2](#0-1) 

This BlockEpilogue transaction executes the `block::block_epilogue` Move function, which calls `stake::record_fee` to add fees to validators' pending rewards. [3](#0-2) 

The `record_fee` function uses an aggregator's `.add()` operation to accumulate fees: [4](#0-3) 

All transactions, including BlockEpilogue transactions, are committed to storage and can be retrieved by state sync. [5](#0-4) 

**The vulnerability occurs during state sync re-execution:**

When nodes sync using `ExecuteTransactionsFromGenesis` mode, they fetch and re-execute all transactions from storage. [6](#0-5) 

The chunk executor processes these transactions via `ChunkToExecute`, which calls the block executor with `TransactionSliceMetadata::unknown()`. [7](#0-6) 

When `TransactionSliceMetadata::unknown()` is used, `append_state_checkpoint_to_block()` returns `None`, so no new BlockEpilogue is generated. [8](#0-7) 

However, the sequential executor still processes all transactions from the input, including any existing BlockEpilogue transactions. [9](#0-8) 

When the BlockEpilogue transaction is encountered, it is executed via `execute_single_transaction`, which calls `process_block_epilogue`. [10](#0-9) 

For BlockEpilogue V1 transactions, this executes the Move `block_epilogue` function again, calling `stake::record_fee` with the same fee distribution data, causing fees to be **added twice** to validators' pending rewards.

**Attack Scenario:**

1. Block N is executed normally with transactions T0, T1, T2
2. BlockEpilogue transaction T3 is generated with fee distribution (validator 0: 1000 octa)
3. T3 executes, adding 1000 octa to validator 0's pending fees
4. All transactions (T0, T1, T2, T3) are committed to storage
5. A new node syncs using `ExecuteTransactionsFromGenesis` mode
6. State sync fetches T0, T1, T2, T3 from storage
7. All four transactions are re-executed
8. T3 is executed again, adding another 1000 octa to validator 0's pending fees
9. **Result:** Validator 0 has 2000 octa instead of 1000 octa
10. Nodes that synced via re-execution have different state than nodes that executed normally

## Impact Explanation

**Critical Severity** - This vulnerability meets multiple critical impact categories:

1. **Loss of Funds / Unauthorized Minting**: Validators receive double the intended transaction fee rewards, effectively minting unauthorized APT tokens. The cumulative effect across all blocks and validators could result in significant inflation.

2. **Consensus/Safety Violations**: Nodes reach different states depending on their synchronization method:
   - Nodes that executed blocks normally have state S1
   - Nodes that synced via `ExecuteTransactionsFromGenesis` have state S2 (with double fees)
   - This violates the **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks"

3. **State Consistency**: The blockchain state becomes inconsistent across the network, with different nodes having different validator reward balances. This could require manual intervention or a hard fork to resolve.

4. **Staking Security**: Validator rewards are incorrectly calculated, violating the invariant that "Validator rewards and penalties must be calculated correctly."

The impact affects every node using state sync re-execution modes and compounds with each block that contains transactions, making this a network-wide critical issue.

## Likelihood Explanation

**High Likelihood** - This vulnerability occurs automatically under normal operations:

1. **Common Trigger Conditions:**
   - `ExecuteTransactionsFromGenesis` is a standard bootstrapping mode for new nodes
   - `ExecuteTransactions` is used in continuous syncing mode
   - These modes are documented and commonly used for node synchronization

2. **No Special Requirements:**
   - No malicious actors required
   - No validator collusion needed
   - Happens naturally when nodes join the network

3. **Widespread Effect:**
   - Every new node joining the network using execute mode
   - Every node that falls behind and re-syncs
   - All historical blocks containing BlockEpilogue V1 transactions

4. **Detection Difficulty:**
   - State divergence may not be immediately obvious
   - Aggregator values are opaque until distribution
   - Could persist undetected until epoch change when rewards are distributed

The vulnerability is currently active in production if any nodes use re-execution sync modes.

## Recommendation

**Immediate Fix:** Detect and skip BlockEpilogue transactions during state sync re-execution.

**Option 1 - Skip BlockEpilogue in re-execution path:**

In `execution/executor/src/chunk_executor/transaction_chunk.rs`, filter out BlockEpilogue transactions before execution:

```rust
impl TransactionChunk for ChunkToExecute {
    fn into_output<V: VMBlockExecutor>(
        self,
        parent_state: &LedgerState,
        state_view: CachedStateView,
    ) -> Result<ExecutionOutput> {
        let ChunkToExecute {
            mut transactions,
            mut persisted_aux_info,
            first_version: _,
        } = self;

        // Filter out BlockEpilogue transactions during re-execution
        let mut filtered_transactions = Vec::new();
        let mut filtered_aux_info = Vec::new();
        
        for (txn, aux_info) in transactions.into_iter().zip(persisted_aux_info.into_iter()) {
            if !matches!(txn, Transaction::BlockEpilogue(_)) {
                filtered_transactions.push(txn);
                filtered_aux_info.push(aux_info);
            }
        }

        // Execute only non-epilogue transactions
        let sig_verified_txns = SIG_VERIFY_POOL.install(|| {
            filtered_transactions
                .into_par_iter()
                .with_min_len(optimal_min_len(filtered_transactions.len(), 32))
                .map(|t| t.into())
                .collect::<Vec<_>>()
        });

        DoGetExecutionOutput::by_transaction_execution::<V>(
            &V::new(),
            sig_verified_txns.into(),
            filtered_aux_info.into_iter().map(|info| AuxiliaryInfo::new(info, None)).collect(),
            parent_state,
            state_view,
            BlockExecutorConfigFromOnchain::new_no_block_limit(),
            TransactionSliceMetadata::unknown(),
        )
    }
}
```

**Option 2 - Use apply-outputs mode instead:**

Prefer `enqueue_chunk_by_transaction_outputs` over `enqueue_chunk_by_execution` for state sync, as the apply-outputs path correctly handles pre-computed BlockEpilogue outputs without re-executing them.

**Long-term Solution:**

Add validation in `execute_single_transaction` to prevent BlockEpilogue re-execution during state sync:

```rust
Transaction::BlockEpilogue(block_epilogue) => {
    // Prevent re-execution of BlockEpilogue during state sync
    if matches!(txn_metadata.transaction_slice_metadata, TransactionSliceMetadata::Unknown | TransactionSliceMetadata::Chunk { .. }) {
        // During state sync, return pre-computed output instead of re-executing
        return Ok((VMStatus::Executed, VMOutput::empty_with_status(TransactionStatus::Keep(ExecutionStatus::Success))));
    }
    
    self.process_block_epilogue(resolver, code_storage, block_epilogue.clone(), log_context)?
}
```

## Proof of Concept

**Setup:**
1. Start a local Aptos network with 4 validators
2. Execute several blocks with user transactions
3. Start a new validator node configured with `BootstrappingMode::ExecuteTransactionsFromGenesis`

**Verification Steps:**

```rust
// In a test environment:

#[test]
fn test_block_epilogue_double_execution() {
    // 1. Execute block normally
    let block_executor = BlockExecutor::new();
    let transactions = vec![create_user_transaction()]; // User transaction with fee
    
    let block_output = block_executor.execute_block(
        &transactions,
        &state_view,
        TransactionSliceMetadata::block(parent_hash, block_hash),
        &mut module_cache_manager,
    ).unwrap();
    
    let (mut outputs, epilogue_txn) = block_output.into_inner();
    assert!(epilogue_txn.is_some()); // BlockEpilogue was generated
    
    // 2. Commit to storage
    transactions.push(epilogue_txn.unwrap().into_inner());
    storage.save_transactions(&transactions, &outputs);
    
    // 3. Query validator pending fees
    let fees_before = get_validator_pending_fees(&state_view, validator_0);
    assert_eq!(fees_before, 1000); // Initial fee from first execution
    
    // 4. Re-execute via state sync path
    let synced_transactions = storage.get_transactions(start_version, 10);
    
    let chunk = ChunkToExecute {
        transactions: synced_transactions.transactions.clone(),
        persisted_aux_info: synced_transactions.aux_infos,
        first_version: start_version,
    };
    
    chunk.into_output::<AptosVM>(&state_view, cached_state_view).unwrap();
    
    // 5. Verify double-counting occurred
    let fees_after = get_validator_pending_fees(&state_view, validator_0);
    assert_eq!(fees_after, 2000); // DOUBLED - this proves the vulnerability
}
```

**Expected behavior:** Fees should remain 1000 after re-execution
**Actual behavior:** Fees become 2000, proving the double-counting vulnerability

**Real-world reproduction:**
1. Deploy local testnet
2. Configure one node with `state_sync.bootstrapping_mode = "ExecuteTransactionsFromGenesis"`
3. Generate blocks with transaction fees
4. Compare `PendingTransactionFee` state between nodes
5. Observe divergence in validator pending fee balances

## Notes

This vulnerability highlights a fundamental issue in how state sync handles system-generated transactions. BlockEpilogue transactions are stored in the database like regular transactions but should not be re-executed during sync. The fix requires either:

1. Filtering BlockEpilogue transactions in the re-execution path
2. Using apply-outputs mode exclusively for state sync
3. Adding idempotency checks in the `stake::record_fee` function
4. Marking BlockEpilogue transactions with metadata to prevent re-execution

The root cause is the lack of distinction between user-submitted transactions (which should be re-executable) and system-generated transactions (which should not be re-executed as they've already affected state).

### Citations

**File:** types/src/transaction/block_output.rs (L7-17)
```rust
#[derive(Debug)]
pub struct BlockOutput<T, Output>
where
    T: BlockExecutableTransaction,
    Output: Debug,
{
    transaction_outputs: Vec<Output>,
    // A BlockEpilogueTxn might be appended to the block.
    // This field will be None iff the input is not a block, or an epoch change is triggered.
    block_epilogue_txn: Option<T>,
}
```

**File:** aptos-move/block-executor/src/executor.rs (L2217-2224)
```rust
        while idx <= num_txns {
            let txn = if idx != num_txns {
                signature_verified_block.get_txn(idx as TxnIndex)
            } else if block_epilogue_txn.is_some() {
                block_epilogue_txn.as_ref().unwrap()
            } else {
                break;
            };
```

**File:** aptos-move/block-executor/src/executor.rs (L2515-2530)
```rust
                if let Some(block_id) =
                    transaction_slice_metadata.append_state_checkpoint_to_block()
                {
                    if !has_reconfig {
                        block_epilogue_txn = Some(self.gen_block_epilogue(
                            block_id,
                            signature_verified_block,
                            ret.iter(),
                            idx as TxnIndex,
                            block_limit_processor.get_block_end_info(),
                            module_cache_manager_guard.environment().features(),
                        )?);
                    } else {
                        info!("Reach epoch ending, do not append BlockEpilogue txn, block_id: {block_id:?}.");
                    }
                }
```

**File:** aptos-move/framework/aptos-framework/sources/block.move (L249-255)
```text
    fun block_epilogue(
        vm: &signer,
        fee_distribution_validator_indices: vector<u64>,
        fee_amounts_octa: vector<u64>,
    ) {
        stake::record_fee(vm, fee_distribution_validator_indices, fee_amounts_octa);
    }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L616-635)
```text
    public(friend) fun record_fee(
        vm: &signer,
        fee_distribution_validator_indices: vector<u64>,
        fee_amounts_octa: vector<u64>,
    ) acquires PendingTransactionFee {
        // Operational constraint: can only be invoked by the VM.
        system_addresses::assert_vm(vm);

        assert!(fee_distribution_validator_indices.length() == fee_amounts_octa.length());

        let num_validators_to_distribute = fee_distribution_validator_indices.length();
        let pending_fee = borrow_global_mut<PendingTransactionFee>(@aptos_framework);
        let i = 0;
        while (i < num_validators_to_distribute) {
            let validator_index = fee_distribution_validator_indices[i];
            let fee_octa = fee_amounts_octa[i];
            pending_fee.pending_fee_by_validator.borrow_mut(&validator_index).add(fee_octa);
            i = i + 1;
        }
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L391-422)
```rust
            let (txn_infos, txns_and_outputs, persisted_aux_info) = (start_version
                ..start_version + limit)
                .map(|version| {
                    let txn_info = self
                        .ledger_db
                        .transaction_info_db()
                        .get_transaction_info(version)?;
                    let events = self.ledger_db.event_db().get_events_by_version(version)?;
                    let write_set = self.ledger_db.write_set_db().get_write_set(version)?;
                    let txn = self.ledger_db.transaction_db().get_transaction(version)?;
                    let auxiliary_data = self
                        .ledger_db
                        .transaction_auxiliary_data_db()
                        .get_transaction_auxiliary_data(version)?
                        .unwrap_or_default();
                    let txn_output = TransactionOutput::new(
                        write_set,
                        events,
                        txn_info.gas_used(),
                        txn_info.status().clone().into(),
                        auxiliary_data,
                    );
                    let persisted_aux_info = self
                        .ledger_db
                        .persisted_auxiliary_info_db()
                        .get_persisted_auxiliary_info(version)?
                        .unwrap_or(PersistedAuxiliaryInfo::None);
                    Ok((txn_info, (txn, txn_output), persisted_aux_info))
                })
                .collect::<Result<Vec<_>>>()?
                .into_iter()
                .multiunzip();
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1026-1045)
```rust
async fn execute_transaction_chunk<ChunkExecutor: ChunkExecutorTrait + 'static>(
    chunk_executor: Arc<ChunkExecutor>,
    transactions_with_proof: TransactionListWithProofV2,
    target_ledger_info: LedgerInfoWithSignatures,
    end_of_epoch_ledger_info: Option<LedgerInfoWithSignatures>,
) -> anyhow::Result<()> {
    // Execute the transaction chunk
    let num_transactions = transactions_with_proof
        .get_transaction_list_with_proof()
        .transactions
        .len();
    let result = tokio::task::spawn_blocking(move || {
        chunk_executor.enqueue_chunk_by_execution(
            transactions_with_proof,
            &target_ledger_info,
            end_of_epoch_ledger_info.as_ref(),
        )
    })
    .await
    .expect("Spawn_blocking(execute_transaction_chunk) failed!");
```

**File:** execution/executor/src/chunk_executor/transaction_chunk.rs (L68-113)
```rust
    fn into_output<V: VMBlockExecutor>(
        self,
        parent_state: &LedgerState,
        state_view: CachedStateView,
    ) -> Result<ExecutionOutput> {
        let ChunkToExecute {
            transactions,
            persisted_aux_info,
            first_version: _,
        } = self;

        assert_eq!(
            transactions.len(),
            persisted_aux_info.len(),
            "transactions and persisted_aux_info must have the same length"
        );

        // TODO(skedia) In the chunk executor path, we ideally don't need to verify the signature
        // as only transactions with verified signatures are committed to the storage.
        let sig_verified_txns = {
            let _timer = CHUNK_OTHER_TIMERS.timer_with(&["sig_verify"]);

            let num_txns = transactions.len();
            SIG_VERIFY_POOL.install(|| {
                transactions
                    .into_par_iter()
                    .with_min_len(optimal_min_len(num_txns, 32))
                    .map(|t| t.into())
                    .collect::<Vec<_>>()
            })
        };

        let _timer = VM_EXECUTE_CHUNK.start_timer();
        DoGetExecutionOutput::by_transaction_execution::<V>(
            &V::new(),
            sig_verified_txns.into(),
            persisted_aux_info
                .into_iter()
                .map(|info| AuxiliaryInfo::new(info, None))
                .collect(),
            parent_state,
            state_view,
            BlockExecutorConfigFromOnchain::new_no_block_limit(),
            TransactionSliceMetadata::unknown(),
        )
    }
```

**File:** types/src/block_executor/transaction_slice_metadata.rs (L49-57)
```rust
    pub fn append_state_checkpoint_to_block(&self) -> Option<HashValue> {
        use TransactionSliceMetadata::*;

        match self {
            Unknown => None,
            Block { child, .. } => Some(*child),
            Chunk { .. } => None,
        }
    }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L3019-3024)
```rust
            Transaction::BlockEpilogue(block_epilogue) => self.process_block_epilogue(
                resolver,
                code_storage,
                block_epilogue.clone(),
                log_context,
            )?,
```
