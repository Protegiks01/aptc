# Audit Report

## Title
State Sync Subscription Instability Due to Unbounded Peer Priority Recalculation

## Summary
The state sync data client lacks rate limiting for peer priority calculations during subscription requests. When network state changes (trusted peer status, connection metadata, or network registration) occur, peer priorities are recalculated on every subscription request without debouncing, causing active subscriptions to terminate prematurely and repeatedly switch between peers, preventing state sync convergence.

## Finding Description

The `get_peer_priority()` function in `priority.rs` calculates peer priorities based on dynamic network state without any caching or rate limiting. [1](#0-0) 

For VFN and PFN nodes, priority depends on:
- Trusted peer status (checked via `is_trusted_peer()`)
- Connection direction (outbound vs inbound)  
- Network type [2](#0-1) [3](#0-2) 

These network state values can change dynamically:
- Trusted peers updated via `set_trusted_peers()` from connectivity manager
- Connection metadata updated via `insert_connection_metadata()` on reconnections [4](#0-3) [5](#0-4) 

The subscription peer selection logic recalculates priorities on **every request** without debouncing: [6](#0-5) [7](#0-6) 

When a peer's priority changes and it's no longer in the highest-priority serviceable set, the subscription is forcibly terminated: [8](#0-7) 

**Attack Scenario:**
1. A VFN node has an active subscription to a Public network peer with outbound connection (MediumPriority)
2. Network churn causes the connection to drop and reconnect as inbound (becomes LowPriority)
3. Subscription terminates because peer is no longer in serviceable set
4. New subscription starts with different peer
5. Network churn continues, causing repeated subscription restarts
6. State sync fails to converge due to continuous subscription instability

Unlike the consensus observer which has explicit rate limiting via `subscription_peer_change_interval_ms` and `subscription_refresh_interval_ms`: [9](#0-8) 

The state sync data client has **no such protection**.

## Impact Explanation

**High Severity** - Validator node slowdowns and significant protocol violations.

When subscription oscillation occurs:
- Nodes cannot maintain stable state sync connections
- Repeated subscription restarts prevent data convergence  
- Nodes fall behind the blockchain, unable to participate in consensus
- VFN and PFN nodes become unreliable for serving clients
- Affects network-wide availability during periods of connection instability

This breaks the **State Consistency** invariant - nodes must be able to reliably synchronize state to maintain system integrity. While not a consensus safety violation, it directly impacts validator availability and network liveness.

## Likelihood Explanation

**Medium Likelihood** in production environments with:
- Dynamic peer discovery systems causing trusted peer set changes
- Unstable network conditions with frequent reconnections
- VFN/PFN deployments with mixed connection types
- High peer churn in public networks

While not trivially exploitable by external attackers (requires network-level conditions rather than protocol manipulation), the vulnerability can be triggered by legitimate operational conditions that are common in distributed systems.

## Recommendation

Implement rate limiting for peer priority-based subscription changes, similar to the consensus observer pattern:

```rust
// In AptosDataClient struct, add:
last_subscription_peer_check: Arc<Mutex<Instant>>,

// In choose_serviceable_peer_for_subscription_request:
fn choose_serviceable_peer_for_subscription_request(
    &self,
    request: &StorageServiceRequest,
    serviceable_peers: HashSet<PeerNetworkId>,
) -> crate::error::Result<Option<PeerNetworkId>, Error> {
    // ... existing code ...
    
    if let Some(subscription_state) = active_subscription_state.take() {
        if subscription_state.subscription_stream_id == request_stream_id {
            let peer_network_id = subscription_state.peer_network_id;
            
            // NEW: Check if peer is still connected (must check)
            if !serviceable_peers.contains(&peer_network_id) {
                // NEW: Apply rate limiting before terminating
                let mut last_check = self.last_subscription_peer_check.lock();
                let time_since_last_check = self.time_service.now().duration_since(*last_check);
                let min_check_interval = Duration::from_secs(
                    self.data_client_config.subscription_peer_change_interval_secs.unwrap_or(30)
                );
                
                if time_since_last_check < min_check_interval {
                    // Within rate limit - keep existing subscription despite priority change
                    *active_subscription_state = Some(subscription_state);
                    return Ok(Some(peer_network_id));
                }
                
                *last_check = self.time_service.now();
                // Now safe to terminate
            } else {
                *active_subscription_state = Some(subscription_state);
                return Ok(Some(peer_network_id));
            }
        }
    }
    // ... rest of existing code ...
}
```

Add configuration parameter:
```rust
// In AptosDataClientConfig:
pub subscription_peer_change_interval_secs: Option<u64>, // Default: 30
```

## Proof of Concept

```rust
#[cfg(test)]
mod test_priority_flapping {
    use super::*;
    use aptos_config::config::Peer;
    use aptos_netcore::transport::ConnectionOrigin;
    use std::collections::HashMap;
    use maplit::hashmap;

    #[tokio::test]
    async fn test_subscription_terminates_on_priority_flap() {
        // Setup VFN node with subscription to Public network peer
        let base_config = Arc::new(BaseConfig {
            role: RoleType::FullNode,
            ..Default::default()
        });
        
        let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Vfn, NetworkId::Public]);
        let peer = PeerNetworkId::new(NetworkId::Public, PeerId::random());
        
        // Start with outbound connection (MediumPriority for VFN)
        peers_and_metadata.insert_connection_metadata(
            peer,
            ConnectionMetadata::mock_with_role_and_origin(
                peer.peer_id(),
                PeerRole::Upstream,
                ConnectionOrigin::Outbound
            )
        ).unwrap();
        
        let priority1 = get_peer_priority(
            base_config.clone(),
            peers_and_metadata.clone(),
            &peer
        );
        assert_eq!(priority1, PeerPriority::MediumPriority);
        
        // Simulate reconnection as inbound (LowPriority for VFN)
        peers_and_metadata.remove_peer_metadata(peer, ConnectionId::default()).unwrap();
        peers_and_metadata.insert_connection_metadata(
            peer,
            ConnectionMetadata::mock_with_role_and_origin(
                peer.peer_id(),
                PeerRole::Unknown,
                ConnectionOrigin::Inbound
            )
        ).unwrap();
        
        let priority2 = get_peer_priority(
            base_config.clone(),
            peers_and_metadata.clone(),
            &peer
        );
        assert_eq!(priority2, PeerPriority::LowPriority);
        
        // Priority flapped from Medium to Low
        // Active subscription to this peer would now terminate
        // because it's no longer in the MediumPriority serviceable set
    }
}
```

## Notes

This vulnerability represents a **robustness gap** in the state sync implementation. The consensus observer component already implements the necessary rate limiting protection, demonstrating that the Aptos team recognizes this pattern as important. The state sync data client should adopt the same defensive design to ensure stable subscriptions during normal network operational conditions.

### Citations

**File:** state-sync/aptos-data-client/src/priority.rs (L53-122)
```rust
pub fn get_peer_priority(
    base_config: Arc<BaseConfig>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    peer: &PeerNetworkId,
) -> PeerPriority {
    // Handle the case that this node is a validator
    let peer_network_id = peer.network_id();
    if base_config.role.is_validator() {
        // Validators should highly prioritize other validators
        if peer_network_id.is_validator_network() {
            return PeerPriority::HighPriority;
        }

        // VFNs should be prioritized over PFNs. Note: having PFNs
        // connected to a validator is a rare (but possible) scenario.
        return if peer_network_id.is_vfn_network() {
            PeerPriority::MediumPriority
        } else {
            PeerPriority::LowPriority
        };
    }

    // Handle the case that this node is a VFN
    if peers_and_metadata
        .get_registered_networks()
        .contains(&NetworkId::Vfn)
    {
        // VFNs should highly prioritize validators
        if peer_network_id.is_vfn_network() {
            return PeerPriority::HighPriority;
        }

        // Trusted peers should be prioritized over untrusted peers.
        // This prioritizes other VFNs/seed peers over regular PFNs.
        if is_trusted_peer(peers_and_metadata.clone(), peer) {
            return PeerPriority::MediumPriority;
        }

        // Outbound connections should be prioritized over inbound connections.
        // This prioritizes other VFNs/seed peers over regular PFNs.
        return if let Some(metadata) = utils::get_metadata_for_peer(&peers_and_metadata, *peer) {
            if metadata.get_connection_metadata().is_outbound_connection() {
                PeerPriority::MediumPriority
            } else {
                PeerPriority::LowPriority
            }
        } else {
            PeerPriority::LowPriority // We don't have connection metadata
        };
    }

    // Otherwise, this node is a PFN. PFNs should highly
    // prioritize trusted peers (i.e., VFNs and seed peers).
    if is_trusted_peer(peers_and_metadata.clone(), peer) {
        return PeerPriority::HighPriority;
    }

    // Outbound connections should be prioritized. This prioritizes
    // other VFNs/seed peers over regular PFNs. Inbound connections
    // are always low priority (as they are generally unreliable).
    if let Some(metadata) = utils::get_metadata_for_peer(&peers_and_metadata, *peer) {
        if metadata.get_connection_metadata().is_outbound_connection() {
            PeerPriority::HighPriority
        } else {
            PeerPriority::LowPriority
        }
    } else {
        PeerPriority::LowPriority // We don't have connection metadata
    }
}
```

**File:** network/framework/src/application/storage.rs (L186-214)
```rust
    pub fn insert_connection_metadata(
        &self,
        peer_network_id: PeerNetworkId,
        connection_metadata: ConnectionMetadata,
    ) -> Result<(), Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Update the metadata for the peer or insert a new entry
        peer_metadata_for_network
            .entry(peer_network_id.peer_id())
            .and_modify(|peer_metadata| {
                peer_metadata.connection_metadata = connection_metadata.clone()
            })
            .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        let event =
            ConnectionNotification::NewPeer(connection_metadata, peer_network_id.network_id());
        self.broadcast(event);

        Ok(())
    }
```

**File:** network/framework/src/application/storage.rs (L361-368)
```rust
    pub fn set_trusted_peers(
        &self,
        network_id: &NetworkId,
        trusted_peer_set: PeerSet,
    ) -> Result<(), Error> {
        let trusted_peers = self.get_trusted_peer_set_for_network(network_id)?;
        trusted_peers.store(Arc::new(trusted_peer_set));
        Ok(())
```

**File:** state-sync/aptos-data-client/src/client.rs (L265-270)
```rust
    pub(crate) fn choose_peers_for_request(
        &self,
        request: &StorageServiceRequest,
    ) -> crate::error::Result<HashSet<PeerNetworkId>, Error> {
        // Get all peers grouped by priorities
        let peers_by_priorities = self.get_peers_by_priorities()?;
```

**File:** state-sync/aptos-data-client/src/client.rs (L484-501)
```rust
        if let Some(subscription_state) = active_subscription_state.take() {
            if subscription_state.subscription_stream_id == request_stream_id {
                // The stream IDs match. Verify that the request is still serviceable.
                let peer_network_id = subscription_state.peer_network_id;
                return if serviceable_peers.contains(&peer_network_id) {
                    // The previously chosen peer can still service the request
                    *active_subscription_state = Some(subscription_state);
                    Ok(Some(peer_network_id))
                } else {
                    // The previously chosen peer is either: (i) unable to service
                    // the request; or (ii) no longer the highest priority peer. So
                    // we need to return an error so the stream will be terminated.
                    Err(Error::DataIsUnavailable(format!(
                        "The peer that we were previously subscribing to should no \
                        longer service the subscriptions! Peer: {:?}, request: {:?}",
                        peer_network_id, request
                    )))
                };
```

**File:** state-sync/aptos-data-client/src/client.rs (L574-598)
```rust
    /// Returns all peers grouped by priorities
    fn get_peers_by_priorities(
        &self,
    ) -> crate::error::Result<BTreeMap<PeerPriority, HashSet<PeerNetworkId>>, Error> {
        // Get all connected peers
        let all_connected_peers = self.get_all_connected_peers()?;

        // Group the peers by priority
        let mut peers_by_priorities = BTreeMap::new();
        for peer in all_connected_peers {
            // Get the priority for the peer
            let priority = priority::get_peer_priority(
                self.base_config.clone(),
                self.get_peers_and_metadata(),
                &peer,
            );

            // Insert the peer into the priority map
            peers_by_priorities
                .entry(priority)
                .or_insert_with(HashSet::new)
                .insert(peer);
        }

        Ok(peers_by_priorities)
```

**File:** consensus/src/consensus_observer/observer/subscription.rs (L116-138)
```rust
        // Determine if enough time has elapsed to force a refresh
        let duration_since_last_check = time_now.duration_since(last_optimality_check_time);
        let refresh_interval = Duration::from_millis(
            self.consensus_observer_config
                .subscription_refresh_interval_ms,
        );
        let force_refresh = duration_since_last_check >= refresh_interval;

        // Determine if the peers have changed since the last check.
        // Note: we only check for peer changes periodically to avoid
        // excessive subscription churn due to peer connects/disconnects.
        let current_connected_peers = peers_and_metadata.keys().cloned().collect();
        let peer_check_interval = Duration::from_millis(
            self.consensus_observer_config
                .subscription_peer_change_interval_ms,
        );
        let peers_changed = duration_since_last_check >= peer_check_interval
            && current_connected_peers != last_optimality_check_peers;

        // Determine if we should perform the optimality check
        if !force_refresh && !peers_changed {
            return Ok(()); // We don't need to check optimality yet
        }
```
