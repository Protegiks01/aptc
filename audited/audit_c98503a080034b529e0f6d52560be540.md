# Audit Report

## Title
Rate Limiting Bypass via dry_run Mode in Aptos Faucet `/is_eligible` Endpoint

## Summary
The Aptos faucet's `/is_eligible` endpoint allows attackers to bypass rate limiting protections by exploiting the `dry_run` parameter behavior in rate limiting checkers. Both `MemoryRatelimitChecker` and `RedisRatelimitChecker` perform validation checks but skip incrementing rate limit counters when `dry_run=true`, allowing unlimited eligibility probes without triggering rate limits.

## Finding Description

The vulnerability exists in the interaction between the `/is_eligible` endpoint and the rate limiting checkers. [1](#0-0) 

The `/is_eligible` endpoint calls `preprocess_request()` with `dry_run=true` to check eligibility without persisting state. This `dry_run` flag is then passed to all checkers: [2](#0-1) 

The `CheckerTrait` documentation states that checkers should not store anything during dry_run, but should still validate: [3](#0-2) 

However, both rate limiting implementations have a critical flaw. In `MemoryRatelimitChecker`: [4](#0-3) 

The issue: `get_or_insert_mut(data.source_ip, || 1)` creates a new entry with value 1 if the IP doesn't exist. Then it checks if the limit is exceeded. However, the counter increment only happens when `!dry_run`. This means:
- First dry_run request: counter set to 1, check passes, stays at 1
- Subsequent dry_run requests: counter reads as 1, check passes, stays at 1
- Result: Unlimited requests possible

The same vulnerability exists in `RedisRatelimitChecker`: [5](#0-4) 

The Redis checker reads the current limit value, checks it, but only increments when `!dry_run`, allowing the same bypass.

**Attack Scenario:**
1. Attacker repeatedly calls POST `/is_eligible` with different or same addresses
2. Each request goes through rate limiting validation but never increments counters
3. Attacker can make unlimited requests to:
   - Probe which addresses are valid/funded
   - Determine faucet configuration details
   - Potentially DoS the service with high request volume
   - Bypass intended rate limiting protections

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria for the following reasons:

1. **Security Control Bypass**: The rate limiting mechanism is a critical security control designed to prevent abuse. This vulnerability completely bypasses it for the `/is_eligible` endpoint.

2. **Denial of Service Risk**: An attacker can overwhelm the faucet service with unlimited `/is_eligible` requests, potentially degrading service for legitimate users or causing resource exhaustion.

3. **Information Disclosure**: Attackers can probe the system to learn about valid addresses, faucet configuration, and system behavior without cost.

4. **Limited Direct Fund Impact**: While this doesn't directly lead to fund theft, it undermines the security architecture and could be combined with other attacks.

This fits the Medium severity category: "State inconsistencies requiring intervention" and represents a significant security control bypass that could require operational intervention to mitigate active exploitation.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Barrier to Entry**: Any attacker can call the public `/is_eligible` API endpoint without authentication
2. **Trivial Exploitation**: Requires only simple HTTP POST requests in a loop
3. **No Special Resources**: No special infrastructure, credentials, or technical knowledge required
4. **Immediate Value**: Attackers gain reconnaissance capabilities and can probe the system at will
5. **Difficult to Detect**: Since these are legitimate API calls that return expected responses, distinguishing attack traffic from legitimate usage is challenging

The combination of ease of exploitation and clear attacker benefit makes this highly likely to be discovered and exploited.

## Recommendation

The root cause is that rate limiting checkers use `get_or_insert_mut()` or similar read-and-initialize logic before the dry_run check. This creates state even in dry_run mode.

**Fix for MemoryRatelimitChecker:**
```rust
async fn check(
    &self,
    data: CheckerData,
    dry_run: bool,
) -> Result<Vec<RejectionReason>, AptosTapError> {
    self.clear_if_new_day().await;

    let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;

    // In dry_run mode, only read without inserting
    let requests_today = if dry_run {
        ip_to_requests_today.get(&data.source_ip).copied().unwrap_or(0)
    } else {
        *ip_to_requests_today.get_or_insert_mut(data.source_ip, || 0)
    };
    
    if requests_today >= self.max_requests_per_day {
        return Ok(vec![RejectionReason::new(
            format!(
                "IP {} has exceeded the daily limit of {} requests",
                data.source_ip, self.max_requests_per_day
            ),
            RejectionReasonCode::UsageLimitExhausted,
        )]);
    }
    
    if !dry_run {
        *ip_to_requests_today.get_or_insert_mut(data.source_ip, || 0) += 1;
    }

    Ok(vec![])
}
```

**Fix for RedisRatelimitChecker:**
The Redis implementation is already correct in structure (reads first, then conditionally writes), so no changes needed there. However, consider whether dry_run requests should count towards some separate monitoring metric to detect abuse.

**Alternative Approach:**
Consider whether `/is_eligible` should enforce a separate, lighter rate limit even in dry_run mode to prevent reconnaissance attacks while still allowing legitimate eligibility checks.

## Proof of Concept

```bash
#!/bin/bash
# PoC: Demonstrate unlimited /is_eligible calls bypass rate limiting

FAUCET_URL="http://localhost:8081"
ADDRESS="0x1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef"

# Assuming max_requests_per_day is configured to 5 for this IP
# Normal /fund endpoint would be rate limited after 5 requests

echo "Making 100 /is_eligible requests (should all succeed despite rate limit of 5)..."
for i in {1..100}; do
    response=$(curl -s -w "\n%{http_code}" -X POST \
        "${FAUCET_URL}/is_eligible" \
        -H "Content-Type: application/json" \
        -d "{\"address\": \"${ADDRESS}\"}")
    
    http_code=$(echo "$response" | tail -n1)
    
    if [ "$http_code" != "200" ]; then
        echo "Request $i failed with status $http_code (unexpected!)"
        exit 1
    fi
    echo "Request $i: Success (HTTP $http_code)"
done

echo ""
echo "All 100 requests succeeded! Rate limiting was bypassed."
echo ""
echo "Now trying actual /fund request (should fail due to rate limit):"
response=$(curl -s -w "\n%{http_code}" -X POST \
    "${FAUCET_URL}/fund" \
    -H "Content-Type: application/json" \
    -d "{\"address\": \"${ADDRESS}\"}")

http_code=$(echo "$response" | tail -n1)
body=$(echo "$response" | head -n-1)

echo "Fund request status: $http_code"
echo "Response: $body"

# Expected: /is_eligible calls don't increment counter, so /fund would succeed
# This demonstrates the rate limit was never incremented by /is_eligible calls
```

**Rust Integration Test:**
```rust
#[tokio::test]
async fn test_is_eligible_bypasses_rate_limit() {
    // Configure faucet with max_requests_per_day = 5
    let config = /* setup faucet config with MemoryRatelimitChecker */;
    let server = start_test_server(config).await;
    let client = reqwest::Client::new();
    
    let address = "0x1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef";
    let request_body = serde_json::json!({
        "address": address
    });
    
    // Make 100 is_eligible requests - all should succeed
    for i in 0..100 {
        let response = client
            .post(format!("{}/is_eligible", server.url))
            .json(&request_body)
            .send()
            .await
            .unwrap();
        
        assert_eq!(response.status(), 200, 
            "Request {} failed, but should succeed due to dry_run bypass", i);
    }
    
    // The rate limit counter should still be 0
    // A single fund request should succeed (proving counter wasn't incremented)
    let response = client
        .post(format!("{}/fund", server.url))
        .json(&request_body)
        .send()
        .await
        .unwrap();
    
    // This demonstrates the vulnerability: 
    // 100 is_eligible calls didn't increment counter
    assert_eq!(response.status(), 200);
}
```

## Notes

This vulnerability specifically affects the faucet component, not core consensus or Move VM functionality. However, it represents a significant security control bypass that undermines the faucet's ability to prevent abuse and maintain fair distribution of testnet/devnet funds.

### Citations

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L133-146)
```rust
    async fn is_eligible(
        &self,
        fund_request: Json<FundRequest>,
        asset: poem_openapi::param::Query<Option<String>>,
        // This automagically uses FromRequest to get this data from the request.
        // It takes into things like X-Forwarded-IP and X-Real-IP.
        source_ip: RealIp,
        // Same thing, this uses FromRequest.
        header_map: &HeaderMap,
    ) -> poem::Result<(), AptosTapErrorResponse> {
        let (checker_data, bypass, _semaphore_permit) = self
            .components
            .preprocess_request(&fund_request.0, source_ip, header_map, true)
            .await?;
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L261-270)
```rust
        // Ensure request passes checkers.
        let mut rejection_reasons = Vec::new();
        for checker in &self.checkers {
            rejection_reasons.extend(checker.check(checker_data.clone(), dry_run).await.map_err(
                |e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError),
            )?);
            if !rejection_reasons.is_empty() && self.return_rejections_early {
                break;
            }
        }
```

**File:** crates/aptos-faucet/core/src/checkers/mod.rs (L45-52)
```rust
    /// Returns a list of rejection reasons for the request, if any. If dry_run
    /// is set, if this Checker would store anything based on the request, it
    /// instead will not. This is useful for the is_eligible endpoint.
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError>;
```

**File:** crates/aptos-faucet/core/src/checkers/memory_ratelimit.rs (L68-91)
```rust
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        self.clear_if_new_day().await;

        let mut ip_to_requests_today = self.ip_to_requests_today.lock().await;

        let requests_today = ip_to_requests_today.get_or_insert_mut(data.source_ip, || 1);
        if *requests_today >= self.max_requests_per_day {
            return Ok(vec![RejectionReason::new(
                format!(
                    "IP {} has exceeded the daily limit of {} requests",
                    data.source_ip, self.max_requests_per_day
                ),
                RejectionReasonCode::UsageLimitExhausted,
            )]);
        } else if !dry_run {
            *requests_today += 1;
        }

        Ok(vec![])
    }
```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L226-304)
```rust
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        let mut conn = self
            .get_redis_connection()
            .await
            .map_err(|e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::StorageError))?;

        // Generate a key corresponding to this identifier and the current day.
        let key_prefix = self.ratelimit_key_provider.ratelimit_key_prefix();
        let key_value = self
            .ratelimit_key_provider
            .ratelimit_key_value(&data)
            .await?;
        let (key, seconds_until_next_day) =
            self.get_key_and_secs_until_next_day(key_prefix, &key_value);

        // Get the value for the key, indicating how many non-500 requests we have
        // serviced for it today.
        let limit_value: Option<i64> = conn.get(&key).await.map_err(|e| {
            AptosTapError::new_with_error_code(
                format!("Failed to get value for redis key {}: {}", key, e),
                AptosTapErrorCode::StorageError,
            )
        })?;

        // If the limit value is greater than what we allow per day, signal that we
        // should reject this request.
        if let Some(rejection_reason) = self.check_limit_value(limit_value, seconds_until_next_day)
        {
            return Ok(vec![rejection_reason]);
        }

        // Atomically increment the counter for the given key, creating it and setting
        // the expiration time if it doesn't already exist.
        if !dry_run {
            let incremented_limit_value = match limit_value {
                Some(_) => conn.incr(&key, 1).await.map_err(|e| {
                    AptosTapError::new_with_error_code(
                        format!("Failed to increment redis key {}: {}", key, e),
                        AptosTapErrorCode::StorageError,
                    )
                })?,
                // If the limit value doesn't exist, create it and set the
                // expiration time.
                None => {
                    let (incremented_limit_value,): (i64,) = redis::pipe()
                        .atomic()
                        .incr(&key, 1)
                        // Expire at the end of the day roughly.
                        .expire(&key, seconds_until_next_day as usize)
                        // Only set the expiration if one isn't already set.
                        // Only works with Redis 7 sadly.
                        // .arg("NX")
                        .ignore()
                        .query_async(&mut *conn)
                        .await
                        .map_err(|e| {
                            AptosTapError::new_with_error_code(
                                format!("Failed to increment value for redis key {}: {}", key, e),
                                AptosTapErrorCode::StorageError,
                            )
                        })?;
                    incremented_limit_value
                },
            };

            // Check limit again, to ensure there wasn't a get / set race.
            if let Some(rejection_reason) =
                self.check_limit_value(Some(incremented_limit_value), seconds_until_next_day)
            {
                return Ok(vec![rejection_reason]);
            }
        }

        Ok(vec![])
    }
```
