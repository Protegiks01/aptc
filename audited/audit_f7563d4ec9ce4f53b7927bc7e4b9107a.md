# Audit Report

## Title
Event Sequence Number Reset Vulnerability Causes API Crashes and Data Corruption

## Summary
The EventSequenceNumberSchema is never pruned during event pruning operations, but event translators default to sequence number 0 when on-chain resources are deleted. This causes sequence number resets that violate the continuity invariant, leading to API crashes when querying events and permanent data corruption in event indices.

## Finding Description

The Aptos indexer translates V2 events to V1 events by querying on-chain resources to determine event handle sequence numbers. However, the system has three critical design flaws that combine to cause sequence number collisions:

**Flaw 1: EventSequenceNumberSchema is never pruned**

During event pruning, only `EventByKeySchema` and `EventByVersionSchema` entries are deleted, but `EventSequenceNumberSchema` entries persist indefinitely. [1](#0-0) 

**Flaw 2: Translators query latest state instead of historical state**

When translating V2 events, the system queries the latest on-chain state rather than the state at the transaction version being indexed. [2](#0-1) 

If the resource has been deleted by the time indexing occurs, the translator cannot find it and defaults to sequence number 0, completely bypassing the `EventSequenceNumberSchema` lookup. [3](#0-2) 

**Flaw 3: Unsafe fallback in EventSequenceNumberSchema persistence**

When persisting cached sequence numbers, the code uses `.unwrap_or(0)` which can overwrite existing entries with 0. [4](#0-3) 

**Attack Scenario:**

1. Events are emitted and indexed for EventKey K with sequence numbers 0-100
2. `EventSequenceNumberSchema` stores K → 100  
3. The on-chain resource associated with K is deleted (e.g., account cleanup, coin store removal)
4. Events 0-50 are pruned from `EventByKeySchema`, but `EventSequenceNumberSchema` remains K → 100
5. A fresh node syncs or the indexer processes delayed transactions
6. For any new V2 events for EventKey K, the translator:
   - Queries latest state (resource is deleted)
   - Falls into the `else` branch defaulting to sequence_number = 0
   - Writes EventSequenceNumberSchema K → 0 (overwriting K → 100)
7. Future events for K get sequence numbers 1, 2, 3...
8. `EventByKeySchema` now contains mixed old and new entries:
   - (K, 0) → new event at version 500
   - (K, 1) → new event at version 501  
   - (K, 51) → old event at version 151 (not pruned yet)

9. When `lookup_events_by_key(K, 0, 100, ...)` is called, the continuity check fails: [5](#0-4) 

The function expects sequence 2 but finds 51, triggering "DB corruption: Sequence number not continuous" and bailing with an error.

**Invariants Broken:**
- **State Consistency**: Event indices become corrupted with non-continuous sequence numbers
- **Deterministic Execution**: Different nodes processing the same events at different times produce different sequence numbers depending on when resources were deleted

## Impact Explanation

This vulnerability achieves **HIGH severity** under the Aptos bug bounty criteria due to **API crashes**:

1. **API Query Failures**: Any client querying events by key will receive database corruption errors when sequence number gaps exist, rendering the event query API unusable for affected EventKeys

2. **Data Corruption**: Event indices permanently lose historical event references when sequence numbers are reused, silently overwriting old `EventByKeySchema` entries

3. **Node Synchronization Issues**: Fresh nodes syncing historical blocks will systematically mis-assign sequence numbers for any events whose resources were later deleted, creating divergent event indices across the network

4. **Protocol Violation**: Event sequence numbers are meant to be monotonically increasing and unique across the lifetime of an EventKey, which this bug violates

The impact is widespread because resource deletion is common in normal operations (account cleanup, resource destruction, etc.), and the bug affects all event types that use resource-based translation (coin events, token events, NFT events, etc.).

## Likelihood Explanation

**High Likelihood** - This bug will occur naturally without malicious intervention:

1. **Fresh Node Syncing**: Any new validator or fullnode syncing from genesis will encounter this issue for all historical events whose resources were later deleted

2. **Resource Lifecycle**: Resources are regularly deleted in normal operations:
   - Users deleting accounts
   - Burning tokens/NFTs
   - Cleaning up temporary resources
   - Protocol upgrades removing old resource types

3. **Event Pruning**: The protocol actively prunes old events, creating the partial pruning state that triggers API failures

4. **No Special Permissions Required**: The bug manifests through normal node operation and protocol mechanics

The combination of these factors makes this a **systematic issue** that will affect production nodes in regular operation.

## Recommendation

**Immediate Fix: Store and Use Transaction Version in Translation**

The root cause is querying latest state instead of historical state. The translator should:

1. Accept the transaction version as a parameter
2. Query state at that specific version, not latest
3. Implement proper fallback logic that checks `EventSequenceNumberSchema` before defaulting to 0

**Code Fix for `event_v2_translator.rs`:**

```rust
// Update get_state_value_bytes_for_resource to accept version
pub fn get_state_value_bytes_for_resource(
    &self,
    address: &AccountAddress,
    struct_tag: &StructTag,
    version: Version, // NEW PARAMETER
) -> Result<Option<Bytes>> {
    // Query state at specific version, not latest
    let state_view = self
        .main_db_reader
        .get_state_checkpoint_view(version)?; // Use versioned view
    let state_key = StateKey::resource(address, struct_tag)?;
    let maybe_state_value = state_view.get_state_value(&state_key)?;
    Ok(maybe_state_value.map(|state_value| state_value.bytes().clone()))
}
```

**Update Translators to Check EventSequenceNumberSchema:**

```rust
} else {
    // Resource not found - check EventSequenceNumberSchema before defaulting
    let key = EventKey::new(DEPOSIT_EVENT_CREATION_NUMBER, *coin_deposit.account());
    let sequence_number = engine
        .get_next_sequence_number(&key, 0)?; // This will check schema first
    (key, sequence_number)
}
```

**Remove Unsafe Fallback:**

```rust
// In db_indexer.rs, remove .unwrap_or(0) and handle missing cache properly
for event_key in event_keys {
    if let Some(seq) = self.event_v2_translation_engine
        .get_cached_sequence_number(&event_key) 
    {
        batch.put::<EventSequenceNumberSchema>(&event_key, &seq)?;
    } else {
        // Log error - this should never happen if caching is correct
        warn!("EventKey {:?} in event_keys but not in cache", event_key);
    }
}
```

## Proof of Concept

```rust
// Conceptual PoC - would need to be adapted to actual test framework

#[test]
fn test_sequence_number_reset_on_resource_deletion() {
    // 1. Setup: Create account with CoinStore
    let account = create_test_account();
    create_coin_store(&account);
    
    // 2. Emit 100 coin deposit events (sequence 0-99)
    for i in 0..100 {
        emit_coin_deposit_event(&account, 100);
    }
    
    // 3. Verify EventSequenceNumberSchema has correct value
    let event_key = get_deposit_event_key(&account);
    assert_eq!(get_sequence_number(&event_key), Some(99));
    
    // 4. Delete the CoinStore resource
    delete_coin_store(&account);
    
    // 5. Prune events 0-50 from EventByKeySchema
    prune_events(&event_key, 0, 51);
    
    // 6. Process new deposit event for same account
    // (This might happen during sync of historical blocks)
    emit_coin_deposit_event(&account, 200);
    
    // 7. Verify sequence number was reset to 0
    let new_seq = get_sequence_number(&event_key);
    assert_eq!(new_seq, Some(0)); // BUG: Should be 100
    
    // 8. Attempt to query events - should fail with continuity error
    let result = lookup_events_by_key(&event_key, 0, 100);
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("not continuous"));
    
    // 9. Database is now corrupted with:
    //    - EventByKeySchema: (key, 0) -> new event, (key, 1) -> new event, (key, 51) -> old event
    //    - Gap between seq 1 and 51 causes query failures
}
```

**Notes**

This vulnerability represents a fundamental design flaw in the V2-to-V1 event translation system. The use of latest state for historical event processing is architecturally unsound and will cause systematic failures across the network as resources are deleted through normal operations. The issue affects all nodes performing event indexing, including validators and fullnodes, making it a high-priority fix for network reliability.

### Citations

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L192-222)
```rust
    pub(crate) fn prune_event_indices(
        &self,
        start: Version,
        end: Version,
        mut indices_batch: Option<&mut SchemaBatch>,
    ) -> Result<Vec<usize>> {
        let mut ret = Vec::new();

        let mut current_version = start;

        for events in self.get_events_by_version_iter(start, (end - start) as usize)? {
            let events = events?;
            ret.push(events.len());

            if let Some(ref mut batch) = indices_batch {
                for event in events {
                    if let ContractEvent::V1(v1) = event {
                        batch.delete::<EventByKeySchema>(&(*v1.key(), v1.sequence_number()))?;
                        batch.delete::<EventByVersionSchema>(&(
                            *v1.key(),
                            current_version,
                            v1.sequence_number(),
                        ))?;
                    }
                }
            }
            current_version += 1;
        }

        Ok(ret)
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L202-214)
```rust
    pub fn get_state_value_bytes_for_resource(
        &self,
        address: &AccountAddress,
        struct_tag: &StructTag,
    ) -> Result<Option<Bytes>> {
        let state_view = self
            .main_db_reader
            .latest_state_checkpoint_view()
            .expect("Failed to get state view");
        let state_key = StateKey::resource(address, struct_tag)?;
        let maybe_state_value = state_view.get_state_value(&state_key)?;
        Ok(maybe_state_value.map(|state_value| state_value.bytes().clone()))
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L258-265)
```rust
        } else {
            // The creation number of DepositEvent is deterministically 2.
            static DEPOSIT_EVENT_CREATION_NUMBER: u64 = 2;
            (
                EventKey::new(DEPOSIT_EVENT_CREATION_NUMBER, *coin_deposit.account()),
                0,
            )
        };
```

**File:** storage/indexer/src/db_indexer.rs (L232-239)
```rust
            if seq != cur_seq {
                let msg = if cur_seq == start_seq_num {
                    "First requested event is probably pruned."
                } else {
                    "DB corruption: Sequence number not continuous."
                };
                bail!("{} expected: {}, actual: {}", msg, cur_seq, seq);
            }
```

**File:** storage/indexer/src/db_indexer.rs (L511-521)
```rust
            for event_key in event_keys {
                batch
                    .put::<EventSequenceNumberSchema>(
                        &event_key,
                        &self
                            .event_v2_translation_engine
                            .get_cached_sequence_number(&event_key)
                            .unwrap_or(0),
                    )
                    .expect("Failed to put events by key to a batch");
            }
```
