# Audit Report

## Title
Critical Hash Collision Vulnerability in Optimistic Block Proposal Hash Function Leading to Consensus Safety Violation

## Summary
The `hash()` implementation for optimistic proposals only includes the `VoteData` portion of the `QuorumCert`, excluding the signature components. This allows multiple blocks with identical content but different quorum certificate signatures to produce the same hash value, causing hash collisions in block storage and enabling consensus safety violations.

## Finding Description

The vulnerability exists in the block hashing mechanism for optimistic proposals. When computing the hash of a `BlockData` for an optimistic proposal, the implementation uses a different code path than regular blocks: [1](#0-0) 

For optimistic blocks, only the `vote_data` from the `QuorumCert` is included in the hash computation, while the full `QuorumCert` (including `LedgerInfoWithSignatures` with aggregate signatures) is excluded. This breaks the fundamental blockchain invariant that **a block's hash must uniquely identify its complete content**.

The attack scenario occurs naturally during optimistic proposal processing: [2](#0-1) 

When validators receive an `OptBlockData`, they each add their own local highest quorum certificate via `Block::new_from_opt()`. Since different validators may have different valid QCs for the same parent block (same `VoteData` but different validator signature sets), they create blocks with **identical hashes but different QC content**.

The `QuorumCert` structure contains both vote data and signatures: [3](#0-2) 

The signatures are stored in `AggregateSignature` which includes a validator bitmask: [4](#0-3) 

Multiple valid QCs can exist for the same `VoteData` with different validator sets (e.g., QC_A with validators {1,2,3,4} vs QC_B with validators {1,2,5,6}), both having >2/3 voting power. When these are included in optimistic blocks, the blocks hash identically despite having different content.

Blocks are stored in a `HashMap` indexed by hash: [5](#0-4) 

When inserting a block with a duplicate hash, the insertion logic silently returns the existing block: [6](#0-5) 

This causes different validators to maintain different blocks for the same hash ID, violating consensus safety.

## Impact Explanation

**Severity: Critical** ($1,000,000 category)

This vulnerability directly violates the **Consensus Safety** invariant stated in the requirements: "AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine." The impact includes:

1. **Consensus Split**: Different validators store different blocks for the same block ID, causing them to build divergent chains
2. **Non-Deterministic State**: Validators may execute different transactions depending on which version of the "same" block they received first
3. **Double-Spending Risk**: Chain forks enable double-spending attacks as different branches may commit conflicting transactions
4. **Network Partition**: The blockchain could split into multiple incompatible chains requiring a hard fork to resolve

This qualifies as a "Consensus/Safety violation" under Critical Severity in the Aptos Bug Bounty program.

## Likelihood Explanation

**Likelihood: High**

This vulnerability occurs naturally during normal protocol operation without requiring any Byzantine behavior:

1. **Natural Occurrence**: During optimistic proposal propagation, validators legitimately have different highest QCs due to network timing
2. **No Special Permissions Required**: Any validator participating in consensus will encounter this issue
3. **Frequent Trigger**: Happens whenever validators have collected different valid signature sets (>2/3) for parent blocks
4. **Not Detectable**: The hash collision is silent - no error is raised, making it difficult to detect in production

The vulnerability is triggered automatically when:
- Optimistic proposals are enabled (common configuration)
- Network conditions cause validators to receive votes from different subsets of the validator set
- Multiple valid QCs exist for the same block (common in asynchronous networks)

## Recommendation

**Fix: Include the full QuorumCert in optimistic block hash computation**

Modify the `hash()` function to include the complete `QuorumCert` (including signatures) for all block types:

```rust
impl CryptoHash for BlockData {
    type Hasher = BlockDataHasher;

    fn hash(&self) -> HashValue {
        let mut state = Self::Hasher::default();
        // Remove the special case for opt blocks - always hash the full BlockData
        bcs::serialize_into(&mut state, &self).expect("BlockData must be serializable");
        state.finish()
    }
}
```

**Alternative Fix: Use deterministic QC selection**

If the optimistic proposal optimization requires excluding QC from hash, implement a deterministic QC selection mechanism where all validators use the same canonical QC (e.g., the one with the lexicographically smallest signature set) when converting `OptBlockData` to `Block`.

**Verification Steps**:
1. Add unit test creating two blocks with same content but different QCs
2. Verify they produce different hashes after the fix
3. Add integration test ensuring block storage correctly handles multiple QCs
4. Audit all `CryptoHash` implementations for similar issues

## Proof of Concept

```rust
#[cfg(test)]
mod hash_collision_test {
    use super::*;
    use aptos_crypto::HashValue;
    use aptos_types::{
        block_info::BlockInfo,
        aggregate_signature::AggregateSignature,
        ledger_info::{LedgerInfo, LedgerInfoWithSignatures},
    };
    use aptos_bitvec::BitVec;

    #[test]
    fn test_opt_block_hash_collision() {
        // Create a parent block info
        let parent_block_info = BlockInfo::new(
            1,  // epoch
            10, // round
            HashValue::random(),
            HashValue::random(),
            100, // version
            1000, // timestamp
            None,
        );
        
        // Create identical vote data
        let vote_data = VoteData::new(
            parent_block_info.clone(),
            parent_block_info.clone(),
        );
        
        // Create QC_A with one validator set (validators 0,1,2)
        let mut bitvec_a = BitVec::with_num_bits(4);
        bitvec_a.set(0);
        bitvec_a.set(1);
        bitvec_a.set(2);
        let qc_a = QuorumCert::new(
            vote_data.clone(),
            LedgerInfoWithSignatures::new(
                LedgerInfo::new(parent_block_info.clone(), vote_data.hash()),
                AggregateSignature::new(bitvec_a, None),
            ),
        );
        
        // Create QC_B with different validator set (validators 0,2,3)
        let mut bitvec_b = BitVec::with_num_bits(4);
        bitvec_b.set(0);
        bitvec_b.set(2);
        bitvec_b.set(3);
        let qc_b = QuorumCert::new(
            vote_data.clone(),
            LedgerInfoWithSignatures::new(
                LedgerInfo::new(parent_block_info.clone(), vote_data.hash()),
                AggregateSignature::new(bitvec_b, None),
            ),
        );
        
        // Create opt block body
        let opt_block_body = OptBlockBody::V0 {
            validator_txns: vec![],
            payload: Payload::empty(false, true),
            author: AccountAddress::random(),
            grandparent_qc: QuorumCert::dummy(),
        };
        
        // Create two BlockData instances with same content but different QCs
        let block_data_a = BlockData::new_for_testing(
            1,  // epoch
            11, // round
            2000, // timestamp
            qc_a,
            BlockType::OptimisticProposal(opt_block_body.clone()),
        );
        
        let block_data_b = BlockData::new_for_testing(
            1,  // epoch
            11, // round
            2000, // timestamp
            qc_b,
            BlockType::OptimisticProposal(opt_block_body.clone()),
        );
        
        // VULNERABILITY: Both blocks hash to the same value!
        let hash_a = block_data_a.hash();
        let hash_b = block_data_b.hash();
        
        assert_eq!(hash_a, hash_b, "Hash collision: two different blocks have the same hash!");
        
        // But the blocks have different content (different QCs)
        assert_ne!(
            block_data_a.quorum_cert().ledger_info().get_voters_bitvec(),
            block_data_b.quorum_cert().ledger_info().get_voters_bitvec(),
            "The QCs have different validator sets"
        );
    }
}
```

**Notes**

The vulnerability is particularly insidious because:

1. **Silent Failure**: The block storage's `insert_block` function silently returns the existing block without error when a hash collision occurs, making this difficult to detect
2. **Design vs Implementation Gap**: The optimistic proposal feature was designed to reduce latency by allowing validators to add their own QC, but the hash function wasn't updated to handle this correctly
3. **Protocol-Level Issue**: This cannot be fixed with validation logic alone - it requires changing the fundamental hash computation
4. **Affects Production**: Any Aptos network using optimistic proposals (which is likely the default configuration) is vulnerable

The fix must ensure that block hashes are deterministically computed from **all** block content, not just a subset. The current optimization of excluding QC signatures from the hash breaks the critical security property that hash uniquely identifies content.

### Citations

**File:** consensus/consensus-types/src/block_data.rs (L108-134)
```rust
    fn hash(&self) -> HashValue {
        let mut state = Self::Hasher::default();
        if self.is_opt_block() {
            #[derive(Serialize)]
            struct OptBlockDataForHash<'a> {
                epoch: u64,
                round: Round,
                timestamp_usecs: u64,
                quorum_cert_vote_data: &'a VoteData,
                block_type: &'a BlockType,
            }

            let opt_block_data_for_hash = OptBlockDataForHash {
                epoch: self.epoch,
                round: self.round,
                timestamp_usecs: self.timestamp_usecs,
                quorum_cert_vote_data: self.quorum_cert.vote_data(),
                block_type: &self.block_type,
            };
            bcs::serialize_into(&mut state, &opt_block_data_for_hash)
                .expect("OptBlockDataForHash must be serializable");
        } else {
            bcs::serialize_into(&mut state, &self).expect("BlockData must be serializable");
        }
        state.finish()
    }
}
```

**File:** consensus/src/round_manager.rs (L843-875)
```rust
    async fn process_opt_proposal(&mut self, opt_block_data: OptBlockData) -> anyhow::Result<()> {
        ensure!(
            self.block_store
                .get_block_for_round(opt_block_data.round())
                .is_none(),
            "Proposal has already been processed for round: {}",
            opt_block_data.round()
        );
        let hqc = self.block_store.highest_quorum_cert().as_ref().clone();
        ensure!(
            hqc.certified_block().round() + 1 == opt_block_data.round(),
            "Opt proposal round {} is not the next round after the highest qc round {}",
            opt_block_data.round(),
            hqc.certified_block().round()
        );
        ensure!(
            hqc.certified_block().id() == opt_block_data.parent_id(),
            "Opt proposal parent id {} is not the same as the highest qc certified block id {}",
            opt_block_data.parent_id(),
            hqc.certified_block().id()
        );
        let proposal = Block::new_from_opt(opt_block_data, hqc);
        observe_block(proposal.timestamp_usecs(), BlockStage::PROCESS_OPT_PROPOSAL);
        info!(
            self.new_log(LogEvent::ProcessOptProposal),
            block_author = proposal.author(),
            block_epoch = proposal.epoch(),
            block_round = proposal.round(),
            block_hash = proposal.id(),
            block_parent_hash = proposal.quorum_cert().certified_block().id(),
        );
        self.process_proposal(proposal).await
    }
```

**File:** consensus/consensus-types/src/quorum_cert.rs (L17-23)
```rust
#[derive(Deserialize, Serialize, Clone, Debug, Eq, PartialEq)]
pub struct QuorumCert {
    /// The vote information is certified by the quorum.
    vote_data: VoteData,
    /// The signed LedgerInfo of a committed block that carries the data about the certified block.
    signed_ledger_info: LedgerInfoWithSignatures,
}
```

**File:** types/src/aggregate_signature.rs (L11-30)
```rust
/// This struct represents a BLS multi-signature or aggregated signature:
/// it stores a bit mask representing the set of validators participating in the signing process
/// and the multi-signature/aggregated signature itself,
/// which was aggregated from these validators' partial BLS signatures.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, CryptoHasher, BCSCryptoHash)]
pub struct AggregateSignature {
    validator_bitmask: BitVec,
    sig: Option<bls12381::Signature>,
}

impl AggregateSignature {
    pub fn new(
        validator_bitmask: BitVec,
        aggregated_signature: Option<bls12381::Signature>,
    ) -> Self {
        Self {
            validator_bitmask,
            sig: aggregated_signature,
        }
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L73-75)
```rust
pub struct BlockTree {
    /// All the blocks known to this replica (with parent links)
    id_to_block: HashMap<HashValue, LinkableBlock>,
```

**File:** consensus/src/block_storage/block_tree.rs (L307-339)
```rust
    pub(super) fn insert_block(
        &mut self,
        block: PipelinedBlock,
    ) -> anyhow::Result<Arc<PipelinedBlock>> {
        let block_id = block.id();
        if let Some(existing_block) = self.get_block(&block_id) {
            debug!("Already had block {:?} for id {:?} when trying to add another block {:?} for the same id",
                       existing_block,
                       block_id,
                       block);
            Ok(existing_block)
        } else {
            match self.get_linkable_block_mut(&block.parent_id()) {
                Some(parent_block) => parent_block.add_child(block_id),
                None => bail!("Parent block {} not found", block.parent_id()),
            };
            let linkable_block = LinkableBlock::new(block);
            let arc_block = Arc::clone(linkable_block.executed_block());
            assert!(self.id_to_block.insert(block_id, linkable_block).is_none());
            // Note: the assumption is that we have/enforce unequivocal proposer election.
            if let Some(old_block_id) = self.round_to_ids.get(&arc_block.round()) {
                warn!(
                    "Multiple blocks received for round {}. Previous block id: {}",
                    arc_block.round(),
                    old_block_id
                );
            } else {
                self.round_to_ids.insert(arc_block.round(), block_id);
            }
            counters::NUM_BLOCKS_IN_TREE.inc();
            Ok(arc_block)
        }
    }
```
