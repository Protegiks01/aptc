# Audit Report

## Title
Peer Monitoring Task Cancellation Silently Drops Byzantine Behavior Detection

## Summary

The peer monitoring service client spawns async tasks to monitor peer health and detect Byzantine behavior, but immediately drops the `JoinHandle` returned from task spawning without awaiting completion or observing cancellation. When tasks are cancelled (e.g., during runtime shutdown), any Byzantine behavior detected mid-processing is silently lost, and the request tracker state becomes inconsistent, allowing malicious peers to evade detection thresholds.

## Finding Description

The peer monitoring client detects various forms of Byzantine/malicious peer behavior including incorrect ping counter responses, invalid network topology claims, and protocol violations. When such behavior is detected, it increments a consecutive failure counter, and peers exceeding the failure threshold should be flagged for disconnection.

However, the task spawning mechanism has a critical flaw in error propagation: [1](#0-0) 

The `refresh_peer_state_key()` function returns `Result<JoinHandle<()>, Error>`, but the `JoinHandle` is immediately dropped. Only spawn errors are checked via the `?` operator, but task completion, cancellation, or panics are never observed.

Inside the spawned task, a critical race condition exists: [2](#0-1) 

The task marks the request as completed (clearing the in-flight flag) at line 121, **before** processing responses or handling errors. If the task is cancelled between line 121 and the error handling code (lines 127-130), the system believes the request completed successfully (no longer in-flight), but:

1. No success was recorded (no call to `record_response_success()`)
2. No failure was recorded (no call to `record_response_failure()`)
3. Byzantine behavior detection is lost

Byzantine behavior is detected in multiple locations:

**Incorrect Ping Counters (Latency Monitoring):** [3](#0-2) 

**Invalid Network Topology (Network Monitoring):** [4](#0-3) 

When Byzantine behavior is detected, `handle_request_failure()` should be called: [5](#0-4) 

This increments the consecutive failure counter. If this counter reaches `max_latency_ping_failures`, the peer should be flagged. However, task cancellation prevents this counter from incrementing.

**Attack Scenario:**

1. Malicious peer connects to an Aptos node
2. Malicious peer sends invalid responses (wrong ping counters, false network depth claims)
3. Peer monitoring task begins processing the response and detects Byzantine behavior
4. Before error handling completes, node initiates shutdown/restart (common during updates)
5. Task is cancelled after line 121 but before error handling (lines 127-130)
6. Byzantine behavior is never logged, failure counter never increments
7. Peer reconnects after restart with clean state (no accumulated failures)
8. Malicious peer repeats during each restart window, evading detection

## Impact Explanation

This vulnerability meets **Medium Severity** criteria per the Aptos Bug Bounty program:

- **State Inconsistencies**: The request tracker enters an inconsistent state where `in_flight_request=false` but neither success nor failure was recorded, violating the state machine invariant
- **Weakened Byzantine Detection**: Malicious peers can exploit restart/shutdown windows to send invalid responses without accumulating failure counts
- **Peer Reputation System Bypass**: The consecutive failure threshold mechanism intended to identify and disconnect problematic peers can be circumvented

This does not meet Higher severity because:
- It does not directly cause consensus failure or fund loss
- It does not crash validator nodes or partition the network
- It only affects peer monitoring metadata, not consensus-critical operations

However, it represents a meaningful security degradation in the peer health monitoring system, which is designed to protect nodes from resource exhaustion and information poisoning by malicious peers.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability has moderate to high likelihood of exploitation:

**Factors Increasing Likelihood:**
- Node restarts are common (updates, config changes, crash recovery)
- The window of vulnerability exists during every shutdown sequence
- No special privileges required - any peer can send malicious responses
- Attack can be automated to trigger during detected restart patterns
- Multiple Byzantine behaviors can be exploited (ping counters, network info, node info)

**Factors Decreasing Likelihood:**
- Requires precise timing during shutdown windows
- Peer state is reset on reconnection anyway (but this actually helps attacker)
- Other monitoring systems may still detect persistent malicious behavior

The real concern is systematic exploitation: an attacker operating multiple malicious peers could strategically send invalid responses during restart windows across many nodes, persistently evading the consecutive failure detection mechanism while remaining connected longer than intended.

## Recommendation

**Solution 1: Store and Await JoinHandles**

Modify the peer monitoring loop to store `JoinHandle`s and await them before proceeding or during shutdown:

```rust
// In peer_states/mod.rs
pub fn refresh_peer_states(
    monitoring_service_config: &PeerMonitoringServiceConfig,
    peer_monitor_state: PeerMonitorState,
    peer_monitoring_client: PeerMonitoringServiceClient<NetworkClient<PeerMonitoringServiceMessage>>,
    connected_peers_and_metadata: HashMap<PeerNetworkId, PeerMetadata>,
    time_service: TimeService,
    runtime: Option<Handle>,
) -> Result<Vec<JoinHandle<()>>, Error> {  // Return handles instead of ()
    let mut join_handles = Vec::new();
    
    for peer_state_key in PeerStateKey::get_all_keys() {
        for (peer_network_id, peer_metadata) in &connected_peers_and_metadata {
            let peer_state = get_peer_state(&peer_monitor_state, peer_network_id)?;
            let request_tracker = peer_state.get_request_tracker(&peer_state_key)?;
            
            if request_tracker.read().new_request_required() {
                let join_handle = peer_state.refresh_peer_state_key(
                    monitoring_service_config,
                    &peer_state_key,
                    peer_monitoring_client.clone(),
                    *peer_network_id,
                    peer_metadata.clone(),
                    peer_monitor_state.request_id_generator.clone(),
                    time_service.clone(),
                    runtime.clone(),
                )?;
                join_handles.push(join_handle);  // Store handle
            }
        }
    }
    
    Ok(join_handles)
}
```

Then in the main loop, await handles during graceful shutdown: [6](#0-5) 

**Solution 2: Move `request_completed()` After Error Handling**

Alternatively, move the `request_completed()` call to after all error handling is complete. However, this is less robust as it doesn't address task cancellation during shutdown.

**Solution 3: Use Cancellation Tokens**

Implement graceful cancellation using `tokio::sync::CancellationToken` to allow tasks to complete critical sections before cancelling:

```rust
let cancellation_token = CancellationToken::new();

let request_task = async move {
    sleep(Duration::from_millis(request_jitter_ms)).await;
    let start_time = time_service.now();
    
    let monitoring_service_response = network::send_request_to_peer(...).await;
    let request_duration_secs = start_time.elapsed().as_secs_f64();
    
    // Critical section - must not be cancelled
    request_tracker.write().request_completed();
    
    match monitoring_service_response {
        Ok(response) => {
            // Process response atomically
            peer_state_value.write().handle_monitoring_service_response(...);
        },
        Err(error) => {
            // Handle error atomically  
            peer_state_value.write().handle_monitoring_service_response_error(...);
        }
    }
};

tokio::select! {
    _ = request_task => {},
    _ = cancellation_token.cancelled() => {
        // Task was cancelled, but critical section already completed
    }
}
```

**Recommended Approach**: Implement Solution 1 (store and await handles) combined with graceful shutdown signaling. This ensures all in-flight monitoring operations complete their error handling before the runtime terminates.

## Proof of Concept

```rust
#[cfg(test)]
mod test_task_cancellation {
    use super::*;
    use aptos_config::config::NodeConfig;
    use aptos_peer_monitoring_service_types::PeerMonitoringServiceMessage;
    use aptos_time_service::TimeService;
    use tokio::runtime::Runtime;
    use std::sync::Arc;
    use std::sync::atomic::{AtomicBool, Ordering};
    
    #[test]
    fn test_byzantine_detection_lost_on_cancellation() {
        // Create runtime that will be dropped (simulating shutdown)
        let runtime = Runtime::new().unwrap();
        let handle = runtime.handle().clone();
        
        // Setup peer monitoring state
        let node_config = NodeConfig::default();
        let peer_monitor_state = PeerMonitorState::new();
        let time_service = TimeService::mock();
        
        // Create a peer state
        let peer_network_id = PeerNetworkId::random();
        peer_monitor_state.peer_states.write().insert(
            peer_network_id,
            PeerState::new(node_config.clone(), time_service.clone()),
        );
        
        // Track if error handling was called
        let error_handled = Arc::new(AtomicBool::new(false));
        let error_handled_clone = error_handled.clone();
        
        // Spawn a task that detects Byzantine behavior
        let join_handle = handle.spawn(async move {
            // Simulate detecting Byzantine behavior
            sleep(Duration::from_millis(50)).await;
            
            // Mark request completed (line 121 in peer_state.rs)
            // ... request_tracker.write().request_completed();
            
            // Simulate Byzantine detection and error handling
            sleep(Duration::from_millis(50)).await;
            error_handled_clone.store(true, Ordering::SeqCst);
            
            // This should call handle_monitoring_service_response_error
            // which increments failure counter
        });
        
        // Immediately drop the JoinHandle (as the code currently does)
        drop(join_handle);
        
        // Simulate shutdown by dropping runtime after short delay
        std::thread::sleep(Duration::from_millis(75));
        drop(runtime);
        
        // Verify error handling was NOT called due to cancellation
        assert!(!error_handled.load(Ordering::SeqCst), 
                "Byzantine error handling should have been cancelled");
        
        // In production, this means:
        // 1. request_completed() was called (in_flight = false)
        // 2. But neither record_response_success() nor record_response_failure() was called
        // 3. Byzantine behavior was detected but never recorded
        // 4. Consecutive failure counter was not incremented
        // 5. Malicious peer evades detection threshold
    }
    
    #[test]
    fn test_correct_behavior_with_awaited_handles() {
        let runtime = Runtime::new().unwrap();
        let handle = runtime.handle().clone();
        
        let error_handled = Arc::new(AtomicBool::new(false));
        let error_handled_clone = error_handled.clone();
        
        // Spawn task and KEEP the handle
        let join_handle = handle.spawn(async move {
            sleep(Duration::from_millis(50)).await;
            error_handled_clone.store(true, Ordering::SeqCst);
        });
        
        // Await completion before shutdown
        runtime.block_on(join_handle).unwrap();
        
        // Verify error handling completed
        assert!(error_handled.load(Ordering::SeqCst),
                "Error handling should complete when handles are awaited");
        
        drop(runtime);
    }
}
```

This PoC demonstrates that:
1. Tasks spawned without storing/awaiting `JoinHandle`s are silently cancelled during shutdown
2. Byzantine behavior detection code never completes, leaving failure counters unincremented
3. Proper handle management ensures error handling completes before shutdown

## Notes

This vulnerability is particularly concerning because:

1. **Silent Failures**: The dropped `JoinHandle` means task cancellation, panics, or completion are never observed
2. **State Machine Violation**: Request tracker enters invalid state (not in-flight, but no success/failure recorded)
3. **Systematic Exploitation**: Attackers can repeatedly exploit restart windows across the network
4. **Defense Evasion**: The consecutive failure threshold mechanism, designed to protect against malicious peers, is effectively bypassed

The peer monitoring service is a critical defense layer. While it doesn't directly protect consensus, it safeguards nodes from resource exhaustion and information poisoning by identifying and disconnecting problematic peers. This vulnerability significantly weakens that protection.

### Citations

**File:** peer-monitoring-service/client/src/peer_states/mod.rs (L56-68)
```rust
            let should_refresh_peer_state_key = request_tracker.read().new_request_required();
            if should_refresh_peer_state_key {
                peer_state.refresh_peer_state_key(
                    monitoring_service_config,
                    &peer_state_key,
                    peer_monitoring_client.clone(),
                    *peer_network_id,
                    peer_metadata.clone(),
                    peer_monitor_state.request_id_generator.clone(),
                    time_service.clone(),
                    runtime.clone(),
                )?;
            }
```

**File:** peer-monitoring-service/client/src/peer_states/peer_state.rs (L120-131)
```rust
            // Mark the in-flight request as now complete
            request_tracker.write().request_completed();

            // Process any response errors
            let monitoring_service_response = match monitoring_service_response {
                Ok(monitoring_service_response) => monitoring_service_response,
                Err(error) => {
                    peer_state_value
                        .write()
                        .handle_monitoring_service_response_error(&peer_network_id, error);
                    return;
                },
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L59-72)
```rust
    /// Handles a ping failure for the specified peer
    fn handle_request_failure(&self, peer_network_id: &PeerNetworkId) {
        // Update the number of ping failures for the request tracker
        self.request_tracker.write().record_response_failure();

        // TODO: If the number of ping failures is too high, disconnect from the node
        let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
        if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::TooManyPingFailures)
                .peer(peer_network_id)
                .message("Too many ping failures occurred for the peer!"));
        }
    }
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L178-191)
```rust
        // Verify the latency ping response contains the correct counter
        let request_ping_counter = latency_ping_request.ping_counter;
        let response_ping_counter = latency_ping_response.ping_counter;
        if request_ping_counter != response_ping_counter {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::PeerPingError)
                .peer(peer_network_id)
                .message(&format!(
                    "Peer responded with the incorrect ping counter! Expected: {:?}, found: {:?}",
                    request_ping_counter, response_ping_counter
                )));
            self.handle_request_failure(peer_network_id);
            return;
        }
```

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L143-154)
```rust
        // If the depth did not pass our sanity checks, handle a failure
        if !is_valid_depth {
            warn!(LogSchema::new(LogEntry::NetworkInfoRequest)
                .event(LogEvent::InvalidResponse)
                .peer(peer_network_id)
                .message(&format!(
                    "Peer returned invalid depth from validators: {}",
                    network_info_response.distance_from_validators
                )));
            self.handle_request_failure();
            return;
        }
```

**File:** peer-monitoring-service/client/src/lib.rs (L143-156)
```rust
        if let Err(error) = peer_states::refresh_peer_states(
            &monitoring_service_config,
            peer_monitor_state.clone(),
            peer_monitoring_client.clone(),
            connected_peers_and_metadata,
            time_service.clone(),
            runtime.clone(),
        ) {
            warn!(LogSchema::new(LogEntry::PeerMonitorLoop)
                .event(LogEvent::UnexpectedErrorEncountered)
                .error(&error)
                .message("Failed to refresh peer states!"));
        }
    }
```
