# Audit Report

## Title
Time-of-Check-Time-of-Use (TOCTOU) Race Condition in Block Payload Verification Allows Stale Payload Re-insertion and Resource Exhaustion

## Summary
The `verify_payload_signatures()` function in `BlockPayloadStore` contains a TOCTOU race condition where payload verification and re-insertion are not atomic. The function clones verified payloads while holding a lock, releases the lock, then re-inserts the clones. Between lock release and re-insertion, concurrent commit operations can remove already-committed payloads, which are then incorrectly re-added as "verified," causing stale data accumulation and potential resource exhaustion.

## Finding Description

The vulnerability exists in the verification and re-insertion pattern: [1](#0-0) 

The problematic flow:

1. **Lines 235-256**: The function locks the map, retrieves an unverified payload, verifies signatures, clones the payload, then **releases the lock** (scope ends at line 256)
2. **Lines 268-270**: Later, it re-locks and inserts the cloned payloads as verified

Between steps 1 and 2, another thread can execute commit operations that remove payloads: [2](#0-1) 

**Race Condition Scenario:**

- **Thread A** (verify_payload_signatures): Locks map → Verifies payload for epoch=5, round=100 → Clones payload → **Unlocks map** (line 256)
- **Thread B** (handle_committed_blocks): Block (5, 100) commits → Locks map → Removes all payloads ≤ (5, 100) → Unlocks map  
- **Thread A** (continues): Re-locks map → **Re-inserts the cloned payload** for (5, 100) as "verified" (line 269)

**Result**: A payload for an already-committed block is re-inserted into the store, violating the invariant that only pending blocks should have stored payloads.

The clone operation itself correctly preserves all data from the original payload: [3](#0-2) 

However, the **timing of re-insertion after cloning** creates the vulnerability. The cloned data becomes stale because the block it represents was committed and should have been permanently removed.

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos bug bounty)

This vulnerability causes:

1. **Resource Exhaustion**: Stale payloads accumulate in memory, potentially exceeding `max_num_pending_blocks`: [4](#0-3) 

2. **State Inconsistency**: The payload store contains verified payloads for blocks consensus has already committed, violating state management invariants

3. **Memory Leak**: Over time, committed payloads that should be removed permanently remain in memory

4. **Potential DoS**: If an attacker can reliably trigger this race (e.g., by controlling block commit timing relative to epoch changes that trigger mass payload verification), they can fill the payload store with stale entries, causing:
   - Legitimate payloads to be dropped when the limit is reached
   - Increased memory consumption on observer nodes
   - Performance degradation from scanning stale entries

This breaks the **Resource Limits** invariant (operations must respect storage limits) and the **State Consistency** invariant (state should be kept clean of already-processed data).

## Likelihood Explanation

**Likelihood: Medium to High**

The race occurs when:
1. `verify_payload_signatures()` is called during epoch transitions (when buffered unverified payloads are batch-verified): [5](#0-4) 

2. Simultaneously, blocks are being committed via the commit callback: [6](#0-5) 

This is **likely** because:
- Epoch transitions trigger mass payload verification of all buffered payloads
- Block commits happen continuously during normal operation
- The window between line 256 (unlock) and line 269 (re-insert) can be substantial if many payloads need re-insertion
- No synchronization prevents commit operations during payload verification

## Recommendation

Fix the race by making verification and status update atomic. Do not release the lock between verification and status change:

```rust
pub fn verify_payload_signatures(&mut self, epoch_state: &EpochState) -> Vec<Round> {
    let current_epoch = epoch_state.epoch;
    let payload_epochs_and_rounds: Vec<(u64, Round)> =
        self.block_payloads.lock().keys().cloned().collect();

    let mut verified_payload_rounds = vec![];
    for (epoch, round) in payload_epochs_and_rounds {
        if epoch > current_epoch {
            break;
        }

        if epoch == current_epoch {
            // Acquire lock and keep it for the entire operation
            let mut block_payloads = self.block_payloads.lock();
            if let Entry::Occupied(mut entry) = block_payloads.entry((epoch, round)) {
                if let BlockPayloadStatus::AvailableAndUnverified(block_payload) = entry.get() {
                    // Verify without taking mutable reference
                    if let Err(error) = block_payload.verify_payload_signatures(epoch_state) {
                        error!(LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to verify block payload signatures for epoch: {:?}, round: {:?}. Error: {:?}",
                            epoch, round, error
                        )));
                        entry.remove();
                    } else {
                        // Clone and immediately replace in the same critical section
                        let verified_payload = block_payload.clone();
                        let verified_status = BlockPayloadStatus::AvailableAndVerified(verified_payload);
                        entry.insert(verified_status);
                        verified_payload_rounds.push(round);
                    }
                }
            }
            // Lock is released here, but only after atomic update
        }
    }

    verified_payload_rounds
}
```

**Key Changes:**
1. Keep the lock held while transitioning from unverified to verified status
2. Use `entry.insert()` to atomically replace the status instead of deferring re-insertion
3. Build `verified_payload_rounds` directly instead of `verified_payloads_to_update`

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;

    #[test]
    fn test_toctou_race_condition() {
        let config = ConsensusObserverConfig {
            max_num_pending_blocks: 10,
            ..ConsensusObserverConfig::default()
        };
        let mut store = BlockPayloadStore::new(config);
        
        // Insert an unverified payload for epoch 1, round 100
        let epoch = 1;
        let round = 100;
        let block_info = BlockInfo::random_with_epoch(epoch, round);
        let payload = BlockPayload::new(block_info, BlockTransactionPayload::empty());
        store.insert_block_payload(payload.clone(), false);
        
        let store_arc = Arc::new(Mutex::new(store));
        let barrier = Arc::new(Barrier::new(2));
        
        // Thread 1: Verify payload signatures
        let store_clone1 = store_arc.clone();
        let barrier_clone1 = barrier.clone();
        let verify_thread = thread::spawn(move || {
            let epoch_state = EpochState::new(epoch, ValidatorVerifier::new(vec![]));
            barrier_clone1.wait(); // Synchronize start
            
            // This will verify, clone, release lock, then re-insert
            store_clone1.lock().verify_payload_signatures(&epoch_state);
        });
        
        // Thread 2: Remove committed blocks
        let store_clone2 = store_arc.clone();
        let barrier_clone2 = barrier.clone();
        let commit_thread = thread::spawn(move || {
            barrier_clone2.wait(); // Synchronize start
            thread::sleep(std::time::Duration::from_millis(10)); // Let verify progress
            
            // Remove the block as if it was committed
            store_clone2.lock().remove_blocks_for_epoch_round(epoch, round);
        });
        
        verify_thread.join().unwrap();
        commit_thread.join().unwrap();
        
        // Check if payload was re-inserted after being removed
        let final_store = store_arc.lock();
        let payloads = final_store.get_block_payloads();
        let payloads_locked = payloads.lock();
        
        // BUG: Payload for committed block should not exist, but race allows re-insertion
        if payloads_locked.contains_key(&(epoch, round)) {
            panic!("RACE CONDITION DETECTED: Payload for committed block was re-inserted!");
        }
    }
}
```

## Notes

The vulnerability is specifically in the **asynchronous pattern** of verification, not in the clone operation itself. The `BlockPayload::clone()` correctly creates an identical copy with all security properties preserved. However, by releasing the lock between verification and re-insertion, the code creates a window where committed blocks can be removed, only to be incorrectly re-added moments later. This violates the consensus observer's assumption that the payload store only contains payloads for pending blocks, not committed ones.

### Citations

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L84-95)
```rust
        // Verify that the number of payloads doesn't exceed the maximum
        let max_num_pending_blocks = self.consensus_observer_config.max_num_pending_blocks as usize;
        if self.block_payloads.lock().len() >= max_num_pending_blocks {
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Exceeded the maximum number of payloads: {:?}. Dropping block: {:?}!",
                    max_num_pending_blocks,
                    block_payload.block(),
                ))
            );
            return; // Drop the block if we've exceeded the maximum
        }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L217-274)
```rust
    pub fn verify_payload_signatures(&mut self, epoch_state: &EpochState) -> Vec<Round> {
        // Get the current epoch
        let current_epoch = epoch_state.epoch;

        // Gather the keys for the block payloads
        let payload_epochs_and_rounds: Vec<(u64, Round)> =
            self.block_payloads.lock().keys().cloned().collect();

        // Go through all unverified blocks and attempt to verify the signatures
        let mut verified_payloads_to_update = vec![];
        for (epoch, round) in payload_epochs_and_rounds {
            // Check if we can break early (BtreeMaps are sorted by key)
            if epoch > current_epoch {
                break;
            }

            // Otherwise, attempt to verify the payload signatures
            if epoch == current_epoch {
                if let Entry::Occupied(mut entry) = self.block_payloads.lock().entry((epoch, round))
                {
                    if let BlockPayloadStatus::AvailableAndUnverified(block_payload) =
                        entry.get_mut()
                    {
                        if let Err(error) = block_payload.verify_payload_signatures(epoch_state) {
                            // Log the verification failure
                            error!(
                                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                                    "Failed to verify the block payload signatures for epoch: {:?} and round: {:?}. Error: {:?}",
                                    epoch, round, error
                                ))
                            );

                            // Remove the block payload from the store
                            entry.remove();
                        } else {
                            // Save the block payload for reinsertion
                            verified_payloads_to_update.push(block_payload.clone());
                        }
                    }
                }
            }
        }

        // Collect the rounds of all newly verified blocks
        let verified_payload_rounds: Vec<Round> = verified_payloads_to_update
            .iter()
            .map(|block_payload| block_payload.round())
            .collect();

        // Update the verified block payloads. Note: this will cause
        // notifications to be sent to any listeners that are waiting.
        for verified_payload in verified_payloads_to_update {
            self.insert_block_payload(verified_payload, true);
        }

        // Return the newly verified payload rounds
        verified_payload_rounds
    }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L182-189)
```rust
    fn handle_committed_blocks(&mut self, ledger_info: LedgerInfoWithSignatures) {
        // Remove the committed blocks from the payload and ordered block stores
        self.block_payload_store.remove_blocks_for_epoch_round(
            ledger_info.commit_info().epoch(),
            ledger_info.commit_info().round(),
        );
        self.ordered_block_store
            .remove_blocks_for_commit(&ledger_info);
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L325-333)
```rust
pub fn create_commit_callback(
    observer_block_data: Arc<Mutex<ObserverBlockData>>,
) -> Box<dyn FnOnce(WrappedLedgerInfo, LedgerInfoWithSignatures) + Send + Sync> {
    Box::new(move |_, ledger_info: LedgerInfoWithSignatures| {
        observer_block_data
            .lock()
            .handle_committed_blocks(ledger_info);
    })
}
```

**File:** consensus/src/consensus_observer/network/observer_message.rs (L839-844)
```rust
/// Payload message contains the block and transaction payload
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
pub struct BlockPayload {
    block: BlockInfo,
    transaction_payload: BlockTransactionPayload,
}
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L1034-1044)
```rust
            let new_epoch_state = self.get_epoch_state();
            let verified_payload_rounds = self
                .observer_block_data
                .lock()
                .verify_payload_signatures(&new_epoch_state);

            // Order all the pending blocks that are now ready (these were buffered during state sync)
            for payload_round in verified_payload_rounds {
                self.order_ready_pending_block(new_epoch_state.epoch, payload_round)
                    .await;
            }
```
