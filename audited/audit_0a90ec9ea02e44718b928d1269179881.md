# Audit Report

## Title
Silent Database Corruption in Randomness Generation Leads to Consensus Liveness Failure and Non-Deterministic Validator Behavior

## Summary
The `AugDataStore::new()` function silently drops corrupted `CertifiedAugData` entries during initialization, causing validators to operate with incomplete augmented public key sets. This leads to randomness share verification failures, potential consensus liveness issues, and non-deterministic behavior across validators with different corruption patterns.

## Finding Description

The vulnerability exists in the database iteration logic used by the randomness generation subsystem. When `AugDataStore::new()` initializes during node restart or epoch transition, it loads certified augmented data from persistent storage. However, the underlying `get_all()` function silently filters out corrupted database entries that fail deserialization. [1](#0-0) 

The `get_all()` function uses `filter_map` to silently convert deserialization errors into `None`, effectively dropping corrupted entries without propagating the error. The function returns `Ok(partial_data)` even when some entries are corrupted. [2](#0-1) 

When `AugDataStore::new()` calls `db.get_all_certified_aug_data()`, the `.unwrap_or_default()` only catches connection-level database errors, not partial corruption. The function proceeds with incomplete data. [3](#0-2) 

Only the successfully loaded certified data entries have their `augment()` method called, which populates the certified augmented public keys (APKs) in the `RandConfig`. [4](#0-3) 

The `augment()` method adds certified deltas to `RandConfig`, which are stored as `OnceCell<APK>` entries in the `RandKeys.certified_apks` vector. [5](#0-4) 

Later, during randomness share verification, if a validator's certified APK is missing (because it was in a corrupted database entry), the verification fails: [6](#0-5) 

When `maybe_apk.get()` returns `None` at line 64, the verification bails with "No augmented public key for validator", causing the share to be rejected.

**Attack Scenario:**
1. Database corruption occurs naturally (bit rot, disk failure) or through attack (malicious disk writes, storage layer bugs)
2. Some `CertifiedAugData` entries become undeserializable
3. On node restart or epoch transition, `AugDataStore::new()` is called
4. Corrupted entries are silently dropped during database iteration
5. Node initializes successfully but with incomplete certified APK set  
6. When randomness shares arrive from validators whose APKs are missing, verification fails
7. Different validators with different corruption patterns accept/reject different shares
8. Consensus divergence or liveness failure occurs

**Broken Invariants:**
- **Deterministic Execution**: Different validators with different corruption patterns produce different randomness verification results
- **Consensus Safety**: Non-deterministic share acceptance can lead to consensus divergence

## Impact Explanation

This is a **HIGH severity** vulnerability per Aptos bug bounty criteria:

1. **Consensus Liveness Failure**: If enough validators' certified APKs are missing due to corruption, the threshold for randomness aggregation cannot be met, causing consensus to stall.

2. **Non-Deterministic Validator Behavior**: Different validators with different database corruption patterns will accept/reject different randomness shares, violating the deterministic execution requirement critical for consensus safety.

3. **Silent Failure Mode**: The corruption is completely silent - no error messages, no warnings, no indication to node operators that the system is operating with incomplete state.

4. **Network-Wide Impact**: If multiple validators experience corruption (realistic in coordinated hardware failures or storage bugs), the entire network's randomness generation becomes unreliable.

5. **Difficult Recovery**: Even if new `CertifiedAugData` is broadcast via reliable broadcast, there's a race condition where shares may be verified before recovery completes. Across epoch boundaries, recovery becomes impossible as old epoch data is filtered out.

While not reaching "Critical" severity (no direct fund loss), this qualifies as "Significant protocol violation" causing "Validator node slowdowns" or worse - complete randomness generation failure affecting consensus.

## Likelihood Explanation

**High Likelihood:**

1. **Natural Occurrence**: Database corruption is a well-known issue in production systems due to:
   - Hardware failures (disk errors, memory corruption)
   - Software bugs in RocksDB, serialization libraries
   - File system corruption
   - Improper shutdowns or crashes during writes

2. **Attack Vectors**: 
   - Storage layer exploits affecting RocksDB
   - Malicious actors with system access corrupting database files
   - Bugs in BCS serialization leading to inconsistent data

3. **No Detection**: The silent nature means corruption can accumulate over time before manifesting as consensus issues.

4. **Widespread Impact**: Aptos validators run on diverse hardware/infrastructure, increasing the probability that some validators will experience storage issues.

## Recommendation

Implement explicit error handling and validation in the database loading path:

**Option 1: Fail Fast During Initialization**

Modify `get_all()` to propagate deserialization errors instead of silently dropping them:

```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    iter.collect::<Result<Vec<_>, _>>()
        .map_err(|e| DbError::Other(format!("Deserialization failed during iteration: {}", e)))
}
```

**Option 2: Log and Count Corruption**

If graceful degradation is preferred, at minimum log each corruption incident and validate completeness:

```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    let mut corruption_count = 0;
    let results: Vec<_> = iter
        .filter_map(|e| match e {
            Ok((k, v)) => Some((k, v)),
            Err(e) => {
                corruption_count += 1;
                error!("[RandDB] Corrupted entry detected during iteration: {:?}", e);
                None
            }
        })
        .collect();
    
    if corruption_count > 0 {
        return Err(DbError::Corruption(format!(
            "{} corrupted entries detected in {}",
            corruption_count,
            S::COLUMN_FAMILY_NAME
        )));
    }
    Ok(results)
}
```

**Option 3: Validate Completeness in AugDataStore::new()**

Add validation to ensure all expected validators have certified APKs:

```rust
pub fn new(
    epoch: u64,
    signer: Arc<ValidatorSigner>,
    config: RandConfig,
    fast_config: Option<RandConfig>,
    db: Arc<dyn RandStorage<D>>,
) -> anyhow::Result<Self> {
    let all_certified_data = db.get_all_certified_aug_data()?;
    let (to_remove, certified_data) = Self::filter_by_epoch(epoch, all_certified_data.into_iter());
    
    // Validate we have data from all validators
    let validator_count = config.validator.len();
    if certified_data.len() < validator_count {
        error!(
            "[AugDataStore] Missing certified aug data: expected {}, got {}",
            validator_count,
            certified_data.len()
        );
    }
    
    // ... rest of initialization
}
```

**Recommended Approach**: Combine Options 1 and 3 - fail fast on corruption detection and validate completeness to ensure all validators are represented.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_schemadb::{SchemaBatch, DB};
    use tempfile::TempDir;

    #[test]
    fn test_corrupted_certified_aug_data_silent_failure() {
        // Setup: Create RandDb with test data
        let tmpdir = TempDir::new().unwrap();
        let db = RandDb::new(tmpdir.path());
        
        // Create valid CertifiedAugData for validator 0
        let valid_data = create_test_certified_aug_data(0);
        db.save_certified_aug_data(&valid_data).unwrap();
        
        // Manually corrupt database entry for validator 1 by writing invalid bytes
        let corrupted_id = AugDataId::new(1, test_author(1));
        let mut batch = SchemaBatch::new();
        // Write garbage bytes that will fail BCS deserialization
        batch.put_raw::<CertifiedAugDataSchema<TestData>>(
            &bcs::to_bytes(&corrupted_id).unwrap(),
            vec![0xFF, 0xFF, 0xFF, 0xFF],
        ).unwrap();
        db.commit(batch).unwrap();
        
        // Create AugDataStore - this should detect corruption but doesn't
        let config = create_test_config(2); // Expect 2 validators
        let store = AugDataStore::new(
            1,
            test_signer(),
            config.clone(),
            None,
            Arc::new(db),
        );
        
        // Verify that only 1 certified APK was loaded (validator 0)
        // Validator 1's corrupted entry was silently dropped
        assert_eq!(store.certified_data.len(), 1);
        assert!(store.certified_data.contains_key(&test_author(0)));
        assert!(!store.certified_data.contains_key(&test_author(1)));
        
        // Now when validator 1 sends a randomness share, verification will fail
        let share = create_test_share(1);
        let result = share.verify(&config, &test_metadata(), &test_author(1));
        
        // This fails with "No augmented public key for validator"
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("No augmented public key"));
    }
}
```

**Notes:**

1. The vulnerability affects both `get_all_aug_data()` and `get_all_certified_aug_data()` since they both use the same `get_all()` implementation.

2. While network-based recovery is theoretically possible through reliable broadcast, it creates a race condition and may fail across epoch boundaries.

3. The severity could escalate to CRITICAL if coordinated corruption affects enough validators to permanently halt consensus, requiring a hard fork to recover.

4. This is a foundational issue in the database abstraction layer that could affect other components using similar iteration patterns.

### Citations

**File:** consensus/src/rand/rand_gen/storage/db.rs (L73-82)
```rust
    fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter
            .filter_map(|e| match e {
                Ok((k, v)) => Some((k, v)),
                Err(_) => None,
            })
            .collect::<Vec<(S::Key, S::Value)>>())
    }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L57-65)
```rust
        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L67-71)
```rust
        for (_, certified_data) in &certified_data {
            certified_data
                .data()
                .augment(&config, &fast_config, certified_data.author());
        }
```

**File:** consensus/src/rand/rand_gen/types.rs (L52-81)
```rust
    fn verify(
        &self,
        rand_config: &RandConfig,
        rand_metadata: &RandMetadata,
        author: &Author,
    ) -> anyhow::Result<()> {
        let index = *rand_config
            .validator
            .address_to_validator_index()
            .get(author)
            .ok_or_else(|| anyhow!("Share::verify failed with unknown author"))?;
        let maybe_apk = &rand_config.keys.certified_apks[index];
        if let Some(apk) = maybe_apk.get() {
            WVUF::verify_share(
                &rand_config.vuf_pp,
                apk,
                bcs::to_bytes(&rand_metadata)
                    .map_err(|e| anyhow!("Serialization failed: {}", e))?
                    .as_slice(),
                &self.share,
            )?;
        } else {
            bail!(
                "[RandShare] No augmented public key for validator id {}, {}",
                index,
                author
            );
        }
        Ok(())
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L178-194)
```rust
    fn augment(
        &self,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        author: &Author,
    ) {
        let AugmentedData { delta, fast_delta } = self;
        rand_config
            .add_certified_delta(author, delta.clone())
            .expect("Add delta should succeed");

        if let (Some(config), Some(fast_delta)) = (fast_rand_config, fast_delta) {
            config
                .add_certified_delta(author, fast_delta.clone())
                .expect("Add delta for fast path should succeed");
        }
    }
```

**File:** types/src/randomness.rs (L128-135)
```rust
    pub fn add_certified_apk(&self, index: usize, apk: APK) -> anyhow::Result<()> {
        assert!(index < self.certified_apks.len());
        if self.certified_apks[index].get().is_some() {
            return Ok(());
        }
        self.certified_apks[index].set(apk).unwrap();
        Ok(())
    }
```
