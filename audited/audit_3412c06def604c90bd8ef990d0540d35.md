# Audit Report

## Title
EventByKeySchema and EventByVersionSchema Index Desynchronization via Duplicate Sequence Numbers

## Summary
The event storage system maintains two index schemas (EventByKeySchema and EventByVersionSchema) that can become desynchronized if the same event key and sequence number combination is written to the database across different transaction versions. This violates the state consistency invariant and can lead to different query results depending on which index is used.

## Finding Description

The event storage system uses two separate indexing schemas to enable efficient event lookup:

1. **EventByKeySchema**: Maps `(EventKey, SequenceNumber)` → `(Version, Index)`
2. **EventByVersionSchema**: Maps `(EventKey, Version, SequenceNumber)` → `Index` [1](#0-0) [2](#0-1) 

When events are written to the database, both schemas are populated atomically in the same batch: [3](#0-2) [4](#0-3) 

However, **there is no validation to prevent writing the same `(EventKey, SequenceNumber)` combination in different transaction versions**. If this occurs:

- **EventByKeySchema** will only retain the **last write** because it uses `(EventKey, SequenceNumber)` as the key, causing overwrites
- **EventByVersionSchema** will retain **all writes** because it includes `Version` in the key, preventing overwrites

This creates a desynchronization where:
- Querying via `lookup_events_by_key()` (uses EventByKeySchema) returns the most recent version's index
- Querying via `lookup_event_before_or_at_version()` (uses EventByVersionSchema) returns the index for a specific version

The codebase shows evidence that duplicate event detection is a known concern: [5](#0-4) 

**Root Cause**: The storage layer lacks defensive validation against duplicate sequence numbers, relying entirely on the Move VM's event emission logic to maintain uniqueness. This creates a gap in defense-in-depth.

## Impact Explanation

**Severity: Medium** (State inconsistencies requiring intervention)

While this does not directly enable unprivileged attackers to exploit the system, it represents a critical failure mode during:

1. **Database restore operations**: Restoring from backup at version V₁, then continuing to process transactions that emit events with sequence numbers that existed at versions > V₁
2. **State synchronization edge cases**: During catch-up, if events are indexed multiple times
3. **Move VM bugs**: If a bug allows duplicate sequence numbers to be emitted

The consequences include:
- **State Consistency Violation**: Different nodes may return different results for the same query depending on code path
- **Consensus Implications**: If different validator implementations use different query methods, they may compute different state roots
- **Data Integrity Issues**: Historical event queries become unreliable

This does not meet Critical severity because it requires specific preconditions (backup/restore, VM bugs) rather than being directly exploitable by attackers.

## Likelihood Explanation

**Likelihood: Low to Medium**

In normal operation with a bug-free Move VM, sequence numbers are monotonically increasing per event key, preventing this scenario: [6](#0-5) 

However, likelihood increases during:
- Database maintenance operations (backup/restore)
- Catastrophic recovery scenarios
- Potential Move VM implementation bugs
- State synchronization edge cases

The defensive code in `analyze_validators.rs` suggests this has been observed or anticipated in practice.

## Recommendation

Implement defensive validation at the storage layer to detect and prevent duplicate sequence numbers:

1. **Add pre-write validation in `put_events()`**:
   - Before writing to EventByKeySchema, check if `(EventKey, SequenceNumber)` already exists
   - If it exists, verify the version and index match the new write
   - If they differ, log an error and abort the transaction

2. **Add invariant checking in `save_transactions_impl()`**:
   - During restore operations, validate that sequence numbers are monotonically increasing
   - Reject any batch containing duplicate sequence numbers across versions

3. **Implement reconciliation logic**:
   - Periodically scan for desynchronization between schemas
   - Add a validation mode that checks EventByKeySchema entries match EventByVersionSchema

Example validation code to add to `put_events()`:

```rust
// Before writing to EventByKeySchema
if let ContractEvent::V1(v1) = event {
    if !skip_index {
        // Check for existing entry
        if let Some((existing_ver, existing_idx)) = 
            batch.get::<EventByKeySchema>(&(*v1.key(), v1.sequence_number()))? {
            
            // Verify consistency
            ensure!(
                existing_ver == version && existing_idx == idx as u64,
                "Duplicate sequence number detected: key={:?}, seq={}, existing=({}, {}), new=({}, {})",
                v1.key(), v1.sequence_number(), existing_ver, existing_idx, version, idx
            );
        }
        // Proceed with writes...
    }
}
```

## Proof of Concept

The following test demonstrates the desynchronization scenario:

```rust
#[test]
fn test_event_schema_desynchronization() {
    use aptos_types::contract_event::{ContractEvent, ContractEventV1};
    use aptos_types::event::EventKey;
    
    let db = create_test_db();
    let event_db = db.event_db();
    
    // Create two events with same (key, seq_num) but different versions/indices
    let event_key = EventKey::new(0, AccountAddress::random());
    let seq_num = 100u64;
    
    // Event 1: Version 50, Index 3
    let event1 = ContractEvent::V1(ContractEventV1::new(
        event_key,
        seq_num,
        TypeTag::Bool,
        bcs::to_bytes(&true).unwrap(),
    ));
    
    let mut batch1 = SchemaBatch::new();
    event_db.put_events(50, &[event1.clone()], false, &mut batch1).unwrap();
    db.write_schemas(batch1).unwrap();
    
    // Event 2: Version 100, Index 5 (same key, same seq_num)
    let event2 = ContractEvent::V1(ContractEventV1::new(
        event_key,
        seq_num,
        TypeTag::Bool,
        bcs::to_bytes(&false).unwrap(),
    ));
    
    let mut batch2 = SchemaBatch::new();
    // This writes to index 0, but we'll verify the desynchronization
    event_db.put_events(100, &[event2.clone()], false, &mut batch2).unwrap();
    db.write_schemas(batch2).unwrap();
    
    // Query via EventByKeySchema - should return version 100 (last write)
    let (ver_from_key_schema, _) = db
        .get::<EventByKeySchema>(&(event_key, seq_num))
        .unwrap()
        .unwrap();
    
    // Query via EventByVersionSchema - should have both entries
    let idx_from_version_schema_v50 = db
        .get::<EventByVersionSchema>(&(event_key, 50, seq_num))
        .unwrap();
    
    let idx_from_version_schema_v100 = db
        .get::<EventByVersionSchema>(&(event_key, 100, seq_num))
        .unwrap();
    
    // Desynchronization detected: EventByKeySchema only has version 100,
    // but EventByVersionSchema has both versions
    assert_eq!(ver_from_key_schema, 100);
    assert!(idx_from_version_schema_v50.is_some());
    assert!(idx_from_version_schema_v100.is_some());
    
    // The indices will differ, demonstrating the desynchronization
}
```

**Notes:**
- This PoC requires direct database access and cannot be triggered by unprivileged attackers in normal operation
- It demonstrates the technical desynchronization but not a realistic attack vector
- The vulnerability exists as a defensive gap rather than an actively exploitable bug

### Citations

**File:** storage/indexer_schemas/src/schema/event_by_key/mod.rs (L23-29)
```rust
define_pub_schema!(EventByKeySchema, Key, Value, EVENT_BY_KEY_CF_NAME);

type SeqNum = u64;
type Key = (EventKey, SeqNum);

type Index = u64;
type Value = (Version, Index);
```

**File:** storage/indexer_schemas/src/schema/event_by_version/mod.rs (L23-29)
```rust
define_pub_schema!(EventByVersionSchema, Key, Value, EVENT_BY_VERSION_CF_NAME);

type SeqNum = u64;
type Key = (EventKey, Version, SeqNum);

type Index = u64;
type Value = Index;
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L157-167)
```rust
                if let ContractEvent::V1(v1) = event {
                    if !skip_index {
                        batch.put::<EventByKeySchema>(
                            &(*v1.key(), v1.sequence_number()),
                            &(version, idx as u64),
                        )?;
                        batch.put::<EventByVersionSchema>(
                            &(*v1.key(), version, v1.sequence_number()),
                            &(idx as u64),
                        )?;
                    }
```

**File:** storage/indexer/src/db_indexer.rs (L433-446)
```rust
                events.iter().enumerate().try_for_each(|(idx, event)| {
                    if let ContractEvent::V1(v1) = event {
                        batch
                            .put::<EventByKeySchema>(
                                &(*v1.key(), v1.sequence_number()),
                                &(version, idx as u64),
                            )
                            .expect("Failed to put events by key to a batch");
                        batch
                            .put::<EventByVersionSchema>(
                                &(*v1.key(), version, v1.sequence_number()),
                                &(idx as u64),
                            )
                            .expect("Failed to put events by version to a batch");
```

**File:** crates/aptos/src/node/analyze/analyze_validators.rs (L328-333)
```rust
                if cursor <= raw_event.event.v1()?.sequence_number() {
                    println!(
                        "Duplicate event found for {} : {:?}",
                        cursor,
                        raw_event.event.v1()?.sequence_number()
                    );
```

**File:** aptos-move/framework/aptos-framework/sources/event.move (L54-60)
```text
    public fun emit_event<T: drop + store>(handle_ref: &mut EventHandle<T>, msg: T) {
        write_to_event_store<T>(bcs::to_bytes(&handle_ref.guid), handle_ref.counter, msg);
        spec {
            assume handle_ref.counter + 1 <= MAX_U64;
        };
        handle_ref.counter += 1;
    }
```
