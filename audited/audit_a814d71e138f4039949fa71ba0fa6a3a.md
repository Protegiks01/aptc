# Audit Report

## Title
Unencrypted Redis Connections in Indexer GRPC Enable Man-in-the-Middle Data Corruption Attacks

## Summary
The indexer-grpc system's `RedisUrl` type explicitly restricts Redis connections to the unencrypted `redis://` scheme and rejects TLS-encrypted `rediss://` connections. This forces all transaction data cached in Redis to be transmitted without encryption, allowing network attackers to intercept and modify transaction data being served to indexer clients.

## Finding Description

The `RedisUrl` type enforces an unencrypted connection policy: [1](#0-0) 

The validation explicitly rejects any URL scheme other than `redis://`, including the standard TLS-encrypted scheme `rediss://`: [2](#0-1) 

This `RedisUrl` type is used throughout the indexer-grpc system for all Redis connections:

**In the data service:** [3](#0-2) [4](#0-3) 

**In the cache worker:** [5](#0-4) 

**Attack Path:**

1. Attacker positions themselves on the network path between indexer components (cache worker, data service) and Redis (e.g., compromised network device, cloud networking misconfiguration, or malicious ISP)

2. Attacker intercepts unencrypted Redis protocol traffic containing transaction data being written to cache via `update_cache_transactions`: [6](#0-5) 

3. Transaction objects contain highly sensitive data including sender addresses, signatures, payloads, events, and complete state changes: [7](#0-6) 

4. Attacker modifies Redis `SET` commands in transit to inject corrupted transaction data or alter existing transactions

5. Corrupted data is cached and subsequently served to indexer clients when they request transactions: [8](#0-7) 

6. Indexer clients (dApps, wallets, block explorers) consume corrupted data, leading to incorrect application state, wrong balance displays, or incorrect transaction history

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program for the following reasons:

1. **API Crashes/Failures**: Malformed transaction data could cause indexer clients to crash when attempting to parse corrupted protobuf messages

2. **Significant Protocol Violations**: The indexer API is a critical infrastructure component that dApps rely on for chain state. Serving corrupted transactions violates the integrity guarantees expected from blockchain data services

3. **Data Corruption**: Unlike a simple denial-of-service, this enables persistent corruption of cached data that affects all downstream consumers

4. **Broad Impact**: Affects all users of the indexer-grpc infrastructure, including major dApps, wallets, and explorers built on Aptos

While this doesn't directly compromise consensus or validator operations, it breaks the **State Consistency** invariant by serving unverifiable, potentially malicious transaction data to clients who trust the indexer infrastructure.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Network access between indexer components and Redis (achievable via cloud networking misconfiguration, compromised network devices, or malicious hosting provider)
- Basic understanding of Redis protocol
- Tools for packet interception and modification (e.g., mitmproxy, Wireshark)

**Feasibility:**
- MITM attacks are well-established and practical in cloud environments
- No authentication bypass or complex cryptographic attacks required
- The attack is passive (interception) with optional active component (modification)
- Production deployments often have Redis on separate hosts/regions, creating network attack surface

**Real-World Scenarios:**
- Misconfigured cloud VPC peering
- Compromised load balancer or network appliance
- Malicious cloud provider employee
- Shared hosting environment with network sniffing capabilities

## Recommendation

**Immediate Fix**: Modify `RedisUrl` to support TLS-encrypted connections using the `rediss://` scheme:

```rust
// ecosystem/indexer-grpc/indexer-grpc-utils/src/types.rs

/// A URL that allows redis:// and rediss:// (TLS) schemes.
#[derive(Clone, Debug, Eq, PartialEq, Serialize)]
pub struct RedisUrl(pub Url);

impl FromStr for RedisUrl {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let url = Url::parse(s)?;
        if url.scheme() != "redis" && url.scheme() != "rediss" {
            return Err(anyhow::anyhow!(
                "Invalid scheme: {}. Expected 'redis' or 'rediss'", 
                url.scheme()
            ));
        }
        Ok(RedisUrl(url))
    }
}

impl<'de> Deserialize<'de> for RedisUrl {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let url = Url::deserialize(deserializer)?;
        if url.scheme() != "redis" && url.scheme() != "rediss" {
            return Err(serde::de::Error::custom(format!(
                "Invalid scheme: {}. Expected 'redis' or 'rediss'",
                url.scheme()
            )));
        }
        Ok(Self(url))
    }
}
```

**Additional Recommendations:**
1. **Enforce TLS by default**: Make `rediss://` the default and deprecate unencrypted connections
2. **Certificate validation**: Ensure Redis TLS connections validate server certificates
3. **Configuration documentation**: Update deployment guides to require TLS configuration
4. **Network isolation**: As defense-in-depth, deploy Redis on isolated networks with strict firewall rules

## Proof of Concept

**Setup:**
```bash
# Terminal 1: Start Redis
redis-server

# Terminal 2: Start mitmproxy to intercept traffic
mitmproxy -p 6380 --mode reverse:redis://localhost:6379
```

**Configuration (malicious):**
```yaml
# Point indexer to proxy instead of direct Redis
redis_read_replica_address: "redis://localhost:6380"
```

**Attack Script:**
```python
# mitmproxy addon to modify Redis SET commands
from mitmproxy import ctx

class RedisCorruptor:
    def tcp_message(self, flow):
        message = flow.messages[-1]
        if b'SET' in message.content:
            # Intercept SET command for transaction data
            if b'version' in message.content.lower():
                ctx.log.info(f"Intercepted transaction: {message.content[:100]}")
                # Modify transaction data (e.g., change version number)
                message.content = message.content.replace(b'version":123', b'version":999')
                ctx.log.warn("Modified transaction version!")

addons = [RedisCorruptor()]
```

**Verification:**
```bash
# Run cache worker with the proxy configuration
# Observe corrupted transactions being cached and served

# Query the data service - it will serve modified transactions
grpcurl -d '{"starting_version": 100}' \
  -plaintext localhost:50052 \
  aptos.indexer.v1.RawData/GetTransactions
```

**Expected Result**: Transaction data retrieved from the indexer will show the modified version numbers, demonstrating successful data corruption via MITM attack.

## Notes

This vulnerability affects the **indexer-grpc infrastructure** specifically, not the core validator/consensus layer. However, it poses significant risk to the Aptos ecosystem because:

1. Most dApps rely on indexer APIs rather than running full nodes
2. Corrupted indexer data can lead to incorrect application behavior, wrong balance displays, and failed transactions
3. The attack is persistent - once corrupted data is cached, it continues to be served until cache expiration
4. Users have no way to verify that indexer-provided data hasn't been tampered with in transit

The fix is straightforward and should be implemented immediately to protect production deployments. Until fixed, operators should ensure Redis connections use network-level encryption (VPN, SSH tunneling) or deploy Redis on the same host as indexer components.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/types.rs (L12-25)
```rust
/// A URL that only allows the redis:// scheme.
#[derive(Clone, Debug, Eq, PartialEq, Serialize)]
pub struct RedisUrl(pub Url);

impl FromStr for RedisUrl {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let url = Url::parse(s)?;
        if url.scheme() != "redis" {
            return Err(anyhow::anyhow!("Invalid scheme: {}", url.scheme()));
        }
        Ok(RedisUrl(url))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/types.rs (L28-42)
```rust
impl<'de> Deserialize<'de> for RedisUrl {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let url = Url::deserialize(deserializer)?;
        if url.scheme() != "redis" {
            return Err(serde::de::Error::custom(format!(
                "Invalid scheme: {}",
                url.scheme()
            )));
        }
        Ok(Self(url))
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L166-168)
```rust
        let redis_conn = redis::Client::open(self.redis_read_replica_address.0.clone())?
            .get_tokio_connection_manager()
            .await?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L110-114)
```rust
            redis_client: Arc::new(
                redis::Client::open(redis_address.0.clone()).with_context(|| {
                    format!("Failed to create redis client for {}", redis_address)
                })?,
            ),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L84-90)
```rust
        let redis_client = redis::Client::open(redis_main_instance_address.0.clone())
            .with_context(|| {
                format!(
                    "[Indexer Cache] Failed to create redis client for {}",
                    redis_main_instance_address
                )
            })?;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L222-249)
```rust
    pub async fn batch_get_encoded_proto_data_with_length(
        &mut self,
        start_version: u64,
        transaction_count: u64,
    ) -> anyhow::Result<(Vec<Transaction>, f64, f64)> {
        let start_time = std::time::Instant::now();
        let versions = (start_version..start_version + transaction_count)
            .map(|e| CacheEntry::build_key(e, self.storage_format).to_string())
            .collect::<Vec<String>>();
        let encoded_transactions: Vec<Vec<u8>> = self
            .conn
            .mget(versions)
            .await
            .context("Failed to mget from Redis")?;
        let io_duration = start_time.elapsed().as_secs_f64();
        let start_time = std::time::Instant::now();
        let mut transactions = vec![];
        for encoded_transaction in encoded_transactions {
            let cache_entry: CacheEntry = CacheEntry::new(encoded_transaction, self.storage_format);
            let transaction = cache_entry.into_transaction();
            transactions.push(transaction);
        }
        ensure!(
            transactions.len() == transaction_count as usize,
            "Failed to get all transactions from cache."
        );
        let decoding_duration = start_time.elapsed().as_secs_f64();
        Ok((transactions, io_duration, decoding_duration))
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L252-278)
```rust
    pub async fn update_cache_transactions(
        &mut self,
        transactions: Vec<Transaction>,
    ) -> anyhow::Result<()> {
        let start_version = transactions.first().unwrap().version;
        let end_version = transactions.last().unwrap().version;
        let num_transactions = transactions.len();
        let start_txn_timestamp = transactions.first().unwrap().timestamp;
        let end_txn_timestamp = transactions.last().unwrap().timestamp;
        let mut size_in_bytes = 0;
        let mut redis_pipeline = redis::pipe();
        let start_time = std::time::Instant::now();
        for transaction in transactions {
            let version = transaction.version;
            let cache_key = CacheEntry::build_key(version, self.storage_format).to_string();
            let timestamp_in_seconds = transaction.timestamp.map_or(0, |t| t.seconds as u64);
            let cache_entry: CacheEntry =
                CacheEntry::from_transaction(transaction, self.storage_format);
            let bytes = cache_entry.into_inner();
            size_in_bytes += bytes.len();
            redis_pipeline
                .cmd("SET")
                .arg(cache_key)
                .arg(bytes)
                .arg("EX")
                .arg(get_ttl_in_seconds(timestamp_in_seconds))
                .ignore();
```

**File:** protos/proto/aptos/transaction/v1/transaction.proto (L40-72)
```text
message Transaction {
  aptos.util.timestamp.Timestamp timestamp = 1;
  uint64 version = 2 [jstype = JS_STRING];
  TransactionInfo info = 3;
  uint64 epoch = 4 [jstype = JS_STRING];
  uint64 block_height = 5 [jstype = JS_STRING];

  enum TransactionType {
    TRANSACTION_TYPE_UNSPECIFIED = 0;
    TRANSACTION_TYPE_GENESIS = 1;
    TRANSACTION_TYPE_BLOCK_METADATA = 2;
    TRANSACTION_TYPE_STATE_CHECKPOINT = 3;
    TRANSACTION_TYPE_USER = 4;
    // values 5-19 skipped for no reason
    TRANSACTION_TYPE_VALIDATOR = 20;
    TRANSACTION_TYPE_BLOCK_EPILOGUE = 21;
  }

  TransactionType type = 6;

  oneof txn_data {
    BlockMetadataTransaction block_metadata = 7;
    GenesisTransaction genesis = 8;
    StateCheckpointTransaction state_checkpoint = 9;
    UserTransaction user = 10;
    // value 11-19 skipped for no reason
    ValidatorTransaction validator = 21;
    // value 22 is used up below (all Transaction fields have to have different index), so going to 23
    BlockEpilogueTransaction block_epilogue = 23;
  }

  TransactionSizeInfo size_info = 22;
}
```
