# Audit Report

## Title
Subscription Flood Attack Enables Resource Exhaustion on Storage Service Nodes

## Summary
The storage service's subscription mechanism lacks a global limit on the number of concurrent subscription streams, allowing an attacker to create thousands of long-lived subscription requests across multiple peer connections. This exhausts server resources including memory (for held channels and request objects) and CPU (for periodic subscription processing), causing validator node slowdowns and potential service degradation.

## Finding Description

The storage service allows peers to create subscription requests for receiving continuous data updates. The vulnerability exists in the subscription management architecture where three separate limits exist but fail to prevent resource exhaustion when combined: [1](#0-0) 

The subscription storage uses an unbounded `DashMap` keyed by `PeerNetworkId`, with no global limit on entries: [2](#0-1) 

Each subscription stream can hold up to `max_num_active_subscriptions` (default: 30) pending requests: [3](#0-2) [4](#0-3) 

The only global constraint is the inbound connection limit for unknown peers (default: 100): [5](#0-4) [6](#0-5) 

**Attack Vector:**

An attacker can bypass authentication by generating new x25519 key pairs and deriving valid peer IDs. In `MaybeMutual` authentication mode (used for non-validator networks), unknown peers are accepted as long as their peer ID is correctly derived from their public key: [7](#0-6) 

The attacker executes the following steps:
1. Generates 100 different x25519 key pairs with corresponding peer IDs
2. Establishes 100 inbound connections (the maximum for unknown peers)
3. From each connection, creates a subscription stream with 30 pending subscription requests
4. Total: **3,000 active subscription requests**

Each `SubscriptionRequest` holds a `ResponseSender` wrapping a oneshot channel that remains open until responded to: [8](#0-7) [9](#0-8) 

The subscription handler periodically processes all active subscriptions, consuming CPU cycles: [10](#0-9) 

Even though subscriptions expire after 30 seconds, the attacker can continuously recreate them to maintain sustained resource exhaustion.

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria for the following reasons:

1. **Validator Node Slowdowns**: The attack causes measurable performance degradation through:
   - 3,000 held oneshot channels consuming memory
   - 3,000 `SubscriptionRequest` objects plus associated `StorageServiceRequest` data
   - Periodic CPU-intensive iteration through all subscriptions in `handle_active_subscriptions`
   - 100 network connections maintained simultaneously

2. **Storage Service Degradation**: The storage service is critical for state synchronization. Resource exhaustion here affects:
   - Legitimate full nodes attempting to sync state
   - New validators joining the network
   - Nodes recovering from downtime

3. **Potential Cascade Effects**: If the storage service becomes sufficiently degraded:
   - State sync delays could impact consensus participation
   - Full nodes may fall behind in block processing
   - Network-wide synchronization could be disrupted

The attack does not directly steal funds or break consensus safety, but it significantly impacts network availability and validator performance, meeting the "Validator node slowdowns" criterion for High severity.

## Likelihood Explanation

**Likelihood: High**

The attack is trivially executable with low barriers to entry:

1. **No Authentication Barrier**: Generating x25519 key pairs and deriving peer IDs requires only standard cryptographic libraries
2. **Low Resource Cost for Attacker**: Opening 100 connections and sending subscription requests is computationally cheap
3. **Sustainable Attack**: Subscriptions can be continuously recreated as they expire
4. **No Rate Limiting**: The request moderator only blocks peers sending invalid requests, not valid subscription requests
5. **Network Accessibility**: Public-facing storage service nodes are reachable by any internet-connected attacker

## Recommendation

Implement a global limit on total active subscription streams across all peers:

```rust
// In config/src/config/state_sync_config.rs
pub struct StorageServiceConfig {
    // ... existing fields ...
    
    /// Maximum total number of active subscription streams across all peers
    pub max_total_subscription_streams: usize,
}

impl Default for StorageServiceConfig {
    fn default() -> Self {
        Self {
            // ... existing defaults ...
            max_total_subscription_streams: 200, // Reasonable global limit
        }
    }
}

// In state-sync/storage-service/server/src/handler.rs
pub fn handle_subscription_request(
    &self,
    storage_service_config: StorageServiceConfig,
    peer_network_id: PeerNetworkId,
    request: StorageServiceRequest,
    response_sender: ResponseSender,
) {
    // Check global subscription stream limit before creating new stream
    if self.subscriptions.len() >= storage_service_config.max_total_subscription_streams {
        let error = Error::InvalidRequest(format!(
            "Global subscription stream limit reached: {}. Cannot create new subscription.",
            storage_service_config.max_total_subscription_streams
        ));
        self.handle_subscription_request_failure(
            peer_network_id,
            request,
            error,
            SubscriptionRequest::new(request.clone(), response_sender, self.time_service.clone()),
        );
        return;
    }
    
    // ... rest of existing logic ...
}
```

Additionally, consider implementing per-IP rate limiting for unknown peers to prevent a single attacker from consuming all available slots.

## Proof of Concept

```rust
// Integration test demonstrating subscription flood
#[tokio::test]
async fn test_subscription_flood_attack() {
    use aptos_config::config::NetworkConfig;
    use aptos_crypto::x25519;
    use aptos_types::PeerId;
    use std::collections::HashMap;
    
    // Setup storage service with default config
    let (storage_service, network_handles) = setup_storage_service_with_defaults().await;
    
    // Attacker generates 100 key pairs
    let num_attacking_peers = 100;
    let subscriptions_per_peer = 30;
    
    let mut attacking_peers = Vec::new();
    for _ in 0..num_attacking_peers {
        // Generate new key pair
        let private_key = x25519::PrivateKey::generate(&mut rand::rngs::OsRng);
        let public_key = private_key.public_key();
        
        // Derive peer ID from public key
        let peer_id = PeerId::from_identity_public_key(public_key);
        
        attacking_peers.push((peer_id, private_key));
    }
    
    // Each attacker peer creates a subscription stream with 30 requests
    let mut total_subscriptions = 0;
    for (peer_id, _private_key) in attacking_peers {
        let peer_network_id = PeerNetworkId::new(NetworkId::Public, peer_id);
        
        // Create subscription stream with max pending requests
        for stream_index in 0..subscriptions_per_peer {
            let subscription_request = create_subscription_request(stream_index);
            
            // Send subscription request (would succeed up to per-stream limit)
            send_storage_request(
                &network_handles,
                peer_network_id,
                subscription_request,
            ).await;
            
            total_subscriptions += 1;
        }
    }
    
    // Verify: 3,000 active subscriptions created
    assert_eq!(total_subscriptions, 3000);
    
    // Measure resource consumption
    let memory_usage = measure_memory_usage(&storage_service);
    let cpu_usage = measure_cpu_usage_during_subscription_processing(&storage_service).await;
    
    // Demonstrate resource exhaustion
    assert!(memory_usage > NORMAL_MEMORY_THRESHOLD);
    assert!(cpu_usage > NORMAL_CPU_THRESHOLD);
    
    // Verify legitimate requests experience degradation
    let legitimate_request_latency = send_legitimate_request(&network_handles).await;
    assert!(legitimate_request_latency > ACCEPTABLE_LATENCY_THRESHOLD);
}
```

## Notes

The vulnerability exists because the subscription system was designed with per-stream limits but lacks holistic resource management. The assumption that connection limits would prevent abuse fails because the per-connection limit (100) is high enough when combined with the per-stream limit (30) to enable resource exhaustion. The fix requires adding a global limit that constrains total subscription resource consumption regardless of how it's distributed across peers.

### Citations

**File:** state-sync/storage-service/server/src/handler.rs (L55-55)
```rust
    subscriptions: Arc<DashMap<PeerNetworkId, SubscriptionStreamRequests>>,
```

**File:** state-sync/storage-service/server/src/lib.rs (L109-109)
```rust
        let subscriptions = Arc::new(DashMap::new());
```

**File:** config/src/config/state_sync_config.rs (L206-206)
```rust
            max_num_active_subscriptions: 30,
```

**File:** state-sync/storage-service/server/src/subscription.rs (L46-51)
```rust
/// A single subscription request that is part of a stream
pub struct SubscriptionRequest {
    request: StorageServiceRequest,  // The original request
    response_sender: ResponseSender, // The sender along which to send the response
    request_start_time: Instant,     // The time the request started (i.e., when it was received)
}
```

**File:** state-sync/storage-service/server/src/subscription.rs (L370-381)
```rust
        // Verify that the number of active subscriptions respects the maximum
        let max_num_active_subscriptions =
            storage_service_config.max_num_active_subscriptions as usize;
        if self.pending_subscription_requests.len() >= max_num_active_subscriptions {
            return Err((
                Error::InvalidRequest(format!(
                    "The maximum number of active subscriptions has been reached! Max: {:?}, found: {:?}",
                    max_num_active_subscriptions, self.pending_subscription_requests.len()
                )),
                subscription_request,
            ));
        }
```

**File:** state-sync/storage-service/server/src/subscription.rs (L588-639)
```rust
pub(crate) async fn handle_active_subscriptions<T: StorageReaderInterface>(
    runtime: Handle,
    cached_storage_server_summary: Arc<ArcSwap<StorageServerSummary>>,
    config: StorageServiceConfig,
    optimistic_fetches: Arc<DashMap<PeerNetworkId, OptimisticFetchRequest>>,
    lru_response_cache: Cache<StorageServiceRequest, StorageServiceResponse>,
    request_moderator: Arc<RequestModerator>,
    storage: T,
    subscriptions: Arc<DashMap<PeerNetworkId, SubscriptionStreamRequests>>,
    time_service: TimeService,
) -> Result<(), Error> {
    // Continuously handle the subscriptions until we identify that
    // there are no more subscriptions ready to be served now.
    loop {
        // Update the number of active subscriptions
        update_active_subscription_metrics(subscriptions.clone());

        // Identify the peers with ready subscriptions
        let peers_with_ready_subscriptions = get_peers_with_ready_subscriptions(
            runtime.clone(),
            config,
            cached_storage_server_summary.clone(),
            optimistic_fetches.clone(),
            lru_response_cache.clone(),
            request_moderator.clone(),
            storage.clone(),
            subscriptions.clone(),
            time_service.clone(),
        )
        .await?;

        // If there are no peers with ready subscriptions, we're finished
        if peers_with_ready_subscriptions.is_empty() {
            return Ok(());
        }

        // Remove and handle the ready subscriptions
        handle_ready_subscriptions(
            runtime.clone(),
            cached_storage_server_summary.clone(),
            config,
            optimistic_fetches.clone(),
            lru_response_cache.clone(),
            request_moderator.clone(),
            storage.clone(),
            subscriptions.clone(),
            time_service.clone(),
            peers_with_ready_subscriptions,
        )
        .await;
    }
}
```

**File:** config/src/config/network_config.rs (L44-44)
```rust
pub const MAX_INBOUND_CONNECTIONS: usize = 100;
```

**File:** network/framework/src/peer_manager/mod.rs (L370-388)
```rust
                // We control outbound connections with Connectivity manager before we even send them
                // and we must allow connections that already exist to pass through tie breaking.
                if !self
                    .active_peers
                    .contains_key(&conn.metadata.remote_peer_id)
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .connection_metadata_with_address(&conn.metadata),
                        "{} Connection rejected due to connection limit: {}",
                        self.network_context,
                        conn.metadata
                    );
                    counters::connections_rejected(&self.network_context, conn.metadata.origin)
                        .inc();
                    self.disconnect(conn);
                    return;
                }
```

**File:** network/framework/src/noise/handshake.rs (L384-426)
```rust
            HandshakeAuthMode::MaybeMutual(peers_and_metadata) => {
                let trusted_peers = peers_and_metadata.get_trusted_peers(&network_id)?;
                let trusted_peer = trusted_peers.get(&remote_peer_id).cloned();
                match trusted_peer {
                    Some(peer) => {
                        Self::authenticate_inbound(remote_peer_short, &peer, &remote_public_key)
                    },
                    None => {
                        // The peer is not in the trusted peer set. Verify that the Peer ID is
                        // constructed correctly from the public key.
                        let derived_remote_peer_id =
                            aptos_types::account_address::from_identity_public_key(
                                remote_public_key,
                            );
                        if derived_remote_peer_id != remote_peer_id {
                            // The peer ID is not constructed correctly from the public key
                            Err(NoiseHandshakeError::ClientPeerIdMismatch(
                                remote_peer_short,
                                remote_peer_id,
                                derived_remote_peer_id,
                            ))
                        } else {
                            // Try to infer the role from the network context
                            if self.network_context.role().is_validator() {
                                if network_id.is_vfn_network() {
                                    // Inbound connections to validators on the VFN network must be VFNs
                                    Ok(PeerRole::ValidatorFullNode)
                                } else {
                                    // Otherwise, they're unknown. Validators will connect through
                                    // authenticated channels (on the validator network) so shouldn't hit
                                    // this, and PFNs will connect on public networks (which aren't common).
                                    Ok(PeerRole::Unknown)
                                }
                            } else {
                                // We're a VFN or PFN. VFNs get no inbound connections on the vfn network
                                // (so the peer won't be a validator). Thus, we're on the public network
                                // so mark the peer as unknown.
                                Ok(PeerRole::Unknown)
                            }
                        }
                    },
                }
            },
```

**File:** state-sync/storage-service/server/src/network.rs (L95-99)
```rust
/// A channel for fulfilling a pending StorageService RPC request.
/// Provides a more strongly typed interface around the raw RPC response channel.
pub struct ResponseSender {
    response_tx: oneshot::Sender<Result<Bytes, RpcError>>,
}
```
