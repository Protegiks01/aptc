# Audit Report

## Title
Binary Search Resource Exhaustion via Malicious max_response_bytes Parameter

## Summary
The storage service's legacy response construction functions (`get_transactions_with_proof_by_size_legacy()`, `get_epoch_ending_ledger_infos_by_size_legacy()`, and similar) accept client-controlled `max_response_bytes` values without enforcing a minimum threshold. An attacker can send requests with absurdly small values (e.g., 1 byte), forcing the server to perform O(log n) database reads and serialization operations instead of the optimal single operation, leading to resource exhaustion.

## Finding Description
The storage service processes requests from remote peers for blockchain data (transactions, epoch endings, state values, etc.). When constructing responses, it uses a binary search approach to fit data within the `max_response_bytes` limit by repeatedly halving the chunk size until the serialized response fits. [1](#0-0) 

The server takes the minimum of the client's requested `max_response_bytes` and its own configured limit, but critically, there is **no lower bound validation**. A malicious peer can send a request with `max_response_bytes = 1` (or any arbitrarily small value), which will be accepted. [2](#0-1) 

The binary search loop in `get_transactions_with_proof_by_size_legacy()` then repeatedly:
1. Fetches `num_transactions_to_fetch` transactions from the database
2. Serializes the entire response
3. Checks if the serialized size exceeds `max_response_size` (which is 1 byte)
4. Halves `num_transactions_to_fetch` and repeats

This continues for log₂(initial_chunk_size) iterations. For a typical initial chunk size of 3000, this means ~11-12 database read operations and serialization passes instead of just 1. Similar vulnerable code exists at: [3](#0-2) [4](#0-3) 

The `GetTransactionDataWithProofRequest` structure allows clients to specify this value: [5](#0-4) 

The request moderator validates whether the request can be serviced but does NOT validate the reasonableness of `max_response_bytes`: [6](#0-5) 

**Attack Path:**
1. Attacker establishes P2P connection to a node's storage service
2. Sends `GetTransactionDataWithProofRequest` with `max_response_bytes = 1`
3. Server processes request, using `min(1, 40MB) = 1 byte` as the limit
4. Binary search begins with `num_transactions_to_fetch = 3000`
5. Server fetches 3000 transactions from database and serializes them (~several MB)
6. Size check fails (response >> 1 byte), chunk size halved to 1500
7. Server fetches 1500 transactions and serializes (~still too large)
8. Process repeats for ~11 iterations until chunk_size = 1
9. Server finally returns 1 transaction (even though it still exceeds 1 byte)

Each malicious request causes ~11x the database I/O and CPU work compared to a normal request.

**Invariant Violation:**
This breaks **Invariant #9: Resource Limits** - "All operations must respect gas, storage, and computational limits." The server performs excessive unnecessary work due to client-controlled input.

## Impact Explanation
**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This vulnerability enables resource exhaustion attacks against any node running the storage service:

- **Resource Amplification**: Each malicious request consumes ~10-12x the intended resources (database reads, CPU for serialization, memory)
- **Concurrent Attack**: Multiple malicious peers sending such requests simultaneously can significantly degrade node performance
- **Bounded but Real Impact**: While the impact is bounded by log₂(chunk_size) ≈ 10-12 iterations, this is sufficient to cause meaningful resource exhaustion when amplified across many concurrent requests
- **No Easy Detection**: The server cannot easily distinguish this from a misconfigured legitimate client

While this doesn't reach High severity (which requires "Validator node slowdowns" specifically), it qualifies as Medium severity causing "State inconsistencies requiring intervention" due to potential node performance degradation requiring operator intervention to block malicious peers.

## Likelihood Explanation
**Likelihood: Medium-High**

- **Low Attack Barrier**: Only requires establishing a P2P connection to the storage service - no special privileges or validator access needed
- **Simple Exploitation**: Trivial to craft the malicious request - just set `max_response_bytes = 1`
- **Limited Detection**: No validation prevents this attack, and the RequestModerator only tracks invalid requests (these requests are technically valid)
- **Persistent Impact**: The moderator eventually ignores peers after 500 invalid requests, but these requests are not counted as "invalid" since they're technically serviceable

The attack is straightforward to execute and difficult to mitigate without code changes.

## Recommendation
Implement a minimum threshold for `max_response_bytes` to prevent abuse:

```rust
// In get_transaction_data_with_proof()
const MIN_RESPONSE_BYTES: u64 = 64 * 1024; // 64 KB minimum

let max_response_bytes = min(
    max(transaction_data_with_proof_request.max_response_bytes, MIN_RESPONSE_BYTES),
    self.config.max_network_chunk_bytes_v2,
);
```

This ensures that even malicious clients cannot force the binary search into excessive iterations. A minimum of 64 KB would limit iterations to at most log₂(3000/~1) ≈ 5-6 iterations even for single-transaction responses, while still accommodating legitimate small requests.

Apply similar fixes to:
- `get_epoch_ending_ledger_infos_by_size_legacy()`
- `get_transaction_outputs_with_proof_by_size_legacy()`
- `get_transactions_or_outputs_with_proof_by_size_legacy()`
- `get_state_value_chunk_with_proof_by_size_legacy()`

Alternatively, consider deprecating the legacy binary search approach in favor of the newer size-aware chunking that progressively builds responses: [7](#0-6) 

## Proof of Concept

```rust
// Test to demonstrate the vulnerability
#[tokio::test]
async fn test_malicious_small_max_response_bytes() {
    use aptos_storage_service_types::requests::DataRequest;
    
    // Setup test environment with mock storage containing 1000 transactions
    let (mut mock_db, storage_service) = setup_test_environment(1000);
    
    // Attacker creates request with maliciously small max_response_bytes
    let malicious_request = DataRequest::get_transaction_data_with_proof(
        1000,     // proof_version
        0,        // start_version  
        999,      // end_version (requesting 1000 transactions)
        false,    // include_events
        1,        // max_response_bytes = 1 byte (malicious!)
    );
    
    // Track database read operations
    let initial_read_count = mock_db.get_read_count();
    
    // Send request to storage service
    let response = storage_service
        .handle_request(malicious_request)
        .await
        .unwrap();
    
    let final_read_count = mock_db.get_read_count();
    let total_reads = final_read_count - initial_read_count;
    
    // Verify excessive reads occurred due to binary search
    // Expected: ~11 reads (log₂(1000) ≈ 10) instead of 1
    assert!(total_reads >= 10, "Expected ~10+ reads, got {}", total_reads);
    
    // Response still succeeds but with minimal data
    assert!(response.is_ok());
    println!("Resource exhaustion attack succeeded: {} DB reads for 1 request", total_reads);
}
```

**Notes:**
- The actual test implementation would require mocking the storage interface to track read operations
- In production, this can be observed by monitoring database query metrics when processing such requests
- Multiple concurrent malicious requests would amplify the impact proportionally

### Citations

**File:** state-sync/storage-service/server/src/storage.rs (L300-344)
```rust
    fn get_epoch_ending_ledger_infos_by_size_legacy(
        &self,
        start_epoch: u64,
        expected_end_epoch: u64,
        mut num_ledger_infos_to_fetch: u64,
        max_response_size: u64,
    ) -> Result<EpochChangeProof, Error> {
        while num_ledger_infos_to_fetch >= 1 {
            // The DbReader interface returns the epochs up to: `end_epoch - 1`.
            // However, we wish to fetch epoch endings up to end_epoch (inclusive).
            let end_epoch = start_epoch
                .checked_add(num_ledger_infos_to_fetch)
                .ok_or_else(|| {
                    Error::UnexpectedErrorEncountered("End epoch has overflown!".into())
                })?;
            let epoch_change_proof = self
                .storage
                .get_epoch_ending_ledger_infos(start_epoch, end_epoch)?;
            if num_ledger_infos_to_fetch == 1 {
                return Ok(epoch_change_proof); // We cannot return less than a single item
            }

            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&epoch_change_proof, max_response_size)?;
            if !overflow_frame {
                return Ok(epoch_change_proof);
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::EpochEndingLedgerInfos(epoch_change_proof).get_label(),
                );
                let new_num_ledger_infos_to_fetch = num_ledger_infos_to_fetch / 2;
                debug!("The request for {:?} ledger infos was too large (num bytes: {:?}, limit: {:?}). Retrying with {:?}.",
                    num_ledger_infos_to_fetch, num_bytes, max_response_size, new_num_ledger_infos_to_fetch);
                num_ledger_infos_to_fetch = new_num_ledger_infos_to_fetch; // Try again with half the amount of data
            }
        }

        Err(Error::UnexpectedErrorEncountered(format!(
            "Unable to serve the get_epoch_ending_ledger_infos request! Start epoch: {:?}, \
            expected end epoch: {:?}. The data cannot fit into a single network frame!",
            start_epoch, expected_end_epoch
        )))
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L515-563)
```rust
    fn get_transactions_with_proof_by_size_legacy(
        &self,
        proof_version: u64,
        start_version: u64,
        end_version: u64,
        mut num_transactions_to_fetch: u64,
        include_events: bool,
        max_response_size: u64,
    ) -> Result<TransactionDataWithProofResponse, Error> {
        while num_transactions_to_fetch >= 1 {
            let transaction_list_with_proof = self.storage.get_transactions(
                start_version,
                num_transactions_to_fetch,
                proof_version,
                include_events,
            )?;
            let response = TransactionDataWithProofResponse {
                transaction_data_response_type: TransactionDataResponseType::TransactionData,
                transaction_list_with_proof: Some(transaction_list_with_proof),
                transaction_output_list_with_proof: None,
            };
            if num_transactions_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
            }

            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&response, max_response_size)?;
            if !overflow_frame {
                return Ok(response);
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::TransactionDataWithProof(response).get_label(),
                );
                let new_num_transactions_to_fetch = num_transactions_to_fetch / 2;
                debug!("The request for {:?} transactions was too large (num bytes: {:?}, limit: {:?}). Retrying with {:?}.",
                    num_transactions_to_fetch, num_bytes, max_response_size, new_num_transactions_to_fetch);
                num_transactions_to_fetch = new_num_transactions_to_fetch; // Try again with half the amount of data
            }
        }

        Err(Error::UnexpectedErrorEncountered(format!(
            "Unable to serve the get_transactions_with_proof request! Proof version: {:?}, \
            start version: {:?}, end version: {:?}, include events: {:?}. The data cannot fit into \
            a single network frame!",
            proof_version, start_version, end_version, include_events,
        )))
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L739-784)
```rust
    fn get_transaction_outputs_with_proof_by_size_legacy(
        &self,
        proof_version: u64,
        start_version: u64,
        end_version: u64,
        mut num_outputs_to_fetch: u64,
        max_response_size: u64,
    ) -> Result<TransactionDataWithProofResponse, Error> {
        while num_outputs_to_fetch >= 1 {
            let output_list_with_proof = self.storage.get_transaction_outputs(
                start_version,
                num_outputs_to_fetch,
                proof_version,
            )?;
            let response = TransactionDataWithProofResponse {
                transaction_data_response_type: TransactionDataResponseType::TransactionOutputData,
                transaction_list_with_proof: None,
                transaction_output_list_with_proof: Some(output_list_with_proof),
            };
            if num_outputs_to_fetch == 1 {
                return Ok(response); // We cannot return less than a single item
            }

            // Attempt to divide up the request if it overflows the message size
            let (overflow_frame, num_bytes) =
                check_overflow_network_frame(&response, max_response_size)?;
            if !overflow_frame {
                return Ok(response);
            } else {
                metrics::increment_chunk_truncation_counter(
                    metrics::TRUNCATION_FOR_SIZE,
                    DataResponse::TransactionDataWithProof(response).get_label(),
                );
                let new_num_outputs_to_fetch = num_outputs_to_fetch / 2;
                debug!("The request for {:?} outputs was too large (num bytes: {:?}, limit: {:?}). Retrying with {:?}.",
                    num_outputs_to_fetch, num_bytes, max_response_size, new_num_outputs_to_fetch);
                num_outputs_to_fetch = new_num_outputs_to_fetch; // Try again with half the amount of data
            }
        }

        Err(Error::UnexpectedErrorEncountered(format!(
            "Unable to serve the get_transaction_outputs_with_proof request! Proof version: {:?}, \
            start version: {:?}, end version: {:?}. The data cannot fit into a single network frame!",
            proof_version, start_version, end_version
        )))
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L1140-1153)
```rust
    fn get_transaction_data_with_proof(
        &self,
        transaction_data_with_proof_request: &GetTransactionDataWithProofRequest,
    ) -> aptos_storage_service_types::Result<TransactionDataWithProofResponse, Error> {
        // Extract the data versions from the request
        let proof_version = transaction_data_with_proof_request.proof_version;
        let start_version = transaction_data_with_proof_request.start_version;
        let end_version = transaction_data_with_proof_request.end_version;

        // Calculate the max response size to use
        let max_response_bytes = min(
            transaction_data_with_proof_request.max_response_bytes,
            self.config.max_network_chunk_bytes_v2,
        );
```

**File:** state-sync/storage-service/types/src/requests.rs (L425-431)
```rust
pub struct GetTransactionDataWithProofRequest {
    pub transaction_data_request_type: TransactionDataRequestType, // The type of transaction data to request
    pub proof_version: u64,      // The version the proof should be relative to
    pub start_version: u64,      // The starting version of the data
    pub end_version: u64,        // The ending version of the data (inclusive)
    pub max_response_bytes: u64, // The max number of bytes to return in the response
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-196)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** config/src/config/state_sync_config.rs (L12-14)
```rust
// Whether to enable size and time-aware chunking (for non-production networks).
// Note: once this becomes stable, we should enable it for all networks (e.g., Mainnet).
const ENABLE_SIZE_AND_TIME_AWARE_CHUNKING: bool = true;
```
