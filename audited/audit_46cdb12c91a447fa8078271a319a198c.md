# Audit Report

## Title
Non-Deterministic Layout Validation in Change Set Squashing Breaks Consensus Safety

## Summary
The `randomly_check_layout_matches()` function uses non-deterministic random sampling via `rand::thread_rng()` to validate type layout consistency during change set squashing in transaction execution. This non-deterministic validation in consensus-critical code directly violates blockchain deterministic execution requirements, creating a consensus failure risk whenever layout mismatches occur.

## Finding Description

The `randomly_check_layout_matches()` function implements a probabilistic validation check using system entropy: [1](#0-0) 

The function generates a non-deterministic random number using `rand::thread_rng().gen_range(0, 100)` and only performs layout validation when `random_number == 1` (1% probability). When a layout mismatch exists and the check is performed, it returns a `PanicError`, causing transaction failure. When the check is skipped (99% probability), the transaction proceeds.

This function is called during change set squashing when merging `WriteWithDelayedFields` operations: [2](#0-1) 

The squashing occurs in the epilogue phase of every user transaction: [3](#0-2) [4](#0-3) 

**The Critical Flaw:**

Each validator executes transactions independently and generates their own system-seeded random number. When a layout mismatch exists:

1. **Validator A**: `random_number = 1` → layout check performed → mismatch detected → returns `PanicError` → transaction fails with `UNKNOWN_INVARIANT_VIOLATION_ERROR`
2. **Validator B**: `random_number = 50` → layout check skipped → no error → transaction succeeds
3. **Validator C**: `random_number = 99` → layout check skipped → no error → transaction succeeds

This produces **different transaction outcomes across validators** for identical block inputs, causing different state roots and consensus failure.

The execution path is: [5](#0-4) 

## Impact Explanation

**Critical Severity - Consensus/Safety Violation**

This vulnerability directly breaks the fundamental **Deterministic Execution** invariant that all validators must produce identical state roots for identical blocks.

The non-deterministic behavior causes:

1. **Consensus Splits**: Different validators produce different state roots for the same block, preventing consensus agreement and halting the network
2. **Network Partition**: The network fragments into groups that validated transactions differently, requiring hardfork to recover
3. **Bug Amplification**: Any condition causing layout mismatches (VM bugs, cache inconsistencies, race conditions) is immediately elevated to a guaranteed consensus failure

This meets the Aptos Bug Bounty **Critical Severity** categories:
- "Consensus/Safety Violations" - different validators commit different states
- "Non-recoverable Network Partition (requires hardfork)" - consensus divergence cannot be resolved without manual intervention

Even if layout mismatches are rare, the presence of non-deterministic code in consensus-critical execution is a fundamental architectural violation that creates unbounded risk.

## Likelihood Explanation

**Likelihood: Medium (Logic Vulnerability)**

This is a **logic vulnerability** - the use of non-deterministic randomness (`thread_rng()`) in deterministic consensus execution is fundamentally incorrect regardless of trigger frequency.

**Trigger scenarios include:**

1. **Layout cache inconsistencies** - VM layout caching bugs could cause different layouts for the same type
2. **Module upgrade race conditions** - Concurrent module loading during upgrades
3. **VM configuration drift** - Different delayed field optimization settings between execution phases
4. **Future VM bugs** - Any future bug causing layout inconsistencies immediately becomes a consensus failure

The function is executed in the critical path of every user transaction that uses delayed fields (aggregator v2 operations), which are actively used in production: [6](#0-5) 

While layout mismatches may be rare under normal conditions, the architectural flaw guarantees consensus failure if they occur, making this a critical security defect.

## Recommendation

Replace non-deterministic random validation with deterministic validation:

```rust
pub fn check_layout_matches(
    layout_1: Option<&MoveTypeLayout>,
    layout_2: Option<&MoveTypeLayout>,
) -> Result<(), PanicError> {
    if layout_1.is_some() != layout_2.is_some() {
        return Err(code_invariant_error(format!(
            "Layouts don't match when they are expected to: {:?} and {:?}",
            layout_1, layout_2
        )));
    }
    if layout_1.is_some() && layout_1 != layout_2 {
        return Err(code_invariant_error(format!(
            "Layouts don't match when they are expected to: {:?} and {:?}",
            layout_1, layout_2
        )));
    }
    Ok(())
}
```

If performance is a concern, consider:
1. Caching layout comparison results deterministically
2. Using compile-time or configuration-based validation flags
3. Performing full validation with optimized comparison algorithms

**Never use non-deterministic operations in consensus-critical execution paths.**

## Proof of Concept

A Rust test demonstrating the non-deterministic behavior:

```rust
#[test]
fn test_non_deterministic_layout_validation() {
    use move_core_types::value::MoveTypeLayout;
    
    // Create two different layouts
    let layout1 = MoveTypeLayout::U64;
    let layout2 = MoveTypeLayout::U128;
    
    let mut results = Vec::new();
    
    // Run check multiple times - results will vary
    for _ in 0..1000 {
        let result = randomly_check_layout_matches(
            Some(&layout1), 
            Some(&layout2)
        );
        results.push(result.is_ok());
    }
    
    // With mismatched layouts, some runs succeed (99%) and some fail (1%)
    let success_count = results.iter().filter(|&&x| x).count();
    let failure_count = results.len() - success_count;
    
    // This demonstrates non-determinism: same inputs produce different outputs
    assert!(success_count > 0, "Some checks passed");
    assert!(failure_count > 0, "Some checks failed");
    println!("Non-deterministic results: {} succeeded, {} failed", 
             success_count, failure_count);
}
```

This test demonstrates that identical inputs produce different outputs across multiple runs, violating deterministic execution requirements essential for blockchain consensus.

## Notes

This vulnerability is classified as **Critical** because:

1. It affects production consensus-critical code in the Aptos VM execution engine
2. It uses system entropy (`thread_rng()`) which is explicitly non-deterministic
3. The code path is executed during normal transaction processing by all validators
4. Different validators will independently generate different random numbers, causing consensus divergence when layout mismatches occur
5. It violates the fundamental blockchain invariant of deterministic execution

The vulnerability exists even if layout mismatches are currently rare - the architectural flaw of using non-deterministic validation in consensus code creates an unbounded risk that any future bug causing layout inconsistencies will immediately trigger network-wide consensus failure.

### Citations

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L49-74)
```rust
pub fn randomly_check_layout_matches(
    layout_1: Option<&MoveTypeLayout>,
    layout_2: Option<&MoveTypeLayout>,
) -> Result<(), PanicError> {
    if layout_1.is_some() != layout_2.is_some() {
        return Err(code_invariant_error(format!(
            "Layouts don't match when they are expected to: {:?} and {:?}",
            layout_1, layout_2
        )));
    }
    if layout_1.is_some() {
        // Checking if 2 layouts are equal is a recursive operation and is expensive.
        // We generally call this `randomly_check_layout_matches` function when we know
        // that the layouts are supposed to match. As an optimization, we only randomly
        // check if the layouts are matching.
        let mut rng = rand::thread_rng();
        let random_number: u32 = rng.gen_range(0, 100);
        if random_number == 1 && layout_1 != layout_2 {
            return Err(code_invariant_error(format!(
                "Layouts don't match when they are expected to: {:?} and {:?}",
                layout_1, layout_2
            )));
        }
    }
    Ok(())
}
```

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L576-598)
```rust
                        (
                            WriteWithDelayedFields(WriteWithDelayedFieldsOp {
                                write_op,
                                layout,
                                materialized_size,
                            }),
                            WriteWithDelayedFields(WriteWithDelayedFieldsOp {
                                write_op: additional_write_op,
                                layout: additional_layout,
                                materialized_size: additional_materialized_size,
                            }),
                        ) => {
                            randomly_check_layout_matches(Some(layout), Some(additional_layout))?;
                            let to_delete = !WriteOp::squash(write_op, additional_write_op.clone())
                                .map_err(|e| {
                                    code_invariant_error(format!(
                                        "Error while squashing two write ops: {}.",
                                        e
                                    ))
                                })?;
                            *materialized_size = *additional_materialized_size;
                            (to_delete, false)
                        },
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/session/respawned_session.rs (L72-109)
```rust
    pub fn finish_with_squashed_change_set(
        mut self,
        change_set_configs: &ChangeSetConfigs,
        module_storage: &impl ModuleStorage,
        assert_no_additional_creation: bool,
    ) -> Result<VMChangeSet, VMStatus> {
        let additional_change_set = self.with_session_mut(|session| {
            unwrap_or_invariant_violation(
                session.take(),
                "VM session cannot be finished more than once.",
            )?
            .finish(change_set_configs, module_storage)
            .map_err(|e| e.into_vm_status())
        })?;
        if assert_no_additional_creation && additional_change_set.has_creation() {
            // After respawning in the epilogue, there shouldn't be new slots
            // created, otherwise there's a potential vulnerability like this:
            // 1. slot created by the user
            // 2. another user transaction deletes the slot and claims the refund
            // 3. in the epilogue the same slot gets recreated, and the final write set will have
            //    a ModifyWithMetadata carrying the original metadata
            // 4. user keeps doing the same and repeatedly claim refund out of the slot.
            return Err(VMStatus::error(
                StatusCode::UNKNOWN_INVARIANT_VIOLATION_ERROR,
                err_msg("Unexpected storage allocation after respawning session."),
            ));
        }
        let mut change_set = self.into_heads().executor_view.change_set;
        change_set
            .squash_additional_change_set(additional_change_set)
            .map_err(|_err| {
                VMStatus::error(
                    StatusCode::UNKNOWN_INVARIANT_VIOLATION_ERROR,
                    err_msg("Failed to squash VMChangeSet"),
                )
            })?;
        Ok(change_set)
    }
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/session/user_transaction_sessions/epilogue.rs (L102-127)
```rust
    pub fn finish(
        self,
        fee_statement: FeeStatement,
        execution_status: ExecutionStatus,
        change_set_configs: &ChangeSetConfigs,
        module_storage: &impl AptosModuleStorage,
    ) -> Result<VMOutput, VMStatus> {
        let Self {
            session,
            storage_refund: _,
            module_write_set,
        } = self;

        let change_set =
            session.finish_with_squashed_change_set(change_set_configs, module_storage, true)?;
        let epilogue_session_change_set =
            UserSessionChangeSet::new(change_set, module_write_set, change_set_configs)?;

        let (change_set, module_write_set) = epilogue_session_change_set.unpack();
        Ok(VMOutput::new(
            change_set,
            module_write_set,
            fee_statement,
            TransactionStatus::Keep(execution_status),
        ))
    }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2871-2927)
```rust
    pub fn execute_single_transaction(
        &self,
        txn: &SignatureVerifiedTransaction,
        resolver: &impl AptosMoveResolver,
        code_storage: &(impl AptosCodeStorage + BlockSynchronizationKillSwitch),
        log_context: &AdapterLogSchema,
        auxiliary_info: &AuxiliaryInfo,
    ) -> Result<(VMStatus, VMOutput), VMStatus> {
        assert!(!self.is_simulation, "VM has to be created for execution");

        if let SignatureVerifiedTransaction::Invalid(_) = txn {
            let vm_status = VMStatus::error(StatusCode::INVALID_SIGNATURE, None);
            let discarded_output = discarded_output(vm_status.status_code());
            return Ok((vm_status, discarded_output));
        }

        Ok(match txn.expect_valid() {
            Transaction::BlockMetadata(block_metadata) => {
                fail_point!("aptos_vm::execution::block_metadata");
                let (vm_status, output) = self.process_block_prologue(
                    resolver,
                    code_storage,
                    block_metadata.clone(),
                    log_context,
                )?;
                (vm_status, output)
            },
            Transaction::BlockMetadataExt(block_metadata_ext) => {
                fail_point!("aptos_vm::execution::block_metadata_ext");
                let (vm_status, output) = self.process_block_prologue_ext(
                    resolver,
                    code_storage,
                    block_metadata_ext.clone(),
                    log_context,
                )?;
                (vm_status, output)
            },
            Transaction::GenesisTransaction(write_set_payload) => {
                let (vm_status, output) = self.process_waypoint_change_set(
                    resolver,
                    code_storage,
                    write_set_payload.clone(),
                    log_context,
                )?;
                (vm_status, output)
            },
            Transaction::UserTransaction(txn) => {
                fail_point!("aptos_vm::execution::user_transaction");
                let _timer = TXN_TOTAL_SECONDS.start_timer();
                let (vm_status, output) = self.execute_user_transaction(
                    resolver,
                    code_storage,
                    txn,
                    log_context,
                    auxiliary_info,
                );

```

**File:** aptos-move/aptos-vm-types/src/abstract_write_op.rs (L17-48)
```rust
    WriteWithDelayedFields(WriteWithDelayedFieldsOp),
    // Prior to adding a dedicated write-set for resource groups, all resource group
    // updates are merged into a single WriteOp included in the resource_write_set.
    WriteResourceGroup(GroupWrite),
    // No writes in the resource, except for delayed field changes.
    InPlaceDelayedFieldChange(InPlaceDelayedFieldChangeOp),
    // No writes in the resource group, except for delayed field changes.
    ResourceGroupInPlaceDelayedFieldChange(ResourceGroupInPlaceDelayedFieldChangeOp),
}

impl AbstractResourceWriteOp {
    pub fn try_as_concrete_write(&self) -> Option<&WriteOp> {
        if let AbstractResourceWriteOp::Write(write_op) = self {
            Some(write_op)
        } else {
            None
        }
    }

    pub fn try_into_concrete_write(self) -> Option<WriteOp> {
        if let AbstractResourceWriteOp::Write(write_op) = self {
            Some(write_op)
        } else {
            None
        }
    }

    pub fn materialized_size(&self) -> WriteOpSize {
        use AbstractResourceWriteOp::*;
        match self {
            Write(write) => write.write_op_size(),
            WriteWithDelayedFields(WriteWithDelayedFieldsOp {
```
