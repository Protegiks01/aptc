# Audit Report

## Title
Non-Deterministic State Sync Target Selection Enables Resource Exhaustion and Amplifies Consensus Violations

## Summary
The `highest_synced_ledger_info()` function uses `position_max()` on a vector populated by iterating over a `DashMap` with non-deterministic order. When multiple ledger infos share the same version (which is not validated), different nodes select different targets based on peer advertisement arrival order, causing non-deterministic behavior, resource waste, and potential amplification of consensus violations.

## Finding Description

The vulnerability exists in the state sync data client's global data summary construction: [1](#0-0) 

The `highest_synced_ledger_info()` function uses `position_max()` which returns the position of the first occurrence of the maximum version. However, the `synced_ledger_infos` vector is populated by iterating over a `DashMap`: [2](#0-1) 

**Critical Issues:**

1. **No validation prevents duplicate versions**: The code unconditionally pushes each peer's ledger info without checking if that version already exists in the vector.

2. **Non-deterministic iteration order**: `DashMap` is a concurrent hashmap that provides no iteration order guarantees. Different nodes receive peer advertisements in different orders, leading to different vector orderings.

3. **Position-dependent selection**: `position_max()` returns the first position with the maximum value, making the selection dependent on the non-deterministic iteration order.

**Attack Scenarios:**

**Scenario 1: Resource Exhaustion**
- Malicious peer advertises fake ledger info with version 1000 (forged signatures)
- Honest peers also advertise legitimate ledger info for version 1000
- Node A receives advertisements: [malicious, honest] → selects malicious target
- Node B receives advertisements: [honest, malicious] → selects honest target
- Node A wastes resources: attempts sync, signature verification fails, resets stream
- Malicious peer can flood network with fake advertisements, causing widespread resource waste

**Scenario 2: Consensus Violation Amplification**
- If >1/3 validators are Byzantine and create two valid ledger infos for version 1000 with different state roots (consensus safety violation)
- Different nodes select different targets based on advertisement order
- Node A syncs to state_root_X, Node B syncs to state_root_Y
- Instead of detecting the anomaly, the code amplifies the divergence by making different selections deterministically based on non-deterministic input order

The selected ledger info becomes the target for continuous transaction streaming: [3](#0-2) 

This target is included in data notifications and verified before commit: [4](#0-3) 

While signature verification prevents committing invalid states, the non-deterministic selection still causes:
- **Resource waste**: Nodes selecting invalid targets repeatedly fail verification
- **Unpredictable behavior**: Same node may make different selections across restarts
- **Amplification risk**: If multiple valid but conflicting ledger infos exist (consensus violation), different nodes deterministically diverge

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **Significant Protocol Violations**: The code violates the fundamental requirement of deterministic behavior. State sync target selection should be deterministic given the same network state, but instead depends on unpredictable iteration order.

2. **Validator Node Slowdowns**: Malicious peers can force validator nodes to repeatedly select invalid targets, causing verification failures and stream resets. This wastes CPU cycles on signature verification and network bandwidth on retrying.

3. **Defense-in-Depth Failure**: Even though consensus violations require >1/3 Byzantine validators, the code should detect and handle anomalous situations (multiple ledger infos for same version) rather than amplifying them through non-deterministic selection.

4. **Breaks Invariant #1 (Deterministic Execution)**: Different nodes make different selections for the same advertised data, violating the requirement that "all validators must produce identical state roots for identical blocks."

## Likelihood Explanation

**High Likelihood** for resource waste scenario:
- Any malicious or buggy peer can advertise fake ledger infos
- No privileged access required
- Simple to exploit repeatedly

**Medium Likelihood** for amplification scenario:
- Requires pre-existing consensus violation (>1/3 Byzantine)
- But when it occurs, the vulnerability makes recovery harder by amplifying divergence

**Constant Occurrence** of non-determinism:
- Every node builds global data summary by iterating DashMap
- Iteration order varies between nodes and even between executions on the same node
- Non-deterministic behavior is inherent to current implementation

## Recommendation

**Add validation and deduplication by version:**

```rust
pub fn highest_synced_ledger_info(&self) -> Option<LedgerInfoWithSignatures> {
    // Use BTreeMap to ensure deterministic ordering and detect duplicates
    let mut ledger_infos_by_version: std::collections::BTreeMap<
        Version, 
        Vec<LedgerInfoWithSignatures>
    > = std::collections::BTreeMap::new();
    
    for ledger_info in &self.synced_ledger_infos {
        let version = ledger_info.ledger_info().version();
        ledger_infos_by_version
            .entry(version)
            .or_insert_with(Vec::new)
            .push(ledger_info.clone());
    }
    
    // Get the highest version
    let (highest_version, ledger_infos) = ledger_infos_by_version.last_key_value()?;
    
    // If multiple ledger infos exist for the same version, log warning and select deterministically
    if ledger_infos.len() > 1 {
        warn!(
            "Multiple ledger infos detected for version {}: {} instances. Selecting by hash.",
            highest_version, ledger_infos.len()
        );
        // Select deterministically by comparing ledger info hashes
        return ledger_infos.iter()
            .max_by_key(|li| li.ledger_info().hash())
            .cloned();
    }
    
    Some(ledger_infos[0].clone())
}
```

**Additionally, prevent duplicates during population:**

```rust
// In calculate_global_data_summary()
let mut seen_versions: std::collections::HashSet<Version> = std::collections::HashSet::new();

for summary in storage_summaries {
    if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
        let version = synced_ledger_info.ledger_info().version();
        
        // Only add if we haven't seen this version yet, or validate consistency
        if !seen_versions.contains(&version) {
            advertised_data.synced_ledger_infos.push(synced_ledger_info.clone());
            seen_versions.insert(version);
        } else {
            // Log warning about duplicate version advertisement
            warn!("Duplicate synced ledger info version {} from peer", version);
        }
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::ledger_info::{LedgerInfo, LedgerInfoWithSignatures};
    use aptos_types::block_info::BlockInfo;
    use aptos_crypto::hash::HashValue;
    use aptos_types::aggregate_signature::AggregateSignature;

    #[test]
    fn test_non_deterministic_selection() {
        // Create two different ledger infos with the same version but different content
        let version = 100;
        let epoch = 1;
        
        let block_info_1 = BlockInfo::new(
            epoch,
            0, // round
            HashValue::random(),
            HashValue::random(), // Different state root A
            version,
            0,
            None,
        );
        let ledger_info_1 = LedgerInfo::new(block_info_1, HashValue::zero());
        let ledger_info_with_sigs_1 = LedgerInfoWithSignatures::new(
            ledger_info_1,
            AggregateSignature::empty(),
        );
        
        let block_info_2 = BlockInfo::new(
            epoch,
            0, // round
            HashValue::random(),
            HashValue::random(), // Different state root B
            version,
            0,
            None,
        );
        let ledger_info_2 = LedgerInfo::new(block_info_2, HashValue::zero());
        let ledger_info_with_sigs_2 = LedgerInfoWithSignatures::new(
            ledger_info_2,
            AggregateSignature::empty(),
        );
        
        // Verify they have the same version but different state roots
        assert_eq!(
            ledger_info_with_sigs_1.ledger_info().version(),
            ledger_info_with_sigs_2.ledger_info().version()
        );
        assert_ne!(
            ledger_info_with_sigs_1.ledger_info().transaction_accumulator_hash(),
            ledger_info_with_sigs_2.ledger_info().transaction_accumulator_hash()
        );
        
        // Create advertised data with both ledger infos in different orders
        let mut advertised_data_order_1 = AdvertisedData::empty();
        advertised_data_order_1.synced_ledger_infos.push(ledger_info_with_sigs_1.clone());
        advertised_data_order_1.synced_ledger_infos.push(ledger_info_with_sigs_2.clone());
        
        let mut advertised_data_order_2 = AdvertisedData::empty();
        advertised_data_order_2.synced_ledger_infos.push(ledger_info_with_sigs_2.clone());
        advertised_data_order_2.synced_ledger_infos.push(ledger_info_with_sigs_1.clone());
        
        // Get highest synced ledger info from both orderings
        let selected_1 = advertised_data_order_1.highest_synced_ledger_info().unwrap();
        let selected_2 = advertised_data_order_2.highest_synced_ledger_info().unwrap();
        
        // Verify that different orderings lead to different selections
        // position_max() returns first occurrence, so different orders = different results
        assert_eq!(
            selected_1.ledger_info().transaction_accumulator_hash(),
            ledger_info_with_sigs_1.ledger_info().transaction_accumulator_hash()
        );
        assert_eq!(
            selected_2.ledger_info().transaction_accumulator_hash(),
            ledger_info_with_sigs_2.ledger_info().transaction_accumulator_hash()
        );
        
        // This demonstrates that different nodes with different iteration orders
        // will select different ledger infos, causing non-deterministic behavior
        println!("VULNERABILITY CONFIRMED: Different orderings lead to different selections!");
    }
}
```

## Notes

While signature verification prevents committing invalid states, the vulnerability still causes significant issues:
- **Resource exhaustion** through repeated invalid target selection
- **Non-deterministic behavior** that makes debugging and reasoning difficult
- **Failure to detect anomalies** that should trigger alerts
- **Amplification of consensus violations** if they occur

The fix is straightforward: validate uniqueness by version and use deterministic selection criteria when duplicates are detected.

### Citations

**File:** state-sync/aptos-data-client/src/global_summary.rs (L184-198)
```rust
    pub fn highest_synced_ledger_info(&self) -> Option<LedgerInfoWithSignatures> {
        let highest_synced_position = self
            .synced_ledger_infos
            .iter()
            .map(|ledger_info_with_sigs| ledger_info_with_sigs.ledger_info().version())
            .position_max();

        if let Some(highest_synced_position) = highest_synced_position {
            self.synced_ledger_infos
                .get(highest_synced_position)
                .cloned()
        } else {
            None
        }
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L363-378)
```rust
        for summary in storage_summaries {
            // Collect aggregate data advertisements
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L522-534)
```rust
        // We don't have a final target, select the highest to make progress
        if let Some(highest_synced_ledger_info) = advertised_data.highest_synced_ledger_info() {
            let (next_request_version, _) = self.next_request_version_and_epoch;
            if next_request_version > highest_synced_ledger_info.ledger_info().version() {
                Ok(None) // We're already at the highest synced ledger info. There's no known target.
            } else {
                Ok(Some(highest_synced_ledger_info))
            }
        } else {
            Err(Error::DataIsUnavailable(
                "Unable to find the highest synced ledger info!".into(),
            ))
        }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L579-594)
```rust
        let target_ledger_info = self.get_target_ledger_info()?.clone();
        self.update_stream_version_and_epoch(
            request_start_version,
            request_end_version,
            &target_ledger_info,
            last_received_version,
        )?;

        // Create the data notification
        let data_notification = create_data_notification(
            notification_id_generator,
            client_response_payload,
            Some(target_ledger_info),
            self.clone().into(),
        )?;
        Ok(data_notification)
```
