# Audit Report

## Title
IndexerAsyncV2 Metadata Update Split Across Multiple Transactions Creates Crash-Inconsistency Window

## Summary
The `IndexerAsyncV2` implementation splits table info writes and metadata updates (`LatestVersion`) across two separate database transactions, violating atomicity guarantees. If a node crashes between these transactions, the indexer metadata will be inconsistent with the actual indexed data, requiring manual intervention to recover.

## Finding Description
The vulnerability exists in the transaction handling pattern of `IndexerAsyncV2` where table info parsing and metadata updates are not atomic: [1](#0-0) 

In this code, `index_with_annotator` creates a `SchemaBatch`, adds table info to it via `finish_table_info_parsing`, and writes the batch to the database. However, the `LatestVersion` metadata update is **NOT** included in this batch.

The metadata update happens in a separate transaction through the `update_next_version` method, which is called externally: [2](#0-1) 

This method uses a direct `db.put` call, which internally creates its own atomic transaction: [3](#0-2) 

The separation is visible in the calling code: [4](#0-3) 

**Attack Scenario:**
1. Node processes transactions and writes table info for versions 1000-1999 (Transaction 1 commits)
2. Node crashes before `update_next_version` executes
3. On restart, `LatestVersion` metadata still points to 999
4. Indexer re-processes versions 1000-1999, creating potential duplicates or inconsistencies
5. Table info database now contains conflicting or duplicate entries

**Invariant Violation:**
This violates the **State Consistency** invariant: "State transitions must be atomic and verifiable." The indexer's state (table info + metadata) is not updated atomically, allowing intermediate inconsistent states to persist after crashes.

**Contrast with Correct Implementations:**

The older `Indexer` implementation correctly batches metadata with data: [5](#0-4) 

Similarly, `DBIndexer` correctly includes all metadata in the same batch: [6](#0-5) 

## Impact Explanation
**Severity: Medium** - "State inconsistencies requiring intervention"

After a crash, the indexer will be in an inconsistent state where:
- Table info for versions X to Y exists in the database
- `LatestVersion` metadata indicates version X-1 (not yet processed)
- On restart, the indexer attempts to re-index versions X to Y
- Depending on the idempotency of table info writes, this may cause duplicate entries, incorrect mappings, or database corruption
- Manual intervention is required to determine the actual latest indexed version and update metadata accordingly
- In a distributed deployment, different nodes could have different metadata states depending on when they crashed

While this doesn't directly lead to consensus violations or fund loss, it compromises the reliability of the indexer subsystem, which is critical for blockchain explorers, wallets, and dApps that rely on table info lookups.

## Likelihood Explanation
**Likelihood: High**

- Node crashes are common in production environments (hardware failures, OOM conditions, power loss, Kubernetes pod evictions)
- The vulnerable time window exists during every batch processing cycle
- The indexer processes thousands of transactions continuously, creating frequent opportunities for this race condition
- No special attacker privileges are required - this is a crash-consistency bug affecting normal operations

## Recommendation

**Fix:** Include the `LatestVersion` metadata update in the same `SchemaBatch` as the table info writes to ensure atomicity.

Modify `index_with_annotator` in `db_v2.rs`:

```rust
pub fn index_with_annotator<R: StateView>(
    &self,
    annotator: &AptosValueAnnotator<R>,
    first_version: Version,
    write_sets: &[&WriteSet],
) -> Result<()> {
    let end_version = first_version + write_sets.len() as Version;
    let mut table_info_parser = TableInfoParser::new(self, annotator, &self.pending_on);
    for write_set in write_sets {
        for (state_key, write_op) in write_set.write_op_iter() {
            table_info_parser.collect_table_info_from_write_op(state_key, write_op)?;
        }
    }
    let mut batch = SchemaBatch::new();
    match self.finish_table_info_parsing(&mut batch, &table_info_parser.result) {
        Ok(_) => {},
        Err(err) => {
            aptos_logger::error!(
                first_version = first_version,
                end_version = end_version,
                error = ?&err,
                "[DB] Failed to parse table info"
            );
            bail!("{}", err);
        },
    };
    
    // ADD THIS: Include metadata update in the same batch
    batch.put::<IndexerMetadataSchema>(
        &MetadataKey::LatestVersion,
        &MetadataValue::Version(end_version - 1),
    )?;
    
    self.db.write_schemas(batch)?;
    self.next_version.store(end_version, Ordering::Relaxed);
    Ok(())
}
```

Then remove the separate `update_next_version` call from `table_info_service.rs`, or make it a no-op that only updates the in-memory counter.

## Proof of Concept

```rust
#[cfg(test)]
mod crash_consistency_test {
    use super::*;
    use aptos_schemadb::DB;
    use aptos_temppath::TempPath;
    use aptos_types::write_set::WriteSet;
    
    #[test]
    fn test_metadata_inconsistency_after_simulated_crash() {
        let tmpdir = TempPath::new();
        let db = DB::open(
            tmpdir.path(),
            "test_indexer",
            vec!["table_info", "indexer_metadata"],
            &rocksdb::Options::default(),
        ).unwrap();
        
        let indexer = IndexerAsyncV2::new(db).unwrap();
        
        // Create mock write sets
        let write_sets: Vec<&WriteSet> = vec![/* mock data */];
        
        // Process transactions - this writes table info
        indexer.index_with_annotator(&annotator, 0, &write_sets).unwrap();
        
        // Simulate crash BEFORE update_next_version is called
        // Drop the indexer without calling update_next_version
        drop(indexer);
        
        // Restart: open the DB again
        let db2 = DB::open(
            tmpdir.path(),
            "test_indexer",
            vec!["table_info", "indexer_metadata"],
            &rocksdb::Options::default(),
        ).unwrap();
        
        let indexer2 = IndexerAsyncV2::new(db2).unwrap();
        
        // BUG: next_version from metadata is 0, but table info exists for versions 0-999
        assert_eq!(indexer2.next_version(), 0);
        
        // The indexer will now attempt to re-process the same transactions
        // causing potential duplicates or conflicts
    }
}
```

## Notes

This vulnerability is specific to `IndexerAsyncV2` in the table info indexer service. Other indexer implementations (`Indexer` and `DBIndexer`) correctly batch metadata updates with data writes. The issue was likely introduced during refactoring to support asynchronous parallel processing, where the metadata update was separated to occur after all parallel batches complete. However, this separation violated the atomicity guarantee required for crash-consistent state management.

### Citations

**File:** storage/indexer/src/db_v2.rs (L87-114)
```rust
    pub fn index_with_annotator<R: StateView>(
        &self,
        annotator: &AptosValueAnnotator<R>,
        first_version: Version,
        write_sets: &[&WriteSet],
    ) -> Result<()> {
        let end_version = first_version + write_sets.len() as Version;
        let mut table_info_parser = TableInfoParser::new(self, annotator, &self.pending_on);
        for write_set in write_sets {
            for (state_key, write_op) in write_set.write_op_iter() {
                table_info_parser.collect_table_info_from_write_op(state_key, write_op)?;
            }
        }
        let mut batch = SchemaBatch::new();
        match self.finish_table_info_parsing(&mut batch, &table_info_parser.result) {
            Ok(_) => {},
            Err(err) => {
                aptos_logger::error!(
                    first_version = first_version,
                    end_version = end_version,
                    error = ?&err,
                    "[DB] Failed to parse table info"
                );
                bail!("{}", err);
            },
        };
        self.db.write_schemas(batch)?;
        Ok(())
```

**File:** storage/indexer/src/db_v2.rs (L117-124)
```rust
    pub fn update_next_version(&self, end_version: u64) -> Result<()> {
        self.db.put::<IndexerMetadataSchema>(
            &MetadataKey::LatestVersion,
            &MetadataValue::Version(end_version - 1),
        )?;
        self.next_version.store(end_version, Ordering::Relaxed);
        Ok(())
    }
```

**File:** storage/schemadb/src/lib.rs (L238-244)
```rust
    /// Writes single record.
    pub fn put<S: Schema>(&self, key: &S::Key, value: &S::Value) -> DbResult<()> {
        // Not necessary to use a batch, but we'd like a central place to bump counters.
        let mut batch = self.new_native_batch();
        batch.put::<S>(key, value)?;
        self.write_schemas(batch)
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/table_info_service.rs (L280-304)
```rust
                // If pending on items are not empty, meaning the current loop hasn't fully parsed all table infos
                // due to the nature of multithreading where instructions used to parse table info might come later,
                // retry sequentially to ensure parsing is complete
                //
                // Risk of this sequential approach is that it could be slow when the txns to process contain extremely
                // nested table items, but the risk is bounded by the configuration of the number of txns to process and number of threads
                if !self.indexer_async_v2.is_indexer_async_v2_pending_on_empty() {
                    self.indexer_async_v2.clear_pending_on();
                    Self::process_transactions(
                        context.clone(),
                        indexer_async_v2.clone(),
                        &transactions,
                    )
                    .await;
                }

                assert!(
                    self.indexer_async_v2.is_indexer_async_v2_pending_on_empty(),
                    "Missing data in table info parsing after sequential retry"
                );

                // Update rocksdb's to be processed next version after verifying all txns are successfully parsed
                self.indexer_async_v2
                    .update_next_version(end_version + 1)
                    .unwrap();
```

**File:** storage/indexer/src/lib.rs (L126-147)
```rust
        let mut batch = SchemaBatch::new();
        match table_info_parser.finish(&mut batch) {
            Ok(_) => {},
            Err(err) => {
                aptos_logger::error!(first_version = first_version, end_version = end_version, error = ?&err);
                write_sets
                    .iter()
                    .enumerate()
                    .for_each(|(i, write_set)| {
                        aptos_logger::error!(version = first_version as usize + i, write_set = ?write_set);
                    });
                db_other_bail!("Failed to parse table info: {:?}", err);
            },
        };
        batch.put::<IndexerMetadataSchema>(
            &MetadataKey::LatestVersion,
            &MetadataValue::Version(end_version - 1),
        )?;
        self.db.write_schemas(batch)?;
        self.next_version.store(end_version, Ordering::Relaxed);

        Ok(())
```

**File:** storage/indexer/src/db_indexer.rs (L506-549)
```rust
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::EventV2TranslationVersion,
                &MetadataValue::Version(version - 1),
            )?;

            for event_key in event_keys {
                batch
                    .put::<EventSequenceNumberSchema>(
                        &event_key,
                        &self
                            .event_v2_translation_engine
                            .get_cached_sequence_number(&event_key)
                            .unwrap_or(0),
                    )
                    .expect("Failed to put events by key to a batch");
            }
        }

        if self.indexer_db.transaction_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::TransactionVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        if self.indexer_db.event_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::EventVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        if self.indexer_db.statekeys_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::StateVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        batch.put::<InternalIndexerMetadataSchema>(
            &MetadataKey::LatestVersion,
            &MetadataValue::Version(version - 1),
        )?;
        self.sender
            .send(Some(batch))
            .map_err(|e| AptosDbError::Other(e.to_string()))?;
        Ok(version)
```
