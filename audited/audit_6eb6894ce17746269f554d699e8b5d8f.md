# Audit Report

## Title
Race Condition in insert_block() Causes Node Panic Through Weak Pointer Invalidation

## Summary
The `insert_block()` function in `consensus/src/block_storage/block_store.rs` contains a Time-of-Check to Time-of-Use (TOCTOU) race condition that can cause validator node panics. The function creates an `OrderedBlockWindow` with Weak pointers to blocks while holding a read lock, but then accesses these Weak pointers without any lock protection. If blocks are concurrently pruned and removed from memory between these operations, the Weak pointer upgrade fails and causes a panic, crashing the validator node. [1](#0-0) 

## Finding Description
The vulnerability exists in the consensus block insertion logic and breaks the availability invariant that validators should remain operational under normal conditions.

**The Race Condition Flow:**

1. **Window Creation (with READ lock)**: The `insert_block()` function calls `get_ordered_block_window()` which traverses parent blocks and returns an `OrderedBlockWindow` containing Weak references to recent blocks. [2](#0-1) 

2. **OrderedBlockWindow stores Weak pointers**: The window stores `Vec<(HashValue, Weak<PipelinedBlock>)>` instead of strong references. [3](#0-2) 

3. **RACE WINDOW**: After `get_ordered_block_window()` returns and the READ lock is released, another thread can acquire a WRITE lock and execute `commit_callback()`, which calls `process_pruned_blocks()`. When the pruned block buffer exceeds `max_pruned_blocks_in_mem` (default: 100), old blocks are removed from the `id_to_block` HashMap via `remove_block()`. [4](#0-3) 

4. **Panic on Weak Upgrade Failure**: When `block_window.blocks()` is called without holding any lock, it attempts to upgrade the Weak pointers. If a block was removed from memory during the race window, the upgrade fails and triggers a panic. [5](#0-4) 

**Concurrent Execution Path:**

The `commit_callback` is invoked asynchronously from the consensus pipeline with a WRITE lock on the BlockTree: [6](#0-5) 

This callback executes `process_pruned_blocks()` which can remove blocks that were referenced by the OrderedBlockWindow's Weak pointers, causing the subsequent upgrade to fail.

## Impact Explanation
This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria for the following reasons:

1. **Validator Node Crash**: The panic causes immediate termination of the validator process, taking it offline and preventing it from participating in consensus.

2. **Consensus Availability Impact**: If multiple validators experience this race condition simultaneously (possible under network stress or high block production rates), it can degrade network liveness and consensus participation rates.

3. **No Data Corruption**: While severe, this is an availability issue rather than a safety violation. It does not compromise consensus safety, cause state corruption, or enable fund theft.

The impact aligns with **"High Severity: Validator node slowdowns"** from the bug bounty program, though node crashes are more severe than mere slowdowns. It could also be categorized under **"High Severity: API crashes"** as the consensus API becomes unavailable.

## Likelihood Explanation
The likelihood is **LOW to MEDIUM** and depends on specific timing and system conditions:

**Conditions Required for Exploitation:**
1. A new block must be inserted while blocks are being committed concurrently
2. The blocks in the window must be old enough (beyond the 100-block pruned buffer threshold) to be removed from memory
3. The race window timing must align such that pruning occurs between creating the OrderedBlockWindow and calling `blocks()`

**Scenarios That Increase Likelihood:**
- Network delays causing blocks to arrive out of order
- Validators catching up after being offline or experiencing network partitions
- High block production rates that fill the pruned block buffer rapidly
- Concurrent commit operations while processing incoming blocks

**Scenarios That Decrease Likelihood:**
- Low-latency networks with fast block propagation
- Small window sizes (4-8 blocks typical)
- Low block production rates keeping the pruned buffer below capacity

While not trivially exploitable, this is a latent bug that can manifest under adverse network conditions or operational stress, making it a legitimate reliability concern for production validators.

## Recommendation
**Solution**: Hold the lock while accessing the OrderedBlockWindow blocks, or convert to strong references before releasing the lock.

**Option 1 - Hold Read Lock During Access** (Minimal Change):
```rust
pub async fn insert_block(&self, block: Block) -> anyhow::Result<Arc<PipelinedBlock>> {
    if let Some(existing_block) = self.get_block(block.id()) {
        return Ok(existing_block);
    }
    ensure!(
        self.inner.read().ordered_root().round() < block.round(),
        "Block with old round"
    );

    let (block_window, blocks_for_prefetch) = {
        let guard = self.inner.read();
        let block_window = guard.get_ordered_block_window(&block, self.window_size)?;
        // Extract blocks while holding the lock
        let blocks = block_window.blocks();
        (block_window, blocks)
    }; // Lock released here

    for block in blocks_for_prefetch {
        if let Some(payload) = block.payload() {
            self.payload_manager.prefetch_payload_data(
                payload,
                block.author().expect("Payload block must have author"),
                block.timestamp_usecs(),
            );
        }
    }

    let pipelined_block = PipelinedBlock::new_ordered(block, block_window);
    self.insert_block_inner(pipelined_block).await
}
```

**Option 2 - Use Strong References in OrderedBlockWindow** (More Robust):
Modify `OrderedBlockWindow` to store `Arc<PipelinedBlock>` instead of `Weak<PipelinedBlock>`, eliminating the upgrade operation entirely. This ensures blocks remain valid for the lifetime of the window.

**Additional Fix Required:**
The same vulnerability exists in `find_window_root()` which also calls `pipelined_blocks()` without lock protection: [7](#0-6) 

This function should be modified similarly to ensure blocks remain valid during access.

## Proof of Concept
```rust
#[tokio::test]
async fn test_insert_block_race_condition_panic() {
    use std::sync::Arc;
    use std::sync::atomic::{AtomicBool, Ordering};
    use tokio::time::Duration;
    
    // Setup: Create a BlockStore with a small max_pruned_blocks_in_mem
    let (block_store, mut block_tree) = setup_block_store_with_config(
        /* max_pruned_blocks_in_mem */ 5,
        /* window_size */ Some(3),
    );
    
    // Create a chain of blocks
    let mut blocks = vec![];
    for i in 1..=20 {
        let block = create_block(i, blocks.last().map(|b: &Block| b.id()));
        blocks.push(block);
    }
    
    // Insert and commit blocks up to block 15
    for block in blocks.iter().take(15) {
        block_store.insert_block(block.clone()).await.unwrap();
        if block.round() % 3 == 0 {
            // Commit every 3rd block to advance commit root
            let qc = create_qc_for_block(block);
            block_store.send_for_execution(qc.into_wrapped_ledger_info()).await.unwrap();
        }
    }
    
    // Now create a scenario where:
    // 1. Thread A starts inserting block 20 (which references blocks 17-19 in window)
    // 2. Thread B commits blocks aggressively, filling pruned buffer
    // 3. This causes blocks 17-19 to be removed while Thread A's OrderedBlockWindow holds Weak refs
    
    let block_store_clone = block_store.clone();
    let block_20 = blocks[19].clone();
    
    // Thread A: Insert block (will hit race condition)
    let handle_a = tokio::spawn(async move {
        // Add small delay to ensure Thread B can execute
        tokio::time::sleep(Duration::from_millis(10)).await;
        block_store_clone.insert_block(block_20).await
    });
    
    // Thread B: Aggressively commit to prune old blocks
    for i in 15..19 {
        let block = &blocks[i];
        block_store.insert_block(block.clone()).await.unwrap();
        let qc = create_qc_for_block(block);
        block_store.send_for_execution(qc.into_wrapped_ledger_info()).await.unwrap();
        tokio::time::sleep(Duration::from_millis(5)).await;
    }
    
    // Thread A should panic with:
    // "Block with id: {} not found during upgrade in OrderedBlockWindow::blocks()"
    let result = handle_a.await;
    assert!(result.is_err() || result.unwrap().is_err(), 
            "Expected panic or error due to race condition");
}
```

**Note**: This test demonstrates the race condition conceptually. In practice, triggering the exact timing requires careful orchestration of concurrent operations, potentially with additional synchronization primitives or stress testing to increase probability.

## Notes
This vulnerability is a classic concurrency bug where the code assumes that data accessed after releasing a lock will remain valid. The use of Weak pointers without proper locking creates a window for concurrent modifications to invalidate assumptions about data availability. While the race window is small, the consequences (node crash) are severe enough to warrant fixing, especially in production consensus systems where availability is critical.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L421-425)
```rust
        let block_window = self
            .inner
            .read()
            .get_ordered_block_window(&block, self.window_size)?;
        let blocks = block_window.blocks();
```

**File:** consensus/src/block_storage/block_store.rs (L475-489)
```rust
            let callback = Box::new(
                move |finality_proof: WrappedLedgerInfo,
                      commit_decision: LedgerInfoWithSignatures| {
                    if let Some(tree) = block_tree.upgrade() {
                        tree.write().commit_callback(
                            storage,
                            id,
                            round,
                            finality_proof,
                            commit_decision,
                            window_size,
                        );
                    }
                },
            );
```

**File:** consensus/src/block_storage/block_tree.rs (L264-305)
```rust
    pub fn get_ordered_block_window(
        &self,
        block: &Block,
        window_size: Option<u64>,
    ) -> anyhow::Result<OrderedBlockWindow> {
        // Block round should never be less than the commit root round
        ensure!(
            block.round() >= self.commit_root().round(),
            "Block round {} is less than the commit root round {}, cannot get_ordered_block_window",
            block.round(),
            self.commit_root().round()
        );

        // window_size is None only if execution pool is turned off
        let Some(window_size) = window_size else {
            return Ok(OrderedBlockWindow::empty());
        };
        let round = block.round();
        let window_start_round = calculate_window_start_round(round, window_size);
        let window_size = round - window_start_round + 1;
        ensure!(window_size > 0, "window_size must be greater than 0");

        let mut window = vec![];
        let mut current_block = block.clone();

        // Add each block to the window until you reach the start round
        while !current_block.is_genesis_block()
            && current_block.quorum_cert().certified_block().round() >= window_start_round
        {
            if let Some(current_pipelined_block) = self.get_block(&current_block.parent_id()) {
                current_block = current_pipelined_block.block().clone();
                window.push(current_pipelined_block);
            } else {
                bail!("Parent block not found for block {}", current_block.id());
            }
        }

        // The window order is lower round -> higher round
        window.reverse();
        ensure!(window.len() < window_size as usize);
        Ok(OrderedBlockWindow::new(window))
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L467-489)
```rust
    pub(super) fn find_window_root(
        &self,
        block_to_commit_id: HashValue,
        window_size: Option<u64>,
    ) -> HashValue {
        // Window Size is None only if execution pool is off
        if let Some(window_size) = window_size {
            assert_ne!(window_size, 0, "Window size must be greater than 0");
        }

        // Try to get the block, then the ordered window, then the first block's parent ID
        let block = self
            .get_block(&block_to_commit_id)
            .expect("Block not found");
        let ordered_block_window = self
            .get_ordered_block_window(block.block(), window_size)
            .expect("Ordered block window not found");
        let pipelined_blocks = ordered_block_window.pipelined_blocks();

        // If the first block is None, it falls back on the current block as the window root
        let window_root_block = pipelined_blocks.first().unwrap_or(&block);
        window_root_block.id()
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L496-510)
```rust
    pub(super) fn process_pruned_blocks(&mut self, mut newly_pruned_blocks: VecDeque<HashValue>) {
        counters::NUM_BLOCKS_IN_TREE.sub(newly_pruned_blocks.len() as i64);
        // The newly pruned blocks are pushed back to the deque pruned_block_ids.
        // In case the overall number of the elements is greater than the predefined threshold,
        // the oldest elements (in the front of the deque) are removed from the tree.
        self.pruned_block_ids.append(&mut newly_pruned_blocks);
        if self.pruned_block_ids.len() > self.max_pruned_blocks_in_mem {
            let num_blocks_to_remove = self.pruned_block_ids.len() - self.max_pruned_blocks_in_mem;
            for _ in 0..num_blocks_to_remove {
                if let Some(id) = self.pruned_block_ids.pop_front() {
                    self.remove_block(id);
                }
            }
        }
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L136-150)
```rust
pub struct OrderedBlockWindow {
    /// `block_id` (HashValue) helps with logging in the unlikely case there are issues upgrading
    /// the `Weak` pointer (we can use `block_id`)
    blocks: Vec<(HashValue, Weak<PipelinedBlock>)>,
}

impl OrderedBlockWindow {
    pub fn new(blocks: Vec<Arc<PipelinedBlock>>) -> Self {
        Self {
            blocks: blocks
                .iter()
                .map(|x| (x.id(), Arc::downgrade(x)))
                .collect::<Vec<(HashValue, Weak<PipelinedBlock>)>>(),
        }
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L161-175)
```rust
    pub fn blocks(&self) -> Vec<Block> {
        let mut blocks: Vec<Block> = vec![];
        for (block_id, block) in self.blocks.iter() {
            let upgraded_block = block.upgrade();
            if let Some(block) = upgraded_block {
                blocks.push(block.block().clone())
            } else {
                panic!(
                    "Block with id: {} not found during upgrade in OrderedBlockWindow::blocks()",
                    block_id
                )
            }
        }
        blocks
    }
```
