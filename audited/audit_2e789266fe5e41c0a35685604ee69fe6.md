# Audit Report

## Title
Stall State Desynchronization in BlockSTMv2 Execution Queue Management

## Summary
A race condition exists in the BlockSTMv2 scheduler's `try_increase_executed_once_max_idx` function where concurrent `add_stall()` operations can cause a transaction to remain in the execution queue despite being stalled, violating the stall mechanism's intended behavior of deferring stalled transaction execution.

## Finding Description

The vulnerability occurs in the interaction between `try_increase_executed_once_max_idx` [1](#0-0)  and the stall management functions in `scheduler_status.rs`.

The critical race window exists because `pending_scheduling_and_not_stalled` [2](#0-1)  performs a lock-free read of `num_stalls` via `is_stalled()` [3](#0-2) , releases the status lock, and then the transaction is inserted into the execution queue at [4](#0-3)  without holding any lock.

Between these operations, a concurrent `add_stall()` call [5](#0-4)  can:
1. Atomically increment `num_stalls` from 0 to 1 via `fetch_add` [6](#0-5) 
2. Acquire the status lock
3. Attempt to remove the transaction from the schedule [7](#0-6)  (no-op since not yet inserted)
4. Release the lock

After this, the transaction is inserted into the queue despite `num_stalls = 1` (stalled state). When a worker pops this transaction via `next_task` [8](#0-7) , the `start_executing` call [9](#0-8)  succeeds because the status is `PendingScheduling`, without any check of the stall state.

**Exploitation Sequence:**
1. Transaction `idx` is in `PendingScheduling` with `num_stalls=0`
2. Thread A (`try_increase_executed_once_max_idx`): Checks and sees not stalled
3. Thread B (`add_stall`): Increments `num_stalls` to 1, acquires lock, calls `remove_from_schedule` (no-op), releases
4. Thread A: Inserts `idx` into execution queue
5. Worker: Pops and executes transaction despite `num_stalls=1`

## Impact Explanation

**Severity Assessment: Medium**

While the stall mechanism is documented as "best-effort" [10](#0-9) , this race condition represents a state inconsistency that can lead to:

1. **Performance Degradation**: Stalled transactions are executed when they shouldn't be, potentially triggering cascading aborts that the stall mechanism was designed to prevent [11](#0-10) 

2. **Validator Resource Waste**: Unnecessary re-executions consume validator computational resources

However, this does NOT directly cause:
- Consensus violations (execution remains deterministic)
- Loss of funds
- State corruption
- Network partition

The developers acknowledge this area needs careful handling, as evidenced by comments at [12](#0-11) , though their reasoning assumes atomicity that doesn't exist in the implementation.

## Likelihood Explanation

**Likelihood: High**

This race condition can occur naturally during normal parallel block execution when:
- Multiple transactions have dependency relationships
- Stalls are being propagated through the dependency graph
- The `executed_once_max_idx` watermark is advancing
- Multiple worker threads are executing concurrently

No malicious intent is required - it's an inherent timing issue in concurrent operations. The race window is small but non-negligible given the high frequency of stall operations during block execution.

## Recommendation

**Fix 1: Atomic Check-and-Insert**
Hold the status lock during both the stall check and queue insertion:

```rust
// In scheduler_v2.rs try_increase_executed_once_max_idx
if self.txn_statuses.ever_executed(idx) {
    execution_queue_manager
        .executed_once_max_idx
        .store(idx + 1, Ordering::Relaxed);
    
    let status = &self.txn_statuses.get_status(idx);
    let guard = status.status_with_incarnation.lock();
    if guard.pending_scheduling().is_some() && !status.is_stalled() {
        execution_queue_manager.execution_queue.lock().insert(idx);
    }
    idx += 1;
}
```

**Fix 2: Re-check in start_executing**
Add stall state validation before transitioning to Executing:

```rust
// In scheduler_status.rs to_executing
fn to_executing(...) -> Result<Option<Incarnation>, PanicError> {
    let status = &self.statuses[txn_idx as usize];
    
    // Check if stalled before allowing execution
    if status.is_stalled() {
        return Ok(None); // Refuse to execute if stalled
    }
    
    let ret = status_guard.start_executing();
    // ... rest of function
}
```

## Proof of Concept

```rust
#[test]
fn test_stall_desync_race() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let statuses = Arc::new(ExecutionStatuses::new(10));
    let barrier = Arc::new(Barrier::new(2));
    
    // Setup: transaction 5 in PendingScheduling, not stalled, incarnation=1
    let status_5 = statuses.get_status_mut(5);
    *status_5.status_with_incarnation.lock() = 
        StatusWithIncarnation::new_for_test(SchedulingStatus::PendingScheduling, 1);
    status_5.num_stalls.store(0, Ordering::SeqCst);
    
    // Update executed_once_max_idx to 5
    statuses.get_execution_queue_manager()
        .executed_once_max_idx.store(5, Ordering::Relaxed);
    
    let statuses1 = Arc::clone(&statuses);
    let barrier1 = Arc::clone(&barrier);
    
    // Thread 1: Simulates try_increase_executed_once_max_idx
    let handle1 = thread::spawn(move || {
        // Check pending_scheduling_and_not_stalled
        let is_pending = statuses1.pending_scheduling_and_not_stalled(5);
        assert!(is_pending, "Should see as not stalled");
        
        barrier1.wait(); // Synchronize with thread 2
        std::thread::sleep(std::time::Duration::from_millis(10)); // Let thread 2 add stall
        
        // Insert into queue (simulated)
        if is_pending {
            statuses1.get_execution_queue_manager().execution_queue.lock().insert(5);
        }
    });
    
    let statuses2 = Arc::clone(&statuses);
    let barrier2 = Arc::clone(&barrier);
    
    // Thread 2: add_stall while thread 1 is between check and insert
    let handle2 = thread::spawn(move || {
        barrier2.wait(); // Wait for thread 1 to check
        
        // Add stall - should mark transaction as stalled
        let result = statuses2.add_stall(5).unwrap();
        assert!(result, "Should successfully add first stall");
    });
    
    handle1.join().unwrap();
    handle2.join().unwrap();
    
    // Verify desync: transaction is in queue but stalled
    let in_queue = statuses.get_execution_queue_manager()
        .execution_queue.lock().contains(&5);
    let is_stalled = statuses.get_status(5).is_stalled();
    
    assert!(in_queue, "Transaction should be in queue");
    assert!(is_stalled, "Transaction should be stalled");
    // This combination violates the invariant!
}
```

**Notes:**
- The race is timing-dependent and may require multiple runs to reproduce reliably
- The desynchronization window is between the unlocked read in `pending_scheduling_and_not_stalled` and the subsequent queue insertion
- Fix 1 provides stronger consistency guarantees by making the check-and-insert atomic
- Fix 2 provides defense-in-depth by catching stalled transactions at execution time

### Citations

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L818-821)
```rust
        if let Some(txn_idx) = self.txn_statuses.get_execution_queue_manager().pop_next() {
            if let Some(incarnation) = self.start_executing(txn_idx)? {
                return Ok(TaskKind::Execute(txn_idx, incarnation));
            }
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1282-1323)
```rust
    fn try_increase_executed_once_max_idx(&self, txn_idx: TxnIndex) {
        let execution_queue_manager = self.txn_statuses.get_execution_queue_manager();
        // Synchronization is provided by the ordering of [SchedulerV2::finish_execution]
        // updating the transaction inner status (under lock), and the ever_executed
        // check below, which also acquires the lock. In particular, ordering is as follows:
        // (a) finish_execution(idx) with idx lock -> executed_idx == txn_idx check
        // (b) increment executed_idx to txn_idx -> ever_executed check under lock
        // Note that (classic flags principle), in case when ever_executed check fails,
        // executed_idx == txn_idx check is guaranteed to succeed.
        if execution_queue_manager
            .executed_once_max_idx
            .load(Ordering::Relaxed)
            == txn_idx
        {
            let mut idx = txn_idx;
            while idx < self.num_txns && self.txn_statuses.ever_executed(idx) {
                // A successful check of ever_executed holds idx-th status lock and follows an
                // increment of executed_once_max_idx to idx in the prior loop iteration.
                execution_queue_manager
                    .executed_once_max_idx
                    .store(idx + 1, Ordering::Relaxed);

                // Note: for first re-execution, [ExecutionQueueManager::add_to_schedule] adds
                // an index to the execution queue only once executed_once_max_idx >= idx.
                // We need to ensure that re-execution is not missed due to a concurrency
                // race where after the index is added to the execution queue below, it gets
                // removed by [ExecutionStatuses::add_stall] but not re-added due to the
                // aforementioned check after [ExecutionStatuses::remove_stall]. This holds
                // because stall can only remove idx from the execution queue while holding
                // the idx-th status lock, which would have to be after ever_executed, and
                // the corresponding remove_stall would hence acquire the same lock even later,
                // and hence be guaranteed to observe executed_once_max_idx >= idx.

                // TODO(BlockSTMv2): Audit / should we keep ever_executed lock instead of re-acquiring.
                if self.txn_statuses.pending_scheduling_and_not_stalled(idx) {
                    execution_queue_manager.execution_queue.lock().insert(idx);
                }

                idx += 1;
            }
        }
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L101-106)
```rust
1. Purpose:
   - Records that a transaction has dependencies that are more likely to cause re-execution
   - Can be used to:
     a) Avoid scheduling transactions for re-execution until stalls are removed
     b) Guide handling when another transaction observes a dependency during execution
   - Helps constrain optimistic concurrency by limiting cascading aborts
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L108-111)
```rust
2. Behavior:
   - Best-effort approach that allows flexibility in concurrency scenarios, but such that
     high-priority transactions may still be re-executed even in stalled state

```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L363-405)
```rust
    pub(crate) fn add_stall(&self, txn_idx: TxnIndex) -> Result<bool, PanicError> {
        let status = &self.statuses[txn_idx as usize];
        if status.num_stalls.fetch_add(1, Ordering::SeqCst) == 0 {
            // Acquire write lock for (non-monitor) shortcut modifications.
            let status_guard = status.status_with_incarnation.lock();

            let dependency_status =
                DependencyStatus::from_u8(status.dependency_shortcut.load(Ordering::Relaxed))?;

            match (status_guard.pending_scheduling(), dependency_status) {
                (Some(0), DependencyStatus::ShouldDefer) => {
                    // Adding a stall requires being recorded in aborted dependencies in scheduler_v2,
                    // which in turn only happens in the scheduler after a successful abort (that must
                    // increment the incarnation of the status).
                    return Err(code_invariant_error("0-th incarnation in add_stall"));
                },
                (Some(_), DependencyStatus::ShouldDefer) => {
                    self.execution_queue_manager.remove_from_schedule(txn_idx);
                    // Shortcut not affected.
                },
                (Some(_), DependencyStatus::IsSafe | DependencyStatus::WaitForExecution) => {
                    return Err(code_invariant_error(
                        "Inconsistent status and dependency shortcut in add_stall",
                    ));
                },
                (None, DependencyStatus::IsSafe) => {
                    // May not update IsSafe dependency status at an incorrect time in the future
                    // (i.e. ABA), as observing num_stalls = 0 under status is required to set
                    // IsSafe status, but impossible until the corresponding remove_stall (that
                    // starts only after add_stall finishes).
                    status
                        .dependency_shortcut
                        .store(DependencyStatus::ShouldDefer as u8, Ordering::Relaxed);
                },
                (None, DependencyStatus::WaitForExecution | DependencyStatus::ShouldDefer) => {
                    // Executing or aborted: shortcut not affected.
                },
            }

            return Ok(true);
        }
        Ok(false)
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L508-516)
```rust
    pub(crate) fn start_executing(
        &self,
        txn_idx: TxnIndex,
    ) -> Result<Option<Incarnation>, PanicError> {
        let status_guard = &mut *self.statuses[txn_idx as usize]
            .status_with_incarnation
            .lock();
        self.to_executing(txn_idx, status_guard)
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L744-748)
```rust
    pub(crate) fn pending_scheduling_and_not_stalled(&self, txn_idx: TxnIndex) -> bool {
        let status = &self.statuses[txn_idx as usize];
        let guard = status.status_with_incarnation.lock();
        guard.pending_scheduling().is_some() && !status.is_stalled()
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L959-961)
```rust
    pub(crate) fn is_stalled(&self) -> bool {
        self.num_stalls.load(Ordering::Relaxed) > 0
    }
```
