# Audit Report

## Title
SafetyData Rollback Attack: OnDiskStorage Lack of Integrity Protection Enables BFT Consensus Safety Violation

## Summary
The `OnDiskStorage` backend for SafetyRules provides no integrity protection, cryptographic verification, or monotonicity checks on persisted `SafetyData`. An attacker with file system access to a validator node can perform a rollback attack by replacing the current `SafetyData` with an older version containing lower `last_voted_round` values, bypassing the fundamental "vote once per round" safety rule and enabling double-voting/equivocation attacks that violate BFT consensus safety guarantees.

## Finding Description
The AptosBFT consensus protocol depends on SafetyRules to enforce voting invariants, particularly the first voting rule: a validator must never vote twice in the same round. This state is maintained in `SafetyData` which tracks `last_voted_round`, `preferred_round`, and other critical consensus state. [1](#0-0) 

When validators use `OnDiskStorage` (which is allowed for mainnet validators and used in production configs), this critical safety data is stored as plaintext JSON with no integrity protection: [2](#0-1) [3](#0-2) 

The storage includes a `last_update` timestamp in `GetResponse`, but SafetyRules completely ignores this field when reading SafetyData: [4](#0-3) [5](#0-4) 

When checking voting rules, the code only validates that the new round is greater than `last_voted_round` from storage, with no verification that this value hasn't been rolled back: [6](#0-5) 

The configuration sanitizer allows `OnDiskStorage` for mainnet validators (only blocking `InMemoryStorage`): [7](#0-6) 

**Attack Path:**
1. Validator with `OnDiskStorage` backend votes in round N, persisting `{last_voted_round: N}` to disk
2. Attacker gains file system access (via SSH compromise, container escape, misconfigured permissions, etc.)
3. Attacker saves a copy of the SafetyData file when `last_voted_round = N`
4. Validator continues operating normally, voting in rounds N+1, N+2, ..., N+K
5. Attacker replaces current SafetyData file with the saved copy (`last_voted_round = N`)
6. Validator restarts or safety data cache is cleared
7. Validator reads corrupted SafetyData with rolled-back state
8. Validator receives vote proposal for round N+1
9. Safety check passes: `round(N+1) > last_voted_round(N)` âœ“
10. Validator signs and broadcasts vote for round N+1 (which it already voted on)
11. **Result: Double-voting/equivocation** - validator has now voted twice on the same round with potentially different votes

## Impact Explanation
**Severity: CRITICAL** (per Aptos Bug Bounty: up to $1,000,000)

This vulnerability breaks **Consensus Safety** (Invariant #2), which is the most critical security guarantee of any BFT consensus protocol. Specifically:

1. **Equivocation/Double-Voting**: A validator votes multiple times in the same round, potentially with conflicting votes. This is the exact behavior BFT consensus is designed to prevent.

2. **Chain Split Risk**: If multiple validators are compromised and made to double-vote, the network could experience conflicting committed blocks, potentially requiring a hard fork to resolve.

3. **Validator Slashing**: The compromised validator's double-vote can be proven cryptographically and should result in slashing, but the damage to consensus safety has already occurred.

4. **Network Partition**: Under Byzantine conditions with multiple compromised nodes, this could lead to non-recoverable network partition.

This qualifies as "Consensus/Safety violations" which is explicitly listed as Critical severity in the bug bounty program.

## Likelihood Explanation
**Likelihood: MEDIUM to HIGH**

**Factors increasing likelihood:**
- Production configurations use `OnDiskStorage`: [8](#0-7) 

- File system access can be obtained through: misconfigured file permissions, container escape vulnerabilities, SSH key compromise, supply chain attacks on validator infrastructure, insider threats from hosting providers

- No cryptographic or technical barriers prevent the attack once file access is gained

- The README explicitly warns against production use, but the config sanitizer allows it: [9](#0-8) 

**Factors reducing likelihood:**
- Requires file system access to validator node (not remotely exploitable)
- Validator operators should use proper OS-level security controls
- VaultStorage backend is available and provides better security

## Recommendation

**Short-term mitigations:**

1. **Enforce VaultStorage for mainnet validators** - Update the config sanitizer to reject `OnDiskStorage` for mainnet: [7](#0-6) 

Add additional check:
```rust
if chain_id.is_mainnet() 
    && node_type.is_validator() 
    && matches!(safety_rules_config.backend, SecureBackend::OnDiskStorage(_)) 
{
    return Err(Error::ConfigSanitizerFailed(
        sanitizer_name,
        "OnDiskStorage should not be used for mainnet validators - use Vault instead!".to_string(),
    ));
}
```

2. **Add file permissions** - For OnDiskStorage used in testing/dev, set restrictive Unix permissions (0600): [10](#0-9) 

**Long-term fixes:**

3. **Implement integrity protection** - Add HMAC or signature to SafetyData writes, verify on reads

4. **Validate monotonicity** - Check that `last_update` timestamp is strictly increasing and `last_voted_round` never decreases

5. **Add secure versioning** - Include a monotonic counter with each SafetyData write, reject reads with lower counter values

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_safety_data_rollback_attack() {
    use aptos_secure_storage::{KVStorage, OnDiskStorage, Storage};
    use aptos_temppath::TempPath;
    use consensus::safety_rules::SafetyRules;
    use consensus_types::safety_data::SafetyData;
    
    // Setup validator with OnDiskStorage
    let temp_path = TempPath::new();
    let mut storage = Storage::from(OnDiskStorage::new(temp_path.path().to_path_buf()));
    
    // Initialize with SafetyData at round 10
    let initial_data = SafetyData::new(1, 10, 9, 9, None, 0);
    storage.set("safety_data", initial_data.clone()).unwrap();
    
    // Simulate validator voting to round 20
    let updated_data = SafetyData::new(1, 20, 19, 19, None, 0);
    storage.set("safety_data", updated_data.clone()).unwrap();
    
    // Attacker copies the file at round 10 and replaces current file
    std::fs::copy(
        temp_path.path(),
        temp_path.path().with_extension("backup")
    ).unwrap();
    
    // Later, attacker replaces current state with backup
    std::fs::copy(
        temp_path.path().with_extension("backup"),
        temp_path.path()
    ).unwrap();
    
    // Validator reads rolled-back data
    let rolled_back: SafetyData = storage.get("safety_data").unwrap().value;
    
    // Verify rollback succeeded
    assert_eq!(rolled_back.last_voted_round, 10); // Should be 20 but is 10!
    
    // Now validator can vote again on rounds 11-20, violating safety
    // A proper safety check would reject this, but the code only checks:
    // round > last_voted_round, which now passes for round 11 (11 > 10)
    assert!(11 > rolled_back.last_voted_round); // VULNERABILITY: This passes!
    
    println!("VULNERABILITY CONFIRMED: Validator can double-vote on rounds 11-20");
}
```

**Notes:**
- The vulnerability exists specifically in the `OnDiskStorage` backend, which lacks integrity protection despite being used in production configurations
- While the security question asks about `SecureStorageMissingDataError`, the actual critical vulnerability is **data corruption/rollback** (not deletion), which bypasses safety rules rather than triggering errors
- Data **deletion** causes denial of service (operations fail) but not safety violations - the rollback attack is the critical security issue
- VaultStorage backend with proper access controls would mitigate this vulnerability, but the current sanitizer allows the vulnerable OnDiskStorage for mainnet validators

### Citations

**File:** consensus/consensus-types/src/safety_data.rs (L8-21)
```rust
/// Data structure for safety rules to ensure consensus safety.
#[derive(Debug, Deserialize, Eq, PartialEq, Serialize, Clone, Default)]
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** secure/storage/src/on_disk.rs (L16-22)
```rust
/// OnDiskStorage represents a key value store that is persisted to the local filesystem and is
/// intended for single threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission
/// checks and simply offers a proof of concept to unblock building of applications without more
/// complex data stores. Internally, it reads and writes all data to a file, which means that it
/// must make copies of all key material which violates the code base. It violates it because
/// the anticipation is that data stores would securely handle key material. This should not be used
/// in production.
```

**File:** secure/storage/src/on_disk.rs (L53-70)
```rust
    fn read(&self) -> Result<HashMap<String, Value>, Error> {
        let mut file = File::open(&self.file_path)?;
        let mut contents = String::new();
        file.read_to_string(&mut contents)?;
        if contents.is_empty() {
            return Ok(HashMap::new());
        }
        let data = serde_json::from_str(&contents)?;
        Ok(data)
    }

    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** secure/storage/src/kv_storage.rs (L54-63)
```rust
/// A container for a get response that contains relevant metadata and the value stored at the
/// given key.
#[derive(Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(tag = "data")]
pub struct GetResponse<T> {
    /// Time since Unix Epoch in seconds.
    pub last_update: u64,
    /// Value stored at the provided key
    pub value: T,
}
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L134-148)
```rust
    pub fn safety_data(&mut self) -> Result<SafetyData, Error> {
        if !self.enable_cached_safety_data {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            return self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
        }

        if let Some(cached_safety_data) = self.cached_safety_data.clone() {
            Ok(cached_safety_data)
        } else {
            let _timer = counters::start_timer("get", SAFETY_DATA);
            let safety_data: SafetyData = self.internal_store.get(SAFETY_DATA).map(|v| v.value)?;
            self.cached_safety_data = Some(safety_data.clone());
            Ok(safety_data)
        }
    }
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```

**File:** config/src/config/safety_rules_config.rs (L86-96)
```rust
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }
```

**File:** docker/compose/aptos-node/validator.yaml (L11-13)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** secure/storage/README.md (L37-42)
```markdown
- `OnDisk`: Similar to InMemory, the OnDisk secure storage implementation provides another
useful testing implementation: an on-disk storage engine, where the storage backend is
implemented using a single file written to local disk. In a similar fashion to the in-memory
storage, on-disk should not be used in production environments as it provides no security
guarantees (e.g., encryption before writing to disk). Moreover, OnDisk storage does not
currently support concurrent data accesses.
```
