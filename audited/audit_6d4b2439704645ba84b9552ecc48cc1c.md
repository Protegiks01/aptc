# Audit Report

## Title
Unbounded Memory Allocation in API Resource Expansion Leading to API Server DoS

## Summary
The `/accounts/:address/resources` API endpoint lacks proper bounds checking when expanding resource groups into individual resources. An attacker can create resource groups containing thousands of resources each, and although pagination limits the number of top-level items to 9,999, resource group expansion can multiply this to millions of resources, causing unbounded memory allocation and API server crashes.

## Finding Description

The vulnerability exists in the resource retrieval flow when the API endpoint `/accounts/:address/resources` is queried: [1](#0-0) 

The `try_into_resources()` function accepts an iterator and processes all items without any size limit. This function is called from the accounts endpoint: [2](#0-1) 

The pagination limit is enforced here with `max_account_resources_page_size` (default: 9,999): [3](#0-2) 

However, the critical vulnerability occurs in `get_resources_by_pagination()` where resource groups are expanded: [4](#0-3) 

**Attack Flow:**

1. Attacker creates an account and uses Move transactions to populate it with resource groups
2. Each resource group can contain many resources (limited only by 1MB BCS serialization size during write, not by resource count)
3. Resource groups are defined as: [5](#0-4) 

4. The only resource count limit that exists is for delayed fields (10 per resource): [6](#0-5) 

5. Regular resources (non-aggregator) have no per-group count limit, only a 1MB size limit during writes: [7](#0-6) 

6. When the API endpoint is queried, up to 9,999 resource groups are retrieved, then expanded without checking the expanded count
7. If each resource group contains 1,000 small resources (e.g., 100 bytes each = 100KB total per group, well under 1MB limit), the total becomes 9,999,000 resources
8. All expanded resources are loaded into memory and converted to JSON format simultaneously

**Invariant Broken:**
This violates the documented invariant: "Resource Limits: All operations must respect gas, storage, and computational limits." The API read operation does not enforce memory/computational limits after resource group expansion.

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program criteria:
- **"API crashes"** - The unbounded memory allocation can crash API servers
- **"Validator node slowdowns"** - If API runs on validator nodes, this causes performance degradation

The impact includes:
- Denial of service attacks against API infrastructure
- API server crashes requiring restart
- Degraded performance for all API users
- Potential cascade failure if multiple API servers are targeted

While this doesn't directly affect consensus or blockchain state, it severely impacts the availability of the API layer which is critical for user interactions, exchanges, wallets, and other services.

## Likelihood Explanation

**Likelihood: HIGH**

The attack is highly feasible because:
- **Low Cost to Setup**: Attacker only needs to pay gas/storage costs once to create the malicious resource groups
- **Persistent Attack**: Once created, the resource groups remain on-chain indefinitely
- **Repeatable Queries**: Attacker can repeatedly query the endpoint with zero cost
- **No Special Privileges**: Any account can create resource groups
- **Practical Resource Counts**: Creating 1,000 small resources per group is realistic within the 1MB write limit
- **Easy Discovery**: The endpoint is publicly documented and widely used

The attack becomes more effective with multiple resource groups, as even legitimate-seeming accounts could be weaponized.

## Recommendation

Add a post-expansion limit check in `get_resources_by_pagination()` to ensure the total number of expanded resources doesn't exceed a reasonable threshold:

**Fix Location**: `api/src/context.rs` around lines 536-558

**Recommended Solution**:
1. Track the expanded resource count during resource group expansion
2. If the count exceeds a configured maximum (e.g., 10,000 or the original pagination limit), either:
   - Return an error indicating too many resources
   - Truncate the results and return a continuation cursor
   - Apply the limit to expanded resources, not just storage items

**Pseudocode for Fix**:
```rust
// After line 548 in context.rs
let kvs: Vec<(StructTag, Vec<u8>)> = kvs
    .into_iter()
    .map(|(tag, value)| {
        if converter.is_resource_group(&tag) {
            bcs::from_bytes::<ResourceGroup>(&value)
                .map(|map| map.into_iter().collect::<Vec<_>>())
                .map_err(|e| e.into())
        } else {
            Ok(vec![(tag, value)])
        }
    })
    .collect::<Result<Vec<Vec<(StructTag, Vec<u8>)>>>>()?
    .into_iter()
    .flatten()
    .collect();

// ADD THIS CHECK:
if kvs.len() > limit as usize {
    // Truncate to limit and compute proper next_key
    kvs.truncate(limit as usize);
    // Recompute next_key based on truncated position
}
```

Alternatively, count expanded resources during iteration and stop early if the limit is exceeded.

## Proof of Concept

**Step 1: Create Move Module with Resource Group**

```move
module attacker::resource_bomb {
    use std::signer;
    
    #[resource_group(scope = global)]
    struct BombContainer {}
    
    #[resource_group_member(group = attacker::resource_bomb::BombContainer)]
    struct Bomb0 has key { val: u64 }
    
    #[resource_group_member(group = attacker::resource_bomb::BombContainer)]
    struct Bomb1 has key { val: u64 }
    
    // ... Define Bomb2 through Bomb999 (1000 total resource types)
    
    public entry fun create_bomb(account: &signer) {
        move_to(account, Bomb0 { val: 1 });
        move_to(account, Bomb1 { val: 1 });
        // ... move_to for all 1000 bomb resources
    }
}
```

**Step 2: Execute Attack**

1. Deploy the module and execute `create_bomb()` transaction
2. Repeat to create multiple resource groups if possible
3. Query: `GET /v1/accounts/{attacker_address}/resources`
4. Observe API server memory consumption spike as it expands and processes all resources
5. With sufficient resource groups, the API server runs out of memory and crashes

**Expected Result**: API server experiences severe memory pressure or crashes when processing the expanded resources.

## Notes

This vulnerability specifically affects the API layer's resource reading mechanism. The write-time limit of 1MB per resource group is insufficient protection because:
- 1MB can contain thousands of small resources
- The limit is only checked during transaction execution, not during API reads
- Multiple resource groups compound the problem (9,999 groups Ã— 1,000 resources = 9,999,000 total)

The fix should enforce consistent limits between the number of items read from storage and the number of items returned after expansion, ensuring that resource group expansion doesn't bypass pagination limits.

### Citations

**File:** api/types/src/convert.rs (L85-91)
```rust
    pub fn try_into_resources<'b>(
        &self,
        data: impl Iterator<Item = (StructTag, &'b [u8])>,
    ) -> Result<Vec<MoveResource>> {
        data.map(|(typ, bytes)| self.inner.view_resource(&typ, bytes)?.try_into())
            .collect()
    }
```

**File:** api/src/accounts.rs (L449-462)
```rust
        let max_account_resources_page_size = self.context.max_account_resources_page_size();
        let (resources, next_state_key) = self
            .context
            .get_resources_by_pagination(
                self.address.into(),
                self.start.as_ref(),
                self.ledger_version,
                // Just use the max as the default
                determine_limit(
                    self.limit,
                    max_account_resources_page_size,
                    max_account_resources_page_size,
                    &self.latest_ledger_info,
                )? as u64,
```

**File:** config/src/config/api_config.rs (L100-100)
```rust
const DEFAULT_MAX_ACCOUNT_RESOURCES_PAGE_SIZE: u16 = 9999;
```

**File:** api/src/context.rs (L536-551)
```rust
        let kvs = kvs
            .into_iter()
            .map(|(tag, value)| {
                if converter.is_resource_group(&tag) {
                    // An error here means a storage invariant has been violated
                    bcs::from_bytes::<ResourceGroup>(&value)
                        .map(|map| map.into_iter().collect::<Vec<_>>())
                        .map_err(|e| e.into())
                } else {
                    Ok(vec![(tag, value)])
                }
            })
            .collect::<Result<Vec<Vec<(StructTag, Vec<u8>)>>>>()?
            .into_iter()
            .flatten()
            .collect();
```

**File:** api/types/src/move_types.rs (L35-35)
```rust
pub type ResourceGroup = BTreeMap<StructTag, Vec<u8>>;
```

**File:** third_party/move/move-vm/types/src/value_serde.rs (L50-65)
```rust
    // Temporarily limit the number of delayed fields per resource, until proper charges are
    // implemented.
    // TODO[agg_v2](clean):
    //   Propagate up, so this value is controlled by the gas schedule version.
    const MAX_DELAYED_FIELDS_PER_RESOURCE: usize = 10;

    /// Increments the delayed fields count, and checks if there are too many of them. If so, an
    /// error is returned.
    pub(crate) fn inc_and_check_delayed_fields_count(&self) -> PartialVMResult<()> {
        *self.delayed_fields_count.borrow_mut() += 1;
        if *self.delayed_fields_count.borrow() > Self::MAX_DELAYED_FIELDS_PER_RESOURCE {
            return Err(PartialVMError::new(StatusCode::TOO_MANY_DELAYED_FIELDS)
                .with_message("Too many Delayed fields in a single resource.".to_string()));
        }
        Ok(())
    }
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L68-72)
```rust
    fn for_feature_version_3() -> Self {
        const MB: u64 = 1 << 20;

        Self::new_impl(3, MB, u64::MAX, MB, 10 * MB, u64::MAX)
    }
```
