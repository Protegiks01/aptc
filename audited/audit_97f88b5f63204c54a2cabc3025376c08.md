# Audit Report

## Title
State Sync Failure Due to Overly Restrictive Empty Ledger Info Check

## Summary
The `save_ledger_infos()` function in `restore_utils.rs` contains an overly restrictive check that causes state synchronization to fail when syncing to a version within the same epoch. This prevents legitimate node synchronization operations and impacts network liveness.

## Finding Description

The vulnerability exists in the state sync finalization path. The complete execution flow is:

1. **Same-Epoch Detection**: During bootstrapping, when a node syncs to a target version within the current epoch (no epoch boundaries crossed), the bootstrapper correctly identifies this scenario and logs "No new epoch ending ledger infos to fetch! All peers are in the same epoch!" [1](#0-0) 

2. **Empty Vector Return**: The `all_epoch_ending_ledger_infos()` method returns an empty vector because the internal `new_epoch_ending_ledger_infos` BTreeMap contains no entries (no epoch boundaries were crossed). [2](#0-1) 

3. **Propagation Through State Sync**: When processing state values beyond genesis, this empty vector is retrieved and passed as `epoch_change_proofs` to `initialize_state_synchronizer()`. [3](#0-2) 

4. **Finalization Call**: The empty `epoch_change_proofs` is stored and eventually passed to `finalize_state_snapshot()` during snapshot finalization. [4](#0-3) 

5. **Database Write Attempt**: The `finalize_state_snapshot()` function calls `save_ledger_infos()` with the empty array and an existing batch parameter. [5](#0-4) 

6. **Failure Point**: The `save_ledger_infos()` function has an unconditional check that rejects empty arrays: `ensure!(!ledger_infos.is_empty(), "No LedgerInfos to save.")` [6](#0-5) 

This check causes the entire state sync operation to abort with "No LedgerInfos to save." error. The check was likely added to prevent panics in `update_latest_ledger_info()` which calls `ledger_infos.last().unwrap()` [7](#0-6) , but it prevents a legitimate scenario where no epoch changes occurred during the sync.

The issue is that when syncing within the same epoch, there are legitimately no epoch-ending ledger infos to save, and this should be handled gracefully rather than causing the entire operation to fail.

## Impact Explanation

**Medium Severity** - This vulnerability causes temporary liveness issues:

- **Node Synchronization Failure**: Nodes attempting to fast-sync to a version within the current epoch will fail and cannot catch up with the network until the next epoch boundary
- **Network Availability Impact**: During periods of low epoch turnover (epochs can span hours or days in Aptos), multiple nodes could be affected simultaneously
- **Operational Disruption**: Requires manual intervention or workarounds to restore affected nodes
- **No Consensus Violation**: Does not affect consensus safety, cannot enable fund theft, but impacts network health and node liveness

This aligns with Medium Severity criteria per Aptos bug bounty: "State inconsistencies requiring manual intervention" and "temporary liveness issues" - impacts network liveness without causing critical consensus or fund security issues.

## Likelihood Explanation

**High Likelihood** - This will occur in production under normal conditions:

- Epochs in Aptos can span many transactions (hours or days of network operation)
- State sync operations frequently occur within the same epoch during normal operation
- The bootstrapper code explicitly acknowledges this as a valid scenario with dedicated logging [8](#0-7) 
- No special attacker action required - happens naturally during normal node operation
- Affected nodes include: new validators joining mid-epoch, nodes recovering from downtime, archive nodes syncing

The execution path from same-epoch detection to failure is direct and unavoidable in the current implementation.

## Recommendation

Modify the `save_ledger_infos()` function to allow empty arrays, and update `update_latest_ledger_info()` to handle empty arrays gracefully:

```rust
// In restore_utils.rs, remove or modify the restrictive check at line 46
pub(crate) fn save_ledger_infos(
    ledger_metadata_db: &LedgerMetadataDb,
    ledger_infos: &[LedgerInfoWithSignatures],
    existing_batch: Option<&mut SchemaBatch>,
) -> Result<()> {
    // Allow empty arrays - it's valid when no epoch changes occurred
    if ledger_infos.is_empty() {
        return Ok(());
    }
    
    // Rest of the function remains unchanged
    // ...
}

// Update update_latest_ledger_info to handle empty arrays
pub(crate) fn update_latest_ledger_info(
    ledger_metadata_db: &LedgerMetadataDb,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    // Early return for empty arrays - nothing to update
    if ledger_infos.is_empty() {
        return Ok(());
    }
    
    // Rest of the function remains unchanged
    // ...
}
```

This allows the state sync operation to complete successfully when syncing within the same epoch, which is a legitimate and common scenario.

## Proof of Concept

The vulnerability can be triggered by:

1. Starting a node that needs to sync to a target version within the current epoch
2. The bootstrapper will detect that all peers are in the same epoch and not fetch new epoch-ending ledger infos
3. When state sync attempts to finalize the snapshot, it will fail at the `save_ledger_infos()` check

A test case would create a scenario where:
- Initial state: Node at version 1000, epoch 5
- Target state: Version 2000, still in epoch 5  
- Expected: Successful sync
- Actual: Failure with "No LedgerInfos to save." error

The execution path is deterministic and reproducible whenever a node syncs within the same epoch, which is a common operational scenario in Aptos.

### Citations

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L197-202)
```rust
    pub fn all_epoch_ending_ledger_infos(&self) -> Vec<LedgerInfoWithSignatures> {
        self.new_epoch_ending_ledger_infos
            .values()
            .cloned()
            .collect()
    }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L861-866)
```rust
        } else if self.verified_epoch_states.verified_waypoint() {
            info!(LogSchema::new(LogEntry::Bootstrapper).message(
                "No new epoch ending ledger infos to fetch! All peers are in the same epoch!"
            ));
            self.verified_epoch_states
                .set_fetched_epoch_ending_ledger_infos();
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L988-992)
```rust
            let epoch_change_proofs = if version_to_sync == GENESIS_TRANSACTION_VERSION {
                vec![ledger_info_to_sync.clone()] // Sync to genesis
            } else {
                self.verified_epoch_states.all_epoch_ending_ledger_infos() // Sync beyond genesis
            };
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1130-1136)
```rust
        .writer
        .finalize_state_snapshot(
            version,
            target_output_with_proof.clone(),
            epoch_change_proofs,
        )
        .map_err(|error| format!("Failed to finalize the state snapshot! Error: {:?}", error))?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L201-205)
```rust
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L46-46)
```rust
    ensure!(!ledger_infos.is_empty(), "No LedgerInfos to save.");
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L66-71)
```rust
        if li.ledger_info().epoch() > ledger_infos.last().unwrap().ledger_info().epoch() {
            // No need to update latest ledger info.
            return Ok(());
        }
    }
    ledger_metadata_db.set_latest_ledger_info(ledger_infos.last().unwrap().clone());
```
