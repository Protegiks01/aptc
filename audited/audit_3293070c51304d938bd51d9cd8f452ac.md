# Audit Report

## Title
Transaction Loss During Validator Node Bootstrapping Due to Historical Commit Notifications

## Summary
BCS transactions submitted via the REST API during validator node synchronization can be permanently lost without error notification when the node processes historical blocks containing transactions with the same sender and sequence number, causing mempool to incorrectly remove the newly submitted transaction.

## Finding Description

During validator node bootstrapping, the REST API accepts transaction submissions while state sync is simultaneously processing historical blocks. This creates a critical race condition:

**The Flow:**

1. **API Accepts Transactions During Bootstrapping**: The REST API transaction submission endpoint does not check whether the node has completed bootstrapping before accepting transactions. [1](#0-0) 

2. **Mempool Validates Against Current State**: When transactions arrive, mempool fetches the current state checkpoint to validate sequence numbers. [2](#0-1) 

3. **State Sync Processes Historical Commits**: During bootstrapping, the storage synchronizer spawns a commit post-processor that notifies mempool about all historical committed transactions. [3](#0-2) 

4. **Mempool Removes Based on Sequence Numbers**: When mempool receives a commit notification, it updates the account sequence number and removes all transactions with sequence numbers below the committed one. [4](#0-3) 

5. **Transaction Removal Logic**: The `clean_committed_transactions_below_account_seq_num` method removes transactions with sequence numbers strictly less than the new account sequence number (which is committed_seq + 1). [5](#0-4) 

**Attack Scenario:**

1. Validator node restarts and begins bootstrapping from version 1000 to version 2000
2. At version 1000, account A has on-chain sequence number 50
3. User submits transaction A:50 via `/transactions` API endpoint
4. Mempool validates against state at version 1000, sees sequence number 50 is valid, returns HTTP 202 Accepted
5. Transaction A:50 is added to mempool
6. State sync continues processing and commits a chunk containing version 1500
7. At version 1500, there exists a historical transaction from account A with sequence number 50 (different transaction content)
8. Storage synchronizer sends commit notification for the historical transaction A:50
9. Mempool's `commit_transaction` updates account A's sequence to 51 and calls `clean_committed_transactions_below_account_seq_num(51)`
10. This removes ALL transactions with sequence < 51, including the user's newly submitted transaction A:50
11. User's transaction is permanently lost, never broadcast to consensus, never executed

**Why This Breaks Invariants:**
- Violates transaction delivery guarantees (accepted transaction never executed)
- Silent failure with no error returned to user after initial 202 Accepted
- Breaks state consistency as user sees acceptance but transaction vanishes

## Impact Explanation

This qualifies as **Medium Severity** per the Aptos bug bounty criteria:

- **Limited funds loss or manipulation**: Users submitting transactions during node bootstrapping may lose those transactions entirely, leading to failed transfers that they believe succeeded
- **State inconsistencies requiring intervention**: Mempool state becomes inconsistent with user expectations
- **Silent failure**: Users receive HTTP 202 Accepted response but transaction never executes
- **No notification mechanism**: Users have no way to detect the transaction was lost unless they actively query for it

The impact is not Critical because:
- It only affects transactions submitted during bootstrapping windows (temporary)
- It doesn't affect consensus safety or network-wide state
- Only impacts individual users, not the entire network

However, it's more severe than Low because:
- Leads to actual transaction loss (potential funds not transferred)
- Can happen during normal operations (node restarts, new validators joining)
- Affects real user transactions with financial implications

## Likelihood Explanation

**High Likelihood:**

1. **Common Scenario**: Validator nodes frequently bootstrap when:
   - New validators join the network
   - Existing validators restart after maintenance
   - Nodes recover from crashes or network issues
   - Nodes fall behind and need to catch up

2. **Default API State**: The `transaction_submission_enabled` flag defaults to true and is not automatically disabled during bootstrapping. [6](#0-5) 

3. **No Bootstrap Check**: Neither the API nor mempool checks `is_bootstrapped()` before accepting transactions - this check is only used for consensus execution, not API availability. [7](#0-6) 

4. **Mempool Runs During Bootstrapping**: Mempool is started before state sync completes initialization. [8](#0-7) 

5. **Window of Vulnerability**: The vulnerability window spans the entire bootstrapping period, which can be minutes to hours depending on how far behind the node is.

## Recommendation

**Immediate Fix**: Disable transaction submission API during bootstrapping by checking the bootstrap status before accepting transactions.

```rust
// In api/src/transactions.rs, modify submit_transaction:
async fn submit_transaction(
    &self,
    accept_type: AcceptType,
    data: SubmitTransactionPost,
) -> SubmitTransactionResult<PendingTransaction> {
    // Existing checks...
    if !self.context.node_config.api.transaction_submission_enabled {
        return Err(api_disabled("Submit transaction"));
    }
    
    // NEW: Check if node is bootstrapped
    if let Some(bootstrap_status) = &self.context.bootstrap_status {
        if !bootstrap_status.is_bootstrapped() {
            return Err(SubmitTransactionError::service_unavailable_with_code(
                "Node is currently bootstrapping and cannot accept transactions",
                AptosErrorCode::NodeBootstrapping,
                &ledger_info,
            ));
        }
    }
    
    // Rest of the existing code...
}
```

**Alternative Approaches:**

1. **Mempool-Level Protection**: Have mempool reject transactions when the node is bootstrapping
2. **State Version Tracking**: Only remove transactions from mempool if their validation state version matches the current committed version
3. **Commit Notification Filtering**: Don't send mempool notifications for historical commits during bootstrapping (only send for real-time commits)

**Recommended Approach**: Combination of API-level check (prevents issue at source) + improved mempool logic (defense in depth).

## Proof of Concept

The following test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_transaction_loss_during_bootstrapping() {
    use aptos_types::transaction::SignedTransaction;
    use aptos_mempool::MempoolClientRequest;
    
    // Setup: Create a node with state at version 1000
    let mut node = setup_test_node_at_version(1000).await;
    let account = generate_test_account();
    
    // Verify account has sequence number 50 at version 1000
    assert_eq!(node.get_account_sequence_number(&account).await, 50);
    
    // Step 1: User submits transaction with sequence 50
    let user_txn = create_signed_transaction(
        &account,
        50, // sequence number
        "transfer_payload"
    );
    
    // Submit via API - should return 202 Accepted
    let response = node.submit_transaction(user_txn.clone()).await;
    assert_eq!(response.status(), 202);
    
    // Verify transaction is in mempool
    assert!(node.mempool_contains(&user_txn.hash()).await);
    
    // Step 2: Simulate state sync processing historical block at version 1500
    // This block contains a DIFFERENT transaction from same account with seq 50
    let historical_txn = create_historical_transaction(&account, 50);
    let historical_block = create_block_at_version(1500, vec![historical_txn]);
    
    // State sync commits this historical block
    node.state_sync_commit_block(historical_block).await;
    
    // Step 3: Verify the vulnerability
    // The user's transaction should have been removed from mempool
    assert!(!node.mempool_contains(&user_txn.hash()).await);
    
    // But the user received 202 Accepted and has no idea it was lost
    // The historical transaction at version 1500 was committed, not the user's txn
    let committed_txns = node.get_committed_transactions_at_version(1500).await;
    assert!(!committed_txns.contains(&user_txn.hash()));
    
    // Account sequence number is now 51
    assert_eq!(node.get_account_sequence_number(&account).await, 51);
    
    // User's transaction is permanently lost
}
```

This PoC demonstrates that a transaction accepted during bootstrapping is silently removed when state sync processes historical commits, breaking the implicit guarantee that accepted transactions will be processed.

**Notes:**
- This vulnerability affects all validator nodes during bootstrapping periods
- Users have no indication their transaction was lost beyond monitoring for execution
- The issue compounds during network-wide events causing multiple nodes to bootstrap simultaneously
- Real-world impact depends on transaction volume during bootstrap windows and user retry behavior

### Citations

**File:** api/src/transactions.rs (L476-499)
```rust
    async fn submit_transaction(
        &self,
        accept_type: AcceptType,
        data: SubmitTransactionPost,
    ) -> SubmitTransactionResult<PendingTransaction> {
        data.verify()
            .context("Submitted transaction invalid'")
            .map_err(|err| {
                SubmitTransactionError::bad_request_with_code_no_info(
                    err,
                    AptosErrorCode::InvalidInput,
                )
            })?;
        fail_point_poem("endpoint_submit_transaction")?;
        if !self.context.node_config.api.transaction_submission_enabled {
            return Err(api_disabled("Submit transaction"));
        }
        self.context
            .check_api_output_enabled("Submit transaction", &accept_type)?;
        let ledger_info = self.context.get_latest_ledger_info()?;
        let signed_transaction = self.get_signed_transaction(&ledger_info, data)?;
        self.create(&accept_type, &ledger_info, signed_transaction)
            .await
    }
```

**File:** mempool/src/shared_mempool/tasks.rs (L328-350)
```rust
    let start_storage_read = Instant::now();
    let state_view = smp
        .db
        .latest_state_checkpoint_view()
        .expect("Failed to get latest state checkpoint view.");

    // Track latency: fetching seq number
    let account_seq_numbers = IO_POOL.install(|| {
        transactions
            .par_iter()
            .map(|(t, _, _)| match t.replay_protector() {
                ReplayProtector::Nonce(_) => Ok(None),
                ReplayProtector::SequenceNumber(_) => {
                    get_account_sequence_number(&state_view, t.sender())
                        .map(Some)
                        .inspect_err(|e| {
                            error!(LogSchema::new(LogEntry::DBError).error(e));
                            counters::DB_ERROR.inc();
                        })
                },
            })
            .collect::<Vec<_>>()
    });
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L783-824)
```rust
/// Spawns a dedicated commit post-processor that handles commit notifications
fn spawn_commit_post_processor<
    MempoolNotifier: MempoolNotificationSender,
    StorageServiceNotifier: StorageServiceNotificationSender,
>(
    mut commit_post_processor_listener: mpsc::Receiver<ChunkCommitNotification>,
    event_subscription_service: Arc<Mutex<EventSubscriptionService>>,
    mempool_notification_handler: MempoolNotificationHandler<MempoolNotifier>,
    storage_service_notification_handler: StorageServiceNotificationHandler<StorageServiceNotifier>,
    pending_data_chunks: Arc<AtomicU64>,
    runtime: Option<Handle>,
    storage: Arc<dyn DbReader>,
) -> JoinHandle<()> {
    // Create a commit post-processor
    let commit_post_processor = async move {
        while let Some(notification) = commit_post_processor_listener.next().await {
            // Start the commit post-process timer
            let _timer = metrics::start_timer(
                &metrics::STORAGE_SYNCHRONIZER_LATENCIES,
                metrics::STORAGE_SYNCHRONIZER_COMMIT_POST_PROCESS,
            );

            // Handle the committed transaction notification (e.g., notify mempool)
            let committed_transactions = CommittedTransactions {
                events: notification.subscribable_events,
                transactions: notification.committed_transactions,
            };
            utils::handle_committed_transactions(
                committed_transactions,
                storage.clone(),
                mempool_notification_handler.clone(),
                event_subscription_service.clone(),
                storage_service_notification_handler.clone(),
            )
            .await;
            decrement_pending_data_chunks(pending_data_chunks.clone());
        }
    };

    // Spawn the commit post-processor
    spawn(runtime, commit_post_processor)
}
```

**File:** mempool/src/core_mempool/transaction_store.rs (L635-665)
```rust
    fn clean_committed_transactions_below_account_seq_num(
        &mut self,
        address: &AccountAddress,
        account_sequence_number: u64,
    ) {
        // Remove all previous seq number transactions for this account.
        // This can happen if transactions are sent to multiple nodes and one of the
        // nodes has sent the transaction to consensus but this node still has the
        // transaction sitting in mempool.
        if let Some(txns) = self.transactions.get_mut(address) {
            let mut active = txns.seq_num_split_off(account_sequence_number);
            let txns_for_removal = txns.clone();
            txns.clear();
            txns.append(&mut active);

            let mut rm_txns = match aptos_logger::enabled!(Level::Trace) {
                true => TxnsLog::new(),
                false => TxnsLog::new_with_max(10),
            };
            for transaction in txns_for_removal.values() {
                rm_txns.add(transaction.get_sender(), transaction.get_replay_protector());
                self.index_remove(transaction);
            }
            trace!(
                LogSchema::new(LogEntry::CleanCommittedTxn).txns(rm_txns),
                "txns cleaned with committing tx {}:{}",
                address,
                account_sequence_number
            );
        }
    }
```

**File:** mempool/src/core_mempool/transaction_store.rs (L671-707)
```rust
    pub fn commit_transaction(
        &mut self,
        account: &AccountAddress,
        replay_protector: ReplayProtector,
    ) {
        match replay_protector {
            ReplayProtector::SequenceNumber(txn_sequence_number) => {
                let current_account_seq_number =
                    self.get_account_sequence_number(account).map_or(0, |v| *v);
                let new_account_seq_number =
                    max(current_account_seq_number, txn_sequence_number + 1);
                self.account_sequence_numbers
                    .insert(*account, new_account_seq_number);
                self.clean_committed_transactions_below_account_seq_num(
                    account,
                    new_account_seq_number,
                );
                self.process_ready_seq_num_based_transactions(account, new_account_seq_number);
            },
            ReplayProtector::Nonce(nonce) => {
                if let Some(txns) = self.transactions.get_mut(account) {
                    if let Some(txn) = txns.remove(&ReplayProtector::Nonce(nonce)) {
                        self.index_remove(&txn);
                        trace!(
                            LogSchema::new(LogEntry::CleanCommittedTxn).txns(TxnsLog::new_txn(
                                txn.get_sender(),
                                txn.get_replay_protector()
                            )),
                            "txns cleaned with committing tx {}:{:?}",
                            txn.get_sender(),
                            txn.get_replay_protector()
                        );
                    }
                }
            },
        }
    }
```

**File:** state-sync/state-sync-driver/src/driver.rs (L692-720)
```rust
        // Drive progress depending on if we're bootstrapping or continuously syncing
        if self.bootstrapper.is_bootstrapped() {
            // Fetch any consensus sync requests
            let consensus_sync_request = self.consensus_notification_handler.get_sync_request();

            // Attempt to continuously sync
            if let Err(error) = self
                .continuous_syncer
                .drive_progress(consensus_sync_request)
                .await
            {
                sample!(
                    SampleRate::Duration(Duration::from_secs(DRIVER_ERROR_LOG_FREQ_SECS)),
                    warn!(LogSchema::new(LogEntry::Driver)
                        .error(&error)
                        .message("Error found when driving progress of the continuous syncer!"));
                );
                metrics::increment_counter(&metrics::CONTINUOUS_SYNCER_ERRORS, error.get_label());
            }
        } else if let Err(error) = self.bootstrapper.drive_progress(&global_data_summary).await {
            sample!(
                    SampleRate::Duration(Duration::from_secs(DRIVER_ERROR_LOG_FREQ_SECS)),
                    warn!(LogSchema::new(LogEntry::Driver)
                        .error(&error)
                        .message("Error found when checking the bootstrapper progress!"));
            );
            metrics::increment_counter(&metrics::BOOTSTRAPPER_ERRORS, error.get_label());
        };
    }
```

**File:** aptos-node/src/lib.rs (L801-827)
```rust
    let (mempool_runtime, consensus_to_mempool_sender) =
        services::start_mempool_runtime_and_get_consensus_sender(
            &mut node_config,
            &db_rw,
            mempool_reconfig_subscription,
            mempool_network_interfaces,
            mempool_listener,
            mempool_client_receiver,
            peers_and_metadata,
        );

    // Create the DKG runtime and get the VTxn pool
    let (vtxn_pool, dkg_runtime) =
        consensus::create_dkg_runtime(&mut node_config, dkg_subscriptions, dkg_network_interfaces);

    // Create the JWK consensus runtime
    let jwk_consensus_runtime = consensus::create_jwk_consensus_runtime(
        &mut node_config,
        jwk_consensus_subscriptions,
        jwk_consensus_network_interfaces,
        &vtxn_pool,
    );

    // Wait until state sync has been initialized
    debug!("Waiting until state sync is initialized!");
    state_sync_runtimes.block_until_initialized();
    debug!("State sync initialization complete.");
```
