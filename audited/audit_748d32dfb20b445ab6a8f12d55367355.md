# Audit Report

## Title
Atomicity Violation in EventStorePruner Initialization Leads to Permanent Storage Bloat and State Inconsistency

## Summary
The `EventStorePruner::new()` function contains a critical atomicity violation where progress metadata initialization (lines 90-94) and catch-up pruning (line 106) are non-atomic operations. A crash between these operations permanently marks events as pruned when they were never deleted, leading to unbounded storage growth and requiring manual database repair. [1](#0-0) 

## Finding Description

The vulnerability occurs during the initialization of the `EventStorePruner` component. The function performs two critical operations:

1. **Progress metadata initialization** (lines 90-94): Calls `get_or_initialize_subpruner_progress()` which writes `EventPrunerProgress = metadata_progress` to the database via a synchronous, durable write operation. [2](#0-1) 

2. **Catch-up pruning** (line 106): Executes actual event deletion from the stored progress to the target metadata progress.

The problem is that the first operation performs a durable database write (`sub_db.put()` at lines 53-56 in pruner_utils.rs) that is immediately committed with `sync=true`: [3](#0-2) [4](#0-3) [5](#0-4) 

**Exploitation Scenario:**

1. Node starts with no `EventPrunerProgress` metadata (first initialization or after reset)
2. `LedgerMetadataPruner` has already pruned to version 1000 (`metadata_progress = 1000`)
3. `EventStorePruner::new(ledger_db, 1000, indexer_db)` is called
4. Line 90-94: `get_or_initialize_subpruner_progress()` finds no existing progress, **writes `EventPrunerProgress = 1000` to database and syncs to disk**
5. **CRASH OCCURS** before line 106 executes
6. On restart: `get_or_initialize_subpruner_progress()` now reads `EventPrunerProgress = 1000` from the database
7. Line 106: `myself.prune(1000, 1000)` is called - **this is a no-op since start equals end**
8. Events from versions 0-999 were NEVER pruned but the progress marker indicates they were

The subsequent pruning operations start from the initialized progress value: [6](#0-5) 

Since `LedgerPruner` initializes with `progress = metadata_progress` (line 174), future pruning operations only process versions beyond 1000, leaving versions 0-999 unpruned forever. [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos Bug Bounty program: "State inconsistencies requiring intervention".

**Concrete Impact:**

1. **Permanent Storage Bloat**: Events that should have been pruned accumulate indefinitely, consuming disk space. On a high-throughput chain with millions of events per day, this can lead to gigabytes of unnecessary storage over time.

2. **State Inconsistency**: The progress metadata (`EventPrunerProgress`) and actual database state diverge permanently. The system believes events are pruned when they are not.

3. **Manual Intervention Required**: There is no automatic recovery mechanism. Operators must manually:
   - Detect the inconsistency through storage analysis
   - Reset the `EventPrunerProgress` metadata to 0
   - Restart the node to trigger catch-up pruning
   - Or manually prune the affected range

4. **Affects All Nodes**: Any node that crashes during initialization (common during upgrades, restarts, or infrastructure failures) can experience this issue.

This breaks the **State Consistency** critical invariant: "State transitions must be atomic and verifiable via Merkle proofs."

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This vulnerability is likely to occur in production environments:

1. **Common Trigger**: Node crashes during startup are common due to:
   - Infrastructure failures (power loss, OOM kills)
   - Software crashes during initialization
   - Deployment interruptions during upgrades
   - Manual interruptions (SIGKILL during bootstrap)

2. **Narrow Window**: The vulnerability window is small (between lines 94 and 106), but startup is a critical period where nodes are under resource pressure and more likely to crash.

3. **First Initialization**: Most vulnerable during first node initialization, when setting up pruning for the first time, or after database migrations.

4. **Silent Failure**: The issue is silent - the node continues to operate normally, but storage accumulates. Operators may not notice until disk space becomes critically low.

## Recommendation

**Solution: Make progress initialization and catch-up pruning atomic using a transaction batch.**

Modified `EventStorePruner::new()`:

```rust
pub(in crate::pruner) fn new(
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
    internal_indexer_db: Option<InternalIndexerDB>,
) -> Result<Self> {
    let progress = ledger_db.event_db_raw()
        .get::<DbMetadataSchema>(&DbMetadataKey::EventPrunerProgress)?
        .map(|v| v.expect_version())
        .unwrap_or(0); // Start from 0 if not initialized

    let myself = EventStorePruner {
        ledger_db,
        internal_indexer_db,
    };

    info!(
        progress = progress,
        metadata_progress = metadata_progress,
        "Catching up EventStorePruner."
    );
    
    // Perform catch-up pruning and update progress atomically
    myself.prune(progress, metadata_progress)?;
    
    Ok(myself)
}
```

The key changes:
1. Remove `get_or_initialize_subpruner_progress()` call that performs premature write
2. Read existing progress or default to 0
3. The `prune()` method already updates progress atomically at the end (line 66-68 in event_store_pruner.rs), so progress initialization and pruning are now atomic

This ensures that progress is only updated AFTER pruning completes successfully.

## Proof of Concept

```rust
// Integration test demonstrating the vulnerability
#[test]
fn test_event_pruner_crash_leaves_inconsistent_state() {
    use std::sync::Arc;
    use aptos_temppath::TempPath;
    use aptos_storage_interface::DbReader;
    
    let tmpdir = TempPath::new();
    
    // Step 1: Create initial database with events at versions 0-999
    {
        let db = AptosDB::new_for_test(&tmpdir);
        // Insert events for versions 0-999
        for version in 0..1000 {
            let events = vec![create_test_event()];
            db.save_transactions(&[create_test_transaction_with_events(events)], 
                                version, &[], false, None).unwrap();
        }
        // Simulate LedgerMetadataPruner has pruned to 1000
        db.ledger_db().metadata_db().put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerPrunerProgress,
            &DbMetadataValue::Version(1000)
        ).unwrap();
    }
    
    // Step 2: Simulate crash during EventStorePruner initialization
    {
        let db = AptosDB::open(&tmpdir, false, NO_OP_STORAGE_PRUNER_CONFIG, RocksdbConfigs::default(), false, 10000).unwrap();
        
        // Manually trigger the problematic scenario:
        // Initialize progress without pruning (simulating crash after line 94)
        db.ledger_db().event_db_raw().put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(1000)
        ).unwrap();
        // Don't call prune() - simulating crash before line 106
    }
    
    // Step 3: Restart and verify inconsistency
    {
        let db = AptosDB::open(&tmpdir, false, NO_OP_STORAGE_PRUNER_CONFIG, RocksdbConfigs::default(), false, 10000).unwrap();
        
        // EventPrunerProgress says 1000
        let progress = db.ledger_db().event_db_raw()
            .get::<DbMetadataSchema>(&DbMetadataKey::EventPrunerProgress)
            .unwrap()
            .unwrap()
            .expect_version();
        assert_eq!(progress, 1000);
        
        // But events 0-999 still exist in database!
        for version in 0..1000 {
            let events = db.get_events(version, 0, 100).unwrap();
            assert!(!events.is_empty(), "Events at version {} should exist but were marked as pruned", version);
        }
    }
}
```

## Notes

This vulnerability exemplifies a classic distributed systems problem: non-atomic multi-step operations with persistent state. The fix aligns with the principle that metadata updates should be committed atomically with the data operations they describe. Similar patterns should be audited in other pruner implementations (`TransactionPruner`, `StateKvPruner`, etc.) that use the same `get_or_initialize_subpruner_progress()` utility function. [8](#0-7)

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L85-109)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```

**File:** storage/schemadb/src/lib.rs (L239-244)
```rust
    pub fn put<S: Schema>(&self, key: &S::Key, value: &S::Value) -> DbResult<()> {
        // Not necessary to use a batch, but we'd like a central place to bump counters.
        let mut batch = self.new_native_batch();
        batch.put::<S>(key, value)?;
        self.write_schemas(batch)
    }
```

**File:** storage/schemadb/src/lib.rs (L307-309)
```rust
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }
```

**File:** storage/schemadb/src/lib.rs (L374-378)
```rust
fn sync_write_option() -> rocksdb::WriteOptions {
    let mut opts = rocksdb::WriteOptions::default();
    opts.set_sync(true);
    opts
}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L62-92)
```rust
    fn prune(&self, max_versions: usize) -> Result<Version> {
        let mut progress = self.progress();
        let target_version = self.target_version();

        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);

            info!(
                progress = progress,
                target_version = current_batch_target_version,
                "Pruning ledger data."
            );
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;

            progress = current_batch_target_version;
            self.record_progress(progress);
            info!(progress = progress, "Pruning ledger data is done.");
        }

        Ok(target_version)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L118-194)
```rust
    pub fn new(
        ledger_db: Arc<LedgerDb>,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        info!(name = LEDGER_PRUNER_NAME, "Initializing...");

        let ledger_metadata_pruner = Box::new(
            LedgerMetadataPruner::new(ledger_db.metadata_db_arc())
                .expect("Failed to initialize ledger_metadata_pruner."),
        );

        let metadata_progress = ledger_metadata_pruner.progress()?;

        info!(
            metadata_progress = metadata_progress,
            "Created ledger metadata pruner, start catching up all sub pruners."
        );

        let transaction_store = Arc::new(TransactionStore::new(Arc::clone(&ledger_db)));

        let event_store_pruner = Box::new(EventStorePruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db.clone(),
        )?);
        let persisted_auxiliary_info_pruner = Box::new(PersistedAuxiliaryInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_accumulator_pruner = Box::new(TransactionAccumulatorPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_auxiliary_data_pruner = Box::new(TransactionAuxiliaryDataPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_info_pruner = Box::new(TransactionInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_pruner = Box::new(TransactionPruner::new(
            Arc::clone(&transaction_store),
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db,
        )?);
        let write_set_pruner = Box::new(WriteSetPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let pruner = LedgerPruner {
            target_version: AtomicVersion::new(metadata_progress),
            progress: AtomicVersion::new(metadata_progress),
            ledger_metadata_pruner,
            sub_pruners: vec![
                event_store_pruner,
                persisted_auxiliary_info_pruner,
                transaction_accumulator_pruner,
                transaction_auxiliary_data_pruner,
                transaction_info_pruner,
                transaction_pruner,
                write_set_pruner,
            ],
        };

        info!(
            name = pruner.name(),
            progress = metadata_progress,
            "Initialized."
        );

        Ok(pruner)
    }
```
