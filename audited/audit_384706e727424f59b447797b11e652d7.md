# Audit Report

## Title
Unvalidated DAG QuorumStore Configuration Allows Transaction Rate Manipulation

## Summary
The DAG consensus configuration's QuorumStore settings are not sanitized during node startup, allowing validators to arbitrarily set `dynamic_max_txn_per_s` values that deviate from the intended default of 200 TPS. This enables malicious validators to significantly degrade network throughput while claiming to be properly configured for DAG mode, or conversely, attempt to overwhelm the network with excessive transaction rates.

## Finding Description

When DAG consensus is enabled via on-chain governance, validators use their local `dag_consensus.quorum_store` configuration to determine transaction pulling rates. The default configuration sets `dynamic_max_txn_per_s` to 200 TPS, which is a 60x reduction from the standard 12,000 TPS used in non-DAG mode. [1](#0-0) 

The critical vulnerability is that this configuration is **never validated** during node startup. The config sanitization only checks the `DagPayloadConfig`, but completely ignores the `quorum_store` field within `DagConsensusConfig`: [2](#0-1) 

Furthermore, the existing `QuorumStoreConfig::sanitize` only validates `node_config.consensus.quorum_store`, not `node_config.dag_consensus.quorum_store`: [3](#0-2) 

When the network switches to DAG mode, the epoch manager selects which configuration to use based on the on-chain consensus config: [4](#0-3) 

This configuration directly controls the transaction pull rate in the batch generator: [5](#0-4) [6](#0-5) 

**Attack Scenario 1 - Transaction Starvation:**
A malicious validator modifies their local `dag_consensus.quorum_store.back_pressure.dynamic_max_txn_per_s` to 1 or 10 (instead of 200). They:
- Contribute minimal transactions to consensus
- Claim to be "properly configured for DAG mode" since they're using the dag_consensus config structure
- Face no validation errors or penalties
- If multiple validators collude or misconfigure, network throughput degrades proportionally

**Attack Scenario 2 - Network Resource Exhaustion:**
A validator sets `dynamic_max_txn_per_s` to 1,000,000. While individual batch sizes are still limited by receiver constraints, the high rate of batch creation and network transmission could cause:
- Network congestion from excessive batch broadcasts
- CPU/memory exhaustion on receiving validators processing batches
- Degraded performance for honest validators

## Impact Explanation

This vulnerability fits the **Medium Severity** category per Aptos bug bounty criteria as it causes "state inconsistencies requiring intervention":

1. **Network Throughput Degradation**: If multiple validators use misconfigured values, overall network TPS can degrade significantly, requiring governance intervention to identify and fix

2. **Configuration Inconsistency**: Different validators may unknowingly run with vastly different transaction contribution rates, creating unpredictable network behavior

3. **Validator Performance Issues**: Aligns with "Validator node slowdowns" (High severity category) when combined with the throughput impact

4. **No Detection Mechanism**: The lack of validation means misconfigured validators appear identical to properly configured ones, making diagnosis difficult

The issue doesn't directly cause fund loss or consensus safety violations, but it undermines the DAG consensus model's assumption that all validators contribute transactions proportionally.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability is likely to manifest because:

1. **Easy to Exploit**: Validators only need to modify a single configuration value in their local config file
2. **No Detection**: There's no runtime validation or monitoring that would detect misconfigured validators
3. **Plausible Deniability**: Validators can claim accidental misconfiguration or different interpretations of "proper DAG configuration"
4. **Default Value Questions**: The 60x reduction in the default (200 vs 12,000) may itself cause confusion, leading validators to "correct" it back to higher values
5. **No Enforcement**: The on-chain governance can enable DAG mode network-wide, but cannot enforce specific QuorumStore parameters on individual validators

## Recommendation

Implement validation for the DAG QuorumStore configuration with the following changes:

**1. Add QuorumStore validation to DagConsensusConfig sanitizer:**

```rust
impl ConfigSanitizer for DagConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        DagPayloadConfig::sanitize(node_config, node_type, chain_id)?;
        
        // Validate the DAG QuorumStore configuration
        let sanitizer_name = Self::get_sanitizer_name();
        QuorumStoreConfig::sanitize_send_recv_batch_limits(
            &sanitizer_name,
            &node_config.dag_consensus.quorum_store,
        )?;
        QuorumStoreConfig::sanitize_batch_total_limits(
            &sanitizer_name, 
            &node_config.dag_consensus.quorum_store
        )?;
        
        // Validate dynamic_max_txn_per_s is within reasonable bounds for DAG
        let back_pressure = &node_config.dag_consensus.quorum_store.back_pressure;
        if back_pressure.dynamic_max_txn_per_s < 50 || back_pressure.dynamic_max_txn_per_s > 500 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "DAG dynamic_max_txn_per_s must be between 50 and 500, got {}",
                    back_pressure.dynamic_max_txn_per_s
                ),
            ));
        }
        
        Ok(())
    }
}
```

**2. Make QuorumStore sanitization methods public:**

In `config/src/config/quorum_store_config.rs`, change the visibility of the validation methods:

```rust
impl QuorumStoreConfig {
    pub fn sanitize_send_recv_batch_limits(
        sanitizer_name: &str,
        config: &QuorumStoreConfig,
    ) -> Result<(), Error> {
        // ... existing implementation
    }

    pub fn sanitize_batch_total_limits(
        sanitizer_name: &str,
        config: &QuorumStoreConfig,
    ) -> Result<(), Error> {
        // ... existing implementation
    }
}
```

**3. Add runtime monitoring:**

Implement metrics and alarms that track each validator's transaction contribution rate to detect anomalies.

## Proof of Concept

**Setup:**
1. Configure a validator node with modified `dag_consensus.quorum_store.back_pressure.dynamic_max_txn_per_s`
2. Enable DAG mode on the network via on-chain governance
3. Observe that the node starts successfully without validation errors
4. Monitor the node's transaction contribution rate

**Configuration File Modification:**
```yaml
dag_consensus:
  quorum_store:
    back_pressure:
      dynamic_min_txn_per_s: 1
      dynamic_max_txn_per_s: 10  # Maliciously low value
      # ... other default settings
```

**Expected Behavior (Current - Vulnerable):**
- Node starts successfully
- No configuration validation errors
- Node pulls only ~10 transactions per second from mempool
- Other validators accept batches (they meet size limits)
- Network throughput degrades proportionally

**Expected Behavior (After Fix):**
- Node fails to start with config sanitizer error:
  ```
  Error: ConfigSanitizerFailed("DagConsensusConfigSanitizer", 
    "DAG dynamic_max_txn_per_s must be between 50 and 500, got 10")
  ```

## Notes

The 60x reduction in `dynamic_max_txn_per_s` for DAG mode (200 vs 12,000) is intentional according to the code comments, as DAG allows all validators to contribute in parallel rather than having a single leader per round. However, the lack of validation enforcement creates a vector for network performance degradation through misconfiguration or malicious intent.

This vulnerability is particularly concerning because:
- DAG mode is a newer feature that may not have undergone extensive real-world testing
- The mismatch between DAG payload limits (10,000 txns/round) and QuorumStore rate (200 TPS) suggests potential throughput bottlenecks
- No reputation or penalty system exists to detect lazy or malicious validators who contribute fewer transactions than expected

### Citations

**File:** config/src/config/quorum_store_config.rs (L155-176)
```rust
    pub fn default_for_dag() -> Self {
        Self {
            sender_max_batch_txns: 300,
            sender_max_batch_bytes: 4 * 1024 * 1024,
            sender_max_num_batches: 5,
            sender_max_total_txns: 500,
            sender_max_total_bytes: 8 * 1024 * 1024,
            receiver_max_batch_txns: 300,
            receiver_max_batch_bytes: 4 * 1024 * 1024,
            receiver_max_num_batches: 5,
            receiver_max_total_txns: 500,
            receiver_max_total_bytes: 8 * 1024 * 1024,
            back_pressure: QuorumStoreBackPressureConfig {
                backlog_txn_limit_count: 100000,
                backlog_per_validator_batch_limit_count: 20,
                dynamic_min_txn_per_s: 100,
                dynamic_max_txn_per_s: 200,
                ..Default::default()
            },
            ..Default::default()
        }
    }
```

**File:** config/src/config/quorum_store_config.rs (L253-272)
```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Sanitize the send/recv batch limits
        Self::sanitize_send_recv_batch_limits(
            &sanitizer_name,
            &node_config.consensus.quorum_store,
        )?;

        // Sanitize the batch total limits
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;

        Ok(())
    }
}
```

**File:** config/src/config/dag_consensus_config.rs (L169-179)
```rust
impl ConfigSanitizer for DagConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        DagPayloadConfig::sanitize(node_config, node_type, chain_id)?;

        Ok(())
    }
}
```

**File:** consensus/src/epoch_manager.rs (L731-735)
```rust
        let quorum_store_config = if consensus_config.is_dag_enabled() {
            self.dag_config.quorum_store.clone()
        } else {
            self.config.quorum_store.clone()
        };
```

**File:** consensus/src/quorum_store/batch_generator.rs (L419-421)
```rust
        let mut dynamic_pull_txn_per_s = (self.config.back_pressure.dynamic_min_txn_per_s
            + self.config.back_pressure.dynamic_max_txn_per_s)
            / 2;
```

**File:** consensus/src/quorum_store/batch_generator.rs (L451-454)
```rust
                            dynamic_pull_txn_per_s = std::cmp::min(
                                dynamic_pull_txn_per_s + self.config.back_pressure.additive_increase_when_no_backpressure,
                                self.config.back_pressure.dynamic_max_txn_per_s,
                            );
```
