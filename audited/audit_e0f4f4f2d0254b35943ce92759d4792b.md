# Audit Report

## Title
Subscription Stream Memory Leak Due to Missing Automatic Garbage Collection

## Summary
The data streaming service lacks automatic garbage collection for subscription streams when clients fail to explicitly terminate them. Streams can accumulate indefinitely in memory if the listener is dropped without proper cleanup, particularly when no data is available to send (preventing send-failure detection). This violates the "Resource Limits" invariant requiring all operations to respect memory constraints.

## Finding Description

The vulnerability exists in the data streaming service's lifecycle management for subscription streams. [1](#0-0) 

The TODO comment explicitly acknowledges this missing feature. The current cleanup mechanisms rely on:

1. **Explicit termination** via `TerminateStreamRequest`
2. **Send failure detection** - setting `send_failure` flag when notification sends fail [2](#0-1) 

However, send failure detection requires attempting to send a notification. For subscription streams waiting for new data that never arrives: [3](#0-2) 

If subscription requests are sent but responses never arrive (no new blockchain data, slow peers, or network issues), no notifications are generated, no send attempts occur, and `send_failure` is never set. The stream persists in the HashMap indefinitely: [4](#0-3) 

When subscription errors occur, the stream engine clears the active subscription but doesn't terminate the entire data stream: [5](#0-4) 

The stream can then create new subscription streams and continue indefinitely without cleanup.

## Impact Explanation

This issue qualifies as **Medium severity** per Aptos bug bounty criteria as it causes resource exhaustion through unbounded memory accumulation. While not directly affecting consensus or funds, it degrades node performance and availability over time. Memory leaks can eventually lead to:

- Node slowdowns and performance degradation  
- Increased memory pressure affecting other subsystems
- Potential crashes if memory exhaustion occurs
- Reduced capacity to handle legitimate sync requests

The server-side has timeout protection via `max_subscription_period_ms`, but the client-side lacks equivalent automatic cleanup. [6](#0-5) 

## Likelihood Explanation

Likelihood is **Medium** because this requires specific conditions:

1. Client creates subscription streams via state sync
2. Listener is dropped (client crashes, bug, or deliberate abandonment) without explicit termination
3. No data arrives to trigger send-failure detection
4. Stream accumulates in memory over time

While not trivial to exploit externally, internal client bugs, crash scenarios, or edge cases in state sync logic can trigger this. The TODO comment indicates developers are aware this is a concern for production deployment.

## Recommendation

Implement automatic garbage collection with timeout-based cleanup:

```rust
// Add to DataStream struct
pub last_activity_time: Instant,

// Add to DataStreamingServiceConfig  
pub max_stream_idle_timeout_ms: u64, // e.g., 60000 (60 seconds)

// In streaming_service.rs, check_progress_of_all_data_streams:
async fn check_progress_of_all_data_streams(&mut self) {
    let data_stream_ids = self.get_all_data_stream_ids();
    let current_time = self.time_service.now();
    
    for data_stream_id in &data_stream_ids {
        let data_stream = self.get_data_stream(data_stream_id)?;
        
        // Check for idle timeout
        let idle_duration = current_time.duration_since(data_stream.last_activity_time);
        if idle_duration.as_millis() > self.streaming_service_config.max_stream_idle_timeout_ms as u128 {
            info!("Removing idle stream with ID: {:?}", data_stream_id);
            self.data_streams.remove(data_stream_id);
            continue;
        }
        
        // Existing progress update logic...
    }
}
```

Update `last_activity_time` whenever the stream makes progress (sends notifications, receives responses, etc.).

## Proof of Concept

```rust
#[tokio::test]
async fn test_subscription_stream_memory_leak() {
    use std::time::Duration;
    
    // Create streaming service with long progress check interval
    let config = DataStreamingServiceConfig {
        progress_check_interval_ms: 100,
        ..Default::default()
    };
    
    let (streaming_client, mut streaming_service) = 
        create_streaming_client_and_server(Some(config), false, false, true, true);
    
    // Track initial stream count
    let initial_count = streaming_service.data_streams.len();
    
    // Create multiple subscription streams
    let num_streams = 10;
    for _ in 0..num_streams {
        let stream_listener = streaming_client
            .continuously_stream_transactions(0, 0, None, true)
            .await
            .unwrap();
        
        // Immediately drop listener without terminating
        drop(stream_listener);
    }
    
    // Wait and periodically check progress (simulating no data arriving)
    for _ in 0..50 {
        streaming_service.check_progress_of_all_data_streams().await;
        tokio::time::sleep(Duration::from_millis(100)).await;
    }
    
    // Streams should accumulate since no send failures detected
    let final_count = streaming_service.data_streams.len();
    assert_eq!(final_count, initial_count + num_streams, 
        "Streams leaked: expected {}, got {}", 
        initial_count + num_streams, final_count);
}
```

## Notes

The server-side subscription management properly implements timeouts and cleanup. The vulnerability is specific to the client-side data streaming service. While this requires client-side issues to trigger (buggy code, crashes), the TODO comment indicates this is a known concern for production robustness. Implementing timeout-based garbage collection would provide defense-in-depth against various client-side failure scenarios.

### Citations

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L67-68)
```rust
    // All requested data streams from clients
    data_streams: HashMap<DataStreamId, DataStream<T>>,
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L199-201)
```rust
    /// Processes a request for terminating a data stream.
    /// TODO(joshlind): once this is exposed to the wild, we'll need automatic
    /// garbage collection for misbehaving clients.
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L347-364)
```rust
        // If there was a send failure, terminate the stream
        let data_stream = self.get_data_stream(data_stream_id)?;
        if data_stream.send_failure() {
            info!(
                (LogSchema::new(LogEntry::TerminateStream)
                    .stream_id(*data_stream_id)
                    .event(LogEvent::Success)
                    .message("There was a send failure, terminating the stream."))
            );
            metrics::DATA_STREAM_SEND_FAILURE.inc();
            if self.data_streams.remove(data_stream_id).is_none() {
                return Err(Error::UnexpectedErrorEncountered(format!(
                    "Failed to terminate stream id {:?} for send failure! Stream not found.",
                    data_stream_id
                )));
            }
            return Ok(());
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L399-417)
```rust
    async fn send_data_notification(
        &mut self,
        data_notification: DataNotification,
    ) -> Result<(), Error> {
        if let Err(error) = self.notification_sender.send(data_notification).await {
            let error = Error::UnexpectedErrorEncountered(error.to_string());
            warn!(
                (LogSchema::new(LogEntry::StreamNotification)
                    .stream_id(self.data_stream_id)
                    .event(LogEvent::Error)
                    .error(&error)
                    .message("Failed to send data notification to listener!"))
            );
            self.send_failure = true;
            Err(error)
        } else {
            Ok(())
        }
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L937-953)
```rust
    /// Handles a subscription error for the specified client request
    fn handle_subscription_error(
        &mut self,
        client_request: &DataClientRequest,
        request_error: aptos_data_client::error::Error,
    ) -> Result<(), Error> {
        // We should only receive an error notification if we have an active stream
        if self.active_subscription_stream.is_none() {
            return Err(Error::UnexpectedErrorEncountered(format!(
                "Received a subscription notification error but no active subscription stream exists! Error: {:?}, request: {:?}",
                request_error, client_request
            )));
        }

        // Reset the active subscription stream and update the metrics
        self.active_subscription_stream = None;
        update_terminated_subscription_metrics(request_error.get_label());
```

**File:** state-sync/storage-service/server/src/subscription.rs (L418-433)
```rust
    fn is_expired(&self, timeout_ms: u64) -> bool {
        // Determine the time when the stream was first blocked
        let time_when_first_blocked =
            if let Some(subscription_request) = self.first_pending_request() {
                subscription_request.request_start_time // The stream is blocked on the first pending request
            } else {
                self.last_stream_update_time // The stream is idle and hasn't been updated in a while
            };

        // Verify the stream hasn't been blocked for too long
        let current_time = self.time_service.now();
        let elapsed_time = current_time
            .duration_since(time_when_first_blocked)
            .as_millis();
        elapsed_time > (timeout_ms as u128)
    }
```
