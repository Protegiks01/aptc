# Audit Report

## Title
Unbounded Memory Growth in Indexer GRPC Due to Missing Configuration Validation

## Summary
The Indexer GRPC configuration parameters `processor_task_count`, `processor_batch_size`, and `output_batch_size` lack upper bound validation, allowing node operators to set arbitrarily large values that lead to unbounded memory consumption and node crashes when clients connect.

## Finding Description

The `IndexerGrpcConfig` structure defines three critical parameters without any upper bound enforcement: [1](#0-0) 

The configuration sanitizer only validates that the indexer backend is enabled, but performs no bounds checking on these parameters: [2](#0-1) 

When a client connects to the Indexer GRPC service, the `IndexerStreamCoordinator` uses these parameters to control concurrent batch processing. The `get_batches()` function creates up to `processor_task_count` batches: [3](#0-2) 

Each batch spawns an async task that fetches up to `processor_batch_size` transactions from storage: [4](#0-3) 

The critical vulnerability is that these async tasks are spawned using `tokio::spawn` (not `spawn_blocking`), so they are **not limited** by the `MAX_BLOCKING_THREADS` constant of 64 defined in the runtime: [5](#0-4) 

**Attack Scenario:**

1. Node operator sets configuration (through misconfiguration or following incomplete examples):
   - `processor_task_count: 10000`
   - `processor_batch_size: 10000`

2. Malicious client connects and requests transactions via `GetTransactionsFromNode`

3. The coordinator spawns up to 10,000 concurrent async tasks

4. Each task fetches up to 10,000 transactions from storage (via database reads)

5. Memory consumption: 10,000 tasks × 10,000 transactions × ~5KB avg = **~500GB RAM** for a single client request

6. Multiple concurrent clients multiply this effect linearly

7. Node runs out of memory and crashes or becomes unresponsive

This violates **Invariant #9**: "Resource Limits: All operations must respect gas, storage, and computational limits."

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: If a validator enables indexer GRPC and misconfigures these values, memory exhaustion can cause the validator to slow down or crash, affecting consensus participation
  
- **API crashes**: Fullnodes running indexer GRPC will crash when clients connect, causing service unavailability

The vulnerability enables resource exhaustion attacks that can make nodes completely unavailable. While it requires operator misconfiguration, the system MUST validate configuration parameters and reject dangerous values rather than allowing unbounded resource allocation.

## Likelihood Explanation

**Medium-High Likelihood:**

1. **Easy to misconfigure**: The README example shows `processor_task_count: 10` and `processor_batch_size: 100`, but provides no guidance on maximum safe values [6](#0-5) 

2. **No runtime protection**: The default values are reasonable (1000 and 100), but operators seeking "better performance" might increase them without understanding the memory implications

3. **Triggerable by any client**: Once misconfigured, any client connecting to the GRPC endpoint can trigger the memory exhaustion

4. **No safeguards**: There are no warnings, no validation, and no runtime checks to prevent this scenario

## Recommendation

Implement strict upper bounds validation in the `ConfigSanitizer` for `IndexerGrpcConfig`:

```rust
impl ConfigSanitizer for IndexerGrpcConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        if !node_config.indexer_grpc.enabled {
            return Ok(());
        }

        // Existing validation...
        if !node_config.storage.enable_indexer
            && !node_config
                .indexer_table_info
                .table_info_service_mode
                .is_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "storage.enable_indexer must be true...".to_string(),
            ));
        }

        // NEW: Validate upper bounds
        const MAX_PROCESSOR_TASK_COUNT: u16 = 100;
        const MAX_PROCESSOR_BATCH_SIZE: u16 = 5000;
        const MAX_OUTPUT_BATCH_SIZE: u16 = 1000;

        let task_count = node_config
            .indexer_grpc
            .processor_task_count
            .unwrap_or_else(|| get_default_processor_task_count(
                node_config.indexer_grpc.use_data_service_interface
            ));

        if task_count > MAX_PROCESSOR_TASK_COUNT {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "processor_task_count ({}) exceeds maximum allowed value ({})",
                    task_count, MAX_PROCESSOR_TASK_COUNT
                ),
            ));
        }

        if node_config.indexer_grpc.processor_batch_size > MAX_PROCESSOR_BATCH_SIZE {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "processor_batch_size ({}) exceeds maximum allowed value ({})",
                    node_config.indexer_grpc.processor_batch_size,
                    MAX_PROCESSOR_BATCH_SIZE
                ),
            ));
        }

        if node_config.indexer_grpc.output_batch_size > MAX_OUTPUT_BATCH_SIZE {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                format!(
                    "output_batch_size ({}) exceeds maximum allowed value ({})",
                    node_config.indexer_grpc.output_batch_size,
                    MAX_OUTPUT_BATCH_SIZE
                ),
            ));
        }

        Ok(())
    }
}
```

Additionally, consider implementing runtime protections such as:
- Memory usage monitoring per client connection
- Request rate limiting
- Maximum concurrent client connections
- Timeout mechanisms for long-running batch operations

## Proof of Concept

**Test Configuration:**

Create a test config file `dangerous_indexer_config.yaml`:
```yaml
storage:
  enable_indexer: true

indexer_grpc:
  enabled: true
  address: 0.0.0.0:50051
  processor_task_count: 10000
  processor_batch_size: 10000
  output_batch_size: 5000
```

**Exploitation Steps:**

1. Start a fullnode with the dangerous configuration
2. Wait for the node to sync some transactions (at least 100M transactions for full effect)
3. Connect a client using `grpcurl`:

```bash
grpcurl -max-msg-sz 10000000 \
  -d '{ "starting_version": 0, "transactions_count": 100000000 }' \
  -import-path crates/aptos-protos/proto \
  -proto aptos/internal/fullnode/v1/fullnode_data.proto \
  -plaintext 127.0.0.1:50051 \
  aptos.internal.fullnode.v1.FullnodeData/GetTransactionsFromNode
```

**Expected Result:**

The node will spawn 10,000 concurrent async tasks, each attempting to fetch 10,000 transactions from storage. Memory usage will spike to hundreds of gigabytes, causing:
- System OOM killer to terminate the process, OR
- Node becomes completely unresponsive due to memory exhaustion, OR  
- System swap thrashing making the node unusable

**Observable Metrics:**
- Monitor memory usage: `watch -n 1 'ps aux | grep aptos-node'`
- Monitor task count: `ps -eLf | grep aptos-node | wc -l`
- Both will show exponential growth immediately after the client connects

---

## Notes

This vulnerability specifically affects the Indexer GRPC service, which is typically run on fullnodes rather than validators. However, there is no technical restriction preventing validators from enabling this service, and if they do with misconfigured values, it could impact consensus participation through resource exhaustion. The core issue is the absence of defensive programming - the system should validate all configuration parameters and reject values that violate resource safety invariants, regardless of whether the operator is trusted.

### Citations

**File:** config/src/config/indexer_grpc_config.rs (L45-52)
```rust
    /// Number of processor tasks to fan out
    pub processor_task_count: Option<u16>,

    /// Number of transactions each processor will process
    pub processor_batch_size: u16,

    /// Number of transactions returned in a single stream response
    pub output_batch_size: u16,
```

**File:** config/src/config/indexer_grpc_config.rs (L103-128)
```rust
impl ConfigSanitizer for IndexerGrpcConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        if !node_config.indexer_grpc.enabled {
            return Ok(());
        }

        if !node_config.storage.enable_indexer
            && !node_config
                .indexer_table_info
                .table_info_service_mode
                .is_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "storage.enable_indexer must be true or indexer_table_info.table_info_service_mode must be IndexingOnly if indexer_grpc.enabled is true".to_string(),
            ));
        }
        Ok(())
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L242-272)
```rust
    async fn fetch_transactions_from_storage(&mut self) -> Vec<(TransactionOnChainData, usize)> {
        let batches = self.get_batches().await;
        let mut storage_fetch_tasks = vec![];
        let ledger_version = self.highest_known_version;
        for batch in batches {
            let context = self.context.clone();
            let task = tokio::spawn(async move {
                Self::fetch_raw_txns_with_retries(context.clone(), ledger_version, batch).await
            });
            storage_fetch_tasks.push(task);
        }

        let transactions_from_storage =
            match futures::future::try_join_all(storage_fetch_tasks).await {
                Ok(res) => res,
                Err(err) => panic!(
                    "[Indexer Fullnode] Error fetching transaction batches: {:?}",
                    err
                ),
            };

        transactions_from_storage
            .into_iter()
            .flatten()
            .sorted_by(|a, b| a.version.cmp(&b.version))
            .map(|txn| {
                let size = bcs::serialized_size(&txn).expect("Unable to serialize txn");
                (txn, size)
            })
            .collect::<Vec<_>>()
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L293-318)
```rust
    async fn get_batches(&mut self) -> Vec<TransactionBatchInfo> {
        if !self.ensure_highest_known_version().await {
            return vec![];
        }

        let mut starting_version = self.current_version;
        let mut num_fetches = 0;
        let mut batches = vec![];
        let end_version = std::cmp::min(self.end_version, self.highest_known_version + 1);

        while num_fetches < self.processor_task_count && starting_version < end_version {
            let num_transactions_to_fetch = std::cmp::min(
                self.processor_batch_size as u64,
                end_version - starting_version,
            ) as u16;

            batches.push(TransactionBatchInfo {
                start_version: starting_version,
                head_version: self.highest_known_version,
                num_transactions_to_fetch,
            });
            starting_version += num_transactions_to_fetch as u64;
            num_fetches += 1;
        }
        batches
    }
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-27)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;
```

**File:** ecosystem/indexer-grpc/README.md (L48-53)
```markdown
    indexer_grpc:
      enabled: true
      address: 0.0.0.0:50051
      processor_task_count: 10
      processor_batch_size: 100
      output_batch_size: 100```
```
