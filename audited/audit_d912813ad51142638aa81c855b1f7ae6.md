# Audit Report

## Title
Race Condition in BatchStore Leading to Validator Node Crash via TimeExpirations-db_cache Inconsistency

## Summary
A critical race condition exists between `insert_to_cache()` and `clear_expired_payload()` in the BatchStore implementation. Due to non-atomic operations on the `expirations` and `db_cache` data structures, a digest can exist in `expirations` but not in `db_cache`, violating a core invariant and causing validator nodes to panic with `unreachable!("Expired entry not in cache")`. [1](#0-0) 

## Finding Description

The vulnerability stems from the non-atomic nature of operations across two shared data structures: `expirations` (a Mutex-protected TimeExpirations heap) and `db_cache` (a DashMap). 

In `insert_to_cache()`, a batch digest is first inserted into `db_cache`, then the function releases the db_cache lock, and finally adds the digest to `expirations`: [2](#0-1) 

In `clear_expired_payload()`, the function first acquires the expirations lock, calls `expire()` to pop expired digests from the heap, releases the lock, and then processes each digest by removing it from `db_cache`: [3](#0-2) 

The `TimeExpirations` data structure uses a BinaryHeap internally: [4](#0-3) 

**Race Condition Scenario:**

1. **Initial State:** Digest D exists in both `db_cache` (expiration=100) and `expirations` (expiration=100)

2. **Thread A** calls `clear_expired_payload(150)`:
   - Acquires expirations lock
   - Calls `expire(150)`, which pops D from the heap (since 100 ≤ 150)
   - Releases expirations lock
   - **Context switch occurs** before processing D at line 451

3. **Thread B** calls `insert_to_cache(D, expiration=110)` (same digest, slightly higher expiration):
   - Acquires db_cache entry lock for D
   - Sees existing entry with expiration=100, compares with new 110
   - Since 100 < 110, replaces entry with expiration=110
   - Releases db_cache entry lock
   - Acquires expirations lock
   - Adds D with expiration=110 to expirations
   - Releases expirations lock and completes

4. **Thread A resumes:**
   - For digest D (from the expired_digests set), acquires db_cache entry lock
   - Finds D with expiration=110
   - Checks: 110 ≤ 150? **TRUE**
   - Removes D from db_cache
   - Frees quota

**Result:** 
- `db_cache`: D is NOT present (removed by Thread A)
- `expirations`: D with expiration=110 (added by Thread B)

5. **Future Thread C** calls `clear_expired_payload(120)`:
   - `expire(120)` returns {D} (since 110 ≤ 120)
   - `db_cache.entry(D)` finds Vacant
   - **Hits `unreachable!()` at line 463 and panics** [5](#0-4) 

The code assumes the invariant: "if a digest is in expirations and has expired, it MUST be in db_cache". This race condition breaks that invariant.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program:

- **Validator node crashes**: When the `unreachable!()` is triggered, the validator node panics and terminates
- **API crashes**: The BatchStore is a critical component of the consensus layer; its crash affects the entire node
- **Liveness impact**: Crashed validators cannot participate in consensus, potentially affecting network liveness if multiple validators are affected
- **No recovery without restart**: The panic requires node operator intervention to restart the validator

This falls under "Validator node slowdowns" and "API crashes" categories, justifying High severity classification (up to $50,000 per the bug bounty program).

## Likelihood Explanation

**Likelihood: Medium-High**

The race condition requires specific timing but occurs under normal operational conditions:

- **No attacker required**: This is a natural race condition that can occur during regular consensus operations
- **Frequent operations**: Batch insertions and expirations happen continuously during normal block production
- **Concurrent execution**: Modern validators run with high concurrency, increasing the probability of this interleaving
- **Re-insertions with higher expirations**: The specific scenario (same digest, slightly higher expiration) is plausible when batches are re-propagated or when there are network delays causing re-submissions

The testing suite shows concurrent scenarios are tested, but the specific interleaving that causes the corruption is not covered: [6](#0-5) 

The existing test coordinates threads with atomic flags but doesn't trigger the specific race condition identified.

## Recommendation

**Solution: Make the insertion atomic or use proper synchronization**

The root cause is that operations on `db_cache` and `expirations` are not atomic. The fix should ensure that when a digest is in `expirations`, it's guaranteed to be in `db_cache`.

**Option 1: Hold db_cache lock while adding to expirations (Simple but less performant)**

```rust
pub(crate) fn insert_to_cache(
    &self,
    value: &PersistedValue<BatchInfoExt>,
) -> anyhow::Result<bool> {
    let digest = *value.digest();
    let author = value.author();
    let expiration_time = value.expiration();

    let cache_entry = self.db_cache.entry(digest);
    
    if let Occupied(entry) = &cache_entry {
        match entry.get().expiration().cmp(&expiration_time) {
            std::cmp::Ordering::Equal => return Ok(false),
            std::cmp::Ordering::Greater => {
                return Ok(false);
            },
            std::cmp::Ordering::Less => {},
        }
    };
    
    let value_to_be_stored = if self
        .peer_quota
        .entry(author)
        .or_insert(QuotaManager::new(
            self.db_quota,
            self.memory_quota,
            self.batch_quota,
        ))
        .update_quota(value.num_bytes() as usize)?
        == StorageMode::PersistedOnly
    {
        PersistedValue::new(value.batch_info().clone(), None)
    } else {
        value.clone()
    };

    // Add to expirations FIRST, while still holding the entry lock conceptually
    self.expirations.lock().add_item(digest, expiration_time);
    
    match cache_entry {
        Occupied(entry) => {
            let (k, prev_value) = entry.replace_entry(value_to_be_stored);
            debug_assert!(k == digest);
            self.free_quota(prev_value);
        },
        Vacant(slot) => {
            slot.insert(value_to_be_stored);
        },
    }
    
    Ok(true)
}
```

**Option 2: Check digest in db_cache before removing (Better, maintains performance)**

In `clear_expired_payload()`, add a verification step to handle the race:

```rust
pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
    let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
    let expired_digests = self.expirations.lock().expire(expiration_time);
    let mut ret = Vec::new();
    
    for h in expired_digests {
        let removed_value = match self.db_cache.entry(h) {
            Occupied(entry) => {
                if entry.get().expiration() <= expiration_time {
                    self.persist_subscribers.remove(entry.get().digest());
                    Some(entry.remove())
                } else {
                    None
                }
            },
            Vacant(_) => {
                // Race condition: entry was removed by concurrent clear_expired_payload
                // that processed a re-inserted version with higher expiration.
                // This is safe to ignore - the entry will be expired when its 
                // new expiration is reached.
                warn!("Expired entry {} not in cache, likely due to race condition", h);
                None
            }
        };
        
        if let Some(value) = removed_value {
            self.free_quota(value);
            ret.push(h);
        }
    }
    ret
}
```

Option 2 is preferred as it maintains performance while gracefully handling the race condition without crashing.

## Proof of Concept

```rust
#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
async fn test_expiration_race_condition() {
    use std::sync::Arc;
    use std::sync::atomic::{AtomicBool, Ordering};
    use tokio::task;
    
    let batch_store = batch_store_for_test(2001);
    let digest = HashValue::random();
    
    // Insert initial batch with exp=100
    assert_ok!(batch_store.insert_to_cache(&request_for_test(&digest, 100, 10, None)));
    
    let store_clone1 = batch_store.clone();
    let store_clone2 = batch_store.clone();
    let store_clone3 = batch_store.clone();
    
    let start_flag = Arc::new(AtomicBool::new(false));
    let start1 = start_flag.clone();
    let start2 = start_flag.clone();
    
    // Thread 1: clear_expired_payload(150) - will expire digest with exp=100
    let handle1 = task::spawn(async move {
        while !start1.load(Ordering::Acquire) {}
        store_clone1.clear_expired_payload(150);
    });
    
    // Thread 2: insert same digest with exp=110 (higher)
    let handle2 = task::spawn(async move {
        while !start2.load(Ordering::Acquire) {}
        // Small delay to hit the race window
        tokio::time::sleep(tokio::time::Duration::from_micros(10)).await;
        let _ = store_clone2.insert_to_cache(&request_for_test(&digest, 110, 10, None));
    });
    
    // Start both threads
    start_flag.store(true, Ordering::Release);
    
    handle1.await.unwrap();
    handle2.await.unwrap();
    
    // At this point, digest might be in expirations but not in db_cache
    // Try to trigger the panic
    let result = std::panic::catch_unwind(|| {
        store_clone3.clear_expired_payload(120);
    });
    
    // If the bug exists, this will panic with unreachable!()
    assert!(result.is_err(), "Expected panic due to race condition");
}
```

**Notes:**
- This PoC attempts to reproduce the race condition by coordinating two threads
- The timing window is narrow, so the test may need multiple runs or more sophisticated synchronization to reliably trigger the bug
- The panic message will be "Expired entry not in cache" when the bug is hit

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L118-118)
```rust
    expirations: Mutex<TimeExpirations<HashValue>>,
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-472)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
        let mut ret = Vec::new();
        for h in expired_digests {
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
            // No longer holding the lock on db_cache entry.
            if let Some(value) = removed_value {
                self.free_quota(value);
                ret.push(h);
            }
        }
        ret
    }
```

**File:** consensus/src/quorum_store/utils.rs (L60-95)
```rust
pub(crate) struct TimeExpirations<I: Ord> {
    expiries: BinaryHeap<(Reverse<u64>, I)>,
}

impl<I: Ord + Hash> TimeExpirations<I> {
    pub(crate) fn new() -> Self {
        Self {
            expiries: BinaryHeap::new(),
        }
    }

    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) {
        self.expiries.push((Reverse(expiry_time), item));
    }

    /// Expire and return items corresponding to expiration <= given certified time.
    /// Unwrap is safe because peek() is called in loop condition.
    #[allow(clippy::unwrap_used)]
    pub(crate) fn expire(&mut self, certified_time: u64) -> HashSet<I> {
        let mut ret = HashSet::new();
        while let Some((Reverse(t), _)) = self.expiries.peek() {
            if *t <= certified_time {
                let (_, item) = self.expiries.pop().unwrap();
                ret.insert(item);
            } else {
                break;
            }
        }
        ret
    }

    #[cfg(test)]
    pub(crate) fn is_empty(&self) -> bool {
        self.expiries.is_empty()
    }
}
```

**File:** consensus/src/quorum_store/tests/batch_store_test.rs (L91-184)
```rust
#[tokio::test(flavor = "multi_thread")]
async fn test_extend_expiration_vs_save() {
    let num_experiments = 2000;
    let batch_store = batch_store_for_test(2001);

    let batch_store_clone1 = batch_store.clone();
    let batch_store_clone2 = batch_store.clone();

    let digests: Vec<HashValue> = (0..num_experiments).map(|_| HashValue::random()).collect();
    let later_exp_values: Vec<PersistedValue<BatchInfoExt>> = (0..num_experiments)
        .map(|i| {
            // Pre-insert some of them.
            if i % 2 == 0 {
                assert_ok!(batch_store.save(&request_for_test(
                    &digests[i],
                    i as u64 + 30,
                    1,
                    None
                )));
            }

            request_for_test(&digests[i], i as u64 + 40, 1, None)
        })
        .collect();

    // Marshal threads to start at the same time.
    let start_flag = Arc::new(AtomicUsize::new(0));
    let start_clone1 = start_flag.clone();
    let start_clone2 = start_flag.clone();

    let save_error = Arc::new(AtomicBool::new(false));
    let save_error_clone1 = save_error.clone();
    let save_error_clone2 = save_error.clone();

    // Thread that extends expiration by saving.
    spawn_blocking(move || {
        for (i, later_exp_value) in later_exp_values.into_iter().enumerate() {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone1.load(Ordering::Acquire);
                if flag_val == 3 * i + 1 || flag_val == 3 * i + 2 {
                    break;
                }
            }

            if batch_store_clone1.save(&later_exp_value).is_err() {
                // Save in a separate flag and break so test doesn't hang.
                save_error_clone1.store(true, Ordering::Release);
                break;
            }
            start_clone1.fetch_add(1, Ordering::Relaxed);
        }
    });

    // Thread that expires.
    spawn_blocking(move || {
        for i in 0..num_experiments {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone2.load(Ordering::Acquire);
                if flag_val == 3 * i + 1
                    || flag_val == 3 * i + 2
                    || save_error_clone2.load(Ordering::Acquire)
                {
                    break;
                }
            }

            batch_store_clone2.update_certified_timestamp(i as u64 + 30);
            start_clone2.fetch_add(1, Ordering::Relaxed);
        }
    });

    for (i, &digest) in digests.iter().enumerate().take(num_experiments) {
        // Set the conditions for experiment (both threads waiting).
        while start_flag.load(Ordering::Acquire) % 3 != 0 {
            assert!(!save_error.load(Ordering::Acquire));
        }

        if i % 2 == 1 {
            assert_ok!(batch_store.save(&request_for_test(&digest, i as u64 + 30, 1, None)));
        }

        // Unleash the threads.
        start_flag.fetch_add(1, Ordering::Relaxed);
    }
    // Finish the experiment
    while start_flag.load(Ordering::Acquire) % 3 != 0 {}

    // Expire everything, call for higher times as well.
    for i in 35..50 {
        batch_store.update_certified_timestamp((i + num_experiments) as u64);
    }
}
```
