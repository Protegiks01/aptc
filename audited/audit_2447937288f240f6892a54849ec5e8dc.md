# Audit Report

## Title
Non-Deterministic Transaction Execution Due to Environmental Storage Errors Breaking Consensus Safety

## Summary
When validators experience different storage-layer errors (RocksDbIncompleteResult vs successful read) while executing the same block, the error handling mechanism does not ensure they reach the same execution conclusion. This can lead to validators computing different state roots and voting on different block executions, violating the fundamental **Deterministic Execution** invariant required for consensus safety.

## Finding Description

The vulnerability stems from how storage errors are handled during transaction execution without cross-validator consistency verification.

**Error Flow Analysis:**

1. Different storage errors are converted to the same `STORAGE_ERROR` status code: [1](#0-0) 

2. During transaction execution, storage errors trigger the `unwrap_or_discard!` macro which creates a discarded transaction output: [2](#0-1) 

3. Discarded transactions are excluded from the transaction accumulator used for state root computation: [3](#0-2) 

**Attack Scenario:**

Consider two validators A and B executing the same block with transaction T1:

- **Validator A**: Experiences `RocksDbIncompleteResult` when reading state key K
  - Error converted to `StateViewError::Other` → `STORAGE_ERROR`
  - T1 gets `TransactionStatus::Discard(STORAGE_ERROR)`
  - T1 placed in `to_discard`, excluded from state root
  - Computes state root based on remaining transactions

- **Validator B**: Successfully reads state key K (returns `Ok(None)` or `Ok(Some(value))`)
  - T1 executes normally
  - T1 gets `TransactionStatus::Keep(Success)` or other kept status
  - T1 included in `to_commit` and state root calculation
  - Computes different state root including T1's effects

**Root Cause:**

The `ExecutionStatus` enum is serialized into `TransactionInfo` which is hashed for the transaction accumulator: [4](#0-3) 

Different transaction statuses (Discard vs Keep with different execution results) produce different `TransactionInfo` hashes, leading to different accumulator roots and ultimately different state roots that validators vote on.

## Impact Explanation

**Severity: Critical** - Consensus Safety Violation

This breaks the core **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks."

Potential consequences:
1. **Consensus Split**: If validators split into groups with different execution results, no quorum may form, causing liveness failure
2. **Safety Violation**: Different state roots mean validators fundamentally disagree on the blockchain state
3. **Non-Recoverable State**: Requires manual intervention or hard fork to resolve divergent chains

This meets the Critical severity criteria: "Consensus/Safety violations" (up to $1,000,000).

## Likelihood Explanation

**Likelihood: Low to Medium**

While the vulnerability is real, triggering it requires environmental differences between validators:

1. **RocksDbIncompleteResult** occurs when iterator max_skipped_deletions is exceeded, which can happen with:
   - Different pruning schedules across validators
   - Different database compaction states
   - Varying numbers of deleted keys in RocksDB

2. Database corruption or I/O errors on some validators but not others

3. Race conditions during state synchronization creating temporary inconsistencies

These conditions can occur naturally in distributed systems but are not easily triggerable by external attackers without validator-level access. However, once such environmental differences exist, ANY transaction reading the affected state key will expose the consensus vulnerability.

## Recommendation

Implement deterministic error handling with cross-validator verification:

1. **Critical Storage Errors Should Halt Execution**: When a validator encounters STORAGE_ERROR during block execution, it should not produce an execution result but instead:
   - Refuse to vote on the block
   - Alert operators about database inconsistency
   - Attempt state resynchronization

2. **Add Execution Result Verification**: Before voting, validators should optionally verify their execution results match expected patterns (similar to optimistic execution in some consensus protocols).

3. **Database Health Checks**: Implement periodic database consistency verification to detect and repair environmental differences before they cause consensus issues.

4. **Modified Error Handling**:
```rust
// In vote_block or execute_and_insert
if execution_output.has_storage_errors() {
    // Log critical alert
    alert!("Storage errors during block execution - refusing to vote");
    // Trigger state resync
    self.initiate_state_resync();
    // Return error instead of voting
    return Err(anyhow!("Cannot vote due to storage errors"));
}
```

## Proof of Concept

Due to the environmental nature of this vulnerability (requiring different database states across validators), a full PoC requires a multi-node setup. Here's a conceptual reproduction:

**Setup:**
1. Run two validator nodes A and B
2. Artificially corrupt Node A's database to cause RocksDB errors for specific state keys
3. Submit a transaction that reads the corrupted state key

**Expected Result:**
- Node A: Transaction discarded due to STORAGE_ERROR
- Node B: Transaction executes successfully  
- Different execution outputs → Different state roots → Consensus disagreement

**Code Path to Monitor:** [5](#0-4) 

When this alert fires on one validator but not others for the same block, it indicates the vulnerability is being triggered.

---

**Notes:**

While this vulnerability represents a genuine consensus safety issue, its practical exploitability is limited by the requirement for environmental differences between validators (different database states). An unprivileged external attacker cannot directly cause these conditions without validator-level access or exploitation of separate state synchronization vulnerabilities. The issue is more accurately characterized as a **missing safeguard** against environmental failures rather than a directly exploitable attack vector.

The system implicitly assumes validators maintain identical database states but provides no mechanism to verify this assumption or gracefully handle violations. This represents a gap in the defense-in-depth strategy for consensus safety.

### Citations

**File:** storage/storage-interface/src/errors.rs (L69-77)
```rust
impl From<AptosDbError> for StateViewError {
    fn from(error: AptosDbError) -> Self {
        match error {
            AptosDbError::NotFound(msg) => StateViewError::NotFound(msg),
            AptosDbError::Other(msg) => StateViewError::Other(msg),
            _ => StateViewError::Other(format!("{}", error)),
        }
    }
}
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L176-189)
```rust
macro_rules! unwrap_or_discard {
    ($res:expr) => {
        match $res {
            Ok(s) => s,
            Err(e) => {
                // covers both VMStatus itself and VMError which can convert to VMStatus
                let s: VMStatus = e.into();

                let o = discarded_output(s.status_code());
                return (s, o);
            },
        }
    };
}
```

**File:** execution/executor/src/workflow/do_ledger_update.rs (L30-34)
```rust
        // Assemble `TransactionInfo`s
        let (transaction_infos, transaction_info_hashes) = Self::assemble_transaction_infos(
            &execution_output.to_commit,
            state_checkpoint_output.state_checkpoint_hashes.clone(),
        );
```

**File:** types/src/transaction/mod.rs (L2023-2051)
```rust
#[derive(Clone, CryptoHasher, BCSCryptoHash, Debug, Eq, PartialEq, Serialize, Deserialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct TransactionInfoV0 {
    /// The amount of gas used.
    gas_used: u64,

    /// The vm status. If it is not `Executed`, this will provide the general error class. Execution
    /// failures and Move abort's receive more detailed information. But other errors are generally
    /// categorized with no status code or other information
    status: ExecutionStatus,

    /// The hash of this transaction.
    transaction_hash: HashValue,

    /// The root hash of Merkle Accumulator storing all events emitted during this transaction.
    event_root_hash: HashValue,

    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,

    /// The root hash of the Sparse Merkle Tree describing the world state at the end of this
    /// transaction. Depending on the protocol configuration, this can be generated periodical
    /// only, like per block.
    state_checkpoint_hash: Option<HashValue>,

    /// The hash value summarizing PersistedAuxiliaryInfo.
    auxiliary_info_hash: Option<HashValue>,
}
```

**File:** aptos-move/block-executor/src/view.rs (L1151-1160)
```rust
        if ret.is_err() {
            // Even speculatively, reading from base view should not return an error.
            // Thus, this critical error log and count does not need to be buffered.
            let log_context = AdapterLogSchema::new(self.base_view.id(), self.txn_idx as usize);
            alert!(
                log_context,
                "[VM, StateView] Error getting data from storage for {:?}",
                state_key
            );
        }
```
