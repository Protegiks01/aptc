# Audit Report

## Title
State Snapshot Restore Allows Mismatched Key-Range Data Without Validation

## Summary
The state snapshot backup/restore system fails to validate that blob data matches the declared `first_key`/`last_key` range in the manifest. The `SparseMerkleRangeProof` only verifies the last key actually present in the blob data, not the declared `last_key` in the manifest, allowing corrupted state to be restored.

## Finding Description

The `StateSnapshotChunk` structure separates metadata (key range) from actual data: [1](#0-0) 

During restore, blobs and proofs are loaded independently without cross-validation: [2](#0-1) 

The `add_chunk` implementation adds all keys from the blobs but only verifies the proof for the **last key actually added**: [3](#0-2) 

The `verify()` method only validates the rightmost leaf (the last key added to the tree): [4](#0-3) 

The `SparseMerkleRangeProof::verify()` confirms this single-key verification: [5](#0-4) 

Finally, `finish_impl()` completes without verifying the final root hash matches expectations: [6](#0-5) 

**Attack Path:**
1. Attacker crafts malicious backup with manifest declaring `first_key=hash(A)`, `last_key=hash(C)`
2. Blob file contains keys `[A, B, X]` where `X â‰  C` (wrong key or out-of-range key)
3. Proof file contains valid `SparseMerkleRangeProof` for `hash(X)` (obtained from legitimate state)
4. During restore, all keys `[A, B, X]` are written to storage
5. Proof verification passes because `hash(X)` is correctly proven
6. No validation occurs that `hash(X) == hash(C)` (declared last_key)
7. Corrupted state persists in database

This breaks **Invariant #4: State Consistency** - state transitions must be atomic and verifiable via Merkle proofs. The system accepts unverified state data that doesn't match the declared key range.

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This qualifies as "State inconsistencies requiring intervention" because:
- Malicious backups can inject incorrect state keys into the database
- The corrupted state passes cryptographic verification during restore
- Nodes restoring from malicious backups will have inconsistent state
- The mismatch may not be detected until subsequent operations fail
- Requires manual intervention to identify and repair corrupted state

The impact is limited to Medium (not Critical) because:
- Requires ability to tamper with backup files (not remote exploit)
- The next restore attempt would detect root hash mismatch (line 200-204 in restore/mod.rs)
- Does not directly cause consensus failures or fund loss
- Primarily affects disaster recovery scenarios

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is feasible because:
- Backup files are often stored in cloud storage or shared filesystems
- No cryptographic signatures protect backup file integrity
- The manifest is JSON (easily modifiable)
- Blob and proof files are separate, enabling mix-and-match attacks
- Organizations routinely restore from backups during disaster recovery

However, it requires:
- Access to modify backup files before restore
- Knowledge of valid state keys and proofs from legitimate backups
- Understanding of the Jellyfish Merkle tree structure

## Recommendation

Add validation that the actual keys in blob data match the declared key range:

```rust
// In StateSnapshotRestoreController::run_impl() after loading blobs
pub async fn run_impl(self) -> Result<()> {
    // ... existing code ...
    
    while let Some((chunk_idx, chunk, mut blobs, proof)) = futs_stream.try_next().await? {
        // ADDED: Validate key range matches manifest
        if !blobs.is_empty() {
            let actual_first_key = blobs.first().unwrap().0.hash();
            let actual_last_key = blobs.last().unwrap().0.hash();
            
            ensure!(
                actual_first_key == chunk.first_key,
                "Blob first key mismatch: expected {:?}, got {:?}",
                chunk.first_key,
                actual_first_key
            );
            
            ensure!(
                actual_last_key == chunk.last_key,
                "Blob last key mismatch: expected {:?}, got {:?}",
                chunk.last_key,
                actual_last_key
            );
        }
        
        // ... rest of existing code ...
    }
}
```

Additionally, add final root hash verification in `JellyfishMerkleRestore::finish_impl()`:

```rust
pub fn finish_impl(mut self) -> Result<()> {
    self.wait_for_async_commit()?;
    
    // ... existing code ...
    
    self.freeze(0);
    self.store.write_node_batch(&self.frozen_nodes)?;
    
    // ADDED: Verify final root hash
    let root_node_key = NodeKey::new_empty_path(self.version);
    let root_node = self.store.get_node(&root_node_key)?;
    ensure!(
        root_node.hash() == self.expected_root_hash,
        "Final root hash mismatch: expected {:?}, got {:?}",
        self.expected_root_hash,
        root_node.hash()
    );
    
    Ok(())
}
```

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[test]
fn test_mismatched_key_range_restore() {
    use aptos_crypto::HashValue;
    use aptos_types::state_store::{state_key::StateKey, state_value::StateValue};
    
    // Setup: Create legitimate state with keys A, B, C
    let key_a = StateKey::raw(b"key_a");
    let key_b = StateKey::raw(b"key_b");
    let key_c = StateKey::raw(b"key_c");
    let key_x = StateKey::raw(b"key_x_malicious");
    
    let val = StateValue::new_legacy(b"value".to_vec().into());
    
    // Create malicious chunk manifest
    let malicious_chunk = StateSnapshotChunk {
        first_idx: 0,
        last_idx: 2,
        first_key: key_a.hash(),
        last_key: key_c.hash(), // Declares key_c
        blobs: /* file with keys [A, B, X] instead of [A, B, C] */,
        proof: /* valid proof for key_x */,
    };
    
    // During restore, keys A, B, X are added to tree
    // Proof for X verifies successfully
    // No error is raised even though X != C
    // Result: Corrupted state in database
}
```

## Notes

This vulnerability exists because the backup/restore system treats the manifest's `first_key`/`last_key` as advisory metadata for resumption logic, not as cryptographically enforced constraints. The proof-based verification only validates individual keys connect to the root, not that they match declared ranges. This creates a gap where mismatched data can be accepted during restore operations.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L9-27)
```rust
/// A chunk of a state snapshot manifest, representing accounts in the key range
/// [`first_key`, `last_key`] (right side inclusive).
#[derive(Deserialize, Serialize)]
pub struct StateSnapshotChunk {
    /// index of the first account in this chunk over all accounts.
    pub first_idx: usize,
    /// index of the last account in this chunk over all accounts.
    pub last_idx: usize,
    /// key of the first account in this chunk.
    pub first_key: HashValue,
    /// key of the last account in this chunk.
    pub last_key: HashValue,
    /// Repeated `len(record) + record` where `record` is BCS serialized tuple
    /// `(key, state_value)`
    pub blobs: FileHandle,
    /// BCS serialized `SparseMerkleRangeProof` that proves this chunk adds up to the root hash
    /// indicated in the backup (`StateSnapshotBackup::root_hash`).
    pub proof: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L191-215)
```rust
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
                    Result::<_>::Ok((chunk_idx, chunk, blobs, proof))
                })
                .await?
            }
        });
        let con = self.concurrent_downloads;
        let mut futs_stream = stream::iter(futs_iter).buffered_x(con * 2, con);
        let mut start = None;
        while let Some((chunk_idx, chunk, mut blobs, proof)) = futs_stream.try_next().await? {
            start = start.or_else(|| Some(Instant::now()));
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["add_state_chunk"]);
            let receiver = receiver.clone();
            if self.validate_modules {
                blobs = tokio::task::spawn_blocking(move || {
                    Self::validate_modules(&blobs);
                    blobs
                })
                .await?;
            }
            tokio::task::spawn_blocking(move || {
                receiver.lock().as_mut().unwrap().add_chunk(blobs, proof)
            })
            .await??;
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L373-391)
```rust
        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L628-634)
```rust
    fn verify(&self, proof: SparseMerkleRangeProof) -> Result<()> {
        let previous_leaf = self
            .previous_leaf
            .as_ref()
            .expect("The previous leaf must exist.");

        let previous_key = previous_leaf.account_key();
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L750-789)
```rust
    pub fn finish_impl(mut self) -> Result<()> {
        self.wait_for_async_commit()?;
        // Deal with the special case when the entire tree has a single leaf or null node.
        if self.partial_nodes.len() == 1 {
            let mut num_children = 0;
            let mut leaf = None;
            for i in 0..16 {
                if let Some(ref child_info) = self.partial_nodes[0].children[i] {
                    num_children += 1;
                    if let ChildInfo::Leaf(node) = child_info {
                        leaf = Some(node.clone());
                    }
                }
            }

            match num_children {
                0 => {
                    let node_key = NodeKey::new_empty_path(self.version);
                    assert!(self.frozen_nodes.is_empty());
                    self.frozen_nodes.insert(node_key, Node::Null);
                    self.store.write_node_batch(&self.frozen_nodes)?;
                    return Ok(());
                },
                1 => {
                    if let Some(node) = leaf {
                        let node_key = NodeKey::new_empty_path(self.version);
                        assert!(self.frozen_nodes.is_empty());
                        self.frozen_nodes.insert(node_key, node.into());
                        self.store.write_node_batch(&self.frozen_nodes)?;
                        return Ok(());
                    }
                },
                _ => (),
            }
        }

        self.freeze(0);
        self.store.write_node_batch(&self.frozen_nodes)?;
        Ok(())
    }
```

**File:** types/src/proof/definition.rs (L780-826)
```rust
    /// Verifies that the rightmost known leaf exists in the tree and that the resulting
    /// root hash matches the expected root hash.
    pub fn verify(
        &self,
        expected_root_hash: HashValue,
        rightmost_known_leaf: SparseMerkleLeafNode,
        left_siblings: Vec<HashValue>,
    ) -> Result<()> {
        let num_siblings = left_siblings.len() + self.right_siblings.len();
        let mut left_sibling_iter = left_siblings.iter();
        let mut right_sibling_iter = self.right_siblings().iter();

        let mut current_hash = rightmost_known_leaf.hash();
        for bit in rightmost_known_leaf
            .key()
            .iter_bits()
            .rev()
            .skip(HashValue::LENGTH_IN_BITS - num_siblings)
        {
            let (left_hash, right_hash) = if bit {
                (
                    *left_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing left sibling."))?,
                    current_hash,
                )
            } else {
                (
                    current_hash,
                    *right_sibling_iter
                        .next()
                        .ok_or_else(|| format_err!("Missing right sibling."))?,
                )
            };
            current_hash = SparseMerkleInternalNode::new(left_hash, right_hash).hash();
        }

        ensure!(
            current_hash == expected_root_hash,
            "{}: Root hashes do not match. Actual root hash: {:x}. Expected root hash: {:x}.",
            type_name::<Self>(),
            current_hash,
            expected_root_hash,
        );

        Ok(())
    }
```
