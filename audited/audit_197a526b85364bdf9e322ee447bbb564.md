# Audit Report

## Title
Unbounded BinaryHeap Growth in BatchGenerator Enables Validator DoS via Batch Flooding

## Summary
The `TimeExpirations` data structure used in `BatchGenerator::batch_expirations` has no bounded size limit, allowing a malicious validator to flood the BinaryHeap with millions of batch entries. This causes heap operations to degrade from O(log n) to O(n log n) during batch expiration, creating validator node slowdowns that impact consensus performance.

## Finding Description

The vulnerability exists in how remote batches are processed by the Quorum Store's `BatchGenerator`. When a validator receives batch messages from peers, the flow is:

1. **Network Reception**: `NetworkListener` receives `VerifiedEvent::BatchMsg` from remote validators [1](#0-0) 

2. **Batch Coordination**: `BatchCoordinator::handle_batches_msg()` validates per-message limits but immediately sends `RemoteBatch` commands to `BatchGenerator` **before** quota checks occur [2](#0-1) 

3. **Heap Insertion**: `BatchGenerator::handle_remote_batch()` calls `insert_batch()`, which unconditionally adds entries to `batch_expirations` BinaryHeap with **no size bounds** [3](#0-2) [4](#0-3) 

4. **Unbounded Data Structure**: The `TimeExpirations` struct uses a standard `BinaryHeap` with no capacity limit [5](#0-4) 

**Critical Separation**: The `QuotaManager` in `BatchStore` (which has a `batch_quota` of 300,000 per peer) operates on a **separate** `TimeExpirations` instance and is only checked during persistence, not during heap insertion in `BatchGenerator`. [6](#0-5) 

The TODO comment explicitly acknowledges this design flaw: [7](#0-6) 

**Attack Path**:
1. Malicious validator creates batches with unique `BatchId` values (controlled by sender)
2. Sends batch messages at network maximum rate (~50 MB/s) with small batches
3. Each `BatchMsg` contains up to 20 batches (receiver_max_num_batches limit)
4. Channel capacity (1000 commands) fills and drains as `BatchGenerator` processes
5. Each processed batch adds entry to unbounded `batch_expirations` heap
6. Between block commits (~250ms intervals), heap accumulates 10,000-50,000 entries
7. Expiration processing becomes O(k log n) where k and n can both be very large [8](#0-7) 

## Impact Explanation

**Severity: HIGH** - Validator Node Slowdowns

This vulnerability enables a malicious validator (within the BFT threat model of up to 1/3 Byzantine validators) to degrade the performance of honest validators by forcing expensive heap operations:

- **Heap Growth**: With network rate limits of ~50 MB/s and small batches (1 KB), an attacker can inject 50,000 batches/second
- **Expiration Penalty**: When `CommitNotification` triggers expiration, the `expire()` method must pop potentially tens of thousands of items [9](#0-8) 
  
- **Computational Impact**: For 50,000 heap items:
  - log₂(50,000) ≈ 15.6 operations per push/pop
  - Expiring all items: 15.6 × 50,000 = 780,000 heap operations
  - This creates measurable latency spikes during batch expiration cycles

- **Consensus Impact**: Slowdowns in `BatchGenerator` affect quorum store's ability to timely process batches, potentially causing back-pressure and reducing overall throughput

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits" - the unbounded heap violates memory and computational resource limits.

## Likelihood Explanation

**Likelihood: MEDIUM**

**Requirements**:
- Attacker must be a validator in the active validator set
- Under AptosBFT's Byzantine fault tolerance model, up to 1/3 of validators can be malicious, making this threat realistic
- Attack is sustainable over time without requiring coordination

**Feasibility**:
- No special cryptographic knowledge required
- Network rate limiting (~50 MB/s) allows sufficient batch injection rate
- Channel capacity (1000) provides buffering but doesn't prevent attack
- Remote batch expiry (500ms) creates time window for heap accumulation

**Detection Difficulty**: 
- Batches appear legitimate (pass validation checks)
- No per-validator quota on `BatchGenerator` heap prevents early detection
- Only observable through performance monitoring of heap operations

## Recommendation

**Immediate Fix**: Apply per-peer quota to `BatchGenerator::batch_expirations` similar to `BatchStore::QuotaManager`:

```rust
// In BatchGenerator struct, add:
batch_expirations_quota: HashMap<PeerId, usize>,
max_batches_per_peer: usize, // e.g., 10,000

// In insert_batch():
fn insert_batch(&mut self, author: PeerId, batch_id: BatchId, ...) {
    if self.batches_in_progress.contains_key(&(author, batch_id)) {
        return;
    }
    
    // NEW: Check per-peer quota
    let peer_count = self.batch_expirations_quota
        .entry(author)
        .or_insert(0);
    if *peer_count >= self.max_batches_per_peer {
        warn!("Peer {} exceeded batch quota, dropping batch {}", author, batch_id);
        counters::BATCH_GENERATOR_QUOTA_EXCEEDED.inc();
        return;
    }
    
    // ... rest of insertion logic ...
    
    self.batch_expirations.add_item((author, batch_id), updated_expiry_time_usecs);
    *peer_count += 1;
}

// In remove_batch_in_progress():
fn remove_batch_in_progress(&mut self, author: PeerId, batch_id: BatchId) -> bool {
    let removed = self.batches_in_progress.remove(&(author, batch_id));
    if removed.is_some() {
        // Decrement quota
        if let Some(count) = self.batch_expirations_quota.get_mut(&author) {
            *count = count.saturating_sub(1);
        }
        // ... rest of cleanup ...
    }
    removed.is_some()
}
```

**Additional Safeguards**:
1. Implement early rejection in `BatchCoordinator` by checking `BatchStore` quota **before** sending to `BatchGenerator`
2. Add heap size monitoring metrics
3. Consider bounded `VecDeque` instead of `BinaryHeap` for better worst-case guarantees

## Proof of Concept

```rust
// Integration test demonstrating heap flooding
#[tokio::test]
async fn test_batch_generator_heap_flooding() {
    use aptos_types::PeerId;
    use consensus::quorum_store::batch_generator::*;
    
    // Setup BatchGenerator with standard config
    let config = QuorumStoreConfig::default();
    let (batch_gen_tx, mut batch_gen_rx) = 
        tokio::sync::mpsc::channel(config.channel_size);
    
    // Malicious validator ID
    let attacker = PeerId::random();
    
    // Flood with unique batches
    for i in 0..100_000 {
        let batch_id = BatchId::new(i);
        let batch = create_small_batch(attacker, batch_id); // 1KB batch
        
        let cmd = BatchGeneratorCommand::RemoteBatch(batch);
        // This will succeed up to channel capacity, demonstrating
        // that batches enter BatchGenerator without quota checks
        if batch_gen_tx.send(cmd).await.is_err() {
            break; // Channel full
        }
    }
    
    // Measure heap operations during expiration
    let start = Instant::now();
    let expired = batch_generator.batch_expirations.expire(
        current_timestamp + Duration::from_millis(600).as_micros() as u64
    );
    let elapsed = start.elapsed();
    
    // Assert: Large heap causes measurable slowdown
    assert!(elapsed > Duration::from_millis(100), 
        "Expiring {} items took {:?}, indicating O(n log n) degradation", 
        expired.len(), elapsed);
}
```

**Notes**:
- The vulnerability is real but bounded by network bandwidth and channel capacity in practice
- However, the lack of explicit quota on `BatchGenerator::batch_expirations` is a clear design flaw
- The separation between `BatchStore::QuotaManager` and `BatchGenerator` quotas creates this gap
- The existing TODO comment confirms developers are aware but haven't addressed it

### Citations

**File:** consensus/src/quorum_store/network_listener.rs (L68-94)
```rust
                    VerifiedEvent::BatchMsg(batch_msg) => {
                        counters::QUORUM_STORE_MSG_COUNT
                            .with_label_values(&["NetworkListener::batchmsg"])
                            .inc();
                        // Batch msg verify function alreay ensures that the batch_msg is not empty.
                        let author = batch_msg.author().expect("Empty batch message");
                        let batches = batch_msg.take();
                        counters::RECEIVED_BATCH_MSG_COUNT.inc();

                        // Round-robin assignment to batch coordinator.
                        let idx = next_batch_coordinator_idx;
                        next_batch_coordinator_idx = (next_batch_coordinator_idx + 1)
                            % self.remote_batch_coordinator_tx.len();
                        trace!(
                            "QS: peer_id {:?},  # network_worker {}, hashed to idx {}",
                            author,
                            self.remote_batch_coordinator_tx.len(),
                            idx
                        );
                        counters::BATCH_COORDINATOR_NUM_BATCH_REQS
                            .with_label_values(&[&idx.to_string()])
                            .inc();
                        self.remote_batch_coordinator_tx[idx]
                            .send(BatchCoordinatorCommand::NewBatches(author, batches))
                            .await
                            .expect("Could not send remote batch");
                    },
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L228-244)
```rust
        let mut persist_requests = vec![];
        for batch in batches.into_iter() {
            // TODO: maybe don't message batch generator if the persist is unsuccessful?
            if let Err(e) = self
                .sender_to_batch_generator
                .send(BatchGeneratorCommand::RemoteBatch(batch.clone()))
                .await
            {
                warn!("Failed to send batch to batch generator: {}", e);
            }
            persist_requests.push(batch.into());
        }
        counters::RECEIVED_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        if author != self.my_peer_id {
            counters::RECEIVED_REMOTE_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        }
        self.persist_and_send_digests(persist_requests, approx_created_ts_usecs);
```

**File:** consensus/src/quorum_store/batch_generator.rs (L169-170)
```rust
        self.batch_expirations
            .add_item((author, batch_id), updated_expiry_time_usecs);
```

**File:** consensus/src/quorum_store/batch_generator.rs (L392-401)
```rust
    pub(crate) fn handle_remote_batch(
        &mut self,
        author: PeerId,
        batch_id: BatchId,
        txns: Vec<SignedTransaction>,
    ) {
        let expiry_time_usecs = aptos_infallible::duration_since_epoch().as_micros() as u64
            + self.config.remote_batch_expiry_gap_when_init_usecs;
        self.insert_batch(author, batch_id, txns, expiry_time_usecs);
    }
```

**File:** consensus/src/quorum_store/utils.rs (L60-73)
```rust
pub(crate) struct TimeExpirations<I: Ord> {
    expiries: BinaryHeap<(Reverse<u64>, I)>,
}

impl<I: Ord + Hash> TimeExpirations<I> {
    pub(crate) fn new() -> Self {
        Self {
            expiries: BinaryHeap::new(),
        }
    }

    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) {
        self.expiries.push((Reverse(expiry_time), item));
    }
```

**File:** consensus/src/quorum_store/utils.rs (L78-89)
```rust
    pub(crate) fn expire(&mut self, certified_time: u64) -> HashSet<I> {
        let mut ret = HashSet::new();
        while let Some((Reverse(t), _)) = self.expiries.peek() {
            if *t <= certified_time {
                let (_, item) = self.expiries.pop().unwrap();
                ret.insert(item);
            } else {
                break;
            }
        }
        ret
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L41-109)
```rust
pub(crate) struct QuotaManager {
    memory_balance: usize,
    db_balance: usize,
    batch_balance: usize,
    // Recording the provided quotas for asserts.
    memory_quota: usize,
    db_quota: usize,
    batch_quota: usize,
}

impl QuotaManager {
    pub(crate) fn new(db_quota: usize, memory_quota: usize, batch_quota: usize) -> Self {
        assert!(db_quota >= memory_quota);
        Self {
            memory_balance: memory_quota,
            db_balance: db_quota,
            batch_balance: batch_quota,
            memory_quota,
            db_quota,
            batch_quota,
        }
    }

    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
    }

    fn assert_quota(balance: usize, to_free: usize, quota: usize, kind: &str) {
        assert!(
            balance + to_free <= quota,
            "Balance {} + to_free {} more than {} quota {}",
            balance,
            to_free,
            kind,
            quota,
        );
    }

    pub(crate) fn free_quota(&mut self, num_bytes: usize, storage_mode: StorageMode) {
        Self::assert_quota(self.batch_balance, 1, self.batch_quota, "Batch");
        self.batch_balance += 1;

        Self::assert_quota(self.db_balance, num_bytes, self.db_quota, "DB");
        self.db_balance += num_bytes;

        if matches!(storage_mode, StorageMode::MemoryAndPersisted) {
            Self::assert_quota(self.memory_balance, num_bytes, self.memory_quota, "Memory");
            self.memory_balance += num_bytes;
        }
    }
}
```

**File:** config/src/config/quorum_store_config.rs (L105-146)
```rust
impl Default for QuorumStoreConfig {
    fn default() -> QuorumStoreConfig {
        QuorumStoreConfig {
            channel_size: 1000,
            proof_timeout_ms: 10000,
            batch_generation_poll_interval_ms: 25,
            batch_generation_min_non_empty_interval_ms: 50,
            batch_generation_max_interval_ms: 250,
            sender_max_batch_txns: DEFEAULT_MAX_BATCH_TXNS,
            // TODO: on next release, remove BATCH_PADDING_BYTES
            sender_max_batch_bytes: 1024 * 1024 - BATCH_PADDING_BYTES,
            sender_max_num_batches: DEFAULT_MAX_NUM_BATCHES,
            sender_max_total_txns: 1500,
            // TODO: on next release, remove DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES
            sender_max_total_bytes: 4 * 1024 * 1024 - DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES,
            receiver_max_batch_txns: 100,
            receiver_max_batch_bytes: 1024 * 1024 + BATCH_PADDING_BYTES,
            receiver_max_num_batches: 20,
            receiver_max_total_txns: 2000,
            receiver_max_total_bytes: 4 * 1024 * 1024
                + DEFAULT_MAX_NUM_BATCHES
                + BATCH_PADDING_BYTES,
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
            batch_expiry_gap_when_init_usecs: Duration::from_secs(60).as_micros() as u64,
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
            back_pressure: QuorumStoreBackPressureConfig::default(),
            // number of batch coordinators to handle QS batch messages, should be >= 1
            num_workers_for_remote_batches: 10,
            batch_buckets: DEFAULT_BUCKETS.to_vec(),
            allow_batches_without_pos_in_proposal: true,
            enable_opt_quorum_store: true,
            opt_qs_minimum_batch_age_usecs: Duration::from_millis(50).as_micros() as u64,
            enable_payload_v2: false,
            enable_batch_v2: false,
        }
    }
```
