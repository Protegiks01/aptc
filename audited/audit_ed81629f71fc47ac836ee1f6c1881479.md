# Audit Report

## Title
Indexer State Inconsistency: Missing CurrentTokenOwnership Records Due to Cross-Batch Table Metadata Loss

## Summary
The Aptos indexer fails to create `CurrentTokenOwnership` records when table metadata is unavailable during token operation processing. When a token operation occurs in a transaction batch that lacks the corresponding TokenStore resource write, the indexer creates a historical `TokenOwnership` record (with null `owner_address`) but skips creating the `CurrentTokenOwnership` record, causing tokens to exist in historical records but not in queryable current state.

## Finding Description
The vulnerability exists in the `TokenOwnership::from_token` method where missing table metadata causes a state inconsistency between historical and current ownership records. [1](#0-0) 

The `table_handle_to_owner` mapping is built per-batch from WriteResource changes in the current transaction batch only: [2](#0-1) [3](#0-2) 

When table metadata is missing (None case at line 114), the code:
1. Logs a warning
2. Sets `curr_token_ownership = None` 
3. Creates `TokenOwnership` with `owner_address: None`
4. Returns without creating `CurrentTokenOwnership`

The `CurrentTokenOwnership` struct requires a non-optional `owner_address`: [4](#0-3) 

**Breaking Invariant:** The indexer violates the implicit invariant that current state tables should accurately reflect the latest historical state. Tokens become invisible in current state queries despite existing in historical records and on-chain.

**Scenario:**
1. Transaction T1 (Batch 1, version 1000): User creates/receives TokenStore → metadata available in batch
2. Transaction T2 (Batch 2, version 2000): Token transferred to user's TokenStore → metadata NOT in this batch
3. Indexer processes Batch 2: Finds no metadata for the table handle
4. Result: 
   - `token_ownerships` table has record with `owner_address = NULL`
   - `current_token_ownerships` table has NO record
   - User's token is invisible to indexer queries

## Impact Explanation
**Severity: Medium** - State inconsistencies requiring intervention

Per Aptos bug bounty criteria for Medium severity: "State inconsistencies requiring intervention"

However, this is an **indexer-only** issue with limited impact:
- ✅ State inconsistency: Current vs historical tables diverge
- ✅ Requires intervention: Manual reindexing needed to fix
- ❌ NO fund loss: Blockchain state remains correct
- ❌ NO consensus impact: Off-chain component only
- ❌ NO blockchain availability issues

**Impact Scope:**
- Users cannot see affected tokens via indexer GraphQL API
- Token supply calculations may be incorrect in indexer
- Applications relying on `current_token_ownerships` queries miss tokens
- The blockchain itself maintains correct state (tokens exist on-chain)

**Limitation:** This affects the **indexer query layer**, not the blockchain core. While inconvenient for users and applications, it does not compromise blockchain security, consensus, or fund safety.

## Likelihood Explanation
**Likelihood: Medium to High** - Occurs naturally during normal operations

This condition occurs when:
- Token operations span multiple transaction batches
- TokenStore resource updates occur in different batches than token transfers
- Indexer processes batches independently without persistent metadata cache
- High transaction volume causes metadata to be split across batches

**Frequency:** Likely to occur regularly in production, especially:
- During periods of high token transfer activity
- When users receive tokens after their TokenStore was created in earlier blocks
- During indexer catch-up after downtime (processing historical batches)

**Attacker Requirements:** None - occurs naturally in the system without malicious intervention.

## Recommendation
Implement persistent cross-batch metadata caching for table handle mappings. Options include:

1. **Database-backed metadata cache:** Query `current_token_ownerships` or a dedicated metadata table to retrieve owner information when missing from current batch

2. **RocksDB integration:** Leverage the existing IndexerAsyncV2 table info cache: [5](#0-4) 

3. **Graceful degradation:** When metadata is missing, query the blockchain state directly via API context to retrieve TokenStore owner

**Code Fix Approach:**
```rust
// In token_ownerships.rs, around line 88-123
let maybe_table_metadata = table_handle_to_owner.get(&table_handle)
    .or_else(|| {
        // Fallback: query database for existing ownership record
        query_owner_from_database(conn, &table_handle)
    })
    .or_else(|| {
        // Fallback: query blockchain state
        query_owner_from_chain_state(context, &table_handle)
    });
```

## Proof of Concept
**Reproduction Steps:**

1. **Setup:** Deploy token contract and create TokenStore for user A

2. **Batch 1 (Version 1000):**
   ```
   Transaction: Initialize TokenStore for 0xA
   WriteResource: 0x3::token::TokenStore { tokens: { handle: "0x123..." } }
   Result: table_handle_to_owner["0x123..."] = { owner: "0xA", type: "TokenStore" }
   ```

3. **Batch 2 (Version 2000):** 
   ```
   Transaction: Transfer token to 0xA
   WriteTableItem: handle="0x123...", key=TokenId, value=Token
   NO WriteResource for TokenStore (already exists from Batch 1)
   Result: table_handle_to_owner["0x123..."] = None (missing!)
   ```

4. **Verify Inconsistency:**
   ```sql
   -- Historical table has record (with NULL owner)
   SELECT * FROM token_ownerships 
   WHERE transaction_version = 2000 AND table_handle = '0x123...';
   -- Returns: 1 row, owner_address = NULL
   
   -- Current table missing record
   SELECT * FROM current_token_ownerships
   WHERE token_data_id_hash = '<hash>' AND property_version = 0 AND owner_address = '0xA';
   -- Returns: 0 rows (MISSING!)
   ```

5. **Demonstrate Impact:**
   ```graphql
   query GetUserTokens {
     current_token_ownerships(where: {owner_address: {_eq: "0xA"}}) {
       token_data_id_hash
       amount
     }
   }
   # Result: Missing the token transferred in Batch 2
   ```

**Note:** Full PoC requires running indexer infrastructure with PostgreSQL database and processing multi-batch transaction sequences.

---

## Notes
This vulnerability specifically affects the **indexer subsystem**, not the blockchain consensus or execution layers. While it creates real UX problems for users and applications querying token ownership, the blockchain state itself remains secure and correct. Users can verify actual ownership by querying blockchain state directly, though this requires bypassing the indexer APIs that most applications rely on.

The issue is exacerbated by the fact that `table_handle_to_owner` is ephemeral (per-batch only) and lacks persistent caching across transaction batches, as evidenced by the comment acknowledging within-batch handling but not cross-batch scenarios.

### Citations

**File:** crates/indexer/src/models/token_models/token_ownerships.rs (L47-60)
```rust
pub struct CurrentTokenOwnership {
    pub token_data_id_hash: String,
    pub property_version: BigDecimal,
    pub owner_address: String,
    pub creator_address: String,
    pub collection_name: String,
    pub name: String,
    pub amount: BigDecimal,
    pub token_properties: serde_json::Value,
    pub last_transaction_version: i64,
    pub collection_data_id_hash: String,
    pub table_type: String,
    pub last_transaction_timestamp: chrono::NaiveDateTime,
}
```

**File:** crates/indexer/src/models/token_models/token_ownerships.rs (L95-123)
```rust
        let (curr_token_ownership, owner_address, table_type) = match maybe_table_metadata {
            Some(tm) => (
                Some(CurrentTokenOwnership {
                    collection_data_id_hash: token.collection_data_id_hash.clone(),
                    token_data_id_hash: token.token_data_id_hash.clone(),
                    property_version: token.property_version.clone(),
                    owner_address: standardize_address(&tm.owner_address),
                    creator_address: standardize_address(&token.creator_address.clone()),
                    collection_name: token.collection_name.clone(),
                    name: token.name.clone(),
                    amount: amount.clone(),
                    token_properties: token.token_properties.clone(),
                    last_transaction_version: txn_version,
                    table_type: tm.table_type.clone(),
                    last_transaction_timestamp: token.transaction_timestamp,
                }),
                Some(standardize_address(&tm.owner_address)),
                Some(tm.table_type.clone()),
            ),
            None => {
                aptos_logger::warn!(
                    transaction_version = txn_version,
                    table_handle = table_handle,
                    "Missing table handle metadata for TokenStore. {:?}",
                    table_handle_to_owner
                );
                (None, None, None)
            },
        };
```

**File:** crates/indexer/src/models/token_models/tokens.rs (L350-373)
```rust
    pub fn get_table_handle_to_owner_from_transactions(
        transactions: &[APITransaction],
    ) -> TableHandleToOwner {
        let mut table_handle_to_owner: TableHandleToOwner = HashMap::new();
        // Do a first pass to get all the table metadata in the batch.
        for transaction in transactions {
            if let APITransaction::UserTransaction(user_txn) = transaction {
                let txn_version = user_txn.info.version.0 as i64;
                for wsc in &user_txn.info.changes {
                    if let APIWriteSetChange::WriteResource(write_resource) = wsc {
                        let maybe_map = TableMetadataForToken::get_table_handle_to_owner(
                            write_resource,
                            txn_version,
                        )
                        .unwrap();
                        if let Some(map) = maybe_map {
                            table_handle_to_owner.extend(map);
                        }
                    }
                }
            }
        }
        table_handle_to_owner
    }
```

**File:** crates/indexer/src/processors/token_processor.rs (L860-863)
```rust
        // First get all token related table metadata from the batch of transactions. This is in case
        // an earlier transaction has metadata (in resources) that's missing from a later transaction.
        let table_handle_to_owner =
            TableMetadataForToken::get_table_handle_to_owner_from_transactions(&transactions);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/table_info_service.rs (L31-44)
```rust
/// TableInfoService is responsible for parsing table info from transactions and writing them to rocksdb.
/// Not thread safe.
pub struct TableInfoService {
    pub parser_task_count: u16,
    pub parser_batch_size: u16,
    pub context: Arc<ApiContext>,
    pub indexer_async_v2: Arc<IndexerAsyncV2>,

    // Backup and restore service. If not enabled, this will be None.
    pub backup_restore_operator: Option<Arc<GcsBackupRestoreOperator>>,

    current_version: AtomicU64,
    aborted: AtomicBool,
}
```
