# Audit Report

## Title
Thread Pool Exhaustion in Sparse Merkle Tree Update via Crafted State Update Patterns

## Summary
An attacker can craft transaction state updates that trigger excessive parallel task spawning in the Sparse Merkle Tree (SMT) update thread pool, causing thread exhaustion through blocking database I/O operations. This results in validator node slowdowns and temporary denial of service.

## Finding Description

The vulnerability exists in the parallel SMT update mechanism. The `SubTreeUpdater::run()` function uses a dedicated rayon thread pool to parallelize tree traversal during state commitment. [1](#0-0) 

The recursive update logic spawns parallel tasks when processing left and right subtrees: [2](#0-1) 

The conditions for parallelization are:
- Depth ≤ 8 (`MAX_PARALLELIZABLE_DEPTH`)
- Both left and right branches have ≥2 updates (`MIN_PARALLELIZABLE_SIZE`)

At depth 8, this can spawn up to 2^8 = 256 concurrent branches. The critical issue is that during tree traversal, tasks may need to read Merkle proofs from the database: [3](#0-2) 

These proof reads are **synchronous blocking operations** that perform database I/O: [4](#0-3) 

The database reads involve multiple synchronous I/O operations per proof: [5](#0-4) 

**Attack Path:**

1. Attacker crafts a transaction with up to 8,192 state updates (within the limit): [6](#0-5) 

2. Updates are strategically distributed across the tree to maximize parallel branching at each depth level (0-8)

3. Updates target keys not in memory cache, forcing proof reads from database

4. During SMT update, up to 256 parallel tasks are spawned, many requiring database reads

5. The thread pool (32 threads by default, max 256) becomes saturated with threads blocked on synchronous database I/O: [7](#0-6) 

6. When all threads are blocked on I/O, no new tasks can be processed, causing the entire SMT update operation to stall

7. This blocks transaction commitment, leading to validator node slowdown or temporary unavailability

**Broken Invariants:**
- **Resource Limits**: All operations must respect computational limits (thread pool exhaustion violates this)
- **Move VM Safety**: Execution must respect resource constraints (thread starvation bypasses this)

## Impact Explanation

This vulnerability causes **validator node slowdowns**, meeting the **High Severity** criteria per Aptos bug bounty guidelines. While the question suggests Medium severity, the actual impact is High because:

- **Validator Node Slowdowns**: The SMT update thread pool exhaustion directly impacts transaction processing speed across all validators processing malicious transactions
- **Transaction Pipeline Blockage**: Since SMT updates are required for state commitment, exhausting this pool blocks the entire transaction pipeline
- **Multi-Node Impact**: Attackers can submit the same malicious transaction to multiple validators simultaneously
- **Consensus Participation**: Slowdowns affect validators' ability to participate timely in consensus

However, mitigating factors prevent Critical severity:
- **Temporary**: The DoS is self-resolving once I/O operations complete
- **Bounded**: Transaction size limits bound the maximum parallelization
- **No Permanent Damage**: No funds loss or consensus safety violations

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Barrier to Entry**: Any transaction sender can craft the attack - no special privileges required

2. **Within Normal Limits**: The attack uses 8,192 updates, which is within the allowed maximum per transaction

3. **Predictable Behavior**: The parallel spawning behavior is deterministic and documented in code

4. **No Detection**: There are no specific guards or monitoring for this attack pattern

5. **High Impact/Low Cost**: The attacker pays standard gas fees but can cause disproportionate validator slowdown

6. **Repeatable**: The attack can be executed repeatedly with different transactions

The only uncertainty is cache hit rates - if most proofs are cached, the attack is less effective. However, an attacker can deliberately target uncached keys.

## Recommendation

Implement multiple layers of defense:

**1. Add Dynamic Thread Pool Throttling:**
```rust
const MAX_CONCURRENT_PROOF_READS: usize = 16;
static PROOF_READ_SEMAPHORE: Lazy<Semaphore> = 
    Lazy::new(|| Semaphore::new(MAX_CONCURRENT_PROOF_READS));

impl ProofRead for ColdProvableStateSummary<'_, '_> {
    fn get_proof(&self, key: &HashValue, root_depth: usize) -> Option<SparseMerkleProofExt> {
        let _permit = PROOF_READ_SEMAPHORE.acquire();
        // ... existing code
    }
}
```

**2. Reduce MAX_PARALLELIZABLE_DEPTH:**
Change from 8 to 5 or 6, reducing maximum concurrent branches from 256 to 32-64:
```rust
const MAX_PARALLELIZABLE_DEPTH: usize = 5; // was 8
```

**3. Implement Adaptive Parallelization:**
Track thread pool saturation and disable parallelization when pool is >75% utilized:
```rust
if depth <= MAX_PARALLELIZABLE_DEPTH
    && POOL.current_num_threads() < POOL.max_num_threads() * 3 / 4
    && left.updates.len() >= MIN_PARALLELIZABLE_SIZE
    && right.updates.len() >= MIN_PARALLELIZABLE_SIZE {
    // parallelize
}
```

**4. Add Monitoring:**
Add metrics for thread pool utilization and proof read latency to detect attacks early.

## Proof of Concept

```rust
#[cfg(test)]
mod thread_exhaustion_test {
    use super::*;
    use aptos_crypto::HashValue;
    use std::collections::HashMap;
    
    #[test]
    fn test_thread_pool_exhaustion_via_crafted_updates() {
        // Create a sparse merkle tree
        let smt = SparseMerkleTree::new_empty();
        
        // Craft 8192 updates distributed across all 256 branches at depth 8
        // Each branch gets 32 updates to ensure MIN_PARALLELIZABLE_SIZE is met
        let mut updates = Vec::new();
        for i in 0..8192 {
            // Distribute updates to maximize branching
            // Use keys with different first 8 bits to trigger max depth parallelization
            let mut key_bytes = [0u8; 32];
            key_bytes[0] = (i / 32) as u8; // First byte controls first 2 depth levels
            key_bytes[1] = (i % 32) as u8;
            key_bytes[2] = (i / 256) as u8;
            
            let key = HashValue::from_slice(&key_bytes).unwrap();
            let value = HashValue::random();
            updates.push((key, Some(value)));
        }
        
        // Sort updates as required
        updates.sort_by(|a, b| a.0.cmp(&b.0));
        
        // Create a proof reader that simulates slow database reads
        let slow_proof_reader = SlowProofReader::new();
        
        // Attempt update - this should spawn 256 parallel tasks
        // With 32-thread pool and slow I/O, this will cause saturation
        let start = std::time::Instant::now();
        let result = smt.freeze(&SparseMerkleTree::new_empty())
            .batch_update_sorted_uniq(&updates, &slow_proof_reader);
        let duration = start.elapsed();
        
        // If thread pool is exhausted, operation takes significantly longer
        // Expected: linear time with thread count
        // Actual with exhaustion: much longer due to thread blocking
        assert!(duration.as_secs() > 5, "Update completed too quickly - thread pool not exhausted");
    }
    
    struct SlowProofReader;
    
    impl SlowProofReader {
        fn new() -> Self { Self }
    }
    
    impl ProofRead for SlowProofReader {
        fn get_proof(&self, _key: &HashValue, _root_depth: usize) -> Option<SparseMerkleProofExt> {
            // Simulate slow database read
            std::thread::sleep(std::time::Duration::from_millis(100));
            None // Return None to simulate uncached proof
        }
    }
}
```

## Notes

While transaction limits bound the attack severity, the lack of explicit thread pool protection in the SMT update path creates a real DoS vector. The vulnerability is particularly concerning because:

1. The dedicated SMT thread pool is a single point of failure for transaction processing
2. Synchronous database I/O in a parallel context is inherently vulnerable to resource exhaustion
3. The attack requires no special knowledge beyond understanding the tree structure

The recommended mitigations should be implemented in combination to provide defense-in-depth against this attack vector.

### Citations

**File:** storage/scratchpad/src/sparse_merkle/updater.rs (L18-24)
```rust
static POOL: Lazy<rayon::ThreadPool> = Lazy::new(|| {
    rayon::ThreadPoolBuilder::new()
        .num_threads(AptosVM::get_num_proof_reading_threads())
        .thread_name(|index| format!("smt_update_{}", index))
        .build()
        .unwrap()
});
```

**File:** storage/scratchpad/src/sparse_merkle/updater.rs (L223-228)
```rust
    ) -> Result<(Self, Self)> {
        let myself = if self.is_unknown() {
            SubTreeInfo::from_persisted(a_descendent_key, depth, proof_reader)?
        } else {
            self
        };
```

**File:** storage/scratchpad/src/sparse_merkle/updater.rs (L315-339)
```rust
    fn run(self, proof_reader: &impl ProofRead) -> Result<InMemSubTreeInfo> {
        // Limit total tasks that are potentially sent to other threads.
        const MAX_PARALLELIZABLE_DEPTH: usize = 8;
        // No point to introduce Rayon overhead if work is small.
        const MIN_PARALLELIZABLE_SIZE: usize = 2;

        let generation = self.generation;
        let depth = self.depth;
        match self.maybe_end_recursion()? {
            MaybeEndRecursion::End(ended) => Ok(ended),
            MaybeEndRecursion::Continue(myself) => {
                let (left, right) = myself.into_children(proof_reader)?;
                let (left_ret, right_ret) = if depth <= MAX_PARALLELIZABLE_DEPTH
                    && left.updates.len() >= MIN_PARALLELIZABLE_SIZE
                    && right.updates.len() >= MIN_PARALLELIZABLE_SIZE
                {
                    POOL.join(|| left.run(proof_reader), || right.run(proof_reader))
                } else {
                    (left.run(proof_reader), right.run(proof_reader))
                };

                Ok(InMemSubTreeInfo::combine(left_ret?, right_ret?, generation))
            },
        }
    }
```

**File:** storage/storage-interface/src/state_store/state_summary.rs (L326-336)
```rust
impl ProofRead for HotProvableStateSummary<'_, '_> {
    // TODO(aldenhu): return error
    fn get_proof(&self, key: &HashValue, root_depth: usize) -> Option<SparseMerkleProofExt> {
        let inner = &self.inner;
        inner.version().map(|ver| {
            let _timer = TIMER.timer_with(&["hot_provable_state_summary__get_proof"]);
            inner
                .get_proof(key, ver, root_depth, /* use_hot_state = */ true)
                .expect("Failed to get account state with proof by version.")
        })
    }
```

**File:** storage/jellyfish-merkle/src/lib.rs (L731-741)
```rust
        for nibble_depth in 0..=ROOT_NIBBLE_HEIGHT {
            let next_node = self
                .reader
                .get_node_with_tag(&next_node_key, "get_proof")
                .map_err(|err| {
                    if nibble_depth == 0 {
                        AptosDbError::MissingRootError(version)
                    } else {
                        err
                    }
                })?;
```

**File:** aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs (L174-176)
```rust
            max_write_ops_per_transaction: NumSlots,
            { 11.. => "max_write_ops_per_transaction" },
            8192,
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L485-499)
```rust
    pub fn set_num_proof_reading_threads_once(mut num_threads: usize) {
        // TODO(grao): Do more analysis to tune this magic number.
        num_threads = min(num_threads, 256);
        // Only the first call succeeds, due to OnceCell semantics.
        NUM_PROOF_READING_THREADS.set(num_threads).ok();
    }

    /// Returns the # of async proof reading threads if already set, otherwise return default value
    /// (32).
    pub fn get_num_proof_reading_threads() -> usize {
        match NUM_PROOF_READING_THREADS.get() {
            Some(num_threads) => *num_threads,
            None => 32,
        }
    }
```
