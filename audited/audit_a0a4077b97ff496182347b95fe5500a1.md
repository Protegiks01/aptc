# Audit Report

## Title
TOCTOU Race Condition Between StateKvPruner Initialization and save_min_readable_version() Causes Database Progress Metadata Corruption

## Summary
A time-of-check-time-of-use (TOCTOU) race condition exists between `StateKvPruner` initialization reading progress from the database and `save_min_readable_version()` writing to the same database key. During fast sync finalization, this causes the pruner's in-memory progress to become stale, leading to database metadata inconsistency when the pruner subsequently overwrites the correct progress value.

## Finding Description
The vulnerability occurs due to unsynchronized access to the `DbMetadataKey::StateKvPrunerProgress` database key by three separate code paths without proper synchronization:

**Path 1: Pruner Initialization (Time-of-Check)**

During `StateKvPruner::new()`, the pruner reads the current progress from the database [1](#0-0)  and initializes its in-memory atomic progress variable to this value [2](#0-1) . The `progress()` method reads from the database using `DbMetadataKey::StateKvPrunerProgress` [3](#0-2) .

**Path 2: Fast Sync Finalization (Time-of-Use)**

After fast sync completes, `finalize_state_snapshot()` calls `save_min_readable_version()` on the state_kv_pruner [4](#0-3) . This method updates the manager's atomic `min_readable_version` and writes directly to the database using the same `DbMetadataKey::StateKvPrunerProgress` key [5](#0-4) , specifically calling `write_pruner_progress()` [6](#0-5) .

**Critical Issue:** `save_min_readable_version()` updates `StateKvPrunerManager.min_readable_version` but does NOT update `StateKvPruner.progress`, leaving the pruner's in-memory progress stale.

**Path 3: Pruner Writes Back Stale Value**

When the pruner background worker runs, it calls `StateKvPruner::prune()` which reads the stale in-memory progress [7](#0-6)  and then calls `metadata_pruner.prune()` [8](#0-7) . The metadata pruner unconditionally writes the target_version to `DbMetadataKey::StateKvPrunerProgress` [9](#0-8) , overwriting the correct value set by fast sync with a smaller, incorrect value.

**The Race Condition:**

1. Node initializes with empty database, `StateKvPruner::new()` reads `progress = 0`
2. In-memory `StateKvPruner.progress = 0` (stale after fast sync)
3. Fast sync completes at version 1,000,000
4. `finalize_state_snapshot()` calls `save_min_readable_version(1,000,000)` 
5. Database now has `StateKvPrunerProgress = 1,000,000` (correct)
6. `StateKvPruner.progress` remains 0 (never updated)
7. Normal operation begins, pruner target is set
8. Pruner runs with stale `progress=0`, calls `metadata_pruner.prune(0, batch_target)`
9. `metadata_pruner.prune()` writes `StateKvPrunerProgress = batch_target` where `batch_target < 1,000,000`
10. Database progress corrupted: metadata claims versions < 1,000,000 are available for pruning when they were never synced

The pruner worker continuously runs in the background [10](#0-9) , and there is no mechanism to synchronize `StateKvPruner.progress` with the database after `save_min_readable_version()` is called.

## Impact Explanation
This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring manual intervention."

**Specific Impacts:**

1. **Database Metadata Corruption:** The `StateKvPrunerProgress` database key becomes inconsistent with actual state. After fast sync to version 1M, the database may incorrectly indicate that versions < 1M are available for pruning when those versions were never synced to the node.

2. **Storage Inefficiency:** The pruner will iterate over non-existent version ranges attempting to prune data that doesn't exist, wasting CPU cycles and database I/O resources.

3. **Operational Confusion:** Monitoring systems, debugging tools, and administrators relying on pruner progress metrics will receive incorrect information about the actual state of the database, complicating troubleshooting and capacity planning.

4. **Potential Node Instability:** If other components query pruner progress to determine version availability or make decisions about data retention, they may receive inconsistent information leading to unexpected behavior.

The vulnerability does not directly cause consensus violations or fund loss, but it corrupts critical database metadata that tracks the health and consistency of the storage system, requiring manual intervention to restore correct state.

## Likelihood Explanation
**Likelihood: High**

This vulnerability is triggered during every fast sync operation, which is a common operational scenario:

- **New validator nodes** joining the network perform fast sync to catch up with the current state
- **Nodes recovering from extended downtime** use fast sync to quickly restore state
- **Archive nodes** syncing historical state use fast sync mechanisms
- **Development and test environments** frequently use fast sync for rapid setup

The race condition occurs deterministically in the startup path: pruner initialization happens during database opening, and fast sync finalization happens shortly after. There is no synchronization mechanism to prevent the stale in-memory progress from overwriting the correct database value set by `save_min_readable_version()`.

The vulnerability requires no special attacker action or timing - it occurs naturally during normal node operation with fast sync enabled.

## Recommendation
Synchronize `StateKvPruner.progress` when `save_min_readable_version()` is called. The fix should update the in-memory progress to match the database value:

**Option 1:** In `StateKvPrunerManager::save_min_readable_version()`, access the underlying `StateKvPruner` and call `record_progress(min_readable_version)` to update its in-memory atomic.

**Option 2:** Make `StateKvPruner` re-read its progress from the database after fast sync completes, similar to how it reads during initialization.

**Option 3:** Use a single source of truth - have `StateKvPruner.prune()` read progress from the database on each invocation instead of caching it in memory, or alternatively, have `save_min_readable_version()` update both the database and the in-memory progress atomically.

The fix must ensure that both `StateKvPrunerManager.min_readable_version` and `StateKvPruner.progress` remain synchronized with the database value of `DbMetadataKey::StateKvPrunerProgress`.

## Proof of Concept
This vulnerability manifests during the fast sync flow. A proof of concept would require:

1. Initialize a node with an empty database
2. Verify `StateKvPruner.progress = 0` after initialization
3. Perform fast sync to version 1,000,000
4. Verify database has `StateKvPrunerProgress = 1,000,000` after `finalize_state_snapshot()`
5. Verify `StateKvPruner.progress` still equals 0 (stale)
6. Trigger pruner execution (by setting target version)
7. Observe `StateKvPrunerProgress` in database gets overwritten with value < 1,000,000
8. Confirm metadata corruption: database claims versions < 1,000,000 are prunable when they don't exist

The vulnerability can be observed by adding logging to track the values of `StateKvPruner.progress`, `StateKvPrunerManager.min_readable_version`, and the database key `DbMetadataKey::StateKvPrunerProgress` throughout the fast sync process.

### Citations

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L52-53)
```rust
        let mut progress = self.progress();
        let target_version = self.target_version();
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L64-65)
```rust
            self.metadata_pruner
                .prune(progress, current_batch_target_version)?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L117-117)
```rust
        let metadata_progress = metadata_pruner.progress()?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L140-141)
```rust
            target_version: AtomicVersion::new(metadata_progress),
            progress: AtomicVersion::new(metadata_progress),
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L67-70)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L75-81)
```rust
    pub(in crate::pruner) fn progress(&self) -> Result<Version> {
        Ok(get_progress(
            self.state_kv_db.metadata_db(),
            &DbMetadataKey::StateKvPrunerProgress,
        )?
        .unwrap_or(0))
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L232-234)
```rust
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_pruner_manager.rs (L57-66)
```rust
    fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["state_kv_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.state_kv_db.write_pruner_progress(min_readable_version)
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L217-222)
```rust
    pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
        self.state_kv_metadata_db.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(version),
        )
    }
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L53-68)
```rust
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
```
