# Audit Report

## Title
Empty Array Resource Exhaustion in Telemetry Log Ingestion Endpoint

## Summary
The `handle_log_ingest()` function in the Aptos telemetry service does not validate that incoming log message arrays are non-empty, allowing authenticated nodes to repeatedly send empty `Vec<String>` arrays that waste backend infrastructure resources through unnecessary API calls, serialization, compression, and storage operations.

## Finding Description

The telemetry service's log ingestion endpoint accepts authenticated log batches from Aptos nodes (validators, fullnodes) and forwards them to backend systems (Humio/Loki) for storage and analysis.

The vulnerability exists in the request handling flow:

1. The `handle_log_ingest()` function deserializes the request body into a `Vec<String>` without validating minimum length [1](#0-0) 

2. The empty vector passes deserialization successfully (an empty JSON array `[]` is valid JSON)

3. The code proceeds to create metadata fields and tags, then wraps the empty messages array into an `UnstructuredLog` struct [2](#0-1) 

4. The `UnstructuredLog` with empty messages is sent to the backend client [3](#0-2) 

5. The Humio client serializes, compresses, and transmits the empty log batch to the backend [4](#0-3) 

**Attack Vector:** An attacker who controls an authenticated node can rapidly send requests with empty log arrays, causing:
- Unnecessary CPU cycles for JSON deserialization/serialization
- Wasted GZIP compression operations
- Unnecessary HTTP requests to backend infrastructure
- Backend storage/processing of meaningless empty log entries
- Increased cloud infrastructure costs for Aptos Foundation

**Inconsistent Validation:** The codebase demonstrates awareness of this validation need, as the `handle_custom_event_ingest()` function explicitly validates against empty arrays and rejects them [5](#0-4) 

This inconsistency indicates an oversight rather than a deliberate design decision.

## Impact Explanation

This is a **Low Severity** issue per Aptos bug bounty criteria. It does not affect:
- Consensus safety or validator operations
- Fund security or transaction processing
- Network availability or critical system functionality

The impact is limited to:
- Operational cost increases (backend API calls, storage, compute)
- Potential degradation of telemetry service performance under sustained attack
- Wasted backend resources that could affect legitimate telemetry data ingestion

This qualifies as a "Non-critical implementation bug" under the Low severity category, as it enables resource waste but does not compromise blockchain security guarantees.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Must operate an authenticated Aptos node (validator, validator fullnode, or public fullnode)
- Must obtain valid JWT tokens through the noise handshake authentication [6](#0-5) 
- No rate limiting exists to prevent abuse

**Ease of Exploitation:**
- Attack is trivial once authentication is obtained (simply send `[]` repeatedly)
- No complex timing or race conditions required
- Can be automated easily

**Barriers:**
- Requires running infrastructure (node operation)
- Blacklist mechanism exists but requires manual intervention [7](#0-6) 
- Limited by `MAX_CONTENT_LENGTH` (1MB) but empty arrays are only 2 bytes

## Recommendation

Add validation to reject empty log message arrays before processing:

```rust
// After line 81 in handle_log_ingest()
if log_messages.is_empty() {
    return Err(reject::custom(ServiceError::bad_request(
        LogIngestError::EmptyPayload.into(),
    )));
}
```

This follows the same pattern already implemented in `handle_custom_event_ingest()`. Apply this validation consistently to both:
- `crates/aptos-telemetry-service/src/log_ingest.rs` (line 82)
- `crates/aptos-telemetry-service/src/custom_contract_ingest.rs` (line 222)

**Additional Hardening:**
- Consider implementing per-peer rate limiting for log ingestion requests
- Add metrics to track empty/near-empty log submissions for monitoring
- Consider minimum batch size requirements (e.g., reject batches with <10 messages)

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_empty_array_resource_waste() {
        // Setup: Create authenticated context and valid claims
        let context = create_test_context();
        let claims = create_valid_claims();
        
        // Attack: Send empty log array
        let empty_logs = vec![];
        let body = serde_json::to_vec(&empty_logs).unwrap();
        
        // This should be rejected but currently succeeds
        let result = handle_log_ingest(
            context,
            claims,
            None, // no encoding
            bytes::Bytes::from(body).reader()
        ).await;
        
        // Currently: result.is_ok() == true (vulnerability)
        // Expected: result should be Err with EmptyPayload error
        assert!(result.is_err(), "Empty log arrays should be rejected");
        
        // Attack demonstration: Attacker can send hundreds of these per second
        for _ in 0..1000 {
            // Each iteration wastes resources on:
            // - JSON deserialization
            // - HashMap allocations
            // - JSON serialization
            // - GZIP compression  
            // - HTTP request to backend
            // Total cost multiplied by request frequency
        }
    }
}
```

## Notes

This vulnerability exists in two separate log ingestion endpoints:
1. Standard node telemetry ingestion at `/ingest/logs`
2. Custom contract log ingestion at `/custom-contract/{name}/ingest/logs`

Both should be patched. The custom event endpoint already has proper validation and should serve as the reference implementation.

### Citations

**File:** crates/aptos-telemetry-service/src/log_ingest.rs (L27-33)
```rust
        .and(with_auth(context, vec![
            NodeType::Validator,
            NodeType::ValidatorFullNode,
            NodeType::PublicFullNode,
            NodeType::UnknownFullNode,
            NodeType::UnknownValidator,
        ]))
```

**File:** crates/aptos-telemetry-service/src/log_ingest.rs (L49-55)
```rust
    if let Some(blacklist) = &context.log_ingest_clients().blacklist {
        if blacklist.contains(&claims.peer_id) {
            return Err(reject::custom(ServiceError::forbidden(
                LogIngestError::Forbidden(claims.peer_id).into(),
            )));
        }
    }
```

**File:** crates/aptos-telemetry-service/src/log_ingest.rs (L64-81)
```rust
    let log_messages: Vec<String> = if let Some(encoding) = encoding {
        if encoding.eq_ignore_ascii_case("gzip") {
            let decoder = GzDecoder::new(body.reader());
            serde_json::from_reader(decoder).map_err(|e| {
                debug!("unable to decode and deserialize body: {}", e);
                ServiceError::bad_request(LogIngestError::UnexpectedPayloadBody.into())
            })?
        } else {
            return Err(reject::custom(ServiceError::bad_request(
                LogIngestError::UnexpectedContentEncoding.into(),
            )));
        }
    } else {
        serde_json::from_reader(body.reader()).map_err(|e| {
            error!("unable to deserialize body: {}", e);
            ServiceError::bad_request(LogIngestError::UnexpectedPayloadBody.into())
        })?
    };
```

**File:** crates/aptos-telemetry-service/src/log_ingest.rs (L83-101)
```rust
    let mut fields = HashMap::new();
    fields.insert(PEER_ID_FIELD_NAME.into(), claims.peer_id.to_string());
    fields.insert(EPOCH_FIELD_NAME.into(), claims.epoch.to_string());

    let mut tags = HashMap::new();
    let chain_name = if claims.chain_id.id() == 3 {
        format!("{}", claims.chain_id.id())
    } else {
        format!("{}", claims.chain_id)
    };
    tags.insert(CHAIN_ID_TAG_NAME.into(), chain_name);
    tags.insert(PEER_ROLE_TAG_NAME.into(), claims.node_type.to_string());
    tags.insert(RUN_UUID_TAG_NAME.into(), claims.run_uuid.to_string());

    let unstructured_log = UnstructuredLog {
        fields,
        tags,
        messages: log_messages,
    };
```

**File:** crates/aptos-telemetry-service/src/log_ingest.rs (L107-107)
```rust
    let res = client.ingest_unstructured_log(unstructured_log).await;
```

**File:** crates/aptos-telemetry-service/src/clients/humio.rs (L65-90)
```rust
    pub async fn ingest_unstructured_log(
        &self,
        unstructured_log: UnstructuredLog,
    ) -> Result<reqwest::Response, anyhow::Error> {
        let mut gzip_encoder = GzEncoder::new(Vec::new(), Compression::default());
        serde_json::to_writer(&mut gzip_encoder, &vec![unstructured_log])
            .map_err(|e| anyhow!("unable to serialize json: {}", e))?;
        let compressed_bytes = gzip_encoder.finish()?;

        let req = self
            .inner
            .0
            .post(self.base_url.join("api/v1/ingest/humio-unstructured")?)
            .header("Content-Encoding", "gzip")
            .body(compressed_bytes);

        // Add authentication based on configured auth type
        let req = match &self.auth {
            HumioAuth::Bearer(token) => req.bearer_auth(token),
            HumioAuth::Basic(username, password) => req.basic_auth(username, Some(password)),
        };

        req.send()
            .await
            .map_err(|e| anyhow!("failed to post logs: {}", e))
    }
```

**File:** crates/aptos-telemetry-service/src/custom_contract_ingest.rs (L359-368)
```rust
    if body.events.is_empty() {
        record_custom_contract_error(
            &contract_name,
            CustomContractEndpoint::EventsIngest,
            CustomContractErrorType::InvalidPayload,
        );
        return Err(reject::custom(ServiceError::bad_request(
            CustomEventIngestError::EmptyPayload.into(),
        )));
    }
```
