# Audit Report

## Title
Memory Exhaustion via Unbounded Channels in Remote Executor Service

## Summary
The `NetworkController` in the `secure/net` module uses unbounded crossbeam channels for message handling without any rate limiting, backpressure mechanisms, or memory exhaustion tests. This allows an attacker with network access to the remote executor service gRPC endpoints to cause memory exhaustion and denial of service by flooding the system with messages faster than they can be processed.

## Finding Description

The production code uses unbounded channels in two critical locations:

1. **Inbound message channels** - created in `NetworkController::create_inbound_channel()` [1](#0-0) 

2. **Outbound message channels** - created in `NetworkController::create_outbound_channel()` [2](#0-1) 

When messages arrive via the gRPC server, they are immediately sent to these unbounded channels without any validation of channel capacity: [3](#0-2) 

The critical vulnerability exists in the remote executor service, which uses this networking infrastructure for distributed sharded execution. When the `RemoteCoordinatorClient` receives execution commands, they arrive via an unbounded inbound channel: [4](#0-3) 

Commands are processed synchronously one at a time in `receive_execute_command()`, which involves expensive operations like BCS deserialization and state prefetching: [5](#0-4) 

**Attack Path:**
1. Attacker gains network access to the executor service's gRPC endpoint (no authentication is implemented in the `secure/net` module)
2. Attacker sends execution command messages rapidly to the service
3. While one command is being processed slowly (BCS deserialization, state prefetching), hundreds or thousands more messages arrive
4. Messages accumulate in the unbounded channel, consuming increasing amounts of memory
5. Eventually the process exhausts available memory and crashes (OOM kill)

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria because it causes:
- **Validator node slowdowns**: Memory pressure degrades performance before crash
- **API crashes**: The executor service process terminates due to OOM

While the sharded executor service is used primarily for performance optimization in block execution [6](#0-5) , a crash of this service could impact block processing throughput and cause validator performance degradation.

The vulnerability is particularly severe because:
1. There is no authentication or rate limiting on the gRPC endpoints
2. The channel is completely unbounded with no memory limits
3. No monitoring or alerting exists for channel depth
4. Processing is intentionally slow (complex deserialization and state operations)

## Likelihood Explanation

The likelihood depends on network exposure:

**High likelihood** if:
- The executor service ports are exposed to untrusted networks
- An attacker compromises a machine on the same network segment
- The service is deployed without proper network segmentation

**Lower likelihood** if:
- The service is only accessible on localhost or trusted internal networks
- Proper firewall rules restrict access to coordinator nodes only

However, the lack of authentication means any compromise of the network perimeter leads to exploitability. The codebase shows no TLS, authentication, or authorization mechanisms in the `secure/net` module (misleading name).

Other Aptos components use bounded channels with explicit capacity limits. For example, the main network layer uses `NETWORK_CHANNEL_SIZE: 1024` for buffering, and the consensus system uses bounded channels with backpressure monitoring. The `secure/net` module's use of unbounded channels is an architectural inconsistency.

## Recommendation

Replace unbounded channels with bounded channels and implement proper backpressure:

```rust
// In NetworkController::create_inbound_channel()
pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
    // Use bounded channel instead of unbounded
    const INBOUND_CHANNEL_SIZE: usize = 1024;
    let (inbound_sender, inbound_receiver) = bounded(INBOUND_CHANNEL_SIZE);

    self.inbound_handler
        .lock()
        .unwrap()
        .register_handler(message_type, inbound_sender);

    inbound_receiver
}
```

Additionally:
1. **Implement backpressure in the gRPC server**: Return errors when channels are full instead of accepting all messages
2. **Add rate limiting**: Implement per-peer message rate limits
3. **Add authentication**: Use mutual TLS or the existing Noise protocol authentication
4. **Add monitoring**: Track channel depth metrics and alert on high watermarks
5. **Add memory exhaustion tests**: Write stress tests that verify the system handles message flooding gracefully

Reference the existing bounded channel implementation in `crates/channel/src/lib.rs` which provides backpressure support.

## Proof of Concept

```rust
// Stress test demonstrating unbounded channel memory exhaustion
#[test]
#[ignore] // Run with --ignored flag
fn test_inbound_channel_memory_exhaustion() {
    use aptos_config::utils;
    use std::{
        net::{IpAddr, Ipv4Addr, SocketAddr},
        sync::Arc,
        thread,
        time::Duration,
    };
    use aptos_secure_net::network_controller::{Message, MessageType, NetworkController};

    let server_port = utils::get_available_port();
    let server_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), server_port);
    
    let mut controller = NetworkController::new(
        "stress_test".to_string(),
        server_addr,
        5000,
    );
    
    // Create an inbound channel but never read from it
    let _receiver = controller.create_inbound_channel("test_flood".to_string());
    controller.start();
    
    thread::sleep(Duration::from_millis(100));
    
    // Create a client that sends messages rapidly
    let mut flood_controller = NetworkController::new(
        "flooder".to_string(),
        SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), utils::get_available_port()),
        5000,
    );
    
    let sender = flood_controller.create_outbound_channel(server_addr, "test_flood".to_string());
    flood_controller.start();
    
    thread::sleep(Duration::from_millis(100));
    
    // Flood the channel with 100,000 messages of 1MB each
    // This would consume ~100GB of memory if all queued
    let large_message = vec![0u8; 1024 * 1024]; // 1MB message
    
    for i in 0..100_000 {
        sender.send(Message::new(large_message.clone())).unwrap();
        if i % 1000 == 0 {
            println!("Sent {} messages", i);
        }
    }
    
    // In a system with unbounded channels and no backpressure,
    // memory usage will grow linearly with messages sent
    // Eventually causing OOM
    
    controller.shutdown();
    flood_controller.shutdown();
}
```

This test demonstrates that messages accumulate in memory when the receiver doesn't consume them. In a real attack, the attacker would send messages to the executor service's gRPC endpoint while the service is busy processing previous commands.

**Notes**

The vulnerability exists because:
1. Production code uses `crossbeam_channel::unbounded()` instead of `bounded()` channels [7](#0-6) 
2. The gRPC message handler has no channel capacity checks before sending [8](#0-7) 
3. No memory exhaustion tests exist in the test suite for this module
4. The executor service processes messages slowly but accepts them at network speed [9](#0-8) 

This is an architectural flaw where the network ingress rate is not constrained by the processing capacity, violating basic queueing theory principles and resource management best practices.

### Citations

**File:** secure/net/src/network_controller/mod.rs (L8-8)
```rust
use crossbeam_channel::{unbounded, Receiver, Sender};
```

**File:** secure/net/src/network_controller/mod.rs (L115-126)
```rust
    pub fn create_outbound_channel(
        &mut self,
        remote_peer_addr: SocketAddr,
        message_type: String,
    ) -> Sender<Message> {
        let (outbound_sender, outbound_receiver) = unbounded();

        self.outbound_handler
            .register_handler(message_type, remote_peer_addr, outbound_receiver);

        outbound_sender
    }
```

**File:** secure/net/src/network_controller/mod.rs (L128-137)
```rust
    pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
        let (inbound_sender, inbound_receiver) = unbounded();

        self.inbound_handler
            .lock()
            .unwrap()
            .register_handler(message_type, inbound_sender);

        inbound_receiver
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L105-114)
```rust
        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L32-36)
```rust
        let execute_command_type = format!("execute_command_{}", shard_id);
        let execute_result_type = format!("execute_result_{}", shard_id);
        let command_rx = controller.create_inbound_channel(execute_command_type);
        let result_tx =
            controller.create_outbound_channel(coordinator_address, execute_result_type);
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L80-113)
```rust
    fn receive_execute_command(&self) -> ExecutorShardCommand<RemoteStateViewClient> {
        match self.command_rx.recv() {
            Ok(message) => {
                let _rx_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx"])
                    .start_timer();
                let bcs_deser_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx_bcs_deser"])
                    .start_timer();
                let request: RemoteExecutionRequest = bcs::from_bytes(&message.data).unwrap();
                drop(bcs_deser_timer);

                match request {
                    RemoteExecutionRequest::ExecuteBlock(command) => {
                        let init_prefetch_timer = REMOTE_EXECUTOR_TIMER
                            .with_label_values(&[&self.shard_id.to_string(), "init_prefetch"])
                            .start_timer();
                        let state_keys = Self::extract_state_keys(&command);
                        self.state_view_client.init_for_block(state_keys);
                        drop(init_prefetch_timer);

                        let (sub_blocks, concurrency, onchain_config) = command.into();
                        ExecutorShardCommand::ExecuteSubBlocks(
                            self.state_view_client.clone(),
                            sub_blocks,
                            concurrency,
                            onchain_config,
                        )
                    },
                }
            },
            Err(_) => ExecutorShardCommand::Stop,
        }
    }
```

**File:** execution/executor-service/src/process_executor_service.rs (L11-14)
```rust
/// An implementation of the remote executor service that runs in a standalone process.
pub struct ProcessExecutorService {
    executor_service: ExecutorService,
}
```
