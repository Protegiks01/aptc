# Audit Report

## Title
Missing Round Monotonicity Enforcement in Batch Encryption Allows Multiple Decryption Key Derivations Per Round

## Summary
The batch encryption system lacks enforcement of the documented security requirement that "validators must only generate a single decryption key corresponding to a round number." When Byzantine proposers equivocate or during network partitions, validators can derive multiple decryption key shares for the same round with different digests, violating the cryptographic security invariant.

## Finding Description

The batch threshold encryption trait explicitly states a critical security requirement: [1](#0-0) 

However, this requirement is not enforced at the implementation level. The vulnerability manifests when:

1. **Block Processing Without Round Validation**: Each block triggers the decryption pipeline, which uses the block's round number directly as the encryption round without checking if a decryption key has already been derived for that round: [2](#0-1) 

2. **Multiple Blocks Per Round Allowed**: The block tree allows insertion of multiple blocks for the same round, only issuing a warning: [3](#0-2) 

3. **Pipeline Invoked for Every Block**: Every inserted block goes through the pipeline builder which creates fresh channels and derives decryption key shares: [4](#0-3) [5](#0-4) 

4. **Key Derivation Occurs Before Storage Check**: The decryption key share is derived from the master secret key share and digest before any validation: [6](#0-5) 

5. **No Persistent Round Tracking**: Unlike voting, where SafetyData tracks `last_voted_round` to prevent double-voting, there is no equivalent `last_derived_decryption_key_round` tracking: [7](#0-6) [8](#0-7) 

**Attack Scenario:**

A Byzantine proposer creates two different blocks for round R:
- Block A: Contains transactions {CT1_A, CT2_A, ...} → Digest_A  
- Block B: Contains transactions {CT1_B, CT2_B, ...} → Digest_B

Due to network conditions or intentional distribution, validators receive both blocks. Each block that enters the pipeline will:
1. Derive a decryption key share: `(Digest + hash(mpk)) * shamir_share`
2. Create different key shares for the same round with different digests
3. Violate the one-key-per-round security requirement

While the SecretShareStore prevents storing multiple shares for the same round (failing with "Cannot add self share in PendingDecision state"), the cryptographic derivation has already occurred, potentially leaking information or enabling cross-digest attacks depending on FPTX security properties.

## Impact Explanation

**Severity: HIGH** 

This violates a documented cryptographic security invariant. The potential impacts include:

1. **Consensus Inconsistency**: Different validators may aggregate different sets of key shares for the same round, leading to failed decryption or execution divergence
2. **Cryptographic Security Violation**: Deriving multiple keys for the same round may compromise the FPTX scheme's security properties, potentially enabling unauthorized decryption or key recovery attacks
3. **Transaction Processing Failures**: Mixed key shares during aggregation could cause decryption failures, preventing transaction execution

The issue affects the **Cryptographic Correctness** invariant (#10) and potentially **Deterministic Execution** invariant (#1) if validators produce different decryption results.

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability requires:
- Byzantine proposer creating equivocating blocks (or network partitions causing validators to see conflicting proposals)
- Encrypted transaction feature enabled
- The equivocation detection not preventing block insertion into the pipeline

While consensus safety mechanisms like `UnequivocalProposerElection` detect equivocation, the detection only rejects proposals locally and doesn't prevent the decryption pipeline from executing for blocks already in the tree. During network splits or with sophisticated Byzantine attacks, multiple blocks for the same round can exist in the system simultaneously.

## Recommendation

Implement round monotonicity tracking for decryption key derivations, similar to `last_voted_round` in SafetyRules:

1. **Add to SafetyData**:
```rust
pub struct SafetyData {
    // ... existing fields
    #[serde(default)]
    pub last_derived_decryption_key_round: u64,
}
```

2. **Add validation in decryption pipeline**:
```rust
// In decrypt_encrypted_txns
let encryption_round = block.round();

// Check with SafetyRules or persistent storage
if encryption_round <= last_derived_decryption_key_round {
    return Err(anyhow!("Cannot derive decryption key for round {} - already derived for round {}", 
        encryption_round, last_derived_decryption_key_round));
}

// Derive key share
let derived_key_share = FPTXWeighted::derive_decryption_key_share(&msk_share, &digest)?;

// Update persistent state
update_last_derived_decryption_key_round(encryption_round)?;
```

3. **Reject duplicate rounds early**: In `insert_block_inner`, reject blocks with rounds already used for key derivation rather than just warning.

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_multiple_decryption_key_derivation_same_round() {
    let round = 100u64;
    
    // Setup: Create two different blocks for the same round
    let block_a = create_block_with_encrypted_txns(round, vec![tx1, tx2]);
    let block_b = create_block_with_encrypted_txns(round, vec![tx3, tx4]);
    
    // Simulate validator receiving both blocks
    let mut validator = setup_test_validator();
    
    // Process block A - derives key share for round 100
    let result_a = validator.process_block(block_a).await;
    assert!(result_a.is_ok());
    
    // Process block B - ALSO derives key share for round 100 with different digest
    // This should fail but currently succeeds in deriving (fails in storing)
    let result_b = validator.process_block(block_b).await;
    
    // Vulnerability: Both key shares are derived for the same round
    // Only one is stored, but cryptographic derivation occurred twice
    assert_eq!(validator.derived_key_count_for_round(100), 2); // FAILS - should be 1
}
```

## Notes

The vulnerability stems from a mismatch between the documented security requirement (single key derivation per round) and the implementation (no enforcement at derivation time, only at storage time). The equivocation detection mechanisms operate at the consensus layer but don't prevent the cryptographic operations in the batch encryption layer from violating their stated invariants.

### Citations

**File:** crates/aptos-batch-encryption/src/traits.rs (L30-31)
```rust
    /// The round number used when generating a digest. For security to hold, validators must only
    /// generate a single decryption key corresponding to a round number.
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L91-93)
```rust
        let encryption_round = block.round();
        let (digest, proofs_promise) =
            FPTXWeighted::digest(&digest_key, &txn_ciphertexts, encryption_round)?;
```

**File:** consensus/src/block_storage/block_tree.rs (L326-335)
```rust
            // Note: the assumption is that we have/enforce unequivocal proposer election.
            if let Some(old_block_id) = self.round_to_ids.get(&arc_block.round()) {
                warn!(
                    "Multiple blocks received for round {}. Previous block id: {}",
                    arc_block.round(),
                    old_block_id
                );
            } else {
                self.round_to_ids.insert(arc_block.round(), block_id);
            }
```

**File:** consensus/src/block_storage/block_store.rs (L464-496)
```rust
        if let Some(pipeline_builder) = &self.pipeline_builder {
            let parent_block = self
                .get_block(pipelined_block.parent_id())
                .ok_or_else(|| anyhow::anyhow!("Parent block not found"))?;

            // need weak pointer to break the cycle between block tree -> pipeline block -> callback
            let block_tree = Arc::downgrade(&self.inner);
            let storage = self.storage.clone();
            let id = pipelined_block.id();
            let round = pipelined_block.round();
            let window_size = self.window_size;
            let callback = Box::new(
                move |finality_proof: WrappedLedgerInfo,
                      commit_decision: LedgerInfoWithSignatures| {
                    if let Some(tree) = block_tree.upgrade() {
                        tree.write().commit_callback(
                            storage,
                            id,
                            round,
                            finality_proof,
                            commit_decision,
                            window_size,
                        );
                    }
                },
            );
            pipeline_builder.build_for_consensus(
                &pipelined_block,
                parent_block.pipeline_futs().ok_or_else(|| {
                    anyhow::anyhow!("Parent future doesn't exist, potentially epoch ended")
                })?,
                callback,
            );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L447-469)
```rust
        let (derived_self_key_share_tx, derived_self_key_share_rx) = oneshot::channel();
        let secret_sharing_derive_self_fut = spawn_shared_fut(
            async move {
                derived_self_key_share_rx
                    .await
                    .map_err(|_| TaskError::from(anyhow!("commit proof tx cancelled")))
            },
            Some(&mut abort_handles),
        );

        let materialize_fut = spawn_shared_fut(
            Self::materialize(self.block_preparer.clone(), block.clone(), qc_rx),
            Some(&mut abort_handles),
        );
        let decryption_fut = spawn_shared_fut(
            Self::decrypt_encrypted_txns(
                materialize_fut,
                block.clone(),
                self.signer.author(),
                self.secret_share_config.clone(),
                derived_self_key_share_tx,
                secret_shared_key_rx,
            ),
```

**File:** crates/aptos-batch-encryption/src/shared/key_derivation.rs (L107-115)
```rust
    pub fn derive_decryption_key_share(&self, digest: &Digest) -> Result<BIBEDecryptionKeyShare> {
        let hashed_encryption_key: G1Affine = symmetric::hash_g2_element(self.mpk_g2)?;

        Ok((self.player, BIBEDecryptionKeyShareValue {
            signature_share_eval: G1Affine::from(
                (digest.as_g1() + hashed_encryption_key) * self.shamir_share_eval,
            ),
        }))
    }
```

**File:** consensus/consensus-types/src/safety_data.rs (L10-21)
```rust
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```
