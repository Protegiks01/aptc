# Audit Report

## Title
Lower Epoch Spam Attack: Unauthenticated Old-Epoch Messages Cause Resource Exhaustion

## Summary
The `process_different_epoch()` function in `consensus/src/epoch_manager.rs` does not validate that the sender of a message was actually a validator in the claimed old epoch. This allows any network peer (Byzantine or not) to spam validators and non-validators with messages claiming to be from previous epochs, causing resource exhaustion through repeated validator set membership checks and database queries.

## Finding Description

When a consensus message arrives from a different epoch, the `check_epoch()` function extracts the epoch number and calls `process_different_epoch()`. [1](#0-0) 

The critical vulnerability is in the `process_different_epoch()` function's handling of lower-epoch messages. [2](#0-1) 

When a message from a lower epoch arrives, the function only checks if the **receiving node** (`self.author`) is in the **current** validator set, but **never validates** that the **sender** (`peer_id`) was actually a validator in the claimed old epoch. [3](#0-2) 

The epoch extraction via `event.epoch()?` merely reads a field from the message without any cryptographic verification. [4](#0-3) 

Furthermore, the codebase explicitly skips signature verification for messages from different epochs, as noted in the comment at line 1561. [5](#0-4) 

**Attack Scenario:**

1. An attacker (who may have never been a validator) crafts consensus messages with epoch numbers from old epochs (e.g., epoch 1, 2, 3)
2. The attacker floods current validators/nodes with these messages
3. For each message:
   - **If the receiving node IS a validator**: It performs a HashMap lookup via `get_voting_power(&self.author)` to check its own membership, then discards the message
   - **If the receiving node is NOT a validator**: It performs an **expensive database query** via `process_epoch_retrieval()` to fetch epoch proofs, then sends a response back to the attacker [6](#0-5) 

4. The network channel (capacity: 1024 messages) can be saturated, delaying legitimate current-epoch messages [7](#0-6) 

The main event loop processes messages serially, so spam messages create a queue that delays legitimate consensus messages. [8](#0-7) 

## Impact Explanation

This vulnerability breaks the **Resource Limits** invariant (#9): "All operations must respect gas, storage, and computational limits." Unauthenticated messages should not trigger unbounded resource consumption.

**For Active Validators:**
- Each spam message triggers a `get_voting_power()` HashMap lookup (O(1) but repeated thousands of times wastes CPU)
- Channel saturation delays processing of legitimate consensus messages, potentially impacting liveness

**For Non-Validator Nodes (Observers/Full Nodes):**
- Each spam message triggers a database query via `get_epoch_ending_ledger_infos()`, causing significant I/O load
- An attacker can exhaust disk I/O and database resources on these nodes

**Severity Assessment:** Medium
- Resource exhaustion attack (CPU, I/O, network bandwidth)
- Can degrade validator performance and observer node availability
- Does not directly break consensus safety but impacts liveness through DoS
- Matches "State inconsistencies requiring intervention" (Medium severity, up to $10,000)

## Likelihood Explanation

**Likelihood: High**

- **Attack Complexity:** Low - attacker only needs to craft messages with arbitrary epoch numbers
- **Attacker Requirements:** None - any network peer can send consensus messages
- **Detection Difficulty:** The sampled debug logging only fires once per second for validators, making sustained attacks hard to detect [9](#0-8) 
- **Real-World Applicability:** An adversary can easily script message generation and flooding

The attack is trivial to execute and requires no privileged access or validator credentials.

## Recommendation

**Fix: Validate sender's membership in the claimed epoch before processing**

Add validation that the sender was actually a validator in the epoch claimed by the message. This requires either:

1. **Store recent epoch validator sets in memory** (e.g., last 10 epochs) and check sender membership before calling `process_different_epoch()`

2. **Implement rate limiting per peer** for cross-epoch messages to prevent spam even from legitimate old validators

3. **Add sender validation in `process_different_epoch()`:**

```rust
fn process_different_epoch(
    &mut self,
    different_epoch: u64,
    peer_id: AccountAddress,
) -> anyhow::Result<()> {
    match different_epoch.cmp(&self.epoch()) {
        Ordering::Less => {
            // NEW: Validate sender was in that epoch's validator set
            if let Ok(old_epoch_proof) = self.storage
                .aptos_db()
                .get_epoch_ending_ledger_infos(different_epoch, different_epoch)
            {
                if let Some(epoch_state) = old_epoch_proof.ledger_info_with_sigs
                    .first()
                    .and_then(|li| li.ledger_info().next_epoch_state())
                {
                    // Check if sender was a validator in that epoch
                    if epoch_state.verifier.get_voting_power(&peer_id).is_none() {
                        // Sender was NOT a validator in claimed epoch - ignore spam
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("Ignoring message from non-validator {} claiming epoch {}", 
                                  peer_id, different_epoch);
                        );
                        return Ok(());
                    }
                }
            }
            
            // Existing logic for legitimate old-epoch validators
            if self.epoch_state().verifier.get_voting_power(&self.author).is_some() {
                // ... rest of existing code
            }
        },
        // ... rest of function
    }
}
```

**Additional Mitigations:**
- Implement per-peer rate limiting for cross-epoch messages
- Add metrics to track cross-epoch message frequency per peer
- Consider dropping messages from epochs more than N epochs old (e.g., N=10)

## Proof of Concept

```rust
// Test: consensus/src/epoch_manager_test.rs

#[tokio::test]
async fn test_old_epoch_spam_attack() {
    // Setup: Initialize EpochManager at epoch 10
    let (mut epoch_manager, mut network_rx) = setup_epoch_manager_at_epoch(10).await;
    
    // Attacker: Not a validator in any epoch
    let attacker_peer = AccountAddress::random();
    
    // Attack: Send 1000 messages claiming to be from epoch 1
    let spam_count = 1000;
    for _ in 0..spam_count {
        let fake_proposal = create_proposal_msg(
            1, // epoch = 1 (old epoch)
            0, // round
            attacker_peer, // author (not a real validator)
        );
        
        // Send message - it will be processed without sender validation
        network_rx.send((attacker_peer, ConsensusMsg::ProposalMsg(fake_proposal)));
    }
    
    // Measure impact
    let start = Instant::now();
    
    // Process all spam messages
    for _ in 0..spam_count {
        epoch_manager.process_next_message().await.unwrap();
    }
    
    let elapsed = start.elapsed();
    
    // Assert: Processing spam took significant time
    assert!(elapsed > Duration::from_millis(100), 
            "Spam messages consumed {} ms", elapsed.as_millis());
    
    // Assert: Database queries were made for non-validator nodes
    // (This would show in metrics/logs)
    
    // Assert: Legitimate messages are delayed in queue
    let legitimate_msg = create_proposal_msg(10, 1, get_validator_address(0));
    network_rx.send((get_validator_address(0), ConsensusMsg::ProposalMsg(legitimate_msg)));
    
    // The legitimate message has to wait behind spam in the queue
}
```

**To demonstrate the attack manually:**
1. Deploy a test network with validators at epoch 10
2. From an external node, send 10,000 `ProposalMsg` with `epoch=1` to a validator
3. Observe validator CPU usage and database query metrics
4. For non-validator observers, observe disk I/O from `get_epoch_ending_ledger_infos()` calls
5. Measure latency increase for legitimate epoch-10 consensus messages

---

**Notes**

The vulnerability exists because cross-epoch signature verification is explicitly skipped with the assumption that epoch mismatches will be rare and handled gracefully. However, this creates an unauthenticated channel for resource exhaustion attacks. The fix requires adding sender validation before expensive operations, or implementing rate limiting per peer to bound the damage from spam attacks.

### Citations

**File:** consensus/src/epoch_manager.rs (L451-476)
```rust
    fn process_epoch_retrieval(
        &mut self,
        request: EpochRetrievalRequest,
        peer_id: AccountAddress,
    ) -> anyhow::Result<()> {
        debug!(
            LogSchema::new(LogEvent::ReceiveEpochRetrieval)
                .remote_peer(peer_id)
                .epoch(self.epoch()),
            "[EpochManager] receive {}", request,
        );
        let proof = self
            .storage
            .aptos_db()
            .get_epoch_ending_ledger_infos(request.start_epoch, request.end_epoch)
            .map_err(DbError::from)
            .context("[EpochManager] Failed to get epoch proof")?;
        let msg = ConsensusMsg::EpochChangeProof(Box::new(proof));
        if let Err(err) = self.network_sender.send_to(peer_id, msg) {
            warn!(
                "[EpochManager] Failed to send epoch proof to {}, with error: {:?}",
                peer_id, err,
            );
        }
        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L478-542)
```rust
    fn process_different_epoch(
        &mut self,
        different_epoch: u64,
        peer_id: AccountAddress,
    ) -> anyhow::Result<()> {
        debug!(
            LogSchema::new(LogEvent::ReceiveMessageFromDifferentEpoch)
                .remote_peer(peer_id)
                .epoch(self.epoch()),
            remote_epoch = different_epoch,
        );
        match different_epoch.cmp(&self.epoch()) {
            Ordering::Less => {
                if self
                    .epoch_state()
                    .verifier
                    .get_voting_power(&self.author)
                    .is_some()
                {
                    // Ignore message from lower epoch if we're part of the validator set, the node would eventually see messages from
                    // higher epoch and request a proof
                    sample!(
                        SampleRate::Duration(Duration::from_secs(1)),
                        debug!("Discard message from lower epoch {} from {}", different_epoch, peer_id);
                    );
                    Ok(())
                } else {
                    // reply back the epoch change proof if we're not part of the validator set since we won't broadcast
                    // timeout in this epoch
                    monitor!(
                        "process_epoch_retrieval",
                        self.process_epoch_retrieval(
                            EpochRetrievalRequest {
                                start_epoch: different_epoch,
                                end_epoch: self.epoch(),
                            },
                            peer_id
                        )
                    )
                }
            },
            // We request proof to join higher epoch
            Ordering::Greater => {
                let request = EpochRetrievalRequest {
                    start_epoch: self.epoch(),
                    end_epoch: different_epoch,
                };
                let msg = ConsensusMsg::EpochRetrievalRequest(Box::new(request));
                if let Err(err) = self.network_sender.send_to(peer_id, msg) {
                    warn!(
                        "[EpochManager] Failed to send epoch retrieval to {}, {:?}",
                        peer_id, err
                    );
                    counters::EPOCH_MANAGER_ISSUES_DETAILS
                        .with_label_values(&["failed_to_send_epoch_retrieval"])
                        .inc();
                }

                Ok(())
            },
            Ordering::Equal => {
                bail!("[EpochManager] Same epoch should not come to process_different_epoch");
            },
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L1561-1562)
```rust
        // we can't verify signatures from a different epoch
        let maybe_unverified_event = self.check_epoch(peer_id, consensus_msg).await?;
```

**File:** consensus/src/epoch_manager.rs (L1645-1652)
```rust
                let event: UnverifiedEvent = msg.into();
                if event.epoch()? == self.epoch() {
                    return Ok(Some(event));
                } else {
                    monitor!(
                        "process_different_epoch_consensus_msg",
                        self.process_different_epoch(event.epoch()?, peer_id)
                    )?;
```

**File:** consensus/src/epoch_manager.rs (L1930-1936)
```rust
            tokio::select! {
                (peer, msg) = network_receivers.consensus_messages.select_next_some() => {
                    monitor!("epoch_manager_process_consensus_messages",
                    if let Err(e) = self.process_message(peer, msg).await {
                        error!(epoch = self.epoch(), error = ?e, kind = error_kind(&e));
                    });
                },
```

**File:** consensus/src/round_manager.rs (L233-248)
```rust
    pub fn epoch(&self) -> anyhow::Result<u64> {
        match self {
            UnverifiedEvent::ProposalMsg(p) => Ok(p.epoch()),
            UnverifiedEvent::OptProposalMsg(p) => Ok(p.epoch()),
            UnverifiedEvent::VoteMsg(v) => Ok(v.epoch()),
            UnverifiedEvent::OrderVoteMsg(v) => Ok(v.epoch()),
            UnverifiedEvent::SyncInfo(s) => Ok(s.epoch()),
            UnverifiedEvent::BatchMsg(b) => b.epoch(),
            UnverifiedEvent::SignedBatchInfo(sd) => sd.epoch(),
            UnverifiedEvent::ProofOfStoreMsg(p) => p.epoch(),
            UnverifiedEvent::RoundTimeoutMsg(t) => Ok(t.epoch()),
            UnverifiedEvent::BatchMsgV2(b) => b.epoch(),
            UnverifiedEvent::SignedBatchInfoMsgV2(sd) => sd.epoch(),
            UnverifiedEvent::ProofOfStoreMsgV2(p) => p.epoch(),
        }
    }
```

**File:** config/src/config/consensus_config.rs (L223-223)
```rust
            max_network_channel_size: 1024,
```
