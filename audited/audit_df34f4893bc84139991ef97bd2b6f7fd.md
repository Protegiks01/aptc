# Audit Report

## Title
Cache Worker State Corruption via Invalid gRPC Stream Status Transitions

## Summary
The indexer cache worker fails to properly clean up background tasks when an invalid `StatusType` transition occurs (e.g., receiving a second `INIT` signal). This leaves orphaned async tasks writing partial transaction data to Redis cache without corresponding version updates, causing cache state inconsistency.

## Finding Description

The vulnerability exists in the gRPC stream processing logic where the cache worker consumes transaction data from fullnodes. The expected protocol flow is: [1](#0-0) 

When processing the stream, the cache worker spawns background tasks to write transaction data to Redis: [2](#0-1) 

These tasks are accumulated in a vector and only awaited when `BATCH_END` is received: [3](#0-2) 

However, when an invalid state transition occurs (e.g., receiving a second `INIT` signal), the code breaks immediately without awaiting pending tasks: [4](#0-3) 

The stream processing function returns normally, and the outer loop reconnects: [5](#0-4) 

**The critical issue**: Orphaned background tasks continue executing with their cloned `CacheOperator`, writing transaction data to Redis cache. Meanwhile, the cache version marker (`latest_version`) is never updated because the `BATCH_END` handler was never reached: [6](#0-5) 

This creates a race condition where:
1. Old orphaned tasks write partial batch data using the old connection
2. New stream reconnects and creates fresh tasks with a new connection
3. Both sets of tasks write to the same Redis instance simultaneously
4. Cache contains transaction data without proper version tracking

## Impact Explanation

**Severity: Medium** - State inconsistencies requiring intervention

This vulnerability affects the indexer infrastructure's cache layer, which serves as a critical data source for downstream consumers (wallets, explorers, analytics platforms). When triggered:

1. **Cache State Corruption**: Redis cache contains partial transaction batches without corresponding `latest_version` updates, violating the cache consistency invariant
2. **Version Tracking Failure**: The Lua script that atomically updates cache versions can detect gaps or overlaps, causing downstream failures: [7](#0-6) 

3. **Data Availability Impact**: Downstream consumers reading from cache may receive incomplete batches or experience query failures
4. **Resource Leakage**: Orphaned async tasks consume system resources (Redis connections, memory) until completion

While this does not affect blockchain consensus or validator operations directly, it impacts the data availability layer that applications depend on, requiring manual intervention to restore cache consistency.

## Likelihood Explanation

**Likelihood: Medium-Low**

This vulnerability requires one of the following conditions:
1. **Malicious Fullnode**: An attacker operates a malicious fullnode that deliberately sends invalid status transitions. Indexer operators who mistakenly connect to this fullnode would be affected.
2. **Network Corruption**: Rare network conditions causing message corruption or reordering in the gRPC stream
3. **Fullnode Implementation Bug**: A bug in the fullnode gRPC server causing it to send duplicate `INIT` signals

The most realistic attack vector is scenario 1, where an attacker could:
- Deploy a malicious fullnode
- Advertise it to indexer operators
- Send: `INIT → Data → BATCH_END → INIT` (invalid transition)
- Cause cache corruption in connected workers

However, this requires:
- Indexer operators to trust and connect to the malicious fullnode
- The attacker to have motivation to disrupt indexer services (no direct financial gain)

## Recommendation

**Fix 1: Await or Cancel Orphaned Tasks on Stream Break**

Modify the invalid state transition handler to explicitly cancel or await pending tasks before breaking:

```rust
GrpcDataStatus::StreamInit(new_version) => {
    error!(
        current_version = new_version,
        "[Indexer Cache] Init signal received twice."
    );
    ERROR_COUNT.with_label_values(&["data_init_twice"]).inc();
    
    // CRITICAL FIX: Await all pending tasks before breaking
    let result = join_all(tasks_to_run).await;
    for res in result {
        if let Err(e) = res {
            error!("Failed to complete orphaned task: {:?}", e);
        }
    }
    
    break;
}
```

**Fix 2: Add State Machine Validation**

Implement explicit state tracking to validate transitions:

```rust
enum StreamState {
    WaitingForInit,
    ProcessingBatches,
    Terminated,
}

let mut stream_state = StreamState::WaitingForInit;

// In process_transactions_from_node_response:
match (stream_state, status_type) {
    (StreamState::WaitingForInit, StatusType::Init) => {
        stream_state = StreamState::ProcessingBatches;
        Ok(GrpcDataStatus::StreamInit(status.start_version))
    }
    (StreamState::ProcessingBatches, StatusType::BatchEnd) => {
        Ok(GrpcDataStatus::BatchEnd { ... })
    }
    (StreamState::ProcessingBatches, StatusType::Init) => {
        Err(anyhow!("Invalid state transition: INIT after stream started"))
    }
    _ => Err(anyhow!("Invalid status type for current state"))
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_invalid_state_transition_leaves_orphaned_tasks() {
    use futures::stream;
    use tokio::sync::mpsc;
    
    // Create mock Redis connection
    let mock_redis = setup_mock_redis();
    let cache_operator = CacheOperator::new(mock_redis, StorageFormat::Base64UncompressedProto);
    
    // Create malicious gRPC stream that sends: INIT -> Data -> INIT (invalid)
    let (tx, rx) = mpsc::channel(100);
    
    // Send INIT
    tx.send(Ok(create_init_response(0))).await.unwrap();
    
    // Send Data
    tx.send(Ok(create_data_response(vec![mock_transaction(0)]))).await.unwrap();
    
    // Send invalid second INIT
    tx.send(Ok(create_init_response(0))).await.unwrap();
    
    let stream = ReceiverStream::new(rx);
    
    // Process stream
    let result = process_streaming_response(
        cache_operator.conn,
        StorageFormat::Base64UncompressedProto,
        FileStoreMetadata { version: 0, chain_id: 1 },
        stream,
    ).await;
    
    // Verify that orphaned tasks are still running
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Check Redis - should have partial data without version update
    let latest_version = cache_operator.get_latest_version().await.unwrap();
    let has_transaction = cache_operator.get_transactions(0, 1).await.is_ok();
    
    assert_eq!(latest_version, Some(0)); // Version not updated
    assert!(has_transaction); // But data was written by orphaned task
    
    // This demonstrates cache inconsistency
}
```

## Notes

This vulnerability affects the **indexer-grpc subsystem**, which is infrastructure for serving blockchain data to external consumers. While it causes state inconsistencies in the cache layer requiring manual intervention, it does **not** affect:
- Core blockchain consensus or safety
- Validator operations or block production  
- On-chain transaction execution or state commitment

The impact is limited to the data availability layer. However, given that the indexer infrastructure is critical for wallet and explorer functionality, and the bug can cause cache corruption requiring operator intervention, it qualifies as a **Medium severity** infrastructure vulnerability under the "state inconsistencies requiring intervention" category.

### Citations

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.rs (L6-11)
```rust
// Transaction data is transferred via 1 stream with batches until terminated.
// One stream consists:
//   StreamStatus: INIT with version x
//   loop k:
//     TransactionOutput data(size n)
//     StreamStatus: BATCH_END with version x + (k + 1) * n - 1
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L111-179)
```rust
        loop {
            let conn = self
                .redis_client
                .get_tokio_connection_manager()
                .await
                .context("Get redis connection failed.")?;
            let mut rpc_client = create_grpc_client(self.fullnode_grpc_address.clone()).await;

            // 1. Fetch metadata.
            let file_store_operator: Box<dyn FileStoreOperator> = self.file_store.create();
            // TODO: move chain id check somewhere around here
            // This ensures that metadata is created before we start the cache worker
            let mut starting_version = file_store_operator.get_latest_version().await;
            while starting_version.is_none() {
                starting_version = file_store_operator.get_latest_version().await;
                tracing::warn!(
                    "[Indexer Cache] File store metadata not found. Waiting for {} ms.",
                    FILE_STORE_METADATA_WAIT_MS
                );
                tokio::time::sleep(std::time::Duration::from_millis(
                    FILE_STORE_METADATA_WAIT_MS,
                ))
                .await;
            }

            // There's a guarantee at this point that starting_version is not null
            let starting_version = starting_version.unwrap();

            let file_store_metadata = file_store_operator.get_file_store_metadata().await.unwrap();

            tracing::info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Starting cache worker with version {}",
                starting_version
            );

            // 2. Start streaming RPC.
            let request = tonic::Request::new(GetTransactionsFromNodeRequest {
                starting_version: Some(starting_version),
                ..Default::default()
            });

            let response = rpc_client
                .get_transactions_from_node(request)
                .await
                .with_context(|| {
                    format!(
                        "Failed to get transactions from node at starting version {}",
                        starting_version
                    )
                })?;
            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC started."
            );
            // 3&4. Infinite streaming until error happens. Either stream ends or worker crashes.
            process_streaming_response(
                conn,
                self.cache_storage_format,
                file_store_metadata,
                response.into_inner(),
            )
            .await?;

            info!(
                service_type = SERVICE_TYPE,
                "[Indexer Cache] Streaming RPC ended."
            );
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L213-275)
```rust
            let task: JoinHandle<anyhow::Result<()>> = tokio::spawn({
                let first_transaction = data
                    .transactions
                    .first()
                    .context("There were unexpectedly no transactions in the response")?;
                let first_transaction_version = first_transaction.version;
                let last_transaction = data
                    .transactions
                    .last()
                    .context("There were unexpectedly no transactions in the response")?;
                let last_transaction_version = last_transaction.version;
                let start_version = first_transaction.version;
                let first_transaction_pb_timestamp = first_transaction.timestamp;
                let last_transaction_pb_timestamp = last_transaction.timestamp;

                log_grpc_step(
                    SERVICE_TYPE,
                    IndexerGrpcStep::CacheWorkerReceivedTxns,
                    Some(start_version as i64),
                    Some(last_transaction_version as i64),
                    first_transaction_pb_timestamp.as_ref(),
                    last_transaction_pb_timestamp.as_ref(),
                    Some(data_download_duration_in_secs),
                    Some(size_in_bytes),
                    Some((last_transaction_version + 1 - first_transaction_version) as i64),
                    None,
                );

                let cache_update_start_time = std::time::Instant::now();

                async move {
                    // Push to cache.
                    match cache_operator_clone
                        .update_cache_transactions(data.transactions)
                        .await
                    {
                        Ok(_) => {
                            log_grpc_step(
                                SERVICE_TYPE,
                                IndexerGrpcStep::CacheWorkerTxnsProcessed,
                                Some(first_transaction_version as i64),
                                Some(last_transaction_version as i64),
                                first_transaction_pb_timestamp.as_ref(),
                                last_transaction_pb_timestamp.as_ref(),
                                Some(cache_update_start_time.elapsed().as_secs_f64()),
                                Some(size_in_bytes),
                                Some(
                                    (last_transaction_version + 1 - first_transaction_version)
                                        as i64,
                                ),
                                None,
                            );
                            Ok(())
                        },
                        Err(e) => {
                            ERROR_COUNT
                                .with_label_values(&["failed_to_update_cache_version"])
                                .inc();
                            bail!("Update cache with version failed: {}", e);
                        },
                    }
                }
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L405-411)
```rust
                GrpcDataStatus::StreamInit(new_version) => {
                    error!(
                        current_version = new_version,
                        "[Indexer Cache] Init signal received twice."
                    );
                    ERROR_COUNT.with_label_values(&["data_init_twice"]).inc();
                    break;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L413-432)
```rust
                GrpcDataStatus::BatchEnd {
                    start_version,
                    num_of_transactions,
                } => {
                    // Handle the data multithreading.
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L444-448)
```rust
                    cache_operator
                        .update_cache_latest_version(transaction_count, current_version)
                        .await
                        .context("Failed to update the latest version in the cache")?;
                    transaction_count = 0;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/cache_operator.rs (L359-364)
```rust
            2 => {
                tracing::error!(version=version, "Redis latest version update failed. The version is beyond the next expected version.");
                Err(anyhow::anyhow!("Version is not right."))
            },
            _ => Ok(()),
        }
```
