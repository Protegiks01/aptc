# Audit Report

## Title
Storage Service Priority Inversion: Low-Priority Request Flooding Can Delay State Synchronization

## Summary
The Aptos storage service lacks request-type-based prioritization, allowing any peer to flood the service with low-priority requests (e.g., `GetNumberOfStatesAtVersion`) that can delay or starve critical requests (e.g., `GetEpochEndingLedgerInfos`). However, the impact is limited to state synchronization operations, not direct consensus operations, and per-peer queuing provides partial mitigation.

## Finding Description
The storage service implements a FIFO queue-based request handling system without differentiating between request types by priority. [1](#0-0) 

The network channel is configured with `QueueStyle::FIFO` with a default capacity of 4000 messages per peer. [2](#0-1) [3](#0-2) 

When the queue reaches capacity, FIFO drops the **newest** incoming messages, not the oldest. [4](#0-3) 

The server processes all requests equally by spawning blocking tasks without prioritization. [5](#0-4) 

The `RequestModerator` only validates whether requests can be satisfied by current storage state and temporarily ignores peers sending too many **invalid** requests. It does not rate-limit or deprioritize based on request type. [6](#0-5) 

**Critical Observation**: The storage service is used for peer-to-peer state synchronization and bootstrapping, **not** for direct consensus operations. Consensus accesses local storage directly and does not depend on the network storage service for critical epoch transitions.

## Impact Explanation
This issue qualifies as **Medium Severity** (up to $10,000), not High/Critical, because:

1. **Limited Consensus Impact**: The storage service serves state sync requests from peers, not direct consensus operations. Epoch-ending ledger infos for consensus are fetched from local storage, not the network storage service. The claim that this "delays consensus" is incorrect.

2. **Per-Peer Queuing Mitigation**: The `PerKeyQueue` structure maintains separate queues per peer (keyed by `PeerNetworkId`), limiting the blast radius. An attacker filling their own queue does not directly affect other peers' queues. [7](#0-6) 

3. **Thread Pool Limits**: While the blocking thread pool is limited to 64 concurrent threads, [8](#0-7)  this prevents complete resource exhaustion but allows delays.

4. **Actual Impact**: Affects nodes performing bootstrapping or catching up after downtime, causing state sync slowdowns rather than consensus failures.

5. **DoS Scope Consideration**: This resembles a network-level DoS attack, which is explicitly out of scope per bug bounty rules. However, it targets a specific service with valid requests rather than network flooding.

## Likelihood Explanation
**High likelihood** that an attacker can cause state sync delays:
- Any peer can connect and send storage service requests
- `GetNumberOfStatesAtVersion` requests are valid and not blocked by the moderator
- No authentication or rate limiting based on request type
- Multiple peer connections can be established to amplify the effect

**Low likelihood** of causing actual consensus impact:
- Consensus does not depend on the network storage service for critical operations
- Only affects nodes that are bootstrapping or catching up
- Validators in normal operation are unaffected

## Recommendation
Implement request-type-based prioritization in the storage service:

1. **Add Priority Levels**: Classify requests into priority tiers:
   - **Critical**: `GetEpochEndingLedgerInfos` (epoch transitions)
   - **High**: Transaction data with proofs
   - **Medium**: State values with proofs  
   - **Low**: `GetNumberOfStatesAtVersion`, `GetStorageServerSummary`

2. **Implement Priority Queue**: Replace the simple FIFO queue with a multi-level priority queue that processes critical requests first.

3. **Add Per-Peer Rate Limiting**: Implement request-type-specific rate limits per peer to prevent flooding of any single request type.

4. **Consider Separate Thread Pools**: Use dedicated thread pools for critical vs. non-critical requests to prevent thread pool exhaustion.

## Proof of Concept
```rust
// Simulated attack scenario
// 1. Connect multiple peer identities to a storage service node
// 2. Each peer floods GetNumberOfStatesAtVersion requests
// 3. Observe delays in GetEpochEndingLedgerInfos requests from legitimate peers

// This would require a network test harness to execute, demonstrating:
// - Multiple peers sending 4000 GetNumberOfStatesAtVersion requests each
// - A legitimate peer attempting to send GetEpochEndingLedgerInfos requests
// - Measurement of response time delays (expected: seconds to minutes)
// - Verification that state sync operations are delayed but not permanently blocked
```

## Notes

**Critical Clarification**: After thorough analysis, this vulnerability does **not** "delay consensus" as claimed in the security question. The storage service handles peer-to-peer state synchronization, not consensus-critical operations. Consensus uses local database access directly. [9](#0-8) 

The actual impact is limited to state sync slowdowns for bootstrapping nodes, which is a **state inconsistency requiring intervention** (Medium Severity) rather than a consensus safety or liveness issue (Critical/High Severity).

The per-peer queuing architecture significantly limits the attack surface compared to a global queue, as each attacker peer can only flood their own queue. [10](#0-9)

### Citations

**File:** state-sync/storage-service/types/src/requests.rs (L34-56)
```rust
#[derive(Clone, Debug, Deserialize, Eq, Hash, PartialEq, Serialize)]
pub enum DataRequest {
    GetEpochEndingLedgerInfos(EpochEndingLedgerInfoRequest), // Fetches a list of epoch ending ledger infos
    GetNewTransactionOutputsWithProof(NewTransactionOutputsWithProofRequest), // Optimistically fetches new transaction outputs
    GetNewTransactionsWithProof(NewTransactionsWithProofRequest), // Optimistically fetches new transactions
    GetNumberOfStatesAtVersion(Version), // Fetches the number of states at the specified version
    GetServerProtocolVersion,            // Fetches the protocol version run by the server
    GetStateValuesWithProof(StateValuesWithProofRequest), // Fetches a list of states with a proof
    GetStorageServerSummary,             // Fetches a summary of the storage server state
    GetTransactionOutputsWithProof(TransactionOutputsWithProofRequest), // Fetches a list of transaction outputs with a proof
    GetTransactionsWithProof(TransactionsWithProofRequest), // Fetches a list of transactions with a proof
    GetNewTransactionsOrOutputsWithProof(NewTransactionsOrOutputsWithProofRequest), // Optimistically fetches new transactions or outputs
    GetTransactionsOrOutputsWithProof(TransactionsOrOutputsWithProofRequest), // Fetches a list of transactions or outputs with a proof
    SubscribeTransactionOutputsWithProof(SubscribeTransactionOutputsWithProofRequest), // Subscribes to transaction outputs with a proof
    SubscribeTransactionsOrOutputsWithProof(SubscribeTransactionsOrOutputsWithProofRequest), // Subscribes to transactions or outputs with a proof
    SubscribeTransactionsWithProof(SubscribeTransactionsWithProofRequest), // Subscribes to transactions with a proof

    // All the requests listed below are for transaction data v2 (i.e., transactions with auxiliary information).
    // TODO: eventually we should deprecate all the old request types.
    GetTransactionDataWithProof(GetTransactionDataWithProofRequest), // Fetches transaction data with a proof
    GetNewTransactionDataWithProof(GetNewTransactionDataWithProofRequest), // Optimistically fetches new transaction data with a proof
    SubscribeTransactionDataWithProof(SubscribeTransactionDataWithProofRequest), // Subscribes to transaction data with a proof
}
```

**File:** aptos-node/src/network.rs (L160-165)
```rust
        aptos_channel::Config::new(max_network_channel_size)
            .queue_style(QueueStyle::FIFO)
            .counters(
                &aptos_storage_service_server::metrics::PENDING_STORAGE_SERVER_NETWORK_EVENTS,
            ),
    );
```

**File:** config/src/config/state_sync_config.rs (L203-203)
```rust
            max_network_channel_size: 4000,
```

**File:** crates/channel/src/message_queues.rs (L45-63)
```rust
pub(crate) struct PerKeyQueue<K: Eq + Hash + Clone, T> {
    /// QueueStyle for the messages stored per key
    queue_style: QueueStyle,
    /// per_key_queue maintains a map from a Key to a queue
    /// of all the messages from that Key. A Key is usually
    /// represented by AccountAddress
    per_key_queue: HashMap<K, VecDeque<T>>,
    /// This is a (round-robin)queue of Keys which have pending messages
    /// This queue will be used for performing round robin among
    /// Keys for choosing the next message
    round_robin_queue: VecDeque<K>,
    /// Maximum number of messages to store per key
    max_queue_size: NonZeroUsize,
    /// Number of messages dequeued since last GC
    num_popped_since_gc: u32,
    /// Optional counters for recording # enqueued, # dequeued, and # dropped
    /// messages
    counters: Option<&'static IntCounterVec>,
}
```

**File:** crates/channel/src/message_queues.rs (L112-152)
```rust
    pub(crate) fn push(&mut self, key: K, message: T) -> Option<T> {
        if let Some(c) = self.counters.as_ref() {
            c.with_label_values(&["enqueued"]).inc();
        }

        let key_message_queue = self
            .per_key_queue
            .entry(key.clone())
            // Only allocate a small initial queue for a new key. Previously, we
            // allocated a queue with all `max_queue_size_per_key` entries;
            // however, this breaks down when we have lots of transient peers.
            // For example, many of our queues have a max capacity of 1024. To
            // handle a single rpc from a transient peer, we would end up
            // allocating ~ 96 b * 1024 ~ 64 Kib per queue.
            .or_insert_with(|| VecDeque::with_capacity(1));

        // Add the key to our round-robin queue if it's not already there
        if key_message_queue.is_empty() {
            self.round_robin_queue.push_back(key);
        }

        // Push the message to the actual key message queue
        if key_message_queue.len() >= self.max_queue_size.get() {
            if let Some(c) = self.counters.as_ref() {
                c.with_label_values(&["dropped"]).inc();
            }
            match self.queue_style {
                // Drop the newest message for FIFO
                QueueStyle::FIFO => Some(message),
                // Drop the oldest message for LIFO
                QueueStyle::LIFO | QueueStyle::KLAST => {
                    let oldest = key_message_queue.pop_front();
                    key_message_queue.push_back(message);
                    oldest
                },
            }
        } else {
            key_message_queue.push_back(message);
            None
        }
    }
```

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L132-196)
```rust
    /// Validates the given request and verifies that the peer is behaving
    /// correctly. If the request fails validation, an error is returned.
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** crates/aptos-runtimes/src/lib.rs (L1-100)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use rayon::{ThreadPool, ThreadPoolBuilder};
use std::sync::atomic::{AtomicUsize, Ordering};
use tokio::runtime::{Builder, Runtime};

/// The max thread name length before the name will be truncated
/// when it's displayed. Note: the max display length is 15, but
/// we need to leave space for the thread IDs.
const MAX_THREAD_NAME_LENGTH: usize = 12;

/// Returns a tokio runtime with named threads.
/// This is useful for tracking threads when debugging.
pub fn spawn_named_runtime(thread_name: String, num_worker_threads: Option<usize>) -> Runtime {
    spawn_named_runtime_with_start_hook(thread_name, num_worker_threads, || {})
}

pub fn spawn_named_runtime_with_start_hook<F>(
    thread_name: String,
    num_worker_threads: Option<usize>,
    on_thread_start: F,
) -> Runtime
where
    F: Fn() + Send + Sync + 'static,
{
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
    if let Some(num_worker_threads) = num_worker_threads {
        builder.worker_threads(num_worker_threads);
    }

    // Spawn and return the runtime
    builder.build().unwrap_or_else(|error| {
        panic!(
            "Failed to spawn named runtime! Name: {:?}, Error: {:?}",
            thread_name, error
        )
    })
}

/// Returns a rayon threadpool with threads.
/// This is useful for tracking threads when debugging.
pub fn spawn_rayon_thread_pool(
    thread_name: String,
    num_worker_threads: Option<usize>,
) -> ThreadPool {
    spawn_rayon_thread_pool_with_start_hook(thread_name, num_worker_threads, || {})
}

pub fn spawn_rayon_thread_pool_with_start_hook<F>(
    thread_name: String,
    num_worker_threads: Option<usize>,
    on_thread_start: F,
) -> ThreadPool
where
    F: Fn() + Send + Sync + 'static,
{
    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    let thread_name_clone = thread_name.clone();
    let mut builder = ThreadPoolBuilder::new()
        .thread_name(move |index| format!("{}-{index}", thread_name_clone))
        .start_handler(move |_| on_thread_start());

    if let Some(num_worker_threads) = num_worker_threads {
        builder = builder.num_threads(num_worker_threads);
    }

    // Spawn and return the threadpool
    builder.build().unwrap_or_else(|error| {
```

**File:** state-sync/storage-service/server/src/handler.rs (L80-139)
```rust
    /// Handles the given storage service request and responds to the
    /// request directly.
    pub fn process_request_and_respond(
        &self,
        storage_service_config: StorageServiceConfig,
        peer_network_id: PeerNetworkId,
        protocol_id: ProtocolId,
        request: StorageServiceRequest,
        response_sender: ResponseSender,
    ) {
        // Log the request
        trace!(LogSchema::new(LogEntry::ReceivedStorageRequest)
            .request(&request)
            .message(&format!(
                "Received storage request. Peer: {:?}, protocol: {:?}.",
                peer_network_id, protocol_id,
            )));

        // Update the request count
        increment_counter(
            &metrics::STORAGE_REQUESTS_RECEIVED,
            peer_network_id.network_id(),
            request.get_label(),
        );

        // If the request is for transaction v2 data, only process it
        // if the server supports it. Otherwise, drop the request.
        if request.data_request.is_transaction_data_v2_request()
            && !storage_service_config.enable_transaction_data_v2
        {
            warn!(LogSchema::new(LogEntry::StorageServiceError)
                .error(&Error::InvalidRequest(format!(
                    "Received a v2 data request ({}), which is not supported!",
                    request.get_label()
                )))
                .peer_network_id(&peer_network_id));
            return;
        }

        // Handle any optimistic fetch requests
        if request.data_request.is_optimistic_fetch() {
            self.handle_optimistic_fetch_request(peer_network_id, request, response_sender);
            return;
        }

        // Handle any subscription requests
        if request.data_request.is_subscription_request() {
            self.handle_subscription_request(
                storage_service_config,
                peer_network_id,
                request,
                response_sender,
            );
            return;
        }

        // Process the request and return the response to the client
        let response = self.process_request(&peer_network_id, request.clone(), false);
        self.send_response(request, response, response_sender);
    }
```
