# Audit Report

## Title
Race Condition in Layout Cache Invalidation During Module Publishing Causes Non-Deterministic Execution and Consensus Failure

## Summary
A critical race condition exists in the layout cache management during parallel block execution. When a transaction publishes an upgraded module, the new module becomes visible to concurrent transactions before the layout cache is flushed. This allows concurrent transactions to load the new module but deserialize structs using stale cached layouts from the old module, leading to type confusion, non-deterministic execution, and consensus divergence across validators.

## Finding Description

The vulnerability occurs in the interaction between module publishing and layout caching during parallel block execution.

**Architecture Background:**

The global module cache maintains two separate data structures:
1. Module cache (`module_cache: HashMap<K, Entry<D, V, E>>`) - versioned, with "overridden" flags [1](#0-0) 
2. Layout cache (`struct_layouts: DashMap<StructKey, LayoutCacheEntry>`) - NOT versioned, keyed only by struct name [1](#0-0) 

When `get_struct_layout()` is called, it directly reads from the global layout cache without any version checking: [2](#0-1) 

**The Vulnerability:**

When a transaction T1 publishes a module upgrade in parallel execution, the commit sequence in `publish_module_write_set` is:
1. Add new module to per-block cache via `add_module_write_to_module_cache` [3](#0-2) 
2. **RACE WINDOW**: New module is now visible to all concurrent transactions
3. Flush layout cache [4](#0-3) 

During the race window between steps 1 and 3, a concurrent transaction T2 can:
- Load the NEW module version (from per-block cache, since old version is marked overridden) [5](#0-4) 
- But get the OLD layout from the global cache (not yet flushed) [6](#0-5) 

The `StructKey` used for layout caching is based solely on `StructNameIndex` (struct identifier) and type arguments, with NO module version component: [7](#0-6) 

The `StructNameIndex` remains identical across module upgrades because it's based on (address, module_name, struct_name): [8](#0-7) 

Even though cached layouts trigger module re-reads for gas charging, these re-reads get the NEW module but return the OLD layout: [9](#0-8) 

**Attack Scenario:**

1. Initial state: Module `0xAttacker::Token` with `struct Coin { value: u64 }`, layout L1 cached
2. T1 (txn_idx=5) publishes upgraded module with `struct Coin { value: u64, owner: address }`
3. T1 reaches line 564 in `publish_module_write_set` - new module added to per-block cache
4. T2 (txn_idx=10) executing in parallel:
   - Loads module Token - gets NEW version with 2 fields
   - Calls `type_to_type_layout_with_delayed_fields` for Coin struct
   - Cache hit returns L1 (OLD layout expecting 1 field)
   - Deserializes Coin struct using wrong field layout
5. T1 eventually flushes cache at line 574 (too late)

The module version changes but the layout cache entry persists with the same key, causing type confusion.

## Impact Explanation

**Critical Severity: Consensus/Safety Violation**

This vulnerability breaks the fundamental **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks."

When different validators execute the same block with this race condition:
- Validators that execute T2 before T1 flushes the cache will use the old layout
- Validators that execute T2 after T1 flushes the cache will recompute the new layout
- Both read the same module (new version) but use different layouts
- Deserialization produces different `MoveValue` structures
- This leads to different execution results and different state roots
- **Validators cannot reach consensus** on the block's state root

The impact cascades to:
- **Consensus failure**: Validators produce conflicting state roots for the same block
- **Network partition**: Honest validators cannot agree on chain state
- **Requires hard fork**: No automatic recovery mechanism exists
- **Fund safety compromised**: Transactions may execute differently across nodes

This meets the **Critical Severity** criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**High Likelihood** for the following reasons:

1. **Common Operation**: Module upgrades are a standard governance operation on Aptos
2. **Natural Occurrence**: No precise timing required - parallel execution naturally creates the race window
3. **Broad Attack Surface**: Any module upgrade that changes struct layouts triggers the vulnerability
4. **No Special Permissions**: Any account authorized to publish modules can trigger this
5. **No Detection**: The race is silent - no errors thrown, just different execution results
6. **Timing Window**: In parallel execution with multiple worker threads, concurrent transactions frequently overlap with commits

The vulnerability will manifest probabilistically during normal operation whenever:
- A module with modified struct layouts is published
- Other transactions use those structs concurrently
- The timing window is hit (which is likely with 8+ parallel workers)

## Recommendation

**Immediate Fix**: Make layout cache flush atomic with module publication

**Option 1 - Flush Layout Cache Before Publishing Module** (Safest):
```rust
// In txn_last_input_output.rs, publish_module_write_set function
pub(crate) fn publish_module_write_set(...) -> Result<bool, PanicError> {
    let output_wrapper = self.output_wrappers[txn_idx as usize].lock();
    let output_before_guard = output_wrapper
        .check_success_or_skip_status()?
        .before_materialization()?;

    let mut published = false;
    let mut module_ids_for_v2 = BTreeSet::new();
    
    // FLUSH LAYOUT CACHE BEFORE PUBLISHING MODULES
    if !output_before_guard.module_write_set().is_empty() {
        global_module_cache.flush_layout_cache();
    }
    
    for write in output_before_guard.module_write_set().values() {
        published = true;
        if scheduler.is_v2() {
            module_ids_for_v2.insert(write.module_id().clone());
        }
        add_module_write_to_module_cache::<T>(
            write,
            txn_idx,
            runtime_environment,
            global_module_cache,
            versioned_cache.module_cache(),
        )?;
    }
    
    // No longer need to flush here since already done
    if published {
        scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
    }
    Ok(published)
}
```

**Option 2 - Add Module Version to Layout Cache Key** (More Complex):
Modify `StructKey` to include module version information, requiring changes to:
- `StructKey` structure to include version hash
- Layout cache lookup logic
- Layout invalidation logic

**Option 3 - Disable Layout Caching for Published Modules** (Performance Impact):
Immediately mark all layouts for affected modules as invalid when `mark_overridden` is called.

**Recommended: Option 1** - Simplest fix with minimal performance impact. Flushing before publishing ensures no transaction can see the new module with an old layout.

## Proof of Concept

```rust
// Rust integration test demonstrating the race condition
#[test]
fn test_layout_cache_race_condition() {
    use aptos_types::transaction::Transaction;
    use aptos_vm::AptosVM;
    
    // Setup: Deploy initial module with struct S { a: u64 }
    let initial_module = compile_module(r#"
        module 0xCAFE::Test {
            struct Coin has key { value: u64 }
            public fun create(): Coin { Coin { value: 100 } }
        }
    "#);
    
    // Execute initial module deployment in block N
    execute_block(vec![Transaction::UserTransaction(initial_module)]);
    
    // Create a transaction that uses Coin struct
    let use_coin_txn = compile_transaction(r#"
        script {
            use 0xCAFE::Test;
            fun main() {
                let coin = Test::create();
                // Serialize and deserialize coin
                Test::verify_coin(coin);
            }
        }
    "#);
    
    // Create upgrade transaction changing Coin layout
    let upgrade_module = compile_module(r#"
        module 0xCAFE::Test {
            struct Coin has key { 
                value: u64,
                owner: address  // NEW FIELD
            }
            public fun create(): Coin { 
                Coin { value: 100, owner: @0xABCD } 
            }
        }
    "#);
    
    // Execute both transactions in parallel in block N+1
    // Transaction 1: Upgrade module (txn_idx=0)
    // Transaction 2: Use Coin struct (txn_idx=1)
    let block = vec![
        Transaction::UserTransaction(upgrade_module),
        Transaction::UserTransaction(use_coin_txn),
    ];
    
    // Execute with parallel executor
    let executor = BlockExecutor::new(...);
    let results = executor.execute_block(block, ...);
    
    // BUG: Transaction 2 may deserialize with old layout (1 field)
    // while module has new layout (2 fields), causing type confusion
    
    // Different validators hitting the race at different times will
    // produce different state roots, breaking consensus
    assert_consensus_failure_possible(results);
}
```

**Move Test PoC** (demonstrates impact):
```move
// test_layout_race.move
#[test_only]
module 0xCAFE::LayoutRaceTest {
    use std::signer;
    
    struct CoinV1 has key, store { value: u64 }
    
    #[test(deployer = @0xCAFE, user = @0xABCD)]
    public fun test_layout_confusion(deployer: &signer, user: &signer) {
        // Initial deployment with V1
        move_to(deployer, CoinV1 { value: 100 });
        
        // Simulate upgrade to V2 (with additional field owner: address)
        // In parallel execution, another transaction reads the struct
        // using cached V1 layout but new V2 module definition
        
        // This results in:
        // - Expected: { value: 100 }
        // - Actual struct: { value: 100, owner: 0xABCD }
        // - Deserialized with V1 layout: { value: <garbage> }
        
        // Type confusion occurs, breaking deterministic execution
    }
}
```

**Notes:**
- The sequential execution path also has the flush (line 2130 in executor.rs) but suffers the same race issue
- The comment at line 2128 acknowledges this is "for simplicity" rather than correctness
- The issue affects both BlockSTM v1 and v2 schedulers

### Citations

**File:** aptos-move/block-executor/src/code_cache_global.rs (L89-97)
```rust
pub struct GlobalModuleCache<K, D, V, E> {
    /// Module cache containing the verified code.
    module_cache: HashMap<K, Entry<D, V, E>>,
    /// Sum of serialized sizes (in bytes) of all cached modules.
    size: usize,
    /// Cached layouts of structs or enums. This cache stores roots only and is invalidated when
    /// modules are published.
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L171-179)
```rust
    pub(crate) fn get_struct_layout_entry(&self, key: &StructKey) -> Option<LayoutCacheEntry> {
        match self.struct_layouts.get(key) {
            None => {
                GLOBAL_LAYOUT_CACHE_MISSES.inc();
                None
            },
            Some(e) => Some(e.deref().clone()),
        }
    }
```

**File:** aptos-move/block-executor/src/code_cache.rs (L156-161)
```rust
                if let Some(module) = self.global_module_cache.get(key) {
                    state
                        .captured_reads
                        .borrow_mut()
                        .capture_global_cache_read(key.clone(), module.clone());
                    return Ok(Some((module, Self::Version::default())));
```

**File:** aptos-move/block-executor/src/code_cache.rs (L254-257)
```rust
impl<T: Transaction, S: TStateView<Key = T::Key>> LayoutCache for LatestView<'_, T, S> {
    fn get_struct_layout(&self, key: &StructKey) -> Option<LayoutCacheEntry> {
        self.global_module_cache.get_struct_layout_entry(key)
    }
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L564-570)
```rust
            add_module_write_to_module_cache::<T>(
                write,
                txn_idx,
                runtime_environment,
                global_module_cache,
                versioned_cache.module_cache(),
            )?;
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L574-574)
```rust
            global_module_cache.flush_layout_cache();
```

**File:** third_party/move/move-vm/runtime/src/storage/ty_layout_converter.rs (L90-106)
```rust
            let key = match ty {
                Type::Struct { idx, .. } => {
                    let ty_args_id = ty_pool.intern_ty_args(&[]);
                    Some(StructKey {
                        idx: *idx,
                        ty_args_id,
                    })
                },
                Type::StructInstantiation { idx, ty_args, .. } => {
                    let ty_args_id = ty_pool.intern_ty_args(ty_args);
                    Some(StructKey {
                        idx: *idx,
                        ty_args_id,
                    })
                },
                _ => None,
            };
```

**File:** third_party/move/move-vm/types/src/loaded_data/struct_name_indexing.rs (L70-99)
```rust
    pub fn struct_name_to_idx(
        &self,
        struct_name: &StructIdentifier,
    ) -> PartialVMResult<StructNameIndex> {
        {
            let index_map = self.0.read();
            if let Some(idx) = index_map.forward_map.get(struct_name) {
                return Ok(StructNameIndex(*idx));
            }
        }

        // Possibly need to insert, so make the copies outside of the lock.
        let forward_key = struct_name.clone();
        let backward_value = Arc::new(struct_name.clone());

        let idx = {
            let mut index_map = self.0.write();

            if let Some(idx) = index_map.forward_map.get(struct_name) {
                return Ok(StructNameIndex(*idx));
            }

            let idx = index_map.backward_map.len() as u32;
            index_map.backward_map.push(backward_value);
            index_map.forward_map.insert(forward_key, idx);
            idx
        };

        Ok(StructNameIndex(idx))
    }
```

**File:** third_party/move/move-vm/runtime/src/storage/loader/lazy.rs (L203-221)
```rust
    fn load_layout_from_cache(
        &self,
        gas_meter: &mut impl DependencyGasMeter,
        traversal_context: &mut TraversalContext,
        key: &StructKey,
    ) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
        let entry = self.module_storage.get_struct_layout(key)?;
        let (layout, modules) = entry.unpack();
        for module_id in modules.iter() {
            // Re-read all modules for this layout, so that transaction gets invalidated
            // on module publish. Also, we re-read them in exactly the same way as they
            // were traversed during layout construction, so gas charging should be exactly
            // the same as on the cache miss.
            if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
                return Some(Err(err));
            }
        }
        Some(Ok(layout))
    }
```
