# Audit Report

## Title
Critical Deadlock in Sharded Block Executor Due to Unimplemented Abort Handler

## Summary
The sharded block executor contains an unimplemented `on_execution_aborted()` handler that panics with `todo!()`, causing permanent deadlock when transactions encounter fatal errors. This results in complete loss of node liveness as the receiver thread blocks indefinitely waiting for messages that will never arrive.

## Finding Description

The vulnerability exists in the cross-shard dependency handling mechanism of the sharded block executor. When executing blocks with cross-shard dependencies, the system creates `RemoteStateValue::waiting()` instances and spawns two threads in a rayon scope:

1. **Receiver thread**: Continuously calls `receive_cross_shard_msg()` which blocks on channel recv()
2. **Execution thread**: Executes transactions and sends cross-shard updates [1](#0-0) 

The receiver thread loops indefinitely until it receives a `StopMsg`: [2](#0-1) 

However, when a transaction encounters a fatal error (FatalVMError, DelayedFieldsCodeInvariantError, or SpeculativeExecutionAbortError), the `CrossShardCommitSender::on_execution_aborted()` method is called, which contains only: [3](#0-2) 

This `todo!()` macro **panics**, causing the execution thread to terminate. The critical issue is that `StopMsg` is only sent after successful execution: [4](#0-3) 

Since the execution thread panicked before reaching this code, the `StopMsg` is never sent. The receiver thread remains blocked in `receive_cross_shard_msg()`, which internally calls `.recv()` on a channel - a blocking operation with no timeout: [5](#0-4) 

The rayon scope waits for all spawned threads to complete before returning. With one thread panicked and one thread blocked forever, the entire executor deadlocks.

Additionally, any `RemoteStateValue` instances that were created with `waiting()` will never receive their `set_value()` calls, and any code attempting to read these values via `get_value()` will block indefinitely: [6](#0-5) 

Fatal errors that trigger this vulnerability include VM errors during execution: [7](#0-6) 

## Impact Explanation

This is a **Critical Severity** vulnerability under the Aptos bug bounty program classification "Total loss of liveness/network availability" because:

1. **Complete Node Freeze**: Once triggered, the entire sharded executor thread pool deadlocks permanently
2. **No Recovery Mechanism**: There is no timeout, circuit breaker, or error handling to recover from this state
3. **Validator Impact**: Affected validator nodes cannot process any further blocks, breaking consensus participation
4. **Network Degradation**: If multiple validators encounter this simultaneously, the network could lose liveness entirely
5. **Deterministic Trigger**: Any transaction causing a fatal VM error during sharded execution will trigger this

The vulnerability breaks the **liveness invariant** - the system must continue making progress under normal operation. A deadlocked executor violates this fundamental requirement.

## Likelihood Explanation

**High Likelihood** due to:

1. **Legitimate Trigger Conditions**: Fatal VM errors can occur through legitimate but edge-case transactions, not just malicious inputs
2. **Unfinished Implementation**: The presence of `todo!()` in production code indicates this path was never tested
3. **No Safeguards**: No timeout mechanisms, error recovery, or panic handling exists in the critical path
4. **Wide Attack Surface**: Any transaction payload that triggers DelayedFieldsCodeInvariantError, SpeculativeExecutionAbortError, or FatalVMError will cause the deadlock

While sharded execution may not be enabled by default on all nodes, when it is enabled, this vulnerability is easily triggerable.

## Recommendation

**Immediate Fix**: Implement proper error handling in `on_execution_aborted()` to send `StopMsg` and set sentinel values for all pending `RemoteStateValue` instances:

```rust
fn on_execution_aborted(&self, _txn_idx: TxnIndex) {
    // Send StopMsg to unblock receiver thread
    if let Some(shard_id) = self.shard_id {
        self.cross_shard_client.send_cross_shard_msg(
            shard_id,
            self.current_round,
            CrossShardMsg::StopMsg,
        );
    } else {
        self.cross_shard_client.send_global_msg(CrossShardMsg::StopMsg);
    }
    
    // Optionally: send None values for all dependent edges to unblock waiting transactions
    // This allows graceful degradation rather than hanging
}
```

**Additional Safeguards**:
1. Add timeout to `receive_cross_shard_msg()` using `recv_timeout()` instead of `recv()`
2. Implement panic handler in rayon scope to ensure cleanup on thread panic
3. Add `RemoteStateValue::set_error()` method to signal failure states
4. Implement deadlock detection and recovery mechanisms

## Proof of Concept

```rust
// Add this test to aptos-move/aptos-vm/src/sharded_block_executor/tests.rs

#[test]
#[should_panic(expected = "not supported for sharded execution yet")]
fn test_abort_handler_deadlock() {
    use crate::sharded_block_executor::{
        cross_shard_client::{CrossShardClient, CrossShardCommitSender},
        local_executor_shard::LocalCrossShardClient,
    };
    use aptos_types::block_executor::partitioner::{SubBlock, ShardId};
    use std::sync::mpsc::channel;
    
    // Create minimal cross-shard client setup
    let (global_tx, _global_rx) = channel();
    let (msg_tx, _msg_rx) = channel();
    let client = Arc::new(LocalCrossShardClient::new(
        global_tx,
        vec![vec![msg_tx]],
        vec![],
    ));
    
    // Create a sub-block with dependencies (details omitted for brevity)
    let sub_block = SubBlock::new(/* ... */);
    let sender = CrossShardCommitSender::new(0 as ShardId, client, &sub_block);
    
    // This will panic with todo!(), leaving receiver thread blocked
    sender.on_execution_aborted(0);
    // Execution never reaches here - deadlock occurs
}
```

**Notes**

- This vulnerability only affects nodes using sharded block execution
- The `todo!()` macro in production code indicates incomplete implementation that should never have been deployed
- The fix requires careful coordination to ensure both receiver thread cleanup and dependent transaction unblocking
- This issue demonstrates the critical importance of implementing all error paths, not just happy paths, in concurrent systems

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L134-141)
```rust
        executor_thread_pool.clone().scope(|s| {
            s.spawn(move |_| {
                CrossShardCommitReceiver::start(
                    cross_shard_state_view_clone,
                    cross_shard_client,
                    round,
                );
            });
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L163-173)
```rust
                    // Send a self message to stop the cross-shard commit receiver.
                    cross_shard_client_clone.send_cross_shard_msg(
                        shard_id,
                        round,
                        CrossShardMsg::StopMsg,
                    );
                } else {
                    trace!("executed block for global shard and round {}", round);
                    // Send a self message to stop the cross-shard commit receiver.
                    cross_shard_client_clone.send_global_msg(CrossShardMsg::StopMsg);
                }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L31-44)
```rust
        loop {
            let msg = cross_shard_client.receive_cross_shard_msg(round);
            match msg {
                RemoteTxnWriteMsg(txn_commit_msg) => {
                    let (state_key, write_op) = txn_commit_msg.take();
                    cross_shard_state_view
                        .set_value(&state_key, write_op.and_then(|w| w.as_state_value()));
                },
                CrossShardMsg::StopMsg => {
                    trace!("Cross shard commit receiver stopped for round {}", round);
                    break;
                },
            }
        }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L149-151)
```rust
    fn on_execution_aborted(&self, _txn_idx: TxnIndex) {
        todo!("on_transaction_aborted not supported for sharded execution yet")
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L335-337)
```rust
    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        self.message_rxs[current_round].recv().unwrap()
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/remote_state_value.rs (L29-39)
```rust
    pub fn get_value(&self) -> Option<StateValue> {
        let (lock, cvar) = &*self.value_condition;
        let mut status = lock.lock().unwrap();
        while let RemoteValueStatus::Waiting = *status {
            status = cvar.wait(status).unwrap();
        }
        match &*status {
            RemoteValueStatus::Ready(value) => value.clone(),
            RemoteValueStatus::Waiting => unreachable!(),
        }
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L2237-2248)
```rust
                ExecutionStatus::Abort(err) => {
                    if let Some(commit_hook) = &self.transaction_commit_hook {
                        commit_hook.on_execution_aborted(idx as TxnIndex);
                    }
                    error!(
                        "Sequential execution FatalVMError by transaction {}",
                        idx as TxnIndex
                    );
                    // Record the status indicating the unrecoverable VM failure.
                    return Err(SequentialBlockExecutionError::ErrorToReturn(
                        BlockExecutionError::FatalVMError(err),
                    ));
```
