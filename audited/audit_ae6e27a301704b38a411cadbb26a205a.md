# Audit Report

## Title
Race Condition in Layout Cache Loading Causes Consensus Divergence on Module Republishing

## Summary
A critical race condition exists in `LazyLoader::load_layout_from_cache()` that allows transactions to use stale struct layouts while capturing reads of updated module versions. This bypasses validation checks and can cause different validators to produce divergent state roots for identical blocks, violating the deterministic execution invariant.

## Finding Description

The vulnerability occurs in the `load_layout_from_cache` method where struct layout entries are cloned from the global cache before module dependencies are validated: [1](#0-0) 

When a transaction T1 loads a cached layout, it follows this sequence:
1. **Line 209**: Retrieves and **clones** the layout entry from global cache
2. **Line 210**: Unpacks the cloned entry to extract layout and module list  
3. **Lines 211-219**: Iterates through modules to charge gas and capture reads

Between steps 1-2 and step 3, another transaction T2 can publish an updated module version, which triggers cache invalidation: [2](#0-1) 

The cache flush on line 574 clears all cached layouts, but transaction T1 already holds a **cloned copy** of the stale layout entry: [3](#0-2) [4](#0-3) 

When T1 subsequently calls `charge_module`, it reads the **new module version** from the per-block cache (added by T2's commit), but continues using the **old cached layout**. The module read is captured during this process: [5](#0-4) 

**Critical Issue**: Validation only checks module version consistency, not whether the layout matches the module version: [6](#0-5) 

Since T1 captured a read of the new module version, validation passes even though T1 used a stale layout based on the old module version.

**Consensus Divergence Mechanism**: Different validators may experience different race timings due to:
- Non-deterministic thread scheduling in parallel execution
- Different cache states from previous blocks  
- Timing variations in when T2's commit flushes the cache relative to T1's layout load

Validator A may load the stale layout before the flush, while Validator B loads after the flush (getting a cache miss and recomputing with the correct layout). Both validators then commit T1 with different execution results, producing different state roots for the same block.

## Impact Explanation

**Severity: Critical** (Consensus/Safety Violation - up to $1,000,000 per Aptos Bug Bounty)

This vulnerability directly violates **Invariant #1: Deterministic Execution** - "All validators must produce identical state roots for identical blocks."

When struct layouts change between module versions (e.g., field reordering, type changes, new fields), transactions using stale layouts will:
- Read incorrect field offsets when accessing struct data
- Misinterpret struct field values
- Execute different code paths based on misread values
- Produce different write sets and state changes
- Generate different event emissions

Since validation does not catch layout-module version mismatches, affected transactions commit with incorrect results. Different validators experiencing different race timings will commit different state roots, causing:
- **Chain split** requiring coordinated hardfork to resolve
- **Loss of consensus** among honest validators
- **Transaction rollback** for affected blocks
- **Network partition** until manual intervention

## Likelihood Explanation

**Likelihood: Medium-High**

The vulnerability triggers when:
1. A transaction loads a layout from cache (common for frequently-used structs)
2. Another transaction publishes a module update (happens during protocol upgrades, dApp deployments)
3. The race window is hit (microseconds between lines 209 and 216)

In Aptos's high-throughput environment with parallel execution:
- Blocks contain hundreds of transactions executing concurrently
- Module publications occur regularly during network upgrades and dApp updates
- The race window, though small, becomes statistically likely over time
- Different validators have independent thread scheduling, increasing divergence probability

**Attack Amplification**: A sophisticated attacker could deliberately:
- Publish module updates with carefully crafted struct layout changes
- Submit many concurrent transactions that use the affected structs
- Maximize the probability of race condition triggering
- Target critical system modules (account, coin, staking) for maximum impact

## Recommendation

**Fix: Atomically validate layout-module consistency within cache load**

Modify `load_layout_from_cache` to verify that all defining modules match their cached versions **before** returning the layout:

```rust
fn load_layout_from_cache(
    &self,
    gas_meter: &mut impl DependencyGasMeter,
    traversal_context: &mut TraversalContext,
    key: &StructKey,
) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
    let entry = self.module_storage.get_struct_layout(key)?;
    let (layout, modules) = entry.unpack();
    
    // NEW: Capture all module reads FIRST, storing their versions
    let mut captured_versions = Vec::with_capacity(modules.iter().count());
    for module_id in modules.iter() {
        // Charge and capture module read
        if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
            return Some(Err(err));
        }
        
        // NEW: Record the version that was just captured
        let module_version = self.module_storage
            .unmetered_get_existing_lazily_verified_module(module_id)
            .ok()?
            .code()
            .hash();
        captured_versions.push

### Citations

**File:** third_party/move/move-vm/runtime/src/storage/loader/lazy.rs (L203-221)
```rust
    fn load_layout_from_cache(
        &self,
        gas_meter: &mut impl DependencyGasMeter,
        traversal_context: &mut TraversalContext,
        key: &StructKey,
    ) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
        let entry = self.module_storage.get_struct_layout(key)?;
        let (layout, modules) = entry.unpack();
        for module_id in modules.iter() {
            // Re-read all modules for this layout, so that transaction gets invalidated
            // on module publish. Also, we re-read them in exactly the same way as they
            // were traversed during layout construction, so gas charging should be exactly
            // the same as on the cache miss.
            if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
                return Some(Err(err));
            }
        }
        Some(Ok(layout))
    }
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L559-576)
```rust
        for write in output_before_guard.module_write_set().values() {
            published = true;
            if scheduler.is_v2() {
                module_ids_for_v2.insert(write.module_id().clone());
            }
            add_module_write_to_module_cache::<T>(
                write,
                txn_idx,
                runtime_environment,
                global_module_cache,
                versioned_cache.module_cache(),
            )?;
        }
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L163-168)
```rust
    pub fn flush_layout_cache(&self) {
        // TODO(layouts):
        //   Flushing is only needed because of enums. Once we refactor layouts to store a single
        //   variant instead, this can be removed.
        self.struct_layouts.clear();
    }
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L171-179)
```rust
    pub(crate) fn get_struct_layout_entry(&self, key: &StructKey) -> Option<LayoutCacheEntry> {
        match self.struct_layouts.get(key) {
            None => {
                GLOBAL_LAYOUT_CACHE_MISSES.inc();
                None
            },
            Some(e) => Some(e.deref().clone()),
        }
    }
```

**File:** aptos-move/block-executor/src/code_cache.rs (L164-174)
```rust
                // If not global cache, check per-block cache.
                let _timer = GLOBAL_MODULE_CACHE_MISS_SECONDS.start_timer();
                let read = state
                    .versioned_map
                    .module_cache()
                    .get_module_or_build_with(key, builder)?;
                state
                    .captured_reads
                    .borrow_mut()
                    .capture_per_block_cache_read(key.clone(), read.clone());
                Ok(read)
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L1060-1067)
```rust
        let validate = |key: &K, read: &ModuleRead<DC, VC, S>| match read {
            ModuleRead::GlobalCache(_) => global_module_cache.contains_not_overridden(key),
            ModuleRead::PerBlockCache(previous) => {
                let current_version = per_block_module_cache.get_module_version(key);
                let previous_version = previous.as_ref().map(|(_, version)| *version);
                current_version == previous_version
            },
        };
```
