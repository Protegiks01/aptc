# Audit Report

## Title
OptQS Complete Author Exclusion Leading to Persistent Throughput Degradation

## Summary
The `get_exclude_authors()` function in `ExponentialWindowFailureTracker` can accumulate all validators into the exclusion set when multiple rounds experience `PayloadUnavailable` timeouts with different missing authors. This causes OptQS (Optimistic Quorum Store) to fail pulling any batches, creating a persistent throughput degradation that is difficult to recover from. While consensus continues with proof-based batches, the optimization is completely disabled.

## Finding Description

The vulnerability exists in how the Optimistic Quorum Store (OptQS) tracks and excludes problematic validators. When a validator cannot vote on a proposal because OptQS payload batches are unavailable locally, it creates a `PayloadUnavailable` timeout with a `missing_authors` BitVec marking which validators' batches are missing. [1](#0-0) 

The `ExponentialWindowFailureTracker` accumulates these missing authors across multiple rounds: [2](#0-1) 

The critical issue is that `get_exclude_authors()` performs a **UNION** of all missing authors from the last `window` rounds (up to 100 rounds in production): [3](#0-2) 

There is **no validation** that prevents `exclude_authors` from containing all validators: [4](#0-3) 

When OptQS attempts to pull batches with this exclusion set, it filters out all authors: [5](#0-4) 

If `exclude_authors` contains all validators, the filter at line 599 excludes everyone, `iters` becomes empty, and no OptQS batches are pulled.

**Attack Scenario:**
1. Network degradation or partition occurs affecting different validators over time
2. Round N: Validators A,B,C have unavailable payloads → added to exclude_authors
3. Round N+1: Validators D,E,F have unavailable payloads → added to exclude_authors
4. ...continues...
5. After enough rounds, ALL validators are in exclude_authors
6. OptQS returns empty batches on every proposal
7. Window stays at max (100), requiring 100 consecutive successes to reset
8. System enters recovery deadlock

## Impact Explanation

This is a **HIGH severity** vulnerability, not Critical as initially claimed:

**Why NOT Critical:**
- Consensus does **not** completely halt
- Proof-based batches continue to work (they use `&HashSet::new()` for exclusion): [6](#0-5) 
- Inline batches also continue functioning
- Blocks are still proposed and committed

**Why HIGH:**
- **Significant persistent throughput degradation**: OptQS is the optimization layer designed to improve performance. Its complete failure substantially reduces transaction throughput
- **Difficult recovery**: Requires 100 consecutive successful rounds to reset the window back to 2: [7](#0-6) 
- **Recovery deadlock**: If network conditions remain degraded, the system cannot naturally recover since each failure doubles the window
- **Validator node slowdowns**: Aligns with High severity criteria per Aptos bug bounty

## Likelihood Explanation

**Medium to High Likelihood:**

**Natural occurrence:**
- Network partitions or degraded connectivity across geographically distributed validators
- Rolling network issues affecting different validator subsets in sequence
- Infrastructure problems (DNS, routing, peering issues) that create intermittent connectivity

**Triggered scenario:**
- Network-level attacker causing selective connectivity disruption (though DoS itself is out of scope, the resulting state is in scope)
- Cloud provider issues affecting validator hosting
- BGP routing instabilities

With 100 rounds of lookback and potentially 100-200 validators in the network, accumulating all validators is realistic during sustained network degradation lasting several minutes to hours.

## Recommendation

Add validation to prevent complete author exclusion:

```rust
fn get_exclude_authors(&self) -> HashSet<Author> {
    let mut exclude_authors = HashSet::new();
    
    let limit = self.window;
    for round_reason in self.past_round_statuses.iter().rev().take(limit) {
        if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
            missing_authors,
        }) = round_reason
        {
            for author_idx in missing_authors.iter_ones() {
                if let Some(author) = self.ordered_authors.get(author_idx) {
                    exclude_authors.insert(*author);
                }
            }
        }
    }
    
    // MITIGATION: Ensure at least some authors remain available
    // Keep at least 1/3 of validators available for OptQS
    let max_exclude = (self.ordered_authors.len() * 2) / 3;
    if exclude_authors.len() > max_exclude {
        warn!(
            "OptQS exclude_authors ({}) exceeds safety threshold ({}), clearing to prevent complete exclusion",
            exclude_authors.len(),
            max_exclude
        );
        // Clear exclusions and reset window to recover
        return HashSet::new();
    }
    
    exclude_authors
}
```

Additionally, add validation in `get_params()`:

```rust
let exclude_authors = tracker.get_exclude_authors();
if exclude_authors.len() >= tracker.ordered_authors.len() {
    warn!("OptQS: All authors would be excluded, disabling OptQS for this round");
    return None;
}
```

## Proof of Concept

```rust
#[test]
fn test_all_validators_excluded() {
    use aptos_types::validator_verifier::random_validator_verifier;
    use aptos_bitvec::BitVec;
    
    let num_validators = 10;
    let (_signers, verifier) = random_validator_verifier(num_validators, None, false);
    let mut tracker = ExponentialWindowFailureTracker::new(
        100, 
        verifier.get_ordered_account_addresses()
    );
    
    // Simulate network degradation where different validators fail over time
    // Each round, 2 different validators have unavailable payloads
    for round in 0..5 {
        let mut missing_authors = BitVec::with_num_bits(num_validators as u16);
        let start_idx = (round * 2) % num_validators;
        missing_authors.set(start_idx as u16);
        missing_authors.set(((start_idx + 1) % num_validators) as u16);
        
        tracker.push(NewRoundReason::Timeout(
            RoundTimeoutReason::PayloadUnavailable { missing_authors }
        ));
    }
    
    // After 5 rounds with different missing authors, all 10 validators are excluded
    let exclude_authors = tracker.get_exclude_authors();
    
    // VULNERABILITY: exclude_authors contains all validators
    assert_eq!(exclude_authors.len(), num_validators);
    
    // This means OptQS would pull zero batches
    // In production, this causes persistent throughput degradation
    println!("All {} validators excluded from OptQS!", exclude_authors.len());
}
```

**Notes:**
- The vulnerability is real and exploitable under realistic network conditions
- The severity is **HIGH**, not Critical, because consensus continues with proof-based batches
- Recovery requires 100 consecutive successful rounds, creating a potential deadlock
- The fix should maintain at least 1/3 of validators available for OptQS or disable OptQS entirely when exclusion threshold is reached

### Citations

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L72-78)
```rust
        if self.last_consecutive_success_count == 0 {
            self.window *= 2;
            self.window = self.window.min(self.max_window);
        } else if self.last_consecutive_success_count == self.past_round_statuses.len() {
            self.window = 2;
        }
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L145-160)
```rust
        let exclude_authors = tracker.get_exclude_authors();
        if !exclude_authors.is_empty() {
            let exclude_authors_str: Vec<_> =
                exclude_authors.iter().map(|a| a.short_str()).collect();
            for author in &exclude_authors_str {
                counters::OPTQS_EXCLUDE_AUTHORS_COUNT
                    .with_label_values(&[author.as_str()])
                    .inc();
            }
            warn!("OptQS exclude authors: {:?}", exclude_authors_str);
        }
        Some(OptQSPayloadPullParams {
            exclude_authors,
            minimum_batch_age_usecs: self.minimum_batch_age_usecs,
        })
    }
```

**File:** consensus/src/epoch_manager.rs (L901-904)
```rust
        let failures_tracker = Arc::new(Mutex::new(ExponentialWindowFailureTracker::new(
            100,
            epoch_state.verifier.get_ordered_account_addresses(),
        )));
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L409-419)
```rust
        let (result, all_txns, unique_txns, is_full) = self.pull_internal(
            false,
            excluded_batches,
            &HashSet::new(),
            max_txns,
            max_txns_after_filtering,
            soft_max_txns_after_filtering,
            return_non_full,
            block_timestamp,
            None,
        );
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L596-625)
```rust
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
        {
            let batch_iter = batches.iter().rev().filter_map(|(sort_key, info)| {
                if let Some(item) = self.items.get(&sort_key.batch_key) {
                    let batch_create_ts_usecs =
                        item.info.expiration() - self.batch_expiry_gap_when_init_usecs;

                    // Ensure that the batch was created at least `min_batch_age_usecs` ago to
                    // reduce the chance of inline fetches.
                    if max_batch_creation_ts_usecs
                        .is_some_and(|max_create_ts| batch_create_ts_usecs > max_create_ts)
                    {
                        return None;
                    }

                    if item.is_committed() {
                        return None;
                    }
                    if !(batches_without_proofs ^ item.proof.is_none()) {
                        return Some((info, item));
                    }
                }
                None
            });
            iters.push(batch_iter);
        }

```
