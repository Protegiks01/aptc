# Audit Report

## Title
Silent Message Drop in Remote Executor Causes Permanent Consensus Deadlock

## Summary
The `send_incoming_message_to_handler` function in the secure networking layer silently drops messages when no handler is registered, logging only a warning. When this occurs during critical consensus block execution via the remote executor system, the coordinator deadlocks indefinitely waiting for execution results that never arrive, causing total loss of network liveness.

## Finding Description

The vulnerability exists in the message routing logic for the remote executor system used in sharded block execution: [1](#0-0) [2](#0-1) 

When a message arrives for an unregistered handler, both code paths only log a warning/error and drop the message. Critically, the GRPC service returns `Ok(Response::new(Empty {}))`, providing no indication to the sender that the message was not processed.

This becomes a critical issue in the consensus execution path where the remote executor coordinator sends sharded execution commands: [3](#0-2) [4](#0-3) 

The coordinator sends execution commands and then blocks indefinitely waiting for results: [5](#0-4) 

**Attack Scenario:**

1. **Timing Race on Initialization:** Remote executor shards initialize slower than the coordinator. The coordinator starts sending execution commands via the network before shards have registered their handlers via `create_inbound_channel`: [6](#0-5) 

2. **Shard Restart Window:** A shard crashes and restarts (e.g., due to OOM or resource exhaustion). During the restart window, execution commands arrive and are silently dropped because handlers aren't yet registered.

3. The messages are lost with only a log entry. The coordinator's `rx.recv().unwrap()` has no timeout and blocks forever waiting for results that will never arrive.

4. The validator node deadlocks and cannot complete block execution, breaking consensus liveness.

The test code itself acknowledges this timing issue: [7](#0-6) 

## Impact Explanation

This vulnerability meets **Critical Severity** criteria per the Aptos bug bounty program:

**Total loss of liveness/network availability**: When the remote executor deadlocks during consensus block execution, the affected validator cannot process blocks. If multiple validators are affected (common in synchronized deployments or coordinated restarts), the network loses the ability to reach consensus and stops producing blocks.

**Non-recoverable without intervention**: The `recv().unwrap()` call has no timeout mechanism. The deadlock is permanent until the validator process is manually killed and restarted, requiring operational intervention.

This breaks the **Consensus Liveness** invariant - the network must be able to continuously process and commit blocks under normal operating conditions (< 1/3 Byzantine failures).

## Likelihood Explanation

**High Likelihood** in production deployments using remote executor shards:

1. **Natural Occurrence:** Distributed systems commonly experience initialization timing issues, especially during:
   - Rolling upgrades where shards restart sequentially
   - Network partitions causing delayed initialization
   - Resource contention during startup causing variable timing

2. **Attacker Amplification:** An attacker could increase likelihood by:
   - Sending resource-intensive transactions to trigger OOM and force shard restarts
   - Creating network congestion to delay handler registration
   - Exploiting any crash bugs to force shard restarts during execution

3. **No Mitigation:** The code has no retry logic, timeout handling, or error propagation. Once messages are dropped, there is no recovery path.

## Recommendation

Implement proper error handling and timeout mechanisms:

1. **Add timeout to result waiting:**
   - Replace `rx.recv().unwrap()` with `rx.recv_timeout(Duration::from_secs(timeout))`
   - Return appropriate error when timeout occurs

2. **Propagate errors from message handlers:**
   - Return error from `simple_msg_exchange` when no handler exists instead of `Ok(Response::new(Empty {}))`
   - Allow caller to detect and retry failed messages

3. **Implement synchronization barrier:**
   - Add health check endpoint to verify all handlers are registered before accepting execution commands
   - Wait for all shards to signal readiness before coordinator sends commands

4. **Add message acknowledgment:**
   - Implement explicit ACK/NACK responses so coordinator knows if command was processed
   - Retry unacknowledged messages with exponential backoff

## Proof of Concept

**Reproduction Steps:**

1. Deploy remote executor with coordinator and 4 shards
2. Configure coordinator address and shard addresses
3. Start coordinator first (initializes quickly)
4. Start shards with intentional 2-second delay before handler registration
5. Coordinator sends execution commands during initialization window
6. Observe: Commands dropped with warning logs, coordinator deadlocks on `recv()`
7. Result: Validator cannot execute blocks, consensus stalls

**Verification:**
```bash
# Terminal 1 - Start coordinator
REMOTE_ADDRESSES="127.0.0.1:52201,127.0.0.1:52202,127.0.0.1:52203,127.0.0.1:52204" \
./aptos-node --config coordinator.yaml

# Terminal 2-5 - Start shards with delayed handler registration
# Simulate slow initialization
sleep 2 && ./executor-shard --shard-id 0 --port 52201

# Observe coordinator logs:
# "Sending block to shards"
# "Waiting for results"
# [hangs indefinitely]

# Observe shard logs:
# "No handler registered for message type: execute_command_0"
```

The coordinator never recovers and requires manual process termination.

**Notes:**
This vulnerability is particularly concerning because:
- It affects consensus execution, not just auxiliary features
- The failure mode is silent until deadlock occurs
- No automated recovery exists
- Operators may not immediately identify the root cause

The code comment at line 199 of `grpc_network_service/mod.rs` acknowledges that retry logic is needed, confirming this is a known gap in the implementation.

### Citations

**File:** secure/net/src/network_controller/inbound_handler.rs (L66-74)
```rust
    pub fn send_incoming_message_to_handler(&self, message_type: &MessageType, message: Message) {
        // Check if there is a registered handler for the sender
        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(message_type) {
            // Send the message to the registered handler
            handler.send(message).unwrap();
        } else {
            warn!("No handler registered for message type: {:?}", message_type);
        }
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L105-114)
```rust
        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
```

**File:** secure/net/src/grpc_network_service/mod.rs (L198-201)
```rust
    // wait for the server to be ready before sending messages
    // TODO: We need to implement retry on send_message failures such that we can pass this test
    //       without this sleep
    thread::sleep(std::time::Duration::from_millis(10));
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L261-267)
```rust
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
```

**File:** execution/executor-service/src/remote_executor_client.rs (L163-172)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        trace!("RemoteExecutorClient Waiting for results");
        let mut results = vec![];
        for rx in self.result_rxs.iter() {
            let received_bytes = rx.recv().unwrap().to_bytes();
            let result: RemoteExecutionResult = bcs::from_bytes(&received_bytes).unwrap();
            results.push(result.inner?);
        }
        Ok(results)
    }
```

**File:** execution/executor-service/src/remote_executor_client.rs (L201-205)
```rust
            senders[shard_id]
                .lock()
                .unwrap()
                .send(Message::new(bcs::to_bytes(&execution_request).unwrap()))
                .unwrap();
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L32-36)
```rust
        let execute_command_type = format!("execute_command_{}", shard_id);
        let execute_result_type = format!("execute_result_{}", shard_id);
        let command_rx = controller.create_inbound_channel(execute_command_type);
        let result_tx =
            controller.create_outbound_channel(coordinator_address, execute_result_type);
```
