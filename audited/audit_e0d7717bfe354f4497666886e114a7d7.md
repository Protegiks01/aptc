# Audit Report

## Title
Mempool Broadcast Clone Overhead Creates DoS Opportunity via Unbounded retry_messages Accumulation

## Summary
The `determine_broadcast_batch()` function in the mempool network layer clones `sent_messages` and `retry_messages` collections in their entirety before filtering out committed transactions. Since `retry_messages` has no explicit size limit and can grow large through repeated retry ACKs from malicious peers, this creates a DoS opportunity through excessive CPU/memory overhead and mempool lock contention. [1](#0-0) 

## Finding Description
The vulnerability exists in the broadcast batch determination logic where transaction message tracking structures are inefficiently updated. The code performs full clones of `BTreeMap` and `BTreeSet` structures before filtering, rather than filtering in-place.

**Data Structures:** [2](#0-1) 

**Attack Flow:**
1. Malicious peer connects to victim node
2. Victim broadcasts transactions to peer (governed by `max_broadcasts_per_peer` limit of 20 for fullnodes, 2 for validators)
3. Attacker immediately acknowledges each broadcast with `retry=true` flag
4. This causes entries to move from `sent_messages` to `retry_messages` [3](#0-2) 

5. Since `sent_messages` now has available capacity, new broadcasts can be sent
6. Attacker repeats the process, causing `retry_messages` to accumulate entries
7. Each subsequent call to `determine_broadcast_batch()` performs expensive clone operations on growing collections while holding the mempool lock [4](#0-3) 

**Why retry_messages is Unbounded:**
Unlike `sent_messages` which is bounded by the check at line 446, `retry_messages` has no explicit size limit: [5](#0-4) 

The only cleanup mechanism is filtering out messages for committed transactions, but if transactions remain uncommitted (due to network congestion or attacker delays), entries accumulate indefinitely.

**Configuration Values:** [6](#0-5) 

For validators, this is optimized to 2: [7](#0-6) 

## Impact Explanation
This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program criteria for "Validator node slowdowns."

**Resource Impact:**
- **CPU Overhead**: BTreeMap/BTreeSet clone operations are O(n) in both time and space complexity where n is the collection size
- **Memory Pressure**: Each clone allocates temporary memory proportional to collection size
- **Lock Contention**: Cloning occurs while holding the mempool lock, blocking concurrent mempool operations
- **Amplification**: Multiple malicious peers can independently exploit this, multiplying the effect

**Affected Systems:**
- All node types (validators, VFNs, PFNs) are vulnerable
- Validators are slightly less vulnerable due to `max_broadcasts_per_peer=2` setting
- Fullnodes with default `max_broadcasts_per_peer=20` are more exposed

**Realistic Bounds:**
With broadcast tick interval of 10ms and an attacker consistently ACKing with retry=true, hundreds of entries could accumulate in `retry_messages` over a short period, making each clone operation increasingly expensive.

## Likelihood Explanation
**Likelihood: HIGH**

**Attacker Requirements:**
- Must be a connected peer (low barrier)
- No special privileges required
- No validator collusion needed
- Simple attack: just send retry ACKs

**Attack Complexity:**
- Very low - requires only standard network protocol implementation
- Can be automated easily
- Multiple attackers can coordinate for amplified effect

**Practical Constraints:**
- Transactions must remain uncommitted to prevent filtering
- Under normal network conditions, transactions commit relatively quickly
- However, during network congestion or high load, transactions naturally stay in mempool longer, making the attack more effective
- Attacker can also artificially slow transaction processing by being selective about forwarding

## Recommendation

Replace the clone-then-filter pattern with in-place filtering using the `retain()` method, which removes elements during iteration without allocating temporary collections.

**Fixed Code:**
```rust
// Instead of cloning, filter in-place
let mempool = smp.mempool.lock();
state.broadcast_info.sent_messages.retain(|message_id, _batch| {
    !mempool.timeline_range_of_message(message_id.decode()).is_empty()
});
state.broadcast_info.retry_messages.retain(|message_id| {
    !mempool.timeline_range_of_message(message_id.decode()).is_empty()
});
```

**Additional Hardening:**
Consider adding an explicit size limit on `retry_messages` to prevent unbounded growth:
```rust
const MAX_RETRY_MESSAGES_PER_PEER: usize = 100;

// In process_broadcast_ack()
if retry && state.broadcast_info.retry_messages.len() < MAX_RETRY_MESSAGES_PER_PEER {
    sync_state.broadcast_info.retry_messages.insert(message_id);
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod dos_test {
    use super::*;
    use std::time::{SystemTime, Duration};
    
    #[tokio::test]
    async fn test_retry_messages_clone_overhead() {
        // Setup: Create mempool with test config
        let mut config = MempoolConfig::default();
        config.max_broadcasts_per_peer = 20;
        
        // Simulate malicious peer that repeatedly ACKs with retry=true
        let peer = PeerNetworkId::random();
        let mut network_interface = /* setup network interface */;
        
        // Phase 1: Send broadcasts and immediately ACK with retry
        for round in 0..50 {
            // Node sends up to max_broadcasts_per_peer
            for i in 0..config.max_broadcasts_per_peer {
                let message_id = MempoolMessageId(vec![(round * 100 + i, round * 100 + i + 50)]);
                
                // Simulate broadcast
                network_interface.update_broadcast_state(
                    peer,
                    message_id.clone(),
                    SystemTime::now(),
                ).unwrap();
                
                // Attacker immediately ACKs with retry=true
                network_interface.process_broadcast_ack(
                    peer,
                    message_id,
                    true,  // retry=true
                    false, // backoff=false
                    SystemTime::now(),
                );
            }
        }
        
        // Phase 2: Measure clone overhead
        let start = std::time::Instant::now();
        for _ in 0..1000 {
            // This call will clone the large retry_messages set
            let _ = network_interface.determine_broadcast_batch(
                peer,
                false,
                &mut smp,
            );
        }
        let duration = start.elapsed();
        
        // Expected: With large retry_messages, this takes significant time
        // versus the baseline with small retry_messages
        println!("Time for 1000 determine_broadcast_batch calls: {:?}", duration);
        
        // Verify retry_messages accumulated without bound
        let sync_states = network_interface.sync_states.read();
        let state = sync_states.get(&peer).unwrap();
        assert!(state.broadcast_info.retry_messages.len() > 100);
        println!("retry_messages size: {}", state.broadcast_info.retry_messages.len());
    }
}
```

**Notes**

The vulnerability stems from a performance optimization oversight where the filtering logic was implemented as clone-filter-collect rather than in-place filtering. While the filtering itself serves the correct purpose (removing stale entries), the implementation creates an exploitable DoS vector. The issue is exacerbated by:

1. No explicit bound on `retry_messages` size
2. Frequent invocation on the broadcast hot path (every ~10ms)
3. Execution while holding the mempool lock, amplifying the impact
4. Potential for multiple malicious peers to compound the effect

This breaks the **Resource Limits** invariant (#9 from the specification): "All operations must respect gas, storage, and computational limits" by allowing unbounded resource consumption through clone operations.

### Citations

**File:** mempool/src/shared_mempool/network.rs (L315-346)
```rust
        if let Some(sent_timestamp) = sync_state.broadcast_info.sent_messages.remove(&message_id) {
            let rtt = timestamp
                .duration_since(sent_timestamp)
                .expect("failed to calculate mempool broadcast RTT");

            let network_id = peer.network_id();
            counters::SHARED_MEMPOOL_BROADCAST_RTT
                .with_label_values(&[network_id.as_str()])
                .observe(rtt.as_secs_f64());

            counters::shared_mempool_pending_broadcasts(&peer).dec();
        } else {
            trace!(
                LogSchema::new(LogEntry::ReceiveACK)
                    .peer(&peer)
                    .message_id(&message_id),
                "request ID does not exist or expired"
            );
            return;
        }

        trace!(
            LogSchema::new(LogEntry::ReceiveACK)
                .peer(&peer)
                .message_id(&message_id)
                .backpressure(backoff),
            retry = retry,
        );
        tasks::update_ack_counter(&peer, counters::RECEIVED_LABEL, retry, backoff);

        if retry {
            sync_state.broadcast_info.retry_messages.insert(message_id);
```

**File:** mempool/src/shared_mempool/network.rs (L399-421)
```rust
        let mempool = smp.mempool.lock();
        state.broadcast_info.sent_messages = state
            .broadcast_info
            .sent_messages
            .clone()
            .into_iter()
            .filter(|(message_id, _batch)| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeMap<MempoolMessageId, SystemTime>>();
        state.broadcast_info.retry_messages = state
            .broadcast_info
            .retry_messages
            .clone()
            .into_iter()
            .filter(|message_id| {
                !mempool
                    .timeline_range_of_message(message_id.decode())
                    .is_empty()
            })
            .collect::<BTreeSet<MempoolMessageId>>();
```

**File:** mempool/src/shared_mempool/network.rs (L446-448)
```rust
            if pending_broadcasts >= self.mempool_config.max_broadcasts_per_peer {
                return Err(BroadcastError::TooManyPendingBroadcasts(peer));
            }
```

**File:** mempool/src/shared_mempool/types.rs (L455-474)
```rust
/// Txn broadcast-related info for a given remote peer.
#[derive(Clone, Debug)]
pub struct BroadcastInfo {
    // Sent broadcasts that have not yet received an ack.
    pub sent_messages: BTreeMap<MempoolMessageId, SystemTime>,
    // Broadcasts that have received a retry ack and are pending a resend.
    pub retry_messages: BTreeSet<MempoolMessageId>,
    // Whether broadcasting to this peer is in backoff mode, e.g. broadcasting at longer intervals.
    pub backoff_mode: bool,
}

impl BroadcastInfo {
    fn new() -> Self {
        Self {
            sent_messages: BTreeMap::new(),
            retry_messages: BTreeSet::new(),
            backoff_mode: false,
        }
    }
}
```

**File:** config/src/config/mempool_config.rs (L117-117)
```rust
            max_broadcasts_per_peer: 20,
```

**File:** config/src/config/mempool_config.rs (L199-203)
```rust
            // Set the max_broadcasts_per_peer to 2 (default is 20)
            if local_mempool_config_yaml["max_broadcasts_per_peer"].is_null() {
                mempool_config.max_broadcasts_per_peer = 2;
                modified_config = true;
            }
```
