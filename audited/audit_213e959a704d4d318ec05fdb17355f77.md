# Audit Report

## Title
Race Condition in Order Vote Garbage Collection Leading to Loss of Valid Votes

## Summary
The `garbage_collect()` function in `PendingOrderVotes` can prematurely delete partially aggregated order votes when `highest_ordered_round` is updated from peer synchronization, potentially causing individual nodes to lose progress on vote aggregation for intermediate rounds. While this does not cause network-wide liveness failure, it represents a design flaw where local vote collection can be disrupted.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Vote Collection Window**: [1](#0-0) 
   Order votes are only accepted if `order_vote_round > highest_ordered_round AND order_vote_round < highest_ordered_round + 100`.

2. **Garbage Collection Logic**: [2](#0-1) 
   The function deletes all votes where `round <= highest_ordered_round` using a strict inequality check.

3. **Dynamic Update of highest_ordered_round**: [3](#0-2) 
   When receiving a `SyncInfo` from peers, the local `highest_ordered_round` can jump forward significantly.

**Attack Scenario:**
1. Node A collects 2 out of 3 order votes for block at round 105 (stored in `pending_order_votes`)
2. Node A receives a `SyncInfo` message from Node B with `highest_ordered_cert` for round 120
3. Node A processes the sync: [4](#0-3) 
4. This updates Node A's `highest_ordered_round` to 120
5. Subsequently, `garbage_collect(120)` is invoked: [5](#0-4) 
6. All pending votes for round 105 are deleted since `105 <= 120`
7. When the third validator sends its order vote for round 105, it's rejected: [6](#0-5) 
8. Node A cannot locally complete the ordered certificate for round 105

**Key Evidence of Design Uncertainty:**
The developers themselves questioned this behavior: [7](#0-6) 
The comment "Question: We are updating highest_ordered_cert but not highest_ordered_root. Is that fine?" indicates uncertainty about updating the ordered cert without ensuring local state consistency.

## Impact Explanation

**Severity Assessment: Medium** 

This issue does NOT meet Critical or High severity because:
- It does not cause **network-wide liveness failure** - other nodes can still order blocks
- It does not violate **consensus safety** - no double-spending or chain splits
- Affected nodes can recover through synchronization with peers

However, it represents a **state inconsistency requiring intervention** (Medium severity per Aptos Bug Bounty):
- Individual nodes lose partially collected votes unnecessarily
- Nodes waste resources re-collecting votes that were already partially aggregated
- In edge cases with network partitions, this could temporarily slow block ordering

The impact is limited because the SyncInfo mechanism ensures that ordered certificates from other nodes will eventually propagate, allowing affected nodes to catch up.

## Likelihood Explanation

**Likelihood: Medium-High** in normal network conditions

This can occur during:
- Normal peer synchronization when nodes have different views of ordered rounds
- Network latency causing some nodes to be temporarily behind
- Validator restarts or catch-up scenarios
- Any situation where nodes receive SyncInfo from faster peers

The scenario does NOT require:
- Byzantine validators
- Malicious attacks
- Bugs in other components

It can happen organically in a distributed network where validators process blocks at different rates.

## Recommendation

**Solution 1: More Conservative Garbage Collection**
Only garbage collect votes that are significantly behind the ordered root, not just based on `highest_ordered_cert`:

```rust
pub fn garbage_collect(&mut self, highest_ordered_round: u64, ordered_root_round: u64) {
    // Use ordered_root (what's been executed) rather than highest_ordered_cert
    // Also add a safety buffer
    let gc_threshold = ordered_root_round.saturating_sub(10);
    
    self.li_digest_to_votes
        .retain(|_, (_, status)| match status {
            OrderVoteStatus::EnoughVotes(li_with_sig) => {
                li_with_sig.ledger_info().round() > gc_threshold
            },
            OrderVoteStatus::NotEnoughVotes(sig_aggregator) => {
                sig_aggregator.data().round() > gc_threshold
            },
        });
}
```

**Solution 2: Separate Tracking of Local vs Network State**
Track `local_highest_ordered_round` (based on locally aggregated votes) separately from `network_highest_ordered_round` (from SyncInfo), and only garbage collect based on the local value.

## Proof of Concept

```rust
// This would be a test in consensus/src/pending_order_votes.rs

#[test]
fn test_premature_garbage_collection() {
    use aptos_consensus_types::{order_vote::OrderVote, quorum_cert::QuorumCert};
    use aptos_types::validator_verifier::random_validator_verifier;
    
    let (signers, verifier) = random_validator_verifier(3, Some(2), false);
    let mut pending_votes = PendingOrderVotes::new();
    
    // Create votes for round 105
    let li_round_105 = LedgerInfo::new(
        BlockInfo::new(1, 105, HashValue::random(), HashValue::random(), 0, 0, None),
        HashValue::random(),
    );
    let qc = QuorumCert::dummy();
    
    // Validator 0 and 1 send votes for round 105 (2 out of 3)
    let vote_0 = OrderVote::new_with_signature(
        signers[0].author(),
        li_round_105.clone(),
        signers[0].sign(&li_round_105).unwrap(),
    );
    let vote_1 = OrderVote::new_with_signature(
        signers[1].author(),
        li_round_105.clone(),
        signers[1].sign(&li_round_105).unwrap(),
    );
    
    pending_votes.insert_order_vote(&vote_0, &verifier, Some(qc.clone()));
    pending_votes.insert_order_vote(&vote_1, &verifier, None);
    
    // Verify we have pending votes
    assert!(pending_votes.exists(&li_round_105.hash()));
    
    // Simulate receiving SyncInfo with highest_ordered_round = 120
    // This triggers garbage collection
    pending_votes.garbage_collect(120);
    
    // Votes for round 105 are now deleted!
    assert!(!pending_votes.exists(&li_round_105.hash()));
    
    // Third validator tries to vote, but votes were already lost
    let vote_2 = OrderVote::new_with_signature(
        signers[2].author(),
        li_round_105.clone(),
        signers[2].sign(&li_round_105).unwrap(),
    );
    
    // This vote would complete the quorum, but the previous votes were deleted
    let result = pending_votes.insert_order_vote(&vote_2, &verifier, None);
    
    // We cannot form QC anymore because we lost the previous 2 votes
    assert!(matches!(result, OrderVoteReceptionResult::VoteAdded(_)));
    assert!(!pending_votes.has_enough_order_votes(&li_round_105));
}
```

## Notes

While this issue causes local state disruption and wasted work, it does NOT cause permanent network-wide liveness failure because:

1. The SyncInfo with `highest_ordered_round = 120` should contain (or lead to fetching) ordered certificates for intermediate rounds
2. Nodes recover through the synchronization mechanism
3. The network as a whole continues to make progress

The vulnerability represents a **design flaw** rather than a critical consensus break. The developer comment at [7](#0-6)  indicates this uncertainty was known but not fully addressed.

### Citations

**File:** consensus/src/round_manager.rs (L466-467)
```rust
        self.pending_order_votes
            .garbage_collect(self.block_store.sync_info().highest_ordered_round());
```

**File:** consensus/src/round_manager.rs (L1571-1572)
```rust
            if order_vote_round > highest_ordered_round
                && order_vote_round < highest_ordered_round + 100
```

**File:** consensus/src/round_manager.rs (L1603-1621)
```rust
            } else {
                ORDER_VOTE_NOT_IN_RANGE.inc();
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    info!(
                        "[sampled] Received an order vote not in the 100 rounds. Order vote round: {:?}, Highest ordered round: {:?}",
                        order_vote_msg.order_vote().ledger_info().round(),
                        self.block_store.sync_info().highest_ordered_round()
                    )
                );
                sample!(
                    SampleRate::Frequency(2),
                    debug!(
                        "Received an order vote not in the next 100 rounds. Order vote round: {:?}, Highest ordered round: {:?}",
                        order_vote_msg.order_vote().ledger_info().round(),
                        self.block_store.sync_info().highest_ordered_round()
                    )
                );
            }
```

**File:** consensus/src/pending_order_votes.rs (L160-169)
```rust
    pub fn garbage_collect(&mut self, highest_ordered_round: u64) {
        self.li_digest_to_votes
            .retain(|_, (_, status)| match status {
                OrderVoteStatus::EnoughVotes(li_with_sig) => {
                    li_with_sig.ledger_info().round() > highest_ordered_round
                },
                OrderVoteStatus::NotEnoughVotes(sig_aggregator) => {
                    sig_aggregator.data().round() > highest_ordered_round
                },
            });
```

**File:** consensus/src/block_storage/block_tree.rs (L381-381)
```rust
            // Question: We are updating highest_ordered_cert but not highest_ordered_root. Is that fine?
```

**File:** consensus/src/block_storage/block_tree.rs (L388-391)
```rust
    pub fn insert_ordered_cert(&mut self, ordered_cert: WrappedLedgerInfo) {
        if ordered_cert.commit_info().round() > self.highest_ordered_cert.commit_info().round() {
            self.highest_ordered_cert = Arc::new(ordered_cert);
        }
```

**File:** consensus/src/block_storage/sync_manager.rs (L150-152)
```rust
        if self.order_vote_enabled {
            self.insert_ordered_cert(&sync_info.highest_ordered_cert())
                .await?;
```
