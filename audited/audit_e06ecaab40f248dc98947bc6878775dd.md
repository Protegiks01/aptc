# Audit Report

## Title
Health Checker Memory Leak via Channel Overflow Leading to Unbounded Resource Exhaustion

## Summary
The health checker component contains a critical flaw where rapid peer connect/disconnect cycles can cause `LostPeer` notification events to be dropped due to channel overflow, resulting in stale entries accumulating indefinitely in the `health_check_data` HashMap. This leads to memory exhaustion and continuous wasted CPU/network resources on dead peers, causing validator node degradation.

## Finding Description

The vulnerability arises from the interaction between three components:

1. **Channel Overflow Event Dropping**: When the connection notification channel reaches capacity (1000 events), new `LostPeer` events are silently dropped rather than queued or blocking. [1](#0-0) 

2. **Conditional Cleanup on Disconnect**: The health checker only removes entries from `health_check_data` when `disconnect_from_peer` succeeds. If the peer is already disconnected (which returns an error), cleanup is skipped. [2](#0-1) 

3. **No Alternative Cleanup Mechanism**: There is no garbage collection, timeout-based cleanup, or other fallback mechanism to remove stale entries.

**Attack Execution Path:**

1. Attacker rapidly establishes connections with many unique PeerIds (exploiting the max_inbound_connections limit cyclically)
2. Each connection triggers a `NewPeer` event that adds an entry to `health_check_data` [3](#0-2) 

3. Attacker immediately disconnects all peers
4. Each disconnect generates a `LostPeer` notification that should clean up the entry [4](#0-3) 

5. The notification channel fills to capacity (NOTIFICATION_BACKLOG = 1000), causing subsequent `LostPeer` events to be dropped [5](#0-4) 

6. Health checker retains stale entries and attempts to ping disconnected peers
7. After ping failures accumulate, health checker calls `disconnect_peer` [6](#0-5) 

8. The disconnect operation fails with `PeerManagerError::NotConnected` because the peer was already removed from `active_peers` [7](#0-6) 

9. Due to the error result, the entry is NOT removed from `health_check_data` [2](#0-1) 

10. Stale entries accumulate indefinitely with each attack cycle

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria due to "Validator node slowdowns":

- **Memory Exhaustion**: Unbounded growth of the `health_check_data` HashMap consumes increasing memory over time
- **CPU Waste**: Health checker continuously attempts to ping non-existent peers every ping interval
- **Network Bandwidth Waste**: Failed ping attempts consume outbound connection attempts and network resources
- **Validator Performance Degradation**: Accumulated overhead slows down the validator node, potentially affecting consensus participation timing
- **Persistent Impact**: Without node restart, the leak continues indefinitely

The attack does not directly compromise consensus safety or cause fund loss, but it creates sustained operational degradation that affects validator reliability and network health.

## Likelihood Explanation

**Likelihood: HIGH**

- **No Special Privileges Required**: Any network peer can connect and disconnect
- **Low Attack Complexity**: Simple repeated connection cycling
- **Bypass of Rate Limits**: While `max_inbound_connections` limits concurrent connections, rapid connect/disconnect cycles can generate thousands of events over time
- **Automatic Amplification**: Each connection attempt automatically creates a stale entry that persists forever
- **No Detection**: The attack appears as normal network churn until resource exhaustion symptoms manifest

The channel capacity of 1000 can be exceeded through:
- 1000+ rapid connects/disconnects in quick succession
- Sustained attack over time where the health checker processes events slower than the attacker generates them
- Multiple coordinated attackers

## Recommendation

Implement multi-layered defense:

**1. Unconditional Cleanup on Disconnect Attempt:**
```rust
pub async fn disconnect_peer(
    &mut self,
    peer_network_id: PeerNetworkId,
    disconnect_reason: DisconnectReason,
) -> Result<(), Error> {
    let _ = self.update_connection_state(peer_network_id, ConnectionState::Disconnecting);
    let result = self
        .network_client
        .disconnect_from_peer(peer_network_id, disconnect_reason)
        .await;
    let peer_id = peer_network_id.peer_id();
    
    // ALWAYS remove from health_check_data, regardless of disconnect result
    // If peer is already gone, we should clean up our tracking anyway
    self.health_check_data.write().remove(&peer_id);
    
    result
}
```

**2. Implement Periodic Garbage Collection:**
Add a periodic cleanup task that removes entries for peers not in the connected peers list:
```rust
// In health checker main loop, add periodic cleanup
if self.round % CLEANUP_INTERVAL == 0 {
    let connected_peer_ids: HashSet<_> = self.network_interface
        .get_peers_and_metadata()
        .get_connected_peers_and_metadata()
        .unwrap_or_default()
        .keys()
        .map(|pni| pni.peer_id())
        .collect();
    
    self.network_interface.health_check_data.write()
        .retain(|peer_id, _| connected_peer_ids.contains(peer_id));
}
```

**3. Increase Channel Capacity or Use Blocking Semantics:**
Consider using a larger channel or blocking send to prevent event loss during high churn periods.

## Proof of Concept

```rust
#[tokio::test]
async fn test_health_checker_memory_leak_via_channel_overflow() {
    // Setup health checker and network components
    let (mut health_checker, connection_tx) = setup_health_checker_for_test();
    
    // Simulate rapid connect/disconnect cycles
    const NUM_PEERS: usize = 2000;
    let mut peer_ids = Vec::new();
    
    // Phase 1: Rapidly connect many peers
    for i in 0..NUM_PEERS {
        let peer_id = PeerId::random();
        peer_ids.push(peer_id);
        
        let metadata = create_test_connection_metadata(peer_id);
        connection_tx.send(ConnectionNotification::NewPeer(
            metadata.clone(),
            NetworkId::Validator
        )).await.unwrap();
    }
    
    // Allow health checker to process NewPeer events
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Verify all peers added
    let initial_count = health_checker.network_interface
        .health_check_data.read().len();
    assert_eq!(initial_count, NUM_PEERS);
    
    // Phase 2: Rapidly disconnect all peers (faster than channel can deliver)
    // This will cause LostPeer events to be dropped due to channel overflow
    for (i, peer_id) in peer_ids.iter().enumerate() {
        let metadata = create_test_connection_metadata(*peer_id);
        connection_tx.send(ConnectionNotification::LostPeer(
            metadata,
            NetworkId::Validator
        )).await.unwrap();
    }
    
    // Phase 3: Trigger ping failures and disconnect attempts
    // Process some events but not all due to channel overflow
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    // Verify stale entries remain due to dropped LostPeer events
    let remaining_count = health_checker.network_interface
        .health_check_data.read().len();
    
    // With the bug: remaining_count > 0 (stale entries leak)
    // Expected: Many entries remain because LostPeer events were dropped
    assert!(remaining_count > 1000, 
        "Expected stale entries to leak, but found {}", remaining_count);
    
    // Verify these are actually stale (not in active_peers)
    let active_peers = get_active_peer_count();
    assert_eq!(active_peers, 0, "All peers should be disconnected");
    
    println!("Memory leak confirmed: {} stale entries remain in health_check_data", 
        remaining_count);
}
```

## Notes

This vulnerability demonstrates a critical gap in defensive programming: relying solely on event-driven cleanup without fallback mechanisms. The combination of droppable events and conditional cleanup creates an unbounded resource leak. The fix requires both immediate tactical changes (unconditional cleanup) and strategic improvements (garbage collection) to ensure robustness against high-churn network conditions.

### Citations

**File:** network/framework/src/application/storage.rs (L35-35)
```rust
const NOTIFICATION_BACKLOG: usize = 1000;
```

**File:** network/framework/src/application/storage.rs (L241-245)
```rust
                let event = ConnectionNotification::LostPeer(
                    peer_metadata.connection_metadata.clone(),
                    peer_network_id.network_id(),
                );
                self.broadcast(event);
```

**File:** network/framework/src/application/storage.rs (L378-385)
```rust
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L77-79)
```rust
        if result.is_ok() {
            self.health_check_data.write().remove(&peer_id);
        }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L214-216)
```rust
                                self.network_interface.create_peer_and_health_data(
                                    metadata.remote_peer_id, self.round
                                );
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L375-378)
```rust
                        self.network_interface.disconnect_peer(
                            peer_network_id,
                            DisconnectReason::NetworkHealthCheckFailure,
                        ),
```

**File:** network/framework/src/peer_manager/mod.rs (L494-494)
```rust
                    if let Err(err) = resp_tx.send(Err(PeerManagerError::NotConnected(peer_id))) {
```
