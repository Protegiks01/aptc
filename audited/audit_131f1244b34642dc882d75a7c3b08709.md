# Audit Report

## Title
BATCH_END Signal Sent Without Data Messages When Transaction Filtering Removes All Transactions

## Summary
The `IndexerStreamCoordinator` in the fullnode streaming protocol can send `BATCH_END` status messages without any preceding `Data` messages when transaction filters remove all transactions from a batch. This violates the protocol specification and causes version counter advancement without actual transaction delivery, leading to client-server state desynchronization.

## Finding Description

The streaming protocol specification defines a strict message ordering: [1](#0-0) 

However, a vulnerability exists in `IndexerStreamCoordinator::process_next_batch()` where transaction filtering can result in protocol violations: [2](#0-1) 

When a `BooleanTransactionFilter` is applied and filters out **all** transactions in a batch, the `pb_txns` vector becomes empty. The subsequent response construction logic creates an empty `responses` vector: [3](#0-2) 

Since `responses` is empty, the send loop never executes: [4](#0-3) 

However, the method still returns the `end_version`: [5](#0-4) 

Back in `FullnodeDataService`, this non-empty result triggers `BATCH_END` transmission: [6](#0-5) 

The version counter is then advanced: [7](#0-6) 

**Attack Path:**
1. Attacker connects to `LocalnetDataService` with a malicious transaction filter
2. Filter is crafted to exclude all transactions in a batch (e.g., filtering for non-existent event types)
3. Server fetches transactions from storage (versions X to Y)
4. All transactions are filtered out, `responses` vector is empty
5. No `Data` messages sent to client
6. `BATCH_END` sent claiming versions X to Y were delivered
7. Server advances its version counter to Y+1
8. Client expects Y-X+1 transactions but received zero

Client-side detection occurs here: [8](#0-7) 

The client crashes with a version mismatch error, but the server's state is already inconsistent.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty criteria for the following reasons:

1. **State Inconsistencies Requiring Intervention**: The server advances its version counter without delivering transactions, creating a permanent state mismatch between server tracking and actual data delivery. This requires manual intervention to correct.

2. **Indexer Infrastructure Disruption**: Cache workers and indexers that consume this stream will crash when detecting the version mismatch, disrupting the indexing infrastructure that applications depend on.

3. **Protocol Violation**: The bug violates the documented protocol specification, breaking the contract between server and clients.

4. **Limited Scope**: While serious, the impact is limited to the indexer streaming subsystem and doesn't directly affect consensus, validator operations, or user funds. The issue is contained within the data service layer.

## Likelihood Explanation

**Likelihood: Medium to High**

**Current Exploitability:**
- `FullnodeDataService` currently passes `None` for the filter parameter, making it **not directly exploitable** in production deployments
- `LocalnetDataService` accepts client-provided filters and **is immediately exploitable** [9](#0-8) 

**Attack Complexity:**
- **Low**: Attacker only needs to craft a filter that excludes all transactions
- Simple filters like `EventFilter` matching non-existent event types can achieve this
- No special privileges or validator access required

**Future Risk:**
- The vulnerable code path exists in production (`FullnodeDataService`)
- If transaction filtering is enabled in the future, the vulnerability becomes immediately exploitable
- The bug represents a latent security issue in the codebase

## Recommendation

Add validation to ensure `BATCH_END` is only sent when transactions were actually delivered. Modify `IndexerStreamCoordinator::process_next_batch()`:

```rust
// After line 218 in stream_coordinator.rs
let num_responses_sent = responses.len();

// ... existing send loop ...

// After line 226, before returning:
if num_responses_sent == 0 {
    // No data was sent, return empty to signal no progress
    return vec![];
}

vec![Ok(end_version as u64)]
```

Additionally, add a check in `FullnodeDataService` before sending `BATCH_END`:

```rust
// Before line 163 in fullnode_data_service.rs
if results.is_empty() {
    // No transactions sent in this batch, skip BATCH_END
    continue;
}

// Verify that the batch actually advanced the version
let max_version = match IndexerStreamCoordinator::get_max_batch_version(results) {
    Ok(max_version) => max_version,
    Err(e) => {
        error!("[Indexer Fullnode] Error sending to stream: {}", e);
        break;
    },
};

// Only send BATCH_END if we actually advanced past the current version
if max_version >= coordinator.current_version {
    let batch_end_status = get_status(
        StatusType::BatchEnd,
        coordinator.current_version,
        Some(max_version),
        ledger_chain_id,
    );
    // ... rest of send logic
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_transaction_filter::{BooleanTransactionFilter, filters::EventFilter};
    use aptos_protos::transaction::v1::Event;
    
    #[tokio::test]
    async fn test_batch_end_without_data_vulnerability() {
        // Setup test context with transactions
        let context = setup_test_context_with_transactions(100, 110).await;
        let (tx, mut rx) = mpsc::channel(100);
        
        // Create a filter that excludes ALL transactions
        // This filter looks for an event type that doesn't exist
        let impossible_filter = BooleanTransactionFilter::from(
            EventFilter::new(
                "0x999::NonExistentModule::NonExistentEvent".to_string(),
            )
        );
        
        let mut coordinator = IndexerStreamCoordinator::new(
            context,
            100, // starting_version
            110, // end_version
            4,   // processor_task_count
            100, // processor_batch_size
            1000, // output_batch_size
            tx,
            Some(impossible_filter), // The malicious filter
            None,
        );
        
        // Process batch - should filter out all transactions
        let results = coordinator.process_next_batch().await;
        
        // BUG: results is non-empty even though no data was sent!
        assert!(!results.is_empty(), "Vulnerability: returns non-empty result");
        
        // Check what was actually sent to the channel
        let mut data_messages_received = 0;
        while let Ok(msg) = rx.try_recv() {
            if let Ok(response) = msg {
                if matches!(response.response, Some(Response::Data(_))) {
                    data_messages_received += 1;
                }
            }
        }
        
        // VULNERABILITY CONFIRMED: No data messages sent, but results indicate success
        assert_eq!(data_messages_received, 0, "No data messages should be sent");
        assert!(results[0].is_ok(), "But method returns Ok(version)");
        
        println!("VULNERABILITY CONFIRMED:");
        println!("- Filter removed all {} transactions", 110 - 100 + 1);
        println!("- No Data messages sent: {}", data_messages_received);
        println!("- But process_next_batch returned: {:?}", results);
        println!("- This would cause BATCH_END to be sent without data!");
    }
}
```

## Notes

While `FullnodeDataService` currently doesn't use transaction filters (mitigating immediate production risk), the vulnerable code path exists in the shared `IndexerStreamCoordinator` component. `LocalnetDataService` is immediately exploitable since it accepts client-provided filters. This represents a violation of the protocol specification and the State Consistency invariant, where version counters advance without corresponding transaction delivery. The fix should enforce that `BATCH_END` signals are only sent when transactions were actually delivered to clients.

### Citations

**File:** protos/proto/aptos/internal/fullnode/v1/fullnode_data.proto (L11-16)
```text
// Transaction data is transferred via 1 stream with batches until terminated.
// One stream consists:
//  StreamStatus: INIT with version x
//  loop k:
//    TransactionOutput data(size n)
//    StreamStatus: BATCH_END with version x + (k + 1) * n - 1
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L175-182)
```rust
                let pb_txns = if let Some(ref filter) = filter {
                    pb_txns
                        .into_iter()
                        .filter(|txn| filter.matches(txn))
                        .collect::<Vec<_>>()
                } else {
                    pb_txns
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L183-198)
```rust
                let mut responses = vec![];
                // Wrap in stream response object and send to channel
                for chunk in pb_txns.chunks(output_batch_size as usize) {
                    for chunk in chunk_transactions(chunk.to_vec(), MESSAGE_SIZE_LIMIT) {
                        let item = TransactionsFromNodeResponse {
                            response: Some(transactions_from_node_response::Response::Data(
                                TransactionsOutput {
                                    transactions: chunk,
                                },
                            )),
                            chain_id: ledger_chain_id as u32,
                        };
                        responses.push(item);
                    }
                }
                responses
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L221-226)
```rust
        for response in responses {
            if self.transactions_sender.send(Ok(response)).await.is_err() {
                // Error from closed channel. This means the client has disconnected.
                return vec![];
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L237-237)
```rust
        vec![Ok(end_version as u64)]
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L163-168)
```rust
                let batch_end_status = get_status(
                    StatusType::BatchEnd,
                    coordinator.current_version,
                    Some(max_version),
                    ledger_chain_id,
                );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L198-198)
```rust
                coordinator.current_version = max_version + 1;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L433-442)
```rust
                    if current_version != start_version + num_of_transactions {
                        error!(
                            current_version = current_version,
                            actual_current_version = start_version + num_of_transactions,
                            "[Indexer Cache] End signal received with wrong version."
                        );
                        ERROR_COUNT
                            .with_label_values(&["data_end_wrong_version"])
                            .inc();
                        break;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/localnet_data_service.rs (L64-71)
```rust
        let filter = if let Some(proto_filter) = r.transaction_filter {
            Some(parse_transaction_filter(
                proto_filter,
                self.service_context.max_transaction_filter_size_bytes,
            )?)
        } else {
            None
        };
```
