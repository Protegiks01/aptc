# Audit Report

## Title
Blocking Thread Pool Exhaustion via Repeated BcsBlock Requests with Transactions

## Summary
Repeated concurrent requests to block endpoints with `with_transactions=true` can exhaust the tokio blocking thread pool (limited to 64 threads), causing complete API unavailability. While the security question mentions "database connections," the actual resource being exhausted is the blocking thread pool used for synchronous database operations, but the impact (API unavailability) remains the same.

## Finding Description

The Aptos REST API uses `tokio::task::spawn_blocking` to offload CPU-intensive and I/O-bound database operations from the async runtime. This blocking thread pool is capped at 64 threads: [1](#0-0) 

All block API endpoints use `api_spawn_blocking` which wraps this mechanism: [2](#0-1) [3](#0-2) 

When fetching blocks with transactions enabled, the code retrieves up to `max_block_transactions_page_size` transactions (default: 10,000) from the database: [4](#0-3) [5](#0-4) [6](#0-5) 

**Attack Path:**
1. Attacker sends 64+ concurrent requests to `/blocks/by_height/:height?with_transactions=true` or `/blocks/by_version/:version?with_transactions=true`
2. Each request spawns a blocking task via `api_spawn_blocking`
3. Fetching large blocks with thousands of transactions is I/O and CPU intensive, causing each blocking thread to be held for extended periods
4. Once all 64 blocking threads are occupied, new API requests (to ANY endpoint) that require `api_spawn_blocking` will queue indefinitely
5. The entire API becomes unavailable to all users

**No Rate Limiting:** The API layer has no request rate limiting middleware, only size limits: [7](#0-6) 

All endpoints (accounts, state, transactions, events, etc.) use `api_spawn_blocking`, meaning exhaustion of the blocking pool affects the entire API surface.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria:
- **"API crashes"**: The API becomes completely unavailable when the blocking thread pool is exhausted
- **"Validator node slowdowns"**: While the validator's consensus and execution continue, the API layer becomes unresponsive, preventing external clients from querying blockchain state or submitting transactions

The impact is amplified because:
1. All API endpoints share the same 64-thread blocking pool
2. Large blocks (with up to 10,000 transactions) take significant time to fetch and serialize
3. The attack is sustainable with minimal resources (64 concurrent connections)
4. All users are affected, not just the attacker

## Likelihood Explanation

**Likelihood: High**

Exploitation requirements:
- No authentication required (public API endpoint)
- Minimal resources needed (64 concurrent HTTP connections)
- Any publicly accessible block height/version can be targeted
- Attack is easily scriptable

Mitigating factors:
- The 64-thread limit prevents unbounded resource consumption
- Infrastructure-level rate limiting (HAProxy) may exist but is not guaranteed
- Blocking threads eventually complete and become available again

The developers were aware of this risk, as evidenced by the comment in the code regarding limiting "too many Rest API calls." However, the 64-thread threshold is low enough to be easily exploitable.

## Recommendation

Implement application-level rate limiting for block endpoints:

1. **Add per-IP rate limiting middleware** to the API layer:
   - Limit block requests with transactions to N per minute per IP
   - Use token bucket algorithm with configurable limits
   - Consider using the existing `aptos-rate-limiter` crate

2. **Implement request queueing with backpressure**:
   - Add a semaphore-based limiter (similar to `BoundedExecutor`) for expensive operations
   - Return 429 (Too Many Requests) when limits are exceeded

3. **Add monitoring and alerting**:
   - Track blocking thread pool utilization
   - Alert when sustained high utilization is detected

4. **Consider response size optimization**:
   - Allow clients to request specific transaction subsets
   - Implement streaming responses for large blocks

## Proof of Concept

```rust
// This is a conceptual PoC - actual implementation would require HTTP client setup
use std::sync::Arc;
use tokio::task::JoinHandle;

async fn exploit_blocking_pool_exhaustion() {
    let target_url = "http://localhost:8080/v1/blocks/by_height/1000000?with_transactions=true";
    let num_requests = 70; // Exceed the 64 thread limit
    
    let mut handles: Vec<JoinHandle<()>> = Vec::new();
    
    // Send concurrent requests to exhaust blocking thread pool
    for i in 0..num_requests {
        let url = target_url.to_string();
        let handle = tokio::spawn(async move {
            let client = reqwest::Client::new();
            let start = std::time::Instant::now();
            
            match client.get(&url).send().await {
                Ok(response) => {
                    println!("Request {}: Status {} after {:?}", i, response.status(), start.elapsed());
                },
                Err(e) => {
                    println!("Request {}: Failed after {:?} - {}", i, start.elapsed(), e);
                }
            }
        });
        handles.push(handle);
    }
    
    // Wait for all requests
    for handle in handles {
        let _ = handle.await;
    }
    
    // Try to use other API endpoints - they should be blocked/slow
    let client = reqwest::Client::new();
    let ledger_info_start = std::time::Instant::now();
    match client.get("http://localhost:8080/v1/").send().await {
        Ok(response) => {
            println!("Ledger info endpoint: Status {} after {:?}", 
                     response.status(), ledger_info_start.elapsed());
        },
        Err(e) => {
            println!("Ledger info endpoint failed: {}", e);
        }
    }
}
```

**Expected behavior:** After the first 64 requests occupy all blocking threads, subsequent requests (including to other endpoints like `/v1/`) will experience significant delays or timeouts, demonstrating API-wide unavailability.

## Notes

- The security question mentions "database connections," but AptosDB uses RocksDB which doesn't have traditional connection pools. The actual resource being exhausted is the tokio blocking thread pool.
- The vulnerability exists because expensive database read operations (fetching large blocks with many transactions) hold blocking threads for extended periods, and there's no application-level rate limiting to prevent concurrent request floods.
- Infrastructure-level mitigations (HAProxy rate limiting) may exist in production deployments but are not part of the application code and cannot be relied upon universally.

### Citations

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** api/src/blocks.rs (L56-63)
```rust
        api_spawn_blocking(move || {
            api.get_by_height(
                accept_type,
                block_height.0,
                with_transactions.0.unwrap_or_default(),
            )
        })
        .await
```

**File:** api/src/context.rs (L706-725)
```rust
        // We can only get the max_transactions page size
        let max_txns = std::cmp::min(
            self.node_config.api.max_block_transactions_page_size,
            (last_version - first_version + 1) as u16,
        );
        let txns = if with_transactions {
            Some(
                self.get_transactions(first_version, max_txns, ledger_version)
                    .context("Failed to read raw transactions from storage")
                    .map_err(|err| {
                        E::internal_with_code(
                            err,
                            AptosErrorCode::InternalError,
                            latest_ledger_info,
                        )
                    })?,
            )
        } else {
            None
        };
```

**File:** api/src/context.rs (L1645-1654)
```rust
pub async fn api_spawn_blocking<F, T, E>(func: F) -> Result<T, E>
where
    F: FnOnce() -> Result<T, E> + Send + 'static,
    T: Send + 'static,
    E: InternalError + Send + 'static,
{
    tokio::task::spawn_blocking(func)
        .await
        .map_err(|err| E::internal_with_code_no_info(err, AptosErrorCode::InternalError))?
}
```

**File:** config/src/config/api_config.rs (L130-130)
```rust
            max_block_transactions_page_size: *MAX_RECEIVING_BLOCK_TXNS as u16,
```

**File:** config/src/config/consensus_config.rs (L22-24)
```rust
const MAX_SENDING_BLOCK_TXNS: u64 = 5000;
pub(crate) static MAX_RECEIVING_BLOCK_TXNS: Lazy<u64> =
    Lazy::new(|| 10000.max(2 * MAX_SENDING_BLOCK_TXNS));
```

**File:** api/src/runtime.rs (L42-56)
```rust
pub fn bootstrap(
    config: &NodeConfig,
    chain_id: ChainId,
    db: Arc<dyn DbReader>,
    mp_sender: MempoolClientSender,
    indexer_reader: Option<Arc<dyn IndexerReader>>,
    port_tx: Option<oneshot::Sender<u16>>,
) -> anyhow::Result<Runtime> {
    let max_runtime_workers = get_max_runtime_workers(&config.api);
    let runtime = aptos_runtimes::spawn_named_runtime("api".into(), Some(max_runtime_workers));

    let context = Context::new(chain_id, db, mp_sender, config.clone(), indexer_reader);

    attach_poem_to_runtime(runtime.handle(), context.clone(), config, false, port_tx)
        .context("Failed to attach poem to runtime")?;
```
