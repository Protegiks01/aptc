# Audit Report

## Title
Silent Data Loss in Event Indexer Due to Graceful BCS Deserialization Failure Handling

## Summary
The internal event indexer silently skips V2 events that fail BCS deserialization (including `Mint` events for NFTs) by catching all translation errors and converting them to `Ok(None)` with only a warning log. This causes permanent data loss in NFT tracking systems when corrupted event data exists in AptosDB, with no error signal to alert operators or trigger recovery mechanisms. [1](#0-0) 

## Finding Description

The vulnerability exists in the event V2 to V1 translation pipeline where the indexer processes events for backward compatibility and storage.

**Event Deserialization Flow:**

1. During transaction execution, the Move VM emits V2 events with BCS-serialized data that is validated at emission time [2](#0-1) 

2. Events are stored in AptosDB and later read by the indexer

3. The indexer processes events in batches, calling `translate_event_v2_to_v1()` for each V2 event [3](#0-2) 

4. For `Mint` events, the translator calls `Mint::try_from_bytes()` which performs BCS deserialization [4](#0-3) [5](#0-4) 

**The Critical Flaw:**

When `try_from_bytes()` fails (due to corrupted storage, state sync bugs, or database corruption), the error is caught in `translate_event_v2_to_v1()` and converted to `Ok(None)` with only a warning log. The calling code treats `None` as "no translation available" and silently skips the event, continuing to process the rest of the batch.

**Attack Scenario:**

1. AptosDB storage becomes corrupted (hardware failure, storage layer bug, state sync issue)
2. A transaction with NFT `Mint` event has corrupted `event_data` bytes
3. Indexer reads the transaction and attempts to deserialize the event
4. `bcs::from_bytes()` fails with deserialization error
5. Error is caught, logged as warning: "Failed to translate event: ... Error: ..."
6. Event is silently skipped (returns `Ok(None)`)
7. Indexer marks the version as successfully processed
8. NFT tracking systems downstream have incomplete data - mint event is permanently lost

**Invariant Violation:**

This breaks the **State Consistency** invariant: the indexer database should contain a complete and accurate representation of all on-chain events. Silent skipping creates data integrity issues where:
- NFT mint events are lost (tokens appear to not exist)
- Burn events are lost (supply counts incorrect)
- Transfer events are lost (ownership data wrong)
- No error signal exists for operators to detect or recover from the issue

## Impact Explanation

This is a **Medium Severity** issue per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

**Specific Impacts:**

1. **NFT Tracking Data Loss**: Missing mint/burn/transfer events cause incorrect NFT metadata, ownership, and supply tracking
2. **Silent Degradation**: No error propagation means operators are unaware of data loss until users report discrepancies
3. **No Recovery Mechanism**: Once an event is skipped, there's no retry logic or re-indexing trigger
4. **Cascading Effects**: Downstream indexers and applications built on top of this data inherit the incompleteness
5. **Audit Trail Corruption**: Historical event data becomes permanently incomplete

While this doesn't directly cause loss of funds or consensus violations, it severely impacts data integrity guarantees that NFT applications depend on, requiring manual intervention to detect and fix.

## Likelihood Explanation

**Likelihood: Low to Medium**

**Factors Increasing Likelihood:**
- Database corruption is rare but happens in production systems (hardware failures, cosmic rays, storage bugs)
- State sync bugs could introduce corrupted data during node synchronization
- Complex event structures increase chance of deserialization issues
- High transaction throughput increases probability of encountering corruption
- No integrity checks exist specifically for event data BCS validity

**Factors Decreasing Likelihood:**
- AptosDB uses checksums and integrity checks
- Move VM validates serialization at emission time
- Consensus ensures all validators agree on event data

**When it occurs:** The impact is guaranteed - every corrupted event will be silently skipped with no recovery.

## Recommendation

**Fix 1: Fail Fast on Deserialization Errors**

Modify `translate_event_v2_to_v1()` to propagate non-expected errors instead of swallowing them:

```rust
pub fn translate_event_v2_to_v1(
    &self,
    v2: &ContractEventV2,
) -> Result<Option<ContractEventV1>> {
    let _timer = TIMER.timer_with(&["translate_event_v2_to_v1"]);
    if let Some(translator) = self
        .event_v2_translation_engine
        .translators
        .get(v2.type_tag())
    {
        let result = translator.translate_event_v2_to_v1(v2, &self.event_v2_translation_engine);
        match result {
            Ok(v1) => Ok(Some(v1)),
            Err(e) => {
                // Only ignore expected "resource not found" errors for ConcurrentSupply
                let is_ignored_error = (v2.type_tag() == &*MINT_TYPE
                    || v2.type_tag() == &*BURN_TYPE)
                    && e.to_string().contains("resource not found");
                
                if is_ignored_error {
                    Ok(None)
                } else {
                    // Propagate unexpected errors (including BCS deserialization failures)
                    // This will cause the batch to fail and trigger retry/alert mechanisms
                    Err(e)
                }
            },
        }
    } else {
        Ok(None)
    }
}
```

**Fix 2: Add Monitoring Metrics**

Add a counter for translation failures:

```rust
// In storage/indexer/src/metrics.rs
pub static EVENT_TRANSLATION_FAILURES: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "indexer_event_translation_failures_total",
        "Number of event translation failures by event type",
        &["event_type", "error_type"]
    ).unwrap()
});

// In translate_event_v2_to_v1():
if !is_ignored_error {
    EVENT_TRANSLATION_FAILURES
        .with_label_values(&[v2.type_tag().to_string().as_str(), "deserialization"])
        .inc();
    return Err(e);
}
```

**Fix 3: Add Integrity Validation**

Extend the database validation tool to verify BCS deserialization:

```rust
// In storage/aptosdb/src/db_debugger/validation.rs
fn verify_events(/* ... */) -> Result<()> {
    // ... existing code ...
    match event {
        ContractEvent::V2(v2) => {
            // Attempt to deserialize event_data for known types
            if let Some(translator) = translators.get(v2.type_tag()) {
                translator.translate_event_v2_to_v1(v2, engine)
                    .map_err(|e| anyhow::anyhow!(
                        "Event deserialization validation failed at version {}, index {}: {}",
                        version, idx, e
                    ))?;
            }
        },
        // ... rest of code ...
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_types::account_config::events::mint::Mint;
    use aptos_types::contract_event::ContractEventV2;
    
    #[test]
    fn test_corrupted_mint_event_causes_silent_data_loss() {
        // Create a Mint event type tag
        let mint_type_tag = MINT_TYPE.clone();
        
        // Create corrupted BCS data that will fail deserialization
        let corrupted_data = vec![0xFF, 0xFF, 0xFF, 0xFF]; // Invalid BCS bytes
        
        // Create V2 event with corrupted data
        let v2_event = ContractEventV2::new(mint_type_tag, corrupted_data).unwrap();
        
        // Attempt to deserialize - this should fail
        let result = Mint::try_from_bytes(v2_event.event_data());
        assert!(result.is_err(), "Corrupted data should fail deserialization");
        
        // In the actual indexer flow, this error is caught and converted to Ok(None)
        // simulating the bug:
        let indexer_result = match result {
            Ok(mint) => Some(mint),
            Err(e) => {
                // Current buggy behavior: log warning and return None
                eprintln!("Warning: Failed to deserialize: {}", e);
                None
            }
        };
        
        // The event is silently lost
        assert!(indexer_result.is_none(), "Event was silently skipped - DATA LOSS!");
        
        // No error was propagated to alert operators
        // Indexer would continue processing and mark this version as "successful"
    }
    
    #[test]
    fn test_correct_behavior_should_propagate_error() {
        let mint_type_tag = MINT_TYPE.clone();
        let corrupted_data = vec![0xFF, 0xFF, 0xFF, 0xFF];
        let v2_event = ContractEventV2::new(mint_type_tag, corrupted_data).unwrap();
        
        // Fixed behavior: propagate the error
        let result = Mint::try_from_bytes(v2_event.event_data());
        
        // Error should bubble up to batch processor
        match result {
            Ok(_) => panic!("Should have failed"),
            Err(e) => {
                // This error should cause batch processing to fail
                // triggering retry logic and alerting operators
                println!("Correctly propagated error: {}", e);
            }
        }
    }
}
```

To run this PoC:
```bash
cd aptos-core/types
cargo test test_corrupted_mint_event_causes_silent_data_loss -- --nocapture
```

**Notes**

The vulnerability specifically affects NFT and token event tracking because:

1. **High-value data**: NFT metadata, ownership, and supply tracking depend on complete event history
2. **User-facing impact**: Missing events directly affect user experience (incorrect balances, missing NFTs)
3. **Financial implications**: Incorrect supply/ownership data can affect NFT marketplace operations

The database validation tool also has this gap - it only checks that events exist and sequence numbers are correct, but doesn't validate that event_data can be properly deserialized. [6](#0-5)

### Citations

**File:** storage/indexer/src/db_indexer.rs (L448-487)
```rust
                    if self.indexer_db.event_v2_translation_enabled() {
                        if let ContractEvent::V2(v2) = event {
                            if let Some(translated_v1_event) =
                                self.translate_event_v2_to_v1(v2).map_err(|e| {
                                    anyhow::anyhow!(
                                        "Failed to translate event: {:?}. Error: {}",
                                        v2,
                                        e
                                    )
                                })?
                            {
                                let key = *translated_v1_event.key();
                                let sequence_number = translated_v1_event.sequence_number();
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
                                event_keys.insert(key);
                                batch
                                    .put::<EventByKeySchema>(
                                        &(key, sequence_number),
                                        &(version, idx as u64),
                                    )
                                    .expect("Failed to put events by key to a batch");
                                batch
                                    .put::<EventByVersionSchema>(
                                        &(key, version, sequence_number),
                                        &(idx as u64),
                                    )
                                    .expect("Failed to put events by version to a batch");
                                batch
                                    .put::<TranslatedV1EventSchema>(
                                        &(version, idx as u64),
                                        &translated_v1_event,
                                    )
                                    .expect("Failed to put translated v1 events to a batch");
                            }
                        }
                    }
                    Ok::<(), AptosDbError>(())
                })?;
            }
```

**File:** storage/indexer/src/db_indexer.rs (L552-584)
```rust
    pub fn translate_event_v2_to_v1(
        &self,
        v2: &ContractEventV2,
    ) -> Result<Option<ContractEventV1>> {
        let _timer = TIMER.timer_with(&["translate_event_v2_to_v1"]);
        if let Some(translator) = self
            .event_v2_translation_engine
            .translators
            .get(v2.type_tag())
        {
            let result = translator.translate_event_v2_to_v1(v2, &self.event_v2_translation_engine);
            match result {
                Ok(v1) => Ok(Some(v1)),
                Err(e) => {
                    // If the token object collection uses ConcurrentSupply, skip the translation and ignore the error.
                    // This is expected, as the event handle won't be found in either FixedSupply or UnlimitedSupply.
                    let is_ignored_error = (v2.type_tag() == &*MINT_TYPE
                        || v2.type_tag() == &*BURN_TYPE)
                        && e.to_string().contains("resource not found");
                    if !is_ignored_error {
                        warn!(
                            "Failed to translate event: {:?}. Error: {}",
                            v2,
                            e.to_string()
                        );
                    }
                    Ok(None)
                },
            }
        } else {
            Ok(None)
        }
    }
```

**File:** aptos-move/framework/src/natives/event.rs (L247-323)
```rust
fn native_write_module_event_to_store(
    context: &mut SafeNativeContext,
    ty_args: &[Type],
    mut arguments: VecDeque<Value>,
) -> SafeNativeResult<SmallVec<[Value; 1]>> {
    debug_assert!(ty_args.len() == 1);
    debug_assert!(arguments.len() == 1);

    let ty = &ty_args[0];
    let msg = arguments.pop_back().unwrap();

    context.charge(
        EVENT_WRITE_TO_EVENT_STORE_BASE
            + EVENT_WRITE_TO_EVENT_STORE_PER_ABSTRACT_VALUE_UNIT * context.abs_val_size(&msg)?,
    )?;

    let type_tag = context.type_to_type_tag(ty)?;

    // Additional runtime check for module call.
    let stack_frames = context.stack_frames(1);
    let id = stack_frames
        .stack_trace()
        .first()
        .map(|(caller, _, _)| caller)
        .ok_or_else(|| {
            let err = PartialVMError::new_invariant_violation(
                "Caller frame for 0x1::emit::event is not found",
            );
            SafeNativeError::InvariantViolation(err)
        })?
        .as_ref()
        .ok_or_else(|| {
            // If module is not known, this call must come from the script, which is not allowed.
            let err = PartialVMError::new_invariant_violation("Scripts cannot emit events");
            SafeNativeError::InvariantViolation(err)
        })?;

    if let TypeTag::Struct(ref struct_tag) = type_tag {
        if id != &struct_tag.module_id() {
            return Err(SafeNativeError::InvariantViolation(PartialVMError::new(
                StatusCode::INTERNAL_TYPE_ERROR,
            )));
        }
    } else {
        return Err(SafeNativeError::InvariantViolation(PartialVMError::new(
            StatusCode::INTERNAL_TYPE_ERROR,
        )));
    }

    let (layout, contains_delayed_fields) = context
        .type_to_type_layout_with_delayed_fields(ty)?
        .unpack();

    let function_value_extension = context.function_value_extension();
    let max_value_nest_depth = context.max_value_nest_depth();
    let blob = ValueSerDeContext::new(max_value_nest_depth)
        .with_delayed_fields_serde()
        .with_func_args_deserialization(&function_value_extension)
        .serialize(&msg, &layout)?
        .ok_or_else(|| {
            SafeNativeError::InvariantViolation(PartialVMError::new_invariant_violation(
                "Event serialization failure",
            ))
        })?;

    let ctx = context.extensions_mut().get_mut::<NativeEventContext>();
    let event = ContractEvent::new_v2(type_tag, blob).map_err(|_| SafeNativeError::Abort {
        abort_code: ECANNOT_CREATE_EVENT,
    })?;
    // TODO(layouts): avoid cloning layouts for events with delayed fields.
    ctx.events.push((
        event,
        contains_delayed_fields.then(|| layout.as_ref().clone()),
    ));

    Ok(smallvec![])
}
```

**File:** types/src/account_config/events/mint.rs (L38-40)
```rust
    pub fn try_from_bytes(bytes: &[u8]) -> anyhow::Result<Self> {
        bcs::from_bytes(bytes).map_err(Into::into)
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L509-556)
```rust
struct MintTranslator;
impl EventV2Translator for MintTranslator {
    fn translate_event_v2_to_v1(
        &self,
        v2: &ContractEventV2,
        engine: &EventV2TranslationEngine,
    ) -> Result<ContractEventV1> {
        let mint = Mint::try_from_bytes(v2.event_data())?;
        let fixed_supply_struct_tag = StructTag::from_str("0x4::collection::FixedSupply")?;
        let unlimited_supply_struct_tag = StructTag::from_str("0x4::collection::UnlimitedSupply")?;
        let (key, sequence_number) = if let Some(state_value_bytes) = engine
            .get_state_value_bytes_for_object_group_resource(
                mint.collection(),
                &fixed_supply_struct_tag,
            )? {
            let fixed_supply_resource: FixedSupplyResource = bcs::from_bytes(&state_value_bytes)?;
            let key = *fixed_supply_resource.mint_events().key();
            let sequence_number = engine
                .get_next_sequence_number(&key, fixed_supply_resource.mint_events().count())?;
            (key, sequence_number)
        } else if let Some(state_value_bytes) = engine
            .get_state_value_bytes_for_object_group_resource(
                mint.collection(),
                &unlimited_supply_struct_tag,
            )?
        {
            let unlimited_supply_resource: UnlimitedSupplyResource =
                bcs::from_bytes(&state_value_bytes)?;
            let key = *unlimited_supply_resource.mint_events().key();
            let sequence_number = engine
                .get_next_sequence_number(&key, unlimited_supply_resource.mint_events().count())?;
            (key, sequence_number)
        } else {
            // If the collection resource is not found, we skip the event translation to avoid panic
            // because the creation number cannot be decided. The collection may have ConcurrentSupply.
            return Err(AptosDbError::from(anyhow::format_err!(
                "FixedSupply or UnlimitedSupply resource not found"
            )));
        };
        let mint_event = MintEvent::new(mint.index().value, *mint.token());
        Ok(ContractEventV1::new(
            key,
            sequence_number,
            MINT_EVENT_TYPE.clone(),
            bcs::to_bytes(&mint_event)?,
        )?)
    }
}
```

**File:** storage/aptosdb/src/db_debugger/validation.rs (L276-316)
```rust
fn verify_events(
    transaction_list: &TransactionListWithProofV2,
    internal_indexer_db: &DB,
    start_version: u64,
) -> Result<()> {
    let mut version = start_version;
    match &transaction_list.get_transaction_list_with_proof().events {
        None => {
            return Ok(());
        },
        Some(event_vec) => {
            for events in event_vec {
                for (idx, event) in events.iter().enumerate() {
                    match event {
                        ContractEvent::V1(event) => {
                            let seq_num = event.sequence_number();
                            let event_key = event.key();
                            verify_event_by_version(
                                event_key,
                                seq_num,
                                internal_indexer_db,
                                version,
                                idx,
                            )?;
                            verify_event_by_key(
                                event_key,
                                seq_num,
                                internal_indexer_db,
                                idx,
                                version,
                            )?;
                        },
                        _ => continue,
                    }
                }
                version += 1;
            }
        },
    }
    Ok(())
}
```
