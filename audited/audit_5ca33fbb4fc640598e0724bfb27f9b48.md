# Audit Report

## Title
Memory Amplification DoS via Unbounded BinaryHeap Allocation in Use Case Tracking

## Summary
The `compute_tracking_set()` function in mempool's use case history tracking allocates a `BinaryHeap` containing all unique use cases from the tracking window without any size checks. An attacker can submit transactions to hundreds of thousands of unique contract addresses within the 40-block tracking window, causing excessive memory allocation on every block commit across all validator nodes. [1](#0-0) 

## Finding Description
The `UseCaseHistory` structure tracks transaction use cases across a sliding window to identify the most frequently used contracts. Each unique contract address called by transactions creates a unique `UseCaseKey::ContractAddress(AccountAddress)` entry in the `total` HashMap. [2](#0-1) 

When transactions are committed, state sync notifies mempool with the list of committed transactions. For each user transaction, the use case is parsed from the transaction payload based on the contract address being called: [3](#0-2) 

These use cases are accumulated in the `total` HashMap through the `add_to_recent()` method: [4](#0-3) 

The vulnerability occurs in `compute_tracking_set()`, which is called on **every block commit** to determine which use cases to track. The function creates a `BinaryHeap` by iterating through ALL entries in the `total` HashMap, even though only the top 5 use cases are ultimately needed: [5](#0-4) 

**Attack Path:**
1. Attacker submits transactions calling many different contract addresses (even non-existent ones)
2. These transactions get included in blocks (up to 10,000 transactions per block per consensus limits)
3. Over the 40-block tracking window (default configuration), hundreds of thousands of unique contract addresses accumulate in the `total` HashMap
4. On every block commit, `process_committed_transactions()` calls `compute_tracking_set()` while holding the `use_case_history` lock
5. The function allocates a `BinaryHeap` with ALL unique use cases, consuming 16+ MB of memory repeatedly [6](#0-5) [7](#0-6) 

**Realistic Scenario:**
- Maximum transactions per block: 10,000 (consensus limit)
- Tracking window: 40 blocks
- Potential unique use cases: up to 400,000
- Memory per `BinaryHeap` allocation: ~16-20 MB (400,000 entries Ã— ~40-50 bytes)
- Frequency: Every block commit (~1-2 seconds)

## Impact Explanation
This vulnerability enables a **Medium severity** resource exhaustion attack affecting validator node performance:

1. **Memory Amplification**: Attacker-controlled data (unique contract addresses) causes excessive memory allocation proportional to the number of unique contracts called
2. **Repeated Allocation**: The allocation occurs on every block commit, causing continuous memory pressure
3. **Lock Contention**: The `use_case_history` lock is held during the allocation, potentially blocking other mempool operations
4. **Network-Wide Impact**: All validator nodes running default configuration are affected

While the attack requires significant gas expenditure to maintain high unique contract counts, a well-resourced attacker could cause validator slowdowns or crashes, fitting the **Medium severity** category: "State inconsistencies requiring intervention" and potential "Validator node slowdowns" (High severity borderline).

## Likelihood Explanation
**Likelihood: Medium-High**

The attack is feasible because:
1. **No validation**: No checks limit the size of the `total` HashMap before BinaryHeap allocation
2. **Default configuration**: Default window size (40 blocks) and no rate limiting on unique use cases
3. **Cost barrier moderate**: While requiring gas fees, the attack's impact (affecting all validators) may justify the cost for attackers seeking to disrupt the network
4. **Simple execution**: Attacker only needs to submit transactions to different contract addresses

However, the cost of maintaining hundreds of thousands of unique transactions across 40 blocks provides some natural limitation.

## Recommendation
Implement a bounded approach to prevent memory amplification:

**Option 1: Early Filtering (Recommended)**
Instead of creating a BinaryHeap with all entries, use a min-heap limited to `num_top_to_track` entries during iteration:

```rust
pub fn compute_tracking_set(&self) -> HashMap<UseCaseKey, String> {
    let mut result = HashMap::new();
    result.insert(UseCaseKey::Platform, "entry_platform".to_string());
    result.insert(UseCaseKey::Others, "non_entry".to_string());

    // Use a min-heap to track only the top N entries
    let mut min_heap: BinaryHeap<std::cmp::Reverse<UseCaseByCount>> = 
        BinaryHeap::with_capacity(self.num_top_to_track);
    
    for (use_case, count) in self.total.iter() {
        if *use_case == UseCaseKey::Platform || *use_case == UseCaseKey::Others {
            continue;
        }
        
        let entry = UseCaseByCount {
            use_case: use_case.clone(),
            count: *count,
        };
        
        if min_heap.len() < self.num_top_to_track {
            min_heap.push(std::cmp::Reverse(entry));
        } else if let Some(std::cmp::Reverse(min)) = min_heap.peek() {
            if entry.count > min.count {
                min_heap.pop();
                min_heap.push(std::cmp::Reverse(entry));
            }
        }
    }
    
    // Extract results
    let mut list_to_print = Vec::new();
    let mut sorted: Vec<_> = min_heap.into_iter()
        .map(|std::cmp::Reverse(entry)| entry)
        .collect();
    sorted.sort_by(|a, b| b.count.cmp(&a.count));
    
    for (i, UseCaseByCount { use_case, count }) in sorted.into_iter().enumerate() {
        let name = format!("entry_user_top_{}", i + 1);
        list_to_print.push((use_case.clone(), name.clone(), count));
        result.insert(use_case, name);
    }
    
    info!("Computed new use case tracking set: {:?}", list_to_print);
    result
}
```

**Option 2: Limit Total HashMap Size**
Add a maximum limit on unique use cases tracked and drop least-frequently-used entries when the limit is exceeded.

## Proof of Concept

```rust
#[test]
fn test_memory_amplification_attack() {
    use aptos_types::{account_address::AccountAddress, transaction::ReplayProtector};
    use aptos_mempool_notifications::CommittedTransaction;
    use aptos_types::transaction::use_case::UseCaseKey;
    
    // Create history with default config
    let mut history = UseCaseHistory::new(40, 5);
    
    // Simulate attacker submitting transactions to 100,000 unique contracts
    // across 40 blocks (2,500 unique contracts per block)
    for block in 0..40 {
        let mut transactions = Vec::new();
        
        for i in 0..2500 {
            let unique_contract = AccountAddress::from_hex_literal(
                &format!("0x{:064x}", block * 2500 + i)
            ).unwrap();
            
            transactions.push(CommittedTransaction {
                sender: AccountAddress::ONE,
                replay_protector: ReplayProtector::SequenceNumber(i),
                use_case: UseCaseKey::ContractAddress(unique_contract),
            });
        }
        
        history.update_usecases(&transactions);
    }
    
    // At this point, total HashMap has 100,000 entries
    assert!(history.total.len() >= 100_000);
    
    // Measure memory allocation in compute_tracking_set
    let start = std::time::Instant::now();
    let tracking_set = history.compute_tracking_set();
    let duration = start.elapsed();
    
    // Even though only 5 use cases are tracked, the function
    // allocated memory for all 100,000 entries in the BinaryHeap
    println!("Time to compute tracking set with {} unique use cases: {:?}", 
             history.total.len(), duration);
    
    // Only 5 actual results plus Platform and Others
    assert_eq!(tracking_set.len(), 7);
}
```

This test demonstrates that the function creates a BinaryHeap with 100,000 entries even though only 7 results are needed, causing unnecessary memory allocation proportional to attacker-controlled data.

## Notes
The vulnerability is exacerbated by the fact that `compute_tracking_set()` is called synchronously on the block commit path while holding the `use_case_history` mutex lock. This makes it part of the critical consensus path, where performance degradation directly impacts validator operations and network liveness. The attack is more severe on validators with limited memory resources.

### Citations

**File:** mempool/src/shared_mempool/use_case_history.rs (L29-56)
```rust
    fn add_to_recent(&mut self, count_by_usecase: HashMap<UseCaseKey, usize>) {
        for (use_case, count) in &count_by_usecase {
            assert!(*count > 0);
            *self.total.entry(use_case.clone()).or_insert(0) += *count;
        }
        self.recent.push_back(count_by_usecase);

        while self.recent.len() > self.window_size {
            let to_remove = self.recent.pop_front().expect("non-empty after size check");
            for (use_case, count) in to_remove {
                assert!(count > 0);

                use std::collections::hash_map::Entry;
                match self.total.entry(use_case) {
                    Entry::Occupied(mut o) => {
                        assert!(*o.get() >= count);
                        *o.get_mut() -= count;
                        if *o.get() == 0 {
                            o.remove_entry();
                        }
                    },
                    Entry::Vacant(e) => {
                        panic!("Entry present in recent cannot be missing in total {:?}", e)
                    },
                }
            }
        }
    }
```

**File:** mempool/src/shared_mempool/use_case_history.rs (L58-88)
```rust
    pub fn compute_tracking_set(&self) -> HashMap<UseCaseKey, String> {
        let mut result = HashMap::new();
        result.insert(UseCaseKey::Platform, "entry_platform".to_string());
        result.insert(UseCaseKey::Others, "non_entry".to_string());

        let mut max_heap: BinaryHeap<UseCaseByCount> = self
            .total
            .iter()
            .filter(|(use_case, _)| {
                *use_case != &UseCaseKey::Platform && *use_case != &UseCaseKey::Others
            })
            .map(|(use_case, count)| UseCaseByCount {
                use_case: use_case.clone(),
                count: *count,
            })
            .collect::<BinaryHeap<_>>();

        let mut list_to_print = Vec::new();

        for i in 0..self.num_top_to_track {
            if let Some(UseCaseByCount { use_case, count }) = max_heap.pop() {
                let name = format!("entry_user_top_{}", i + 1);

                list_to_print.push((use_case.clone(), name.clone(), count));
                result.insert(use_case, name);
            }
        }
        info!("Computed new use case tracking set: {:?}", list_to_print);

        result
    }
```

**File:** types/src/transaction/use_case.rs (L10-16)
```rust
#[derive(Clone, Eq, Hash, PartialEq)]
pub enum UseCaseKey {
    Platform,
    ContractAddress(AccountAddress),
    // ModuleBundle (deprecated anyway), scripts, Multisig.
    Others,
}
```

**File:** state-sync/inter-component/mempool-notifications/src/lib.rs (L83-93)
```rust
        let user_transactions: Vec<CommittedTransaction> = transactions
            .iter()
            .filter_map(|transaction| match transaction {
                Transaction::UserTransaction(signed_txn) => Some(CommittedTransaction {
                    sender: signed_txn.sender(),
                    replay_protector: signed_txn.replay_protector(),
                    use_case: signed_txn.parse_use_case(),
                }),
                _ => None,
            })
            .collect();
```

**File:** config/src/config/mempool_config.rs (L135-136)
```rust
            usecase_stats_num_blocks_to_track: 40,
            usecase_stats_num_top_to_track: 5,
```

**File:** mempool/src/shared_mempool/tasks.rs (L713-743)
```rust
pub(crate) fn process_committed_transactions(
    mempool: &Mutex<CoreMempool>,
    use_case_history: &Mutex<UseCaseHistory>,
    transactions: Vec<CommittedTransaction>,
    block_timestamp_usecs: u64,
) {
    let mut pool = mempool.lock();
    let block_timestamp = Duration::from_micros(block_timestamp_usecs);

    let tracking_usecases = {
        let mut history = use_case_history.lock();
        history.update_usecases(&transactions);
        history.compute_tracking_set()
    };

    for transaction in transactions {
        pool.log_commit_transaction(
            &transaction.sender,
            transaction.replay_protector,
            tracking_usecases
                .get(&transaction.use_case)
                .map(|name| (transaction.use_case.clone(), name)),
            block_timestamp,
        );
        pool.commit_transaction(&transaction.sender, transaction.replay_protector);
    }

    if block_timestamp_usecs > 0 {
        pool.gc_by_expiration_time(block_timestamp);
    }
}
```
