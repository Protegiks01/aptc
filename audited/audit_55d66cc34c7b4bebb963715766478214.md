# Audit Report

## Title
Race Condition in Commit Range Validation Allows Invariant Violation During Epoch Boundaries

## Summary
A critical race condition exists in the `get_and_check_commit_range` function where non-atomic reads of commit progress from database and in-memory state can be interleaved with `finalize_state_snapshot` operations during epoch boundaries. This violates the invariant that `old_committed_ver ≤ version_to_commit ≤ pre_committed_ver`, potentially causing consensus commit failures and chain stalls.

## Finding Description
The vulnerability exists in the interaction between three key functions: [1](#0-0) 

This function reads two values non-atomically:
1. `old_committed_ver` from database (`OverallCommitProgress`)
2. `pre_committed_ver` from in-memory state (`current_state`)

The critical issue is that `finalize_state_snapshot` modifies BOTH values without acquiring any locks: [2](#0-1) 

Specifically:
- It writes `OverallCommitProgress` to the database
- It calls `reset()` which reloads the in-memory state from the database [3](#0-2) 

Meanwhile, `commit_ledger` only holds the `commit_lock` but this doesn't protect against `finalize_state_snapshot`: [4](#0-3) 

The comment states "Consensus and state sync must hand over to each other after all pending execution and committing complete" but this is not enforced by locks. [5](#0-4) 

**Attack Scenario During Epoch Boundary:**

1. **Initial State:** Consensus has pre-committed blocks up to version 199 (epoch ending). Database shows `old_committed_ver = 99`, in-memory `pre_committed_ver = 199`.

2. **Thread A (Consensus):** Calls `commit_ledger(199)` to commit epoch-ending block:
   - Acquires `commit_lock`
   - Reads `old_committed_ver = 99` from database
   - **Pauses before reading `pre_committed_ver`**

3. **Thread B (State Sync):** Calls `finalize_state_snapshot(150)` to fast-forward to a checkpoint:
   - **NO lock acquired**
   - Writes database batch with `OverallCommitProgress = 150`
   - Calls `reset()` which reloads state to version 150
   - **In-memory state now shows version 150**

4. **Thread A continues:**
   - Reads `pre_committed_ver = 150`
   - Check fails: `199 ≤ 150` is FALSE
   - **Error: "Version too new to commit. Pre-committed: Some(150), Trying to commit with LI: 199"**

The invariant is violated because state sync "rewound" the pre-committed version while consensus was attempting to commit a higher version.

## Impact Explanation
This qualifies as **HIGH severity** under the Aptos bug bounty criteria:

1. **Validator Node Failures:** Consensus nodes attempting to commit epoch-ending blocks will crash with invariant violation errors, preventing them from transitioning to the next epoch.

2. **Protocol Violations:** The fundamental commit ordering invariant (`old_committed ≤ version_to_commit ≤ pre_committed`) is violated, breaking State Consistency guarantees.

3. **Chain Stalls at Epoch Boundaries:** If multiple validators encounter this race during epoch transitions, the network may fail to progress to the next epoch, requiring manual intervention or causing extended downtime.

4. **State Inconsistency:** Alternatively, if the race proceeds differently, the database committed version can exceed the in-memory pre-committed version, leaving the node in a permanently inconsistent state where no further commits can succeed.

This does not meet Critical severity as it doesn't directly cause fund loss or permanent network partition, but it significantly impacts network availability and requires intervention to resolve.

## Likelihood Explanation
**HIGH likelihood** during normal operation:

1. **Epoch boundaries are frequent:** Aptos has regular epoch transitions where this race window is exposed.

2. **State sync commonly runs during epochs:** Validators catching up or syncing checkpoints during epoch changes will trigger `finalize_state_snapshot`.

3. **No adversarial action required:** This is a natural race condition that occurs during legitimate protocol operation, not requiring attacker intervention.

4. **Large timing window:** The window between reading database and reading memory in `get_and_check_commit_range` is sufficient for state sync operations to complete.

5. **Fast-forward sync is standard:** State sync's fast-forward mode to epoch checkpoints is a common optimization that triggers this code path.

## Recommendation
Implement proper synchronization by having `finalize_state_snapshot` acquire both locks before modifying state:

```rust
fn finalize_state_snapshot(
    &self,
    version: Version,
    output_with_proof: TransactionOutputListWithProofV2,
    ledger_infos: &[LedgerInfoWithSignatures],
) -> Result<()> {
    gauged_api("finalize_state_snapshot", || {
        // Acquire both locks to prevent races with commit_ledger
        let _pre_commit_lock = self.pre_commit_lock.lock();
        let _commit_lock = self.commit_lock.lock();
        
        // ... rest of function unchanged ...
        
        self.state_store.reset();
        Ok(())
    })
}
```

Alternatively, make the two reads in `get_and_check_commit_range` atomic by:
1. Holding a single lock that protects both database reads and state store access
2. Reading both values within a transaction that includes the state store version

A third option is to implement a higher-level coordination mechanism between consensus and state sync that ensures proper handover at epoch boundaries, such as a state machine that blocks commits during state sync fast-forward operations.

## Proof of Concept

```rust
// Rust reproduction test (add to aptosdb_test.rs)
#[test]
fn test_commit_range_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let db = setup_test_db();
    
    // Pre-commit blocks up to version 199
    let chunk = create_test_chunk(100, 199);
    db.pre_commit_ledger(chunk, false).unwrap();
    
    // Barrier to synchronize threads at critical point
    let barrier = Arc::new(Barrier::new(2));
    let db1 = Arc::clone(&db);
    let db2 = Arc::clone(&db);
    let barrier1 = Arc::clone(&barrier);
    let barrier2 = Arc::clone(&barrier);
    
    // Thread 1: Attempt to commit version 199
    let handle1 = thread::spawn(move || {
        // Start commit_ledger
        barrier1.wait(); // Sync point
        
        // This should fail due to race
        let result = db1.commit_ledger(199, None, None);
        result
    });
    
    // Thread 2: Fast-forward via finalize_state_snapshot
    let handle2 = thread::spawn(move || {
        barrier2.wait(); // Sync point
        
        // Fast-forward to version 150
        let output = create_snapshot_output(150);
        let ledger_infos = vec![create_test_ledger_info(150)];
        db2.finalize_state_snapshot(150, output, &ledger_infos).unwrap();
    });
    
    let result1 = handle1.join().unwrap();
    handle2.join().unwrap();
    
    // Expected: Thread 1 fails with "Version too new to commit"
    assert!(result1.is_err());
    assert!(result1.unwrap_err().to_string().contains("Version too new to commit"));
}
```

## Notes
This vulnerability is particularly dangerous because:

1. It can manifest as different failure modes depending on exact timing, making it difficult to diagnose in production.

2. The comment explicitly acknowledges the need for handover coordination but the code doesn't enforce it with proper locking mechanisms.

3. During epoch boundaries, when this is most likely to occur, the impact is maximized as it prevents the network from progressing to the next epoch.

4. The fix is straightforward but requires careful consideration of lock ordering to avoid deadlocks, as `finalize_state_snapshot` would be acquiring multiple locks in a specific order.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-241)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
            // Ensure the output with proof only contains a single transaction output and info
            let num_transaction_outputs = output_with_proof.get_num_outputs();
            let num_transaction_infos = output_with_proof.proof.transaction_infos.len();
            ensure!(
                num_transaction_outputs == 1,
                "Number of transaction outputs should == 1, but got: {}",
                num_transaction_outputs
            );
            ensure!(
                num_transaction_infos == 1,
                "Number of transaction infos should == 1, but got: {}",
                num_transaction_infos
            );

            // TODO(joshlind): include confirm_or_save_frozen_subtrees in the change set
            // bundle below.

            // Update the merkle accumulator using the given proof
            let frozen_subtrees = output_with_proof
                .proof
                .ledger_info_to_transaction_infos_proof
                .left_siblings();
            restore_utils::confirm_or_save_frozen_subtrees(
                self.ledger_db.transaction_accumulator_db_raw(),
                version,
                frozen_subtrees,
                None,
            )?;

            // Create a single change set for all further write operations
            let mut ledger_db_batch = LedgerDbSchemaBatches::new();
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
            // Save the target transactions, outputs, infos and events
            let (transactions, outputs): (Vec<Transaction>, Vec<TransactionOutput>) =
                output_with_proof
                    .transactions_and_outputs
                    .into_iter()
                    .unzip();
            let events = outputs
                .clone()
                .into_iter()
                .map(|output| output.events().to_vec())
                .collect::<Vec<_>>();
            let wsets: Vec<WriteSet> = outputs
                .into_iter()
                .map(|output| output.write_set().clone())
                .collect();
            let transaction_infos = output_with_proof.proof.transaction_infos;
            // We should not save the key value since the value is already recovered for this version
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;

            // Save the epoch ending ledger infos
            restore_utils::save_ledger_infos(
                self.ledger_db.metadata_db(),
                ledger_infos,
                Some(&mut ledger_db_batch.ledger_metadata_db_batches),
            )?;

            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;

            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .epoch_snapshot_pruner
                .save_min_readable_version(version)?;
            self.state_store
                .state_kv_pruner
                .save_min_readable_version(version)?;

            restore_utils::update_latest_ledger_info(self.ledger_db.metadata_db(), ledger_infos)?;
            self.state_store.reset();

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L522-538)
```rust
    fn get_and_check_commit_range(&self, version_to_commit: Version) -> Result<Option<Version>> {
        let old_committed_ver = self.ledger_db.metadata_db().get_synced_version()?;
        let pre_committed_ver = self.state_store.current_state_locked().version();
        ensure!(
            old_committed_ver.is_none() || version_to_commit >= old_committed_ver.unwrap(),
            "Version too old to commit. Committed: {:?}; Trying to commit with LI: {}",
            old_committed_ver,
            version_to_commit,
        );
        ensure!(
            pre_committed_ver.is_some() && version_to_commit <= pre_committed_ver.unwrap(),
            "Version too new to commit. Pre-committed: {:?}, Trying to commit with LI: {}",
            pre_committed_ver,
            version_to_commit,
        );
        Ok(old_committed_ver)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L707-719)
```rust
    pub fn reset(&self) {
        self.buffered_state.lock().quit();
        *self.buffered_state.lock() = Self::create_buffered_state_from_latest_snapshot(
            &self.state_db,
            self.buffered_state_target_items,
            false,
            true,
            self.current_state.clone(),
            self.persisted_state.clone(),
            self.hot_state_config,
        )
        .expect("buffered state creation failed.");
    }
```
