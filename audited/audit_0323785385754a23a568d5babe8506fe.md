# Audit Report

## Title
Incomplete Metadata Listing Attack Enables Restore from Compromised Checkpoints

## Summary
The `BackupStorage::list_metadata_files()` method can return partial results due to error suppression in cloud storage commands, causing the restore process to delete valid metadata from cache and restore from older, potentially compromised checkpoints. This breaks backup integrity guarantees.

## Finding Description

The backup/restore system has a critical flaw in how it handles metadata file listings from cloud storage backends. The vulnerability exists in the interaction between three components:

1. **Command Execution with Error Suppression**: The sample configuration files for cloud storage (GCS, S3, Azure) use the `||:` shell pattern to suppress errors in the `list_metadata_files` command. [1](#0-0) 

2. **Metadata Synchronization Logic**: The `sync_and_load()` function retrieves the list of remote metadata files and compares it with the local cache. [2](#0-1)  Files present in the local cache but NOT in the remote listing are considered "stale" and are deleted. [3](#0-2) 

3. **MetadataView Construction**: After synchronization, a `MetadataView` is constructed from the remaining metadata, which is then used to select state snapshots and transaction backups for restore operations. [4](#0-3) 

**Attack Flow:**

When `list_metadata_files()` is called through the CommandAdapter backend, it spawns a shell command that lists files from cloud storage. [5](#0-4) 

If the cloud storage command (`gsutil ls`, `aws s3 ls`, etc.) is interrupted due to:
- Network timeouts or packet loss
- Resource exhaustion (OOM, CPU starvation)
- Cloud provider rate limiting or API errors
- SIGTERM/SIGKILL signals

The `||:` pattern causes the command to return exit code 0 with partial output, rather than failing. The partial output is then treated as the complete list of metadata files.

**Critical Consequence:**

Valid metadata files that exist in remote storage but weren't included in the partial listing are treated as "stale" and **deleted from the local cache**. When the `MetadataView` is constructed, it only contains the partial metadata, causing:

1. `select_state_snapshot()` to select an older snapshot than what's actually available [6](#0-5) 
2. `select_transaction_backups()` to either fail continuity checks or return an incomplete set [7](#0-6) 
3. The restore process to use older backups, potentially restoring to a compromised state [8](#0-7) 

## Impact Explanation

**Severity: High** (per Aptos bug bounty criteria)

This vulnerability enables multiple high-impact attacks:

1. **Forced Restore from Compromised Checkpoints**: An attacker who has compromised an older backup can force the restore process to use that compromised checkpoint by causing incomplete metadata listings. This could result in:
   - Restoration of manipulated state data
   - Loss of recent valid transactions
   - Potential consensus divergence if different nodes restore from different checkpoints

2. **Backup Integrity Violation**: The deletion of valid metadata files from cache violates the fundamental guarantee that all available backups can be accessed for restore operations.

3. **Data Availability Issues**: Critical backup metadata being deleted could prevent proper disaster recovery, as the system may not be able to restore to the most recent valid state.

The impact meets the **High Severity** criteria: "Significant protocol violations" and "Validator node slowdowns" (due to restore failures or incorrect state restoration).

## Likelihood Explanation

**Likelihood: Medium to High**

The vulnerability is likely to be exploited in the following scenarios:

1. **Network Adversaries**: Attackers with the ability to cause packet loss or connection interruptions during backup operations can trigger partial listings. This is feasible for adversaries on the same network or with BGP manipulation capabilities.

2. **Resource Exhaustion Attacks**: DoS attackers can exhaust system resources (memory, CPU) during the metadata listing operation, causing commands to be killed or timeout with partial results.

3. **Cloud Provider Issues**: Legitimate cloud provider issues (rate limiting, regional outages, API degradation) can naturally cause partial listings, especially for large metadata directories.

4. **Configuration Errors**: The sample configurations provided by Aptos use the vulnerable `||:` pattern, meaning many production deployments likely use this pattern without understanding the security implications.

The attack requires:
- No privileged access (can be executed by external network adversary)
- Timing of attack during backup/restore operations
- Ability to cause network or resource disruption

## Recommendation

**Immediate Fixes:**

1. **Remove Error Suppression**: Update sample configuration files to remove `||:` and allow commands to fail properly:

```yaml
list_metadata_files: |
    # list files under the metadata folder (without error suppression)
    gsutil -q ls gs://$BUCKET/$SUB_DIR/metadata/ | sed -ne "s#gs://.*/metadata/#metadata/#p"
```

2. **Add Validation Logic**: Implement metadata listing validation in `sync_and_load()`:

```rust
async fn sync_and_load(
    opt: &MetadataCacheOpt,
    storage: Arc<dyn BackupStorage>,
    concurrent_downloads: usize,
) -> Result<MetadataView> {
    // ... existing code ...
    
    let mut remote_file_handles = storage.list_metadata_files().await?;
    
    // Validate listing completeness by checking for expected metadata patterns
    if !remote_file_handles.is_empty() {
        // Check if listing appears truncated (heuristic: no recent files)
        let has_recent_metadata = remote_file_handles.iter()
            .any(|h| h.contains(&format!("_{}", duration_since_epoch().as_secs() / 86400)));
        
        if !has_recent_metadata {
            warn!("Metadata listing may be incomplete - no recent files found");
            // Retry or fail rather than proceeding with partial list
            return Err(anyhow!("Incomplete metadata listing detected"));
        }
    }
    
    // DO NOT delete files from cache if remote listing is suspicious
    // Instead, only add new files and update existing ones
    
    // ... rest of code ...
}
```

3. **Implement Pagination Handling**: For cloud storage backends, implement proper pagination handling to ensure complete listings:

```rust
async fn list_metadata_files(&self) -> Result<Vec<FileHandle>> {
    // Add pagination logic for large directories
    // Validate response completeness
    // Implement retries with exponential backoff
    // Add checksums or markers to detect truncation
}
```

4. **Add Monotonicity Checks**: Track the maximum metadata version seen and validate that subsequent listings don't show regression (missing newer metadata).

## Proof of Concept

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_incomplete_metadata_listing_attack() {
    use tempfile::TempDir;
    use std::sync::Arc;
    
    // Setup: Create backup storage with multiple metadata files
    let temp_dir = TempDir::new().unwrap();
    let storage = Arc::new(LocalFs::new(temp_dir.path().to_path_buf()));
    
    // Create multiple metadata files representing different backup versions
    for version in 0..10 {
        let metadata = Metadata::new_state_snapshot(version * 1000, /* ... */);
        storage.save_metadata_line(
            &ShellSafeName::try_from(format!("snapshot_{}.meta", version)).unwrap(),
            &metadata.to_text_line().unwrap()
        ).await.unwrap();
    }
    
    // Simulate first successful sync
    let cache_opt = MetadataCacheOpt::new(Some(temp_dir.path().join("cache")));
    let view1 = metadata::cache::sync_and_load(&cache_opt, storage.clone(), 4).await.unwrap();
    assert_eq!(view1.all_state_snapshots().len(), 10);
    
    // Simulate incomplete listing attack by using a modified CommandAdapter
    // that returns only the first 5 metadata files
    let malicious_storage = Arc::new(MaliciousCommandAdapter::new(storage, 5));
    
    // On second sync with partial listing, newer metadata gets deleted from cache
    let view2 = metadata::cache::sync_and_load(&cache_opt, malicious_storage, 4).await.unwrap();
    
    // VULNERABILITY: Only 5 snapshots remain, forcing restore from older checkpoint
    assert_eq!(view2.all_state_snapshots().len(), 5);
    assert!(view2.select_state_snapshot(9000).unwrap().unwrap().version < 5000);
}
```

**Notes:**

This vulnerability is particularly dangerous because:
1. It's subtle - operators may not notice partial listings until restore operations fail or produce unexpected results
2. The sample configurations provided by Aptos include the vulnerable pattern, making it likely that production deployments are affected
3. The impact compounds over time as more valid metadata gets deleted from cache
4. Recovery requires manual intervention to re-download deleted metadata files

The vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable" by allowing restore operations to proceed with incomplete metadata, potentially restoring to inconsistent or compromised states.

### Citations

**File:** storage/backup/backup-cli/src/storage/command_adapter/sample_configs/gcp.sample.yaml (L27-30)
```yaml
  list_metadata_files: |
    # list files under the metadata folder
    (gsutil -q ls gs://$BUCKET/$SUB_DIR/metadata/ ||:) \
    | sed -ne "s#gs://.*/metadata/#metadata/#p"
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L114-114)
```rust
    let mut remote_file_handles = storage.list_metadata_files().await?;
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L133-141)
```rust
    let stale_local_hashes = local_hashes.difference(&remote_hashes);
    let new_remote_hashes = remote_hashes.difference(&local_hashes).collect::<Vec<_>>();
    let up_to_date_local_hashes = local_hashes.intersection(&remote_hashes);

    for h in stale_local_hashes {
        let file = cache_dir.join(h);
        remove_file(&file).await.err_notes(&file)?;
        info!(file_name = h, "Deleted stale metadata file in cache.");
    }
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L213-213)
```rust
    Ok(MetadataView::new(metadata_vec, remote_file_handles))
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/mod.rs (L126-138)
```rust
    async fn list_metadata_files(&self) -> Result<Vec<FileHandle>> {
        let child = self
            .cmd(&self.config.commands.list_metadata_files, vec![])
            .spawn()?;

        let mut buf = FileHandle::new();
        child
            .into_data_source()
            .read_to_string(&mut buf)
            .await
            .err_notes((file!(), line!(), &buf))?;
        Ok(buf.lines().map(str::to_string).collect())
    }
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L111-122)
```rust
    pub fn select_state_snapshot(
        &self,
        target_version: Version,
    ) -> Result<Option<StateSnapshotBackupMeta>> {
        Ok(self
            .state_snapshot_backups
            .iter()
            .sorted()
            .rev()
            .find(|m| m.version <= target_version)
            .cloned())
    }
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L132-160)
```rust
    pub fn select_transaction_backups(
        &self,
        start_version: Version,
        target_version: Version,
    ) -> Result<Vec<TransactionBackupMeta>> {
        // This can be more flexible, but for now we assume and check backups are continuous in
        // range (which is always true when we backup from a single backup coordinator)
        let mut next_ver = 0;
        let mut res = Vec::new();
        for backup in self.transaction_backups.iter().sorted() {
            if backup.first_version > target_version {
                break;
            }
            ensure!(
                backup.first_version == next_ver,
                "Transaction backup ranges not continuous, expecting version {}, got {}.",
                next_ver,
                backup.first_version,
            );

            if backup.last_version >= start_version {
                res.push(backup.clone());
            }

            next_ver = backup.last_version + 1;
        }

        Ok(res)
    }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L163-213)
```rust
                    let snapshot = metadata_view.select_state_snapshot(ver)?;
                    ensure!(
                        snapshot.is_some() && snapshot.as_ref().unwrap().version == ver,
                        "cannot find in-progress state snapshot {}",
                        ver
                    );
                    snapshot
                }
            },
            Ok(None) | Err(_) => {
                assert_eq!(
                    db_next_version, 0,
                    "DB should be empty if no in-progress state snapshot found"
                );
                metadata_view
                    .select_state_snapshot(std::cmp::min(lhs, max_txn_ver))
                    .expect("Cannot find any snapshot before ledger history start version")
            },
        };

        let tree_snapshot = if let Some((latest_tree_version, _)) = latest_tree_version {
            let snapshot = metadata_view.select_state_snapshot(latest_tree_version)?;

            ensure!(
                snapshot.is_some() && snapshot.as_ref().unwrap().version == latest_tree_version,
                "cannot find tree snapshot {}",
                latest_tree_version
            );
            snapshot.unwrap()
        } else {
            metadata_view
                .select_state_snapshot(target_version)?
                .expect("Cannot find tree snapshot before target version")
        };

        let mut do_phase_1 = if let Some(kv_snapshot) = kv_snapshot.as_ref() {
            // if we have a kv snapshot, we need to restore the state between lhs and rs
            // if the version are equal, we don't need to restore phase 1. we can directly restore a snapshot with both tree and KV, and then replay txn till the target_version
            kv_snapshot.version < tree_snapshot.version
        } else {
            // if we don't have a kv snapshot, we need to restore the state between db_next_version and rs
            db_next_version < tree_snapshot.version
        };
        let txn_start_version = if let Some(kv_snapshot) = kv_snapshot.as_ref() {
            kv_snapshot.version
        } else {
            db_next_version
        };
        let transaction_backups =
            metadata_view.select_transaction_backups(txn_start_version, target_version)?;
        let epoch_ending_backups = metadata_view.select_epoch_ending_backups(target_version)?;
```
