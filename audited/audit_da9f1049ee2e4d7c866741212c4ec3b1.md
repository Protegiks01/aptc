# Audit Report

## Title
ReplayVerifyCoordinator Accepts Untrusted Storage Backend Without Cryptographic Verification of LedgerInfo Signatures

## Summary
The `ReplayVerifyCoordinator` struct accepts an arbitrary `Arc<dyn BackupStorage>` implementation with no authentication or trust validation. When restoring blockchain state from this storage, it never verifies the cryptographic signatures on `LedgerInfoWithSignatures`, allowing a malicious storage backend to inject completely fabricated blockchain data that will be accepted and restored into the node's database.

## Finding Description
The vulnerability exists in the backup restoration flow used by the replay-verify coordinator. The attack path is as follows:

1. **No Storage Backend Validation**: The `ReplayVerifyCoordinator` constructor accepts an `Arc<dyn BackupStorage>` parameter with zero validation of the storage backend's authenticity or trustworthiness. [1](#0-0) 

2. **Missing EpochHistory in Restore Operations**: The coordinator explicitly passes `epoch_history: None` when restoring both state snapshots and transactions. [2](#0-1) [3](#0-2) 

3. **Conditional Signature Verification Skipped**: In `StateSnapshotRestoreController`, LedgerInfo signatures are only verified if `epoch_history` is present. When it's `None`, signatures are completely ignored. [4](#0-3) 

4. **Transaction Restore Also Skips Verification**: Similarly, `TransactionRestoreBatchController` only verifies LedgerInfo signatures when `epoch_history` exists. [5](#0-4) 

5. **EpochHistory Would Verify Signatures**: The `EpochHistory::verify_ledger_info` method does verify signatures using previous epoch's validator sets or trusted waypoints, but this is never invoked because `epoch_history` is always `None`. [6](#0-5) 

**Attack Scenario:**
An attacker provides a malicious `CommandAdapter` configuration pointing to attacker-controlled storage, or directly injects a malicious `BackupStorage` implementation. The malicious storage returns:
- Fake metadata pointing to attacker-controlled manifests
- Fake manifests with fabricated `LedgerInfoWithSignatures` (containing invalid or no signatures)
- Fake transaction data and state data with internally consistent Merkle proofs that match the fake LedgerInfo's accumulator roots

Since signature verification is skipped, the system only checks that the Merkle proofs are mathematically consistent with the fake LedgerInfo's root hashes. The attacker can construct such proofs for arbitrary blockchain state, effectively allowing them to restore any state they desire into the node's database.

This breaks the **State Consistency** invariant (state transitions must be atomic and verifiable via Merkle proofs) and the **Deterministic Execution** invariant (all validators must produce identical state roots), as malicious data can be injected without consensus validation.

## Impact Explanation
**Severity: CRITICAL**

This vulnerability meets multiple Critical Severity criteria from the Aptos Bug Bounty program:

1. **Loss of Funds**: An attacker can restore fabricated state that includes minting tokens to their own addresses or transferring existing funds.

2. **Consensus/Safety Violations**: If different nodes restore from different malicious backups, they will have divergent state, causing consensus failures and potentially permanent chain splits.

3. **Non-recoverable Network Partition**: Nodes with corrupted state from malicious backups cannot automatically recover and may require manual intervention or a hard fork to restore network consensus.

4. **State Corruption**: Complete compromise of the node's database with arbitrary attacker-controlled state, including:
   - Manipulated validator sets
   - Bypassed governance controls  
   - Arbitrary token balances
   - Invalid transaction history

The impact affects the entire network if malicious backups are widely distributed, or individual nodes if targeted specifically.

## Likelihood Explanation
**Likelihood: MEDIUM to HIGH**

The attack requires:
1. The victim node operator to use the replay-verify tool with a malicious storage configuration
2. The attacker to control or compromise the backup storage location

This is realistic in several scenarios:
- **Supply chain attacks**: Compromised backup storage credentials or infrastructure
- **Social engineering**: Tricking operators to use attacker-provided backup locations for "disaster recovery"
- **Insider threats**: Malicious operators with access to backup configurations
- **Misconfigured infrastructure**: Using untrusted cloud storage or shared backup locations

The vulnerability is particularly dangerous because:
- No trusted waypoints are required to be configured (they default to empty)
- The tool is designed for operational use in recovery scenarios when trust is already compromised
- There are no warnings or safeguards against using untrusted storage backends

## Recommendation
Implement mandatory cryptographic verification of LedgerInfo signatures during replay-verify operations:

1. **Require Trusted Waypoints**: Make `TrustedWaypointOpt` mandatory with at least a genesis waypoint. Modify the constructor to validate this: [7](#0-6) 

2. **Build and Use EpochHistory**: Before restoring state or transactions, restore epoch ending backups to build a complete `EpochHistory`, then pass it to all restore controllers: [8](#0-7) 

3. **Add Storage Authentication**: Implement an authentication layer for `BackupStorage` implementations that verifies the storage backend's identity before accepting any data.

4. **Validate Signatures Explicitly**: Even without full epoch history, verify that LedgerInfo signatures match expected validator sets from trusted waypoints.

## Proof of Concept

```rust
// Malicious BackupStorage implementation that returns fake data
struct MaliciousBackupStorage {
    // Attacker-controlled state root and transaction accumulator
    fake_state_root: HashValue,
    fake_txn_accumulator_root: HashValue,
}

#[async_trait]
impl BackupStorage for MaliciousBackupStorage {
    async fn list_metadata_files(&self) -> Result<Vec<FileHandle>> {
        // Return fake metadata pointing to malicious manifests
        Ok(vec!["metadata/fake_snapshot.meta".to_string()])
    }
    
    async fn open_for_read(&self, file_handle: &FileHandleRef) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
        // Return fake manifest with LedgerInfoWithSignatures containing INVALID signatures
        // but correct root hashes matching attacker's fake state
        let fake_ledger_info = LedgerInfo::new(
            BlockInfo::new(
                0, // epoch
                0, // round  
                HashValue::zero(), // id
                self.fake_txn_accumulator_root, // executed_state_id (includes state_root)
                0, // version
                0, // timestamp
                None, // next_epoch_state
            ),
            HashValue::zero(), // consensus_data_hash
        );
        
        // Create LedgerInfoWithSignatures with NO valid signatures
        let fake_li_with_sigs = LedgerInfoWithSignatures::new(
            fake_ledger_info,
            BTreeMap::new(), // Empty signatures map - INVALID but not checked!
        );
        
        // Return this fake data - it will be accepted since signatures aren't verified
        let serialized = bcs::to_bytes(&fake_li_with_sigs)?;
        Ok(Box::new(Cursor::new(serialized)))
    }
    
    // Other methods return fake data consistent with attacker's chosen state...
}

// Usage:
let malicious_storage = Arc::new(MaliciousBackupStorage { 
    fake_state_root: /* attacker's desired state */,
    fake_txn_accumulator_root: /* attacker's desired txn history */,
});

// This will accept the fake data without verifying signatures:
let coordinator = ReplayVerifyCoordinator::new(
    malicious_storage,
    MetadataCacheOpt::default(),
    TrustedWaypointOpt::default(), // Empty waypoints - not enforced!
    1, // concurrent_downloads
    1, // replay_concurrency_level  
    restore_handler,
    0, // start_version
    100, // end_version
    false, // validate_modules
    VerifyExecutionMode::verify_all(),
)?;

coordinator.run().await?; // Malicious state restored successfully!
```

## Notes
The vulnerability is particularly severe because:
1. The backup/restore system is designed for disaster recovery scenarios where operational security may already be compromised
2. Operators may not realize the criticality of verifying backup storage authenticity
3. The code structure suggests signatures should be verified (via `epoch_history`), but this is systematically bypassed
4. No warnings are issued when running without trusted waypoints or epoch history validation

### Citations

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L58-82)
```rust
    pub fn new(
        storage: Arc<dyn BackupStorage>,
        metadata_cache_opt: MetadataCacheOpt,
        trusted_waypoints_opt: TrustedWaypointOpt,
        concurrent_downloads: usize,
        replay_concurrency_level: usize,
        restore_handler: RestoreHandler,
        start_version: Version,
        end_version: Version,
        validate_modules: bool,
        verify_execution_mode: VerifyExecutionMode,
    ) -> Result<Self> {
        Ok(Self {
            storage,
            metadata_cache_opt,
            trusted_waypoints_opt,
            concurrent_downloads,
            replay_concurrency_level,
            restore_handler,
            start_version,
            end_version,
            validate_modules,
            verify_execution_mode,
        })
    }
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L174-188)
```rust
            if let Some(backup) = state_snapshot {
                StateSnapshotRestoreController::new(
                    StateSnapshotRestoreOpt {
                        manifest_handle: backup.manifest,
                        version: backup.version,
                        validate_modules: self.validate_modules,
                        restore_mode: Default::default(),
                    },
                    global_opt.clone(),
                    Arc::clone(&self.storage),
                    None, /* epoch_history */
                )
                .run()
                .await?;
            }
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L191-205)
```rust
        TransactionRestoreBatchController::new(
            global_opt,
            self.storage,
            transactions
                .into_iter()
                .map(|t| t.manifest)
                .collect::<Vec<_>>(),
            save_start_version,
            Some((next_txn_version, false)), /* replay_from_version */
            None,                            /* epoch_history */
            self.verify_execution_mode.clone(),
            None,
        )
        .run()
        .await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L137-139)
```rust
        if let Some(epoch_history) = self.epoch_history.as_ref() {
            epoch_history.verify_ledger_info(&li)?;
        }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L152-154)
```rust
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L268-273)
```rust
/// Represents a history of epoch changes since epoch 0.
#[derive(Clone)]
pub struct EpochHistory {
    pub epoch_endings: Vec<LedgerInfo>,
    pub trusted_waypoints: Arc<HashMap<Version, Waypoint>>,
}
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L276-312)
```rust
    pub fn verify_ledger_info(&self, li_with_sigs: &LedgerInfoWithSignatures) -> Result<()> {
        let epoch = li_with_sigs.ledger_info().epoch();
        ensure!(!self.epoch_endings.is_empty(), "Empty epoch history.",);
        if epoch > self.epoch_endings.len() as u64 {
            // TODO(aldenhu): fix this from upper level
            warn!(
                epoch = epoch,
                epoch_history_until = self.epoch_endings.len(),
                "Epoch is too new and can't be verified. Previous chunks are verified and node \
                won't be able to start if this data is malicious."
            );
            return Ok(());
        }
        if epoch == 0 {
            ensure!(
                li_with_sigs.ledger_info() == &self.epoch_endings[0],
                "Genesis epoch LedgerInfo info doesn't match.",
            );
        } else if let Some(wp_trusted) = self
            .trusted_waypoints
            .get(&li_with_sigs.ledger_info().version())
        {
            let wp_li = Waypoint::new_any(li_with_sigs.ledger_info());
            ensure!(
                *wp_trusted == wp_li,
                "Waypoints don't match. In backup: {}, trusted: {}",
                wp_li,
                wp_trusted,
            );
        } else {
            self.epoch_endings[epoch as usize - 1]
                .next_epoch_state()
                .ok_or_else(|| anyhow!("Shouldn't contain non- epoch bumping LIs."))?
                .verify(li_with_sigs)?;
        };
        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L348-362)
```rust
impl TrustedWaypointOpt {
    pub fn verify(self) -> Result<HashMap<Version, Waypoint>> {
        let mut trusted_waypoints = HashMap::new();
        for w in self.trust_waypoint {
            trusted_waypoints
                .insert(w.version(), w)
                .map_or(Ok(()), |w| {
                    Err(AptosDbError::Other(format!(
                        "Duplicated waypoints at version {}",
                        w.version()
                    )))
                })?;
        }
        Ok(trusted_waypoints)
    }
```
