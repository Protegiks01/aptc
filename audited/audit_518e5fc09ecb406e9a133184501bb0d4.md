# Audit Report

## Title
Non-Deterministic HashSet Iteration in Block Partitioner Breaks Consensus Safety

## Summary
The block partitioner uses `HashSet` to store transaction write sets, leading to non-deterministic iteration order across different validator nodes. When the ConnectedComponentPartitioner iterates over these write sets to build union-find conflict groups, different validators produce different transaction orderings, causing consensus safety violations where validators disagree on the final state root for identical blocks.

## Finding Description

The vulnerability exists in the intersection of two files: [1](#0-0) 

The write sets are stored as `HashSet<StorageKeyIdx>`, which has non-deterministic iteration order in Rust. When initializing these sets, keys are inserted in a deterministic order: [2](#0-1) 

However, the critical bug occurs during the pre-partitioning phase where the ConnectedComponentPartitioner iterates over these HashSets: [3](#0-2) 

The code even contains a comment acknowledging non-determinism, claiming it will be "fixed" in subsequent steps: [4](#0-3) 

However, this claim is incorrect. The subsequent steps (lines 78-86) process transactions in order and preserve relative ordering within conflict sets, but they cannot fix the fundamental non-determinism introduced by HashSet iteration. When different validators iterate over the same HashSet, they encounter keys in different orders, leading to:

1. Different sequences of `uf.union(key_idx_in_uf, sender_idx)` calls
2. Different union-find tree structures (even though they represent the same logical sets)
3. Different `uf.find()` results when building `set_idx_registry`
4. Different transaction-to-shard assignments
5. Different global execution orders after partitioning

**Attack Path:**

1. A block contains transactions where at least one transaction writes to multiple storage keys (e.g., a DEX swap touching multiple coin stores)
2. The block is broadcast to all validators
3. Each validator independently runs the block partitioner
4. Validator A's HashSet iteration produces key order: `[K1, K2, K3]`
5. Validator B's HashSet iteration produces key order: `[K2, K1, K3]` (non-deterministic)
6. Different union operations lead to different conflict groupings
7. Validators execute transactions in different orders
8. For conflicting transactions, different orders produce different final states
9. Validators compute different state roots
10. Consensus fails - no quorum can be reached

This breaks the fundamental consensus invariant: [5](#0-4) 

The iteration through transactions is deterministic, but the union-find groupings have already been corrupted by the non-deterministic HashSet iteration, making the "fix" ineffective.

## Impact Explanation

**Critical Severity - Consensus Safety Violation**

This vulnerability directly breaks **Deterministic Execution**, the most critical invariant for blockchain consensus. According to the Aptos Bug Bounty program, "Consensus/Safety violations" are Critical severity (up to $1,000,000).

The impact is catastrophic:
- **All validators affected**: Every validator partitioning blocks is subject to this bug
- **Consensus failure**: Validators cannot reach agreement on state roots
- **Network halt**: The chain cannot progress when validators disagree
- **Requires hardfork**: No recovery path exists without patching all validator nodes

The existing tests pass because they run multiple partitioning attempts within the **same process**, where HashSet iteration order remains consistent. The bug only manifests across **different processes/validators**: [6](#0-5) 

This test verifies determinism within a single process but cannot detect cross-process non-determinism.

## Likelihood Explanation

**Likelihood: High**

This vulnerability triggers automatically under normal operation:

1. **No attacker required**: Happens naturally when blocks contain transactions writing to multiple keys
2. **Common transaction patterns**: DEX swaps, multi-token transfers, and complex DeFi operations all write to multiple storage locations
3. **No special conditions**: Any block with such transactions will exhibit the bug
4. **Already occurring**: If sharded execution is enabled in production, this bug is likely already causing intermittent consensus issues

The only reason this might not have been discovered yet:
- Sharded block execution may not be enabled in production
- The bug might manifest as rare, hard-to-debug consensus failures attributed to other causes

## Recommendation

**Immediate Fix:** Replace `HashSet` with `BTreeSet` for deterministic ordering, or sort keys before iteration.

**Option 1 - Use BTreeSet (Preferred):**

Change the type definition in `state.rs`:
```rust
pub(crate) write_sets: Vec<RwLock<BTreeSet<StorageKeyIdx>>>,
pub(crate) read_sets: Vec<RwLock<BTreeSet<StorageKeyIdx>>>,
```

**Option 2 - Sort Before Iteration:**

In `connected_component/mod.rs`, collect and sort keys before iteration:
```rust
let write_set = state.write_sets[txn_idx].read().unwrap();
let mut sorted_keys: Vec<_> = write_set.iter().copied().collect();
sorted_keys.sort_unstable();
for key_idx in sorted_keys {
    let key_idx_in_uf = num_senders + key_idx;
    uf.union(key_idx_in_uf, sender_idx);
}
```

**Long-term:** Audit all uses of `HashMap` and `HashSet` in consensus-critical code paths for similar determinism issues.

## Proof of Concept

```rust
// Test demonstrating non-deterministic partitioning across processes
// This would need to be implemented as a multi-process integration test

#[test]
fn test_cross_process_determinism() {
    use std::process::Command;
    
    // Create a block with a transaction writing to multiple keys
    let block = create_test_block_with_multi_write_txn();
    
    // Serialize the block
    let block_bytes = serialize_block(&block);
    
    // Spawn multiple separate processes to partition the same block
    let mut results = vec![];
    for _ in 0..10 {
        let output = Command::new("./partition_helper")
            .arg(&block_bytes)
            .output()
            .expect("Failed to spawn process");
        
        let partitioned = deserialize_result(&output.stdout);
        results.push(partitioned);
    }
    
    // Verify all results are identical
    for i in 1..results.len() {
        assert_eq!(
            results[0], results[i],
            "Partitioning produced different results across processes! \
             Process 0 and {} disagree",
            i
        );
    }
}

// Helper to create a transaction writing to 3+ keys
fn create_test_block_with_multi_write_txn() -> Vec<AnalyzedTransaction> {
    let sender = generate_test_account();
    
    // Create a transaction that writes to multiple coin stores
    // This simulates a DEX swap or complex DeFi operation
    let txn = create_multi_write_transaction(
        &sender,
        vec![
            StateKey::for_coin_store(ADDR1, AptosCoin::type_tag()),
            StateKey::for_coin_store(ADDR2, USDC::type_tag()),
            StateKey::for_coin_store(ADDR3, DAI::type_tag()),
        ]
    );
    
    vec![txn]
}
```

**Notes:**
- This vulnerability requires a multi-process test to demonstrate, as HashSet iteration is consistent within a single process
- The existing `assert_deterministic_result` test in `test_utils.rs` only tests within a single process and thus misses this bug
- A proper reproduction would require running the partitioner in separate OS processes or using `std::hash::RandomState` with different random seeds to simulate cross-process behavior

### Citations

**File:** execution/block-partitioner/src/v2/state.rs (L68-68)
```rust
    pub(crate) write_sets: Vec<RwLock<HashSet<StorageKeyIdx>>>,
```

**File:** execution/block-partitioner/src/v2/init.rs (L34-38)
```rust
                            if is_write {
                                state.write_sets[ori_txn_idx]
                                    .write()
                                    .unwrap()
                                    .insert(key_idx);
```

**File:** execution/block-partitioner/src/pre_partition/connected_component/mod.rs (L49-56)
```rust
        for txn_idx in 0..state.num_txns() {
            let sender_idx = state.sender_idx(txn_idx);
            let write_set = state.write_sets[txn_idx].read().unwrap();
            for &key_idx in write_set.iter() {
                let key_idx_in_uf = num_senders + key_idx;
                uf.union(key_idx_in_uf, sender_idx);
            }
        }
```

**File:** execution/block-partitioner/src/pre_partition/connected_component/mod.rs (L57-57)
```rust
        // NOTE: union-find result is NOT deterministic. But the following step can fix it.
```

**File:** execution/block-partitioner/src/pre_partition/connected_component/mod.rs (L78-86)
```rust
        for ori_txn_idx in 0..state.num_txns() {
            let sender_idx = state.sender_idx(ori_txn_idx);
            let uf_set_idx = uf.find(sender_idx);
            let set_idx = set_idx_registry.entry(uf_set_idx).or_insert_with(|| {
                txns_by_set.push(VecDeque::new());
                set_idx_counter.fetch_add(1, Ordering::SeqCst)
            });
            txns_by_set[*set_idx].push_back(ori_txn_idx);
        }
```

**File:** execution/block-partitioner/src/test_utils.rs (L321-332)
```rust
pub fn assert_deterministic_result(partitioner: Arc<dyn BlockPartitioner>) {
    let mut rng = thread_rng();
    let block_gen = P2PBlockGenerator::new(1000);
    for _ in 0..10 {
        let txns = block_gen.rand_block(&mut rng, 100);
        let result_0 = partitioner.partition(txns.clone(), 10);
        for _ in 0..2 {
            let result_1 = partitioner.partition(txns.clone(), 10);
            assert_eq!(result_1, result_0);
        }
    }
}
```
