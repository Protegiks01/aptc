# Audit Report

## Title
State Sync Peer Selection Allows Resource Exhaustion via False Storage Summary Advertisement (Medium Severity)

## Summary
The Aptos state sync system accepts peer-advertised storage summaries without validation, allowing malicious peers to falsely advertise data availability. While cryptographic proof verification prevents state corruption, malicious peers can cause subscription stream failures and resource exhaustion, particularly impacting single-peer subscription requests that lack multi-fetch redundancy.

## Finding Description

The vulnerability exists in the peer selection mechanism for state synchronization requests. When peers advertise their storage capabilities via `StorageServerSummary`, no validation occurs to verify these claims are truthful. [1](#0-0) 

The peer selection logic relies entirely on these unvalidated advertisements: [2](#0-1) 

The `can_service` method only checks if advertised ranges match the request, without verifying authenticity: [3](#0-2) 

**Attack Path:**

1. Malicious peer advertises false `StorageServerSummary` claiming extensive data coverage
2. Peer gets selected via `choose_peers_for_request()` based on false advertisements
3. For **subscription streams** (which select only ONE peer), the malicious peer is chosen: [4](#0-3) 

4. Malicious peer sends invalid proofs or corrupted data
5. Proof verification fails, triggering `ProofVerificationError`: [5](#0-4) 

6. Each failure increments `request_failure_count`
7. After 5 consecutive failures, the stream terminates: [6](#0-5) 

**Key Limitation:** While multi-fetch is enabled by default for regular requests (selecting 2-3 peers), subscription streams are inherently single-peer: [7](#0-6) 

## Impact Explanation

This constitutes **Medium Severity** under Aptos bug bounty criteria for the following reasons:

**Positive Security Controls (preventing Critical impact):**
- Cryptographic proof verification prevents state corruption
- Multi-fetch redundancy for regular requests minimizes impact
- Peer scoring system (0.8 multiplier for malicious behavior) eventually excludes bad actors

**Actual Impact:**
- **Subscription Stream Disruption**: Forces stream restarts every 5 failures, degrading validator synchronization performance
- **Resource Exhaustion**: Wastes bandwidth, CPU cycles for proof verification of invalid data
- **Selective Targeting**: Attackers can use Sybil identities to persistently disrupt specific validators

This does NOT reach Critical severity because:
- No consensus safety violation (proofs prevent state corruption)
- No permanent liveness loss (honest peers can eventually serve data)
- No fund theft or network partition

However, it exceeds Low severity due to measurable validator performance degradation and potential for sustained disruption through Sybil attacks.

## Likelihood Explanation

**High Likelihood** for the following reasons:

1. **No barrier to entry**: Any network peer can advertise false summaries
2. **Immediate selection**: False advertisements lead to immediate peer selection
3. **Sybil attack feasibility**: Attacker can create multiple identities to rotate through as each gets penalized
4. **Subscription vulnerability**: Single-peer subscription streams lack redundancy protection
5. **Default configuration susceptibility**: While multi-fetch helps, subscription mode remains vulnerable

The scoring system (MALICIOUS_MULTIPLIER = 0.8) requires multiple bad responses to drop below IGNORE_PEER_THRESHOLD (25.0), giving attackers a window to cause disruption: [8](#0-7) 

## Recommendation

**Immediate Mitigations:**

1. **Add storage summary validation** against local blockchain state:
```rust
// In DataSummaryPoller::poll_peer
if let Some(synced_ledger_info) = storage_summary.data_summary.synced_ledger_info {
    // Verify the advertised version doesn't exceed known network maximum
    if synced_ledger_info.ledger_info().version() > max_known_version + REASONABLE_LAG {
        warn!("Peer advertised implausibly high version, ignoring");
        return; // Don't update peer storage summary
    }
}
```

2. **Implement multi-peer fallback for subscriptions**:
    - Maintain backup subscription peers
    - Automatically rotate to backup on first failure rather than waiting for 5 failures

3. **Enhance peer reputation system**:
```rust
const MALICIOUS_MULTIPLIER: f64 = 0.5; // More aggressive penalty
const IGNORE_PEER_THRESHOLD: f64 = 40.0; // Higher threshold before ignoring
```

4. **Add cross-peer consistency checks**:
    - Compare storage summaries across multiple peers
    - Flag outliers as suspicious
    - Require consensus among majority of peers for critical version numbers

## Proof of Concept

```rust
// Test demonstrating subscription stream failure due to malicious peer
#[tokio::test]
async fn test_malicious_peer_subscription_stream_failure() {
    // Setup: Create data client with malicious peer
    let (mut mock_network, data_client, poller) = MockNetwork::new();
    let malicious_peer = mock_network.add_peer(Priority::High);
    
    // Malicious peer advertises false storage summary
    let false_summary = StorageServerSummary {
        data_summary: DataSummary {
            synced_ledger_info: Some(create_ledger_info(1000000)), // False high version
            transactions: Some(CompleteDataRange::new(0, 1000000).unwrap()),
            ..Default::default()
        },
        ..Default::default()
    };
    mock_network.send_storage_summary(malicious_peer, false_summary);
    
    // Create subscription stream - will select malicious peer
    let streaming_client = create_streaming_client(data_client);
    let stream = streaming_client
        .continuously_stream_transactions(0, 0, false, None)
        .await
        .unwrap();
    
    // Malicious peer sends invalid proofs repeatedly
    for _ in 0..5 {
        let request = mock_network.next_request().await;
        mock_network.send_response(
            request.peer,
            request.id,
            create_invalid_proof_response(), // Fails verification
        );
    }
    
    // Verify stream terminated after max_request_retry failures
    assert!(stream.is_terminated());
    
    // Verify peer was penalized but stream failed before full ban
    let peer_score = data_client.get_peer_states()
        .get_peer_to_states()
        .get(&malicious_peer)
        .unwrap()
        .get_score();
    assert!(peer_score < STARTING_SCORE); // Penalized
    assert!(peer_score > IGNORE_PEER_THRESHOLD); // But not yet ignored
}
```

## Notes

**Defense-in-Depth Analysis:**

While cryptographic proof verification ultimately prevents state corruption (maintaining the critical State Consistency invariant), the lack of storage summary validation creates a resource exhaustion vector. The system's reliance on a posteriori verification (check proofs after selection) rather than a priori validation (verify advertisements before selection) allows malicious actors to force wasteful computation. [9](#0-8) 

The multi-fetch mechanism provides significant protection for regular requests: [10](#0-9) 

However, subscription streams remain vulnerable due to architectural constraints requiring single-peer selection for maintaining stream continuity.

### Citations

**File:** state-sync/aptos-data-client/src/poller.rs (L406-439)
```rust
        let data_request = DataRequest::GetStorageServerSummary;
        let use_compression = data_summary_poller.data_client_config.use_compression;
        let storage_request = StorageServiceRequest::new(data_request, use_compression);

        // Fetch the storage summary for the peer and stop the timer
        let request_timeout = data_summary_poller.data_client_config.response_timeout_ms;
        let result: crate::error::Result<StorageServerSummary> = data_summary_poller
            .data_client
            .send_request_to_peer_and_decode(peer, storage_request, request_timeout)
            .await
            .map(Response::into_payload);

        // Mark the in-flight poll as now complete
        data_summary_poller.in_flight_request_complete(&peer);

        // Check the storage summary response
        let storage_summary = match result {
            Ok(storage_summary) => storage_summary,
            Err(error) => {
                warn!(
                    (LogSchema::new(LogEntry::StorageSummaryResponse)
                        .event(LogEvent::PeerPollingError)
                        .message("Error encountered when polling peer!")
                        .error(&error)
                        .peer(&peer))
                );
                return;
            },
        };

        // Update the summary for the peer
        data_summary_poller
            .data_client
            .update_peer_storage_summary(peer, storage_summary);
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L200-227)
```rust
    pub fn can_service_request(
        &self,
        peer: &PeerNetworkId,
        time_service: TimeService,
        request: &StorageServiceRequest,
    ) -> bool {
        // Storage services can always respond to data advertisement requests.
        // We need this outer check, since we need to be able to send data summary
        // requests to new peers (who don't have a peer state yet).
        if request.data_request.is_storage_summary_request()
            || request.data_request.is_protocol_version_request()
        {
            return true;
        }

        // Check if the peer can service the request
        if let Some(peer_state) = self.peer_to_state.get(peer) {
            return match peer_state.get_storage_summary_if_not_ignored() {
                Some(storage_summary) => {
                    storage_summary.can_service(&self.data_client_config, time_service, request)
                },
                None => false, // The peer is temporarily ignored
            };
        }

        // Otherwise, the request cannot be serviced
        false
    }
```

**File:** state-sync/storage-service/types/src/responses.rs (L621-631)
```rust
    pub fn can_service(
        &self,
        aptos_data_client_config: &AptosDataClientConfig,
        time_service: TimeService,
        request: &StorageServiceRequest,
    ) -> bool {
        self.protocol_metadata.can_service(request)
            && self
                .data_summary
                .can_service(aptos_data_client_config, time_service, request)
    }
```

**File:** state-sync/aptos-data-client/src/client.rs (L284-287)
```rust
        if request.data_request.is_subscription_request() {
            return self
                .choose_peer_for_subscription_request(request, serviceable_peers_by_priorities);
        }
```

**File:** state-sync/aptos-data-client/src/client.rs (L421-434)
```rust
    /// Chooses a single peer to service the given subscription request.
    /// Peers are selected first by priority, and then by validator
    /// distance and latency (within priority groups).
    fn choose_peer_for_subscription_request(
        &self,
        request: &StorageServiceRequest,
        serviceable_peers_by_priorities: Vec<HashSet<PeerNetworkId>>,
    ) -> crate::error::Result<HashSet<PeerNetworkId>, Error> {
        // Prioritize peer selection by choosing the highest priority peer first
        for serviceable_peers in serviceable_peers_by_priorities {
            if let Some(selected_peer) =
                self.choose_serviceable_peer_for_subscription_request(request, serviceable_peers)?
            {
                return Ok(hashset![selected_peer]); // A peer was found!
```

**File:** state-sync/aptos-data-client/src/client.rs (L675-687)
```rust
        // Wait for the first successful response and abort all other tasks.
        // If all requests fail, gather the errors and return them.
        let num_sent_requests = sent_requests.len();
        let mut sent_request_errors = vec![];
        for _ in 0..num_sent_requests {
            if let Ok(response_result) = sent_requests.select_next_some().await {
                match response_result {
                    Ok(response) => {
                        // We received a valid response. Abort all pending tasks.
                        for abort_handle in abort_handles {
                            abort_handle.abort();
                        }
                        return Ok(response); // Return the response
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L234-263)
```rust
    pub fn handle_notification_feedback(
        &self,
        notification_id: &NotificationId,
        notification_feedback: &NotificationFeedback,
    ) -> Result<(), Error> {
        if self.stream_end_notification_id == Some(*notification_id) {
            return if matches!(notification_feedback, NotificationFeedback::EndOfStream) {
                Ok(())
            } else {
                Err(Error::UnexpectedErrorEncountered(format!(
                    "Invalid feedback given for stream end: {:?}",
                    notification_feedback
                )))
            };
        }

        let response_context = self
            .notifications_to_responses
            .get(notification_id)
            .ok_or_else(|| {
                Error::UnexpectedErrorEncountered(format!(
                    "Response context missing for notification ID: {:?}",
                    notification_id
                ))
            })?;
        let response_error = extract_response_error(notification_feedback)?;
        self.notify_bad_response(response_context, response_error);

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L442-454)
```rust
    pub async fn process_data_responses(
        &mut self,
        global_data_summary: GlobalDataSummary,
    ) -> Result<(), Error> {
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L747-764)
```rust
    fn notify_bad_response(
        &self,
        response_context: &ResponseContext,
        response_error: ResponseError,
    ) {
        let response_id = response_context.id;
        info!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .message(&format!(
                "Notifying the data client of a bad response. Response id: {:?}, error: {:?}",
                response_id, response_error
            )));

        response_context
            .response_callback
            .notify_bad_response(response_error);
    }
```
