# Audit Report

## Title
PeerId Rotation Bypass Allows Infinite Invalid Request Attacks on Storage Service

## Summary
Malicious peers can bypass the `TooManyInvalidRequests` protection mechanism in the state-sync storage service by disconnecting and reconnecting with a new PeerId derived from a freshly generated x25519 keypair. This allows attackers to reset their invalid request counter indefinitely and continue resource exhaustion attacks against validator and fullnode storage services.

## Finding Description

The storage service implements request validation and rate limiting through the `RequestModerator` component, which tracks invalid requests per peer using a `DashMap<PeerNetworkId, UnhealthyPeerState>` structure. [1](#0-0) 

Each `UnhealthyPeerState` maintains an `invalid_request_count` that increments when peers send requests that cannot be satisfied. [2](#0-1) 

When the counter reaches `max_invalid_requests_per_peer`, the peer is marked as ignored (for public network peers only), and subsequent requests return `TooManyInvalidRequests` errors. [3](#0-2) 

The critical vulnerability lies in how peer identity is established and tracked:

1. **PeerId Derivation**: `PeerId` is derived from an x25519 public key by taking the last 16 bytes. [4](#0-3) 

2. **Weak Authentication on Public Networks**: During the Noise handshake on public networks (`MaybeMutual` mode), the server only validates that the claimed PeerId correctly derives from the provided x25519 public key. [5](#0-4) 

3. **No Persistent Identity Binding**: There is no mechanism to bind a network identity (IP address, connection metadata) to a PeerId across reconnections. An attacker can generate unlimited x25519 keypairs, each producing a unique valid PeerId.

4. **Garbage Collection**: Disconnected peers are removed from the `unhealthy_peer_states` map during periodic refresh. [6](#0-5) 

**Attack Flow:**
1. Attacker connects to storage service with `PeerId_1` (derived from `keypair_1`)
2. Sends `max_invalid_requests_per_peer` invalid storage requests (e.g., requesting non-existent data ranges)
3. Gets marked with `TooManyInvalidRequests` and is temporarily ignored
4. Disconnects (either wait for garbage collection or immediately)
5. Generates new `keypair_2`, derives `PeerId_2`
6. Reconnects with `PeerId_2` - passes authentication since `PeerId_2 == from_identity_public_key(keypair_2.public_key)`
7. Now has fresh `invalid_request_count = 0`, can send another `max_invalid_requests_per_peer` invalid requests
8. Repeats indefinitely

The exponential backoff mechanism (doubling `min_time_to_ignore_secs`) only applies to the same PeerId. [7](#0-6) 

## Impact Explanation

**Severity: HIGH** (per Aptos Bug Bounty Program)

This vulnerability enables persistent DoS attacks against storage service nodes:

1. **Validator Node Slowdowns**: Each invalid request triggers validation logic, storage queries, and error handling. An attacker can consume significant CPU and I/O resources by sending invalid requests continuously with rotating PeerIds. This directly maps to "Validator node slowdowns" in the HIGH severity category.

2. **Resource Exhaustion**: The storage service must:
   - Validate each request against the cached storage summary
   - Process network messages
   - Track peer state in `unhealthy_peer_states`
   - Log warnings for ignored peers

3. **Connection Slot Exhaustion**: The `max_inbound_connections` limit (100 unknown peers) only applies per active connection. [8](#0-7)  An attacker can rotate through 100 concurrent malicious PeerIds, disconnect them, and immediately connect 100 new PeerIds, effectively monopolizing all inbound connection slots.

4. **State Sync Disruption**: Legitimate peers attempting to sync state may experience degraded service or timeouts as the storage service is overwhelmed processing malicious requests.

5. **Network-Wide Impact**: If multiple validators/fullnodes are targeted simultaneously, this could significantly degrade network health and state sync availability.

## Likelihood Explanation

**Likelihood: HIGH**

This attack is highly likely to be exploited because:

1. **Trivial Execution**: Generating x25519 keypairs is computationally cheap (microseconds per keypair). Standard Rust crypto libraries make this a single function call.

2. **No Prerequisites**: The attacker needs no special privileges, stake, or prior network reputation. Any peer can connect to public network endpoints.

3. **Low Cost**: The attack requires minimal bandwidth and computation from the attacker - just sending malformed storage requests.

4. **No Detection**: The rotating PeerId strategy makes it difficult to distinguish from legitimate peers experiencing network issues or making accidental invalid requests.

5. **Scalable**: An attacker can easily automate this with a simple script to rotate PeerIds when rate-limited.

6. **Current Default Configuration**: The default `max_invalid_requests_per_peer` is relatively low, meaning attackers reach the threshold quickly and can start rotating.

## Recommendation

Implement multi-layered defense:

### 1. IP-Based Rate Limiting (Primary Defense)
Add IP address tracking to `RequestModerator` to track invalid requests across all PeerIds from the same source:

```rust
// In moderator.rs
pub struct RequestModerator {
    // ... existing fields ...
    
    // Track invalid requests by IP address
    ip_invalid_request_tracking: Arc<DashMap<IpAddr, IpInvalidRequestState>>,
}

pub struct IpInvalidRequestState {
    invalid_request_count: u64,
    first_invalid_time: Instant,
    blocked_until: Option<Instant>,
}
```

Modify validation to check both PeerId and IP address:
- Extract IP from `ConnectionMetadata` 
- Track cumulative invalid requests per IP across all PeerIds
- Implement longer-duration blocks for IPs (hours, not seconds)
- Use exponential backoff per IP, not just per PeerId

### 2. Connection Rate Limiting
Implement per-IP connection rate limiting at the `PeerManager` level:

```rust
// Limit new connections from the same IP address
const MAX_CONNECTIONS_PER_IP_PER_MINUTE: u32 = 10;
```

Track connection attempts per IP and reject rapid reconnections.

### 3. Cryptographic Proof-of-Work (Optional)
For public networks, require new connections to solve a small proof-of-work challenge before being allowed to send storage requests. This increases the cost of generating new identities.

### 4. Persistent Peer Reputation
Maintain a persistent reputation database (on disk, not just in-memory) that tracks:
- Historical invalid request rates per IP range
- Known malicious IP addresses
- Gradual reputation recovery over time

### 5. Configuration Hardening
Increase default `max_invalid_requests_per_peer` to reduce rotation frequency, and increase `min_time_to_ignore_peers_secs` to make attacks slower.

**Critical Fix**: The primary mitigation MUST include IP-based tracking since PeerId-only tracking is fundamentally bypassable on permissionless networks.

## Proof of Concept

```rust
// PoC demonstrating PeerId rotation bypass
// This would be added to state-sync/storage-service/server/src/tests/

#[tokio::test]
async fn test_peer_id_rotation_bypass() {
    // Setup mock storage service with default config
    let storage_service_config = StorageServiceConfig::default();
    let max_invalid_requests = storage_service_config.max_invalid_requests_per_peer;
    
    // Create mock time and storage
    let mock_time = TimeService::mock();
    let storage = MockDbReader::new();
    
    // Initialize storage service
    let (mut mock_client, mut service, _peers_and_metadata) = 
        MockClient::new(Some(storage_service_config), None);
    tokio::spawn(service.start());
    
    // Attack Iteration 1: Use PeerId_1
    let peer_id_1 = PeerId::random();
    let peer_network_id_1 = PeerNetworkId::new(NetworkId::Public, peer_id_1);
    
    // Send max_invalid_requests invalid requests with PeerId_1
    for i in 0..max_invalid_requests {
        let response = send_invalid_transaction_request(
            100, // highest_synced_version
            &mut mock_client,
            peer_network_id_1,
        ).await;
        
        if i < max_invalid_requests - 1 {
            // First N-1 requests should return InvalidRequest
            assert!(matches!(response, Err(StorageServiceError::InvalidRequest(_))));
        } else {
            // Last request should trigger TooManyInvalidRequests
            assert!(matches!(response, Err(StorageServiceError::TooManyInvalidRequests(_))));
        }
    }
    
    // Verify PeerId_1 is now blocked
    let response = send_invalid_transaction_request(
        100,
        &mut mock_client,
        peer_network_id_1,
    ).await;
    assert!(matches!(response, Err(StorageServiceError::TooManyInvalidRequests(_))));
    
    // Attack Iteration 2: Rotate to PeerId_2
    // In real attack, this would be a new x25519 keypair → new PeerId
    let peer_id_2 = PeerId::random();
    let peer_network_id_2 = PeerNetworkId::new(NetworkId::Public, peer_id_2);
    
    // Connect peer_id_2 - simulates new connection with fresh keypair
    mock_client.set_peer_network_id(peer_network_id_2);
    
    // Verify: Can now send another max_invalid_requests with PeerId_2
    for i in 0..max_invalid_requests {
        let response = send_invalid_transaction_request(
            100,
            &mut mock_client,
            peer_network_id_2,
        ).await;
        
        if i < max_invalid_requests - 1 {
            // Should succeed again - counter is reset for new PeerId!
            assert!(matches!(response, Err(StorageServiceError::InvalidRequest(_))));
        }
    }
    
    // Attack can continue indefinitely with PeerId_3, PeerId_4, etc.
    println!("✓ Successfully bypassed TooManyInvalidRequests protection via PeerId rotation");
    println!("✓ Attacker can repeat indefinitely with new x25519 keypairs");
}
```

**Real-World Exploitation:**
```bash
# Simplified attack script concept
while true; do
    # Generate new x25519 keypair
    NEW_KEYPAIR=$(generate_x25519_keypair)
    NEW_PEER_ID=$(derive_peer_id $NEW_KEYPAIR)
    
    # Connect to target storage service
    connect_to_storage_service --peer-id $NEW_PEER_ID --keypair $NEW_KEYPAIR
    
    # Send invalid requests until blocked
    for i in {1..10}; do
        send_invalid_storage_request --request "invalid_data_range"
    done
    
    # Disconnect and repeat
    disconnect
done
```

## Notes

1. **HAProxy Mitigation Insufficient**: While HAProxy configurations show IP-based rate limiting, this is optional infrastructure not enforced by the protocol itself. Nodes without HAProxy (or with misconfigured HAProxy) remain vulnerable.

2. **Validator Network Not Affected**: The `Mutual` authentication mode used on validator networks requires peers to be in the trusted peer set, preventing this attack. Only public networks (`MaybeMutual`/`ServerOnly` mode) are vulnerable.

3. **Related Attack Vector**: The same PeerId rotation technique could potentially bypass other peer-based rate limiting mechanisms throughout the codebase if they similarly track by PeerId without IP correlation.

4. **Network Layer vs Application Layer**: The vulnerability exists because application-layer tracking (storage service) relies on network-layer identity (PeerId) that has no persistence guarantees on permissionless networks.

5. **Current Garbage Collection**: The `refresh_unhealthy_peer_states()` method removes disconnected peers, which actually makes the attack easier - attackers don't even need to wait for timeouts. [9](#0-8)

### Citations

**File:** state-sync/storage-service/server/src/moderator.rs (L23-29)
```rust
#[derive(Clone, Debug)]
pub struct UnhealthyPeerState {
    ignore_start_time: Option<Instant>, // The time when we first started ignoring the peer
    invalid_request_count: u64,         // The total number of invalid requests from the peer
    max_invalid_requests: u64, // The max number of invalid requests before ignoring the peer
    min_time_to_ignore_secs: u64, // The min time (secs) to ignore the peer (doubles each round)
    time_service: TimeService, // The time service
```

**File:** state-sync/storage-service/server/src/moderator.rs (L50-68)
```rust
    pub fn increment_invalid_request_count(&mut self, peer_network_id: &PeerNetworkId) {
        // Increment the invalid request count
        self.invalid_request_count += 1;

        // If the peer is a PFN and has sent too many invalid requests, start ignoring it
        if self.ignore_start_time.is_none()
            && peer_network_id.network_id().is_public_network()
            && self.invalid_request_count >= self.max_invalid_requests
        {
            // TODO: at some point we'll want to terminate the connection entirely

            // Start ignoring the peer
            self.ignore_start_time = Some(self.time_service.now());

            // Log the fact that we're now ignoring the peer
            warn!(LogSchema::new(LogEntry::RequestModeratorIgnoredPeer)
                .peer_network_id(peer_network_id)
                .message("Ignoring peer due to too many invalid requests!"));
        }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L76-98)
```rust
    /// Refreshes the peer's state (if it has been ignored for long enough).
    /// Note: each time we unblock a peer, we double the min time to ignore the peer.
    /// This provides an exponential backoff for peers that are sending too many invalid requests.
    pub fn refresh_peer_state(&mut self, peer_network_id: &PeerNetworkId) {
        if let Some(ignore_start_time) = self.ignore_start_time {
            let ignored_duration = self.time_service.now().duration_since(ignore_start_time);
            if ignored_duration >= Duration::from_secs(self.min_time_to_ignore_secs) {
                // Reset the invalid request count
                self.invalid_request_count = 0;

                // Reset the ignore start time
                self.ignore_start_time = None;

                // Double the min time to ignore the peer
                self.min_time_to_ignore_secs *= 2;

                // Log the fact that we're no longer ignoring the peer
                warn!(LogSchema::new(LogEntry::RequestModeratorIgnoredPeer)
                    .peer_network_id(peer_network_id)
                    .message("No longer ignoring peer! Enough time has elapsed."));
            }
        }
    }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L111-111)
```rust
    unhealthy_peer_states: Arc<DashMap<PeerNetworkId, UnhealthyPeerState>>,
```

**File:** state-sync/storage-service/server/src/moderator.rs (L199-238)
```rust
    pub fn refresh_unhealthy_peer_states(&self) -> Result<(), Error> {
        // Get the currently connected peers
        let connected_peers_and_metadata = self
            .peers_and_metadata
            .get_connected_peers_and_metadata()
            .map_err(|error| {
                Error::UnexpectedErrorEncountered(format!(
                    "Unable to get connected peers and metadata: {}",
                    error
                ))
            })?;

        // Remove disconnected peers and refresh ignored peer states
        let mut num_ignored_peers = 0;
        self.unhealthy_peer_states
            .retain(|peer_network_id, unhealthy_peer_state| {
                if connected_peers_and_metadata.contains_key(peer_network_id) {
                    // Refresh the ignored peer state
                    unhealthy_peer_state.refresh_peer_state(peer_network_id);

                    // If the peer is ignored, increment the ignored peer count
                    if unhealthy_peer_state.is_ignored() {
                        num_ignored_peers += 1;
                    }

                    true // The peer is still connected, so we should keep it
                } else {
                    false // The peer is no longer connected, so we should remove it
                }
            });

        // Update the number of ignored peers
        metrics::set_gauge(
            &metrics::IGNORED_PEER_COUNT,
            NetworkId::Public.as_str(),
            num_ignored_peers,
        );

        Ok(())
    }
```

**File:** types/src/account_address.rs (L140-146)
```rust
pub fn from_identity_public_key(identity_public_key: x25519::PublicKey) -> AccountAddress {
    let mut array = [0u8; AccountAddress::LENGTH];
    let pubkey_slice = identity_public_key.as_slice();
    // keep only the last 16 bytes
    array.copy_from_slice(&pubkey_slice[x25519::PUBLIC_KEY_SIZE - AccountAddress::LENGTH..]);
    AccountAddress::new(array)
}
```

**File:** network/framework/src/noise/handshake.rs (L391-405)
```rust
                    None => {
                        // The peer is not in the trusted peer set. Verify that the Peer ID is
                        // constructed correctly from the public key.
                        let derived_remote_peer_id =
                            aptos_types::account_address::from_identity_public_key(
                                remote_public_key,
                            );
                        if derived_remote_peer_id != remote_peer_id {
                            // The peer ID is not constructed correctly from the public key
                            Err(NoiseHandshakeError::ClientPeerIdMismatch(
                                remote_peer_short,
                                remote_peer_id,
                                derived_remote_peer_id,
                            ))
                        } else {
```

**File:** network/framework/src/peer_manager/mod.rs (L351-390)
```rust
        // Verify that we have not reached the max connection limit for unknown inbound peers
        if conn.metadata.origin == ConnectionOrigin::Inbound {
            // Everything below here is meant for unknown peers only. The role comes from
            // the Noise handshake and if it's not `Unknown` then it is trusted.
            if conn.metadata.role == PeerRole::Unknown {
                // TODO: Keep track of somewhere else to not take this hit in case of DDoS
                // Count unknown inbound connections
                let unknown_inbound_conns = self
                    .active_peers
                    .iter()
                    .filter(|(peer_id, (metadata, _))| {
                        metadata.origin == ConnectionOrigin::Inbound
                            && trusted_peers
                                .get(peer_id)
                                .is_none_or(|peer| peer.role == PeerRole::Unknown)
                    })
                    .count();

                // Reject excessive inbound connections made by unknown peers
                // We control outbound connections with Connectivity manager before we even send them
                // and we must allow connections that already exist to pass through tie breaking.
                if !self
                    .active_peers
                    .contains_key(&conn.metadata.remote_peer_id)
                    && unknown_inbound_conns + 1 > self.inbound_connection_limit
                {
                    info!(
                        NetworkSchema::new(&self.network_context)
                            .connection_metadata_with_address(&conn.metadata),
                        "{} Connection rejected due to connection limit: {}",
                        self.network_context,
                        conn.metadata
                    );
                    counters::connections_rejected(&self.network_context, conn.metadata.origin)
                        .inc();
                    self.disconnect(conn);
                    return;
                }
            }
        }
```
