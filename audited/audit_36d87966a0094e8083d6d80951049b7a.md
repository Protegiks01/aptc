# Audit Report

## Title
Unrecoverable Node Liveness Failure Due to Non-Atomic Transaction Accumulator Truncation

## Summary
A crash or database corruption during transaction accumulator truncation can leave the node in an unrecoverable state where the assertion at line 320 fails on every restart attempt, causing permanent liveness failure requiring manual database repair.

## Finding Description

The vulnerability exists in the transaction accumulator truncation logic across three files: [1](#0-0) [2](#0-1) [3](#0-2) [4](#0-3) 

The vulnerability stems from three architectural flaws:

**1. Non-Atomic Multi-Database Writes:** The `LedgerDb::write_schemas()` function writes to 8 separate RocksDB instances sequentially. Each individual write is atomic, but the overall operation is not. A crash after writing to some databases but before completing all writes creates inconsistent state.

**2. Progress Updated Before Data:** In `truncate_ledger_db_single_batch()`, the `LedgerCommitProgress` is committed to the metadata database BEFORE the actual data deletions are committed. If the node crashes after the progress update but during the multi-database write sequence, the progress indicates truncation succeeded while the accumulator database remains untruncated or partially corrupted.

**3. Strict Assertion Without Recovery:** The assertion `assert_eq!(num_nodes_to_delete, 0)` at line 320 enforces strict consistency but provides no recovery path. When this assertion fails, the function returns an error which propagates to `sync_commit_progress()`, where it triggers a panic via `.expect()`.

**Attack Scenario:**

1. Node is at version 2000, truncation to version 1000 begins
2. `truncate_ledger_db_single_batch()` is called with `start_version = 1001`
3. Progress markers are prepared and various deletion batches are built
4. Line 358: `LedgerCommitProgress` is updated to 1000 and **COMMITTED**
5. Line 360: `write_schemas(batch)` begins sequential writes to 8 databases
6. Databases write in order: write_set_db → transaction_info_db → transaction_db → persisted_auxiliary_info_db → event_db → **CRASH** before transaction_accumulator_db
7. Node state after crash:
   - `LedgerCommitProgress = 1000` (committed)
   - Most databases truncated to version 1000
   - Transaction accumulator DB still contains nodes for versions 1001-2000, possibly with corruption
8. Node restart triggers `sync_commit_progress()`:
   - Reads progress markers: both at version 1000
   - Calls `truncate_ledger_db(1000)` to ensure consistency
   - `truncate_transaction_accumulator()` executes with corrupted/incomplete accumulator state
   - Expected node count calculation is based on version 1000, but accumulator may have nodes beyond this or missing nodes due to corruption
   - Iteration finds mismatched node count
   - **Assertion fails: `assert_eq!(num_nodes_to_delete, 0)`**
9. Error propagates to `sync_commit_progress()` line 449 which calls `.expect()` → **NODE PANICS**
10. Every subsequent restart repeats steps 8-9 → **PERMANENT LIVENESS FAILURE**

This breaks the State Consistency invariant: "State transitions must be atomic and verifiable via Merkle proofs." The non-atomic truncation across multiple databases creates unrecoverable inconsistency.

## Impact Explanation

**Critical Severity** - This vulnerability meets the "Total loss of liveness/network availability" criterion from the Aptos bug bounty program:

- **Single Node Impact:** Affected validator node cannot restart and becomes permanently unavailable
- **Network Impact:** If multiple validators encounter this during coordinated truncation operations (e.g., after network upgrades or synchronization), it could cause widespread validator unavailability
- **Recovery Requirement:** Requires manual database inspection and repair or restoration from backup - no automatic recovery mechanism exists
- **Consensus Impact:** Loss of validator nodes reduces network redundancy and could approach the 1/3 Byzantine threshold if enough validators are affected
- **Availability Violation:** Directly violates the liveness guarantee that nodes should recover from crashes during normal operations

The vulnerability is particularly severe because:
1. Truncation operations occur during normal node operations (startup synchronization, debugging, recovery)
2. The trigger condition (crash during multi-DB write) is a realistic failure scenario
3. No automatic detection or recovery mechanism exists
4. Silent corruption could accumulate until a restart attempt reveals the issue

## Likelihood Explanation

**High Likelihood** due to multiple triggering scenarios:

1. **Power Failures:** Validator nodes experiencing power outages during truncation operations - common in datacenter operations
2. **Hardware Failures:** Disk failures or corruption during writes
3. **Software Crashes:** Process crashes, OOM kills, or kernel panics during truncation
4. **Operational Procedures:** Manual truncation via debugger tools could be interrupted
5. **State Synchronization:** Nodes catching up after network issues may perform truncation operations

The vulnerability window exists during every truncation operation, which occurs:
- During node startup recovery (`sync_commit_progress`)
- During manual database maintenance (truncate debugger command)
- Potentially during state synchronization operations

The probability of hitting this exact window (after progress update, during multi-DB write) is non-trivial given the sequential nature of 8 database writes and the realistic occurrence of crashes.

## Recommendation

Implement atomic cross-database truncation with proper error recovery:

**1. Make Progress Update Atomic with Data Writes:**
Update `truncate_ledger_db_single_batch()` to commit progress AFTER all data writes succeed, or use a two-phase commit protocol.

**2. Add Graceful Assertion Handling:**
Replace `assert_eq!(num_nodes_to_delete, 0)` with explicit error handling:
- Log detailed diagnostics about the mismatch
- Attempt to repair by re-calculating expected state
- If unrepairable, mark database as corrupted and provide clear recovery instructions
- Do not panic - return a recoverable error

**3. Implement Transactional Semantics:**
Use write-ahead logging or transaction markers to track truncation progress across all databases, allowing rollback on failure.

**4. Add Consistency Verification:**
Before attempting truncation, verify accumulator consistency:
- Check that accumulator node count matches expected count for current version
- Validate no gaps exist in accumulator structure
- If inconsistencies detected, trigger repair before truncation

**5. Replace `.expect()` with Graceful Error Handling:**
In `sync_commit_progress()`, handle truncation failures gracefully instead of panicking:
- Log detailed error information
- Attempt automatic repair if possible
- Provide actionable recovery steps for operators
- Allow node to continue in read-only mode if truncation is non-critical

## Proof of Concept

```rust
// Reproduction steps (pseudo-code):

// 1. Start AptosDB node at version 2000
let db = AptosDB::new_for_test(&tmp_dir);
// Commit 2000 transactions...

// 2. Initiate truncation to version 1000
let target_version = 1000;
let mut batch = SchemaBatch::new();
batch.put::<DbMetadataSchema>(
    &DbMetadataKey::OverallCommitProgress,
    &DbMetadataValue::Version(target_version),
)?;
ledger_db.metadata_db().write_schemas(batch)?;

// 3. Call sync_commit_progress which internally calls truncate_ledger_db_single_batch
// 4. Simulate crash after LedgerCommitProgress update but before full write_schemas completion:
//    - Hook into write_schemas at line 541 (transaction_accumulator_db write)
//    - Force crash/corruption: delete random accumulator nodes
//    - OR: kill process after event_db write but before transaction_accumulator_db write

// 5. Restart node - observe that sync_commit_progress is called
// 6. Watch truncate_transaction_accumulator fail assertion at line 320
// 7. Observe node panic via .expect() at state_store/mod.rs:449
// 8. Repeat restart - observe permanent panic loop

// Expected: Node panics with "Failed to truncate ledger db"
// Actual vulnerability: No recovery path exists, node cannot start
```

**Notes**

This vulnerability represents a critical gap in the fault-tolerance design of the Aptos storage layer. While individual RocksDB writes are atomic, the lack of transactional semantics across multiple database instances creates unrecoverable failure states. The issue is exacerbated by the use of panics (`.expect()`) instead of graceful error handling, and by updating progress markers before ensuring all operations complete successfully. Production blockchain systems must handle crashes during operations gracefully - this vulnerability violates that fundamental requirement and could cause cascading validator failures during adverse conditions.

### Citations

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L299-323)
```rust
fn truncate_transaction_accumulator(
    transaction_accumulator_db: &DB,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    let mut iter = transaction_accumulator_db.iter::<TransactionAccumulatorSchema>()?;
    iter.seek_to_last();
    let (position, _) = iter.next().transpose()?.unwrap();
    let num_frozen_nodes = position.to_postorder_index() + 1;
    let num_frozen_nodes_after = num_frozen_nodes_in_accumulator(start_version);
    let mut num_nodes_to_delete = num_frozen_nodes - num_frozen_nodes_after;

    let start_position = Position::from_postorder_index(num_frozen_nodes_after)?;
    iter.seek(&start_position)?;

    for item in iter {
        let (position, _) = item?;
        batch.delete::<TransactionAccumulatorSchema>(&position)?;
        num_nodes_to_delete -= 1;
    }

    assert_eq!(num_nodes_to_delete, 0);

    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L325-361)
```rust
fn truncate_ledger_db_single_batch(
    ledger_db: &LedgerDb,
    transaction_store: &TransactionStore,
    start_version: Version,
) -> Result<()> {
    let mut batch = LedgerDbSchemaBatches::new();

    delete_transaction_index_data(
        ledger_db,
        transaction_store,
        start_version,
        &mut batch.transaction_db_batches,
    )?;
    delete_per_epoch_data(
        &ledger_db.metadata_db_arc(),
        start_version,
        &mut batch.ledger_metadata_db_batches,
    )?;
    delete_per_version_data(ledger_db, start_version, &mut batch)?;

    delete_event_data(ledger_db, start_version, &mut batch.event_db_batches)?;

    truncate_transaction_accumulator(
        ledger_db.transaction_accumulator_db_raw(),
        start_version,
        &mut batch.transaction_accumulator_db_batches,
    )?;

    let mut progress_batch = SchemaBatch::new();
    progress_batch.put::<DbMetadataSchema>(
        &DbMetadataKey::LedgerCommitProgress,
        &DbMetadataValue::Version(start_version - 1),
    )?;
    ledger_db.metadata_db().write_schemas(progress_batch)?;

    ledger_db.write_schemas(batch)
}
```

**File:** storage/aptosdb/src/ledger_db/mod.rs (L531-548)
```rust
    pub fn write_schemas(&self, schemas: LedgerDbSchemaBatches) -> Result<()> {
        self.write_set_db
            .write_schemas(schemas.write_set_db_batches)?;
        self.transaction_info_db
            .write_schemas(schemas.transaction_info_db_batches)?;
        self.transaction_db
            .write_schemas(schemas.transaction_db_batches)?;
        self.persisted_auxiliary_info_db
            .write_schemas(schemas.persisted_auxiliary_info_db_batches)?;
        self.event_db.write_schemas(schemas.event_db_batches)?;
        self.transaction_accumulator_db
            .write_schemas(schemas.transaction_accumulator_db_batches)?;
        self.transaction_auxiliary_data_db
            .write_schemas(schemas.transaction_auxiliary_data_db_batches)?;
        // TODO: remove this after sharding migration
        self.ledger_metadata_db
            .write_schemas(schemas.ledger_metadata_db_batches)
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L410-449)
```rust
    pub fn sync_commit_progress(
        ledger_db: Arc<LedgerDb>,
        state_kv_db: Arc<StateKvDb>,
        state_merkle_db: Arc<StateMerkleDb>,
        crash_if_difference_is_too_large: bool,
    ) {
        let ledger_metadata_db = ledger_db.metadata_db();
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);

            // LedgerCommitProgress was not guaranteed to commit after all ledger changes finish,
            // have to attempt truncating every column family.
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```
