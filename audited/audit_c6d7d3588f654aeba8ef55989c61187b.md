# Audit Report

## Title
Incomplete Backup Verification Coverage Due to Partial Range Job Generation

## Summary
The `gen_replay_verify_jobs.rs` job generation logic creates "partial" verification jobs when the version range between consecutive state snapshots exceeds `max_versions_per_range`. These partial jobs only verify the first `max_versions_per_range` transactions in the range, leaving the remaining transactions completely unverified. An attacker with access to backup storage can corrupt or delete data in these unverified ranges, and the verification process will still report success, providing false confidence in backup integrity.

## Finding Description

The vulnerability exists in the job generation logic that creates replay-verify tasks for backup validation. When analyzing backup metadata, the system identifies version ranges between consecutive state snapshots and generates verification jobs for these ranges. [1](#0-0) 

The critical flaw occurs when a version range exceeds `max_versions_per_range`. In this case, the code creates a "partial" job that only covers the first `max_versions_per_range` transactions starting from `begin.version`. The remaining transactions (explicitly noted as "omitted" in the job description) are never added to any verification job.

The generated jobs are written to a JSON file and consumed by the GitHub workflow: [2](#0-1) 

Each job extracts the `begin` and `end` version ranges and passes them directly to `replay-verify`, which only verifies those specific versions: [3](#0-2) 

**Attack Scenario:**

1. State snapshot S1 exists at version 1,000,000
2. State snapshot S2 exists at version 5,000,000 (4M version gap)
3. Operator sets `MAX_VERSIONS_PER_RANGE=1000000` (1M)
4. Job generation creates: `partial job [1000000, 1999999]`
5. Versions 2,000,000 to 4,999,999 are NEVER verified
6. Attacker corrupts/deletes backup data for versions 3,000,000-3,500,000
7. Verification completes successfully with all jobs passing
8. During disaster recovery, corrupted data causes consensus failure or incorrect state restoration

The only indication is a warning message when the epoch gap is large, but this doesn't fail the verification: [4](#0-3) 

## Impact Explanation

**Critical Severity** - This vulnerability breaks the fundamental backup integrity invariant and can lead to consensus violations:

1. **Backup Integrity Violation**: The verification system provides false assurance that backups are complete and uncorrupted when significant portions are never checked.

2. **Consensus Risk**: During disaster recovery scenarios, if corrupted backup data in unverified ranges is restored, it could cause:
   - State root mismatches between validators
   - Transaction replay failures leading to chain halts
   - Incorrect state transitions violating consensus safety

3. **Exploitability**: An attacker with backup storage access (S3/GCS credentials, compromised backup system, or insider) can:
   - Identify unverified ranges from job logs
   - Corrupt or delete specific transaction/state data
   - Cause undetectable backup corruption

4. **Scale**: In production deployments with infrequent state snapshots (common during load tests or high transaction periods), millions of transactions can remain unverified.

This meets **Critical severity** criteria as it can lead to consensus/safety violations during disaster recovery, which is when backup integrity is most critical.

## Likelihood Explanation

**High Likelihood:**

1. **Common Configuration**: Large gaps between state snapshots occur naturally during:
   - Load testing periods with millions of transactions
   - Production operations between scheduled snapshots
   - Any scenario where snapshot frequency < transaction throughput

2. **Default Behavior**: The code explicitly includes a comment "hopefully automatically skips load tests", indicating this is expected and intentional behavior, not an edge case.

3. **No Validation**: There is no check to ensure complete coverage of the blockchain history. The system accepts partial verification as success.

4. **Attacker Requirements**: Only requires backup storage access, not validator privileges or network position. Many organizations have multiple personnel with backup access.

5. **Detection Difficulty**: The warning message ("Need more snapshots") is easily overlooked in logs, and the verification still reports overall success.

## Recommendation

**Immediate Fix:** Fail verification if any version range cannot be fully covered:

```rust
if end.version - begin.version >= self.max_versions_per_range {
    let msg = if end.epoch - begin.epoch > 15 {
        "!!! Need more snapshots !!!"
    } else {
        ""
    };
    
    // Return error instead of creating partial job
    return Err(anyhow::anyhow!(
        "Version range [{}, {}] ({} txns) exceeds max_versions_per_range ({}). \
         More frequent state snapshots are required for complete verification. {}",
        begin.version,
        end.version,
        end.version - begin.version,
        self.max_versions_per_range,
        msg
    ));
}
```

**Alternative Solution:** Generate multiple jobs to cover the entire range:

```rust
if end.version - begin.version >= self.max_versions_per_range {
    // Split into multiple jobs that cover the entire range
    let mut current_version = begin.version;
    let mut jobs = Vec::new();
    
    while current_version < end.version {
        let job_end = std::cmp::min(
            current_version + self.max_versions_per_range - 1,
            end.version - 1
        );
        
        jobs.push((
            false, // not partial - full coverage
            current_version,
            job_end,
            format!("Replay epoch {} - {}, versions {} to {}",
                begin.epoch, end.epoch - 1, current_version, job_end)
        ));
        
        current_version = job_end + 1;
    }
    
    return Ok(jobs);
}
```

**Long-term Solution:** Implement verification coverage validation that ensures all versions between the minimum and maximum verified versions have been checked, failing if any gaps exist.

## Proof of Concept

To demonstrate this vulnerability:

**Step 1: Create test scenario with large gap**
```bash
# Set up backup storage with snapshots at versions 0 and 10,000,000
# with max_versions_per_range = 1,000,000

./aptos-debugger aptos-db gen-replay-verify-jobs \
  --metadata-cache-dir ./metadata_cache \
  --command-adapter-config backup_config.yaml \
  --start-version 0 \
  --max-versions-per-range 1000000 \
  --max-ranges-per-job 16 \
  --output-json-file jobs.json
```

**Step 2: Examine generated jobs.json**
```bash
cat jobs.json
# Output shows: ["0-0-partial 0 999999 Partial replay... another 9000000 versions omitted..."]
# Versions 1,000,000 to 9,999,999 are NOT in any job
```

**Step 3: Corrupt unverified range**
```bash
# Delete or corrupt backup files for versions 5,000,000 to 6,000,000
# in the backup storage (S3/GCS)
```

**Step 4: Run verification**
```bash
# Verification will complete successfully because it only checks versions 0-999,999
# The corrupted versions 5,000,000-6,000,000 are never accessed
```

**Expected behavior:** Verification should fail or require operator acknowledgment that coverage is incomplete.

**Actual behavior:** Verification passes with success status despite millions of unverified versions.

---

## Notes

This vulnerability is particularly concerning because:

1. The warning message ("Need more snapshots") is only shown when epoch difference > 15, not for all partial ranges
2. The workflow design treats partial jobs as normal, not exceptional
3. There's no post-verification coverage report showing which versions were actually checked
4. The comment "hopefully automatically skips load tests" suggests this behavior is considered a feature rather than a security risk

The fix should be deployed urgently to all environments using backup verification, and existing verification results should be audited to identify any gaps in coverage.

### Citations

**File:** storage/db-tool/src/gen_replay_verify_jobs.rs (L96-117)
```rust
                        if end.version - begin.version >= self.max_versions_per_range {
                            // cut big range short, this hopefully automatically skips load tests
                            let msg = if end.epoch - begin.epoch > 15 {
                                "!!! Need more snapshots !!!"
                            } else {
                                ""
                            };
                            Some((
                                true,
                                begin.version,
                                begin.version + self.max_versions_per_range - 1,
                                format!(
                                    "Partial replay epoch {} - {}, {} txns starting from version {}, another {} versions omitted, until {}. {}",
                                    begin.epoch,
                                    end.epoch - 1,
                                    self.max_versions_per_range,
                                    begin.version,
                                    end.version - begin.version - self.max_versions_per_range,
                                    end.version,
                                    msg
                                )
                            ))
```

**File:** .github/workflows/workflow-run-replay-verify.yaml (L217-252)
```yaml
      - name: Run replay-verify in parallel
        env:
          BUCKET: ${{ inputs.BUCKET }}
          SUB_DIR: ${{ inputs.SUB_DIR }}
        shell: bash
        run: |
          set -o nounset -o errexit -o pipefail
          replay() {
              idx=$1
              id=$2
              begin=$3
              end=$4
              desc=$5

              echo ---------
              echo Job start. $id: $desc
              echo ---------

              MC=metadata_cache_$idx
              cp -r metadata_cache $MC
              DB=db_$idx

              for try in {0..6}
              do
                if [ $try -gt 0 ]; then
                  SLEEP=$((10 * $try))
                  echo "sleeping for $SLEEP seconds before retry #$try" >&2
                  sleep $SLEEP
                fi

                res=0
                ./aptos-debugger aptos-db replay-verify \
                  --metadata-cache-dir $MC \
                  --command-adapter-config ${{ inputs.BACKUP_CONFIG_TEMPLATE_PATH }} \
                  --start-version $begin \
                  --end-version $end \
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L159-164)
```rust
        let transactions = metadata_view.select_transaction_backups(
            // transaction info at the snapshot must be restored otherwise the db will be confused
            // about the latest version after snapshot is restored.
            next_txn_version.saturating_sub(1),
            self.end_version,
        )?;
```
