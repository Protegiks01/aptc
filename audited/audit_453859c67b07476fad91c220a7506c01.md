# Audit Report

## Title
Computational DoS via Repeated Invalid Signature Verification in Randomness Generation Reliable Broadcast

## Summary
Byzantine validators can force honest validators to perform expensive BLS signature verification operations repeatedly by sending invalid `AugDataSignature` responses during the randomness generation protocol. The `AugDataCertBuilder::add()` function verifies signatures before checking for duplicates, and the reliable broadcast's retry mechanism with infinite exponential backoff allows Byzantine validators to trigger multiple costly verification operations before quorum is reached from honest validators.

## Finding Description
The randomness generation protocol uses reliable broadcast to disseminate augmented data and collect signatures. When an honest validator broadcasts its `AugData`, other validators respond with `AugDataSignature` messages. The vulnerability exists in how these signatures are processed: [1](#0-0) 

The signature verification occurs at line 49 BEFORE acquiring the lock on `partial_signatures` and BEFORE checking if a signature from this peer already exists. The `PartialSignatures` data structure has a `contains_voter()` method but it's never called before verification: [2](#0-1) 

The reliable broadcast retry mechanism enables the attack. When signature verification fails, the reliable broadcast schedules a retry: [3](#0-2) 

The backoff policy is an infinite iterator using `tokio_retry::strategy::ExponentialBackoff`: [4](#0-3) 

With default configuration values: [5](#0-4) 

**Attack Flow:**
1. Honest validator A broadcasts its `AugData` using reliable broadcast
2. Byzantine validator B receives the RPC request
3. B responds with an invalid `AugDataSignature` (wrong signature over the data)
4. A calls `AugDataCertBuilder::add(B, invalid_sig)` which performs BLS signature verification
5. Verification fails, `add()` returns error
6. Reliable broadcast schedules retry with exponential backoff (2ms, 100ms, 3000ms, ...)
7. RPC sent again to B
8. B responds with another invalid signature
9. Steps 4-8 repeat until A receives enough valid signatures from honest validators to form quorum

Each retry forces a full BLS signature verification operation, which is computationally expensive. With F Byzantine validators out of 3F+1 total, and requiring 2F+1 signatures for quorum, the attack causes:
- F Byzantine validators × multiple retries per validator × BLS verification cost = significant computational overhead

Notably, other consensus components like vote aggregation properly check for duplicates BEFORE verification: [6](#0-5) 

## Impact Explanation
This vulnerability meets **Medium Severity** criteria per the Aptos bug bounty program:
- Causes validator node slowdowns during randomness generation (fits High severity category "Validator node slowdowns")
- Does not break consensus safety or liveness permanently
- Protocol eventually succeeds once quorum is reached from honest validators
- Wasted computational resources affect node performance and increase block latency

The impact is amplified when:
- Multiple Byzantine validators coordinate the attack simultaneously
- Network latency is high, allowing more retries before honest validators respond
- The attack is sustained across multiple rounds of randomness generation

## Likelihood Explanation
**Likelihood: Medium to High**

The attack is highly realistic because:
1. It only requires Byzantine validators to send invalid signatures (trivial to implement)
2. No special timing or coordination required beyond being a validator
3. The retry mechanism is built into the protocol and cannot be avoided
4. Byzantine validators are assumed to exist in BFT consensus (up to F out of 3F+1)

Mitigating factors:
- Attack stops once quorum is reached from honest validators
- Exponential backoff spreads the cost over time
- Each validator network is independent (doesn't amplify across network)

## Recommendation
Add a deduplication check BEFORE signature verification in `AugDataCertBuilder::add()`:

```rust
fn add(&self, peer: Author, ack: Self::Response) -> anyhow::Result<Option<Self::Aggregated>> {
    // Check if we already have a signature from this peer
    let mut parital_signatures_guard = self.partial_signatures.lock();
    if parital_signatures_guard.contains_voter(&peer) {
        // Already have signature from this peer, return current state without re-verification
        let qc_aug_data = self
            .epoch_state
            .verifier
            .check_voting_power(parital_signatures_guard.signatures().keys(), true)
            .ok()
            .map(|_| {
                let aggregated_signature = self
                    .epoch_state
                    .verifier
                    .aggregate_signatures(parital_signatures_guard.signatures_iter())
                    .expect("Signature aggregation should succeed");
                CertifiedAugData::new(self.aug_data.clone(), aggregated_signature)
            });
        return Ok(qc_aug_data);
    }
    drop(parital_signatures_guard);
    
    // Only verify if we don't have a signature from this peer yet
    ack.verify(peer, &self.epoch_state.verifier, &self.aug_data)?;
    
    let mut parital_signatures_guard = self.partial_signatures.lock();
    parital_signatures_guard.add_signature(peer, ack.into_signature());
    // ... rest of the method
}
```

This matches the pattern used in `pending_votes.rs` for vote aggregation where duplicate checks occur before verification.

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::validator_signer::ValidatorSigner;
    use aptos_crypto::bls12381;
    
    #[test]
    fn test_repeated_invalid_signature_verification() {
        // Setup: Create epoch state with 4 validators (3F+1 where F=1)
        let signers: Vec<_> = (0..4)
            .map(|_| ValidatorSigner::random(None))
            .collect();
        let epoch_state = create_epoch_state(&signers);
        
        // Create augmented data from validator 0
        let aug_data = AugData::new(1, signers[0].author(), MockAugData);
        let cert_builder = AugDataCertBuilder::new(aug_data.clone(), Arc::new(epoch_state));
        
        // Byzantine validator (validator 1) sends multiple invalid signatures
        let byzantine_author = signers[1].author();
        let invalid_sig = AugDataSignature::new(
            1,
            bls12381::Signature::dummy_signature(), // Invalid signature
        );
        
        // Track number of expensive verify operations
        let mut verify_count = 0;
        
        // Simulate reliable broadcast retries (5 attempts)
        for i in 0..5 {
            let result = cert_builder.add(byzantine_author, invalid_sig.clone());
            
            // Each call performs expensive signature verification
            verify_count += 1;
            
            // Verification should fail
            assert!(result.is_err(), "Attempt {}: Expected verification failure", i);
            println!("Attempt {}: Invalid signature verification performed", i);
        }
        
        println!("Total expensive signature verifications: {}", verify_count);
        assert_eq!(verify_count, 5, "Should have performed 5 costly verifications");
        
        // This demonstrates the vulnerability: same invalid signature from same peer
        // was verified 5 times, wasting computational resources
    }
}
```

## Notes
- The vulnerability is exacerbated by the fact that `ExponentialBackoff` is an infinite iterator, meaning retries continue indefinitely until quorum is reached
- The issue affects both the randomness generation fast path and slow path, as both use the same reliable broadcast mechanism
- Similar patterns in vote aggregation (`pending_votes.rs`) correctly implement duplicate checks before verification, indicating this is an oversight rather than a design decision
- The computational cost scales with the number of Byzantine validators and network latency

### Citations

**File:** consensus/src/rand/rand_gen/reliable_broadcast_state.rs (L48-51)
```rust
    fn add(&self, peer: Author, ack: Self::Response) -> anyhow::Result<Option<Self::Aggregated>> {
        ack.verify(peer, &self.epoch_state.verifier, &self.aug_data)?;
        let mut parital_signatures_guard = self.partial_signatures.lock();
        parital_signatures_guard.add_signature(peer, ack.into_signature());
```

**File:** types/src/aggregate_signature.rs (L93-95)
```rust
    pub fn add_signature(&mut self, validator: AccountAddress, signature: bls12381::Signature) {
        self.signatures.insert(validator, signature);
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L183-201)
```rust
                    Some(result) = aggregate_futures.next() => {
                        let (receiver, result) = result.expect("spawned task must succeed");
                        match result {
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
                                }
                            },
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
                        }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L85-87)
```rust
        let rb_backoff_policy = ExponentialBackoff::from_millis(rb_config.backoff_policy_base_ms)
            .factor(rb_config.backoff_policy_factor)
            .max_delay(Duration::from_millis(rb_config.backoff_policy_max_delay_ms));
```

**File:** config/src/config/dag_consensus_config.rs (L114-121)
```rust
        Self {
            // A backoff policy that starts at 100ms and doubles each iteration up to 3secs.
            backoff_policy_base_ms: 2,
            backoff_policy_factor: 50,
            backoff_policy_max_delay_ms: 3000,

            rpc_timeout_ms: 1000,
        }
```

**File:** consensus/src/pending_votes.rs (L287-296)
```rust
        if let Some((previously_seen_vote, previous_li_digest)) =
            self.author_to_vote.get(&vote.author())
        {
            // is it the same vote?
            if &li_digest == previous_li_digest {
                // we've already seen an equivalent vote before
                let new_timeout_vote = vote.is_timeout() && !previously_seen_vote.is_timeout();
                if !new_timeout_vote {
                    // it's not a new timeout vote
                    return VoteReceptionResult::DuplicateVote;
```
