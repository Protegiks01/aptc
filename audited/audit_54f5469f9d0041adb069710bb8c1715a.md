# Audit Report

## Title
Indexer gRPC Manager DoS via Status Message Flooding from Malicious Fullnode

## Summary
The `DataManager::start()` function in the indexer-grpc-manager blindly skips all Status responses without any rate limiting, timeout, or validation. A malicious fullnode can send an infinite stream of Status messages, preventing actual transaction data transfer while keeping the connection alive, effectively DoSing the indexer service.

## Finding Description

The indexer-grpc-manager's `DataManager::start()` function fetches transaction data from configured fullnodes via gRPC streaming. According to the protocol specification, the legitimate response pattern should be:
1. One INIT Status message
2. Alternating Data and BATCH_END Status messages [1](#0-0) 

However, the implementation at line 268 unconditionally continues on ANY Status response without validation: [2](#0-1) 

This `continue` statement simply loops back to `response.next().await` at line 233, waiting for the next message indefinitely: [3](#0-2) 

The attack works as follows:

1. **Malicious fullnode accepts connection**: The `get_fullnode_for_request()` selects a fullnode from the configured list [4](#0-3) 

2. **Sends initial INIT Status**: Appears legitimate
3. **Floods with BATCH_END Status messages**: Never sends actual Data responses
4. **Victim loops forever**: Each Status message triggers `continue`, returning to `response.next().await`

The gRPC client has NO timeout configured: [5](#0-4) 

There is no:
- Timeout on stream reading
- Counter for consecutive Status messages
- Validation that Status comes after Data
- Mechanism to break out and retry with a different fullnode

The outer loop at line 196 never gets a chance to re-execute because the inner while loop at line 233 never exits: [6](#0-5) 

Compare this to the cache worker implementation which properly validates Status types: [7](#0-6) 

## Impact Explanation

**Severity: Medium**

This vulnerability causes:
1. **Indexer Service Unavailability**: No new transactions are indexed, breaking wallets, explorers, and dApps dependent on the indexer API
2. **Silent Failure**: The system appears healthy (connection alive, no errors logged) but makes zero progress
3. **Cache Starvation**: Downstream consumers waiting for new transaction data never receive updates [8](#0-7) 

This falls under **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention" - the indexer requires manual restart and fullnode reconfiguration to recover.

While this doesn't directly affect consensus or validator operations, the indexer is critical infrastructure for the Aptos ecosystem, making this a significant availability issue.

## Likelihood Explanation

**Likelihood: High**

- **Attack Complexity: Low** - Simply send Status responses without Data
- **Attacker Requirements: Low** - Must control or compromise one fullnode in the configured list, or MITM the connection
- **Detection Difficulty: Medium** - Connection appears healthy, no errors logged, only symptom is lack of progress
- **Deployment: Common** - All indexer-grpc-manager deployments are vulnerable

## Recommendation

Add timeout and validation mechanisms:

```rust
// Add timeout configuration to gRPC client
impl Fullnode {
    fn new(address: GrpcAddress) -> Self {
        let channel = Channel::from_shared(address)
            .expect("Bad address.")
            .timeout(Duration::from_secs(60))  // Add timeout
            .connect_lazy();
        // ... rest of implementation
    }
}

// In DataManager::start(), add Status message validation
let mut consecutive_status_count = 0;
const MAX_CONSECUTIVE_STATUS: u32 = 10;
const DATA_RECEIVE_TIMEOUT: Duration = Duration::from_secs(30);

while let Some(response_item) = response.next().await {
    // ... GC loop ...
    match response_item {
        Ok(r) => {
            if let Some(response) = r.response {
                match response {
                    Response::Data(data) => {
                        consecutive_status_count = 0;  // Reset on data
                        self.cache.write().await.put_transactions(data.transactions);
                    },
                    Response::Status(status) => {
                        consecutive_status_count += 1;
                        if consecutive_status_count > MAX_CONSECUTIVE_STATUS {
                            warn!("Too many consecutive Status messages from fullnode, reconnecting.");
                            break;  // Exit to outer loop to retry
                        }
                        continue;
                    },
                }
            }
        },
        Err(e) => {
            warn!("Error when getting transactions from fullnode: {}", e);
            continue 'out;
        },
    }
}
```

Additionally, implement a watchdog timer that breaks out if no Data messages are received within a timeout period.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio::sync::mpsc;
    use aptos_protos::internal::fullnode::v1::{
        StreamStatus, stream_status::StatusType,
        transactions_from_node_response::Response,
    };

    #[tokio::test]
    async fn test_status_flood_dos() {
        // Setup: Create a mock stream that only sends Status messages
        let (tx, rx) = mpsc::channel(100);
        
        // Spawn task to flood with Status messages
        tokio::spawn(async move {
            for _ in 0..1000 {
                let status_response = TransactionsFromNodeResponse {
                    response: Some(Response::Status(StreamStatus {
                        r#type: StatusType::BatchEnd as i32,
                        start_version: 0,
                        end_version: Some(100),
                    })),
                    chain_id: 1,
                };
                tx.send(Ok(status_response)).await.unwrap();
                tokio::time::sleep(Duration::from_millis(1)).await;
            }
        });

        // Test: Verify that processing gets stuck
        let start = std::time::Instant::now();
        let mut count = 0;
        let mut stream = ReceiverStream::new(rx);
        
        while let Some(Ok(response)) = stream.next().await {
            if let Some(Response::Status(_)) = response.response {
                count += 1;
                // In real code, this would continue indefinitely
                if count >= 100 {
                    break;
                }
            }
        }
        
        let elapsed = start.elapsed();
        // Attack succeeds: spent >100ms processing Status messages
        // without receiving any actual transaction data
        assert!(elapsed.as_millis() > 100);
        assert_eq!(count, 100);
        println!("DoS successful: processed {} Status messages without data transfer", count);
    }
}
```

**Notes**

This vulnerability is specific to the indexer-grpc-manager component and does not directly affect blockchain consensus or validator operations. However, it represents a critical availability issue for the Aptos ecosystem since the indexer service is essential infrastructure used by wallets, block explorers, analytics platforms, and dApps to access blockchain data. The lack of timeout configuration, rate limiting, and sequence validation creates an exploitable DoS vector that can be triggered by any compromised or malicious fullnode.

### Citations

**File:** protos/proto/aptos/internal/fullnode/v1/fullnode_data.proto (L11-16)
```text
// Transaction data is transferred via 1 stream with batches until terminated.
// One stream consists:
//  StreamStatus: INIT with version x
//  loop k:
//    TransactionOutput data(size n)
//    StreamStatus: BATCH_END with version x + (k + 1) * n - 1
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L196-196)
```rust
        'out: loop {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L217-220)
```rust
            let (address, mut fullnode_client) =
                self.metadata_manager.get_fullnode_for_request(&request);
            trace!("Fullnode ({address}) is picked for request.");
            let response = fullnode_client.get_transactions_from_node(request).await;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L233-233)
```rust
            while let Some(response_item) = response.next().await {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L266-266)
```rust
                                    self.cache.write().await.put_transactions(data.transactions);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/data_manager.rs (L268-268)
```rust
                                Response::Status(_) => continue,
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/metadata_manager.rs (L67-80)
```rust
    fn new(address: GrpcAddress) -> Self {
        let channel = Channel::from_shared(address)
            .expect("Bad address.")
            .connect_lazy();
        let client = FullnodeDataClient::new(channel)
            .send_compressed(CompressionEncoding::Zstd)
            .accept_compressed(CompressionEncoding::Zstd)
            .max_encoding_message_size(MAX_MESSAGE_SIZE)
            .max_decoding_message_size(MAX_MESSAGE_SIZE);
        Self {
            client,
            recent_states: VecDeque::new(),
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L190-207)
```rust
        Response::Status(status) => {
            match StatusType::try_from(status.r#type).expect("[Indexer Cache] Invalid status type.")
            {
                StatusType::Init => Ok(GrpcDataStatus::StreamInit(status.start_version)),
                StatusType::BatchEnd => {
                    let start_version = status.start_version;
                    let num_of_transactions = status
                        .end_version
                        .expect("TransactionsFromNodeResponse status end_version is None")
                        - start_version
                        + 1;
                    Ok(GrpcDataStatus::BatchEnd {
                        start_version,
                        num_of_transactions,
                    })
                },
                StatusType::Unspecified => unreachable!("Unspecified status type."),
            }
```
