# Audit Report

## Title
Unbounded Concurrent Stream Spawning Enables Memory Exhaustion DoS in Indexer-grpc Services

## Summary
The indexer-grpc-data-service-v2 and indexer-grpc-manager services accept unlimited concurrent gRPC streaming connections, with each connection spawning an unbounded async task. Combined with the 256MB `MAX_MESSAGE_SIZE` limit and lack of authentication in v2, an attacker can exhaust server memory by opening many concurrent streams, causing service crashes and degradation.

## Finding Description

The vulnerability exists across multiple indexer-grpc components that fail to limit concurrent stream connections: [1](#0-0) [2](#0-1) 

Both services configure tonic gRPC servers with 256MB message size limits for encoding and decoding: [3](#0-2) [4](#0-3) 

The critical flaw is in how streaming requests are handled. Each incoming `GetTransactions` request spawns an unbounded async task: [5](#0-4) [6](#0-5) 

These tasks execute within `tokio_scoped::scope` without any concurrency limits: [7](#0-6) 

Notably, the codebase contains `BoundedExecutor` for limiting concurrent tasks in critical paths, but the indexer-grpc services do not use it—no matches were found for `BoundedExecutor` in the indexer-grpc codebase.

Each spawned streaming task allocates response channels with buffers: [8](#0-7) 

The default channel size is 5 messages: [9](#0-8) 

For HistoricalDataService, transaction batches are chunked by count, not byte size: [10](#0-9) 

The `get_transaction_batch` method reads multiple files without byte limits when `max_files` is None: [11](#0-10) [12](#0-11) 

Critically, indexer-grpc-data-service-v2 removed authentication that existed in v1—there are no `whitelisted_auth_tokens` or authentication interceptors in the v2 configuration or service implementation, making the attack completely unauthenticated.

**Attack Scenario:**
1. Attacker opens N concurrent gRPC streaming connections to indexer-grpc-data-service-v2
2. Each connection calls `GetTransactions` without authentication
3. Each request spawns an unbounded async task via `scope.spawn`
4. Each task allocates a response channel (5 message buffer)
5. Each channel message can be up to 256MB (tonic limit) or 20MB (LiveDataService practical limit)
6. Total memory: N × 5 × message_size + task overhead + data fetching buffers
7. With N=1000 streams: 1000 × 5 × 20MB = 100GB in channel buffers alone
8. Server runs out of memory and crashes or becomes severely degraded

## Impact Explanation

This qualifies as **High Severity** under the Aptos Bug Bounty program for "API crashes." The indexer-grpc services are critical API infrastructure that external indexers depend on for transaction data streaming. 

Unlike generic network-level DoS (which is out of scope), this is an application-level logic vulnerability:
- Missing concurrency controls in application code
- Unbounded memory allocation per request
- No authentication or rate limiting in v2

The impact is amplified because:
- **indexer-grpc-fullnode** runs alongside fullnodes, and crashes could destabilize fullnode operations
- **indexer-grpc-manager** coordinates the entire indexing infrastructure
- Service crashes break external indexer integrations, affecting ecosystem tools

While not consensus-critical, these services are production infrastructure explicitly covered under "API crashes" in the bounty program.

## Likelihood Explanation

**Likelihood: High**

The attack requires no special privileges or setup:
- No authentication in indexer-grpc-data-service-v2
- Standard gRPC clients can open concurrent streams
- No rate limiting or IP-based restrictions visible in the code
- Attack can be executed from a single machine with sufficient network bandwidth

The vulnerability is deterministic—opening N concurrent streams will spawn N unbounded tasks, each allocating predictable memory. An attacker with basic gRPC knowledge can trivially exploit this.

## Recommendation

Implement bounded concurrency controls:

1. **Add stream concurrency limits** using the existing `BoundedExecutor`:
   - Limit total concurrent streams per service instance
   - Reject new stream requests when at capacity
   - Return `RESOURCE_EXHAUSTED` status code to clients

2. **Add per-client rate limiting**:
   - Track concurrent streams per client IP/identity
   - Implement token bucket rate limiter
   - Consider integration with existing `aptos-rate-limiter` crate

3. **Configure HTTP/2 limits** on tonic Server:
   - Set `http2_max_concurrent_streams()` to reasonable limit (e.g., 100)
   - This provides defense-in-depth at the protocol layer

4. **Reduce MAX_MESSAGE_SIZE**:
   - Consider lowering from 256MB to more reasonable limits
   - LiveDataService already uses 20MB batches internally
   - Align tonic limits with actual usage patterns

5. **Add authentication** to data-service-v2:
   - Restore token-based auth or use API Gateway
   - Prevent anonymous unlimited access

Example fix for LiveDataService:

```rust
use bounded_executor::BoundedExecutor;

const MAX_CONCURRENT_STREAMS: usize = 100;

pub struct LiveDataService<'a> {
    // ... existing fields
    stream_executor: BoundedExecutor,
}

impl<'a> LiveDataService<'a> {
    pub fn new(...) -> Self {
        let stream_executor = BoundedExecutor::new(
            MAX_CONCURRENT_STREAMS,
            tokio::runtime::Handle::current(),
        );
        // ...
    }
    
    pub fn run(&'a self, mut handler_rx: Receiver<...>) {
        while let Some((request, response_sender)) = handler_rx.blocking_recv() {
            // Check capacity before spawning
            if self.stream_executor.num_running() >= MAX_CONCURRENT_STREAMS {
                let _ = response_sender.blocking_send(Err(
                    Status::resource_exhausted("Too many concurrent streams")
                ));
                continue;
            }
            
            // Use bounded executor
            let executor = self.stream_executor.clone();
            executor.spawn(async move {
                self.start_streaming(...).await
            });
        }
    }
}
```

## Proof of Concept

```rust
// Reproduction test - requires running indexer-grpc-data-service-v2

use aptos_protos::indexer::v1::data_service_client::DataServiceClient;
use aptos_protos::indexer::v1::GetTransactionsRequest;
use futures::StreamExt;
use tonic::transport::Channel;

#[tokio::test]
async fn test_concurrent_stream_dos() {
    let endpoint = "http://localhost:50051"; // indexer-grpc-data-service-v2
    
    // Spawn 1000 concurrent streaming connections
    let mut handles = vec![];
    
    for i in 0..1000 {
        let endpoint = endpoint.to_string();
        let handle = tokio::spawn(async move {
            let channel = Channel::from_shared(endpoint)
                .unwrap()
                .connect()
                .await
                .unwrap();
            
            let mut client = DataServiceClient::new(channel);
            
            let request = GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: None, // Infinite stream
                batch_size: Some(10000), // Large batches
                transaction_filter: None,
            };
            
            // Start streaming - this spawns unbounded task on server
            let mut stream = client
                .get_transactions(request)
                .await
                .unwrap()
                .into_inner();
            
            // Keep stream alive, consuming slowly to maximize server memory
            while let Some(response) = stream.next().await {
                if response.is_err() {
                    break;
                }
                tokio::time::sleep(tokio::time::Duration::from_secs(60)).await;
            }
        });
        
        handles.push(handle);
    }
    
    // Wait for all streams to connect
    tokio::time::sleep(tokio::time::Duration::from_secs(10)).await;
    
    // At this point, server should be experiencing severe memory pressure
    // with 1000 concurrent tasks and ~5000 channel buffers allocated
    
    // Monitor server memory - should see 50-100GB allocated depending on message sizes
    println!("All streams spawned. Server memory should be exhausted.");
    
    // Cleanup
    for handle in handles {
        handle.abort();
    }
}
```

**Notes**
- This vulnerability breaks the "Resource Limits" invariant (#9) which states "All operations must respect gas, storage, and computational limits"
- The indexer-grpc services fail to enforce memory limits on concurrent operations
- While the 256MB `MAX_MESSAGE_SIZE` constant enables large individual messages, the root cause is the unbounded concurrent stream spawning
- The vulnerability is exploitable on public indexer-grpc endpoints that lack authentication
- This is distinct from network-level DoS (which floods network infrastructure) - this is an application logic vulnerability enabling resource exhaustion through legitimate API usage patterns

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/config.rs (L15-15)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L39-39)
```rust
const DEFAULT_MAX_RESPONSE_CHANNEL_SIZE: usize = 5;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L240-248)
```rust
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
        let wrapper_service =
            aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
                .send_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Zstd)
                .accept_compressed(CompressionEncoding::Gzip)
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/grpc_manager.rs (L99-100)
```rust
        .max_encoding_message_size(MAX_MESSAGE_SIZE)
        .max_decoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L66-66)
```rust
        tokio_scoped::scope(|scope| {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L127-139)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        MAX_BYTES_PER_BATCH,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L112-123)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L169-180)
```rust
            tokio::spawn(async move {
                file_store_reader
                    .get_transaction_batch(
                        next_version,
                        /*retries=*/ 3,
                        /*max_files=*/ None,
                        filter,
                        Some(ending_version),
                        tx,
                    )
                    .await;
            });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L204-219)
```rust
                    let mut responses: Vec<_> = transactions
                        .chunks(max_num_transactions_per_batch)
                        .map(|chunk| {
                            let first_version = current_version;
                            let last_version = chunk.last().unwrap().version;
                            current_version = last_version + 1;
                            TransactionsResponse {
                                transactions: chunk.to_vec(),
                                chain_id: Some(self.chain_id),
                                processed_range: Some(ProcessedRange {
                                    first_version,
                                    last_version,
                                }),
                            }
                        })
                        .collect();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/service.rs (L142-143)
```rust
        let (tx, rx) = channel(self.data_service_response_channel_size);
        self.handler_tx.send((req, tx)).await.unwrap();
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator_v2/file_store_reader.rs (L77-156)
```rust
    pub async fn get_transaction_batch(
        &self,
        version: u64,
        retries: u8,
        max_files: Option<usize>,
        filter: Option<BooleanTransactionFilter>,
        ending_version: Option<u64>,
        tx: Sender<(Vec<Transaction>, usize, Timestamp, (u64, u64))>,
    ) {
        trace!(
            "Getting transactions from file store, version: {version}, max_files: {max_files:?}."
        );
        let batch_metadata = self.get_batch_metadata(version).await;
        if batch_metadata.is_none() {
            // TODO(grao): This is unexpected, should only happen when data is corrupted. Consider
            // make it panic!.
            error!("Failed to get the batch metadata, unable to serve the request.");
            return;
        }

        let batch_metadata = batch_metadata.unwrap();

        let mut file_index = None;
        for (i, file_metadata) in batch_metadata.files.iter().enumerate().rev() {
            let file_first_version = file_metadata.first_version;
            if file_first_version <= version {
                file_index = Some(i);
                break;
            }
        }

        let file_index =
            file_index.unwrap_or_else(|| panic!("Must find file_index for version: {version}."));
        let mut end_file_index = batch_metadata.files.len();
        if let Some(max_files) = max_files {
            end_file_index = end_file_index.min(file_index.saturating_add(max_files));
        }

        for i in file_index..end_file_index {
            let current_version = batch_metadata.files[i].first_version;
            if let Some(ending_version) = ending_version {
                if current_version >= ending_version {
                    break;
                }
            }
            let transactions = self
                .get_transaction_file_at_version(current_version, batch_metadata.suffix, retries)
                .await;
            if let Ok(mut transactions) = transactions {
                let timestamp = transactions.last().unwrap().timestamp.unwrap();
                let num_to_skip = version.saturating_sub(current_version) as usize;
                if num_to_skip > 0 {
                    transactions = transactions.split_off(num_to_skip);
                }
                let mut processed_range = (
                    transactions.first().unwrap().version,
                    transactions.last().unwrap().version,
                );
                if let Some(ending_version) = ending_version {
                    transactions
                        .truncate(transactions.partition_point(|t| t.version < ending_version));
                    processed_range.1 = processed_range.1.min(ending_version - 1);
                }
                if let Some(ref filter) = filter {
                    transactions.retain(|t| filter.matches(t));
                }
                let size_bytes = transactions.iter().map(|t| t.encoded_len()).sum();
                trace!("Got {} transactions from file store to send, size: {size_bytes}, processed_range: [{}, {}]", transactions.len(), processed_range.0, processed_range.1);
                if tx
                    .send((transactions, size_bytes, timestamp, processed_range))
                    .await
                    .is_err()
                {
                    break;
                }
            } else {
                error!("Got error from file store: {:?}.", transactions);
                break;
            }
        }
```
