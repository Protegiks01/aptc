# Audit Report

## Title
Token Indexer Crash via V1 Token Creation Due to Null Table Data Field

## Summary
The token indexer crashes with a panic when processing V1 token transactions because it unconditionally unwraps the optional `data` field of `WriteTableItem` objects, which is `None` when the table info indexer is not enabled. Any user creating V1 tokens can trigger this crash.

## Finding Description

The vulnerability exists in the token indexer's processing of V1 token-related table item changes. The data flow is as follows:

1. **Indexer Initialization**: The indexer explicitly passes `None` for the table info reader when creating its Context: [1](#0-0) 

2. **WriteTableItem Data Population**: When transactions are converted to API types, the `data` field of `WriteTableItem` is only populated if a table info reader is available. The field is documented as optional: [2](#0-1) 

3. **Converter Logic**: The converter's `get_table_info()` method returns `None` when no indexer reader is configured: [3](#0-2) 

4. **Table Data Decoding**: When table info cannot be retrieved, the function returns `Ok(None)` to avoid crashes: [4](#0-3) 

5. **Crash Point**: The token processor unconditionally unwraps this optional field without checking if it's `None`: [5](#0-4) 

**Attack Vector**: Any user can trigger this crash by creating V1 tokens using the public entry functions in the Token V1 framework: [6](#0-5) 

When `create_tokendata` executes, it adds data to the `Collections.token_data` table: [7](#0-6) 

This generates a `WriteTableItem` in the transaction's write set, which the token processor attempts to parse. The processor calls the vulnerable function and crashes: [8](#0-7) 

## Impact Explanation

This qualifies as **HIGH severity** per the Aptos bug bounty program under the category "API crashes". Specifically:

- **Availability Impact**: The token indexer crashes and stops processing transactions, causing all token-related API queries to become stale or unavailable
- **Service Disruption**: Token metadata, ownership, and collection information becomes inaccessible through the API
- **Scope**: Affects any third-party indexer operator who runs the token processor without enabling the table info indexer on their source node

**Not Affected**: Consensus, block production, transaction execution, validator operations, or other indexer processors (default, coin, stake).

## Likelihood Explanation

**VERY HIGH** likelihood:

- **Ease of Exploitation**: Any user can trigger the crash by simply creating a V1 token through standard Token V1 framework functions
- **No Special Privileges**: Requires only a normal user account with gas fees
- **100% Reliability**: The crash is deterministic - it will occur every time a V1 token transaction is processed
- **Common Scenario**: V1 tokens are still actively used in the Aptos ecosystem
- **Configuration Flaw**: The token indexer does not validate that table info is available before attempting to process table items, making this a silent failure mode

## Recommendation

**Immediate Fix**: Add null checking before unwrapping the `data` field:

```rust
pub fn get_v1_from_write_table_item(
    table_item: &APIWriteTableItem,
    txn_version: i64,
    write_set_change_index: i64,
    txn_timestamp: chrono::NaiveDateTime,
) -> anyhow::Result<Option<(Self, CurrentTokenDataV2)>> {
    // Check if data is available
    let table_item_data = match table_item.data.as_ref() {
        Some(data) => data,
        None => {
            aptos_logger::warn!(
                transaction_version = txn_version,
                "WriteTableItem missing decoded data - table indexer may not be enabled"
            );
            return Ok(None);
        }
    };

    let maybe_token_data = match TokenWriteSet::from_table_item_type(
        table_item_data.value_type.as_str(),
        &table_item_data.value,
        txn_version,
    )? {
        Some(TokenWriteSet::TokenData(inner)) => Some(inner),
        _ => None,
    };
    // ... rest of function
}
```

**Systematic Fix**: Apply the same pattern to all similar instances found in:
- `crates/indexer/src/models/move_tables.rs` (6 instances)
- `crates/indexer/src/models/token_models/token_claims.rs` (2 instances)
- `crates/indexer/src/models/token_models/tokens.rs` (2 instances)
- `crates/indexer/src/models/token_models/v2_token_ownerships.rs` (2 instances)
- `crates/indexer/src/models/stake_models/delegator_pools.rs` (1 instance)
- `crates/indexer/src/models/token_models/collection_datas.rs` (1 instance)
- `crates/indexer/src/models/token_models/token_datas.rs` (1 instance)
- `crates/indexer/src/models/token_models/v2_collections.rs` (1 instance)

**Architectural Fix**: Either:
1. Make table info indexer a hard dependency for token/stake processors, or
2. Add startup validation to ensure table info is available before starting dependent processors

## Proof of Concept

**Move Script** to trigger the crash:

```move
script {
    use aptos_framework::aptos_account;
    use aptos_token::token;
    use std::string;
    use std::vector;

    fun create_crash_token(creator: &signer) {
        // Create a collection first if not exists
        let collection_name = string::utf8(b"CrashCollection");
        
        token::create_collection_script(
            creator,
            collection_name,
            string::utf8(b"A collection to crash the indexer"),
            string::utf8(b"https://example.com"),
            1000,
            vector[false, false, false]
        );

        // Create a token - this will crash the indexer
        token::create_token_script(
            creator,
            collection_name,
            string::utf8(b"CrashToken"),
            string::utf8(b"This token crashes the indexer"),
            1,
            100,
            string::utf8(b"https://example.com/token"),
            @0x1,
            100,
            0,
            vector[false, false, false, false, false],
            vector[],
            vector[],
            vector[]
        );
    }
}
```

**Reproduction Steps**:
1. Deploy a fullnode with the token indexer processor enabled
2. Do NOT enable the table info indexer (leave `table_info_service_mode: Disabled`)
3. Submit the above Move script to create a V1 token
4. Observe the token indexer panic with: `thread 'tokio-runtime-worker' panicked at 'called Option::unwrap() on a None value'`

## Notes

This is an architectural flaw where the token indexer has an implicit dependency on the table info indexer but does not validate this dependency. The vulnerability affects any deployment where operators run specialized indexer processors without understanding the full dependency chain. While Aptos Foundation's own infrastructure likely has table info enabled, third-party indexer operators are at risk.

### Citations

**File:** crates/indexer/src/runtime.rs (L93-99)
```rust
        let context = Arc::new(Context::new(
            chain_id,
            db,
            mp_sender,
            node_config,
            None, /* table info reader */
        ));
```

**File:** api/types/src/transaction.rs (L1177-1187)
```rust
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, Object)]
pub struct WriteTableItem {
    pub state_key_hash: String,
    pub handle: HexEncodedBytes,
    pub key: HexEncodedBytes,
    pub value: HexEncodedBytes,
    // This is optional, and only possible to populate if the table indexer is enabled for this node
    #[serde(skip_serializing_if = "Option::is_none")]
    #[serde(default)]
    pub data: Option<DecodedTableData>,
}
```

**File:** api/types/src/convert.rs (L555-567)
```rust
    pub fn try_write_table_item_into_decoded_table_data(
        &self,
        handle: TableHandle,
        key: &[u8],
        value: &[u8],
    ) -> Result<Option<DecodedTableData>> {
        let table_info = match self.get_table_info(handle)? {
            Some(ti) => ti,
            None => {
                log_missing_table_info(handle);
                return Ok(None); // if table item not found return None anyway to avoid crash
            },
        };
```

**File:** api/types/src/convert.rs (L1060-1065)
```rust
    fn get_table_info(&self, handle: TableHandle) -> Result<Option<TableInfo>> {
        if let Some(indexer_reader) = self.indexer_reader.as_ref() {
            return Ok(indexer_reader.get_table_info(handle).unwrap_or(None));
        }
        Ok(None)
    }
```

**File:** crates/indexer/src/models/token_models/v2_token_datas.rs (L161-161)
```rust
        let table_item_data = table_item.data.as_ref().unwrap();
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L492-507)
```text
    public entry fun create_token_script(
        account: &signer,
        collection: String,
        name: String,
        description: String,
        balance: u64,
        maximum: u64,
        uri: String,
        royalty_payee_address: address,
        royalty_points_denominator: u64,
        royalty_points_numerator: u64,
        mutate_setting: vector<bool>,
        property_keys: vector<String>,
        property_values: vector<vector<u8>>,
        property_types: vector<String>
    ) acquires Collections, TokenStore {
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1311-1311)
```text
        collections.token_data.add(token_data_id, token_data);
```

**File:** crates/indexer/src/processors/token_processor.rs (L1248-1256)
```rust
                        if let Some((token_data, current_token_data)) =
                            TokenDataV2::get_v1_from_write_table_item(
                                table_item,
                                txn_version,
                                wsc_index,
                                txn_timestamp,
                            )
                            .unwrap()
                        {
```
