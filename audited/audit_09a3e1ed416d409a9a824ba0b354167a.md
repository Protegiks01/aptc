# Audit Report

## Title
Time-of-Check-Time-of-Use Race Condition in Peer Protocol Metadata Cache Causes Message Delivery Failures During Protocol Upgrades

## Summary
A TOCTOU race condition exists in the peer metadata caching system where senders can use stale protocol information when peers reconnect with updated protocols. This causes message delivery failures during node upgrades, potentially impacting consensus liveness and validator communication.

## Finding Description

The `PeersAndMetadata` system uses a cached snapshot approach for peer metadata retrieval. [1](#0-0) 

When sending messages, the `NetworkClient` retrieves peer protocol information by loading this cached snapshot. [2](#0-1) 

The race condition occurs in this sequence:

**Thread A (Message Sender):**
1. Calls `send_to_peer()` [3](#0-2) 
2. Calls `get_supported_protocols()` which loads the cached metadata snapshot [4](#0-3) 
3. Selects preferred protocol from stale snapshot [5](#0-4) 

**Thread B (Peer Manager):**
1. Peer reconnects with upgraded protocols after software update
2. Updates metadata via `insert_connection_metadata()` [6](#0-5) 
3. Updates cache with new protocol set [7](#0-6) 

**Thread A continues:**
4. Sends message using protocol from stale snapshot
5. Receiving peer has no handler for deprecated protocol [8](#0-7) 
6. Message is silently dropped with UNKNOWN_LABEL counter increment

**Real-World Scenario:**
During rolling upgrades, validators may deprecate old protocol variants (e.g., switching from `ConsensusDirectSendBcs` to `ConsensusDirectSendCompressed`). [9](#0-8) 

When a validator reconnects after upgrading:
1. Old metadata shows protocols {ConsensusDirectSendBcs, ConsensusRpcBcs}
2. Peer upgrades and reconnects with {ConsensusDirectSendCompressed, ConsensusRpcCompressed}
3. Metadata update happens in peer manager [10](#0-9) 
4. Concurrent senders using old snapshot send with deprecated protocols
5. Messages are dropped, causing consensus timeouts

## Impact Explanation

**HIGH Severity** per Aptos Bug Bounty criteria:

1. **Validator Node Slowdowns**: Dropped consensus messages cause timeout-based retries, increasing latency and reducing throughput during critical upgrade windows.

2. **Significant Protocol Violations**: Message delivery guarantees are violated. The network layer promises to deliver messages to connected peers, but stale metadata causes silent failures.

3. **Consensus Liveness Risk**: During network-wide upgrades when multiple validators upgrade simultaneously, accumulated message losses can cause consensus delays. While not a complete liveness failure, it degrades the system's ability to make progress during a critical operational period.

The vulnerability affects AptosBFT consensus safety indirectly by potentially causing validators to miss critical consensus messages (votes, proposals, quorum certificates) during protocol transitions.

## Likelihood Explanation

**Medium-High Likelihood:**

1. **Occurs During Every Node Upgrade**: Any time a validator upgrades and changes supported protocols, this race condition window opens.

2. **Small but Real Window**: The race window exists between cache snapshot load and message send. While brief, it's sufficient for concurrent operations in a multi-threaded validator node.

3. **Network-Wide Upgrades Amplify Impact**: During coordinated upgrades across the validator set, multiple nodes experience this simultaneously, multiplying the probability of consensus message loss.

4. **No Attacker Required**: This happens naturally during legitimate operations. While not actively exploited, it still represents a security-relevant reliability failure affecting consensus.

5. **Protocol Evolution Trend**: As Aptos evolves, protocol changes (like the observed BCS â†’ Compressed migration pattern) will trigger this condition regularly.

## Recommendation

Implement atomic protocol information retrieval that ensures consistency between metadata read and message send:

**Option 1: Re-validate Protocol Before Send**
After selecting the protocol from cached metadata, re-check that the peer still supports it immediately before sending. If not, reload metadata and retry protocol selection.

**Option 2: Version-Stamped Cache**
Include a version counter with cached metadata. Before sending, verify the version hasn't changed. If changed, reload and retry.

**Option 3: Lock-Based Consistency**
Use a read lock during the entire send operation to prevent metadata updates mid-operation. This ensures the protocol information remains consistent throughout message preparation and sending.

**Recommended Fix (Option 1 - Least Invasive):**

In `send_to_peer()` and related methods, add a re-validation step:

```rust
fn send_to_peer(&self, message: Message, peer: PeerNetworkId) -> Result<(), Error> {
    let network_sender = self.get_sender_for_network_id(&peer.network_id())?;
    
    // Select protocol from current metadata
    let direct_send_protocol_id = self
        .get_preferred_protocol_for_peer(&peer, &self.direct_send_protocols_and_preferences)?;
    
    // Re-validate protocol support immediately before send
    let current_protocols = self.get_supported_protocols(&peer)?;
    if !current_protocols.contains(direct_send_protocol_id) {
        // Protocol changed between selection and send, retry with fresh metadata
        let direct_send_protocol_id = self
            .get_preferred_protocol_for_peer(&peer, &self.direct_send_protocols_and_preferences)?;
    }
    
    Ok(network_sender.send_to(peer.peer_id(), direct_send_protocol_id, message)?)
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_stale_metadata_race_condition() {
    use network::application::interface::NetworkClient;
    use network::application::storage::PeersAndMetadata;
    use network::transport::ConnectionMetadata;
    use network::protocols::wire::handshake::v1::{ProtocolId, ProtocolIdSet};
    
    // Setup: Create peers and metadata with initial protocol set
    let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Validator]);
    let peer_id = PeerId::random();
    let peer_network_id = PeerNetworkId::new(NetworkId::Validator, peer_id);
    
    // Initial connection with old protocols
    let mut old_protocols = ProtocolIdSet::empty();
    old_protocols.insert(ProtocolId::ConsensusDirectSendBcs);
    let old_conn_metadata = ConnectionMetadata::new(
        peer_id,
        ConnectionId::from(1),
        NetworkAddress::mock(),
        ConnectionOrigin::Outbound,
        MessagingProtocolVersion::V1,
        old_protocols,
        PeerRole::Validator,
    );
    peers_and_metadata.insert_connection_metadata(peer_network_id, old_conn_metadata)?;
    
    // Create network client
    let network_client = NetworkClient::new(
        vec![ProtocolId::ConsensusDirectSendBcs, ProtocolId::ConsensusDirectSendCompressed],
        vec![],
        HashMap::new(),
        peers_and_metadata.clone(),
    );
    
    // Thread A: Start send operation (loads stale metadata)
    let handle_a = tokio::spawn({
        let client = network_client.clone();
        let peer = peer_network_id;
        async move {
            // This will load metadata showing ConsensusDirectSendBcs is supported
            let protocols = client.get_supported_protocols(&peer).unwrap();
            
            // Simulate delay to widen race window
            tokio::time::sleep(Duration::from_millis(10)).await;
            
            // Protocol selection uses stale snapshot
            let protocol = client.get_preferred_protocol_for_peer(
                &peer,
                &[ProtocolId::ConsensusDirectSendBcs, ProtocolId::ConsensusDirectSendCompressed]
            ).unwrap();
            
            protocol // Returns ConsensusDirectSendBcs from stale metadata
        }
    });
    
    // Thread B: Peer reconnects with updated protocols
    let handle_b = tokio::spawn({
        let peers_meta = peers_and_metadata.clone();
        let peer = peer_network_id;
        async move {
            tokio::time::sleep(Duration::from_millis(5)).await;
            
            // Peer upgraded and now only supports compressed variant
            let mut new_protocols = ProtocolIdSet::empty();
            new_protocols.insert(ProtocolId::ConsensusDirectSendCompressed);
            let new_conn_metadata = ConnectionMetadata::new(
                peer.peer_id(),
                ConnectionId::from(2),
                NetworkAddress::mock(),
                ConnectionOrigin::Outbound,
                MessagingProtocolVersion::V1,
                new_protocols,
                PeerRole::Validator,
            );
            
            // Update metadata - peer no longer supports ConsensusDirectSendBcs
            peers_meta.insert_connection_metadata(peer, new_conn_metadata).unwrap();
        }
    });
    
    let selected_protocol = handle_a.await.unwrap();
    handle_b.await.unwrap();
    
    // Verify race condition: sender selected protocol from stale metadata
    assert_eq!(selected_protocol, ProtocolId::ConsensusDirectSendBcs);
    
    // Current metadata shows peer doesn't support this protocol anymore
    let current_protocols = peers_and_metadata.get_metadata_for_peer(peer_network_id)
        .unwrap()
        .get_supported_protocols();
    assert!(!current_protocols.contains(ProtocolId::ConsensusDirectSendBcs));
    
    // Message would be sent with ConsensusDirectSendBcs but peer will drop it
    // because it has no handler for that protocol ID
}
```

This test demonstrates that a sender can select a protocol from stale cached metadata that the peer no longer supports after a concurrent reconnection, leading to message delivery failure.

## Notes

While this vulnerability does not require active exploitation by a malicious attacker, it represents a significant reliability and security issue. The race condition violates message delivery guarantees during protocol upgrades, which is a critical operational period for the network. The impact on consensus liveness, though temporary, could be severe during coordinated network-wide upgrades when multiple validators experience this simultaneously.

The vulnerability is particularly concerning because:
1. It affects consensus-critical message paths
2. It occurs during validator upgrades, a known stress point for distributed systems
3. The failure mode is silent (messages dropped without sender notification)
4. Current retry mechanisms may not fully mitigate the impact during high-frequency upgrade windows

### Citations

**File:** network/framework/src/application/storage.rs (L48-51)
```rust
    // but infrequent writes. The cache is updated on all underlying updates.
    //
    // TODO: should we remove this when generational versioning is supported?
    cached_peers_and_metadata: Arc<ArcSwap<HashMap<NetworkId, HashMap<PeerId, PeerMetadata>>>>,
```

**File:** network/framework/src/application/storage.rs (L151-169)
```rust
    pub fn get_metadata_for_peer(
        &self,
        peer_network_id: PeerNetworkId,
    ) -> Result<PeerMetadata, Error> {
        // Get the cached peers and metadata
        let cached_peers_and_metadata = self.cached_peers_and_metadata.load();

        // Fetch the peers and metadata for the given network
        let network_id = peer_network_id.network_id();
        let peer_metadata_for_network = cached_peers_and_metadata
            .get(&network_id)
            .ok_or_else(|| missing_network_metadata_error(&network_id))?;

        // Get the metadata for the peer
        peer_metadata_for_network
            .get(&peer_network_id.peer_id())
            .cloned()
            .ok_or_else(|| missing_peer_metadata_error(&peer_network_id))
    }
```

**File:** network/framework/src/application/storage.rs (L186-214)
```rust
    pub fn insert_connection_metadata(
        &self,
        peer_network_id: PeerNetworkId,
        connection_metadata: ConnectionMetadata,
    ) -> Result<(), Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Update the metadata for the peer or insert a new entry
        peer_metadata_for_network
            .entry(peer_network_id.peer_id())
            .and_modify(|peer_metadata| {
                peer_metadata.connection_metadata = connection_metadata.clone()
            })
            .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        let event =
            ConnectionNotification::NewPeer(connection_metadata, peer_network_id.network_id());
        self.broadcast(event);

        Ok(())
    }
```

**File:** network/framework/src/application/storage.rs (L319-326)
```rust
    /// Updates the cached peers and metadata using the given map
    fn set_cached_peers_and_metadata(
        &self,
        cached_peers_and_metadata: HashMap<NetworkId, HashMap<PeerId, PeerMetadata>>,
    ) {
        self.cached_peers_and_metadata
            .store(Arc::new(cached_peers_and_metadata));
    }
```

**File:** network/framework/src/application/interface.rs (L133-138)
```rust
    fn get_supported_protocols(&self, peer: &PeerNetworkId) -> Result<ProtocolIdSet, Error> {
        let peers_and_metadata = self.get_peers_and_metadata();
        peers_and_metadata
            .get_metadata_for_peer(*peer)
            .map(|peer_metadata| peer_metadata.get_supported_protocols())
    }
```

**File:** network/framework/src/application/interface.rs (L142-158)
```rust
    fn get_preferred_protocol_for_peer(
        &self,
        peer: &PeerNetworkId,
        preferred_protocols: &[ProtocolId],
    ) -> Result<ProtocolId, Error> {
        let protocols_supported_by_peer = self.get_supported_protocols(peer)?;
        for protocol in preferred_protocols {
            if protocols_supported_by_peer.contains(*protocol) {
                return Ok(*protocol);
            }
        }
        Err(Error::NetworkError(format!(
            "None of the preferred protocols are supported by this peer! \
            Peer: {:?}, supported protocols: {:?}",
            peer, protocols_supported_by_peer
        )))
    }
```

**File:** network/framework/src/application/interface.rs (L229-234)
```rust
    fn send_to_peer(&self, message: Message, peer: PeerNetworkId) -> Result<(), Error> {
        let network_sender = self.get_sender_for_network_id(&peer.network_id())?;
        let direct_send_protocol_id = self
            .get_preferred_protocol_for_peer(&peer, &self.direct_send_protocols_and_preferences)?;
        Ok(network_sender.send_to(peer.peer_id(), direct_send_protocol_id, message)?)
    }
```

**File:** network/framework/src/peer/mod.rs (L459-464)
```rust
                match self.upstream_handlers.get(&direct.protocol_id) {
                    None => {
                        counters::direct_send_messages(&self.network_context, UNKNOWN_LABEL).inc();
                        counters::direct_send_bytes(&self.network_context, UNKNOWN_LABEL)
                            .inc_by(data_len as u64);
                    },
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L45-75)
```rust
pub enum ProtocolId {
    ConsensusRpcBcs = 0,
    ConsensusDirectSendBcs = 1,
    MempoolDirectSend = 2,
    StateSyncDirectSend = 3,
    DiscoveryDirectSend = 4, // Currently unused
    HealthCheckerRpc = 5,
    ConsensusDirectSendJson = 6, // Json provides flexibility for backwards compatible upgrade
    ConsensusRpcJson = 7,
    StorageServiceRpc = 8,
    MempoolRpc = 9, // Currently unused
    PeerMonitoringServiceRpc = 10,
    ConsensusRpcCompressed = 11,
    ConsensusDirectSendCompressed = 12,
    NetbenchDirectSend = 13,
    NetbenchRpc = 14,
    DKGDirectSendCompressed = 15,
    DKGDirectSendBcs = 16,
    DKGDirectSendJson = 17,
    DKGRpcCompressed = 18,
    DKGRpcBcs = 19,
    DKGRpcJson = 20,
    JWKConsensusDirectSendCompressed = 21,
    JWKConsensusDirectSendBcs = 22,
    JWKConsensusDirectSendJson = 23,
    JWKConsensusRpcCompressed = 24,
    JWKConsensusRpcBcs = 25,
    JWKConsensusRpcJson = 26,
    ConsensusObserver = 27,
    ConsensusObserverRpc = 28,
}
```

**File:** network/framework/src/peer_manager/mod.rs (L684-687)
```rust
        self.peers_and_metadata.insert_connection_metadata(
            PeerNetworkId::new(self.network_context.network_id(), peer_id),
            conn_meta.clone(),
        )?;
```
