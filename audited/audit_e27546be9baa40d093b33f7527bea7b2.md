# Audit Report

## Title
Race Condition in Optimistic Fetch Request Handling Causes Lost Updates and Data Inconsistencies in State Sync

## Summary
A Time-of-Check-Time-of-Use (TOCTOU) race condition exists in the storage service's optimistic fetch handling mechanism. When concurrent optimistic fetch requests arrive from the same peer while background processing identifies ready fetches, the DashMap entry can be overwritten between identification and processing phases, causing lost fetch requests, mismatched epoch/version data delivery, and state synchronization failures.

## Finding Description

The storage service maintains optimistic fetch requests in a shared `DashMap<PeerNetworkId, OptimisticFetchRequest>` that is accessed concurrently by two critical code paths:

**Path 1 - Incoming network requests** (runs on blocking threads): [1](#0-0) 

When a new optimistic fetch request arrives, it uses `insert()` which unconditionally overwrites any existing entry for that peer.

**Path 2 - Background fetch processor** (runs periodically): [2](#0-1) 

The background processor identifies ready fetches, then later removes and processes them: [3](#0-2) 

The identification phase (lines 410-428) reads each peer's `highest_known_version` and `highest_known_epoch` from the DashMap and determines an appropriate `target_ledger_info` for each peer. This creates a list of ready fetches.

Later, the processing phase attempts to remove these entries: [4](#0-3) 

**The Race Condition:**

Between the identification phase (line 410) and the removal phase (line 275), a **new optimistic fetch request** can arrive for the same peer via `handle_optimistic_fetch_request`, which calls `insert()` and **overwrites** the old entry. When `remove_if` executes, it checks the **NEW** entry's `highest_known_version()` against the **OLD** `target_ledger_info` that was determined for the OLD entry.

**Attack Scenario - Epoch Boundary Mismatch:**

1. **T0**: Background processor identifies Peer X has fetch request with `known_version=100, known_epoch=5`
2. **T1**: Processor determines this peer is ready and calculates `target_ledger_info` = epoch ending ledger info for epoch 5 (version 200)
3. **T2**: Peer X sends NEW optimistic fetch request with `known_version=150, known_epoch=6` (peer advanced to new epoch)
4. **T3**: `handle_optimistic_fetch_request` calls `insert(Peer X, new_fetch)` - **overwrites** the old fetch
5. **T4**: `handle_ready_optimistic_fetches` calls `remove_if(Peer X, |fetch| fetch.highest_known_version() < 200)`
6. **T5**: Checks the NEW fetch: `150 < 200` = TRUE, removes and processes it
7. **T6**: Processes NEW fetch (epoch 6, version 150) using OLD target (epoch 5 ending ledger info, version 200)

The code then creates a storage request with mismatched epoch parameters: [5](#0-4) 

This causes data for epoch 6 to be packaged with proof information from epoch 5's ending, leading to verification failures on the client side.

**Attack Scenario - Lost Updates:**

If the NEW request has `known_version > target_version` (e.g., 250 > 200):
- The `remove_if` condition fails (250 < 200 = FALSE)  
- The NEW request is NOT removed
- The OLD request (version 100) is completely lost - never processed
- The NEW request remains in the map but won't be ready until synced_version > 250

## Impact Explanation

This vulnerability constitutes **High Severity** based on the Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: State synchronization is critical for validator nodes to maintain consensus. Failed or stalled optimistic fetches cause repeated timeouts and retries, degrading performance and potentially causing validators to fall behind.

2. **Significant Protocol Violations**: The state sync protocol's integrity is violated when:
   - Fetch requests are silently dropped (never completed)
   - Data is delivered with incorrect epoch/version proof information
   - Clients receive data that fails cryptographic verification

3. **State Inconsistencies**: Nodes relying on optimistic fetches to catch up may:
   - Experience repeated verification failures
   - Fall behind on state synchronization
   - Require manual intervention to recover

The vulnerability specifically breaks the **State Consistency** invariant: state sync data must be delivered reliably with correct proof information. It also impacts the **Deterministic Execution** invariant by potentially causing different nodes to have different views of the chain state during synchronization.

## Likelihood Explanation

**Likelihood: HIGH**

This race condition occurs naturally during normal network operations:

1. **Frequent Trigger**: The background processor runs on a timer [6](#0-5)  with the refresh interval creating constant race windows.

2. **No Attacker Privilege Required**: Any network peer can send optimistic fetch requests. No special permissions or validator access needed.

3. **Timing Window**: The race window exists for the entire duration between identifying ready fetches (potentially spawning multiple async tasks that could take milliseconds) and removing them. This is a substantial window where concurrent requests commonly arrive.

4. **Client Behavior**: Legitimate clients may naturally send updated optimistic fetch requests as they incrementally sync, making this race condition trigger during normal operations, not just under attack.

5. **No Rate Limiting**: While the code logs when an existing fetch is found [7](#0-6) , the `insert()` still proceeds, making the race consistently exploitable.

## Recommendation

**Implement atomic fetch-and-process pattern using DashMap's entry API:**

Replace the two-phase identify-then-remove pattern with an atomic operation that processes each fetch without a race window. Specifically:

1. **Use `entry()` API for atomic operations**: Instead of iterating to identify ready fetches and later removing them, use `entry().and_modify()` or `remove_if()` atomically within the same critical section where readiness is checked.

2. **Add sequence numbers**: Include a sequence number or generation counter in `OptimisticFetchRequest` that is incremented on each insert. Store this sequence number when identifying ready fetches, and only process if the sequence number matches during removal. This prevents processing with stale metadata.

3. **Lock-based coordination**: Add a per-peer mutex or use DashMap's `Entry` API to ensure that once a fetch is identified as ready, no new inserts can occur for that peer until processing completes.

**Example fix outline:**

```rust
// In handle_ready_optimistic_fetches, use atomic remove_if with freshness check
let ready_optimistic_fetch = optimistic_fetches.remove_if(
    &peer_network_id, 
    |_, optimistic_fetch| {
        // Check both version condition AND that metadata still matches
        let known_version = optimistic_fetch.highest_known_version();
        let known_epoch = optimistic_fetch.highest_known_epoch();
        
        // Only remove if version is lower AND epoch matches what we expected
        known_version < target_ledger_info.ledger_info().version()
            && known_epoch == expected_epoch_for_this_target
    }
);
```

Alternatively, add generation tracking:
```rust
pub struct OptimisticFetchRequest {
    request: StorageServiceRequest,
    response_sender: ResponseSender,
    fetch_start_time: Instant,
    time_service: TimeService,
    generation: u64,  // Incremented on each insert
}
```

## Proof of Concept

```rust
#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
async fn test_optimistic_fetch_race_condition() {
    use std::sync::Arc;
    use dashmap::DashMap;
    use tokio::time::{sleep, Duration};
    
    // Setup: Simulate the race condition
    let optimistic_fetches = Arc::new(DashMap::new());
    let peer_id = PeerNetworkId::random();
    
    // Insert initial fetch request (known_version=100, known_epoch=5)
    let initial_fetch = OptimisticFetchRequest::new(
        create_request(100, 5),
        response_sender_1,
        time_service.clone(),
    );
    optimistic_fetches.insert(peer_id, initial_fetch);
    
    // Simulate background processor identifying ready fetches
    let processor_fetches = optimistic_fetches.clone();
    let processor_peer = peer_id;
    let processor_task = tokio::spawn(async move {
        // Phase 1: Identify ready fetches (simulate delay)
        let fetch = processor_fetches.get(&processor_peer).unwrap();
        let known_version = fetch.highest_known_version(); // Reads 100
        let target_version = 200u64;
        drop(fetch); // Release read lock
        
        // Simulate processing delay (race window)
        sleep(Duration::from_millis(50)).await;
        
        // Phase 2: Remove and process
        let removed = processor_fetches.remove_if(&processor_peer, |_, f| {
            f.highest_known_version() < target_version
        });
        
        (removed.is_some(), removed.map(|(_, f)| f.highest_known_version()))
    });
    
    // Simulate concurrent new request arriving (known_version=150, known_epoch=6)
    let concurrent_fetches = optimistic_fetches.clone();
    let concurrent_peer = peer_id;
    let concurrent_task = tokio::spawn(async move {
        sleep(Duration::from_millis(25)).await; // Arrive during race window
        
        let new_fetch = OptimisticFetchRequest::new(
            create_request(150, 6), // NEW epoch!
            response_sender_2,
            time_service.clone(),
        );
        
        // This overwrites the entry
        let old_value = concurrent_fetches.insert(concurrent_peer, new_fetch);
        old_value.is_some() // Returns true - overwrote old fetch
    });
    
    // Wait for both tasks
    let (removed, version_processed) = processor_task.await.unwrap();
    let was_overwritten = concurrent_task.await.unwrap();
    
    // Assertions demonstrating the race condition:
    assert!(was_overwritten, "Old fetch should have been overwritten");
    assert!(removed, "Entry should have been removed");
    assert_eq!(version_processed, Some(150), "NEW fetch (v150) was processed");
    
    // The problem: We processed the NEW fetch (epoch 6, version 150) 
    // with target_ledger_info intended for OLD fetch (epoch 5, version 200)
    // This causes epoch mismatch and verification failures!
}
```

**Notes:**

The race condition is inherent in the two-phase design where identification and processing are separated by asynchronous task spawning and DashMap operations. The code comment at line 271-273 acknowledges concurrent updates but doesn't prevent the resulting data inconsistencies. This vulnerability affects all nodes using the storage service's optimistic fetch mechanism for state synchronization, making it a systemic issue requiring immediate remediation.

### Citations

**File:** state-sync/storage-service/server/src/handler.rs (L256-260)
```rust
        // Store the optimistic fetch and check if any existing fetches were found
        if self
            .optimistic_fetches
            .insert(peer_network_id, optimistic_fetch)
            .is_some()
```

**File:** state-sync/storage-service/server/src/handler.rs (L262-271)
```rust
            sample!(
                SampleRate::Duration(Duration::from_secs(ERROR_LOG_FREQUENCY_SECS)),
                trace!(LogSchema::new(LogEntry::OptimisticFetchRequest)
                    .error(&Error::InvalidRequest(
                        "An active optimistic fetch was already found for the peer!".into()
                    ))
                    .peer_network_id(&peer_network_id)
                    .request(&request)
                );
            );
```

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L100-141)
```rust
        // Create the storage request
        let data_request = match &self.request.data_request {
            DataRequest::GetNewTransactionOutputsWithProof(_) => {
                DataRequest::GetTransactionOutputsWithProof(TransactionOutputsWithProofRequest {
                    proof_version: target_version,
                    start_version,
                    end_version,
                })
            },
            DataRequest::GetNewTransactionsWithProof(request) => {
                DataRequest::GetTransactionsWithProof(TransactionsWithProofRequest {
                    proof_version: target_version,
                    start_version,
                    end_version,
                    include_events: request.include_events,
                })
            },
            DataRequest::GetNewTransactionsOrOutputsWithProof(request) => {
                DataRequest::GetTransactionsOrOutputsWithProof(
                    TransactionsOrOutputsWithProofRequest {
                        proof_version: target_version,
                        start_version,
                        end_version,
                        include_events: request.include_events,
                        max_num_output_reductions: request.max_num_output_reductions,
                    },
                )
            },
            DataRequest::GetNewTransactionDataWithProof(request) => {
                DataRequest::GetTransactionDataWithProof(GetTransactionDataWithProofRequest {
                    transaction_data_request_type: request.transaction_data_request_type,
                    proof_version: target_version,
                    start_version,
                    end_version,
                    max_response_bytes: request.max_response_bytes,
                })
            },
            request => unreachable!("Unexpected optimistic fetch request: {:?}", request),
        };
        let storage_request =
            StorageServiceRequest::new(data_request, self.request.use_compression);
        Ok(storage_request)
```

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L210-254)
```rust
pub(crate) async fn handle_active_optimistic_fetches<T: StorageReaderInterface>(
    runtime: Handle,
    cached_storage_server_summary: Arc<ArcSwap<StorageServerSummary>>,
    config: StorageServiceConfig,
    optimistic_fetches: Arc<DashMap<PeerNetworkId, OptimisticFetchRequest>>,
    lru_response_cache: Cache<StorageServiceRequest, StorageServiceResponse>,
    request_moderator: Arc<RequestModerator>,
    storage: T,
    subscriptions: Arc<DashMap<PeerNetworkId, SubscriptionStreamRequests>>,
    time_service: TimeService,
) -> Result<(), Error> {
    // Update the number of active optimistic fetches
    update_optimistic_fetch_metrics(optimistic_fetches.clone());

    // Identify the peers with ready optimistic fetches
    let peers_with_ready_optimistic_fetches = get_peers_with_ready_optimistic_fetches(
        runtime.clone(),
        config,
        cached_storage_server_summary.clone(),
        optimistic_fetches.clone(),
        lru_response_cache.clone(),
        request_moderator.clone(),
        storage.clone(),
        subscriptions.clone(),
        time_service.clone(),
    )
    .await?;

    // Remove and handle the ready optimistic fetches
    handle_ready_optimistic_fetches(
        runtime,
        cached_storage_server_summary,
        config,
        optimistic_fetches,
        lru_response_cache,
        request_moderator,
        storage,
        subscriptions,
        time_service,
        peers_with_ready_optimistic_fetches,
    )
    .await;

    Ok(())
}
```

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L274-278)
```rust
        let ready_optimistic_fetch =
            optimistic_fetches.remove_if(&peer_network_id, |_, optimistic_fetch| {
                optimistic_fetch.highest_known_version()
                    < target_ledger_info.ledger_info().version()
            });
```

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L407-429)
```rust
    // Gather the highest synced version and epoch for each peer
    let mut peers_and_highest_synced_data = HashMap::new();
    let mut peers_with_expired_optimistic_fetches = vec![];
    for optimistic_fetch in optimistic_fetches.iter() {
        // Get the peer and the optimistic fetch request
        let peer_network_id = *optimistic_fetch.key();
        let optimistic_fetch = optimistic_fetch.value();

        // Gather the peer's highest synced version and epoch
        if !optimistic_fetch.is_expired(config.max_optimistic_fetch_period_ms) {
            let highest_known_version = optimistic_fetch.highest_known_version();
            let highest_known_epoch = optimistic_fetch.highest_known_epoch();

            // Save the peer's version and epoch
            peers_and_highest_synced_data.insert(
                peer_network_id,
                (highest_known_version, highest_known_epoch),
            );
        } else {
            // The request has expired -- there's nothing to do
            peers_with_expired_optimistic_fetches.push(peer_network_id);
        }
    }
```

**File:** state-sync/storage-service/server/src/lib.rs (L243-252)
```rust
                let duration = Duration::from_millis(config.storage_summary_refresh_interval_ms);
                let ticker = time_service.interval(duration);
                futures::pin_mut!(ticker);

                // Continuously handle the optimistic fetches
                loop {
                    futures::select! {
                        _ = ticker.select_next_some() => {
                            // Handle the optimistic fetches periodically
                            handle_active_optimistic_fetches(
```
