# Audit Report

## Title
Unbounded Per-Peer Request Spawning Allows Byzantine Peer to Exhaust Storage Service Thread Pool and Cause Validator Slowdown

## Summary
A Byzantine peer can cause validator slowdown by rapidly sending alternating valid subscription and one-off requests to the storage service. Each request spawns a blocking task without per-peer concurrency limits, allowing a single malicious peer to monopolize the shared 64-thread pool, causing legitimate peer requests to queue or timeout and degrading validator consensus participation.

## Finding Description

The storage service processes incoming network requests by spawning a blocking task for each request. [1](#0-0) 

The request handler differentiates between subscription requests and one-off requests, routing them to different handlers. [2](#0-1) 

Subscription requests update state in a shared `DashMap<PeerNetworkId, SubscriptionStreamRequests>` data structure, acquiring locks during updates. [3](#0-2) 

One-off requests immediately read from storage and respond. [4](#0-3) 

The runtime has a hard limit of 64 blocking threads. [5](#0-4) 

**Critical Missing Protections:**

1. The `RequestModerator` only tracks and limits **invalid** requests per peer (default 500), not valid requests. [6](#0-5) 

2. The subscription limit (30 active per peer) only applies to subscription requests, not one-off requests. [7](#0-6) 

3. Network-level inbound rate limiting is **disabled by default**. [8](#0-7) 

4. There is **no per-peer concurrency limit** on valid requests - all peers share the same 64 blocking thread pool.

**Attack Execution:**

A Byzantine peer can:
1. Connect to a validator's storage service
2. Rapidly send alternating valid requests:
   - Subscription requests (defined in requests.rs) that create/update DashMap state
   - One-off Get requests (e.g., `GetTransactionsWithProof`, `GetStorageServerSummary`) that read from storage [9](#0-8) 

3. Each request spawns a blocking task, consuming thread pool capacity
4. Subscription requests cause lock contention on the shared DashMap
5. One-off requests force repeated storage reads
6. The 64-thread limit is reached, causing legitimate peer requests to queue
7. Validator experiences slowdown affecting consensus participation

The attack bypasses existing protections because:
- Both request types can be **valid** (won't trigger the invalid request counter)
- The attacker can stay under the 30 subscription limit while sending unlimited one-off requests
- No rate limit exists on the frequency of valid requests
- No per-peer concurrency control prevents thread pool monopolization

## Impact Explanation

This vulnerability qualifies as **HIGH severity** per the Aptos bug bounty program's explicit category: "Validator node slowdowns".

**Concrete Impact:**
- **Validator Performance Degradation**: The validator's storage service becomes unresponsive or severely delayed for all peers
- **Consensus Participation Affected**: State sync delays can prevent validators from keeping up with the chain, affecting their ability to vote on blocks
- **Denial of Service to Legitimate Peers**: Other peers attempting to sync state experience timeouts and failures
- **Network-Wide Impact**: If multiple validators are attacked simultaneously, the network's overall state sync capability is compromised

**Severity Justification:**
- Causes measurable validator slowdown (explicit HIGH severity category)
- Single attacker can impact multiple validators
- Affects critical validator operations (state synchronization)
- No recovery mechanism without disconnecting the malicious peer
- Can be sustained indefinitely with minimal attacker resources

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements:**
- Ability to connect to a validator's storage service (standard P2P connection)
- No special privileges or validator access needed
- Minimal computational resources (sending requests is cheap)

**Attack Complexity: LOW**
- Simple to execute: rapidly send alternating valid subscription and one-off requests
- No cryptographic operations or complex protocol manipulation required
- Attack can be automated with a basic script
- No timing dependencies or race conditions to exploit

**Detection Difficulty:**
- Requests appear valid (pass all validation checks)
- Attacker can rotate between different valid request types
- Difficult to distinguish from legitimate heavy users
- No clear signature of malicious behavior

**Attack Persistence:**
- Can be sustained indefinitely
- Attacker can reconnect if disconnected
- Multiple attackers can amplify the effect

## Recommendation

**Implement Per-Peer Concurrency Limits:**

1. **Add per-peer request concurrency tracking** in the storage service:

```rust
// In lib.rs, add to StorageServiceServer
struct PerPeerState {
    active_requests: Arc<AtomicUsize>,
}

// Track active requests per peer
let peer_states: Arc<DashMap<PeerNetworkId, PerPeerState>> = Arc::new(DashMap::new());

// In the request handling loop (lib.rs ~401), before spawning:
let peer_state = peer_states.entry(network_request.peer_network_id)
    .or_insert_with(|| PerPeerState {
        active_requests: Arc::new(AtomicUsize::new(0)),
    });

let active_count = peer_state.active_requests.fetch_add(1, Ordering::SeqCst);
if active_count >= config.max_concurrent_requests_per_peer {
    // Reject request or apply backpressure
    peer_state.active_requests.fetch_sub(1, Ordering::SeqCst);
    response_sender.send(Err(StorageServiceError::TooManyRequests));
    continue;
}

// Wrap the spawn_blocking to decrement on completion
let active_requests = peer_state.active_requests.clone();
self.runtime.spawn_blocking(move || {
    // ... handle request ...
    active_requests.fetch_sub(1, Ordering::SeqCst);
});
```

2. **Add configuration parameter** to `StorageServiceConfig`:

```rust
// In state_sync_config.rs
pub struct StorageServiceConfig {
    // ... existing fields ...
    /// Maximum number of concurrent requests per peer
    pub max_concurrent_requests_per_peer: u64,
}

impl Default for StorageServiceConfig {
    fn default() -> Self {
        Self {
            // ... existing defaults ...
            max_concurrent_requests_per_peer: 10, // Reasonable limit
        }
    }
}
```

3. **Add request rate limiting** as a secondary defense:

```rust
// Track request timestamps per peer
struct RequestRateState {
    recent_requests: Mutex<VecDeque<Instant>>,
}

// In validation, check request rate
let now = time_service.now();
let mut recent = rate_state.recent_requests.lock();
recent.retain(|&t| now.duration_since(t).as_secs() < 1);
if recent.len() >= config.max_requests_per_second_per_peer {
    return Err(Error::TooManyRequests);
}
recent.push_back(now);
```

4. **Implement priority queuing** to protect legitimate validator peers over public fullnode peers.

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[tokio::test]
async fn test_byzantine_peer_thread_pool_exhaustion() {
    use std::sync::Arc;
    use tokio::time::{sleep, Duration};
    use aptos_storage_service_types::requests::{DataRequest, StorageServiceRequest};
    
    // Setup: Create storage service with 64 thread limit
    let runtime = tokio::runtime::Builder::new_multi_thread()
        .max_blocking_threads(64)
        .build()
        .unwrap();
    
    // Create a Byzantine peer ID
    let byzantine_peer = PeerNetworkId::new(NetworkId::Public, PeerId::random());
    
    // Attack: Send rapid alternating requests
    let attack_handles = (0..100).map(|i| {
        let peer = byzantine_peer.clone();
        runtime.spawn(async move {
            let request = if i % 2 == 0 {
                // Subscription request
                StorageServiceRequest::new(
                    DataRequest::SubscribeTransactionsWithProof(
                        SubscribeTransactionsWithProofRequest {
                            subscription_stream_metadata: SubscriptionStreamMetadata {
                                known_version_at_stream_start: 0,
                                known_epoch_at_stream_start: 0,
                                subscription_stream_id: i,
                            },
                            subscription_stream_index: 0,
                            include_events: false,
                        }
                    ),
                    false
                )
            } else {
                // One-off request
                StorageServiceRequest::new(
                    DataRequest::GetStorageServerSummary,
                    false
                )
            };
            
            // Send request (simulated)
            send_storage_request(peer, request).await
        })
    }).collect::<Vec<_>>();
    
    // Attempt legitimate request from different peer
    sleep(Duration::from_millis(100)).await;
    
    let legitimate_peer = PeerNetworkId::new(NetworkId::Validator, PeerId::random());
    let start = Instant::now();
    let result = send_storage_request_with_timeout(
        legitimate_peer,
        StorageServiceRequest::new(DataRequest::GetStorageServerSummary, false),
        Duration::from_secs(5)
    ).await;
    
    let elapsed = start.elapsed();
    
    // Verify: Legitimate request is severely delayed or times out
    assert!(
        result.is_err() || elapsed > Duration::from_secs(2),
        "Byzantine peer attack did not cause slowdown. Elapsed: {:?}",
        elapsed
    );
    
    println!("Attack successful: Legitimate request delayed by {:?}", elapsed);
}
```

**Reproduction Steps:**
1. Deploy a validator node with default storage service configuration
2. Connect as a peer from a controlled machine
3. Send 100 rapid alternating subscription and one-off requests (valid but rapid)
4. Observe validator's storage service response times increase dramatically
5. Observe legitimate peer requests timeout or experience >2 second delays
6. Monitor CPU usage showing context-switching overhead and thread pool saturation

**Expected Result:** Validator experiences measurable slowdown, affecting its ability to serve state sync requests and potentially impacting consensus participation.

## Notes

This vulnerability exists because the storage service lacks per-peer resource isolation. While the request moderator protects against invalid requests, it does not limit the rate or concurrency of valid requests from a single peer. The shared 64-thread blocking pool becomes a bottleneck that a single Byzantine peer can exploit.

The impact is compounded by:
- Lock contention on the subscription DashMap during rapid subscription updates
- Repeated storage I/O for one-off requests
- Context-switching overhead between many blocking tasks
- Queue buildup when thread pool is saturated

**Additional Context:**
The network channel buffer of 4000 messages provides some backpressure, but once messages enter the handler, there is no per-peer throttling before spawning blocking tasks. The attack works because request validation (moderator) and request processing (blocking tasks) occur in separate stages without per-peer concurrency tracking between them.

### Citations

**File:** state-sync/storage-service/server/src/lib.rs (L389-419)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/server/src/handler.rs (L120-139)
```rust
        if request.data_request.is_optimistic_fetch() {
            self.handle_optimistic_fetch_request(peer_network_id, request, response_sender);
            return;
        }

        // Handle any subscription requests
        if request.data_request.is_subscription_request() {
            self.handle_subscription_request(
                storage_service_config,
                peer_network_id,
                request,
                response_sender,
            );
            return;
        }

        // Process the request and return the response to the client
        let response = self.process_request(&peer_network_id, request.clone(), false);
        self.send_response(request, response, response_sender);
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L302-349)
```rust
        let subscription_stream_entry = self.subscriptions.entry(peer_network_id);

        // If the entry is empty, or the stream ID does not match the request ID,
        // create a new subscription stream for the peer. Otherwise, add the
        // request to the existing stream (the stream IDs match!).
        match subscription_stream_entry {
            Entry::Occupied(mut occupied_entry) => {
                // If the stream has a different ID than the request, replace the stream.
                // Otherwise, add the request to the existing stream.
                let existing_stream_id = occupied_entry.get().subscription_stream_id();
                if existing_stream_id != request_stream_id {
                    // Create a new subscription stream for the peer
                    let subscription_stream = SubscriptionStreamRequests::new(
                        subscription_request,
                        self.time_service.clone(),
                    );
                    occupied_entry.replace_entry(subscription_stream);

                    // Update the subscription metrics
                    update_created_stream_metrics(&peer_network_id);
                } else {
                    // Add the request to the existing stream
                    if let Err((error, subscription_request)) = occupied_entry
                        .get_mut()
                        .add_subscription_request(storage_service_config, subscription_request)
                    {
                        // Handle the subscription failure
                        self.handle_subscription_request_failure(
                            peer_network_id,
                            request,
                            error,
                            subscription_request,
                        );
                    }
                }
            },
            Entry::Vacant(vacant_entry) => {
                // Create a new subscription stream for the peer
                let subscription_stream = SubscriptionStreamRequests::new(
                    subscription_request,
                    self.time_service.clone(),
                );
                vacant_entry.insert(subscription_stream);

                // Update the subscription metrics
                update_created_stream_metrics(&peer_network_id);
            },
        }
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** config/src/config/state_sync_config.rs (L163-164)
```rust
    /// Maximum number of invalid requests per peer
    pub max_invalid_requests_per_peer: u64,
```

**File:** config/src/config/state_sync_config.rs (L173-174)
```rust
    /// Maximum number of active subscriptions (per peer)
    pub max_num_active_subscriptions: u64,
```

**File:** config/src/config/network_config.rs (L158-159)
```rust
            inbound_rate_limit_config: None,
            outbound_rate_limit_config: None,
```

**File:** state-sync/storage-service/types/src/requests.rs (L35-56)
```rust
pub enum DataRequest {
    GetEpochEndingLedgerInfos(EpochEndingLedgerInfoRequest), // Fetches a list of epoch ending ledger infos
    GetNewTransactionOutputsWithProof(NewTransactionOutputsWithProofRequest), // Optimistically fetches new transaction outputs
    GetNewTransactionsWithProof(NewTransactionsWithProofRequest), // Optimistically fetches new transactions
    GetNumberOfStatesAtVersion(Version), // Fetches the number of states at the specified version
    GetServerProtocolVersion,            // Fetches the protocol version run by the server
    GetStateValuesWithProof(StateValuesWithProofRequest), // Fetches a list of states with a proof
    GetStorageServerSummary,             // Fetches a summary of the storage server state
    GetTransactionOutputsWithProof(TransactionOutputsWithProofRequest), // Fetches a list of transaction outputs with a proof
    GetTransactionsWithProof(TransactionsWithProofRequest), // Fetches a list of transactions with a proof
    GetNewTransactionsOrOutputsWithProof(NewTransactionsOrOutputsWithProofRequest), // Optimistically fetches new transactions or outputs
    GetTransactionsOrOutputsWithProof(TransactionsOrOutputsWithProofRequest), // Fetches a list of transactions or outputs with a proof
    SubscribeTransactionOutputsWithProof(SubscribeTransactionOutputsWithProofRequest), // Subscribes to transaction outputs with a proof
    SubscribeTransactionsOrOutputsWithProof(SubscribeTransactionsOrOutputsWithProofRequest), // Subscribes to transactions or outputs with a proof
    SubscribeTransactionsWithProof(SubscribeTransactionsWithProofRequest), // Subscribes to transactions with a proof

    // All the requests listed below are for transaction data v2 (i.e., transactions with auxiliary information).
    // TODO: eventually we should deprecate all the old request types.
    GetTransactionDataWithProof(GetTransactionDataWithProofRequest), // Fetches transaction data with a proof
    GetNewTransactionDataWithProof(GetNewTransactionDataWithProofRequest), // Optimistically fetches new transaction data with a proof
    SubscribeTransactionDataWithProof(SubscribeTransactionDataWithProofRequest), // Subscribes to transaction data with a proof
}
```
