# Audit Report

## Title
Storage Leak Due to Incomplete Schema Migration Between StaleStateValueIndexSchema and StaleStateValueIndexByKeyHashSchema

## Summary
When migrating from non-sharded to sharded storage by enabling `enable_storage_sharding`, stale state value index entries and their associated state values in the old `StaleStateValueIndexSchema` are never pruned, leading to unbounded storage accumulation.

## Finding Description

The Aptos storage layer supports two different schemas for tracking stale state values ready for pruning:

1. **StaleStateValueIndexSchema**: Uses full `StateKey` in the index key [1](#0-0) 
2. **StaleStateValueIndexByKeyHashSchema**: Uses `state_key_hash` (HashValue) instead [2](#0-1) 

These schemas reside in different column families and are selected based on the `enable_storage_sharding` configuration flag [3](#0-2) 

**The Vulnerability:**

During index writes, the system chooses which schema to use based on the `enable_sharding` parameter [4](#0-3) 

However, during pruning, the `StateKvMetadataPruner` conditionally processes schemas: when sharding is enabled, it only iterates (does not delete) from the sharded indices, while actual deletion happens in `StateKvShardPruner` instances [5](#0-4) 

**Migration Scenario:**

For mainnet/testnet, the configuration enforces that `enable_storage_sharding` must be explicitly set to `true` [6](#0-5) , indicating a mandatory migration path from non-sharded to sharded mode.

During migration:
1. Pre-migration: Indices written to `StaleStateValueIndexSchema`, values to `StateValueSchema`
2. Post-migration: Indices written to `StaleStateValueIndexByKeyHashSchema`, values to `StateValueByKeyHashSchema`
3. **Pruning only targets the new schema** - old entries are never deleted

The `StateKvShardPruner` only deletes from `StaleStateValueIndexByKeyHashSchema` [7](#0-6) 

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria due to:
- **Validator node slowdowns**: Accumulated unpruned data degrades database performance over time
- **Storage exhaustion**: Unbounded growth can lead to disk space exhaustion, causing node failures
- **Operational impact**: Affects all nodes that perform the mandatory sharding migration

While not directly exploitable by external attackers, this breaks the **Resource Limits** invariant (#9) where storage operations should respect limits, and violates the **State Consistency** invariant (#4) by leaving orphaned data that cannot be garbage collected.

## Likelihood Explanation

**High likelihood** for affected nodes:
- All mainnet/testnet nodes **must** enable sharding per configuration enforcement
- The migration is mandatory and one-way
- Every node performing this migration will accumulate unpruned old-schema entries
- No cleanup mechanism exists in the codebase for the old schema post-migration

## Recommendation

Implement a migration cleanup mechanism that:

1. **Add a one-time migration cleanup function**:
   - After enabling sharding, scan and delete all entries from `StaleStateValueIndexSchema`
   - Delete corresponding entries from `StateValueSchema`
   - Track cleanup progress in metadata to handle interruptions

2. **Modify `StateKvMetadataPruner::prune()` to handle both schemas during transition period**:
   - Check for existence of old schema entries
   - If found, prune from both old and new schemas
   - After confirming old schema is empty, switch to new schema only

3. **Add migration validation**: Verify old schema is empty before considering migration complete

The fix should add dual-schema pruning support during the transition: [5](#0-4) 

## Proof of Concept

**Reproduction Steps:**

1. Initialize a node with `enable_storage_sharding = false`
2. Run transactions to generate state updates and stale values (entries written to `StaleStateValueIndexSchema`)
3. Wait for pruner to run (verify entries are being pruned from old schema)
4. Change configuration to `enable_storage_sharding = true` and restart node
5. Generate more state updates (new entries written to `StaleStateValueIndexByKeyHashSchema`)
6. Wait for pruner to run again
7. **Verify**: Query both column families:
   - `StaleStateValueIndexSchema` still contains old entries (never pruned)
   - `StaleStateValueIndexByKeyHashSchema` is being pruned correctly
   - Storage continues growing due to accumulated old entries

**Database Query to Verify:**
```rust
// Pseudocode to demonstrate the issue
let old_schema_count = db.iter::<StaleStateValueIndexSchema>().count();
let new_schema_count = db.iter::<StaleStateValueIndexByKeyHashSchema>().count();
// old_schema_count will remain non-zero and grow over time
```

## Notes

While index entries are **missed** during pruning (not double-counted), the security question is answered: entries are definitively missed during the migration transition. However, this vulnerability requires operator configuration changes (trusted actor) rather than external attacker exploitation, which may affect its classification under the bug bounty program's "exploitable by unprivileged attacker" requirement.

### Citations

**File:** storage/aptosdb/src/schema/stale_state_value_index/mod.rs (L13-16)
```rust
//! ```text
//! |<-------------------key------------------->|
//! | stale_since_version | version | state_key |
//! ```
```

**File:** storage/aptosdb/src/schema/stale_state_value_index_by_key_hash/mod.rs (L13-16)
```rust
//! ```text
//! |<-------------------key------------------------>|
//! | stale_since_version | version | state_key_hash |
//! ```
```

**File:** storage/aptosdb/src/schema/mod.rs (L52-54)
```rust
pub const STALE_STATE_VALUE_INDEX_CF_NAME: ColumnFamilyName = "stale_state_value_index";
pub const STALE_STATE_VALUE_INDEX_BY_KEY_HASH_CF_NAME: ColumnFamilyName =
    "stale_state_value_index_by_key_hash";
```

**File:** storage/aptosdb/src/state_store/mod.rs (L985-1015)
```rust
    fn put_state_kv_index(
        batch: &mut NativeBatch,
        enable_sharding: bool,
        stale_since_version: Version,
        version: Version,
        key: &StateKey,
    ) {
        if enable_sharding {
            batch
                .put::<StaleStateValueIndexByKeyHashSchema>(
                    &StaleStateValueByKeyHashIndex {
                        stale_since_version,
                        version,
                        state_key_hash: key.hash(),
                    },
                    &(),
                )
                .unwrap();
        } else {
            batch
                .put::<StaleStateValueIndexSchema>(
                    &StaleStateValueIndex {
                        stale_since_version,
                        version,
                        state_key: (*key).clone(),
                    },
                    &(),
                )
                .unwrap();
        }
    }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L28-73)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        if self.state_kv_db.enabled_sharding() {
            let num_shards = self.state_kv_db.num_shards();
            // NOTE: This can be done in parallel if it becomes the bottleneck.
            for shard_id in 0..num_shards {
                let mut iter = self
                    .state_kv_db
                    .db_shard(shard_id)
                    .iter::<StaleStateValueIndexByKeyHashSchema>()?;
                iter.seek(&current_progress)?;
                for item in iter {
                    let (index, _) = item?;
                    if index.stale_since_version > target_version {
                        break;
                    }
                }
            }
        } else {
            let mut iter = self
                .state_kv_db
                .metadata_db()
                .iter::<StaleStateValueIndexSchema>()?;
            iter.seek(&current_progress)?;
            for item in iter {
                let (index, _) = item?;
                if index.stale_since_version > target_version {
                    break;
                }
                batch.delete::<StaleStateValueIndexSchema>(&index)?;
                batch.delete::<StateValueSchema>(&(index.state_key, index.version))?;
            }
        }

        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        self.state_kv_db.metadata_db().write_schemas(batch)
    }
```

**File:** config/src/config/storage_config.rs (L664-668)
```rust
            if (chain_id.is_testnet() || chain_id.is_mainnet())
                && config_yaml["rocksdb_configs"]["enable_storage_sharding"].as_bool() != Some(true)
            {
                panic!("Storage sharding (AIP-97) is not enabled in node config. Please follow the guide to migration your node, and set storage.rocksdb_configs.enable_storage_sharding to true explicitly in your node config. https://aptoslabs.notion.site/DB-Sharding-Migration-Public-Full-Nodes-1978b846eb7280b29f17ceee7d480730");
            }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L47-72)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
            &DbMetadataValue::Version(target_version),
        )?;

        self.db_shard.write_schemas(batch)
    }
```
