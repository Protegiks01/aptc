# Audit Report

## Title
Unvalidated Transaction Type Field Causes Panic in Indexer-gRPC Data Service v2

## Summary
The `fetch_and_update_cache()` function in the indexer-grpc data service v2 caches Transaction protobuf objects without validating their well-formedness. When consumers attempt to read cached transactions using a `TransactionRootFilter` with a transaction type filter, malformed `type` field values cause a panic, crashing the data service.

## Finding Description

The indexer-grpc data service v2 fetches Transaction objects from upstream gRPC services and caches them for consumers. The vulnerability exists in the data flow through three key components:

1. **Fetching without validation**: [1](#0-0) 

   The `fetch_and_update_cache()` function retrieves transactions and directly caches them without any validation of protobuf field values.

2. **Caching malformed data**: [2](#0-1) 

   The `update_data()` method stores transactions in the cache without validating the `type` field or any other protobuf fields for well-formedness.

3. **Panic during consumption**: [3](#0-2) 

   When consumers request data with a `TransactionRootFilter` that checks transaction type, the code calls `.expect()` on a `try_from()` conversion that can fail for invalid type values.

The Transaction protobuf definition shows that the `type` field is an `i32`: [4](#0-3) 

The TransactionType enum only accepts specific values (0, 1, 2, 3, 4, 20, 21), with values 5-19 explicitly skipped: [5](#0-4) 

**Attack Scenario:**
1. A malicious or buggy upstream gRPC service sends Transaction objects with invalid `type` field values (e.g., 5, 6, 7, ..., 19, or any value outside valid enum range)
2. These malformed transactions are fetched and cached without validation
3. A consumer requests transactions with a `TransactionRootFilter` that has `txn_type` set
4. The filter's `matches()` method is invoked on the cached transaction: [6](#0-5) 
5. The `TransactionType::try_from(item.r#type).expect()` call panics, crashing the service

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty program criteria:
- **API crashes**: The indexer-grpc data service v2 will panic and crash when processing malformed transactions
- **Service disruption**: The service requires restart, and the same malformed data will continue causing crashes
- **No privileged access required**: Any upstream gRPC service (malicious or buggy) can trigger this vulnerability
- **Wide impact**: All consumers using transaction type filters will be affected

This breaks the service availability invariant and constitutes a denial-of-service vulnerability against the indexer infrastructure.

## Likelihood Explanation

**Likelihood: Medium to High**

- **Easy to trigger**: Simply sending protobuf data with an invalid transaction type value (any i32 outside the valid enum range)
- **No authentication bypass needed**: The malformed data flows through normal gRPC channels
- **Realistic scenarios**:
  - Compromised upstream gRPC service
  - Software bugs in transaction generation
  - Protocol version mismatches
  - Intentional DoS attacks
- **Common operation**: Transaction filtering by type is a standard use case for indexer consumers

## Recommendation

Add validation for Transaction protobuf objects before caching. Specifically:

1. **Validate transaction type on fetch**:
```rust
// In fetch_and_update_cache() or data_client.fetch_transactions()
fn validate_transaction(txn: &Transaction) -> Result<(), String> {
    // Validate transaction type is a valid enum value
    TransactionType::try_from(txn.r#type)
        .map_err(|_| format!("Invalid transaction type: {}", txn.r#type))?;
    
    // Optionally validate other required fields
    Ok(())
}
```

2. **Filter out invalid transactions** or **reject the entire batch** when validation fails

3. **Replace `.expect()` with safe error handling** in the filter:
```rust
// In TransactionRootFilter::matches()
if let Some(txn_type) = &self.txn_type {
    match TransactionType::try_from(item.r#type) {
        Ok(item_type) => {
            if txn_type != &item_type {
                return false;
            }
        },
        Err(_) => {
            // Invalid transaction type - treat as non-matching
            return false;
        }
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_protos::transaction::v1::{Transaction, transaction::TransactionType};
    use aptos_transaction_filter::{BooleanTransactionFilter, TransactionRootFilterBuilder};
    use aptos_transaction_filter::traits::Filterable;

    #[test]
    #[should_panic(expected = "Invalid transaction type")]
    fn test_malformed_transaction_type_causes_panic() {
        // Create a transaction with an invalid type value (5 is in the skipped range)
        let mut malformed_txn = Transaction::default();
        malformed_txn.r#type = 5; // Invalid value in the 5-19 skipped range
        malformed_txn.version = 12345;
        
        // Create a filter that checks transaction type
        let filter = TransactionRootFilterBuilder::default()
            .txn_type(TransactionType::User)
            .build()
            .unwrap();
        
        // This will panic with "Invalid transaction type"
        // In production, this would crash the indexer-grpc data service
        let _ = filter.matches(&malformed_txn);
    }
    
    #[test]
    fn test_valid_transaction_type_works() {
        // Create a transaction with a valid type
        let mut valid_txn = Transaction::default();
        valid_txn.r#type = TransactionType::User as i32; // Valid value
        valid_txn.version = 12345;
        
        let filter = TransactionRootFilterBuilder::default()
            .txn_type(TransactionType::User)
            .build()
            .unwrap();
        
        // This should work fine
        assert!(filter.matches(&valid_txn));
    }
}
```

## Notes

This vulnerability specifically affects the indexer-grpc-data-service-v2 component, not the core blockchain consensus or execution layers. However, it represents a critical availability issue for applications relying on the indexer service. The same pattern should be checked throughout the codebase wherever protobuf enums are converted using `.expect()` or `.unwrap()` on fallible conversions.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/fetch_manager.rs (L48-64)
```rust
    async fn fetch_and_update_cache(
        data_client: Arc<DataClient>,
        data_manager: Arc<RwLock<DataManager>>,
        version: u64,
    ) -> usize {
        let transactions = data_client.fetch_transactions(version).await;
        let len = transactions.len();

        if len > 0 {
            data_manager
                .write()
                .await
                .update_data(version, transactions);
        }

        len
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/data_manager.rs (L44-87)
```rust
    pub(super) fn update_data(&mut self, start_version: u64, transactions: Vec<Transaction>) {
        let end_version = start_version + transactions.len() as u64;

        trace!(
            "Updating data for {} transactions in range [{start_version}, {end_version}).",
            transactions.len(),
        );
        if start_version > self.end_version {
            error!(
                "The data is in the future, cache end_version: {}, data start_version: {start_version}.",
                self.end_version
            );
            COUNTER.with_label_values(&["data_too_new"]).inc();
            return;
        }

        if end_version <= self.start_version {
            warn!(
                "The data is too old, cache start_version: {}, data end_version: {end_version}.",
                self.start_version
            );
            COUNTER.with_label_values(&["data_too_old"]).inc();
            return;
        }

        let num_to_skip = self.start_version.saturating_sub(start_version);
        let start_version = start_version.max(self.start_version);

        let mut size_increased = 0;
        let mut size_decreased = 0;

        for (i, transaction) in transactions
            .into_iter()
            .enumerate()
            .skip(num_to_skip as usize)
        {
            let version = start_version + i as u64;
            let slot_index = version as usize % self.num_slots;
            if let Some(transaction) = self.data[slot_index].take() {
                size_decreased += transaction.encoded_len();
            }
            size_increased += transaction.encoded_len();
            self.data[version as usize % self.num_slots] = Some(Box::new(transaction));
        }
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/filters/transaction_root.rs (L67-73)
```rust
        if let Some(txn_type) = &self.txn_type {
            if txn_type
                != &TransactionType::try_from(item.r#type).expect("Invalid transaction type")
            {
                return false;
            }
        }
```

**File:** protos/rust/src/pb/aptos.transaction.v1.rs (L51-52)
```rust
    #[prost(enumeration="transaction::TransactionType", tag="6")]
    pub r#type: i32,
```

**File:** protos/rust/src/pb/aptos.transaction.v1.rs (L62-71)
```rust
    pub enum TransactionType {
        Unspecified = 0,
        Genesis = 1,
        BlockMetadata = 2,
        StateCheckpoint = 3,
        User = 4,
        /// values 5-19 skipped for no reason
        Validator = 20,
        BlockEpilogue = 21,
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L88-93)
```rust
                if let Some(transaction) = data_manager.get_data(version).as_ref() {
                    // NOTE: We allow 1 more txn beyond the size limit here, for simplicity.
                    if filter.is_none() || filter.as_ref().unwrap().matches(transaction) {
                        total_bytes += transaction.encoded_len();
                        result.push(transaction.as_ref().clone());
                    }
```
