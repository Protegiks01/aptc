# Audit Report

## Title
Event V2 Translation Sequence Number Cache Poisoning via Stale State Reads

## Summary
The Event V2 translation engine incorrectly uses `latest_state_checkpoint_view()` to read resource state when determining sequence numbers for translated V1 events. When backfilling historical events, this causes the translator to assign sequence numbers based on future state rather than historical state, poisoning the cache and corrupting all subsequent translations for that event key.

## Finding Description

The vulnerability exists in the Event V2 to V1 translation flow: [1](#0-0) 

When translating V2 events, the sequence number is cached. However, this sequence number is determined by querying resource state using `latest_state_checkpoint_view()`: [2](#0-1) 

Each translator (e.g., `CoinDepositTranslator`) reads the resource's event handle count from the **latest** state: [3](#0-2) 

This count is then used as the default in `get_next_sequence_number()`: [4](#0-3) 

**Attack Scenario:**

1. Node runs for 10,000 versions without Event V2 translation enabled
2. During this period, 1,000 `CoinDeposit` V2 events are emitted for a user's account
3. At version 10,000, the `CoinStore.deposit_events.count = 1000`
4. Operator enables Event V2 translation indexer
5. Indexer begins processing from version 0:
   - Version 50 has a `CoinDeposit` event (should be sequence number 49)
   - Translator queries `latest_state_checkpoint_view()` which returns state at version 10,000
   - Reads `CoinStore.deposit_events.count = 1000` from current state
   - Calls `get_next_sequence_number(&key, 1000)` with no cache/DB entry
   - **Returns 1000 as sequence number (WRONG - should be 49)**
   - Caches: `event_sequence_number_cache[key] = 1000`
6. Version 51 processes:
   - Cache exists with value 1000
   - Returns 1001 (WRONG - should be 50)
   - All subsequent events get sequences 1000, 1001, 1002... instead of 0, 1, 2...

**Cache Poisoning Effect:**

Once the first incorrect sequence is cached, all future translations for that event key are corrupted because they build on the poisoned cache value. The offset persists even after being written to the database: [5](#0-4) 

**Sequence Number Collision Scenarios:**

While direct collisions within a single indexer run are prevented by sequential processing, collisions occur when:

1. **Partial reindexing**: If the indexer DB is corrupted and only certain version ranges are reprocessed, events can be assigned different sequences than their original assignments, creating conflicts in `EventByKeySchema`

2. **Non-deterministic behavior**: The same event processed at different times (with different `latest_state` values) receives different sequence numbers, violating the determinism invariant

3. **Continuity violations**: If events are reprocessed with gaps, the sequence continuity check will fail: [6](#0-5) 

This causes permanent "DB corruption: Sequence number not continuous" errors, bricking event queries.

## Impact Explanation

**Severity: Medium**

This vulnerability causes state inconsistencies in the internal indexer database, meeting the Medium severity criterion of "State inconsistencies requiring intervention."

**Impact:**
- All translated V1 events have incorrect, non-deterministic sequence numbers
- Event queries via `lookup_events_by_key()` fail with corruption errors
- APIs relying on the indexer return incorrect data or crash
- Applications depending on event ordering break
- Different nodes running indexers at different times produce inconsistent event indices
- Indexer database requires manual intervention to fix (reindexing from scratch)

While this does not affect consensus or the main blockchain state (the indexer is off-chain), it breaks critical query infrastructure and violates the correctness guarantee that event indices should be deterministic and match emission order.

## Likelihood Explanation

**Likelihood: High**

This bug triggers automatically whenever:
- The Event V2 translation indexer is enabled on a node with historical transactions
- The indexer is restarted after a crash or maintenance
- Backfilling is performed to catch up with the main database

No attacker action is required - this is a systematic bug in the translation logic that affects all nodes running the indexer.

## Recommendation

The translator must use state at the **version being processed**, not the latest state. Replace `latest_state_checkpoint_view()` with `state_view_at_version()`:

**Fix for `event_v2_translator.rs`:**

```rust
pub struct EventV2TranslationEngine {
    pub main_db_reader: Arc<dyn DbReader>,
    pub internal_indexer_db: Arc<DB>,
    pub translators: HashMap<TypeTag, Box<dyn EventV2Translator + Send + Sync>>,
    event_sequence_number_cache: DashMap<EventKey, u64>,
}

// Add version tracking
impl EventV2TranslationEngine {
    pub fn get_state_value_bytes_for_resource(
        &self,
        address: &AccountAddress,
        struct_tag: &StructTag,
        version: Version,  // ADD THIS PARAMETER
    ) -> Result<Option<Bytes>> {
        use aptos_storage_interface::state_store::state_view::db_state_view::DbStateViewAtVersion;
        
        // Use state at the specific version, not latest
        let state_view = self
            .main_db_reader
            .state_view_at_version(Some(version))?;  // CHANGED
        let state_key = StateKey::resource(address, struct_tag)?;
        let maybe_state_value = state_view.get_state_value(&state_key)?;
        Ok(maybe_state_value.map(|state_value| state_value.bytes().clone()))
    }
}
```

**Update `db_indexer.rs` to pass version:**

```rust
// In process_a_batch(), pass the current version to the translator
let translated_v1_event = self.translate_event_v2_to_v1(v2, version)?;

// Update translate_event_v2_to_v1 signature:
pub fn translate_event_v2_to_v1(
    &self,
    v2: &ContractEventV2,
    version: Version,  // ADD THIS
) -> Result<Option<ContractEventV1>> {
    // Pass version to translator
    translator.translate_event_v2_to_v1(v2, &self.event_v2_translation_engine, version)
}
```

All translators must be updated to accept and pass the version parameter to `get_state_value_bytes_for_resource()`.

## Proof of Concept

```rust
#[cfg(test)]
mod test_sequence_poisoning {
    use super::*;
    use aptos_types::account_address::AccountAddress;
    
    #[test]
    fn test_event_v2_sequence_cache_poisoning() {
        // Setup: Create a test database with historical V2 events
        let (db_reader, internal_indexer_db) = setup_test_dbs();
        let indexer = DBIndexer::new(internal_indexer_db, db_reader.clone());
        
        // Emit 100 CoinDeposit V2 events at versions 0-99
        for version in 0..100 {
            emit_coin_deposit_v2_event(version);
        }
        
        // Verify: At version 99, CoinStore.deposit_events.count = 100
        let state_at_99 = db_reader.state_view_at_version(Some(99)).unwrap();
        let coin_store = read_coin_store(&state_at_99, &test_account());
        assert_eq!(coin_store.deposit_events().count(), 100);
        
        // Now enable indexer and process from version 0
        // This will use latest_state (version 99) for all translations
        indexer.process(0, 100).unwrap();
        
        // BUG: Event at version 0 should have sequence 0, but gets sequence 100
        let event_0 = internal_indexer_db
            .db
            .get::<EventByKeySchema>(&(event_key, 0))
            .unwrap();
        assert!(event_0.is_none(), "Sequence 0 should exist but doesn't!");
        
        let event_100 = internal_indexer_db
            .db
            .get::<EventByKeySchema>(&(event_key, 100))
            .unwrap();
        assert!(event_100.is_some(), "Event incorrectly assigned sequence 100");
        assert_eq!(event_100.unwrap().0, 0, "Version 0 event has wrong sequence");
        
        // Demonstrate cache poisoning: subsequent events also wrong
        for i in 1..100 {
            let expected_seq = i + 100;  // All offset by 100
            let event = internal_indexer_db
                .db
                .get::<EventByKeySchema>(&(event_key, expected_seq))
                .unwrap();
            assert!(event.is_some(), "Event at version {} has wrong sequence", i);
        }
        
        // Demonstrate lookup failure due to non-continuous sequences
        let result = indexer.indexer_db.lookup_events_by_key(&event_key, 0, 10, 99);
        assert!(result.is_err(), "Lookup should fail due to non-continuous sequences");
        assert!(result.unwrap_err().to_string().contains("probably pruned"));
    }
}
```

**Notes:**

This vulnerability demonstrates that reading from `latest_state_checkpoint_view()` instead of version-specific state breaks the correctness guarantee of event sequence number assignment. While the indexer is off-chain and doesn't affect consensus, it causes systematic corruption of the event index that requires manual intervention to fix, qualifying as Medium severity under "State inconsistencies requiring intervention."

### Citations

**File:** storage/indexer/src/db_indexer.rs (L232-239)
```rust
            if seq != cur_seq {
                let msg = if cur_seq == start_seq_num {
                    "First requested event is probably pruned."
                } else {
                    "DB corruption: Sequence number not continuous."
                };
                bail!("{} expected: {}, actual: {}", msg, cur_seq, seq);
            }
```

**File:** storage/indexer/src/db_indexer.rs (L461-462)
```rust
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
```

**File:** storage/indexer/src/db_indexer.rs (L511-521)
```rust
            for event_key in event_keys {
                batch
                    .put::<EventSequenceNumberSchema>(
                        &event_key,
                        &self
                            .event_v2_translation_engine
                            .get_cached_sequence_number(&event_key)
                            .unwrap_or(0),
                    )
                    .expect("Failed to put events by key to a batch");
            }
```

**File:** storage/indexer/src/event_v2_translator.rs (L190-200)
```rust
    pub fn get_next_sequence_number(&self, event_key: &EventKey, default: u64) -> Result<u64> {
        if let Some(seq) = self.get_cached_sequence_number(event_key) {
            Ok(seq + 1)
        } else {
            let seq = self
                .internal_indexer_db
                .get::<EventSequenceNumberSchema>(event_key)?
                .map_or(default, |seq| seq + 1);
            Ok(seq)
        }
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L207-210)
```rust
        let state_view = self
            .main_db_reader
            .latest_state_checkpoint_view()
            .expect("Failed to get state view");
```

**File:** storage/indexer/src/event_v2_translator.rs (L248-257)
```rust
        let (key, sequence_number) = if let Some(state_value_bytes) =
            engine.get_state_value_bytes_for_resource(coin_deposit.account(), &struct_tag)?
        {
            // We can use `DummyCoinType` as it does not affect the correctness of deserialization.
            let coin_store_resource: CoinStoreResource<DummyCoinType> =
                bcs::from_bytes(&state_value_bytes)?;
            let key = *coin_store_resource.deposit_events().key();
            let sequence_number = engine
                .get_next_sequence_number(&key, coin_store_resource.deposit_events().count())?;
            (key, sequence_number)
```
