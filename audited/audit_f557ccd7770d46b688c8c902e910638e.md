# Audit Report

## Title
Transaction Pruner Progress Desynchronization via Non-Atomic Multi-Database Writes

## Summary
The `TransactionPruner::prune()` function performs two separate, non-atomic database writes (indexer_db and transaction_db) that each update pruner progress metadata. If the first write succeeds but the second fails, the two databases become permanently desynchronized regarding what data has been pruned, violating the State Consistency invariant.

## Finding Description

The vulnerability exists in the transaction pruner's dual-database write pattern. When internal indexer functionality is enabled, the pruner writes to two separate physical databases: [1](#0-0) 

The critical flaw is that these two `write_schemas()` calls are NOT atomic with respect to each other. Each batch contains both:
1. Data deletion operations (pruning transactions)
2. Progress metadata updates (`TransactionPrunerProgress`)

**Failure Scenario:**
1. Pruner attempts to prune versions [100, 500)
2. Line 67: `indexer_db.write_schemas(index_batch)` **succeeds**
   - Deletes transaction index data for [100, 500)
   - Updates `IndexerMetadataKey::TransactionPrunerProgress = 500`
3. Line 73: `transaction_db.write_schemas(batch)` **fails** (disk I/O error, corruption, etc.)
   - Transaction data for [100, 500) is **NOT** deleted
   - `DbMetadataKey::TransactionPrunerProgress` remains at 100

**Resulting State:**
- `indexer_db`: progress=500, data=[500, ...]
- `transaction_db`: progress=100, data=[0, ...]
- The two databases have inconsistent views of pruning state

**Compounding Issue - Premature min_readable_version Update:**

The LedgerPrunerManager sets the global `min_readable_version` **before** actual pruning occurs: [2](#0-1) 

This creates a race condition where the system claims data is pruned (line 165-166) while the actual pruning may fail, leading to: [3](#0-2) 

Queries for versions [100, 500) will be rejected as "pruned" even though the data still exists in `transaction_db` but is missing from `indexer_db`.

**Persistence Across Restarts:**

On node restart, the TransactionPruner reads progress from `transaction_db`: [4](#0-3) 

The catch-up prune at line 101 will re-attempt deletion, but if the underlying issue persists (disk corruption, permissions), the desynchronization becomes permanent.

## Impact Explanation

**Severity: Medium to High**

This violates **Invariant #4: State Consistency** - "State transitions must be atomic and verifiable via Merkle proofs."

**Medium Severity Impacts:**
- **State inconsistencies requiring intervention** (per bug bounty criteria): The two databases have conflicting views of what data exists
- **Query result inconsistency**: Some queries read from `indexer_db`, others from `transaction_db`, leading to non-deterministic results
- **Data corruption**: Re-pruning attempts may encounter edge cases with already-deleted indexer data

**Potential High Severity Escalation:**
- **Validator divergence**: If different validators experience failures at different times, they may end up with different database states
- **Consensus risk**: While unlikely, if validators query different databases for the same information and get different results, this could lead to state root mismatches
- **Recovery complexity**: Requires manual intervention to identify and reconcile the inconsistent progress markers

## Likelihood Explanation

**Likelihood: Medium**

**Triggering Conditions:**
- Internal indexer must be enabled (`internal_indexer_db.is_some()`)
- Transaction indexing must be enabled (`indexer_db.transaction_enabled()`)
- Write failure must occur between lines 67 and 73

**Common Causes:**
- Disk I/O errors (hardware failures, network storage issues)
- Disk space exhaustion (indexer_db write succeeds, then disk fills before transaction_db write)
- File system corruption
- Permission changes
- Process termination between writes (crashes, OOM kills)

**Production Occurrence:**
In production validator environments with high transaction throughput and continuous pruning, disk I/O failures are not uncommon. The asynchronous pruner worker retries on failure, but if the failure is persistent (e.g., disk corruption on a specific database), the desynchronization persists.

## Recommendation

**Solution: Use Two-Phase Commit or Single Database Write**

**Option 1 - Preferred: Consolidate to Single Write**
Modify the pruner to write all progress metadata to a single source of truth (e.g., `transaction_db`), and have the indexer_db read from it rather than maintaining separate progress:

```rust
pub fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
    let mut batch = SchemaBatch::new();
    let candidate_transactions = 
        self.get_pruning_candidate_transactions(current_progress, target_version)?;
    
    // Prune from transaction_db
    self.ledger_db.transaction_db().prune_transaction_by_hash_indices(...)?;
    self.ledger_db.transaction_db().prune_transactions(...)?;
    self.transaction_store.prune_transaction_summaries_by_account(...)?;
    
    // Update progress ONCE in transaction_db
    batch.put::<DbMetadataSchema>(
        &DbMetadataKey::TransactionPrunerProgress,
        &DbMetadataValue::Version(target_version),
    )?;
    
    // Write to transaction_db FIRST
    self.ledger_db.transaction_db().write_schemas(batch)?;
    
    // Then prune indexer_db WITHOUT updating its progress separately
    if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
        if indexer_db.transaction_enabled() {
            let mut index_batch = SchemaBatch::new();
            self.transaction_store.prune_transaction_by_account(...)?;
            // NO progress update here - read from transaction_db instead
            indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
        }
    }
    
    Ok(())
}
```

**Option 2: Implement Transaction Coordinator**
Add a transaction coordinator that ensures both writes succeed or both are rolled back, similar to two-phase commit protocols.

**Option 3: Defer min_readable_version Update**
Modify `LedgerPrunerManager` to only update `min_readable_version` AFTER successful pruning confirmation, not before.

## Proof of Concept

```rust
// Rust integration test demonstrating the vulnerability
#[test]
fn test_pruner_progress_desync_on_partial_write_failure() {
    use aptos_temppath::TempPath;
    use aptos_types::transaction::Version;
    use std::sync::Arc;
    
    // Setup: Create AptosDB with internal indexer enabled
    let tmpdir = TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    
    // Commit transactions to version 1000
    for version in 0..1000 {
        // ... commit transaction at version ...
    }
    
    // Setup pruner to prune to version 500
    let pruner_config = PrunerConfig {
        ledger_pruner_config: LedgerPrunerConfig {
            enable: true,
            prune_window: 100,
            batch_size: 500,
            ..Default::default()
        },
        ..Default::default()
    };
    
    // Inject failure: Mock indexer_db to succeed, transaction_db to fail
    // This requires test infrastructure to simulate write failures
    
    // Step 1: Trigger pruning
    db.ledger_pruner.maybe_set_pruner_target_db_version(1000);
    
    // Step 2: Wait for pruner worker to execute with injected failure
    std::thread::sleep(Duration::from_secs(2));
    
    // Step 3: Verify desynchronization
    let indexer_progress = read_indexer_progress(&db); // Should be 500
    let transaction_db_progress = read_transaction_db_progress(&db); // Should be 100
    
    assert_ne!(indexer_progress, transaction_db_progress, 
        "Progress desynchronization detected!");
    
    // Step 4: Verify data inconsistency
    let indexer_has_data = check_indexer_data_exists(&db, 250); // Should be false
    let transaction_db_has_data = check_transaction_db_data_exists(&db, 250); // Should be true
    
    assert_ne!(indexer_has_data, transaction_db_has_data,
        "Data inconsistency detected - indexer pruned but transaction_db not!");
    
    // Step 5: Verify min_readable_version incorrectly reports data as pruned
    assert!(db.ledger_pruner.get_min_readable_version() > 250,
        "min_readable_version claims data is pruned");
    assert!(transaction_db_has_data,
        "But data still exists in transaction_db!");
}
```

**Notes:**
- Full PoC requires test infrastructure to simulate selective write failures
- The core issue is architecturally evident in the code structure
- Manual testing can be performed by inducing disk failures during pruning in a test environment

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L58-73)
```rust
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L78-104)
```rust
    pub(in crate::pruner) fn new(
        transaction_store: Arc<TransactionStore>,
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_db_raw(),
            &DbMetadataKey::TransactionPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionPruner {
            transaction_store,
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L162-176)
```rust
    fn set_pruner_target_db_version(&self, latest_version: Version) {
        assert!(self.pruner_worker.is_some());
        let min_readable_version = latest_version.saturating_sub(self.prune_window);
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["ledger_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.pruner_worker
            .as_ref()
            .unwrap()
            .set_target_db_version(min_readable_version);
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L261-271)
```rust
    pub(super) fn error_if_ledger_pruned(&self, data_type: &str, version: Version) -> Result<()> {
        let min_readable_version = self.ledger_pruner.get_min_readable_version();
        ensure!(
            version >= min_readable_version,
            "{} at version {} is pruned, min available version is {}.",
            data_type,
            version,
            min_readable_version
        );
        Ok(())
    }
```
