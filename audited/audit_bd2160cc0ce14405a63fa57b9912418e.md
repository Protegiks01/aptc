# Audit Report

## Title
Unauthenticated Admin Service CPU Profiling Endpoint Enables Validator Performance Degradation

## Summary
The AdminService exposes a CPU profiling endpoint (`/profilez`) that accepts external API calls without authentication on testnet/devnet validator nodes when no authentication is configured and network access is enabled. This allows unprivileged attackers to trigger resource-intensive profiling operations, causing validator performance degradation.

## Finding Description

The AdminService in Aptos Core provides debugging endpoints including CPU profiling at `/profilez`. The authentication mechanism has an insecure default behavior that grants access when no authentication methods are configured. [1](#0-0) 

The critical flaw is on lines 155-156: when `authentication_configs` is empty, the service automatically sets `authenticated = true`, granting access without any credential verification. [2](#0-1) 

The default configuration initializes `authentication_configs` as an empty vector (line 47), meaning authentication is disabled by default. [3](#0-2) 

The ConfigOptimizer enables the AdminService by default on non-mainnet chains (lines 94-100), while mainnet has explicit protection via the ConfigSanitizer that prevents enabling the service without authentication. [4](#0-3) 

The `/profilez` endpoint accepts query parameters (`seconds`, `frequency`) and immediately initiates CPU profiling without any rate limiting beyond a single mutex. An attacker can repeatedly trigger profiling sessions by sending requests like:
```
GET http://validator:9102/profilez?seconds=60&frequency=99
```

**Attack Vector:**
1. Attacker identifies a testnet/devnet validator with AdminService externally accessible (requires operator to set `enableAdminPort: true` in Kubernetes or custom deployment without network isolation)
2. Attacker sends repeated HTTP GET requests to `/profilez?seconds=60&frequency=99`
3. Each request triggers 60 seconds of CPU profiling at 99Hz sampling frequency
4. The mutex `CPU_PROFILE_MUTEX` only prevents concurrent sessions, not sequential abuse
5. Continuous profiling degrades validator performance, potentially causing:
   - Slower block proposals
   - Missed consensus rounds
   - Delayed transaction processing
   - Increased risk of validator penalties [5](#0-4) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria under "Validator node slowdowns". 

CPU profiling introduces measurable overhead through:
- Stack trace collection at 99Hz (every ~10ms)
- Frame processing and aggregation  
- Output generation (flamegraph/proto serialization)

While a single profiling session has manageable impact, sustained or repeated profiling can degrade validator performance during critical consensus operations. This is particularly concerning because:

1. Validators must maintain strict timing requirements for block proposals and voting
2. Performance degradation could cause validators to miss slots or rounds
3. Systematic abuse across multiple validators could impact network liveness
4. The attack requires minimal resources (simple HTTP requests) but consumes significant validator resources

The vulnerability does not directly compromise consensus safety or cause loss of funds, but it enables targeted performance attacks against validator infrastructure.

## Likelihood Explanation

**Exploitability: Medium-Low**

The vulnerability exists in the codebase, but exploitation requires specific conditions:

**Default deployments (NOT vulnerable):** [6](#0-5) 

Kubernetes deployments have `enableAdminPort: false` by default, preventing external load balancer exposure. [7](#0-6) 

Docker Compose binds the admin port to `127.0.0.1` only, blocking external access.

**Vulnerable scenarios:**
1. **Operators enable external access for debugging** - Testnet/devnet operators may set `enableAdminPort: true` to access debugging tools, unknowingly exposing the unauthenticated endpoint
2. **Custom deployments** - Bare metal or VM deployments without proper firewall configuration
3. **Internal network compromise** - Attackers with access to Kubernetes cluster network or Docker network can bypass load balancer restrictions
4. **Misconfigured HAProxy** - IP allowlists in `blocked.ips` may not cover all attacker IPs [8](#0-7) 

The likelihood increases because:
- The insecure default (no authentication) violates secure-by-default principles
- The code comment explicitly acknowledges this is "Not allowed on mainnet"
- Operators may not realize enabling the admin port exposes unauthenticated debugging endpoints

## Recommendation

**Immediate fixes:**

1. **Require authentication by default** - Modify the authentication logic to deny access when `authentication_configs` is empty:

```rust
let mut authenticated = false;
if context.config.authentication_configs.is_empty() {
    // CHANGED: Deny by default instead of allowing
    return Ok(reply_with_status(
        StatusCode::NETWORK_AUTHENTICATION_REQUIRED,
        "AdminService requires authentication configuration.",
    ));
}
``` [9](#0-8) 

2. **Add rate limiting** - Implement per-IP rate limiting for the profiling endpoint to prevent abuse even with valid credentials.

3. **Update documentation** - Clearly document that enabling external admin port access requires configuring authentication.

4. **Enforce authentication on all chains** - Extend the ConfigSanitizer to require authentication on testnet/devnet if the admin service is externally exposed: [10](#0-9) 

5. **Consider automatic authentication generation** - For testnet/devnet, automatically generate a random passcode if none is configured and log it, rather than allowing unauthenticated access.

## Proof of Concept

**Setup:**
1. Deploy an Aptos testnet validator with default configuration
2. Set `enableAdminPort: true` in Kubernetes helm values (simulating an operator enabling debugging)
3. Note the external IP of the validator load balancer

**Exploitation:**
```bash
# Trigger CPU profiling for 60 seconds at 99Hz frequency
curl -v "http://<validator-ip>:9102/profilez?seconds=60&frequency=99&format=proto" -o profile.pb

# Request completes successfully without any authentication
# HTTP 200 response with profiling data

# Repeat continuously to degrade validator performance
while true; do
    curl "http://<validator-ip>:9102/profilez?seconds=30&frequency=99" > /dev/null 2>&1
    sleep 1  # Brief gap between profiling sessions
done
```

**Expected Result:**
- All requests succeed without authentication
- Validator CPU usage increases during profiling
- Sustained profiling causes measurable performance degradation
- Block proposal timing may be affected under continuous load

**Verification:**
Monitor validator metrics at port 9101 (if exposed) to observe:
- Increased CPU utilization during profiling
- Potential increase in consensus round times
- Resource consumption from profiling operations

## Notes

While the vulnerability exists in the authentication logic, default Kubernetes and Docker deployments include network-level protections (admin port not externally exposed). However, this represents a defense-in-depth failure - the application-level security should not rely solely on network configuration.

The issue is most critical for:
- Testnet/devnet operators who enable admin port for legitimate debugging
- Custom deployments without Kubernetes/Docker network isolation  
- Internal network threat scenarios (compromised adjacent services)

The code comment acknowledging "Not allowed on mainnet" indicates the developers were aware of the security implications but chose different protection mechanisms (network isolation + mainnet sanitizer) rather than secure-by-default authentication logic.

### Citations

**File:** crates/aptos-admin-service/src/server/mod.rs (L154-181)
```rust
        let mut authenticated = false;
        if context.config.authentication_configs.is_empty() {
            authenticated = true;
        } else {
            for authentication_config in &context.config.authentication_configs {
                match authentication_config {
                    AuthenticationConfig::PasscodeSha256(passcode_sha256) => {
                        let query = req.uri().query().unwrap_or("");
                        let query_pairs: HashMap<_, _> =
                            url::form_urlencoded::parse(query.as_bytes()).collect();
                        let passcode: Option<String> =
                            query_pairs.get("passcode").map(|p| p.to_string());
                        if let Some(passcode) = passcode {
                            if sha256::digest(passcode) == *passcode_sha256 {
                                authenticated = true;
                            }
                        }
                    },
                }
            }
        };

        if !authenticated {
            return Ok(reply_with_status(
                StatusCode::NETWORK_AUTHENTICATION_REQUIRED,
                format!("{} endpoint requires authentication.", req.uri().path()),
            ));
        }
```

**File:** config/src/config/admin_service_config.rs (L41-50)
```rust
impl Default for AdminServiceConfig {
    fn default() -> Self {
        Self {
            enabled: None,
            address: "0.0.0.0".to_string(),
            port: 9102,
            authentication_configs: vec![],
            malloc_stats_max_len: 2 * 1024 * 1024,
        }
    }
```

**File:** config/src/config/admin_service_config.rs (L59-82)
```rust
impl ConfigSanitizer for AdminServiceConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        if node_config.admin_service.enabled == Some(true) {
            if let Some(chain_id) = chain_id {
                if chain_id.is_mainnet()
                    && node_config.admin_service.authentication_configs.is_empty()
                {
                    return Err(Error::ConfigSanitizerFailed(
                        sanitizer_name,
                        "Must enable authentication for AdminService on mainnet.".into(),
                    ));
                }
            }
        }

        Ok(())
    }
}
```

**File:** config/src/config/admin_service_config.rs (L84-106)
```rust
impl ConfigOptimizer for AdminServiceConfig {
    fn optimize(
        node_config: &mut NodeConfig,
        _local_config_yaml: &Value,
        _node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<bool, Error> {
        let mut modified_config = false;

        if node_config.admin_service.enabled.is_none() {
            // Only enable the admin service if the chain is not mainnet
            let admin_service_enabled = if let Some(chain_id) = chain_id {
                !chain_id.is_mainnet()
            } else {
                false // We cannot determine the chain ID, so we disable the admin service
            };
            node_config.admin_service.enabled = Some(admin_service_enabled);

            modified_config = true; // The config was modified
        }

        Ok(modified_config)
    }
```

**File:** crates/aptos-system-utils/src/profiling.rs (L19-78)
```rust
pub async fn handle_cpu_profiling_request(req: Request<Body>) -> hyper::Result<Response<Body>> {
    let query = req.uri().query().unwrap_or("");
    let query_pairs: HashMap<_, _> = url::form_urlencoded::parse(query.as_bytes()).collect();

    let seconds: u64 = match query_pairs.get("seconds") {
        Some(val) => match val.parse() {
            Ok(val) => val,
            Err(err) => return Ok(reply_with_status(StatusCode::BAD_REQUEST, err.to_string())),
        },
        None => 10,
    };

    let frequency: i32 = match query_pairs.get("frequency") {
        Some(val) => match val.parse() {
            Ok(val) => val,
            Err(err) => return Ok(reply_with_status(StatusCode::BAD_REQUEST, err.to_string())),
        },
        None => 99,
    };

    let use_proto = match query_pairs.get("format") {
        Some(format) => match format.as_ref() {
            "proto" => true,
            "flamegraph" => false,
            _ => {
                return Ok(reply_with_status(
                    StatusCode::BAD_REQUEST,
                    "Unsupported format.",
                ))
            },
        },
        _ => true,
    };

    match start_cpu_profiling(seconds, frequency, use_proto).await {
        Ok(body) => {
            let content_type = if use_proto {
                mime::APPLICATION_OCTET_STREAM
            } else {
                mime::IMAGE_SVG
            };
            let headers: Vec<(_, HeaderValue)> = vec![
                (CONTENT_LENGTH, HeaderValue::from(body.len())),
                (CONTENT_DISPOSITION, HeaderValue::from_static("inline")),
                (
                    CONTENT_TYPE,
                    HeaderValue::from_str(content_type.as_ref()).unwrap(),
                ),
            ];
            Ok(reply_with(headers, body))
        },
        Err(e) => {
            info!("Failed to generate cpu profile: {e:?}");
            Ok(reply_with_status(
                StatusCode::INTERNAL_SERVER_ERROR,
                e.to_string(),
            ))
        },
    }
}
```

**File:** crates/aptos-system-utils/src/profiling.rs (L80-122)
```rust
pub async fn start_cpu_profiling(
    seconds: u64,
    frequency: i32,
    use_proto: bool,
) -> anyhow::Result<Vec<u8>> {
    info!(
        seconds = seconds,
        frequency = frequency,
        use_proto = use_proto,
        "Starting cpu profiling."
    );
    let lock = CPU_PROFILE_MUTEX.try_lock();
    ensure!(lock.is_some(), "A profiling task is already running.");

    // TODO(grao): Consolidate the code with aptos-profiler crate.
    let guard = pprof::ProfilerGuard::new(frequency)
        .map_err(|e| anyhow!("Failed to start cpu profiling: {e:?}."))?;

    tokio::time::sleep(Duration::from_secs(seconds)).await;

    let mut body = Vec::new();
    let report = guard
        .report()
        .frames_post_processor(frames_post_processor())
        .build()
        .map_err(|e| anyhow!("Failed to generate cpu profiling report: {e:?}."))?;

    if use_proto {
        report
            .pprof()
            .map_err(|e| anyhow!("Failed to generate proto report: {e:?}."))?
            .write_to_vec(&mut body)
            .map_err(|e| anyhow!("Failed to serialize proto report: {e:?}."))?;
    } else {
        report
            .flamegraph(&mut body)
            .map_err(|e| anyhow!("Failed to generate flamegraph report: {e:?}."))?;
    }

    info!("Cpu profiling is done.");

    Ok(body)
}
```

**File:** terraform/helm/aptos-node/values.yaml (L159-159)
```yaml
    enableAdminPort: false
```

**File:** docker/compose/aptos-node/docker-compose.yaml (L32-33)
```yaml
      - "127.0.0.1:9101:9101"
      - "127.0.0.1:9102:9102"
```

**File:** terraform/helm/aptos-node/files/haproxy.cfg (L110-126)
```text
## Specify the validator admin frontend
frontend validator-admin
    mode http
    option httplog
    bind :9202
    default_backend validator-admin

    # Deny requests from blocked IPs
    tcp-request connection reject if { src -n -f /usr/local/etc/haproxy/blocked.ips }

    ## Add the forwarded header
    http-request add-header Forwarded "for=%ci"

## Specify the validator admin backend
backend validator-admin
    mode http
    server {{ include "aptos-validator.fullname" $ }}-{{ $.Values.i }}-validator {{ include "aptos-validator.fullname" $ }}-{{ $.Values.i }}-validator:9102
```
