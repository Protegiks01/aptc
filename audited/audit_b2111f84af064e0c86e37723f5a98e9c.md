# Audit Report

## Title
Cached Backup Metadata Version Mismatch Enables State Snapshot Confusion Attack Leading to Consensus Divergence

## Summary
The backup metadata cache system lacks integrity protection (checksums, signatures, or Merkle proofs), allowing attackers with filesystem access to modify cached `StateSnapshotBackupMeta` entries. By changing the `manifest` FileHandle while preserving the `version` field, an attacker can cause validators to restore state from an incorrect snapshot version. The restoration code fails to validate that the metadata version matches the manifest version, resulting in database corruption where the version number and actual state are mismatched, causing consensus divergence.

## Finding Description

The vulnerability exists in the state snapshot restoration flow where cached metadata is used without integrity verification.

The metadata cache loads backup metadata files without any integrity checks: [1](#0-0) 

These cached files are plain JSON with no checksums, signatures, or Merkle proofs: [2](#0-1) 

The metadata structure contains a version field and a manifest FileHandle: [3](#0-2) 

During restoration, the code loads the manifest from the FileHandle specified in the cached metadata: [4](#0-3) 

The manifest contains its own version field: [5](#0-4) 

**Critical Flaw**: The verification uses the manifest's version for proof validation, but creates the database receiver with the metadata's version: [6](#0-5) 

There is no check ensuring `self.version` (from metadata) equals `manifest.version` (from the loaded manifest).

**Attack Scenario:**
1. Attacker gains filesystem access to validator's persistent cache directory (specified via `--metadata-cache-dir`)
2. Identifies cached metadata file for StateSnapshotBackupMeta at version 1000
3. Modifies the cached JSON to change the `manifest` FileHandle to point to a snapshot from version 2000 (while keeping `version: 1000` unchanged)
4. When validator restores:
   - Loads corrupted metadata: `version=1000, manifest=<handle_to_v2000_snapshot>`
   - Loads manifest from storage: `version=2000, root_hash=<hash_v2000>, ...`
   - Verifies proof against `manifest.version=2000` → **passes** (legitimate proof for v2000)
   - Creates StateSnapshotRestore receiver with `self.version=1000` and `manifest.root_hash=<hash_v2000>`
5. Database is told it's restoring to version 1000, but receives state data from version 2000
6. When transaction replay begins from version 1001, the state root is incorrect
7. Validator produces different state roots than honest validators → **consensus divergence**

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under the Aptos bug bounty program for the following reasons:

**Consensus/Safety Violation**: The fundamental invariant "All validators must produce identical state roots for identical blocks" is broken. A validator restoring from corrupted cached metadata will have mismatched state (version X with state from version Y), causing it to compute different state roots when executing subsequent transactions.

**Non-Recoverable Network Partition**: If multiple validators are affected (e.g., operators using shared infrastructure or automated deployment with compromised cache), the network could split into honest and corrupted validator sets. The corrupted validators cannot self-correct since their database state appears valid internally but diverges from consensus.

**Requires Hard Fork**: Recovery would require coordinated intervention, potentially a hard fork, as the corrupted validators have fundamentally incorrect state that cannot be automatically reconciled with the correct chain.

The attack directly targets the "Deterministic Execution" and "State Consistency" invariants, both critical to blockchain consensus.

## Likelihood Explanation

**Likelihood: Medium-to-High** for the following reasons:

**Attack Prerequisites:**
- Filesystem access to validator node's cache directory
- Knowledge of backup storage structure to identify valid manifest FileHandles

**Realistic Attack Vectors:**
1. **Compromised Infrastructure**: If validator infrastructure (cloud VMs, containers, storage) is compromised, attacker gains filesystem access
2. **Malicious Insider**: Validator operator or infrastructure admin with legitimate access
3. **Supply Chain Attack**: Compromised deployment automation that modifies cache during setup
4. **Persistent Cache Recommended**: The help text encourages using persistent cache directories for performance, increasing attack surface

**Why Practical:**
- No authentication or integrity checks on cached files
- Cache directory location is predictable (user-specified or default)
- Manifest FileHandles are discoverable from remote backup storage
- Attack leaves no immediate traces (corrupted cache appears legitimate)
- Validator operators unlikely to detect the subtle version mismatch

The comment in the cache implementation itself acknowledges the risk: [7](#0-6) 

This warning about "messed up" cache content confirms the system's awareness that cache integrity is vulnerable.

## Recommendation

Implement integrity protection for cached metadata files with a multi-layered approach:

**1. Add Version-Manifest Consistency Check** (Immediate Fix):
```rust
// In storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs
async fn run_impl(self) -> Result<()> {
    if self.version > self.target_version {
        warn!("Trying to restore state snapshot to version {}, which is newer than the target version {}, skipping.",
            self.version, self.target_version);
        return Ok(());
    }

    let manifest: StateSnapshotBackup =
        self.storage.load_json_file(&self.manifest_handle).await?;
    
    // ADD THIS CHECK:
    ensure!(
        manifest.version == self.version,
        "Version mismatch: metadata claims version {}, but manifest is for version {}. \
         This indicates corrupted cache or malicious metadata manipulation.",
        self.version,
        manifest.version
    );
    
    let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
        self.storage.load_bcs_file(&manifest.proof).await?;
    // ... rest of verification
}
```

**2. Add Cryptographic Integrity to Cache** (Complete Fix):
```rust
// In storage/backup/backup-cli/src/metadata/cache.rs
async fn download_file(
    storage_ref: &dyn BackupStorage,
    file_handle: &FileHandle,
    local_tmp_file: &Path,
) -> Result<()> {
    let mut hasher = Sha3_256::new();
    let mut file = storage_ref.open_for_read(file_handle).await?;
    let mut local_file = OpenOptions::new()
        .write(true)
        .create_new(true)
        .open(local_tmp_file)
        .await?;
    
    let mut buffer = vec![0u8; 8192];
    loop {
        let n = file.read(&mut buffer).await?;
        if n == 0 { break; }
        hasher.update(&buffer[..n]);
        local_file.write_all(&buffer[..n]).await?;
    }
    
    let computed_hash = hasher.finalize();
    let expected_hash = file_handle.content_hash()
        .ok_or_else(|| anyhow!("FileHandle missing content hash"))?;
    
    ensure!(
        computed_hash.as_slice() == expected_hash.as_ref(),
        "Checksum verification failed for metadata file"
    );
    
    Ok(())
}
```

**3. Sign Metadata Files at Creation** (Defense in Depth):
Store cryptographic signatures from backup coordinators with metadata files and verify signatures before loading from cache.

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// File: storage/backup/backup-cli/src/backup_types/state_snapshot/restore_test.rs

#[tokio::test]
async fn test_version_mismatch_attack() {
    use crate::metadata::StateSnapshotBackupMeta;
    use std::fs;
    use tempfile::TempDir;
    
    // Setup: Create mock backup storage with two snapshots
    let cache_dir = TempDir::new().unwrap();
    let storage = Arc::new(MockBackupStorage::new());
    
    // Snapshot 1: version 1000, root_hash A
    let manifest_v1000 = create_test_manifest(1000, "hash_A");
    let handle_v1000 = storage.save_manifest(&manifest_v1000).await.unwrap();
    
    // Snapshot 2: version 2000, root_hash B  
    let manifest_v2000 = create_test_manifest(2000, "hash_B");
    let handle_v2000 = storage.save_manifest(&manifest_v2000).await.unwrap();
    
    // Create legitimate metadata for version 1000
    let meta_v1000 = StateSnapshotBackupMeta {
        version: 1000,
        epoch: 10,
        manifest: handle_v1000.clone(),
    };
    
    // Attack: Modify cached metadata to point to v2000 manifest while claiming v1000
    let corrupted_meta = StateSnapshotBackupMeta {
        version: 1000,  // Keep version as 1000
        epoch: 10,
        manifest: handle_v2000,  // Point to v2000 manifest!
    };
    
    // Save corrupted metadata to cache
    let cache_file = cache_dir.path().join("metadata.json");
    fs::write(&cache_file, serde_json::to_string(&corrupted_meta).unwrap()).unwrap();
    
    // Attempt restore
    let controller = StateSnapshotRestoreController::new(
        StateSnapshotRestoreOpt {
            manifest_handle: corrupted_meta.manifest,
            version: corrupted_meta.version,  // Claims version 1000
            validate_modules: false,
            restore_mode: StateSnapshotRestoreMode::Default,
        },
        global_opt,
        storage.clone(),
        None,
    );
    
    // BUG: This should fail but succeeds!
    // The proof verification uses manifest.version (2000) and passes
    // But the receiver is created with self.version (1000)
    // Result: Database thinks it's at v1000 but has state from v2000
    let result = controller.run().await;
    
    // Vulnerability demonstrated: restore succeeds with version mismatch
    assert!(result.is_ok());
    
    // Verify the database corruption:
    let db_version = get_db_version().await;
    let db_root_hash = get_db_root_hash().await;
    
    assert_eq!(db_version, 1000);  // DB thinks it's at version 1000
    assert_eq!(db_root_hash, "hash_B");  // But has root hash from version 2000!
    
    // This validator will now diverge when executing transactions from v1001+
}
```

## Notes

The vulnerability is exacerbated by the fact that:

1. The cache system explicitly recommends persistent storage for performance, increasing the attack window
2. No audit logging exists for cache modifications
3. The file naming uses content hashing of FileHandle objects, not cryptographic hashing of file contents
4. Multiple validators using shared infrastructure (e.g., Kubernetes persistent volumes) could all be affected simultaneously

This represents a fundamental design flaw where the security boundary (cache) is treated as trusted when it should be untrusted, violating the principle that all external inputs must be validated.

### Citations

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L32-36)
```rust
        help = "Metadata cache dir. If specified and shared across runs, \
        metadata files in cache won't be downloaded again from backup source, speeding up tool \
        boot up significantly. Cache content can be messed up if used across the devnet, \
        the testnet and the mainnet, hence it [Defaults to temporary dir]."
    )]
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L193-207)
```rust
    let mut metadata_vec = Vec::new();
    for h in new_remote_hashes.into_iter().chain(up_to_date_local_hashes) {
        let cached_file = cache_dir.join(h);
        metadata_vec.extend(
            OpenOptions::new()
                .read(true)
                .open(&cached_file)
                .await
                .err_notes(&cached_file)?
                .load_metadata_lines()
                .await
                .err_notes(&cached_file)?
                .into_iter(),
        )
    }
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L236-246)
```rust
impl<R: AsyncRead + Send + Unpin> LoadMetadataLines for R {
    async fn load_metadata_lines(&mut self) -> Result<Vec<Metadata>> {
        let mut buf = String::new();
        self.read_to_string(&mut buf)
            .await
            .err_notes((file!(), line!(), &buf))?;
        Ok(buf
            .lines()
            .map(serde_json::from_str::<Metadata>)
            .collect::<Result<_, serde_json::error::Error>>()?)
    }
```

**File:** storage/backup/backup-cli/src/metadata/mod.rs (L184-189)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct StateSnapshotBackupMeta {
    pub epoch: u64,
    pub version: Version,
    pub manifest: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-124)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L127-145)
```rust
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
        if let Some(epoch_history) = self.epoch_history.as_ref() {
            epoch_history.verify_ledger_info(&li)?;
        }

        let receiver = Arc::new(Mutex::new(Some(self.run_mode.get_state_restore_receiver(
            self.version,
            manifest.root_hash,
            self.restore_mode,
        )?)));
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L29-51)
```rust
/// State snapshot backup manifest, representing a complete state view at specified version.
#[derive(Deserialize, Serialize)]
pub struct StateSnapshotBackup {
    /// Version at which this state snapshot is taken.
    pub version: Version,
    /// Epoch in which this state snapshot is taken.
    pub epoch: u64,
    /// Hash of the state tree root.
    pub root_hash: HashValue,
    /// All account blobs in chunks.
    pub chunks: Vec<StateSnapshotChunk>,
    /// BCS serialized
    /// `Tuple(TransactionInfoWithProof, LedgerInfoWithSignatures)`.
    ///   - The `TransactionInfoWithProof` is at `Version` above, and carries the same `root_hash`
    /// above; It proves that at specified version the root hash is as specified in a chain
    /// represented by the LedgerInfo below.
    ///   - The signatures on the `LedgerInfoWithSignatures` has a version greater than or equal to
    /// the version of this backup but is within the same epoch, so the signatures on it can be
    /// verified by the validator set in the same epoch, which can be provided by an
    /// `EpochStateBackup` recovered prior to this to the DB; Requiring it to be in the same epoch
    /// limits the requirement on such `EpochStateBackup` to no older than the same epoch.
    pub proof: FileHandle,
}
```
