# Audit Report

## Title
Path Traversal in Backup Metadata File Handler Enables Arbitrary File Movement and Data Exfiltration

## Summary
The `LocalFs::backup_metadata_file()` implementation contains a path traversal vulnerability where unsanitized file handles from `CompactionTimestampsMeta` can be exploited to move arbitrary files accessible to the backup process. An attacker with write access to backup storage can inject malicious file handles containing `../` sequences into metadata files, which after the expiration period will cause the backup compactor to move sensitive system files to the backup directory, enabling data exfiltration or denial of service.

## Finding Description

The vulnerability exists in the interaction between three components:

1. **Deserialization without validation**: [1](#0-0) 

2. **Metadata merging preserves malicious handles**: [2](#0-1) 

3. **Path traversal in file operations**: [3](#0-2) 

**Attack Flow:**

An attacker who gains write access to backup storage (e.g., compromised S3 credentials, misconfigured bucket permissions) can create a malicious `CompactionTimestampsMeta` file with a future timestamp containing file handles like `"metadata/../../home/aptos/.ssh/id_rsa"`. When the backup compactor loads metadata, it deserializes this file without validating the `FileHandle` strings. The malicious handles are merged into the metadata view and persist across runs.

After the configured expiration period (`remove_compacted_files_after_secs`), these handles are marked as expired. The compactor then calls `backup_metadata_file()` which:
- Extracts only the filename (`id_rsa`) for the destination
- Uses the FULL handle with `../` for the source via `self.dir.join(file_handle)`
- Executes `rename("/home/aptos/.ssh/id_rsa", "/backup/metadata_backup/id_rsa")`

The source path resolution occurs at: [4](#0-3) 

This moves the SSH private key to backup storage where the attacker can retrieve it, compromising node access.

**Why Normal Flow is Safe but Metadata Injection is Not:**

The `list_metadata_files()` implementation uses `entry.file_name()` which cannot contain directory separators: [5](#0-4) 

However, the vulnerability is triggered through a different path where file handles come from deserialized `CompactionTimestampsMeta` loaded from backup storage: [6](#0-5) 

The metadata loading process reads JSON files and deserializes them without validation, and the metadata view preserves all handles from the CompactionTimestampsMeta even if they don't exist in the current file listing.

## Impact Explanation

**High Severity** - This vulnerability enables:

1. **Data Exfiltration**: Moving sensitive files (SSH keys, configuration files, credentials) to backup storage accessible to the attacker
2. **Denial of Service**: Moving critical system files breaks node operation ("validator node slowdowns" per bounty criteria)
3. **Privilege Escalation**: Stealing authentication credentials enables full node compromise
4. **Lateral Movement**: In multi-node deployments sharing backup storage, one compromised storage credential can affect multiple nodes

While this requires prior compromise of backup storage credentials, such credentials often have weaker security boundaries than node access itself (shared across teams, broader IAM policies, third-party backup services). This represents a realistic privilege escalation vector in production deployments.

The impact is limited only by filesystem permissions of the backup process user, but typical validator deployments run backup processes with significant file access for operational needs.

## Likelihood Explanation

**Medium to High Likelihood** given:

1. **Common Misconfiguration**: Cloud storage buckets are frequently misconfigured with overly permissive write access
2. **Credential Leakage**: Backup credentials are often shared more widely than node access credentials
3. **No Validation**: Complete absence of input validation on deserialized file handles
4. **Persistent Exploitation**: Once malicious metadata is injected, it persists until manually removed
5. **Long Exposure Window**: The expiration period provides ample time for exploitation

The attack requires monitoring when the backup compactor runs and waiting for the expiration period, but these are predictable based on configuration.

## Recommendation

Implement strict validation of `FileHandle` strings when deserializing from untrusted sources:

```rust
// In storage/backup/backup-cli/src/storage/mod.rs
impl FileHandle {
    pub fn validate_safe_path(&self) -> Result<()> {
        // Reject any path containing directory traversal sequences
        ensure!(
            !self.contains("..") && !self.contains("//"),
            "FileHandle contains unsafe path sequences: {}",
            self
        );
        
        // Ensure path stays within expected directories
        let normalized = Path::new(self).components()
            .collect::<Vec<_>>();
        ensure!(
            !normalized.iter().any(|c| matches!(c, Component::ParentDir)),
            "FileHandle contains parent directory references: {}",
            self
        );
        
        Ok(())
    }
}

// In storage/backup/backup-cli/src/storage/local_fs/mod.rs
async fn backup_metadata_file(&self, file_handle: &FileHandleRef) -> Result<()> {
    // Validate file_handle before use
    FileHandle::from(file_handle).validate_safe_path()?;
    
    let dir = self.metadata_backup_dir();
    // ... rest of implementation
}
```

Additionally, validate all file handles when loading `CompactionTimestampsMeta`: [7](#0-6) 

## Proof of Concept

```rust
#[cfg(test)]
mod path_traversal_test {
    use super::*;
    use std::fs;
    use tempfile::TempDir;
    
    #[tokio::test]
    async fn test_path_traversal_via_compaction_metadata() {
        // Setup: Create backup directory structure
        let temp_dir = TempDir::new().unwrap();
        let backup_dir = temp_dir.path().join("backup");
        let target_file = temp_dir.path().join("sensitive.key");
        
        fs::create_dir_all(&backup_dir).unwrap();
        fs::write(&target_file, b"SENSITIVE_DATA").unwrap();
        
        let storage = LocalFs::new(backup_dir.clone());
        
        // Attack: Create malicious CompactionTimestampsMeta
        let malicious_handle = format!(
            "metadata/../../sensitive.key"
        );
        
        // Trigger backup_metadata_file with malicious handle
        let result = storage.backup_metadata_file(&malicious_handle).await;
        
        // Verify: The sensitive file was moved to backup directory
        if result.is_ok() {
            let exfiltrated = backup_dir.join("metadata_backup/sensitive.key");
            assert!(exfiltrated.exists(), "File was moved via path traversal");
            assert!(!target_file.exists(), "Original file was removed");
            
            let content = fs::read(&exfiltrated).unwrap();
            assert_eq!(content, b"SENSITIVE_DATA", "Sensitive data exfiltrated");
        }
    }
}
```

## Notes

This vulnerability demonstrates a critical security principle: **never trust deserialized data from external storage without validation**. Even though the normal code paths through `list_metadata_files()` are safe, the metadata deserialization path bypasses all protections. The lack of centralized `FileHandle` validation allows malicious data to propagate through multiple system layers before triggering the path traversal.

The fix requires defense-in-depth: validate at deserialization time, validate before filesystem operations, and consider implementing allow-list based path restrictions for backup operations.

### Citations

**File:** storage/backup/backup-cli/src/metadata/mod.rs (L203-207)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, Eq)]
pub struct CompactionTimestampsMeta {
    pub file_compacted_at: u64,
    pub compaction_timestamps: HashMap<FileHandle, Option<u64>>,
}
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L29-78)
```rust
    pub(crate) fn new(metadata_vec: Vec<Metadata>, file_handles: Vec<FileHandle>) -> Self {
        let mut epoch_ending_backups = Vec::new();
        let mut state_snapshot_backups = Vec::new();
        let mut transaction_backups = Vec::new();
        let mut identity = None;
        let mut compaction_timestamps = Vec::new();

        for meta in metadata_vec {
            match meta {
                Metadata::EpochEndingBackup(e) => epoch_ending_backups.push(e),
                Metadata::StateSnapshotBackup(s) => state_snapshot_backups.push(s),
                Metadata::TransactionBackup(t) => transaction_backups.push(t),
                Metadata::Identity(i) => identity = Some(i),
                Metadata::CompactionTimestamps(t) => compaction_timestamps.push(t),
            }
        }
        epoch_ending_backups.sort_unstable();
        epoch_ending_backups.dedup();
        state_snapshot_backups.sort_unstable();
        state_snapshot_backups.dedup();
        transaction_backups.sort_unstable();
        transaction_backups.dedup();

        let mut compaction_meta_opt = compaction_timestamps.iter().max().cloned();
        if let Some(ref mut compaction_meta) = compaction_meta_opt {
            // insert new_files into the previous_compaction_timestamps
            for file in file_handles.into_iter() {
                // if file is not in timestamps, set it to None, otherwise, keep it the same
                compaction_meta
                    .compaction_timestamps
                    .entry(file)
                    .or_insert(None);
            }
        } else {
            // Create new compaction timestamp meta with new files only
            let compaction_timestamps = file_handles.into_iter().map(|file| (file, None)).collect();
            compaction_meta_opt = Some(CompactionTimestampsMeta {
                file_compacted_at: duration_since_epoch().as_secs(),
                compaction_timestamps,
            });
        };

        Self {
            epoch_ending_backups,
            state_snapshot_backups,
            transaction_backups,
            _identity: identity,
            compaction_timestamps: compaction_meta_opt,
        }
    }
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L111-123)
```rust
    async fn list_metadata_files(&self) -> Result<Vec<FileHandle>> {
        let dir = self.metadata_dir();
        let rel_path = Path::new(Self::METADATA_DIR);

        let mut res = Vec::new();
        if path_exists(&dir).await {
            let mut entries = read_dir(&dir).await.err_notes(&dir)?;
            while let Some(entry) = entries.next_entry().await.err_notes(&dir)? {
                res.push(rel_path.join(entry.file_name()).path_to_string()?)
            }
        }
        Ok(res)
    }
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L127-146)
```rust
    async fn backup_metadata_file(&self, file_handle: &FileHandleRef) -> Result<()> {
        let dir = self.metadata_backup_dir();

        // Check if the backup directory exists, create it if it doesn't
        if !dir.exists() {
            create_dir_all(&dir).await?;
        }

        // Get the file name and the backup file path
        let name = Path::new(file_handle)
            .file_name()
            .and_then(OsStr::to_str)
            .ok_or_else(|| format_err!("cannot extract filename from {}", file_handle))?;
        let mut backup_path = PathBuf::from(&dir);
        backup_path.push(name);

        // Move the file to the backup directory
        rename(&self.dir.join(file_handle), &backup_path).await?;

        Ok(())
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L237-246)
```rust
    async fn load_metadata_lines(&mut self) -> Result<Vec<Metadata>> {
        let mut buf = String::new();
        self.read_to_string(&mut buf)
            .await
            .err_notes((file!(), line!(), &buf))?;
        Ok(buf
            .lines()
            .map(serde_json::from_str::<Metadata>)
            .collect::<Result<_, serde_json::error::Error>>()?)
    }
```
