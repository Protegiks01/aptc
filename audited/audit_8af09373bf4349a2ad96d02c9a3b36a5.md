# Audit Report

## Title
KV-Only Replay Bypasses Critical State Checkpoint Hash Validation in ChunkExecutor Leading to State Inconsistency

## Summary
The `replay_kv()` function in transaction restore directly saves transactions and applies write sets without involving ChunkExecutor, bypassing critical validation that ensures `state_checkpoint_hash` values in `TransactionInfo` match the actual computed state root. This allows corrupted backup data to create state inconsistencies that break consensus determinism.

## Finding Description

The vulnerability exists in the KV-only replay path used during database restore operations. When restoring from backups with `--kv_only_replay=true`, the system takes a shortcut that bypasses ChunkExecutor's validation logic.

**Normal replay path with ChunkExecutor validation:** [1](#0-0) 

The normal `replay_transactions()` path uses ChunkExecutor which performs critical validations:

1. **State checkpoint hash validation** - DoStateCheckpoint validates that known state checkpoint hashes from `TransactionInfo` match the computed state root: [2](#0-1) 

2. **Transaction info matching** - After computing ledger updates, ChunkExecutor verifies all `TransactionInfo` fields match expected values: [3](#0-2) 

3. The verification ensures computed transaction infos match expected ones: [4](#0-3) 

**KV-only replay path that bypasses validation:** [5](#0-4) 

The `replay_kv()` function directly calls `save_transactions_and_replay_kv()` which: [6](#0-5) 

**The critical flaw:** Lines 223-228 write `TransactionInfo` objects directly to the database without any validation. Lines 269-276 apply write sets to compute the state, but **never validate** that the `state_checkpoint_hash` field in each `TransactionInfo` matches the computed state root.

**TransactionInfo structure contains critical hash fields:** [7](#0-6) 

**Attack scenario:**

1. Attacker corrupts backup data to modify `state_checkpoint_hash` in `TransactionInfo` objects while keeping `write_sets` unchanged
2. Victim node restores using KV-only mode (used by default in restore coordinator): [8](#0-7) 

3. The corrupted `TransactionInfo` with wrong `state_checkpoint_hash` is written to database
4. State is computed correctly from write sets, creating mismatch
5. Transaction accumulator is built using hashes of corrupted `TransactionInfo` objects
6. Result: State merkle tree root â‰  `state_checkpoint_hash` in `TransactionInfo`

## Impact Explanation

This qualifies as **HIGH severity** per Aptos bug bounty criteria for "Significant protocol violations":

1. **Breaks Consensus Invariant #1**: "All validators must produce identical state roots for identical blocks" - Nodes restoring from different corrupted backups will have different transaction accumulator roots, preventing consensus

2. **Breaks Consensus Invariant #4**: "State transitions must be atomic and verifiable via Merkle proofs" - State is no longer verifiable against transaction infos

3. **Network Partition Risk**: If multiple validators restore from corrupted backups with different `state_checkpoint_hash` values, they cannot reach consensus

4. **State Sync Failure**: Nodes cannot sync state from affected nodes because state root verification will fail

5. **Requires Manual Intervention**: Cannot self-heal, requires coordinated recovery or hard fork

## Likelihood Explanation

**Likelihood: Medium to High**

**Factors increasing likelihood:**
- KV-only replay is the **default mode** in restore coordinator (not an obscure code path)
- Backup corruption can occur through: compromised backup storage, malicious backup service providers, supply chain attacks on backup infrastructure, or insider threats
- No cryptographic protection on backup transaction infos (only signed ledger infos)
- Silent failure - inconsistency is not detected until nodes attempt state sync

**Factors decreasing likelihood:**
- Requires attacker to compromise backup infrastructure
- Requires victim to perform restore operation (not continuous exposure)
- Backup data includes signed ledger infos at chunk boundaries which provide some integrity checking

## Recommendation

Add validation in the KV-only replay path to verify state consistency:

```rust
// In save_transactions_impl, after line 276:
if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
    let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
        &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
        &mut ledger_db_batch.ledger_metadata_db_batches,
        state_kv_batches,
    )?;
    
    // NEW VALIDATION: Verify state checkpoint hashes match computed state
    for (idx, txn_info) in txn_infos.iter().enumerate() {
        if let Some(expected_hash) = txn_info.state_checkpoint_hash() {
            // Find the checkpoint version for this transaction
            let version = first_version + idx as Version;
            if ledger_state.is_checkpoint_at(version) {
                let actual_hash = ledger_state.checkpoint_at(version).root_hash();
                ensure!(
                    expected_hash == actual_hash,
                    "State checkpoint hash mismatch at version {}: expected {}, computed {}",
                    version, expected_hash, actual_hash
                );
            }
        }
    }
    
    state_store.set_state_ignoring_summary(ledger_state);
}
```

Additionally, verify write set and event hashes match transaction infos:

```rust
// Before saving transaction infos (before line 223):
for (idx, (txn_info, ws, events)) in multizip((txn_infos.iter(), write_sets.iter(), events.iter())).enumerate() {
    let version = first_version + idx as Version;
    
    // Verify write set hash
    ensure!(
        txn_info.state_change_hash() == CryptoHash::hash(ws),
        "Write set hash mismatch at version {}", version
    );
    
    // Verify event root hash
    let event_hashes: Vec<_> = events.iter().map(CryptoHash::hash).collect();
    let computed_event_root = InMemoryEventAccumulator::from_leaves(&event_hashes).root_hash();
    ensure!(
        txn_info.event_root_hash() == computed_event_root,
        "Event root hash mismatch at version {}", version
    );
}
```

## Proof of Concept

```rust
// PoC demonstrating the vulnerability
// This would be added as a test in storage/backup/backup-cli/src/backup_types/transaction/restore.rs

#[tokio::test]
async fn test_kv_replay_missing_state_checkpoint_validation() {
    use aptos_crypto::{hash::CryptoHash, HashValue};
    use aptos_types::transaction::{TransactionInfo, ExecutionStatus};
    
    // Setup: Create a restore environment with corrupted backup data
    let (storage, restore_handler, _) = setup_restore_test_environment().await;
    
    // Create a transaction with correct write set but corrupted TransactionInfo
    let txn = create_test_transaction();
    let correct_write_set = create_test_write_set();
    let events = vec![];
    
    // Compute what the correct state checkpoint hash SHOULD be
    let correct_state_root = compute_state_root_from_writeset(&correct_write_set);
    
    // Create CORRUPTED transaction info with WRONG state checkpoint hash
    let corrupted_txn_info = TransactionInfo::new(
        txn.hash(),
        CryptoHash::hash(&correct_write_set), // correct write set hash
        HashValue::zero(), // correct event root (empty)
        Some(HashValue::random()), // WRONG state checkpoint hash! 
        100,
        ExecutionStatus::Success,
        None,
    );
    
    // Perform KV-only replay with corrupted data
    restore_handler.save_transactions_and_replay_kv(
        0, // first_version
        &[txn],
        &[PersistedAuxiliaryInfo::None],
        &[corrupted_txn_info.clone()], // corrupted!
        &[events],
        vec![correct_write_set],
    ).expect("KV replay should succeed despite corruption");
    
    // Verify the vulnerability: State is inconsistent
    let db = restore_handler.aptosdb;
    
    // The TransactionInfo in DB has wrong state_checkpoint_hash
    let saved_txn_info = db.reader.get_transaction_info(0).unwrap();
    assert_eq!(saved_txn_info, corrupted_txn_info);
    
    // But the actual state root is correct
    let actual_state_root = db.reader.get_state_proof(0).unwrap().into_inner().1;
    assert_eq!(actual_state_root, correct_state_root);
    
    // INCONSISTENCY: saved_txn_info.state_checkpoint_hash != actual_state_root
    assert_ne!(
        saved_txn_info.state_checkpoint_hash().unwrap(),
        actual_state_root,
        "BUG: KV replay accepted inconsistent state checkpoint hash!"
    );
    
    // This inconsistency will break consensus and state sync
    // In contrast, the normal replay_transactions path would catch this
}
```

## Notes

This vulnerability demonstrates a critical security principle: **shortcut paths that bypass validation layers are dangerous**. The KV-only replay was likely optimized for performance during large-scale restores, but the optimization removed essential integrity checks that ChunkExecutor provides.

The vulnerability is particularly concerning because:
1. It's in the **default code path** used by restore coordinator
2. The inconsistency is **silent** - no error is raised during restore
3. The impact manifests later during normal operation when nodes attempt consensus or state sync
4. Recovery requires **manual intervention** or coordinated hard fork

The fix should either:
- Add equivalent validation to the KV-only path (recommended)
- Remove KV-only bypass and always use ChunkExecutor (safer but slower)
- Add post-restore verification that validates state consistency before node startup

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L554-637)
```rust
    async fn replay_kv(
        &self,
        restore_handler: &RestoreHandler,
        txns_to_execute_stream: impl Stream<
            Item = Result<(
                Transaction,
                PersistedAuxiliaryInfo,
                TransactionInfo,
                WriteSet,
                Vec<ContractEvent>,
            )>,
        >,
    ) -> Result<()> {
        let (first_version, _) = self.replay_from_version.unwrap();
        restore_handler.force_state_version_for_kv_restore(first_version.checked_sub(1))?;

        let mut base_version = first_version;
        let mut offset = 0u64;
        let replay_start = Instant::now();
        let arc_restore_handler = Arc::new(restore_handler.clone());

        let db_commit_stream = txns_to_execute_stream
            .try_chunks(BATCH_SIZE)
            .err_into::<anyhow::Error>()
            .map_ok(|chunk| {
                let (txns, persisted_aux_info, txn_infos, write_sets, events): (
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                ) = chunk.into_iter().multiunzip();
                let handler = arc_restore_handler.clone();
                base_version += offset;
                offset = txns.len() as u64;
                async move {
                    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["replay_txn_chunk_kv_only"]);
                    tokio::task::spawn_blocking(move || {
                        // we directly save transaction and kvs to DB without involving chunk executor
                        handler.save_transactions_and_replay_kv(
                            base_version,
                            &txns,
                            &persisted_aux_info,
                            &txn_infos,
                            &events,
                            write_sets,
                        )?;
                        // return the last version after the replaying
                        Ok(base_version + offset - 1)
                    })
                    .err_into::<anyhow::Error>()
                    .await
                }
            })
            .try_buffered_x(self.global_opt.concurrent_downloads, 1)
            .and_then(future::ready);

        let total_replayed = db_commit_stream
            .and_then(|version| async move {
                let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_txn_chunk_kv_only"]);
                tokio::task::spawn_blocking(move || {
                    // version is the latest version finishing the KV replaying
                    let total_replayed = version - first_version;
                    TRANSACTION_REPLAY_VERSION.set(version as i64);
                    info!(
                        version = version,
                        accumulative_tps =
                            (total_replayed as f64 / replay_start.elapsed().as_secs_f64()) as u64,
                        "KV replayed."
                    );
                    Ok(version)
                })
                .await?
            })
            .try_fold(0, |_total, total| future::ok(total))
            .await?;
        info!(
            total_replayed = total_replayed,
            accumulative_tps =
                (total_replayed as f64 / replay_start.elapsed().as_secs_f64()) as u64,
            "KV Replay finished."
        );
        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L640-744)
```rust
    async fn replay_transactions(
        &self,
        restore_handler: &RestoreHandler,
        txns_to_execute_stream: impl Stream<
            Item = Result<(
                Transaction,
                PersistedAuxiliaryInfo,
                TransactionInfo,
                WriteSet,
                Vec<ContractEvent>,
            )>,
        >,
    ) -> Result<()> {
        let (first_version, _) = self.replay_from_version.unwrap();
        restore_handler.reset_state_store();
        let replay_start = Instant::now();
        let db = DbReaderWriter::from_arc(Arc::clone(&restore_handler.aptosdb));
        let chunk_replayer = Arc::new(ChunkExecutor::<AptosVMBlockExecutor>::new(db));
        let ledger_update_stream = txns_to_execute_stream
            .try_chunks(BATCH_SIZE)
            .err_into::<anyhow::Error>()
            .map_ok(|chunk| {
                let (txns, persisted_aux_info, txn_infos, write_sets, events): (
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                    Vec<_>,
                ) = chunk.into_iter().multiunzip();
                let chunk_replayer = chunk_replayer.clone();
                let verify_execution_mode = self.verify_execution_mode.clone();

                async move {
                    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["enqueue_chunks"]);

                    tokio::task::spawn_blocking(move || {
                        chunk_replayer.enqueue_chunks(
                            txns,
                            persisted_aux_info,
                            txn_infos,
                            write_sets,
                            events,
                            &verify_execution_mode,
                        )
                    })
                    .await
                    .expect("spawn_blocking failed")
                }
            })
            .try_buffered_x(3, 1)
            .map_ok(|chunks_enqueued| {
                futures::stream::repeat_with(|| Result::Ok(())).take(chunks_enqueued)
            })
            .try_flatten();

        let db_commit_stream = ledger_update_stream
            .map_ok(|()| {
                let chunk_replayer = chunk_replayer.clone();
                async move {
                    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["ledger_update"]);

                    tokio::task::spawn_blocking(move || chunk_replayer.update_ledger())
                        .await
                        .expect("spawn_blocking failed")
                }
            })
            .try_buffered_x(3, 1);

        let total_replayed = db_commit_stream
            .and_then(|()| {
                let chunk_replayer = chunk_replayer.clone();
                async move {
                    let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit"]);

                    tokio::task::spawn_blocking(move || {
                        let v = chunk_replayer.commit()?;

                        let total_replayed = v - first_version + 1;
                        TRANSACTION_REPLAY_VERSION.set(v as i64);
                        info!(
                            version = v,
                            accumulative_tps = (total_replayed as f64
                                / replay_start.elapsed().as_secs_f64())
                                as u64,
                            "Transactions replayed."
                        );
                        Ok(total_replayed)
                    })
                    .await
                    .expect("spawn_blocking failed")
                }
            })
            .try_fold(0, |_prev_total, total| future::ok(total))
            .await?;
        // assert all chunks are fully processed and in DB.
        assert!(chunk_replayer.is_empty());

        info!(
            total_replayed = total_replayed,
            accumulative_tps =
                (total_replayed as f64 / replay_start.elapsed().as_secs_f64()) as u64,
            "Replay finished."
        );
        Ok(())
    }
```

**File:** execution/executor/src/workflow/do_state_checkpoint.rs (L64-70)
```rust
            if let Some(idx) = last_checkpoint_index {
                ensure!(
                    known[idx] == Some(state_summary.last_checkpoint().root_hash()),
                    "Root hash mismatch with known hashes passed in. {:?} vs {:?}",
                    known[idx],
                    Some(&state_summary.last_checkpoint().root_hash()),
                );
```

**File:** execution/executor/src/chunk_executor/mod.rs (L359-365)
```rust
        let ledger_update_output = DoLedgerUpdate::run(
            &output.execution_output,
            &state_checkpoint_output,
            parent_accumulator.clone(),
        )?;

        chunk_verifier.verify_chunk_result(&parent_accumulator, &ledger_update_output)?;
```

**File:** execution/executor-types/src/ledger_update_output.rs (L90-112)
```rust
    pub fn ensure_transaction_infos_match(
        &self,
        transaction_infos: &[TransactionInfo],
    ) -> Result<()> {
        ensure!(
            self.transaction_infos.len() == transaction_infos.len(),
            "Lengths don't match. {} vs {}",
            self.transaction_infos.len(),
            transaction_infos.len(),
        );

        let mut version = self.first_version();
        for (txn_info, expected_txn_info) in
            zip_eq(self.transaction_infos.iter(), transaction_infos.iter())
        {
            ensure!(
                txn_info == expected_txn_info,
                "Transaction infos don't match. version:{version}, txn_info:{txn_info}, expected_txn_info:{expected_txn_info}",
            );
            version += 1;
        }
        Ok(())
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L193-294)
```rust
pub(crate) fn save_transactions_impl(
    state_store: Arc<StateStore>,
    ledger_db: Arc<LedgerDb>,
    first_version: Version,
    txns: &[Transaction],
    persisted_aux_info: &[PersistedAuxiliaryInfo],
    txn_infos: &[TransactionInfo],
    events: &[Vec<ContractEvent>],
    write_sets: &[WriteSet],
    ledger_db_batch: &mut LedgerDbSchemaBatches,
    state_kv_batches: &mut ShardedStateKvSchemaBatch,
    kv_replay: bool,
) -> Result<()> {
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }

    for (idx, aux_info) in persisted_aux_info.iter().enumerate() {
        PersistedAuxiliaryInfoDb::put_persisted_auxiliary_info(
            first_version + idx as Version,
            aux_info,
            &mut ledger_db_batch.persisted_auxiliary_info_db_batches,
        )?;
    }

    for (idx, txn_info) in txn_infos.iter().enumerate() {
        TransactionInfoDb::put_transaction_info(
            first_version + idx as Version,
            txn_info,
            &mut ledger_db_batch.transaction_info_db_batches,
        )?;
    }

    ledger_db
        .transaction_accumulator_db()
        .put_transaction_accumulator(
            first_version,
            txn_infos,
            &mut ledger_db_batch.transaction_accumulator_db_batches,
        )?;

    ledger_db.event_db().put_events_multiple_versions(
        first_version,
        events,
        &mut ledger_db_batch.event_db_batches,
    )?;

    if ledger_db.enable_storage_sharding() {
        for (idx, txn_events) in events.iter().enumerate() {
            for event in txn_events {
                if let Some(event_key) = event.event_key() {
                    if *event_key == new_block_event_key() {
                        LedgerMetadataDb::put_block_info(
                            first_version + idx as Version,
                            event,
                            &mut ledger_db_batch.ledger_metadata_db_batches,
                        )?;
                    }
                }
            }
        }
    }
    // insert changes in write set schema batch
    for (idx, ws) in write_sets.iter().enumerate() {
        WriteSetDb::put_write_set(
            first_version + idx as Version,
            ws,
            &mut ledger_db_batch.write_set_db_batches,
        )?;
    }

    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }

    let last_version = first_version + txns.len() as u64 - 1;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;
    ledger_db_batch
        .ledger_metadata_db_batches
        .put::<DbMetadataSchema>(
            &DbMetadataKey::OverallCommitProgress,
            &DbMetadataValue::Version(last_version),
        )?;

    Ok(())
}
```

**File:** types/src/transaction/mod.rs (L2025-2051)
```rust
pub struct TransactionInfoV0 {
    /// The amount of gas used.
    gas_used: u64,

    /// The vm status. If it is not `Executed`, this will provide the general error class. Execution
    /// failures and Move abort's receive more detailed information. But other errors are generally
    /// categorized with no status code or other information
    status: ExecutionStatus,

    /// The hash of this transaction.
    transaction_hash: HashValue,

    /// The root hash of Merkle Accumulator storing all events emitted during this transaction.
    event_root_hash: HashValue,

    /// The hash value summarizing all changes caused to the world state by this transaction.
    /// i.e. hash of the output write set.
    state_change_hash: HashValue,

    /// The root hash of the Sparse Merkle Tree describing the world state at the end of this
    /// transaction. Depending on the protocol configuration, this can be generated periodical
    /// only, like per block.
    state_checkpoint_hash: Option<HashValue>,

    /// The hash value summarizing PersistedAuxiliaryInfo.
    auxiliary_info_hash: Option<HashValue>,
}
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L289-300)
```rust
            TransactionRestoreBatchController::new(
                transaction_restore_opt,
                Arc::clone(&self.storage),
                txn_manifests,
                Some(db_next_version),
                Some((kv_replay_version, true /* only replay KV */)),
                epoch_history.clone(),
                VerifyExecutionMode::NoVerify,
                None,
            )
            .run()
            .await?;
```
