# Audit Report

## Title
Post-Commit Notification Failure Causes False Commit Failures and Permanent Indexer Desynchronization

## Summary
In `aptosdb_writer.rs`, the `commit_ledger` function writes transaction data to disk before calling `post_commit`. If the `update_sender.send()` call fails within `post_commit`, an error is returned to the caller even though the commit has already been persisted. This creates a critical inconsistency where the database contains committed transactions but the system reports a commit failure, and downstream systems (particularly the internal indexer) permanently miss these committed transactions.

## Finding Description

The vulnerability exists in the commit flow of AptosDB's writer implementation:

**Step 1: Commit is Persisted to Disk**

In the `commit_ledger` function, the ledger info and commit progress are written to the database: [1](#0-0) 

At line 107, `write_schemas(ledger_batch)` durably commits the transaction metadata to RocksDB. This operation is **irreversible** - the data is now persisted on disk.

**Step 2: Post-Commit Notification Fails**

After the commit is persisted, `post_commit` is called: [2](#0-1) 

Inside `post_commit`, if an update subscriber exists, it attempts to send a notification: [3](#0-2) 

The `send()` call on a `tokio::sync::watch::Sender` can only fail when all receivers have been dropped. When this happens, the error is propagated with `?`, causing `post_commit` to return an error.

**Step 3: Error Propagates to Caller**

The error from `post_commit` is returned through `commit_ledger` to the executor: [4](#0-3) 

The executor receives an error and believes the commit failed, but the transactions are already durably committed to the database.

**How the Attack Occurs:**

1. The internal indexer service is initialized with a watch channel receiver: [5](#0-4) 

2. The indexer service runs and waits for updates: [6](#0-5) 

3. If the indexer service crashes, panics, or the receiver is dropped due to any error condition, all receivers are dropped.

4. Subsequent commits write to disk successfully but fail when attempting to send notifications.

5. The consensus layer receives errors for successful commits, creating state inconsistency.

6. The internal indexer never receives notifications about new transactions and permanently falls behind.

**Invariants Broken:**

1. **State Consistency** - Commits succeed on disk but are reported as failed, breaking atomicity guarantees
2. **Deterministic Execution** - Different nodes may have different perceptions of commit success/failure based on indexer state
3. **Transaction Validation** - The system reports failures for successful operations, violating basic correctness

## Impact Explanation

**Severity: High**

This vulnerability meets the **High Severity** criteria for the following reasons:

1. **Validator Node Slowdowns** - Once the indexer crashes, all subsequent commits fail in consensus view but succeed on disk. This causes the node to enter an inconsistent state requiring manual intervention or restart.

2. **API Crashes** - The internal indexer provides critical data for API queries. When it falls permanently behind and misses committed transactions: [7](#0-6) 
   
   API queries depending on indexed data will fail or return stale information.

3. **Significant Protocol Violations** - The fundamental contract that "commit success means data is persisted" is violated. The system reports commit failures for successful commits, breaking the trust model between consensus and storage.

4. **Consensus Confusion** - The consensus layer may retry commits that already succeeded, potentially causing version conflicts or entering error states that require node restart.

## Likelihood Explanation

**Likelihood: Medium-High**

This issue is likely to occur in production environments:

1. **Indexer Service Instability** - The internal indexer service can panic or crash due to:
   - Database errors during indexing operations
   - Resource exhaustion (OOM, disk full)
   - Bugs in the indexing code path
   - Runtime errors in async task execution

2. **Permanent Failure Mode** - Once the receiver is dropped, **every subsequent commit will fail** even though transactions are being committed to disk. This is a permanent failure that persists until node restart.

3. **Production Conditions** - Under high load or stress conditions, the indexer is more likely to encounter errors, making this issue more probable in real-world deployments.

4. **No Recovery Mechanism** - There is no automatic recovery. Once the watch channel receiver is dropped, there's no way to re-establish it without restarting the node.

## Recommendation

The `update_sender.send()` failure should **not** cause the commit to fail, since the commit has already been durably persisted to disk. Instead, the error should be logged and the function should continue.

**Recommended Fix:**

```rust
if let Some(update_sender) = &self.update_subscriber {
    // Don't propagate errors from send() since commit already succeeded
    if let Err(err) = update_sender.send((Instant::now(), version)) {
        // Log the error but don't fail the commit
        error!(
            version = version,
            error = ?err,
            "Failed to send update notification to subscriber - indexer may fall behind"
        );
        // Optionally: Set a metric to alert operators
        // INDEXER_NOTIFICATION_FAILURES.inc();
    }
}
```

**Additional Recommendations:**

1. **Decouple Notification from Commit** - Move notification sending to a separate async task that can retry or handle failures independently.

2. **Add Health Monitoring** - Implement health checks that detect when the indexer falls behind and alert operators.

3. **Graceful Degradation** - Allow the system to continue operating even when the indexer is unavailable.

4. **Consider Moving write_schemas After Notifications** - If notifications are critical, consider sending them before the final commit, though this introduces other consistency concerns.

## Proof of Concept

```rust
// This is a conceptual test demonstrating the vulnerability
// Location: storage/aptosdb/src/db/aptosdb_writer.rs (test module)

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::sync::watch;
    
    #[tokio::test]
    async fn test_commit_succeeds_but_reports_failure_when_receiver_dropped() {
        // Setup: Create AptosDB instance
        let db = setup_test_db();
        
        // Create watch channel and register sender
        let (sender, receiver) = watch::channel((Instant::now(), 0u64));
        db.add_version_update_subscriber(sender).unwrap();
        
        // Drop the receiver to simulate indexer crash
        drop(receiver);
        
        // Prepare a transaction to commit
        let chunk = create_test_chunk(/* ... */);
        
        // Pre-commit the transaction
        db.pre_commit_ledger(chunk.clone(), false).unwrap();
        
        // Attempt to commit - this will fail due to send() error
        let result = db.commit_ledger(
            chunk.expect_last_version(),
            Some(&test_ledger_info),
            Some(chunk)
        );
        
        // BUG: commit_ledger returns an error
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("Failed to send update"));
        
        // BUT: The transaction is actually committed to disk!
        let committed_version = db.ledger_db
            .metadata_db()
            .get_synced_version()
            .unwrap();
        assert_eq!(committed_version, Some(chunk.expect_last_version()));
        
        // VULNERABILITY: The caller thinks commit failed, but data is persisted
        // IMPACT: Consensus will be confused, and indexer missed the transaction
    }
}
```

## Notes

- The issue only manifests when an `update_subscriber` is registered via `add_version_update_subscriber`. Nodes without the internal indexer enabled are not affected. [8](#0-7) 

- The watch channel pattern is specifically used to notify the internal indexer of committed versions, enabling it to process new data without polling. [9](#0-8) 

- Once all receivers are dropped, tokio's `watch::Sender::send()` returns a `SendError`, which is the only failure condition for this operation. This is by design in tokio's watch channel implementation.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L97-107)
```rust
            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L109-111)
```rust
            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L618-624)
```rust
            if let Some(update_sender) = &self.update_subscriber {
                update_sender
                    .send((Instant::now(), version))
                    .map_err(|err| {
                        AptosDbError::Other(format!("Failed to send update to subscriber: {}", err))
                    })?;
            }
```

**File:** execution/executor/src/block_executor/mod.rs (L388-390)
```rust
        self.db
            .writer
            .commit_ledger(target_version, Some(&ledger_info_with_sigs), None)?;
```

**File:** aptos-node/src/storage.rs (L56-61)
```rust
    let (update_sender, update_receiver) = if internal_indexer_db.is_some() {
        let (sender, receiver) = channel::<(Instant, Version)>((Instant::now(), 0 as Version));
        (Some(sender), Some(receiver))
    } else {
        (None, None)
    };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L167-198)
```rust
    pub async fn run(&mut self, node_config: &NodeConfig) -> Result<()> {
        let mut start_version = self.get_start_version(node_config).await?;
        let mut target_version = self.db_indexer.main_db_reader.ensure_synced_version()?;
        let mut step_timer = std::time::Instant::now();

        loop {
            if target_version <= start_version {
                match self.update_receiver.changed().await {
                    Ok(_) => {
                        (step_timer, target_version) = *self.update_receiver.borrow();
                    },
                    Err(e) => {
                        panic!("Failed to get update from update_receiver: {}", e);
                    },
                }
            }
            let next_version = self.db_indexer.process(start_version, target_version)?;
            INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::InternalIndexerDBProcessed,
                Some(start_version as i64),
                Some(next_version as i64),
                None,
                None,
                Some(step_timer.elapsed().as_secs_f64()),
                None,
                Some((next_version - start_version) as i64),
                None,
            );
            start_version = next_version;
        }
```

**File:** storage/aptosdb/src/db/mod.rs (L158-164)
```rust
    pub fn add_version_update_subscriber(
        &mut self,
        sender: Sender<(Instant, Version)>,
    ) -> Result<()> {
        self.update_subscriber = Some(sender);
        Ok(())
    }
```

**File:** storage/aptosdb/src/fast_sync_storage_wrapper.rs (L60-62)
```rust
        if let Some(sender) = update_sender {
            db_main.add_version_update_subscriber(sender)?;
        }
```
