# Audit Report

## Title
Critical Configuration Validation Missing: Zero RPC Timeout Causes Validator Liveness Failure

## Summary
The `batch_request_rpc_timeout_ms` configuration parameter in `QuorumStoreConfig` lacks validation to prevent being set to zero. When set to 0, all batch RPC requests timeout immediately, causing validators to enter an infinite retry loop and fall behind consensus, resulting in total loss of liveness for the affected validator.

## Finding Description
The vulnerability exists in the configuration validation layer of the Aptos consensus system. The `QuorumStoreConfig::default()` function sets `batch_request_rpc_timeout_ms` to 5000ms, but the `ConfigSanitizer::sanitize()` implementation does not validate that this value is non-zero. [1](#0-0) 

When a validator operator misconfigures this value to 0, the following execution path leads to validator failure:

1. The timeout value is converted to a `Duration` in `BatchRequester::request_batch()`: [2](#0-1) 

2. This zero-duration timeout is passed to the network RPC layer: [3](#0-2) 

3. The `Timeout` future implementation polls the wrapped future first, then the delay timer: [4](#0-3) 

4. With a zero-duration timeout, the delay is immediately ready on the first poll (before the network RPC can respond), causing immediate timeout: [5](#0-4) 

5. All batch requests fail with `ExecutorError::CouldNotGetData`: [6](#0-5) 

6. This error propagates through the transaction retrieval pipeline and causes `materialize_block()` to fail: [7](#0-6) 

7. The pipeline catches the error and retries indefinitely: [8](#0-7) 

The validator enters an infinite retry loop, logging warnings every 100ms, unable to execute any blocks requiring quorum store batches, and falling permanently behind consensus.

The `ConfigSanitizer` only validates batch size limits, not timeout values: [9](#0-8) 

## Impact Explanation
**Severity: High** (per Aptos Bug Bounty: "Validator node slowdowns" / "Significant protocol violations")

This is **not** a Critical severity issue because:
- It only affects validators who misconfigure themselves, not the entire network
- It does not allow external attackers to exploit the system
- It requires privileged access to validator configuration files
- The validator can recover by restarting with correct configuration

However, it qualifies as High severity because:
- Affected validators experience **total loss of liveness** - they cannot process blocks
- The validator falls behind consensus and stops participating
- This is a **missing validation bug** that should be caught at startup
- Multiple validators with this misconfiguration could impact network performance

## Likelihood Explanation
**Likelihood: Low to Medium**

While the configuration error is easy to make (accidentally setting the value to 0 in YAML), this requires:
1. Direct access to validator configuration files (privileged operator access)
2. Intentional or accidental modification of the timeout value
3. Restart of the validator node with the bad configuration

The likelihood is reduced by:
- Validator operators are typically careful with configuration
- The default value is correct (5000ms)
- Testing would likely catch this during deployment

However, the likelihood increases because:
- No validation exists to prevent this at startup
- The error message is generic and may not immediately indicate the root cause
- Operators might set it to 0 thinking it means "no timeout" or "unlimited"

## Recommendation
Add validation in the `ConfigSanitizer::sanitize()` method to ensure timeout values are within reasonable bounds:

```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();
        let config = &node_config.consensus.quorum_store;

        // Validate timeout values
        if config.batch_request_rpc_timeout_ms == 0 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_owned(),
                "batch_request_rpc_timeout_ms must be greater than 0".to_string(),
            ));
        }
        
        // Minimum recommended timeout to allow for network latency
        if config.batch_request_rpc_timeout_ms < 100 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_owned(),
                format!(
                    "batch_request_rpc_timeout_ms must be at least 100ms, got {}",
                    config.batch_request_rpc_timeout_ms
                ),
            ));
        }

        // Existing validations...
        Self::sanitize_send_recv_batch_limits(&sanitizer_name, config)?;
        Self::sanitize_batch_total_limits(&sanitizer_name, config)?;

        Ok(())
    }
}
```

## Proof of Concept

**Configuration Test:**
```rust
#[test]
fn test_zero_batch_request_timeout_rejected() {
    let node_config = NodeConfig {
        consensus: ConsensusConfig {
            quorum_store: QuorumStoreConfig {
                batch_request_rpc_timeout_ms: 0,  // Invalid
                ..Default::default()
            },
            ..Default::default()
        },
        ..Default::default()
    };

    let error = QuorumStoreConfig::sanitize(
        &node_config,
        NodeType::Validator,
        Some(ChainId::mainnet()),
    )
    .unwrap_err();
    
    assert!(matches!(error, Error::ConfigSanitizerFailed(_, _)));
}
```

**Reproduction Steps:**
1. Create a validator node with YAML config containing `batch_request_rpc_timeout_ms: 0`
2. Start the validator node
3. Observe that all batch requests timeout immediately
4. Check logs for continuous "[BlockPreparer] failed to prepare block, retrying" warnings
5. Observe validator falls behind consensus and cannot process blocks

**Notes**
This is a **configuration validation bug** rather than a security vulnerability exploitable by external attackers. It requires privileged validator operator access to trigger and only affects the misconfigured validator, not the network as a whole. The issue should be fixed by adding proper configuration validation to prevent operational failures.

### Citations

**File:** config/src/config/quorum_store_config.rs (L130-130)
```rust
            batch_request_rpc_timeout_ms: 5000,
```

**File:** config/src/config/quorum_store_config.rs (L253-271)
```rust
impl ConfigSanitizer for QuorumStoreConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Sanitize the send/recv batch limits
        Self::sanitize_send_recv_batch_limits(
            &sanitizer_name,
            &node_config.consensus.quorum_store,
        )?;

        // Sanitize the batch total limits
        Self::sanitize_batch_total_limits(&sanitizer_name, &node_config.consensus.quorum_store)?;

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L115-115)
```rust
        let rpc_timeout = Duration::from_millis(self.rpc_timeout_ms as u64);
```

**File:** consensus/src/quorum_store/batch_requester.rs (L127-127)
```rust
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** crates/aptos-time-service/src/timeout.rs (L44-54)
```rust
    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let this = self.project();

        // First, try polling the future
        if let Poll::Ready(v) = this.future.poll(cx) {
            return Poll::Ready(Ok(v));
        }

        // Now check the timer
        this.delay.poll(cx).map(|_| Err(Elapsed))
    }
```

**File:** network/framework/src/protocols/rpc/mod.rs (L515-525)
```rust
        let wait_for_response = self
            .time_service
            .timeout(timeout, response_rx)
            .map(|result| {
                // Flatten errors.
                match result {
                    Ok(Ok(response)) => Ok(Bytes::from(response.raw_response)),
                    Ok(Err(oneshot::Canceled)) => Err(RpcError::UnexpectedResponseChannelCancel),
                    Err(timeout::Elapsed) => Err(RpcError::TimedOut),
                }
            });
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L118-120)
```rust
        for result in futures::future::join_all(futures).await {
            all_txns.append(&mut result?);
        }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```
