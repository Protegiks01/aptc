# Audit Report

## Title
Unicode Normalization Bypass in Token Name Uniqueness Allows Duplicate Token Creation

## Summary
The Aptos token system does not perform Unicode normalization on token and collection names before using them as identifiers in `TokenDataId`. This allows attackers to create multiple distinct tokens with visually identical names by using different Unicode normalization forms (NFC vs NFD), bypassing the uniqueness constraint intended to prevent duplicate token names within a collection.

## Finding Description

The vulnerability exists in how token identifiers are created and compared in the token framework. When a new token is created, the system constructs a `TokenDataId` using the collection name and token name as strings. [1](#0-0) [2](#0-1) 

The `String` type in Move is defined as a simple wrapper around bytes with UTF-8 validation but no normalization: [3](#0-2) 

When checking for token uniqueness during token creation, the system verifies that no token with the same `TokenDataId` already exists: [4](#0-3) 

However, since `Table.contains()` uses structural equality (byte-level comparison) and Move strings are not normalized, the same semantic string in different Unicode normalizations will have different byte representations and thus be treated as distinct:

- **NFC**: "Café" = `[C, a, f, é(U+00E9)]` - precomposed
- **NFD**: "Café" = `[C, a, f, e(U+0065), ́(U+0301)]` - decomposed

**Attack Path:**
1. Attacker creates a collection "Premium NFTs"
2. Creates token "Café Token" using NFC normalization (é as U+00E9)
3. System accepts and stores with `TokenDataId { creator, collection: "Premium NFTs", name: "Café Token" (NFC) }`
4. Attacker creates another token "Café Token" using NFD normalization (é as U+0065 + U+0301)
5. Uniqueness check looks for `TokenDataId` with NFD bytes in the table
6. Check returns false (NFD bytes ≠ NFC bytes), allowing creation
7. System now contains two distinct tokens with visually identical names

This breaks the invariant that token names must be unique within a collection, as users and wallets will display both tokens with identical names, causing confusion about which token is which.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos Bug Bounty criteria:

1. **Limited funds loss or manipulation**: Users may mistakenly transfer the wrong token variant, sending valuable NFTs to incorrect recipients or accepting counterfeit tokens believing they are legitimate ones. The confusion between visually identical tokens can lead to financial loss through misidentification.

2. **State inconsistencies requiring intervention**: The blockchain state contains multiple tokens with the same visual identity but different technical identities, requiring manual intervention to identify legitimate tokens and warn users about duplicates.

3. **Scam Vector**: Malicious actors can create fake tokens that appear identical to popular/valuable tokens, deceiving users who rely on visual name matching rather than verifying the exact byte representation.

This does not reach **High Severity** because:
- No validator nodes are affected
- No API crashes occur
- No direct protocol violations at the consensus level

This exceeds **Low Severity** because:
- Actual fund loss is possible through user confusion
- State consistency is materially impacted
- Requires active intervention to resolve

## Likelihood Explanation

**Likelihood: Medium**

This vulnerability is likely to occur because:

1. **Common Use Case**: Many NFT collections use Unicode characters with normalization variants, especially:
   - International names: "Pokémon", "Café", "Naïve Art"
   - Artistic names with accents or special characters
   - Non-English collection names

2. **Easy to Exploit**: Once a creator chooses a name with normalizable characters, creating the duplicate requires minimal effort - simply encode the name in a different normalization form

3. **No Special Privileges**: Any user can create tokens, making this exploitable by any unprivileged attacker

4. **May Occur Accidentally**: Different text editors, keyboards, and input methods may produce different normalizations naturally, leading to unintentional duplicates

The likelihood is not "High" because it requires specific Unicode characters that have normalization variants in the token name.

## Recommendation

Implement Unicode normalization (preferably NFC) for all string fields used as identifiers in `TokenDataId` before storage and comparison.

**Solution 1: Native Normalization Function**

Add a native Move function for Unicode normalization:

```move
// In string.move
native fun internal_normalize_nfc(v: &vector<u8>): vector<u8>;

public fun normalize_nfc(s: &String): String {
    String { bytes: internal_normalize_nfc(&s.bytes) }
}
```

**Solution 2: Validation at Token Creation**

Modify `create_token_data_id` to normalize inputs:

```move
public fun create_token_data_id(
    creator: address,
    collection: String,
    name: String,
): TokenDataId {
    let normalized_collection = string::normalize_nfc(&collection);
    let normalized_name = string::normalize_nfc(&name);
    assert!(normalized_collection.length() <= MAX_COLLECTION_NAME_LENGTH, 
            error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
    assert!(normalized_name.length() <= MAX_NFT_NAME_LENGTH, 
            error::invalid_argument(ENFT_NAME_TOO_LONG));
    TokenDataId { creator, collection: normalized_collection, name: normalized_name }
}
```

The native function should use a Rust Unicode normalization library like `unicode-normalization` crate to ensure consistent normalization across all validators.

## Proof of Concept

```move
#[test(creator = @0xCAFE)]
fun test_unicode_normalization_bypass(creator: &signer) acquires Collections, TokenStore {
    use std::string;
    use std::bcs;
    
    account::create_account_for_test(signer::address_of(creator));
    
    // Create collection
    create_collection(
        creator,
        string::utf8(b"Test Collection"),
        string::utf8(b"Test"),
        string::utf8(b"https://test.com"),
        10,
        vector<bool>[false, false, false]
    );
    
    // Create first token with NFC normalization: "Café" = [C,a,f,é(U+00E9)]
    let nfc_name = string::utf8(b"Caf\xC3\xA9"); // é as U+00E9 (NFC)
    let token_data_id_nfc = create_tokendata(
        creator,
        string::utf8(b"Test Collection"),
        nfc_name,
        string::utf8(b"Token 1"),
        1,
        string::utf8(b"https://test.com"),
        signer::address_of(creator),
        100, 0,
        create_token_mutability_config(&vector<bool>[false, false, false, false, false]),
        vector<String>[],
        vector<vector<u8>>[],
        vector<String>[]
    );
    
    // Create second token with NFD normalization: "Café" = [C,a,f,e(U+0065),́(U+0301)]
    let nfd_name = string::utf8(b"Cafe\xCC\x81"); // e + ́ as U+0065 U+0301 (NFD)
    
    // This should fail with ETOKEN_DATA_ALREADY_EXISTS if normalization worked properly
    // But it will SUCCEED because byte comparison treats NFC ≠ NFD
    let token_data_id_nfd = create_tokendata(
        creator,
        string::utf8(b"Test Collection"),
        nfd_name,
        string::utf8(b"Token 2"),
        1,
        string::utf8(b"https://test.com"),
        signer::address_of(creator),
        100, 0,
        create_token_mutability_config(&vector<bool>[false, false, false, false, false]),
        vector<String>[],
        vector<vector<u8>>[],
        vector<String>[]
    );
    
    // Verify both tokens exist as separate entries
    assert!(check_tokendata_exists(
        signer::address_of(creator), 
        string::utf8(b"Test Collection"),
        nfc_name
    ), 1);
    
    assert!(check_tokendata_exists(
        signer::address_of(creator),
        string::utf8(b"Test Collection"), 
        nfd_name
    ), 2);
    
    // Both tokens have visually identical names but are treated as different tokens
    // This demonstrates the Unicode normalization bypass vulnerability
}
```

**Notes:**
- The vulnerability exists because Move's `String` type performs no Unicode normalization, treating different byte representations of semantically identical strings as distinct values
- This affects all token operations including creation, transfer, lookup, and balance queries
- The issue is most prevalent with characters that have combining diacriticals (é, ñ, ü, etc.) commonly used in international names
- A similar vulnerability could exist in collection names, though the same fix applies
- The recommended solution requires implementing native Unicode normalization support in the Move VM to ensure deterministic execution across all validators

### Citations

**File:** aptos-move/framework/aptos-token/sources/token.move (L177-184)
```text
    struct TokenDataId has copy, drop, store {
        /// The address of the creator, eg: 0xcafe
        creator: address,
        /// The name of collection; this is unique under the same account, eg: "Aptos Animal Collection"
        collection: String,
        /// The name of the token; this is the same as the name field of TokenData
        name: String,
    }
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1276-1285)
```text
        let token_data_id = create_token_data_id(account_addr, collection, name);

        assert!(
            collections.collection_data.contains(token_data_id.collection),
            error::not_found(ECOLLECTION_NOT_PUBLISHED),
        );
        assert!(
            !collections.token_data.contains(token_data_id),
            error::already_exists(ETOKEN_DATA_ALREADY_EXISTS),
        );
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1538-1546)
```text
    public fun create_token_data_id(
        creator: address,
        collection: String,
        name: String,
    ): TokenDataId {
        assert!(collection.length() <= MAX_COLLECTION_NAME_LENGTH, error::invalid_argument(ECOLLECTION_NAME_TOO_LONG));
        assert!(name.length() <= MAX_NFT_NAME_LENGTH, error::invalid_argument(ENFT_NAME_TOO_LONG));
        TokenDataId { creator, collection, name }
    }
```

**File:** third_party/move/move-stdlib/sources/string.move (L12-21)
```text
    /// A `String` holds a sequence of bytes which is guaranteed to be in utf8 format.
    struct String has copy, drop, store {
        bytes: vector<u8>,
    }

    /// Creates a new string from a sequence of bytes. Aborts if the bytes do not represent valid utf8.
    public fun utf8(bytes: vector<u8>): String {
        assert!(internal_check_utf8(&bytes), EINVALID_UTF8);
        String{bytes}
    }
```
