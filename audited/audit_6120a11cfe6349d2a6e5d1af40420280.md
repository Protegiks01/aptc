# Audit Report

## Title
Mempool State Inconsistency Due to Shared Channel in Misconfigured Validator Nodes

## Summary
When a validator node is manually configured with `observer_enabled=true` (contrary to design intent), both `start_consensus()` and `start_consensus_observer()` run simultaneously and share the same `consensus_to_mempool_sender` channel with buffer size 1. This causes transaction rejection notifications to fail when both components attempt to send concurrently, resulting in rejected transactions remaining in mempool.

## Finding Description

The vulnerability occurs when both consensus paths are active on a single validator node: [1](#0-0) [2](#0-1) 

Both functions create separate `MempoolNotifier` instances that use the **same** `consensus_to_mempool_sender` parameter passed in. The channel is created with a buffer size of only 1: [3](#0-2) [4](#0-3) 

When transactions fail execution, `MempoolNotifier::notify_failed_txn` sends `RejectNotification` using `try_send()`: [5](#0-4) 

With a buffer size of 1, if both consensus and observer attempt to send rejection notifications simultaneously, one will succeed and the other's `try_send()` will fail immediately. When this fails, the error is only logged: [6](#0-5) 

This causes rejected transactions to remain in mempool, as they were never notified for removal.

## Impact Explanation

This breaks the **State Consistency** invariant (#4) specifically for mempool state. Rejected transactions should be removed from mempool but remain present, leading to:

1. **Mempool pollution** with known-invalid transactions
2. **Performance degradation** as QuorumStore may re-propose these transactions
3. **Unnecessary execution overhead** from repeatedly executing transactions that will fail

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention" - the mempool contains stale transactions that should have been removed.

## Likelihood Explanation

**LOW Likelihood** - This requires specific misconfiguration:

1. Validator operators must manually set `observer_enabled=true` in their config
2. The configuration optimizer explicitly sets only `publisher_enabled` for validators: [7](#0-6) 

3. Test utilities and documentation show validators should only have `publisher_enabled`: [8](#0-7) 

However, the code doesn't **prevent** this misconfiguration, making it a latent defect.

## Recommendation

Implement configuration validation to prevent invalid combinations:

```rust
// In consensus_provider.rs or node startup
pub fn validate_consensus_observer_config(
    node_config: &NodeConfig,
    has_consensus_network: bool,
) -> Result<()> {
    // Validators should not have observer_enabled
    if has_consensus_network && node_config.consensus_observer.observer_enabled {
        bail!(
            "Invalid configuration: Validator nodes cannot have consensus_observer.observer_enabled=true. \
             Validators should only enable publisher_enabled."
        );
    }
    Ok(())
}
```

Alternative fixes:
1. Use separate channels for consensus and observer with adequate buffering
2. Increase `INTRA_NODE_CHANNEL_BUFFER_SIZE` to accommodate concurrent sends
3. Implement retry logic in `MempoolNotifier` instead of immediate failure

## Proof of Concept

```rust
// Reproduction steps:
// 1. Start a validator node with this config override:
// consensus_observer:
//   observer_enabled: true
//   publisher_enabled: true
//
// 2. Submit transactions that will fail execution (e.g., insufficient gas)
// 3. Observe that both consensus and observer paths execute blocks
// 4. Monitor logs for "try_send" failures: "Failed to notify mempool of rejected txns"
// 5. Query mempool to verify rejected transactions remain present
// 6. Observe QuorumStore re-proposing the same failed transactions

// Verification query:
// Use the inspection service to check mempool contents after blocks with
// rejected transactions, comparing against ledger to identify stale transactions.
```

---

## Notes

**CRITICAL CAVEAT**: This vulnerability **requires validator operator access** to manually misconfigure the node. According to the stated trust model, validator operators are trusted actors. This makes the issue a **configuration defect** rather than an exploitable security vulnerability by external attackers.

The validation checklist requirement "Exploitable by unprivileged attacker (no validator insider access required)" is **NOT met**, as this requires operator-level configuration changes.

While the technical issue is real and causes mempool state inconsistency, it falls into a gray area between "security vulnerability" and "robustness issue." The proper classification depends on whether operator-level misconfigurations are considered in-scope for the bug bounty program.

### Citations

**File:** consensus/src/consensus_provider.rs (L45-63)
```rust
pub fn start_consensus(
    node_config: &NodeConfig,
    network_client: NetworkClient<ConsensusMsg>,
    network_service_events: NetworkServiceEvents<ConsensusMsg>,
    state_sync_notifier: Arc<dyn ConsensusNotificationSender>,
    consensus_to_mempool_sender: mpsc::Sender<QuorumStoreRequest>,
    aptos_db: DbReaderWriter,
    reconfig_events: ReconfigNotificationListener<DbBackedOnChainConfig>,
    vtxn_pool: VTxnPoolState,
    consensus_publisher: Option<Arc<ConsensusPublisher>>,
) -> (Runtime, Arc<StorageWriteProxy>, Arc<QuorumStoreDB>) {
    let runtime = aptos_runtimes::spawn_named_runtime("consensus".into(), None);
    let storage = Arc::new(StorageWriteProxy::new(node_config, aptos_db.reader.clone()));
    let quorum_store_db = Arc::new(QuorumStoreDB::new(node_config.storage.dir()));

    let txn_notifier = Arc::new(MempoolNotifier::new(
        consensus_to_mempool_sender.clone(),
        node_config.consensus.mempool_executed_txn_timeout_ms,
    ));
```

**File:** consensus/src/consensus_provider.rs (L127-157)
```rust
pub fn start_consensus_observer(
    node_config: &NodeConfig,
    consensus_observer_runtime: &Runtime,
    consensus_observer_client: Arc<
        ConsensusObserverClient<NetworkClient<ConsensusObserverMessage>>,
    >,
    consensus_observer_message_receiver: Receiver<(), ConsensusObserverNetworkMessage>,
    consensus_publisher: Option<Arc<ConsensusPublisher>>,
    state_sync_notifier: Arc<dyn ConsensusNotificationSender>,
    consensus_to_mempool_sender: mpsc::Sender<QuorumStoreRequest>,
    aptos_db: DbReaderWriter,
    reconfig_events: Option<ReconfigNotificationListener<DbBackedOnChainConfig>>,
) {
    // Create the (dummy) consensus network client
    let (self_sender, _self_receiver) =
        aptos_channels::new_unbounded(&counters::PENDING_SELF_MESSAGES);
    let consensus_network_client = ConsensusNetworkClient::new(NetworkClient::new(
        vec![],
        vec![],
        HashMap::new(),
        consensus_observer_client.get_peers_and_metadata(),
    ));

    // If the consensus observer is enabled, create the execution client.
    // If not, stub it out with a dummy client.
    let execution_client = if node_config.consensus_observer.observer_enabled {
        // Create the execution proxy
        let txn_notifier = Arc::new(MempoolNotifier::new(
            consensus_to_mempool_sender.clone(),
            node_config.consensus.mempool_executed_txn_timeout_ms,
        ));
```

**File:** aptos-node/src/services.rs (L47-47)
```rust
const INTRA_NODE_CHANNEL_BUFFER_SIZE: usize = 1;
```

**File:** aptos-node/src/services.rs (L184-186)
```rust
    // Create a communication channel between consensus and mempool
    let (consensus_to_mempool_sender, consensus_to_mempool_receiver) =
        mpsc::channel(INTRA_NODE_CHANNEL_BUFFER_SIZE);
```

**File:** consensus/src/txn_notifier.rs (L78-85)
```rust
        let (callback, callback_rcv) = oneshot::channel();
        let req = QuorumStoreRequest::RejectNotification(rejected_txns, callback);

        // send to shared mempool
        self.consensus_to_mempool_sender
            .clone()
            .try_send(req)
            .map_err(anyhow::Error::from)?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L964-971)
```rust
            if let Err(e) = mempool_notifier
                .notify_failed_txn(&txns, user_txn_status)
                .await
            {
                error!(
                    error = ?e, "Failed to notify mempool of rejected txns",
                );
            }
```

**File:** config/src/config/consensus_observer_config.rs (L112-118)
```rust
            NodeType::Validator => {
                if ENABLE_ON_VALIDATORS && !publisher_manually_set {
                    // Only enable the publisher for validators
                    consensus_observer_config.publisher_enabled = true;
                    modified_config = true;
                }
            },
```

**File:** testsuite/smoke-test/src/state_sync_utils.rs (L46-58)
```rust
pub fn enable_consensus_observer(use_consensus_observer: bool, node_config: &mut NodeConfig) {
    if use_consensus_observer {
        match node_config.base.role {
            aptos_config::config::RoleType::Validator => {
                node_config.consensus_observer.publisher_enabled = true;
            },
            aptos_config::config::RoleType::FullNode => {
                node_config.consensus_observer.observer_enabled = true;
                node_config.consensus_observer.publisher_enabled = true;
            },
        }
    }
}
```
