# Audit Report

## Title
Missing Sender Authorization Check in DKG Transcript Request Handler Allows Resource Exhaustion and Potential Information Disclosure

## Summary
The DKG (Distributed Key Generation) message handling code does not verify that `DKGTranscriptRequest` originators are authorized validators with voting power in the current epoch. While network-layer mutual authentication provides partial protection, the application layer lacks explicit authorization validation, creating a gap in defense-in-depth that could be exploited during epoch transitions or through compromised network connections.

## Finding Description

When a `DKGTranscriptRequest` is received by a validator, the request handling code performs only minimal validation before responding with sensitive DKG transcript material. [1](#0-0) 

The `process_rpc_request` function only checks if the request epoch matches the current epoch, then forwards to DKGManager without validating the sender's authorization. [2](#0-1) 

The `process_peer_rpc_msg` function similarly only validates epoch matching and internal state, but does **not** verify that the sender is an authorized validator with voting power. It responds with the full DKG transcript to any peer that passes the epoch check.

In contrast, when handling `DKGTranscript` **responses**, the code properly validates sender authorization: [3](#0-2) 

The transcript aggregation code explicitly checks `peer_power.is_some()` to ensure the sender has voting power and is a legitimate validator before accepting their transcript.

**Attack Vector:**

During epoch transitions, there exists a time window where:
1. The `epoch_state` is updated to the new epoch
2. Network layer's `trusted_peers` may not yet be synchronized
3. A validator removed from the new epoch but still connected could send `DKGTranscriptRequest` messages

Additionally, even within a stable epoch, a malicious validator could:
1. Send repeated `DKGTranscriptRequest` messages to all validators
2. Force each validator to respond with full DKG transcripts
3. Consume network bandwidth and CPU resources for serialization/response generation
4. Potentially extract information about the DKG process through timing analysis [4](#0-3) 

## Impact Explanation

This vulnerability falls under **High Severity** impact per Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: A malicious validator can spam DKGTranscriptRequest messages, forcing other validators to repeatedly serialize and send transcript responses, consuming CPU and network resources. This could degrade consensus performance during critical DKG periods.

2. **Information Disclosure**: Validators that should not have access to certain DKG transcripts (e.g., validators removed in the new epoch during the transition window) could obtain cryptographic material they're not authorized to possess.

3. **Protocol Violations**: The lack of authorization checking violates the principle of least privilege and creates an inconsistency between request and response handling security models.

While the network layer's mutual authentication provides baseline protection, the application layer should enforce its own authorization checks as a defense-in-depth measure, especially given that:
- Transcript responses ARE validated for sender authorization
- The discrepancy suggests transcript requests SHOULD also be validated
- Network-layer protections may have implementation gaps during epoch transitions

## Likelihood Explanation

**Likelihood: Medium to High**

The attack is feasible because:

1. **No Implementation Complexity**: A malicious validator simply needs to send multiple `DKGTranscriptRequest` messages with valid epoch numbers
2. **No Special Privileges Required**: Any validator in the current epoch can exploit this
3. **Timing Window Exists**: During epoch transitions, synchronization between `epoch_state` updates and `trusted_peers` updates creates exploitation opportunities
4. **No Rate Limiting**: The code shows no rate limiting or request deduplication for DKGTranscriptRequest messages

The primary mitigation is network-layer mutual authentication, but this is insufficient because:
- It doesn't prevent validators within an epoch from abusing the system
- Epoch transition windows may allow brief exploitation
- Defense-in-depth requires application-layer validation

## Recommendation

Add explicit sender authorization validation in both `EpochManager::process_rpc_request` and `DKGManager::process_peer_rpc_msg`:

```rust
// In EpochManager::process_rpc_request
fn process_rpc_request(
    &mut self,
    peer_id: AccountAddress,
    dkg_request: IncomingRpcRequest,
) -> Result<()> {
    if Some(dkg_request.msg.epoch()) == self.epoch_state.as_ref().map(|s| s.epoch) {
        // Add authorization check
        if let Some(epoch_state) = &self.epoch_state {
            let peer_power = epoch_state.verifier.get_voting_power(&peer_id);
            ensure!(
                peer_power.is_some(),
                "[DKG] rejecting request from unauthorized peer without voting power"
            );
        }
        
        // Forward to DKGManager if it is alive
        if let Some(tx) = &self.dkg_rpc_msg_tx {
            let _ = tx.push(peer_id, (peer_id, dkg_request));
        }
    }
    Ok(())
}
```

Additionally, implement rate limiting to prevent request flooding:

```rust
// Add to DKGManager struct
request_counter: Arc<Mutex<HashMap<AccountAddress, (usize, Instant)>>>,

// In process_peer_rpc_msg
const MAX_REQUESTS_PER_PEER: usize = 10;
const RATE_LIMIT_WINDOW: Duration = Duration::from_secs(60);

// Check rate limit before processing
let mut counters = self.request_counter.lock();
let entry = counters.entry(peer_id).or_insert((0, Instant::now()));
if entry.1.elapsed() > RATE_LIMIT_WINDOW {
    *entry = (1, Instant::now());
} else {
    entry.0 += 1;
    ensure!(
        entry.0 <= MAX_REQUESTS_PER_PEER,
        "[DKG] rate limit exceeded for peer"
    );
}
```

## Proof of Concept

```rust
// Test demonstrating unauthorized request handling
#[tokio::test]
async fn test_unauthorized_dkg_transcript_request() {
    // Setup: Create two validators, V1 in epoch N, V2 removed in epoch N
    let (mut v1_manager, mut v2_peer_id) = setup_test_validators();
    
    // V2 is removed from validator set but still has network connection
    // (simulating epoch transition window)
    
    // V2 sends DKGTranscriptRequest to V1
    let malicious_request = DKGTranscriptRequest::new(v1_manager.epoch_state.epoch);
    let incoming_request = IncomingRpcRequest {
        msg: DKGMessage::TranscriptRequest(malicious_request),
        sender: v2_peer_id,
        response_sender: Box::new(test_response_sender()),
    };
    
    // Current code: Request succeeds even though V2 has no voting power
    let result = v1_manager.process_peer_rpc_msg(incoming_request).await;
    assert!(result.is_ok()); // BUG: Should fail but passes
    
    // V2 receives transcript despite being unauthorized
    // This demonstrates information disclosure
    
    // With fix: Request should be rejected
    // assert!(result.is_err());
    // assert!(result.unwrap_err().to_string().contains("unauthorized peer"));
}
```

**Notes**

While the network layer's mutual authentication with `trusted_peers` provides significant protection, the application layer's lack of explicit authorization checking creates a security gap. The inconsistency between request handling (no validation) and response handling (strict validation) suggests this is an oversight rather than intentional design. During epoch transitions, the asynchronous nature of `epoch_state` updates versus `trusted_peers` updates creates a timing window for exploitation. Additionally, any validator in the current epoch can abuse the system to cause resource exhaustion or information gathering attacks. The fix is straightforward and aligns with the security model already implemented for transcript response validation.

### Citations

**File:** dkg/src/epoch_manager.rs (L94-106)
```rust
    fn process_rpc_request(
        &mut self,
        peer_id: AccountAddress,
        dkg_request: IncomingRpcRequest,
    ) -> Result<()> {
        if Some(dkg_request.msg.epoch()) == self.epoch_state.as_ref().map(|s| s.epoch) {
            // Forward to DKGManager if it is alive.
            if let Some(tx) = &self.dkg_rpc_msg_tx {
                let _ = tx.push(peer_id, (peer_id, dkg_request));
            }
        }
        Ok(())
    }
```

**File:** dkg/src/dkg_manager/mod.rs (L454-478)
```rust
    async fn process_peer_rpc_msg(&mut self, req: IncomingRpcRequest) -> Result<()> {
        let IncomingRpcRequest {
            msg,
            mut response_sender,
            ..
        } = req;
        ensure!(
            msg.epoch() == self.epoch_state.epoch,
            "[DKG] msg not for current epoch"
        );
        let response = match (&self.state, &msg) {
            (InnerState::Finished { my_transcript, .. }, DKGMessage::TranscriptRequest(_))
            | (InnerState::InProgress { my_transcript, .. }, DKGMessage::TranscriptRequest(_)) => {
                Ok(DKGMessage::TranscriptResponse(my_transcript.clone()))
            },
            _ => Err(anyhow!(
                "[DKG] msg {:?} unexpected in state {:?}",
                msg.name(),
                self.state.variant_name()
            )),
        };

        response_sender.send(response);
        Ok(())
    }
```

**File:** dkg/src/transcript_aggregation/mod.rs (L79-86)
```rust
        let peer_power = self.epoch_state.verifier.get_voting_power(&sender);
        ensure!(
            peer_power.is_some(),
            "[DKG] adding peer transcript failed with illegal dealer"
        );
        ensure!(
            metadata.author == sender,
            "[DKG] adding peer transcript failed with node author mismatch"
```

**File:** dkg/src/types.rs (L10-22)
```rust
/// Once DKG starts, a validator should send this message to peers in order to collect DKG transcripts from peers.
#[derive(Clone, Serialize, Deserialize, CryptoHasher, Debug, PartialEq)]
pub struct DKGTranscriptRequest {
    dealer_epoch: u64,
}

impl DKGTranscriptRequest {
    pub fn new(epoch: u64) -> Self {
        Self {
            dealer_epoch: epoch,
        }
    }
}
```
