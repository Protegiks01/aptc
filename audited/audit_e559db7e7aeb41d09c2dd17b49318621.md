# Audit Report

## Title
Validator Network Topology Disclosure via Peer Monitoring Service Cross-Network Information Leak

## Summary
The Peer Monitoring Service's `GetNetworkInformation` endpoint returns connected peers from ALL networks without filtering by the requesting peer's network context. This allows untrusted peers on a validator's VFN (Validator Full Node) network to query and discover the validator's connections on the private validator network, enabling complete mapping of validator network topology.

## Finding Description

The security question asks whether NewPeer/LostPeer events can be used to map validator network topology. While these events are logged at DEBUG level and not exposed via telemetry by default, [1](#0-0)  the underlying peer connection information they represent is directly exposed through a more serious vulnerability in the Peer Monitoring Service.

Validators run multiple networks simultaneously: a private validator network with mutual authentication, and VFN networks that accept connections from validator full nodes. [2](#0-1)  The Peer Monitoring Service is registered on ALL configured networks without network isolation. [3](#0-2) 

When a peer queries `GetNetworkInformation`, the service calls `get_connected_peers_and_metadata()` which iterates through ALL networks and returns all connected peers without filtering: [4](#0-3) 

The handler receives the requesting peer's network_id but only uses it for metrics, not for response filtering: [5](#0-4) 

VFN networks use `MaybeMutual` authentication mode, which accepts connections from any peer (marking them as trusted or untrusted): [6](#0-5) 

**Attack Path:**
1. Attacker operates a malicious VFN or compromises an existing one
2. Attacker connects to target validator's VFN network (accepts untrusted connections by design)
3. Attacker sends `PeerMonitoringServiceRequest::GetNetworkInformation` via RPC [7](#0-6) 
4. Response includes `connected_peers` containing `PeerNetworkId` entries from BOTH the VFN network AND the validator network [8](#0-7) 
5. Each `PeerNetworkId` contains the NetworkId (Validator/Vfn/Public) and PeerId (validator's account address) [9](#0-8) 
6. Attacker queries multiple validators to build complete topology map

## Impact Explanation

This is a **Medium Severity** information disclosure vulnerability per Aptos bug bounty categories. It does not directly cause:
- Loss of funds or consensus violations (Critical)
- Validator node crashes or significant protocol violations (High)

However, it enables:
- Complete mapping of the private validator network topology
- Identification of validator interconnections and network structure
- Information that could facilitate more sophisticated attacks (eclipse attacks, targeted DoS, network analysis)
- Violation of network privacy assumptions for validator operations

The impact is limited to information disclosure but the information revealed (validator network topology) is considered sensitive and could enable follow-on attacks, justifying Medium severity.

## Likelihood Explanation

**High Likelihood**:
- No special privileges required - any peer can connect to VFN networks
- No authentication checks on the Peer Monitoring Service API
- Exploit is trivial: single RPC call returns all network information
- Validators commonly run VFN networks to support their validator full nodes
- The vulnerability is systematic across all validators using standard configurations

The attack requires only:
1. Ability to run a node and connect to validators' VFN networks (public capability)
2. Knowledge of the Peer Monitoring Service protocol (documented in codebase)
3. Basic RPC interaction capability

No cryptographic breaks, race conditions, or complex exploitation chains required.

## Recommendation

**Immediate Fix**: Filter `GetNetworkInformation` responses to only include peers from the same network as the requesting peer.

Modify `Handler::get_network_information()` to accept and use the `network_id` parameter:

```rust
fn get_network_information(
    &self,
    requesting_network_id: NetworkId,
) -> Result<PeerMonitoringServiceResponse, Error> {
    // Get all connected peers
    let all_connected_peers = 
        self.peers_and_metadata.get_connected_peers_and_metadata()?;
    
    // Filter to only peers on the same network as the requester
    let connected_peers = all_connected_peers
        .into_iter()
        .filter(|(peer_network_id, _)| {
            peer_network_id.network_id() == requesting_network_id
        })
        .map(|(peer, metadata)| {
            let connection_metadata = metadata.get_connection_metadata();
            (
                peer,
                ConnectionMetadata::new(
                    connection_metadata.addr,
                    connection_metadata.remote_peer_id,
                    connection_metadata.role,
                ),
            )
        })
        .collect();

    // ... rest of implementation
}
```

Update the call site to pass the network_id parameter.

**Additional Hardening**:
- Consider limiting GetNetworkInformation to trusted peers only on VFN networks
- Add rate limiting per peer for monitoring service queries
- Log suspicious query patterns for security monitoring

## Proof of Concept

```rust
// Conceptual PoC - would need full network setup to execute
use aptos_peer_monitoring_service_types::{
    request::PeerMonitoringServiceRequest,
    response::PeerMonitoringServiceResponse,
};

async fn exploit_topology_leak(vfn_network_client: &NetworkClient) {
    // Connect to validator's VFN network (no special auth required)
    
    // Send GetNetworkInformation request
    let request = PeerMonitoringServiceRequest::GetNetworkInformation;
    
    // Response will include peers from ALL networks including validator network
    let response = vfn_network_client.send_rpc(request).await.unwrap();
    
    if let PeerMonitoringServiceResponse::NetworkInformation(info) = response {
        // Extract validator network peers
        for (peer_network_id, connection_metadata) in info.connected_peers {
            if peer_network_id.network_id() == NetworkId::Validator {
                println!("Discovered validator peer: {} at {}",
                    peer_network_id.peer_id(),
                    connection_metadata.addr
                );
                // Repeat for other validators to build complete topology
            }
        }
    }
}
```

## Notes

While the security question specifically asks about NewPeer/LostPeer log events, the investigation revealed that the actual exploitable vulnerability is in the Peer Monitoring Service API which exposes the same peer connection information more directly. The logs themselves are at DEBUG level [10](#0-9)  and not exposed to untrusted parties by default, but the Peer Monitoring Service provides a direct RPC interface to query this information across network boundaries.

### Citations

**File:** mempool/src/shared_mempool/coordinator.rs (L433-440)
```rust
        for peer in &newly_added_upstream {
            debug!(LogSchema::new(LogEntry::NewPeer).peer(peer));
            tasks::execute_broadcast(*peer, false, smp, scheduled_broadcasts, executor.clone())
                .await;
        }
        for peer in &disabled {
            debug!(LogSchema::new(LogEntry::LostPeer).peer(peer));
        }
```

**File:** config/src/config/test_data/validator.yaml (L21-38)
```yaml
# For validator node we setup two networks, validator_network to allow validator connect to each other,
# and full_node_networks to allow fullnode connects to validator.

full_node_networks:
    - listen_address: "/ip4/0.0.0.0/tcp/6181"
      max_outbound_connections: 0
      identity:
          type: "from_storage"
          key_name: "fullnode_network"
          peer_id_name: "owner_account"
          backend:
              type: "vault"
              server: "https://127.0.0.1:8200"
              ca_certificate: "/full/path/to/certificate"
              token:
                  from_disk: "/full/path/to/token"
      network_id:
          private: "vfn"
```

**File:** aptos-node/src/network.rs (L370-378)
```rust
        // Register the peer monitoring service (both client and server) with the network
        let peer_monitoring_service_network_handle = register_client_and_service_with_network(
            &mut network_builder,
            network_id,
            &network_config,
            peer_monitoring_network_configuration(node_config),
            true,
        );
        peer_monitoring_service_network_handles.push(peer_monitoring_service_network_handle);
```

**File:** network/framework/src/application/storage.rs (L108-125)
```rust
    pub fn get_connected_peers_and_metadata(
        &self,
    ) -> Result<HashMap<PeerNetworkId, PeerMetadata>, Error> {
        // Get the cached peers and metadata
        let cached_peers_and_metadata = self.cached_peers_and_metadata.load();

        // Collect all connected peers
        let mut connected_peers_and_metadata = HashMap::new();
        for (network_id, peers_and_metadata) in cached_peers_and_metadata.iter() {
            for (peer_id, peer_metadata) in peers_and_metadata.iter() {
                if peer_metadata.is_connected() {
                    let peer_network_id = PeerNetworkId::new(*network_id, *peer_id);
                    connected_peers_and_metadata.insert(peer_network_id, peer_metadata.clone());
                }
            }
        }
        Ok(connected_peers_and_metadata)
    }
```

**File:** peer-monitoring-service/server/src/lib.rs (L155-182)
```rust
    pub fn call(
        &self,
        network_id: NetworkId,
        request: PeerMonitoringServiceRequest,
    ) -> Result<PeerMonitoringServiceResponse> {
        // Update the request count
        increment_counter(
            &metrics::PEER_MONITORING_REQUESTS_RECEIVED,
            network_id,
            request.get_label(),
        );

        // Time the request processing (the timer will stop when it's dropped)
        let _timer = start_timer(
            &metrics::PEER_MONITORING_REQUEST_PROCESSING_LATENCY,
            network_id,
            request.get_label(),
        );

        // Process the request
        let response = match &request {
            PeerMonitoringServiceRequest::GetNetworkInformation => self.get_network_information(),
            PeerMonitoringServiceRequest::GetServerProtocolVersion => {
                self.get_server_protocol_version()
            },
            PeerMonitoringServiceRequest::GetNodeInformation => self.get_node_information(),
            PeerMonitoringServiceRequest::LatencyPing(request) => self.handle_latency_ping(request),
        };
```

**File:** peer-monitoring-service/server/src/lib.rs (L217-248)
```rust
    fn get_network_information(&self) -> Result<PeerMonitoringServiceResponse, Error> {
        // Get the connected peers
        let connected_peers_and_metadata =
            self.peers_and_metadata.get_connected_peers_and_metadata()?;
        let connected_peers = connected_peers_and_metadata
            .into_iter()
            .map(|(peer, metadata)| {
                let connection_metadata = metadata.get_connection_metadata();
                (
                    peer,
                    ConnectionMetadata::new(
                        connection_metadata.addr,
                        connection_metadata.remote_peer_id,
                        connection_metadata.role,
                    ),
                )
            })
            .collect();

        // Get the distance from the validators
        let distance_from_validators =
            get_distance_from_validators(&self.base_config, self.peers_and_metadata.clone());

        // Create and return the response
        let network_information_response = NetworkInformationResponse {
            connected_peers,
            distance_from_validators,
        };
        Ok(PeerMonitoringServiceResponse::NetworkInformation(
            network_information_response,
        ))
    }
```

**File:** network/framework/src/noise/handshake.rs (L77-83)
```rust
pub enum HandshakeAuthMode {
    /// In `Mutual` mode, both sides will authenticate each other with their
    /// `trusted_peers` set. We also include replay attack mitigation in this mode.
    ///
    /// For example, in the Aptos validator network, validator peers will only
    /// allow connections from other validator peers. They will use this mode to
    /// check that inbound connections authenticate to a network public key
```

**File:** peer-monitoring-service/types/src/request.rs (L7-13)
```rust
#[derive(Clone, Debug, Deserialize, Eq, Hash, PartialEq, Serialize)]
pub enum PeerMonitoringServiceRequest {
    GetNetworkInformation,    // Returns relevant network information for the peer
    GetNodeInformation,       // Returns relevant node information about the peer
    GetServerProtocolVersion, // Fetches the protocol version run by the server
    LatencyPing(LatencyPingRequest), // A simple message used by the client to ensure liveness and measure latency
}
```

**File:** config/src/network_id.rs (L235-257)
```rust
#[derive(Clone, Copy, Deserialize, Eq, Hash, Ord, PartialEq, PartialOrd, Serialize)]
/// Identifier of a node, represented as (network_id, peer_id)
pub struct PeerNetworkId {
    network_id: NetworkId,
    peer_id: PeerId,
}

impl PeerNetworkId {
    pub fn new(network_id: NetworkId, peer_id: PeerId) -> Self {
        Self {
            network_id,
            peer_id,
        }
    }

    pub fn network_id(&self) -> NetworkId {
        self.network_id
    }

    pub fn peer_id(&self) -> PeerId {
        self.peer_id
    }

```

**File:** config/src/config/logger_config.rs (L40-56)
```rust
impl Default for LoggerConfig {
    fn default() -> LoggerConfig {
        LoggerConfig {
            chan_size: CHANNEL_SIZE,
            enable_backtrace: false,
            is_async: true,
            level: Level::Info,
            enable_telemetry_remote_log: true,
            enable_telemetry_flush: true,
            telemetry_level: Level::Error,

            // This is the default port used by tokio-console.
            // Setting this to None will disable tokio-console
            // even if the "tokio-console" feature is enabled.
            tokio_console_port: None,
        }
    }
```
