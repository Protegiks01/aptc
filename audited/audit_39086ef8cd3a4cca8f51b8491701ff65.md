# Audit Report

## Title
SecretShareManager BlockQueue Not Reset During State Sync Causing Stale Block Processing

## Summary
The `ExecutionProxyClient::reset()` method fails to reset the `SecretShareManager` during state sync operations (`sync_to_target` and `sync_for_duration`), while correctly resetting `rand_manager` and `buffer_manager`. This causes stale blocks from before the sync target to remain in the `BlockQueue`, which can later be processed and sent to the execution pipeline, violating consensus ordering guarantees.

## Finding Description
The vulnerability exists in the state sync reset flow. When a node performs state synchronization to catch up with the network, it must clear all pending consensus state to avoid processing outdated blocks.

The issue occurs in [1](#0-0) 

This `reset()` method only retrieves and resets two components:
- `reset_tx_to_rand_manager` 
- `reset_tx_to_buffer_manager`

However, it **completely omits** `reset_tx_to_secret_share_manager`, which exists in the handle structure as shown in [2](#0-1) 

Compare this to the `end_epoch()` method which correctly resets all three components: [3](#0-2) 

The `SecretShareManager` maintains a `BlockQueue` that stores blocks waiting for secret shares: [4](#0-3) 

When reset is properly triggered, the `process_reset()` method clears the queue: [5](#0-4) 

**Exploitation Path:**

1. Node is at round 100, processing blocks 95-100 which are in `SecretShareManager`'s `BlockQueue` awaiting secret share aggregation
2. Node falls behind and initiates state sync to round 200 via `sync_to_target(target_round_200)`
3. The sync path calls `reset(target)` which:
   - Resets `buffer_manager`: sets `highest_committed_round = 200`, clears all buffers [6](#0-5) 
   - Resets `rand_manager` to round 200
   - **Does NOT reset** `secret_share_manager` - blocks 95-100 remain in `BlockQueue`
4. State sync completes, consensus resumes from round 201
5. New blocks (201+) arrive and are sent to `SecretShareManager` via the coordinator
6. Meanwhile, old blocks (95-100) complete their secret share aggregation
7. `dequeue_ready_prefix()` returns blocks in round order (BTreeMap ordering): [7](#0-6) 
8. Stale blocks 95-100 are sent to `buffer_manager` which has been reset to expect blocks from round 200+
9. `BufferManager::process_ordered_blocks()` has no validation against `highest_committed_round` and processes the stale blocks: [8](#0-7) 

This violates the fundamental consensus invariant that after syncing to round N, only blocks with round > N should be processed.

## Impact Explanation
**Severity: Critical - Consensus Safety Violation**

This vulnerability breaks the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." After a node syncs to round 200, it should only process blocks from round 201 onward. Processing blocks 95-100 after the sync creates several critical issues:

1. **State Divergence**: Different nodes syncing at different times may execute blocks in different orders, leading to state root mismatches
2. **Double Execution Risk**: Blocks partially executed before the sync may be executed again, potentially causing transaction replay
3. **Consensus Violation**: The execution order guarantee is broken, as blocks from before the sync target are processed after blocks from after the sync target
4. **Network Partition Risk**: If this causes state divergence, validators cannot reach consensus on subsequent blocks

This meets the **Critical Severity** criteria per the Aptos bug bounty program: "Consensus/Safety violations" that can cause different nodes to produce different state roots for the same block sequence.

## Likelihood Explanation
**Likelihood: Medium-High**

This vulnerability triggers in common operational scenarios:

1. **State Sync Operations**: Any node performing `sync_to_target` or `sync_for_duration` will experience this bug
2. **Network Partitions**: Nodes recovering from temporary network issues will sync and trigger this
3. **New Validators Joining**: Validators joining the network perform state sync
4. **Lagging Nodes**: Validators that fall behind due to slow execution will sync

The vulnerability does not require malicious input - it's triggered by normal consensus operations. The only condition is that blocks must be pending in `SecretShareManager`'s queue when the sync occurs, which is common during normal operation when secret sharing is enabled.

The impact severity depends on:
- Whether blocks complete secret sharing after the reset
- Whether the stale blocks cause execution errors or are silently processed
- Whether other validators also experience the same issue

## Recommendation
Modify the `reset()` method to include `reset_tx_to_secret_share_manager` in the reset flow, matching the behavior of `end_epoch()`:

```rust
async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
    let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager, reset_tx_to_secret_share_manager) = {
        let handle = self.handle.read();
        (
            handle.reset_tx_to_rand_manager.clone(),
            handle.reset_tx_to_buffer_manager.clone(),
            handle.reset_tx_to_secret_share_manager.clone(),  // ADD THIS LINE
        )
    };

    if let Some(mut reset_tx) = reset_tx_to_rand_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::RandResetDropped)?;
        ack_rx.await.map_err(|_| Error::RandResetDropped)?;
    }

    // ADD THIS BLOCK
    if let Some(mut reset_tx) = reset_tx_to_secret_share_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::SecretShareResetDropped)?;
        ack_rx.await.map_err(|_| Error::SecretShareResetDropped)?;
    }

    if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
        let (tx, rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::ResetDropped)?;
        rx.await.map_err(|_| Error::ResetDropped)?;
    }

    Ok(())
}
```

Additionally, add a corresponding error variant to the `Error` enum:
```rust
SecretShareResetDropped
```

## Proof of Concept
**Rust Reproduction Steps:**

1. **Setup**: Deploy a test network with secret sharing enabled
2. **Create blocks**: Generate blocks 95-100, send them to `SecretShareManager` but delay secret share completion
3. **Trigger sync**: Invoke `sync_to_target(round=200)` while blocks 95-100 are still in the queue
4. **Verify bug**: Observe that `SecretShareManager`'s `BlockQueue` still contains blocks 95-100 after reset
5. **Complete shares**: Allow secret shares for blocks 95-100 to complete
6. **Observe violation**: Blocks 95-100 are sent to `BufferManager` and processed despite being before the sync target round 200

**Expected behavior**: `BlockQueue` should be empty after `reset()`, preventing stale blocks from being processed.

**Actual behavior**: `BlockQueue` retains blocks 95-100, which are later dequeued and sent to the execution pipeline, violating round ordering.

**Verification code** (pseudo-code for test):
```rust
#[tokio::test]
async fn test_secret_share_manager_not_reset_during_sync() {
    // Setup SecretShareManager with blocks 95-100 pending
    let mut manager = setup_secret_share_manager();
    manager.add_blocks(create_blocks(95..=100)).await;
    
    // Verify blocks are in queue
    assert_eq!(manager.block_queue.queue().len(), 6);
    
    // Trigger reset to round 200 (simulating sync_to_target)
    let (tx, rx) = oneshot::channel();
    manager.process_reset(ResetRequest {
        tx,
        signal: ResetSignal::TargetRound(200),
    });
    rx.await.unwrap();
    
    // BUG: BlockQueue is cleared, but via different code path than end_epoch
    // This test would need to be run against the actual reset() in execution_client
    // to show that secret_share_manager is NOT reset while others are
}
```

### Citations

**File:** consensus/src/pipeline/execution_client.rs (L124-131)
```rust
struct BufferManagerHandle {
    pub execute_tx: Option<UnboundedSender<OrderedBlocks>>,
    pub commit_tx:
        Option<aptos_channel::Sender<AccountAddress, (AccountAddress, IncomingCommitRequest)>>,
    pub reset_tx_to_buffer_manager: Option<UnboundedSender<ResetRequest>>,
    pub reset_tx_to_rand_manager: Option<UnboundedSender<ResetRequest>>,
    pub reset_tx_to_secret_share_manager: Option<UnboundedSender<ResetRequest>>,
}
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L711-760)
```rust
    async fn end_epoch(&self) {
        let (
            reset_tx_to_rand_manager,
            reset_tx_to_buffer_manager,
            reset_tx_to_secret_share_manager,
        ) = {
            let mut handle = self.handle.write();
            handle.reset()
        };

        if let Some(mut tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel();
            tx.send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::Stop,
            })
            .await
            .expect("[EpochManager] Fail to drop rand manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop rand manager");
        }

        if let Some(mut tx) = reset_tx_to_secret_share_manager {
            let (ack_tx, ack_rx) = oneshot::channel();
            tx.send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::Stop,
            })
            .await
            .expect("[EpochManager] Fail to drop secret share manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop secret share manager");
        }

        if let Some(mut tx) = reset_tx_to_buffer_manager {
            let (ack_tx, ack_rx) = oneshot::channel();
            tx.send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::Stop,
            })
            .await
            .expect("[EpochManager] Fail to drop buffer manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop buffer manager");
        }
        self.execution_proxy.end_epoch();
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L48-63)
```rust
pub struct SecretShareManager {
    author: Author,
    epoch_state: Arc<EpochState>,
    stop: bool,
    config: SecretShareConfig,
    reliable_broadcast: Arc<ReliableBroadcast<SecretShareMessage, ExponentialBackoff>>,
    network_sender: Arc<NetworkSender>,

    // local channel received from dec_store
    decision_rx: Receiver<SecretSharedKey>,
    // downstream channels
    outgoing_blocks: Sender<OrderedBlocks>,
    // local state
    secret_share_store: Arc<Mutex<SecretShareStore>>,
    block_queue: BlockQueue,
}
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L172-184)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.secret_share_store
            .lock()
            .update_highest_known_round(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L382-424)
```rust
    async fn process_ordered_blocks(&mut self, ordered_blocks: OrderedBlocks) {
        let OrderedBlocks {
            ordered_blocks,
            ordered_proof,
        } = ordered_blocks;

        info!(
            "Receive {} ordered block ends with [epoch: {}, round: {}, id: {}], the queue size is {}",
            ordered_blocks.len(),
            ordered_proof.commit_info().epoch(),
            ordered_proof.commit_info().round(),
            ordered_proof.commit_info().id(),
            self.buffer.len() + 1,
        );

        let request = self.create_new_request(ExecutionRequest {
            ordered_blocks: ordered_blocks.clone(),
        });
        if let Some(consensus_publisher) = &self.consensus_publisher {
            let message = ConsensusObserverMessage::new_ordered_block_message(
                ordered_blocks.clone(),
                ordered_proof.clone(),
            );
            consensus_publisher.publish_message(message);
        }
        self.execution_schedule_phase_tx
            .send(request)
            .await
            .expect("Failed to send execution schedule request");

        let mut unverified_votes = HashMap::new();
        if let Some(block) = ordered_blocks.last() {
            if let Some(votes) = self.pending_commit_votes.remove(&block.round()) {
                for (_, vote) in votes {
                    if vote.commit_info().id() == block.id() {
                        unverified_votes.insert(vote.author(), vote);
                    }
                }
            }
        }
        let item = BufferItem::new_ordered(ordered_blocks, ordered_proof, unverified_votes);
        self.buffer.push_back(item);
    }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L579-596)
```rust
    async fn process_reset_request(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        info!("Receive reset");

        match signal {
            ResetSignal::Stop => self.stop = true,
            ResetSignal::TargetRound(round) => {
                self.highest_committed_round = round;
                self.latest_round = round;

                let _ = self.drain_pending_commit_proof_till(round);
            },
        }

        self.reset().await;
        let _ = tx.send(ResetAck::default());
        info!("Reset finishes");
    }
```

**File:** consensus/src/rand/secret_sharing/block_queue.rs (L112-127)
```rust
    pub fn dequeue_ready_prefix(&mut self) -> Vec<OrderedBlocks> {
        let mut ready_prefix = vec![];
        while let Some((_starting_round, item)) = self.queue.first_key_value() {
            if item.is_fully_secret_shared() {
                let (_, item) = self.queue.pop_first().expect("First key must exist");
                for block in item.blocks() {
                    observe_block(block.timestamp_usecs(), BlockStage::SECRET_SHARING_READY);
                }
                let QueueItem { ordered_blocks, .. } = item;
                ready_prefix.push(ordered_blocks);
            } else {
                break;
            }
        }
        ready_prefix
    }
```
