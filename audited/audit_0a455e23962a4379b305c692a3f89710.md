# Audit Report

## Title
Cross-Shard Dependency Bypass in Block Partitioner Allows Non-Deterministic Parallel Execution

## Summary
The `key_owned_by_another_shard()` function in the block partitioner V2 contains a critical bug that fails to detect cross-shard dependencies when a transaction is located in the anchor shard of a storage key. This allows transactions with read-after-write dependencies to be placed in the same execution round on different shards, violating deterministic execution and potentially causing consensus failures.

## Finding Description

The vulnerability exists in the `key_owned_by_another_shard()` function which is used during the `remove_cross_shard_dependencies()` phase to detect conflicts between transactions in different shards. [1](#0-0) 

When checking if a storage key has cross-shard dependencies, the function computes a range between the anchor shard's starting index and the current shard's starting index. However, when `shard_id == tracker.anchor_shard_id`, both `range_start` and `range_end` are equal, creating an empty range `[X, X)`. [2](#0-1) 

The `has_write_in_range()` function returns `false` for empty ranges, meaning transactions in the anchor shard never detect pending writes from other shards.

**Attack Scenario:**

1. Storage key K is deterministically assigned `anchor_shard_id = 0` via hash: [3](#0-2) 

2. Pre-partitioning assigns:
   - Transaction T1 (reads K) → Shard 0 (anchor shard), PrePartitionedTxnIdx = 1
   - Transaction T2 (writes K) → Shard 1, PrePartitionedTxnIdx = 4

3. During `discarding_round()`: [4](#0-3) 

   - T1 checks `key_owned_by_another_shard(0, K)` → range `[0, 0)` is empty → returns `false` → T1 is **ACCEPTED**
   - T2 checks `key_owned_by_another_shard(1, K)` → range `[0, 3)` is empty (no writes detected) → returns `false` → T2 is **ACCEPTED**

4. Both T1 and T2 are placed in round 0 on different shards and execute in parallel.

5. **Result**: T1 may read stale data while T2 writes new data concurrently, breaking deterministic execution. Different validators may produce different state roots depending on execution timing.

## Impact Explanation

This vulnerability represents a **Critical Severity** issue under the Aptos bug bounty program as it directly violates the **Consensus/Safety** guarantee and breaks the **Deterministic Execution** invariant.

**Specific Impact:**
- **Consensus Split**: Different validators executing the same block may produce different state roots due to race conditions between parallel read and write operations
- **State Corruption**: The blockchain state becomes non-deterministic, potentially causing permanent network forks
- **Requires Hardfork**: Recovery would require manual intervention and potentially a hardfork to restore consensus

This breaks Critical Invariant #1: "All validators must produce identical state roots for identical blocks" and affects the entire network's ability to reach consensus.

## Likelihood Explanation

**Likelihood: HIGH**

The vulnerability is highly likely to be exploited because:

1. **No special privileges required**: Any transaction sender can trigger this by submitting transactions that naturally conflict
2. **Deterministic trigger condition**: The anchor shard is determined by hash, so an attacker can craft storage locations to target specific shards
3. **Natural occurrence**: Even without malicious intent, legitimate workloads with concurrent reads and writes could trigger this bug
4. **No detection mechanism**: The current implementation has no safeguards to detect when this occurs

The probability increases linearly with the number of shards - with more shards, there's a higher chance that conflicting transactions land in the problematic configuration where one is in the anchor shard.

## Recommendation

Modify `key_owned_by_another_shard()` to check **all** other shards for pending writes, not just those between the anchor and current shard:

```rust
pub(crate) fn key_owned_by_another_shard(&self, shard_id: ShardId, key: StorageKeyIdx) -> bool {
    let tracker_ref = self.trackers.get(&key).unwrap();
    let tracker = tracker_ref.read().unwrap();
    
    // Check all shards except the current one
    for other_shard_id in 0..self.num_executor_shards {
        if other_shard_id == shard_id {
            continue;
        }
        let range_start = self.start_txn_idxs_by_shard[other_shard_id];
        let range_end = if other_shard_id + 1 < self.num_executor_shards {
            self.start_txn_idxs_by_shard[other_shard_id + 1]
        } else {
            self.num_txns()
        };
        
        if tracker.has_write_in_range(range_start, range_end) {
            return true;
        }
    }
    false
}
```

Alternatively, remove the anchor-shard optimization entirely and always check all shards for conflicts, accepting the performance cost to ensure correctness.

## Proof of Concept

```rust
#[test]
fn test_cross_shard_dependency_bypass() {
    use crate::pre_partition::uniform_partitioner::UniformPartitioner;
    use crate::v2::PartitionerV2;
    use crate::test_utils::generate_test_account;
    use aptos_types::transaction::analyzed_transaction::AnalyzedTransaction;
    use aptos_types::state_store::state_key::StateKey;
    use move_core_types::account_address::AccountAddress;
    
    // Create 9 transactions for 3 shards (3 per shard)
    let mut sender = generate_test_account();
    
    // Craft a storage key that will hash to anchor_shard_id = 0
    // (In practice, iterate until hash % 3 == 0)
    let target_key = StateKey::raw(b"crafted_key_for_shard_0");
    
    // Create T1: reads target_key (will be in shard 0)
    let t1 = create_read_transaction(&mut sender, &target_key);
    
    // Create 2 filler transactions for shard 0
    let filler1 = create_non_conflicting_transaction();
    let filler2 = create_non_conflicting_transaction();
    
    // Create T2: writes target_key (will be in shard 1) 
    let t2 = create_write_transaction(&mut sender, &target_key);
    
    // Create 5 more filler transactions for shards 1 and 2
    let fillers = (0..5).map(|_| create_non_conflicting_transaction()).collect::<Vec<_>>();
    
    // Construct block: [t1, filler1, filler2, t2, filler3, filler4, filler5, filler6, filler7]
    let mut block = vec![t1, filler1, filler2, t2];
    block.extend(fillers);
    
    let partitioner = PartitionerV2::new(
        4, 4, 0.9, 64, false,
        Box::new(UniformPartitioner {})
    );
    
    let result = partitioner.partition(block, 3);
    
    // Verify bug: Both t1 and t2 should be in round 0
    // t1 in shard 0, t2 in shard 1 - INCORRECT!
    let round_0_txns = &result.0[0];
    
    // Both transactions are in round 0 on different shards
    // This violates deterministic execution
    assert!(round_0_txns.iter().any(|sub_block| 
        sub_block.transactions.iter().any(|txn| is_t1(txn))
    ));
    assert!(round_0_txns.iter().any(|sub_block| 
        sub_block.transactions.iter().any(|txn| is_t2(txn))
    ));
    
    // They should be in different shards
    let t1_shard = find_shard_for_txn(round_0_txns, is_t1);
    let t2_shard = find_shard_for_txn(round_0_txns, is_t2);
    assert_ne!(t1_shard, t2_shard, "BUG: Conflicting transactions in same round, different shards!");
}
```

**Notes:**
- The anchor shard assignment is deterministic based on storage location hash, allowing targeted exploitation
- The bug affects any workload with concurrent reads and writes to the same storage location across different shards
- The vulnerability is present in both `UniformPartitioner` and `ConnectedComponentPartitioner` implementations
- This could cause validators to permanently diverge on state roots, requiring manual intervention

### Citations

**File:** execution/block-partitioner/src/v2/state.rs (L210-217)
```rust
    /// For a key, check if there is any write between the anchor shard and a given shard.
    pub(crate) fn key_owned_by_another_shard(&self, shard_id: ShardId, key: StorageKeyIdx) -> bool {
        let tracker_ref = self.trackers.get(&key).unwrap();
        let tracker = tracker_ref.read().unwrap();
        let range_start = self.start_txn_idxs_by_shard[tracker.anchor_shard_id];
        let range_end = self.start_txn_idxs_by_shard[shard_id];
        tracker.has_write_in_range(range_start, range_end)
    }
```

**File:** execution/block-partitioner/src/v2/conflicting_txn_tracker.rs (L69-84)
```rust
    /// Check if there is a txn writing to the current storage location and its txn_id in the given wrapped range [start, end).
    pub fn has_write_in_range(
        &self,
        start_txn_id: PrePartitionedTxnIdx,
        end_txn_id: PrePartitionedTxnIdx,
    ) -> bool {
        if start_txn_id <= end_txn_id {
            self.pending_writes
                .range(start_txn_id..end_txn_id)
                .next()
                .is_some()
        } else {
            self.pending_writes.range(start_txn_id..).next().is_some()
                || self.pending_writes.range(..end_txn_id).next().is_some()
        }
    }
```

**File:** execution/block-partitioner/src/lib.rs (L39-43)
```rust
fn get_anchor_shard_id(storage_location: &StorageLocation, num_shards: usize) -> ShardId {
    let mut hasher = DefaultHasher::new();
    storage_location.hash(&mut hasher);
    (hasher.finish() % num_shards as u64) as usize
}
```

**File:** execution/block-partitioner/src/v2/partition_to_matrix.rs (L115-142)
```rust
                .for_each(|(shard_id, txn_idxs)| {
                    txn_idxs.into_par_iter().for_each(|txn_idx| {
                        let ori_txn_idx = state.ori_idxs_by_pre_partitioned[txn_idx];
                        let mut in_round_conflict_detected = false;
                        let write_set = state.write_sets[ori_txn_idx].read().unwrap();
                        let read_set = state.read_sets[ori_txn_idx].read().unwrap();
                        for &key_idx in write_set.iter().chain(read_set.iter()) {
                            if state.key_owned_by_another_shard(shard_id, key_idx) {
                                in_round_conflict_detected = true;
                                break;
                            }
                        }

                        if in_round_conflict_detected {
                            let sender = state.sender_idx(ori_txn_idx);
                            min_discard_table
                                .entry(sender)
                                .or_insert_with(|| AtomicUsize::new(usize::MAX))
                                .fetch_min(txn_idx, Ordering::SeqCst);
                            discarded[shard_id].write().unwrap().push(txn_idx);
                        } else {
                            tentatively_accepted[shard_id]
                                .write()
                                .unwrap()
                                .push(txn_idx);
                        }
                    });
                });
```
