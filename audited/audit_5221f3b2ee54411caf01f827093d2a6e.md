# Audit Report

## Title
Indexer Backfiller Silent Task Failure Leading to Permanent Data Loss and Service Hang

## Summary
The file store backfiller's error handling at line 207 uses `.unwrap()` on upload failures within a `tokio::spawn` task, causing only that specific task to panic rather than crashing the entire process as intended. This results in permanent loss of transaction batches, indefinite progress stalling, and silent service degradation without operator notification. [1](#0-0) 

## Finding Description

The backfiller spawns multiple worker tasks to upload transaction batches to storage in parallel. Each worker task processes batches from a shared receiver channel. The code comment explicitly states the intended behavior: "If uploading failure, crash the process and let k8s restart it." [2](#0-1) 

However, the implementation violates this design intent. The `.unwrap()` call on upload failure occurs inside a `tokio::spawn` task. In Rust's tokio runtime, panics inside spawned tasks **only abort that specific task**, not the entire process. The tokio runtime catches the panic and stores it in the task's `JoinHandle`.

The critical flaw is that these `JoinHandle` objects are collected in a vector but never awaited: [3](#0-2) 

The main loop continues indefinitely without ever checking if worker tasks have failed: [4](#0-3) 

**Attack Sequence**:

1. Worker task receives batch of 1000 transactions from receiver (batch consumed and removed from channel)
2. Upload to storage fails due to network error, rate limiting, quota exceeded, or temporary GCS outage
3. `.unwrap()` at line 207 panics, aborting only that worker task
4. Batch is permanently lost - never uploaded, never marked as finished
5. Progress updater waits indefinitely for the lost version to appear in `finished_starting_versions`: [5](#0-4) 

6. Other worker tasks continue uploading later batches successfully
7. Progress file cannot advance past the gap, despite later versions being uploaded
8. Process appears healthy but makes zero forward progress
9. No alerts, no crashes, no indication to operators that the service has failed

The upload function returns `anyhow::Result` which can fail for numerous legitimate reasons: [6](#0-5) 

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria for two reasons:

1. **API Crashes**: The indexer-grpc backfiller is critical API infrastructure for serving historical blockchain data. When this bug triggers, the service effectively crashes - it remains running but becomes non-functional, unable to make progress. This requires manual intervention to identify and resolve.

2. **Significant Protocol Violations**: The backfiller's recovery protocol is fundamentally broken. The system was explicitly designed to handle upload failures via process restart (as stated in the comment), but the implementation silently fails instead.

**Concrete Impact**:
- Permanent data loss: 1000-transaction batches are lost when worker tasks crash
- Service unavailability: Backfiller hangs indefinitely, blocking all progress
- Data integrity violations: Gaps in the indexer's historical data
- Resource waste: Remaining workers continue using CPU, memory, and network uploading batches that cannot be committed
- Operational burden: Requires manual investigation and intervention to detect and fix

While this does not affect consensus or validator operations (indexer is separate infrastructure), it severely impacts the availability and reliability of the Aptos indexer API, which applications depend on for querying historical blockchain data.

## Likelihood Explanation

**Likelihood: HIGH**

Upload failures are a normal operational occurrence in distributed systems:
- Transient network errors
- GCS API rate limiting under high load  
- Storage quota exhaustion
- Temporary credential expiration
- Cloud provider service disruptions
- Network partition between backfiller and GCS

The system was explicitly designed to handle these failures via restart, acknowledging they are expected. Any such failure immediately triggers this bug. Given that the backfiller operates continuously processing large volumes of transactions, encountering upload failures is inevitable over time.

The bug is deterministic - once triggered, it always results in data loss and service hang. No attacker action is required; normal operational conditions will eventually trigger this vulnerability.

## Recommendation

**Fix**: Properly handle upload failures by crashing the entire process as intended. There are three viable approaches:

**Option 1** (Recommended): Use `panic!` explicitly to ensure process termination via the panic handler:

```rust
if let Err(e) = current_file_store_operator
    .upload_transaction_batch(chain_id, transactions.clone())
    .await
{
    panic!("Upload failure - crashing process for k8s restart: {:?}", e);
}
```

**Option 2**: Monitor worker tasks and exit if any fail:

```rust
// After spawning all worker tasks, monitor them
tokio::select! {
    res = async {
        for task in tasks {
            if let Err(e) = task.await {
                return Err(anyhow::anyhow!("Worker task failed: {:?}", e));
            }
        }
        Ok(())
    } => {
        if let Err(e) = res {
            panic!("Worker task panicked: {:?}", e);
        }
    }
    // ... rest of main loop
}
```

**Option 3**: Use proper error handling and return Result from tasks:

```rust
let task = tokio::spawn(async move {
    loop {
        // ... 
        current_file_store_operator
            .upload_transaction_batch(chain_id, transactions)
            .await
            .context("Failed to upload batch")?; // Return error instead of unwrap
        // ...
    }
    Ok(())
});
```

Then await all tasks and propagate errors:

```rust
for task in tasks {
    task.await.context("Task panicked")??.context("Task returned error")?;
}
```

The panic handler will properly terminate the process when these errors occur: [7](#0-6) 

## Proof of Concept

**Rust Test to Reproduce**:

```rust
#[tokio::test]
async fn test_worker_task_panic_not_caught() {
    use std::sync::Arc;
    use tokio::sync::Mutex;
    
    let tasks = Vec::new();
    let finished_versions = Arc::new(Mutex::new(std::collections::BTreeSet::new()));
    
    // Simulate worker task that panics
    let finished_versions_clone = finished_versions.clone();
    let task = tokio::spawn(async move {
        // Simulate upload failure
        let result: Result<(), anyhow::Error> = Err(anyhow::anyhow!("Upload failed"));
        result.unwrap(); // This panics
        
        // This line never executes
        finished_versions_clone.lock().await.insert(1000);
    });
    
    // Main "loop" continues - task panic is not detected
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    // Verify version was never marked as finished
    assert!(finished_versions.lock().await.is_empty());
    
    // Task panicked but process continues
    assert!(task.is_finished());
    assert!(task.await.is_err()); // JoinError indicates panic
}
```

**Simulation Steps**:

1. Deploy backfiller with GCS credentials that will rate-limit (or use test harness with mock storage)
2. Start backfilling large version range
3. Trigger upload failure (disconnect network, exhaust quota, or mock GCS error)
4. Observe: Worker task crashes, batch lost, progress stalls indefinitely
5. Process continues running but progress_file_path shows no advancement
6. Metrics show other batches being uploaded but not committed

This demonstrates that the panic does not crash the process as intended, violating the documented recovery protocol.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L170-171)
```rust
        let mut tasks = Vec::new();
        let receiver_ref = std::sync::Arc::new(Mutex::new(receiver));
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L173-216)
```rust
        for _ in 0..self.backfill_processing_task_count {
            tracing::info!("Creating a new task");
            let mut current_file_store_operator = file_store_operator.clone_box();
            let current_finished_starting_versions = finished_starting_versions.clone();
            let receiver_ref = receiver_ref.clone();
            let task = tokio::spawn(async move {
                tracing::info!("Task started");
                loop {
                    let transactions = {
                        let mut receiver = receiver_ref.lock().await;
                        // Connection may end.
                        let transactions = match receiver.recv().await {
                            Some(transactions) => transactions,
                            None => return Ok(()),
                        };
                        // Data quality check.
                        ensure!(transactions.len() == 1000, "Unexpected transaction count");
                        ensure!(
                            transactions[0].version % 1000 == 0,
                            "Unexpected starting version"
                        );
                        for (ide, t) in transactions.iter().enumerate() {
                            ensure!(
                                t.version == transactions[0].version + ide as u64,
                                "Unexpected version"
                            );
                        }
                        transactions
                    };
                    let starting_version = transactions[0].version;
                    // If uploading failure, crash the process and let k8s restart it.
                    current_file_store_operator
                        .upload_transaction_batch(chain_id, transactions)
                        .await
                        .unwrap();
                    {
                        let mut finished_starting_versions =
                            current_finished_starting_versions.lock().await;
                        finished_starting_versions.insert(starting_version);
                    }
                }
            });
            tasks.push(task);
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L218-259)
```rust
        let task = tokio::spawn(async move {
            loop {
                tokio::time::sleep(Duration::from_millis(5000)).await;
                {
                    {
                        let mut finished_starting_versions =
                            finished_starting_versions.lock().await;
                        let mut need_to_update = false;
                        loop {
                            if finished_starting_versions.contains(&next_version_to_process) {
                                finished_starting_versions.remove(&next_version_to_process);
                                next_version_to_process += 1000;
                                need_to_update = true;
                            } else {
                                break;
                            }
                        }
                        if !need_to_update {
                            continue;
                        }
                    }
                    // Update the progress file.
                    let progress_file = ProgressFile {
                        version: next_version_to_process,
                    };
                    let bytes = serde_json::to_vec(&progress_file)
                        .context("Failed to serialize progress file")?;
                    std::fs::write(&progress_file_path, &bytes)
                        .context("Failed to write progress file")?;
                    tracing::info!(
                        "Progress file updated to version {}",
                        next_version_to_process
                    );
                    if let Some(ending_version) = ending_version {
                        if ending_version <= next_version_to_process {
                            // Backfill is done.
                            std::process::exit(0);
                        }
                    }
                }
            }
        });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L265-302)
```rust
        loop {
            let item = grpc_stream.next().await;
            let item = item.unwrap();
            let response = match item {
                Ok(response) => response,
                Err(e) => {
                    tracing::error!("Failed to get response: {:?}", e);
                    panic!("Failed to get response: {:?}", e);
                },
            };

            let resp = response.response.unwrap();
            match resp {
                Response::Data(txns) => {
                    let transactions = txns.transactions;
                    for txn in transactions {
                        let version = txn.version;
                        // Partial batch may be received; split and insert into buffer.
                        transactions_buffer.insert(version, txn);
                    }
                },
                Response::Status(signal) => {
                    if signal.r#type() != StatusType::BatchEnd {
                        anyhow::bail!("Unexpected status signal type");
                    }
                    while transactions_buffer.len() >= 1000 {
                        // Take the first 1000 transactions.
                        let mut transactions = Vec::new();
                        // Pop the first 1000 transactions from buffer.
                        for _ in 0..1000 {
                            let (_, txn) = transactions_buffer.pop_first().unwrap();
                            transactions.push(txn);
                        }
                        sender.send(transactions).await?;
                    }
                },
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/gcs.rs (L207-246)
```rust
    async fn upload_transaction_batch(
        &mut self,
        _chain_id: u64,
        transactions: Vec<Transaction>,
    ) -> anyhow::Result<(u64, u64)> {
        let start_version = transactions.first().unwrap().version;
        let end_version = transactions.last().unwrap().version;
        let batch_size = transactions.len();
        anyhow::ensure!(
            start_version % FILE_ENTRY_TRANSACTION_COUNT == 0,
            "Starting version has to be a multiple of BLOB_STORAGE_SIZE."
        );
        anyhow::ensure!(
            batch_size == FILE_ENTRY_TRANSACTION_COUNT as usize,
            "The number of transactions to upload has to be multiplier of BLOB_STORAGE_SIZE."
        );
        let start_time = std::time::Instant::now();
        let bucket_name = self.bucket_name.clone();
        let file_entry = FileEntry::from_transactions(transactions, self.storage_format);
        let file_entry_key_path = self.get_file_entry_key_path(start_version);
        log_grpc_step(
            "file_worker",
            IndexerGrpcStep::FileStoreEncodedTxns,
            Some(start_version as i64),
            Some((start_version + FILE_ENTRY_TRANSACTION_COUNT - 1) as i64),
            None,
            None,
            Some(start_time.elapsed().as_secs_f64()),
            None,
            Some(FILE_ENTRY_TRANSACTION_COUNT as i64),
            None,
        );
        Object::create(
            bucket_name.clone().as_str(),
            file_entry.into_inner(),
            file_entry_key_path.as_str(),
            JSON_FILE_TYPE,
        )
        .await?;
        Ok((start_version, end_version))
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L149-168)
```rust
pub fn setup_panic_handler() {
    std::panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());
    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);
    // Kill the process
    process::exit(12);
}
```
