# Audit Report

## Title
Missing Integrity Verification for Backup Metadata Files Enables Undetected Corruption and Manipulation

## Summary
The `save_metadata_lines()` function in the backup system writes metadata files without computing or storing checksums, allowing bit flips, disk corruption, or malicious modifications to go completely undetected during restoration. These metadata files control which backup data gets restored and at what version ranges, making their integrity critical for disaster recovery.

## Finding Description

The backup system stores two types of data: (1) backup data files containing actual blockchain state, transactions, and epochs, which have cryptographic verification; and (2) metadata files that serve as an index/directory pointing to these backup files and specifying their version ranges. [1](#0-0) 

The `save_metadata_lines()` function writes metadata content directly to disk without any integrity protection. It simply writes the bytes and calls `shutdown()` with no checksum computation or storage. [2](#0-1) 

The CommandAdapter implementation also writes metadata without integrity checks.

During restoration, metadata files are loaded and parsed without any integrity verification: [3](#0-2) 

The `load_metadata_lines()` function simply reads the file content and deserializes JSON, with no checksum validation.

These metadata files contain critical information that controls restoration: [4](#0-3) 

The metadata structures include `manifest` FileHandles that point to actual backup data, along with version/epoch ranges. During restoration, this metadata directs which backup files to use: [5](#0-4) [6](#0-5) 

The `select_transaction_backups()` method uses metadata version ranges to select which backups to restore, and extracts manifest FileHandles to load the actual data. If this metadata is corrupted or maliciously modified, the wrong backups may be selected.

**Attack Scenarios:**

1. **Storage Access Attack**: Attacker gains access to backup storage (S3/GCS/Azure bucket via compromised credentials, misconfigured permissions, or storage provider breach) and modifies metadata files to point to wrong manifest files or altered version ranges.

2. **Bit Flip/Corruption**: Hardware failures or storage corruption cause silent bit flips in metadata files that persist undetected through the backup-restore cycle.

3. **Subtle Version Manipulation**: Metadata version ranges are modified to skip critical data or cause overlapping/gapped restores, leading to state inconsistencies.

The vulnerability breaks the **State Consistency** invariant: while the backup data itself has cryptographic verification, the metadata controlling which data gets restored has no integrity protection, creating a gap in the verification chain.

## Impact Explanation

This qualifies as **HIGH severity** under the Aptos bug bounty criteria for the following reasons:

1. **Availability Impact**: Corrupted metadata can prevent successful disaster recovery, causing "validator node slowdowns" or complete restore failures. Validators unable to restore from backup cannot rejoin the network after catastrophic failures.

2. **Significant Protocol Violation**: The lack of integrity verification on metadata that controls critical restoration operations represents a fundamental security gap in the backup/restore subsystem.

3. **Silent Failure Risk**: Unlike obvious corruption that causes immediate errors, subtle metadata manipulation could cause validators to restore incorrect but cryptographically valid backup data (e.g., from wrong version ranges or different network environments), leading to state divergence.

4. **Disaster Recovery Compromise**: The backup system is the last line of defense against data loss. Compromised metadata integrity undermines this critical safety mechanism.

This does not reach CRITICAL severity because it does not directly enable funds theft, consensus safety breaks, or RCE. However, it significantly exceeds MEDIUM severity by affecting core protocol operations rather than isolated components.

## Likelihood Explanation

The likelihood is **MEDIUM to HIGH**:

**Factors Increasing Likelihood:**
- Backup storage is often a high-value target with potentially weaker security than validator nodes themselves
- Cloud storage misconfigurations are common (overly permissive IAM roles, public buckets)
- Storage credentials may be stored in less secure environments than validator keys
- Bit flips and storage corruption are real concerns for long-term backup retention
- No runtime detection means corruption can persist unnoticed until restoration is attempted

**Factors Decreasing Likelihood:**
- Requires storage-level access (not directly network-exploitable)
- Production deployments typically have IAM access controls
- Cryptographic verification of backup data provides partial protection

However, the complete absence of metadata integrity checking means any storage compromise or corruption immediately becomes exploitable with no detection mechanism.

## Recommendation

Implement cryptographic integrity verification for metadata files using SHA-256 or similar hash functions. The fix should include:

1. **During Backup** - Compute checksum when saving metadata:
   - Calculate SHA-256 hash of metadata content
   - Store hash alongside or within metadata file (e.g., as header or companion `.sha256` file)

2. **During Restoration** - Verify checksum when loading metadata:
   - Recompute hash of loaded content
   - Compare against stored hash
   - Fail restoration immediately if mismatch detected

3. **Implementation Approach**:
```rust
// In save_metadata_lines()
use sha2::{Sha256, Digest};

let content = lines.iter().map(|e| e.as_ref()).collect::<Vec<&str>>().join("");
let mut hasher = Sha256::new();
hasher.update(content.as_bytes());
let checksum = format!("{:x}", hasher.finalize());

// Write content
f.write_all(content.as_bytes()).await?;
// Write checksum as final line or separate file
f.write_all(format!("\n__CHECKSUM__:{}", checksum).as_bytes()).await?;
f.shutdown().await?;

// In load_metadata_lines()
// Extract and verify checksum before parsing JSON
```

4. **Backward Compatibility**: Support reading metadata without checksums for existing backups, but emit warnings and require checksums for new backups.

5. **Additional Hardening**: Consider signing metadata files with validator keys for additional authenticity guarantees.

## Proof of Concept

```rust
// PoC demonstrating undetected metadata corruption
// File: storage/backup/backup-cli/tests/metadata_corruption_poc.rs

use aptos_backup_cli::{
    metadata::{Metadata, TransactionBackupMeta},
    storage::{local_fs::LocalFs, BackupStorage, ShellSafeName, TextLine},
};
use std::path::PathBuf;
use tempfile::TempDir;
use tokio;

#[tokio::test]
async fn test_metadata_corruption_undetected() {
    let temp_dir = TempDir::new().unwrap();
    let storage = LocalFs::new(temp_dir.path().to_path_buf());
    
    // Step 1: Save legitimate metadata
    let original_meta = Metadata::new_transaction_backup(0, 999, "backup_0-999.json".to_string());
    let name: ShellSafeName = "transaction_0-999.meta".parse().unwrap();
    let line = TextLine::new(&serde_json::to_string(&original_meta).unwrap()).unwrap();
    
    storage.save_metadata_lines(&name, &[line]).await.unwrap();
    
    // Step 2: Maliciously modify metadata file to point to different backup
    let metadata_file = temp_dir.path().join("metadata").join("transaction_0-999.meta");
    let corrupted_meta = Metadata::new_transaction_backup(0, 999, "malicious_backup.json".to_string());
    let corrupted_content = serde_json::to_string(&corrupted_meta).unwrap() + "\n";
    tokio::fs::write(&metadata_file, corrupted_content).await.unwrap();
    
    // Step 3: Load metadata - corruption is NOT detected
    let loaded = tokio::fs::read_to_string(&metadata_file).await.unwrap();
    let parsed: Metadata = serde_json::from_str(&loaded.lines().next().unwrap()).unwrap();
    
    // Step 4: Verify manifest path was changed without detection
    if let Metadata::TransactionBackup(meta) = parsed {
        assert_eq!(meta.manifest, "malicious_backup.json");
        println!("âœ— VULNERABILITY CONFIRMED: Metadata corruption undetected!");
        println!("  Original manifest: backup_0-999.json");
        println!("  Modified manifest: {}", meta.manifest);
        println!("  No integrity check prevented this modification!");
    }
}
```

**Notes:**
The vulnerability affects all storage backends (LocalFs, CommandAdapter for S3/GCS/Azure) since none implement integrity checking. While backup data has cryptographic verification via TransactionAccumulatorRangeProof and LedgerInfoWithSignatures, the metadata layer lacks any integrity protection, creating a critical gap in the security chain.

### Citations

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L149-181)
```rust
    async fn save_metadata_lines(
        &self,
        name: &ShellSafeName,
        lines: &[TextLine],
    ) -> Result<FileHandle> {
        let dir = self.metadata_dir();
        create_dir_all(&dir).await.err_notes(name)?; // in case not yet created
        let content = lines
            .iter()
            .map(|e| e.as_ref())
            .collect::<Vec<&str>>()
            .join("");
        let path = dir.join(name.as_ref());
        let file = OpenOptions::new()
            .write(true)
            .create_new(true)
            .open(&path)
            .await;
        match file {
            Ok(mut f) => {
                f.write_all(content.as_bytes()).await.err_notes(&path)?;
                f.shutdown().await.err_notes(&path)?;
            },
            Err(e) if e.kind() == io::ErrorKind::AlreadyExists => {
                info!("File {} already exists, Skip", name.as_ref());
            },
            _ => bail!("Unexpected Error in saving metadata file {}", name.as_ref()),
        }
        let fh = PathBuf::from(Self::METADATA_DIR)
            .join(name.as_ref())
            .path_to_string()?;
        Ok(fh)
    }
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/mod.rs (L162-191)
```rust
    async fn save_metadata_lines(
        &self,
        name: &ShellSafeName,
        lines: &[TextLine],
    ) -> Result<FileHandle> {
        let mut child = self
            .cmd(&self.config.commands.save_metadata_line, vec![
                EnvVar::file_name(name.as_ref()),
            ])
            .spawn()?;
        let mut file_handle = FileHandle::new();
        child
            .stdout()
            .read_to_string(&mut file_handle)
            .await
            .err_notes(name)?;
        let content = lines
            .iter()
            .map(|e| e.as_ref())
            .collect::<Vec<&str>>()
            .join("");
        child
            .stdin()
            .write_all(content.as_bytes())
            .await
            .err_notes(name)?;
        child.join().await?;
        file_handle.truncate(file_handle.trim_end().len());
        Ok(file_handle)
    }
```

**File:** storage/backup/backup-cli/src/metadata/cache.rs (L236-247)
```rust
impl<R: AsyncRead + Send + Unpin> LoadMetadataLines for R {
    async fn load_metadata_lines(&mut self) -> Result<Vec<Metadata>> {
        let mut buf = String::new();
        self.read_to_string(&mut buf)
            .await
            .err_notes((file!(), line!(), &buf))?;
        Ok(buf
            .lines()
            .map(serde_json::from_str::<Metadata>)
            .collect::<Result<_, serde_json::error::Error>>()?)
    }
}
```

**File:** storage/backup/backup-cli/src/metadata/mod.rs (L175-196)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct EpochEndingBackupMeta {
    pub first_epoch: u64,
    pub last_epoch: u64,
    pub first_version: Version,
    pub last_version: Version,
    pub manifest: FileHandle,
}

#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct StateSnapshotBackupMeta {
    pub epoch: u64,
    pub version: Version,
    pub manifest: FileHandle,
}

#[derive(Clone, Debug, Deserialize, Serialize, Eq, PartialEq, Ord, PartialOrd)]
pub struct TransactionBackupMeta {
    pub first_version: Version,
    pub last_version: Version,
    pub manifest: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L211-218)
```rust
        let transaction_backups =
            metadata_view.select_transaction_backups(txn_start_version, target_version)?;
        let epoch_ending_backups = metadata_view.select_epoch_ending_backups(target_version)?;
        let epoch_handles = epoch_ending_backups
            .iter()
            .filter(|e| e.first_version <= target_version)
            .map(|backup| backup.manifest.clone())
            .collect();
```

**File:** storage/backup/backup-cli/src/metadata/view.rs (L132-160)
```rust
    pub fn select_transaction_backups(
        &self,
        start_version: Version,
        target_version: Version,
    ) -> Result<Vec<TransactionBackupMeta>> {
        // This can be more flexible, but for now we assume and check backups are continuous in
        // range (which is always true when we backup from a single backup coordinator)
        let mut next_ver = 0;
        let mut res = Vec::new();
        for backup in self.transaction_backups.iter().sorted() {
            if backup.first_version > target_version {
                break;
            }
            ensure!(
                backup.first_version == next_ver,
                "Transaction backup ranges not continuous, expecting version {}, got {}.",
                next_ver,
                backup.first_version,
            );

            if backup.last_version >= start_version {
                res.push(backup.clone());
            }

            next_ver = backup.last_version + 1;
        }

        Ok(res)
    }
```
