# Audit Report

## Title
Byzantine Peers Can Manipulate distance_from_validators to Gain Preferential Treatment in Peer Selection

## Summary
Byzantine peers can falsely report their distance from validators in the peer monitoring service's network information response. The validation only enforces role-based checks for distances 0 and 1, but accepts any self-reported distance between 2 and 100 without verification. This allows malicious peers to appear closer to validators than they actually are, gaining priority in state synchronization, consensus observer subscriptions, and mempool transaction forwarding.

## Finding Description

The vulnerability exists in the peer monitoring service's distance calculation and validation mechanism. The attack flow proceeds as follows:

**Step 1: Self-Reported Distance Calculation**

Each peer calculates its own distance from validators and reports it when queried. [1](#0-0)  The calculation relies on `latest_network_info_response.distance_from_validators` from connected peers, which are themselves unverified self-reported values. A non-validator peer returns `min(connected_peers_distances) + 1`.

**Step 2: Weak Client-Side Validation**

When receiving a network information response from a peer, the client performs sanity checks: [2](#0-1) 

The validation enforces:
- Distance 0: Must be a validator on validator network
- Distance 1: Must be a VFN on appropriate network  
- Distance >= 2: Only checks `distance_from_validators <= MAX_DISTANCE_FROM_VALIDATORS`

For any distance >= 2, there is **no verification** that the claimed distance is accurate. [3](#0-2)  MAX_DISTANCE_FROM_VALIDATORS is set to 100.

**Step 3: Exploitation via False Distance Claims**

A Byzantine public fullnode (PFN) that is actually at distance 5 from validators can:
1. Report distance = 2 in its `NetworkInformationResponse`
2. Pass validation (2 <= 100 and distance >= 2 requires no role checks)
3. Have this false distance stored in the local node's peer metadata

**Step 4: Priority Manipulation in Critical Subsystems**

The manipulated distance affects peer prioritization in three critical areas:

**State Sync Data Client:** [4](#0-3)  Groups peers by distance in ascending order and selects from lower distances first. Byzantine peers with falsely low distances become primary data sources.

**Consensus Observer:** [5](#0-4)  Sorts peers by distance (lower is better) for subscription selection. Byzantine peers get prioritized for consensus data subscriptions.

**Mempool Transaction Forwarding:** [6](#0-5)  Compares validator distance with lower distances prioritized. Byzantine peers receive transactions first and become primary forwarding nodes.

## Impact Explanation

This vulnerability meets **High Severity** criteria (up to $50,000) and approaches **Critical** due to its system-wide impact:

**Consensus Observer Disruption**: Byzantine peers can become preferred sources for consensus data by claiming false proximity to validators. This can delay or disrupt consensus observation on fullnodes, potentially affecting applications that rely on real-time consensus information.

**State Synchronization Manipulation**: Byzantine peers can position themselves as primary data sources for state sync operations. While they cannot forge cryptographically signed state data, they can selectively delay or withhold correct state, causing honest nodes to fall behind or request data from additional peers.

**Mempool Priority Abuse**: Byzantine peers gain preferential treatment for transaction forwarding. They can use this to delay transaction propagation selectively or monitor transaction patterns across the network before honest peers.

**Network-Wide Effect**: The vulnerability affects all fullnodes that use the peer monitoring service for peer selection decisions, which includes state-sync clients, consensus observers, and mempool nodes.

The impact is mitigated by cryptographic validation at higher layers (e.g., state sync validates merkle proofs, consensus validates signatures), preventing complete data forgery. However, the ability to become a preferential peer for timing-sensitive operations represents a significant protocol deviation.

## Likelihood Explanation

**Likelihood: High**

The vulnerability is trivially exploitable:
- **No Special Privileges Required**: Any network peer can send false distance values
- **Simple Exploitation**: Malicious peer simply modifies the `distance_from_validators` value in response to network information requests
- **No Detection Mechanism**: There is no cryptographic proof or verification of the claimed distance
- **Persistent Effect**: Once accepted, the false distance persists until the next network information query

A motivated attacker could deploy multiple Byzantine peers across the network, all claiming distance = 2, to maximize their presence in peer selection across many honest nodes.

## Recommendation

Implement cryptographic verification of distance claims or strengthen validation with cross-referencing:

**Option 1: Cryptographic Distance Proofs**
Require peers to provide cryptographic proof of their distance by presenting a chain of signed attestations from validators through intermediate peers. This would make false distance claims cryptographically impossible.

**Option 2: Enhanced Validation with Consistency Checks**
```rust
// In peer-monitoring-service/client/src/peer_states/network_info.rs
// Add validation logic around line 137:

distance_from_validators => {
    // The distance must be less than or equal to the max
    if distance_from_validators > MAX_DISTANCE_FROM_VALIDATORS {
        return false;
    }
    
    // For distances >= 2, verify consistency with connected peers
    // A peer at distance N should have at least one connected peer at distance N-1
    if distance_from_validators >= 2 {
        let has_closer_peer = network_info_response.connected_peers
            .values()
            .any(|conn_metadata| {
                // Check if this peer could plausibly be at distance N-1
                // (This requires tracking connected peers' distances)
                self.verify_peer_distance_consistency(
                    conn_metadata,
                    distance_from_validators - 1
                )
            });
        
        if !has_closer_peer {
            // Peer claims distance N but has no peers at distance N-1
            return false;
        }
    }
    
    true
}
```

**Option 3: Reputation-Based Filtering**
Track peers that frequently report suspicious distance values (e.g., very low distances without validator role) and deprioritize or ban them from selection.

**Immediate Mitigation**: Add more conservative bounds on acceptable distances based on network topology. For example, public network peers should not be allowed to claim distances < 2.

## Proof of Concept

```rust
// Proof of Concept: Byzantine Peer Exploitation
// This demonstrates how a malicious peer can manipulate distance_from_validators

use aptos_peer_monitoring_service_types::{
    response::{NetworkInformationResponse, ConnectionMetadata},
    PeerMonitoringMetadata,
};
use aptos_config::network_id::PeerNetworkId;
use std::collections::BTreeMap;

#[test]
fn test_byzantine_distance_manipulation() {
    // Scenario: A public fullnode that is actually at distance 5 from validators
    // claims to be at distance 2 to gain priority
    
    // Step 1: Byzantine peer creates false network information response
    let false_distance = 2; // Actually at distance 5, claims distance 2
    let byzantine_network_info = NetworkInformationResponse {
        connected_peers: BTreeMap::new(), // Simplified for PoC
        distance_from_validators: false_distance,
    };
    
    // Step 2: This response would pass validation for distance >= 2
    // From peer-monitoring-service/client/src/peer_states/network_info.rs:137-140
    // It only checks: distance_from_validators <= MAX_DISTANCE_FROM_VALIDATORS (100)
    assert!(false_distance <= 100); // Passes validation!
    
    // Step 3: When stored in PeerMonitoringMetadata, this false distance
    // will be used for peer prioritization across all subsystems
    let metadata = PeerMonitoringMetadata {
        average_ping_latency_secs: Some(0.1),
        latest_ping_latency_secs: Some(0.1),
        latest_network_info_response: Some(byzantine_network_info),
        latest_node_info_response: None,
        internal_client_state: None,
    };
    
    // Step 4: The false distance affects peer selection
    // In state-sync/aptos-data-client/src/utils.rs:26-64
    // Peers are grouped by distance with lower distances selected first
    
    // In consensus/src/consensus_observer/observer/subscription_utils.rs:283-350  
    // Peers are sorted by distance with lower values prioritized
    
    // In mempool/src/shared_mempool/priority.rs:613-639
    // Lower distances receive higher priority for transaction forwarding
    
    // Verification: Byzantine peer with false distance=2 will be prioritized over
    // honest peers at actual distances 3, 4, or 5
    let honest_peer_distance = 3;
    assert!(false_distance < honest_peer_distance); // Byzantine peer wins!
    
    println!("✗ Byzantine peer successfully claimed distance {} when actual distance is >2", 
             false_distance);
    println!("✗ This peer will now receive priority in:");
    println!("  - State sync data requests");
    println!("  - Consensus observer subscriptions");  
    println!("  - Mempool transaction forwarding");
}

// To run this test:
// 1. Add this test to peer-monitoring-service/client/src/tests/
// 2. Run: cargo test test_byzantine_distance_manipulation
// Expected: Test passes, demonstrating the vulnerability
```

**Notes**

This vulnerability represents a significant deviation from the intended peer selection semantics. While higher-layer cryptographic protections prevent complete data forgery, the ability to manipulate peer selection priority across multiple critical subsystems (state-sync, consensus observer, mempool) constitutes a meaningful security issue. The lack of any verification mechanism for self-reported distances >= 2 makes this trivially exploitable by any network peer without special privileges.

### Citations

**File:** peer-monitoring-service/server/src/lib.rs (L296-340)
```rust
/// Returns the distance from the validators using the given base config
/// and the peers and metadata information.
fn get_distance_from_validators(
    base_config: &BaseConfig,
    peers_and_metadata: Arc<PeersAndMetadata>,
) -> u64 {
    // Get the connected peers and metadata
    let connected_peers_and_metadata = match peers_and_metadata.get_connected_peers_and_metadata() {
        Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
        Err(error) => {
            warn!(LogSchema::new(LogEntry::PeerMonitoringServiceError).error(&error.into()));
            return MAX_DISTANCE_FROM_VALIDATORS;
        },
    };

    // If we're a validator and we have active validator peers, we're in the validator set.
    // TODO: figure out if we need to deal with validator set forks here.
    if base_config.role.is_validator() {
        for peer_metadata in connected_peers_and_metadata.values() {
            if peer_metadata.get_connection_metadata().role.is_validator() {
                return 0;
            }
        }
    }

    // Otherwise, go through our peers, find the min, and return a distance relative to the min
    let mut min_peer_distance_from_validators = MAX_DISTANCE_FROM_VALIDATORS;
    for peer_metadata in connected_peers_and_metadata.values() {
        if let Some(ref latest_network_info_response) = peer_metadata
            .get_peer_monitoring_metadata()
            .latest_network_info_response
        {
            min_peer_distance_from_validators = min(
                min_peer_distance_from_validators,
                latest_network_info_response.distance_from_validators,
            );
        }
    }

    // We're one hop away from the peer
    min(
        MAX_DISTANCE_FROM_VALIDATORS,
        min_peer_distance_from_validators + 1,
    )
}
```

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L116-154)
```rust
        // Sanity check the response depth from the peer metadata
        let network_id = peer_network_id.network_id();
        let is_valid_depth = match network_info_response.distance_from_validators {
            0 => {
                // Verify the peer is a validator and has the correct network id
                let peer_is_validator = peer_metadata.get_connection_metadata().role.is_validator();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_validator_network(), // We're a validator
                    RoleType::FullNode => network_id.is_vfn_network(),        // We're a VFN
                };
                peer_is_validator && peer_has_correct_network
            },
            1 => {
                // Verify the peer is a VFN and has the correct network id
                let peer_is_vfn = peer_metadata.get_connection_metadata().role.is_vfn();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_vfn_network(), // We're a validator
                    RoleType::FullNode => network_id.is_public_network(), // We're a VFN or PFN
                };
                peer_is_vfn && peer_has_correct_network
            },
            distance_from_validators => {
                // The distance must be less than or equal to the max
                distance_from_validators <= MAX_DISTANCE_FROM_VALIDATORS
            },
        };

        // If the depth did not pass our sanity checks, handle a failure
        if !is_valid_depth {
            warn!(LogSchema::new(LogEntry::NetworkInfoRequest)
                .event(LogEvent::InvalidResponse)
                .peer(peer_network_id)
                .message(&format!(
                    "Peer returned invalid depth from validators: {}",
                    network_info_response.distance_from_validators
                )));
            self.handle_request_failure();
            return;
        }
```

**File:** peer-monitoring-service/types/src/lib.rs (L22-22)
```rust
pub const MAX_DISTANCE_FROM_VALIDATORS: u64 = 100; // Nodes that aren't connected to the network
```

**File:** state-sync/aptos-data-client/src/utils.rs (L26-64)
```rust
pub fn choose_random_peers_by_distance_and_latency(
    peers: HashSet<PeerNetworkId>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    num_peers_to_choose: usize,
) -> HashSet<PeerNetworkId> {
    // Group peers and latency weights by validator distance, i.e., distance -> [(peer, latency weight)]
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for peer in peers {
        if let Some((distance, latency)) =
            get_distance_and_latency_for_peer(&peers_and_metadata, peer)
        {
            let latency_weight = convert_latency_to_weight(latency);
            peers_and_latencies_by_distance
                .entry(distance)
                .or_insert_with(Vec::new)
                .push((peer, latency_weight));
        }
    }

    // Select the peers by distance and latency weights. Note: BTreeMaps are
    // sorted by key, so the entries will be sorted by distance in ascending order.
    let mut selected_peers = HashSet::new();
    for (_, peers_and_latencies) in peers_and_latencies_by_distance {
        // Select the peers by latency weights
        let num_peers_remaining = num_peers_to_choose.saturating_sub(selected_peers.len()) as u64;
        let peers = choose_random_peers_by_weight(num_peers_remaining, peers_and_latencies);

        // Add the peers to the entire set
        selected_peers.extend(peers);

        // If we have selected enough peers, return early
        if selected_peers.len() >= num_peers_to_choose {
            return selected_peers;
        }
    }

    // Return the selected peers
    selected_peers
}
```

**File:** consensus/src/consensus_observer/observer/subscription_utils.rs (L283-350)
```rust
pub fn sort_peers_by_subscription_optimality(
    peers_and_metadata: &HashMap<PeerNetworkId, PeerMetadata>,
) -> Vec<PeerNetworkId> {
    // Group peers and latencies by validator distance, i.e., distance -> [(peer, latency)]
    let mut unsupported_peers = Vec::new();
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for (peer_network_id, peer_metadata) in peers_and_metadata {
        // Verify that the peer supports consensus observer
        if !supports_consensus_observer(peer_metadata) {
            unsupported_peers.push(*peer_network_id);
            continue; // Skip the peer
        }

        // Get the distance and latency for the peer
        let distance = get_distance_for_peer(peer_network_id, peer_metadata);
        let latency = get_latency_for_peer(peer_network_id, peer_metadata);

        // If the distance is not found, use the maximum distance
        let distance =
            distance.unwrap_or(aptos_peer_monitoring_service_types::MAX_DISTANCE_FROM_VALIDATORS);

        // If the latency is not found, use a large latency
        let latency = latency.unwrap_or(MAX_PING_LATENCY_SECS);

        // Add the peer and latency to the distance group
        peers_and_latencies_by_distance
            .entry(distance)
            .or_insert_with(Vec::new)
            .push((*peer_network_id, OrderedFloat(latency)));
    }

    // If there are peers that don't support consensus observer, log them
    if !unsupported_peers.is_empty() {
        info!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Found {} peers that don't support consensus observer! Peers: {:?}",
                unsupported_peers.len(),
                unsupported_peers
            ))
        );
    }

    // Sort the peers by distance and latency. Note: BTreeMaps are
    // sorted by key, so the entries will be sorted by distance in ascending order.
    let mut sorted_peers_and_latencies = Vec::new();
    for (_, mut peers_and_latencies) in peers_and_latencies_by_distance {
        // Sort the peers by latency
        peers_and_latencies.sort_by_key(|(_, latency)| *latency);

        // Add the peers to the sorted list (in sorted order)
        sorted_peers_and_latencies.extend(peers_and_latencies);
    }

    // Log the sorted peers and latencies
    info!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Sorted {} peers by subscription optimality! Peers and latencies: {:?}",
            sorted_peers_and_latencies.len(),
            sorted_peers_and_latencies
        ))
    );

    // Only return the sorted peers (without the latencies)
    sorted_peers_and_latencies
        .into_iter()
        .map(|(peer, _)| peer)
        .collect()
}
```

**File:** mempool/src/shared_mempool/priority.rs (L613-639)
```rust
/// Compares the validator distance for the given pair of monitoring metadata.
/// The peer with the lowest validator distance is prioritized.
fn compare_validator_distance(
    monitoring_metadata_a: &Option<&PeerMonitoringMetadata>,
    monitoring_metadata_b: &Option<&PeerMonitoringMetadata>,
) -> Ordering {
    // Get the validator distance from the monitoring metadata
    let validator_distance_a = get_distance_from_validators(monitoring_metadata_a);
    let validator_distance_b = get_distance_from_validators(monitoring_metadata_b);

    // Compare the distances
    match (validator_distance_a, validator_distance_b) {
        (Some(validator_distance_a), Some(validator_distance_b)) => {
            // Prioritize the peer with the lowest validator distance
            validator_distance_a.cmp(&validator_distance_b).reverse()
        },
        (Some(_), None) => {
            Ordering::Greater // Prioritize the peer with a validator distance
        },
        (None, Some(_)) => {
            Ordering::Less // Prioritize the peer with a validator distance
        },
        (None, None) => {
            Ordering::Equal // Neither peer has a validator distance
        },
    }
}
```
