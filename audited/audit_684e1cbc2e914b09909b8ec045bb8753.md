# Audit Report

## Title
Unbounded Metrics Cardinality Explosion via Malicious gas_bucket_start Values in Quorum Store Batches

## Summary
A Byzantine validator can create batches with arbitrary `gas_bucket_start` values that are used as metric labels without validation, causing unbounded cardinality explosion in multiple Prometheus metrics and potentially crashing the metrics backend on all validator nodes.

## Finding Description

The Quorum Store consensus component uses the `gas_bucket_start` field from batch metadata as a label in several metrics without validating that it comes from the configured bucket set. [1](#0-0) 

The `gas_bucket_start` value originates from `BatchInfo` deserialized from network messages: [2](#0-1) 

When batches are received and verified, the validation only checks that transaction gas prices are greater than or equal to `gas_bucket_start`, but does NOT validate that `gas_bucket_start` itself is one of the allowed bucket values: [3](#0-2) 

The configured buckets are a fixed set of 10 values: [4](#0-3) 

However, a malicious validator can create batches with any `gas_bucket_start` value. When these batches receive proof-of-store signatures from honest validators (who unknowingly sign them because they pass all verification checks), the arbitrary bucket values are used as labels in four metrics:

1. `REMOTE_POS_COUNT` counter: [5](#0-4) 

2. `LOCAL_POS_COUNT` counter: [6](#0-5) 

3. `POS_TO_PULL` histogram: [1](#0-0) 

4. `POS_TO_COMMIT` histogram: [7](#0-6) 

**Attack Path:**
1. Byzantine validator creates a batch with `gas_bucket_start = 999999999` (or any arbitrary value) and transactions with gas prices >= 999999999
2. Broadcasts batch to network via `BatchMsg`
3. Honest validators receive and verify the batch - it passes validation because transactions satisfy the gas price constraint
4. Byzantine validator collects signatures and creates `ProofOfStore`
5. Proof is inserted on all validators via `insert_proof()`: [8](#0-7) 
6. `inc_remote_pos_count(999999999)` creates new metric label
7. When proof is pulled for blocks, `pos_to_pull(999999999, ...)` creates another label
8. When committed, `pos_to_commit(999999999, ...)` creates another label
9. Attacker repeats with millions of unique bucket values, creating millions of unique metric time series

## Impact Explanation

This is **High Severity** per Aptos bug bounty criteria ("Validator node slowdowns").

Prometheus and similar metrics backends store each unique label combination as a separate time series. With millions of unique bucket values, this causes:

- **Metrics Backend Memory Exhaustion**: Each time series consumes memory; millions of series can exhaust available RAM and crash the metrics system
- **Query Performance Degradation**: Metrics queries scan all time series, becoming extremely slow or timing out with high cardinality
- **Loss of Observability**: Operators lose visibility into validator health, making incident response impossible
- **Operational Instability**: Failed monitoring can mask real issues and delay critical interventions

While not directly causing consensus failure, this degrades the operational infrastructure that validators depend on for production deployment, qualifying as "validator node slowdowns" under High severity.

## Likelihood Explanation

**Likelihood: Medium-High**

- Requires a single Byzantine validator (up to 1/3 of validators under BFT assumptions)
- Does NOT require collusion - honest validators unknowingly sign malicious batches because they pass all verification checks
- Attack is trivial to execute once validator access is obtained
- No rate limiting or detection mechanisms exist for this attack
- Impact is network-wide - all validators' metrics are affected simultaneously

The only barrier is requiring validator status, but Byzantine fault tolerance assumes up to 1/3 malicious validators, making this a realistic threat within the threat model.

## Recommendation

Add validation to ensure `gas_bucket_start` is one of the configured bucket values. This should be checked during batch verification:

**In `consensus/src/quorum_store/types.rs`, modify the `verify()` method:**

```rust
pub fn verify(&self, config_buckets: &[u64]) -> anyhow::Result<()> {
    ensure!(
        self.payload.author() == self.author(),
        "Payload author doesn't match the info"
    );
    ensure!(
        self.payload.hash() == *self.digest(),
        "Payload hash doesn't match the digest"
    );
    ensure!(
        self.payload.num_txns() as u64 == self.num_txns(),
        "Payload num txns doesn't match batch info"
    );
    ensure!(
        self.payload.num_bytes() as u64 == self.num_bytes(),
        "Payload num bytes doesn't match batch info"
    );
    
    // ADD THIS VALIDATION
    ensure!(
        config_buckets.contains(&self.gas_bucket_start()),
        "Invalid gas_bucket_start: {} not in configured buckets",
        self.gas_bucket_start()
    );
    
    for txn in self.payload.txns() {
        ensure!(
            txn.gas_unit_price() >= self.gas_bucket_start(),
            "Payload gas unit price doesn't match batch info"
        );
        ensure!(
            !txn.payload().is_encrypted_variant(),
            "Encrypted transaction is not supported yet"
        );
    }
    Ok(())
}
```

**In `consensus/src/quorum_store/types.rs`, update `BatchMsg::verify()` to pass config buckets:**

```rust
pub fn verify(
    &self,
    peer_id: PeerId,
    max_num_batches: usize,
    verifier: &ValidatorVerifier,
    config_buckets: &[u64],  // ADD THIS PARAMETER
) -> anyhow::Result<()> {
    // ... existing checks ...
    for batch in self.batches.iter() {
        // ... existing checks ...
        batch.verify(config_buckets)?;  // PASS BUCKETS
    }
    Ok(())
}
```

Update all call sites to pass the configured buckets from `QuorumStoreConfig`.

## Proof of Concept

```rust
// Simulated attack demonstrating the vulnerability
// This would be executed by a malicious validator

use aptos_consensus_types::proof_of_store::{BatchInfo, BatchInfoExt};
use aptos_types::transaction::SignedTransaction;

// Create malicious batch with arbitrary bucket
fn create_malicious_batch() -> BatchInfoExt {
    let malicious_bucket = 999999999u64;  // Arbitrary value
    
    // Create transactions with high gas prices
    let txns: Vec<SignedTransaction> = vec![
        // transactions with gas_unit_price >= 999999999
    ];
    
    // Create batch - this will pass verification because
    // txns have gas >= malicious_bucket
    BatchInfoExt::new_v1(
        my_peer_id,
        batch_id,
        epoch,
        expiration,
        digest,
        num_txns,
        num_bytes,
        malicious_bucket,  // EXPLOIT: arbitrary value
    )
}

// Broadcast batch, collect signatures, create proof
// When proof is inserted on any validator:
// 1. inc_remote_pos_count(999999999) - creates new metric label
// 2. Later: pos_to_pull(999999999, ...) - creates new metric label  
// 3. Later: pos_to_commit(999999999, ...) - creates new metric label

// Repeat with millions of unique bucket values:
// for i in 0..1_000_000 {
//     create_and_broadcast_batch_with_bucket(i);
// }
// Result: Millions of unique metric time series, metrics backend crashes
```

**To reproduce:**
1. Deploy validator node with metrics enabled
2. Have Byzantine validator send batches with unique `gas_bucket_start` values outside the configured set (e.g., sequential integers from 1000000 to 2000000)
3. Monitor Prometheus metrics cardinality: `curl localhost:9090/api/v1/status/tsdb` shows time series count growing unbounded
4. Observe metrics query slowdowns and eventual memory exhaustion

## Notes

This vulnerability exists because the consensus protocol assumes validators will only create batches using configured bucket values, but there is no cryptographic or protocol-level enforcement of this assumption. The fix requires adding explicit validation at the batch verification layer.

The vulnerability affects all validators in the network simultaneously when a single Byzantine validator exploits it, making the operational impact network-wide rather than localized.

### Citations

**File:** consensus/src/quorum_store/counters.rs (L446-450)
```rust
pub fn pos_to_pull(bucket: u64, secs: f64) {
    POS_TO_PULL
        .with_label_values(&[bucket.to_string().as_str()])
        .observe(secs)
}
```

**File:** consensus/src/quorum_store/counters.rs (L462-466)
```rust
pub fn pos_to_commit(bucket: u64, secs: f64) {
    POS_TO_COMMIT
        .with_label_values(&[bucket.to_string().as_str()])
        .observe(secs);
}
```

**File:** consensus/src/quorum_store/counters.rs (L645-649)
```rust
pub fn inc_local_pos_count(bucket: u64) {
    LOCAL_POS_COUNT
        .with_label_values(&[bucket.to_string().as_str()])
        .inc()
}
```

**File:** consensus/src/quorum_store/counters.rs (L661-665)
```rust
pub fn inc_remote_pos_count(bucket: u64) {
    REMOTE_POS_COUNT
        .with_label_values(&[bucket.to_string().as_str()])
        .inc()
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L49-58)
```rust
pub struct BatchInfo {
    author: PeerId,
    batch_id: BatchId,
    epoch: u64,
    expiration: u64,
    digest: HashValue,
    num_txns: u64,
    num_bytes: u64,
    gas_bucket_start: u64,
}
```

**File:** consensus/src/quorum_store/types.rs (L279-283)
```rust
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
```

**File:** config/global-constants/src/lib.rs (L36-36)
```rust
pub const DEFAULT_BUCKETS: &[u64] = &[0, 150, 300, 500, 1000, 3000, 5000, 10000, 100000, 1000000];
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L246-249)
```rust
            counters::inc_local_pos_count(bucket);
        } else {
            counters::inc_remote_pos_count(bucket);
        }
```
