# Audit Report

## Title
Stale Randomness Shares Processed After Reset Can Corrupt Consensus Randomness

## Summary
During reset operations in `RandManager::process_reset()`, in-flight messages from the `verified_msg_rx` channel are not drained, allowing stale randomness shares and augmented data from before the reset to be processed afterward. These stale shares can mix with fresh shares for new blocks, potentially corrupting randomness generation and violating consensus safety invariants.

## Finding Description

The vulnerability exists in the reset handling mechanism of the randomness generation manager. When a reset occurs (typically during state sync or chain reorganization), the system clears local state but fails to discard in-flight verified messages.

**Critical Code Path:**

The reset handler only drains `incoming_blocks` but not `verified_msg_rx`: [1](#0-0) 

The `process_reset()` function clears `block_queue` and `rand_store` but has no mechanism to clear the verified message queue: [2](#0-1) 

**Why Stale Shares Are Accepted:**

1. **Epoch-only verification**: Messages are verified against `epoch_state.epoch` but not against specific block identities: [3](#0-2) 

2. **Wide round acceptance window**: Shares are accepted if within 200 rounds of the highest known round: [4](#0-3) [5](#0-4) 

3. **Block-agnostic metadata**: `RandMetadata` contains only epoch and round, not block ID: [6](#0-5) 

4. **Retain logic keeps matching shares**: The `retain()` function filters shares by `(epoch, round)` only: [7](#0-6) 

**Attack Scenario:**

1. Validator processes blocks up to round 100 on fork A
2. Network partition/reorg triggers reset to round 50 (via `sync_to_target`): [8](#0-7) 

3. Randomness shares for rounds 51-100 (fork A) remain queued in `verified_msg_rx`
4. Reset clears `block_queue` and `rand_store` for rounds â‰¥ 50
5. Validator rejoins network on fork B (different blocks for rounds 51-100)
6. Stale shares from fork A are processed from `verified_msg_rx` and added to fresh `RandItem` entries
7. New blocks from fork B arrive, their metadata is added via `add_rand_metadata()`
8. `retain()` keeps stale shares because they match `(epoch, round)`
9. Aggregation mixes shares from fork A (old chain) with shares from fork B (new chain)
10. Randomness generation either fails or produces incorrect values

This violates the consensus safety invariant that all validators must produce identical randomness for identical blocks.

## Impact Explanation

**High Severity** - This qualifies as a "Significant protocol violation" per the bug bounty criteria:

1. **Consensus Randomness Corruption**: Randomness is used for leader election and validator selection. Corrupted randomness can cause:
   - Different validators computing different random values for the same round
   - Consensus liveness failures if randomness aggregation fails
   - Potential for chain splits if validators disagree on leader election

2. **No Privilege Required**: This vulnerability triggers during normal network operations (state sync, reorgs). No malicious validator action is needed.

3. **Affects All Validators**: Any validator experiencing a reset during network instability is vulnerable.

4. **Breaks Cryptographic Correctness Invariant**: The system design assumes randomness shares for a given `(epoch, round)` correspond to the same block, but stale shares violate this assumption.

## Likelihood Explanation

**High Likelihood**:

1. **Common Trigger Events**: 
   - State sync operations occur regularly when validators fall behind
   - Chain reorganizations happen during network partitions or Byzantine behavior
   - Both are normal network conditions, not attack scenarios

2. **Race Condition Window**: The `verified_msg_rx` queue can contain messages from the past 200 rounds due to `FUTURE_ROUNDS_TO_ACCEPT`. During active consensus, this provides a large window for stale messages.

3. **No Mitigation**: There is no existing code to detect or prevent this scenario. The verification task runs independently and continues queueing messages even during reset.

4. **Network Partition Amplification**: During network partitions, different validators may be on different forks, maximizing the likelihood of stale share accumulation.

## Recommendation

**Solution**: Drain the `verified_msg_rx` channel during reset, similar to how `incoming_blocks` is drained.

**Modified reset handler**:

```rust
Some(reset) = reset_rx.next() => {
    // Drain incoming blocks
    while matches!(incoming_blocks.try_next(), Ok(Some(_))) {}
    
    // ADDED: Drain verified messages to prevent stale shares
    while matches!(verified_msg_rx.try_next(), Ok(Some(_))) {}
    
    self.process_reset(reset);
}
```

**Alternative**: Track the reset epoch/round in the verification task and reject messages from before the reset point. This would require passing the reset signal to the verification task and adding state to track the current valid range.

**Additional Hardening**: Consider including `block_id` in `RandMetadata` to cryptographically bind shares to specific blocks, preventing cross-fork share reuse entirely. However, this would be a protocol-level change requiring broader consensus.

## Proof of Concept

```rust
// Reproduction scenario (conceptual Rust test)
#[tokio::test]
async fn test_stale_shares_after_reset() {
    // Setup: Create RandManager at epoch 1
    let (mut rand_manager, mut incoming_blocks, mut verified_msg_rx, mut reset_tx) = 
        setup_rand_manager(/* epoch */ 1);
    
    // Step 1: Process blocks for rounds 1-100
    for round in 1..=100 {
        let block = create_test_block(/* epoch */ 1, round);
        incoming_blocks.send(block).await.unwrap();
    }
    
    // Step 2: Generate shares for round 51 (fork A)
    let stale_share_fork_a = generate_share(/* epoch */ 1, /* round */ 51);
    
    // Step 3: Queue share in verified_msg_rx
    verified_msg_rx.send(RpcRequest {
        req: RandMessage::Share(stale_share_fork_a.clone()),
        protocol: ProtocolId::ConsensusRpc,
        response_sender: /* ... */,
    }).await.unwrap();
    
    // Step 4: Trigger reset to round 50
    let (ack_tx, ack_rx) = oneshot::channel();
    reset_tx.send(ResetRequest {
        tx: ack_tx,
        signal: ResetSignal::TargetRound(50),
    }).await.unwrap();
    ack_rx.await.unwrap();
    
    // Step 5: Send new block for round 51 (fork B - different block_id)
    let block_fork_b = create_test_block_with_id(
        /* epoch */ 1, 
        /* round */ 51, 
        /* block_id */ HashValue::random()
    );
    incoming_blocks.send(block_fork_b).await.unwrap();
    
    // Step 6: Generate new shares for round 51 (fork B)
    let fresh_share_fork_b = generate_share(/* epoch */ 1, /* round */ 51);
    verified_msg_rx.send(RpcRequest {
        req: RandMessage::Share(fresh_share_fork_b),
        protocol: ProtocolId::ConsensusRpc,
        response_sender: /* ... */,
    }).await.unwrap();
    
    // Verify: Check that rand_store contains BOTH stale_share_fork_a and fresh_share_fork_b
    // This violates the invariant that shares should be for the same block
    let stored_shares = rand_manager.rand_store.lock().get_all_shares_authors(51);
    assert!(stored_shares.contains(stale_share_fork_a.author()));
    assert!(stored_shares.contains(fresh_share_fork_b.author()));
    
    // The shares are from different forks but will be aggregated together,
    // potentially corrupting randomness generation
}
```

## Notes

This vulnerability stems from an architectural decision to separate message verification from message processing. The verification task runs independently and has no visibility into reset events. The fix requires either:

1. **Immediate mitigation**: Drain `verified_msg_rx` during reset (simple, effective)
2. **Long-term fix**: Include `block_id` in `RandMetadata` to prevent cross-fork share validity (requires protocol upgrade)

The current implementation's comment in `FullRandMetadata` states `block_id` is "not used for signing", which creates this vulnerability. The design assumes validators will only generate shares for blocks they actually see, but doesn't account for reset scenarios where stale messages can persist.

### Citations

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L184-194)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.rand_store.lock().reset(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L383-386)
```rust
                Some(reset) = reset_rx.next() => {
                    while matches!(incoming_blocks.try_next(), Ok(Some(_))) {}
                    self.process_reset(reset);
                }
```

**File:** consensus/src/rand/rand_gen/network_messages.rs (L36-43)
```rust
    pub fn verify(
        &self,
        epoch_state: &EpochState,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        sender: Author,
    ) -> anyhow::Result<()> {
        ensure!(self.epoch() == epoch_state.epoch);
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L91-99)
```rust
    fn retain(&mut self, rand_config: &RandConfig, rand_metadata: &FullRandMetadata) {
        self.shares
            .retain(|_, share| share.metadata() == &rand_metadata.metadata);
        self.total_weight = self
            .shares
            .keys()
            .map(|author| rand_config.get_peer_weight(author))
            .sum();
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-288)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```

**File:** types/src/randomness.rs (L23-27)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, Default, PartialEq, Eq, Hash)]
pub struct RandMetadata {
    pub epoch: u64,
    pub round: Round,
}
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```
