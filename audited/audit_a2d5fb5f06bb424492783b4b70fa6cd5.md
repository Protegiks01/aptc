# Audit Report

## Title
Credential Path Exposure Through Unredacted Debug Logging in Indexer gRPC Manager

## Summary
The `GcsFileStore` configuration struct exposes the service account key file path through Debug trait logging in the indexer gRPC manager. The sensitive `gcs_file_store_service_account_key_path` field is logged at INFO level during normal startup and in panic messages during error conditions, violating established security patterns in the codebase for handling sensitive credentials.

## Finding Description

The `GcsFileStore` struct derives the `Debug` trait without implementing custom redaction for sensitive fields: [1](#0-0) 

This configuration is then logged using the `{:?}` format specifier in two locations within the gRPC manager initialization:

**Location 1 - Normal startup logging (INFO level):** [2](#0-1) 

**Location 2 - Error condition panic:** [3](#0-2) 

When the Debug trait is auto-derived, all struct fields are included in the output. This means both the `gcs_file_store_bucket_name` and the sensitive `gcs_file_store_service_account_key_path` are exposed in logs.

**Attack Path:**
1. Attacker gains access to application logs through:
   - Compromised log aggregation service (Splunk, ELK, etc.)
   - Exposed monitoring dashboards
   - Container orchestration system logs (Kubernetes)
   - CI/CD pipeline logs
   - Insecure log storage/backups
   - Debug endpoints
2. Attacker searches logs for "FilestoreUploader is created" messages
3. Attacker extracts the service account key path (e.g., `/secrets/prod-gcs-sa-key.json`)
4. If combined with another vulnerability (path traversal, container escape, RCE), attacker can:
   - Read the actual service account key file
   - Authenticate to GCS using the stolen credentials
   - Access, modify, or delete critical indexer transaction data

**Contrast with Established Patterns:**
The codebase has established patterns for protecting sensitive data in logs: [4](#0-3) 

The `IndexerConfig` implements a custom Debug trait that redacts passwords from database URIs, demonstrating awareness of credential exposure risks. However, this pattern was not applied to `GcsFileStore`.

## Impact Explanation

**Severity: HIGH** (per Aptos Bug Bounty categories)

This vulnerability enables:

1. **Information Disclosure**: Direct exposure of sensitive infrastructure configuration including:
   - Service account key file paths
   - GCS bucket names
   - Storage architecture details

2. **Facilitates Further Attacks**: The exposed path becomes a high-value target for:
   - Path traversal attacks
   - Container escape exploits
   - Remote code execution vulnerabilities
   - Server-Side Request Forgery (SSRF)

3. **Critical Data at Risk**: The GCS bucket contains the complete blockchain transaction history processed by the indexer. Unauthorized access enables:
   - **Data Integrity Attacks**: Modifying historical transaction data
   - **Data Availability Attacks**: Deleting indexer data causing service disruption
   - **Data Confidentiality Breach**: Exfiltrating transaction data for analysis

4. **Operational Impact**: 
   - Requires secret rotation across all affected services
   - Potential service downtime during incident response
   - Compliance violations for inadequate credential protection

While this doesn't directly cause consensus violations or fund loss (as the indexer is off-chain infrastructure), it represents a significant security weakness in a critical component that:
- Violates the principle of least privilege
- Increases attack surface substantially
- Contradicts established security patterns in the same codebase

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is **guaranteed to occur** on every service startup:
- The INFO-level log at line 46 executes unconditionally during `GrpcManager::new()`
- No conditional logic prevents the logging
- The tracing framework is configured with JSON formatting that preserves all Debug fields [5](#0-4) 

**Exploitation Prerequisites:**
- **Log Access**: Attacker needs read access to application logs (moderate barrier)
- **No Special Privileges**: Does not require validator access or on-chain permissions
- **Automated Detection**: Attackers can easily search log aggregation systems for the exposed patterns

**Real-World Scenarios:**
- Log management systems are frequent breach targets
- Developers may inadvertently expose logs through debug endpoints
- Cloud provider misconfigurations can expose log buckets
- Insider threats have trivial access to logs

## Recommendation

Implement a custom `Debug` trait for `GcsFileStore` that redacts the sensitive `gcs_file_store_service_account_key_path` field:

```rust
use std::fmt::{Debug, Formatter};

// Remove Debug from the derive macro
#[derive(Serialize, Deserialize, Clone)]
pub struct GcsFileStore {
    pub gcs_file_store_bucket_name: String,
    pub gcs_file_store_bucket_sub_dir: Option<PathBuf>,
    pub gcs_file_store_service_account_key_path: String,
    #[serde(default = "default_enable_compression")]
    pub enable_compression: bool,
}

impl Debug for GcsFileStore {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("GcsFileStore")
            .field("gcs_file_store_bucket_name", &self.gcs_file_store_bucket_name)
            .field("gcs_file_store_bucket_sub_dir", &self.gcs_file_store_bucket_sub_dir)
            .field("gcs_file_store_service_account_key_path", &"<redacted>")
            .field("enable_compression", &self.enable_compression)
            .finish()
    }
}
```

**Additional Recommendations:**
1. Audit all configuration structs containing credentials for similar issues
2. Consider implementing a `#[sensitive]` attribute macro for automatic redaction
3. Review log aggregation access controls
4. Implement automated scanning for credential patterns in logs

## Proof of Concept

**Step 1**: Create a minimal config file `test_config.yaml`:
```yaml
health_check_port: 8080
server_config:
  chain_id: 1
  is_master: true
  self_advertised_address: "127.0.0.1:50051"
  grpc_manager_addresses: []
  fullnode_addresses: []
  file_store_config:
    file_store_type: GcsFileStore
    gcs_file_store_bucket_name: "test-bucket"
    gcs_file_store_service_account_key_path: "/secrets/prod-sa-key.json"
  allow_fn_fallback: false
  cache_config:
    chain_id: 1
    enable_cache_compression: false
    redis_ttl_in_secs: 3600
```

**Step 2**: Start the indexer-grpc-manager service:
```bash
cd ecosystem/indexer-grpc/indexer-grpc-manager
cargo run -- --config-path test_config.yaml
```

**Step 3**: Observe the logs. The following line will be logged at INFO level:
```
INFO chain_id=1 FilestoreUploader is created, config: GcsFileStore { gcs_file_store_bucket_name: "test-bucket", gcs_file_store_bucket_sub_dir: None, gcs_file_store_service_account_key_path: "/secrets/prod-sa-key.json", enable_compression: false }
```

**Step 4**: Verify the credential path is exposed in the log output.

**Expected Result**: The sensitive service account key path `/secrets/prod-sa-key.json` is visible in plaintext logs.

**With Fix Applied**: The log would show:
```
INFO chain_id=1 FilestoreUploader is created, config: GcsFileStore { gcs_file_store_bucket_name: "test-bucket", gcs_file_store_bucket_sub_dir: None, gcs_file_store_service_account_key_path: "<redacted>", enable_compression: false }
```

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/config.rs (L9-17)
```rust
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct GcsFileStore {
    pub gcs_file_store_bucket_name: String,
    pub gcs_file_store_bucket_sub_dir: Option<PathBuf>,
    // Required to operate on GCS.
    pub gcs_file_store_service_account_key_path: String,
    #[serde(default = "default_enable_compression")]
    pub enable_compression: bool,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/grpc_manager.rs (L36-41)
```rust
                .unwrap_or_else(|e| {
                    panic!(
                        "Failed to create filestore uploader, config: {:?}, error: {e:?}",
                        config.file_store_config
                    )
                }),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-manager/src/grpc_manager.rs (L44-47)
```rust
        info!(
            chain_id = chain_id,
            "FilestoreUploader is created, config: {:?}.", config.file_store_config
        );
```

**File:** config/src/config/indexer_config.rs (L92-100)
```rust
impl Debug for IndexerConfig {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        let postgres_uri = self.postgres_uri.as_ref().map(|u| {
            let mut parsed_url = url::Url::parse(u).expect("Invalid postgres uri");
            if parsed_url.password().is_some() {
                parsed_url.set_password(Some("*")).unwrap();
            }
            parsed_url.to_string()
        });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L174-192)
```rust
pub fn setup_logging(make_writer: Option<Box<dyn Fn() -> Box<dyn std::io::Write> + Send + Sync>>) {
    let env_filter = EnvFilter::try_from_default_env()
        .or_else(|_| EnvFilter::try_new("info"))
        .unwrap();

    let subscriber = tracing_subscriber::fmt()
        .json()
        .flatten_event(true)
        .with_file(true)
        .with_line_number(true)
        .with_thread_ids(true)
        .with_target(false)
        .with_thread_names(true)
        .with_env_filter(env_filter);

    match make_writer {
        Some(w) => subscriber.with_writer(w).init(),
        None => subscriber.init(),
    }
```
