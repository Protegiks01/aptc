# Audit Report

## Title
Missing Cryptographic Verification in Backup Replay Process Allows Acceptance of Malicious Blockchain State

## Summary
The `ReplayVerifyCoordinator` accepts untrusted backup storage backends without cryptographic verification of the blockchain's chain-of-trust. While the tool performs internal consistency checks (Merkle proof validation), it completely skips signature verification on `LedgerInfoWithSignatures` by hardcoding `epoch_history` to `None`, allowing an attacker to inject arbitrary but internally-consistent fake blockchain data.

## Finding Description

The `ReplayVerifyCoordinator` struct accepts an `Arc<dyn BackupStorage>` parameter with no runtime validation of the storage backend's authenticity: [1](#0-0) 

The storage backend is initialized from command-line arguments that specify either a local filesystem path or a `CommandAdapter` configuration file, which can execute arbitrary shell commands to fetch backup data: [2](#0-1) [3](#0-2) 

During the replay verification process, the coordinator explicitly passes `None` for `epoch_history` when restoring both state snapshots and transactions: [4](#0-3) 

This causes signature verification to be completely skipped. In the state snapshot restore, verification is conditional on `epoch_history` being present: [5](#0-4) 

Similarly, in transaction restore, signature verification is skipped when `epoch_history` is `None`: [6](#0-5) 

The `EpochHistory::verify_ledger_info()` method is the ONLY place where cryptographic signature verification occurs via the validator verifier: [7](#0-6) 

Which calls the signature verification at the EpochState level: [8](#0-7) 

The proof verification that DOES occur only validates internal Merkle tree consistency, NOT the authenticity of the LedgerInfo itself: [9](#0-8) 

**Attack Path:**
1. Attacker sets up malicious storage backend (HTTP server, S3 bucket, etc.) serving fake backup data
2. Attacker creates fake `LedgerInfoWithSignatures` with invalid/missing signatures
3. Attacker generates transactions and state with internally-consistent Merkle proofs matching their fake LedgerInfo
4. Operator runs `aptos-debugger aptos-db replay-verify` with `CommandAdapter` config pointing to attacker's storage
5. Verification passes because: (a) Merkle proofs are internally consistent, (b) No signature verification occurs, (c) Transaction replay produces expected outputs (all attacker-controlled)
6. Operator believes backup is "verified" and uses it to bootstrap/restore a validator node
7. Node operates with corrupted state that differs from legitimate blockchain history

## Impact Explanation

**Severity: Critical**

This vulnerability directly violates multiple critical invariants:

1. **State Consistency**: The tool claims to "verify" backups but accepts unverified state that could differ from the canonical blockchain
2. **Deterministic Execution**: Different nodes could replay different fake histories, causing consensus divergence  
3. **Consensus Safety**: If multiple validators restore from attacker-controlled backups, they could form a divergent chain

The impact qualifies as **Critical** under Aptos bug bounty criteria:
- **Consensus/Safety violations**: Nodes with different restored states cannot reach consensus
- **State inconsistencies**: Arbitrary state injection breaks the integrity of the blockchain database
- Could lead to **Loss of Funds** if fake state includes manipulated token balances or validator sets

While the tool requires operator access to run, the vulnerability exploits the tool's stated purpose (verification) and the reasonable expectation that "verified" backups are cryptographically authentic. Operators performing their duties correctly (verifying backups before use) can be exploited if they verify backups from untrusted or compromised sources.

## Likelihood Explanation

**Likelihood: Medium-High**

Realistic scenarios where exploitation could occur:

1. **Community Backup Snapshots**: Community members often share backup snapshots to help bootstrap new nodes faster. A malicious actor could provide fake but "verified" snapshots.

2. **Compromised Backup Storage**: If legitimate backup storage (cloud storage, CDN) is compromised, attackers could replace valid backups with malicious ones that would pass "verification."

3. **Supply Chain Attack**: Attackers could compromise backup infrastructure used by multiple operators, affecting numerous nodes simultaneously.

4. **Social Engineering**: Attackers could convince operators to verify backups from attacker-controlled sources by claiming to provide "fast bootstrap" services.

The attack requires:
- Setting up malicious storage backend (low technical barrier)
- Creating internally-consistent fake blockchain data (moderate effort but automatable)
- Operator running the tool on attacker-controlled backup (social engineering or infrastructure compromise)

The likelihood is elevated because operators are specifically encouraged to verify backups before use, creating a false sense of security.

## Recommendation

**Immediate Fix**: Make `epoch_history` construction mandatory in `ReplayVerifyCoordinator`:

1. **Required Epoch History**: Modify `ReplayVerifyCoordinator::run_impl()` to always construct `EpochHistory` from epoch ending backups before verifying state and transactions.

2. **Mandatory Trusted Waypoints**: Require at least a genesis/bootstrap waypoint to be specified via `TrustedWaypointOpt` to establish the root of trust.

3. **Storage Backend Authentication**: Add a verification step that validates the storage backend is authorized:
   - For `CommandAdapter`: validate the config file is from a trusted location and signed
   - Add option to verify storage backend returns data matching expected cryptographic checksums
   - Implement storage backend allowlisting in production configurations

4. **Clear Security Warnings**: Document that replay-verify without trusted waypoints provides only internal consistency checking, not cryptographic verification.

**Code Fix Approach** (conceptual):

```rust
// In ReplayVerifyCoordinator::run_impl()
// Before state snapshot restore:

// 1. Build epoch history from epoch ending backups
let epoch_ending_manifests = metadata_view.select_epoch_ending_backups(...)?;
let epoch_history = if !epoch_ending_manifests.is_empty() {
    Some(Arc::new(
        EpochHistoryRestoreController::new(
            epoch_ending_manifests,
            global_opt.clone(),
            Arc::clone(&self.storage),
        )
        .run()
        .await?
    ))
} else {
    return Err(ReplayError::OtherError(
        "Cannot verify backup without epoch history for signature verification".to_string()
    ));
};

// 2. Verify minimum trusted waypoints are provided
ensure!(
    !self.trusted_waypoints_opt.trust_waypoint.is_empty(),
    "Replay verification requires at least genesis waypoint for trust anchor"
);

// 3. Pass epoch_history to restore controllers instead of None
StateSnapshotRestoreController::new(
    ...,
    epoch_history.clone(), // Instead of None
)
```

## Proof of Concept

**Setup Malicious Storage Backend:**

```rust
// malicious_storage.rs - Mock implementation
use aptos_backup_cli::storage::*;

pub struct MaliciousStorage {
    fake_ledger_info: LedgerInfoWithSignatures,
    fake_transactions: Vec<Transaction>,
}

impl MaliciousStorage {
    pub fn new() -> Self {
        // Create fake LedgerInfo with invalid signatures
        let mut fake_li = LedgerInfo::new(...);
        // Set arbitrary state root, transaction accumulator root
        
        // Create fake signatures (invalid but structurally correct)
        let fake_sigs = AggregateSignature::empty();
        let fake_ledger_info = LedgerInfoWithSignatures::new(fake_li, fake_sigs);
        
        // Create fake transactions that execute consistently
        let fake_transactions = vec![/* malicious transactions */];
        
        Self { fake_ledger_info, fake_transactions }
    }
}

#[async_trait]
impl BackupStorage for MaliciousStorage {
    async fn open_for_read(&self, _handle: &FileHandleRef) -> Result<Box<dyn AsyncRead>> {
        // Return fake data with self-consistent Merkle proofs
        // Proofs will validate because they match the fake LedgerInfo's accumulators
    }
    // ... implement other methods to serve fake backup data
}
```

**Exploitation Steps:**

```bash
# 1. Create CommandAdapter config pointing to malicious storage
cat > /tmp/malicious_config.yaml <<EOF
commands:
  create_backup: "echo malicious_backup"
  open_for_read: "/path/to/malicious_server.sh \$FILE_HANDLE"
  list_metadata_files: "echo metadata.json"
  save_metadata_line: "cat > /dev/null && echo saved"
env_vars: []
EOF

# 2. Run replay-verify with malicious config
aptos-debugger aptos-db replay-verify \
  --target-db-dir /tmp/corrupted_db \
  --command-adapter-config /tmp/malicious_config.yaml \
  --start-version 0 \
  --end-version 1000000

# 3. Verification PASSES despite fake data (no signature checks)
# Output: "ReplayVerify coordinator succeeded"

# 4. Corrupted database now contains attacker-controlled state
# If used to start a validator, consensus will fail when comparing with honest nodes
```

**Verification that signatures are not checked:**

```rust
// Test demonstrating the vulnerability
#[tokio::test]
async fn test_missing_signature_verification() {
    let malicious_storage = Arc::new(MaliciousStorage::new());
    
    let coordinator = ReplayVerifyCoordinator::new(
        malicious_storage,
        MetadataCacheOpt::default(),
        TrustedWaypointOpt::default(), // Empty - no waypoints!
        1,
        1,
        restore_handler,
        0,
        1000,
        false,
        VerifyExecutionMode::NoVerify,
    ).unwrap();
    
    // This should fail with signature verification error
    // but actually succeeds because epoch_history is None
    let result = coordinator.run().await;
    assert!(result.is_ok()); // VULNERABILITY: accepts invalid signatures!
}
```

## Notes

This vulnerability represents a **trust boundary violation** where a tool designed for verification fails to perform complete cryptographic verification. The `TrustedWaypointOpt` documentation explicitly states that "LedgerInfos are NOT checked at all when doing one-shot restoring of the transaction and state backups," but this limitation is dangerous when the tool's name and purpose imply full verification.

The fix requires balancing usability (fast replay for testing) with security (mandatory signature verification for production use). At minimum, the tool should prominently warn operators when signature verification is disabled and refuse to operate without explicit override flags when waypoints are not provided.

### Citations

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L44-82)
```rust
pub struct ReplayVerifyCoordinator {
    storage: Arc<dyn BackupStorage>,
    metadata_cache_opt: MetadataCacheOpt,
    trusted_waypoints_opt: TrustedWaypointOpt,
    concurrent_downloads: usize,
    replay_concurrency_level: usize,
    restore_handler: RestoreHandler,
    start_version: Version,
    end_version: Version,
    validate_modules: bool,
    verify_execution_mode: VerifyExecutionMode,
}

impl ReplayVerifyCoordinator {
    pub fn new(
        storage: Arc<dyn BackupStorage>,
        metadata_cache_opt: MetadataCacheOpt,
        trusted_waypoints_opt: TrustedWaypointOpt,
        concurrent_downloads: usize,
        replay_concurrency_level: usize,
        restore_handler: RestoreHandler,
        start_version: Version,
        end_version: Version,
        validate_modules: bool,
        verify_execution_mode: VerifyExecutionMode,
    ) -> Result<Self> {
        Ok(Self {
            storage,
            metadata_cache_opt,
            trusted_waypoints_opt,
            concurrent_downloads,
            replay_concurrency_level,
            restore_handler,
            start_version,
            end_version,
            validate_modules,
            verify_execution_mode,
        })
    }
```

**File:** storage/backup/backup-cli/src/coordinators/replay_verify.rs (L173-205)
```rust
        if !skip_snapshot {
            if let Some(backup) = state_snapshot {
                StateSnapshotRestoreController::new(
                    StateSnapshotRestoreOpt {
                        manifest_handle: backup.manifest,
                        version: backup.version,
                        validate_modules: self.validate_modules,
                        restore_mode: Default::default(),
                    },
                    global_opt.clone(),
                    Arc::clone(&self.storage),
                    None, /* epoch_history */
                )
                .run()
                .await?;
            }
        }

        TransactionRestoreBatchController::new(
            global_opt,
            self.storage,
            transactions
                .into_iter()
                .map(|t| t.manifest)
                .collect::<Vec<_>>(),
            save_start_version,
            Some((next_txn_version, false)), /* replay_from_version */
            None,                            /* epoch_history */
            self.verify_execution_mode.clone(),
            None,
        )
        .run()
        .await?;
```

**File:** storage/db-tool/src/replay_verify.rs (L63-86)
```rust
    pub async fn run(self) -> Result<()> {
        let restore_handler = Arc::new(AptosDB::open_kv_only(
            StorageDirPaths::from_path(self.db_dir),
            false,                       /* read_only */
            NO_OP_STORAGE_PRUNER_CONFIG, /* pruner config */
            self.rocksdb_opt.into(),
            false, /* indexer */
            BUFFERED_STATE_TARGET_ITEMS,
            DEFAULT_MAX_NUM_NODES_PER_LRU_CACHE_SHARD,
            None,
        )?)
        .get_restore_handler();
        let ret = ReplayVerifyCoordinator::new(
            self.storage.init_storage().await?,
            self.metadata_cache_opt,
            self.trusted_waypoints_opt,
            self.concurrent_downloads.get(),
            self.replay_concurrency_level.get(),
            restore_handler,
            self.start_version.unwrap_or(0),
            self.end_version.unwrap_or(Version::MAX),
            self.validate_modules,
            VerifyExecutionMode::verify_except(self.txns_to_skip).set_lazy_quit(self.lazy_quit),
        )?
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/config.rs (L74-95)
```rust
#[derive(Clone, Default, Deserialize)]
pub struct CommandAdapterConfig {
    /// Command lines that implements `BackupStorage` APIs.
    pub commands: Commands,
    /// Additional environment variables to be set when command lines are spawned.
    pub env_vars: Vec<EnvVar>,
}

impl CommandAdapterConfig {
    pub async fn load_from_file(path: &Path) -> Result<Self> {
        let path_str = path.to_str().unwrap_or_default();
        let mut file = tokio::fs::File::open(path).await.err_notes(path_str)?;
        let mut content = Vec::new();
        file.read_to_end(&mut content).await.err_notes(path_str)?;

        Ok(serde_yaml::from_slice(&content)?)
    }

    pub fn load_from_str(content: &str) -> Result<Self> {
        Ok(serde_yaml::from_str(content)?)
    }
}
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-139)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
        let (txn_info_with_proof, li): (TransactionInfoWithProof, LedgerInfoWithSignatures) =
            self.storage.load_bcs_file(&manifest.proof).await?;
        txn_info_with_proof.verify(li.ledger_info(), manifest.version)?;
        let state_root_hash = txn_info_with_proof
            .transaction_info()
            .ensure_state_checkpoint_hash()?;
        ensure!(
            state_root_hash == manifest.root_hash,
            "Root hash mismatch with that in proof. root hash: {}, expected: {}",
            manifest.root_hash,
            state_root_hash,
        );
        if let Some(epoch_history) = self.epoch_history.as_ref() {
            epoch_history.verify_ledger_info(&li)?;
        }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L147-154)
```rust
        let (range_proof, ledger_info) = storage
            .load_bcs_file::<(TransactionAccumulatorRangeProof, LedgerInfoWithSignatures)>(
                &manifest.proof,
            )
            .await?;
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L276-312)
```rust
    pub fn verify_ledger_info(&self, li_with_sigs: &LedgerInfoWithSignatures) -> Result<()> {
        let epoch = li_with_sigs.ledger_info().epoch();
        ensure!(!self.epoch_endings.is_empty(), "Empty epoch history.",);
        if epoch > self.epoch_endings.len() as u64 {
            // TODO(aldenhu): fix this from upper level
            warn!(
                epoch = epoch,
                epoch_history_until = self.epoch_endings.len(),
                "Epoch is too new and can't be verified. Previous chunks are verified and node \
                won't be able to start if this data is malicious."
            );
            return Ok(());
        }
        if epoch == 0 {
            ensure!(
                li_with_sigs.ledger_info() == &self.epoch_endings[0],
                "Genesis epoch LedgerInfo info doesn't match.",
            );
        } else if let Some(wp_trusted) = self
            .trusted_waypoints
            .get(&li_with_sigs.ledger_info().version())
        {
            let wp_li = Waypoint::new_any(li_with_sigs.ledger_info());
            ensure!(
                *wp_trusted == wp_li,
                "Waypoints don't match. In backup: {}, trusted: {}",
                wp_li,
                wp_trusted,
            );
        } else {
            self.epoch_endings[epoch as usize - 1]
                .next_epoch_state()
                .ok_or_else(|| anyhow!("Shouldn't contain non- epoch bumping LIs."))?
                .verify(li_with_sigs)?;
        };
        Ok(())
    }
```

**File:** types/src/epoch_state.rs (L40-50)
```rust
impl Verifier for EpochState {
    fn verify(&self, ledger_info: &LedgerInfoWithSignatures) -> anyhow::Result<()> {
        ensure!(
            self.epoch == ledger_info.ledger_info().epoch(),
            "LedgerInfo has unexpected epoch {}, expected {}",
            ledger_info.ledger_info().epoch(),
            self.epoch
        );
        ledger_info.verify_signatures(&self.verifier)?;
        Ok(())
    }
```

**File:** types/src/proof/mod.rs (L40-61)
```rust
fn verify_transaction_info(
    ledger_info: &LedgerInfo,
    transaction_version: Version,
    transaction_info: &TransactionInfo,
    ledger_info_to_transaction_info_proof: &TransactionAccumulatorProof,
) -> Result<()> {
    ensure!(
        transaction_version <= ledger_info.version(),
        "Transaction version {} is newer than LedgerInfo version {}.",
        transaction_version,
        ledger_info.version(),
    );

    let transaction_info_hash = transaction_info.hash();
    ledger_info_to_transaction_info_proof.verify(
        ledger_info.transaction_accumulator_hash(),
        transaction_info_hash,
        transaction_version,
    )?;

    Ok(())
}
```
