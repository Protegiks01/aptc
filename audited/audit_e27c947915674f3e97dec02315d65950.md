# Audit Report

## Title
Unbounded Memory Consumption in ConsensusDB Block Loading Causes Validator Crash

## Summary
The `start()` function in `persistent_liveness_storage.rs` loads all blocks from ConsensusDB into memory without any size limit before performing pruning. If a validator falls significantly behind and syncs millions of blocks, then crashes before pruning occurs, on restart it will attempt to load all blocks simultaneously, causing out-of-memory (OOM) crashes and validator unavailability.

## Finding Description

The vulnerability exists in the consensus block recovery flow:

**Step 1 - Unbounded Block Loading:**
In `ConsensusDB::get_data()`, ALL blocks are loaded from the database via `get_all::<BlockSchema>()` which collects every block into a `Vec<Block>` with no pagination or size limit. [1](#0-0) 

The `get_all()` method iterates through the entire BlockSchema column family and collects all entries: [2](#0-1) 

**Step 2 - Blocks Loaded Before Pruning:**
In `StorageWriteProxy::start()`, the blocks vector is populated from `get_data()` before any validation or pruning: [3](#0-2) 

Only AFTER loading all blocks into memory does pruning occur at line 571.

**Step 3 - Unbounded Block Accumulation During Sync:**
During fast-forward sync, `num_blocks` is calculated as the round difference with no upper bound check (only validates `< usize::MAX`): [4](#0-3) 

All retrieved blocks are then persisted to ConsensusDB atomically: [5](#0-4) 

**Attack Scenario:**
1. Validator V goes offline or is kept offline via network DoS for an extended period
2. Network progresses from round M to round N (where N - M = millions)
3. Validator V comes online and calls `sync_to_highest_quorum_cert`
4. V fetches millions of valid blocks from peers (in chunks of `max_blocks_to_request` = 10)
5. V saves all blocks to ConsensusDB via `storage.save_tree()`
6. Before V commits and prunes these blocks (via `commit_callback`), attacker crashes V via DoS attack or resource exhaustion
7. On restart, V loads ALL blocks from ConsensusDB into memory simultaneously
8. Memory exhaustion causes OOM crash, validator becomes unavailable

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits" - there is no memory limit enforced during block loading.

## Impact Explanation

**Severity: High** (per Aptos Bug Bounty: "Validator node slowdowns" / crashes, up to $50,000)

**Impact:**
- Validator becomes unavailable due to OOM crash
- Repeated crash loop if restart continues to trigger OOM
- Reduces network's validator set, weakening consensus guarantees
- If multiple validators exploited simultaneously, could significantly impact network liveness

**Quantification:**
- At ~1-2 second block times, 1 million rounds ≈ 12-23 days of network operation
- Each `Block` structure plus associated data (QCs, payloads) likely >1KB
- 1 million blocks ≈ >1GB memory just for block structures
- With modern transactions, could be 5-10GB+ for associated data structures
- Typical validator nodes with 16GB RAM could crash with 2-3 million blocks

The impact is localized to specific validators that fall behind, but constitutes clear validator availability disruption.

## Likelihood Explanation

**Likelihood: Medium**

**Prerequisites:**
- Validator must fall millions of rounds behind (achievable if offline 1-2 weeks)
- Network must operate long enough to produce millions of rounds (achievable in production)
- Attacker needs ability to crash validator after sync starts but before pruning (via network DoS, resource exhaustion)

**Mitigating Factors:**
- Requires validator to be significantly behind
- Blocks must be legitimate (cannot inject fake blocks)
- Primarily affects validators already experiencing issues

**Enabling Factors:**
- No validation or limit on blocks loaded from database
- No pagination in `get_all::<BlockSchema>()`
- Pruning happens AFTER loading all blocks
- `max_blocks_to_request` only limits batch size, not total blocks synced

The attack is realistic in production environments where validators may experience extended downtime and then attempt to rejoin the network.

## Recommendation

Implement pagination or streaming when loading blocks from ConsensusDB to prevent unbounded memory consumption:

**Option 1: Implement pagination in block loading**
```rust
// In consensusdb/mod.rs
pub fn get_data_paginated(
    &self,
    max_blocks: usize,
) -> Result<(
    Option<Vec<u8>>,
    Option<Vec<u8>>,
    Vec<Block>,
    Vec<QuorumCert>,
)> {
    let last_vote = self.get_last_vote()?;
    let highest_2chain_timeout_certificate = self.get_highest_2chain_timeout_certificate()?;
    
    // Load blocks with limit
    let mut iter = self.db.iter::<BlockSchema>()?;
    iter.seek_to_first();
    let consensus_blocks: Vec<Block> = iter
        .take(max_blocks)
        .collect::<Result<Vec<_>, _>>()?
        .into_iter()
        .map(|(_, block)| block)
        .collect();
    
    // Similarly for QCs
    let mut qc_iter = self.db.iter::<QCSchema>()?;
    qc_iter.seek_to_first();
    let consensus_qcs: Vec<QuorumCert> = qc_iter
        .take(max_blocks)
        .collect::<Result<Vec<_>, _>>()?
        .into_iter()
        .map(|(_, qc)| qc)
        .collect();
    
    Ok((last_vote, highest_2chain_timeout_certificate, consensus_blocks, consensus_qcs))
}
```

**Option 2: Add hard limit on blocks synced**
```rust
// In sync_manager.rs, add constant
const MAX_BLOCKS_TO_SYNC: u64 = 100_000; // ~1-2 days of blocks

// In fast_forward_sync
let num_blocks = Self::generate_target_block_retrieval_payload_and_num_blocks(
    highest_quorum_cert,
    highest_commit_cert,
    window_size,
).1;

// Add validation
if num_blocks > MAX_BLOCKS_TO_SYNC {
    bail!("Sync gap too large ({} blocks), use state sync instead", num_blocks);
}
```

**Option 3: Progressive loading with early pruning**
Load blocks in batches, prune after each batch to limit memory footprint.

## Proof of Concept

**Reproduction Steps:**

1. **Setup test validator**
```bash
# Run validator node with limited memory (8GB)
aptos node run-local-testnet --test-dir /tmp/testnet --memory-limit 8GB
```

2. **Simulate network progression**
```rust
// In integration test
let mut blocks = Vec::new();
let mut qcs = Vec::new();

// Generate 2 million valid blocks
for i in 0..2_000_000 {
    let block = create_test_block(i);
    let qc = create_test_qc(&block);
    blocks.push(block);
    qcs.push(qc);
}

// Save to ConsensusDB
consensus_db.save_blocks_and_quorum_certificates(blocks, qcs)?;
```

3. **Trigger crash on restart**
```rust
// Restart validator - will attempt to load all 2M blocks
let storage = StorageWriteProxy::new(&config, aptos_db);
let recovery_data = storage.start(true, Some(1000)); // OOM crash here
```

**Expected Result:** Validator crashes with OOM error when `get_data()` attempts to allocate Vec for 2 million blocks (~2-10GB depending on block size).

**Memory Calculation:**
- 2 million blocks × 1KB minimum = 2GB
- Plus QuorumCerts, parent references, execution state = ~5-10GB total
- Exceeds 8GB memory limit → OOM crash

This demonstrates how an attacker can render a syncing validator unavailable by forcing it to load millions of blocks from persistent storage during recovery.

### Citations

**File:** consensus/src/consensusdb/mod.rs (L80-106)
```rust
    pub fn get_data(
        &self,
    ) -> Result<(
        Option<Vec<u8>>,
        Option<Vec<u8>>,
        Vec<Block>,
        Vec<QuorumCert>,
    )> {
        let last_vote = self.get_last_vote()?;
        let highest_2chain_timeout_certificate = self.get_highest_2chain_timeout_certificate()?;
        let consensus_blocks = self
            .get_all::<BlockSchema>()?
            .into_iter()
            .map(|(_, block)| block)
            .collect();
        let consensus_qcs = self
            .get_all::<QCSchema>()?
            .into_iter()
            .map(|(_, qc)| qc)
            .collect();
        Ok((
            last_vote,
            highest_2chain_timeout_certificate,
            consensus_blocks,
            consensus_qcs,
        ))
    }
```

**File:** consensus/src/consensusdb/mod.rs (L201-205)
```rust
    pub fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter.collect::<Result<Vec<(S::Key, S::Value)>, AptosDbError>>()?)
    }
```

**File:** consensus/src/persistent_liveness_storage.rs (L519-540)
```rust
    fn start(&self, order_vote_enabled: bool, window_size: Option<u64>) -> LivenessStorageData {
        info!("Start consensus recovery.");
        let raw_data = self
            .db
            .get_data()
            .expect("unable to recover consensus data");

        let last_vote = raw_data
            .0
            .map(|bytes| bcs::from_bytes(&bytes[..]).expect("unable to deserialize last vote"));

        let highest_2chain_timeout_cert = raw_data.1.map(|b| {
            bcs::from_bytes(&b).expect("unable to deserialize highest 2-chain timeout cert")
        });
        let blocks = raw_data.2;
        let quorum_certs: Vec<_> = raw_data.3;
        let blocks_repr: Vec<String> = blocks.iter().map(|b| format!("\n\t{}", b)).collect();
        info!(
            "The following blocks were restored from ConsensusDB : {}",
            blocks_repr.concat()
        );
        let qc_repr: Vec<String> = quorum_certs
```

**File:** consensus/src/block_storage/sync_manager.rs (L383-403)
```rust
        let (target_block_retrieval_payload, num_blocks) =
            Self::generate_target_block_retrieval_payload_and_num_blocks(
                highest_quorum_cert,
                highest_commit_cert,
                window_size,
            );

        // although unlikely, we might wrap num_blocks around on a 32-bit machine
        assert!(num_blocks < usize::MAX as u64);

        BLOCKS_FETCHED_FROM_NETWORK_WHILE_FAST_FORWARD_SYNC.inc_by(num_blocks);
        let mut blocks = retriever
            .retrieve_blocks_in_range(
                highest_quorum_cert.certified_block().id(),
                num_blocks,
                target_block_retrieval_payload,
                highest_quorum_cert
                    .ledger_info()
                    .get_voters(&retriever.validator_addresses()),
            )
            .await?;
```

**File:** consensus/src/block_storage/sync_manager.rs (L503-503)
```rust
        storage.save_tree(blocks.clone(), quorum_certs.clone())?;
```
