# Audit Report

## Title
Memory Leak in BatchProofQueue Due to Expirations Index Desynchronization

## Summary
The `gc_expired_batch_summaries_without_proofs` function removes expired batches without proofs from `items` and `author_to_batches`, but fails to remove them from the `expirations` TimeExpirations index. This creates a desynchronization that causes memory accumulation and CPU waste during periods when block timestamps lag behind wall clock time, degrading validator performance.

## Finding Description

The `BatchProofQueue` struct maintains three data structures that must remain synchronized:

1. `expirations: TimeExpirations<BatchSortKey>` - BinaryHeap tracking batch expiration times [1](#0-0) 
2. `author_to_batches: HashMap<PeerId, BTreeMap<BatchSortKey, BatchInfoExt>>` - Per-author batch queues [2](#0-1) 
3. `items: HashMap<BatchKey, QueueItem>` - Batch data and proofs [3](#0-2) 

The `TimeExpirations` structure only supports two operations: `add_item()` to insert entries and `expire()` to remove expired entries based on certified time. There is no mechanism to remove individual items from the BinaryHeap. [4](#0-3) 

The vulnerability occurs in `gc_expired_batch_summaries_without_proofs()`, which removes expired batch summaries that never received proofs. [5](#0-4) 

This function uses wall clock time to determine expiration [6](#0-5)  and removes expired batches from `items` (via retain returning false) and from `author_to_batches` [7](#0-6) , but critically fails to remove them from `expirations`.

The desynchronization occurs because:
- `gc_expired_batch_summaries_without_proofs()` uses wall clock time to remove entries from two structures
- `handle_updated_block_timestamp()` uses block timestamp to expire entries from the `expirations` BinaryHeap [8](#0-7) 

When block timestamps lag behind wall clock time (during network issues or block production delays), phantom entries accumulate in `expirations`. Later, when `handle_updated_block_timestamp()` processes these phantom entries, it performs wasteful lookups in `author_to_batches` and `items` that will fail because those entries were already removed. [9](#0-8) 

**Trigger Scenario:**
1. Batch summaries are received via `insert_batches()` and inserted into all three structures [10](#0-9) 
2. Corresponding proofs never arrive (network delays or malicious withholding)
3. Wall clock time advances but block timestamps lag behind
4. `gc_expired_batch_summaries_without_proofs()` (called via sampling every 500ms) [11](#0-10)  removes entries from `items` and `author_to_batches`
5. Phantom entries accumulate in `expirations` BinaryHeap
6. When block timestamps eventually catch up, CPU is wasted processing these phantom entries

## Impact Explanation

This vulnerability qualifies as **High Severity** under Aptos Bug Bounty criteria: "Validator node slowdowns."

**Resource Exhaustion Impact:**

1. **Memory Accumulation**: The `expirations` BinaryHeap grows unbounded during the gap between wall clock time and block timestamps. Each `BatchSortKey` entry consumes approximately 56 bytes (Reverse<u64> + PeerId + BatchId + gas_bucket_start). At 1000 batches/second with 1 hour of lag, this results in ~200 MB of accumulated phantom entries.

2. **CPU Waste**: When block timestamps catch up, `handle_updated_block_timestamp()` processes all accumulated phantom entries, performing unsuccessful HashMap and BTreeMap lookups for entries that no longer exist in those structures. Processing millions of phantom entries causes CPU spikes.

3. **Validator Performance Degradation**: Validators experiencing memory pressure and CPU spikes may fall behind in consensus, timeout on votes, or experience reduced network performance, potentially requiring restarts and causing temporary unavailability.

This violates resource management invariants that validators depend on for stable operation during network recovery periods.

## Likelihood Explanation

**Likelihood: High**

This vulnerability manifests during normal network operations:

1. **Normal Conditions Trigger It**: Batch summaries without corresponding proofs occur legitimately due to network delays, partition events, or coordinator failures - no malicious actor required.

2. **No Privileges Required**: Any network peer can send batch summaries through the normal quorum store protocol.

3. **Automatic Accumulation**: The issue accumulates passively whenever block production lags behind wall clock time, which happens during network congestion or consensus delays - common in distributed systems.

4. **Real-World Applicability**: Network delays and block production variance are expected conditions in blockchain systems, making this a practical operational concern rather than a theoretical edge case.

## Recommendation

Modify `gc_expired_batch_summaries_without_proofs()` to also remove entries from the `expirations` index. However, since `TimeExpirations` doesn't support individual item removal, consider one of these approaches:

**Option 1**: Add a removal mechanism to `TimeExpirations`:
```rust
pub(crate) fn remove_item(&mut self, item: &I) {
    self.expiries.retain(|(_, i)| i != item);
}
```

Then call it in `gc_expired_batch_summaries_without_proofs()` when removing items.

**Option 2**: Use a different data structure that supports efficient individual removal, such as a BTreeMap indexed by expiration time.

**Option 3**: Accept phantom entries but track them separately to avoid lookup overhead in `handle_updated_block_timestamp()`.

## Proof of Concept

A PoC would demonstrate:
1. Inserting batch summaries with future expiration times
2. Advancing wall clock time past expiration
3. Calling `gc_expired_batch_summaries_without_proofs()` to remove entries from `items` and `author_to_batches`
4. Verifying phantom entries remain in `expirations` (by checking `is_empty()` returns false)
5. Calling `handle_updated_block_timestamp()` with appropriate block timestamp
6. Observing CPU cycles wasted on lookups for non-existent entries

The core issue is architecturally evident from the code structure: two different time sources (wall clock vs. block timestamp) operating on three synchronized data structures with incomplete cleanup in one code path.

### Citations

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L59-59)
```rust
    author_to_batches: HashMap<PeerId, BTreeMap<BatchSortKey, BatchInfoExt>>,
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L61-61)
```rust
    items: HashMap<BatchKey, QueueItem>,
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L66-66)
```rust
    expirations: TimeExpirations<BatchSortKey>,
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L252-255)
```rust
        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L278-283)
```rust
            self.author_to_batches
                .entry(batch_info.author())
                .or_default()
                .insert(batch_sort_key.clone(), batch_info.clone());
            self.expirations
                .add_item(batch_sort_key, batch_info.expiration());
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L324-339)
```rust
    fn gc_expired_batch_summaries_without_proofs(&mut self) {
        let timestamp = aptos_infallible::duration_since_epoch().as_micros() as u64;
        self.items.retain(|_, item| {
            if item.is_committed() || item.proof.is_some() || item.info.expiration() > timestamp {
                true
            } else {
                self.author_to_batches
                    .get_mut(&item.info.author())
                    .map(|queue| queue.remove(&BatchSortKey::from_info(&item.info)));
                counters::GARBAGE_COLLECTED_IN_PROOF_QUEUE_COUNTER
                    .with_label_values(&["expired_batch_without_proof"])
                    .inc();
                false
            }
        });
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L729-729)
```rust
        let expired = self.expirations.expire(block_timestamp);
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L731-765)
```rust
        for key in &expired {
            if let Some(mut queue) = self.author_to_batches.remove(&key.author()) {
                if let Some(batch) = queue.remove(key) {
                    let item = self
                        .items
                        .get(&key.batch_key)
                        .expect("Entry for unexpired batch must exist");
                    if item.proof.is_some() {
                        // not committed proof that is expired
                        num_expired_but_not_committed += 1;
                        counters::GAP_BETWEEN_BATCH_EXPIRATION_AND_CURRENT_TIME_WHEN_COMMIT
                            .observe((block_timestamp - batch.expiration()) as f64);
                        if let Some(ref txn_summaries) = item.txn_summaries {
                            for txn_summary in txn_summaries {
                                if let Some(count) =
                                    self.txn_summary_num_occurrences.get_mut(txn_summary)
                                {
                                    *count -= 1;
                                    if *count == 0 {
                                        self.txn_summary_num_occurrences.remove(txn_summary);
                                    }
                                };
                            }
                        }
                        self.dec_remaining_proofs(&batch.author(), batch.num_txns());
                        counters::GARBAGE_COLLECTED_IN_PROOF_QUEUE_COUNTER
                            .with_label_values(&["expired_proof"])
                            .inc();
                    }
                    claims::assert_some!(self.items.remove(&key.batch_key));
                }
                if !queue.is_empty() {
                    self.author_to_batches.insert(key.author(), queue);
                }
            }
```

**File:** consensus/src/quorum_store/utils.rs (L71-89)
```rust
    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) {
        self.expiries.push((Reverse(expiry_time), item));
    }

    /// Expire and return items corresponding to expiration <= given certified time.
    /// Unwrap is safe because peek() is called in loop condition.
    #[allow(clippy::unwrap_used)]
    pub(crate) fn expire(&mut self, certified_time: u64) -> HashSet<I> {
        let mut ret = HashSet::new();
        while let Some((Reverse(t), _)) = self.expiries.peek() {
            if *t <= certified_time {
                let (_, item) = self.expiries.pop().unwrap();
                ret.insert(item);
            } else {
                break;
            }
        }
        ret
    }
```
