# Audit Report

## Title
Batch Expiration Validation Missing: Malicious Peers Can Cause Resource Exhaustion with Far-Future Expiration Times

## Summary
The quorum store batch insertion logic does not validate that batch expiration times are within a reasonable future timeframe. Malicious network peers can send batches with expiration set to `u64::MAX` or other extremely large values, causing these batches to accumulate indefinitely and permanently consume per-peer storage quotas until manual intervention.

## Finding Description

The vulnerability exists in the batch reception and validation pipeline across multiple components:

**1. Batch Reception Without Upper-Bound Expiration Validation**

When batches are received from network peers in `batch_coordinator::handle_batches_msg`, the `ensure_max_limits` function only validates size and transaction count limits, but does NOT validate expiration times: [1](#0-0) 

**2. Batch Storage With Only Lower-Bound Check**

When batches are persisted to `batch_store`, the `save` function only rejects batches that have ALREADY expired (expiration <= last_certified_time), but accepts any future-dated expiration including `u64::MAX`: [2](#0-1) 

**3. Batch Queue Insertion Without Validation**

When batches are inserted into the proof queue via `insert_batches`, there is no validation of expiration time - batches are simply added to the expirations index: [3](#0-2) 

**4. Similarly, Proof Insertion Has Same Issue**

For proofs of store, the `insert_proof` function only rejects already-expired proofs but accepts far-future expiration times: [4](#0-3) 

**Attack Scenario:**

1. A malicious network peer crafts batches with `expiration = u64::MAX` (approximately 584 million years in the future)
2. These batches pass all validation checks in `batch_coordinator` and `batch_store`
3. They are inserted into `batch_proof_queue` and added to the expirations index
4. The batches will NEVER be cleaned up by the expiration logic in `handle_updated_block_timestamp`
5. They permanently consume the peer's quota (up to 300,000 batches per peer per config)
6. Legitimate batches from that peer may eventually be rejected due to quota exhaustion
7. These batches contribute to back pressure metrics, potentially degrading performance [5](#0-4) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria:

- **State Inconsistencies Requiring Intervention**: Batches with far-future expiration times permanently consume storage quotas and require manual intervention (node restart or manual cleanup) to resolve
- **Resource Exhaustion**: While per-peer quotas limit the immediate impact (batch_quota = 300,000), malicious batches permanently occupy these quotas
- **Degraded Performance**: Accumulated batches contribute to back pressure calculations, potentially causing validators to throttle batch creation

The impact is mitigated by:
- Per-peer quota limits preventing unbounded growth from a single peer
- Back pressure mechanisms that throttle when limits are reached

However, the vulnerability still causes:
- Permanent quota consumption requiring manual intervention
- Potential for coordinated attack from multiple malicious peer IDs
- Degraded quorum store performance over time [6](#0-5) 

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is straightforward to execute:
- Any network peer can send batch messages
- No special privileges or validator access required
- Simple to craft batches with `expiration = u64::MAX`
- No cryptographic operations needed to bypass

Limiting factors:
- Per-peer quotas limit impact from single attacker
- Requires sustained attack or multiple malicious peer IDs for significant impact
- Network-level batch size/count limits apply

The attack becomes more severe if:
- Attacker controls multiple peer identities
- Network has many validators (more targets for quota exhaustion)
- Attack is sustained over time

## Recommendation

Add upper-bound validation for batch expiration times. Introduce a maximum allowed expiration duration configuration parameter and validate incoming batches against it.

**Recommended Fix:**

1. Add configuration parameter in `QuorumStoreConfig`:

```rust
/// Maximum allowed batch expiration duration from current time (in microseconds)
/// Default: 5 minutes = 300 seconds = 300_000_000 microseconds
pub max_batch_expiration_duration_usecs: u64,
```

2. Modify `batch_coordinator::ensure_max_limits` to validate expiration:

```rust
fn ensure_max_limits(&self, batches: &[Batch<BatchInfoExt>]) -> anyhow::Result<()> {
    let current_time = aptos_infallible::duration_since_epoch().as_micros() as u64;
    let max_allowed_expiration = current_time + self.max_batch_expiration_duration_usecs;
    
    let mut total_txns = 0;
    let mut total_bytes = 0;
    for batch in batches.iter() {
        // Existing validations...
        ensure!(
            batch.num_txns() <= self.max_batch_txns,
            "Exceeds batch txn limit {} > {}",
            batch.num_txns(),
            self.max_batch_txns,
        );
        
        // NEW: Validate expiration is not too far in the future
        ensure!(
            batch.expiration() <= max_allowed_expiration,
            "Batch expiration {} exceeds maximum allowed {} (current time {} + max duration {})",
            batch.expiration(),
            max_allowed_expiration,
            current_time,
            self.max_batch_expiration_duration_usecs,
        );
        
        total_txns += batch.num_txns();
        total_bytes += batch.num_bytes();
    }
    // ... rest of validation
    Ok(())
}
```

3. Similarly, add validation in `batch_proof_queue::insert_proof`:

```rust
pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
    if proof.expiration() <= self.latest_block_timestamp {
        counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
        return;
    }
    
    // NEW: Reject proofs with expiration too far in the future
    let max_allowed_expiration = self.latest_block_timestamp + self.batch_expiry_gap_when_init_usecs * 10; // 10x normal expiry as safety margin
    if proof.expiration() > max_allowed_expiration {
        counters::inc_rejected_pos_count("expiration_too_far_future");
        return;
    }
    
    // ... rest of insertion logic
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::{transaction::SignedTransaction, PeerId};
    use consensus::quorum_store::batch_coordinator::BatchCoordinator;
    use consensus::quorum_store::types::Batch;
    
    #[tokio::test]
    async fn test_batch_with_max_expiration_exhausts_quota() {
        // Setup: Create batch coordinator with quota limits
        let (coordinator, quota_tracker) = setup_batch_coordinator_with_quotas();
        let malicious_peer = PeerId::random();
        
        // Create batches with u64::MAX expiration
        let mut malicious_batches = vec![];
        for i in 0..300 {
            let batch = create_batch_with_expiration(
                malicious_peer,
                i,
                u64::MAX, // Far-future expiration
                create_dummy_transactions(10),
            );
            malicious_batches.push(batch);
        }
        
        // Send malicious batches
        coordinator.handle_batches_msg(malicious_peer, malicious_batches).await;
        
        // Verify: Batches are stored and consume quota
        assert_eq!(quota_tracker.get_batch_count(malicious_peer), 300);
        
        // Simulate time passing (e.g., 1 hour = 3600 seconds)
        advance_time_by_seconds(3600);
        
        // Verify: Batches are NOT cleaned up by expiration
        coordinator.cleanup_expired_batches();
        assert_eq!(quota_tracker.get_batch_count(malicious_peer), 300);
        // Quota still fully consumed!
        
        // Now legitimate batch from same peer should be rejected due to quota
        let legit_batch = create_batch_with_normal_expiration(
            malicious_peer,
            create_dummy_transactions(10),
        );
        
        let result = coordinator.handle_batches_msg(malicious_peer, vec![legit_batch]).await;
        assert!(result.is_err()); // Should fail due to quota exhaustion
        assert!(result.unwrap_err().to_string().contains("quota exceeded"));
    }
}
```

## Notes

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." Batches with extremely far-future expiration times violate the expected resource cleanup behavior and permanently consume quotas until manual intervention.

While per-peer quota limits prevent unbounded resource consumption from a single attacker, the vulnerability still enables:
1. Permanent quota exhaustion for targeted peers
2. Accumulated memory/storage usage over time
3. Degraded quorum store performance
4. Potential for coordinated multi-peer attacks

The recommended fix adds a reasonable upper bound on batch expiration times (e.g., 5 minutes from current time) while maintaining protocol flexibility for network delays and clock skew.

### Citations

**File:** consensus/src/quorum_store/batch_coordinator.rs (L137-171)
```rust
    fn ensure_max_limits(&self, batches: &[Batch<BatchInfoExt>]) -> anyhow::Result<()> {
        let mut total_txns = 0;
        let mut total_bytes = 0;
        for batch in batches.iter() {
            ensure!(
                batch.num_txns() <= self.max_batch_txns,
                "Exceeds batch txn limit {} > {}",
                batch.num_txns(),
                self.max_batch_txns,
            );
            ensure!(
                batch.num_bytes() <= self.max_batch_bytes,
                "Exceeds batch bytes limit {} > {}",
                batch.num_bytes(),
                self.max_batch_bytes,
            );

            total_txns += batch.num_txns();
            total_bytes += batch.num_bytes();
        }
        ensure!(
            total_txns <= self.max_total_txns,
            "Exceeds total txn limit {} > {}",
            total_txns,
            self.max_total_txns,
        );
        ensure!(
            total_bytes <= self.max_total_bytes,
            "Exceeds total bytes limit: {} > {}",
            total_bytes,
            self.max_total_bytes,
        );

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L419-439)
```rust
    pub(crate) fn save(&self, value: &PersistedValue<BatchInfoExt>) -> anyhow::Result<bool> {
        let last_certified_time = self.last_certified_time();
        if value.expiration() > last_certified_time {
            fail_point!("quorum_store::save", |_| {
                // Skip caching and storing value to the db
                Ok(false)
            });
            counters::GAP_BETWEEN_BATCH_EXPIRATION_AND_CURRENT_TIME_WHEN_SAVE.observe(
                Duration::from_micros(value.expiration() - last_certified_time).as_secs_f64(),
            );

            return self.insert_to_cache(value);
        }
        counters::NUM_BATCH_EXPIRED_WHEN_SAVE.inc();
        bail!(
            "Incorrect expiration {} in epoch {}, last committed timestamp {}",
            value.expiration(),
            self.epoch(),
            last_certified_time,
        );
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L175-256)
```rust
    pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
        if proof.expiration() <= self.latest_block_timestamp {
            counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
            return;
        }
        let batch_key = BatchKey::from_info(proof.info());
        if self
            .items
            .get(&batch_key)
            .is_some_and(|item| item.proof.is_some() || item.is_committed())
        {
            counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
            return;
        }

        let author = proof.author();
        let bucket = proof.gas_bucket_start();
        let num_txns = proof.num_txns();
        let expiration = proof.expiration();

        let batch_sort_key = BatchSortKey::from_info(proof.info());
        let batches_for_author = self.author_to_batches.entry(author).or_default();
        batches_for_author.insert(batch_sort_key.clone(), proof.info().clone());

        // Check if a batch with a higher batch Id (reverse sorted) exists
        if let Some((prev_batch_key, _)) = batches_for_author
            .range((Bound::Unbounded, Bound::Excluded(batch_sort_key.clone())))
            .next_back()
        {
            if prev_batch_key.gas_bucket_start() == batch_sort_key.gas_bucket_start() {
                counters::PROOF_MANAGER_OUT_OF_ORDER_PROOF_INSERTION
                    .with_label_values(&[author.short_str().as_str()])
                    .inc();
            }
        }

        self.expirations.add_item(batch_sort_key, expiration);

        // If we are here, then proof is added for the first time. Otherwise, we will
        // return early. We only count when proof is added for the first time and txn
        // summary exists.
        if let Some(txn_summaries) = self
            .items
            .get(&batch_key)
            .and_then(|item| item.txn_summaries.as_ref())
        {
            for txn_summary in txn_summaries {
                *self
                    .txn_summary_num_occurrences
                    .entry(*txn_summary)
                    .or_insert(0) += 1;
            }
        }

        match self.items.entry(batch_key) {
            Entry::Occupied(mut entry) => {
                let item = entry.get_mut();
                item.proof = Some(proof);
                item.proof_insertion_time = Some(Instant::now());
            },
            Entry::Vacant(entry) => {
                entry.insert(QueueItem {
                    info: proof.info().clone(),
                    proof: Some(proof),
                    proof_insertion_time: Some(Instant::now()),
                    txn_summaries: None,
                });
            },
        }

        if author == self.my_peer_id {
            counters::inc_local_pos_count(bucket);
        } else {
            counters::inc_remote_pos_count(bucket);
        }
        self.inc_remaining_proofs(&author, num_txns);

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L258-320)
```rust
    pub fn insert_batches(
        &mut self,
        batches_with_txn_summaries: Vec<(BatchInfoExt, Vec<TxnSummaryWithExpiration>)>,
    ) {
        let start = Instant::now();

        for (batch_info, txn_summaries) in batches_with_txn_summaries.into_iter() {
            let batch_sort_key = BatchSortKey::from_info(&batch_info);
            let batch_key = BatchKey::from_info(&batch_info);

            // If the batch is either committed or the txn summary already exists, skip
            // inserting this batch.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.is_committed() || item.txn_summaries.is_some())
            {
                continue;
            }

            self.author_to_batches
                .entry(batch_info.author())
                .or_default()
                .insert(batch_sort_key.clone(), batch_info.clone());
            self.expirations
                .add_item(batch_sort_key, batch_info.expiration());

            // We only count txn summaries first time it is added to the queue
            // and only if the proof already exists.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.proof.is_some())
            {
                for txn_summary in &txn_summaries {
                    *self
                        .txn_summary_num_occurrences
                        .entry(*txn_summary)
                        .or_insert(0) += 1;
                }
            }

            match self.items.entry(batch_key) {
                Entry::Occupied(mut entry) => {
                    entry.get_mut().txn_summaries = Some(txn_summaries);
                },
                Entry::Vacant(entry) => {
                    entry.insert(QueueItem {
                        info: batch_info,
                        proof: None,
                        proof_insertion_time: None,
                        txn_summaries: Some(txn_summaries),
                    });
                },
            }
        }

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
        counters::PROOF_QUEUE_ADD_BATCH_SUMMARIES_DURATION.observe_duration(start.elapsed());
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L716-769)
```rust
    pub(crate) fn handle_updated_block_timestamp(&mut self, block_timestamp: u64) {
        // tolerate asynchronous notification
        if self.latest_block_timestamp > block_timestamp {
            return;
        }
        let start = Instant::now();
        self.latest_block_timestamp = block_timestamp;
        if let Some(time_lag) = aptos_infallible::duration_since_epoch()
            .checked_sub(Duration::from_micros(block_timestamp))
        {
            counters::TIME_LAG_IN_BATCH_PROOF_QUEUE.observe_duration(time_lag);
        }

        let expired = self.expirations.expire(block_timestamp);
        let mut num_expired_but_not_committed = 0;
        for key in &expired {
            if let Some(mut queue) = self.author_to_batches.remove(&key.author()) {
                if let Some(batch) = queue.remove(key) {
                    let item = self
                        .items
                        .get(&key.batch_key)
                        .expect("Entry for unexpired batch must exist");
                    if item.proof.is_some() {
                        // not committed proof that is expired
                        num_expired_but_not_committed += 1;
                        counters::GAP_BETWEEN_BATCH_EXPIRATION_AND_CURRENT_TIME_WHEN_COMMIT
                            .observe((block_timestamp - batch.expiration()) as f64);
                        if let Some(ref txn_summaries) = item.txn_summaries {
                            for txn_summary in txn_summaries {
                                if let Some(count) =
                                    self.txn_summary_num_occurrences.get_mut(txn_summary)
                                {
                                    *count -= 1;
                                    if *count == 0 {
                                        self.txn_summary_num_occurrences.remove(txn_summary);
                                    }
                                };
                            }
                        }
                        self.dec_remaining_proofs(&batch.author(), batch.num_txns());
                        counters::GARBAGE_COLLECTED_IN_PROOF_QUEUE_COUNTER
                            .with_label_values(&["expired_proof"])
                            .inc();
                    }
                    claims::assert_some!(self.items.remove(&key.batch_key));
                }
                if !queue.is_empty() {
                    self.author_to_batches.insert(key.author(), queue);
                }
            }
        }
        counters::PROOF_QUEUE_UPDATE_TIMESTAMP_DURATION.observe_duration(start.elapsed());
        counters::NUM_PROOFS_EXPIRED_WHEN_COMMIT.inc_by(num_expired_but_not_committed);
    }
```

**File:** config/src/config/quorum_store_config.rs (L131-136)
```rust
            batch_expiry_gap_when_init_usecs: Duration::from_secs(60).as_micros() as u64,
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
            back_pressure: QuorumStoreBackPressureConfig::default(),
```
