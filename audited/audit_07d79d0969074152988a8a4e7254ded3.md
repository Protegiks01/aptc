# Audit Report

## Title
SyncInfo Message Flooding Can Trigger Repeated Expensive Signature Verification

## Summary
Malicious validators can repeatedly send SyncInfo messages with valid but stale certificates to force victim nodes to perform expensive BLS signature verification operations, causing CPU resource exhaustion and potential consensus performance degradation.

## Finding Description

The consensus protocol allows validators to send standalone `SyncInfo` messages to help peers synchronize state. However, the processing logic performs expensive cryptographic verification **before** checking whether the referenced blocks already exist locally. [1](#0-0) 

The vulnerability exists in the `sync_up` function which checks if the received `SyncInfo` has any component (certified round, timeout round, ordered round, or commit round) higher than the local state using an **OR** condition: [2](#0-1) 

When any round component is higher, the node performs full BLS signature verification on up to 4 certificates (highest quorum cert, highest ordered cert, highest commit cert, and timeout cert): [3](#0-2) 

Each certificate verification involves expensive BLS signature validation: [4](#0-3) 

**Attack Mechanism:**
1. A malicious validator collects valid `SyncInfo` messages from recent consensus rounds (publicly broadcast during normal operation)
2. The attacker repeatedly sends these messages to target victims
3. Each message triggers full cryptographic verification if ANY round component appears "newer" to the victim
4. Only **after** expensive verification does the system check if blocks already exist
5. No deduplication or caching prevents repeated verification of the same certificates

**Why This Works:**
- The `has_newer_certificates()` check uses OR logic, so even if a victim is ahead in 3 dimensions, being behind in 1 dimension (e.g., timeout round) triggers full processing
- The consensus message channel has only limited backpressure (capacity 10 per peer): [5](#0-4) 

- SyncInfo messages bypass signature verification during initial receipt and are marked as `UnverifiedSyncInfo`: [6](#0-5) 

- No rate limiting exists specifically for SyncInfo messages beyond channel capacity
- No caching mechanism exists to avoid re-verifying previously seen certificates

## Impact Explanation

This vulnerability enables **CPU resource exhaustion** attacks against validator nodes, categorized as **Medium severity** based on the following analysis:

**Actual Impact:**
- Each malicious SyncInfo message forces expensive BLS signature verification (CPU-intensive)
- With typical validator sets (~100 validators), an attacker can sustain moderate flooding (10 messages queued per peer)
- Multiple colluding malicious validators (within Byzantine < 1/3 threshold) can amplify the attack
- Sustained attacks cause measurable CPU exhaustion and consensus performance degradation

**Severity Classification:**
Per Aptos bug bounty criteria, this falls between:
- **High Severity** "Validator node slowdowns" (up to $50,000) - if causing significant operational impact
- **Medium Severity** "State inconsistencies requiring intervention" (up to $10,000) - performance degradation

The bounded nature of the attack (limited by channel capacity and requiring validator privileges) suggests **Medium severity** is appropriate. While not causing consensus safety violations or fund loss, sustained attacks can degrade network performance and increase validator operational costs.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Requirements:**
- Must be a validator in the active validator set (or compromise one)
- Requires collecting valid certificates from recent rounds (trivially obtained during normal consensus operation)
- Does NOT require controlling 2f+1 validators or breaking cryptographic assumptions

**Feasibility:**
- Attack is trivial to execute once validator access is obtained
- Valid certificates are freely available from observing network traffic
- No technical sophistication required beyond sending network messages
- Within the Byzantine fault tolerance threat model (< 1/3 malicious validators)

**Detection Difficulty:**
- Attack traffic resembles legitimate synchronization attempts
- No obvious pattern distinguishes malicious from legitimate SyncInfo messages
- Requires monitoring CPU utilization and message patterns to detect

## Recommendation

Implement multi-layered defense against SyncInfo flooding:

**1. Certificate Verification Cache:**
Add an LRU cache to avoid re-verifying recently seen certificates:

```rust
// In RoundManager struct
certificate_cache: LruCache<HashValue, ()>,

// In sync_up function, before line 888
if let Some(cached) = self.certificate_cache.get(&sync_info.highest_quorum_cert().id()) {
    // Skip verification for recently verified certificates
} else {
    sync_info.verify(&self.epoch_state.verifier)?;
    self.certificate_cache.put(sync_info.highest_quorum_cert().id(), ());
}
```

**2. Per-Peer Rate Limiting:**
Add exponential backoff for peers sending excessive SyncInfo messages:

```rust
// Track SyncInfo rate per peer
sync_info_rate_limiter: HashMap<Author, (u64, Instant)>,

// Before processing, check rate limit
if let Some((count, last_time)) = self.sync_info_rate_limiter.get_mut(&peer) {
    if last_time.elapsed() < Duration::from_secs(1) {
        *count += 1;
        if *count > MAX_SYNC_INFO_PER_SECOND {
            return Err(anyhow!("SyncInfo rate limit exceeded"));
        }
    } else {
        *count = 1;
        *last_time = Instant::now();
    }
}
```

**3. Optimize Verification Order:**
Check block existence BEFORE expensive signature verification:

```rust
// In sync_up, before verification
if !sync_info.has_genuinely_new_data(&self.block_store) {
    return Ok(()); // Skip if we already have all referenced blocks
}
// Then perform verification
sync_info.verify(&self.epoch_state.verifier)?;
```

**4. Metrics and Monitoring:**
Add specific counters for SyncInfo processing to detect attacks:
- `SYNC_INFO_VERIFICATION_TIME` - histogram of verification latency
- `SYNC_INFO_ALREADY_HAVE_BLOCKS` - counter for unnecessary syncs
- `SYNC_INFO_PER_PEER_RATE` - per-peer message rate

## Proof of Concept

```rust
// Proof of concept demonstrating the attack
// This would be added as a test in consensus/src/round_manager_test.rs

#[tokio::test]
async fn test_sync_info_flooding_attack() {
    // Setup: Create a victim node at round 100
    let (mut round_manager, _) = create_round_manager_at_round(100);
    let malicious_peer = PeerId::random();
    
    // Attacker collects a valid SyncInfo from round 95 with a timeout cert at round 99
    let attack_sync_info = create_valid_sync_info(
        95,  // certified_round
        94,  // ordered_round
        93,  // commit_round
        99,  // timeout_round - higher than victim's 0
    );
    
    // Measure CPU time for processing
    let start = Instant::now();
    let iterations = 100;
    
    for _ in 0..iterations {
        // Each call triggers expensive BLS signature verification
        let _ = round_manager.process_sync_info_msg(
            attack_sync_info.clone(),
            malicious_peer,
        ).await;
    }
    
    let elapsed = start.elapsed();
    
    // Assert significant CPU time was consumed
    assert!(elapsed > Duration::from_millis(100 * iterations),
        "Expected significant CPU time for {} verifications", iterations);
    
    // Assert no actual synchronization was needed
    assert_eq!(round_manager.block_store.highest_round(), 100,
        "Victim should still be at round 100");
}
```

## Notes

This vulnerability is explicitly scoped in the security question as Medium severity. The attack requires validator network access but operates within the Byzantine fault tolerance threat model (< 1/3 malicious validators). While the channel backpressure provides some mitigation, the lack of verification caching and proper rate limiting enables sustained CPU exhaustion attacks. The recommended fixes provide defense-in-depth without breaking legitimate synchronization behavior.

### Citations

**File:** consensus/src/round_manager.rs (L165-165)
```rust
            UnverifiedEvent::SyncInfo(s) => VerifiedEvent::UnverifiedSyncInfo(s),
```

**File:** consensus/src/round_manager.rs (L878-907)
```rust
    async fn sync_up(&mut self, sync_info: &SyncInfo, author: Author) -> anyhow::Result<()> {
        let local_sync_info = self.block_store.sync_info();
        if sync_info.has_newer_certificates(&local_sync_info) {
            info!(
                self.new_log(LogEvent::ReceiveNewCertificate)
                    .remote_peer(author),
                "Local state {},\n remote state {}", local_sync_info, sync_info
            );
            // Some information in SyncInfo is ahead of what we have locally.
            // First verify the SyncInfo (didn't verify it in the yet).
            sync_info.verify(&self.epoch_state.verifier).map_err(|e| {
                error!(
                    SecurityEvent::InvalidSyncInfoMsg,
                    sync_info = sync_info,
                    remote_peer = author,
                    error = ?e,
                );
                VerifyError::from(e)
            })?;
            SYNC_INFO_RECEIVED_WITH_NEWER_CERT.inc();
            let result = self
                .block_store
                .add_certs(sync_info, self.create_block_retriever(author))
                .await;
            self.process_certificates().await?;
            result
        } else {
            Ok(())
        }
    }
```

**File:** consensus/consensus-types/src/sync_info.rs (L138-212)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let epoch = self.highest_quorum_cert.certified_block().epoch();
        ensure!(
            epoch == self.highest_ordered_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HQC"
        );
        ensure!(
            epoch == self.highest_commit_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HCC"
        );
        if let Some(tc) = &self.highest_2chain_timeout_cert {
            ensure!(epoch == tc.epoch(), "Multi epoch in SyncInfo - TC and HQC");
        }

        ensure!(
            self.highest_quorum_cert.certified_block().round()
                >= self.highest_ordered_cert().commit_info().round(),
            "HQC has lower round than HOC"
        );

        ensure!(
            self.highest_ordered_round() >= self.highest_commit_round(),
            format!(
                "HOC {} has lower round than HLI {}",
                self.highest_ordered_cert(),
                self.highest_commit_cert()
            )
        );

        ensure!(
            *self.highest_ordered_cert().commit_info() != BlockInfo::empty(),
            "HOC has no committed block"
        );

        ensure!(
            *self.highest_commit_cert().commit_info() != BlockInfo::empty(),
            "HLI has empty commit info"
        );

        // we don't have execution in unit tests, so this check would fail
        #[cfg(not(any(test, feature = "fuzzing")))]
        {
            ensure!(
                !self.highest_commit_cert().commit_info().is_ordered_only(),
                "HLI {} has ordered only commit info",
                self.highest_commit_cert().commit_info()
            );
        }

        self.highest_quorum_cert
            .verify(validator)
            .and_then(|_| {
                self.highest_ordered_cert
                    .as_ref()
                    .map_or(Ok(()), |cert| cert.verify(validator))
                    .context("Fail to verify ordered certificate")
            })
            .and_then(|_| {
                // we do not verify genesis ledger info
                if self.highest_commit_cert.commit_info().round() > 0 {
                    self.highest_commit_cert
                        .verify(validator)
                        .context("Fail to verify commit certificate")?
                }
                Ok(())
            })
            .and_then(|_| {
                if let Some(tc) = &self.highest_2chain_timeout_cert {
                    tc.verify(validator)?;
                }
                Ok(())
            })
            .context("Fail to verify SyncInfo")?;
        Ok(())
    }
```

**File:** consensus/consensus-types/src/sync_info.rs (L218-223)
```rust
    pub fn has_newer_certificates(&self, other: &SyncInfo) -> bool {
        self.highest_certified_round() > other.highest_certified_round()
            || self.highest_timeout_round() > other.highest_timeout_round()
            || self.highest_ordered_round() > other.highest_ordered_round()
            || self.highest_commit_round() > other.highest_commit_round()
    }
```

**File:** consensus/consensus-types/src/quorum_cert.rs (L119-148)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let vote_hash = self.vote_data.hash();
        ensure!(
            self.ledger_info().ledger_info().consensus_data_hash() == vote_hash,
            "Quorum Cert's hash mismatch LedgerInfo"
        );
        // Genesis's QC is implicitly agreed upon, it doesn't have real signatures.
        // If someone sends us a QC on a fake genesis, it'll fail to insert into BlockStore
        // because of the round constraint.
        if self.certified_block().round() == 0 {
            ensure!(
                self.parent_block() == self.certified_block(),
                "Genesis QC has inconsistent parent block with certified block"
            );
            ensure!(
                self.certified_block() == self.ledger_info().ledger_info().commit_info(),
                "Genesis QC has inconsistent commit block with certified block"
            );
            ensure!(
                self.ledger_info().get_num_voters() == 0,
                "Genesis QC should not carry signatures"
            );
            return Ok(());
        }
        self.ledger_info()
            .verify_signatures(validator)
            .context("Fail to verify QuorumCert")?;
        self.vote_data.verify()?;
        Ok(())
    }
```

**File:** consensus/src/network.rs (L757-761)
```rust
        let (consensus_messages_tx, consensus_messages) = aptos_channel::new(
            QueueStyle::FIFO,
            10,
            Some(&counters::CONSENSUS_CHANNEL_MSGS),
        );
```
