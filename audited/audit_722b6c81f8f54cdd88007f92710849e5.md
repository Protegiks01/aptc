# Audit Report

## Title
Unbounded Memory Growth in Remote Executor Shard via Coordinator Message Flooding

## Summary
The `RemoteStateViewClient` in the executor service uses an unbounded channel to receive key-value responses from the coordinator. A malicious or compromised coordinator can flood this channel with messages faster than the fixed-size thread pool can process them, causing unbounded memory growth and eventual Out-of-Memory (OOM) crash of the executor shard process.

## Finding Description

The vulnerability exists in the remote state view architecture where executor shards communicate with a coordinator to fetch state values during parallel block execution.

**Vulnerable Code Flow:**

1. The `RemoteStateViewClient` creates an unbounded channel to receive responses from the coordinator: [1](#0-0) 

2. This channel is created via `NetworkController::create_inbound_channel()` which explicitly uses an unbounded crossbeam channel: [2](#0-1) 

3. When messages arrive from the coordinator via gRPC, they are immediately sent into the unbounded channel without any rate limiting or backpressure: [3](#0-2) 

4. The receiver processes messages in a loop, spawning each message to a fixed-size thread pool: [4](#0-3) 

5. The thread pool has a fixed size of `num_cpus::get()` threads: [5](#0-4) 

**Attack Scenario:**

A malicious or compromised coordinator can exploit this by:

1. Sending continuous `RemoteKVResponse` messages to the executor shard at a high rate
2. Messages are legitimate protocol messages but sent at a rate exceeding the thread pool's processing capacity
3. Since the channel is unbounded and gRPC handler immediately accepts all messages, they accumulate in memory
4. The fixed-size thread pool creates a bottleneck - if it can process N messages/second but the coordinator sends 10N messages/second, the queue grows at 9N messages/second
5. Memory consumption grows unbounded until the executor shard process runs out of memory and crashes

**Critical Finding:**

The codebase has bounded channel implementations available (as evidenced in `crates/channel/src/aptos_channel.rs`) and uses them in other components like mempool, but the remote executor service explicitly chose unbounded channels. Additionally, there is NO authentication or authorization between coordinator and executor shards: [6](#0-5) 

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**Severity: HIGH** (per Aptos Bug Bounty criteria: "Validator node slowdowns" and "API crashes")

**Impact:**
- **Availability**: Executor shard process crashes due to OOM, disrupting block execution
- **Consensus Impact**: Failed executor shards can prevent the validator from participating in consensus, potentially affecting network liveness
- **Cascading Failures**: In a distributed deployment with multiple shards, crashing individual shards degrades the validator's execution capacity

**Affected Systems:**
- All validator nodes using remote executor shards (distributed/sharded block execution architecture)
- Each shard is independently vulnerable to this attack

**Quantified Damage:**
- With a typical message size of ~1MB and processing rate of 100 messages/second vs attack rate of 1000 messages/second, memory grows at ~900MB/second
- A node with 64GB RAM would crash in approximately 70 seconds
- Recovery requires process restart and state synchronization, causing validator downtime

This does NOT meet Critical severity because it does not cause permanent state corruption, consensus safety violations, or fund loss. However, it clearly meets High severity for "Validator node slowdowns" and causing process crashes.

## Likelihood Explanation

**Likelihood: MEDIUM**

**Requirements for Exploitation:**
1. Attacker must compromise or control the coordinator process
2. Coordinator has network access to executor shards
3. No authentication prevents a rogue coordinator from connecting

**Feasibility Factors:**

*In Favor of Exploitation:*
- No authentication or rate limiting protects the channel
- Attack is technically trivial once coordinator access is obtained
- The coordinator address is configured at startup and remains static
- gRPC has no builtin protection against application-level message flooding

*Against Exploitation:*
- Coordinator is typically part of trusted validator infrastructure
- Requires insider access or infrastructure compromise
- Monitoring would likely detect unusual message rates
- The architecture assumes coordinator and shards run within trusted boundaries

However, defense-in-depth principles suggest that even trusted components should have safeguards. The explicit choice of unbounded channels when bounded alternatives exist in the codebase represents a design gap, especially given that similar components (mempool) use bounded executors and rate limiting for protection.

## Recommendation

**Solution: Replace unbounded channel with bounded channel and implement backpressure**

1. **Use bounded channel with reasonable capacity:**

```rust
// In NetworkController::create_inbound_channel
pub fn create_inbound_channel(&mut self, message_type: String, capacity: usize) -> Receiver<Message> {
    let (inbound_sender, inbound_receiver) = bounded(capacity);
    
    self.inbound_handler
        .lock()
        .unwrap()
        .register_handler(message_type, inbound_sender);
    
    inbound_receiver
}
```

2. **Add configuration for channel capacity in RemoteStateViewClient:**

```rust
const DEFAULT_KV_RESPONSE_CHANNEL_CAPACITY: usize = 1000;

pub fn new(
    shard_id: ShardId,
    controller: &mut NetworkController,
    coordinator_address: SocketAddr,
    channel_capacity: Option<usize>,
) -> Self {
    let capacity = channel_capacity.unwrap_or(DEFAULT_KV_RESPONSE_CHANNEL_CAPACITY);
    let result_rx = controller.create_inbound_channel(
        kv_response_type.to_string(), 
        capacity
    );
    // ... rest of initialization
}
```

3. **Implement proper error handling in gRPC handler when channel is full:**

```rust
// In grpc_network_service/mod.rs simple_msg_exchange
if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
    match handler.try_send(msg) {
        Ok(_) => {},
        Err(TrySendError::Full(_)) => {
            // Apply backpressure - return error to coordinator
            return Err(Status::resource_exhausted("Message queue full"));
        },
        Err(TrySendError::Disconnected(_)) => {
            return Err(Status::unavailable("Handler disconnected"));
        }
    }
}
```

4. **Add monitoring and alerting:**
    - Expose metrics for channel occupancy
    - Alert when channel approaches capacity
    - Log dropped or rejected messages

This approach provides defense-in-depth by ensuring that even a compromised coordinator cannot exhaust shard memory.

## Proof of Concept

```rust
// Proof of Concept: Flood executor shard with messages
// File: execution/executor-service/src/tests/flood_attack_test.rs

use crossbeam_channel::{unbounded, Receiver, Sender};
use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
use std::thread;
use std::time::Duration;

#[test]
fn test_unbounded_channel_memory_exhaustion() {
    // Simulate the vulnerable setup
    let (tx, rx): (Sender<Vec<u8>>, Receiver<Vec<u8>>) = unbounded();
    
    let memory_counter = Arc::new(AtomicUsize::new(0));
    let counter_clone = memory_counter.clone();
    
    // Simulated "thread pool" with limited workers (like num_cpus::get())
    let num_workers = 4;
    let thread_pool = rayon::ThreadPoolBuilder::new()
        .num_threads(num_workers)
        .build()
        .unwrap();
    
    // Receiver thread (simulates RemoteStateValueReceiver::start)
    let receiver_handle = thread::spawn(move || {
        while let Ok(message) = rx.recv() {
            let counter = counter_clone.clone();
            thread_pool.spawn(move || {
                // Simulate processing (handle_message work)
                thread::sleep(Duration::from_millis(100)); // 100ms processing time
                counter.fetch_add(message.len(), Ordering::Relaxed);
            });
        }
    });
    
    // Attacker thread (simulates malicious coordinator flooding)
    let attacker_handle = thread::spawn(move || {
        let message_size = 1024 * 1024; // 1MB per message
        let messages_per_second = 100;
        
        for i in 0..1000 {
            let message = vec![0u8; message_size];
            tx.send(message).unwrap();
            
            if i % messages_per_second == 0 {
                thread::sleep(Duration::from_millis(10)); // Send 100 msg/sec
            }
            
            // In reality, this would continue until OOM
            if i % 100 == 0 {
                println!("Sent {} messages, channel has unbounded backlog", i);
            }
        }
    });
    
    attacker_handle.join().unwrap();
    
    // At this point, most messages are still queued in the unbounded channel
    // In a real attack, this would cause OOM before processing completes
    println!("Attack complete. Messages queued but not processed.");
    println!("With bounded channel, this would apply backpressure.");
    
    // Demonstrate that processing lags far behind sending
    thread::sleep(Duration::from_secs(2));
    let processed = memory_counter.load(Ordering::Relaxed);
    println!("Processed only {} bytes while 1GB was sent", processed);
    
    assert!(processed < 1024 * 1024 * 1000, "Processing should lag behind");
}

// Additional test showing the fix
#[test]
fn test_bounded_channel_provides_backpressure() {
    use crossbeam_channel::bounded;
    
    let capacity = 10;
    let (tx, rx) = bounded(capacity);
    
    // Fill the channel to capacity
    for i in 0..capacity {
        tx.send(vec![0u8; 1024]).unwrap();
    }
    
    // Next send will block/fail, providing backpressure
    match tx.try_send(vec![0u8; 1024]) {
        Ok(_) => panic!("Should have failed due to full channel"),
        Err(_) => println!("Bounded channel correctly applied backpressure"),
    }
}
```

**To Run:**
```bash
cd execution/executor-service
cargo test --test flood_attack_test -- --nocapture
```

This PoC demonstrates that the unbounded channel allows messages to accumulate indefinitely when the sending rate exceeds the processing rate, validating the vulnerability.

## Notes

**Additional Context:**

1. The vulnerability is present in both `RemoteStateViewClient` (receiving KV responses) and `RemoteStateViewService` (receiving KV requests), as both use the same unbounded channel pattern.

2. Other parts of the Aptos codebase properly use bounded channels and rate limiting (e.g., mempool coordinator uses `BoundedExecutor`), indicating this is an architectural oversight rather than intentional design.

3. While the coordinator is typically trusted infrastructure, this vulnerability violates defense-in-depth principles. Even trusted components should have resource limits to prevent cascading failures from bugs or compromises.

4. The issue is exacerbated by the lack of authentication between coordinator and shards, meaning any process that can reach the shard's network port could potentially exploit this.

### Citations

**File:** execution/executor-service/src/remote_state_view.rs (L79-82)
```rust
    pub fn new(
        shard_id: ShardId,
        controller: &mut NetworkController,
        coordinator_address: SocketAddr,
```

**File:** execution/executor-service/src/remote_state_view.rs (L84-90)
```rust
        let thread_pool = Arc::new(
            rayon::ThreadPoolBuilder::new()
                .thread_name(move |index| format!("remote-state-view-shard-{}-{}", shard_id, index))
                .num_threads(num_cpus::get())
                .build()
                .unwrap(),
        );
```

**File:** execution/executor-service/src/remote_state_view.rs (L93-93)
```rust
        let result_rx = controller.create_inbound_channel(kv_response_type.to_string());
```

**File:** execution/executor-service/src/remote_state_view.rs (L233-241)
```rust
    fn start(&self) {
        while let Ok(message) = self.kv_rx.recv() {
            let state_view = self.state_view.clone();
            let shard_id = self.shard_id;
            self.thread_pool.spawn(move || {
                Self::handle_message(shard_id, message, state_view);
            });
        }
    }
```

**File:** secure/net/src/network_controller/mod.rs (L128-137)
```rust
    pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
        let (inbound_sender, inbound_receiver) = unbounded();

        self.inbound_handler
            .lock()
            .unwrap()
            .register_handler(message_type, inbound_sender);

        inbound_receiver
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L105-107)
```rust
        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
```
