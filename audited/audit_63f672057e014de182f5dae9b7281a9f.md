# Audit Report

## Title
Consensus Observer Pending Blocks TOCTOU Race Enabling Memory Exhaustion DoS via Hash Store Bypass

## Summary
A Time-of-Check-to-Time-of-Use (TOCTOU) race condition in the consensus observer's pending block insertion logic allows malicious peers to bypass the `max_pending_blocks` limit by exploiting inconsistent state between two internal stores. The garbage collection mechanism uses only the epoch/round store size to determine cleanup, allowing the hash store to grow unbounded and causing memory exhaustion that can crash observer nodes.

## Finding Description

The `PendingBlockStore` maintains two synchronized maps: `blocks_without_payloads` (keyed by epoch/round) and `blocks_without_payloads_by_hash` (keyed by block hash). These stores should always contain the same number of entries. [1](#0-0) 

The vulnerability stems from a TOCTOU race in the message processing flow. When an `OrderedBlock` message arrives, the code checks if it's already pending before insertion: [2](#0-1) 

The check at line 681-684 releases the mutex after `existing_pending_block()` returns, then reacquires it at line 710-712 for `insert_pending_block()`. This creates a race window where two concurrent messages with the same `(epoch, round)` but different block hashes can both pass the check.

The `existing_pending_block()` method only checks the epoch/round store: [3](#0-2) 

During `insert_pending_block()`, the first block successfully inserts into the epoch/round store, but the second fails. However, both blocks successfully insert into the hash store (different keys), creating inconsistency: [4](#0-3) 

The critical flaw is in `garbage_collect_pending_blocks()`, which only uses `num_pending_blocks` (from epoch/round store) to calculate cleanup: [5](#0-4) 

When inconsistency exists, the error is logged but execution continues. The garbage collection removes blocks only from the epoch/round store, leaving orphaned entries in the hash store that are never cleaned up.

**Attack Scenario:**
1. Malicious subscribed peer sends multiple `OrderedBlock` messages concurrently
2. All messages have the same `(epoch, round)` pairs but different block hashes
3. Due to TOCTOU race, only one per epoch/round enters the epoch/round store
4. All blocks enter the hash store (unique hashes)
5. Epoch/round store stays below `max_pending_blocks`, so `num_blocks_to_remove = 0`
6. Hash store grows unbounded with orphaned entries
7. Memory exhaustion leads to node slowdown or crash

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

1. **Validator node slowdowns**: As memory grows, garbage collection pressure increases, causing performance degradation
2. **Significant protocol violations**: The `max_pending_blocks` limit exists specifically to prevent DoS attacks. This vulnerability completely bypasses that protection for the hash store
3. **Potential node crashes**: Unbounded memory growth can lead to Out-of-Memory crashes, taking observer nodes offline

While consensus observer nodes don't directly participate in consensus (they observe), their unavailability degrades network observability and can impact dependent services. The attack bypasses a core DoS protection mechanism designed to limit resource consumption.

The vulnerability does not directly impact consensus safety, but meets the High severity criteria for node slowdowns and protocol violations.

## Likelihood Explanation

**Likelihood: High**

The attack is highly likely to succeed because:

1. **Low barrier to entry**: Attacker only needs to be a subscribed peer (not a validator)
2. **No cryptographic bypass required**: Valid ordered blocks can be constructed with different content
3. **Concurrent processing guaranteed**: Network messages are inherently processed in parallel by async tasks
4. **Persistent vulnerability**: The inconsistency persists until `remove_ready_block()` is called, which only happens when payloads arrive
5. **Repeatable attack**: Attacker can continuously exploit the race to maintain memory pressure

The TOCTOU window is wide enough (between separate lock acquisitions) that concurrent message processing will reliably trigger the race condition with moderate message volume.

## Recommendation

**Fix 1: Atomic Check-and-Insert (Recommended)**

Hold the mutex across both the check and insert operations to eliminate the TOCTOU race:

```rust
// In consensus_observer.rs, process_ordered_block_message()
let pending_block_with_metadata = PendingBlockWithMetadata::new_with_arc(
    peer_network_id,
    message_received_time,
    observed_ordered_block,
);

// Atomically check and insert under same lock
let should_insert = {
    let mut block_data = self.observer_block_data.lock();
    
    // Check if already pending
    if block_data.existing_pending_block(&ordered_block) {
        false
    } else if !self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
        // Insert immediately if missing payloads
        block_data.insert_pending_block(pending_block_with_metadata.clone());
        false
    } else {
        true // Process block outside lock
    }
};

if should_insert {
    self.process_ordered_block(pending_block_with_metadata).await;
}
```

**Fix 2: Consistent Garbage Collection**

Modify `garbage_collect_pending_blocks()` to use the maximum of both store sizes and clean both stores:

```rust
fn garbage_collect_pending_blocks(&mut self) {
    let num_pending_blocks = self.blocks_without_payloads.len() as u64;
    let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
    
    if num_pending_blocks != num_pending_blocks_by_hash {
        error!("Store inconsistency detected: {} vs {} (by hash)", 
               num_pending_blocks, num_pending_blocks_by_hash);
        
        // Rebuild both stores from epoch/round store to ensure consistency
        let epoch_round_entries: Vec<_> = self.blocks_without_payloads.iter()
            .map(|(k, v)| (*k, v.clone())).collect();
        
        self.blocks_without_payloads_by_hash.clear();
        for (_, pending_block) in &epoch_round_entries {
            let first_block = pending_block.ordered_block().first_block();
            self.blocks_without_payloads_by_hash.insert(first_block.id(), pending_block.clone());
        }
    }
    
    // Use max of both stores for cleanup calculation
    let max_entries = num_pending_blocks.max(num_pending_blocks_by_hash);
    let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
    let num_blocks_to_remove = max_entries.saturating_sub(max_pending_blocks);
    
    // ... rest of cleanup logic
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod toctou_race_test {
    use super::*;
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    #[test]
    fn test_concurrent_insert_creates_inconsistency() {
        let config = ConsensusObserverConfig {
            max_num_pending_blocks: 10,
            ..Default::default()
        };
        let store = Arc::new(Mutex::new(PendingBlockStore::new(config)));
        
        // Create two different ordered blocks with same (epoch, round)
        let epoch = 1;
        let round = 100;
        let block1 = create_ordered_block_with_hash(epoch, round, HashValue::random());
        let block2 = create_ordered_block_with_hash(epoch, round, HashValue::random());
        
        let pending1 = create_pending_block(block1);
        let pending2 = create_pending_block(block2);
        
        // Use barrier to synchronize threads for maximum race window
        let barrier = Arc::new(Barrier::new(2));
        let store1 = store.clone();
        let store2 = store.clone();
        let barrier1 = barrier.clone();
        let barrier2 = barrier.clone();
        
        let handle1 = thread::spawn(move || {
            barrier1.wait();
            store1.lock().insert_pending_block(pending1);
        });
        
        let handle2 = thread::spawn(move || {
            barrier2.wait();
            store2.lock().insert_pending_block(pending2);
        });
        
        handle1.join().unwrap();
        handle2.join().unwrap();
        
        // Verify inconsistency: epoch/round store has 1 entry, hash store has 2
        let locked_store = store.lock();
        let epoch_round_count = locked_store.blocks_without_payloads.len();
        let hash_count = locked_store.blocks_without_payloads_by_hash.len();
        
        // Inconsistency detected - hash store has orphaned entry
        assert_eq!(epoch_round_count, 1, "Epoch/round store should have 1 entry");
        assert_eq!(hash_count, 2, "Hash store should have 2 entries due to race");
        assert_ne!(epoch_round_count, hash_count, "Stores are inconsistent");
    }
    
    #[test]
    fn test_garbage_collection_ignores_hash_store_overflow() {
        let config = ConsensusObserverConfig {
            max_num_pending_blocks: 5,
            ..Default::default()
        };
        let mut store = PendingBlockStore::new(config);
        
        // Manually create inconsistency: 4 in epoch/round, 10 in hash
        for i in 0..4 {
            let block = create_ordered_block_with_hash(1, 100 + i, HashValue::random());
            let pending = create_pending_block(block.clone());
            
            // Insert into epoch/round store
            store.blocks_without_payloads.insert(
                (1, 100 + i),
                pending.clone()
            );
            
            // Insert into hash store
            store.blocks_without_payloads_by_hash.insert(
                block.first_block().id(),
                pending
            );
        }
        
        // Add 6 orphaned entries to hash store only
        for i in 0..6 {
            let block = create_ordered_block_with_hash(1, 200 + i, HashValue::random());
            let pending = create_pending_block(block.clone());
            store.blocks_without_payloads_by_hash.insert(
                block.first_block().id(),
                pending
            );
        }
        
        assert_eq!(store.blocks_without_payloads.len(), 4);
        assert_eq!(store.blocks_without_payloads_by_hash.len(), 10);
        
        // Trigger garbage collection
        store.garbage_collect_pending_blocks();
        
        // Garbage collection doesn't remove orphaned entries!
        // Epoch/round store is below limit (4 < 5), so num_blocks_to_remove = 0
        // Hash store remains at 10 entries, way above the limit of 5
        assert_eq!(store.blocks_without_payloads.len(), 4);
        assert_eq!(store.blocks_without_payloads_by_hash.len(), 10, 
                   "Hash store overflow not cleaned up - DoS vulnerability!");
    }
}
```

## Notes

The vulnerability requires the attacker to be a subscribed peer to the consensus observer, which provides some natural access control. However, in a permissionless network, any node can potentially become a peer, making this exploitable. The inconsistency is eventually cleared by `remove_ready_block()` when called during payload processing, but an attacker can maintain memory pressure by continuously exploiting the race faster than cleanup occurs.

The fix should prioritize eliminating the TOCTOU race (Fix 1) as the root cause, with defensive consistency checking in garbage collection (Fix 2) as defense-in-depth.

### Citations

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L61-73)
```rust
pub struct PendingBlockStore {
    // The configuration of the consensus observer
    consensus_observer_config: ConsensusObserverConfig,

    // A map of ordered blocks that are without payloads. The key is
    // the (epoch, round) of the first block in the ordered block.
    blocks_without_payloads: BTreeMap<(u64, Round), Arc<PendingBlockWithMetadata>>,

    // A map of ordered blocks that are without payloads. The key is
    // the hash of the first block in the ordered block.
    // Note: this is the same as blocks_without_payloads, but with a different key.
    blocks_without_payloads_by_hash: BTreeMap<HashValue, Arc<PendingBlockWithMetadata>>,
}
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L91-99)
```rust
    pub fn existing_pending_block(&self, ordered_block: &OrderedBlock) -> bool {
        // Get the epoch and round of the first block
        let first_block = ordered_block.first_block();
        let first_block_epoch_round = (first_block.epoch(), first_block.round());

        // Check if the block is already in the store by epoch and round
        self.blocks_without_payloads
            .contains_key(&first_block_epoch_round)
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L112-154)
```rust
    pub fn insert_pending_block(&mut self, pending_block: Arc<PendingBlockWithMetadata>) {
        // Get the first block in the ordered blocks
        let first_block = pending_block.ordered_block().first_block();

        // Insert the block into the store using the epoch round of the first block
        let first_block_epoch_round = (first_block.epoch(), first_block.round());
        match self.blocks_without_payloads.entry(first_block_epoch_round) {
            Entry::Occupied(_) => {
                // The block is already in the store
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "A pending block was already found for the given epoch and round: {:?}",
                        first_block_epoch_round
                    ))
                );
            },
            Entry::Vacant(entry) => {
                // Insert the block into the store
                entry.insert(pending_block.clone());
            },
        }

        // Insert the block into the hash store using the hash of the first block
        let first_block_hash = first_block.id();
        match self.blocks_without_payloads_by_hash.entry(first_block_hash) {
            Entry::Occupied(_) => {
                // The block is already in the hash store
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "A pending block was already found for the given block hash: {:?}",
                        first_block_hash
                    ))
                );
            },
            Entry::Vacant(entry) => {
                // Insert the block into the hash store
                entry.insert(pending_block);
            },
        }

        // Perform garbage collection if the store is too large
        self.garbage_collect_pending_blocks();
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L158-195)
```rust
    fn garbage_collect_pending_blocks(&mut self) {
        // Verify that both stores have the same number of entries.
        // If not, log an error as this should never happen.
        let num_pending_blocks = self.blocks_without_payloads.len() as u64;
        let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
        if num_pending_blocks != num_pending_blocks_by_hash {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "The pending block stores have different numbers of entries: {} and {} (by hash)",
                    num_pending_blocks, num_pending_blocks_by_hash
                ))
            );
        }

        // Calculate the number of blocks to remove
        let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
        let num_blocks_to_remove = num_pending_blocks.saturating_sub(max_pending_blocks);

        // Remove the oldest blocks if the store is too large
        for _ in 0..num_blocks_to_remove {
            if let Some((oldest_epoch_round, pending_block)) =
                self.blocks_without_payloads.pop_first()
            {
                // Log a warning message for the removed block
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "The pending block store is too large: {:?} blocks. Removing the block for the oldest epoch and round: {:?}",
                        num_pending_blocks, oldest_epoch_round
                    ))
                );

                // Remove the block from the hash store
                let first_block = pending_block.ordered_block().first_block();
                self.blocks_without_payloads_by_hash
                    .remove(&first_block.id());
            }
        }
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L681-712)
```rust
        let block_pending = self
            .observer_block_data
            .lock()
            .existing_pending_block(&ordered_block);

        // If the block is out of date or already pending, ignore it
        if block_out_of_date || block_pending {
            // Update the metrics for the dropped ordered block
            update_metrics_for_dropped_ordered_block_message(peer_network_id, &ordered_block);
            return;
        }

        // Update the metrics for the received ordered block
        update_metrics_for_ordered_block_message(peer_network_id, &ordered_block);

        // Create a new pending block with metadata
        let observed_ordered_block = ObservedOrderedBlock::new(ordered_block);
        let pending_block_with_metadata = PendingBlockWithMetadata::new_with_arc(
            peer_network_id,
            message_received_time,
            observed_ordered_block,
        );

        // If all payloads exist, process the block. Otherwise, store it
        // in the pending block store and wait for the payloads to arrive.
        if self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        } else {
            self.observer_block_data
                .lock()
                .insert_pending_block(pending_block_with_metadata);
```
