# Audit Report

## Title
Health Check Failure State Corruption via Duplicate NewPeer Notifications During Connection Replacement

## Summary
The health checker's `create_peer_and_health_data()` function uses an `and_modify()` pattern that unconditionally updates a peer's round without resetting accumulated failures. When combined with duplicate `NewPeer` notifications sent during simultaneous dial connection replacements, this causes health check failure counts to persist across connection changes, violating the invariant that new connections should have fresh health check state.

## Finding Description

The vulnerability involves a chain of issues across three components:

**1. Unconditional NewPeer Broadcast in PeersAndMetadata** [1](#0-0) 

The `insert_connection_metadata()` function broadcasts `NewPeer` notifications unconditionally, even when merely updating an existing peer's connection metadata via the `and_modify()` branch. This means every call sends a notification regardless of whether it's a genuinely new peer or a connection update.

**2. Connection Replacement Triggers Duplicate Notifications** [2](#0-1) 

During simultaneous dial resolution, when `add_peer()` decides to replace an existing connection, it sets `send_new_peer_notification = false` to avoid duplicate notifications. However: [3](#0-2) 

The code still calls `insert_connection_metadata()`, which unconditionally sends a `NewPeer` notification, bypassing the intended duplicate suppression.

**3. Health Check State Corruption** [4](#0-3) 

When the health checker receives the duplicate `NewPeer` event, it calls `create_peer_and_health_data()` for a peer that already exists: [5](#0-4) 

The `and_modify()` closure only updates the round field without resetting failures. Compare this to the correct implementation in `reset_peer_round_state()`: [6](#0-5) 

This function properly resets both round AND failures when advancing rounds.

**Attack Scenario:**

1. Attacker peer connects to victim validator at round 100 → Health state: `{round: 100, failures: 0}`
2. Attacker deliberately fails health checks at rounds 101-102 → State: `{round: 100, failures: 2}`
3. Before reaching disconnect threshold, attacker initiates a new connection while maintaining the old one
4. Simultaneous dial resolution chooses to replace the connection
5. `insert_connection_metadata()` sends `NewPeer` notification
6. Health checker calls `create_peer_and_health_data(peer, 103)` → State becomes: `{round: 103, failures: 2}`
7. **Failures from old connection persist on new connection**
8. Attacker can repeat this pattern to maintain a controllable failure count, avoiding disconnection despite continued misbehavior

Alternatively, legitimate network conditions (natural simultaneous dials) cause honest peers to have stale failure counts persisted, leading to inappropriate disconnections.

## Impact Explanation

This vulnerability meets **High Severity** criteria under the Aptos bug bounty program for "Significant protocol violations" affecting the P2P network health checker protocol.

**Direct Impact:**
- Breaks the health check invariant that new connections should start with fresh state
- Enables malicious peers to manipulate their failure tracking to avoid disconnection
- Causes legitimate peers to be disconnected inappropriately when natural simultaneous dials occur

**Indirect Impact:**
- Degrades P2P network health by allowing unhealthy peers to remain connected
- Reduces validator connectivity if legitimate peers are disconnected prematurely  
- Could impact consensus participation if validators lose too many peer connections
- Affects network reliability and liveness guarantees

## Likelihood Explanation

**Likelihood: High**

- Simultaneous dial is a documented and expected network condition with dedicated handling logic
- Occurs naturally when two peers attempt to connect to each other simultaneously
- Can be deliberately triggered by any attacker controlling a peer node
- The vulnerability is triggered automatically every time connection replacement occurs
- No special privileges or timing requirements needed - any peer can initiate connections
- The code path is deterministic and reliably exploitable

The combination of natural occurrence and deliberate exploitability makes this highly likely to impact production deployments.

## Recommendation

**Fix 1: Reset failures in `create_peer_and_health_data()`**

Modify the `and_modify()` closure to reset failures when updating an existing peer:

```rust
pub fn create_peer_and_health_data(&mut self, peer_id: PeerId, round: u64) {
    self.health_check_data
        .write()
        .entry(peer_id)
        .and_modify(|health_check_data| {
            health_check_data.round = round;
            health_check_data.failures = 0;  // Reset failures on connection update
        })
        .or_insert_with(|| HealthCheckData::new(round));
}
```

**Fix 2: Prevent duplicate notifications in `insert_connection_metadata()`**

Track whether the peer already exists before broadcasting:

```rust
pub fn insert_connection_metadata(
    &self,
    peer_network_id: PeerNetworkId,
    connection_metadata: ConnectionMetadata,
) -> Result<(), Error> {
    let mut peers_and_metadata = self.peers_and_metadata.write();
    let peer_metadata_for_network =
        get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

    let is_new_peer = !peer_metadata_for_network.contains_key(&peer_network_id.peer_id());
    
    peer_metadata_for_network
        .entry(peer_network_id.peer_id())
        .and_modify(|peer_metadata| {
            peer_metadata.connection_metadata = connection_metadata.clone()
        })
        .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));

    self.set_cached_peers_and_metadata(peers_and_metadata.clone());

    // Only broadcast NewPeer for genuinely new peers
    if is_new_peer {
        let event = ConnectionNotification::NewPeer(
            connection_metadata, 
            peer_network_id.network_id()
        );
        self.broadcast(event);
    }

    Ok(())
}
```

**Recommended approach:** Implement **both** fixes for defense in depth. Fix 1 ensures health check state is always clean, while Fix 2 prevents the root cause of duplicate notifications.

## Proof of Concept

```rust
#[cfg(test)]
mod health_checker_state_corruption_test {
    use super::*;
    use aptos_types::PeerId;
    
    #[test]
    fn test_failure_persistence_across_connection_replacement() {
        // Create health checker interface
        let (network_client, receiver) = setup_test_network();
        let mut interface = HealthCheckNetworkInterface::new(network_client, receiver);
        
        let peer_id = PeerId::random();
        
        // Step 1: Peer connects at round 100
        interface.create_peer_and_health_data(peer_id, 100);
        assert_eq!(interface.get_peer_failures(peer_id), Some(0));
        
        // Step 2: Health checks fail at rounds 101 and 102
        interface.increment_peer_round_failure(peer_id, 101);
        interface.increment_peer_round_failure(peer_id, 102);
        assert_eq!(interface.get_peer_failures(peer_id), Some(2));
        
        // Step 3: Simulate connection replacement via simultaneous dial at round 103
        // This triggers duplicate NewPeer notification
        interface.create_peer_and_health_data(peer_id, 103);
        
        // BUG: Failures should be reset to 0 for new connection, but they persist!
        let failures = interface.get_peer_failures(peer_id).unwrap();
        assert_eq!(failures, 2, "BUG: Failures from old connection persist!");
        // Expected: 0 (fresh state for new connection)
        // Actual: 2 (stale failures carried over)
        
        // Step 4: One more failure puts peer over disconnect threshold
        interface.increment_peer_round_failure(peer_id, 103);
        assert_eq!(interface.get_peer_failures(peer_id), Some(3));
        
        // Peer will now be disconnected even though new connection only failed once!
        // This demonstrates the security impact: inappropriate disconnection
    }
}
```

## Notes

This vulnerability represents a state management flaw in the intersection of connection lifecycle management and health checking. The root cause is that the health checker was not designed to handle connection replacements without full disconnect/reconnect cycles. The simultaneous dial optimization, while improving connection establishment efficiency, inadvertently bypasses the health checker's assumption that `NewPeer` events always represent genuinely new connections.

The issue is exacerbated by the fact that `insert_connection_metadata()` serves a dual purpose (insert and update) but always broadcasts as if it were an insert operation, creating semantic confusion across the component boundary.

### Citations

**File:** network/framework/src/application/storage.rs (L198-211)
```rust
        // Update the metadata for the peer or insert a new entry
        peer_metadata_for_network
            .entry(peer_network_id.peer_id())
            .and_modify(|peer_metadata| {
                peer_metadata.connection_metadata = connection_metadata.clone()
            })
            .or_insert_with(|| PeerMetadata::new(connection_metadata.clone()));

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        let event =
            ConnectionNotification::NewPeer(connection_metadata, peer_network_id.network_id());
        self.broadcast(event);
```

**File:** network/framework/src/peer_manager/mod.rs (L626-643)
```rust
        if let Entry::Occupied(active_entry) = self.active_peers.entry(peer_id) {
            let (curr_conn_metadata, _) = active_entry.get();
            if Self::simultaneous_dial_tie_breaking(
                self.network_context.peer_id(),
                peer_id,
                curr_conn_metadata.origin,
                conn_meta.origin,
            ) {
                let (_, peer_handle) = active_entry.remove();
                // Drop the existing connection and replace it with the new connection
                drop(peer_handle);
                info!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    "{} Closing existing connection with Peer {} to mitigate simultaneous dial",
                    self.network_context,
                    peer_id.short_str()
                );
                send_new_peer_notification = false;
```

**File:** network/framework/src/peer_manager/mod.rs (L684-687)
```rust
        self.peers_and_metadata.insert_connection_metadata(
            PeerNetworkId::new(self.network_context.network_id(), peer_id),
            conn_meta.clone(),
        )?;
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L209-217)
```rust
                conn_event = connection_events.select_next_some() => {
                    match conn_event {
                        ConnectionNotification::NewPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.create_peer_and_health_data(
                                    metadata.remote_peer_id, self.round
                                );
                            }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L95-101)
```rust
    pub fn create_peer_and_health_data(&mut self, peer_id: PeerId, round: u64) {
        self.health_check_data
            .write()
            .entry(peer_id)
            .and_modify(|health_check_data| health_check_data.round = round)
            .or_insert_with(|| HealthCheckData::new(round));
    }
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L128-135)
```rust
    pub fn reset_peer_round_state(&mut self, peer_id: PeerId, round: u64) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            if round > health_check_data.round {
                health_check_data.round = round;
                health_check_data.failures = 0;
            }
        }
    }
```
