# Audit Report

## Title
Transaction Pruner Skips Re-Pruning on Recovery When Progress Metadata Diverges from Actual State

## Summary
If `DbMetadataKey::TransactionPrunerProgress` becomes ahead of the actual pruned state due to a crash or corruption during `write_schemas()`, the catch-up logic in `TransactionPruner::new()` at line 101 will **skip re-pruning** rather than re-prune the missing transactions. This leads to permanent storage bloat and database state inconsistency. [1](#0-0) 

## Finding Description

The vulnerability occurs in the initialization and recovery flow of the transaction pruner. During normal pruning operations, the `prune()` method creates a `SchemaBatch` containing both transaction deletion operations and a progress metadata update, which should be written atomically: [2](#0-1) 

While RocksDB's `WriteBatch` with `sync=true` should provide atomicity guarantees: [3](#0-2) 

The question's premise accepts that divergence can occur (e.g., through filesystem corruption, hardware failure, or storage-level bugs). When this happens:

1. **Divergent State Creation:** `TransactionPrunerProgress` is written to version `X`, but actual transaction deletions for versions `[current, X)` are not persisted.

2. **Faulty Recovery:** On node restart, `TransactionPruner::new()` calls `get_or_initialize_subpruner_progress()` which reads the stored (ahead) progress value `X`: [4](#0-3) 

3. **Skip Logic Triggered:** The catch-up call at line 101 executes `myself.prune(X, X)`, which invokes `get_pruning_candidate_transactions(X, X)`: [5](#0-4) 

Since `start == end`, the iteration at lines 122-128 returns an empty vector because no version satisfies `version < end` when seeking from `start`.

4. **Permanent State Corruption:** Transactions that should have been deleted remain in the database indefinitely, while the metadata falsely indicates they were pruned. No future pruning operation will revisit these versions since the progress metadata has already advanced past them.

This violates **Invariant #4: State Consistency** - state transitions must be atomic and the database state must accurately reflect metadata.

## Impact Explanation

This vulnerability meets **Medium Severity** criteria per Aptos bug bounty guidelines:

- **"State inconsistencies requiring intervention":** The pruner progress metadata becomes permanently desynchronized from actual database state, requiring manual detection and remediation.

- **Storage Bloat:** Unpruned transactions accumulate, consuming disk space that should have been reclaimed. If this occurs repeatedly across multiple crashes, storage can grow unbounded beyond configured pruning windows.

- **Database Integrity Violation:** The database contains transactions older than the pruning window while metadata claims they don't exist, breaking storage invariants that other components may rely on.

- **No Direct Consensus Impact:** This does not immediately cause consensus splits or validator disagreements, as the unpruned data is not actively used in consensus (it's historical data that should have been deleted).

The issue does not qualify as Critical or High because it doesn't cause fund loss, consensus safety violations, or immediate node failures. However, it does create persistent state corruption requiring operator intervention.

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires a specific failure scenario:
- A crash or corruption occurring during `write_schemas()` that violates RocksDB's atomicity guarantees
- This could occur through filesystem corruption, storage hardware failures, kernel panics, or edge-case bugs in RocksDB/storage drivers

While RocksDB with `sync=true` provides strong atomicity guarantees, real-world storage systems can experience:
- Power failures during fsync operations
- Filesystem bugs causing partial writes
- Storage device firmware bugs
- Rare race conditions in crash recovery

The impact accumulates over time - each occurrence leaves permanent "holes" in the pruned data, making long-running nodes increasingly affected.

## Recommendation

Add validation logic in `TransactionPruner::new()` to detect and handle divergent progress states. Before trusting the stored progress, verify that transactions at or after that version actually don't exist in the database:

```rust
pub(in crate::pruner) fn new(
    transaction_store: Arc<TransactionStore>,
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
    internal_indexer_db: Option<InternalIndexerDB>,
) -> Result<Self> {
    let stored_progress = get_or_initialize_subpruner_progress(
        ledger_db.transaction_db_raw(),
        &DbMetadataKey::TransactionPrunerProgress,
        metadata_progress,
    )?;

    // Validate progress consistency: check if transactions that should be pruned still exist
    let actual_progress = if stored_progress > 0 {
        // Scan backwards to find the actual first unpruned transaction
        let mut validated_progress = stored_progress;
        for check_version in (metadata_progress..stored_progress).rev() {
            if ledger_db.transaction_db_raw().get::<TransactionSchema>(&check_version)?.is_some() {
                // Found a transaction that should have been pruned - use this as actual progress
                validated_progress = check_version;
                info!(
                    stored_progress = stored_progress,
                    actual_progress = validated_progress,
                    "Detected progress divergence, will re-prune from actual progress"
                );
                break;
            }
        }
        validated_progress
    } else {
        stored_progress
    };

    let myself = TransactionPruner {
        transaction_store,
        ledger_db,
        internal_indexer_db,
    };

    info!(
        progress = actual_progress,
        metadata_progress = metadata_progress,
        "Catching up TransactionPruner."
    );
    myself.prune(actual_progress, metadata_progress)?;

    Ok(myself)
}
```

This validates the stored progress by checking if supposedly-pruned transactions actually exist, and uses the actual progress for catch-up pruning.

## Proof of Concept

```rust
#[cfg(test)]
mod progress_divergence_test {
    use super::*;
    use crate::AptosDB;
    use aptos_temppath::TempPath;
    use aptos_types::transaction::{Transaction, Version};
    use aptos_schemadb::SchemaBatch;
    
    #[test]
    fn test_progress_ahead_of_actual_state_skips_pruning() {
        let tmp_dir = TempPath::new();
        let db = AptosDB::new_for_test(&tmp_dir);
        
        // Write transactions 0-99
        let mut batch = SchemaBatch::new();
        for v in 0..100 {
            let txn = Transaction::BlockMetadata(/* ... */);
            db.transaction_store.put_transaction(v, &txn, true, &mut batch).unwrap();
        }
        db.ledger_db.transaction_db().write_schemas(batch).unwrap();
        
        // Simulate corrupted state: manually set progress to 50 without actually deleting transactions
        db.ledger_db.transaction_db().write_pruner_progress(50).unwrap();
        
        // Create new pruner - this should catch up from 50 to 50 (skip logic)
        let transaction_store = Arc::new(TransactionStore::new(Arc::clone(&db.ledger_db)));
        let pruner = TransactionPruner::new(
            transaction_store,
            Arc::clone(&db.ledger_db),
            50, // metadata_progress
            None,
        ).unwrap();
        
        // Verify that transactions 0-49 still exist (they weren't re-pruned!)
        for v in 0..50 {
            assert!(db.ledger_db.transaction_db_raw()
                .get::<TransactionSchema>(&v).unwrap().is_some(),
                "Transaction {} should still exist but was expected to be pruned", v);
        }
        
        // This demonstrates the vulnerability: progress metadata says 50,
        // but transactions < 50 still exist in the database
    }
}
```

This test demonstrates that when progress metadata is artificially set ahead of actual pruned state, the initialization logic fails to re-prune the orphaned transactions, leaving them permanently in the database despite metadata claiming they were deleted.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-74)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
        self.ledger_db.transaction_db().prune_transactions(
            current_progress,
            target_version,
            &mut batch,
        )?;
        self.transaction_store
            .prune_transaction_summaries_by_account(&candidate_transactions, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L78-104)
```rust
    pub(in crate::pruner) fn new(
        transaction_store: Arc<TransactionStore>,
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_db_raw(),
            &DbMetadataKey::TransactionPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionPruner {
            transaction_store,
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L106-131)
```rust
    fn get_pruning_candidate_transactions(
        &self,
        start: Version,
        end: Version,
    ) -> Result<Vec<(Version, Transaction)>> {
        ensure!(end >= start, "{} must be >= {}", end, start);

        let mut iter = self
            .ledger_db
            .transaction_db_raw()
            .iter::<TransactionSchema>()?;
        iter.seek(&start)?;

        // The capacity is capped by the max number of txns we prune in a single batch. It's a
        // relatively small number set in the config, so it won't cause high memory usage here.
        let mut txns = Vec::with_capacity((end - start) as usize);
        for item in iter {
            let (version, txn) = item?;
            if version >= end {
                break;
            }
            txns.push((version, txn));
        }

        Ok(txns)
    }
```

**File:** storage/schemadb/src/lib.rs (L289-309)
```rust
    fn write_schemas_inner(&self, batch: impl IntoRawBatch, option: &WriteOptions) -> DbResult<()> {
        let labels = [self.name.as_str()];
        let _timer = APTOS_SCHEMADB_BATCH_COMMIT_LATENCY_SECONDS.timer_with(&labels);

        let raw_batch = batch.into_raw_batch(self)?;

        let serialized_size = raw_batch.inner.size_in_bytes();
        self.inner
            .write_opt(raw_batch.inner, option)
            .into_db_res()?;

        raw_batch.stats.commit();
        APTOS_SCHEMADB_BATCH_COMMIT_BYTES.observe_with(&[&self.name], serialized_size as f64);

        Ok(())
    }

    /// Writes a group of records wrapped in a [`SchemaBatch`].
    pub fn write_schemas(&self, batch: impl IntoRawBatch) -> DbResult<()> {
        self.write_schemas_inner(batch, &sync_write_option())
    }
```

**File:** storage/aptosdb/src/pruner/pruner_utils.rs (L44-60)
```rust
pub(crate) fn get_or_initialize_subpruner_progress(
    sub_db: &DB,
    progress_key: &DbMetadataKey,
    metadata_progress: Version,
) -> Result<Version> {
    Ok(
        if let Some(v) = sub_db.get::<DbMetadataSchema>(progress_key)? {
            v.expect_version()
        } else {
            sub_db.put::<DbMetadataSchema>(
                progress_key,
                &DbMetadataValue::Version(metadata_progress),
            )?;
            metadata_progress
        },
    )
}
```
