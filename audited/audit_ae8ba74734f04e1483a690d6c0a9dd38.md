# Audit Report

## Title
Missing Storage Format Validation Causes Data Deserialization Failures in Indexer-GRPC Data Service

## Summary
The indexer-grpc data service lacks validation to ensure that the configured `StorageFormat` matches the format stored in `FileStoreMetadata` and used by the cache worker. This can lead to transaction data deserialization failures or corruption when there are configuration mismatches between components.

## Finding Description
The indexer-grpc data service reads transaction data from both Redis cache and file storage. The storage format (compression scheme) can be either `Lz4CompressedProto` or `Base64UncompressedProto` for cache, and `Lz4CompressedProto` or `JsonBase64UncompressedProto` for file store, determined by the `enable_cache_compression` configuration setting.

**The vulnerability occurs because:**

1. The `FileStoreMetadata` contains a `storage_format` field that records which format was used to write the data [1](#0-0) 

2. When the data service initializes, it creates a file store operator with a `storage_format` based on its local configuration [2](#0-1) 

3. The data service validates only the `chain_id` from metadata, but **does not validate** that the metadata's `storage_format` matches its configured format [3](#0-2) 

4. When reading transactions from file store, the operator blindly uses its configured format to decode data [4](#0-3) 

5. Similarly, for Redis cache, different storage formats use different key prefixes (`l4:{version}` vs `{version}`), and the wrong format will cause cache misses or deserialization failures [5](#0-4) 

**Configuration mismatch scenario:**
- File store was written with `enable_cache_compression: true` (uses `Lz4CompressedProto`)
- Data service configured with `enable_cache_compression: false` (expects `JsonBase64UncompressedProto`)
- Data service attempts to decode LZ4-compressed protobuf data as JSON, causing deserialization panic or returning corrupted transactions

## Impact Explanation
**Medium Severity** - This qualifies as "State inconsistencies requiring intervention" per the bug bounty criteria. However, this issue requires operator misconfiguration rather than attacker exploitation, which significantly limits its severity. The impact includes:

- Transaction data deserialization failures leading to service crashes
- Potential data corruption if deserialization succeeds with wrong format but produces invalid data
- Cache misses forcing unnecessary file store access, degrading performance
- Service unavailability affecting downstream indexer consumers

This does not reach High or Critical severity because:
- It requires configuration errors by trusted operators, not attacker exploitation
- It does not directly affect consensus or validator operations
- It is limited to the indexer infrastructure, not the core blockchain

## Likelihood Explanation
**Medium Likelihood** - This can occur during:
- Rolling deployments where different service instances have mismatched configurations
- Configuration file errors or template mistakes in deployment automation
- Migration scenarios when upgrading from legacy to compressed storage format
- Multiple teams managing different components with inconsistent settings

The GCS file store implementation includes this validation check [6](#0-5)  but only for write operations, while the local file store implementation lacks it entirely [7](#0-6) 

## Recommendation
Add storage format validation in the data service's startup sequence to ensure configuration consistency:

```rust
// In data_fetcher_task function, after getting metadata:
let metadata = file_store_operator.get_file_store_metadata().await.unwrap();
let metadata_chain_id = metadata.chain_id;

// ADD THIS VALIDATION:
if metadata.storage_format != file_store_operator.storage_format() {
    let _result = tx
        .send_timeout(
            Err(Status::failed_precondition(format!(
                "[Data Service] Storage format mismatch: metadata has {:?}, service configured for {:?}",
                metadata.storage_format,
                file_store_operator.storage_format()
            ))),
            RESPONSE_CHANNEL_SEND_TIMEOUT,
        )
        .await;
    error!(
        "[Data Service] Storage format mismatch: metadata={:?}, configured={:?}",
        metadata.storage_format,
        file_store_operator.storage_format()
    );
    return;
}
```

Additionally, add validation for cache storage format by storing it in Redis metadata and checking at startup.

## Proof of Concept
```rust
#[tokio::test]
async fn test_storage_format_mismatch() {
    // 1. Create file store with Lz4CompressedProto
    let mut file_operator_writer = GcsFileStoreOperator::new(
        "test-bucket".to_string(),
        None,
        "service-account.json".to_string(),
        true, // enable_cache_compression
    );
    
    // 2. Write metadata with Lz4CompressedProto format
    file_operator_writer
        .update_file_store_metadata_internal(1, 1000)
        .await
        .unwrap();
    
    // 3. Create data service operator with mismatched format
    let file_operator_reader = GcsFileStoreOperator::new(
        "test-bucket".to_string(),
        None,
        "service-account.json".to_string(),
        false, // disable compression - MISMATCH!
    );
    
    // 4. Attempt to read - this will fail with deserialization error
    // because it tries to decode Lz4 data as JSON
    let metadata = file_operator_reader.get_file_store_metadata().await.unwrap();
    assert_eq!(metadata.storage_format, StorageFormat::Lz4CompressedProto);
    assert_eq!(file_operator_reader.storage_format(), StorageFormat::JsonBase64UncompressedProto);
    
    // This mismatch is NOT validated, causing deserialization failures
    // when reading transaction data
}
```

## Notes
While this is a real implementation gap that should be fixed for operational reliability, it **does not qualify as an exploitable security vulnerability** per strict bug bounty criteria because it requires operator misconfiguration rather than attacker action. The issue should be addressed as part of defensive programming and operational safety improvements.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L34-46)
```rust
/// FileStoreMetadata is the metadata for the file store.
/// It's a JSON file with name: metadata.json.
#[derive(Serialize, Deserialize, Copy, Clone, Debug, PartialEq, Eq)]
pub struct FileStoreMetadata {
    pub chain_id: u64,
    // The size of each file folder, BLOB_STORAGE_SIZE, i.e., 1_000.
    pub file_folder_size: usize,
    // The current version of the file store.
    pub version: u64,
    // Storage format; backward compatible.
    #[serde(default = "default_file_storage_format")]
    pub storage_format: StorageFormat,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/compression_util.rs (L127-140)
```rust
    pub fn build_key(version: u64, storage_format: StorageFormat) -> String {
        match storage_format {
            StorageFormat::Lz4CompressedProto => {
                format!("l4:{}", version)
            },
            StorageFormat::Base64UncompressedProto => {
                format!("{}", version)
            },
            StorageFormat::JsonBase64UncompressedProto => {
                // This is fatal to see that we are using legacy file format in cache side.
                panic!("JsonBase64UncompressedProto is not supported in cache.")
            },
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L156-160)
```rust
        let cache_storage_format: StorageFormat = if self.enable_cache_compression {
            StorageFormat::Lz4CompressedProto
        } else {
            StorageFormat::Base64UncompressedProto
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L414-463)
```rust
    // Validate chain id
    let mut metadata = file_store_operator.get_file_store_metadata().await;
    while metadata.is_none() {
        metadata = file_store_operator.get_file_store_metadata().await;
        tracing::warn!(
            "[File worker] File store metadata not found. Waiting for {} ms.",
            FILE_STORE_METADATA_WAIT_MS
        );
        tokio::time::sleep(std::time::Duration::from_millis(
            FILE_STORE_METADATA_WAIT_MS,
        ))
        .await;
    }

    let metadata_chain_id = metadata.unwrap().chain_id;

    // Validate redis chain id. Must be present by the time it gets here
    let chain_id = match cache_operator.get_chain_id().await {
        Ok(chain_id) => chain_id.unwrap(),
        Err(e) => {
            ERROR_COUNT
                .with_label_values(&["redis_get_chain_id_failed"])
                .inc();
            // Connection will be dropped anyway, so we ignore the error here.
            let _result = tx
                .send_timeout(
                    Err(Status::unavailable(
                        "[Data Service] Cannot get the chain id from redis; please retry.",
                    )),
                    RESPONSE_CHANNEL_SEND_TIMEOUT,
                )
                .await;
            error!(
                error = e.to_string(),
                "[Data Service] Failed to get chain id from redis."
            );
            return;
        },
    };

    if metadata_chain_id != chain_id {
        let _result = tx
            .send_timeout(
                Err(Status::unavailable("[Data Service] Chain ID mismatch.")),
                RESPONSE_CHANNEL_SEND_TIMEOUT,
            )
            .await;
        error!("[Data Service] Chain ID mismatch.",);
        return;
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/mod.rs (L59-86)
```rust
    async fn get_transactions_with_durations(
        &self,
        version: u64,
        retries: u8,
    ) -> Result<(Vec<Transaction>, f64, f64)> {
        let io_start_time = std::time::Instant::now();
        let bytes = self.get_raw_file_with_retries(version, retries).await?;
        let io_duration = io_start_time.elapsed().as_secs_f64();
        let decoding_start_time = std::time::Instant::now();
        let storage_format = self.storage_format();

        let transactions_in_storage = tokio::task::spawn_blocking(move || {
            FileEntry::new(bytes, storage_format).into_transactions_in_storage()
        })
        .await
        .context("Converting storage bytes to FileEntry transactions thread panicked")?;

        let decoding_duration = decoding_start_time.elapsed().as_secs_f64();
        Ok((
            transactions_in_storage
                .transactions
                .into_iter()
                .skip((version % FILE_ENTRY_TRANSACTION_COUNT) as usize)
                .collect(),
            io_duration,
            decoding_duration,
        ))
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/gcs.rs (L167-172)
```rust
        if let Some(metadata) = self.get_file_store_metadata().await {
            assert_eq!(metadata.chain_id, expected_chain_id, "Chain ID mismatch.");
            assert_eq!(
                metadata.storage_format, self.storage_format,
                "Storage format mismatch."
            );
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/file_store_operator/local.rs (L94-124)
```rust
    async fn update_file_store_metadata_with_timeout(
        &mut self,
        expected_chain_id: u64,
        _version: u64,
    ) -> anyhow::Result<()> {
        let metadata_path = self.path.join(METADATA_FILE_NAME);
        match tokio::fs::read(metadata_path).await {
            Ok(metadata) => {
                let metadata: FileStoreMetadata =
                    serde_json::from_slice(&metadata).expect("Expected metadata to be valid JSON.");
                anyhow::ensure!(metadata.chain_id == expected_chain_id, "Chain ID mismatch.");
                Ok(())
            },
            Err(err) => {
                if err.kind() == std::io::ErrorKind::NotFound {
                    // If the metadata is not found, it means the file store is empty.
                    info!("File store is empty. Creating metadata file.");
                    self.update_file_store_metadata_internal(expected_chain_id, 0)
                        .await
                        .expect("[Indexer File] Update metadata failed.");
                    Ok(())
                } else {
                    // If not in write mode, the metadata must exist.
                    Err(anyhow::Error::msg(format!(
                        "Metadata not found or file store operator is not in write mode. {}",
                        err
                    )))
                }
            },
        }
    }
```
