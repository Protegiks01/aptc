# Audit Report

## Title
RPC Timeout Bypass Enables Coordinated Validator DoS Attack on Batch Retrieval

## Summary
Malicious validators can delay batch response messages to just under the `rpc_timeout` threshold (default: 5000ms), avoiding timeout detection while significantly degrading batch retrieval performance. This attack slows down block execution and consensus progress without triggering retry mechanisms.

## Finding Description

The `request_batch()` function in the batch requester implements timeout-based retry logic, but the timeout is enforced at the individual RPC level rather than globally across all peer attempts. [1](#0-0) 

**Attack Mechanism:**

When a block requires batch retrieval for execution, the system sends RPC requests to multiple peers who should have the batch (typically those who signed the ProofOfStore). [2](#0-1) 

Each RPC request has an individual timeout configured via `batch_request_rpc_timeout_ms` (default: 5000ms). [3](#0-2) 

Malicious validators can:
1. Receive batch requests from honest validators
2. Delay their response to ~4999ms (just under the 5000ms timeout)
3. Eventually send a valid response or error (avoiding timeout detection)
4. Repeat this pattern across multiple batch requests

The vulnerability exists because:
- The RPC timeout only fires at â‰¥5000ms, so a 4999ms delay doesn't trigger error handling [4](#0-3) 
- The `futures.next()` waits for ANY future to complete, but if all contacted peers delay, retrieval stalls [5](#0-4) 
- Retry intervals (500ms) send requests to additional peers, but early-round delays still impact total latency [6](#0-5) 

**Propagation to Block Execution:**

The payload manager aggregates all batch retrievals using `join_all`, meaning if even one batch is delayed, the entire block execution is delayed. [7](#0-6) 

## Impact Explanation

**Severity: Medium (per Aptos Bug Bounty criteria)**

This vulnerability causes "Validator node slowdowns" which qualifies as **High Severity** ($50,000) per the bounty program. However, the coordinated nature and validator-level access required reduces practical exploitability.

**Impact on Network:**
- Delays batch retrieval by up to `rpc_timeout` (5 seconds) per affected batch
- Slows block execution and transaction confirmation
- Degrades consensus performance without breaking safety guarantees
- Can cause temporary liveness issues if sustained across multiple blocks

**Affected Components:**
- All validators performing block execution
- Consensus progress and block proposal rates
- End-user transaction latency

The attack does NOT:
- Break consensus safety (no double-spending or forks)
- Cause fund loss or theft
- Permanently halt the network (honest validators eventually respond)

## Likelihood Explanation

**Likelihood: Low to Medium**

**Requirements for successful attack:**
1. Attacker must control one or more active validators in the validator set
2. Malicious validators must be selected as responders (signers of ProofOfStore) for targeted batches
3. Coordination among multiple validators increases effectiveness
4. Attack is detectable through latency monitoring and peer reputation systems

**Mitigating factors:**
- Requests sent to multiple peers simultaneously (default: 5) [8](#0-7) 
- Continuous retry mechanism sends requests to new peers every 500ms
- Bounded retry limit (10 attempts) prevents indefinite delays
- Peer rotation reduces probability of contacting only malicious validators

**Attack complexity:**
- Moderate: Requires validator access but no complex cryptographic attacks
- Easily detectable through network monitoring
- Limited impact without sustained coordination

## Recommendation

**Immediate Fix: Implement Global Batch Retrieval Timeout**

Add a global timeout for the entire batch retrieval operation, not just individual RPCs:

```rust
pub(crate) async fn request_batch(
    &self,
    digest: HashValue,
    expiration: u64,
    responders: Arc<Mutex<BTreeSet<PeerId>>>,
    mut subscriber_rx: oneshot::Receiver<PersistedValue<BatchInfoExt>>,
) -> ExecutorResult<Vec<SignedTransaction>> {
    // Add global timeout wrapper
    let global_timeout = Duration::from_millis(
        (self.rpc_timeout_ms * self.retry_limit) as u64
    );
    
    tokio::time::timeout(global_timeout, async {
        // Existing logic here...
    })
    .await
    .map_err(|_| ExecutorError::CouldNotGetData)?
}
```

**Additional Hardening Measures:**

1. **Early Response Detection**: Track per-peer response latencies and prioritize faster peers in future requests
2. **Adaptive Timeout**: Reduce `rpc_timeout` for peers with history of slow responses
3. **Parallel Request Limit**: Increase `batch_request_num_peers` to query more peers simultaneously
4. **Reputation System**: Penalize consistently slow responders in peer selection

## Proof of Concept

```rust
#[tokio::test]
async fn test_malicious_peer_delay_attack() {
    use std::time::{Duration, Instant};
    use tokio::time::sleep;
    
    // Create mock malicious sender that delays to just under timeout
    #[derive(Clone)]
    struct MaliciousSender {
        delay_ms: u64,
    }
    
    #[async_trait::async_trait]
    impl QuorumStoreSender for MaliciousSender {
        async fn request_batch(
            &self,
            request: BatchRequest,
            _recipient: Author,
            timeout: Duration,
        ) -> anyhow::Result<BatchResponse> {
            // Delay to just under timeout (e.g., 4999ms for 5000ms timeout)
            let delay = Duration::from_millis(
                timeout.as_millis() as u64 - 1
            );
            sleep(delay).await;
            
            // Return error to force retry
            Err(anyhow::anyhow!("Delayed error response"))
        }
        
        // Other methods unimplemented...
    }
    
    let rpc_timeout_ms = 5000;
    let retry_interval_ms = 500;
    let retry_limit = 3; // Limited for test
    
    let batch_requester = BatchRequester::new(
        1, // epoch
        AccountAddress::random(),
        5, // request_num_peers
        retry_limit,
        retry_interval_ms,
        rpc_timeout_ms,
        MaliciousSender { delay_ms: 4999 },
        ValidatorVerifier::new_single(
            AccountAddress::random(),
            bls12381::PublicKey::dummy_key()
        ).into(),
    );
    
    let start = Instant::now();
    let (_, subscriber_rx) = oneshot::channel();
    
    let result = batch_requester
        .request_batch(
            HashValue::random(),
            u64::MAX,
            Arc::new(Mutex::new(btreeset![
                AccountAddress::random(),
                AccountAddress::random(),
                AccountAddress::random(),
                AccountAddress::random(),
                AccountAddress::random(),
            ])),
            subscriber_rx,
        )
        .await;
    
    let elapsed = start.elapsed();
    
    // Verify the attack succeeded in delaying retrieval
    // Should take close to rpc_timeout despite not timing out
    assert!(elapsed >= Duration::from_millis(4999));
    assert!(elapsed < Duration::from_millis(10000)); // Within reasonable bounds
    assert!(result.is_err()); // Eventually fails after retries
    
    println!("Batch retrieval delayed by: {:?}", elapsed);
}
```

**Notes**

This vulnerability represents a DoS attack vector that requires validator-level access. While technically exploitable, the impact is bounded by the retry mechanism and the requirement for coordination among multiple validators. The attack degrades performance but does not break consensus safety guarantees. Network operators should implement monitoring for abnormal batch retrieval latencies and consider implementing the recommended global timeout and reputation system to mitigate this attack vector.

### Citations

**File:** consensus/src/quorum_store/batch_requester.rs (L101-180)
```rust
    pub(crate) async fn request_batch(
        &self,
        digest: HashValue,
        expiration: u64,
        responders: Arc<Mutex<BTreeSet<PeerId>>>,
        mut subscriber_rx: oneshot::Receiver<PersistedValue<BatchInfoExt>>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let validator_verifier = self.validator_verifier.clone();
        let mut request_state = BatchRequesterState::new(responders, self.retry_limit);
        let network_sender = self.network_sender.clone();
        let request_num_peers = self.request_num_peers;
        let my_peer_id = self.my_peer_id;
        let epoch = self.epoch;
        let retry_interval = Duration::from_millis(self.retry_interval_ms as u64);
        let rpc_timeout = Duration::from_millis(self.rpc_timeout_ms as u64);

        monitor!("batch_request", {
            let mut interval = time::interval(retry_interval);
            let mut futures = FuturesUnordered::new();
            let request = BatchRequest::new(my_peer_id, epoch, digest);
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
                    },
                    Some(response) = futures.next() => {
                        match response {
                            Ok(BatchResponse::Batch(batch)) => {
                                counters::RECEIVED_BATCH_RESPONSE_COUNT.inc();
                                let payload = batch.into_transactions();
                                return Ok(payload);
                            }
                            // Short-circuit if the chain has moved beyond expiration
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
                            }
                            Ok(BatchResponse::BatchV2(_)) => {
                                error!("Batch V2 response is not supported");
                            }
                            Err(e) => {
                                counters::RECEIVED_BATCH_RESPONSE_ERROR_COUNT.inc();
                                debug!("QS: batch request error, digest:{}, error:{:?}", digest, e);
                            }
                        }
                    },
                    result = &mut subscriber_rx => {
                        match result {
                            Ok(persisted_value) => {
                                counters::RECEIVED_BATCH_FROM_SUBSCRIPTION_COUNT.inc();
                                let (_, maybe_payload) = persisted_value.unpack();
                                return Ok(maybe_payload.expect("persisted value must exist"));
                            }
                            Err(err) => {
                                debug!("channel closed: {}", err);
                            }
                        };
                    },
                }
            }
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
        })
    }
```

**File:** config/src/config/quorum_store_config.rs (L127-130)
```rust
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L111-122)
```rust
    async fn request_and_wait_transactions(
        batches: Vec<(BatchInfo, Vec<PeerId>)>,
        block_timestamp: u64,
        batch_reader: Arc<dyn BatchReader>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
        let futures = Self::request_transactions(batches, block_timestamp, batch_reader);
        let mut all_txns = Vec::new();
        for result in futures::future::join_all(futures).await {
            all_txns.append(&mut result?);
        }
        Ok(all_txns)
    }
```
