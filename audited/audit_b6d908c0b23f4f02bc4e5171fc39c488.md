# Audit Report

## Title
Unbounded Resource Consumption in Validator Performance Analysis CLI Command

## Summary
The `analyze-validator-performance` CLI command lacks bounds validation on epoch ranges, allowing unbounded memory consumption and excessive API calls. An attacker or user can request analysis across thousands of epochs, causing memory exhaustion on the client machine and potentially overwhelming the REST API server with tens of thousands of requests.

## Finding Description

The `AnalyzeValidatorPerformance` command in the Aptos CLI allows users to analyze validator performance across epoch ranges, but contains no limits on the number of epochs that can be processed or the total memory consumed. [1](#0-0) 

The command accepts `start_epoch` and `end_epoch` parameters with no validation. When `end_epoch` is not specified, the code defaults to `i64::MAX`: [2](#0-1) 

The `fetch_new_block_events()` function then enters an unbounded loop, fetching block events in batches and storing ALL blocks for ALL epochs in memory: [3](#0-2) 

Each `EpochInfo` structure contains a complete vector of all block events for that epoch, plus all validator information: [4](#0-3) 

Additionally, for each epoch transition, the code fetches all transactions between epochs, making additional API calls: [5](#0-4) 

The fetched data is then stored in a HashMap containing ALL epoch statistics in memory: [6](#0-5) 

This breaks the Resource Limits invariant: all operations must respect computational and memory constraints.

## Impact Explanation

**Medium Severity** - This vulnerability causes resource exhaustion through:

1. **Client-side memory exhaustion**: Analyzing 1,000 epochs with 10,000 blocks each results in 10 million block events stored in memory, potentially consuming multiple gigabytes of RAM and crashing the client machine.

2. **Excessive API calls**: The API has a default rate limit of 100 requests per minute: [7](#0-6) 

Analyzing 1,000 epochs requires:
- ~10,000+ calls to fetch block events (at MAX_FETCH_BATCH_SIZE = 1000 per call) [8](#0-7) 
- ~1,000 additional calls for epoch transition transaction fetching
- Binary search overhead for finding the start epoch

This can overwhelm API servers, particularly if the API runs on validator nodes, causing "API crashes" or "Validator node slowdowns" (High severity impacts), though classified as Medium due to the indirect nature of the attack.

## Likelihood Explanation

**High Likelihood** - Exploitation requires only:
1. Running the CLI command: `aptos node analyze-validator-performance --start-epoch 0`
2. No authentication or special permissions needed
3. No rate limiting or validation prevents execution
4. Likely to occur accidentally by legitimate users analyzing long time periods

The vulnerability can be triggered intentionally by malicious actors or unintentionally by operators analyzing historical validator performance on mainnets with thousands of epochs.

## Recommendation

Implement bounded resource consumption with the following mitigations:

1. **Add maximum epoch range validation**:
```rust
const MAX_EPOCH_RANGE: u64 = 100; // Reasonable limit for analysis

#[derive(Parser)]
pub struct AnalyzeValidatorPerformance {
    #[clap(long, default_value_t = -2)]
    pub start_epoch: i64,
    
    #[clap(long)]
    pub end_epoch: Option<i64>,
    // ... other fields
}

impl AnalyzeValidatorPerformance {
    fn validate_epoch_range(&self, actual_start: u64, actual_end: u64) -> CliTypedResult<()> {
        let range = actual_end.saturating_sub(actual_start);
        if range > MAX_EPOCH_RANGE {
            return Err(CliError::CommandArgumentError(
                format!(
                    "Epoch range too large: {}. Maximum allowed: {}. Consider analyzing in smaller batches.",
                    range, MAX_EPOCH_RANGE
                )
            ));
        }
        Ok(())
    }
}
```

2. **Add memory-efficient streaming**: Process epochs one at a time rather than loading all into memory.

3. **Add progress indicators and warnings**: Warn users when requesting large ranges.

4. **Implement pagination**: Allow users to process results in chunks with continuation tokens.

## Proof of Concept

Execute the following command on a network with 1000+ epochs:

```bash
# This will cause memory exhaustion and make 10,000+ API calls
aptos node analyze-validator-performance \
  --start-epoch 0 \
  --url https://api.mainnet.aptoslabs.com/v1 \
  --analyze-mode All

# Monitor memory consumption:
# - Memory usage will grow linearly with epochs processed
# - API will receive 100+ requests/minute until rate limited
# - Process will eventually crash or hang for extended periods
```

Expected behavior:
- Client memory consumption: 100MB - 10GB+ depending on epochs analyzed
- API requests: 10,000+ over 100+ minutes
- High CPU usage processing millions of block events
- Potential client crash due to OOM (Out of Memory)

**Notes**

The vulnerability exists in production CLI code and affects any user running validator performance analysis. While the REST API has server-side rate limiting (100 requests/minute), this only slows down the attack rather than preventing it. The fundamental issue is the lack of client-side bounds checking and memory-efficient processing patterns. If the API server runs on validator infrastructure, excessive API load could indirectly impact consensus performance, escalating this from Medium to High severity in production deployments.

### Citations

**File:** crates/aptos/src/node/mod.rs (L1151-1180)
```rust
/// Analyze the performance of one or more validators
#[derive(Parser)]
pub struct AnalyzeValidatorPerformance {
    /// First epoch to analyze
    ///
    /// Defaults to the first epoch
    #[clap(long, default_value_t = -2)]
    pub start_epoch: i64,

    /// Last epoch to analyze
    ///
    /// Defaults to the latest epoch
    #[clap(long)]
    pub end_epoch: Option<i64>,

    /// Analyze mode for the validator: [All, DetailedEpochTable, ValidatorHealthOverTime, NetworkHealthOverTime]
    #[clap(value_enum, ignore_case = true, long)]
    pub(crate) analyze_mode: AnalyzeMode,

    /// Filter of stake pool addresses to analyze
    ///
    /// Defaults to all stake pool addresses
    #[clap(long, num_args = 0.., value_parser = crate::common::types::load_account_arg)]
    pub pool_addresses: Vec<AccountAddress>,

    #[clap(flatten)]
    pub(crate) rest_options: RestOptions,
    #[clap(flatten)]
    pub(crate) profile_options: ProfileOptions,
}
```

**File:** crates/aptos/src/node/mod.rs (L1212-1268)
```rust
        let mut stats = HashMap::new();

        let print_detailed = self.analyze_mode == AnalyzeMode::DetailedEpochTable
            || self.analyze_mode == AnalyzeMode::All;
        let print_max_tps =
            self.analyze_mode == AnalyzeMode::MaxTps || self.analyze_mode == AnalyzeMode::All;
        for epoch_info in &epochs {
            let mut epoch_stats =
                AnalyzeValidators::analyze(&epoch_info.blocks, &epoch_info.validators);
            if !self.pool_addresses.is_empty() {
                let mut filtered_stats: HashMap<AccountAddress, ValidatorStats> = HashMap::new();
                for pool_address in &self.pool_addresses {
                    filtered_stats.insert(
                        *pool_address,
                        *epoch_stats.validator_stats.get(pool_address).unwrap(),
                    );
                }
                epoch_stats.validator_stats = filtered_stats;
            }
            if print_detailed {
                println!(
                    "Detailed table for {}epoch {}:",
                    if epoch_info.partial { "partial " } else { "" },
                    epoch_info.epoch
                );
                AnalyzeValidators::print_detailed_epoch_table(
                    &epoch_stats,
                    Some((
                        "voting_power",
                        &epoch_info
                            .validators
                            .iter()
                            .map(|v| (v.address, v.voting_power.to_string()))
                            .collect::<HashMap<_, _>>(),
                    )),
                    true,
                );
            }
            if print_max_tps {
                for (num_blocks_for_max_tps, max_tps) in &epoch_stats.max_tps_per_block_interval {
                    println!(
                        "In {}epoch {}: during consecutive {:?}, found peak of {} TPS, ending on version: {}, {} txns over {}s and {} blocks",
                        if epoch_info.partial { "partial " } else { "" },
                        epoch_info.epoch,
                        num_blocks_for_max_tps,
                        max_tps.tps,
                        max_tps.end_version,
                        max_tps.txns,
                        max_tps.duration,
                        max_tps.blocks,
                    );
                }
            }
            if !epoch_info.partial {
                stats.insert(epoch_info.epoch, epoch_stats);
            }
        }
```

**File:** crates/aptos/src/node/analyze/fetch_metadata.rs (L12-12)
```rust
const MAX_FETCH_BATCH_SIZE: u16 = 1000;
```

**File:** crates/aptos/src/node/analyze/fetch_metadata.rs (L21-26)
```rust
pub struct EpochInfo {
    pub epoch: u64,
    pub blocks: Vec<VersionedNewBlockEvent>,
    pub validators: Vec<ValidatorInfo>,
    pub partial: bool,
}
```

**File:** crates/aptos/src/node/analyze/fetch_metadata.rs (L171-180)
```rust
        let wanted_end_epoch = {
            let mut wanted_end_epoch = end_epoch.unwrap_or(i64::MAX);
            if wanted_end_epoch < 0 {
                wanted_end_epoch = last_event.event.epoch() as i64 + wanted_end_epoch + 1;
            }
            std::cmp::min(
                last_event.event.epoch() + 1,
                std::cmp::max(2, wanted_end_epoch) as u64,
            )
        };
```

**File:** crates/aptos/src/node/analyze/fetch_metadata.rs (L215-245)
```rust
        let mut result: Vec<EpochInfo> = vec![];
        if wanted_start_epoch >= wanted_end_epoch {
            return Ok(result);
        }

        let mut validators: Vec<ValidatorInfo> = vec![];
        let mut current: Vec<VersionedNewBlockEvent> = vec![];
        let mut epoch = 0;

        let mut cursor = start_seq_num;
        loop {
            let response = client
                .get_new_block_events_bcs(Some(cursor), Some(MAX_FETCH_BATCH_SIZE))
                .await;

            if response.is_err() {
                println!(
                    "Failed to read new_block_events beyond {}, stopping. {:?}",
                    cursor,
                    response.unwrap_err()
                );
                assert!(!validators.is_empty());
                result.push(EpochInfo {
                    epoch,
                    blocks: current,
                    validators: validators.clone(),
                    partial: true,
                });
                return Ok(result);
            }
            let events = response.unwrap().into_inner();
```

**File:** crates/aptos/src/node/analyze/fetch_metadata.rs (L266-271)
```rust
                            let transactions = FetchMetadata::get_transactions_in_range(
                                client,
                                last.version,
                                event.version,
                            )
                            .await?;
```

**File:** api/doc/README.md (L26-29)
```markdown
## Limitations
- Rate limiting: 100 requests per minute by default
- Maximum request size: 2MB
- Connection timeout: 30 seconds
```
