# Audit Report

## Title
Race Condition in PartialStateComputeResult OnceCell Initialization Causes Validator Node Panic on Duplicate Block Insertion

## Summary
Multiple validator threads can concurrently execute ledger update for the same block due to inadequate synchronization in the consensus pipeline's duplicate block handling, causing a panic when racing to initialize OnceCell fields in `PartialStateComputeResult`. This results in validator node crashes and network availability degradation.

## Finding Description

The vulnerability exists in a race condition chain spanning the consensus and execution layers:

**1. Duplicate Block Insertion is Expected Behavior**

The consensus layer explicitly allows duplicate block inserts as documented: [1](#0-0) 

When a validator receives certificates for blocks currently being processed, duplicate inserts occur naturally through normal protocol operation.

**2. Pipeline Construction Precedes Duplicate Detection**

In the block insertion flow, the pipeline is built BEFORE checking for duplicates: [2](#0-1) 

The duplicate check only happens later when inserting into the block tree: [3](#0-2) 

**3. Pipeline Futures Overwrite Without Protection**

The `set_pipeline_futs` method has no synchronization to prevent overwrites: [4](#0-3) 

When a duplicate block is inserted, the second pipeline's futures overwrite the first pipeline's futures, meaning TWO separate `ledger_update_fut` tasks are spawned and executing concurrently for the same block.

**4. Ledger Update Allows Concurrent Access**

The `BlockExecutor::ledger_update` method only takes a read lock, permitting concurrent execution: [5](#0-4) 

Both concurrent threads can execute ledger_update for the same block_id simultaneously.

**5. TOCTOU Vulnerability in Completion Check**

The check for existing results is not atomic with the subsequent OnceCell initialization: [6](#0-5) 

Both threads can pass this check before either completes the initialization.

**6. OnceCell Panic on Duplicate Initialization**

The OnceCell fields panic when set twice: [7](#0-6) [8](#0-7) 

The `.expect()` calls will panic when the second thread attempts to set already-initialized cells.

**Attack Scenario:**

1. Attacker sends duplicate blocks/certificates to a validator node (normal network behavior)
2. Two threads concurrently call `insert_block_inner` for the same block_id
3. Both threads execute `build_for_consensus`, spawning separate ledger_update futures
4. Both futures call `executor.ledger_update(block_id, parent_id)` concurrently
5. Both acquire RwLock::read() and retrieve the same `Arc<Block>`
6. Both check `get_complete_result()` and see None (TOCTOU race)
7. Both compute state checkpoint and ledger update (deterministic, same values)
8. Thread A successfully calls `set_state_checkpoint_output()` and `set_ledger_update_output()`
9. Thread B panics when attempting to set already-initialized OnceCell fields
10. Validator node crashes with panic message: "StateCheckpointOutput already set"

## Impact Explanation

**High Severity** - This vulnerability causes validator node crashes, meeting the "API crashes" and "Validator node slowdowns" criteria from the Aptos bug bounty High Severity category.

**Availability Impact:**
- Validator node crashes immediately upon panic
- Node must be restarted to resume operation
- Reduces network validator capacity
- If multiple validators are affected simultaneously, could degrade network liveness

**Why Not Critical:**
- No consensus safety violation (both threads compute identical deterministic results)
- No funds at risk
- No permanent network partition (nodes can restart)
- No state corruption (values computed are correct)

**Affected Invariant:**
Violates the network availability guarantee by causing validator node crashes through a race condition in normal protocol operation.

## Likelihood Explanation

**Medium-High Likelihood:**

This vulnerability can occur during normal network operation when:
- Validators broadcast certificates for the same block
- Network delays cause duplicate block messages
- High consensus round activity increases concurrent processing

The vulnerability requires:
- **No attacker privileges** - Any network peer can send blocks/certificates
- **Normal protocol behavior** - Duplicate block delivery is explicitly expected
- **Timing overlap** - Two inserts must overlap in the critical window

The likelihood increases with:
- Network congestion or delays
- High transaction throughput
- Multiple validators proposing similar blocks
- Byzantine actors deliberately sending duplicate messages

The code comment explicitly acknowledging duplicate inserts as normal indicates this is a realistic scenario that developers anticipated but incompletely protected against.

## Recommendation

Implement proper synchronization to prevent concurrent ledger_update execution for the same block:

**Option 1: Check for Existing Block Before Building Pipeline**

In `block_store.rs`, check for duplicate blocks BEFORE calling `build_for_consensus`:

```rust
pub async fn insert_block_inner(&self, pipelined_block: PipelinedBlock) -> anyhow::Result<Arc<PipelinedBlock>> {
    // Check for duplicate FIRST
    if let Some(existing) = self.inner.read().get_block(&pipelined_block.id()) {
        return Ok(existing);
    }
    
    // ... rest of insertion logic including build_for_consensus
}
```

**Option 2: Make ledger_update Truly Idempotent with Once Per Block Guarantee**

Replace the non-atomic check with an atomic operation that guarantees single execution:

```rust
// In BlockExecutorInner::ledger_update
fn ledger_update(&self, block_id: HashValue, parent_block_id: HashValue) -> ExecutorResult<StateComputeResult> {
    let block = self.block_tree.get_block(block_id)?;
    
    // Use OnceCell's get_or_try_init for atomic check-and-set
    let state_checkpoint = block.output.state_checkpoint_output.get_or_try_init(|| {
        DoStateCheckpoint::run(/* ... */)
    })?;
    
    let ledger_update = block.output.ledger_update_output.get_or_try_init(|| {
        DoLedgerUpdate::run(/* ... */)
    })?;
    
    Ok(block.output.expect_complete_result())
}
```

**Option 3: Add Exclusive Lock for ledger_update**

Add a per-block mutex to serialize ledger_update calls:

```rust
// In BlockExecutorInner
fn ledger_update(&self, block_id: HashValue, parent_block_id: HashValue) -> ExecutorResult<StateComputeResult> {
    let block = self.block_tree.get_block(block_id)?;
    let _guard = block.ledger_update_lock.lock(); // Add per-block lock
    
    // Now safe from races
    if let Some(complete_result) = block.output.get_complete_result() {
        return Ok(complete_result);
    }
    // ... rest of logic
}
```

**Recommended Solution:** Option 1 is simplest and most efficient - preventing duplicate pipeline construction eliminates the root cause.

## Proof of Concept

```rust
#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
async fn test_concurrent_duplicate_block_insert_race() {
    use std::sync::Arc;
    use tokio::task::JoinSet;
    
    // Initialize test executor and block store
    let executor = Arc::new(create_test_block_executor());
    let block_store = Arc::new(create_test_block_store(executor.clone()));
    
    // Create a test block
    let parent_id = executor.committed_block_id();
    let block_id = HashValue::random();
    let test_block = create_test_block(block_id, parent_id);
    
    // Spawn multiple concurrent insert attempts for the SAME block
    let mut join_set = JoinSet::new();
    
    for i in 0..10 {
        let store = block_store.clone();
        let block = test_block.clone();
        
        join_set.spawn(async move {
            println!("Thread {} attempting insert", i);
            match store.insert_block_inner(block).await {
                Ok(b) => {
                    println!("Thread {} succeeded", i);
                    Ok(b)
                },
                Err(e) => {
                    println!("Thread {} error: {}", i, e);
                    Err(e)
                }
            }
        });
    }
    
    // Wait for all tasks - expect at least one panic
    let mut success_count = 0;
    let mut panic_count = 0;
    
    while let Some(result) = join_set.join_next().await {
        match result {
            Ok(Ok(_)) => success_count += 1,
            Ok(Err(_)) => {},
            Err(e) if e.is_panic() => {
                panic_count += 1;
                println!("Caught panic: {:?}", e);
            },
            Err(e) => println!("Task error: {:?}", e),
        }
    }
    
    println!("Success: {}, Panics: {}", success_count, panic_count);
    
    // Vulnerability triggers if we see panics
    assert!(panic_count > 0, "Expected panic from OnceCell race condition");
}
```

**Expected Result:** Multiple threads panic with "StateCheckpointOutput already set" or "LedgerUpdateOutput already set" when racing to initialize the OnceCell fields.

**Notes**

The vulnerability is present in the consensus pipeline's handling of duplicate block inserts, which is an explicitly documented and expected scenario in the Aptos protocol. The race condition occurs because pipeline construction happens before duplicate detection, creating multiple concurrent futures that execute ledger updates for the same block through a read-locked code path. The OnceCell panic is a symptom of inadequate synchronization rather than a logic error - both threads compute identical deterministic results, so this is purely an availability issue, not a consensus safety violation.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L445-447)
```rust
    /// Duplicate inserts will return the previously inserted block (
    /// note that it is considered a valid non-error case, for example, it can happen if a validator
    /// receives a certificate for a block that is currently being added).
```

**File:** consensus/src/block_storage/block_store.rs (L490-496)
```rust
            pipeline_builder.build_for_consensus(
                &pipelined_block,
                parent_block.pipeline_futs().ok_or_else(|| {
                    anyhow::anyhow!("Parent future doesn't exist, potentially epoch ended")
                })?,
                callback,
            );
```

**File:** consensus/src/block_storage/block_store.rs (L515-516)
```rust
        self.inner.write().insert_block(pipelined_block)
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L512-514)
```rust
    pub fn set_pipeline_futs(&self, pipeline_futures: PipelineFutures) {
        *self.pipeline_futs.lock() = Some(pipeline_futures);
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L115-129)
```rust
    fn ledger_update(
        &self,
        block_id: HashValue,
        parent_block_id: HashValue,
    ) -> ExecutorResult<StateComputeResult> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "ledger_update"]);

        self.inner
            .read()
            .as_ref()
            .ok_or_else(|| ExecutorError::InternalError {
                error: "BlockExecutor is not reset".into(),
            })?
            .ledger_update(block_id, parent_block_id)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L290-294)
```rust
        // TODO(aldenhu): remove, assuming no retries.
        if let Some(complete_result) = block.output.get_complete_result() {
            info!(block_id = block_id, "ledger_update already done.");
            return Ok(complete_result);
        }
```

**File:** execution/executor/src/types/partial_state_compute_result.rs (L76-80)
```rust
    pub fn set_state_checkpoint_output(&self, state_checkpoint_output: StateCheckpointOutput) {
        self.state_checkpoint_output
            .set(state_checkpoint_output)
            .expect("StateCheckpointOutput already set");
    }
```

**File:** execution/executor/src/types/partial_state_compute_result.rs (L88-92)
```rust
    pub fn set_ledger_update_output(&self, ledger_update_output: LedgerUpdateOutput) {
        self.ledger_update_output
            .set(ledger_update_output)
            .expect("LedgerUpdateOutput already set");
    }
```
