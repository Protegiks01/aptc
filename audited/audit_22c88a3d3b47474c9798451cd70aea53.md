# Audit Report

## Title
Missing Configuration Validation Causes Node Crash or Permanent Broadcast Failure When `shared_mempool_backoff_interval_ms` Set to `u64::MAX`

## Summary
The `MempoolConfig::sanitize()` method does not validate the `shared_mempool_backoff_interval_ms` configuration parameter. When set to `u64::MAX` (or other extremely large values), the mempool coordinator will either panic due to `Instant` arithmetic overflow or schedule broadcasts so far in the future they effectively never execute, causing permanent peer isolation.

## Finding Description

The vulnerability exists due to missing input validation in the mempool configuration sanitizer combined with unchecked arithmetic when scheduling broadcast deadlines. [1](#0-0) 

The `sanitize()` method contains only a TODO comment and performs no validation on `shared_mempool_backoff_interval_ms`, which defaults to 30,000ms but can be set to any `u64` value. [2](#0-1) 

When a peer's mempool is full, it responds with a backoff signal: [3](#0-2) 

This sets `backoff_mode = true`, which changes the broadcast scheduling interval: [4](#0-3) 

The critical issue occurs at line 117 where `Instant::now() + Duration::from_millis(interval_ms)` is computed. When `interval_ms = u64::MAX`:

1. **Panic scenario**: On most platforms, adding `Duration::from_millis(u64::MAX)` (~584 million years) to an `Instant` overflows the platform's monotonic clock representation, causing a panic that crashes the coordinator task.

2. **Far-future scenario**: If the addition succeeds, the broadcast is scheduled for the distant future and will never execute. Since backoff mode can only be disabled by executing a broadcast: [5](#0-4) 

And new broadcasts are blocked while in backoff mode: [6](#0-5) 

The peer becomes permanently isolated until disconnect/reconnect.

The coordinator task processes all scheduled broadcasts: [7](#0-6) 

A panic in this path terminates the entire mempool coordinator, preventing all transaction processing.

## Impact Explanation

**Severity: HIGH** (meets "API crashes" and "Validator node slowdowns" criteria)

**Panic scenario:**
- Complete failure of the mempool coordinator task
- Node cannot process, validate, or propagate transactions
- Validators cannot participate in consensus effectively
- Requires node restart to recover
- Affects network liveness if multiple validators are misconfigured

**Far-future scenario:**
- Permanent loss of transaction propagation to peers that send backoff signals
- Validators may miss transactions needed for block production
- Network partition if enough validators are affected
- State inconsistencies requiring manual intervention

The vulnerability is triggered by **normal network behavior** (peers sending legitimate backoff signals when their mempools are full), not by attacker actions. Any peer can trigger the failure on a misconfigured node.

## Likelihood Explanation

**Likelihood: MEDIUM**

**Preconditions:**
- Node operator sets `shared_mempool_backoff_interval_ms` to `u64::MAX` or extremely large value
- Could occur through configuration errors, testing, or automated config management

**Triggering condition:**
- Any peer's mempool becomes full (common during network congestion)
- Peer sends ACK with `backoff: true` (normal backpressure mechanism)

**Evidence of risk:**
- Tests use `u64::MAX` for other timeout values but NOT for `backoff_interval_ms` [8](#0-7) 

This suggests extreme values for this parameter are untested and potentially dangerous.

- The TODO comment explicitly acknowledges missing validation: [9](#0-8) 

## Recommendation

Implement comprehensive validation in `MempoolConfig::sanitize()`:

```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        // Validate backoff interval is reasonable (max 5 minutes)
        const MAX_BACKOFF_INTERVAL_MS: u64 = 5 * 60 * 1000;
        if self.shared_mempool_backoff_interval_ms > MAX_BACKOFF_INTERVAL_MS {
            return Err(Error::ConfigSanitization(format!(
                "shared_mempool_backoff_interval_ms ({}) exceeds maximum allowed ({})",
                self.shared_mempool_backoff_interval_ms,
                MAX_BACKOFF_INTERVAL_MS
            )));
        }
        
        // Validate other critical parameters
        if self.shared_mempool_backoff_interval_ms < self.shared_mempool_tick_interval_ms {
            return Err(Error::ConfigSanitization(
                "shared_mempool_backoff_interval_ms must be >= shared_mempool_tick_interval_ms"
            ));
        }
        
        Ok(())
    }
}
```

Additionally, use checked arithmetic when scheduling broadcasts:

```rust
let deadline = Instant::now()
    .checked_add(Duration::from_millis(interval_ms))
    .ok_or_else(|| anyhow::anyhow!("Broadcast deadline overflow"))?;

scheduled_broadcasts.push(ScheduledBroadcast::new(
    deadline,
    peer,
    schedule_backoff,
    executor,
))
```

## Proof of Concept

**Configuration file (`mempool_config.yaml`):**
```yaml
mempool:
  shared_mempool_backoff_interval_ms: 18446744073709551615  # u64::MAX
```

**Reproduction steps:**
1. Start an Aptos node with the above configuration
2. Connect to a peer and send transactions until peer's mempool fills
3. Peer sends `BroadcastTransactionsResponse { backoff: true }`
4. Node attempts to schedule next broadcast with `Instant::now() + Duration::from_millis(u64::MAX)`
5. Observe panic: "arithmetic operation overflow" or similar
6. Mempool coordinator task terminates
7. Node cannot process transactions until restart

**Expected behavior:** Configuration should be rejected at startup with validation error.

**Actual behavior:** Node crashes when peer sends backoff signal.

## Notes

This vulnerability demonstrates a defense-in-depth failure where missing configuration validation allows dangerous values that crash the node when combined with normal network behavior. While setting the configuration requires node operator access, the crash is triggered by any peer sending legitimate backoff signals, making this exploitable by untrusted network participants against misconfigured nodes.

The issue is particularly concerning for validators, where mempool failures can cause consensus participation problems and network liveness issues. The TODO comment in the code explicitly acknowledges this validation gap.

### Citations

**File:** config/src/config/mempool_config.rs (L62-63)
```rust
    /// The amount of time to backoff between retries of Mempool submission to an upstream node.
    pub shared_mempool_backoff_interval_ms: u64,
```

**File:** config/src/config/mempool_config.rs (L176-184)
```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        Ok(()) // TODO: add reasonable verifications
    }
}
```

**File:** mempool/src/shared_mempool/network.rs (L349-354)
```rust
        // Backoff mode can only be turned off by executing a broadcast that was scheduled
        // as a backoff broadcast.
        // This ensures backpressure request from remote peer is honored at least once.
        if backoff {
            sync_state.broadcast_info.backoff_mode = true;
        }
```

**File:** mempool/src/shared_mempool/network.rs (L389-394)
```rust
        // If backoff mode is on for this peer, only execute broadcasts that were scheduled as a backoff broadcast.
        // This is to ensure the backoff mode is actually honored (there is a chance a broadcast was scheduled
        // in non-backoff mode before backoff mode was turned on - ignore such scheduled broadcasts).
        if state.broadcast_info.backoff_mode && !scheduled_backoff {
            return Err(BroadcastError::PeerNotScheduled(peer));
        }
```

**File:** mempool/src/shared_mempool/network.rs (L626-628)
```rust
        // Turn off backoff mode after every broadcast.
        state.broadcast_info.backoff_mode = false;
        state.broadcast_info.retry_messages.remove(&message_id);
```

**File:** mempool/src/shared_mempool/tasks.rs (L108-121)
```rust
    let schedule_backoff = network_interface.is_backoff_mode(&peer);

    let interval_ms = if schedule_backoff {
        smp.config.shared_mempool_backoff_interval_ms
    } else {
        smp.config.shared_mempool_tick_interval_ms
    };

    scheduled_broadcasts.push(ScheduledBroadcast::new(
        Instant::now() + Duration::from_millis(interval_ms),
        peer,
        schedule_backoff,
        executor,
    ))
```

**File:** mempool/src/shared_mempool/coordinator.rs (L118-120)
```rust
            (peer, backoff) = scheduled_broadcasts.select_next_some() => {
                tasks::execute_broadcast(peer, backoff, &mut smp, &mut scheduled_broadcasts, executor.clone()).await;
            },
```

**File:** mempool/src/tests/multi_node_test.rs (L542-543)
```rust
    validator_mempool_config.ack_timeout_ms = Some(u64::MAX);
    validator_mempool_config.backoff_interval_ms = Some(50);
```
