# Audit Report

## Title
Property Key Name Null Byte Injection Causes Indexer State Inconsistency

## Summary
Property key names in token default properties lack validation for null bytes, allowing token creators to inject keys containing `\0` characters. This causes data corruption in the PostgreSQL indexer when null bytes are stripped, leading to key collisions and inconsistent off-chain state compared to on-chain data.

## Finding Description

The `DefaultPropertyMutate` event in [1](#0-0)  accepts arbitrary property keys without validation in the Rust deserialization layer.

On-chain, the Move code validates property keys only for the `TOKEN_` prefix restriction: [2](#0-1) 

This validation in `assert_non_standard_reserved_property` checks only if keys start with "TOKEN_" but does not validate against null bytes or other special characters. Since Move's `String` type only requires valid UTF-8 encoding [3](#0-2) , null bytes (`\0`) are perfectly valid UTF-8 and pass all on-chain validation.

However, when these events reach the indexer, PostgreSQL cannot store null bytes in text fields. The indexer handles this by stripping null bytes: [4](#0-3) 

This creates a critical inconsistency: two distinct on-chain property keys like `"attack"` and `"attack\0"` both become `"attack"` in the indexer's HashMap [5](#0-4) , causing a last-write-wins collision where one property value overwrites the other.

**Attack Scenario:**
1. Token creator calls `mutate_tokendata_property` with keys: `["rarity", "rarity\0", "rarity\0\0"]`
2. On-chain state correctly stores three distinct properties
3. Indexer strips null bytes, all three become `"rarity"`  
4. HashMap stores only one entry, losing two property values
5. API queries return incorrect token metadata
6. Applications relying on indexer data make incorrect decisions

## Impact Explanation

This qualifies as **Medium Severity** under "State inconsistencies requiring intervention":

- **Off-chain state corruption**: The indexer (which powers the API and explorer) shows different property data than what exists on-chain
- **Data integrity violation**: Property key collisions cause permanent loss of property values in the indexer database
- **API reliability impact**: Downstream applications querying token metadata receive incorrect information
- **Intervention required**: Manual indexer state reconstruction needed to fix corrupted historical data

This does NOT constitute Critical or High severity because:
- On-chain blockchain state remains correct and deterministic
- No consensus violation (all validators execute identically)
- No fund theft or unauthorized minting
- No validator node crashes or liveness issues

## Likelihood Explanation

**High likelihood** because:
- Any token creator can exploit this without special permissions
- No complex setup or timing requirements
- The attack is deterministic and repeatable
- Property names are user-controlled input with no sanitization
- The collision behavior is guaranteed by PostgreSQL constraints and HashMap semantics

The only barrier is that an attacker must have the technical knowledge to inject null bytes into Move string literals or construct them programmatically.

## Recommendation

Add null byte validation at multiple layers:

**1. Move Layer (Primary Fix):**
Add validation in `property_map.move`:
```move
fun assert_valid_property_key(key: &String) {
    let bytes = key.bytes();
    let len = bytes.length();
    let mut i = 0;
    while (i < len) {
        assert!(bytes[i] != 0, EINVALID_PROPERTY_KEY_NULL_BYTE);
        i = i + 1;
    };
}
```

Call this in `token.move` before property mutations: [6](#0-5) 

**2. Rust Layer (Defense in Depth):**
Add validation in `DefaultPropertyMutate::new()`:
```rust
pub fn new(
    creator: AccountAddress,
    collection: String,
    token: String,
    keys: Vec<String>,
    old_values: Vec<OptionType<PropertyValue>>,
    new_values: Vec<PropertyValue>,
) -> Result<Self> {
    // Validate keys don't contain null bytes
    for key in &keys {
        if key.contains('\0') {
            return Err(anyhow::anyhow!("Property key contains null byte"));
        }
    }
    Ok(Self { creator, collection, token, keys, old_values, new_values })
}
```

## Proof of Concept

```move
#[test(creator = @0xCAFE)]
public fun test_null_byte_key_collision(creator: signer) {
    use std::string;
    use std::vector;
    
    // Create token with property keys containing null bytes
    let keys = vector[
        string::utf8(b"rarity"),           // Normal key
        string::utf8(b"rarity\x00"),       // Key with one null byte
        string::utf8(b"rarity\x00\x00"),   // Key with two null bytes
    ];
    let values = vector[
        bcs::to_bytes(&b"common"),
        bcs::to_bytes(&b"rare"),
        bcs::to_bytes(&b"legendary"),
    ];
    let types = vector[
        string::utf8(b"String"),
        string::utf8(b"String"),
        string::utf8(b"String"),
    ];
    
    // This succeeds on-chain - all three keys are distinct
    mutate_tokendata_property(&creator, token_data_id, keys, values, types);
    
    // On-chain state has 3 properties
    // Indexer state has 1 property (after null byte stripping causes collision)
    // Result: Data inconsistency between blockchain and API
}
```

**Notes:**

The vulnerability exists but impacts only the indexer layer, not blockchain consensus. The on-chain state remains correct and deterministic across all validators. However, this breaks the data integrity guarantee that off-chain derived data should accurately reflect on-chain state, requiring manual intervention to detect and fix inconsistencies.

### Citations

**File:** types/src/account_config/events/default_property_mutate.rs (L16-24)
```rust
#[derive(Debug, Deserialize, Serialize)]
pub struct DefaultPropertyMutate {
    creator: AccountAddress,
    collection: String,
    token: String,
    keys: Vec<String>,
    old_values: Vec<OptionType<PropertyValue>>,
    new_values: Vec<PropertyValue>,
}
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L870-883)
```text
        assert_tokendata_exists(creator, token_data_id);
        let key_len = keys.length();
        let val_len = values.length();
        let typ_len = types.length();
        assert!(key_len == val_len, error::invalid_state(ETOKEN_PROPERTIES_COUNT_NOT_MATCH));
        assert!(key_len == typ_len, error::invalid_state(ETOKEN_PROPERTIES_COUNT_NOT_MATCH));

        let all_token_data = &mut Collections[token_data_id.creator].token_data;
        let token_data = all_token_data.borrow_mut(token_data_id);
        assert!(token_data.mutability_config.properties, error::permission_denied(EFIELD_NOT_MUTABLE));
        let old_values: vector<Option<PropertyValue>> = vector::empty();
        let new_values: vector<PropertyValue> = vector::empty();
        assert_non_standard_reserved_property(&keys);
        for (i in 0..keys.length()){
```

**File:** aptos-move/framework/aptos-token/sources/token.move (L1861-1870)
```text
    fun assert_non_standard_reserved_property(keys: &vector<String>) {
        keys.for_each_ref(|key| {
            let key: &String = key;
            let length = key.length();
            if (length >= 6) {
                let prefix = key.sub_string(0, 6);
                assert!(prefix != string::utf8(b"TOKEN_"), error::permission_denied(EPROPERTY_RESERVED_BY_STANDARD));
            };
        });
    }
```

**File:** aptos-move/framework/move-stdlib/sources/string.move (L16-20)
```text
    /// Creates a new string from a sequence of bytes. Aborts if the bytes do not represent valid utf8.
    public fun utf8(bytes: vector<u8>): String {
        assert!(internal_check_utf8(&bytes), EINVALID_UTF8);
        String{bytes}
    }
```

**File:** crates/indexer/src/util.rs (L67-97)
```rust
pub fn remove_null_bytes<T: serde::Serialize + for<'de> serde::Deserialize<'de>>(input: &T) -> T {
    let mut txn_json = serde_json::to_value(input).unwrap();
    recurse_remove_null_bytes_from_json(&mut txn_json);
    serde_json::from_value::<T>(txn_json).unwrap()
}

fn recurse_remove_null_bytes_from_json(sub_json: &mut Value) {
    match sub_json {
        Value::Array(array) => {
            for item in array {
                recurse_remove_null_bytes_from_json(item);
            }
        },
        Value::Object(object) => {
            for (_key, value) in object {
                recurse_remove_null_bytes_from_json(value);
            }
        },
        Value::String(str) => {
            if !str.is_empty() {
                let replacement = string_null_byte_replacement(str);
                *str = replacement;
            }
        },
        _ => {},
    }
}

fn string_null_byte_replacement(value: &mut str) -> String {
    value.replace('\u{0000}', "").replace("\\u0000", "")
}
```

**File:** crates/indexer/src/models/property_map.rs (L35-42)
```rust
            let key = entry.get("key")?.as_str()?;
            let val = entry.get("value")?.get("value")?.as_str()?;
            let typ = entry.get("value")?.get("type")?.as_str()?;
            let pv = create_property_value(typ.to_string(), val.to_string()).ok()?;
            pm.data.insert(key.to_string(), pv);
        }
        Some(Self::to_flat_json(pm))
    }
```
