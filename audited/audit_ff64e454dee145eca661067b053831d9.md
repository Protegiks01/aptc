# Audit Report

## Title
State Merkle Pruner Can Delete Live Nodes Due to Unchecked Stale Node Index Corruption

## Summary
The state merkle pruner blindly trusts `node_key` values from `StaleNodeIndex` records without validation, allowing corrupted database entries to cause deletion of live nodes that are still part of the current state tree, leading to state corruption and inability to serve queries.

## Finding Description

The state merkle shard pruner retrieves stale node indices and deletes the corresponding nodes from `JellyfishMerkleNodeSchema` without validating that the `node_key` in the index actually corresponds to a stale node. [1](#0-0) 

The pruner fetches indices where `stale_since_version <= target_version` and deletes nodes using `index.node_key`. However, there is **no validation** that:
1. The `node_key.version()` is actually older than `stale_since_version` (expected invariant: `node_key.version() < stale_since_version`)
2. The node being deleted is outside the pruning window
3. The node is not referenced by the current state tree

**Expected Invariant (from normal operation):** [2](#0-1) 

When nodes become stale, the system creates indices where the `node_key` points to an OLD version and `stale_since_version` is the NEW version that replaced it. This establishes the invariant: `node_key.version() < stale_since_version`.

**Corruption Scenario:**

If a `StaleNodeIndex` record becomes corrupted (via database corruption, filesystem issues, or bit flips), the `node_key` field could point to:
- A completely different node with a NEWER version
- A node that is still LIVE and part of current state (version within pruning window)
- Any arbitrary node key that passes decode validation [3](#0-2) 

The `NodeKey::decode()` validation only checks format validity (number of nibbles, padding), not whether the version makes sense in the pruning context.

**Attack Path:**

1. A `StaleNodeIndex` record exists: `{stale_since_version: 850,000, node_key: (version=800,000, path=/0x1)}`
2. Database corruption modifies it to: `{stale_since_version: 850,000, node_key: (version=999,000, path=/0x5)}`
3. Current blockchain state: `latest_version = 1,000,000`, `prune_window = 100,000`, so `target_version = 900,000`
4. Node at `(version=999,000, path=/0x5)` is LIVE (within prune window: 900,000 to 1,000,000)
5. Pruner processes index: `stale_since_version (850,000) <= target_version (900,000)` âœ“
6. Pruner deletes node at `(version=999,000, path=/0x5)` - **DELETES LIVE NODE**
7. Result: State tree corrupted, queries for affected keys fail, Merkle proofs become invalid [4](#0-3) 

The delete operation has no validation logic - it simply encodes the key and marks it for deletion.

## Impact Explanation

**Severity: High to Critical**

This vulnerability breaks the **State Consistency** invariant (Critical Invariant #4). When live nodes are deleted:

1. **Query Failures**: Any query accessing the deleted node's subtree will fail with "Missing node" errors, making state unreadable
2. **Invalid Merkle Proofs**: The node cannot generate valid sparse Merkle proofs for affected state keys, breaking cryptographic verification
3. **Consensus Divergence Risk**: If corruption affects only some nodes, different validators may have different queryable state, potentially causing consensus issues
4. **Manual Recovery Required**: Affected nodes must perform state sync to recover the missing nodes, requiring intervention

This maps to:
- **High Severity**: "Significant protocol violations" - state tree integrity compromised
- Potentially **Critical Severity** if it causes consensus divergence: "Consensus/Safety violations"

## Likelihood Explanation

**Likelihood: Medium**

**Trigger Conditions:**
1. Database corruption from hardware failures, filesystem issues, or cosmic rays
2. Software bugs in code that writes `StaleNodeIndex` records
3. Malicious manipulation if attacker gains filesystem access to RocksDB

**Probability Factors:**
- **Database corruption**: While RocksDB is generally reliable, corruption can occur in production systems
- **Corrupted key validity**: The corrupted `node_key` must pass `NodeKey::decode()` validation (format checks only)
- **Pointing to live node**: The corrupted key must coincidentally point to a node within the pruning window
- **No detection mechanism**: There is no integrity check or anomaly detection for this condition

While individual corruption events are rare, over thousands of validator nodes operating continuously, the probability becomes non-negligible. The complete absence of validation makes this exploitable whenever corruption occurs.

## Recommendation

**Add validation before deletion to verify the node_key represents an actually stale node:**

```rust
pub(in crate::pruner) fn prune(
    &self,
    current_progress: Version,
    target_version: Version,
    max_nodes_to_prune: usize,
) -> Result<()> {
    loop {
        let mut batch = SchemaBatch::new();
        let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
            &self.db_shard,
            current_progress,
            target_version,
            max_nodes_to_prune,
        )?;

        indices.into_iter().try_for_each(|index| {
            // VALIDATION: Check invariant before deletion
            ensure!(
                index.node_key.version() < index.stale_since_version,
                "Invalid stale node index: node version {} >= stale_since_version {}",
                index.node_key.version(),
                index.stale_since_version
            );
            
            // ADDITIONAL CHECK: Verify node is old enough
            // target_version represents current_latest_version - prune_window
            // So nodes at versions > target_version should NOT be pruned
            ensure!(
                index.node_key.version() <= target_version,
                "Cannot prune live node: node version {} > target_version {}",
                index.node_key.version(),
                target_version
            );
            
            batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
            batch.delete::<S>(&index)
        })?;

        // ... rest of function
    }
}
```

**Additional safeguards:**
1. Add database-level checksums for critical schemas like `StaleNodeIndexSchema`
2. Implement periodic integrity checks that verify stale indices match expected invariants
3. Log warnings when anomalous index patterns are detected
4. Consider adding a separate table tracking "safe to prune" version ranges

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use crate::schema::{jellyfish_merkle_node::JellyfishMerkleNodeSchema, stale_node_index::StaleNodeIndexSchema};
    use aptos_jellyfish_merkle::{StaleNodeIndex, node_type::{NodeKey, Node, LeafNode}};
    use aptos_schemadb::{SchemaBatch, DB};
    use aptos_types::state_store::state_key::StateKey;
    use aptos_crypto::HashValue;
    use std::sync::Arc;
    use tempfile::TempDir;
    
    #[test]
    fn test_corrupted_stale_index_deletes_live_node() {
        // Setup: Create a temporary database
        let tmpdir = TempDir::new().unwrap();
        let db = Arc::new(DB::open(
            tmpdir.path(),
            "test_db",
            vec!["default"],
            &Default::default()
        ).unwrap());
        
        // Simulate blockchain state
        let latest_version = 1000;
        let prune_window = 100;
        let target_version = latest_version - prune_window; // = 900
        
        // Create a LIVE node at version 950 (within prune window)
        let live_node_key = NodeKey::new(950, NibblePath::new_even(vec![0x05]));
        let live_node = Node::new_leaf(
            HashValue::random(),
            HashValue::random(),
            (StateKey::raw(vec![1, 2, 3]), 950)
        );
        
        // Write live node to database
        let mut batch = SchemaBatch::new();
        batch.put::<JellyfishMerkleNodeSchema>(&live_node_key, &live_node).unwrap();
        db.write_schemas(batch).unwrap();
        
        // Verify live node exists
        assert!(db.get::<JellyfishMerkleNodeSchema>(&live_node_key).unwrap().is_some());
        
        // CORRUPTION: Create stale index with WRONG node_key pointing to live node
        // This violates invariant: node_key.version (950) should be < stale_since_version (850)
        let corrupted_index = StaleNodeIndex {
            stale_since_version: 850, // Old version - should trigger pruning
            node_key: live_node_key.clone(), // Points to LIVE node at version 950!
        };
        
        // Write corrupted stale index
        let mut batch = SchemaBatch::new();
        batch.put::<StaleNodeIndexSchema>(&corrupted_index, &()).unwrap();
        db.write_schemas(batch).unwrap();
        
        // Now simulate pruning
        let mut prune_batch = SchemaBatch::new();
        
        // This is what the pruner does - NO VALIDATION
        // It sees stale_since_version (850) <= target_version (900), so it prunes
        if corrupted_index.stale_since_version <= target_version {
            prune_batch.delete::<JellyfishMerkleNodeSchema>(&corrupted_index.node_key).unwrap();
        }
        
        db.write_schemas(prune_batch).unwrap();
        
        // VULNERABILITY DEMONSTRATED: Live node was deleted!
        assert!(db.get::<JellyfishMerkleNodeSchema>(&live_node_key).unwrap().is_none());
        
        // This breaks state consistency - queries for this node will now fail
        // State root becomes unverifiable
        // Merkle proofs cannot be generated for affected keys
    }
}
```

## Notes

This vulnerability is particularly insidious because:

1. **Silent Corruption**: The system continues operating until affected state keys are queried
2. **No Recovery Path**: Once deleted, nodes must be recovered via state sync from other validators
3. **Cascading Failures**: If multiple validators experience corruption, state divergence may occur
4. **Detection Difficulty**: Without integrity checks, corrupted indices are indistinguishable from valid ones until pruning executes

The root cause is the implicit trust in database contents without validation of critical invariants. The fix requires adding defensive checks that verify the relationship between `node_key.version()` and `stale_since_version` matches expected semantics before performing irreversible delete operations.

### Citations

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L66-76)
```rust
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;
```

**File:** storage/jellyfish-merkle/src/lib.rs (L451-453)
```rust
        if let Some(persisted_version) = persisted_version {
            tree_update_batch.put_stale_node(NodeKey::new_empty_path(persisted_version), version);
        }
```

**File:** storage/jellyfish-merkle/src/node_type/mod.rs (L112-141)
```rust
    pub fn decode(val: &[u8]) -> Result<NodeKey> {
        let mut reader = Cursor::new(val);
        let version = reader.read_u64::<BigEndian>()?;
        let num_nibbles = reader.read_u8()? as usize;
        ensure!(
            num_nibbles <= ROOT_NIBBLE_HEIGHT,
            "Invalid number of nibbles: {}",
            num_nibbles,
        );
        let mut nibble_bytes = Vec::with_capacity(num_nibbles.div_ceil(2));
        reader.read_to_end(&mut nibble_bytes)?;
        ensure!(
            num_nibbles.div_ceil(2) == nibble_bytes.len(),
            "encoded num_nibbles {} mismatches nibble path bytes {:?}",
            num_nibbles,
            nibble_bytes
        );
        let nibble_path = if num_nibbles % 2 == 0 {
            NibblePath::new_even(nibble_bytes)
        } else {
            let padding = nibble_bytes.last().unwrap() & 0x0F;
            ensure!(
                padding == 0,
                "Padding nibble expected to be 0, got: {}",
                padding,
            );
            NibblePath::new_odd(nibble_bytes)
        };
        Ok(NodeKey::new(version, nibble_path))
    }
```

**File:** storage/schemadb/src/batch.rs (L111-116)
```rust
    fn delete<S: Schema>(&mut self, key: &S::Key) -> DbResult<()> {
        let key = <S::Key as KeyCodec<S>>::encode_key(key)?;

        self.stats().delete(S::COLUMN_FAMILY_NAME);
        self.raw_delete(S::COLUMN_FAMILY_NAME, key)
    }
```
