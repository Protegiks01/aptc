# Audit Report

## Title
Incomplete Stream Handling Vulnerability: Memory Accumulation and Log Spam from Failed Fragment Transmission

## Summary
The network streaming protocol lacks timeout mechanisms for incomplete streams, allowing attackers to cause memory accumulation and log spam by sending stream headers with partial fragments. When `stream_tx.send()` fails during `OutboundStream::stream_message()`, receivers retain incomplete streams indefinitely until replaced, creating resource management and observability issues.

## Finding Description

The streaming protocol in `network/framework/src/protocols/stream/mod.rs` handles large messages (>4 MiB) by fragmenting them into chunks. When transmission fails mid-stream, the receiver's `InboundStreamBuffer` retains an incomplete stream with no cleanup mechanism. [1](#0-0) [2](#0-1) 

If these `send()` operations fail (network errors, channel backpressure), the sender stops but the receiver has already stored the header and partial fragments: [3](#0-2) 

The `InboundStreamBuffer` has no timeout mechanism. When a new stream arrives, it replaces the incomplete stream but returns an error: [4](#0-3) 

This error is logged but doesn't close the connection: [5](#0-4) 

**Attack Scenario:**
1. Attacker establishes connection to validator
2. Attacker sends stream header with `num_fragments=255` (maximum)
3. Attacker sends 1-2 fragments
4. Attacker stops (simulating network error or deliberate attack)
5. Victim's `inbound_stream` buffer holds incomplete stream indefinitely
6. When next large message arrives, error "Discarding existing stream for request ID: X" is logged
7. New stream works but error is logged
8. Attacker repeats on multiple connections or repeatedly on same connection

**Impact:**
- **Log Flooding**: Continuous incomplete streams generate error logs on every new large message
- **Memory Accumulation**: Partial fragments (up to 4 MiB per incomplete stream) held until replaced
- **Resource Waste**: Each connection can hold one incomplete stream consuming memory
- **Observability Degradation**: Legitimate errors obscured by spam

State sync messages can be up to 40 MiB, making them likely to use streaming: [6](#0-5) 

## Impact Explanation

This vulnerability qualifies as **Medium Severity** based on Aptos bug bounty criteria:
- Does not directly cause validator slowdowns (new streams self-heal by replacing incomplete ones)
- Does not crash APIs or cause consensus failures
- Creates resource management issues requiring intervention (log analysis, memory monitoring)
- Degrades observability and could mask legitimate issues

The impact is limited because:
1. Each connection holds at most one incomplete stream
2. New streams automatically replace incomplete ones
3. Small messages (<4 MiB) unaffected
4. Issue is per-connection, not network-wide

However, at scale across many connections/validators, cumulative memory waste and log spam could require operational intervention.

## Likelihood Explanation

**High Likelihood** due to:
- State sync regularly uses messages >4 MiB (up to 40 MiB)
- Network interruptions naturally occur during transmission
- Deliberate exploitation requires only basic network access
- No privileged access needed - any peer can send streams
- Attack is trivial to execute repeatedly

**Mitigation factors:**
- Self-healing when new streams arrive
- Limited to one incomplete stream per connection
- No persistent state corruption

## Recommendation

Implement timeout-based cleanup for incomplete streams:

```rust
pub struct InboundStreamBuffer {
    stream: Option<InboundStream>,
    max_fragments: usize,
    stream_timeout: Duration,
    stream_start_time: Option<Instant>,
}

impl InboundStreamBuffer {
    pub fn new(max_fragments: usize, stream_timeout: Duration) -> Self {
        Self {
            stream: None,
            max_fragments,
            stream_timeout,
            stream_start_time: None,
        }
    }
    
    pub fn check_timeout(&mut self, now: Instant) -> bool {
        if let Some(start_time) = self.stream_start_time {
            if now.duration_since(start_time) > self.stream_timeout {
                // Timeout expired, clear incomplete stream
                self.stream = None;
                self.stream_start_time = None;
                return true;
            }
        }
        false
    }
    
    pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
        let inbound_stream = InboundStream::new(header, self.max_fragments)?;
        self.stream_start_time = Some(Instant::now());
        if let Some(old) = self.stream.replace(inbound_stream) {
            // Log at debug level instead of error to reduce spam
            debug!("Replacing incomplete stream for request ID: {}", old.request_id);
        }
        Ok(())
    }
}
```

Additionally, in `Peer::start()` event loop, periodically check for timeouts and clear stale streams.

## Proof of Concept

```rust
#[tokio::test]
async fn test_incomplete_stream_memory_accumulation() {
    use aptos_channels;
    use crate::protocols::stream::{InboundStreamBuffer, OutboundStream, StreamHeader};
    use crate::protocols::wire::messaging::v1::{NetworkMessage, DirectSendMsg, MultiplexMessage};
    
    // Setup
    let max_frame_size = 4 * 1024 * 1024; // 4 MiB
    let max_message_size = 64 * 1024 * 1024; // 64 MiB
    let (stream_tx, mut stream_rx) = aptos_channels::new(1024, &counters::PENDING_MULTIPLEX_STREAM);
    
    let mut outbound_stream = OutboundStream::new(max_frame_size, max_message_size, stream_tx);
    let mut inbound_buffer = InboundStreamBuffer::new(255);
    
    // Create large message requiring streaming
    let large_msg = NetworkMessage::DirectSendMsg(DirectSendMsg {
        protocol_id: ProtocolId::ConsensusRpcBcs,
        priority: 0,
        raw_msg: vec![0u8; 10 * 1024 * 1024], // 10 MiB
    });
    
    // Simulate incomplete stream: send header but not all fragments
    let result = outbound_stream.stream_message(large_msg.clone()).await;
    assert!(result.is_ok());
    
    // Receiver gets header
    if let Some(MultiplexMessage::Stream(StreamMessage::Header(header))) = stream_rx.next().await {
        inbound_buffer.new_stream(header).unwrap();
    }
    
    // Receiver gets only first fragment (simulating send failure)
    if let Some(MultiplexMessage::Stream(StreamMessage::Fragment(fragment))) = stream_rx.next().await {
        let result = inbound_buffer.append_fragment(fragment);
        assert!(result.is_ok());
        assert!(result.unwrap().is_none()); // Stream not complete
    }
    
    // Drop remaining fragments (simulating network failure)
    drop(stream_rx);
    
    // Now incomplete stream is stuck in inbound_buffer
    // Memory for partial fragments is held indefinitely
    // Next stream will replace it but generate error log
    
    // Verify incomplete stream exists
    assert!(inbound_buffer.stream.is_some());
    // Incomplete stream holds memory until replaced or connection closes
}
```

**Notes:**

The vulnerability exists but has limited impact due to self-healing properties when new streams arrive. The primary concerns are resource management (memory, logs) rather than critical protocol failures. The severity assessment is Medium given that operational intervention may be needed to manage log spam and memory usage at scale, but the issue doesn't directly impact consensus safety or cause validator crashes.

### Citations

**File:** network/framework/src/protocols/stream/mod.rs (L82-92)
```rust
    pub fn new_stream(&mut self, header: StreamHeader) -> anyhow::Result<()> {
        let inbound_stream = InboundStream::new(header, self.max_fragments)?;
        if let Some(old) = self.stream.replace(inbound_stream) {
            bail!(
                "Discarding existing stream for request ID: {}",
                old.request_id
            )
        } else {
            Ok(())
        }
    }
```

**File:** network/framework/src/protocols/stream/mod.rs (L318-320)
```rust
        self.stream_tx
            .send(MultiplexMessage::Stream(header))
            .await?;
```

**File:** network/framework/src/protocols/stream/mod.rs (L335-337)
```rust
            self.stream_tx
                .send(MultiplexMessage::Stream(message))
                .await?;
```

**File:** network/framework/src/peer/mod.rs (L252-265)
```rust
                maybe_message = reader.next() => {
                    match maybe_message {
                        Some(message) =>  {
                            if let Err(err) = self.handle_inbound_message(message, &mut write_reqs_tx) {
                                warn!(
                                    NetworkSchema::new(&self.network_context)
                                        .connection_metadata(&self.connection_metadata),
                                    error = %err,
                                    "{} Error in handling inbound message from peer: {}, error: {}",
                                    self.network_context,
                                    remote_peer_id.short_str(),
                                    err
                                );
                            }
```

**File:** config/src/config/state_sync_config.rs (L19-21)
```rust
// The maximum message size per state sync message (for v2 data requests)
const CLIENT_MAX_MESSAGE_SIZE_V2: usize = 20 * 1024 * 1024; // 20 MiB (used for v2 data requests)
const SERVER_MAX_MESSAGE_SIZE_V2: usize = 40 * 1024 * 1024; // 40 MiB (used for v2 data requests)
```
