# Audit Report

## Title
Event V2 Translation Cache Not Cleared on Error, Causing Permanent Indexer State Corruption

## Summary
When `db_indexer.process()` returns an error during batch processing, the `?` operator in `run()` propagates the error without cleaning up the in-memory event sequence number cache. This leaves stale cached data that causes subsequent batches to assign incorrect sequence numbers, creating permanent gaps in the event index that the system explicitly treats as database corruption.

## Finding Description

The internal indexer maintains an in-memory cache for Event V2 to V1 translation sequence numbers in `EventV2TranslationEngine`: [1](#0-0) 

During batch processing in `process_a_batch()`, when V2 events are translated, their sequence numbers are immediately cached: [2](#0-1) 

These cached values are only persisted to the database at the end of successful batch processing: [3](#0-2) 

The critical vulnerability occurs when translation fails mid-batch. The error is propagated via the `?` operator: [4](#0-3) 

When this error propagates up through `process()` and `run()`: [5](#0-4) 

**The cache is never cleared.** The `DBIndexer` instance persists across the loop in `run()`, so the cache retains all sequence numbers from the failed batch. When the next batch processes the same event keys, `get_next_sequence_number()` reads from the stale cache: [6](#0-5) 

This causes the indexer to assign sequence numbers that skip over the values from the failed batch, creating gaps. The system explicitly checks for sequence number continuity and treats gaps as database corruption: [7](#0-6) 

**Attack Scenario:**
1. Indexer processes batch with versions 0-99 containing V2 events for `event_key_A`
2. Event at version 10 is translated → sequence number 5 is cached
3. Event at version 20 is translated → sequence number 6 is cached
4. Translation fails at version 50 (e.g., resource not found - common for burned tokens)
5. Batch is not written due to error, database still shows last sequence number as 4
6. Cache retains: `event_key_A → 6`
7. Retry batch processes versions 0-99 again
8. Event at version 10 now gets sequence number 7 (cache value 6 + 1)
9. Event at version 20 now gets sequence number 8
10. Batch succeeds, database has sequence numbers 7, 8 but missing 5, 6
11. Any query attempting to read events starting from sequence 5 fails with "DB corruption: Sequence number not continuous"

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria as it causes "State inconsistencies requiring intervention":

1. **Data Integrity Violation**: The indexer database enters a corrupted state with non-continuous sequence numbers, violating the documented invariant
2. **Service Degradation**: Event queries for affected event keys fail permanently with database corruption errors, breaking indexer functionality for those events
3. **Operational Impact**: Requires manual intervention (database repair or full reindexing) to restore service
4. **Scope**: Affects the internal indexer used by validator nodes for event lookup APIs

This does not reach High severity as it doesn't directly impact consensus or cause validator slowdowns, but it does corrupt critical indexer state that applications depend on.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can trigger under normal operational conditions:

1. **Natural Occurrence**: Translation errors occur when resources are missing (common after token burns, object deletions)
2. **No Attacker Control Needed**: The bug triggers from any translation failure during batch processing
3. **Persistent DBIndexer**: The same `DBIndexer` instance processes all batches in the `run()` loop, so cache persists across retries
4. **Common Pattern**: Failed batches followed by retries are standard error recovery behavior

The vulnerability has likely already manifested in production indexers processing V2 events where resources are frequently created and destroyed (token operations, NFT burns, etc.).

## Recommendation

Clear the event sequence number cache whenever a batch fails. Add cache cleanup to the error path:

**Option 1: Clear cache on error in `process_a_batch()`**
```rust
pub fn process_a_batch(&self, start_version: Version, end_version: Version) -> Result<Version> {
    // ... existing code ...
    let result = db_iter.try_for_each(|res| {
        // ... translation logic ...
    });
    
    // On error, clear the cache before propagating
    if result.is_err() {
        self.event_v2_translation_engine.event_sequence_number_cache.clear();
    }
    result?;
    
    // ... rest of function ...
}
```

**Option 2: Add cache clear method and use RAII guard**
Add to `EventV2TranslationEngine`:
```rust
pub fn clear_cache(&self) {
    self.event_sequence_number_cache.clear();
}
```

Then use a guard pattern in `process_a_batch()` to ensure cleanup on any error path.

**Recommended: Option 2 with explicit guard**, as it's more robust and handles all error paths including panics during development.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_types::contract_event::ContractEventV2;
    
    #[test]
    fn test_cache_not_cleared_on_error() {
        // Setup: Create DBIndexer with event v2 translation enabled
        let db_indexer = setup_test_db_indexer();
        
        // Initial state: cache is empty, DB has event_key_A at seq 4
        let event_key_a = EventKey::new(1, AccountAddress::random());
        
        // First batch attempt: process transactions with V2 events
        // This should cache seq 5, 6 but fail before writing
        let txn1 = create_txn_with_v2_event(&event_key_a); // Will get seq 5
        let txn2 = create_txn_with_v2_event(&event_key_a); // Will get seq 6
        let txn3 = create_failing_txn(); // Causes translation error
        
        // Process batch - should fail
        let result = db_indexer.process_a_batch(0, 3);
        assert!(result.is_err());
        
        // Verify cache has stale data
        assert_eq!(
            db_indexer.event_v2_translation_engine
                .get_cached_sequence_number(&event_key_a),
            Some(6)
        );
        
        // Second batch attempt: retry same transactions
        let result = db_indexer.process_a_batch(0, 2);
        assert!(result.is_ok());
        
        // BUG: Events now have seq 7, 8 instead of 5, 6
        let events = db_indexer.indexer_db.lookup_events_by_key(
            &event_key_a, 5, 10, 100
        );
        
        // This query should work but will fail with "DB corruption"
        assert!(events.is_err());
        assert!(events.unwrap_err().to_string()
            .contains("Sequence number not continuous"));
    }
}
```

## Notes

This vulnerability directly answers the security question: the `?` operator in `run()` does NOT properly clean up partial state (the event sequence number cache), leaving the indexer in an inconsistent state that breaks event queries. While transactions themselves are atomically indexed via RocksDB's batch writes, the in-memory cache represents partial state that persists across error boundaries and corrupts subsequent batches.

The issue affects any node running the internal indexer with Event V2 translation enabled (`enable_event_v2_translation = true`), which is standard for nodes serving event query APIs.

### Citations

**File:** storage/indexer/src/event_v2_translator.rs (L68-74)
```rust
pub struct EventV2TranslationEngine {
    pub main_db_reader: Arc<dyn DbReader>,
    pub internal_indexer_db: Arc<DB>,
    // Map from event type to translator
    pub translators: HashMap<TypeTag, Box<dyn EventV2Translator + Send + Sync>>,
    event_sequence_number_cache: DashMap<EventKey, u64>,
}
```

**File:** storage/indexer/src/event_v2_translator.rs (L190-200)
```rust
    pub fn get_next_sequence_number(&self, event_key: &EventKey, default: u64) -> Result<u64> {
        if let Some(seq) = self.get_cached_sequence_number(event_key) {
            Ok(seq + 1)
        } else {
            let seq = self
                .internal_indexer_db
                .get::<EventSequenceNumberSchema>(event_key)?
                .map_or(default, |seq| seq + 1);
            Ok(seq)
        }
    }
```

**File:** storage/indexer/src/db_indexer.rs (L232-239)
```rust
            if seq != cur_seq {
                let msg = if cur_seq == start_seq_num {
                    "First requested event is probably pruned."
                } else {
                    "DB corruption: Sequence number not continuous."
                };
                bail!("{} expected: {}, actual: {}", msg, cur_seq, seq);
            }
```

**File:** storage/indexer/src/db_indexer.rs (L450-457)
```rust
                            if let Some(translated_v1_event) =
                                self.translate_event_v2_to_v1(v2).map_err(|e| {
                                    anyhow::anyhow!(
                                        "Failed to translate event: {:?}. Error: {}",
                                        v2,
                                        e
                                    )
                                })?
```

**File:** storage/indexer/src/db_indexer.rs (L459-463)
```rust
                                let key = *translated_v1_event.key();
                                let sequence_number = translated_v1_event.sequence_number();
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
                                event_keys.insert(key);
```

**File:** storage/indexer/src/db_indexer.rs (L511-521)
```rust
            for event_key in event_keys {
                batch
                    .put::<EventSequenceNumberSchema>(
                        &event_key,
                        &self
                            .event_v2_translation_engine
                            .get_cached_sequence_number(&event_key)
                            .unwrap_or(0),
                    )
                    .expect("Failed to put events by key to a batch");
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L183-183)
```rust
            let next_version = self.db_indexer.process(start_version, target_version)?;
```
