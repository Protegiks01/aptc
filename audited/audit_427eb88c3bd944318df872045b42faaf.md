# Audit Report

## Title
JWK Consensus Indefinite Hang Without Detection When Quorum Cannot Be Reached

## Summary
The JWK consensus subsystem lacks timeout and detection mechanisms when > 1/3 of validators fail to participate. The `ReliableBroadcast` implementation retries indefinitely with unbounded exponential backoff, causing resource exhaustion and preventing graceful failure when Byzantine fault tolerance thresholds are exceeded.

## Finding Description

The JWK (JSON Web Key) consensus mechanism requires a 2/3+1 quorum of validator voting power to certify OIDC provider key updates. When more than 1/3 of validators refuse to participate (due to crashes, network partitions, or Byzantine behavior), the consensus process enters an unrecoverable state. [1](#0-0) 

The quorum calculation enforces super-majority requirements (2/3+1 of total voting power). [2](#0-1) 

The observation aggregation explicitly checks for super-majority via `check_voting_power(..., true)`.

The critical vulnerability lies in the `ReliableBroadcast` implementation, which retries failed RPCs indefinitely: [3](#0-2) 

The loop at line 167-205 only exits when `aggregating.add()` returns `Some(aggregated)` (line 187-188), which requires reaching quorum. If quorum is impossible (< 2/3 honest validators), the loop executes indefinitely:
- Line 191-200: Failed RPCs are retried with exponential backoff
- Line 197: `backoff_strategy.next().expect("should produce value")` - the iterator never returns None
- Line 203: `else => unreachable!()` - assumes all responses eventually succeed

The JWK consensus configures this backoff without maximum delay caps: [4](#0-3) 

Line 208 shows `ExponentialBackoff::from_millis(5)` with no `.factor()` or `.max_delay()` configuration, unlike other consensus components that properly bound retry delays.

**Attack Scenario:**
1. Network partition or crash affects > 1/3 of validators (or > 1/3 Byzantine validators refuse to participate)
2. Honest validators observe a JWK update from an OIDC provider
3. `UpdateCertifier.start_produce()` spawns a task calling `ReliableBroadcast.broadcast()`
4. The broadcast cannot reach 2/3+1 quorum
5. The task enters an infinite retry loop with exponentially growing backoff delays
6. No timeout, no error surfaced to operators
7. Resources remain allocated indefinitely
8. JWK updates for that issuer permanently stall

## Impact Explanation

**Severity: High** (potentially Critical depending on keyless authentication deployment)

This vulnerability causes:

1. **Liveness Failure**: JWK consensus for affected issuers permanently stalls when > 1/3 validators are unavailable
2. **Resource Exhaustion**: Async tasks remain alive indefinitely, consuming memory and executor threads
3. **No Detection**: Operators receive no alerts that quorum cannot be reached
4. **Authentication Degradation**: If OIDC providers rotate keys, on-chain JWKs become stale, breaking keyless authentication for affected providers
5. **No Graceful Failure**: Unlike main consensus which has explicit timeout and round-state management, JWK consensus hangs silently

While the main blockchain continues operating (not Critical severity for "Total loss of liveness"), this constitutes a **Significant protocol violation** (High severity) because:
- The subsystem fails to maintain liveness guarantees
- No detection or alerting mechanism exists
- Recovery requires manual intervention (epoch change or system restart)
- Affects user-facing authentication features

If keyless authentication is widely deployed and multiple OIDC providers are affected, this could escalate to Critical severity.

## Likelihood Explanation

**Likelihood: Medium to High**

This scenario occurs whenever:
- Network partitions isolate > 1/3 of validators (common in distributed systems)
- Software bugs cause > 1/3 validators to crash or hang
- Configuration errors prevent validators from processing JWK consensus messages
- Byzantine validators deliberately refuse participation

Given the decentralized nature of validator operations across different organizations, network conditions, and geographic regions, temporary loss of > 1/3 validator connectivity is a realistic operational scenario, especially during:
- Major network incidents
- Cloud provider outages affecting multiple validators
- Coordinated software upgrades with compatibility issues
- DDoS attacks (while out of scope for bounty, they trigger this condition)

## Recommendation

Implement bounded retries with timeout detection:

```rust
// In epoch_manager.rs, configure proper backoff bounds:
let rb = ReliableBroadcast::new(
    self.my_addr,
    epoch_state.verifier.get_ordered_account_addresses(),
    Arc::new(network_sender),
    ExponentialBackoff::from_millis(5)
        .factor(50)  // Add exponential growth factor
        .max_delay(Duration::from_secs(30)),  // Cap retry delays
    aptos_time_service::TimeService::real(),
    Duration::from_millis(1000),
    BoundedExecutor::new(8, tokio::runtime::Handle::current()),
);

// In update_certifier.rs, add overall timeout:
let task = async move {
    let timeout_duration = Duration::from_secs(300); // 5 minute timeout
    match tokio::time::timeout(timeout_duration, rb.broadcast(req, agg_state)).await {
        Ok(Ok(qc_update)) => {
            ConsensusMode::log_certify_done(epoch, &qc_update);
            // ... existing handling
        },
        Ok(Err(e)) => {
            error!("JWK consensus failed: {}", e);
            // Emit metric/alert for monitoring
        },
        Err(_) => {
            error!("JWK consensus timeout - quorum not reachable");
            // Emit metric/alert for operators
        }
    }
};
```

Additional improvements:
1. Add monitoring metrics when quorum cannot be reached
2. Implement exponential backoff with jitter and maximum attempts
3. Surface consensus health status via node APIs
4. Log warnings when validator participation drops below thresholds

## Proof of Concept

A Rust test demonstrating the hang:

```rust
#[tokio::test]
async fn test_jwk_consensus_hangs_without_quorum() {
    // Setup: 4 validators, total voting power 100
    // Validator distribution: [30, 30, 30, 10]
    // Quorum required: 67 (2/3 * 100 + 1)
    
    let validators = create_test_validators(vec![30, 30, 30, 10]);
    let epoch_state = create_epoch_state(validators);
    
    // Simulate 2 validators (60 voting power) refusing to respond
    let mock_network = MockNetworkThatDropsMessages::new(
        vec![validators[0].address, validators[1].address]
    );
    
    let rb = ReliableBroadcast::new(
        validators[2].address,
        epoch_state.verifier.get_ordered_account_addresses(),
        Arc::new(mock_network),
        ExponentialBackoff::from_millis(5), // No max_delay!
        TimeService::mock(),
        Duration::from_millis(100),
        BoundedExecutor::new(4, Handle::current()),
    );
    
    let agg_state = Arc::new(ObservationAggregationState::new(
        epoch_state,
        test_provider_jwks()
    ));
    
    // This will hang indefinitely since 40 < 67 quorum
    // Timeout added for test to complete
    let result = tokio::time::timeout(
        Duration::from_secs(10),
        rb.broadcast(test_request(), agg_state)
    ).await;
    
    assert!(result.is_err(), "Expected timeout, but broadcast completed");
    // In production, this would hang forever without the timeout
}
```

## Notes

While BFT systems are expected to lose liveness with > 1/3 Byzantine validators, the Aptos JWK consensus implementation exhibits worse-than-expected behavior:
1. Main consensus has explicit timeout and round progression mechanisms
2. JWK consensus lacks these safeguards, hanging silently
3. The misconfigured `ExponentialBackoff` (no max_delay) compounds the issue

This vulnerability affects only the JWK consensus subsystem and does not compromise the main blockchain consensus or safety properties. However, it represents a significant operational and availability risk for keyless authentication features.

### Citations

**File:** types/src/validator_verifier.rs (L206-214)
```rust
    pub fn new(validator_infos: Vec<ValidatorConsensusInfo>) -> Self {
        let total_voting_power = sum_voting_power(&validator_infos);
        let quorum_voting_power = if validator_infos.is_empty() {
            0
        } else {
            total_voting_power * 2 / 3 + 1
        };
        Self::build_index(validator_infos, quorum_voting_power, total_voting_power)
    }
```

**File:** crates/aptos-jwk-consensus/src/observation_aggregation/mod.rs (L94-97)
```rust
        let power_check_result = self
            .epoch_state
            .verifier
            .check_voting_power(voters.iter(), true);
```

**File:** crates/reliable-broadcast/src/lib.rs (L167-206)
```rust
            loop {
                tokio::select! {
                    Some((receiver, result)) = rpc_futures.next() => {
                        let aggregating = aggregating.clone();
                        let future = executor.spawn(async move {
                            (
                                    receiver,
                                    result
                                        .and_then(|msg| {
                                            msg.try_into().map_err(|e| anyhow::anyhow!("{:?}", e))
                                        })
                                        .and_then(|ack| aggregating.add(receiver, ack)),
                            )
                        }).await;
                        aggregate_futures.push(future);
                    },
                    Some(result) = aggregate_futures.next() => {
                        let (receiver, result) = result.expect("spawned task must succeed");
                        match result {
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
                                }
                            },
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
                        }
                    },
                    else => unreachable!("Should aggregate with all responses")
                }
            }
        }
```

**File:** crates/aptos-jwk-consensus/src/epoch_manager.rs (L204-212)
```rust
            let rb = ReliableBroadcast::new(
                self.my_addr,
                epoch_state.verifier.get_ordered_account_addresses(),
                Arc::new(network_sender),
                ExponentialBackoff::from_millis(5),
                aptos_time_service::TimeService::real(),
                Duration::from_millis(1000),
                BoundedExecutor::new(8, tokio::runtime::Handle::current()),
            );
```
