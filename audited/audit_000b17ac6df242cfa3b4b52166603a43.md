# Audit Report

## Title
CPU Exhaustion via Unprotected Inspection Service System Information Endpoint

## Summary
The inspection service's `/system_information` endpoint performs expensive system refresh operations (`refresh_system()` and `refresh_disks()`) without any rate limiting or authentication, allowing attackers with network access to cause CPU exhaustion on validator nodes and degrade consensus performance.

## Finding Description

The vulnerability exists in the inspection service's system information endpoint. When a request is made to `/system_information`, the following execution path occurs: [1](#0-0) 

The handler calls `get_system_information_json()` which invokes expensive system information collection: [2](#0-1) 

This calls into the telemetry system where expensive operations occur: [3](#0-2) 

The code explicitly acknowledges these operations are expensive with the comment at line 59: "Note: this might be expensive, so it shouldn't be done often". The operations `refresh_system()` and `refresh_disks()` from the sysinfo crate perform extensive system calls to query CPU, memory, and disk information.

**Security Guarantee Violations:**

1. **Resource Limits Invariant Broken**: The endpoint violates invariant #9 ("All operations must respect gas, storage, and computational limits") by allowing unbounded expensive operations without rate limiting.

2. **No Authentication**: The inspection service has no authentication mechanism: [4](#0-3) 

3. **Endpoint Exposed by Default**: The system information endpoint is exposed by default: [5](#0-4) 

4. **Network Accessible**: The service binds to all interfaces (0.0.0.0) by default and runs on all nodes including validators: [6](#0-5) 

5. **Exposed Through HAproxy**: In Kubernetes deployments, the metrics port (9101) can be exposed externally: [7](#0-6) 

**Attack Propagation:**

An attacker with access to the inspection service endpoint (either externally if metrics port is enabled, or internally from within the cluster) can send rapid concurrent requests to `/system_information`. Each request:

1. Acquires the `GLOBAL_SYSTEM` mutex lock
2. Executes expensive `refresh_system()` - queries all CPU, memory, and process information via system calls
3. Executes expensive `refresh_disks()` - queries all disk information via system calls
4. Processes and serializes the collected data

With sufficient concurrent requests, this causes:
- CPU exhaustion from repeated expensive system calls
- Mutex contention delaying legitimate metric collection
- Resource starvation affecting consensus operations on validator nodes

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: Repeated expensive system calls consume CPU resources needed for consensus operations, potentially causing validators to miss consensus rounds or process blocks slowly.

- **Affects consensus performance**: Validator nodes running consensus algorithms are CPU-intensive. Additional CPU load from handling malicious requests to this endpoint can degrade consensus participation, leading to slower block production and reduced network throughput.

The impact is amplified because:
1. The operations are synchronous and block while holding a mutex
2. Comparison with other metrics collectors shows targeted refresh operations (e.g., `refresh_cpu()`) are preferred over full system refreshes: [8](#0-7) 

3. The endpoint is accessible from monitoring systems within Kubernetes clusters at minimum, and potentially externally if configured

## Likelihood Explanation

**Likelihood: Medium to High**

The attack is highly feasible because:

1. **No Complexity**: Simple HTTP GET requests, no authentication required
2. **Default Configuration Vulnerable**: The endpoint is enabled by default (`expose_system_information: true`)
3. **Network Accessible**: In Kubernetes deployments, accessible from monitoring pods and health checkers. Can be externally exposed via HAproxy configuration
4. **Developer Acknowledgment**: The code comment explicitly warns the operations are expensive and "shouldn't be done often"
5. **No Protection**: Zero rate limiting, throttling, or access control

The only barrier is network accessibility, which varies by deployment:
- **Internal cluster access**: Always available (monitoring, health checkers can access)
- **External access**: Depends on HAproxy `enableMetricsPort` configuration

Given that validator operators typically enable monitoring, the endpoint is practically accessible in production environments.

## Recommendation

Implement multiple layers of defense:

**1. Add Rate Limiting**
```rust
// In crates/aptos-inspection-service/src/server/mod.rs
use aptos_rate_limiter::{RateLimiter, RateLimitConfig};

// Add rate limiter to service state
struct InspectionServiceState {
    system_info_limiter: RateLimiter,
    // ... other fields
}

// In serve_requests, before calling handle_system_information_request:
if !state.system_info_limiter.try_acquire() {
    return Ok(Response::builder()
        .status(StatusCode::TOO_MANY_REQUESTS)
        .body(Body::from("Rate limit exceeded"))
        .unwrap());
}
```

**2. Add Caching**
```rust
// In crates/aptos-telemetry/src/system_information.rs
use std::time::{Duration, Instant};

static CACHED_INFO: Lazy<Mutex<(BTreeMap<String, String>, Instant)>> = 
    Lazy::new(|| Mutex::new((BTreeMap::new(), Instant::now())));

const CACHE_TTL: Duration = Duration::from_secs(60);

pub fn get_system_information() -> BTreeMap<String, String> {
    let mut cached = CACHED_INFO.lock();
    if cached.1.elapsed() < CACHE_TTL {
        return cached.0.clone();
    }
    
    let mut system_information = BTreeMap::new();
    collect_system_info(&mut system_information);
    cached.0 = system_information.clone();
    cached.1 = Instant::now();
    system_information
}
```

**3. Disable by Default for Mainnet Validators**
```rust
// In config/src/config/inspection_service_config.rs
impl ConfigOptimizer for InspectionServiceConfig {
    fn optimize(...) -> Result<bool, Error> {
        // Disable system_information for mainnet validators
        if let Some(chain_id) = chain_id {
            if node_type.is_validator() && chain_id.is_mainnet() {
                if local_inspection_config_yaml["expose_system_information"].is_null() {
                    inspection_service_config.expose_system_information = false;
                    modified_config = true;
                }
            }
        }
        // ... rest of optimization
    }
}
```

**4. Use Targeted Refreshes**
Instead of full `refresh_system()` and `refresh_disks()`, use targeted refresh operations like other collectors.

## Proof of Concept

```bash
#!/bin/bash
# PoC: CPU Exhaustion Attack on Inspection Service

INSPECTION_SERVICE_URL="http://validator-node:9101/system_information"
CONCURRENT_REQUESTS=100
DURATION_SECONDS=60

echo "Starting CPU exhaustion attack..."
echo "Target: $INSPECTION_SERVICE_URL"
echo "Concurrent requests: $CONCURRENT_REQUESTS"
echo "Duration: ${DURATION_SECONDS}s"

end_time=$((SECONDS + DURATION_SECONDS))

while [ $SECONDS -lt $end_time ]; do
    for i in $(seq 1 $CONCURRENT_REQUESTS); do
        curl -s "$INSPECTION_SERVICE_URL" > /dev/null &
    done
    # Brief pause to avoid overwhelming the shell
    sleep 0.1
    # Wait for background processes to complete
    wait
done

echo "Attack completed. Monitor validator node CPU usage and consensus performance."
```

**Expected Results:**
- CPU usage on validator node increases significantly
- Consensus round latency increases
- Potential missed consensus proposals or votes
- System becomes unresponsive to legitimate monitoring requests

**Validation Steps:**
1. Deploy Aptos validator node with inspection service enabled (default)
2. Run the PoC script from a machine with network access to port 9101
3. Monitor CPU usage via system tools: `top`, `htop`, or Prometheus metrics
4. Observe consensus metrics for degradation: `aptos_consensus_round_timeout_total`, `aptos_consensus_proposals_sent`
5. Compare baseline performance vs. under attack

### Citations

**File:** crates/aptos-inspection-service/src/server/system_information.rs (L14-28)
```rust
pub fn handle_system_information_request(node_config: NodeConfig) -> (StatusCode, Body, String) {
    // Only return system information if the endpoint is enabled
    if node_config.inspection_service.expose_system_information {
        (
            StatusCode::OK,
            Body::from(get_system_information_json()),
            CONTENT_TYPE_JSON.into(),
        )
    } else {
        (
            StatusCode::FORBIDDEN,
            Body::from(SYS_INFO_DISABLED_MESSAGE),
            CONTENT_TYPE_TEXT.into(),
        )
    }
```

**File:** crates/aptos-inspection-service/src/server/system_information.rs (L32-42)
```rust
fn get_system_information_json() -> String {
    // Get the system and build information
    let mut system_information = aptos_telemetry::system_information::get_system_information();
    system_information.extend(build_information!());

    // Return the system information as a JSON string
    match serde_json::to_string(&system_information) {
        Ok(system_information) => system_information,
        Err(error) => format!("Failed to get system information! Error: {}", error),
    }
}
```

**File:** crates/aptos-telemetry/src/system_information.rs (L58-68)
```rust
pub(crate) fn collect_system_info(system_information: &mut BTreeMap<String, String>) {
    // Note: this might be expensive, so it shouldn't be done often
    GLOBAL_SYSTEM.lock().refresh_system();
    GLOBAL_SYSTEM.lock().refresh_disks();

    // Collect relevant and available system information
    collect_cpu_info(system_information, &GLOBAL_SYSTEM);
    collect_disk_info(system_information, &GLOBAL_SYSTEM);
    collect_memory_info(system_information, &GLOBAL_SYSTEM);
    collect_sys_info(system_information, &GLOBAL_SYSTEM);
}
```

**File:** crates/aptos-inspection-service/src/server/mod.rs (L104-169)
```rust
async fn serve_requests(
    req: Request<Body>,
    node_config: NodeConfig,
    aptos_data_client: AptosDataClient,
    peers_and_metadata: Arc<PeersAndMetadata>,
) -> Result<Response<Body>, hyper::Error> {
    // Process the request and get the response components
    let (status_code, body, content_type) = match req.uri().path() {
        CONFIGURATION_PATH => {
            // /configuration
            // Exposes the node configuration
            configuration::handle_configuration_request(&node_config)
        },
        CONSENSUS_HEALTH_CHECK_PATH => {
            // /consensus_health_check
            // Exposes the consensus health check
            metrics::handle_consensus_health_check(&node_config).await
        },
        FORGE_METRICS_PATH => {
            // /forge_metrics
            // Exposes forge encoded metrics
            metrics::handle_forge_metrics()
        },
        IDENTITY_INFORMATION_PATH => {
            // /identity_information
            // Exposes the identity information of the node
            identity_information::handle_identity_information_request(&node_config)
        },
        INDEX_PATH => {
            // /
            // Exposes the index and list of available endpoints
            index::handle_index_request()
        },
        JSON_METRICS_PATH => {
            // /json_metrics
            // Exposes JSON encoded metrics
            metrics::handle_json_metrics_request()
        },
        METRICS_PATH => {
            // /metrics
            // Exposes text encoded metrics
            metrics::handle_metrics_request()
        },
        PEER_INFORMATION_PATH => {
            // /peer_information
            // Exposes the peer information
            peer_information::handle_peer_information_request(
                &node_config,
                aptos_data_client,
                peers_and_metadata,
            )
        },
        SYSTEM_INFORMATION_PATH => {
            // /system_information
            // Exposes the system and build information
            system_information::handle_system_information_request(node_config)
        },
        _ => {
            // Handle the invalid path
            (
                StatusCode::NOT_FOUND,
                Body::from(INVALID_ENDPOINT_MESSAGE),
                CONTENT_TYPE_TEXT.into(),
            )
        },
    };
```

**File:** config/src/config/inspection_service_config.rs (L26-37)
```rust
impl Default for InspectionServiceConfig {
    fn default() -> InspectionServiceConfig {
        InspectionServiceConfig {
            address: "0.0.0.0".to_string(),
            port: 9101,
            expose_configuration: false,
            expose_identity_information: true,
            expose_peer_information: true,
            expose_system_information: true,
        }
    }
}
```

**File:** aptos-node/src/lib.rs (L771-776)
```rust
    // Start the node inspection service
    services::start_node_inspection_service(
        &node_config,
        aptos_data_client,
        peers_and_metadata.clone(),
    );
```

**File:** terraform/helm/aptos-node/templates/haproxy.yaml (L39-43)
```yaml
  {{- if $.Values.service.validator.enableMetricsPort }}
  - name: metrics
    port: 9101
    targetPort: 9102
  {{- end }}
```

**File:** crates/node-resource-metrics/src/collectors/cpu_metrics_collector.rs (L70-73)
```rust
        let mut system = self.system.lock();

        system.refresh_cpu();

```
