# Audit Report

## Title
Server-Side Request Forgery (SSRF) in NFT Metadata Crawler - Insufficient URI Validation Before HTTP Requests

## Summary
The NFT metadata crawler's `JSONParser::parse()` function extracts `raw_image_uri` and `raw_animation_uri` from untrusted JSON metadata without proper validation. The calling code in `Worker::parse()` performs only a simple blacklist check before using these URIs in HTTP requests, enabling Server-Side Request Forgery (SSRF) attacks against internal infrastructure.

## Finding Description

The vulnerability exists in the NFT metadata parsing workflow:

1. **Extraction without validation**: The `JSONParser::parse()` function extracts URI strings directly from JSON fields without any security validation [1](#0-0) 

2. **Insufficient validation in caller**: The `Worker::parse()` method receives these Option<String> values and only performs a blacklist check using simple substring matching [2](#0-1) 

3. **No SSRF protections**: The URIs are passed to `ImageOptimizer::optimize()` which makes HTTP requests without validating against:
   - Private IP ranges (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16)
   - Localhost addresses (127.0.0.1, ::1)
   - Cloud metadata endpoints (169.254.169.254)
   - Link-local addresses
   - Restricted URL schemes

4. **HTTP client lacks protections**: The reqwest clients are built with only timeout configuration, no redirect policy or proxy restrictions [3](#0-2) 

**Attack Path:**
1. Attacker creates NFT with metadata containing: `{"image": "http://169.254.169.254/latest/meta-data/iam/security-credentials/"}`
2. NFT metadata crawler processes the NFT
3. `JSONParser::parse()` extracts the malicious URI [4](#0-3) 
4. `Worker::parse()` applies blacklist check which fails to catch cloud metadata endpoint (unless explicitly configured)
5. `ImageOptimizer::optimize()` calls `get_uri_metadata()` making HEAD request [5](#0-4) 
6. Then makes GET request to fetch the "image" [6](#0-5) 
7. Internal credentials/metadata exposed in response

## Impact Explanation

**Important Context**: This vulnerability affects the **NFT metadata crawler**, which is an off-chain indexing service in the `ecosystem/` directory, **NOT** a core blockchain component. It does not impact:
- Blockchain consensus or validator nodes
- On-chain state or transactions  
- User funds or staking mechanisms
- Move VM execution or smart contracts

**Actual Impact**: 
While this is a legitimate SSRF vulnerability, it falls **outside the primary scope** of critical blockchain security as defined by the Aptos bug bounty focus areas (consensus, Move VM, state management, governance, staking). 

However, if the indexer infrastructure is considered in-scope, this could qualify as **High Severity** under "API crashes" if:
- The indexer service is publicly exposed
- SSRF could crash the service or compromise infrastructure
- Internal service credentials could be stolen via cloud metadata endpoints

The blacklist mechanism [7](#0-6)  is configured per deployment but provides insufficient protection against sophisticated SSRF attacks.

## Likelihood Explanation

**High likelihood** of exploitation:
- Any user can create NFTs with arbitrary metadata
- No authentication required to trigger the vulnerability
- Attack is deterministic and requires no special timing
- Cloud metadata endpoints are well-known targets (169.254.169.254)

**Low impact** to core blockchain:
- Does not affect consensus, validator operations, or on-chain security
- Limited to off-chain indexer infrastructure compromise

## Recommendation

Implement comprehensive URI validation before making HTTP requests:

```rust
use std::net::IpAddr;
use url::Url;

fn is_safe_uri(uri: &str) -> Result<(), anyhow::Error> {
    let url = Url::parse(uri)?;
    
    // Only allow http/https schemes
    if !matches!(url.scheme(), "http" | "https") {
        return Err(anyhow::anyhow!("Only HTTP/HTTPS schemes allowed"));
    }
    
    // Resolve and check IP address
    if let Some(host) = url.host_str() {
        // Block localhost
        if host == "localhost" || host == "127.0.0.1" || host == "::1" {
            return Err(anyhow::anyhow!("Localhost not allowed"));
        }
        
        // Block cloud metadata
        if host == "169.254.169.254" || host.starts_with("169.254.") {
            return Err(anyhow::anyhow!("Cloud metadata endpoint blocked"));
        }
        
        // Block private IP ranges
        if let Ok(ip) = host.parse::<IpAddr>() {
            if ip.is_loopback() || is_private_ip(&ip) {
                return Err(anyhow::anyhow!("Private IP addresses not allowed"));
            }
        }
    }
    
    Ok(())
}

fn is_private_ip(ip: &IpAddr) -> bool {
    match ip {
        IpAddr::V4(ipv4) => {
            ipv4.is_private() || ipv4.is_link_local()
        },
        IpAddr::V6(ipv6) => {
            ipv6.is_loopback() || ipv6.is_unique_local()
        }
    }
}
```

Apply validation in `Worker::parse()` before calling image optimizer:
```rust
// After line 213 in worker.rs
if let Err(e) = is_safe_uri(&img_uri) {
    self.log_warn("URI failed security validation", Some(&e));
    self.model.set_do_not_parse(true);
    self.upsert();
    return Ok(());
}
```

Additionally, configure reqwest client with redirect restrictions and DNS resolution checks.

## Proof of Concept

This test demonstrates the vulnerability (would need to be integrated into the test suite):

```rust
#[tokio::test]
async fn test_ssrf_vulnerability() {
    // Malicious NFT metadata with cloud metadata endpoint
    let malicious_json = r#"{
        "image": "http://169.254.169.254/latest/meta-data/",
        "animation_url": "http://127.0.0.1:8080/internal-api"
    }"#;
    
    // Simulate parsing - this would make actual HTTP requests
    // to internal endpoints without proper validation
    let result = JSONParser::parse(
        format!("data:application/json,{}", malicious_json),
        1024 * 1024
    ).await;
    
    // Currently succeeds and makes requests to internal endpoints
    assert!(result.is_ok());
    let (raw_image_uri, raw_animation_uri, _) = result.unwrap();
    
    // Extracted URIs point to internal resources
    assert_eq!(raw_image_uri, Some("http://169.254.169.254/latest/meta-data/".to_string()));
    assert_eq!(raw_animation_uri, Some("http://127.0.0.1:8080/internal-api".to_string()));
    
    // These would then be used in HTTP requests without validation
    // enabling SSRF attacks against internal infrastructure
}
```

## Notes

**Critical Clarification**: While this is a real SSRF vulnerability in the codebase, it affects the **NFT metadata crawler** - an off-chain indexing service - and does **not** impact:
- Aptos blockchain consensus or protocol security
- Validator node operations  
- On-chain state, transactions, or smart contract execution
- User funds or staking mechanisms

This vulnerability is **outside the primary focus** of an "Elite Aptos Blockchain Security Auditor specializing in consensus vulnerabilities, Move VM implementation bugs, state management attacks, and on-chain governance security."

The NFT metadata crawler is located in `ecosystem/nft-metadata-crawler/` and serves as auxiliary infrastructure for indexing NFT metadata, separate from core blockchain components in `consensus/`, `aptos-move/`, `storage/`, etc.

### Citations

**File:** ecosystem/nft-metadata-crawler/src/utils/json_parser.rs (L71-73)
```rust
                let raw_image_uri = parsed_json["image"].as_str().map(|s| s.to_string());
                let raw_animation_uri =
                    parsed_json["animation_url"].as_str().map(|s| s.to_string());
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L126-134)
```rust
            let (raw_image_uri, raw_animation_uri, json) =
                JSONParser::parse(json_uri, self.parser_config.max_file_size_bytes)
                    .await
                    .unwrap_or_else(|e| {
                        // Increment retry count if JSON parsing fails
                        self.log_warn("JSON parsing failed", Some(&e));
                        self.model.increment_json_parser_retry_count();
                        (None, None, Value::Null)
                    });
```

**File:** ecosystem/nft-metadata-crawler/src/parser/worker.rs (L386-391)
```rust
    fn is_blacklisted_uri(&mut self, uri: &str) -> bool {
        self.parser_config
            .uri_blacklist
            .iter()
            .any(|blacklist_uri| uri.contains(blacklist_uri))
    }
```

**File:** ecosystem/nft-metadata-crawler/src/utils/image_optimizer.rs (L56-59)
```rust
                let client = Client::builder()
                    .timeout(Duration::from_secs(MAX_IMAGE_REQUEST_RETRY_SECONDS))
                    .build()
                    .context("Failed to build reqwest client")?;
```

**File:** ecosystem/nft-metadata-crawler/src/utils/image_optimizer.rs (L61-65)
```rust
                let response = client
                    .get(uri.trim())
                    .send()
                    .await
                    .context("Failed to get image")?;
```

**File:** ecosystem/nft-metadata-crawler/src/lib.rs (L17-23)
```rust
pub async fn get_uri_metadata(url: &str) -> anyhow::Result<(String, u32)> {
    let client = Client::builder()
        .timeout(Duration::from_secs(MAX_HEAD_REQUEST_RETRY_SECONDS))
        .build()
        .context("Failed to build reqwest client")?;
    let request = client.head(url.trim());
    let response = request.send().await?;
```

**File:** ecosystem/nft-metadata-crawler/src/parser/config.rs (L28-29)
```rust
    #[serde(default)]
    pub uri_blacklist: Vec<String>,
```
