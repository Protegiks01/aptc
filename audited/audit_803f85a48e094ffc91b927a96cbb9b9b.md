# Audit Report

## Title
Unbounded Memory Consumption in Epoch Data Deletion During Database Recovery

## Summary
The `delete_per_epoch_data()` function in the ledger database truncation helper iterates through all epoch entries without bounds checking or batching, accumulating delete operations in memory. If database corruption results in millions of epoch entries, this causes out-of-memory conditions during node recovery operations.

## Finding Description

The vulnerability exists in the `delete_per_epoch_data()` function which is called during ledger database truncation operations. [1](#0-0) 

The function creates an iterator over the `EpochByVersionSchema` and iterates from `start_version` to the end without any bounds checking or batch size limits. For each epoch entry found, it adds two delete operations to a `SchemaBatch`: one for `EpochByVersionSchema` and one for `LedgerInfoSchema`. [2](#0-1) 

The `SchemaBatch` stores all write operations in memory using a `HashMap<ColumnFamilyName, Vec<WriteOp>>`, where each `WriteOp::Deletion` contains a `Vec<u8>` for the encoded key. [3](#0-2) 

This design means that all delete operations accumulate in memory before being committed to the database. With millions of epoch entries (which could exist in a corrupted database), this results in:
- 2 delete operations per epoch entry
- Each delete stores an 8-byte key (Version or epoch number encoded as u64)
- Plus Vec<u8> and WriteOp overhead (approximately 40+ bytes per operation)
- Total: ~100 bytes × 2 million operations = ~200 MB for 1 million epochs, scaling linearly

The truncation is triggered during node recovery when there's a mismatch in commit progress between different database components: [4](#0-3) 

In contrast, other truncation functions implement proper bounds or batching: [5](#0-4) 

The `delete_transaction_index_data()` function limits processing to `MAX_COMMIT_PROGRESS_DIFFERENCE * 2` entries. [6](#0-5) 

Similarly, state KV truncation implements progressive batching: [7](#0-6) 

## Impact Explanation

**Severity: Medium** per Aptos bug bounty criteria - "State inconsistencies requiring intervention"

**Impact Details:**
1. **Node Unavailability**: When a node with corrupted database attempts recovery through truncation, it will experience memory exhaustion and crash
2. **Failed Recovery**: The node operator cannot use the standard recovery mechanisms and must resort to manual database manipulation
3. **Operational Disruption**: Requires operator intervention to manually clean the corrupted database or restore from backup

However, this vulnerability has significant limitations:
- **Not directly exploitable**: External attackers cannot inject epoch entries through the consensus protocol
- **Requires pre-existing corruption**: Database corruption must already exist from hardware failure, bugs in write paths, or state synchronization issues
- **Single node impact**: Only affects the corrupted node, does not propagate to network

While the issue breaks the **Resource Limits** invariant (operations should respect memory constraints), it does not affect consensus safety, validator set integrity, or funds security.

## Likelihood Explanation

**Likelihood: Low to Medium**

Database corruption leading to millions of epoch entries could occur through:

1. **Hardware Failures**: Bit flips or disk corruption creating phantom epoch entries (mitigated by RocksDB checksums but still possible)
2. **State Sync Bugs**: Corrupted data written during state synchronization if validation is bypassed
3. **Historical Write Path Bugs**: Previous bugs may have created excessive epoch entries in production databases

However, under normal operations:
- Epochs typically occur every 2-4 hours in production
- Over years: ~12 epochs/day × 365 days × 5 years = ~22,000 epochs
- This would only consume ~2.2 MB of memory, which is acceptable

The vulnerability only manifests when corruption creates unrealistic epoch counts (hundreds of thousands to millions).

## Recommendation

Implement bounded iteration with batching similar to other truncation functions:

```rust
fn delete_per_epoch_data(
    ledger_db: &DB,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    const MAX_EPOCHS_PER_BATCH: usize = 10000;
    
    let mut iter = ledger_db.iter::<LedgerInfoSchema>()?;
    iter.seek_to_last();
    if let Some((epoch, ledger_info)) = iter.next().transpose()? {
        let version = ledger_info.commit_info().version();
        if version >= start_version {
            batch.delete::<LedgerInfoSchema>(&epoch)?;
        }
    }

    let mut iter = ledger_db.iter::<EpochByVersionSchema>()?;
    iter.seek(&start_version)?;
    
    let mut count = 0;
    for item in iter {
        let (version, epoch) = item?;
        
        if count >= MAX_EPOCHS_PER_BATCH {
            warn!(
                count = count,
                "Reached maximum epochs per batch during truncation, stopping iteration"
            );
            break;
        }
        
        info!(
            version = version,
            epoch = epoch,
            "Truncate epoch ending data."
        );
        batch.delete::<EpochByVersionSchema>(&version)?;
        batch.delete::<LedgerInfoSchema>(&epoch)?;
        count += 1;
    }

    Ok(())
}
```

Additionally, consider adding validation during epoch writes to detect anomalous epoch creation rates.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_types::ledger_info::{LedgerInfo, LedgerInfoWithSignatures};
    
    #[test]
    fn test_epoch_deletion_memory_exhaustion() {
        // Create temporary database
        let tmpdir = TempPath::new();
        let db = DB::open_cf(
            tmpdir.path(),
            "test_db",
            vec!["epoch_by_version", "ledger_info"],
        ).unwrap();
        
        let mut batch = SchemaBatch::new();
        
        // Simulate corrupted database with 1 million epoch entries
        const CORRUPT_EPOCH_COUNT: u64 = 1_000_000;
        
        for i in 0..CORRUPT_EPOCH_COUNT {
            // Write fake epoch entries
            batch.put::<EpochByVersionSchema>(&i, &i).unwrap();
            
            // Create minimal ledger info
            let ledger_info = LedgerInfo::new(
                BlockInfo::empty(),
                HashValue::zero(),
            );
            batch.put::<LedgerInfoSchema>(
                &i, 
                &LedgerInfoWithSignatures::new(ledger_info, BTreeMap::new())
            ).unwrap();
            
            // Commit in batches to avoid memory issues during setup
            if i % 10000 == 0 {
                db.write_schemas(batch).unwrap();
                batch = SchemaBatch::new();
            }
        }
        db.write_schemas(batch).unwrap();
        
        // Now attempt to delete all epochs - this should exhaust memory
        let mut delete_batch = SchemaBatch::new();
        
        // This call will accumulate 2 million delete operations in memory
        // and likely cause OOM on systems with limited RAM
        delete_per_epoch_data(&db, 0, &mut delete_batch)
            .expect("Should handle large epoch counts gracefully");
        
        // If we reach here without OOM, the batch contains millions of operations
        // Committing this batch would also stress the database
    }
}
```

## Notes

This vulnerability represents a defensive programming failure where the code does not gracefully handle corrupted database states. While not directly exploitable by external attackers, it prevents node operators from recovering corrupted nodes using standard recovery procedures. The fix is straightforward: implement the same bounded iteration pattern used in other truncation functions.

The issue is particularly concerning because it affects error recovery paths - precisely when robustness is most critical. A node experiencing corruption should fail gracefully with clear error messages, not crash with OOM during recovery attempts.

### Citations

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L81-116)
```rust
pub(crate) fn truncate_state_kv_db(
    state_kv_db: &StateKvDb,
    current_version: Version,
    target_version: Version,
    batch_size: usize,
) -> Result<()> {
    assert!(batch_size > 0);
    let status = StatusLine::new(Progress::new("Truncating State KV DB", target_version));
    status.set_current_version(current_version);

    let mut current_version = current_version;
    // current_version can be the same with target_version while there is data written to the db before
    // the progress is recorded -- we need to run the truncate for at least one batch
    loop {
        let target_version_for_this_batch = std::cmp::max(
            current_version.saturating_sub(batch_size as Version),
            target_version,
        );
        // By writing the progress first, we still maintain that it is less than or equal to the
        // actual progress per shard, even if it dies in the middle of truncation.
        state_kv_db.write_progress(target_version_for_this_batch)?;
        // the first batch can actually delete more versions than the target batch size because
        // we calculate the start version of this batch assuming the latest data is at
        // `current_version`. Otherwise, we need to seek all shards to determine the
        // actual latest version of data.
        truncate_state_kv_db_shards(state_kv_db, target_version_for_this_batch)?;
        current_version = target_version_for_this_batch;
        status.set_current_version(current_version);

        if current_version <= target_version {
            break;
        }
    }
    assert_eq!(current_version, target_version);
    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L363-372)
```rust
fn delete_transaction_index_data(
    ledger_db: &LedgerDb,
    transaction_store: &TransactionStore,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    let transactions = ledger_db
        .transaction_db()
        .get_transaction_iter(start_version, MAX_COMMIT_PROGRESS_DIFFERENCE as usize * 2)?
        .collect::<Result<Vec<_>>>()?;
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L394-428)
```rust
fn delete_per_epoch_data(
    ledger_db: &DB,
    start_version: Version,
    batch: &mut SchemaBatch,
) -> Result<()> {
    let mut iter = ledger_db.iter::<LedgerInfoSchema>()?;
    iter.seek_to_last();
    if let Some((epoch, ledger_info)) = iter.next().transpose()? {
        let version = ledger_info.commit_info().version();
        if version >= start_version {
            info!(
                version = version,
                epoch = epoch,
                "Truncate latest epoch data."
            );
            batch.delete::<LedgerInfoSchema>(&epoch)?;
        }
    }

    let mut iter = ledger_db.iter::<EpochByVersionSchema>()?;
    iter.seek(&start_version)?;

    for item in iter {
        let (version, epoch) = item?;
        info!(
            version = version,
            epoch = epoch,
            "Truncate epoch ending data."
        );
        batch.delete::<EpochByVersionSchema>(&version)?;
        batch.delete::<LedgerInfoSchema>(&epoch)?;
    }

    Ok(())
}
```

**File:** storage/schemadb/src/batch.rs (L122-125)
```rust
pub enum WriteOp {
    Value { key: Vec<u8>, value: Vec<u8> },
    Deletion { key: Vec<u8> },
}
```

**File:** storage/schemadb/src/batch.rs (L129-133)
```rust
#[derive(Debug, Default)]
pub struct SchemaBatch {
    rows: DropHelper<HashMap<ColumnFamilyName, Vec<WriteOp>>>,
    stats: SampledBatchStats,
}
```

**File:** storage/aptosdb/src/state_store/mod.rs (L107-107)
```rust
pub const MAX_COMMIT_PROGRESS_DIFFERENCE: u64 = 1_000_000;
```

**File:** storage/aptosdb/src/state_store/mod.rs (L440-449)
```rust
            info!(
                ledger_commit_progress = ledger_commit_progress,
                "Attempt ledger truncation...",
            );
            let difference = ledger_commit_progress - overall_commit_progress;
            if crash_if_difference_is_too_large {
                assert_le!(difference, MAX_COMMIT_PROGRESS_DIFFERENCE);
            }
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```
