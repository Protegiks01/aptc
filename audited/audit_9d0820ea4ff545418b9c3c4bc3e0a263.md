# Audit Report

## Title
Consensus Observer Pending Block Store DoS via Lack of Per-Peer Rate Limiting

## Summary
The consensus observer's pending block store lacks per-peer rate limiting, allowing an attacker controlling subscribed peers to flood the store with blocks containing invalid signatures. This causes legitimate blocks to be garbage collected before their payloads arrive, forcing observer nodes into fallback mode and degrading availability.

## Finding Description

The consensus observer implements a pending block store to hold ordered blocks that are waiting for their transaction payloads to arrive. However, this store has a critical design flaw: **it only enforces a global limit on total pending blocks without any per-peer quotas or rate limiting**. [1](#0-0) 

The `PendingBlockWithMetadata` struct stores the `peer_network_id` as metadata, but this information is not used to enforce per-peer limits. [2](#0-1) 

The pending block store uses only global storage keyed by `(epoch, round)` and block hash, with a single global limit of `max_num_pending_blocks`. [3](#0-2) 

The default limit is 150 blocks (300 for test networks), shared across all peers.

**Attack Vector:**

While the consensus observer has a subscription system that limits messages to come from at most 2 concurrent subscribed peers: [4](#0-3) [5](#0-4) 

Within these allowed subscriptions, there is no per-peer rate limiting. The critical vulnerability is in the **deferred signature verification** combined with lack of per-peer quotas: [6](#0-5) 

When an ordered block is received, it only undergoes structural validation (`verify_ordered_blocks()`) before being inserted into the pending store. The cryptographic signature verification happens **later** in `process_ordered_block`: [7](#0-6) 

This creates a time window where blocks with invalid signatures can occupy the pending store.

**Exploitation Steps:**

1. Attacker controls or compromises 2 peers that become subscribed to the observer
2. Each peer sends ~75 ordered blocks with:
   - Valid structure (properly chained blocks that pass `verify_ordered_blocks()`)
   - Future rounds (e.g., `current_round + 1` through `current_round + 150`)
   - **Invalid signatures** in the ordered proof
   - References to non-existent or delayed payloads
3. These blocks fill the pending store to its limit (150 blocks)
4. When the limit is exceeded, the oldest blocks are garbage collected: [8](#0-7) 

5. Legitimate blocks from honest validators that are waiting for payloads get garbage collected
6. When payloads arrive for those legitimate blocks, the blocks are already gone
7. Observer loses sync and enters fallback mode

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty criteria)

This vulnerability causes:
- **State inconsistencies requiring intervention**: Observer nodes lose track of legitimate blocks and must enter fallback mode to resync via state sync
- **Degraded availability**: Observer nodes cannot maintain continuous sync with consensus, impacting validator fullnodes and potentially public fullnodes
- **Resource exhaustion**: Forces repeated fallback syncing, consuming bandwidth and storage resources

This meets the **Medium Severity** criteria of "State inconsistencies requiring intervention" as observer nodes must use fallback state sync recovery mechanisms.

The impact is limited to observer nodes and does not affect:
- Consensus safety (validators continue operating normally)
- Consensus liveness (block production is unaffected)
- Fund security (no direct financial loss)

However, it significantly degrades the consensus observer system's intended purpose of efficiently syncing non-validator nodes.

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is realistic because:

1. **Attacker Requirements**: 
   - Control or compromise 2 peers that can establish subscriptions
   - Ability to craft validly-structured blocks (straightforward using public APIs)
   - No need for validator access or consensus participation

2. **No Detection Mechanisms**:
   - No per-peer reputation tracking
   - No rate limiting within subscriptions
   - Invalid signatures are only detected after blocks occupy the store

3. **Observable Symptoms**:
   - Observer nodes repeatedly entering fallback mode
   - High pending block garbage collection rates
   - Subscription health checks may not detect the attack if malicious peers respond normally

The main limiting factor is that the attacker needs to control 2 subscribed peers, but this is achievable through:
- Operating malicious validator fullnodes
- Compromising existing nodes
- Exploiting subscription selection logic

## Recommendation

Implement **per-peer quotas** in the pending block store:

```rust
pub struct PendingBlockStore {
    consensus_observer_config: ConsensusObserverConfig,
    blocks_without_payloads: BTreeMap<(u64, Round), Arc<PendingBlockWithMetadata>>,
    blocks_without_payloads_by_hash: BTreeMap<HashValue, Arc<PendingBlockWithMetadata>>,
    
    // NEW: Track pending blocks per peer
    pending_blocks_per_peer: HashMap<PeerNetworkId, usize>,
    
    // NEW: Maximum blocks per peer (e.g., max_num_pending_blocks / max_concurrent_subscriptions)
    max_blocks_per_peer: u64,
}
```

Modify `insert_pending_block` to enforce per-peer limits:

```rust
pub fn insert_pending_block(&mut self, pending_block: Arc<PendingBlockWithMetadata>) {
    let peer_network_id = pending_block.peer_network_id;
    
    // Check per-peer quota
    let peer_block_count = self.pending_blocks_per_peer.get(&peer_network_id).unwrap_or(&0);
    if *peer_block_count >= self.max_blocks_per_peer {
        warn!("Peer {} has exceeded pending block quota", peer_network_id);
        return; // Drop the block
    }
    
    // ... existing insertion logic ...
    
    // Update per-peer counter
    *self.pending_blocks_per_peer.entry(peer_network_id).or_insert(0) += 1;
}
```

Additionally, consider:
1. **Early signature verification**: Verify ordered proof signatures before inserting into pending store (for current epoch blocks)
2. **Upper bound on future rounds**: Reject blocks with rounds too far ahead (e.g., `current_round + 100`)
3. **Reputation tracking**: Track invalid block submission rates per peer and terminate subscriptions for repeat offenders

## Proof of Concept

```rust
#[tokio::test]
async fn test_pending_block_flooding_attack() {
    // Create consensus observer with default config
    let consensus_observer_config = ConsensusObserverConfig::default();
    let pending_block_store = Arc::new(Mutex::new(PendingBlockStore::new(
        consensus_observer_config,
    )));
    
    // Simulate attacker controlling 2 subscribed peers
    let attacker_peer_1 = PeerNetworkId::random();
    let attacker_peer_2 = PeerNetworkId::random();
    
    let current_epoch = 10;
    let current_round = 100;
    
    // Attacker floods with 75 blocks from each peer (total 150)
    for i in 0..75 {
        // Blocks from attacker peer 1
        let malicious_block_1 = create_ordered_block_with_invalid_signature(
            current_epoch,
            current_round + i * 2,  // Future rounds
        );
        let pending_block_1 = PendingBlockWithMetadata::new_with_arc(
            attacker_peer_1,
            Instant::now(),
            ObservedOrderedBlock::new(malicious_block_1),
        );
        pending_block_store.lock().insert_pending_block(pending_block_1);
        
        // Blocks from attacker peer 2
        let malicious_block_2 = create_ordered_block_with_invalid_signature(
            current_epoch,
            current_round + i * 2 + 1,
        );
        let pending_block_2 = PendingBlockWithMetadata::new_with_arc(
            attacker_peer_2,
            Instant::now(),
            ObservedOrderedBlock::new(malicious_block_2),
        );
        pending_block_store.lock().insert_pending_block(pending_block_2);
    }
    
    // Verify pending store is full (150 blocks)
    assert_eq!(pending_block_store.lock().blocks_without_payloads.len(), 150);
    
    // Now a legitimate block arrives
    let honest_peer = PeerNetworkId::random();
    let legitimate_block = create_ordered_block_with_valid_signature(
        current_epoch,
        current_round + 200,  // Later round
    );
    let pending_block_legit = PendingBlockWithMetadata::new_with_arc(
        honest_peer,
        Instant::now(),
        ObservedOrderedBlock::new(legitimate_block),
    );
    pending_block_store.lock().insert_pending_block(pending_block_legit);
    
    // Verify the oldest malicious block was garbage collected, not the legitimate one
    // This demonstrates the vulnerability: legitimate blocks get evicted by malicious flood
    assert_eq!(pending_block_store.lock().blocks_without_payloads.len(), 150);
}
```

## Notes

This vulnerability exploits the interaction between three design decisions:
1. **Global-only limits** without per-peer quotas
2. **Deferred signature verification** allowing invalid blocks to occupy storage
3. **Age-based garbage collection** that doesn't consider block legitimacy or peer reputation

The fix requires implementing proper per-peer accounting and potentially moving signature verification earlier in the pipeline to reject invalid blocks before they consume resources.

### Citations

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L31-42)
```rust
    pub fn new_with_arc(
        peer_network_id: PeerNetworkId,
        block_receipt_time: Instant,
        observed_ordered_block: ObservedOrderedBlock,
    ) -> Arc<Self> {
        let pending_block_with_metadata = Self {
            peer_network_id,
            block_receipt_time,
            observed_ordered_block,
        };
        Arc::new(pending_block_with_metadata)
    }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L61-73)
```rust
pub struct PendingBlockStore {
    // The configuration of the consensus observer
    consensus_observer_config: ConsensusObserverConfig,

    // A map of ordered blocks that are without payloads. The key is
    // the (epoch, round) of the first block in the ordered block.
    blocks_without_payloads: BTreeMap<(u64, Round), Arc<PendingBlockWithMetadata>>,

    // A map of ordered blocks that are without payloads. The key is
    // the hash of the first block in the ordered block.
    // Note: this is the same as blocks_without_payloads, but with a different key.
    blocks_without_payloads_by_hash: BTreeMap<HashValue, Arc<PendingBlockWithMetadata>>,
}
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L158-195)
```rust
    fn garbage_collect_pending_blocks(&mut self) {
        // Verify that both stores have the same number of entries.
        // If not, log an error as this should never happen.
        let num_pending_blocks = self.blocks_without_payloads.len() as u64;
        let num_pending_blocks_by_hash = self.blocks_without_payloads_by_hash.len() as u64;
        if num_pending_blocks != num_pending_blocks_by_hash {
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "The pending block stores have different numbers of entries: {} and {} (by hash)",
                    num_pending_blocks, num_pending_blocks_by_hash
                ))
            );
        }

        // Calculate the number of blocks to remove
        let max_pending_blocks = self.consensus_observer_config.max_num_pending_blocks;
        let num_blocks_to_remove = num_pending_blocks.saturating_sub(max_pending_blocks);

        // Remove the oldest blocks if the store is too large
        for _ in 0..num_blocks_to_remove {
            if let Some((oldest_epoch_round, pending_block)) =
                self.blocks_without_payloads.pop_first()
            {
                // Log a warning message for the removed block
                warn!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "The pending block store is too large: {:?} blocks. Removing the block for the oldest epoch and round: {:?}",
                        num_pending_blocks, oldest_epoch_round
                    ))
                );

                // Remove the block from the hash store
                let first_block = pending_block.ordered_block().first_block();
                self.blocks_without_payloads_by_hash
                    .remove(&first_block.id());
            }
        }
    }
```

**File:** config/src/config/consensus_observer_config.rs (L36-37)
```rust
    /// Maximum number of blocks to keep in memory (e.g., pending blocks, ordered blocks, etc.)
    pub max_num_pending_blocks: u64,
```

**File:** config/src/config/consensus_observer_config.rs (L41-42)
```rust
    /// The maximum number of concurrent subscriptions
    pub max_concurrent_subscriptions: u64,
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L363-385)
```rust
    pub fn verify_message_for_subscription(
        &mut self,
        message_sender: PeerNetworkId,
    ) -> Result<(), Error> {
        // Check if the message is from an active subscription
        if let Some(active_subscription) = self
            .active_observer_subscriptions
            .lock()
            .get_mut(&message_sender)
        {
            // Update the last message receive time and return early
            active_subscription.update_last_message_receive_time();
            return Ok(());
        }

        // Otherwise, the message is not from an active subscription.
        // Send another unsubscribe request, and return an error.
        self.unsubscribe_from_peer(message_sender);
        Err(Error::InvalidMessageError(format!(
            "Received message from unexpected peer, and not an active subscription: {}!",
            message_sender
        )))
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L658-714)
```rust
        // Verify the ordered blocks before processing
        if let Err(error) = ordered_block.verify_ordered_blocks() {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify ordered blocks! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                    ordered_block.proof_block_info(),
                    peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        };

        // Get the epoch and round of the first block
        let first_block = ordered_block.first_block();
        let first_block_epoch_round = (first_block.epoch(), first_block.round());

        // Determine if the block is behind the last ordered block, or if it is already pending
        let last_ordered_block = self.observer_block_data.lock().get_last_ordered_block();
        let block_out_of_date =
            first_block_epoch_round <= (last_ordered_block.epoch(), last_ordered_block.round());
        let block_pending = self
            .observer_block_data
            .lock()
            .existing_pending_block(&ordered_block);

        // If the block is out of date or already pending, ignore it
        if block_out_of_date || block_pending {
            // Update the metrics for the dropped ordered block
            update_metrics_for_dropped_ordered_block_message(peer_network_id, &ordered_block);
            return;
        }

        // Update the metrics for the received ordered block
        update_metrics_for_ordered_block_message(peer_network_id, &ordered_block);

        // Create a new pending block with metadata
        let observed_ordered_block = ObservedOrderedBlock::new(ordered_block);
        let pending_block_with_metadata = PendingBlockWithMetadata::new_with_arc(
            peer_network_id,
            message_received_time,
            observed_ordered_block,
        );

        // If all payloads exist, process the block. Otherwise, store it
        // in the pending block store and wait for the payloads to arrive.
        if self.all_payloads_exist(pending_block_with_metadata.ordered_block().blocks()) {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        } else {
            self.observer_block_data
                .lock()
                .insert_pending_block(pending_block_with_metadata);
        }
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L727-752)
```rust
        // Verify the ordered block proof
        let epoch_state = self.get_epoch_state();
        if ordered_block.proof_block_info().epoch() == epoch_state.epoch {
            if let Err(error) = ordered_block.verify_ordered_proof(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify ordered proof! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                        ordered_block.proof_block_info(),
                        peer_network_id,
                        error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
                return;
            }
        } else {
            // Drop the block and log an error (the block should always be for the current epoch)
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Received ordered block for a different epoch! Ignoring: {:?}",
                    ordered_block.proof_block_info()
                ))
            );
            return;
        };
```
