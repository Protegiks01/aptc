# Audit Report

## Title
Indexer Denial of Service via Null Bytes in Property Map Keys

## Summary
The `recurse_remove_null_bytes_from_json()` function in `crates/indexer/src/util.rs` fails to sanitize null bytes in JSON object keys, only processing values. This allows property map keys containing null bytes to bypass sanitization and cause PostgreSQL JSONB insertion failures, leading to indexer service denial of service.

## Finding Description

The vulnerability exists in the null byte sanitization logic used by the Aptos indexer service before inserting data into PostgreSQL. [1](#0-0) 

The function recursively processes JSON values but when encountering `Value::Object`, it only iterates over and sanitizes the **values**, completely ignoring the **keys**. Object keys are accessed but never modified (note the underscore prefix `_key` indicating it's unused). [2](#0-1) 

Property maps from on-chain token data have user-controlled keys that are extracted from JSON and inserted into a HashMap. When this HashMap is serialized to JSON, keys containing null bytes become JSON object keys. These keys bypass sanitization. [3](#0-2) 

The insertion flow attempts database insertion, and on failure, applies `clean_data_for_db()` with sanitization enabled. However, since object keys aren't sanitized, the retry also fails.

**Attack Path:**
1. Attacker creates an on-chain token with a property map containing a key with embedded null bytes (e.g., `"test\x00key"`)
2. BCS encoding preserves the null byte
3. Indexer deserializes the property map - null bytes in keys are preserved as actual null bytes in Rust Strings
4. First database insertion fails (PostgreSQL JSONB rejects null bytes in JSON strings, including object keys)
5. `clean_data_for_db()` sanitizes data but skips object keys
6. Second insertion attempt also fails
7. Indexer cannot process this transaction and subsequent transactions are blocked

## Impact Explanation

This is a **Low Severity** issue as marked in the original security question. The impact is limited to:
- Denial of service of the indexer service only
- Does NOT affect blockchain consensus, execution, or core functionality
- Does NOT cause loss of funds or validator disruption
- The blockchain continues to operate normally; only the indexing/querying service is affected

Per Aptos bug bounty criteria, this falls under "Non-critical implementation bugs" in the Low Severity category.

## Likelihood Explanation

**Likelihood: Medium-High**
- Easy to exploit - any user can create tokens with malicious property maps
- No special privileges required
- Attack surface is well-defined (token creation with property maps)
- However, impact is limited to a supporting service, not core blockchain infrastructure

## Recommendation

Modify `recurse_remove_null_bytes_from_json()` to sanitize object keys in addition to values:

```rust
fn recurse_remove_null_bytes_from_json(sub_json: &mut Value) {
    match sub_json {
        Value::Array(array) => {
            for item in array {
                recurse_remove_null_bytes_from_json(item);
            }
        },
        Value::Object(object) => {
            // Create a new map with sanitized keys
            let mut new_map = serde_json::Map::new();
            for (key, mut value) in object.iter_mut() {
                let sanitized_key = string_null_byte_replacement(key);
                recurse_remove_null_bytes_from_json(value);
                new_map.insert(sanitized_key, value.clone());
            }
            *object = new_map;
        },
        Value::String(str) => {
            if !str.is_empty() {
                let replacement = string_null_byte_replacement(str);
                *str = replacement;
            }
        },
        _ => {},
    }
}
```

## Proof of Concept

```rust
#[test]
fn test_null_bytes_in_object_keys() {
    use serde_json::json;
    
    // Create a JSON object with null byte in key
    let mut test_json = json!({
        "test\u0000key": "value",
        "normal_key": "another\u0000value"
    });
    
    crate::util::recurse_remove_null_bytes_from_json(&mut test_json);
    
    // After sanitization, the value should be clean but the key is not
    let obj = test_json.as_object().unwrap();
    
    // This assertion will FAIL - demonstrating the vulnerability
    for key in obj.keys() {
        assert!(!key.contains('\u{0000}'), "Key still contains null byte: {:?}", key);
    }
}
```

## Notes

While this is a genuine implementation bug, it's important to note that:
1. This affects only the indexer service, which is a supporting infrastructure component
2. The core blockchain (consensus, execution, storage) continues operating normally
3. The severity is correctly classified as Low
4. This does NOT meet the Medium/High/Critical severity criteria required for bug bounty rewards above $1,000

### Citations

**File:** crates/indexer/src/util.rs (L73-93)
```rust
fn recurse_remove_null_bytes_from_json(sub_json: &mut Value) {
    match sub_json {
        Value::Array(array) => {
            for item in array {
                recurse_remove_null_bytes_from_json(item);
            }
        },
        Value::Object(object) => {
            for (_key, value) in object {
                recurse_remove_null_bytes_from_json(value);
            }
        },
        Value::String(str) => {
            if !str.is_empty() {
                let replacement = string_null_byte_replacement(str);
                *str = replacement;
            }
        },
        _ => {},
    }
}
```

**File:** crates/indexer/src/models/property_map.rs (L29-53)
```rust
    pub fn from_bcs_encode_str(val: Value) -> Option<Value> {
        let mut pm = PropertyMap {
            data: HashMap::new(),
        };
        let records: &Vec<Value> = val.get("map")?.get("data")?.as_array()?;
        for entry in records {
            let key = entry.get("key")?.as_str()?;
            let val = entry.get("value")?.get("value")?.as_str()?;
            let typ = entry.get("value")?.get("type")?.as_str()?;
            let pv = create_property_value(typ.to_string(), val.to_string()).ok()?;
            pm.data.insert(key.to_string(), pv);
        }
        Some(Self::to_flat_json(pm))
    }

    /// Flattens PropertyMap which can't be easily consumable by downstream.
    /// For example: Object {"data": Object {"creation_time_sec": Object {"value": String("1666125588")}}}
    /// becomes Object {"creation_time_sec": "1666125588"}
    fn to_flat_json(val: PropertyMap) -> Value {
        let mut map = HashMap::new();
        for (k, v) in val.data {
            map.insert(k, v.value);
        }
        serde_json::to_value(map).unwrap()
    }
```

**File:** crates/indexer/src/processors/token_processor.rs (L200-252)
```rust
    match conn
        .build_transaction()
        .read_write()
        .run::<_, Error, _>(|pg_conn| {
            insert_to_db_impl(
                pg_conn,
                (&tokens, &token_ownerships, &token_datas, &collection_datas),
                (
                    &current_token_ownerships,
                    &current_token_datas,
                    &current_collection_datas,
                ),
                &token_activities,
                &current_token_claims,
                &current_ans_lookups,
                &nft_points,
                (
                    &collections_v2,
                    &token_datas_v2,
                    &token_ownerships_v2,
                    &current_collections_v2,
                    &current_token_datas_v2,
                    &current_token_ownerships_v2,
                    &token_activities_v2,
                    &current_token_v2_metadata,
                ),
            )
        }) {
        Ok(_) => Ok(()),
        Err(_) => conn
            .build_transaction()
            .read_write()
            .run::<_, Error, _>(|pg_conn| {
                let tokens = clean_data_for_db(tokens, true);
                let token_datas = clean_data_for_db(token_datas, true);
                let token_ownerships = clean_data_for_db(token_ownerships, true);
                let collection_datas = clean_data_for_db(collection_datas, true);
                let current_token_ownerships = clean_data_for_db(current_token_ownerships, true);
                let current_token_datas = clean_data_for_db(current_token_datas, true);
                let current_collection_datas = clean_data_for_db(current_collection_datas, true);
                let token_activities = clean_data_for_db(token_activities, true);
                let current_token_claims = clean_data_for_db(current_token_claims, true);
                let current_ans_lookups = clean_data_for_db(current_ans_lookups, true);
                let nft_points = clean_data_for_db(nft_points, true);
                let collections_v2 = clean_data_for_db(collections_v2, true);
                let token_datas_v2 = clean_data_for_db(token_datas_v2, true);
                let token_ownerships_v2 = clean_data_for_db(token_ownerships_v2, true);
                let current_collections_v2 = clean_data_for_db(current_collections_v2, true);
                let current_token_datas_v2 = clean_data_for_db(current_token_datas_v2, true);
                let current_token_ownerships_v2 =
                    clean_data_for_db(current_token_ownerships_v2, true);
                let token_activities_v2 = clean_data_for_db(token_activities_v2, true);
                let current_token_v2_metadata = clean_data_for_db(current_token_v2_metadata, true);
```
