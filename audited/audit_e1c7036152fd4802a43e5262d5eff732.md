# Audit Report

## Title
Missing Minimum Validator Count Validation Allows Complete Network Halt Through Empty Validator Set

## Summary
The `on_new_epoch` function in the staking system filters validators based on minimum stake requirements but fails to enforce a minimum validator count. If all validators' stake falls below the minimum threshold, the active validator set becomes empty, causing irreversible consensus failure and total network halt.

## Finding Description

The vulnerability exists in the epoch transition logic where validators are removed without ensuring at least one validator remains active.

**Critical Code Path:** [1](#0-0) 

The `on_new_epoch` function filters validators by checking if their voting power meets the minimum stake requirement. However, there is no validation to ensure at least one validator remains after filtering. The function iterates through all validators and only includes those with sufficient stake in `next_epoch_validators`. If no validators meet the requirement, the vector remains empty.

**Comparison with voluntary exit protection:** [2](#0-1) 

The `leave_validator_set` function explicitly prevents removing the last validator through the `ELAST_VALIDATOR` check. However, this protection does NOT exist in `on_new_epoch` for automatic removal due to insufficient stake.

**Rust-side validation gaps:** [3](#0-2) 

The `ValidatorVerifier` constructor accepts empty validator sets and sets `quorum_voting_power` to 0, which would allow any signature verification to pass trivially (since 0 >= 0).

**Epoch change verification:** [4](#0-3) 

The `verify()` function only validates signatures from the current epoch's validators and extracts the `next_epoch_state` without checking if the new validator set is non-empty or viable for consensus.

**Function specification confirms no-abort design:** [5](#0-4) 

The specification explicitly states `aborts_if false`, meaning `on_new_epoch` is designed to never abort, even when producing an empty validator set.

**Attack Scenario:**

1. All active validators unlock their stake (legitimate operation, no malicious intent required)
2. Stake values fall below `minimum_stake` threshold through pending withdrawals
3. Next epoch begins, `on_new_epoch` executes
4. All validators are filtered out due to insufficient stake
5. `active_validators` becomes empty vector
6. `ValidatorVerifier` is created with 0 validators and `quorum_voting_power = 0`
7. No validators can propose blocks or participate in consensus
8. Chain permanently halts - requires hard fork to recover

## Impact Explanation

**Severity: CRITICAL** (up to $1,000,000)

This vulnerability causes **"Total loss of liveness/network availability"** and **"Non-recoverable network partition (requires hardfork)"**, both explicitly listed as Critical severity in the Aptos bug bounty program.

Once the validator set becomes empty:
- No blocks can be proposed (no validators exist)
- No consensus can be reached (no voting power available)
- The chain is permanently halted
- Requires a hard fork with manual validator set injection to recover
- All economic activity freezes
- Smart contracts become inaccessible
- Funds are effectively frozen (though not permanently lost after recovery)

This breaks the fundamental **Consensus Safety** and **Staking Security** invariants:
- Consensus cannot maintain liveness with zero validators
- The validator set management failed to maintain system operability

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

While requiring all validators to have insufficient stake seems unlikely, several realistic scenarios make this exploitable:

1. **Small validator set configurations**: Testnets or newly launched networks with few validators are highly vulnerable

2. **Coordinated stake unlocking**: During periods of low staking rewards or network concerns, multiple validators might simultaneously unlock stake, pushing all below minimum

3. **Governance-driven minimum stake increases**: If governance raises `minimum_stake` significantly while validators haven't added stake, all could become ineligible simultaneously

4. **Economic conditions**: Market crashes could cause validators to withdraw stake for liquidity, or staking may become economically unviable

5. **No reversal mechanism**: Once triggered in epoch N, the empty validator set is committed for epoch N+1 with no recovery path

The vulnerability doesn't require malicious actors - it can occur through legitimate operational decisions under adverse conditions.

## Recommendation

**Immediate Fix: Add minimum validator count enforcement in `on_new_epoch`**

Add validation after the filtering loop to ensure at least one validator remains:

```move
// After line 1401 in stake.move
validator_set.active_validators = next_epoch_validators;

// Add this validation:
assert!(
    vector::length(&validator_set.active_validators) > 0,
    error::invalid_state(ELAST_VALIDATOR)
);

validator_set.total_voting_power = total_voting_power;
```

**Additional safeguards:**

1. **Minimum validator count configuration**: Add a `minimum_validator_count` parameter to `StakingConfig` (recommend minimum of 4 for BFT safety)

2. **Rust-side validation**: Update `ValidatorVerifier::new()` to reject empty validator sets:
   ```rust
   pub fn new(validator_infos: Vec<ValidatorConsensusInfo>) -> Self {
       assert!(!validator_infos.is_empty(), "Validator set cannot be empty");
       // ... rest of implementation
   }
   ```

3. **Epoch change verification**: Add validation in `epoch_change.rs` to reject epoch changes with empty validator sets

4. **Early warning system**: Emit events when the number of validators falls below a safe threshold

## Proof of Concept

```move
#[test(aptos_framework = @0x1, validator_1 = @0x123, validator_2 = @0x234)]
#[expected_failure(abort_code = 0x60006, location = aptos_framework::stake)]
public entry fun test_empty_validator_set_causes_halt(
    aptos_framework: &signer,
    validator_1: &signer,
    validator_2: &signer,
) {
    use aptos_framework::stake;
    use aptos_framework::staking_config;
    
    // Initialize staking with minimum stake = 100
    stake::initialize_for_test(aptos_framework);
    
    // Register two validators with exactly minimum stake
    let (_sk_1, pk_1, pop_1) = stake::generate_identity();
    let (_sk_2, pk_2, pop_2) = stake::generate_identity();
    stake::initialize_test_validator(&pk_1, &pop_1, validator_1, 100, true, true);
    stake::initialize_test_validator(&pk_2, &pop_2, validator_2, 100, true, true);
    
    // Verify both validators are active
    assert!(vector::length(&borrow_global<stake::ValidatorSet>(@aptos_framework).active_validators) == 2, 0);
    
    // Both validators unlock all their stake
    stake::unlock(validator_1, 100);
    stake::unlock(validator_2, 100);
    
    // Trigger epoch change - this will filter out both validators
    // since their pending_inactive stake moves to inactive, leaving active stake at 0
    // Expected to fail with ELAST_VALIDATOR after fix is applied
    // Without fix, this creates an empty validator set causing network halt
    stake::on_new_epoch();
    
    // This line should never execute - chain would be halted
    let validator_set = borrow_global<stake::ValidatorSet>(@aptos_framework);
    assert!(vector::length(&validator_set.active_validators) == 0, 1); // Network is dead!
}
```

**Notes**

This vulnerability represents a critical gap in the validator set management invariants. While the design intentionally allows validators to leave voluntarily and be automatically removed for insufficient stake (enabling operational flexibility), the absence of a minimum validator count check creates a catastrophic failure mode.

The issue is particularly concerning because:
1. It can occur through entirely legitimate operations (stake unlocking)
2. The Move specification explicitly documents `aborts_if false`, suggesting this edge case was not considered
3. Recovery requires a hard fork with manual intervention
4. No warning or prevention mechanism exists at any layer (Move, Rust consensus, or epoch change verification)

The recommended fix is minimal and should be applied immediately to prevent potential network halts.

### Citations

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L1255-1255)
```text
            assert!(vector::length(&validator_set.active_validators) > 0, error::invalid_state(ELAST_VALIDATOR));
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L1372-1401)
```text
        let next_epoch_validators = vector::empty();
        let (minimum_stake, _) = staking_config::get_required_stake(&config);
        let vlen = vector::length(&validator_set.active_validators);
        let total_voting_power = 0;
        let i = 0;
        while ({
            spec {
                invariant spec_validators_are_initialized(next_epoch_validators);
                invariant i <= vlen;
            };
            i < vlen
        }) {
            let old_validator_info = vector::borrow_mut(&mut validator_set.active_validators, i);
            let pool_address = old_validator_info.addr;
            let validator_config = borrow_global<ValidatorConfig>(pool_address);
            let stake_pool = borrow_global<StakePool>(pool_address);
            let new_validator_info = generate_validator_info(pool_address, stake_pool, *validator_config);

            // A validator needs at least the min stake required to join the validator set.
            if (new_validator_info.voting_power >= minimum_stake) {
                spec {
                    assume total_voting_power + new_validator_info.voting_power <= MAX_U128;
                };
                total_voting_power = total_voting_power + (new_validator_info.voting_power as u128);
                vector::push_back(&mut next_epoch_validators, new_validator_info);
            };
            i = i + 1;
        };

        validator_set.active_validators = next_epoch_validators;
```

**File:** types/src/validator_verifier.rs (L206-214)
```rust
    pub fn new(validator_infos: Vec<ValidatorConsensusInfo>) -> Self {
        let total_voting_power = sum_voting_power(&validator_infos);
        let quorum_voting_power = if validator_infos.is_empty() {
            0
        } else {
            total_voting_power * 2 / 3 + 1
        };
        Self::build_index(validator_infos, quorum_voting_power, total_voting_power)
    }
```

**File:** types/src/epoch_change.rs (L66-118)
```rust
    pub fn verify(&self, verifier: &dyn Verifier) -> Result<&LedgerInfoWithSignatures> {
        ensure!(
            !self.ledger_info_with_sigs.is_empty(),
            "The EpochChangeProof is empty"
        );
        ensure!(
            !verifier
                .is_ledger_info_stale(self.ledger_info_with_sigs.last().unwrap().ledger_info()),
            "The EpochChangeProof is stale as our verifier is already ahead \
             of the entire EpochChangeProof"
        );
        let mut verifier_ref = verifier;

        for ledger_info_with_sigs in self
            .ledger_info_with_sigs
            .iter()
            // Skip any stale ledger infos in the proof prefix. Note that with
            // the assertion above, we are guaranteed there is at least one
            // non-stale ledger info in the proof.
            //
            // It's useful to skip these stale ledger infos to better allow for
            // concurrent client requests.
            //
            // For example, suppose the following:
            //
            // 1. My current trusted state is at epoch 5.
            // 2. I make two concurrent requests to two validators A and B, who
            //    live at epochs 9 and 11 respectively.
            //
            // If A's response returns first, I will ratchet my trusted state
            // to epoch 9. When B's response returns, I will still be able to
            // ratchet forward to 11 even though B's EpochChangeProof
            // includes a bunch of stale ledger infos (for epochs 5, 6, 7, 8).
            //
            // Of course, if B's response returns first, we will reject A's
            // response as it's completely stale.
            .skip_while(|&ledger_info_with_sigs| {
                verifier.is_ledger_info_stale(ledger_info_with_sigs.ledger_info())
            })
        {
            // Try to verify each (epoch -> epoch + 1) jump in the EpochChangeProof.
            verifier_ref.verify(ledger_info_with_sigs)?;
            // While the original verification could've been via waypoints,
            // all the next epoch changes are verified using the (already
            // trusted) validator sets.
            verifier_ref = ledger_info_with_sigs
                .ledger_info()
                .next_epoch_state()
                .ok_or_else(|| format_err!("LedgerInfo doesn't carry a ValidatorSet"))?;
        }

        Ok(self.ledger_info_with_sigs.last().unwrap())
    }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.spec.move (L463-464)
```text
        /// [high-level-req-4]
        aborts_if false;
```
