# Audit Report

## Title
Storage Service Network Channel Overflow Enables Denial of State Synchronization

## Summary
The storage service network channel has a fixed capacity of 4000 messages shared across all peers and networks. When this FIFO queue reaches capacity, new incoming RPC requests are silently dropped without error propagation, causing client timeouts. An attacker can exploit this by establishing multiple peer connections (up to 100) and sending valid but resource-intensive storage requests (100 concurrent per peer), filling the channel and preventing legitimate nodes from synchronizing state.

## Finding Description

The storage service uses an `aptos_channel` configured with `QueueStyle::FIFO` and `max_network_channel_size = 4000` to buffer incoming network RPC requests. [1](#0-0) [2](#0-1) 

When the FIFO queue is full, the `PerKeyQueue::push()` method drops the **newest** incoming message but returns it as `Some(message)` rather than an error: [3](#0-2) 

The `aptos_channel::Sender::push_with_feedback()` method handles this dropped message by notifying an optional status channel, but **still returns `Ok(())`** to the caller: [4](#0-3) 

The network RPC layer calls `push()` without a feedback channel, so it has no way to detect that the message was dropped: [5](#0-4) 

**Attack Flow:**
1. Attacker establishes up to 100 peer connections to a public fullnode (within `MAX_INBOUND_CONNECTIONS`)
2. Each peer sends 100 concurrent storage service RPC requests (within `MAX_CONCURRENT_INBOUND_RPCS` per peer)
3. With 40 peers × 100 requests = 4,000 messages, the channel reaches capacity
4. New legitimate requests are silently dropped (push returns Ok but message is discarded)
5. Legitimate clients timeout after 10 seconds waiting for responses that will never arrive
6. After 5 retries (default `max_request_retry`), data streams terminate and nodes cannot synchronize [6](#0-5) 

The storage service spawns blocking handlers without concurrency limits, so attackers can craft expensive queries (large state chunks) that hold resources while more requests queue: [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos bug bounty criteria:
- **Validator node slowdowns**: Nodes unable to synchronize cannot participate effectively in consensus
- **Significant protocol violations**: State synchronization is critical for network liveness; preventing it violates availability guarantees

While this does not directly cause consensus splits or fund loss, it can:
- Prevent new nodes from bootstrapping
- Prevent recovering nodes from catching up after downtime
- Degrade network resilience by keeping nodes out of sync
- Affect both public fullnodes and potentially validators if the attack targets validator network interfaces

The shared channel across all networks (Validator, Vfn, Public) means attackers on the public network can impact validator synchronization traffic. [8](#0-7) 

## Likelihood Explanation

**High likelihood** of exploitation:
- Attack requires no special privileges—any peer can connect to public fullnodes
- Connection limit (100 peers) is sufficient to fill the channel (40 peers needed)
- Per-peer RPC limit (100) is per-connection, not global
- Attack uses valid requests (not caught by `RequestModerator`), just sustained volume
- No backpressure or rate limiting before channel entry
- Silent failure mode makes detection difficult

The `RequestModerator` only blocks peers after 500 **invalid** requests, but this attack uses valid requests that are simply resource-intensive: [9](#0-8) 

## Recommendation

Implement **backpressure** instead of silent dropping:

1. **Replace FIFO with bounded blocking channel** for critical paths where message loss is unacceptable
2. **Add per-peer rate limiting** before channel entry, not just at RPC concurrency level
3. **Separate channels per network type** to prevent public network attacks from affecting validator traffic
4. **Monitor channel saturation** and apply adaptive backpressure (reject new connections or slow down request acceptance)
5. **Increase channel size** relative to `(MAX_INBOUND_CONNECTIONS × MAX_CONCURRENT_INBOUND_RPCS)` or implement dynamic sizing

Example fix for network configuration:
```rust
// Separate channels for different network types with appropriate sizing
pub fn storage_service_network_configuration(node_config: &NodeConfig) -> NetworkApplicationConfig {
    // Calculate appropriate size: peers × concurrent RPCs + headroom
    let calculated_size = MAX_INBOUND_CONNECTIONS * MAX_CONCURRENT_INBOUND_RPCS + 1000;
    let max_network_channel_size = std::cmp::max(
        node_config.state_sync.storage_service.max_network_channel_size,
        calculated_size
    ) as usize;
    
    // Use blocking channel with backpressure instead of dropping
    ...
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_storage_service_channel_overflow() {
    use aptos_channels::aptos_channel;
    use aptos_channels::message_queues::QueueStyle;
    
    const CHANNEL_SIZE: usize = 4000;
    const NUM_PEERS: usize = 40;
    const REQUESTS_PER_PEER: usize = 100;
    
    // Create a FIFO channel like the storage service uses
    let (tx, mut rx) = aptos_channel::new(
        QueueStyle::FIFO,
        CHANNEL_SIZE,
        None
    );
    
    // Simulate 40 peers each sending 100 requests
    for peer_id in 0..NUM_PEERS {
        for req_id in 0..REQUESTS_PER_PEER {
            let message = format!("peer_{}_req_{}", peer_id, req_id);
            // This push will return Ok even when messages are dropped
            let result = tx.push(peer_id, message);
            assert!(result.is_ok(), "Push should always return Ok");
        }
    }
    
    // Now try to send a legitimate request
    let legitimate_msg = "legitimate_request".to_string();
    let result = tx.push(999, legitimate_msg);
    assert!(result.is_ok(), "Push returns Ok even though message was dropped!");
    
    // Verify the legitimate message was NOT queued
    let mut received = 0;
    while let Ok(Some(_)) = rx.try_next() {
        received += 1;
    }
    
    // Only CHANNEL_SIZE messages were actually queued
    assert_eq!(received, CHANNEL_SIZE);
    println!("Channel held {} messages out of {} sent", 
             received, NUM_PEERS * REQUESTS_PER_PEER + 1);
    println!("Legitimate requests beyond capacity were silently dropped!");
}
```

This demonstrates that:
1. The channel accepts only 4000 messages despite 4001 being sent
2. The `push()` operation returns `Ok()` even for dropped messages
3. No error is propagated to detect the overflow condition
4. Legitimate requests sent when the channel is full are silently lost

### Citations

**File:** config/src/config/state_sync_config.rs (L203-203)
```rust
            max_network_channel_size: 4000,
```

**File:** aptos-node/src/network.rs (L147-166)
```rust
pub fn storage_service_network_configuration(node_config: &NodeConfig) -> NetworkApplicationConfig {
    let direct_send_protocols = vec![]; // The storage service does not use direct send
    let rpc_protocols = vec![ProtocolId::StorageServiceRpc];
    let max_network_channel_size = node_config
        .state_sync
        .storage_service
        .max_network_channel_size as usize;

    let network_client_config =
        NetworkClientConfig::new(direct_send_protocols.clone(), rpc_protocols.clone());
    let network_service_config = NetworkServiceConfig::new(
        direct_send_protocols,
        rpc_protocols,
        aptos_channel::Config::new(max_network_channel_size)
            .queue_style(QueueStyle::FIFO)
            .counters(
                &aptos_storage_service_server::metrics::PENDING_STORAGE_SERVER_NETWORK_EVENTS,
            ),
    );
    NetworkApplicationConfig::new(network_client_config, network_service_config)
```

**File:** crates/channel/src/message_queues.rs (L134-147)
```rust
        if key_message_queue.len() >= self.max_queue_size.get() {
            if let Some(c) = self.counters.as_ref() {
                c.with_label_values(&["dropped"]).inc();
            }
            match self.queue_style {
                // Drop the newest message for FIFO
                QueueStyle::FIFO => Some(message),
                // Drop the oldest message for LIFO
                QueueStyle::LIFO | QueueStyle::KLAST => {
                    let oldest = key_message_queue.pop_front();
                    key_message_queue.push_back(message);
                    oldest
                },
            }
```

**File:** crates/channel/src/aptos_channel.rs (L91-112)
```rust
    pub fn push_with_feedback(
        &self,
        key: K,
        message: M,
        status_ch: Option<oneshot::Sender<ElementStatus<M>>>,
    ) -> Result<()> {
        let mut shared_state = self.shared_state.lock();
        ensure!(!shared_state.receiver_dropped, "Channel is closed");
        debug_assert!(shared_state.num_senders > 0);

        let dropped = shared_state.internal_queue.push(key, (message, status_ch));
        // If this or an existing message had to be dropped because of the queue being full, we
        // notify the corresponding status channel if it was registered.
        if let Some((dropped_val, Some(dropped_status_ch))) = dropped {
            // Ignore errors.
            let _err = dropped_status_ch.send(ElementStatus::Dropped(dropped_val));
        }
        if let Some(w) = shared_state.waker.take() {
            w.wake();
        }
        Ok(())
    }
```

**File:** network/framework/src/protocols/rpc/mod.rs (L246-253)
```rust
        // Forward request to PeerManager for handling.
        let (response_tx, response_rx) = oneshot::channel();
        request.rpc_replier = Some(Arc::new(response_tx));
        if let Err(err) = peer_notifs_tx.push((peer_id, protocol_id), request) {
            counters::rpc_messages(network_context, REQUEST_LABEL, INBOUND_LABEL, FAILED_LABEL)
                .inc();
            return Err(err.into());
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-453)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
```

**File:** state-sync/storage-service/server/src/lib.rs (L388-419)
```rust
        // Handle the storage requests as they arrive
        while let Some(network_request) = self.network_requests.next().await {
            // All handler methods are currently CPU-bound and synchronous
            // I/O-bound, so we want to spawn on the blocking thread pool to
            // avoid starving other async tasks on the same runtime.
            let storage = self.storage.clone();
            let config = self.storage_service_config;
            let cached_storage_server_summary = self.cached_storage_server_summary.clone();
            let optimistic_fetches = self.optimistic_fetches.clone();
            let subscriptions = self.subscriptions.clone();
            let lru_response_cache = self.lru_response_cache.clone();
            let request_moderator = self.request_moderator.clone();
            let time_service = self.time_service.clone();
            self.runtime.spawn_blocking(move || {
                Handler::new(
                    cached_storage_server_summary,
                    optimistic_fetches,
                    lru_response_cache,
                    request_moderator,
                    storage,
                    subscriptions,
                    time_service,
                )
                .process_request_and_respond(
                    config,
                    network_request.peer_network_id,
                    network_request.protocol_id,
                    network_request.storage_service_request,
                    network_request.response_sender,
                );
            });
        }
```

**File:** state-sync/storage-service/server/src/network.rs (L40-59)
```rust
    pub fn new(network_service_events: NetworkServiceEvents<StorageServiceMessage>) -> Self {
        // Transform the event streams to also include the network ID
        let network_events: Vec<_> = network_service_events
            .into_network_and_events()
            .into_iter()
            .map(|(network_id, events)| events.map(move |event| (network_id, event)))
            .collect();
        let network_events = select_all(network_events).fuse();

        // Transform each event to a network request
        let network_request_stream = network_events
            .filter_map(|(network_id, event)| {
                future::ready(Self::event_to_request(network_id, event))
            })
            .boxed();

        Self {
            network_request_stream,
        }
    }
```

**File:** state-sync/storage-service/server/src/moderator.rs (L155-185)
```rust
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }
```
