# Audit Report

## Title
Configuration Validation Bypass Allows Zero-Value Channel Sizes Leading to Validator Initialization Panic

## Summary
Multiple network channel size configuration fields lack validation to ensure non-zero values. When operators explicitly set `max_network_channel_size` to zero in YAML configuration files, the validator node panics during initialization when the `NonZeroUsize!` macro is invoked, causing a complete failure to start.

## Finding Description

The Aptos validator initialization process creates multiple network channels for different subsystems (consensus, mempool, DKG, JWK consensus, peer monitoring, storage service, consensus observer, and netbench). Each subsystem has a `max_network_channel_size` configuration field that determines the channel capacity. [1](#0-0) 

The `NonZeroUsize!` macro wraps `std::num::NonZeroUsize::new()` and calls `.expect()`, which panics when passed a zero value.

During validator initialization, the network setup code passes these configuration values directly to channel creation: [2](#0-1) [3](#0-2) [4](#0-3) [5](#0-4) 

These configuration values eventually reach the channel creation function: [6](#0-5) 

**The vulnerability exists because none of the configuration sanitizers validate that `max_network_channel_size` is non-zero:**

1. **ConsensusConfig** - Has a sanitizer but only checks block limits, not channel size: [7](#0-6) 

2. **MempoolConfig** - Sanitizer is completely empty: [8](#0-7) 

3. **DKGConfig** and **JWKConsensusConfig** - No sanitizers implemented at all: [9](#0-8) [10](#0-9) 

4. **NetbenchConfig** - Has a sanitizer but only checks if enabled on mainnet/testnet, not channel size: [11](#0-10) 

An attacker or misconfigured operator can set any of these values to 0 in the YAML configuration, which will pass serde deserialization but cause a panic during initialization.

## Impact Explanation

**Severity: High** (per Aptos Bug Bounty criteria for "Validator node slowdowns" / "API crashes")

This vulnerability allows:
- Complete denial of service for individual validator nodes during startup
- Operational disruption requiring manual intervention to fix configuration
- Potential network liveness issues if multiple validators are misconfigured simultaneously
- Attack surface for malicious insiders or compromised configuration management systems

While this doesn't directly cause consensus violations or fund loss, it breaks the availability invariant and can prevent validators from participating in consensus, which is classified as High severity in the bug bounty program.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can be triggered through:
1. **Accidental misconfiguration** - Operators manually editing YAML files may inadvertently set values to 0
2. **Configuration management errors** - Automated systems generating configs may produce zero values due to bugs
3. **Malicious configuration injection** - If an attacker gains access to configuration files or systems, they can deliberately set these to 0
4. **Default value confusion** - During troubleshooting or testing, operators might try setting values to 0 without understanding the consequences

The lack of validation makes this easy to trigger, requiring only YAML file modification. The default values are all non-zero, so this won't happen without explicit configuration changes.

## Recommendation

Add validation to ensure all `max_network_channel_size` fields are non-zero. Implement sanitizer checks in each configuration struct:

```rust
// In ConsensusConfig::sanitize()
if node_config.consensus.max_network_channel_size == 0 {
    return Err(Error::ConfigSanitizerFailed(
        sanitizer_name,
        "consensus.max_network_channel_size must be non-zero".to_string(),
    ));
}

// In MempoolConfig::sanitize()
if node_config.mempool.max_network_channel_size == 0 {
    return Err(Error::ConfigSanitizerFailed(
        "MempoolConfig".to_string(),
        "mempool.max_network_channel_size must be non-zero".to_string(),
    ));
}

// Similar checks for DKGConfig, JWKConsensusConfig, PeerMonitoringServiceConfig,
// StorageServiceConfig, ConsensusObserverConfig, and NetbenchConfig
```

Alternatively, change the field types to use `NonZeroUsize` or `NonZeroU64` directly in the configuration structs with a custom serde deserializer that validates non-zero values during deserialization.

## Proof of Concept

Create a validator configuration file with zero channel size:

```yaml
# validator_zero_channel.yaml
consensus:
  max_network_channel_size: 0
```

Start the validator node:
```bash
aptos-node -f validator_zero_channel.yaml
```

**Expected Result:** Node panics during initialization with message:
```
thread 'main' panicked at 'aptos_channel cannot be of size 0'
```

This demonstrates the complete failure to initialize, preventing the validator from starting and participating in consensus.

**Notes**

This vulnerability affects all node types (validators, VFNs, PFNs) and all subsystems that use `max_network_channel_size`. The issue is particularly critical for validators as their failure to start directly impacts network consensus participation. The vulnerability exists because configuration validation (sanitization) happens after deserialization but before the values are used, yet none of the sanitizers check this critical constraint that the runtime code depends on via the `NonZeroUsize!` macro.

### Citations

**File:** crates/aptos-infallible/src/nonzero.rs (L6-13)
```rust
macro_rules! NonZeroUsize {
    ($num:expr) => {
        NonZeroUsize!($num, "Must be non-zero")
    };
    ($num:expr, $message:literal) => {
        std::num::NonZeroUsize::new($num).expect($message)
    };
}
```

**File:** aptos-node/src/network.rs (L67-69)
```rust
        aptos_channel::Config::new(node_config.consensus.max_network_channel_size)
            .queue_style(QueueStyle::FIFO)
            .counters(&aptos_consensus::counters::PENDING_CONSENSUS_NETWORK_EVENTS),
```

**File:** aptos-node/src/network.rs (L85-86)
```rust
        aptos_channel::Config::new(node_config.dkg.max_network_channel_size)
            .queue_style(QueueStyle::FIFO),
```

**File:** aptos-node/src/network.rs (L102-103)
```rust
        aptos_channel::Config::new(node_config.jwk_consensus.max_network_channel_size)
            .queue_style(QueueStyle::FIFO),
```

**File:** aptos-node/src/network.rs (L118-120)
```rust
        aptos_channel::Config::new(node_config.mempool.max_network_channel_size)
            .queue_style(QueueStyle::KLAST) // TODO: why is this not FIFO?
            .counters(&aptos_mempool::counters::PENDING_MEMPOOL_NETWORK_EVENTS),
```

**File:** crates/channel/src/aptos_channel.rs (L240-241)
```rust
    let max_queue_size_per_key =
        NonZeroUsize!(max_queue_size_per_key, "aptos_channel cannot be of size 0");
```

**File:** config/src/config/consensus_config.rs (L503-532)
```rust
impl ConfigSanitizer for ConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Verify that the safety rules and quorum store configs are valid
        SafetyRulesConfig::sanitize(node_config, node_type, chain_id)?;
        QuorumStoreConfig::sanitize(node_config, node_type, chain_id)?;

        // Verify that the consensus-only feature is not enabled in mainnet
        if let Some(chain_id) = chain_id {
            if chain_id.is_mainnet() && is_consensus_only_perf_test_enabled() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "consensus-only-perf-test should not be enabled in mainnet!".to_string(),
                ));
            }
        }

        // Sender block limits must be <= receiver block limits
        Self::sanitize_send_recv_block_limits(&sanitizer_name, &node_config.consensus)?;

        // Quorum store batches must be <= consensus blocks
        Self::sanitize_batch_block_limits(&sanitizer_name, &node_config.consensus)?;

        Ok(())
    }
```

**File:** config/src/config/mempool_config.rs (L176-183)
```rust
impl ConfigSanitizer for MempoolConfig {
    fn sanitize(
        _node_config: &NodeConfig,
        _node_type: NodeType,
        _chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        Ok(()) // TODO: add reasonable verifications
    }
```

**File:** config/src/config/dkg_config.rs (L6-17)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct DKGConfig {
    pub max_network_channel_size: usize,
}

impl Default for DKGConfig {
    fn default() -> Self {
        Self {
            max_network_channel_size: 256,
        }
    }
```

**File:** config/src/config/jwk_consensus_config.rs (L6-17)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct JWKConsensusConfig {
    pub max_network_channel_size: usize,
}

impl Default for JWKConsensusConfig {
    fn default() -> Self {
        Self {
            max_network_channel_size: 256,
        }
    }
```

**File:** config/src/config/netbench_config.rs (L46-77)
```rust
impl ConfigSanitizer for NetbenchConfig {
    fn sanitize(
        node_config: &NodeConfig,
        _node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // If no netbench config is specified, there's nothing to do
        if node_config.netbench.is_none() {
            return Ok(());
        }

        // If netbench is disabled, there's nothing to do
        let netbench_config = node_config.netbench.unwrap();
        if !netbench_config.enabled {
            return Ok(());
        }

        // Otherwise, verify that netbench is not enabled in testnet or mainnet
        if let Some(chain_id) = chain_id {
            if chain_id.is_testnet() || chain_id.is_mainnet() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The netbench application should not be enabled in testnet or mainnet!"
                        .to_string(),
                ));
            }
        }

        Ok(())
    }
```
