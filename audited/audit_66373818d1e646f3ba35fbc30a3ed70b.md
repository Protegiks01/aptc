# Audit Report

## Title
Epoch Transition Denial of Service: Stale Batch Loading Causes Validator Node Panic During Restart

## Summary
The `populate_cache_and_gc_expired_batches_v1()` and `populate_cache_and_gc_expired_batches_v2()` functions in the quorum store batch management system load batches from ALL epochs without epoch filtering, only checking expiration timestamps. When a validator node restarts within the same epoch after an epoch transition, stale batches from previous epochs that haven't expired are loaded into memory and consume storage quotas. If quotas are exhausted, the node panics during initialization and cannot recover, creating a denial of service condition.

## Finding Description

The vulnerability exists in the batch store initialization logic. When `BatchStore::new()` is called with `is_new_epoch=false`, the system calls `populate_cache_and_gc_expired_batches_v1()` and `populate_cache_and_gc_expired_batches_v2()` to restore the in-memory cache from persistent storage. [1](#0-0) 

The critical flaw is that `get_all_batches()` returns ALL batches from the database without any epoch filtering: [2](#0-1) 

The `populate_cache_and_gc_expired_batches_v1()` function only filters by expiration time, NOT by epoch: [3](#0-2) 

Notice at lines 264-279: the code checks `if expiration < gc_timestamp` but does NOT check the batch epoch. Batches from previous epochs are loaded into the cache if they haven't expired yet. Line 278 contains `.expect("Storage limit exceeded upon BatchReader construction")` which panics if quota is exhausted.

The `is_new_epoch` flag is determined by checking if the latest committed ledger info marks an epoch end: [4](#0-3) 

**Attack Scenario:**

1. **Epoch N - Batch Creation**: A malicious validator (or even legitimate usage) creates many batches with long expiration times (e.g., 24 hours) in epoch N. These are stored in the quorum store database.

2. **Epoch Transition**: Epoch N ends and epoch N+1 begins. The epoch-ending block is committed.

3. **Progress in Epoch N+1**: Several blocks are committed in the new epoch. The latest ledger info no longer has `ends_epoch=true`.

4. **Validator Restart**: A validator node restarts (crash, maintenance, or forced restart). 

5. **Vulnerability Triggered**: 
   - `is_new_epoch = latest_ledger_info.ends_epoch()` returns `false` (line 244)
   - `populate_cache_and_gc_expired_batches_v1()` is called instead of the epoch-aware GC function
   - `get_all_batches()` retrieves batches from epoch N that haven't expired
   - These old batches are inserted into the cache, consuming quota
   - When quota is exhausted, `insert_to_cache()` returns an error
   - The `.expect()` on line 278 panics with "Storage limit exceeded upon BatchReader construction"
   - **The validator node crashes and cannot start up**

The quota system enforces strict limits: [5](#0-4) 

If `db_balance` or `batch_balance` is insufficient, the function returns an error which causes the panic.

In contrast, when `is_new_epoch=true`, the correct epoch-aware garbage collection runs: [6](#0-5) 

Notice lines 191-201: this function checks `if epoch < current_epoch` and deletes old batches, preventing the resource exhaustion issue.

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos bug bounty program criteria:

- **Validator node crashes**: Affected validators panic during startup and cannot recover without manual intervention (database deletion or waiting for batch expiration, potentially hours/days)
- **Network availability impact**: If multiple validators are affected simultaneously (common after epoch transitions when nodes restart for upgrades), this could degrade network liveness
- **API crashes**: The panic occurs during initialization, effectively making the validator node unavailable

The vulnerability breaks the **Resource Limits** invariant (#9: "All operations must respect gas, storage, and computational limits") by allowing stale batches from old epochs to consume quotas meant for current epoch operations.

While this doesn't directly cause consensus safety violations or fund loss, the availability impact is severe enough to warrant HIGH severity classification, particularly given that:
1. It can affect multiple validators simultaneously
2. Recovery requires manual intervention or extended downtime
3. It's easily triggerable after normal epoch transitions

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to occur in production:

1. **Natural Trigger Conditions**: Epoch transitions happen regularly in Aptos (when validator sets change). After an epoch transition, validators commonly restart for upgrades or maintenance. If a restart occurs after a few blocks have been committed in the new epoch, `is_new_epoch=false` is guaranteed.

2. **No Malicious Action Required**: While a malicious validator could deliberately create many long-expiring batches to increase impact, the vulnerability can trigger from normal operations if validators create batches with standard expiration times near epoch boundaries.

3. **Common Operational Pattern**: The scenario (epoch transition → blocks committed → validator restart) is a standard operational pattern, not an edge case.

4. **No Rate Limiting**: There are no checks preventing the loading of arbitrary numbers of old-epoch batches during initialization.

The default quotas make exploitation feasible:
- `db_quota`: 300,000,000 bytes (~300 MB)
- `batch_quota`: 300,000 batches

A malicious validator could easily exhaust these quotas by creating batches throughout epoch N.

## Recommendation

Add epoch filtering to `populate_cache_and_gc_expired_batches_v1()` and `populate_cache_and_gc_expired_batches_v2()` to match the behavior of the epoch-aware GC functions:

```rust
fn populate_cache_and_gc_expired_batches_v1(
    db: Arc<dyn QuorumStoreStorage>,
    current_epoch: u64,
    last_certified_time: u64,
    expiration_buffer_usecs: u64,
    batch_store: &BatchStore,
) {
    let db_content = db
        .get_all_batches()
        .expect("failed to read v1 data from db");
    
    info!(
        epoch = current_epoch,
        "QS: Read v1 batches from storage. Len: {}, Last Certified Time: {}",
        db_content.len(),
        last_certified_time
    );

    let mut expired_keys = Vec::new();
    let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
    
    for (digest, value) in db_content {
        let epoch = value.epoch();
        let expiration = value.expiration();

        trace!(
            "QS: Batchreader recovery content epoch {:?}, exp {:?}, digest {}",
            epoch,
            expiration,
            digest
        );

        // FIX: Check BOTH epoch and expiration
        if epoch < current_epoch || expiration < gc_timestamp {
            expired_keys.push(digest);
        } else {
            batch_store
                .insert_to_cache(&value.into())
                .expect("Storage limit exceeded upon BatchReader construction");
        }
    }

    info!(
        "QS: Batch store bootstrap expired keys len {}",
        expired_keys.len()
    );
    
    tokio::task::spawn_blocking(move || {
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    });
}
```

Apply the same fix to `populate_cache_and_gc_expired_batches_v2()` by checking `epoch < current_epoch` before inserting batches into the cache.

## Proof of Concept

**Reproduction Steps:**

1. **Setup (Epoch N)**: Run a validator node and create batches with 24-hour expiration times using the quorum store. Create enough batches to approach quota limits (e.g., 200,000 batches totaling ~200 MB).

2. **Trigger Epoch Transition**: Wait for or trigger an epoch change. Ensure the epoch-ending block is committed.

3. **Progress Epoch N+1**: Allow several blocks to be committed in epoch N+1 (at least 2-3 blocks after the epoch transition block).

4. **Restart Validator**: Restart the validator node. The node will:
   - Determine `is_new_epoch = false` (because latest block is not epoch-ending)
   - Call `populate_cache_and_gc_expired_batches_v1()`
   - Load all batches from epoch N that haven't expired
   - Attempt to insert them into cache
   - Exhaust quota if enough batches exist
   - Panic with "Storage limit exceeded upon BatchReader construction"

5. **Observe**: The validator node will crash during startup and cannot recover until batches expire or the database is manually cleared.

**Expected Behavior**: The node should only load batches from the current epoch (N+1), ignoring batches from epoch N regardless of expiration time.

**Actual Behavior**: The node loads batches from all epochs, panics on quota exhaustion, and cannot start.

**Notes:**
- This affects both V1 and V2 batch schemas
- The same vulnerability exists in both `populate_cache_and_gc_expired_batches_v1()` and `populate_cache_and_gc_expired_batches_v2()`
- Manual recovery requires either waiting for batch expiration or deleting the quorum store database

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L64-84)
```rust
    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L156-176)
```rust
        if is_new_epoch {
            tokio::task::spawn_blocking(move || {
                Self::gc_previous_epoch_batches_from_db_v1(db_clone.clone(), epoch);
                Self::gc_previous_epoch_batches_from_db_v2(db_clone, epoch);
            });
        } else {
            Self::populate_cache_and_gc_expired_batches_v1(
                db_clone.clone(),
                epoch,
                last_certified_time,
                expiration_buffer_usecs,
                &batch_store,
            );
            Self::populate_cache_and_gc_expired_batches_v2(
                db_clone,
                epoch,
                last_certified_time,
                expiration_buffer_usecs,
                &batch_store,
            );
        }
```

**File:** consensus/src/quorum_store/batch_store.rs (L181-210)
```rust
    fn gc_previous_epoch_batches_from_db_v1(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db.get_all_batches().expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L245-290)
```rust
    fn populate_cache_and_gc_expired_batches_v1(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();

            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value.into())
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L103-108)
```rust
    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>> {
        let mut iter = self.db.iter::<BatchSchema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfo>>>>()
    }
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L244-266)
```rust
        let is_new_epoch = latest_ledger_info_with_sigs.ledger_info().ends_epoch();

        let batch_requester = BatchRequester::new(
            self.epoch,
            self.author,
            self.config.batch_request_num_peers,
            self.config.batch_request_retry_limit,
            self.config.batch_request_retry_interval_ms,
            self.config.batch_request_rpc_timeout_ms,
            self.network_sender.clone(),
            self.verifier.clone(),
        );
        let batch_store = Arc::new(BatchStore::new(
            self.epoch,
            is_new_epoch,
            last_committed_timestamp,
            self.quorum_store_storage.clone(),
            self.config.memory_quota,
            self.config.db_quota,
            self.config.batch_quota,
            signer,
            Duration::from_secs(60).as_micros() as u64,
        ));
```
