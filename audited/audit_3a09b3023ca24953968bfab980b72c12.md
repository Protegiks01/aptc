# Audit Report

## Title
Round Rollback Vulnerability in sync_for_duration() Due to Missing Monotonicity Check

## Summary
The `sync_for_duration()` function in `consensus/src/state_computer.rs` unconditionally updates `latest_logical_time` with the synced ledger's epoch and round without verifying that it moves forward. This contrasts with `sync_to_target()`, which explicitly validates round monotonicity before accepting sync results. This missing validation creates a path for round rollback if state sync returns stale data due to network issues, storage inconsistencies, or other system bugs.

## Finding Description
The consensus layer maintains `latest_logical_time` (a `LogicalTime` struct containing epoch and round) to track committed consensus state. This value is protected by `write_mutex` and updated during state synchronization operations. [1](#0-0) 

In `sync_to_target()`, there is explicit validation that prevents accepting a target with lower epoch/round than already committed: [2](#0-1) 

However, `sync_for_duration()` lacks this critical check and unconditionally updates `latest_logical_time` to whatever the state sync returns: [3](#0-2) 

The function flow:
1. Acquires lock on `latest_logical_time`
2. Calls state sync to synchronize for a specified duration
3. **Unconditionally** updates `latest_logical_time` to the synced ledger's epoch/round
4. No validation that synced epoch/round â‰¥ current epoch/round

This asymmetry creates a vulnerability where `sync_for_duration()` could accept and commit to a ledger info with a lower round than previously recorded, violating the critical consensus invariant of round monotonicity.

**Attack Scenario:**
1. Consensus observer uses `sync_to_target()` to sync to a commit decision at epoch E, round 1000
2. `latest_logical_time` is updated to (E, 1000) 
3. Observer enters fallback mode and calls `sync_for_duration()`
4. Due to network partitioning, slow peers, or storage inconsistencies, state sync returns ledger info at epoch E, round 500
5. `sync_for_duration()` unconditionally updates `latest_logical_time` from (E, 1000) to (E, 500)
6. Round has rolled back from 1000 to 500

The consensus observer also unconditionally updates its root without validation: [4](#0-3) 

Compare this with the commit sync handler which has explicit checks: [5](#0-4) 

The root update function itself performs no validation: [6](#0-5) 

## Impact Explanation
This vulnerability breaks the **Consensus Safety** invariant. Round monotonicity is fundamental to BFT consensus protocols - rounds must only move forward within an epoch. If rounds can roll back:

1. **Double-spending potential**: Transactions committed in rounds 501-1000 could be replaced with different transactions
2. **Consensus safety violation**: Different nodes could have divergent views of committed state for the same rounds
3. **State inconsistency**: The node's committed state no longer matches the canonical chain
4. **Fork creation risk**: Could enable chain splits under Byzantine conditions

This qualifies as **Critical Severity** under the Aptos bug bounty program:
- Consensus/Safety violations (direct match)
- Potential loss of funds through double-spending
- State inconsistency requiring manual intervention

## Likelihood Explanation
**Medium-to-High Likelihood:**

The vulnerability is triggered when:
1. Consensus observer enters fallback mode (happens when node falls behind)
2. `sync_for_duration()` is invoked through the fallback mechanism
3. State sync returns stale ledger info (possible due to network issues, storage lag, or bugs)

While state sync is designed to sync forward from the highest synced version, several scenarios could lead to stale data:
- Network partitions preventing access to up-to-date peers
- Storage inconsistencies between `latest_logical_time` and actual committed data
- Timing windows where sync completes before full commit
- Bugs in state sync logic that weren't caught due to the missing validation layer

The lack of defensive validation means ANY bug in the state sync pipeline could trigger this vulnerability. Defense-in-depth principles dictate that each layer should validate its inputs, but `sync_for_duration()` blindly trusts the state sync result.

## Recommendation
Add round monotonicity validation in `sync_for_duration()` matching the check in `sync_to_target()`:

```rust
async fn sync_for_duration(
    &self,
    duration: Duration,
) -> Result<LedgerInfoWithSignatures, StateSyncError> {
    let mut latest_logical_time = self.write_mutex.lock().await;
    
    // ... existing code ...
    
    // Update the latest logical time
    if let Ok(latest_synced_ledger_info) = &result {
        let ledger_info = latest_synced_ledger_info.ledger_info();
        let synced_logical_time = LogicalTime::new(ledger_info.epoch(), ledger_info.round());
        
        // ADD THIS CHECK:
        if synced_logical_time < *latest_logical_time {
            warn!(
                "Sync for duration result {:?} is lower than already committed logical time {:?}. Rejecting stale sync.",
                synced_logical_time, *latest_logical_time
            );
            // Don't update latest_logical_time with stale data
        } else {
            *latest_logical_time = synced_logical_time;
        }
    }
    
    // ... rest of code ...
}
```

Additionally, add validation in the consensus observer's fallback sync handler:

```rust
async fn process_fallback_sync_notification(
    &mut self,
    latest_synced_ledger_info: LedgerInfoWithSignatures,
) {
    let ledger_info = latest_synced_ledger_info.ledger_info();
    let epoch = ledger_info.epoch();
    let round = ledger_info.round();
    
    // ADD: Check against current root
    let current_root = self.observer_block_data.lock().root();
    let current_epoch = current_root.ledger_info().epoch();
    let current_round = current_root.ledger_info().round();
    
    if (epoch, round) < (current_epoch, current_round) {
        warn!(
            "Fallback sync result epoch {}, round {} is behind current root epoch {}, round {}. Ignoring stale sync.",
            epoch, round, current_epoch, current_round
        );
        self.state_sync_manager.clear_active_fallback_sync();
        return;
    }
    
    // ... rest of existing code ...
}
```

## Proof of Concept
The following demonstrates the vulnerability through a sequence of sync operations:

```rust
// Pseudocode demonstrating the vulnerability
#[tokio::test]
async fn test_round_rollback_in_sync_for_duration() {
    // Setup: Node starts with epoch 10, round 500
    let mut execution_proxy = ExecutionProxy::new(...);
    
    // Simulate sync_to_target advancing to round 1000
    let high_round_target = create_ledger_info(epoch: 10, round: 1000, version: 50000);
    execution_proxy.sync_to_target(high_round_target).await.unwrap();
    
    // Verify latest_logical_time is now (10, 1000)
    assert_eq!(execution_proxy.get_logical_time(), LogicalTime::new(10, 1000));
    
    // Setup mock state sync to return stale data (simulating network/storage issue)
    let stale_ledger = create_ledger_info(epoch: 10, round: 500, version: 30000);
    mock_state_sync_notifier.set_sync_for_duration_result(stale_ledger);
    
    // Call sync_for_duration (as would happen in fallback mode)
    let result = execution_proxy.sync_for_duration(Duration::from_secs(5)).await.unwrap();
    
    // VULNERABILITY: latest_logical_time rolled back from 1000 to 500
    assert_eq!(execution_proxy.get_logical_time(), LogicalTime::new(10, 500));
    
    // This violates round monotonicity!
    // Rounds should never decrease: 1000 -> 500 is a rollback
}
```

The test demonstrates that `sync_for_duration()` accepts stale data without validation, causing round rollback. In contrast, `sync_to_target()` would reject the same stale target due to its monotonicity check.

**Note:** A complete working PoC requires mocking the state sync infrastructure, but the code flow clearly shows the missing validation that enables this vulnerability.

### Citations

**File:** consensus/src/state_computer.rs (L27-36)
```rust
#[derive(Clone, Copy, Debug, Eq, PartialEq, PartialOrd, Ord, Hash)]
struct LogicalTime {
    epoch: u64,
    round: Round,
}

impl LogicalTime {
    pub fn new(epoch: u64, round: Round) -> Self {
        Self { epoch, round }
    }
```

**File:** consensus/src/state_computer.rs (L159-163)
```rust
        if let Ok(latest_synced_ledger_info) = &result {
            let ledger_info = latest_synced_ledger_info.ledger_info();
            let synced_logical_time = LogicalTime::new(ledger_info.epoch(), ledger_info.round());
            *latest_logical_time = synced_logical_time;
        }
```

**File:** consensus/src/state_computer.rs (L188-194)
```rust
        if *latest_logical_time >= target_logical_time {
            warn!(
                "State sync target {:?} is lower than already committed logical time {:?}",
                target_logical_time, *latest_logical_time
            );
            return Ok(());
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L947-950)
```rust
        // Update the root with the latest synced ledger info
        self.observer_block_data
            .lock()
            .update_root(latest_synced_ledger_info);
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L1002-1010)
```rust
        if (synced_epoch, synced_round) < (block_data_epoch, block_data_round) {
            info!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Ignoring old commit sync notification for epoch: {}, round: {}! Current root: {:?}",
                    synced_epoch, synced_round, block_data_root
                ))
            );
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L299-302)
```rust
    /// Updates the root ledger info
    pub fn update_root(&mut self, new_root: LedgerInfoWithSignatures) {
        self.root = new_root;
    }
```
