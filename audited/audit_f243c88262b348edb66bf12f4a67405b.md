# Audit Report

## Title
Module Cache Size Miscalculation Allows Memory Exhaustion via Serialized-to-Deserialized Expansion

## Summary
The `GlobalModuleCache` tracks cache size using only the serialized module bytes length from `AptosModuleExtension`, but the actual memory consumption includes the deserialized `CompiledModule` and verified `Module` structures with extensive runtime data. This allows attackers to bypass the 1GB cache limit by publishing modules that expand significantly when deserialized, potentially causing validator node memory exhaustion.

## Finding Description
The vulnerability exists in how the module cache calculates its total size. The cache is designed to enforce a memory limit (default 1GB) to prevent resource exhaustion. [1](#0-0) 

The size calculation relies on the `WithSize` trait bound on the extension type `E`. For `AptosModuleExtension`, this returns the serialized module bytes length: [2](#0-1) [3](#0-2) 

The cache size is incremented using this value: [4](#0-3) 

However, the cache actually stores `Arc<ModuleCode<CompiledModule, Module, AptosModuleExtension>>`: [5](#0-4) 

The `Module` struct contains extensive runtime data structures that can be significantly larger than serialized bytes: [6](#0-5) 

When modules are verified, the size passed to `Module::new()` comes from the extension's serialized size: [7](#0-6) 

**Attack Flow:**
1. Attacker publishes modules under the 64KB serialized limit that contain many functions, structs, generic instantiations, and signatures
2. These modules expand 5-10x when deserialized into `CompiledModule` and `Module` structures with all their Vec, HashMap, and Arc allocations
3. Cache size check only validates against serialized size (thinks cache is ~100MB)
4. Actual memory consumption is much higher (~500MB+)
5. Multiple attackers or coordinated modules cause validator OOM

## Impact Explanation
This is a **High severity** vulnerability per the Aptos bug bounty criteria. It enables:

- **Validator node slowdowns**: Memory pressure causes performance degradation
- **Potential consensus disruption**: If multiple validators OOM simultaneously, consensus could be affected
- **Resource limit violation**: Breaks the invariant that "All operations must respect gas, storage, and computational limits"

The default cache limit is 1GB: [8](#0-7) 

With a 5-10x expansion ratio, attackers can cause actual memory usage of 5-10GB while the cache accounting shows only 1GB, potentially exhausting node memory.

## Likelihood Explanation
**Likelihood: Medium to High**

- Module publishing is permissionless - any user can publish modules
- Individual modules are limited to 64KB serialized (MAX_MODULE_SIZE)
- No additional validation of in-memory expansion ratio
- Expansion ratio of 5-10x is realistic for modules with many functions/structs/instantiations
- Attack requires sustained effort to publish many modules, but is feasible
- The Aptos framework itself (when loaded) demonstrates that modules can have substantial in-memory footprint

## Recommendation
The cache size tracking should account for the actual in-memory size of cached modules, not just serialized bytes. Two approaches:

**Approach 1:** Track actual allocated memory by estimating `Module` size including all internal structures. Modify `Module::new()` to compute an estimated memory footprint and store it.

**Approach 2:** Use a more conservative multiplier on serialized size (e.g., 10x) as an approximation of in-memory expansion when calculating cache size.

**Suggested Fix:**
```rust
// In code_cache_global.rs, replace:
self.size += module.extension().size_in_bytes();

// With:
const EXPANSION_MULTIPLIER: usize = 10;
self.size += module.extension().size_in_bytes() * EXPANSION_MULTIPLIER;
```

And update the configuration comments to reflect this is an approximation.

Better yet, compute actual memory usage by traversing the Module's data structures and summing allocations.

## Proof of Concept
```move
// Attacker publishes modules designed for maximum expansion
// Example: Module with many simple functions (compact bytecode, large runtime structures)

module attacker::expansion_bomb {
    // 1000 simple functions - each serializes to ~10 bytes but creates 
    // a full Function struct (~100+ bytes with Arc, vectors, etc)
    public fun f0() {}
    public fun f1() {}
    // ... repeat for f2 through f999
    
    // Many struct definitions with generic parameters
    struct S0<T> has drop { f: T }
    struct S1<T1, T2> has drop { f1: T1, f2: T2 }
    // ... repeat with increasing type parameters
    
    // Each creates multiple instantiations in the cache
    // Serialized size: ~30-40KB
    // In-memory size: 300-400KB (10x expansion)
}
```

**Rust Reproduction Steps:**
1. Create 100 such modules, each ~50KB serialized
2. Publish them sequentially to the blockchain
3. Cache accounting shows: 100 * 50KB = 5MB
4. Actual memory usage: 100 * 500KB = 50MB (10x actual consumption)
5. Scale to 1000 modules: Cache thinks 50MB, actual usage 500MB
6. Scale to 10,000 modules: Cache thinks 500MB, actual usage 5GB â†’ OOM on many validators

**Notes**
The vulnerability is subtle because the cache size tracking is correct for what it measures (serialized bytes), but this is not representative of actual memory consumption. The expansion ratio depends on module complexity - modules with many functions, structs, and generic instantiations will have higher ratios. The `compute-module-expansion-size` tool in the codebase confirms that expansion size is a real concern tracked by the project. [9](#0-8)

### Citations

**File:** aptos-move/block-executor/src/code_cache_global_manager.rs (L80-80)
```rust
    E: WithSize,
```

**File:** third_party/move/move-vm/types/src/code/cache/types.rs (L14-22)
```rust
pub trait WithSize {
    fn size_in_bytes(&self) -> usize;
}

impl<T: WithBytes> WithSize for T {
    fn size_in_bytes(&self) -> usize {
        self.bytes().len()
    }
}
```

**File:** types/src/vm/modules.rs (L12-44)
```rust
pub struct AptosModuleExtension {
    /// Serialized representation of the module.
    bytes: Bytes,
    /// Module's hash.
    hash: [u8; 32],
    /// The state value metadata associated with the module, when read from or
    /// written to storage.
    state_value_metadata: StateValueMetadata,
}

impl AptosModuleExtension {
    /// Creates new extension based on [StateValue].
    pub fn new(state_value: StateValue) -> Self {
        let (state_value_metadata, bytes) = state_value.unpack();
        let hash = sha3_256(&bytes);
        Self {
            bytes,
            hash,
            state_value_metadata,
        }
    }

    /// Returns the state value metadata stored in extension.
    pub fn state_value_metadata(&self) -> &StateValueMetadata {
        &self.state_value_metadata
    }
}

impl WithBytes for AptosModuleExtension {
    fn bytes(&self) -> &Bytes {
        &self.bytes
    }
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L89-97)
```rust
pub struct GlobalModuleCache<K, D, V, E> {
    /// Module cache containing the verified code.
    module_cache: HashMap<K, Entry<D, V, E>>,
    /// Sum of serialized sizes (in bytes) of all cached modules.
    size: usize,
    /// Cached layouts of structs or enums. This cache stores roots only and is invalidated when
    /// modules are published.
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L216-216)
```rust
                self.size += module.extension().size_in_bytes();
```

**File:** third_party/move/move-vm/runtime/src/loader/modules.rs (L49-106)
```rust
#[derive(Clone, Debug)]
pub struct Module {
    id: ModuleId,

    pub(crate) interned_id: InternedModuleId,

    // size in bytes
    #[allow(dead_code)]
    pub(crate) size: usize,

    // primitive pools
    pub(crate) module: Arc<CompiledModule>,

    //
    // types as indexes into the Loader type list
    //
    pub(crate) structs: Vec<StructDef>,
    // materialized instantiations, whether partial or not
    pub(crate) struct_instantiations: Vec<StructInstantiation>,
    // same for struct variants
    pub(crate) struct_variant_infos: Vec<StructVariantInfo>,
    pub(crate) struct_variant_instantiation_infos: Vec<StructVariantInfo>,

    // functions as indexes into the Loader function list
    // That is effectively an indirection over the ref table:
    // the instruction carries an index into this table which contains the index into the
    // glabal table of functions. No instantiation of generic functions is saved into
    // the global table.
    pub(crate) function_refs: Vec<FunctionHandle>,
    pub(crate) function_defs: Vec<Arc<Function>>,
    // materialized instantiations, whether partial or not
    pub(crate) function_instantiations: Vec<FunctionInstantiation>,

    // fields as a pair of index, first to the type, second to the field position in that type
    pub(crate) field_handles: Vec<FieldHandle>,
    // materialized instantiations, whether partial or not
    pub(crate) field_instantiations: Vec<FieldInstantiation>,
    // Information about variant fields.
    pub(crate) variant_field_infos: Vec<VariantFieldInfo>,
    pub(crate) variant_field_instantiation_infos: Vec<VariantFieldInfo>,

    // function name to index into the Loader function list.
    // This allows a direct access from function name to `Function`
    pub(crate) function_map: HashMap<Identifier, usize>,
    // struct name to index into the module's type list
    // This allows a direct access from struct name to `Struct`
    pub(crate) struct_map: HashMap<Identifier, usize>,

    // a map of single-token signature indices to type.
    // Single-token signatures are usually indexed by the `SignatureIndex` in bytecode. For example,
    // `VecMutBorrow(SignatureIndex)`, the `SignatureIndex` maps to a single `SignatureToken`, and
    // hence, a single type.
    pub(crate) single_signature_token_map: BTreeMap<SignatureIndex, Type>,

    // Friends of this module. Needed for re-entrancy visibility checks if lazy loading is enabled.
    // Particularly, if a callee has friend visibility, the caller's module must be in this set.
    pub(crate) friends: BTreeSet<ModuleId>,
}
```

**File:** third_party/move/move-vm/runtime/src/storage/module_storage.rs (L377-381)
```rust
    let locally_verified_code = runtime_environment.build_locally_verified_module(
        module.code().deserialized().clone(),
        module.extension().size_in_bytes(),
        module.extension().hash(),
    )?;
```

**File:** types/src/block_executor/config.rs (L15-37)
```rust
    /// The maximum size of module cache (the sum of serialized sizes of all cached modules in
    /// bytes).
    pub max_module_cache_size_in_bytes: usize,
    /// The maximum size (in terms of entries) of struct name re-indexing map stored in the runtime
    /// environment.
    pub max_struct_name_index_map_num_entries: usize,
    /// The maximum number of types to intern.
    pub max_interned_tys: usize,
    /// The maximum number of type vectors to intern.
    pub max_interned_ty_vecs: usize,
    /// The maximum number of layout entries.
    pub max_layout_cache_size: usize,
    /// The maximum number of module IDs to intern.
    pub max_interned_module_ids: usize,
}

impl Default for BlockExecutorModuleCacheLocalConfig {
    fn default() -> Self {
        Self {
            prefetch_framework_code: true,
            // Use 1Gb for now, should be large enough to cache all mainnet modules (at the time
            // of writing this comment, 13.11.24).
            max_module_cache_size_in_bytes: 1024 * 1024 * 1024,
```

**File:** tools/compute-module-expansion-size/src/main.rs (L56-73)
```rust
#[derive(Debug, Clone)]
struct ModuleInfo {
    size: usize,
    expansion_size: u64,
}

fn extract_module_info_single(bytes: &[u8]) -> Result<(ModuleId, ModuleInfo)> {
    let res = CompiledModule::deserialize(bytes);
    let module = res?;

    let expansion_size =
        move_binary_format::check_complexity::check_module_complexity(&module, u64::MAX).unwrap();

    Ok((module.self_id().clone(), ModuleInfo {
        size: bytes.len(),
        expansion_size,
    }))
}
```
