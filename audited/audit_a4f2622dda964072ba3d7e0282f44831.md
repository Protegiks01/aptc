# Audit Report

## Title
Peer Monitoring Service Thread Crash Due to Unhandled Panics in Network Stream Processing

## Summary
The peer monitoring service server lacks panic boundaries around its main event loop. If the network request stream panics during polling, the entire monitoring service task crashes without recovery, requiring manual intervention to restore monitoring functionality.

## Finding Description

The peer monitoring service server implements a critical event loop that processes incoming monitoring requests from network peers. [1](#0-0) 

This loop calls `poll_next()` on the network request stream: [2](#0-1) 

The underlying network event stream contains multiple panic points that are not caught:

1. **JoinError panics in deserialization tasks**: The network event stream spawns blocking tasks for message deserialization and uses `.expect()` to unwrap their results, which panics on JoinError. [3](#0-2) 

2. **Double unwrap on Arc handling**: The message-to-event conversion performs unsafe unwrapping operations that can panic if invariants are violated. [4](#0-3) 

**Comparison with other critical services**: Other critical services in the Aptos codebase implement panic boundaries:

- VM Validator wraps transaction validation in `catch_unwind` to prevent panics from crashing mempool validation. [5](#0-4) 

- API runtime uses `CatchPanic` middleware with custom panic handlers. [6](#0-5) 

The peer monitoring service lacks any such protection, making it vulnerable to panics in the network layer.

## Impact Explanation

**Severity: High** (per Aptos Bug Bounty: "API crashes, Validator node slowdowns")

When the monitoring service crashes:
- The service task terminates permanently and does not automatically restart
- Peers cannot query this node for monitoring information (network topology, node information, latency measurements)
- Manual intervention (service restart) is required to restore functionality
- Network operators lose visibility into this node's health and connectivity

While the peer monitoring service is not consensus-critical, it is classified as a service API that can crash, which qualifies as High severity under the bug bounty program.

## Likelihood Explanation

**Likelihood: Low-Medium**

The panic requires specific edge cases:
- Runtime shutdown during message processing (causing JoinError)
- Internal bugs in network message handling causing task panics
- Race conditions in Arc reference handling

However, the lack of defensive programming means that any future bug in the network layer could trigger this vulnerability without warning.

## Recommendation

Implement a panic boundary around the main event loop or network stream processing, consistent with other critical services:

```rust
// In peer-monitoring-service/server/src/lib.rs, modify the start() method:
pub async fn start(mut self) {
    while let Some(network_request) = {
        // Wrap stream polling in catch_unwind
        match std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
            futures::executor::block_on(async {
                self.network_requests.next().await
            })
        })) {
            Ok(Some(req)) => Some(req),
            Ok(None) => None,
            Err(panic_err) => {
                error!("Peer monitoring service stream panicked: {:?}", panic_err);
                // Log and continue processing
                continue;
            }
        }
    } {
        // Process request...
    }
}
```

Alternatively, wrap the entire task spawn in a panic handler: [7](#0-6) 

## Proof of Concept

A proof of concept would require triggering a runtime shutdown or internal network layer bug during message processing. However, this cannot be reliably demonstrated through external API calls alone, as it depends on internal runtime state.

**Conceptual PoC scenario:**
1. Node is processing peer monitoring requests
2. Runtime begins shutdown while a spawn_blocking deserialization task is active
3. Task is cancelled, returning JoinError
4. `.expect("JoinError from spawn blocking")` panics
5. Panic propagates through stream to `poll_next()`
6. Main event loop crashes with no recovery

---

**Notes**

The core finding is validated: the peer monitoring service definitively lacks panic handling that exists in other critical services. However, the practical exploitability is limited because triggering the panic requires internal runtime conditions rather than direct attacker control through malicious network messages.

### Citations

**File:** peer-monitoring-service/server/src/lib.rs (L84-123)
```rust
    pub async fn start(mut self) {
        // Handle the service requests
        while let Some(network_request) = self.network_requests.next().await {
            // Log the request
            let peer_network_id = network_request.peer_network_id;
            let peer_monitoring_service_request = network_request.peer_monitoring_service_request;
            let response_sender = network_request.response_sender;
            trace!(LogSchema::new(LogEntry::ReceivedPeerMonitoringRequest)
                .request(&peer_monitoring_service_request)
                .message(&format!(
                    "Received peer monitoring request. Peer: {:?}",
                    peer_network_id,
                )));

            // All handler methods are currently CPU-bound so we want
            // to spawn on the blocking thread pool.
            let base_config = self.base_config.clone();
            let peers_and_metadata = self.peers_and_metadata.clone();
            let start_time = self.start_time;
            let storage = self.storage.clone();
            let time_service = self.time_service.clone();
            self.bounded_executor
                .spawn_blocking(move || {
                    let response = Handler::new(
                        base_config,
                        peers_and_metadata,
                        start_time,
                        storage,
                        time_service,
                    )
                    .call(
                        peer_network_id.network_id(),
                        peer_monitoring_service_request,
                    );
                    log_monitoring_service_response(&response);
                    response_sender.send(response);
                })
                .await;
        }
    }
```

**File:** peer-monitoring-service/server/src/network.rs (L90-92)
```rust
    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        Pin::new(&mut self.network_request_stream).poll_next(cx)
    }
```

**File:** network/framework/src/protocols/network/mod.rs (L217-234)
```rust
        let data_event_stream = peer_mgr_notifs_rx.map(|notification| {
            tokio::task::spawn_blocking(move || received_message_to_event(notification))
        });

        let data_event_stream: Pin<
            Box<dyn Stream<Item = Event<TMessage>> + Send + Sync + 'static>,
        > = if allow_out_of_order_delivery {
            Box::pin(
                data_event_stream
                    .buffer_unordered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        } else {
            Box::pin(
                data_event_stream
                    .buffered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
```

**File:** network/framework/src/protocols/network/mod.rs (L288-293)
```rust
        NetworkMessage::RpcRequest(rpc_req) => {
            crate::counters::inbound_queue_delay_observe(rpc_req.protocol_id, dt_seconds);
            let rpc_replier = Arc::into_inner(rpc_replier.unwrap()).unwrap();
            request_to_network_event(peer_id, &rpc_req)
                .map(|msg| Event::RpcRequest(peer_id, msg, rpc_req.protocol_id, rpc_replier))
        },
```

**File:** vm-validator/src/vm_validator.rs (L155-170)
```rust
        let result = std::panic::catch_unwind(move || {
            let vm_validator_locked = vm_validator.lock().unwrap();

            use aptos_vm::VMValidator;
            let vm = AptosVM::new(&vm_validator_locked.state.environment);
            vm.validate_transaction(
                txn,
                &vm_validator_locked.state.state_view,
                &vm_validator_locked.state,
            )
        });
        if let Err(err) = &result {
            error!("VMValidator panicked: {:?}", err);
        }
        result.map_err(|_| anyhow::anyhow!("panic validating transaction"))
    }
```

**File:** api/src/runtime.rs (L256-256)
```rust
            .with(CatchPanic::new().with_handler(panic_handler))
```

**File:** aptos-node/src/services.rs (L249-249)
```rust
    peer_monitoring_service_runtime.spawn(peer_monitoring_server.start());
```
