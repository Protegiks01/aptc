# Audit Report

## Title
Disk Space Exhaustion Vulnerability in Table Info Snapshot Restore Function

## Summary
The `restore_db_snapshot()` function in the indexer-grpc-table-info service downloads snapshots from Google Cloud Storage without checking available disk space, which can cause disk exhaustion and node failure during restore operations.

## Finding Description

The `restore_db_snapshot()` function downloads potentially massive blockchain database snapshots without any disk space validation. [1](#0-0) 

The function downloads a GCS object as a stream and writes it directly to disk chunk by chunk, with no pre-flight disk space check. [2](#0-1) 

After download, the function unpacks the tar.gz archive, which requires additional disk space (typically 3-10x the compressed size). [3](#0-2) 

During unpacking, both the compressed tar.gz file and the uncompressed database exist simultaneously on disk. The total required space is: compressed file size + (3-10x compressed size) for uncompressed data.

**Attack Scenario:**
1. Node operator configures restore mode with a GCS bucket containing a large snapshot [4](#0-3) 
2. Node attempts to restore the snapshot during startup
3. Download fills available disk space
4. Either: download fails mid-stream leaving corrupted partial file, unpacking fails due to insufficient space, or system crashes with disk-full errors
5. Node cannot start, causing service unavailability

This breaks **Invariant #9 (Resource Limits)**: "All operations must respect gas, storage, and computational limits" - disk space is a critical resource that must be validated before large operations.

## Impact Explanation

This qualifies as **HIGH severity** per Aptos bug bounty criteria:
- **API crashes**: The indexer-grpc-table-info service fails to start, preventing API functionality
- **Validator node slowdowns**: Node cannot properly initialize its table info database
- **Significant protocol violations**: Violates resource limit invariants

The impact includes:
- Node service unavailability (cannot start)
- Potential database corruption from incomplete writes
- Requires manual intervention to recover (delete partial files, add disk space)
- Affects all nodes using the Restore mode feature

While this doesn't directly cause consensus violations or fund loss, it creates a critical availability issue for fullnode operators.

## Likelihood Explanation

**Current Likelihood: N/A** - The function exists but is not currently called in the codebase. Search results confirm no invocation of `restore_db_snapshot()` exists. [5](#0-4) 

**Future Likelihood (when implemented): HIGH**
- Blockchain databases routinely grow to hundreds of GBs or TBs
- Operators may have insufficient disk space for full restore
- The feature is documented and intended for use [6](#0-5) 
- No warning or validation exists to prevent misconfiguration

## Recommendation

**Pre-flight Disk Space Validation:**

Before downloading, check available disk space and estimate required space based on GCS object metadata. The codebase already has disk space utilities available. [7](#0-6) 

**Recommended Fix:**

```rust
pub async fn restore_db_snapshot(
    &self,
    chain_id: u64,
    metadata: BackupRestoreMetadata,
    db_path: PathBuf,
    base_path: PathBuf,
) -> anyhow::Result<()> {
    assert!(metadata.chain_id == chain_id, "Chain ID mismatch.");

    let epoch = metadata.epoch;
    let epoch_based_filename = generate_blob_name(chain_id, epoch);

    // NEW: Get object metadata to check size
    let object_metadata = self.gcs_client.get_object_metadata(
        &GetObjectRequest {
            bucket: self.bucket_name.clone(),
            object: epoch_based_filename.clone(),
            ..Default::default()
        }
    ).await?;
    
    let snapshot_size = object_metadata.size;
    
    // NEW: Check available disk space (conservative estimate: need 10x compressed size)
    let required_space = snapshot_size * 10;
    let available_space = Self::get_available_disk_space(&base_path)?;
    
    if available_space < required_space {
        anyhow::bail!(
            "Insufficient disk space for restore. Required: {} bytes, Available: {} bytes",
            required_space, available_space
        );
    }
    
    // Continue with existing download logic...
}

fn get_available_disk_space(path: &PathBuf) -> anyhow::Result<u64> {
    use sysinfo::{DiskExt, System, SystemExt};
    let mut system = System::new();
    system.refresh_disks_list();
    system.refresh_disks();
    
    for disk in system.disks() {
        if path.starts_with(disk.mount_point()) {
            return Ok(disk.available_space());
        }
    }
    anyhow::bail!("Could not determine available disk space for path: {:?}", path)
}
```

**Additional safeguards:**
1. Add progressive disk space checks during download
2. Implement cleanup on failure (delete partial files)
3. Add configuration parameter for minimum required free space
4. Log warnings when disk space is low but sufficient

## Proof of Concept

**Note:** This function is not currently invoked in the codebase, so a practical PoC cannot be demonstrated until the restore functionality is fully implemented.

**Conceptual PoC:**

```rust
#[tokio::test]
async fn test_disk_space_exhaustion_during_restore() {
    // Setup: Create a test environment with limited disk space
    let temp_dir = tempfile::tempdir().unwrap();
    let db_path = temp_dir.path().join("db");
    let base_path = temp_dir.path().to_path_buf();
    
    // Create a mock GCS bucket with a 10GB snapshot
    let large_snapshot_size = 10 * 1024 * 1024 * 1024u64; // 10GB
    
    // Simulate insufficient disk space (only 5GB available)
    // This would require mocking the filesystem or using a limited tmpfs mount
    
    let operator = GcsBackupRestoreOperator::new("test-bucket".to_string()).await;
    let metadata = BackupRestoreMetadata::new(1, 100);
    
    // Attempt restore - should fail with insufficient disk space
    let result = operator.restore_db_snapshot(1, metadata, db_path, base_path).await;
    
    // Expected: Should fail with clear error message about disk space
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("disk space"));
}
```

## Notes

**Current Status:** This vulnerability exists in the codebase but is not currently exploitable because the `restore_db_snapshot()` function is never called. The runtime bootstrap only handles Backup mode, not Restore mode. However, the Restore mode is documented as a feature and will likely be implemented in the future, at which point this vulnerability will become active.

**Recommendation Priority:** Implement the fix before enabling the Restore functionality to prevent future availability incidents.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/backup_restore/gcs.rs (L264-314)
```rust
    pub async fn restore_db_snapshot(
        &self,
        chain_id: u64,
        metadata: BackupRestoreMetadata,
        db_path: PathBuf,
        base_path: PathBuf,
    ) -> anyhow::Result<()> {
        assert!(metadata.chain_id == chain_id, "Chain ID mismatch.");

        let epoch = metadata.epoch;
        let epoch_based_filename = generate_blob_name(chain_id, epoch);

        match self
            .gcs_client
            .download_streamed_object(
                &GetObjectRequest {
                    bucket: self.bucket_name.clone(),
                    object: epoch_based_filename.clone(),
                    ..Default::default()
                },
                &Range::default(),
            )
            .await
        {
            Ok(mut stream) => {
                // Create a temporary file and write the stream to it directly
                let temp_file_name = "snapshot.tar.gz";
                let temp_file_path = base_path.join(temp_file_name);
                let temp_file_path_clone = temp_file_path.clone();
                let mut temp_file = File::create(&temp_file_path_clone).await?;
                while let Some(chunk) = stream.next().await {
                    match chunk {
                        Ok(data) => temp_file.write_all(&data).await?,
                        Err(e) => return Err(anyhow::Error::new(e)),
                    }
                }
                temp_file.sync_all().await?;

                // Spawn blocking a thread to synchronously unpack gzipped tar file without blocking the async thread
                task::spawn_blocking(move || unpack_tar_gz(&temp_file_path_clone, &db_path))
                    .await?
                    .expect("Failed to unpack gzipped tar file");

                fs::remove_file(&temp_file_path)
                    .await
                    .context("Failed to remove temporary file after unpacking")?;
                Ok(())
            },
            Err(e) => Err(anyhow::Error::new(e)),
        }
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/backup_restore/fs_ops.rs (L101-112)
```rust
pub fn unpack_tar_gz(temp_file_path: &PathBuf, target_db_path: &PathBuf) -> anyhow::Result<()> {
    let temp_dir_path = target_db_path.with_extension("tmp");
    fs::create_dir(&temp_dir_path)?;

    let file = File::open(temp_file_path)?;
    let gz_decoder = GzDecoder::new(file);
    let mut archive = Archive::new(gz_decoder);
    archive.unpack(&temp_dir_path)?;

    fs::remove_dir_all(target_db_path).unwrap_or(());
    fs::rename(&temp_dir_path, target_db_path)?; // Atomically replace the directory
    Ok(())
```

**File:** config/src/config/indexer_table_info_config.rs (L15-16)
```rust
    /// Restore service mode with GCS bucket name.
    Restore(String),
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/runtime.rs (L93-98)
```rust
        let backup_restore_operator = match node_config.indexer_table_info.table_info_service_mode {
            TableInfoServiceMode::Backup(gcs_bucket_name) => Some(Arc::new(
                GcsBackupRestoreOperator::new(gcs_bucket_name).await,
            )),
            _ => None,
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/README.md (L37-45)
```markdown
* To use the restore service, 

```
  indexer_table_info:
    ...
    table_info_service_mode:
        Restore:
            your-bucket-name
```
```

**File:** crates/node-resource-metrics/src/collectors/disk_metrics_collector.rs (L99-101)
```rust
                let available_space = ConstMetric::new_counter(
                    self.available_space.clone(),
                    disk.available_space() as f64,
```
