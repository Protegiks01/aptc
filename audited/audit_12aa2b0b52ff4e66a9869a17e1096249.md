# Audit Report

## Title
SafetyRules Not Reset After sync_to_target Rollback - Critical Liveness Failure

## Summary
When `sync_to_target` causes a rollback to an earlier blockchain state (e.g., switching from one fork to another), the SafetyRules component is not notified or reset. This leaves SafetyRules with stale round numbers from the old fork, preventing the validator from participating in consensus on the new fork, causing a critical liveness violation.

## Finding Description

The vulnerability exists in the state synchronization coordination flow. When a validator node discovers it is on the wrong fork and needs to rollback, it calls `sync_to_target` to synchronize to the canonical chain. This flow resets multiple consensus components but critically omits SafetyRules.

**The Flow:**

1. When `sync_to_target` is called during fast-forward sync: [1](#0-0) 

2. The execution client resets buffer and rand managers: [2](#0-1) 

3. The reset function updates buffer and rand managers: [3](#0-2) 

4. After sync completes, BlockStore is rebuilt: [4](#0-3) 

5. RoundState is updated via process_certificates: [5](#0-4) 

**The Missing Reset:**

However, SafetyRules maintains persistent voting state that includes: [6](#0-5) 

These values are never reset during the rollback. SafetyRules enforces critical safety rules using these stale values:

**First voting rule** - prevents voting for rounds less than or equal to last_voted_round: [7](#0-6) 

**Second voting rule** - prevents accepting QCs with one_chain_round less than preferred_round: [8](#0-7) 

**Attack Scenario:**

1. Validator is at round 100 on Fork A
2. Validator has voted in round 100, so SafetyRules has: `last_voted_round = 100`, `preferred_round = 98`, `one_chain_round = 99`
3. Network consensus moves to Fork B which diverged at round 40
4. Validator receives SyncInfo showing Fork B has higher committed round
5. `sync_to_target` executes, rolling back to round 50 on Fork B
6. BlockStore rebuilds with Fork B blocks, RoundState updates to round 55
7. **SafetyRules retains stale values from Fork A**
8. When validator receives proposal for round 55 on Fork B:
   - `verify_and_update_last_vote_round(55, ...)` fails because `55 <= 100`
   - Validator cannot vote, is effectively offline
9. When validator receives QC with `one_chain_round = 53`:
   - `verify_and_update_preferred_round(...)` fails because `53 < 98`
   - Validator rejects valid certificates

The validator is bricked until either:
- A new epoch starts (which initializes new SafetyRules)
- Manual restart with SafetyRules reset
- Fork B's round exceeds the stale values (may take hours)

## Impact Explanation

This is a **Critical Severity** vulnerability per Aptos bug bounty criteria:

**"Total loss of liveness/network availability"** - When multiple validators experience this issue simultaneously (which is likely if they were all on the same wrong fork), the network loses validator participation. With sufficient affected validators, this can:
- Prevent new blocks from achieving 2f+1 votes
- Halt consensus progress entirely
- Require emergency hardfork or manual intervention

**Consensus Safety Invariant Preserved**: Importantly, this bug does NOT violate safety (no equivocation, no double-voting) because SafetyRules prevents voting, not enables it. However, liveness is completely broken.

**Network-Wide Impact**: In a realistic scenario where a network partition or eclipse attack causes multiple validators to follow the same wrong fork, the subsequent rollback would brick all affected validators simultaneously, potentially bringing down the network.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability will trigger in several realistic scenarios:

1. **Network Partitions**: When a subset of validators becomes partitioned and builds a separate fork, then rejoins the network
2. **Eclipse Attacks**: When an attacker isolates validators and feeds them a fake fork
3. **Slow Validator Recovery**: When a validator is offline for extended periods then syncs back
4. **Fork Choice Issues**: Any scenario where validators temporarily follow different branches

The vulnerability is **deterministic** - once the conditions are met (rollback to earlier round), the bug always triggers. No race conditions or timing dependencies exist.

**Attacker Requirements:**
- No privileged access needed
- Simply requires causing validators to temporarily follow different forks (common in P2P networks)
- Can be triggered accidentally during normal network issues

## Recommendation

Add SafetyRules reset to the `ExecutionProxyClient::reset()` function or create a new reset path that's called during state sync rollback:

```rust
// In consensus/src/pipeline/execution_client.rs
async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
    let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
        let handle = self.handle.read();
        (
            handle.reset_tx_to_rand_manager.clone(),
            handle.reset_tx_to_buffer_manager.clone(),
        )
    };

    // ... existing rand and buffer manager reset code ...

    // ADD: Reset SafetyRules to target round
    // This requires passing SafetyRules handle to ExecutionProxyClient
    // and implementing a reset mechanism in SafetyRules that:
    // 1. Reads the current committed round from storage
    // 2. Resets last_voted_round, preferred_round, one_chain_round
    //    to safe values based on the new committed state
    // 3. Clears last_vote if it's from a rolled-back round
    
    Ok(())
}
```

Alternative approach: Modify SafetyRules to check against committed state in storage before applying voting rules, with rollback detection:

```rust
// In consensus/safety-rules/src/safety_rules.rs
pub(crate) fn verify_and_update_last_vote_round(
    &self,
    round: Round,
    safety_data: &mut SafetyData,
) -> Result<(), Error> {
    // ADD: Detect if we're behind committed storage (rollback occurred)
    // If so, reset safety_data to safe values from storage
    
    if round <= safety_data.last_voted_round {
        return Err(Error::IncorrectLastVotedRound(
            round,
            safety_data.last_voted_round,
        ));
    }
    // ... rest of function
}
```

The most robust solution is to integrate SafetyRules reset into the existing reset mechanism used for buffer and rand managers, ensuring all consensus components are synchronized after any state sync rollback.

## Proof of Concept

```rust
// This is a conceptual PoC showing the vulnerability flow
// In a real test, you would:
// 1. Start a validator node at round 100 on Fork A
// 2. Have it vote for round 100
// 3. Trigger sync_to_target with a target from round 50 on Fork B
// 4. Observe that SafetyRules still has last_voted_round = 100
// 5. Attempt to vote for round 55 on Fork B
// 6. Observe the vote is rejected with IncorrectLastVotedRound error

#[tokio::test]
async fn test_safety_rules_not_reset_after_sync_rollback() {
    // Setup: Create validator at round 100 on Fork A
    let mut validator = create_test_validator();
    validator.advance_to_round(100).await;
    
    // Validator votes for round 100
    let proposal_100 = create_test_proposal(100);
    let vote_100 = validator.vote_for_proposal(proposal_100).await.unwrap();
    
    // Verify SafetyRules has last_voted_round = 100
    let safety_data = validator.safety_rules.persistent_storage.safety_data().unwrap();
    assert_eq!(safety_data.last_voted_round, 100);
    
    // Network switches to Fork B at round 50
    let fork_b_target = create_ledger_info_at_round(50);
    
    // Trigger sync_to_target rollback
    validator.execution_client.sync_to_target(fork_b_target).await.unwrap();
    
    // Verify BlockStore has been rebuilt at round 50
    assert_eq!(validator.block_store.root().round(), 50);
    
    // Verify SafetyRules STILL has stale last_voted_round = 100 (BUG!)
    let safety_data_after = validator.safety_rules.persistent_storage.safety_data().unwrap();
    assert_eq!(safety_data_after.last_voted_round, 100); // Still stale!
    
    // Try to vote for round 55 on Fork B - should work but will fail
    let proposal_55 = create_test_proposal(55);
    let result = validator.vote_for_proposal(proposal_55).await;
    
    // This assertion demonstrates the bug - vote fails due to stale SafetyRules
    assert!(result.is_err());
    assert!(matches!(result.unwrap_err(), Error::IncorrectLastVotedRound(55, 100)));
    
    // Validator is now bricked and cannot participate in consensus!
}
```

**Notes**

This vulnerability represents a critical gap in the rollback coordination logic. While the execution pipeline, block storage, and round management are properly reset after `sync_to_target`, the SafetyRules component—which enforces the fundamental safety invariants of the consensus protocol—retains stale state from before the rollback. This creates a situation where the safety mechanism designed to prevent equivocation instead prevents legitimate voting, transforming a safety feature into a liveness blocker.

The root cause is architectural: SafetyRules was designed as a stateful component with persistent storage to survive crashes, but the state sync mechanism was not designed to coordinate with SafetyRules during rollbacks. The reset logic in `ExecutionProxyClient` only handles buffer and rand managers but lacks awareness of SafetyRules state.

### Citations

**File:** consensus/src/block_storage/sync_manager.rs (L313-314)
```rust
        self.rebuild(root, root_metadata, blocks, quorum_certs)
            .await;
```

**File:** consensus/src/block_storage/sync_manager.rs (L512-514)
```rust
        execution_client
            .sync_to_target(highest_commit_cert.ledger_info().clone())
            .await?;
```

**File:** consensus/src/pipeline/execution_client.rs (L661-672)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Reset the rand and buffer managers to the target round
        self.reset(&target).await?;

        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```

**File:** consensus/src/round_manager.rs (L902-902)
```rust
            self.process_certificates().await?;
```

**File:** consensus/consensus-types/src/safety_data.rs (L10-21)
```rust
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** consensus/safety-rules/src/safety_rules.rs (L173-188)
```rust
    fn verify_and_update_preferred_round(
        &mut self,
        quorum_cert: &QuorumCert,
        safety_data: &mut SafetyData,
    ) -> Result<bool, Error> {
        let preferred_round = safety_data.preferred_round;
        let one_chain_round = quorum_cert.certified_block().round();

        if one_chain_round < preferred_round {
            return Err(Error::IncorrectPreferredRound(
                one_chain_round,
                preferred_round,
            ));
        }
        Ok(self.observe_qc(quorum_cert, safety_data))
    }
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```
