# Audit Report

## Title
Privacy Leak in Telemetry Logging: Validator Identity Disclosure Through Network Metadata

## Summary
The Aptos telemetry logging system inadvertently exposes validator operator identities by transmitting sensitive network metadata (IP addresses, hostnames, peer IDs) in unfiltered log entries to external telemetry services. This enables correlation attacks that can de-anonymize validator operators and map network infrastructure.

## Finding Description

When telemetry remote logging is enabled via the `enable_telemetry_remote_log` configuration option, the Aptos logger collects and transmits comprehensive log entries to an external telemetry service. These log entries contain multiple identity-revealing fields that, when combined, can de-anonymize validator operators. [1](#0-0) 

Each `LogEntry` includes:
- **peer_id**: The validator's unique cryptographic identifier
- **hostname**: The machine's hostname (potentially revealing)  
- **timestamp**: Microsecond-precision timestamps enabling correlation attacks
- **namespace**: Kubernetes namespace information
- **data**: Arbitrary structured data fields

These fields are populated with real validator identification data: [2](#0-1) 

All fields are serialized to JSON and included in telemetry transmission: [3](#0-2) 

**Critical Privacy Leak Vector**: Network-related logging schemas explicitly include IP addresses and socket addresses. The `NetworkSchema` structure contains a `network_address` field: [4](#0-3) 

This schema is used throughout the codebase to log connection events with full network addresses: [5](#0-4) 

These network addresses containing IP information are logged in production code: [6](#0-5) 

Additionally, secure networking logs directly include socket addresses (IP:port): [7](#0-6) 

**No Content Filtering**: The telemetry logging system applies level-based filtering but performs NO sanitization or redaction of sensitive network information before transmission: [8](#0-7) 

JSON-formatted logs with all sensitive fields intact are transmitted to the external telemetry service: [9](#0-8) 

## Impact Explanation

This constitutes a **Medium severity** privacy leak as specified in the security question, because:

1. **Validator De-anonymization**: Combining peer_id + IP addresses + hostnames enables mapping validator identities to physical infrastructure
2. **Network Topology Exposure**: Reveals validator connectivity patterns, peer relationships, and network architecture
3. **Temporal Correlation**: Microsecond-precision timestamps enable timing analysis and correlation attacks across validators
4. **Operational Security Risk**: Exposed infrastructure details could enable targeted attacks, DDoS, or regulatory action against specific validator operators

While this doesn't directly result in fund loss or consensus violations, it compromises validator operator privacy—a critical security property for decentralized networks. Validators who wish to remain pseudonymous or protect their infrastructure from targeted attacks are inadvertently exposing their identity through telemetry.

The severity is elevated from "Low" (minor information leak) to "Medium" because:
- It affects the security posture of validators (makes them targetable)
- It's systematic and affects all validators with telemetry enabled
- The exposure is permanent (logs are retained by telemetry services)
- It can be correlated with other data sources to increase impact

## Likelihood Explanation

**Likelihood: High** - This vulnerability affects all validators who:
1. Enable the `enable_telemetry_remote_log` configuration option (commonly enabled for monitoring)
2. Use the default logging configuration without custom filters
3. Run at logging levels that capture network connection events (INFO/WARN/ERROR)

The conditions are met in production environments by default when telemetry is enabled for operational monitoring. No special configuration or edge case is required—normal operation of the telemetry system results in the privacy leak.

## Recommendation

Implement content-based filtering and sanitization of sensitive fields in telemetry logs before transmission:

1. **Network Address Redaction**: Strip or hash IP addresses and network addresses from log messages and data fields before sending to telemetry
2. **Hostname Sanitization**: Replace hostnames with anonymized identifiers or omit entirely
3. **Peer ID Protection**: Consider hashing or encrypting peer IDs for telemetry, or making them opt-in
4. **Configuration Option**: Add `telemetry_redact_sensitive_fields` boolean to logger config
5. **Schema-Level Filtering**: Modify `NetworkSchema` and `SecureNetLogSchema` to support redacted modes

Example implementation approach:

```rust
// In aptos_logger.rs, before sending to telemetry:
fn sanitize_for_telemetry(entry: &mut LogEntry) {
    // Redact hostname
    entry.hostname = None;
    
    // Redact IP addresses from data fields
    for (key, value) in entry.data.iter_mut() {
        if let serde_json::Value::String(s) = value {
            *s = redact_ip_addresses(s);
        }
    }
    
    // Optionally hash peer_id
    if let Some(peer_id) = entry.peer_id {
        entry.peer_id = Some(hash_peer_id(peer_id));
    }
}
```

Additionally, document the privacy implications of enabling telemetry in validator operator guides and make the feature more explicitly opt-in with clear warnings.

## Proof of Concept

**Observation Steps** (no exploitation needed, this is observable behavior):

1. Deploy a validator node with telemetry enabled:
```yaml
logger:
  enable_telemetry_remote_log: true
  telemetry_level: INFO
```

2. Monitor outgoing HTTPS requests to the telemetry service endpoint (`/api/v1/ingest/logs`)

3. Decrypt/inspect the JSON payload (if you control the telemetry service or intercept traffic)

4. Observe log entries containing:
```json
{
  "level": "INFO",
  "peer_id": "0xabc123...",
  "hostname": "validator-prod-01.example.com",
  "timestamp": "2024-01-15T10:23:45.123456Z",
  "message": "New connection established: ...",
  "data": {
    "network_address": "/ip4/203.0.113.42/tcp/6180",
    "remote_peer": "0xdef456..."
  }
}
```

5. Correlation: Cross-reference the peer_id with on-chain validator set data to identify the validator operator, now linked to a specific IP address and hostname.

This demonstrates that **by design**, the current implementation transmits identity-revealing metadata without sanitization, enabling de-anonymization of validator operators who enable telemetry.

---

## Notes

The vulnerability assessment acknowledges this is a **privacy concern** rather than a traditional exploitable vulnerability. However, given the explicit security question about validator identity disclosure through telemetry logs, and the classification as "Medium" severity in the prompt, this report documents the systematic exposure of validator identity metadata through the telemetry system.

The issue lies in the design choice to include comprehensive diagnostic information in telemetry without implementing privacy-preserving techniques (hashing, encryption, redaction) that could maintain operational utility while protecting validator operator anonymity.

### Citations

**File:** crates/aptos-logger/src/aptos_logger.rs (L108-123)
```rust
/// A single log entry emitted by a logging macro with associated metadata
#[derive(Debug)]
pub struct LogEntry {
    metadata: Metadata,
    thread_name: Option<String>,
    /// The program backtrace taken when the event occurred. Backtraces
    /// are only supported for errors and must be configured.
    backtrace: Option<String>,
    hostname: Option<&'static str>,
    namespace: Option<&'static str>,
    timestamp: String,
    data: BTreeMap<Key, serde_json::Value>,
    message: Option<String>,
    peer_id: Option<&'static str>,
    chain_id: Option<u8>,
}
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L127-159)
```rust
impl Serialize for LogEntry {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut state = serializer.serialize_struct("LogEntry", 9)?;
        state.serialize_field("level", &self.metadata.level())?;
        state.serialize_field("source", &self.metadata)?;
        if let Some(thread_name) = &self.thread_name {
            state.serialize_field("thread_name", thread_name)?;
        }
        if let Some(hostname) = &self.hostname {
            state.serialize_field("hostname", hostname)?;
        }
        if let Some(namespace) = &self.namespace {
            state.serialize_field("namespace", namespace)?;
        }
        state.serialize_field("timestamp", &self.timestamp)?;
        if let Some(message) = &self.message {
            state.serialize_field("message", message)?;
        }
        if !&self.data.is_empty() {
            state.serialize_field("data", &self.data)?;
        }
        if let Some(backtrace) = &self.backtrace {
            state.serialize_field("backtrace", backtrace)?;
        }
        if let Some(peer_id) = &self.peer_id {
            state.serialize_field("peer_id", peer_id)?;
        }
        state.end()
    }
}
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L197-222)
```rust
        static HOSTNAME: Lazy<Option<String>> = Lazy::new(|| {
            hostname::get()
                .ok()
                .and_then(|name| name.into_string().ok())
        });

        static NAMESPACE: Lazy<Option<String>> =
            Lazy::new(|| env::var("KUBERNETES_NAMESPACE").ok());

        let hostname = HOSTNAME.as_deref();
        let namespace = NAMESPACE.as_deref();

        let peer_id: Option<&str>;
        let chain_id: Option<u8>;

        #[cfg(node_identity)]
        {
            peer_id = aptos_node_identity::peer_id_as_str();
            chain_id = aptos_node_identity::chain_id().map(|chain_id| chain_id.id());
        }

        #[cfg(not(node_identity))]
        {
            peer_id = None;
            chain_id = None;
        }
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L642-653)
```rust
                    if let Some(writer) = &mut telemetry_writer {
                        if self
                            .facade
                            .filter
                            .read()
                            .telemetry_filter
                            .enabled(&entry.metadata)
                        {
                            let s = json_format(&entry).expect("Unable to format");
                            let _ = writer.write(s);
                        }
                    }
```

**File:** network/framework/src/logging.rs (L32-45)
```rust
#[derive(Schema)]
pub struct NetworkSchema<'a> {
    connection_id: Option<&'a ConnectionId>,
    #[schema(display)]
    connection_origin: Option<&'a ConnectionOrigin>,
    #[schema(display)]
    discovery_source: Option<&'a DiscoverySource>,
    message: Option<String>,
    #[schema(display)]
    network_address: Option<&'a NetworkAddress>,
    network_context: &'a NetworkContext,
    #[schema(display)]
    remote_peer: Option<&'a PeerId>,
}
```

**File:** network/framework/src/logging.rs (L66-71)
```rust
    pub fn connection_metadata_with_address(self, metadata: &'a ConnectionMetadata) -> Self {
        self.connection_id(&metadata.connection_id)
            .connection_origin(&metadata.origin)
            .remote_peer(&metadata.remote_peer_id)
            .network_address(&metadata.addr)
    }
```

**File:** network/framework/src/peer_manager/mod.rs (L394-397)
```rust
            NetworkSchema::new(&self.network_context)
                .connection_metadata_with_address(&conn.metadata),
            "{} New connection established: {}", self.network_context, conn.metadata
        );
```

**File:** secure/net/src/lib.rs (L32-41)
```rust
#[derive(Schema)]
struct SecureNetLogSchema<'a> {
    service: &'a str,
    mode: NetworkMode,
    event: LogEvent,
    #[schema(debug)]
    remote_peer: Option<&'a SocketAddr>,
    #[schema(debug)]
    error: Option<&'a Error>,
}
```

**File:** crates/aptos-telemetry/src/sender.rs (L176-193)
```rust
    pub async fn try_send_logs(&self, batch: Vec<String>) {
        if let Ok(json) = serde_json::to_string(&batch) {
            let len = json.len();

            match self.post_logs(json.as_bytes()).await {
                Ok(_) => {
                    increment_log_ingest_successes_by(batch.len() as u64);
                    debug!("Sent log of length: {}", len);
                },
                Err(error) => {
                    increment_log_ingest_failures_by(batch.len() as u64);
                    debug!("Failed send log of length: {} with error: {}", len, error);
                },
            }
        } else {
            debug!("Failed json serde of batch: {:?}", batch);
        }
    }
```
