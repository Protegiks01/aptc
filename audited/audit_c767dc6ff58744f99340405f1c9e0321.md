# Audit Report

## Title
Database Corruption Leads to Silent Permanent Data Loss During Ledger Pruner Initialization

## Summary
When `LedgerPrunerProgress` is missing and database corruption causes `VersionDataSchema` iterator to return an incorrect (higher) minimum version, the ledger pruner initializes all sub-pruners with this corrupted value, causing them to permanently delete unpruned data during "catch up" without detection.

## Finding Description

The vulnerability exists in the ledger pruner initialization logic when handling old or corrupted databases. [1](#0-0) 

The initialization flow has a critical weakness:

1. If `LedgerPrunerProgress` doesn't exist (line 20-21 check fails), the code falls back to scanning `VersionDataSchema`
2. It creates an iterator and seeks to the first entry (lines 27-28)
3. It uses this first version as the initial progress value (lines 29-36)

**Attack Scenario:**

Assume a database with:
- Event data exists from versions 100-1000
- `EventPrunerProgress` = 100 (correctly tracking pruned state)
- `LedgerPrunerProgress` is missing or corrupted
- Database corruption in `VersionDataSchema` causes entries 100-499 to be inaccessible

When `LedgerMetadataPruner::new()` executes:
- Iterator seeks to first but skips corrupted entries, returning version 500
- Sets `LedgerPrunerProgress = 500`

This incorrect value propagates to all sub-pruners: [2](#0-1) 

Each sub-pruner then "catches up" by calling its initialization with `metadata_progress = 500`: [3](#0-2) 

The critical issue is line 106: `myself.prune(progress, metadata_progress)` where `progress=100` and `metadata_progress=500`, causing permanent deletion of versions 100-499. [4](#0-3) 

The same data loss occurs across ALL sub-pruners: [5](#0-4) [6](#0-5) 

**No Validation Present:**

The code assumes the iterator result is correct without any validation against:
- Existing sub-pruner progress values
- Actual data presence in the database
- Consistency checks across different schemas [7](#0-6) 

## Impact Explanation

**Severity: High** per Aptos bug bounty criteria.

This qualifies as a "Significant protocol violation" causing permanent data loss:

1. **Permanent Data Loss**: Transactions, events, write sets, and other ledger data from versions 100-499 are irreversibly deleted
2. **Silent Failure**: No error is raised; the system proceeds as if pruning was successful
3. **Cascading Impact**: Affects ALL ledger sub-pruners simultaneously (events, transactions, transaction info, write sets, transaction accumulator, auxiliary data, persisted auxiliary info)
4. **State Inconsistency**: The node reports data as "pruned" when it should exist, breaking queries and state sync
5. **No Recovery Path**: Once deleted, the data cannot be recovered except through state sync from other nodes

While this doesn't directly cause consensus safety violations or fund loss, it severely impacts node functionality and network reliability, particularly affecting:
- Historical queries returning "version pruned" errors for data that should exist
- State synchronization failures for nodes syncing from affected node
- Blockchain explorers and indexers missing critical historical data

## Likelihood Explanation

**Likelihood: Medium-Low**

**Preconditions Required:**
1. `LedgerPrunerProgress` must be missing (either old database pre-progress tracking or metadata corruption)
2. Partial database corruption in `VersionDataSchema` that makes entries inaccessible but allows iterator to succeed
3. Sub-pruner progress values must exist and be lower than corrupted iterator result

**Realistic Scenarios:**
- Hardware failures (disk corruption, bad sectors)
- Software crashes during write operations
- RocksDB bugs or corruption
- File system corruption
- Partial database restores

While direct exploitation by an unprivileged attacker is not possible, database corruption is a realistic operational concern for long-running blockchain nodes. The lack of defensive validation transforms a recoverable corruption scenario into permanent data loss.

## Recommendation

Add validation to detect and prevent initialization with corrupted values:

```rust
pub(in crate::pruner) fn new(ledger_metadata_db: Arc<DB>) -> Result<Self> {
    if let Some(v) =
        ledger_metadata_db.get::<DbMetadataSchema>(&DbMetadataKey::LedgerPrunerProgress)?
    {
        v.expect_version();
    } else {
        let mut iter = ledger_metadata_db.iter::<VersionDataSchema>()?;
        iter.seek_to_first();
        let version = match iter.next().transpose()? {
            Some((version, _)) => version,
            None => 0,
        };
        
        // VALIDATION: Check if this version is reasonable by verifying
        // data doesn't exist before this point
        if version > 0 {
            // Seek backwards to check for gaps
            iter.seek(&(version.saturating_sub(1)))?;
            if let Some((prev_version, _)) = iter.next().transpose()? {
                if prev_version < version.saturating_sub(1000) {
                    return Err(AptosDbError::Other(
                        format!("Detected potential database corruption: gap in VersionDataSchema between {} and {}. Manual intervention required.", prev_version, version)
                    ));
                }
            }
        }
        
        ledger_metadata_db.put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerPrunerProgress,
            &DbMetadataValue::Version(version),
        )?;
    }
    
    Ok(LedgerMetadataPruner { ledger_metadata_db })
}
```

Additional safeguards:
1. Add checksums/integrity verification to `VersionDataSchema`
2. Cross-validate against sub-pruner progress values before "catch up"
3. Implement dry-run mode that logs what would be deleted
4. Add database consistency checks at startup

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_schemadb::DB;
    
    #[test]
    fn test_corruption_causes_data_loss() {
        let tmpdir = TempPath::new();
        let db = Arc::new(DB::open(&tmpdir, "test", &[], &[]).unwrap());
        
        // Setup: Write VersionData for versions 100-1000
        for v in 100..=1000 {
            db.put::<VersionDataSchema>(&v, &VersionData {
                state_items: 100,
                total_state_bytes: 10000,
            }).unwrap();
        }
        
        // Simulate sub-pruner with progress at 100
        db.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(100),
        ).unwrap();
        
        // Simulate corruption: manually delete VersionData entries 100-499
        for v in 100..500 {
            db.delete::<VersionDataSchema>(&v).unwrap();
        }
        
        // Initialize pruner - this will read version 500 as "first"
        let pruner = LedgerMetadataPruner::new(Arc::clone(&db)).unwrap();
        
        // Verify that LedgerPrunerProgress is now 500 (incorrect!)
        let progress = pruner.progress().unwrap();
        assert_eq!(progress, 500); // Should have detected corruption instead!
        
        // When EventStorePruner initializes, it would call:
        // prune(100, 500) - deleting versions 100-499 that still exist elsewhere!
    }
}
```

**Notes:**

This vulnerability represents a **defensive programming failure** rather than a directly exploitable attack vector. Database corruption is not attacker-controlled in normal operation, but the lack of validation transforms a recoverable corruption scenario into permanent, silent data loss. The fix should add integrity checks and cross-validation to detect inconsistencies before performing destructive operations.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_metadata_pruner.rs (L19-40)
```rust
    pub(in crate::pruner) fn new(ledger_metadata_db: Arc<DB>) -> Result<Self> {
        if let Some(v) =
            ledger_metadata_db.get::<DbMetadataSchema>(&DbMetadataKey::LedgerPrunerProgress)?
        {
            v.expect_version();
        } else {
            // NOTE: I **think** all db should have the LedgerPrunerProgress. Have a fallback path
            // here in case the database was super old before we introducing this progress counter.
            let mut iter = ledger_metadata_db.iter::<VersionDataSchema>()?;
            iter.seek_to_first();
            let version = match iter.next().transpose()? {
                Some((version, _)) => version,
                None => 0,
            };
            ledger_metadata_db.put::<DbMetadataSchema>(
                &DbMetadataKey::LedgerPrunerProgress,
                &DbMetadataValue::Version(version),
            )?;
        }

        Ok(LedgerMetadataPruner { ledger_metadata_db })
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L124-170)
```rust
        let ledger_metadata_pruner = Box::new(
            LedgerMetadataPruner::new(ledger_db.metadata_db_arc())
                .expect("Failed to initialize ledger_metadata_pruner."),
        );

        let metadata_progress = ledger_metadata_pruner.progress()?;

        info!(
            metadata_progress = metadata_progress,
            "Created ledger metadata pruner, start catching up all sub pruners."
        );

        let transaction_store = Arc::new(TransactionStore::new(Arc::clone(&ledger_db)));

        let event_store_pruner = Box::new(EventStorePruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db.clone(),
        )?);
        let persisted_auxiliary_info_pruner = Box::new(PersistedAuxiliaryInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_accumulator_pruner = Box::new(TransactionAccumulatorPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_auxiliary_data_pruner = Box::new(TransactionAuxiliaryDataPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);

        let transaction_info_pruner = Box::new(TransactionInfoPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
        let transaction_pruner = Box::new(TransactionPruner::new(
            Arc::clone(&transaction_store),
            Arc::clone(&ledger_db),
            metadata_progress,
            internal_indexer_db,
        )?);
        let write_set_pruner = Box::new(WriteSetPruner::new(
            Arc::clone(&ledger_db),
            metadata_progress,
        )?);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L85-109)
```rust
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.event_db_raw(),
            &DbMetadataKey::EventPrunerProgress,
            metadata_progress,
        )?;

        let myself = EventStorePruner {
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up EventStorePruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L225-243)
```rust
    pub(crate) fn prune_events(
        &self,
        num_events_per_version: Vec<usize>,
        start: Version,
        end: Version,
        db_batch: &mut SchemaBatch,
    ) -> Result<()> {
        let mut current_version = start;

        for num_events in num_events_per_version {
            for idx in 0..num_events {
                db_batch.delete::<EventSchema>(&(current_version, idx as u64))?;
            }
            current_version += 1;
        }
        self.event_store
            .prune_event_accumulator(start, end, db_batch)?;
        Ok(())
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L78-104)
```rust
    pub(in crate::pruner) fn new(
        transaction_store: Arc<TransactionStore>,
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_db_raw(),
            &DbMetadataKey::TransactionPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionPruner {
            transaction_store,
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/write_set_pruner.rs (L36-58)
```rust
impl WriteSetPruner {
    pub(in crate::pruner) fn new(
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.write_set_db_raw(),
            &DbMetadataKey::WriteSetPrunerProgress,
            metadata_progress,
        )?;

        let myself = WriteSetPruner { ledger_db };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up WriteSetPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
}
```

**File:** storage/aptosdb/src/schema/version_data/mod.rs (L29-49)
```rust
#[derive(Debug, Deserialize, PartialEq, Eq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(Arbitrary))]
pub struct VersionData {
    pub state_items: usize,
    pub total_state_bytes: usize,
}

impl From<StateStorageUsage> for VersionData {
    fn from(usage: StateStorageUsage) -> Self {
        Self {
            state_items: usage.items(),
            total_state_bytes: usage.bytes(),
        }
    }
}

impl VersionData {
    pub fn get_state_storage_usage(&self) -> StateStorageUsage {
        StateStorageUsage::new(self.state_items, self.total_state_bytes)
    }
}
```
