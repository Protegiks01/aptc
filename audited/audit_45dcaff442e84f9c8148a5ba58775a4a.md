# Audit Report

## Title
Indefinite Blocking in CoordinatorClient Trait Enables Liveness Failures in Sharded Block Execution

## Summary
The `CoordinatorClient` trait and its implementations lack any timeout or failure detection mechanism for blocking channel operations. Both `receive_execute_command()` and `send_execution_result()` use indefinite blocking calls that will hang forever if a shard fails silently, causing complete stall of block execution and validator node liveness failures.

## Finding Description

The `CoordinatorClient` trait defines the interface for communication between executor shards and the block execution coordinator, but provides no mechanism to detect silent failures: [1](#0-0) 

Both implementations use blocking operations without timeout:

**LocalCoordinatorClient** uses indefinite blocking recv/send with panic on error: [2](#0-1) 

**RemoteCoordinatorClient** similarly uses blocking recv/send: [3](#0-2) 

The shard execution loop calls these blocking operations: [4](#0-3) 

Meanwhile, the coordinator waits indefinitely for results: [5](#0-4) 

**Silent Failure Scenarios:**
1. **Shard thread pool exhaustion** - If all threads are blocked, execution stalls
2. **Cross-shard deadlock** - Shards waiting for each other's messages in circular dependency
3. **Resource exhaustion** - Out-of-memory or other resource limits causing hangs
4. **Network degradation** - For remote shards, slow networks without connection closure
5. **Unexpected panics** - If a shard thread panics before sending StopMsg to cross-shard receiver

The cross-shard commit receiver also blocks indefinitely: [6](#0-5) 

If the execution thread fails to send `StopMsg`, this receiver hangs forever.

## Impact Explanation

**Severity: Medium** - This breaks the **liveness** invariant of the consensus protocol without directly causing safety violations or fund loss:

1. **Validator Node Unavailability**: A hanging shard causes the entire block execution to stall, preventing the validator from participating in consensus
2. **Block Production Failure**: Validators cannot propose new blocks if execution is stuck
3. **Block Validation Failure**: Validators cannot validate and vote on blocks from other validators
4. **Consensus Degradation**: If enough validators are affected, the network experiences reduced throughput or liveness failures

This qualifies as **Medium severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention" - validators would need to be restarted to recover from indefinite hangs.

## Likelihood Explanation

**Likelihood: Medium** - This can occur through several realistic scenarios:

1. **Software Bugs**: Any bug causing thread deadlock, infinite loop, or panic in shard execution will trigger this
2. **Resource Exhaustion**: System-level resource limits (memory, file descriptors) can cause hangs
3. **Network Issues**: For remote execution, degraded networks can cause indefinite blocking
4. **Race Conditions**: Complex cross-shard dependencies may create subtle deadlock scenarios

The issue is exacerbated by:
- No defensive timeout at the coordinator level
- No health monitoring of shard execution
- `.unwrap()` usage that converts errors into panics rather than graceful failures
- Blocking operations in multiple layers (coordinator, cross-shard communication)

## Recommendation

Implement timeout mechanisms at multiple levels:

**1. Add timeout parameter to CoordinatorClient trait:**
```rust
pub trait CoordinatorClient<S: StateView + Sync + Send + 'static>: Send + Sync {
    fn receive_execute_command(&self, timeout: Duration) -> Result<ExecutorShardCommand<S>, RecvTimeoutError>;
    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>, timeout: Duration) -> Result<(), SendTimeoutError>;
}
```

**2. Implement recv_timeout in implementations:**
```rust
impl<S: StateView + Sync + Send + 'static> CoordinatorClient<S> for LocalCoordinatorClient<S> {
    fn receive_execute_command(&self, timeout: Duration) -> Result<ExecutorShardCommand<S>, RecvTimeoutError> {
        self.command_rx.recv_timeout(timeout)
    }

    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>, timeout: Duration) -> Result<(), SendTimeoutError> {
        self.result_tx.send_timeout(result, timeout)
    }
}
```

**3. Add timeout in coordinator's waiting logic:**
```rust
fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
    let timeout = Duration::from_secs(300); // 5 minutes
    let mut results = vec![];
    for (i, rx) in self.result_rxs.iter().enumerate() {
        match rx.recv_timeout(timeout) {
            Ok(result) => results.push(result?),
            Err(RecvTimeoutError::Timeout) => {
                return Err(VMStatus::Error(StatusCode::EXECUTION_TIMEOUT));
            }
            Err(RecvTimeoutError::Disconnected) => {
                panic!("Shard {} disconnected", i);
            }
        }
    }
    Ok(results)
}
```

**4. Add health monitoring and circuit breaker patterns** to detect and recover from shard failures.

## Proof of Concept

While a complete PoC requires triggering an underlying condition that causes hangs, here's a conceptual demonstration:

```rust
// Simulation of a shard that hangs indefinitely
#[test]
fn test_coordinator_hangs_on_shard_failure() {
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;
    use crossbeam_channel::unbounded;
    
    // Setup channels
    let (cmd_tx, cmd_rx) = unbounded();
    let (result_tx, result_rx) = unbounded();
    
    // Coordinator side - will hang here
    let coordinator_thread = thread::spawn(move || {
        println!("Coordinator: Sending execute command");
        cmd_tx.send(ExecutorShardCommand::ExecuteSubBlocks(/* ... */)).unwrap();
        
        println!("Coordinator: Waiting for result (will hang)...");
        let result = result_rx.recv().unwrap(); // HANGS FOREVER
        println!("Coordinator: Received result (never reached)");
    });
    
    // Shard side - receives command but never sends result (simulating hang)
    let shard_thread = thread::spawn(move || {
        println!("Shard: Receiving command");
        let cmd = cmd_rx.recv().unwrap();
        
        println!("Shard: Simulating hang (infinite sleep)");
        thread::sleep(Duration::from_secs(999999)); // Simulate hang
        
        // Never reached - result never sent
        // result_tx.send(Ok(vec![])).unwrap();
    });
    
    // Wait a bit to show the hang
    thread::sleep(Duration::from_secs(5));
    println!("Test: Both threads are now hanging indefinitely");
    
    // In production, this would cause validator node to stop producing blocks
}
```

## Notes

This vulnerability specifically affects the **operational resilience** of validator nodes rather than the **safety** of the consensus protocol. The lack of timeout mechanisms means any transient issue (bugs, resource exhaustion, network problems) becomes a permanent hang requiring manual intervention.

While the root cause of hangs would be separate bugs (e.g., deadlocks in cross-shard communication, Move VM bugs, resource exhaustion), the **absence of timeout and failure detection mechanisms** converts transient issues into permanent liveness failures, significantly amplifying their impact on the network.

The issue is particularly concerning for remote execution mode where network variability is expected, yet there are no application-level timeouts beyond the 5-second GRPC timeout at the network layer, which only applies to individual RPC calls, not the entire block execution process.

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/coordinator_client.rs (L8-13)
```rust
// Interface to communicate from the executor shards to the block executor coordinator.
pub trait CoordinatorClient<S: StateView + Sync + Send + 'static>: Send + Sync {
    fn receive_execute_command(&self) -> ExecutorShardCommand<S>;

    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>);
}
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L164-175)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        let _timer = WAIT_FOR_SHARDED_OUTPUT_SECONDS.start_timer();
        trace!("LocalExecutorClient Waiting for results");
        let mut results = vec![];
        for (i, rx) in self.result_rxs.iter().enumerate() {
            results.push(
                rx.recv()
                    .unwrap_or_else(|_| panic!("Did not receive output from shard {}", i))?,
            );
        }
        Ok(results)
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L259-267)
```rust
impl<S: StateView + Sync + Send + 'static> CoordinatorClient<S> for LocalCoordinatorClient<S> {
    fn receive_execute_command(&self) -> ExecutorShardCommand<S> {
        self.command_rx.recv().unwrap()
    }

    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
        self.result_tx.send(result).unwrap()
    }
}
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L79-120)
```rust
impl CoordinatorClient<RemoteStateViewClient> for RemoteCoordinatorClient {
    fn receive_execute_command(&self) -> ExecutorShardCommand<RemoteStateViewClient> {
        match self.command_rx.recv() {
            Ok(message) => {
                let _rx_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx"])
                    .start_timer();
                let bcs_deser_timer = REMOTE_EXECUTOR_TIMER
                    .with_label_values(&[&self.shard_id.to_string(), "cmd_rx_bcs_deser"])
                    .start_timer();
                let request: RemoteExecutionRequest = bcs::from_bytes(&message.data).unwrap();
                drop(bcs_deser_timer);

                match request {
                    RemoteExecutionRequest::ExecuteBlock(command) => {
                        let init_prefetch_timer = REMOTE_EXECUTOR_TIMER
                            .with_label_values(&[&self.shard_id.to_string(), "init_prefetch"])
                            .start_timer();
                        let state_keys = Self::extract_state_keys(&command);
                        self.state_view_client.init_for_block(state_keys);
                        drop(init_prefetch_timer);

                        let (sub_blocks, concurrency, onchain_config) = command.into();
                        ExecutorShardCommand::ExecuteSubBlocks(
                            self.state_view_client.clone(),
                            sub_blocks,
                            concurrency,
                            onchain_config,
                        )
                    },
                }
            },
            Err(_) => ExecutorShardCommand::Stop,
        }
    }

    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
        let remote_execution_result = RemoteExecutionResult::new(result);
        let output_message = bcs::to_bytes(&remote_execution_result).unwrap();
        self.result_tx.send(Message::new(output_message)).unwrap();
    }
}
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L223-254)
```rust
            let command = self.coordinator_client.receive_execute_command();
            match command {
                ExecutorShardCommand::ExecuteSubBlocks(
                    state_view,
                    transactions,
                    concurrency_level_per_shard,
                    onchain_config,
                ) => {
                    num_txns += transactions.num_txns();
                    trace!(
                        "Shard {} received ExecuteBlock command of block size {} ",
                        self.shard_id,
                        num_txns
                    );
                    let exe_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "execute_block"]);
                    let ret = self.execute_block(
                        transactions,
                        state_view.as_ref(),
                        BlockExecutorConfig {
                            local: BlockExecutorLocalConfig::default_with_concurrency_level(
                                concurrency_level_per_shard,
                            ),
                            onchain: onchain_config,
                        },
                    );
                    drop(state_view);
                    drop(exe_timer);

                    let _result_tx_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "result_tx"]);
                    self.coordinator_client.send_execution_result(ret);
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L26-45)
```rust
    pub fn start<S: StateView + Sync + Send>(
        cross_shard_state_view: Arc<CrossShardStateView<S>>,
        cross_shard_client: Arc<dyn CrossShardClient>,
        round: RoundId,
    ) {
        loop {
            let msg = cross_shard_client.receive_cross_shard_msg(round);
            match msg {
                RemoteTxnWriteMsg(txn_commit_msg) => {
                    let (state_key, write_op) = txn_commit_msg.take();
                    cross_shard_state_view
                        .set_value(&state_key, write_op.and_then(|w| w.as_state_value()));
                },
                CrossShardMsg::StopMsg => {
                    trace!("Cross shard commit receiver stopped for round {}", round);
                    break;
                },
            }
        }
    }
```
