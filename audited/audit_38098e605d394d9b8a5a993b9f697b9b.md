# Audit Report

## Title
Indexer-gRPC Service Fatal Crash on Health Check Port Binding Failure

## Summary

The `register_probes_and_metrics_handler()` function in the indexer-grpc server framework uses `warp::serve().run()` which **panics** when port binding fails, triggering the panic handler that immediately terminates the entire process with `process::exit(12)`. This creates a denial-of-service vector where attackers can prevent service availability by occupying the health check port, and causes complete service crashes from natural port conflicts. [1](#0-0) 

## Finding Description

The vulnerability exists in the error handling (or lack thereof) for the health check server initialization. The function signature returns `()` rather than `Result<()>`, providing no mechanism to propagate binding errors: [2](#0-1) 

The critical issue occurs at the warp server initialization where `.run()` is called without error handling: [3](#0-2) [4](#0-3) 

When `warp::serve().run()` fails to bind (due to port already in use, permission denied, or invalid address), it **panics** rather than returning an error. This panic is caught by the custom panic handler: [5](#0-4) 

The panic handler logs the crash and calls `process::exit(12)`, terminating the **entire indexer service process**, including the main indexer task that may be successfully processing blockchain data.

The service initialization spawns both tasks concurrently with no coordination: [6](#0-5) 

This creates a race condition where the main indexer service may start successfully, but if the health check server subsequently fails to bind, the entire process crashes.

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria due to "API crashes":

1. **Complete Service Unavailability**: The entire indexer-grpc service crashes on port binding failure, even though the main indexer functionality operates on a different port and could function normally.

2. **Denial-of-Service Attack Vector**: An attacker who can occupy the health check port (through local process spawning, container manipulation, or configuration tampering) can prevent the indexer service from starting, denying blockchain data access to all dependent applications.

3. **Critical Infrastructure Impact**: The indexer-grpc service is critical infrastructure for the Aptos ecosystem, providing gRPC access to historical blockchain data. Its unavailability cascades to all applications, wallets, explorers, and services that depend on blockchain queries.

4. **Operational Brittleness**: Port conflicts occur naturally in production environments due to misconfiguration, rapid restart cycles (OS hasn't released the port), or other services using the same port. Each occurrence causes complete service failure requiring manual intervention.

5. **No Graceful Degradation**: Unlike other parts of the codebase that use `warp::serve().bind()` with proper error handling, this implementation provides no opportunity for error recovery, logging, or graceful shutdown. [7](#0-6) 

## Likelihood Explanation

**High likelihood** of exploitation or accidental triggering:

1. **Low Attacker Complexity**: An attacker with limited local system access can run any process that binds to the configured health check port, immediately preventing service startup.

2. **Common in Production**: Port conflicts are routine operational issues in production environments, especially during:
   - Rapid restart cycles during deployments
   - Container orchestration with dynamic port allocation
   - Multiple services on the same host
   - Configuration errors copying production configs

3. **No Authentication Required**: The attack requires no authentication, credentials, or privileged access - just the ability to bind to a TCP port on the same host.

4. **Persistent DoS**: Once the port is occupied, the indexer service cannot start until manual intervention removes the conflicting process.

## Recommendation

Replace `warp::serve().run()` with `warp::serve().try_bind()` or `warp::serve().bind()` to enable proper error handling:

```rust
async fn register_probes_and_metrics_handler<C>(
    config: GenericConfig<C>, 
    port: u16
) -> Result<()>  // Change return type to Result
where
    C: RunnableConfig,
{
    // ... existing endpoint setup code ...

    let routes = if cfg!(target_os = "linux") {
        #[cfg(target_os = "linux")]
        {
            readiness
                .or(metrics_endpoint)
                .or(status_endpoint)
                .or(profilez)
        }
        #[cfg(not(target_os = "linux"))]
        unreachable!()
    } else {
        readiness.or(metrics_endpoint).or(status_endpoint)
    };

    // Use try_bind instead of run to handle errors gracefully
    match warp::serve(routes).try_bind(([0, 0, 0, 0], port)) {
        Ok((addr, server)) => {
            tracing::info!("Health check server listening on {}", addr);
            server.await;
            Ok(())
        },
        Err(e) => {
            Err(anyhow::anyhow!(
                "Failed to bind health check server on port {}: {}. \
                 Port may already be in use or insufficient permissions.", 
                port, e
            ))
        }
    }
}
```

Update the task spawning to handle errors: [8](#0-7) 

Change to proper error propagation and logging without process termination:

```rust
let task_handler = tokio::spawn(async move {
    register_probes_and_metrics_handler(config_clone, health_port).await
});
```

## Proof of Concept

```rust
#[cfg(test)]
mod exploit_poc {
    use super::*;
    use std::net::TcpListener;
    
    #[tokio::test]
    async fn test_health_check_port_binding_failure_causes_panic() {
        // Simulate port already in use by binding to it first
        let port = 9000u16;
        let _occupied_port = TcpListener::bind(("0.0.0.0", port))
            .expect("Failed to bind to port in test");
        
        // Create test config using the same port
        #[derive(Clone, Debug, serde::Deserialize, serde::Serialize)]
        struct TestConfig {
            name: String,
        }
        
        #[async_trait::async_trait]
        impl RunnableConfig for TestConfig {
            async fn run(&self) -> Result<()> {
                // Main task that should work fine
                tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
                Ok(())
            }
            
            fn get_server_name(&self) -> String {
                self.name.clone()
            }
        }
        
        let config = GenericConfig {
            health_check_port: port,
            server_config: TestConfig { name: "test".into() },
        };
        
        // This will panic when trying to bind to the already-occupied port
        // The panic handler will call process::exit(12)
        // In production, this terminates the entire service
        let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
            tokio::runtime::Runtime::new().unwrap().block_on(async {
                register_probes_and_metrics_handler(config, port).await;
            })
        }));
        
        // Verify that a panic occurred
        assert!(result.is_err(), "Expected panic when port binding fails");
    }
}
```

**Attack Demonstration:**
```bash
# Terminal 1: Occupy the health check port
nc -l 0.0.0.0 8080

# Terminal 2: Attempt to start indexer with same health check port
# The service will panic and exit with code 12
./indexer-grpc-server --config-path config.yaml
# Expected: Fatal panic, process exit 12
# Actual behavior: Should log error and continue or gracefully degrade
```

## Notes

The vulnerability stems from using the convenience method `warp::serve().run()` which provides no error handling capability, contrasted with the proper pattern used elsewhere in the codebase where `warp::serve().bind()` is used with Result handling. The issue is exacerbated by the concurrent task spawning design where the main indexer service and health check server have no coordination, allowing the health check failure to crash a potentially functioning main service.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L50-58)
```rust
    let health_port = config.health_check_port;
    // Start liveness and readiness probes.
    let config_clone = config.clone();
    let task_handler = tokio::spawn(async move {
        register_probes_and_metrics_handler(config_clone, health_port).await;
        anyhow::Ok(())
    });
    let main_task_handler =
        tokio::spawn(async move { config.run().await.expect("task should exit with Ok.") });
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L149-168)
```rust
pub fn setup_panic_handler() {
    std::panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());
    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);
    // Kill the process
    process::exit(12);
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L196-199)
```rust
async fn register_probes_and_metrics_handler<C>(config: GenericConfig<C>, port: u16)
where
    C: RunnableConfig,
{
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L251-258)
```rust
        warp::serve(
            readiness
                .or(metrics_endpoint)
                .or(status_endpoint)
                .or(profilez),
        )
        .run(([0, 0, 0, 0], port))
        .await;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-server-framework/src/lib.rs (L260-263)
```rust
        warp::serve(readiness.or(metrics_endpoint).or(status_endpoint))
            .run(([0, 0, 0, 0], port))
            .await;
    }
```

**File:** crates/aptos-warp-webserver/src/webserver.rs (L34-50)
```rust
    pub async fn serve<F>(&self, routes: F)
    where
        F: Filter<Error = Infallible> + Clone + Sync + Send + 'static,
        F::Extract: Reply,
    {
        match &self.tls_cert_path {
            None => warp::serve(routes).bind(self.address).await,
            Some(cert_path) => {
                warp::serve(routes)
                    .tls()
                    .cert_path(cert_path)
                    .key_path(self.tls_key_path.as_ref().unwrap())
                    .bind(self.address)
                    .await
            },
        }
    }
```
