# Audit Report

## Title
Byzantine Validators Can Execute Split-View Attacks on State Sync Through Unauthenticated Storage Server Summaries

## Summary
Byzantine validators can advertise different `StorageServerSummary` data to different peers without cryptographic verification, enabling split-view attacks that create network partitions where nodes have inconsistent views of data availability in the state synchronization layer.

## Finding Description

The Aptos state-sync system allows validators to advertise their available data through `StorageServerSummary` messages. However, this advertisement mechanism lacks cryptographic authentication, enabling Byzantine validators to send different summaries to different peers.

**Vulnerability Flow:**

1. **Unauthenticated Summary Generation**: The storage service handler returns summaries without any signature or proof. [1](#0-0) 

2. **No Client-Side Verification**: When clients receive summaries from peers, they accept them without cryptographic verification. [2](#0-1) 

3. **Naive Aggregation**: The global data summary is calculated by simply collecting all advertised ranges from all peers via union operation, without cross-validation. [3](#0-2) 

**Attack Execution:**

A Byzantine validator can modify their storage service to return different `StorageServerSummary` responses based on the requesting peer's identity (`peer_network_id` parameter available in the handler). For example:
- To Peer Group A: Advertise transactions 0-1000 are available
- To Peer Group B: Advertise transactions 1001-2000 are available  
- Reality: Only has transactions 0-500

This creates divergent `GlobalDataSummary` views across the network, where different nodes believe different data is available from that validator.

**Broken Invariants:**

This violates the **State Consistency** invariant - while state transitions themselves remain atomic and verifiable, the *discovery* mechanism for available data becomes inconsistent across nodes, leading to divergent views of network state availability.

## Impact Explanation

**Severity: Critical**

This vulnerability qualifies as **Critical** under the Aptos bug bounty program for the following reasons:

1. **Network Partition**: Different nodes maintain fundamentally different views of data availability, creating logical network partitions. Nodes in different partitions may be unable to sync with each other effectively.

2. **State Sync Failure**: If a Byzantine validator advertises critical epoch-ending ledger infos or state snapshots to only some nodes, it can prevent other nodes from synchronizing, causing **partial network liveness failure**.

3. **Consensus Layer Impact**: While this is a state-sync vulnerability, prolonged state sync failures can cascade to consensus participation, as nodes that cannot sync cannot validate or propose blocks effectively.

4. **Difficulty of Detection**: Unlike consensus-layer Byzantine behavior which is cryptographically attributable, split-view attacks on unauthenticated advertisements are difficult to detect and attribute to specific validators.

The peer scoring system provides only reactive mitigation (lowering scores after failures) but cannot prevent the initial split-view or detect that different peers are receiving different summaries from the same validator. [4](#0-3) 

## Likelihood Explanation

**Likelihood: Medium**

**Attack Requirements:**
- Attacker must operate a validator node (privileged position)
- Attacker must modify storage service code to implement peer-specific response logic
- Does NOT require stake majority (works under < 1/3 Byzantine assumption)
- Does NOT require collusion with other validators

**Complexity:**
- Technically straightforward to implement (simple conditional logic based on `peer_network_id`)
- Difficult to detect as the split-view creates no on-chain evidence
- Can be executed continuously without immediate consequences

**Mitigating Factors:**
- Requires validator-level access
- Eventually detected through peer scoring when requests fail
- Limited to state-sync layer (doesn't directly compromise consensus)

## Recommendation

Implement cryptographic authentication for `StorageServerSummary` advertisements:

**1. Add Signature to StorageServerSummary:**
```rust
pub struct StorageServerSummary {
    pub protocol_metadata: ProtocolMetadata,
    pub data_summary: DataSummary,
    pub signature: ValidatorSignature, // NEW: Validator signature over summary
    pub validator_public_key: ValidatorPublicKey, // NEW: For verification
}
```

**2. Sign summaries on server side:**
```rust
fn get_storage_server_summary(&self) -> DataResponse {
    let storage_server_summary = self.cached_storage_server_summary.load().clone();
    // Sign the summary with validator's private key
    let signed_summary = self.validator_signer.sign_storage_summary(storage_server_summary);
    DataResponse::StorageServerSummary(signed_summary)
}
```

**3. Verify signatures on client side:**
```rust
// In poller.rs after receiving storage_summary
let storage_summary = match result {
    Ok(storage_summary) => {
        // NEW: Verify signature before accepting
        if !verify_storage_summary_signature(&storage_summary, &validator_set) {
            warn!("Invalid signature on storage summary from peer: {:?}", peer);
            return;
        }
        storage_summary
    },
    Err(error) => { /* ... */ }
};
```

**4. Add gossip-based cross-validation:**

Implement a mechanism where nodes periodically gossip and compare summaries they've received from the same validators. If inconsistencies are detected, flag the validator for investigation and reduce trust.

**Alternative Mitigation:**

If full cryptographic signatures are too expensive, implement:
- Merkle commitment to the data summary in consensus-committed blocks
- Nodes cross-reference advertised summaries against on-chain commitments
- Byzantine validators advertising false summaries can be provably detected and slashed

## Proof of Concept

```rust
// Modified storage service handler for Byzantine behavior
// File: state-sync/storage-service/server/src/handler.rs

fn get_storage_server_summary_byzantine(
    &self,
    peer_network_id: &PeerNetworkId,
) -> DataResponse {
    let mut storage_server_summary = self.cached_storage_server_summary.load().clone();
    
    // Byzantine behavior: Advertise different data to different peers
    let peer_id_bytes = peer_network_id.peer_id().into_bytes();
    let partition_group = peer_id_bytes[0] % 2; // Split peers into two groups
    
    if partition_group == 0 {
        // Group A: Show limited transaction range
        storage_server_summary.data_summary.transactions = 
            Some(CompleteDataRange::new(0, 1000).unwrap());
    } else {
        // Group B: Show different transaction range
        storage_server_summary.data_summary.transactions = 
            Some(CompleteDataRange::new(1001, 2000).unwrap());
    }
    
    DataResponse::StorageServerSummary(storage_server_summary.as_ref().clone())
}
```

**Demonstration Steps:**

1. Deploy modified storage service with peer-dependent summary logic
2. Connect multiple clients to this Byzantine validator
3. Observe that clients build different `GlobalDataSummary` views
4. Clients in Group A request transactions 500-600 → succeed from Byzantine validator
5. Clients in Group B request transactions 500-600 → fail (Byzantine validator claims not available)
6. Network partition emerges: Group A and B have inconsistent views of data availability

**Expected Result:**
- Different clients maintain divergent global summaries
- State sync failures occur when clients in different groups attempt to sync the same data
- No cryptographic evidence of Byzantine behavior as summaries are unsigned

## Notes

This vulnerability exists at the state synchronization layer rather than the consensus layer. While AptosBFT consensus tolerates < 1/3 Byzantine validators for block agreement, the state-sync data advertisement mechanism lacks equivalent Byzantine-fault-tolerance protections. The absence of cryptographic authentication on `StorageServerSummary` messages creates an exploitable asymmetry where Byzantine validators can partition the network's view of data availability without detection.

The vulnerability is explicitly within scope as the security question directly asks about "Byzantine validators" executing split-view attacks, indicating insider threat scenarios are being evaluated.

### Citations

**File:** state-sync/storage-service/server/src/handler.rs (L505-508)
```rust
    fn get_storage_server_summary(&self) -> DataResponse {
        let storage_server_summary = self.cached_storage_server_summary.load().clone();
        DataResponse::StorageServerSummary(storage_server_summary.as_ref().clone())
    }
```

**File:** state-sync/aptos-data-client/src/poller.rs (L422-439)
```rust
        let storage_summary = match result {
            Ok(storage_summary) => storage_summary,
            Err(error) => {
                warn!(
                    (LogSchema::new(LogEntry::StorageSummaryResponse)
                        .event(LogEvent::PeerPollingError)
                        .message("Error encountered when polling peer!")
                        .error(&error)
                        .peer(&peer))
                );
                return;
            },
        };

        // Update the summary for the peer
        data_summary_poller
            .data_client
            .update_peer_storage_summary(peer, storage_summary);
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L143-174)
```rust
    pub fn get_storage_summary_if_not_ignored(&self) -> Option<&StorageServerSummary> {
        if self.is_ignored() {
            None
        } else {
            self.storage_summary.as_ref()
        }
    }

    /// Returns true iff the peer is currently ignored
    fn is_ignored(&self) -> bool {
        // Only ignore peers if the config allows it
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }

        // Otherwise, ignore peers with a low score
        self.score <= IGNORE_PEER_THRESHOLD
    }

    /// Updates the score of the peer according to a successful operation
    fn update_score_success(&mut self) {
        self.score = f64::min(self.score + SUCCESSFUL_RESPONSE_DELTA, MAX_SCORE);
    }

    /// Updates the score of the peer according to an error
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L339-408)
```rust
    pub fn calculate_global_data_summary(&self) -> GlobalDataSummary {
        // Gather all storage summaries, but exclude peers that are ignored
        let storage_summaries: Vec<StorageServerSummary> = self
            .peer_to_state
            .iter()
            .filter_map(|peer_state| {
                peer_state
                    .value()
                    .get_storage_summary_if_not_ignored()
                    .cloned()
            })
            .collect();

        // If we have no peers, return an empty global summary
        if storage_summaries.is_empty() {
            return GlobalDataSummary::empty();
        }

        // Calculate the global data summary using the advertised peer data
        let mut advertised_data = AdvertisedData::empty();
        let mut max_epoch_chunk_sizes = vec![];
        let mut max_state_chunk_sizes = vec![];
        let mut max_transaction_chunk_sizes = vec![];
        let mut max_transaction_output_chunk_sizes = vec![];
        for summary in storage_summaries {
            // Collect aggregate data advertisements
            if let Some(epoch_ending_ledger_infos) = summary.data_summary.epoch_ending_ledger_infos
            {
                advertised_data
                    .epoch_ending_ledger_infos
                    .push(epoch_ending_ledger_infos);
            }
            if let Some(states) = summary.data_summary.states {
                advertised_data.states.push(states);
            }
            if let Some(synced_ledger_info) = summary.data_summary.synced_ledger_info.as_ref() {
                advertised_data
                    .synced_ledger_infos
                    .push(synced_ledger_info.clone());
            }
            if let Some(transactions) = summary.data_summary.transactions {
                advertised_data.transactions.push(transactions);
            }
            if let Some(transaction_outputs) = summary.data_summary.transaction_outputs {
                advertised_data
                    .transaction_outputs
                    .push(transaction_outputs);
            }

            // Collect preferred max chunk sizes
            max_epoch_chunk_sizes.push(summary.protocol_metadata.max_epoch_chunk_size);
            max_state_chunk_sizes.push(summary.protocol_metadata.max_state_chunk_size);
            max_transaction_chunk_sizes.push(summary.protocol_metadata.max_transaction_chunk_size);
            max_transaction_output_chunk_sizes
                .push(summary.protocol_metadata.max_transaction_output_chunk_size);
        }

        // Calculate optimal chunk sizes based on the advertised data
        let optimal_chunk_sizes = calculate_optimal_chunk_sizes(
            &self.data_client_config,
            max_epoch_chunk_sizes,
            max_state_chunk_sizes,
            max_transaction_chunk_sizes,
            max_transaction_output_chunk_sizes,
        );
        GlobalDataSummary {
            advertised_data,
            optimal_chunk_sizes,
        }
    }
```
