# Audit Report

## Title
Critical Race Condition in Layout Cache During Module Publishing Causes Consensus Divergence

## Summary
A race condition exists in the global layout cache (`GlobalModuleCache.struct_layouts`) that allows stale type layouts to be cached after module republishing. During parallel block execution, a transaction can compute a layout based on an old module version, then store it to the cache after another transaction has published a new module version and flushed the cache. This causes non-deterministic layout caching across validators, violating the deterministic execution invariant and potentially causing state root divergence.

## Finding Description

The vulnerability exists in the interaction between layout construction, caching, and module publishing during parallel block execution (Block-STM).

**Core Issue:** Layout construction and storage are not atomic with respect to module updates. The sequence is:
1. Check cache (miss)
2. Compute layout by reading module definitions
3. Store layout to cache

When a module is republished during parallel execution, `flush_layout_cache()` is called to clear all cached layouts. However, there is no mechanism to prevent a transaction that already computed a layout based on the old module version from storing that stale layout after the flush. [1](#0-0) 

The layout is stored via a DashMap that only checks if the entry is vacant: [2](#0-1) 

**Exploitation Scenario:**

Thread 1 (Transaction T_j, index j):
1. Needs layout for struct `S` in module `M`
2. Cache miss - reads module `M` version V1
3. Begins computing layout based on V1...

Thread 2 (Transaction T_i, index i < j, committing):
1. Publishes module `M` version V2 with different struct definition
2. Adds module to per-block cache
3. Calls `flush_layout_cache()` - cache is now empty [3](#0-2) 

Thread 1 (continues):
1. Finishes computing layout based on V1
2. Calls `store_struct_layout_entry` 
3. Cache entry is vacant (just flushed), inserts STALE layout
4. Returns to transaction execution

Thread 3 (Transaction T_k, index k > i):
1. Needs same layout for struct `S`
2. Cache HIT - gets stale layout based on V1!
3. Reads module `M` version V2 (correct)
4. Uses layout from V1 (WRONG) for serialization/deserialization

**Why This Breaks Consensus:**

The `StructKey` only contains the struct index and type arguments, not the module version: [4](#0-3) 

Different validators executing the same block in parallel may have different timing:
- Validator A: T_j stores stale layout before T_i flushes → stale layout cached
- Validator B: T_i flushes before T_j stores → new layout cached (or no cache)
- Result: Different validators use different layouts for the same type
- This causes different serialization/deserialization behavior
- Leads to different state roots for identical blocks
- **Consensus violation and potential chain split**

While Transaction T_j will be invalidated and re-executed (because it read an overridden module), the stale layout it stored remains in the global cache. The layout cache is shared mutable state outside the transactional validation system - there is no rollback mechanism for layouts stored by invalidated transactions. [5](#0-4) 

## Impact Explanation

**Severity: CRITICAL** (Consensus/Safety violation)

This vulnerability breaks the fundamental "Deterministic Execution" invariant. All validators must produce identical state roots for identical blocks, but this race condition causes non-deterministic layout caching.

**Concrete Impact:**
1. **State Root Divergence**: Validators compute different state roots due to different cached layouts
2. **Consensus Failure**: Validators cannot reach agreement on block state
3. **Chain Split Risk**: Network could partition into validators with different cached states
4. **Requires Hard Fork**: Recovery requires manual intervention and consensus rule changes

This meets the **Critical Severity** criteria from the Aptos bug bounty:
- "Consensus/Safety violations" 
- "Non-recoverable network partition (requires hardfork)"

The impact is magnified because:
- Occurs during normal operation (any module publish in parallel execution)
- Non-deterministic (depends on thread scheduling)
- Silent corruption (no error, just wrong state)
- Persistent (stale layout remains until next flush)

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

**Required Conditions:**
1. Parallel block execution enabled (default for mainnet)
2. Module republishing within a block
3. Concurrent transaction needs layout for affected struct
4. Specific thread interleaving (race window)

**Why It's Likely:**
- Module upgrades are common in Aptos (governance proposals, framework updates)
- Parallel execution creates many opportunities for races
- No special attacker privileges required
- Any transaction can trigger layout construction

**Why It's Not Certain:**
- Requires specific timing (race window)
- Not all module publishes trigger the race
- May only affect validators with high parallelism

**Attack Feasibility:**
An attacker can increase likelihood by:
1. Publishing a module upgrade
2. Immediately submitting transactions that use types from that module
3. Repeating until race conditions manifest
4. No special privileges needed beyond ability to publish modules (which is permissioned in Aptos, but still possible via governance)

The vulnerability is more likely to manifest naturally during legitimate module upgrades combined with heavy transaction load.

## Recommendation

**Fix: Add Version Checking to Layout Storage**

The layout cache should track module versions and validate they haven't changed before storing layouts. 

**Option 1: Include version in cache key (Preferred)**

Modify `StructKey` to include a version or module hash:

```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
    pub module_version: u64, // Add version tracking
}
```

**Option 2: Validate before storage**

Add validation in `store_struct_layout_entry`:

```rust
pub(crate) fn store_struct_layout_entry(
    &self,
    key: &StructKey,
    entry: LayoutCacheEntry,
    module_versions: &HashMap<ModuleId, u64>, // Track versions used during construction
) -> PartialVMResult<()> {
    // Check if any module used during layout construction has been overridden
    for module_id in entry.modules().iter() {
        if !self.module_cache.contains_not_overridden(module_id) {
            // Module was overridden, don't cache stale layout
            return Ok(());
        }
    }
    
    if let dashmap::Entry::Vacant(e) = self.struct_layouts.entry(*key) {
        e.insert(entry);
    }
    Ok(())
}
```

**Option 3: Disable layout caching during module publishes (Simple but less efficient)**

```rust
pub(crate) fn store_struct_layout_entry(
    &self,
    key: &StructKey,
    entry: LayoutCacheEntry,
) -> PartialVMResult<()> {
    // Don't cache layouts if any module has been overridden this block
    if self.has_overridden_modules.load(Ordering::Acquire) {
        return Ok(());
    }
    
    if let dashmap::Entry::Vacant(e) = self.struct_layouts.entry(*key) {
        e.insert(entry);
    }
    Ok(())
}
```

**Recommended Approach:** Option 2 is cleanest as it validates the exact modules used during layout construction without changing the cache key structure.

## Proof of Concept

**Conceptual PoC (Rust test outline):**

```rust
#[test]
fn test_layout_cache_race_on_module_publish() {
    // Setup: Create a module M with struct S { field: u64 }
    let mut global_cache = GlobalModuleCache::empty();
    let module_v1 = create_module_with_struct("S", vec![Type::U64]);
    global_cache.insert(module_id, module_v1);
    
    // Thread 1: Start computing layout for S
    let thread1 = thread::spawn(|| {
        // 1. Check cache - MISS
        let layout_opt = global_cache.get_struct_layout_entry(&key);
        assert!(layout_opt.is_none());
        
        // 2. Read module (V1) and compute layout
        thread::sleep(Duration::from_millis(10)); // Simulate computation
        let layout_v1 = compute_layout_from_module(&module_v1);
        
        // 3. Store to cache (may happen after flush!)
        global_cache.store_struct_layout_entry(&key, layout_v1);
    });
    
    // Thread 2: Publish new module version
    let thread2 = thread::spawn(|| {
        thread::sleep(Duration::from_millis(5));
        
        // Publish module V2 with different struct definition
        let module_v2 = create_module_with_struct("S", vec![Type::U128]); // Changed!
        global_cache.mark_overridden(&module_id);
        per_block_cache.insert_module(module_id, module_v2, txn_idx);
        
        // Flush layout cache
        global_cache.flush_layout_cache();
    });
    
    thread1.join().unwrap();
    thread2.join().unwrap();
    
    // Thread 3: Try to get layout
    let cached_layout = global_cache.get_struct_layout_entry(&key);
    
    // BUG: Cached layout may be based on V1 even though V2 is current!
    // This is non-deterministic depending on thread scheduling
    if let Some(layout) = cached_layout {
        // Verify: layout might be stale!
        assert!(layout_is_stale_check(layout, &module_v2));
    }
}
```

**Real-world reproduction:**
1. Deploy a Move module with a struct
2. Submit a governance proposal to upgrade the module with a different struct layout
3. During block execution when the upgrade commits, submit many transactions using that struct
4. Observe non-deterministic behavior across validator nodes
5. Check state roots diverge across validators

The race window is small but exists in every block with module publishing and parallel execution. In a high-throughput network, this will eventually manifest.

### Citations

**File:** third_party/move/move-vm/runtime/src/storage/ty_layout_converter.rs (L108-130)
```rust
            if let Some(key) = key {
                if let Some(result) = self.struct_definition_loader.load_layout_from_cache(
                    gas_meter,
                    traversal_context,
                    &key,
                ) {
                    return result;
                }

                // Otherwise a cache miss, compute the result and store it.
                let mut modules = DefiningModules::new();
                let layout = self.type_to_type_layout_with_delayed_fields_impl::<false>(
                    gas_meter,
                    traversal_context,
                    &mut modules,
                    ty,
                    check_option_type,
                )?;
                let cache_entry = LayoutCacheEntry::new(layout.clone(), modules);
                self.struct_definition_loader
                    .store_layout_to_cache(&key, cache_entry)?;
                return Ok(layout);
            }
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L86-97)
```rust
/// A global cache for verified code and derived information (such as layouts) that is concurrently
/// accessed during the block execution. Module cache is read-only, and modified safely only at
/// block boundaries. Layout cache can be modified during execution of the block.
pub struct GlobalModuleCache<K, D, V, E> {
    /// Module cache containing the verified code.
    module_cache: HashMap<K, Entry<D, V, E>>,
    /// Sum of serialized sizes (in bytes) of all cached modules.
    size: usize,
    /// Cached layouts of structs or enums. This cache stores roots only and is invalidated when
    /// modules are published.
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L181-189)
```rust
    pub(crate) fn store_struct_layout_entry(
        &self,
        key: &StructKey,
        entry: LayoutCacheEntry,
    ) -> PartialVMResult<()> {
        if let dashmap::Entry::Vacant(e) = self.struct_layouts.entry(*key) {
            e.insert(entry);
        }
        Ok(())
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L572-577)
```rust
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
        Ok(published)
```

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L79-83)
```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
}
```
