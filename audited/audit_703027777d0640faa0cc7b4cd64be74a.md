# Audit Report

## Title
Consensus Key Loading Failure Causes Unrecoverable Validator DoS During Epoch Transition

## Summary
When `load_consensus_key()` fails during epoch transition in `start_new_epoch()`, the code explicitly panics, causing the entire validator process to exit. This creates a validator DoS condition that persists until manual intervention, violating the system's liveness guarantees.

## Finding Description
The vulnerability exists in the epoch transition logic where consensus key loading is handled without graceful degradation. During epoch transitions (triggered by on-chain governance/staking events), the `start_new_epoch()` function loads the validator's consensus key from persistent storage. If this operation fails, the code unconditionally panics: [1](#0-0) 

The key loading can fail in several scenarios as implemented in `PersistentSafetyStorage`:
- Consensus key not found in storage (neither explicit nor default key exists)
- Key exists but doesn't match the expected public key from the validator verifier
- Storage backend errors or corruption [2](#0-1) 

When the panic occurs, the global panic handler terminates the entire process: [3](#0-2) 

The epoch manager runs as a long-lived tokio task spawned during consensus initialization: [4](#0-3) 

**Critical Inconsistency**: While SafetyRules initialization handles key loading failures gracefully by returning `Error::ValidatorKeyNotFound`, the EpochManager's direct call to `load_consensus_key()` panics immediately, preventing graceful degradation. [5](#0-4) 

## Impact Explanation
This issue meets **Critical Severity** criteria under "Total loss of liveness/network availability" and "Non-recoverable network partition" categories.

**Immediate Impact:**
- Complete validator process termination during epoch transition
- Loss of validator participation in consensus for the new epoch
- No automatic recovery mechanism exists in the codebase

**Persistent Impact:**
- Even with automatic restart mechanisms (Docker/Kubernetes), if the underlying storage issue persists, the validator enters a crash loop
- The validator cannot participate in any subsequent epochs until manual intervention
- Reduces overall network validator count, weakening consensus security

**Triggering Scenarios:**
1. **Validator Key Rotation Desynchronization**: On-chain validator key updates (via staking/governance) occur before local storage is updated
2. **Storage Corruption**: Disk failures or filesystem corruption affecting the consensus key storage
3. **Configuration Errors**: Mismatched keys between validator verifier and local storage
4. **Race Conditions**: Concurrent access to storage during key updates and epoch transitions

While some scenarios require operator error or hardware failure, the **validator key rotation desynchronization** scenario can occur during normal operations if the timing window between on-chain updates and local storage synchronization is exploited or occurs naturally.

## Likelihood Explanation
**Moderate to High Likelihood** for the following reasons:

1. **Epoch Transitions Are Frequent**: Occur regularly through on-chain governance
2. **Storage Operations Are Fallible**: Disk I/O, network storage backends, and concurrent access can fail
3. **Key Rotation Is Complex**: Synchronizing on-chain validator set changes with local storage has inherent race conditions
4. **No Graceful Degradation**: The panic is unconditional with no retry or fallback mechanism

The existence of dedicated test cases for key loading failures indicates this is a known operational concern: [6](#0-5) 

## Recommendation
Replace the panic with graceful error handling that matches the pattern used in SafetyRules initialization: [7](#0-6) 

**Proposed Fix:**
```rust
let loaded_consensus_key = match self.load_consensus_key(&epoch_state.verifier) {
    Ok(k) => Arc::new(k),
    Err(e) => {
        error!(
            epoch = epoch_state.epoch,
            error = ?e,
            "Failed to load consensus key. Validator may not be in active set."
        );
        // Return early or use a fallback mechanism
        // Option 1: Skip consensus participation but maintain liveness
        // Option 2: Use default key with degraded functionality
        // Option 3: Retry with exponential backoff
        counters::EPOCH_MANAGER_ISSUES_DETAILS
            .with_label_values(&["consensus_key_load_failure"])
            .inc();
        return; // Or implement appropriate recovery strategy
    },
};
```

Additionally, implement retry logic with exponential backoff for transient storage failures and proper synchronization mechanisms for key rotation scenarios.

## Proof of Concept
```rust
// Test demonstrating the panic condition
#[tokio::test]
async fn test_epoch_transition_key_loading_failure() {
    // Setup: Create a validator with valid storage
    let (mut epoch_manager, validator_signer) = setup_epoch_manager();
    
    // Create an epoch state with a public key different from storage
    let random_signer = ValidatorSigner::random([0xFFu8; 32]);
    let mut epoch_state = EpochState::empty();
    epoch_state.epoch = 2;
    epoch_state.verifier = ValidatorVerifier::new_single(
        validator_signer.author(),
        random_signer.public_key() // Mismatched key
    ).into();
    
    // Create epoch change proof
    let proof = create_epoch_proof_with_state(epoch_state);
    
    // Trigger epoch transition
    // Expected: Process panic and exit with code 12
    // Actual behavior: Panic occurs, process terminates
    let result = epoch_manager.initiate_new_epoch(proof).await;
    
    // This line is never reached due to panic
    assert!(result.is_err());
}
```

## Notes
This vulnerability represents a critical gap between the robust error handling in SafetyRules initialization and the fragile panic-on-error approach in EpochManager's direct key loading. The inconsistency suggests this may have been an oversight during development. The impact is amplified by the fact that epoch transitions are critical consensus events that should have multiple layers of fault tolerance, not single points of failure.

### Citations

**File:** consensus/src/epoch_manager.rs (L826-846)
```rust
        info!(epoch = epoch, "Update SafetyRules");

        let mut safety_rules =
            MetricsSafetyRules::new(self.safety_rules_manager.client(), self.storage.clone());
        match safety_rules.perform_initialize() {
            Err(e) if matches!(e, Error::ValidatorNotInSet(_)) => {
                warn!(
                    epoch = epoch,
                    error = e,
                    "Unable to initialize safety rules.",
                );
            },
            Err(e) => {
                error!(
                    epoch = epoch,
                    error = e,
                    "Unable to initialize safety rules.",
                );
            },
            Ok(()) => (),
        }
```

**File:** consensus/src/epoch_manager.rs (L1228-1233)
```rust
        let loaded_consensus_key = match self.load_consensus_key(&epoch_state.verifier) {
            Ok(k) => Arc::new(k),
            Err(e) => {
                panic!("load_consensus_key failed: {e}");
            },
        };
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L106-132)
```rust
    pub fn consensus_sk_by_pk(
        &self,
        pk: bls12381::PublicKey,
    ) -> Result<bls12381::PrivateKey, Error> {
        let _timer = counters::start_timer("get", CONSENSUS_KEY);
        let pk_hex = hex::encode(pk.to_bytes());
        let explicit_storage_key = format!("{}_{}", CONSENSUS_KEY, pk_hex);
        let explicit_sk = self
            .internal_store
            .get::<bls12381::PrivateKey>(explicit_storage_key.as_str())
            .map(|v| v.value);
        let default_sk = self.default_consensus_sk();
        let key = match (explicit_sk, default_sk) {
            (Ok(sk_0), _) => sk_0,
            (Err(_), Ok(sk_1)) => sk_1,
            (Err(_), Err(_)) => {
                return Err(Error::ValidatorKeyNotFound("not found!".to_string()));
            },
        };
        if key.public_key() != pk {
            return Err(Error::SecureStorageMissingDataError(format!(
                "Incorrect sk saved for {:?} the expected pk",
                pk
            )));
        }
        Ok(key)
    }
```

**File:** crates/crash-handler/src/lib.rs (L26-58)
```rust
pub fn setup_panic_handler() {
    panic::set_hook(Box::new(move |pi: &PanicHookInfo<'_>| {
        handle_panic(pi);
    }));
}

// Formats and logs panic information
fn handle_panic(panic_info: &PanicHookInfo<'_>) {
    // The Display formatter for a PanicHookInfo contains the message, payload and location.
    let details = format!("{}", panic_info);
    let backtrace = format!("{:#?}", Backtrace::new());

    let info = CrashInfo { details, backtrace };
    let crash_info = toml::to_string_pretty(&info).unwrap();
    error!("{}", crash_info);
    // TODO / HACK ALARM: Write crash info synchronously via eprintln! to ensure it is written before the process exits which error! doesn't guarantee.
    // This is a workaround until https://github.com/aptos-labs/aptos-core/issues/2038 is resolved.
    eprintln!("{}", crash_info);

    // Wait till the logs have been flushed
    aptos_logger::flush();

    // Do not kill the process if the panics happened at move-bytecode-verifier.
    // This is safe because the `state::get_state()` uses a thread_local for storing states. Thus the state can only be mutated to VERIFIER by the thread that's running the bytecode verifier.
    //
    // TODO: once `can_unwind` is stable, we should assert it. See https://github.com/rust-lang/rust/issues/92988.
    if state::get_state() == VMState::VERIFIER || state::get_state() == VMState::DESERIALIZER {
        return;
    }

    // Kill the process
    process::exit(12);
}
```

**File:** consensus/src/consensus_provider.rs (L99-123)
```rust
    let epoch_mgr = EpochManager::new(
        node_config,
        time_service,
        self_sender,
        consensus_network_client,
        timeout_sender,
        consensus_to_mempool_sender,
        execution_client,
        storage.clone(),
        quorum_store_db.clone(),
        reconfig_events,
        bounded_executor,
        aptos_time_service::TimeService::real(),
        vtxn_pool,
        rand_storage,
        consensus_publisher,
    );

    let (network_task, network_receiver) = NetworkTask::new(network_service_events, self_receiver);

    runtime.spawn(network_task.start());
    runtime.spawn(epoch_mgr.start(timeout_receiver, network_receiver));

    debug!("Consensus started.");
    (runtime, storage, quorum_store_db)
```

**File:** consensus/safety-rules/src/tests/suite.rs (L641-676)
```rust
// Tests for fetching a missing validator key from persistent storage.
fn test_key_not_in_store(safety_rules: &Callback) {
    let (mut safety_rules, signer) = safety_rules();
    let (mut proof, genesis_qc) = test_utils::make_genesis(&signer);
    let round = genesis_qc.certified_block().round();

    safety_rules.initialize(&proof).unwrap();

    let a1 = test_utils::make_proposal_with_qc(round + 1, genesis_qc, &signer);

    // Update to an epoch where the validator fails to retrive the respective key
    // from persistent storage
    let mut next_epoch_state = EpochState::empty();
    next_epoch_state.epoch = 1;
    let rand_signer = ValidatorSigner::random([0xFu8; 32]);
    next_epoch_state.verifier =
        ValidatorVerifier::new_single(signer.author(), rand_signer.public_key()).into();
    let a2 = test_utils::make_proposal_with_parent_and_overrides(
        Payload::empty(false, true),
        round + 2,
        &a1,
        Some(&a1),
        &signer,
        Some(1),
        Some(next_epoch_state),
    );
    proof
        .ledger_info_with_sigs
        .push(a2.block().quorum_cert().ledger_info().clone());

    // Expected failure due to validator key not being found.
    safety_rules.initialize(&proof).unwrap_err();

    let state = safety_rules.consensus_state().unwrap();
    assert!(!state.in_validator_set());
}
```
