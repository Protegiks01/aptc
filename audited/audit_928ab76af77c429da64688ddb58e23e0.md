# Audit Report

## Title
Silent Data Loss in Indexer gRPC Service: Partial Transaction Range Delivery Without Client Detection Mechanism

## Summary
The `channel_send_multiple_with_timeout()` function in the indexer-grpc-data-service can fail mid-way through sending transaction chunks to clients. When this occurs, clients receive incomplete transaction ranges but have no mechanism to detect the incompleteness because the `processed_range` field is always set to `None`. This results in indexers silently missing transactions, leading to data integrity violations. [1](#0-0) 

## Finding Description

The vulnerability exists in the streaming transaction delivery mechanism. When the data service prepares to send multiple transaction chunks to a client, it calls `channel_send_multiple_with_timeout()` which iterates through `resp_items` (a vector of `TransactionsResponse` objects) and sends each one individually using `send_timeout()`. [2](#0-1) 

The critical flaw is the use of the `?` operator on line 887. If `send_timeout()` fails after successfully sending some chunks, the function immediately returns an error, leaving remaining chunks unsent. The error handling in the caller simply breaks the connection: [3](#0-2) 

Critically, each `TransactionsResponse` has its `processed_range` field set to `None` during construction: [4](#0-3) 

**Attack Scenario:**
1. Server prepares transactions v1000-v2000, split into 10 chunks (100 txns each)
2. Client successfully receives chunks 1-4 (versions 1000-1400)
3. On chunk 5, `send_timeout()` fails due to slow client, network congestion, or buffer full (120s timeout exceeded)
4. Function returns error via `?` operator, chunks 5-10 (versions 1401-2000) are never sent
5. Server breaks connection (appears as normal stream termination to client)
6. Client has no way to detect that versions 1401-2000 are missing because:
   - `processed_range` is `None`, providing no range validation
   - gRPC stream closed without explicit error for already-sent data
   - Transaction versions appear continuous within received chunks

The `ProcessedRange` protobuf field was designed for exactly this purpose: [5](#0-4) 

Evidence this is a recognized issue: the v2 data service correctly populates `processed_range`: [6](#0-5) 

## Impact Explanation

This constitutes **HIGH severity** based on "Significant protocol violations" under the Aptos bug bounty criteria. The indexer-grpc service provides the foundational data layer for the Aptos ecosystem's indexing infrastructure. Applications including NFT marketplaces, DeFi protocols, wallets, and analytics platforms depend on indexers for accurate transaction history.

**Concrete Harms:**
- **Silent Data Gaps**: Indexers miss transactions without triggering errors or alerts
- **State Corruption**: Applications using incomplete indexer data make incorrect decisions (wrong token balances, missed transfers, incomplete event logs)
- **Trust Violation**: The service provides no integrity guarantees despite being critical infrastructure
- **Cascading Failures**: Multiple dependent systems can propagate incorrect state

While this doesn't directly affect consensus or validator nodes, it breaks the data integrity invariant that indexing services must provide complete, accurate transaction history.

## Likelihood Explanation

**HIGH likelihood** - This vulnerability triggers under realistic operational conditions:

1. **Network congestion**: High load periods exceed the 120-second timeout
2. **Slow clients**: Indexers processing complex transactions slowly fill channel buffers
3. **Transient failures**: Temporary network issues during multi-chunk transmission
4. **Resource exhaustion**: Client-side CPU/memory pressure slows consumption

The 120-second timeout and channel buffer size make failures probable under production load. Once triggered, the impact is deterministic - clients receive incomplete data without detection capability.

## Recommendation

Populate the `processed_range` field in `get_transactions_responses_builder()` to enable client-side validation:

```rust
fn get_transactions_responses_builder(
    transactions: Vec<Transaction>,
    chain_id: u32,
    txns_to_strip_filter: &BooleanTransactionFilter,
) -> (Vec<TransactionsResponse>, usize) {
    let (stripped_transactions, num_stripped) =
        strip_transactions(transactions, txns_to_strip_filter);
    let chunks = chunk_transactions(stripped_transactions, MESSAGE_SIZE_LIMIT);
    
    let mut current_version = chunks.first()
        .and_then(|chunk| chunk.first())
        .map(|txn| txn.version)
        .unwrap_or(0);
    
    let responses = chunks
        .into_iter()
        .map(|chunk| {
            let first_version = current_version;
            let last_version = chunk.last().unwrap().version;
            current_version = last_version + 1;
            
            TransactionsResponse {
                chain_id: Some(chain_id as u64),
                transactions: chunk,
                processed_range: Some(ProcessedRange {
                    first_version,
                    last_version,
                }),
            }
        })
        .collect();
    (responses, num_stripped)
}
```

Clients can then validate continuity by checking that each chunk's `first_version` equals the previous chunk's `last_version + 1`.

## Proof of Concept

```rust
#[tokio::test]
async fn test_partial_send_undetectable_gap() {
    use tokio::sync::mpsc::{channel, error::SendTimeoutError};
    use std::time::Duration;
    
    // Simulate channel with small buffer
    let (tx, mut rx) = channel::<Result<TransactionsResponse, Status>>(2);
    
    // Create 5 response chunks (versions 1000-1500)
    let mut resp_items = vec![];
    for i in 0..5 {
        let start = 1000 + i * 100;
        let mut transactions = vec![];
        for v in start..(start + 100) {
            transactions.push(Transaction {
                version: v,
                ..Default::default()
            });
        }
        resp_items.push(TransactionsResponse {
            chain_id: Some(1),
            transactions,
            processed_range: None,  // The vulnerability
        });
    }
    
    // Spawn sender task
    let send_handle = tokio::spawn(async move {
        for (idx, resp_item) in resp_items.into_iter().enumerate() {
            // Simulate send failure on 3rd chunk
            if idx == 2 {
                tokio::time::sleep(Duration::from_millis(100)).await;
                return Err(SendTimeoutError::Timeout(Ok(resp_item)));
            }
            tx.send_timeout(Ok(resp_item), Duration::from_secs(1))
                .await
                .unwrap();
        }
        Ok(())
    });
    
    // Client receives data
    let mut received_versions = vec![];
    while let Some(Ok(resp)) = rx.recv().await {
        for txn in resp.transactions {
            received_versions.push(txn.version);
        }
        // Client CANNOT detect gap without processed_range
        assert!(resp.processed_range.is_none());
    }
    
    // Verify partial receipt
    assert_eq!(received_versions.len(), 200);  // Only 2 chunks received
    assert_eq!(received_versions[0], 1000);
    assert_eq!(received_versions[199], 1199);
    // Gap at 1200-1499 is UNDETECTABLE by client
    
    let result = send_handle.await.unwrap();
    assert!(result.is_err());  // Send failed, but client doesn't know
}
```

This test demonstrates that clients receive incomplete ranges (1000-1199 instead of 1000-1499) without any mechanism to detect the gap when `processed_range` is `None`.

---

## Notes

This vulnerability is specific to `indexer-grpc-data-service` (v1). The v2 service correctly populates `processed_range`, indicating this issue was recognized and addressed in the newer implementation. However, if v1 remains deployed in production, it poses an active risk to indexer data integrity. The fix should be backported to v1 or v1 should be deprecated in favor of v2.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L543-568)
```rust
        match channel_send_multiple_with_timeout(resp_items, tx.clone(), request_metadata.clone())
            .await
        {
            Ok(_) => {
                // TODO: Reasses whether this metric is useful.
                LATEST_PROCESSED_VERSION_PER_PROCESSOR
                    .with_label_values(&request_metadata.get_label_values())
                    .set(end_of_batch_version as i64);
                PROCESSED_VERSIONS_COUNT_PER_PROCESSOR
                    .with_label_values(&request_metadata.get_label_values())
                    .inc_by(current_batch_size as u64);
                if let Some(data_latency_in_secs) = data_latency_in_secs {
                    PROCESSED_LATENCY_IN_SECS_PER_PROCESSOR
                        .with_label_values(&request_metadata.get_label_values())
                        .set(data_latency_in_secs);
                }
            },
            Err(SendTimeoutError::Timeout(_)) => {
                warn!("[Data Service] Receiver is full; exiting.");
                break;
            },
            Err(SendTimeoutError::Closed(_)) => {
                warn!("[Data Service] Receiver is closed; exiting.");
                break;
            },
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L674-691)
```rust
fn get_transactions_responses_builder(
    transactions: Vec<Transaction>,
    chain_id: u32,
    txns_to_strip_filter: &BooleanTransactionFilter,
) -> (Vec<TransactionsResponse>, usize) {
    let (stripped_transactions, num_stripped) =
        strip_transactions(transactions, txns_to_strip_filter);
    let chunks = chunk_transactions(stripped_transactions, MESSAGE_SIZE_LIMIT);
    let responses = chunks
        .into_iter()
        .map(|chunk| TransactionsResponse {
            chain_id: Some(chain_id as u64),
            transactions: chunk,
            processed_range: None,
        })
        .collect();
    (responses, num_stripped)
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L845-917)
```rust
async fn channel_send_multiple_with_timeout(
    resp_items: Vec<TransactionsResponse>,
    tx: tokio::sync::mpsc::Sender<Result<TransactionsResponse, Status>>,
    request_metadata: Arc<IndexerGrpcRequestMetadata>,
) -> Result<(), SendTimeoutError<Result<TransactionsResponse, Status>>> {
    let overall_send_start_time = Instant::now();
    let overall_size_in_bytes = resp_items
        .iter()
        .map(|resp_item| resp_item.encoded_len())
        .sum::<usize>();
    let overall_start_txn = resp_items.first().unwrap().transactions.first().unwrap();
    let overall_end_txn = resp_items.last().unwrap().transactions.last().unwrap();
    let overall_start_version = overall_start_txn.version;
    let overall_end_version = overall_end_txn.version;
    let overall_start_txn_timestamp = overall_start_txn.clone().timestamp;
    let overall_end_txn_timestamp = overall_end_txn.clone().timestamp;

    for resp_item in resp_items {
        let send_start_time = Instant::now();
        let response_size = resp_item.encoded_len();
        let num_of_transactions = resp_item.transactions.len();
        let start_version = resp_item.transactions.first().unwrap().version;
        let end_version = resp_item.transactions.last().unwrap().version;
        let start_version_txn_timestamp = resp_item
            .transactions
            .first()
            .unwrap()
            .timestamp
            .as_ref()
            .unwrap();
        let end_version_txn_timestamp = resp_item
            .transactions
            .last()
            .unwrap()
            .timestamp
            .as_ref()
            .unwrap();

        tx.send_timeout(
            Result::<TransactionsResponse, Status>::Ok(resp_item.clone()),
            RESPONSE_CHANNEL_SEND_TIMEOUT,
        )
        .await?;

        log_grpc_step(
            SERVICE_TYPE,
            IndexerGrpcStep::DataServiceChunkSent,
            Some(start_version as i64),
            Some(end_version as i64),
            Some(start_version_txn_timestamp),
            Some(end_version_txn_timestamp),
            Some(send_start_time.elapsed().as_secs_f64()),
            Some(response_size),
            Some(num_of_transactions as i64),
            Some(&request_metadata),
        );
    }

    log_grpc_step(
        SERVICE_TYPE,
        IndexerGrpcStep::DataServiceAllChunksSent,
        Some(overall_start_version as i64),
        Some(overall_end_version as i64),
        overall_start_txn_timestamp.as_ref(),
        overall_end_txn_timestamp.as_ref(),
        Some(overall_send_start_time.elapsed().as_secs_f64()),
        Some(overall_size_in_bytes),
        Some((overall_end_version - overall_start_version + 1) as i64),
        Some(&request_metadata),
    );

    Ok(())
}
```

**File:** protos/proto/aptos/indexer/v1/raw_data.proto (L35-49)
```text
message ProcessedRange {
    uint64 first_version = 1;
    uint64 last_version = 2;
}

// TransactionsResponse is a batch of transactions.
message TransactionsResponse {
  // Required; transactions data.
  repeated aptos.transaction.v1.Transaction transactions = 1;

  // Required; chain id.
  optional uint64 chain_id = 2 [jstype = JS_STRING];

  optional ProcessedRange processed_range = 3;
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L210-217)
```rust
                            TransactionsResponse {
                                transactions: chunk.to_vec(),
                                chain_id: Some(self.chain_id),
                                processed_range: Some(ProcessedRange {
                                    first_version,
                                    last_version,
                                }),
                            }
```
