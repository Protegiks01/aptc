# Audit Report

## Title
Remote Executor Service Lacks Health Checks Causing Indefinite Coordinator Blocking on Executor Thread Failures

## Summary
The remote executor service spawns a worker thread without storing its `JoinHandle` and provides no health check mechanism after initialization. If the executor thread panics or fails, the main process continues running while the coordinator blocks indefinitely waiting for execution results, causing a liveness failure in the sharded execution system.

## Finding Description

The executor service architecture has a critical flaw in its health monitoring: [1](#0-0) 

The main function creates a `ProcessExecutorService` and then waits indefinitely for Ctrl-C, with no monitoring of the executor's health. [2](#0-1) 

The `ExecutorService::start()` method spawns a thread for the executor but **does not store the `JoinHandle`**. This is in contrast to the local executor implementation: [3](#0-2) 

The local implementation properly stores the `JoinHandle` for thread lifecycle management.

**Failure Scenarios:**

1. **Thread Panic During Execution**: If the executor thread panics (due to OOM, bugs in Move VM, or unexpected errors), the thread terminates but the main process continues running. The panic handler is NOT set up in executor-service/main.rs (only in aptos-node): [4](#0-3) 

2. **Channel Send Failure**: The `send_execution_result` method uses `.unwrap()` which panics if the coordinator disconnects: [5](#0-4) 

3. **Coordinator Blocking**: When an executor fails, the coordinator blocks indefinitely with no timeout: [6](#0-5) 

The `recv().unwrap()` call has no timeout mechanism, confirmed by the codebase search showing no `recv_timeout` usage in this context.

**Execution Flow Leading to Failure:**

1. Coordinator sends `ExecuteBlockCommand` to multiple executor shards
2. One executor thread panics during execution (line 239-248 in sharded_executor_service.rs)
3. The executor's main process continues running (waiting for Ctrl-C)
4. Coordinator blocks on `rx.recv().unwrap()` waiting for results from the failed executor
5. Other executor shards may complete successfully, but the coordinator remains blocked
6. The entire block execution system is deadlocked [7](#0-6) 

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: The coordinator will be indefinitely blocked, preventing any further block execution
- **Significant protocol violations**: Breaks the deterministic execution invariant if some shards complete while one fails, potentially causing state inconsistency
- **Potential liveness failure**: If this occurs in production, it would require manual intervention to restart the executor service, causing downtime

The vulnerability affects the core execution path and can cause:
- Complete halt of block execution
- Inconsistent state across shards (if failure occurs mid-execution)
- No automatic recovery mechanism
- Silent failure (process continues running but is non-functional)

## Likelihood Explanation

**High likelihood** due to:

1. **No panic handler**: The executor service doesn't set up panic handlers, so thread panics don't terminate the process
2. **Multiple panic points**: Several `.unwrap()` calls throughout the execution path (serialization, channel operations)
3. **Normal failure scenarios**: Network disconnections, OOM, bugs in Move VM execution
4. **No timeout protection**: Coordinator has no timeout, so any failure causes indefinite blocking
5. **Complex execution logic**: The sharded executor involves multiple threads, channels, and network operations - all potential failure points

This is not a theoretical vulnerability requiring Byzantine behavior - it can occur through normal system failures or bugs.

## Recommendation

Implement comprehensive health checking and error recovery:

1. **Store JoinHandle and monitor thread health**:
```rust
pub struct ExecutorService {
    shard_id: ShardId,
    controller: NetworkController,
    executor_service: Arc<ShardedExecutorService<RemoteStateViewClient>>,
    executor_thread_handle: Option<thread::JoinHandle<()>>,
}

pub fn start(&mut self) {
    self.controller.start();
    let thread_name = format!("ExecutorService-{}", self.shard_id);
    let builder = thread::Builder::new().name(thread_name);
    let executor_service_clone = self.executor_service.clone();
    let handle = builder
        .spawn(move || {
            executor_service_clone.start();
        })
        .expect("Failed to spawn thread");
    self.executor_thread_handle = Some(handle);
}

pub fn is_healthy(&self) -> bool {
    self.executor_thread_handle
        .as_ref()
        .map(|h| !h.is_finished())
        .unwrap_or(false)
}
```

2. **Add timeout to coordinator recv calls**:
```rust
fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
    let timeout = Duration::from_secs(300); // 5 minute timeout
    let mut results = vec![];
    for rx in self.result_rxs.iter() {
        let received_bytes = rx.recv_timeout(timeout)
            .map_err(|_| VMStatus::Error(StatusCode::EXECUTION_TIMEOUT))?
            .to_bytes();
        let result: RemoteExecutionResult = bcs::from_bytes(&received_bytes)
            .map_err(|_| VMStatus::Error(StatusCode::FAILED_TO_DESERIALIZE_RESOURCE))?;
        results.push(result.inner?);
    }
    Ok(results)
}
```

3. **Add error handling in send_execution_result**:
```rust
fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
    let remote_execution_result = RemoteExecutionResult::new(result);
    match bcs::to_bytes(&remote_execution_result) {
        Ok(output_message) => {
            if let Err(e) = self.result_tx.send(Message::new(output_message)) {
                error!("Failed to send execution result: {:?}", e);
                // Exit the process or implement recovery logic
            }
        },
        Err(e) => {
            error!("Failed to serialize execution result: {:?}", e);
        }
    }
}
```

4. **Set up panic handler in main.rs**:
```rust
fn main() {
    let args = Args::parse();
    aptos_logger::Logger::new().init();
    aptos_crash_handler::setup_panic_handler();
    
    // ... rest of main
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;
    
    #[test]
    fn test_executor_thread_panic_causes_coordinator_hang() {
        // Setup coordinator and executor
        let coordinator_addr = get_available_socket_addr();
        let executor_addr = get_available_socket_addr();
        
        // Start executor service
        let mut executor_service = ExecutorService::new(
            0, // shard_id
            1, // num_shards
            2, // num_threads
            executor_addr,
            coordinator_addr,
            vec![executor_addr],
        );
        executor_service.start();
        
        // Simulate executor thread panic by killing it
        // (In real scenario, this could be OOM, bug, or network failure)
        std::thread::sleep(Duration::from_millis(100));
        
        // Create coordinator client
        let mut coordinator_controller = NetworkController::new(
            "test-coordinator".to_string(),
            coordinator_addr,
            5000,
        );
        let remote_executor_client = RemoteExecutorClient::new(
            vec![executor_addr],
            coordinator_controller,
            None,
        );
        
        // Send execute command - this will hang indefinitely
        // because the executor thread has failed
        let result = std::panic::catch_unwind(|| {
            // This should timeout or return error, but currently hangs
            remote_executor_client.execute_block(
                Arc::new(test_state_view),
                test_transactions,
                4,
                BlockExecutorConfigFromOnchain::default(),
            );
        });
        
        // Test demonstrates the hang - in practice would need timeout
        assert!(result.is_err(), "Should detect executor failure");
    }
}
```

**Notes**

This vulnerability represents a fundamental design flaw in the remote executor service architecture. The lack of health checks, timeout mechanisms, and proper thread lifecycle management creates multiple failure modes that can cause indefinite system blocking. The issue is particularly critical because it affects the core execution path and has no automatic recovery mechanism, requiring manual intervention to restore functionality.

### Citations

**File:** execution/executor-service/src/main.rs (L27-48)
```rust
fn main() {
    let args = Args::parse();
    aptos_logger::Logger::new().init();

    let (tx, rx) = crossbeam_channel::unbounded();
    ctrlc::set_handler(move || {
        tx.send(()).unwrap();
    })
    .expect("Error setting Ctrl-C handler");

    let _exe_service = ProcessExecutorService::new(
        args.shard_id,
        args.num_shards,
        args.num_executor_threads,
        args.coordinator_address,
        args.remote_executor_addresses,
    );

    rx.recv()
        .expect("Could not receive Ctrl-C msg from channel.");
    info!("Process executor service shutdown successfully.");
}
```

**File:** execution/executor-service/src/remote_executor_service.rs (L57-67)
```rust
    pub fn start(&mut self) {
        self.controller.start();
        let thread_name = format!("ExecutorService-{}", self.shard_id);
        let builder = thread::Builder::new().name(thread_name);
        let executor_service_clone = self.executor_service.clone();
        builder
            .spawn(move || {
                executor_service_clone.start();
            })
            .expect("Failed to spawn thread");
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L33-63)
```rust
pub struct LocalExecutorService<S: StateView + Sync + Send + 'static> {
    join_handle: Option<thread::JoinHandle<()>>,
    phantom: std::marker::PhantomData<S>,
}

impl<S: StateView + Sync + Send + 'static> LocalExecutorService<S> {
    fn new(
        shard_id: ShardId,
        num_shards: usize,
        num_threads: usize,
        command_rx: Receiver<ExecutorShardCommand<S>>,
        result_tx: Sender<Result<Vec<Vec<TransactionOutput>>, VMStatus>>,
        cross_shard_client: LocalCrossShardClient,
    ) -> Self {
        let coordinator_client = Arc::new(LocalCoordinatorClient::new(command_rx, result_tx));
        let executor_service = Arc::new(ShardedExecutorService::new(
            shard_id,
            num_shards,
            num_threads,
            coordinator_client,
            Arc::new(cross_shard_client),
        ));
        let join_handle = thread::Builder::new()
            .name(format!("executor-shard-{}", shard_id))
            .spawn(move || executor_service.start())
            .unwrap();
        Self {
            join_handle: Some(join_handle),
            phantom: std::marker::PhantomData,
        }
    }
```

**File:** execution/executor-service/src/remote_cordinator_client.rs (L115-119)
```rust
    fn send_execution_result(&self, result: Result<Vec<Vec<TransactionOutput>>, VMStatus>) {
        let remote_execution_result = RemoteExecutionResult::new(result);
        let output_message = bcs::to_bytes(&remote_execution_result).unwrap();
        self.result_tx.send(Message::new(output_message)).unwrap();
    }
```

**File:** execution/executor-service/src/remote_executor_client.rs (L163-172)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        trace!("RemoteExecutorClient Waiting for results");
        let mut results = vec![];
        for rx in self.result_rxs.iter() {
            let received_bytes = rx.recv().unwrap().to_bytes();
            let result: RemoteExecutionResult = bcs::from_bytes(&received_bytes).unwrap();
            results.push(result.inner?);
        }
        Ok(results)
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L215-260)
```rust
    pub fn start(&self) {
        trace!(
            "Shard starting, shard_id={}, num_shards={}.",
            self.shard_id,
            self.num_shards
        );
        let mut num_txns = 0;
        loop {
            let command = self.coordinator_client.receive_execute_command();
            match command {
                ExecutorShardCommand::ExecuteSubBlocks(
                    state_view,
                    transactions,
                    concurrency_level_per_shard,
                    onchain_config,
                ) => {
                    num_txns += transactions.num_txns();
                    trace!(
                        "Shard {} received ExecuteBlock command of block size {} ",
                        self.shard_id,
                        num_txns
                    );
                    let exe_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "execute_block"]);
                    let ret = self.execute_block(
                        transactions,
                        state_view.as_ref(),
                        BlockExecutorConfig {
                            local: BlockExecutorLocalConfig::default_with_concurrency_level(
                                concurrency_level_per_shard,
                            ),
                            onchain: onchain_config,
                        },
                    );
                    drop(state_view);
                    drop(exe_timer);

                    let _result_tx_timer = SHARDED_EXECUTOR_SERVICE_SECONDS
                        .timer_with(&[&self.shard_id.to_string(), "result_tx"]);
                    self.coordinator_client.send_execution_result(ret);
                },
                ExecutorShardCommand::Stop => {
                    break;
                },
            }
        }
```
