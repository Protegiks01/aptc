# Audit Report

## Title
Asynchronous Metadata Write Failure in Indexer DBCommitter Leads to Silent Data Loss and State Inconsistency

## Summary
The indexer's `DBCommitter` uses an asynchronous write pattern with panic-on-failure error handling, causing silent metadata write failures that lead to indexer state inconsistencies without proper error propagation to the caller.

## Finding Description
The indexer metadata write system has a critical flaw in its error handling architecture. The `DBIndexer` employs an asynchronous commit pattern where metadata writes are delegated to a background thread, but database failures result in thread panics without proper error propagation. [1](#0-0) 

The vulnerability manifests through this execution flow:

1. The main processing thread in `process_a_batch` creates a batch containing critical metadata including `LatestVersion`, `EventVersion`, `TransactionVersion`, and `StateVersion` [2](#0-1) 

2. The batch is sent via channel to the background `DBCommitter` thread, and the main thread immediately returns success [3](#0-2) 

3. The `DBCommitter` thread asynchronously processes writes using `.expect()` which panics on any database failure (disk full, I/O errors, corruption)

4. There is no mechanism to propagate errors back from the committer thread to the caller, meaning the main thread reports successful processing even when metadata persistence fails

This breaks the **State Consistency** invariant for the indexer subsystem. Upon restart, the indexer reads stale metadata from the database, leading to:
- **Transaction skipping**: If the in-memory version counter advanced but `LatestVersion` wasn't persisted
- **Duplicate processing**: If `LatestVersion` was written but event/transaction metadata writes failed
- **Missing index data**: Events, transactions, or state keys that were reported as indexed but weren't persisted
- **Query inconsistencies**: Applications querying the indexer receive incomplete or incorrect historical data

## Impact Explanation
This qualifies as **Medium Severity** under the Aptos bug bounty criteria: "State inconsistencies requiring intervention."

While this doesn't directly affect consensus or core blockchain operation (the indexer is a read-only query layer), it creates significant operational issues:
- The indexer provides critical data for dApps, block explorers, and analytics platforms
- State inconsistencies require manual intervention and potentially full reindexing
- Applications relying on the indexer may receive incorrect data leading to business logic errors
- The async pattern with no error feedback makes debugging extremely difficult

The testing schema only validates successful encoding/decoding paths: [4](#0-3) 

No fault injection tests exist to validate error handling during database failures, leaving this critical failure mode untested.

## Likelihood Explanation
**Likelihood: Medium**

Database write failures can occur through multiple realistic scenarios:
- Disk space exhaustion on validator nodes running the indexer
- I/O errors from hardware failures or network storage issues
- Database corruption from system crashes during writes
- Resource limits (file descriptors, memory) being exceeded
- RocksDB internal errors during compaction or write stalls

The async commit pattern masks these failures, making them difficult to detect until queries return inconsistent data. The lack of monitoring or alerting for committer thread panics increases the likelihood of prolonged undetected failures.

## Recommendation
Implement synchronous error propagation from the DBCommitter to the caller:

1. **Replace panic with error channel**: Create a bidirectional communication channel where the committer can send write results back to the main thread

2. **Synchronous error checking**: After sending a batch, wait for confirmation or error from the committer before returning success

3. **Add comprehensive fault injection tests**: Create tests that simulate various database failure modes (disk full, I/O errors, corruption) to validate error handling and recovery

4. **Implement retry logic with exponential backoff**: For transient failures, add retry mechanisms before failing permanently

5. **Add monitoring and alerting**: Instrument the committer to emit metrics on write failures and thread health

Example fix structure (pseudocode):
```rust
pub struct DBCommitter {
    db: Arc<DB>,
    receiver: Receiver<BatchRequest>,
}

struct BatchRequest {
    batch: SchemaBatch,
    response_tx: oneshot::Sender<Result<()>>,
}

impl DBCommitter {
    pub fn run(&self) {
        loop {
            let request = self.receiver.recv().expect("Channel closed");
            let result = self.db.write_schemas(request.batch);
            let _ = request.response_tx.send(result);
        }
    }
}

// In DBIndexer::process_a_batch
let (response_tx, response_rx) = oneshot::channel();
self.sender.send(BatchRequest { batch, response_tx })?;
response_rx.await??; // Propagate error to caller
```

## Proof of Concept
```rust
#[test]
fn test_metadata_write_failure_detection() {
    // Create a mock DB that fails on write_schemas
    let mock_db = Arc::new(FailingDB::new());
    let (sender, receiver) = mpsc::channel();
    
    let committer = DBCommitter::new(mock_db.clone(), receiver);
    let handle = thread::spawn(move || committer.run());
    
    // Create a batch with metadata
    let mut batch = SchemaBatch::new();
    batch.put::<InternalIndexerMetadataSchema>(
        &MetadataKey::LatestVersion,
        &MetadataValue::Version(100)
    ).unwrap();
    
    // Send batch and expect the error to be propagated
    sender.send(Some(batch)).unwrap();
    
    // Currently: The committer thread panics and the error is lost
    // Expected: Error should be propagated back to caller
    // This test should fail with current implementation
    
    // Verify the committer thread didn't panic
    thread::sleep(Duration::from_millis(100));
    assert!(!handle.is_finished(), "Committer should still be running");
}

struct FailingDB;
impl FailingDB {
    fn write_schemas(&self, _: SchemaBatch) -> Result<()> {
        Err(AptosDbError::OtherRocksDbError("Simulated disk full".into()))
    }
}
```

## Notes
The vulnerability specifically addresses the lack of fault injection testing as raised in the security question. The absence of such tests has allowed this silent failure mode to exist in production code, where database write errors go undetected by callers. While the indexer is not part of consensus, its reliability is critical for the Aptos ecosystem's usability and the trust users place in queried data.

### Citations

**File:** storage/indexer/src/db_indexer.rs (L62-76)
```rust
    pub fn run(&self) {
        loop {
            let batch_opt = self
                .receiver
                .recv()
                .expect("Failed to receive batch from DB Indexer");
            if let Some(batch) = batch_opt {
                self.db
                    .write_schemas(batch)
                    .expect("Failed to write batch to indexer db");
            } else {
                break;
            }
        }
    }
```

**File:** storage/indexer/src/db_indexer.rs (L506-549)
```rust
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::EventV2TranslationVersion,
                &MetadataValue::Version(version - 1),
            )?;

            for event_key in event_keys {
                batch
                    .put::<EventSequenceNumberSchema>(
                        &event_key,
                        &self
                            .event_v2_translation_engine
                            .get_cached_sequence_number(&event_key)
                            .unwrap_or(0),
                    )
                    .expect("Failed to put events by key to a batch");
            }
        }

        if self.indexer_db.transaction_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::TransactionVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        if self.indexer_db.event_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::EventVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        if self.indexer_db.statekeys_enabled() {
            batch.put::<InternalIndexerMetadataSchema>(
                &MetadataKey::StateVersion,
                &MetadataValue::Version(version - 1),
            )?;
        }
        batch.put::<InternalIndexerMetadataSchema>(
            &MetadataKey::LatestVersion,
            &MetadataValue::Version(version - 1),
        )?;
        self.sender
            .send(Some(batch))
            .map_err(|e| AptosDbError::Other(e.to_string()))?;
        Ok(version)
```

**File:** storage/indexer_schemas/src/schema/indexer_metadata/test.rs (L8-24)
```rust
proptest! {
    #[test]
    fn test_encode_decode(
        tag in any::<MetadataKey>(),
        metadata in any::<MetadataValue>(),
    ) {
        assert_encode_decode::<IndexerMetadataSchema>(&tag, &metadata);
    }

    #[test]
    fn test_encode_decode_internal_indexer_metadata(
        key in any::<MetadataKey>(),
        metadata in any::<MetadataValue>(),
    ) {
        assert_encode_decode::<InternalIndexerMetadataSchema>(&key, &metadata);
    }
}
```
