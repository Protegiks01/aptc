# Audit Report

## Title
Delayed Field Exchange Bypass via Layout-Unaware Group Read Filtering

## Summary
The `get_group_read_values_with_delayed_fields()` function filters group reads based on whether inner_reads match the `Versioned(_, _, Some(_))` pattern. When resource group members are read via functions that use `UnknownOrLayout::Unknown` (such as `resource_size_in_group`), the reads are captured as `DataRead::MetadataAndResourceSize` instead of `Versioned`, causing them to be excluded from delayed field exchange processing.

## Finding Description
The vulnerability occurs in the delayed field exchange mechanism for resource group reads. The critical filtering happens here: [1](#0-0) 

This function only returns group reads where at least one `inner_read` matches `DataRead::Versioned(_, _, Some(_))`. However, when reads are captured through certain code paths, they may not match this pattern: [2](#0-1) 

When a value is `RawFromStorage`, it's captured as `DataRead::MetadataAndResourceSize` (line 239-240), which **does not** match the `Versioned(_, _, Some(_))` pattern required by the filter.

The vulnerability is triggered when `resource_size_in_group()` is called during write operation conversion for storage fee calculation: [3](#0-2) 

This function always uses `UnknownOrLayout::Unknown`: [4](#0-3) 

When the layout is `Unknown` and the underlying value is `RawFromStorage`, the patching logic is skipped: [5](#0-4) 

The patching only occurs when `layout` is `Known(layout)` (line 778). With `Unknown` layout, execution proceeds directly to line 805, capturing the read in its raw state.

**Critical Discrepancy:** The sequential execution path explicitly rejects `RawFromStorage` values during exchange: [6](#0-5) 

But the parallel execution path silently excludes them via the filter, without error: [7](#0-6) 

This creates a behavioral difference where:
- **Sequential execution:** Returns a code invariant error if attempting to exchange `RawFromStorage` values
- **Parallel execution:** Silently excludes the read from exchange via the filter

## Impact Explanation
This vulnerability represents a **High Severity** issue that breaks the **Deterministic Execution** invariant:

1. **State Inconsistency**: Resources containing delayed fields that are read via size queries but not properly exchanged will have delayed field IDs instead of materialized values in the committed state.

2. **Execution Mode Divergence**: The different handling between sequential and parallel execution paths could lead to transactions succeeding in one mode but failing in another, violating deterministic execution guarantees.

3. **Delayed Field Corruption**: Modified delayed fields (AggregatorV2, AggregatorSnapshots) in resource groups may not be materialized into the write set, leading to incorrect on-chain state.

This meets **High Severity** criteria per the Aptos bug bounty: "Significant protocol violations" including execution non-determinism and state inconsistencies.

## Likelihood Explanation
**Likelihood: Medium to High**

The vulnerability is triggered when:
1. A transaction modifies a resource group containing delayed fields
2. `resource_size_in_group()` is called for storage fee calculation (happens automatically)
3. The underlying value is `RawFromStorage` (common for first access)
4. The group member contains delayed fields that need exchange

This is a natural code path executed during normal transaction processing, not requiring attacker manipulation. The frequency depends on:
- How often resource groups with delayed fields are accessed
- The state of the MVHashMap (whether values are already exchanged)
- Timing of parallel transaction execution

## Recommendation
Add explicit validation to ensure all group reads containing delayed fields are properly captured with layouts. Modify the filtering logic to detect and error on potential exchange misses:

```rust
pub(crate) fn get_group_read_values_with_delayed_fields<'a>(
    &'a self,
    skip: &'a HashSet<T::Key>,
) -> impl Iterator<Item = (&'a T::Key, &'a GroupRead<T>)> {
    self.group_reads.iter().filter(|(key, group_read)| {
        if skip.contains(key) {
            return false;
        }
        
        let has_delayed_fields = group_read
            .inner_reads
            .iter()
            .any(|(_, data_read)| matches!(data_read, DataRead::Versioned(_, _, Some(_))));
        
        // Detect potential missed exchange: if we have non-Versioned reads,
        // they should have been upgraded before reaching this point
        if !has_delayed_fields {
            for (_, data_read) in &group_read.inner_reads {
                if matches!(data_read, DataRead::MetadataAndResourceSize(_, _)) {
                    // This could indicate a RawFromStorage read that should have been exchanged
                    // Flag for investigation or stricter validation
                }
            }
        }
        
        has_delayed_fields
    })
}
```

Additionally, ensure `resource_size_in_group()` uses layout information when available, or explicitly patches values before capturing reads with `Unknown` layout.

## Proof of Concept
```rust
// Rust test demonstrating the issue
#[test]
fn test_group_read_exchange_bypass() {
    // Setup: Create a resource group with a delayed field
    let group_key = create_test_group_key();
    let resource_tag = create_test_tag();
    
    // Step 1: Initialize group with RawFromStorage value containing delayed field
    let raw_value = create_raw_value_with_delayed_field();
    versioned_map.group_data().set_base_value(
        group_key.clone(),
        resource_tag.clone(), 
        ValueWithLayout::RawFromStorage(raw_value),
    );
    
    // Step 2: Execute transaction that calls resource_size_in_group
    // This uses UnknownOrLayout::Unknown
    let size = view.resource_size_in_group(&group_key, &resource_tag).unwrap();
    
    // Step 3: Check captured reads
    let captured = view.captured_reads.borrow();
    let group_read = captured.group_reads.get(&group_key).unwrap();
    
    // Verify the read is captured as MetadataAndResourceSize, not Versioned
    assert!(matches!(
        group_read.inner_reads.get(&resource_tag),
        Some(DataRead::MetadataAndResourceSize(_, _))
    ));
    
    // Step 4: Call get_group_read_values_with_delayed_fields
    let reads_with_delayed_fields: Vec<_> = captured
        .get_group_read_values_with_delayed_fields(&HashSet::new())
        .collect();
    
    // BUG: The group read is excluded from delayed field exchange
    assert_eq!(reads_with_delayed_fields.len(), 0);
    
    // This means delayed field IDs in this resource won't be materialized!
}
```

**Notes**

The vulnerability stems from a mismatch between the read capture mechanism and the exchange filtering logic. The filter assumes all reads containing delayed fields will be captured as `Versioned(_, _, Some(_))`, but certain code paths (particularly `resource_size_in_group` with `Unknown` layout) capture reads in other formats. This creates an execution mode dependency where sequential execution fails explicitly while parallel execution silently excludes the problematic reads, potentially violating deterministic execution guarantees across the network.

### Citations

**File:** aptos-move/block-executor/src/captured_reads.rs (L234-246)
```rust
    pub(crate) fn from_value_with_layout(version: Version, value: ValueWithLayout<V>) -> Self {
        match value {
            // If value was never exchanged, then value shouldn't be used, and so we construct
            // a MetadataAndResourceSize variant that implies everything non-value. This also
            // ensures that RawFromStorage can't be consistent with any other value read.
            ValueWithLayout::RawFromStorage(v) => {
                DataRead::MetadataAndResourceSize(v.as_state_value_metadata(), Self::value_size(&v))
            },
            ValueWithLayout::Exchanged(v, layout) => {
                DataRead::Versioned(version, v.clone(), layout)
            },
        }
    }
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L637-648)
```rust
    pub(crate) fn get_group_read_values_with_delayed_fields<'a>(
        &'a self,
        skip: &'a HashSet<T::Key>,
    ) -> impl Iterator<Item = (&'a T::Key, &'a GroupRead<T>)> {
        self.group_reads.iter().filter(|(key, group_read)| {
            !skip.contains(key)
                && group_read
                    .inner_reads
                    .iter()
                    .any(|(_, data_read)| matches!(data_read, DataRead::Versioned(_, _, Some(_))))
        })
    }
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/write_op_converter.rs (L181-183)
```rust
            if !matches!(current_op, MoveStorageOp::New(_)) {
                let old_tagged_value_size = self.remote.resource_size_in_group(state_key, &tag)?;
                let old_size = group_tagged_resource_size(&tag, old_tagged_value_size)?;
```

**File:** aptos-move/block-executor/src/view.rs (L777-803)
```rust
                    // If we have a known layout, upgrade RawFromStorage value to Exchanged.
                    if let UnknownOrLayout::Known(layout) = layout {
                        if let ValueWithLayout::RawFromStorage(v) = value_with_layout {
                            assert_eq!(version, Err(StorageVersion),
                            "Fetched resource has unknown layout but the version is not Err(StorageVersion)"
                            );
                            match patch_base_value(v.as_ref(), layout) {
                                Ok(patched_value) => {
                                    self.versioned_map
                                        .group_data()
                                        .update_tagged_base_value_with_layout(
                                            group_key.clone(),
                                            resource_tag.clone(),
                                            patched_value,
                                            layout.cloned().map(TriompheArc::new),
                                        );
                                    // Re-fetch in case a concurrent change went through.
                                    continue;
                                },
                                Err(e) => {
                                    error!("Couldn't patch value from versioned group map: {}", e);
                                    self.captured_reads.borrow_mut().mark_incorrect_use();
                                    return Err(e);
                                },
                            }
                        }
                    }
```

**File:** aptos-move/block-executor/src/view.rs (L1361-1363)
```rust
                    Some(ValueWithLayout::RawFromStorage(_)) => Some(Err(code_invariant_error(
                        "Cannot exchange value that was not exchanged before",
                    ))),
```

**File:** aptos-move/block-executor/src/view.rs (L1376-1381)
```rust
        let reads_with_delayed_fields = parallel_state
            .captured_reads
            .borrow()
            .get_group_read_values_with_delayed_fields(skip)
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect::<Vec<_>>();
```

**File:** aptos-move/block-executor/src/view.rs (L1741-1750)
```rust
    fn resource_size_in_group(
        &self,
        group_key: &Self::GroupKey,
        resource_tag: &Self::ResourceTag,
    ) -> PartialVMResult<usize> {
        self.get_resource_from_group_impl(
            group_key,
            resource_tag,
            UnknownOrLayout::Unknown,
            ReadKind::ResourceSize,
```
