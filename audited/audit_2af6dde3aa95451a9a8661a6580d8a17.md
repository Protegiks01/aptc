# Audit Report

## Title
Unbounded Synchronous Pruner Catch-up Blocks Node Startup During Initialization

## Summary
The `TransactionPruner::new()` function performs unbounded synchronous pruning during node initialization, loading all transactions in the backlog into memory and processing them without batching. This can block node startup for extended periods when a large pruning backlog exists, causing availability issues.

## Finding Description
During AptosDB initialization, all ledger sub-pruners (including `TransactionPruner`) perform a synchronous "catch-up" operation to align their progress with the metadata pruner's progress. [1](#0-0) 

The vulnerability exists in how this catch-up is implemented:

1. **Unbounded Synchronous Call**: The `new()` constructor calls `myself.prune(progress, metadata_progress)?` directly without any batching limit [2](#0-1) 

2. **Memory Allocation**: The `get_pruning_candidate_transactions()` function allocates a vector with capacity `(end - start) as usize` and loads ALL transactions in that range into memory [3](#0-2) 

3. **Blocks Database Initialization**: This occurs during `LedgerPruner::new()`, which is called synchronously from `AptosDB::new_with_dbs()` [4](#0-3) 

**When Large Backlogs Occur:**
A large gap between `progress` and `metadata_progress` can occur when:
- Node crashes after `LedgerMetadataPruner` updates progress but before sub-pruners complete
- Repeated crashes accumulate the gap over time
- Pruner is disabled for extended periods then re-enabled
- Database restoration from old backups

During normal pruning operations, the metadata pruner updates first, then sub-pruners run in parallel. If a crash occurs between these steps, the sub-pruner progress lags behind. [5](#0-4) 

**The Problem:**
Unlike normal pruning which processes batches with `max_versions` limit (default 5,000), the initialization catch-up processes the ENTIRE backlog in one synchronous call, potentially millions of versions.

## Impact Explanation
This qualifies as **Medium Severity** under "State inconsistencies requiring intervention" or **High Severity** under "Validator node slowdowns":

- **Node Unavailability**: With Aptos processing 10,000+ TPS, even 1 hour of backlog represents 36 million transactions. Loading and processing millions of transactions during startup could take minutes to hours
- **Network Impact**: If multiple validators restart simultaneously (e.g., after a network issue), this affects network liveness
- **Startup Timeouts**: Kubernetes probes and other monitoring systems may fail the node if startup exceeds configured timeouts [6](#0-5) 

## Likelihood Explanation
**Likelihood: Medium**

This issue occurs naturally during operational scenarios:
- Node crashes are common in distributed systems
- The timing window between metadata pruner update and sub-pruner update makes this likely
- Accumulation over multiple crash-restart cycles increases backlog size
- Default batch size is 5,000, so even a single interrupted batch creates a 5,000 version backlog

The impact severity increases with blockchain throughput - higher TPS means larger backlogs accumulate faster.

## Recommendation
Implement batched catch-up with progress tracking:

```rust
pub(in crate::pruner) fn new(
    transaction_store: Arc<TransactionStore>,
    ledger_db: Arc<LedgerDb>,
    metadata_progress: Version,
    internal_indexer_db: Option<InternalIndexerDB>,
) -> Result<Self> {
    let progress = get_or_initialize_subpruner_progress(
        ledger_db.transaction_db_raw(),
        &DbMetadataKey::TransactionPrunerProgress,
        metadata_progress,
    )?;

    let myself = TransactionPruner {
        transaction_store,
        ledger_db,
        internal_indexer_db,
    };

    info!(
        progress = progress,
        metadata_progress = metadata_progress,
        "Catching up TransactionPruner."
    );
    
    // Batch the catch-up instead of processing entire backlog
    const CATCH_UP_BATCH_SIZE: u64 = 5_000;
    let mut current_progress = progress;
    while current_progress < metadata_progress {
        let batch_target = std::cmp::min(
            current_progress + CATCH_UP_BATCH_SIZE,
            metadata_progress
        );
        myself.prune(current_progress, batch_target)?;
        current_progress = batch_target;
    }

    Ok(myself)
}
```

Apply the same pattern to all sub-pruners that exhibit this behavior.

## Proof of Concept

```rust
#[test]
fn test_large_backlog_blocks_startup() {
    // Simulate a scenario where metadata progress is far ahead
    let tmp_dir = TempPath::new();
    let db = AptosDB::new_for_test(&tmp_dir);
    
    // Commit many transactions
    let num_txns = 100_000u64;
    for version in 0..num_txns {
        let txn = create_test_transaction(version);
        db.save_transactions(&[txn], version, None).unwrap();
    }
    
    // Manually advance metadata pruner progress
    db.ledger_db()
        .metadata_db()
        .put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerPrunerProgress,
            &DbMetadataValue::Version(num_txns - 1),
        )
        .unwrap();
    
    // Keep sub-pruner progress at 0
    // (simulating crash after metadata update)
    
    // Measure startup time
    let start = std::time::Instant::now();
    
    // This will block for extended time with large backlog
    let pruner = LedgerPruner::new(
        db.ledger_db_arc(),
        None,
    ).unwrap();
    
    let elapsed = start.elapsed();
    println!("Initialization took: {:?}", elapsed);
    
    // With 100k versions, this could take several seconds
    // With millions, it could take minutes
    assert!(elapsed.as_secs() > 1);
}
```

## Notes
This same pattern exists in ALL sub-pruners (EventStorePruner, WriteSetPruner, TransactionAccumulatorPruner, etc.), multiplying the impact. [7](#0-6) [8](#0-7) 

The default batch size configuration is 5,000 versions, which applies to normal operation but is bypassed during initialization. [9](#0-8)

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L78-104)
```rust
    pub(in crate::pruner) fn new(
        transaction_store: Arc<TransactionStore>,
        ledger_db: Arc<LedgerDb>,
        metadata_progress: Version,
        internal_indexer_db: Option<InternalIndexerDB>,
    ) -> Result<Self> {
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_db_raw(),
            &DbMetadataKey::TransactionPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionPruner {
            transaction_store,
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionPruner."
        );
        myself.prune(progress, metadata_progress)?;

        Ok(myself)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L106-131)
```rust
    fn get_pruning_candidate_transactions(
        &self,
        start: Version,
        end: Version,
    ) -> Result<Vec<(Version, Transaction)>> {
        ensure!(end >= start, "{} must be >= {}", end, start);

        let mut iter = self
            .ledger_db
            .transaction_db_raw()
            .iter::<TransactionSchema>()?;
        iter.seek(&start)?;

        // The capacity is capped by the max number of txns we prune in a single batch. It's a
        // relatively small number set in the config, so it won't cause high memory usage here.
        let mut txns = Vec::with_capacity((end - start) as usize);
        for item in iter {
            let (version, txn) = item?;
            if version >= end {
                break;
            }
            txns.push((version, txn));
        }

        Ok(txns)
    }
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L86-90)
```rust
        let ledger_pruner = LedgerPrunerManager::new(
            Arc::clone(&ledger_db),
            pruner_config.ledger_pruner_config,
            internal_indexer_db,
        );
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L75-84)
```rust
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;

            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```

**File:** terraform/helm/fullnode/templates/fullnode.yaml (L1-10)
```yaml
{{ $fullnode_statefulset := lookup "apps/v1" "StatefulSet" $.Release.Namespace (include "aptos-fullnode.fullname" .) }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "aptos-fullnode.fullname" . }}
  labels:
    {{- include "aptos-fullnode.labels" . | nindent 4 }}
    app.kubernetes.io/name: fullnode
spec:
  serviceName: {{ include "aptos-fullnode.fullname" . }}
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L106-106)
```rust
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/write_set_pruner.rs (L54-54)
```rust
        myself.prune(progress, metadata_progress)?;
```

**File:** config/src/config/storage_config.rs (L387-395)
```rust
impl Default for LedgerPrunerConfig {
    fn default() -> Self {
        LedgerPrunerConfig {
            enable: true,
            prune_window: 90_000_000,
            batch_size: 5_000,
            user_pruning_window_offset: 200_000,
        }
    }
```
