# Audit Report

## Title
Memory Exhaustion via Unbounded Allocation from Malicious Backup Service Length Prefixes

## Summary
The transaction backup system in `storage/backup/backup-cli/src/backup_types/transaction/backup.rs` processes length-prefixed records from a configurable backup service without validating the length prefix values. A malicious or compromised backup service can send arbitrarily large length prefixes (up to 4GB), causing unbounded memory allocation that can lead to memory exhaustion and DoS of backup operations.

## Finding Description

The vulnerability exists in the record reading logic used during transaction backup operations. The code path is:

1. The `TransactionBackupController::run_impl()` function retrieves transaction data from a backup service [1](#0-0) 

2. The while loop processes records using `read_record_bytes()` [2](#0-1) 

3. The `read_record_bytes()` implementation reads a 4-byte big-endian length prefix and directly uses it to allocate memory [3](#0-2) 

The critical issue is at line 54 where `record_size` is converted from the 4-byte prefix with no validation, and line 60 where `BytesMut::with_capacity(record_size)` attempts to allocate that amount of memory immediately.

**Attack Scenario:**
A malicious backup service (or compromised legitimate service) sends:
- Initial valid transaction records to pass basic checks
- A corrupted length prefix of `0xFFFFFFFF` (4,294,967,295 bytes ≈ 4GB)
- The backup CLI immediately attempts to allocate 4GB of memory
- Multiple such records exhaust available memory, causing OOM and process termination

The backup service URL is configurable via CLI flag [4](#0-3) , making this exploitable when operators use external backup services or when backup infrastructure is compromised.

**Invariant Violation:**
This breaks Critical Invariant #9: "Resource Limits: All operations must respect gas, storage, and computational limits." The code performs unbounded memory allocation based on untrusted external input without any sanity checks.

**Why Not Infinite Loops:**
The security question also asks about infinite loops. The code DOES have protection against processing more records than expected [5](#0-4) . Therefore, infinite loops are NOT possible, but memory exhaustion IS.

## Impact Explanation

This is a **Medium severity** vulnerability per Aptos bug bounty criteria for the following reasons:

1. **State Inconsistencies**: Failed backup operations can lead to incomplete or corrupted backups, which are critical for disaster recovery. This aligns with "State inconsistencies requiring intervention" in the Medium severity category.

2. **DoS of Critical Infrastructure**: While this doesn't directly affect consensus or blockchain operation, it can DoS the backup infrastructure, preventing operators from creating reliable backups.

3. **Scope**: The same vulnerable pattern exists across all backup types (transactions, state snapshots, epoch endings), amplifying the attack surface.

4. **Real-World Impact**: In practice, legitimate transactions have a maximum size of 1MB [6](#0-5) , but the backup CLI has no such validation, accepting any length prefix up to u32::MAX.

This does NOT qualify as Critical or High because it doesn't affect consensus, validator operation, or cause direct loss of funds. However, it's solidly Medium due to the potential for state inconsistencies in backup infrastructure.

## Likelihood Explanation

**Likelihood: Medium**

Required conditions for exploitation:
1. Operator configures backup CLI to use an external/untrusted backup service URL, OR
2. A legitimate backup service gets compromised, OR  
3. A buggy backup service implementation sends corrupted length prefixes

While the default configuration uses `localhost:6186` (trusted), production deployments often use:
- Dedicated backup servers
- Cloud-based backup-as-a-service providers
- Distributed backup infrastructure

The attack is straightforward once the attacker controls the backup service endpoint - simply send malformed length prefixes. No sophisticated exploitation techniques are required.

## Recommendation

Add validation on `record_size` before allocating memory. A reasonable upper bound would be 10MB (10× the maximum transaction size) to account for serialization overhead:

**Fix for `storage/backup/backup-cli/src/utils/read_record_bytes.rs`:**

```rust
async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
    let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
    // read record size
    let mut size_buf = BytesMut::with_capacity(4);
    self.read_full_buf_or_none(&mut size_buf).await?;
    if size_buf.is_empty() {
        return Ok(None);
    }

    // empty record
    let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
    if record_size == 0 {
        return Ok(Some(Bytes::new()));
    }

    // ADD VALIDATION: Reject unreasonably large records
    const MAX_RECORD_SIZE: usize = 10 * 1024 * 1024; // 10MB
    if record_size > MAX_RECORD_SIZE {
        bail!(
            "Record size {} exceeds maximum allowed size {}",
            record_size,
            MAX_RECORD_SIZE
        );
    }

    // read record
    let mut record_buf = BytesMut::with_capacity(record_size);
    self.read_full_buf_or_none(&mut record_buf).await?;
    if record_buf.is_empty() {
        bail!("Hit EOF when reading record.")
    }

    Ok(Some(record_buf.freeze()))
}
```

Additionally, consider adding rate limiting or total memory caps for backup operations to prevent resource exhaustion from repeated attacks.

## Proof of Concept

```rust
// Proof of Concept - Malicious Backup Service Simulator
// This demonstrates how a malicious backup service can cause memory exhaustion

use bytes::BytesMut;
use std::io::Write;

#[tokio::test]
async fn test_memory_exhaustion_attack() {
    // Simulate malicious backup service response
    let mut malicious_data = Vec::new();
    
    // Send a valid small transaction first
    let valid_txn = vec![0u8; 100];
    malicious_data.write_all(&(valid_txn.len() as u32).to_be_bytes()).unwrap();
    malicious_data.write_all(&valid_txn).unwrap();
    
    // Then send corrupted length prefix claiming 1GB of data
    let malicious_size: u32 = 1_000_000_000; // 1GB
    malicious_data.write_all(&malicious_size.to_be_bytes()).unwrap();
    // Only send partial data to keep the stream open
    malicious_data.extend(vec![0u8; 1000]);
    
    // When backup CLI tries to read this:
    // 1. It reads the 1GB length prefix
    // 2. Calls BytesMut::with_capacity(1_000_000_000)
    // 3. Attempts to allocate 1GB of memory immediately
    // 4. With multiple concurrent backups, this exhausts memory
    
    // Demonstration of allocation attempt
    let record_size = u32::from_be_bytes([0x3B, 0x9A, 0xCA, 0x00]); // 1GB
    println!("Attempting to allocate {} bytes", record_size);
    
    // This would cause memory exhaustion in production:
    // let mut record_buf = BytesMut::with_capacity(record_size as usize);
    
    assert!(record_size > 100_000_000, "Malicious size is unreasonably large");
}

// Demonstration of current vulnerable behavior
#[tokio::test]
async fn test_current_vulnerable_behavior() {
    use tokio::io::AsyncReadExt;
    
    // Simulate reading from malicious stream
    let corrupted_prefix = 0xFFFFFFFFu32; // 4GB
    let mut data = corrupted_prefix.to_be_bytes().to_vec();
    data.extend(vec![0u8; 100]); // Partial data
    
    let mut reader = data.as_slice();
    let mut size_buf = [0u8; 4];
    reader.read_exact(&mut size_buf).await.unwrap();
    
    let record_size = u32::from_be_bytes(size_buf) as usize;
    assert_eq!(record_size, 4_294_967_295);
    
    // Current code would do: BytesMut::with_capacity(record_size)
    // This would attempt to allocate 4GB with NO validation
    println!("Vulnerable code would allocate {} bytes without validation", record_size);
}
```

**Notes:**

This vulnerability affects all backup types (transactions, state snapshots, epoch endings) that use the `ReadRecordBytes` trait. The fix should be applied to the common implementation in `read_record_bytes.rs` to protect all backup operations. The 10MB limit is a reasonable upper bound that's 10× larger than the maximum transaction size, providing safety margin for serialization overhead while preventing absurd allocations.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L80-83)
```rust
        let mut transactions_file = self
            .client
            .get_transactions(self.start_version, self.num_transactions)
            .await?;
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L87-87)
```rust
        while let Some(record_bytes) = transactions_file.read_record_bytes().await? {
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/backup.rs (L109-114)
```rust
        ensure!(
            current_ver == expected_next_version,
            "Server did not return all transactions requested. Expecting last version {}, got {}",
            expected_next_version,
            current_ver,
        );
```

**File:** storage/backup/backup-cli/src/utils/read_record_bytes.rs (L44-61)
```rust
    async fn read_record_bytes(&mut self) -> Result<Option<Bytes>> {
        let _timer = BACKUP_TIMER.timer_with(&["read_record_bytes"]);
        // read record size
        let mut size_buf = BytesMut::with_capacity(4);
        self.read_full_buf_or_none(&mut size_buf).await?;
        if size_buf.is_empty() {
            return Ok(None);
        }

        // empty record
        let record_size = u32::from_be_bytes(size_buf.as_ref().try_into()?) as usize;
        if record_size == 0 {
            return Ok(Some(Bytes::new()));
        }

        // read record
        let mut record_buf = BytesMut::with_capacity(record_size);
        self.read_full_buf_or_none(&mut record_buf).await?;
```

**File:** storage/backup/backup-cli/src/utils/backup_service_client.rs (L23-31)
```rust
pub struct BackupServiceClientOpt {
    #[clap(
        long = "backup-service-address",
        default_value = "http://localhost:6186",
        help = "Backup service address. By default a Aptos Node runs the backup service serving \
        on tcp port 6186 to localhost only."
    )]
    pub address: String,
}
```

**File:** aptos-move/aptos-vm/src/gas.rs (L26-26)
```rust
const MAXIMUM_APPROVED_TRANSACTION_SIZE_LEGACY: u64 = 1024 * 1024;
```
