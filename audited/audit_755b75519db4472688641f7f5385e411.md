# Audit Report

## Title
Resource Leak in Data Stream Service: Pending Responses Not Cleaned Up on Early Termination

## Summary
When `process_data_responses()` returns early due to stream completion or maximum retry failures, it does not clean up pending background tasks and responses. This causes spawned request tasks to continue running unnecessarily, and their responses remain in memory indefinitely until the client explicitly terminates the stream. This resource leak can accumulate across multiple abandoned streams, potentially leading to memory exhaustion and node performance degradation.

## Finding Description
The vulnerability exists in the `process_data_responses()` function where three conditions trigger an early return: [1](#0-0) 

When the stream is complete or max retry count is exceeded, the function returns immediately without calling `clear_sent_data_requests_queue()`. This contrasts with the error handling path where cleanup IS performed: [2](#0-1) 

The `clear_sent_data_requests_queue()` method properly aborts spawned tasks and clears the pending requests queue: [3](#0-2) 

However, when early return occurs at line 453, this cleanup is never performed. As a result:

1. **Spawned tasks continue running**: Background tasks in `spawned_tasks` vector continue executing and fetching data until timeout
2. **Pending responses remain in memory**: The `sent_data_requests` VecDeque retains completed responses that will never be processed
3. **Stream persists indefinitely**: The stream remains in the `data_streams` HashMap until explicit termination [4](#0-3) 

The streaming service acknowledges this limitation with a TODO comment indicating that automatic garbage collection for abandoned streams is not implemented: [5](#0-4) 

**Attack Scenario:**
A malicious or buggy client can exploit this by:
1. Creating multiple data streams via the streaming service API
2. Triggering early termination by requesting data that causes stream completion or repeated failures
3. Never calling `TerminateStream` to clean up
4. Repeating to accumulate abandoned streams with lingering resources

Each abandoned stream retains memory for pending responses (bounded by `max_pending_requests` but defaults to 100+), notification mappings, task handles, and the stream object itself.

## Impact Explanation
This qualifies as **Medium severity** under the Aptos bug bounty program category of "State inconsistencies requiring intervention" because:

1. **Memory exhaustion risk**: Accumulated abandoned streams consume memory that is never freed, potentially exhausting node resources
2. **Performance degradation**: Validator nodes with memory pressure experience slowdowns, affecting block processing and consensus participation
3. **Requires manual intervention**: Operators must restart nodes to clear leaked resources, causing temporary validator unavailability
4. **Bounded but multiplied impact**: While each stream has bounded resources, multiple abandoned streams amplify the leak

The issue does not reach High/Critical severity because:
- It requires sustained attack over time to cause significant impact
- Resources per stream are bounded
- Does not directly compromise consensus safety or cause fund loss
- Node crash is not immediate but gradual through memory pressure

## Likelihood Explanation
**Likelihood: Medium**

The vulnerability is likely to occur because:

1. **Known missing feature**: The TODO comment confirms automatic cleanup is not implemented, making this a documented gap
2. **Legitimate failure scenarios**: Network issues, data unavailability, or client crashes can legitimately trigger early termination without cleanup
3. **Internal component dependency**: State sync drivers and storage synchronizers use this service and may fail to terminate streams properly due to bugs
4. **Future exposure concern**: The TODO explicitly mentions "once this is exposed to the wild", indicating plans for broader API access

Mitigating factors:
- Currently used primarily by internal node components
- Requires either malicious intent or buggy client behavior
- Drop trait provides cleanup when entire DataStreamingService is dropped (node restart) [6](#0-5) 

## Recommendation
Implement automatic cleanup when streams enter terminal states. The fix should call `clear_sent_data_requests_queue()` before early return:

```rust
pub async fn process_data_responses(
    &mut self,
    global_data_summary: GlobalDataSummary,
) -> Result<(), Error> {
    if self.stream_engine.is_stream_complete()
        || self.request_failure_count >= self.streaming_service_config.max_request_retry
        || self.send_failure
    {
        // Clean up pending resources before terminating
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
        {
            self.clear_sent_data_requests_queue();
        }
        
        if !self.send_failure && self.stream_end_notification_id.is_none() {
            self.send_end_of_stream_notification().await?;
        }
        return Ok(());
    }
    // ... rest of function
}
```

Additionally, implement the TODO's suggested automatic garbage collection in the streaming service to detect and remove abandoned streams after a timeout period.

## Proof of Concept

```rust
#[tokio::test]
async fn test_resource_leak_on_early_termination() {
    use crate::tests::utils::{MockAptosDataClient, initialize_data_stream};
    use aptos_config::config::{AptosDataClientConfig, DataStreamingServiceConfig};
    use aptos_time_service::TimeService;
    
    // Create a data stream
    let data_client_config = AptosDataClientConfig::default();
    let streaming_config = DataStreamingServiceConfig::default();
    let aptos_data_client = MockAptosDataClient::new(
        data_client_config, true, false, true, true
    );
    
    let (mut data_stream, _listener) = initialize_data_stream(
        streaming_config,
        aptos_data_client,
        TimeService::mock(),
    ).await;
    
    // Initialize requests and send some
    data_stream.initialize_data_requests(GlobalDataSummary::empty()).unwrap();
    
    // Verify tasks are spawned
    assert!(!data_stream.spawned_tasks.is_empty());
    let initial_task_count = data_stream.spawned_tasks.len();
    
    // Trigger max retry failure to cause early return
    data_stream.request_failure_count = streaming_config.max_request_retry;
    
    // Call process_data_responses - should return early
    data_stream.process_data_responses(GlobalDataSummary::empty()).await.unwrap();
    
    // BUG: Tasks are NOT aborted, they remain in spawned_tasks
    assert_eq!(data_stream.spawned_tasks.len(), initial_task_count);
    
    // BUG: Pending requests are NOT cleared
    if let Some(ref requests) = data_stream.sent_data_requests {
        assert!(!requests.is_empty());
    }
    
    // Expected behavior: All resources should be cleaned up
    // data_stream.clear_sent_data_requests_queue() should have been called
    // spawned_tasks should be empty
    // sent_data_requests should be cleared
}
```

**Notes**

The vulnerability specifically affects the early return paths for stream completion and maximum retry failures. The send failure case is handled correctly with automatic stream removal [7](#0-6) , demonstrating that the system can properly clean up streams when needed, but this logic is not consistently applied to all termination scenarios.

### Citations

**File:** state-sync/data-streaming-service/src/data_stream.rs (L86-96)
```rust
    // The current queue of data client requests and pending responses. When the
    // request at the head of the queue completes (i.e., we receive a response),
    // a data notification can be created and sent along the stream.
    sent_data_requests: Option<VecDeque<PendingClientResponse>>,

    // Handles of all spawned tasks. This is useful for aborting the tasks in
    // the case the stream is terminated prematurely.
    spawned_tasks: Vec<JoinHandle<()>>,

    // Maps a notification ID (sent along the data stream) to a response context.
    notifications_to_responses: BTreeMap<NotificationId, ResponseContext>,
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L176-184)
```rust
    pub fn clear_sent_data_requests_queue(&mut self) {
        // Clear all pending data requests
        if let Some(sent_data_requests) = self.sent_data_requests.as_mut() {
            sent_data_requests.clear();
        }

        // Abort all spawned tasks
        self.abort_spawned_tasks();
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-453)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L633-645)
```rust
    /// Notifies the stream engine that a new data request error was encountered
    fn notify_new_data_request_error(
        &mut self,
        client_request: &DataClientRequest,
        error: aptos_data_client::error::Error,
    ) -> Result<(), Error> {
        // Notify the stream engine and clear the requests queue
        self.stream_engine
            .notify_new_data_request_error(client_request, error)?;
        self.clear_sent_data_requests_queue();

        Ok(())
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L930-935)
```rust
impl<T> Drop for DataStream<T> {
    /// Terminates the stream by aborting all spawned tasks
    fn drop(&mut self) {
        self.abort_spawned_tasks();
    }
}
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L200-201)
```rust
    /// TODO(joshlind): once this is exposed to the wild, we'll need automatic
    /// garbage collection for misbehaving clients.
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L347-364)
```rust
        // If there was a send failure, terminate the stream
        let data_stream = self.get_data_stream(data_stream_id)?;
        if data_stream.send_failure() {
            info!(
                (LogSchema::new(LogEntry::TerminateStream)
                    .stream_id(*data_stream_id)
                    .event(LogEvent::Success)
                    .message("There was a send failure, terminating the stream."))
            );
            metrics::DATA_STREAM_SEND_FAILURE.inc();
            if self.data_streams.remove(data_stream_id).is_none() {
                return Err(Error::UnexpectedErrorEncountered(format!(
                    "Failed to terminate stream id {:?} for send failure! Stream not found.",
                    data_stream_id
                )));
            }
            return Ok(());
        }
```
