# Audit Report

## Title
Eclipse Attack via Single-Peer Network Distance Trust in Peer Monitoring Service

## Summary
The Aptos peer monitoring service stores network topology information (`distance_from_validators`) from individual peers without cross-validation or multi-peer aggregation. This allows a malicious peer to falsely report its distance from validators, causing victim nodes to prioritize the attacker for critical operations including state synchronization, consensus observer subscriptions, and mempool transaction forwarding.

## Finding Description

The vulnerability exists in how Aptos nodes determine peer priority for critical network operations. Each node maintains a `NetworkInfoState` per peer that stores a single `NetworkInformationResponse` containing the peer's self-reported `distance_from_validators` value. [1](#0-0) 

When a peer responds with network information, this distance value is validated only against basic sanity checks (role verification for distances 0-1, and maximum threshold), then stored without comparing against other peers: [2](#0-1) [3](#0-2) 

The validation only checks that:
- Distance 0 claims must come from validator-role peers
- Distance 1 claims must come from VFN-role peers  
- Distance ≥2 claims only need to be ≤ `MAX_DISTANCE_FROM_VALIDATORS` (100)

Critically, for distance ≥2, there is **no validation** that the peer is actually that close to validators. A malicious public fullnode can claim distance 2 and pass all checks.

This single-peer distance information is then used to prioritize peers in three critical subsystems:

**1. State Sync Data Client** - Uses distance to select peers for fetching blockchain state: [4](#0-3) [5](#0-4) 

**2. Consensus Observer** - Uses distance to select which peers to subscribe to for consensus messages: [6](#0-5) [7](#0-6) 

**3. Mempool Priority** - Uses distance to prioritize transaction forwarding: [8](#0-7) [9](#0-8) 

**Attack Scenario:**
1. Attacker runs a malicious Public Fullnode (PFN)
2. Victim PFN connects to attacker's node
3. Attacker falsely reports `distance_from_validators = 2` (claiming proximity to validators)
4. Victim stores this distance without verification against other peers
5. Victim now preferentially:
   - Fetches state sync data from the attacker
   - Subscribes to the attacker for consensus observer messages
   - Forwards transactions to the attacker in mempool
6. Attacker can: serve stale state, withhold consensus messages, censor transactions

Additionally, the victim calculates its own distance based on the attacker's false claim: [10](#0-9) 

This propagates the misinformation to other nodes that connect to the victim.

## Impact Explanation

This vulnerability enables **eclipse attacks** where an attacker can manipulate a node's view of the network topology. The severity is **High** based on:

1. **Validator Node Slowdowns**: If validators are eclipsed and fetch state sync data from malicious/stale peers, synchronization degrades
2. **Significant Protocol Violations**: The peer selection mechanism assumes honest distance reporting, which is violated
3. **Consensus Observer Manipulation**: Non-validator nodes subscribing to malicious peers for consensus messages receive degraded/censored consensus view

While this does not directly break consensus safety (validators still use BFT with ≥2/3 honest assumption), it significantly impacts:
- Network synchronization reliability
- Transaction propagation effectiveness  
- Fullnode consensus observation quality

This falls under the Aptos bug bounty **High Severity** category: "Validator node slowdowns" and "Significant protocol violations."

## Likelihood Explanation

**Likelihood: High**

This attack is highly practical:
- Attacker only needs to run a single malicious peer node
- No special privileges or resources required beyond standard node operation
- The distance claim is not cryptographically verified
- For distance ≥2, validation is minimal (just threshold check)
- Multiple critical systems rely on this unverified distance metric

The attack complexity is **low** - simply modify the peer monitoring service server response to return a false distance value.

## Recommendation

Implement **multi-peer distance validation** with Byzantine fault tolerance:

1. **Aggregate distance information from multiple peers**: Collect distance claims from N peers and use median or consensus-based approach
2. **Cross-validate distance claims**: Verify that peers at distance D have connections to peers at distance D-1
3. **Distance proof mechanism**: Implement cryptographic proofs of validator connectivity chains
4. **Limit impact of single-peer trust**: Use distance as a hint rather than absolute priority, with fallback to other metrics

**Example Fix (Conceptual)**:
```rust
// In NetworkInfoState or higher-level aggregator
struct AggregatedNetworkInfo {
    peer_distances: HashMap<PeerNetworkId, u64>,
    
    fn get_consensus_distance(&self) -> Option<u64> {
        // Collect all reported distances
        let mut distances: Vec<u64> = self.peer_distances.values().copied().collect();
        if distances.len() < MIN_PEERS_FOR_CONSENSUS {
            return None;
        }
        
        // Use median with outlier filtering
        distances.sort();
        let median_idx = distances.len() / 2;
        Some(distances[median_idx])
    }
}

// Update peer selection to use consensus distance
// instead of single-peer distance
```

Additionally, add validation that peer-reported distances are consistent with observed connectivity patterns.

## Proof of Concept

```rust
// Malicious Peer Server Response
// File: peer-monitoring-service/server/src/lib.rs (modified)

fn get_network_information(&self) -> Result<PeerMonitoringServiceResponse, Error> {
    let connected_peers = // ... collect connected peers ...
    
    // ATTACK: Always report distance 2 regardless of actual connectivity
    let distance_from_validators = 2; // FALSE CLAIM
    
    let network_information_response = NetworkInformationResponse {
        connected_peers,
        distance_from_validators, // Victim will trust this without verification
    };
    Ok(PeerMonitoringServiceResponse::NetworkInformation(
        network_information_response,
    ))
}

// Demonstration Steps:
// 1. Deploy modified peer node claiming distance=2
// 2. Connect victim fullnode to malicious peer
// 3. Observe victim's peer_states - it records distance=2 without validation
// 4. Check victim's data client peer selection - malicious peer is prioritized
// 5. Check victim's consensus observer subscriptions - malicious peer is preferred
// 6. Monitor mempool - transactions forwarded to malicious peer with priority
```

The vulnerability is confirmed by the absence of any cross-peer validation logic in the codebase - each peer's distance is trusted independently.

## Notes

The vulnerability is partially mitigated by:
- Role-based validation for distances 0 and 1 (but not ≥2)
- State sync has cryptographic verification of state data
- Validators maintain trusted peer sets

However, the lack of multi-peer aggregation remains a significant weakness enabling eclipse attacks against fullnodes and potentially degrading validator performance.

### Citations

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L28-35)
```rust
/// A simple container that holds a single peer's network info
#[derive(Clone, Debug)]
pub struct NetworkInfoState {
    base_config: BaseConfig, // The base config of this node
    network_monitoring_config: NetworkMonitoringConfig, // The config for network monitoring
    recorded_network_info_response: Option<NetworkInformationResponse>, // The last network info response
    request_tracker: Arc<RwLock<RequestTracker>>, // The request tracker for network info requests
}
```

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L55-64)
```rust
    pub fn record_network_info_response(
        &mut self,
        network_info_response: NetworkInformationResponse,
    ) {
        // Update the request tracker with a successful response
        self.request_tracker.write().record_response_success();

        // Save the network info
        self.recorded_network_info_response = Some(network_info_response);
    }
```

**File:** peer-monitoring-service/client/src/peer_states/network_info.rs (L116-158)
```rust
        // Sanity check the response depth from the peer metadata
        let network_id = peer_network_id.network_id();
        let is_valid_depth = match network_info_response.distance_from_validators {
            0 => {
                // Verify the peer is a validator and has the correct network id
                let peer_is_validator = peer_metadata.get_connection_metadata().role.is_validator();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_validator_network(), // We're a validator
                    RoleType::FullNode => network_id.is_vfn_network(),        // We're a VFN
                };
                peer_is_validator && peer_has_correct_network
            },
            1 => {
                // Verify the peer is a VFN and has the correct network id
                let peer_is_vfn = peer_metadata.get_connection_metadata().role.is_vfn();
                let peer_has_correct_network = match self.base_config.role {
                    RoleType::Validator => network_id.is_vfn_network(), // We're a validator
                    RoleType::FullNode => network_id.is_public_network(), // We're a VFN or PFN
                };
                peer_is_vfn && peer_has_correct_network
            },
            distance_from_validators => {
                // The distance must be less than or equal to the max
                distance_from_validators <= MAX_DISTANCE_FROM_VALIDATORS
            },
        };

        // If the depth did not pass our sanity checks, handle a failure
        if !is_valid_depth {
            warn!(LogSchema::new(LogEntry::NetworkInfoRequest)
                .event(LogEvent::InvalidResponse)
                .peer(peer_network_id)
                .message(&format!(
                    "Peer returned invalid depth from validators: {}",
                    network_info_response.distance_from_validators
                )));
            self.handle_request_failure();
            return;
        }

        // Store the new latency ping result
        self.record_network_info_response(network_info_response);
    }
```

**File:** state-sync/aptos-data-client/src/utils.rs (L26-64)
```rust
pub fn choose_random_peers_by_distance_and_latency(
    peers: HashSet<PeerNetworkId>,
    peers_and_metadata: Arc<PeersAndMetadata>,
    num_peers_to_choose: usize,
) -> HashSet<PeerNetworkId> {
    // Group peers and latency weights by validator distance, i.e., distance -> [(peer, latency weight)]
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for peer in peers {
        if let Some((distance, latency)) =
            get_distance_and_latency_for_peer(&peers_and_metadata, peer)
        {
            let latency_weight = convert_latency_to_weight(latency);
            peers_and_latencies_by_distance
                .entry(distance)
                .or_insert_with(Vec::new)
                .push((peer, latency_weight));
        }
    }

    // Select the peers by distance and latency weights. Note: BTreeMaps are
    // sorted by key, so the entries will be sorted by distance in ascending order.
    let mut selected_peers = HashSet::new();
    for (_, peers_and_latencies) in peers_and_latencies_by_distance {
        // Select the peers by latency weights
        let num_peers_remaining = num_peers_to_choose.saturating_sub(selected_peers.len()) as u64;
        let peers = choose_random_peers_by_weight(num_peers_remaining, peers_and_latencies);

        // Add the peers to the entire set
        selected_peers.extend(peers);

        // If we have selected enough peers, return early
        if selected_peers.len() >= num_peers_to_choose {
            return selected_peers;
        }
    }

    // Return the selected peers
    selected_peers
}
```

**File:** state-sync/aptos-data-client/src/utils.rs (L231-260)
```rust
fn get_distance_and_latency_for_peer(
    peers_and_metadata: &Arc<PeersAndMetadata>,
    peer: PeerNetworkId,
) -> Option<(u64, f64)> {
    if let Some(peer_metadata) = get_metadata_for_peer(peers_and_metadata, peer) {
        // Get the distance and latency for the peer
        let peer_monitoring_metadata = peer_metadata.get_peer_monitoring_metadata();
        let distance = peer_monitoring_metadata
            .latest_network_info_response
            .as_ref()
            .map(|response| response.distance_from_validators);
        let latency = peer_monitoring_metadata.average_ping_latency_secs;

        // Return the distance and latency if both were found
        if let (Some(distance), Some(latency)) = (distance, latency) {
            return Some((distance, latency));
        }
    }

    // Otherwise, no distance and latency was found
    log_warning_with_sample(
        LogSchema::new(LogEntry::PeerStates)
            .event(LogEvent::PeerSelectionError)
            .message(&format!(
                "Unable to get distance and latency for peer! Peer: {:?}",
                peer
            )),
    );
    None
}
```

**File:** consensus/src/consensus_observer/observer/subscription_utils.rs (L196-218)
```rust
fn get_distance_for_peer(
    peer_network_id: &PeerNetworkId,
    peer_metadata: &PeerMetadata,
) -> Option<u64> {
    // Get the distance for the peer
    let peer_monitoring_metadata = peer_metadata.get_peer_monitoring_metadata();
    let distance = peer_monitoring_metadata
        .latest_network_info_response
        .as_ref()
        .map(|response| response.distance_from_validators);

    // If the distance is missing, log a warning
    if distance.is_none() {
        warn!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Unable to get distance for peer! Peer: {:?}",
                peer_network_id
            ))
        );
    }

    distance
}
```

**File:** consensus/src/consensus_observer/observer/subscription_utils.rs (L283-350)
```rust
pub fn sort_peers_by_subscription_optimality(
    peers_and_metadata: &HashMap<PeerNetworkId, PeerMetadata>,
) -> Vec<PeerNetworkId> {
    // Group peers and latencies by validator distance, i.e., distance -> [(peer, latency)]
    let mut unsupported_peers = Vec::new();
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for (peer_network_id, peer_metadata) in peers_and_metadata {
        // Verify that the peer supports consensus observer
        if !supports_consensus_observer(peer_metadata) {
            unsupported_peers.push(*peer_network_id);
            continue; // Skip the peer
        }

        // Get the distance and latency for the peer
        let distance = get_distance_for_peer(peer_network_id, peer_metadata);
        let latency = get_latency_for_peer(peer_network_id, peer_metadata);

        // If the distance is not found, use the maximum distance
        let distance =
            distance.unwrap_or(aptos_peer_monitoring_service_types::MAX_DISTANCE_FROM_VALIDATORS);

        // If the latency is not found, use a large latency
        let latency = latency.unwrap_or(MAX_PING_LATENCY_SECS);

        // Add the peer and latency to the distance group
        peers_and_latencies_by_distance
            .entry(distance)
            .or_insert_with(Vec::new)
            .push((*peer_network_id, OrderedFloat(latency)));
    }

    // If there are peers that don't support consensus observer, log them
    if !unsupported_peers.is_empty() {
        info!(
            LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                "Found {} peers that don't support consensus observer! Peers: {:?}",
                unsupported_peers.len(),
                unsupported_peers
            ))
        );
    }

    // Sort the peers by distance and latency. Note: BTreeMaps are
    // sorted by key, so the entries will be sorted by distance in ascending order.
    let mut sorted_peers_and_latencies = Vec::new();
    for (_, mut peers_and_latencies) in peers_and_latencies_by_distance {
        // Sort the peers by latency
        peers_and_latencies.sort_by_key(|(_, latency)| *latency);

        // Add the peers to the sorted list (in sorted order)
        sorted_peers_and_latencies.extend(peers_and_latencies);
    }

    // Log the sorted peers and latencies
    info!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Sorted {} peers by subscription optimality! Peers and latencies: {:?}",
            sorted_peers_and_latencies.len(),
            sorted_peers_and_latencies
        ))
    );

    // Only return the sorted peers (without the latencies)
    sorted_peers_and_latencies
        .into_iter()
        .map(|(peer, _)| peer)
        .collect()
}
```

**File:** mempool/src/shared_mempool/priority.rs (L103-109)
```rust
        // Otherwise, compare by peer distance from the validators.
        // This avoids badly configured/connected peers (e.g., broken VN-VFN connections).
        let distance_ordering =
            compare_validator_distance(monitoring_metadata_a, monitoring_metadata_b);
        if !distance_ordering.is_eq() {
            return distance_ordering; // Only return if it's not equal
        }
```

**File:** mempool/src/shared_mempool/priority.rs (L613-639)
```rust
/// Compares the validator distance for the given pair of monitoring metadata.
/// The peer with the lowest validator distance is prioritized.
fn compare_validator_distance(
    monitoring_metadata_a: &Option<&PeerMonitoringMetadata>,
    monitoring_metadata_b: &Option<&PeerMonitoringMetadata>,
) -> Ordering {
    // Get the validator distance from the monitoring metadata
    let validator_distance_a = get_distance_from_validators(monitoring_metadata_a);
    let validator_distance_b = get_distance_from_validators(monitoring_metadata_b);

    // Compare the distances
    match (validator_distance_a, validator_distance_b) {
        (Some(validator_distance_a), Some(validator_distance_b)) => {
            // Prioritize the peer with the lowest validator distance
            validator_distance_a.cmp(&validator_distance_b).reverse()
        },
        (Some(_), None) => {
            Ordering::Greater // Prioritize the peer with a validator distance
        },
        (None, Some(_)) => {
            Ordering::Less // Prioritize the peer with a validator distance
        },
        (None, None) => {
            Ordering::Equal // Neither peer has a validator distance
        },
    }
}
```

**File:** peer-monitoring-service/server/src/lib.rs (L296-340)
```rust
/// Returns the distance from the validators using the given base config
/// and the peers and metadata information.
fn get_distance_from_validators(
    base_config: &BaseConfig,
    peers_and_metadata: Arc<PeersAndMetadata>,
) -> u64 {
    // Get the connected peers and metadata
    let connected_peers_and_metadata = match peers_and_metadata.get_connected_peers_and_metadata() {
        Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
        Err(error) => {
            warn!(LogSchema::new(LogEntry::PeerMonitoringServiceError).error(&error.into()));
            return MAX_DISTANCE_FROM_VALIDATORS;
        },
    };

    // If we're a validator and we have active validator peers, we're in the validator set.
    // TODO: figure out if we need to deal with validator set forks here.
    if base_config.role.is_validator() {
        for peer_metadata in connected_peers_and_metadata.values() {
            if peer_metadata.get_connection_metadata().role.is_validator() {
                return 0;
            }
        }
    }

    // Otherwise, go through our peers, find the min, and return a distance relative to the min
    let mut min_peer_distance_from_validators = MAX_DISTANCE_FROM_VALIDATORS;
    for peer_metadata in connected_peers_and_metadata.values() {
        if let Some(ref latest_network_info_response) = peer_metadata
            .get_peer_monitoring_metadata()
            .latest_network_info_response
        {
            min_peer_distance_from_validators = min(
                min_peer_distance_from_validators,
                latest_network_info_response.distance_from_validators,
            );
        }
    }

    // We're one hop away from the peer
    min(
        MAX_DISTANCE_FROM_VALIDATORS,
        min_peer_distance_from_validators + 1,
    )
}
```
