# Audit Report

## Title
StagingArea Cleanup Failure Enables Code Contamination in Chunked Package Publishing

## Summary
The `StagingArea` resource in the large_packages module is not automatically cleaned up when chunked publish transactions fail. This allows old staged code chunks from failed publishes to persist and contaminate subsequent package deployments, potentially leading to the deployment of corrupted or malicious code.

## Finding Description

The large_packages module implements chunked publishing for large Move packages by staging code chunks in a `StagingArea` resource. [1](#0-0) 

The cleanup mechanism is only invoked automatically on successful publish operations. [2](#0-1) [3](#0-2) [4](#0-3) 

When transaction failures occur during chunked publishing, the CLI warns users but does not enforce cleanup. [5](#0-4) 

The critical vulnerability lies in the `stage_code_chunk_internal` function, which appends new data to existing StagingArea contents without validation. [6](#0-5) 

Specifically, new metadata is appended to old metadata, and new code chunks are appended to existing code chunks at the same index. This breaks the integrity guarantee that deployed packages should match the intended source code.

**Attack Scenario:**

1. User attempts to publish Package A by staging chunks (metadata_A, code_A0, code_A1)
2. Final publish transaction fails (e.g., incompatible upgrade, gas exhaustion)
3. StagingArea persists with partial data from Package A
4. User later attempts to publish Package B by staging chunks (metadata_B, code_B0)
5. The staging operation appends: metadata becomes (metadata_A + metadata_B), and code[0] becomes (code_A0 + code_B0)
6. When assembled and published, the resulting package contains contaminated bytecode mixing both packages
7. The deployed code may contain unintended behavior, vulnerabilities, or malicious logic

The existing test suite confirms that staging transactions succeed even when final publish fails, but no tests verify retry behavior. [7](#0-6) 

## Impact Explanation

This vulnerability qualifies as **MEDIUM severity** under the Aptos bug bounty program for the following reasons:

1. **State Inconsistencies Requiring Intervention**: The contaminated StagingArea creates an inconsistent state that requires manual cleanup via `aptos move clear-staging-area`

2. **Potential Limited Funds Loss**: Deployed packages with contaminated code may contain security vulnerabilities or unintended behavior that could lead to fund loss for users interacting with those packages

3. **Integrity Violation**: Breaks the fundamental guarantee that deployed code should be deterministic and match the intended package source

While this does not directly cause consensus violations or network-wide issues, it can result in:
- Unintentional deployment of vulnerable smart contracts
- Financial losses from buggy contaminated code
- Wasted storage fees from leaked StagingArea data
- Attack vector for injecting malicious code into legitimate packages

## Likelihood Explanation

The likelihood of this vulnerability being triggered is **HIGH** because:

1. **Common Failure Scenarios**: Transaction failures during chunked publishing are realistic and frequent:
   - Network connectivity issues
   - Gas estimation errors  
   - Upgrade policy violations (shown in tests)
   - Out-of-gas during execution

2. **User Behavior**: Users may not be aware of the need for manual cleanup:
   - The CLI warning appears only after staging begins, not before
   - Users may assume failed transactions clean up automatically
   - Documentation emphasizes usage but not failure recovery

3. **No Automatic Protection**: The system provides:
   - Warning messages but no enforcement
   - Manual cleanup command but no automatic trigger
   - Detection of non-empty StagingArea but allows proceeding

4. **Real-World Evidence**: The CLI explicitly warns about this issue, indicating it's a known operational concern. [8](#0-7) 

## Recommendation

Implement automatic cleanup or validation safeguards to prevent code contamination:

**Option 1: Automatic Cleanup on Failure** (Preferred)
Add a cleanup mechanism in the transaction epilogue or failure handler to automatically remove StagingArea when publish transactions fail.

**Option 2: Package Identity Validation**
Modify `stage_code_chunk_internal` to store a package identifier (hash of initial metadata) and validate that all subsequent staging operations match the same package:

```move
struct StagingArea has key {
    package_hash: vector<u8>,  // Hash of first metadata chunk
    metadata_serialized: vector<u8>,
    code: SmartTable<u64, vector<u8>>,
    last_module_idx: u64
}

inline fun stage_code_chunk_internal(...) {
    // On first chunk, store package hash
    // On subsequent chunks, verify hash matches
    // Abort if different package detected
}
```

**Option 3: Enforce Cleanup Before New Publish**
Modify the CLI and Move code to enforce cleanup before starting a new chunked publish: [8](#0-7) 

Change the warning into a hard requirement that automatically calls `cleanup_staging_area` or aborts if StagingArea is non-empty.

**Option 4: Add Reset Function**
Add a function to explicitly reset/overwrite StagingArea instead of appending:

```move
public entry fun reset_and_stage_code_chunk(
    owner: &signer,
    metadata_chunk: vector<u8>,
    code_indices: vector<u16>,
    code_chunks: vector<vector<u8>>
) acquires StagingArea {
    cleanup_staging_area(owner);  // Clear old data first
    stage_code_chunk(owner, metadata_chunk, code_indices, code_chunks);
}
```

## Proof of Concept

```move
// File: test_staging_contamination.move
#[test_only]
module 0xcafe::staging_contamination_test {
    use aptos_experimental::large_packages;
    use std::vector;

    #[test(account = @0xcafe)]
    fun test_staging_contamination(account: &signer) {
        // Stage Package A
        let metadata_a = b"Package A metadata";
        let code_a0 = b"module A0 bytecode";
        large_packages::stage_code_chunk(
            account,
            metadata_a,
            vector[0u16],
            vector[code_a0]
        );
        
        // Simulate failed publish - StagingArea persists
        
        // Stage Package B - data gets appended instead of replaced
        let metadata_b = b"Package B metadata";
        let code_b0 = b"module B0 bytecode";
        large_packages::stage_code_chunk(
            account,
            metadata_b,
            vector[0u16],
            vector[code_b0]
        );
        
        // When published, the package will contain:
        // metadata: "Package A metadataPackage B metadata" (contaminated)
        // code[0]: "module A0 bytecodemodule B0 bytecode" (contaminated)
        
        // Expected: Package B only
        // Actual: Corrupted package mixing A and B
    }
}
```

**Rust Reproduction Steps:**

1. Create a large package test that stages chunks for Package A
2. Force the final publish transaction to fail (e.g., set incompatible upgrade policy)
3. Verify StagingArea resource still exists with Package A data
4. Stage chunks for Package B  
5. Verify that Package B chunks are appended to Package A chunks
6. Publish and verify the resulting package contains contaminated bytecode

## Notes

- This vulnerability is acknowledged in the codebase through CLI warnings but lacks automatic enforcement or cleanup
- The issue affects any user performing chunked publishing, not just malicious actors
- Storage refunds exist when cleanup occurs, but users must manually trigger cleanup [9](#0-8) 
- The manual cleanup command exists but is not well-integrated into failure recovery flows [10](#0-9)

### Citations

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L60-64)
```text
    struct StagingArea has key {
        metadata_serialized: vector<u8>,
        code: SmartTable<u64, vector<u8>>,
        last_module_idx: u64
    }
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L94-94)
```text
        cleanup_staging_area(owner);
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L111-111)
```text
        cleanup_staging_area(owner);
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L129-129)
```text
        cleanup_staging_area(owner);
```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L156-179)
```text
        let staging_area = borrow_global_mut<StagingArea>(owner_address);

        if (!vector::is_empty(&metadata_chunk)) {
            vector::append(&mut staging_area.metadata_serialized, metadata_chunk);
        };

        let i = 0;
        while (i < vector::length(&code_chunks)) {
            let inner_code = *vector::borrow(&code_chunks, i);
            let idx = (*vector::borrow(&code_indices, i) as u64);

            if (smart_table::contains(&staging_area.code, idx)) {
                vector::append(
                    smart_table::borrow_mut(&mut staging_area.code, idx), inner_code
                );
            } else {
                smart_table::add(&mut staging_area.code, idx, inner_code);
                if (idx > staging_area.last_module_idx) {
                    staging_area.last_module_idx = idx;
                }
            };
            i = i + 1;
        };

```

**File:** aptos-move/framework/aptos-experimental/sources/large_packages.move (L227-231)
```text
    public entry fun cleanup_staging_area(owner: &signer) acquires StagingArea {
        let StagingArea { metadata_serialized: _, code, last_module_idx: _ } =
            move_from<StagingArea>(signer::address_of(owner));
        smart_table::destroy(code);
    }
```

**File:** crates/aptos/src/move_tool/mod.rs (L1704-1714)
```rust
    if !is_staging_area_empty(txn_options, large_packages_module_address).await? {
        let message = format!(
            "The resource {}::large_packages::StagingArea under account {} is not empty.\
        \nThis may cause package publishing to fail if the data is unexpected. \
        \nUse the `aptos move clear-staging-area` command to clean up the `StagingArea` resource under the account.",
            large_packages_module_address, account_address,
        )
            .bold();
        println!("{}", message);
        prompt_yes_with_override("Do you want to proceed?", txn_options.prompt_options)?;
    }
```

**File:** crates/aptos/src/move_tool/mod.rs (L1736-1740)
```rust
                println!("{}", "Caution: An error occurred while submitting chunked publish transactions. \
                \nDue to this error, there may be incomplete data left in the `StagingArea` resource. \
                \nThis could cause further errors if you attempt to run the chunked publish command again. \
                \nTo avoid this, use the `aptos move clear-staging-area` command to clean up the `StagingArea` resource under your account before retrying.".bold());
                return Err(e);
```

**File:** crates/aptos/src/move_tool/mod.rs (L1817-1850)
```rust
/// Cleans up the `StagingArea` resource under an account, which is used for chunked publish operations
#[derive(Parser)]
pub struct ClearStagingArea {
    #[clap(flatten)]
    pub(crate) txn_options: TransactionOptions,

    #[clap(flatten)]
    pub(crate) large_packages_module: LargePackagesModuleOption,
}

#[async_trait]
impl CliCommand<TransactionSummary> for ClearStagingArea {
    fn command_name(&self) -> &'static str {
        "ClearStagingArea"
    }

    async fn execute(self) -> CliTypedResult<TransactionSummary> {
        let (_, account_address) = self.txn_options.get_public_key_and_address()?;

        let large_packages_module_address = self
            .large_packages_module
            .large_packages_module_address(&self.txn_options)
            .await?;
        println!(
            "Cleaning up resource {}::large_packages::StagingArea under account {}.",
            &large_packages_module_address, account_address,
        );
        let payload = large_packages_cleanup_staging_area(large_packages_module_address);
        self.txn_options
            .submit_transaction(payload)
            .await
            .map(TransactionSummary::from)
    }
}
```

**File:** aptos-move/e2e-move-tests/src/tests/large_package_publishing.rs (L245-262)
```rust
    // Staging metadata and code should pass, and the final publishing transaction should fail
    let mut tx_statuses = context.publish_large_package(
        &acc,
        &common::test_dir_path("large_package_publishing.data/large_pack_upgrade_incompat"),
        |_| {},
        PublishType::AccountDeploy,
    );

    let last_tx_status = tx_statuses.pop().unwrap(); // transaction for publishing

    for tx_status in tx_statuses.into_iter() {
        assert_success!(tx_status);
    }
    assert_vm_status!(
        last_tx_status,
        StatusCode::BACKWARD_INCOMPATIBLE_MODULE_UPDATE
    );
}
```
