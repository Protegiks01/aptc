# Audit Report

## Title
Checkpoint Creation During Concurrent Commits Violates Atomicity Guarantees Across Multiple RocksDB Instances

## Summary
The `AptosDB::create_checkpoint` function can capture partially committed transactions when executed concurrently with ongoing database commits. This occurs because checkpoint creation sequentially snapshots multiple independent RocksDB instances while parallel commit operations write to these same instances without coordination, violating atomic state transition guarantees.

## Finding Description

AptosDB maintains its state across **four separate RocksDB instances**: LedgerDb, StateKvDb, StateMerkleDb (hot), and StateMerkleDb (cold). [1](#0-0) 

During transaction commits, the `pre_commit_ledger` function spawns **parallel threads** that write to these databases concurrently using thread pools. [2](#0-1) 

These parallel writes include:
- Transactions to `transaction_db` (part of LedgerDb)
- Events to `event_db` (part of LedgerDb)  
- State key-values to `state_kv_db` (separate instance)
- Transaction infos to `transaction_info_db` (part of LedgerDb)
- Merkle tree nodes to `state_merkle_db` (separate instance)

The commit process uses instance-level locks (`pre_commit_lock` and `commit_lock`) to prevent concurrent commits. [3](#0-2) 

However, the checkpoint creation function is **static** and operates directly on database files without any access to these locks. [4](#0-3) 

The checkpoint process **sequentially** creates snapshots of each database:
1. LedgerDb checkpoint (includes metadata_db, transaction_db, event_db, etc.)
2. StateKvDb checkpoint (if sharding enabled)
3. StateMerkleDb hot checkpoint (if sharding enabled)
4. StateMerkleDb cold checkpoint

**Race Condition Scenario:**
```
Time T0: Commit starts, acquires pre_commit_lock
Time T1: Parallel tasks write new transactions to LedgerDb.transaction_db
Time T2: Checkpoint starts (no lock coordination), creates LedgerDb snapshot → captures new transactions
Time T3: Checkpoint creates StateKvDb snapshot
Time T4: Parallel tasks write corresponding state to StateKvDb
Time T5: Checkpoint creates StateMerkleDb snapshot → misses state updates
Time T6: Commit completes, releases locks
```

**Result:** The checkpoint contains transactions in LedgerDb without their corresponding state changes in StateKvDb and StateMerkleDb, violating the **State Consistency** invariant that "state transitions must be atomic and verifiable via Merkle proofs."

## Impact Explanation

**Critical Severity** - This vulnerability meets the following critical impact criteria from the Aptos bug bounty program:

1. **State Inconsistency Requiring Intervention**: The checkpoint contains an atomically inconsistent state across multiple databases. If restored, this would result in a database where:
   - Transaction history shows transactions were committed
   - State databases lack the corresponding state updates
   - Merkle tree roots don't match expected values
   - Transaction execution replay would produce different results

2. **Consensus Safety Violations**: If multiple validators restore from checkpoints taken at different moments during parallel commits, they will have divergent state. This can lead to:
   - Different validators computing different state roots for the same version
   - Consensus failures when validators can't agree on state
   - Potential chain splits requiring manual intervention

3. **Non-recoverable Network Partition**: In a worst-case scenario where corrupted checkpoints are widely distributed (e.g., as part of a state sync or backup procedure), recovery may require a hardfork to establish a new canonical state.

The vulnerability directly violates Critical Invariant #4: "State Consistency: State transitions must be atomic and verifiable via Merkle proofs."

## Likelihood Explanation

**High Likelihood** for the following reasons:

1. **Common Operation**: Database checkpoints are a standard operational procedure for:
   - Creating backups before maintenance
   - State sync operations  
   - Database migration/upgrades
   - Testing and debugging via the db_debugger tool

2. **No Guards or Warnings**: The code contains no warnings, locks, or coordination mechanisms to prevent checkpoint creation during active commits. The db_debugger checkpoint command can be run at any time.

3. **Continuous Commits**: Validator nodes continuously commit new blocks (every few seconds in normal operation), creating a large time window where the race condition can occur.

4. **No Atomic Multi-DB Checkpoint**: RocksDB's checkpoint API only provides atomicity guarantees within a single database instance, not across multiple independent instances.

The race condition window is measured in **milliseconds to seconds** (the duration of `calculate_and_commit_ledger_and_state_kv`), making it highly likely to occur if checkpoints are created during normal operation.

## Recommendation

Implement proper coordination between checkpoint creation and database commits. Two approaches:

**Approach 1: Convert to Instance Method with Lock Coordination**
Modify `create_checkpoint` to be an instance method that acquires both `pre_commit_lock` and `commit_lock` before creating checkpoints:

```rust
// In storage/aptosdb/src/db/mod.rs
pub fn create_checkpoint_synchronized(
    &self,
    cp_path: impl AsRef<Path>,
) -> Result<()> {
    // Acquire locks to ensure no concurrent commits
    let _pre_commit = self.pre_commit_lock.lock()
        .expect("Failed to acquire pre_commit_lock for checkpoint");
    let _commit = self.commit_lock.lock()
        .expect("Failed to acquire commit_lock for checkpoint");
    
    let start = Instant::now();
    info!("Creating synchronized checkpoint for AptosDB.");
    
    // Now safe to create checkpoints sequentially
    self.ledger_db.create_checkpoint_instance(cp_path.as_ref())?;
    if self.state_kv_db.is_sharded() {
        self.state_kv_db.create_checkpoint_instance(cp_path.as_ref())?;
        // ... continue for other databases
    }
    
    info!(time_ms = %start.elapsed().as_millis(), "Checkpoint created.");
    Ok(())
}
```

**Approach 2: Require Database Shutdown**
Add explicit documentation and validation that checkpoints should only be created when the database is not actively committing (e.g., during controlled shutdown or in read-only mode):

```rust
pub fn create_checkpoint(
    db_path: impl AsRef<Path>,
    cp_path: impl AsRef<Path>,
    sharding: bool,
) -> Result<()> {
    // Verify database is not actively being written to
    warn!("Creating checkpoint without active instance coordination. 
           Ensure database is stopped or in read-only mode.");
    
    // Consider opening in readonly=true mode to validate
    let _ = Self::open_internal(
        &StorageDirPaths::from_path(&db_path),
        /*readonly=*/ true,  // Verify we can open in readonly
        // ... other params
    )?;
    
    // Proceed with checkpoint creation
    // ...
}
```

**Recommended Solution**: Implement Approach 1 for programmatic checkpoints, and clearly document that the static `create_checkpoint` method should only be used when the database is definitively stopped.

## Proof of Concept

```rust
// File: storage/aptosdb/src/db/checkpoint_race_test.rs
#[cfg(test)]
mod checkpoint_race_tests {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_types::transaction::Transaction;
    use std::sync::{Arc, atomic::{AtomicBool, Ordering}};
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_checkpoint_during_commit_creates_inconsistent_state() {
        // Setup: Create a test database
        let tmpdir = TempPath::new();
        let db = Arc::new(AptosDB::new_for_test(&tmpdir));
        
        // Setup: Prepare test transactions to commit
        let mut transactions = vec![];
        for i in 0..100 {
            transactions.push(create_test_transaction(i));
        }
        
        let checkpoint_dir = TempPath::new();
        let race_occurred = Arc::new(AtomicBool::new(false));
        
        // Thread 1: Continuously commit transactions
        let db_clone = Arc::clone(&db);
        let commit_handle = thread::spawn(move || {
            for chunk in transactions.chunks(10) {
                // This will hold pre_commit_lock during the write
                db_clone.save_transactions(
                    &chunk,
                    /* first_version */ 0,
                    /* base_state_version */ None,
                    /* ledger_info */ None,
                    /* sync_commit */ true,
                ).unwrap();
                thread::sleep(Duration::from_millis(10));
            }
        });
        
        // Thread 2: Create checkpoint during commits
        let db_path = tmpdir.path();
        let cp_path = checkpoint_dir.path();
        let race_flag = Arc::clone(&race_occurred);
        
        thread::sleep(Duration::from_millis(50)); // Let some commits happen
        
        let checkpoint_handle = thread::spawn(move || {
            // This does NOT acquire pre_commit_lock or commit_lock
            AptosDB::create_checkpoint(
                db_path,
                cp_path,
                /*sharding=*/ true,
            ).unwrap();
            race_flag.store(true, Ordering::SeqCst);
        });
        
        commit_handle.join().unwrap();
        checkpoint_handle.join().unwrap();
        
        // Verify: Open checkpoint and check for inconsistency
        let checkpoint_db = AptosDB::open(
            StorageDirPaths::from_path(&checkpoint_dir),
            /*readonly=*/ true,
            // ... config
        ).unwrap();
        
        // Check if transaction count in LedgerDb matches state version in StateKvDb
        let ledger_version = checkpoint_db.get_latest_ledger_info().unwrap().version();
        let state_version = checkpoint_db.get_latest_state_checkpoint_version().unwrap();
        
        // If race occurred during checkpoint creation, these will be inconsistent
        assert!(
            race_occurred.load(Ordering::SeqCst),
            "Race condition test setup failed"
        );
        
        // This assertion may fail, proving the vulnerability:
        // ledger_version should equal state_version for consistency
        if ledger_version != state_version {
            panic!("VULNERABILITY CONFIRMED: Checkpoint captured inconsistent state. \
                    Ledger version: {}, State version: {}", 
                    ledger_version, state_version);
        }
    }
}
```

## Notes

The root cause is the architectural decision to split AptosDB across multiple independent RocksDB instances combined with the static checkpoint method that cannot coordinate with active database instances. While RocksDB provides atomic checkpoints within a single database, it cannot provide atomicity guarantees across the four separate instances that compose AptosDB.

This vulnerability is particularly concerning because:
1. The db_debugger checkpoint tool is documented as an operational tool
2. Checkpoints are commonly used for backup and disaster recovery
3. No warnings exist about checkpoint timing requirements
4. The static method signature suggests it's safe to call without a running instance

### Citations

**File:** storage/aptosdb/src/db/mod.rs (L106-156)
```rust
    pub fn open_dbs(
        db_paths: &StorageDirPaths,
        rocksdb_configs: RocksdbConfigs,
        env: Option<&Env>,
        block_cache: Option<&Cache>,
        readonly: bool,
        max_num_nodes_per_lru_cache_shard: usize,
        reset_hot_state: bool,
    ) -> Result<(LedgerDb, Option<StateMerkleDb>, StateMerkleDb, StateKvDb)> {
        let ledger_db = LedgerDb::new(
            db_paths.ledger_db_root_path(),
            rocksdb_configs,
            env,
            block_cache,
            readonly,
        )?;
        let state_kv_db = StateKvDb::new(
            db_paths,
            rocksdb_configs,
            env,
            block_cache,
            readonly,
            ledger_db.metadata_db_arc(),
        )?;
        let hot_state_merkle_db = if !readonly && rocksdb_configs.enable_storage_sharding {
            Some(StateMerkleDb::new(
                db_paths,
                rocksdb_configs,
                env,
                block_cache,
                readonly,
                max_num_nodes_per_lru_cache_shard,
                /* is_hot = */ true,
                reset_hot_state,
            )?)
        } else {
            None
        };
        let state_merkle_db = StateMerkleDb::new(
            db_paths,
            rocksdb_configs,
            env,
            block_cache,
            readonly,
            max_num_nodes_per_lru_cache_shard,
            /* is_hot = */ false,
            /* delete_on_restart = */ false,
        )?;

        Ok((ledger_db, hot_state_merkle_db, state_merkle_db, state_kv_db))
    }
```

**File:** storage/aptosdb/src/db/mod.rs (L172-205)
```rust
    pub fn create_checkpoint(
        db_path: impl AsRef<Path>,
        cp_path: impl AsRef<Path>,
        sharding: bool,
    ) -> Result<()> {
        let start = Instant::now();

        info!(sharding = sharding, "Creating checkpoint for AptosDB.");

        LedgerDb::create_checkpoint(db_path.as_ref(), cp_path.as_ref(), sharding)?;
        if sharding {
            StateKvDb::create_checkpoint(db_path.as_ref(), cp_path.as_ref())?;
            StateMerkleDb::create_checkpoint(
                db_path.as_ref(),
                cp_path.as_ref(),
                sharding,
                /* is_hot = */ true,
            )?;
        }
        StateMerkleDb::create_checkpoint(
            db_path.as_ref(),
            cp_path.as_ref(),
            sharding,
            /* is_hot = */ false,
        )?;

        info!(
            db_path = db_path.as_ref(),
            cp_path = cp_path.as_ref(),
            time_ms = %start.elapsed().as_millis(),
            "Made AptosDB checkpoint."
        );
        Ok(())
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L43-76)
```rust
impl DbWriter for AptosDB {
    fn pre_commit_ledger(&self, chunk: ChunkToCommit, sync_commit: bool) -> Result<()> {
        gauged_api("pre_commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .pre_commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["pre_commit_ledger"]);

            chunk
                .state_summary
                .latest()
                .global_state_summary
                .log_generation("db_save");

            self.pre_commit_validation(&chunk)?;
            let _new_root_hash =
                self.calculate_and_commit_ledger_and_state_kv(&chunk, self.skip_index_and_usage)?;

            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions__others"]);

            self.state_store.buffered_state().lock().update(
                chunk.result_ledger_state_with_summary(),
                chunk.estimated_total_state_updates(),
                sync_commit || chunk.is_reconfig,
            )?;

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L263-322)
```rust
    fn calculate_and_commit_ledger_and_state_kv(
        &self,
        chunk: &ChunkToCommit,
        skip_index_and_usage: bool,
    ) -> Result<HashValue> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions__work"]);

        let mut new_root_hash = HashValue::zero();
        THREAD_MANAGER.get_non_exe_cpu_pool().scope(|s| {
            // TODO(grao): Write progress for each of the following databases, and handle the
            // inconsistency at the startup time.
            //
            // TODO(grao): Consider propagating the error instead of panic, if necessary.
            s.spawn(|_| {
                self.commit_events(
                    chunk.first_version,
                    chunk.transaction_outputs,
                    skip_index_and_usage,
                )
                .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .write_set_db()
                    .commit_write_sets(chunk.first_version, chunk.transaction_outputs)
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .transaction_db()
                    .commit_transactions(
                        chunk.first_version,
                        chunk.transactions,
                        skip_index_and_usage,
                    )
                    .unwrap()
            });
            s.spawn(|_| {
                self.ledger_db
                    .persisted_auxiliary_info_db()
                    .commit_auxiliary_info(chunk.first_version, chunk.persisted_auxiliary_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_state_kv_and_ledger_metadata(chunk, skip_index_and_usage)
                    .unwrap()
            });
            s.spawn(|_| {
                self.commit_transaction_infos(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
            s.spawn(|_| {
                new_root_hash = self
                    .commit_transaction_accumulator(chunk.first_version, chunk.transaction_infos)
                    .unwrap()
            });
        });

        Ok(new_root_hash)
    }
```
