Based on my thorough analysis of the Aptos Core codebase, I have validated this security claim and found it to be **VALID** with one correction needed.

# Audit Report

## Title
Race Condition in OrderedBlockWindow Weak Pointer Access Causes Validator Node Panic

## Summary
A Time-of-Check-Time-of-Use (TOCTOU) race condition exists in `BlockStore::insert_block()` where a read lock is released after obtaining an `OrderedBlockWindow` with weak pointers, then `blocks()` is called without holding any lock. Concurrently, `commit_callback()` can prune and remove blocks from the tree, causing weak pointer upgrades to fail and triggering an explicit panic that crashes the validator node.

## Finding Description

The vulnerability stems from the design of `OrderedBlockWindow`, which stores `Weak<PipelinedBlock>` pointers rather than strong `Arc` references. [1](#0-0)  When `OrderedBlockWindow::new()` is called, it downgrades all `Arc<PipelinedBlock>` references to weak pointers, leaving the BlockTree's `id_to_block` HashMap as the only source of strong references.

**Vulnerable Code Path in Block Insertion:**

In `BlockStore::insert_block()`, the following race condition occurs: [2](#0-1) 

1. Lines 421-424: A read lock is acquired on `self.inner` (BlockTree), and `get_ordered_block_window()` is called, creating an `OrderedBlockWindow` with weak pointers to ancestor blocks
2. The read lock is **immediately released** when the guard goes out of scope at the semicolon on line 424
3. Line 425: `block_window.blocks()` is called **without holding any lock**

**Panic-Inducing Methods:**

Both `blocks()` and `pipelined_blocks()` methods contain explicit panic statements if weak pointer upgrade fails: [3](#0-2) [4](#0-3) 

**Concurrent Block Removal:**

During the vulnerable window (after lock release, before `blocks()` call), another thread executing the pipeline callback can acquire a write lock and call `commit_callback()`: [5](#0-4) 

The `commit_callback()` function calls `process_pruned_blocks()` to remove old blocks from memory: [6](#0-5) 

When `pruned_block_ids` exceeds `max_pruned_blocks_in_mem` (default 100), `process_pruned_blocks()` calls `remove_block()`: [7](#0-6) 

The `remove_block()` method removes the block from the `id_to_block` HashMap: [8](#0-7) 

When the `Arc<PipelinedBlock>` is removed from the HashMap and it's the last strong reference, the block is deallocated, invalidating all weak pointers to it.

**Race Sequence:**
1. Thread 1 (insert_block): Gets OrderedBlockWindow with weak pointers, releases read lock
2. Thread 2 (pipeline callback): Acquires write lock, calls commit_callback, removes old blocks via process_pruned_blocks
3. Thread 1: Calls blocks() on OrderedBlockWindow, weak pointer upgrade fails → **PANIC**

## Impact Explanation

**Severity: High** (Validator Node Crash)

This vulnerability causes validator node panics, leading to:

1. **Immediate Node Crash**: The explicit panic terminates the validator process, requiring manual restart
2. **Consensus Disruption**: Multiple validators experiencing this race during network stress degrades consensus performance
3. **Liveness Impact**: Repeated crashes reduce validator availability and overall network liveness
4. **No Data Corruption**: The panic occurs before state changes, preventing permanent corruption

This meets **High Severity** criteria per the Aptos bug bounty program under "Validator node slowdowns" and "API crashes." While not causing permanent damage, it creates operational instability and potential denial of service against individual validators.

## Likelihood Explanation

**Likelihood: Medium**

The race condition can occur during normal consensus operation when:

1. **Concurrent Operations**: One thread inserts a new block while another commits an older block (happens continuously)
2. **Memory Pressure**: When `pruned_block_ids` exceeds `max_pruned_blocks_in_mem` (default 100 per [9](#0-8) ), old blocks are removed from memory
3. **High Throughput**: Faster block production increases the probability of timing overlap

The vulnerability is more likely during:
- Network synchronization when nodes catch up
- High transaction throughput periods  
- Validator restarts when replaying blocks

While the race window is small (microseconds to milliseconds), the high frequency of block operations means cumulative probability over time is significant.

## Recommendation

**Fix 1: Hold Lock During Access**
Modify `insert_block()` to hold the read lock while calling `blocks()`:

```rust
pub async fn insert_block(&self, block: Block) -> anyhow::Result<Arc<PipelinedBlock>> {
    // ... existing checks ...
    
    let blocks = {
        let guard = self.inner.read();
        let block_window = guard.get_ordered_block_window(&block, self.window_size)?;
        block_window.blocks() // Call blocks() while still holding lock
    };
    
    for block in blocks {
        // ... prefetch logic ...
    }
    // ... rest of function ...
}
```

**Fix 2: Use Strong References**
Modify `OrderedBlockWindow` to store `Arc<PipelinedBlock>` instead of `Weak<PipelinedBlock>`, ensuring blocks remain alive during the window's lifetime.

**Fix 3: Return Result Instead of Panic**
Modify `blocks()` and `pipelined_blocks()` to return `Result` instead of panicking, allowing graceful error handling.

## Proof of Concept

The vulnerability can be demonstrated by creating concurrent threads that insert blocks while commits are pruning old blocks. When `pruned_block_ids` exceeds 100, the race condition window opens and weak pointer upgrades can fail, causing the panic.

```rust
// Conceptual PoC showing the race:
// Thread 1: insert_block creates OrderedBlockWindow, releases lock
// Thread 2: commit_callback acquires lock, prunes blocks
// Thread 1: calls blocks() → panic if blocks were pruned
```

The panic message will be: `"Block with id: {} not found during upgrade in OrderedBlockWindow::blocks()"`

## Notes

**Important Correction**: The original report claimed that `find_window_root()` is also vulnerable. This is **incorrect**. The `find_window_root()` function is called from within `commit_callback()` which holds an exclusive write lock (&mut self) throughout execution. Since the write lock is held when `find_window_root()` calls `get_ordered_block_window()` and `pipelined_blocks()`, and `process_pruned_blocks()` is only called afterward, there is no race condition in this path. The blocks cannot be removed while `find_window_root()` is executing.

The vulnerability is limited to the `BlockStore::insert_block()` path where the lock is explicitly released before accessing the weak pointers.

### Citations

**File:** consensus/consensus-types/src/pipelined_block.rs (L136-149)
```rust
pub struct OrderedBlockWindow {
    /// `block_id` (HashValue) helps with logging in the unlikely case there are issues upgrading
    /// the `Weak` pointer (we can use `block_id`)
    blocks: Vec<(HashValue, Weak<PipelinedBlock>)>,
}

impl OrderedBlockWindow {
    pub fn new(blocks: Vec<Arc<PipelinedBlock>>) -> Self {
        Self {
            blocks: blocks
                .iter()
                .map(|x| (x.id(), Arc::downgrade(x)))
                .collect::<Vec<(HashValue, Weak<PipelinedBlock>)>>(),
        }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L161-175)
```rust
    pub fn blocks(&self) -> Vec<Block> {
        let mut blocks: Vec<Block> = vec![];
        for (block_id, block) in self.blocks.iter() {
            let upgraded_block = block.upgrade();
            if let Some(block) = upgraded_block {
                blocks.push(block.block().clone())
            } else {
                panic!(
                    "Block with id: {} not found during upgrade in OrderedBlockWindow::blocks()",
                    block_id
                )
            }
        }
        blocks
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L177-190)
```rust
    pub fn pipelined_blocks(&self) -> Vec<Arc<PipelinedBlock>> {
        let mut blocks: Vec<Arc<PipelinedBlock>> = Vec::new();
        for (block_id, block) in self.blocks.iter() {
            if let Some(block) = block.upgrade() {
                blocks.push(block);
            } else {
                panic!(
                    "Block with id: {} not found during upgrade in OrderedBlockWindow::pipelined_blocks()",
                    block_id
                )
            }
        }
        blocks
    }
```

**File:** consensus/src/block_storage/block_store.rs (L421-425)
```rust
        let block_window = self
            .inner
            .read()
            .get_ordered_block_window(&block, self.window_size)?;
        let blocks = block_window.blocks();
```

**File:** consensus/src/block_storage/block_store.rs (L475-488)
```rust
            let callback = Box::new(
                move |finality_proof: WrappedLedgerInfo,
                      commit_decision: LedgerInfoWithSignatures| {
                    if let Some(tree) = block_tree.upgrade() {
                        tree.write().commit_callback(
                            storage,
                            id,
                            round,
                            finality_proof,
                            commit_decision,
                            window_size,
                        );
                    }
                },
```

**File:** consensus/src/block_storage/block_tree.rs (L174-181)
```rust
    fn remove_block(&mut self, block_id: HashValue) {
        // Remove the block from the store
        if let Some(block) = self.id_to_block.remove(&block_id) {
            let round = block.executed_block().round();
            self.round_to_ids.remove(&round);
        };
        self.id_to_quorum_cert.remove(&block_id);
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L496-510)
```rust
    pub(super) fn process_pruned_blocks(&mut self, mut newly_pruned_blocks: VecDeque<HashValue>) {
        counters::NUM_BLOCKS_IN_TREE.sub(newly_pruned_blocks.len() as i64);
        // The newly pruned blocks are pushed back to the deque pruned_block_ids.
        // In case the overall number of the elements is greater than the predefined threshold,
        // the oldest elements (in the front of the deque) are removed from the tree.
        self.pruned_block_ids.append(&mut newly_pruned_blocks);
        if self.pruned_block_ids.len() > self.max_pruned_blocks_in_mem {
            let num_blocks_to_remove = self.pruned_block_ids.len() - self.max_pruned_blocks_in_mem;
            for _ in 0..num_blocks_to_remove {
                if let Some(id) = self.pruned_block_ids.pop_front() {
                    self.remove_block(id);
                }
            }
        }
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L588-598)
```rust
        let window_root_id = self.find_window_root(block_id, window_size);
        let ids_to_remove = self.find_blocks_to_prune(window_root_id);

        if let Err(e) = storage.prune_tree(ids_to_remove.clone().into_iter().collect()) {
            // it's fine to fail here, as long as the commit succeeds, the next restart will clean
            // up dangling blocks, and we need to prune the tree to keep the root consistent with
            // executor.
            warn!(error = ?e, "fail to delete block");
        }
        self.process_pruned_blocks(ids_to_remove);
        self.update_window_root(window_root_id);
```

**File:** config/src/config/consensus_config.rs (L232-232)
```rust
            max_pruned_blocks_in_mem: 100,
```
