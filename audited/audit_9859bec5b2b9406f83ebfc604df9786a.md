# Audit Report

## Title
Consensus Split via Non-Deterministic JWK Consensus Config Fallback During Transient Database Errors

## Summary
When `OnChainJWKConsensusConfig` is not initialized on-chain, validators fall back to computing an equivalent configuration from `Features` and `SupportedOIDCProviders`. The fallback function silently converts database read errors to `None` using `.ok()`, causing different validators experiencing transient database errors to compute different configurations, leading to a consensus split. [1](#0-0) 

## Finding Description

During epoch changes, validators read on-chain configurations to initialize their consensus state. The JWK consensus configuration follows this path:

1. Attempt to read `OnChainJWKConsensusConfig` from the on-chain config payload [2](#0-1) 

2. If reading fails (config not initialized or read error), trigger fallback to compute from deprecated resources [3](#0-2) 

3. In the fallback function, read `Features` and `SupportedOIDCProviders` with `.ok()` converting errors to `None` [1](#0-0) 

4. Convert to `OnChainJWKConsensusConfig` based on whether `Features` contains `JWK_CONSENSUS` flag [4](#0-3) 

The vulnerability occurs when validators experience different database read results:

**Scenario:**
- Validator A successfully reads `Features` (with `JWK_CONSENSUS=enabled`) and `SupportedOIDCProviders`
  - Computes: `OnChainJWKConsensusConfig::V1(ConfigV1 { oidc_providers: [...] })`
- Validator B experiences transient DB error reading `Features`, succeeds reading `SupportedOIDCProviders`
  - Gets `features = None`, `oidc_providers = Some([...])`
  - Computes: `OnChainJWKConsensusConfig::Off` (line 128-129 returns `Off` when features is `None`) [5](#0-4) 

This breaks the **Deterministic Execution** invariant because validators now have different consensus configurations from identical blockchain state.

When blocks containing `ValidatorTransaction::ObservedJWKUpdate` are proposed:
- Validator A checks `is_vtxn_expected()` → returns `true` → accepts block
- Validator B checks `is_vtxn_expected()` → returns `false` → rejects with "unexpected validator txn" error [6](#0-5) [7](#0-6) 

Validators cannot reach consensus on block validity, causing a consensus split.

**Critical Evidence:**
- Unlike other configs, `jwk_consensus_config` read failures are NOT logged (no warning at lines 1187-1197), making this issue silent [8](#0-7) 

- Database reads can fail transiently without retry logic [9](#0-8) 

## Impact Explanation

**Severity: CRITICAL**

This vulnerability causes a **Consensus/Safety violation**, qualifying for Critical severity ($1,000,000 max payout) per Aptos bug bounty criteria:

1. **Consensus Split**: Validators disagree on block validity, unable to form quorum certificates
2. **Chain Fork Risk**: Network partitions into groups with different configs
3. **Non-recoverable**: Requires manual intervention or hard fork to resolve
4. **Violates Core Invariant**: Breaks "Deterministic Execution" - validators produce different results from identical blockchain state

The impact affects the entire validator set and network availability, not just individual nodes.

## Likelihood Explanation

**Likelihood: LOW to MEDIUM**

While the impact is critical, exploitation requires specific conditions:

**Required Conditions:**
1. `OnChainJWKConsensusConfig` not initialized on-chain (triggers fallback for all validators)
2. Transient database read errors during epoch change affecting `Features` or `SupportedOIDCProviders`
3. Errors affect subset of validators (not all or none)

**Factors Increasing Likelihood:**
- No retry logic for database reads during reconfig
- Epoch changes are predictable events
- Large validator sets increase probability of inconsistent errors
- Resource exhaustion during peak load could trigger transient errors
- No error logging makes detection difficult

**Factors Decreasing Likelihood:**
- RocksDB (underlying storage) is highly reliable for committed data
- All validators read from same version (deterministic state)
- Transient errors during config reads are rare in practice

## Recommendation

**Immediate Fix: Add Retry Logic and Error Logging**

1. Add retry logic with exponential backoff for config reads in fallback:

```rust
fn equivalent_jwk_consensus_config_from_deprecated_resources(
    payload: &OnChainConfigPayload<P>,
) -> OnChainJWKConsensusConfig {
    // Retry config reads with backoff instead of silent .ok()
    let features = retry_config_read(|| payload.get::<Features>())
        .unwrap_or_else(|e| {
            error!("Failed to read Features in JWK config fallback after retries: {}", e);
            None
        });
    
    let oidc_providers = retry_config_read(|| payload.get::<SupportedOIDCProviders>())
        .unwrap_or_else(|e| {
            error!("Failed to read SupportedOIDCProviders in JWK config fallback after retries: {}", e);
            None
        });
    
    OnChainJWKConsensusConfig::from((features, oidc_providers))
}
```

2. Add error logging for `OnChainJWKConsensusConfig` read failures (consistent with other configs):

```rust
if let Err(error) = &onchain_jwk_consensus_config {
    warn!("Failed to read on-chain JWK consensus config: {}", error);
}
```

3. Consider panicking on fallback config read failures rather than silently using `None`, since this is safety-critical:

```rust
let features = payload.get::<Features>()
    .expect("FATAL: Cannot read Features for JWK consensus config fallback");
```

**Long-term Fix:**
- Ensure `OnChainJWKConsensusConfig` is always initialized before deprecating fallback path
- Add consensus-level validation that all validators computed same config during epoch change
- Add monitoring/alerting for config read failures during epoch transitions

## Proof of Concept

```rust
// Simulation demonstrating the consensus split
// This would need to be run with fault injection to simulate DB errors

#[test]
fn test_jwk_config_fallback_inconsistency() {
    use aptos_types::on_chain_config::{Features, OnChainJWKConsensusConfig};
    use aptos_types::jwks::SupportedOIDCProviders;
    
    // Setup: Features with JWK_CONSENSUS enabled
    let mut features = Features::default();
    features.enable(FeatureFlag::JWK_CONSENSUS);
    
    // Setup: SupportedOIDCProviders with test provider
    let providers = SupportedOIDCProviders {
        providers: vec![OIDCProvider::new(
            "https://accounts.google.com".to_string(),
            "https://accounts.google.com/.well-known/openid-configuration".to_string()
        )]
    };
    
    // Validator A: Successfully reads both configs
    let features_a = Some(features.clone());
    let providers_a = Some(providers.clone());
    let config_a = OnChainJWKConsensusConfig::from((features_a, providers_a));
    
    // Validator B: DB error reading Features (simulated by None)
    let features_b = None; // Simulates transient DB error converted to None by .ok()
    let providers_b = Some(providers.clone());
    let config_b = OnChainJWKConsensusConfig::from((features_b, providers_b));
    
    // Assert: Validators computed different configs!
    assert_ne!(config_a, config_b);
    
    // config_a is V1 with providers
    assert!(config_a.jwk_consensus_enabled());
    
    // config_b is Off (because features was None)
    assert!(!config_b.jwk_consensus_enabled());
    
    // This causes validators to disagree on whether ObservedJWKUpdate 
    // validator transactions are valid, leading to consensus split
}
```

**Notes:**
- This vulnerability is particularly insidious because it occurs silently without error logging
- The fallback function name "equivalent_jwk_consensus_config_from_deprecated_resources" implies the result should be equivalent, but it's only equivalent when all validators successfully read the same resources
- The use of `.ok()` to silently convert errors to `None` is the root cause, creating non-determinism when validators experience different error conditions

### Citations

**File:** consensus/src/epoch_manager.rs (L1184-1184)
```rust
        let onchain_jwk_consensus_config: anyhow::Result<OnChainJWKConsensusConfig> = payload.get();
```

**File:** consensus/src/epoch_manager.rs (L1187-1197)
```rust
        if let Err(error) = &onchain_consensus_config {
            warn!("Failed to read on-chain consensus config {}", error);
        }

        if let Err(error) = &onchain_execution_config {
            warn!("Failed to read on-chain execution config {}", error);
        }

        if let Err(error) = &randomness_config_move_struct {
            warn!("Failed to read on-chain randomness config {}", error);
        }
```

**File:** consensus/src/epoch_manager.rs (L1223-1226)
```rust
        let jwk_consensus_config = onchain_jwk_consensus_config.unwrap_or_else(|_| {
            // `jwk_consensus_config` not yet initialized, falling back to the old configs.
            Self::equivalent_jwk_consensus_config_from_deprecated_resources(&payload)
        });
```

**File:** consensus/src/epoch_manager.rs (L1963-1969)
```rust
    fn equivalent_jwk_consensus_config_from_deprecated_resources(
        payload: &OnChainConfigPayload<P>,
    ) -> OnChainJWKConsensusConfig {
        let features = payload.get::<Features>().ok();
        let oidc_providers = payload.get::<SupportedOIDCProviders>().ok();
        OnChainJWKConsensusConfig::from((features, oidc_providers))
    }
```

**File:** types/src/on_chain_config/jwk_consensus_config.rs (L112-132)
```rust
impl From<(Option<Features>, Option<SupportedOIDCProviders>)> for OnChainJWKConsensusConfig {
    fn from(
        (features, supported_oidc_providers): (Option<Features>, Option<SupportedOIDCProviders>),
    ) -> Self {
        if let Some(features) = features {
            if features.is_enabled(FeatureFlag::JWK_CONSENSUS) {
                let oidc_providers = supported_oidc_providers
                    .unwrap_or_default()
                    .providers
                    .into_iter()
                    .filter_map(|deprecated| OIDCProvider::try_from(deprecated).ok())
                    .collect();
                OnChainJWKConsensusConfig::V1(ConfigV1 { oidc_providers })
            } else {
                OnChainJWKConsensusConfig::Off
            }
        } else {
            OnChainJWKConsensusConfig::Off
        }
    }
}
```

**File:** consensus/src/round_manager.rs (L1126-1137)
```rust
        if let Some(vtxns) = proposal.validator_txns() {
            for vtxn in vtxns {
                let vtxn_type_name = vtxn.type_name();
                ensure!(
                    is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                    "unexpected validator txn: {:?}",
                    vtxn_type_name
                );
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
            }
        }
```

**File:** consensus/src/util/mod.rs (L15-24)
```rust
pub fn is_vtxn_expected(
    randomness_config: &OnChainRandomnessConfig,
    jwk_consensus_config: &OnChainJWKConsensusConfig,
    vtxn: &ValidatorTransaction,
) -> bool {
    match vtxn {
        ValidatorTransaction::DKGResult(_) => randomness_config.randomness_enabled(),
        ValidatorTransaction::ObservedJWKUpdate(_) => jwk_consensus_config.jwk_consensus_enabled(),
    }
}
```

**File:** state-sync/inter-component/event-notifications/src/lib.rs (L397-412)
```rust
impl OnChainConfigProvider for DbBackedOnChainConfig {
    fn get<T: OnChainConfig>(&self) -> Result<T> {
        let bytes = self
            .reader
            .get_state_value_by_version(&StateKey::on_chain_config::<T>()?, self.version)?
            .ok_or_else(|| {
                anyhow!(
                    "no config {} found in aptos root account state",
                    T::CONFIG_ID
                )
            })?
            .bytes()
            .clone();

        T::deserialize_into_config(&bytes)
    }
```
