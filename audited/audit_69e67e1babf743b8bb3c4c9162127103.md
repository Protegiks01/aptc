# Audit Report

## Title
Byzantine Validator Causes Total Network Liveness Failure via Infinite Batch Fetch Retry Loop

## Summary
A Byzantine validator can deliberately cause a total loss of network liveness by proposing blocks with unavailable transaction batches. The infinite retry loop in the block materialization phase, combined with parent execution dependencies, causes a cascading blockage that halts the entire blockchain after 12 rounds, requiring a hardfork to recover.

## Finding Description

The vulnerability exists in the consensus execution pipeline's batch fetching mechanism. When validators attempt to execute a block, they must first materialize its transaction batches. The `materialize` function contains an infinite retry loop that continuously attempts to fetch batches without any timeout or abort condition. [1](#0-0) 

When batch fetching fails (e.g., due to network timeouts), the `request_batch` function returns a `CouldNotGetData` error after exhausting retry attempts: [2](#0-1) 

The batch requester is configured with finite retry limits (default 10 retries, 5-second RPC timeout each): [3](#0-2) 

However, the `materialize` phase catches this error and retries indefinitely with 100ms delays, creating an infinite loop that never aborts.

**Attack Execution Flow:**

1. **Malicious Block Creation**: A Byzantine validator becomes the block proposer and creates a block containing batch references (ProofOfStore) but deliberately does not serve the actual batch data when requested.

2. **Batch Fetch Timeout**: Other validators attempt to execute the block by fetching the batches. They send batch requests to the peers who signed the ProofOfStore, but the Byzantine validator and colluding peers do not respond.

3. **Infinite Retry Loop**: After ~50 seconds (10 retries Ã— 5 seconds), the batch requester returns `CouldNotGetData`. The materialize function logs a warning and retries after 100ms, entering an infinite loop.

4. **Cascading Execution Block**: The critical issue is that each block's execution phase explicitly waits for its parent block's execution to complete: [4](#0-3) 

Similarly, ledger update and commit phases have parent dependencies: [5](#0-4) [6](#0-5) 

5. **Voting Without Execution**: Critically, validators can still vote on blocks without waiting for execution to complete. The `vote_block` function only calls `insert_block`, which builds the pipeline but doesn't await its completion: [7](#0-6) 

6. **Consensus Progresses, Execution Stalls**: Subsequent blocks (N+1, N+2, ...) can receive votes and QCs, advancing the `ordered_root`. However, none of them can execute because they're all waiting for Block N to complete execution.

7. **Backpressure Triggers Network Halt**: After 12 rounds (default `vote_back_pressure_limit`), the gap between `ordered_root` and `commit_root` exceeds the threshold: [8](#0-7) 

At this point, validators stop voting on new proposals, completely halting consensus progress.

**Invariant Violations:**

This attack violates the fundamental AptosBFT liveness guarantee: the protocol must maintain liveness with < 1/3 Byzantine validators. Here, a **single** Byzantine validator (far less than 1/3) can halt the entire network indefinitely.

## Impact Explanation

**Severity: CRITICAL**

This vulnerability qualifies as **Total Loss of Liveness/Network Availability**, which is a Critical severity issue worth up to $1,000,000 per the Aptos bug bounty program.

**Impact Details:**
- **Complete Network Halt**: After 12 rounds (~1-2 minutes), no new blocks can be proposed, voted on, or committed
- **No Automatic Recovery**: The infinite retry loop has no timeout or abort mechanism. Manual intervention is required
- **Hardfork Required**: Operators must coordinate to restart the network, likely requiring a hardfork to skip the malicious block
- **All Transactions Blocked**: Users cannot submit transactions, dApps cease functioning, and the entire ecosystem is frozen
- **Validator Availability Not Affected**: Unlike DoS attacks that crash nodes, this keeps validators running but deadlocked, making the issue less obvious to detect initially

The attack affects **100% of validators** simultaneously and requires **manual intervention and potential hardfork** to recover, meeting the highest severity criteria.

## Likelihood Explanation

**Likelihood: HIGH**

The attack is highly feasible because:

1. **Low Attacker Requirements**: Only requires a single Byzantine validator to be selected as proposer (happens regularly in round-robin leader election)

2. **Simple Execution**: The attacker simply needs to:
   - Create a batch and get it signed (ProofOfStore)
   - Include it in their block proposal
   - Stop responding to batch requests

3. **No Detection Mechanisms**: The system has no intrinsic way to detect that a proposer is deliberately withholding batch data versus experiencing network issues

4. **Immediate Impact**: The attack takes effect within 12 rounds (~1-2 minutes) of the malicious block being proposed

5. **No Cost**: Unlike some attacks requiring stake or resources, this only requires being selected as a proposer

6. **Repeatable**: Even after recovery, a Byzantine validator can repeat the attack in future rounds

## Recommendation

Implement a timeout mechanism for the materialize phase to prevent infinite retries. The fix should:

1. **Add Timeout to Materialize Loop**: Replace the infinite retry loop with a timeout-based approach:

```rust
async fn materialize(
    preparer: Arc<BlockPreparer>,
    block: Arc<Block>,
    qc_rx: oneshot::Receiver<Arc<QuorumCert>>,
) -> TaskResult<MaterializeResult> {
    let mut tracker = Tracker::start_waiting("materialize", &block);
    tracker.start_working();

    let qc_rx = async {
        match qc_rx.await {
            Ok(qc) => Some(qc),
            Err(_) => {
                warn!("[BlockPreparer] qc tx cancelled for block {}", block.id());
                None
            },
        }
    }
    .shared();
    
    // Add overall timeout for materialization (e.g., 5 minutes)
    let materialize_timeout = Duration::from_secs(300);
    let max_retries = 5;
    let mut retry_count = 0;
    
    let deadline = Instant::now() + materialize_timeout;
    
    loop {
        match tokio::time::timeout(
            deadline.saturating_duration_since(Instant::now()),
            preparer.materialize_block(&block, qc_rx.clone())
        ).await {
            Ok(Ok(input_txns)) => return Ok(input_txns),
            Ok(Err(e)) => {
                retry_count += 1;
                if retry_count >= max_retries {
                    error!(
                        "[BlockPreparer] failed to prepare block {} after {} retries, aborting: {}",
                        block.id(),
                        max_retries,
                        e
                    );
                    return Err(TaskError::from(anyhow!(
                        "Block materialization failed after {} retries: {}",
                        max_retries,
                        e
                    )));
                }
                warn!(
                    "[BlockPreparer] failed to prepare block {}, retry {}/{}: {}",
                    block.id(),
                    retry_count,
                    max_retries,
                    e
                );
                tokio::time::sleep(Duration::from_millis(100)).await;
            },
            Err(_) => {
                error!(
                    "[BlockPreparer] materialize timeout for block {}, aborting after {:?}",
                    block.id(),
                    materialize_timeout
                );
                return Err(TaskError::from(anyhow!(
                    "Block materialization timed out after {:?}",
                    materialize_timeout
                )));
            }
        }
    }
}
```

2. **Handle Materialization Failures Gracefully**: When materialization fails, allow consensus to continue without executing that block, voting NIL instead.

3. **Add Byzantine Detection**: Track validators who repeatedly propose blocks with unavailable batches and temporarily exclude them from proposer selection.

4. **Improve Batch Availability Verification**: Before voting on a block, verify that batch data is locally available or obtainable within a timeout.

## Proof of Concept

**Reproduction Steps:**

1. **Setup**: Deploy a test network with 4 validators (standard BFT setup)

2. **Malicious Validator Actions**:
```rust
// When selected as proposer:
// 1. Create a batch with valid transactions
let batch = create_batch(vec![transaction1, transaction2]);

// 2. Get ProofOfStore from other validators
let proof = get_proof_of_store(batch.clone());

// 3. Propose block with batch reference
let block = create_block_with_batch_ref(proof);
broadcast_proposal(block);

// 4. Ignore all batch requests for this batch
// (Stop responding to BatchRequest messages for this digest)
```

3. **Observe Network Behavior**:
```bash
# Monitor consensus logs on honest validators
# Expected: Repeated warnings about batch fetch failures
[BlockPreparer] failed to prepare block <HASH>, retrying: CouldNotGetData

# After ~1-2 minutes (12 rounds):
# Vote backpressure triggers, consensus halts
# No new blocks proposed or committed
```

4. **Verification**:
```bash
# Check ordered vs committed rounds gap
aptos-node query --endpoint http://localhost:8080 \
  | grep "ordered_round\|commit_round"
# Gap will be > 12, indicating backpressure

# Network is halted - no new transactions processed
aptos-node query --endpoint http://localhost:8080 \
  | grep "latest_ledger_version"
# Version stops incrementing
```

**Expected Result**: Network completely halts within 12 rounds of the malicious block. All validators remain running but deadlocked, unable to commit new blocks. Manual intervention required to recover.

**Note**: This PoC requires a test environment with multiple validator nodes and the ability to modify one validator's behavior to withhold batch data.

### Citations

**File:** consensus/src/pipeline/pipeline_builder.rs (L502-511)
```rust
        let ledger_update_fut = spawn_shared_fut(
            Self::ledger_update(
                rand_check_fut.clone(),
                execute_fut.clone(),
                parent.ledger_update_fut.clone(),
                self.executor.clone(),
                block.clone(),
            ),
            None,
        );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L535-555)
```rust
        let pre_commit_fut = spawn_shared_fut(
            Self::pre_commit(
                ledger_update_fut.clone(),
                parent.pre_commit_fut.clone(),
                order_proof_fut.clone(),
                commit_proof_fut.clone(),
                self.executor.clone(),
                block.clone(),
                self.pre_commit_status(),
            ),
            None,
        );
        let commit_ledger_fut = spawn_shared_fut(
            Self::commit_ledger(
                pre_commit_fut.clone(),
                commit_proof_fut,
                parent.commit_ledger_fut.clone(),
                self.executor.clone(),
                block.clone(),
            ),
            None,
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L787-798)
```rust
    async fn execute(
        prepare_fut: TaskFuture<PrepareResult>,
        parent_block_execute_fut: TaskFuture<ExecuteResult>,
        rand_check: TaskFuture<RandResult>,
        executor: Arc<dyn BlockExecutorTrait>,
        block: Arc<Block>,
        validator: Arc<[AccountAddress]>,
        onchain_execution_config: BlockExecutorConfigFromOnchain,
        persisted_auxiliary_info_version: u8,
    ) -> TaskResult<ExecuteResult> {
        let mut tracker = Tracker::start_waiting("execute", &block);
        parent_block_execute_fut.await?;
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** config/src/config/quorum_store_config.rs (L127-130)
```rust
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
```

**File:** consensus/src/round_manager.rs (L1500-1505)
```rust
    async fn vote_block(&mut self, proposed_block: Block) -> anyhow::Result<Vote> {
        let block_arc = self
            .block_store
            .insert_block(proposed_block)
            .await
            .context("[RoundManager] Failed to execute_and_insert the block")?;
```

**File:** consensus/src/block_storage/block_store.rs (L691-703)
```rust
    fn vote_back_pressure(&self) -> bool {
        #[cfg(any(test, feature = "fuzzing"))]
        {
            if self.back_pressure_for_test.load(Ordering::Relaxed) {
                return true;
            }
        }
        let commit_round = self.commit_root().round();
        let ordered_round = self.ordered_root().round();
        counters::OP_COUNTERS
            .gauge("back_pressure")
            .set((ordered_round - commit_round) as i64);
        ordered_round > self.vote_back_pressure_limit + commit_round
```
