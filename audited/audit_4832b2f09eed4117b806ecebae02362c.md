# Audit Report

## Title
Cross-Shard Message Withholding Causes Indefinite Block Execution Stalling in Sharded Block Executor

## Summary
The sharded block executor lacks timeout mechanisms when waiting for cross-shard messages. Byzantine validators controlling a minority of shards (<1/3) can withhold `RemoteTxnWriteMsg` messages, causing dependent shards to block indefinitely and completely stalling block execution, leading to network unavailability.

## Finding Description

The vulnerability exists in the cross-shard dependency resolution mechanism of the sharded block executor. When transactions are partitioned across multiple shards and have cross-shard dependencies, dependent shards wait for state values from other shards via the `RemoteStateValue` synchronization primitive.

**Critical Code Path:**

The blocking occurs in the `RemoteStateValue::get_value()` method, which uses an indefinite condition variable wait: [1](#0-0) 

This method blocks indefinitely on line 32-33 using `cvar.wait()` without any timeout. When a transaction in a dependent shard reads a cross-shard state key, it calls this method through the `CrossShardStateView`: [2](#0-1) 

**Attack Scenario:**

1. A block is partitioned across 4 shards (Byzantine validator controls Shard B = 25% < 33%)
2. Transaction in Shard A depends on state written by a transaction in Shard B
3. Shard B completes execution but the Byzantine validator withholds the `RemoteTxnWriteMsg` that should be sent via `CrossShardCommitSender`: [3](#0-2) 

4. Shard A's `CrossShardCommitReceiver` never receives the message: [4](#0-3) 

5. The receiver blocks indefinitely on line 32 using `receive_cross_shard_msg()`, which in turn calls the blocking channel receive: [5](#0-4) 

6. The coordinator waits indefinitely for shard results: [6](#0-5) 

7. The consensus layer spawns the execution as a blocking task without timeout: [7](#0-6) 

**Invariant Violation:**

This breaks the **Resource Limits** invariant (#9) - operations must respect computational limits and timeouts. It also breaks the implicit **Liveness** invariant - the system must make progress under Byzantine conditions with <1/3 faulty validators.

## Impact Explanation

This vulnerability meets **Medium to High Severity** criteria:

**Medium Severity** ($10,000): "State inconsistencies requiring intervention" - The network enters a hung state requiring manual intervention to recover.

**High Severity** ($50,000): "Validator node slowdowns" and "Significant protocol violations" - Block execution completely stalls, causing:
- **Complete loss of liveness**: Blocks cannot be executed, consensus cannot progress
- **Network unavailability**: All validator nodes waiting on the hung block become unresponsive
- **Cascading failures**: As blocks pile up, the entire network halts

Even with Byzantine validators controlling less than 1/3 of shards (e.g., 1 out of 4 shards = 25%), they can completely disable the network by selectively withholding messages. This is a **performance degradation attack** that exceeds "acceptable performance thresholds" as specified in the security question.

## Likelihood Explanation

**Likelihood: High**

- **Low Complexity**: The attack requires only withholding messages, no complex manipulation
- **Low Requirements**: Byzantine validator needs to control just 1 shard (can be <10% of total shards)
- **No Detection**: The withholding appears as network delay initially, making it hard to detect
- **Immediate Impact**: First block with cross-shard dependencies will hang
- **Deterministic**: The vulnerability will trigger every time if conditions are met

The attack is trivial to execute for any malicious validator operator controlling even a single shard in a multi-shard deployment.

## Recommendation

Implement timeout mechanisms at multiple levels:

**1. Add timeout to RemoteStateValue::get_value():**

```rust
pub fn get_value_with_timeout(&self, timeout: Duration) -> Result<Option<StateValue>, TimeoutError> {
    let (lock, cvar) = &*self.value_condition;
    let mut status = lock.lock().unwrap();
    let deadline = Instant::now() + timeout;
    
    while let RemoteValueStatus::Waiting = *status {
        let now = Instant::now();
        if now >= deadline {
            return Err(TimeoutError::CrossShardMessageTimeout);
        }
        let timeout_remaining = deadline - now;
        let result = cvar.wait_timeout(status, timeout_remaining).unwrap();
        status = result.0;
        if result.1.timed_out() {
            return Err(TimeoutError::CrossShardMessageTimeout);
        }
    }
    match &*status {
        RemoteValueStatus::Ready(value) => Ok(value.clone()),
        RemoteValueStatus::Waiting => unreachable!(),
    }
}
```

**2. Add timeout to cross-shard message receiving:** [8](#0-7) 

Update the trait to support timeouts:

```rust
pub trait CrossShardClient: Send + Sync {
    fn send_global_msg(&self, msg: CrossShardMsg);
    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg);
    fn receive_cross_shard_msg_with_timeout(&self, current_round: RoundId, timeout: Duration) 
        -> Result<CrossShardMsg, TimeoutError>;
}
```

**3. Add configurable timeout at the executor level** with proper error handling and retry/fallback mechanisms to non-sharded execution on timeout.

## Proof of Concept

```rust
// Test demonstrating the indefinite blocking behavior
// File: aptos-move/aptos-vm/src/sharded_block_executor/remote_state_value.rs (add to tests module)

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_message_withholding_causes_indefinite_block() {
        let state_key = StateKey::raw(b"test_key");
        let remote_value = Arc::new(RemoteStateValue::waiting());
        let remote_value_clone = remote_value.clone();
        
        // Spawn thread that tries to read the value
        let reader_thread = thread::spawn(move || {
            // This will block indefinitely because no value is ever set
            let start = std::time::Instant::now();
            let _value = remote_value_clone.get_value();
            start.elapsed()
        });
        
        // Wait for a reasonable time (e.g., 2 seconds)
        thread::sleep(Duration::from_secs(2));
        
        // Thread should still be blocked after 2 seconds
        // In a real scenario with timeout, it should have returned by now
        assert!(!reader_thread.is_finished(), 
            "Thread should be blocked waiting for message, but it completed - \
             this indicates a timeout mechanism exists (which it doesn't in current code)");
        
        // Clean up: set value to unblock the thread
        remote_value.set_value(Some(StateValue::from(b"value".to_vec())));
        
        let elapsed = reader_thread.join().unwrap();
        println!("Thread was blocked for {:?} waiting for cross-shard message", elapsed);
        
        // This demonstrates the vulnerability: without the cleanup above,
        // the thread would block forever, causing complete execution stall
    }
    
    #[test] 
    #[should_panic(expected = "timeout")]
    fn test_proposed_timeout_mechanism() {
        // This test shows what the behavior SHOULD be with timeout
        let remote_value = RemoteStateValue::waiting();
        
        // Attempt to get value with 100ms timeout
        // Should panic/error since no value is set
        let result = remote_value.get_value_with_timeout(Duration::from_millis(100));
        
        // With proper timeout, this should error, not block forever
        result.expect("timeout"); // This will panic with timeout error
    }
}
```

**To demonstrate in a realistic scenario:**

1. Set up a 4-shard executor with cross-shard dependencies
2. Modify `LocalCrossShardClient` to simulate message withholding for shard 1
3. Execute a block with transactions where Shard 0 depends on Shard 1
4. Observe that Shard 0 blocks indefinitely in `RemoteStateValue::get_value()`
5. Block execution never completes, demonstrating the vulnerability

**Notes**

This vulnerability is particularly severe because:

1. **No existing mitigations**: Code inspection confirms zero timeout mechanisms exist in the sharded block executor
2. **Byzantine threshold irrelevant**: Even 1 malicious shard out of many (<<1/3) can halt the network
3. **Silent failure mode**: The hang appears as slow performance initially, delaying detection
4. **Consensus-level impact**: The consensus layer has no protection against this executor-level hang

The issue directly answers the security question affirmatively: Yes, Byzantine validators controlling <1/3 of shards can cause severe disruption by withholding cross-shard messages, slowing block execution to zero (complete halt), which is definitively below acceptable performance thresholds.

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/remote_state_value.rs (L29-38)
```rust
    pub fn get_value(&self) -> Option<StateValue> {
        let (lock, cvar) = &*self.value_condition;
        let mut status = lock.lock().unwrap();
        while let RemoteValueStatus::Waiting = *status {
            status = cvar.wait(status).unwrap();
        }
        match &*status {
            RemoteValueStatus::Ready(value) => value.clone(),
            RemoteValueStatus::Waiting => unreachable!(),
        }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L77-82)
```rust
    fn get_state_value(&self, state_key: &StateKey) -> Result<Option<StateValue>, StateViewError> {
        if let Some(value) = self.cross_shard_data.get(state_key) {
            return Ok(value.get_value());
        }
        self.base_view.get_state_value(state_key)
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L26-45)
```rust
    pub fn start<S: StateView + Sync + Send>(
        cross_shard_state_view: Arc<CrossShardStateView<S>>,
        cross_shard_client: Arc<dyn CrossShardClient>,
        round: RoundId,
    ) {
        loop {
            let msg = cross_shard_client.receive_cross_shard_msg(round);
            match msg {
                RemoteTxnWriteMsg(txn_commit_msg) => {
                    let (state_key, write_op) = txn_commit_msg.take();
                    cross_shard_state_view
                        .set_value(&state_key, write_op.and_then(|w| w.as_state_value()));
                },
                CrossShardMsg::StopMsg => {
                    trace!("Cross shard commit receiver stopped for round {}", round);
                    break;
                },
            }
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L103-134)
```rust
    fn send_remote_update_for_success(
        &self,
        txn_idx: TxnIndex,
        txn_output: &OnceCell<TransactionOutput>,
    ) {
        let edges = self.dependent_edges.get(&txn_idx).unwrap();
        let write_set = txn_output
            .get()
            .expect("Committed output must be set")
            .write_set();

        for (state_key, write_op) in write_set.expect_write_op_iter() {
            if let Some(dependent_shard_ids) = edges.get(state_key) {
                for (dependent_shard_id, round_id) in dependent_shard_ids.iter() {
                    trace!("Sending remote update for success for shard id {:?} and txn_idx: {:?}, state_key: {:?}, dependent shard id: {:?}", self.shard_id, txn_idx, state_key, dependent_shard_id);
                    let message = RemoteTxnWriteMsg(RemoteTxnWrite::new(
                        state_key.clone(),
                        Some(write_op.clone()),
                    ));
                    if *round_id == GLOBAL_ROUND_ID {
                        self.cross_shard_client.send_global_msg(message);
                    } else {
                        self.cross_shard_client.send_cross_shard_msg(
                            *dependent_shard_id,
                            *round_id,
                            message,
                        );
                    }
                }
            }
        }
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_client.rs (L156-162)
```rust
pub trait CrossShardClient: Send + Sync {
    fn send_global_msg(&self, msg: CrossShardMsg);

    fn send_cross_shard_msg(&self, shard_id: ShardId, round: RoundId, msg: CrossShardMsg);

    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg;
}
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L164-174)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        let _timer = WAIT_FOR_SHARDED_OUTPUT_SECONDS.start_timer();
        trace!("LocalExecutorClient Waiting for results");
        let mut results = vec![];
        for (i, rx) in self.result_rxs.iter().enumerate() {
            results.push(
                rx.recv()
                    .unwrap_or_else(|_| panic!("Did not receive output from shard {}", i))?,
            );
        }
        Ok(results)
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L335-337)
```rust
    fn receive_cross_shard_msg(&self, current_round: RoundId) -> CrossShardMsg {
        self.message_rxs[current_round].recv().unwrap()
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L857-867)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```
