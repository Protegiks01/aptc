# Audit Report

## Title
Epoch Bounds Clamping in EpochEndingStreamEngine Enables Stream Manipulation and Resource Exhaustion

## Summary
The `bound_by_range()` function in `EpochEndingStreamEngine::transform_client_response_into_notification()` clamps received epoch numbers to the requested range before updating stream state, but sends the unclamped epoch data to the bootstrapper for verification. This mismatch allows malicious peers to cause premature stream completion marking and repeated verification failures, leading to resource exhaustion and synchronization slowdowns. [1](#0-0) 

## Finding Description

The vulnerability exists in how the stream engine handles epoch ending ledger info responses from potentially malicious peers. When processing a response, the code extracts the last received epoch from the response payload and applies bounds clamping before updating internal stream state. [2](#0-1) 

The critical issue is that the clamped epoch value is used to update `next_stream_epoch` and determine stream completion: [3](#0-2) 

However, the data notification created and sent to the bootstrapper contains the **original, unclamped** epoch data: [4](#0-3) 

**Attack Scenario:**

1. Node requests epoch ending ledger infos for epochs [10, 20] from a malicious peer
2. Attacker responds with a valid (cryptographically signed) epoch ending ledger info for epoch 100
3. Stream engine extracts epoch 100, clamps it to 20 (the maximum of requested range), sets `next_stream_epoch = 21`, and marks `stream_is_complete = true`
4. Notification containing epoch 100 data is sent to bootstrapper
5. Bootstrapper attempts verification from current epoch state (e.g., epoch 9)
6. Verification fails because epoch 100 cannot be verified from epoch 9 (epochs must be verified sequentially) [5](#0-4) 

7. Stream is reset with error feedback [6](#0-5) 

8. The cycle repeats when the node retries synchronization

**Secondary Attack Vector - Incomplete Responses:**

An attacker can also send epochs within the requested range but skip epochs:
- Request epochs [10, 20] (11 epochs expected)
- Attacker sends only epoch 20 (1 epoch)
- Stream engine marks complete (20 >= 20)
- Missing data detection creates a follow-up request for epochs [11, 20] [7](#0-6) 

- However, because the stream is already marked complete, the next `process_data_responses()` call sends end-of-stream notification and returns early without processing the missing data request [8](#0-7) 

## Impact Explanation

This vulnerability constitutes **Medium severity** per Aptos bug bounty criteria:

**Validator Node Slowdowns:** Malicious peers can force nodes into repeated cycles of:
- Creating data streams
- Receiving invalid/out-of-range epoch responses  
- Attempting verification
- Failing verification
- Resetting streams
- Retrying from scratch

**Resource Exhaustion:** Each cycle consumes:
- Network bandwidth (requesting and receiving responses)
- CPU cycles (cryptographic verification attempts)
- Memory (stream state allocation/deallocation)
- I/O (stream management overhead)

**Synchronization Disruption:** Nodes attempting to bootstrap or catch up are particularly vulnerable, as they must fetch all historical epoch ending ledger infos. A coordinated attack by multiple malicious peers could significantly delay network synchronization for new validators or recovering nodes.

**No Consensus Impact:** Importantly, the cryptographic verification layer prevents actual state corruption. The vulnerability is limited to availability and efficiency, not safety. [9](#0-8) 

## Likelihood Explanation

**High Likelihood** - This vulnerability is easily exploitable:

**Low Attack Complexity:** Any network peer can send malicious responses without special privileges, validator status, or stake requirements.

**No Detection:** The attack appears as normal network behavior (peers sending data responses). There's no mechanism to detect or ban peers specifically for sending out-of-range epochs.

**Persistent Impact:** The attack can be repeated indefinitely across stream resets, as the stream recreation doesn't blacklist malicious peers.

**Real-World Motivation:** Attackers could:
- Delay validator onboarding
- Disrupt nodes recovering from downtime
- Target specific nodes to reduce network decentralization
- Create general network degradation

## Recommendation

**Solution:** Validate that received epochs are within the requested range BEFORE applying bounds clamping and updating stream state. Reject out-of-range responses immediately.

**Proposed Fix:**

```rust
fn transform_client_response_into_notification(
    &mut self,
    client_request: &DataClientRequest,
    client_response_payload: ResponsePayload,
    notification_id_generator: Arc<U64IdGenerator>,
) -> Result<Option<DataNotification>, Error> {
    // ... existing code ...
    
    match client_request {
        EpochEndingLedgerInfos(request) => {
            // ... existing validation ...
            
            let last_received_epoch = match &client_response_payload {
                ResponsePayload::EpochEndingLedgerInfos(ledger_infos) => {
                    // ... existing extraction ...
                    ledger_infos
                        .last()
                        .map(|ledger_info| ledger_info.ledger_info().epoch())
                        .unwrap_or(request.start_epoch)
                },
                _ => invalid_response_type!(client_response_payload),
            };
            
            // ADDED: Validate epoch is within requested range
            if last_received_epoch < request.start_epoch || last_received_epoch > request.end_epoch {
                return Err(Error::AptosDataClientResponseIsInvalid(format!(
                    "Received epoch {} is outside requested range [{}, {}]",
                    last_received_epoch, request.start_epoch, request.end_epoch
                )));
            }
            
            // REMOVED: No longer need bound_by_range since we validated above
            // let last_received_epoch = 
            //     bound_by_range(last_received_epoch, request.start_epoch, request.end_epoch);
            
            // Update stream state with validated epoch
            self.next_stream_epoch = last_received_epoch.checked_add(1).ok_or_else(|| {
                Error::IntegerOverflow("Next stream epoch has overflown!".into())
            })?;
            
            // ... rest of function ...
        }
    }
}
```

**Additional Hardening:** Consider implementing peer reputation tracking to temporarily ban or deprioritize peers that repeatedly send invalid responses.

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_out_of_range_epoch_attack() {
        // Setup: Create stream engine expecting epochs [10, 20]
        let request = GetAllEpochEndingLedgerInfosRequest {
            start_epoch: 10,
            end_epoch: 20,
        };
        let advertised_data = /* mock advertised data */;
        let mut stream_engine = EpochEndingStreamEngine::new(&request, &advertised_data).unwrap();
        
        // Attack: Create malicious response with epoch 100 (out of range)
        let malicious_epoch = 100;
        let malicious_ledger_info = /* create valid LedgerInfoWithSignatures for epoch 100 */;
        let malicious_response = ResponsePayload::EpochEndingLedgerInfos(vec![malicious_ledger_info]);
        
        let client_request = DataClientRequest::EpochEndingLedgerInfos(
            EpochEndingLedgerInfosRequest {
                start_epoch: 10,
                end_epoch: 20,
            }
        );
        
        // Execute: Process the malicious response
        let result = stream_engine.transform_client_response_into_notification(
            &client_request,
            malicious_response,
            Arc::new(U64IdGenerator::new()),
        );
        
        // Verify vulnerability: 
        // 1. Stream is marked complete (clamped 100 to 20)
        assert!(stream_engine.stream_is_complete);
        assert_eq!(stream_engine.next_stream_epoch, 21);
        
        // 2. But notification contains epoch 100 which will fail verification
        assert!(result.is_ok());
        let notification = result.unwrap().unwrap();
        if let DataPayload::EpochEndingLedgerInfos(ledger_infos) = notification.data_payload {
            assert_eq!(ledger_infos.last().unwrap().ledger_info().epoch(), 100);
        }
        
        // 3. This mismatch causes verification failure and stream reset
        // (would require full integration test to verify bootstrapper behavior)
    }
}
```

## Notes

This vulnerability demonstrates a **defense-in-depth failure** where the stream engine's state management trusts responses before validation. While the cryptographic verification layer ultimately prevents state corruption, the intermediate layer (stream engine) should enforce request-response consistency to prevent resource exhaustion attacks.

The fix is straightforward: validate epochs before state updates rather than clamping them. This maintains the invariant that stream state always reflects actually received and validated data, not sanitized/clamped values that don't match the payload.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1603-1633)
```rust
                // Identify the last received epoch and bound it appropriately
                let last_received_epoch = match &client_response_payload {
                    ResponsePayload::EpochEndingLedgerInfos(ledger_infos) => {
                        // Verify that we received at least one ledger info
                        if ledger_infos.is_empty() {
                            return Err(Error::AptosDataClientResponseIsInvalid(format!(
                                "Received an empty epoch ending ledger info response! Request: {:?}",
                                client_request
                            )));
                        }

                        // Return the last epoch
                        ledger_infos
                            .last()
                            .map(|ledger_info| ledger_info.ledger_info().epoch())
                            .unwrap_or(request.start_epoch)
                    },
                    _ => invalid_response_type!(client_response_payload),
                };
                let last_received_epoch =
                    bound_by_range(last_received_epoch, request.start_epoch, request.end_epoch);

                // Update the local stream notification tracker
                self.next_stream_epoch = last_received_epoch.checked_add(1).ok_or_else(|| {
                    Error::IntegerOverflow("Next stream epoch has overflown!".into())
                })?;

                // Check if the stream is complete
                if last_received_epoch >= self.end_epoch {
                    self.stream_is_complete = true;
                }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1636-1641)
```rust
                let data_notification = create_data_notification(
                    notification_id_generator,
                    client_response_payload,
                    None,
                    self.clone().into(),
                )?;
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L98-125)
```rust
    pub fn update_verified_epoch_states(
        &mut self,
        epoch_ending_ledger_info: &LedgerInfoWithSignatures,
        waypoint: &Waypoint,
    ) -> Result<(), Error> {
        // Verify the ledger info against the latest epoch state
        self.latest_epoch_state
            .verify(epoch_ending_ledger_info)
            .map_err(|error| {
                Error::VerificationError(format!("Ledger info failed verification: {:?}", error))
            })?;

        // Update the latest epoch state with the next epoch
        if let Some(next_epoch_state) = epoch_ending_ledger_info.ledger_info().next_epoch_state() {
            self.highest_fetched_epoch_ending_version =
                epoch_ending_ledger_info.ledger_info().version();
            self.latest_epoch_state = next_epoch_state.clone();
            self.insert_new_epoch_ending_ledger_info(epoch_ending_ledger_info.clone())?;

            trace!(LogSchema::new(LogEntry::Bootstrapper).message(&format!(
                "Updated the latest epoch state to epoch: {:?}",
                self.latest_epoch_state.epoch
            )));
        } else {
            return Err(Error::VerificationError(
                "The ledger info was not epoch ending!".into(),
            ));
        }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1095-1105)
```rust
            if let Err(error) = self.verified_epoch_states.update_verified_epoch_states(
                &epoch_ending_ledger_info,
                &self.driver_configuration.waypoint,
            ) {
                self.reset_active_stream(Some(NotificationAndFeedback::new(
                    notification_id,
                    NotificationFeedback::PayloadProofFailed,
                )))
                .await?;
                return Err(error);
            }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-454)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L1064-1101)
```rust
fn create_missing_epoch_ending_ledger_infos_request(
    request: &EpochEndingLedgerInfosRequest,
    response_payload: &ResponsePayload,
) -> Result<Option<DataClientRequest>, Error> {
    // Determine the number of requested ledger infos
    let num_requested_ledger_infos = request
        .end_epoch
        .checked_sub(request.start_epoch)
        .and_then(|v| v.checked_add(1))
        .ok_or_else(|| {
            Error::IntegerOverflow("Number of requested ledger infos has overflown!".into())
        })?;

    // Identify the missing data if the request was not satisfied
    match response_payload {
        ResponsePayload::EpochEndingLedgerInfos(ledger_infos) => {
            // Check if the request was satisfied
            let num_received_ledger_infos = ledger_infos.len() as u64;
            if num_received_ledger_infos < num_requested_ledger_infos {
                let start_epoch = request
                    .start_epoch
                    .checked_add(num_received_ledger_infos)
                    .ok_or_else(|| Error::IntegerOverflow("Start epoch has overflown!".into()))?;
                Ok(Some(DataClientRequest::EpochEndingLedgerInfos(
                    EpochEndingLedgerInfosRequest {
                        start_epoch,
                        end_epoch: request.end_epoch,
                    },
                )))
            } else {
                Ok(None) // The request was satisfied!
            }
        },
        payload => Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Invalid response payload found for epoch ending ledger info request: {:?}",
            payload
        ))),
    }
```
