# Audit Report

## Title
Insufficient Validation of NumberOfStates Response Enables Integer Overflow DoS on State Synchronization

## Summary
Malicious network peers can send crafted `NumberOfStates` responses (either `0` or values near `u64::MAX`) that bypass validation and cause integer overflow errors during state index calculations in `StateStreamEngine`, preventing validators from completing state synchronization and leading to repeated 60-second delays.

## Finding Description

The `StateStreamEngine` in the data streaming service processes `GetAllStates` requests by first querying network peers for the total number of states at a specific version. The validation logic only checks whether `number_of_states >= next_request_index`, which is insufficient to prevent integer overflow in subsequent calculations. [1](#0-0) 

Two attack vectors exist:

**Attack Vector 1: number_of_states = 0**

When a validator begins state sync from index 0, a malicious peer can respond with `number_of_states = 0`. This passes validation (since `0 >= 0`), but causes overflow when calculating `end_state_index`: [2](#0-1) 

The operation `0.checked_sub(1)` returns `None`, triggering an `IntegerOverflow` error.

**Attack Vector 2: number_of_states near u64::MAX**

When a malicious peer responds with `number_of_states = u64::MAX`, the validation passes, but during chunk creation, the calculation overflows: [3](#0-2) 

For example, with `request_start_index = u64::MAX - 3999` and `num_items_to_fetch = 4000`, the operation `(u64::MAX - 3999).checked_add(4000)` overflows, triggering the `IntegerOverflow` error.

**Attack Propagation:**

The error propagates from `create_data_client_requests` without incrementing the request failure counter: [4](#0-3) 

The streaming service logs the error but does not terminate the stream: [5](#0-4) 

Since `number_of_states` is stored and never reset, the validator cannot re-request this value. The stream eventually times out after the configured duration (default: 12 timeouts Ã— 5000ms = 60 seconds) before resetting: [6](#0-5) [7](#0-6) 

If the validator reconnects to the same malicious peer, the cycle repeats, causing persistent delays in state synchronization.

## Impact Explanation

**High Severity** - This qualifies as "Validator node slowdowns" under the Aptos bug bounty program criteria (up to $50,000).

The vulnerability enables malicious network peers to significantly degrade validator performance:

1. **Validator Liveness Impact**: Validators experience repeated 60-second delays during state synchronization
2. **Persistent Effect**: The malicious peer is not scored down because the error occurs after the response is accepted, allowing sustained attacks
3. **Network Participation**: Validators that fall behind cannot participate effectively in consensus
4. **Validator Ejection Risk**: Prolonged synchronization failures may lead to validator ejection

The attack requires only network-level access (ability to respond to data client requests as a peer) without requiring validator privileges or consensus participation.

## Likelihood Explanation

**High Likelihood** - The vulnerability is easily exploitable:

1. **Low Attack Complexity**: Attacker only needs to run a malicious node that responds to `GetNumberOfStatesAtVersion` requests with `0` or `u64::MAX`
2. **No Authentication Required**: The data streaming service accepts responses from any network peer
3. **Insufficient Validation**: Only checks `number_of_states >= next_request_index`, which allows both attack vectors
4. **Persistent Effect**: The stored `number_of_states` value is never reset, causing repeated errors
5. **No Peer Penalization**: The malicious peer is not downgraded in peer scoring because the error occurs after response acceptance

## Recommendation

Add comprehensive validation to the `NumberOfStates` response handling:

```rust
// In transform_client_response_into_notification, line 373:
if number_of_states == 0 {
    return Err(Error::AptosDataClientResponseIsInvalid(
        "Number of states cannot be zero".into()
    ));
}

// Check for values that would cause overflow during chunking
let max_safe_value = u64::MAX - optimal_chunk_size - 1;
if number_of_states > max_safe_value {
    return Err(Error::AptosDataClientResponseIsInvalid(
        format!("Number of states {} is too large and would cause overflow", number_of_states)
    ));
}

if number_of_states < self.next_request_index {
    return Err(Error::NoDataToFetch(format!(
        "The next state index to fetch is higher than the total number of states. Next index: {:?}, total states: {:?}",
        self.next_request_index, number_of_states
    )));
}
```

Additionally, consider reporting invalid `NumberOfStates` responses back to the data client as malicious behavior to enable peer scoring.

## Proof of Concept

This vulnerability can be demonstrated by:

1. Setting up a malicious storage service that responds to `GetNumberOfStatesAtVersion` requests with `number_of_states = 0` when `start_index = 0`
2. Having a validator attempt to sync state from version 0
3. Observing the `IntegerOverflow` error in `create_data_client_requests`
4. Confirming that the stream does not terminate but instead times out after 60 seconds
5. Observing that the cycle repeats if the validator reconnects to the same peer

The vulnerability is confirmed by the code paths shown in the citations above, demonstrating insufficient validation at the response handling stage and overflow-prone arithmetic in the request creation stage.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L250-252)
```rust
            let end_state_index = number_of_states
                .checked_sub(1)
                .ok_or_else(|| Error::IntegerOverflow("End state index has overflown!".into()))?;
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L373-378)
```rust
                    if number_of_states < self.next_request_index {
                        return Err(Error::NoDataToFetch(format!(
                            "The next state index to fetch is higher than the \
                            total number of states. Next index: {:?}, total states: {:?}",
                            self.next_request_index, number_of_states
                        )));
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2076-2079)
```rust
        let request_end_index = request_start_index
            .checked_add(num_items_to_fetch)
            .and_then(|e| e.checked_sub(1)) // = request_start_index + num_items_to_fetch - 1
            .ok_or_else(|| Error::IntegerOverflow("End index to fetch has overflown!".into()))?;
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L288-294)
```rust
            let client_requests = self.stream_engine.create_data_client_requests(
                max_num_requests_to_send,
                max_in_flight_requests,
                num_in_flight_requests,
                global_data_summary,
                self.notification_id_generator.clone(),
            )?;
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L313-331)
```rust
            if let Err(error) = self.update_progress_of_data_stream(data_stream_id).await {
                if matches!(error, Error::NoDataToFetch(_)) {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(NO_DATA_TO_FETCH_LOG_FREQ_SECS)),
                        info!(LogSchema::new(LogEntry::CheckStreamProgress)
                            .stream_id(*data_stream_id)
                            .event(LogEvent::Pending)
                            .error(&error))
                    );
                } else {
                    metrics::increment_counter(
                        &metrics::CHECK_STREAM_PROGRESS_ERROR,
                        error.get_label(),
                    );
                    warn!(LogSchema::new(LogEntry::CheckStreamProgress)
                        .stream_id(*data_stream_id)
                        .event(LogEvent::Error)
                        .error(&error));
                }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L592-596)
```rust
        if matches!(result, Err(Error::CriticalDataStreamTimeout(_))) {
            // If the stream has timed out too many times, we need to reset it
            warn!("Resetting the currently active data stream due to too many timeouts!");
            self.reset_active_stream(None).await?;
        }
```

**File:** config/src/config/state_sync_config.rs (L145-148)
```rust
            max_num_stream_timeouts: 12,
            max_pending_data_chunks: 50,
            max_pending_mempool_notifications: 100,
            max_stream_wait_time_ms: 5000,
```
