# Audit Report

## Title
Missing Cryptographic Validation of Quorum Certificates During Consensus Recovery

## Summary
The `get_data()` function in `consensus/src/consensusdb/mod.rs` retrieves blocks and quorum certificates from persistent storage during recovery without validating QC signatures or structural consistency. This allows corrupted or maliciously modified QCs with invalid BLS signatures to propagate into the consensus state machine, potentially causing validator misbehavior and liveness degradation.

## Finding Description

During consensus recovery, the system loads previously stored blocks and quorum certificates from the consensus database. The recovery flow proceeds as follows: [1](#0-0) 

The `get_data()` function simply retrieves all blocks and QCs from storage without any validation. This data is then processed by the recovery mechanism: [2](#0-1) 

The recovery process constructs `RecoveryData` which finds the root block and matches QCs to blocks: [3](#0-2) 

QCs are matched to blocks purely by ID comparison, with no cryptographic verification. When these QCs are inserted into the BlockStore: [4](#0-3) 

The `insert_single_quorum_cert()` function only validates structural consistency (matching block info), but does NOT verify BLS signatures: [5](#0-4) 

In contrast, when processing NEW proposals during normal consensus operation, the system DOES verify QC signatures: [6](#0-5) 

This creates an inconsistency: recovered QCs bypass signature validation that newly received QCs must pass.

**Attack Scenario:**
1. Attacker gains filesystem access to a validator's consensus database (via system compromise, malicious operator, or hardware access)
2. Attacker modifies stored QC data to:
   - Point to different blocks
   - Claim higher rounds than actually certified
   - Have manipulated vote data
3. Validator restarts and runs recovery
4. Corrupted QCs load without signature verification
5. Invalid QCs become part of consensus state (e.g., `highest_quorum_cert`)
6. Validator makes incorrect consensus decisions based on false QC state

**Invariant Violations:**
- **Cryptographic Correctness**: BLS signatures must be verified but are skipped during recovery
- **Consensus Safety**: Corrupted QCs with false rounds could cause validator to operate on incorrect chain state

## Impact Explanation

**Severity Assessment: HIGH** (per Aptos Bug Bounty criteria)

This vulnerability causes:
1. **Validator node misbehavior**: Corrupted validator operates on false consensus state
2. **Liveness degradation**: If affected validator is a leader/critical proposer, network liveness suffers
3. **Protocol violations**: Validator may make votes/proposals based on invalid QCs

While the attack requires filesystem access (limiting remote exploitability), the impact on validator behavior and potential network liveness degradation qualifies as HIGH severity under the bug bounty program's "Validator node slowdowns" and "Significant protocol violations" categories.

The vulnerability does NOT directly cause:
- Network-wide consensus splits (other honest nodes reject invalid proposals)
- Fund theft or minting
- Complete network halt

Therefore HIGH (not Critical) severity is appropriate.

## Likelihood Explanation

**Likelihood: MEDIUM-LOW**

**Prerequisites for exploitation:**
- Filesystem write access to consensus database (requires system compromise or malicious operator)
- Knowledge of database schema and serialization format
- Ability to craft valid-looking but cryptographically invalid QCs

**Likelihood factors:**
- **Against exploitation**: Requires privileged access (not remote)
- **For exploitation**: Validator compromise is a realistic threat model; hardware failures/corruption could also trigger this unintentionally

**Non-malicious triggers:**
- Database corruption from disk failures
- Software bugs writing invalid data
- Power failures during writes
- Filesystem corruption from system crashes

While deliberate exploitation requires insider access, unintentional corruption triggering this issue is more likely, making defensive validation important for system resilience.

## Recommendation

Add cryptographic validation during recovery by verifying QC signatures before accepting them into consensus state:

```rust
// In persistent_liveness_storage.rs, after line 534:
let epoch_state = self.aptos_db
    .get_epoch_ending_ledger_infos(latest_ledger_info.ledger_info().epoch())
    .and_then(|infos| infos.last().map(|li| li.ledger_info().next_epoch_state()))
    .flatten()
    .expect("Failed to get epoch state for QC validation");

// Validate all recovered QCs
for qc in &quorum_certs {
    if qc.certified_block().round() > 0 {  // Skip genesis QCs
        qc.verify(&epoch_state.verifier)
            .context("Invalid QC signature during recovery")?;
    }
}
```

Additionally, in `BlockStore::build()` after line 299, add validation:

```rust
for qc in quorum_certs {
    // Verify QC signatures before inserting
    if let Some(epoch_state) = get_epoch_state_for_qc(&qc) {
        qc.verify(&epoch_state.verifier)
            .context("Invalid recovered QC")?;
    }
    
    block_store
        .insert_single_quorum_cert(qc)
        .unwrap_or_else(|e| {
            panic!("[BlockStore] failed to insert quorum during build{:?}", e)
        });
}
```

This ensures parity between recovery and normal operation validation paths.

## Proof of Concept

```rust
#[cfg(test)]
mod recovery_validation_test {
    use super::*;
    use aptos_consensus_types::{block::Block, quorum_cert::QuorumCert};
    use aptos_crypto::HashValue;
    
    #[test]
    #[should_panic(expected = "Invalid QC signature")]
    fn test_corrupted_qc_rejected_during_recovery() {
        // Setup: Create a valid block and QC
        let block = Block::make_genesis_block();
        let mut qc = QuorumCert::certificate_for_genesis_from_ledger_info(
            &LedgerInfo::mock_genesis(None),
            block.id(),
        );
        
        // Corrupt the QC by modifying its vote_data to point to wrong block
        let corrupted_vote_data = VoteData::new(
            BlockInfo::random(1),  // Wrong block info
            BlockInfo::random(0),
        );
        qc = QuorumCert::new(corrupted_vote_data, qc.ledger_info().clone());
        
        // Setup consensus DB with corrupted QC
        let db = ConsensusDB::new(temp_dir);
        db.save_blocks_and_quorum_certificates(vec![block], vec![qc]).unwrap();
        
        // Attempt recovery - should fail with signature verification error
        let storage = StorageWriteProxy::new(&config, aptos_db);
        let recovery_data = storage.start(false, None);
        
        // If we reach here without panic, QC validation was skipped (vulnerability confirmed)
        assert!(matches!(recovery_data, LivenessStorageData::PartialRecoveryData(_)),
                "Corrupted QC should cause recovery to fail");
    }
}
```

## Notes

This vulnerability represents a gap between the validation performed on newly received consensus messages versus data loaded from persistent storage. While the attack requires privileged filesystem access, the lack of validation creates a defensive programming weakness that could be triggered by:

1. **Intentional attacks**: Compromised validator operators or system-level exploits
2. **Unintentional corruption**: Hardware failures, software bugs, or filesystem corruption

The recommendation ensures that all QCs entering consensus state—whether from network or storage—undergo the same cryptographic validation, maintaining the "Cryptographic Correctness" invariant throughout the system.

### Citations

**File:** consensus/src/consensusdb/mod.rs (L80-106)
```rust
    pub fn get_data(
        &self,
    ) -> Result<(
        Option<Vec<u8>>,
        Option<Vec<u8>>,
        Vec<Block>,
        Vec<QuorumCert>,
    )> {
        let last_vote = self.get_last_vote()?;
        let highest_2chain_timeout_certificate = self.get_highest_2chain_timeout_certificate()?;
        let consensus_blocks = self
            .get_all::<BlockSchema>()?
            .into_iter()
            .map(|(_, block)| block)
            .collect();
        let consensus_qcs = self
            .get_all::<QCSchema>()?
            .into_iter()
            .map(|(_, qc)| qc)
            .collect();
        Ok((
            last_vote,
            highest_2chain_timeout_certificate,
            consensus_blocks,
            consensus_qcs,
        ))
    }
```

**File:** consensus/src/persistent_liveness_storage.rs (L139-143)
```rust
        let commit_block_quorum_cert = quorum_certs
            .iter()
            .find(|qc| qc.certified_block().id() == commit_block.id())
            .ok_or_else(|| format_err!("No QC found for root: {}", commit_block.id()))?
            .clone();
```

**File:** consensus/src/persistent_liveness_storage.rs (L519-534)
```rust
    fn start(&self, order_vote_enabled: bool, window_size: Option<u64>) -> LivenessStorageData {
        info!("Start consensus recovery.");
        let raw_data = self
            .db
            .get_data()
            .expect("unable to recover consensus data");

        let last_vote = raw_data
            .0
            .map(|bytes| bcs::from_bytes(&bytes[..]).expect("unable to deserialize last vote"));

        let highest_2chain_timeout_cert = raw_data.1.map(|b| {
            bcs::from_bytes(&b).expect("unable to deserialize highest 2-chain timeout cert")
        });
        let blocks = raw_data.2;
        let quorum_certs: Vec<_> = raw_data.3;
```

**File:** consensus/src/block_storage/block_store.rs (L299-305)
```rust
        for qc in quorum_certs {
            block_store
                .insert_single_quorum_cert(qc)
                .unwrap_or_else(|e| {
                    panic!("[BlockStore] failed to insert quorum during build{:?}", e)
                });
        }
```

**File:** consensus/src/block_storage/block_store.rs (L518-550)
```rust
    /// Validates quorum certificates and inserts it into block tree assuming dependencies exist.
    pub fn insert_single_quorum_cert(&self, qc: QuorumCert) -> anyhow::Result<()> {
        // If the parent block is not the root block (i.e not None), ensure the executed state
        // of a block is consistent with its QuorumCert, otherwise persist the QuorumCert's
        // state and on restart, a new execution will agree with it.  A new execution will match
        // the QuorumCert's state on the next restart will work if there is a memory
        // corruption, for example.
        match self.get_block(qc.certified_block().id()) {
            Some(pipelined_block) => {
                ensure!(
                    // decoupled execution allows dummy block infos
                    pipelined_block
                        .block_info()
                        .match_ordered_only(qc.certified_block()),
                    "QC for block {} has different {:?} than local {:?}",
                    qc.certified_block().id(),
                    qc.certified_block(),
                    pipelined_block.block_info()
                );
                observe_block(
                    pipelined_block.block().timestamp_usecs(),
                    BlockStage::QC_ADDED,
                );
                if pipelined_block.block().is_opt_block() {
                    observe_block(
                        pipelined_block.block().timestamp_usecs(),
                        BlockStage::QC_ADDED_OPT_BLOCK,
                    );
                }
                pipelined_block.set_qc(Arc::new(qc.clone()));
            },
            None => bail!("Insert {} without having the block in store first", qc),
        };
```

**File:** consensus/safety-rules/src/safety_rules.rs (L235-243)
```rust
    pub(crate) fn verify_qc(&self, qc: &QuorumCert) -> Result<(), Error> {
        let epoch_state = self.epoch_state()?;

        if !self.skip_sig_verify {
            qc.verify(&epoch_state.verifier)
                .map_err(|e| Error::InvalidQuorumCertificate(e.to_string()))?;
        }
        Ok(())
    }
```
