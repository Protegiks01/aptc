# Audit Report

## Title
Cache Worker State Corruption Due to Missing BATCH_END Messages in Fullnode Streaming Protocol

## Summary
The indexer-grpc-cache-worker can enter an inconsistent state when receiving transaction Data messages without a corresponding BATCH_END status message. This violates the streaming protocol specification and causes accumulated transactions to remain uncommitted, with the cache version marker never being updated, leading to data duplication and cache corruption upon reconnection.

## Finding Description

The fullnode streaming protocol specifies a strict state machine where transaction data must be followed by BATCH_END status messages: [1](#0-0) 

However, the server implementation in `fullnode_data_service.rs` can terminate the stream after sending Data messages but before sending BATCH_END: [2](#0-1) 

The Data messages are sent via `process_next_batch()`: [3](#0-2) 

After this returns successfully, if `abort_handle` is set, the loop breaks before sending BATCH_END: [4](#0-3) 

The cache worker processes these messages by accumulating async tasks in a `tasks_to_run` vector: [5](#0-4) 

These tasks are ONLY awaited when BATCH_END is received: [6](#0-5) 

The critical cache version update ONLY happens after processing BATCH_END: [7](#0-6) 

If the stream ends without BATCH_END, the loop breaks: [8](#0-7) 

**Attack Path:**
1. Cache worker connects to fullnode and begins streaming transactions
2. Fullnode sends INIT status, then multiple Data messages containing transactions
3. Server is aborted via `abort_handle` or the BATCH_END send fails due to channel closure
4. Cache worker receives Data messages and spawns tasks to write them to cache
5. Stream ends without BATCH_END message
6. Tasks in `tasks_to_run` are never awaited
7. Cache version marker is never updated via `update_cache_latest_version()`
8. Upon reconnection, cache worker requests from outdated version, causing duplicate processing

This breaks the **State Consistency** invariant - state transitions must be atomic and cache metadata must accurately reflect cached data.

## Impact Explanation

This qualifies as **Medium Severity** per Aptos bug bounty criteria: "State inconsistencies requiring intervention."

The vulnerability causes:
- **Cache corruption**: Transactions may be partially written to cache without version marker updates
- **Data duplication**: On reconnection, the same transactions are re-requested and re-processed
- **Inconsistent indexer state**: Cache metadata doesn't reflect actual cached data
- **Manual intervention required**: Operators must manually clear and resync the cache

This doesn't directly cause consensus violations or fund loss, but disrupts the indexer infrastructure that downstream applications rely on, requiring manual remediation.

## Likelihood Explanation

**High likelihood** of occurrence:

1. **Network interruptions**: Any network failure between fullnode and cache worker during batch transmission triggers this bug
2. **Server restarts**: Fullnode graceful shutdowns or crashes can leave batches incomplete
3. **Abort handle triggers**: The server-side abort mechanism explicitly creates this scenario
4. **No validation**: The cache worker performs no validation that all received Data messages have corresponding BATCH_END

This will occur repeatedly in production environments with network instability or during maintenance windows.

## Recommendation

Implement defensive handling in the cache worker to detect incomplete batches:

**Option 1: Timeout-based detection**
Add a timeout mechanism that detects when Data messages are received without subsequent BATCH_END within a reasonable timeframe. Upon timeout, clear `tasks_to_run` and reset state.

**Option 2: Explicit batch tracking**
Track the start_version from Data messages and validate against BATCH_END. If stream ends without BATCH_END, discard all uncommitted work:

```rust
// In process_streaming_response function
let mut pending_batch_start: Option<u64> = None;
let mut tasks_to_run = vec![];

loop {
    // ... existing stream processing ...
    
    match status {
        GrpcDataStatus::ChunkDataOk { num_of_transactions, task } => {
            if pending_batch_start.is_none() {
                pending_batch_start = Some(current_version);
            }
            tasks_to_run.push(task);
        },
        GrpcDataStatus::BatchEnd { .. } => {
            // Existing batch end logic
            pending_batch_start = None;
        },
        _ => {}
    }
}

// On loop exit, if pending_batch_start is Some, log error and clear uncommitted work
if pending_batch_start.is_some() {
    error!("Stream ended with incomplete batch starting at version {:?}", pending_batch_start);
    // Don't update cache version - discard uncommitted work
    tasks_to_run.clear();
}
```

**Option 3: Server-side guarantees**
Ensure the fullnode always sends BATCH_END even during abnormal termination by using deferred cleanup or catch-unwind blocks.

## Proof of Concept

This vulnerability can be reproduced by:

1. **Setup**: Deploy cache worker connected to a fullnode
2. **Trigger**: Start streaming, then kill the fullnode process after Data messages are sent but before BATCH_END
3. **Observe**: Cache worker receives Data, spawns tasks, but never awaits them
4. **Verify**: Check cache version marker - it won't be updated despite some transactions potentially being written
5. **Reconnect**: Cache worker reconnects and re-requests the same version range
6. **Result**: Duplicate transaction processing or cache corruption

**Rust test scenario:**
```rust
#[tokio::test]
async fn test_incomplete_batch_handling() {
    // Create mock stream that sends INIT, Data, but terminates without BATCH_END
    let mock_stream = stream! {
        yield Ok(create_init_response(0));
        yield Ok(create_data_response(vec![create_test_transaction(0)]));
        yield Ok(create_data_response(vec![create_test_transaction(1)]));
        // Stream ends here without BATCH_END
    };
    
    let result = process_streaming_response(
        redis_conn,
        StorageFormat::Base64UncompressedProto,
        file_store_metadata,
        mock_stream
    ).await;
    
    // Verify cache version was NOT updated
    // Verify cache is in inconsistent state
}
```

## Notes

This vulnerability affects the indexer-grpc infrastructure, not the core consensus layer. However, it violates protocol invariants and causes state inconsistencies that require manual intervention to resolve. The streaming protocol should enforce atomicity guarantees where partial batches are either fully processed or fully discarded.

### Citations

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.rs (L6-11)
```rust
// Transaction data is transferred via 1 stream with batches until terminated.
// One stream consists:
//   StreamStatus: INIT with version x
//   loop k:
//     TransactionOutput data(size n)
//     StreamStatus: BATCH_END with version x + (k + 1) * n - 1
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L135-142)
```rust
            while coordinator.current_version < coordinator.end_version {
                let start_time = std::time::Instant::now();
                // Processes and sends batch of transactions to client
                let results = coordinator.process_next_batch().await;
                if abort_handle.load(Ordering::SeqCst) {
                    info!("FullnodeDataService is aborted.");
                    break;
                }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L163-197)
```rust
                let batch_end_status = get_status(
                    StatusType::BatchEnd,
                    coordinator.current_version,
                    Some(max_version),
                    ledger_chain_id,
                );
                let channel_size = transaction_channel_size - tx.capacity();
                CHANNEL_SIZE
                    .with_label_values(&["2"])
                    .set(channel_size as i64);
                match tx.send(Result::<_, Status>::Ok(batch_end_status)).await {
                    Ok(_) => {
                        // tps logging
                        let new_base: u64 = ma.sum() / (DEFAULT_EMIT_SIZE as u64);
                        ma.tick_now(max_version - coordinator.current_version + 1);
                        if base != new_base {
                            base = new_base;

                            log_grpc_step_fullnode(
                                IndexerGrpcStep::FullnodeProcessedBatch,
                                Some(coordinator.current_version as i64),
                                Some(max_version as i64),
                                None,
                                Some(highest_known_version as i64),
                                Some(ma.avg() * 1000.0),
                                Some(start_time.elapsed().as_secs_f64()),
                                Some((max_version - coordinator.current_version + 1) as i64),
                            );
                        }
                    },
                    Err(_) => {
                        aptos_logger::warn!("[Indexer Fullnode] Unable to send end batch status");
                        break;
                    },
                }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L221-226)
```rust
        for response in responses {
            if self.transactions_sender.send(Ok(response)).await.is_err() {
                // Error from closed channel. This means the client has disconnected.
                return vec![];
            }
        }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L358-367)
```rust
        let received = match resp_stream.next().await {
            Some(r) => r,
            _ => {
                error!(
                    service_type = SERVICE_TYPE,
                    "[Indexer Cache] Streaming error: no response."
                );
                ERROR_COUNT.with_label_values(&["streaming_error"]).inc();
                break;
            },
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L395-403)
```rust
                GrpcDataStatus::ChunkDataOk {
                    num_of_transactions,
                    task,
                } => {
                    current_version += num_of_transactions;
                    transaction_count += num_of_transactions;
                    tps_calculator.tick_now(num_of_transactions);

                    tasks_to_run.push(task);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L413-432)
```rust
                GrpcDataStatus::BatchEnd {
                    start_version,
                    num_of_transactions,
                } => {
                    // Handle the data multithreading.
                    let result = join_all(tasks_to_run).await;
                    if result
                        .iter()
                        .any(|r| r.is_err() || r.as_ref().unwrap().is_err())
                    {
                        error!(
                            start_version = start_version,
                            num_of_transactions = num_of_transactions,
                            "[Indexer Cache] Process transactions from fullnode failed."
                        );
                        ERROR_COUNT.with_label_values(&["response_error"]).inc();
                        panic!("Error happens when processing transactions from fullnode.");
                    }
                    // Cleanup.
                    tasks_to_run = vec![];
```

**File:** ecosystem/indexer-grpc/indexer-grpc-cache-worker/src/worker.rs (L444-448)
```rust
                    cache_operator
                        .update_cache_latest_version(transaction_count, current_version)
                        .await
                        .context("Failed to update the latest version in the cache")?;
                    transaction_count = 0;
```
