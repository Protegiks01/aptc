# Audit Report

## Title
Race Condition Between Pruner and Internal Indexer Causes Data Loss for Historical Queries

## Summary
The ledger pruner can delete events and transactions from the main database before the internal indexer has processed them, leading to permanent data loss in the indexer database. This occurs because the pruner's target version is calculated independently without checking the indexer's current processing progress, creating a race condition between two asynchronous subsystems.

## Finding Description

The Aptos storage system maintains two separate subsystems that operate concurrently:
1. **The Ledger Pruner**: Runs in a background worker thread to delete old data
2. **The Internal Indexer (DBIndexer)**: Runs in a separate async tokio runtime to index events and transactions for efficient querying

The vulnerability arises from insufficient coordination between these subsystems:

**Pruner Target Calculation Without Indexer Check:** [1](#0-0) 

The pruner target is set based solely on the prune window calculation: [2](#0-1) 

The calculation `min_readable_version = latest_version.saturating_sub(prune_window)` ignores whether the internal indexer has caught up.

**Pruner Execution:**

The pruner runs continuously in a background worker thread: [3](#0-2) 

**Event and Transaction Pruning Without Indexer Verification:**

The EventStorePruner deletes events and writes its own progress but never checks the indexer's `EventVersion`: [4](#0-3) 

The TransactionPruner deletes transactions and writes its own progress but never checks the indexer's `TransactionVersion`: [5](#0-4) 

**Internal Indexer Running Asynchronously:**

The internal indexer runs in a separate tokio runtime spawned independently: [6](#0-5) 

It processes transactions in a continuous async loop: [7](#0-6) 

**No Coordination Mechanism:**

Verification shows the pruners never call `get_event_version()` or `get_transaction_version()` to check if the indexer has caught up before deleting data from the main database. The pruners only write their own progress metadata but never read the indexer's progress metadata.

**Race Condition Scenario:**
1. New transactions committed to main database at version V
2. Pruner target set to `V - prune_window`
3. Pruner worker wakes up and begins pruning up to target
4. Internal indexer is still processing older versions due to processing lag
5. Pruner deletes events/transactions before indexer reads them
6. Indexer attempts to read data via iterators but data is already gone
7. Permanent gaps in indexer database

## Impact Explanation

This vulnerability causes **permanent data loss** in the internal indexer database, affecting the node's ability to serve historical queries through indexer APIs. According to Aptos bug bounty criteria, this maps to **MEDIUM severity**: "State inconsistencies requiring manual intervention."

**Specific Impacts:**
- **Indexer State Inconsistency**: The indexer's view of blockchain history becomes incomplete and inconsistent with what was committed
- **Data Loss**: Events and transactions are permanently lost from the indexer database, making them unrecoverable for historical queries
- **Service Degradation**: APIs relying on the internal indexer (account transaction history, event queries by key) will return incomplete results
- **Recovery Requirement**: Requires manual intervention (full node resync or indexer database rebuild from another source) to restore complete historical data

**Why NOT Higher Severity:**
- Does not affect main blockchain consensus or data integrity
- Does not affect validator operations
- Does not enable fund theft or minting
- Main LedgerDB remains intact; only the derived indexer database is affected

## Likelihood Explanation

This vulnerability has **MEDIUM likelihood** of occurring in production:

**Triggering Conditions:**
- Internal indexer must be enabled (common configuration)
- Ledger pruner must be enabled (enabled by default)
- Indexer processing must lag behind the pruner's calculated target version

**Likelihood Factors:**

With default configuration (`prune_window = 90,000,000` versions): [8](#0-7) 

The large default prune window makes this less likely under normal conditions. However, the vulnerability can manifest when:

1. **Heavy System Load**: During sustained high transaction throughput, the indexer's async processing naturally lags behind commits
2. **Resource Contention**: Indexer and pruner compete for I/O resources on the same database
3. **Custom Configurations**: Operators may configure smaller prune windows for storage management
4. **Asynchronous Architecture**: No synchronization mechanism exists to prevent the race condition

The architectural flaw is present regardless of configuration values.

## Recommendation

Implement coordination between the pruner and internal indexer by checking the indexer's progress before allowing pruning to proceed:

**Solution 1 - Check Indexer Progress in Pruner:**
Modify the pruner to read `EventVersion` and `TransactionVersion` from the internal indexer database before pruning:

```rust
// In event_store_pruner.rs and transaction_pruner.rs
fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
    // Check if indexer has caught up
    if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
        let indexer_version = indexer_db.get_event_version()?.unwrap_or(0);
        if indexer_version < target_version {
            // Don't prune beyond indexer progress
            let safe_target = min(target_version, indexer_version);
            // Proceed with safe_target instead of target_version
        }
    }
    // ... existing pruning logic
}
```

**Solution 2 - Synchronization Barrier:**
Add a coordination mechanism where the pruner waits for the indexer to acknowledge it has processed up to the target version before proceeding with deletion.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Enabling internal indexer with default configuration
2. Configuring a smaller prune window (e.g., 1,000 versions for testing)
3. Generating high transaction load
4. Introducing artificial delay in indexer processing
5. Observing pruner deleting data before indexer processes it
6. Querying indexer API shows gaps in historical data

The architectural issue is evident in the code structure where no synchronization mechanism exists between the pruner (background thread) and the internal indexer (separate async runtime), both operating on the same main database with no coordination of their respective progress tracking.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L628-632)
```rust
            self.ledger_pruner
                .maybe_set_pruner_target_db_version(version);
            self.state_store
                .state_kv_pruner
                .maybe_set_pruner_target_db_version(version);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L162-176)
```rust
    fn set_pruner_target_db_version(&self, latest_version: Version) {
        assert!(self.pruner_worker.is_some());
        let min_readable_version = latest_version.saturating_sub(self.prune_window);
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["ledger_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.pruner_worker
            .as_ref()
            .unwrap()
            .set_target_db_version(min_readable_version);
    }
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L53-69)
```rust
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L43-81)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let mut indexer_batch = None;

        let indices_batch = if let Some(indexer_db) = self.indexer_db() {
            if indexer_db.event_enabled() {
                indexer_batch = Some(SchemaBatch::new());
            }
            indexer_batch.as_mut()
        } else {
            Some(&mut batch)
        };
        let num_events_per_version = self.ledger_db.event_db().prune_event_indices(
            current_progress,
            target_version,
            indices_batch,
        )?;
        self.ledger_db.event_db().prune_events(
            num_events_per_version,
            current_progress,
            target_version,
            &mut batch,
        )?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        if let Some(mut indexer_batch) = indexer_batch {
            indexer_batch.put::<InternalIndexerMetadataSchema>(
                &IndexerMetadataKey::EventPrunerProgress,
                &IndexerMetadataValue::Version(target_version),
            )?;
            self.expect_indexer_db()
                .get_inner_db_ref()
                .write_schemas(indexer_batch)?;
        }
        self.ledger_db.event_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-74)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
        self.ledger_db.transaction_db().prune_transactions(
            current_progress,
            target_version,
            &mut batch,
        )?;
        self.transaction_store
            .prune_transaction_summaries_by_account(&candidate_transactions, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/runtime.rs (L23-47)
```rust
pub fn bootstrap_internal_indexer_db(
    config: &NodeConfig,
    db_rw: DbReaderWriter,
    internal_indexer_db: Option<InternalIndexerDB>,
    update_receiver: Option<WatchReceiver<(Instant, Version)>>,
) -> Option<(Runtime, Arc<DBIndexer>)> {
    if !config.indexer_db_config.is_internal_indexer_db_enabled() || internal_indexer_db.is_none() {
        return None;
    }
    let runtime = aptos_runtimes::spawn_named_runtime("index-db".to_string(), None);
    // Set up db config and open up the db initially to read metadata
    let mut indexer_service = InternalIndexerDBService::new(
        db_rw.reader,
        internal_indexer_db.unwrap(),
        update_receiver.expect("Internal indexer db update receiver is missing"),
    );
    let db_indexer = indexer_service.get_db_indexer();
    // Spawn task for db indexer
    let config_clone = config.to_owned();
    runtime.spawn(async move {
        indexer_service.run(&config_clone).await.unwrap();
    });

    Some((runtime, db_indexer))
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/internal_indexer_db_service.rs (L167-199)
```rust
    pub async fn run(&mut self, node_config: &NodeConfig) -> Result<()> {
        let mut start_version = self.get_start_version(node_config).await?;
        let mut target_version = self.db_indexer.main_db_reader.ensure_synced_version()?;
        let mut step_timer = std::time::Instant::now();

        loop {
            if target_version <= start_version {
                match self.update_receiver.changed().await {
                    Ok(_) => {
                        (step_timer, target_version) = *self.update_receiver.borrow();
                    },
                    Err(e) => {
                        panic!("Failed to get update from update_receiver: {}", e);
                    },
                }
            }
            let next_version = self.db_indexer.process(start_version, target_version)?;
            INDEXER_DB_LATENCY.set(step_timer.elapsed().as_millis() as i64);
            log_grpc_step(
                SERVICE_TYPE,
                IndexerGrpcStep::InternalIndexerDBProcessed,
                Some(start_version as i64),
                Some(next_version as i64),
                None,
                None,
                Some(step_timer.elapsed().as_secs_f64()),
                None,
                Some((next_version - start_version) as i64),
                None,
            );
            start_version = next_version;
        }
    }
```

**File:** config/src/config/storage_config.rs (L387-395)
```rust
impl Default for LedgerPrunerConfig {
    fn default() -> Self {
        LedgerPrunerConfig {
            enable: true,
            prune_window: 90_000_000,
            batch_size: 5_000,
            user_pruning_window_offset: 200_000,
        }
    }
```
