# Audit Report

## Title
Block Output Limit Per-Sub-Block Application Allows Excessive Memory Accumulation in Sharded Execution

## Summary
The `block_output_limit` (default 4MB) is incorrectly applied per sub-block in sharded execution rather than globally across the entire block. This allows total memory accumulation of up to `num_shards × num_rounds × 4MB` (up to 256MB worst case) in unbounded result channels, exceeding the intended global 4MB limit by up to 64x.

## Finding Description

**Correcting the Premise**: The security question's premise of "malicious shards" is incorrect. Shards in `LocalExecutorService` are local worker threads within the same validator process running trusted code, not separate malicious entities. [1](#0-0) 

**The Actual Vulnerability**: The issue lies in how the `block_output_limit` is enforced during sharded block execution. The limit is documented as "Block limit on the total (approximate) txn output size in bytes" [2](#0-1) , with a default value of 4MB. [3](#0-2) 

However, in sharded execution:

1. **Unbounded channels are created** for result communication between shards and coordinator: [4](#0-3) 

2. **Each shard processes multiple rounds** of sub-blocks, where `MAX_ALLOWED_PARTITIONING_ROUNDS = 8` [5](#0-4)  and the default is 4 rounds in production configurations.

3. **Each sub-block execution creates a new `BlockGasLimitProcessor`** with its own independent 4MB limit: [6](#0-5) 

4. **Each shard executes all its rounds**, creating a separate `BlockGasLimitProcessor` for each: [7](#0-6) 

5. **The limit is checked independently per sub-block**: [8](#0-7) 

6. **All results accumulate in unbounded channels** before being consumed: [9](#0-8) 

**Memory Calculation**:
- With 8 shards × 4 rounds (typical): 32 sub-blocks × 4MB = **128MB**
- With 8 shards × 8 rounds (maximum): 64 sub-blocks × 4MB = **256MB**

This violates **Invariant 9: "Resource Limits: All operations must respect gas, storage, and computational limits"** - the intended 4MB global limit is exceeded by 32-64x.

**Attack Path**: An attacker can submit transactions that produce large outputs (up to 10MB writes + 10MB events per transaction, within per-transaction limits [10](#0-9) ). By creating transaction dependency patterns that force multiple partitioning rounds, each sub-block will execute until hitting its independent 4MB limit, causing all outputs to accumulate in memory.

## Impact Explanation

This is a **MEDIUM severity** issue per Aptos bug bounty categories:
- Qualifies as "State inconsistencies requiring intervention" - the resource limit enforcement is inconsistent between non-sharded and sharded execution
- Could contribute to "Validator node slowdowns" when sustained, but unlikely to cause immediate crashes on modern hardware (64GB+ RAM)
- Not Critical severity because 128-256MB memory accumulation is insufficient to crash validators or affect consensus/liveness

The impact is a resource limit bypass where the system accumulates significantly more memory than intended during block execution.

## Likelihood Explanation

**High likelihood** of occurrence:
- Default sharded execution configuration uses 4 rounds and 8 shards
- Every block processed with sharding will exhibit this behavior
- Attacker can reliably trigger maximum accumulation by crafting transactions with large outputs and complex dependencies

## Recommendation

**Fix 1: Implement global block output limit tracking**

Create a shared `BlockGasLimitProcessor` across all shards that tracks cumulative output size:

```rust
// In local_executor_shard.rs setup_local_executor_shards()
let shared_limit_processor = Arc::new(Mutex::new(BlockGasLimitProcessor::new(
    onchain_config.block_gas_limit_type.clone(),
    None,
    estimated_block_size
)));

// Pass to each shard
// Shards should check and update shared limit atomically
```

**Fix 2: Use bounded channels**

Replace unbounded channels with bounded channels sized appropriately:

```rust
// Replace line 88-91 with:
let (result_txs, result_rxs): (
    Vec<Sender<Result<Vec<Vec<TransactionOutput>>, VMStatus>>>,
    Vec<Receiver<Result<Vec<Vec<TransactionOutput>>, VMStatus>>>,
) = (0..num_shards).map(|_| bounded(1)).unzip(); // Bounded to 1 result per shard
```

**Fix 3: Divide block_output_limit among shards**

Adjust the limit per shard to maintain global budget:

```rust
let per_shard_output_limit = block_output_limit / (num_shards * estimated_rounds);
// Pass adjusted limit to each shard's config
```

## Proof of Concept

```rust
// Rust test demonstrating excessive accumulation
#[test]
fn test_sharded_output_accumulation() {
    let num_shards = 8;
    let num_rounds = 4;
    
    // Create large-output transactions (within per-txn limits)
    let transactions = create_transactions_with_large_outputs(1000); // 1000 txns
    
    // Partition into shards with multiple rounds
    let partitioned = partition_with_dependencies(transactions, num_shards, num_rounds);
    
    // Execute with sharded executor
    let client = LocalExecutorService::setup_local_executor_shards(num_shards, None);
    let sharded_executor = ShardedBlockExecutor::new(client);
    
    // Measure memory before
    let mem_before = get_process_memory();
    
    let result = sharded_executor.execute_block(
        state_view,
        partitioned,
        4,
        onchain_config_with_4mb_limit(),
    );
    
    // Measure memory after
    let mem_after = get_process_memory();
    let accumulated = mem_after - mem_before;
    
    // Verify accumulation exceeds intended 4MB limit
    assert!(accumulated > 4 * 1024 * 1024); // More than 4MB
    assert!(accumulated < 256 * 1024 * 1024); // But less than theoretical max
    
    println!("Memory accumulated: {} MB", accumulated / (1024 * 1024));
    // Expected: 16-128 MB depending on actual outputs
}
```

**Notes:**
- The premise of "malicious shards" in the original question is architecturally incorrect
- The actual issue is a design flaw in global limit enforcement during sharded execution
- Impact is resource limit bypass, not node crash
- Modern validators can handle the memory overhead, but it's still a violation of documented limits

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L55-58)
```rust
        let join_handle = thread::Builder::new()
            .name(format!("executor-shard-{}", shard_id))
            .spawn(move || executor_service.start())
            .unwrap();
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L88-91)
```rust
        let (result_txs, result_rxs): (
            Vec<Sender<Result<Vec<Vec<TransactionOutput>>, VMStatus>>>,
            Vec<Receiver<Result<Vec<Vec<TransactionOutput>>, VMStatus>>>,
        ) = (0..num_shards).map(|_| unbounded()).unzip();
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/local_executor_shard.rs (L164-175)
```rust
    fn get_output_from_shards(&self) -> Result<Vec<Vec<Vec<TransactionOutput>>>, VMStatus> {
        let _timer = WAIT_FOR_SHARDED_OUTPUT_SECONDS.start_timer();
        trace!("LocalExecutorClient Waiting for results");
        let mut results = vec![];
        for (i, rx) in self.result_rxs.iter().enumerate() {
            results.push(
                rx.recv()
                    .unwrap_or_else(|_| panic!("Did not receive output from shard {}", i))?,
            );
        }
        Ok(results)
    }
```

**File:** types/src/on_chain_config/execution_config.rs (L151-151)
```rust
            block_output_limit: Some(4 * 1024 * 1024),
```

**File:** types/src/on_chain_config/execution_config.rs (L302-303)
```rust
        /// Block limit on the total (approximate) txn output size in bytes.
        block_output_limit: Option<u64>,
```

**File:** types/src/block_executor/partitioner.rs (L20-20)
```rust
pub static MAX_ALLOWED_PARTITIONING_ROUNDS: usize = 8;
```

**File:** aptos-move/block-executor/src/executor.rs (L1726-1730)
```rust
        let block_limit_processor = ExplicitSyncWrapper::new(BlockGasLimitProcessor::new(
            self.config.onchain.block_gas_limit_type.clone(),
            self.config.onchain.block_gas_limit_override(),
            num_txns,
        ));
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/sharded_executor_service.rs (L192-205)
```rust
        for (round, sub_block) in transactions.into_sub_blocks().into_iter().enumerate() {
            let _timer = SHARDED_BLOCK_EXECUTION_BY_ROUNDS_SECONDS
                .timer_with(&[&self.shard_id.to_string(), &round.to_string()]);
            SHARDED_BLOCK_EXECUTOR_TXN_COUNT.observe_with(
                &[&self.shard_id.to_string(), &round.to_string()],
                sub_block.transactions.len() as f64,
            );
            info!(
                "executing sub block for shard {} and round {}, number of txns {}",
                self.shard_id,
                round,
                sub_block.transactions.len()
            );
            result.push(self.execute_sub_block(sub_block, round, state_view, config.clone())?);
```

**File:** aptos-move/block-executor/src/limit_processor.rs (L143-154)
```rust
        if let Some(per_block_output_limit) = self.block_gas_limit_type.block_output_limit() {
            let accumulated_output = self.get_accumulated_approx_output_size();
            if accumulated_output >= per_block_output_limit {
                counters::EXCEED_PER_BLOCK_OUTPUT_LIMIT_COUNT.inc_with(&[mode]);
                info!(
                    "[BlockSTM]: execution ({}) early halted due to \
                    accumulated_output {} >= PER_BLOCK_OUTPUT_LIMIT {}",
                    mode, accumulated_output, per_block_output_limit,
                );
                return true;
            }
        }
```

**File:** aptos-move/aptos-vm-types/src/storage/change_set_configs.rs (L69-72)
```rust
        const MB: u64 = 1 << 20;

        Self::new_impl(3, MB, u64::MAX, MB, 10 * MB, u64::MAX)
    }
```
