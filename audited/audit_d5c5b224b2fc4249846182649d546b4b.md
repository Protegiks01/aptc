# Audit Report

## Title
Silent Database Corruption Through Duplicate Transaction Version Writes

## Summary
The `put_transaction()` function in the transaction database lacks validation to prevent writing the same transaction version twice with different transaction data. If called with duplicate versions, it silently corrupts the database by creating inconsistent index mappings where multiple transaction hashes point to the same version, while that version only stores one transaction.

## Finding Description

The `put_transaction()` function writes transaction data to multiple database indices without validating whether the version already exists: [1](#0-0) 

When this function is called twice with the same version but different transactions, the underlying WriteBatch behavior causes the last write to win for the version-to-transaction mapping, but **both transaction hashes remain in the hash-to-version index**: [2](#0-1) 

The batch accumulates all write operations in order, and when converted to RocksDB WriteBatch, duplicate keys are overwritten by later operations: [3](#0-2) 

**Corruption Scenario:**
1. First call: `put_transaction(version=100, txn1)` writes:
   - `TransactionSchema`: 100 → txn1
   - `TransactionByHashSchema`: hash(txn1) → 100
   
2. Second call: `put_transaction(version=100, txn2)` writes:
   - `TransactionSchema`: 100 → txn2 (overwrites)
   - `TransactionByHashSchema`: hash(txn2) → 100 (adds new entry)

**Result:** Version 100 maps to txn2, but **both** hash(txn1) and hash(txn2) map to version 100. Looking up txn1 by its hash returns version 100, but fetching version 100 returns txn2 - a critical inconsistency.

The normal commit path has protection through pre-commit validation: [4](#0-3) 

However, the database restore path bypasses these locks and calls transaction writes directly: [5](#0-4) 

This creates a vulnerability window during restore operations where interrupted and restarted restore processes could potentially write overlapping version ranges with different transaction data.

## Impact Explanation

This qualifies as **Critical Severity** under the Aptos Bug Bounty program as it constitutes a **Consensus/Safety violation**:

1. **Deterministic Execution Break**: If different nodes restore from different backup sources or experience different restore interruption patterns, they could store different transactions for the same version, violating the fundamental invariant that all validators must produce identical state.

2. **Merkle Tree Corruption**: The transaction accumulator hash would be inconsistent across nodes, as it depends on transaction content at each version.

3. **Hash Lookup Failures**: Transaction lookups by hash would return incorrect results, potentially affecting state sync, transaction verification, and proof generation.

4. **Silent Failure**: The corruption occurs without error or detection, allowing divergent database states to persist unnoticed until consensus failures occur.

## Likelihood Explanation

**Likelihood: Low to Medium**

The vulnerability requires specific conditions:

1. **Restore Operation Required**: The database restore path must be active, which typically only happens during node recovery or initial sync from backup.

2. **Interrupted Restore**: A restore process must be interrupted after partial writes but before completion, then restarted with potentially different backup data or overlapping version ranges.

3. **Privileged Access**: Triggering this requires node operator privileges to initiate restore operations.

While the normal commit path is well-protected, the restore path's weaker validation creates a real risk during operational scenarios like:
- Disaster recovery from corrupted backups
- Node operators switching between backup sources
- Race conditions in concurrent restore processes
- Programming bugs in future code modifications

The severity is elevated by the silent nature of the corruption and its catastrophic impact on consensus safety.

## Recommendation

Add explicit version existence validation in `put_transaction()` to fail fast when attempting to write duplicate versions:

```rust
pub(crate) fn put_transaction(
    &self,
    version: Version,
    transaction: &Transaction,
    skip_index: bool,
    batch: &mut impl WriteBatch,
) -> Result<()> {
    // Validate version doesn't already exist
    if self.db.get::<TransactionSchema>(&version)?.is_some() {
        return Err(AptosDbError::Other(format!(
            "Transaction version {} already exists in database", 
            version
        )));
    }
    
    // ... rest of existing implementation
}
```

Additionally, add atomic version range locking in the restore path to prevent concurrent writes to overlapping version ranges, and validate that each restore batch starts at the expected next version before writing.

## Proof of Concept

```rust
// Proof of concept demonstrating the vulnerability
#[test]
fn test_duplicate_version_corruption() {
    let tmpdir = aptos_temppath::TempPath::new();
    let db = AptosDB::new_for_test(&tmpdir);
    let transaction_db = db.ledger_db().transaction_db();
    
    // Create two different transactions
    let txn1 = Transaction::StateCheckpoint(HashValue::random());
    let txn2 = Transaction::BlockMetadata(BlockMetadata::new(
        HashValue::random(),
        0,
        0,
        AccountAddress::random(),
        vec![],
        vec![],
        0,
    ));
    
    let version = 100u64;
    let mut batch1 = SchemaBatch::new();
    let mut batch2 = SchemaBatch::new();
    
    // Write version 100 with txn1
    transaction_db.put_transaction(version, &txn1, false, &mut batch1).unwrap();
    db.ledger_db().write_schemas(LedgerDbSchemaBatches {
        transaction_db_batches: batch1,
        ..Default::default()
    }).unwrap();
    
    // Write version 100 again with txn2 (corruption!)
    transaction_db.put_transaction(version, &txn2, false, &mut batch2).unwrap();
    db.ledger_db().write_schemas(LedgerDbSchemaBatches {
        transaction_db_batches: batch2,
        ..Default::default()
    }).unwrap();
    
    // Verify corruption: version maps to txn2
    let stored_txn = transaction_db.get_transaction(version).unwrap();
    assert_eq!(stored_txn, txn2);
    
    // But hash(txn1) also maps to version 100!
    let hash1 = txn1.hash();
    let hash2 = txn2.hash();
    
    let version_for_hash1 = transaction_db
        .get_transaction_version_by_hash(&hash1, version)
        .unwrap();
    let version_for_hash2 = transaction_db
        .get_transaction_version_by_hash(&hash2, version)
        .unwrap();
    
    // Both hashes map to version 100, but version 100 only stores txn2
    assert_eq!(version_for_hash1, Some(version));
    assert_eq!(version_for_hash2, Some(version));
    
    // This proves database corruption: hash1 points to version 100,
    // but fetching version 100 returns txn2, not txn1!
}
```

**Notes:**
While this vulnerability exists in the codebase and represents a serious defensive programming failure, its exploitability by unprivileged attackers is limited. The primary risk occurs during database restore operations which require node operator privileges. The vulnerability is best characterized as a latent safety bug that violates defense-in-depth principles - the `put_transaction` function should validate version uniqueness rather than relying solely on caller guarantees. This becomes critical during edge cases like interrupted restore operations or future code modifications that might introduce new call paths.

### Citations

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L129-166)
```rust
    pub(crate) fn put_transaction(
        // TODO(grao): Consider remove &self.
        &self,
        version: Version,
        transaction: &Transaction,
        skip_index: bool,
        batch: &mut impl WriteBatch,
    ) -> Result<()> {
        if !skip_index {
            if let Some(txn) = transaction.try_as_signed_user_txn() {
                if let ReplayProtector::SequenceNumber(seq_num) = txn.replay_protector() {
                    batch.put::<OrderedTransactionByAccountSchema>(
                        &(txn.sender(), seq_num),
                        &version,
                    )?;
                }
            }
        }

        let transaction_hash = transaction.hash();

        if let Some(signed_txn) = transaction.try_as_signed_user_txn() {
            let txn_summary = IndexedTransactionSummary::V1 {
                sender: signed_txn.sender(),
                replay_protector: signed_txn.replay_protector(),
                version,
                transaction_hash,
            };
            batch.put::<TransactionSummariesByAccountSchema>(
                &(signed_txn.sender(), version),
                &txn_summary,
            )?;
        }
        batch.put::<TransactionByHashSchema>(&transaction_hash, &version)?;
        batch.put::<TransactionSchema>(&version, transaction)?;

        Ok(())
    }
```

**File:** storage/schemadb/src/batch.rs (L156-163)
```rust
    fn raw_put(&mut self, cf_name: ColumnFamilyName, key: Vec<u8>, value: Vec<u8>) -> DbResult<()> {
        self.rows
            .entry(cf_name)
            .or_default()
            .push(WriteOp::Value { key, value });

        Ok(())
    }
```

**File:** storage/schemadb/src/batch.rs (L175-198)
```rust
impl IntoRawBatch for SchemaBatch {
    fn into_raw_batch(self, db: &DB) -> DbResult<RawBatch> {
        let labels = ["schema_batch_to_raw_batch", &db.name];
        let _timer = TIMER.timer_with(&labels);

        let Self { rows, stats } = self;

        let mut db_batch = rocksdb::WriteBatch::default();
        for (cf_name, rows) in rows.iter() {
            let cf_handle = db.get_cf_handle(cf_name)?;
            for write_op in rows {
                match write_op {
                    WriteOp::Value { key, value } => db_batch.put_cf(cf_handle, key, value),
                    WriteOp::Deletion { key } => db_batch.delete_cf(cf_handle, key),
                }
            }
        }

        Ok(RawBatch {
            inner: db_batch,
            stats,
        })
    }
}
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L245-261)
```rust
    fn pre_commit_validation(&self, chunk: &ChunkToCommit) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions_validation"]);

        ensure!(!chunk.is_empty(), "chunk is empty, nothing to save.");

        let next_version = self.state_store.current_state_locked().next_version();
        // Ensure the incoming committing requests are always consecutive and the version in
        // buffered state is consistent with that in db.
        ensure!(
            chunk.first_version == next_version,
            "The first version passed in ({}), and the next version expected by db ({}) are inconsistent.",
            chunk.first_version,
            next_version,
        );

        Ok(())
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L206-213)
```rust
    for (idx, txn) in txns.iter().enumerate() {
        ledger_db.transaction_db().put_transaction(
            first_version + idx as Version,
            txn,
            /*skip_index=*/ false,
            &mut ledger_db_batch.transaction_db_batches,
        )?;
    }
```
