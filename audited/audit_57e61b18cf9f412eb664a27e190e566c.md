# Audit Report

## Title
Hot State Non-Determinism Due to Restart-Induced LRU Inconsistency Leading to Consensus Divergence

## Summary
Validators can develop different hot state LRU structures when they restart or sync from snapshots, even when processing identical transactions. This occurs because the hot state is reset to empty on restart and is not persisted or synced across validators, leading to different eviction decisions and ultimately divergent hot state Merkle tree hashes, breaking the critical deterministic execution invariant.

## Finding Description

The security question asks whether different commit ordering can cause different LRU structures. While commit ordering itself is deterministic in Aptos (due to consensus and BTreeMap-based WriteSets), the investigation reveals a deeper vulnerability: **validators can have fundamentally different LRU structures for the same logical state due to restart/sync behavior**. [1](#0-0) 

When a validator restarts, the hot state is initialized to empty (SPARSE_MERKLE_PLACEHOLDER_HASH) regardless of its previous state. The TODO comment explicitly states: "for now hot state always starts from empty upon restart."

The hot state LRU maintains insertion order metadata in `HotStateMetadata` (head, tail, num_items) and per-slot LRU pointers (prev/next): [2](#0-1) [3](#0-2) 

Critically, while `HotStateValue` that gets hashed into the Merkle tree includes only `value` and `hot_since_version`: [4](#0-3) 

The LRU metadata in `StateSlot` contains the critical `lru_info` field: [5](#0-4) 

This metadata determines eviction order. When `maybe_evict()` is called: [6](#0-5) 

**Attack Scenario:**

1. **Validator A** runs continuously, building hot state with LRU order: `[k1(tail) → k2 → k3(head)]`
2. **Validator B** restarts at the same version, hot state resets to empty
3. Both process new transactions touching keys `[k4, k5, k6]`
4. Validator A's LRU becomes: `[k1 → k2 → k3 → k4 → k5 → k6(head)]`
5. Validator B's LRU becomes: `[k4(tail) → k5 → k6(head)]` (only recent keys)
6. When capacity is exceeded and eviction occurs:
   - Validator A evicts `k1` (oldest overall)
   - Validator B evicts `k4` (oldest in its limited history)
7. Different evictions → different hot state key sets → **different hot state Merkle tree hashes** → **consensus break**

The codebase acknowledges this issue with multiple TODOs: [7](#0-6) 

Hotness operations are marked as "not persisted for now" and state sync doesn't output hotness ops: [8](#0-7) 

## Impact Explanation

This is a **Critical Severity** issue meeting the "$1,000,000" tier criteria:

**Consensus Safety Violation:** Different validators produce different state roots (hot state Merkle tree hashes) for identical blocks, violating Invariant #1 (Deterministic Execution) and Invariant #2 (Consensus Safety). This breaks the fundamental assumption that all honest validators must agree on state.

**Non-Recoverable Network Partition:** Once validators diverge on hot state hashes, they cannot reach consensus on subsequent blocks. This requires manual intervention or a hardfork to resolve, as the divergence compounds with each eviction decision.

**Scope:** Affects ALL validators in the network, as any validator that restarts will have a different hot state structure than those that didn't restart, causing immediate consensus failure on the next transaction that triggers eviction.

## Likelihood Explanation

**High Likelihood:**

1. **Validator Restarts are Common:** Production validators restart for:
   - Software upgrades (routine)
   - Hardware maintenance
   - Crash recovery
   - Configuration changes

2. **State Sync Triggers Issue:** New validators joining via snapshot sync will have empty hot state, immediately diverging from existing validators.

3. **Hot State is Active:** The TODO comments indicate hot state is in active development and deployed, meaning evictions are occurring in production.

4. **Deterministic Trigger:** Once capacity is reached and eviction occurs, the divergence is deterministic and inevitable—no special conditions or timing required.

5. **No Mitigation in Code:** The explicit TODO comment shows this is a known limitation without implemented safeguards.

## Recommendation

**Immediate Fix:** Persist and sync hot state LRU metadata across validators.

**Implementation Steps:**

1. **Persist LRU Metadata to Database:**
   - Store `HotStateMetadata` (head, tail, num_items) in state snapshots
   - Include `lru_info` (prev/next pointers) in serialized `StateSlot`
   - Save hot state structure to `hot_state_merkle_db` at each checkpoint

2. **Restore from Persisted State:**
   ```rust
   // In create_buffered_state_from_latest_snapshot(), replace line 589:
   let hot_state_root_hash = if let Some(version) = latest_snapshot_version {
       state_db
           .hot_state_merkle_db
           .as_ref()
           .and_then(|db| db.get_root_hash(version).ok())
           .unwrap_or(*SPARSE_MERKLE_PLACEHOLDER_HASH)
   } else {
       *SPARSE_MERKLE_PLACEHOLDER_HASH
   };
   ```

3. **Include in State Sync Protocol:**
   - Extend state sync to transfer hot state LRU metadata
   - Ensure `HotStateShardUpdates` includes full LRU structure
   - Verify hot state hash matches after sync

4. **Validation:**
   - Add consensus check: compare hot state root hash at checkpoints
   - Reject blocks if hot state hash diverges
   - Log warnings when LRU metadata is missing

## Proof of Concept

```rust
// Test demonstrating hot state divergence after restart
#[test]
fn test_hot_state_divergence_on_restart() {
    use aptos_types::state_store::state_key::StateKey;
    use std::num::NonZeroUsize;
    
    // Validator A: continuous operation
    let mut validator_a_lru = HotStateLRU::new(
        NonZeroUsize::new(3).unwrap(),
        Arc::new(/* committed state */),
        &overlay,
        None, None, 0
    );
    
    // Insert keys in order: k1, k2, k3
    for i in 1..=3 {
        let key = StateKey::raw(format!("key{}", i).as_bytes());
        validator_a_lru.insert(key, hot_slot());
    }
    // LRU order: k3(head) -> k2 -> k1(tail)
    
    // Validator B: simulates restart (empty hot state)
    let mut validator_b_lru = HotStateLRU::new(
        NonZeroUsize::new(3).unwrap(),
        Arc::new(/* committed state */),
        &overlay,
        None, None, 0  // Empty state!
    );
    
    // Both process same new transactions: k4, k5
    for validator_lru in [&mut validator_a_lru, &mut validator_b_lru] {
        for i in 4..=5 {
            let key = StateKey::raw(format!("key{}", i).as_bytes());
            validator_lru.insert(key, hot_slot());
        }
    }
    
    // Trigger eviction on both
    let evicted_a = validator_a_lru.maybe_evict();
    let evicted_b = validator_b_lru.maybe_evict();
    
    // ASSERTION FAILURE: Different keys evicted!
    // Validator A evicts k1 (oldest overall)
    // Validator B evicts k4 (oldest in its limited history)
    assert_ne!(evicted_a, evicted_b); // This will fail, proving divergence
    
    // Extract final states
    let (updates_a, head_a, tail_a, _) = validator_a_lru.into_updates();
    let (updates_b, head_b, tail_b, _) = validator_b_lru.into_updates();
    
    // Different LRU structures despite same logical operations
    assert_ne!(head_a, head_b);
    assert_ne!(tail_a, tail_b);
    
    // This leads to different hot state Merkle tree hashes -> CONSENSUS BREAK
}
```

**Notes:**

This vulnerability exists because the hot state feature is in active development (as evidenced by multiple TODOs) but is deployed without full determinism guarantees. While the question asks about "commit ordering," the real issue is that validators can have different historical context (restart vs. continuous operation) leading to different LRU structures and consensus divergence.

### Citations

**File:** storage/aptosdb/src/state_store/mod.rs (L589-589)
```rust
            *SPARSE_MERKLE_PLACEHOLDER_HASH, // TODO(HotState): for now hot state always starts from empty upon restart.
```

**File:** storage/storage-interface/src/state_store/state.rs (L43-56)
```rust
pub struct HotStateMetadata {
    latest: Option<StateKey>,
    oldest: Option<StateKey>,
    num_items: usize,
}

impl HotStateMetadata {
    fn new() -> Self {
        Self {
            latest: None,
            oldest: None,
            num_items: 0,
        }
    }
```

**File:** types/src/state_store/hot_state.rs (L16-30)
```rust
pub struct LRUEntry<K> {
    /// The key that is slightly newer than the current entry. `None` for the newest entry.
    pub prev: Option<K>,
    /// The key that is slightly older than the current entry. `None` for the oldest entry.
    pub next: Option<K>,
}

impl<K> LRUEntry<K> {
    pub fn uninitialized() -> Self {
        Self {
            prev: None,
            next: None,
        }
    }
}
```

**File:** types/src/state_store/hot_state.rs (L44-50)
```rust
/// `HotStateValue` is what gets hashed into the hot state Merkle tree.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize, BCSCryptoHash, CryptoHasher)]
pub struct HotStateValue {
    /// `Some` means occupied and `None` means vacant.
    value: Option<StateValue>,
    hot_since_version: Version,
}
```

**File:** types/src/state_store/state_slot.rs (L34-39)
```rust
    HotOccupied {
        value_version: Version,
        value: StateValue,
        hot_since_version: Version,
        lru_info: LRUEntry<StateKey>,
    },
```

**File:** storage/storage-interface/src/state_store/hot_state.rs (L82-106)
```rust
    pub fn maybe_evict(&mut self) -> Vec<(StateKey, StateSlot)> {
        let mut current = match &self.tail {
            Some(tail) => tail.clone(),
            None => {
                assert_eq!(self.num_items, 0);
                return Vec::new();
            },
        };

        let mut evicted = Vec::new();
        while self.num_items > self.capacity.get() {
            let slot = self
                .delete(&current)
                .expect("There must be entries to evict when current size is above capacity.");
            let prev_key = slot
                .prev()
                .cloned()
                .expect("There must be at least one newer entry (num_items > capacity >= 1).");
            evicted.push((current.clone(), slot.clone()));
            self.pending.insert(current, slot.to_cold());
            current = prev_key;
            self.num_items -= 1;
        }
        evicted
    }
```

**File:** types/src/write_set.rs (L516-517)
```rust
// TODO(HotState): revisit when the hot state is deterministic.
/// Represents a hotness only change, not persisted for now.
```

**File:** storage/storage-interface/src/state_store/state_update_refs.rs (L284-285)
```rust
                    // TODO(HotState): also double check this logic for state sync later. For now
                    // we do not output hotness ops for state sync.
```
