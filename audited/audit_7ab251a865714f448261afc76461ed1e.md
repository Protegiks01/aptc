# Audit Report

## Title
LoggerService Thread Death from Formatter Panic Causes Silent Log Dropping

## Summary
The `LoggerService::run()` method uses `.expect()` on formatter function calls that can return errors, causing thread panic and permanent silent log dropping when serialization fails. This affects all validator nodes using async logging mode.

## Finding Description

The vulnerability exists in the async logging infrastructure where the `LoggerService` runs in a dedicated thread to handle log processing. When a log entry fails to format (either through custom format logic bugs or built-in formatter failures), the thread panics and terminates permanently, causing all subsequent logs to be silently dropped. [1](#0-0) 

The formatter is called with `.expect("Unable to format")`, which panics when the formatter returns `Err(fmt::Error)`. This occurs in multiple locations: [2](#0-1) 

The `json_format` function explicitly returns `Err(fmt::Error)` when serialization fails: [3](#0-2) 

Additionally, `text_format` contains a `.unwrap()` that can panic: [4](#0-3) 

The LoggerService runs in a separate thread spawned during logger initialization: [5](#0-4) 

When this thread panics and dies, the receiver is dropped. Subsequent log attempts via `try_send()` fail silently, only incrementing a counter: [6](#0-5) 

**Attack Vector**: An attacker can trigger log entries that fail serialization through:
1. Crafting transactions that cause log entries with complex data structures that fail JSON serialization
2. Exploiting edge cases in Move VM execution that generate malformed log metadata
3. Network messages that trigger logging of unserializable data structures

Once triggered, the validator node permanently loses logging capability without any visible indication to operators.

## Impact Explanation

This qualifies as **HIGH severity** per the Aptos bug bounty program under "Validator node slowdowns" and "Significant protocol violations" because:

1. **Complete Loss of Observability**: Validators cannot debug consensus issues, monitor network attacks, or troubleshoot operational problems without logs.

2. **Silent Failure**: The `STRUCT_LOG_QUEUE_ERROR_COUNT` metric increases but provides no indication that the entire logging subsystem has permanently failed. Operators remain unaware until attempting manual log inspection.

3. **Forensic Evidence Loss**: Security incidents, consensus violations, or validator misbehavior cannot be investigated post-mortem without log data.

4. **Compliance Impact**: Blockchain validators often have regulatory or operational requirements for audit trails and logging.

5. **Cascading Effects**: Inability to diagnose issues may lead to prolonged validator downtime or incorrect operational decisions.

While this doesn't directly cause consensus failure or fund loss, it severely degrades validator operational capability and could mask other attacks or issues, making it a significant security concern.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The vulnerability is highly likely to occur because:

1. **Multiple Trigger Points**: Both `json_format` and `text_format` have code paths that can fail or panic.

2. **Complex Serialization**: The custom `Serialize` implementation for `LogEntry` has numerous error propagation points that could fail with unexpected data: [7](#0-6) 

3. **Custom Formatters**: The API allows custom format functions that may contain bugs: [8](#0-7) 

4. **Acknowledged Issue**: The code contains a TODO comment explicitly acknowledging poor error handling in `json_format`, indicating the developers are aware this is problematic but haven't fixed it yet.

5. **Production Use**: All validators using async logging mode (which is typical for production deployments) are vulnerable.

## Recommendation

Replace all `.expect()` calls with proper error handling that logs the error and continues operation. The LoggerService thread should never panic from formatter errors.

**Recommended fix for line 637:**

```rust
// Instead of:
let s = (self.facade.formatter)(&entry).expect("Unable to format");

// Use:
let s = match (self.facade.formatter)(&entry) {
    Ok(formatted) => formatted,
    Err(e) => {
        eprintln!("[Logger] Failed to format log entry: {:?}. Entry metadata: {:?}", 
                  e, entry.metadata);
        STRUCT_LOG_PARSE_ERROR_COUNT.inc();
        continue; // Skip this entry but keep thread alive
    }
};
```

Apply similar error handling to:
- Line 650 (`json_format` call)
- Line 552 (formatter call in `send_entry`)
- Line 774 (replace `.unwrap()` with proper error handling in `text_format`)

Additionally, add monitoring alerts when `STRUCT_LOG_PARSE_ERROR_COUNT` increases to notify operators of formatting failures.

## Proof of Concept

```rust
#[cfg(test)]
mod logger_panic_test {
    use super::*;
    use std::sync::atomic::{AtomicBool, Ordering};
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;

    // Custom formatter that always fails
    fn always_failing_formatter(_entry: &LogEntry) -> Result<String, fmt::Error> {
        Err(fmt::Error)
    }

    #[test]
    fn test_logger_service_thread_death_on_format_panic() {
        let thread_alive = Arc::new(AtomicBool::new(true));
        let thread_alive_clone = thread_alive.clone();

        // Create logger with failing custom formatter
        let (tx, rx) = futures::channel::mpsc::channel(100);
        let mut builder = AptosDataBuilder::new();
        builder
            .is_async(true)
            .custom_format(always_failing_formatter)
            .remote_log_tx(tx)
            .channel_size(10);

        let logger = builder.build();

        // Monitor if LoggerService thread is alive
        thread::spawn(move || {
            thread::sleep(Duration::from_millis(100));
            // After first log with failing formatter, thread should be dead
            thread_alive_clone.store(false, Ordering::SeqCst);
        });

        // Create a log entry that will trigger the formatter
        let metadata = Metadata::new(
            Level::Info,
            "test_target",
            "test_module",
            "test_source.rs:1"
        );
        let event = Event::new(&metadata, Some(format_args!("Test message")), &[]);
        
        // First log will cause panic and kill thread
        logger.record(&event);
        thread::sleep(Duration::from_millis(200));

        // Subsequent logs should be silently dropped
        logger.record(&event);
        logger.record(&event);

        // Verify thread is dead by checking that flush times out
        // (flush would work if thread was alive)
        let start = std::time::Instant::now();
        logger.flush();
        let elapsed = start.elapsed();

        // Flush should timeout (~5 seconds) because thread is dead
        assert!(elapsed.as_secs() >= 4, 
                "Flush should timeout, indicating thread death");
        
        assert!(!thread_alive.load(Ordering::SeqCst), 
                "LoggerService thread should be dead after format panic");
    }
}
```

**Notes**

This vulnerability demonstrates a critical observability failure in production blockchain validators. The silent nature of the failure makes it particularly dangerous, as operators may not realize their node has lost logging capability until they attempt to investigate an incident and find no recent logs. The TODO comment in the `json_format` function indicates the development team is aware of error handling issues in the logging subsystem, but the severity of allowing thread death was apparently not fully appreciated. This affects the operational security posture of all Aptos validators using async logging mode.

### Citations

**File:** crates/aptos-logger/src/aptos_logger.rs (L127-158)
```rust
impl Serialize for LogEntry {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut state = serializer.serialize_struct("LogEntry", 9)?;
        state.serialize_field("level", &self.metadata.level())?;
        state.serialize_field("source", &self.metadata)?;
        if let Some(thread_name) = &self.thread_name {
            state.serialize_field("thread_name", thread_name)?;
        }
        if let Some(hostname) = &self.hostname {
            state.serialize_field("hostname", hostname)?;
        }
        if let Some(namespace) = &self.namespace {
            state.serialize_field("namespace", namespace)?;
        }
        state.serialize_field("timestamp", &self.timestamp)?;
        if let Some(message) = &self.message {
            state.serialize_field("message", message)?;
        }
        if !&self.data.is_empty() {
            state.serialize_field("data", &self.data)?;
        }
        if let Some(backtrace) = &self.backtrace {
            state.serialize_field("backtrace", backtrace)?;
        }
        if let Some(peer_id) = &self.peer_id {
            state.serialize_field("peer_id", peer_id)?;
        }
        state.end()
    }
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L382-388)
```rust
    pub fn custom_format(
        &mut self,
        format: fn(&LogEntry) -> Result<String, fmt::Error>,
    ) -> &mut Self {
        self.custom_format = Some(format);
        self
    }
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L461-461)
```rust
            thread::spawn(move || service.run());
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L556-562)
```rust
        if let Some(sender) = &self.sender {
            if sender
                .try_send(LoggerServiceEvent::LogEntry(entry))
                .is_err()
            {
                STRUCT_LOG_QUEUE_ERROR_COUNT.inc();
            }
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L637-638)
```rust
                            let s = (self.facade.formatter)(&entry).expect("Unable to format");
                            printer.write_buferred(s);
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L650-650)
```rust
                            let s = json_format(&entry).expect("Unable to format");
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L774-774)
```rust
        write!(w, " {}", serde_json::to_string(&entry.data).unwrap())?;
```

**File:** crates/aptos-logger/src/aptos_logger.rs (L781-789)
```rust
fn json_format(entry: &LogEntry) -> Result<String, fmt::Error> {
    match serde_json::to_string(&entry) {
        Ok(s) => Ok(s),
        Err(_) => {
            // TODO: Improve the error handling here. Currently we're just increasing some misleadingly-named metric and dropping any context on why this could not be deserialized.
            STRUCT_LOG_PARSE_ERROR_COUNT.inc();
            Err(fmt::Error)
        },
    }
```
