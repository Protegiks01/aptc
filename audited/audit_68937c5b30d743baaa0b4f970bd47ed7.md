# Audit Report

## Title
Byzantine Validators Can Cause Resource Exhaustion Through Acknowledgment Withholding in Certified Augmented Data Broadcast

## Summary
The `CertifiedAugDataAckState::add()` function requires acknowledgments from ALL validators before completing the certified augmented data broadcast, violating BFT fault tolerance assumptions. A single Byzantine validator can withhold acknowledgments to cause indefinite retries, resulting in network resource exhaustion, CPU waste, and log spam without being detected. [1](#0-0) 

## Finding Description

The randomness generation protocol performs a two-phase broadcast to distribute augmented data:

1. **Phase 1**: Broadcast `AugData` to collect signatures from 2f+1 validators, creating `CertifiedAugData`
2. **Phase 2**: Broadcast `CertifiedAugData` to all validators and wait for acknowledgments

The vulnerability exists in Phase 2's acknowledgment aggregation logic. The `CertifiedAugDataAckState::add()` function only completes when acknowledgments are received from ALL validators (checked via `validators_guard.is_empty()`). This breaks the fundamental BFT assumption that the system should tolerate up to f Byzantine validators. [2](#0-1) 

**Attack Execution Path:**

1. Honest validator initiates augmented data broadcast at epoch start [3](#0-2) 

2. Phase 1 completes successfully (2f+1 signatures collected)

3. Phase 2 begins: reliable broadcast sends `CertifiedAugData` to all validators [4](#0-3) 

4. Honest validator receives its own message and adds certified data locally (enabling block processing) [5](#0-4) 

5. Byzantine validator(s) withhold `CertifiedAugDataAck` responses

6. Reliable broadcast retries indefinitely with exponential backoff (up to 10 seconds delay) [6](#0-5) 

7. Resources are continuously wasted until epoch transition or node restart

**Key Issues:**

- The acknowledgment parameter is ignored (prefixed with `_`), only peer identity is validated
- No BFT threshold applied (should accept 2f+1 instead of n acknowledgments)
- No timeout mechanism exists for the overall broadcast task
- Byzantine validators cannot be detected or penalized [7](#0-6) 

## Impact Explanation

**Severity: High** per Aptos bug bounty criteria: "Validator node slowdowns"

The attack causes:

1. **Network Resource Exhaustion**: Continuous RPC retries to Byzantine validators every 10 seconds (exponential backoff maximum)
2. **CPU Waste**: Processing retry attempts and aggregation checks
3. **Log Spam**: RPC failure warnings logged every 30 seconds due to sampling [8](#0-7) 

4. **Protocol Violation**: The system fails to tolerate f Byzantine validators as required by BFT assumptions
5. **Indefinite Task Execution**: The broadcast task never completes, remaining active throughout the epoch

While block processing continues (since the validator adds its own certified data locally when receiving its self-message), the indefinite retry loop degrades validator performance and wastes network resources. In a network with multiple validators under this attack, the cumulative impact becomes significant.

## Likelihood Explanation

**Likelihood: High**

- **Ease of Execution**: Byzantine validator simply drops `CertifiedAugData` messages without responding
- **Low Barrier**: Requires only 1 malicious validator out of n validators
- **Undetectable**: Cannot distinguish from legitimate network failures
- **No Penalties**: No slashing or reputation damage for withholding acknowledgments
- **Strategic Timing**: Can be executed selectively at epoch boundaries for maximum impact
- **Standard BFT Threat Model**: Up to f Byzantine validators is the assumed threat model

The attack is trivial to execute and falls within the standard BFT threat model where up to 1/3 of validators may be Byzantine.

## Recommendation

Replace the ALL-validator requirement with a BFT threshold (2f+1 or quorum-based):

```rust
pub struct CertifiedAugDataAckState {
    validators: Mutex<HashSet<Author>>,
    threshold: usize,  // Add threshold based on voting power
}

impl CertifiedAugDataAckState {
    pub fn new(validators: impl Iterator<Item = Author>, verifier: &ValidatorVerifier) -> Self {
        let threshold = verifier.quorum_voting_power() as usize;
        Self {
            validators: Mutex::new(validators.collect()),
            threshold,
        }
    }
}

impl<S: TShare, D: TAugmentedData> BroadcastStatus<RandMessage<S, D>, RandMessage<S, D>>
    for Arc<CertifiedAugDataAckState>
{
    // ... same types ...

    fn add(&self, peer: Author, ack: Self::Response) -> anyhow::Result<Option<Self::Aggregated>> {
        // Validate the acknowledgment
        ack.verify(peer)?;
        
        let mut validators_guard = self.validators.lock();
        ensure!(
            validators_guard.remove(&peer),
            "[RandMessage] Unknown author: {}",
            peer
        );
        
        // Complete when quorum threshold is reached instead of all validators
        if validators_guard.len() <= (total_validators - self.threshold) {
            Ok(Some(()))
        } else {
            Ok(None)
        }
    }
}
```

Additionally:
1. Validate the `CertifiedAugDataAck` content instead of ignoring it
2. Consider adding a timeout for the overall broadcast task (e.g., 5 minutes)
3. Implement detection heuristics for persistent non-responders

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::validator_verifier::ValidatorVerifier;
    
    #[tokio::test]
    async fn test_byzantine_withholding_attack() {
        // Setup: Create 4 validators (f=1, requires 3/4 for BFT)
        let validators = vec![
            Author::random(), // Honest validator (self)
            Author::random(), // Honest validator
            Author::random(), // Honest validator  
            Author::random(), // Byzantine validator
        ];
        
        // Create acknowledgment state requiring ALL validators
        let ack_state = Arc::new(CertifiedAugDataAckState::new(
            validators.iter().cloned()
        ));
        
        // Simulate receiving acks from 3/4 validators (missing Byzantine)
        for i in 0..3 {
            let result = ack_state.add(
                validators[i],
                CertifiedAugDataAck::new(0)
            );
            assert!(result.is_ok());
            if i < 2 {
                assert!(result.unwrap().is_none()); // Not complete yet
            }
        }
        
        // After 3/4 validators (exceeds BFT threshold), broadcast still incomplete
        let result = ack_state.add(
            validators[2],
            CertifiedAugDataAck::new(0)
        );
        assert!(result.unwrap().is_none()); // Still not complete!
        
        // Only completes when 4th (Byzantine) validator responds
        // In practice, this never happens, causing indefinite retries
        
        // Expected: Should complete with 3/4 (2f+1) acknowledgments
        // Actual: Requires 4/4 (all) acknowledgments
    }
}
```

To observe the resource exhaustion in a running system:
1. Deploy a validator that selectively drops `RandMessage::CertifiedAugData` messages
2. Observe the honest validator's logs for repeated RPC failure warnings
3. Monitor network traffic showing retry attempts every 10 seconds
4. Verify the broadcast task remains active indefinitely in the task queue

### Citations

**File:** consensus/src/rand/rand_gen/reliable_broadcast_state.rs (L69-79)
```rust
pub struct CertifiedAugDataAckState {
    validators: Mutex<HashSet<Author>>,
}

impl CertifiedAugDataAckState {
    pub fn new(validators: impl Iterator<Item = Author>) -> Self {
        Self {
            validators: Mutex::new(validators.collect()),
        }
    }
}
```

**File:** consensus/src/rand/rand_gen/reliable_broadcast_state.rs (L88-101)
```rust
    fn add(&self, peer: Author, _ack: Self::Response) -> anyhow::Result<Option<Self::Aggregated>> {
        let mut validators_guard = self.validators.lock();
        ensure!(
            validators_guard.remove(&peer),
            "[RandMessage] Unknown author: {}",
            peer
        );
        // If receive from all validators, stop the reliable broadcast
        if validators_guard.is_empty() {
            Ok(Some(()))
        } else {
            Ok(None)
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L305-346)
```rust
    async fn broadcast_aug_data(&mut self) -> DropGuard {
        let data = self
            .aug_data_store
            .get_my_aug_data()
            .unwrap_or_else(|| D::generate(&self.config, &self.fast_config));
        // Add it synchronously to avoid race that it sends to others but panics before it persists locally.
        self.aug_data_store
            .add_aug_data(data.clone())
            .expect("Add self aug data should succeed");
        let aug_ack = AugDataCertBuilder::new(data.clone(), self.epoch_state.clone());
        let rb = self.reliable_broadcast.clone();
        let rb2 = self.reliable_broadcast.clone();
        let validators = self.epoch_state.verifier.get_ordered_account_addresses();
        let maybe_existing_certified_data = self.aug_data_store.get_my_certified_aug_data();
        let phase1 = async move {
            if let Some(certified_data) = maybe_existing_certified_data {
                info!("[RandManager] Already have certified aug data");
                return certified_data;
            }
            info!("[RandManager] Start broadcasting aug data");
            info!(LogSchema::new(LogEvent::BroadcastAugData)
                .author(*data.author())
                .epoch(data.epoch()));
            let certified_data = rb.broadcast(data, aug_ack).await.expect("cannot fail");
            info!("[RandManager] Finish broadcasting aug data");
            certified_data
        };
        let ack_state = Arc::new(CertifiedAugDataAckState::new(validators.into_iter()));
        let task = phase1.then(|certified_data| async move {
            info!(LogSchema::new(LogEvent::BroadcastCertifiedAugData)
                .author(*certified_data.author())
                .epoch(certified_data.epoch()));
            info!("[RandManager] Start broadcasting certified aug data");
            rb2.broadcast(certified_data, ack_state)
                .await
                .expect("Broadcast cannot fail");
            info!("[RandManager] Finish broadcasting certified aug data");
        });
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(task, abort_registration));
        DropGuard::new(abort_handle)
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L452-461)
```rust
                        RandMessage::CertifiedAugData(certified_aug_data) => {
                            info!(LogSchema::new(LogEvent::ReceiveCertifiedAugData)
                                .author(self.author)
                                .epoch(certified_aug_data.epoch())
                                .remote_peer(*certified_aug_data.author()));
                            match self.aug_data_store.add_certified_aug_data(certified_aug_data) {
                                Ok(ack) => self.process_response(protocol, response_sender, RandMessage::CertifiedAugDataAck(ack)),
                                Err(e) => error!("[RandManager] Failed to add certified aug data: {}", e),
                            }
                        }
```

**File:** crates/reliable-broadcast/src/lib.rs (L191-200)
```rust
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
```

**File:** crates/reliable-broadcast/src/lib.rs (L210-220)
```rust
fn log_rpc_failure(error: anyhow::Error, receiver: Author) {
    // Log a sampled warning (to prevent spam)
    sample!(
        SampleRate::Duration(Duration::from_secs(30)),
        warn!("[sampled] rpc to {} failed, error {:#}", receiver, error)
    );

    // Log at the debug level (this is useful for debugging
    // and won't spam the logs in a production environment).
    debug!("rpc to {} failed, error {:#}", receiver, error);
}
```

**File:** config/src/config/consensus_config.rs (L373-378)
```rust
            rand_rb_config: ReliableBroadcastConfig {
                backoff_policy_base_ms: 2,
                backoff_policy_factor: 100,
                backoff_policy_max_delay_ms: 10000,
                rpc_timeout_ms: 10000,
            },
```
