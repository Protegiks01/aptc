# Audit Report

## Title
Transaction Backup Restore Can Leave Validator in Inconsistent State Due to Missing File Validation

## Summary
The `TransactionBackup::verify()` method does not validate that FileHandles reference existing files, allowing restore operations to fail mid-execution after partially committing transaction data to the database. This leaves validators in an inconsistent state requiring manual intervention to recover.

## Finding Description

The transaction backup and restore system has a critical gap in its validation logic. When a `TransactionBackup` manifest is loaded, the `verify()` method only validates structural properties (version ranges and chunk continuity) but never checks whether the FileHandles actually reference existing files. [1](#0-0) 

The actual file access occurs later during `LoadedChunk::load()` when chunks are processed in a streaming fashion: [2](#0-1) 

The critical vulnerability arises because:

1. **No Pre-flight Validation**: Manifests are validated without checking file existence
2. **Lazy Loading**: Files are accessed only when each chunk is processed in the stream
3. **Progressive Commits**: Transactions are saved to the database in batches as chunks are successfully loaded [3](#0-2) 

4. **No Rollback Mechanism**: When a missing file is encountered, previous batches have already been committed with no way to rollback [4](#0-3) 

**Attack Scenario:**
1. A manifest references FileHandles where some files exist and others don't (due to deletion, corruption, or malicious creation)
2. `verify()` passes because it only checks version ranges
3. Restore begins through `TransactionRestoreBatchController`
4. First N chunks load successfully and transactions are committed to the database
5. Chunk N+1 references a non-existent file - `open_for_read()` fails [5](#0-4) 

6. The restore operation fails, leaving the validator with incomplete transaction history
7. The validator cannot safely participate in consensus without complete state

This violates the **State Consistency** invariant: "State transitions must be atomic and verifiable via Merkle proofs." The database is left in a partial state that is neither fully restored nor clean.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** per Aptos bug bounty criteria:
- **"State inconsistencies requiring intervention"**: The validator is left with partial transaction history requiring manual database cleanup and restore restart
- **Validator unavailability**: Affected validator cannot participate in consensus until state is corrected
- **Not Critical** because: Does not affect live consensus (only restore operations), no funds directly at risk, network continues operating with other validators

The impact is contained to restore operations but can cause significant operational disruption:
- Wasted restoration time and resources
- Validator downtime until issue is resolved
- Potential for accidental triggers via storage system failures
- Possible deliberate exploitation via malicious manifests

## Likelihood Explanation

**Likelihood: Medium to High**

This can occur through multiple vectors:

1. **Accidental Triggers** (Most Common):
   - Files deleted from backup storage due to retention policies
   - Storage system failures or corruptions
   - Incomplete backup uploads
   - Race conditions between manifest creation and file availability

2. **Malicious Exploitation** (Less Common but Possible):
   - Attacker with write access to backup storage creates manifests referencing non-existent files
   - Corrupted backup distribution to operators

The vulnerability is particularly concerning because:
- Validators regularly perform restore operations (bootstrapping, disaster recovery)
- No warning is provided before starting the restore
- Error detection happens mid-restore, after partial commits
- Manual intervention required to recover

## Recommendation

Implement **pre-flight file validation** before beginning restore operations. Add a validation phase that checks all FileHandles reference existing files:

```rust
impl TransactionBackup {
    pub fn verify(&self) -> Result<()> {
        // ... existing version range checks ...
        Ok(())
    }
    
    // NEW: Add file existence validation
    pub async fn verify_file_handles(&self, storage: &Arc<dyn BackupStorage>) -> Result<()> {
        for chunk in &self.chunks {
            // Validate transaction file exists
            storage.validate_file_exists(&chunk.transactions).await
                .with_context(|| format!(
                    "Transaction file not found for chunk [{}, {}]", 
                    chunk.first_version, chunk.last_version
                ))?;
            
            // Validate proof file exists
            storage.validate_file_exists(&chunk.proof).await
                .with_context(|| format!(
                    "Proof file not found for chunk [{}, {}]", 
                    chunk.first_version, chunk.last_version
                ))?;
        }
        Ok(())
    }
}
```

Add to `BackupStorage` trait:
```rust
#[async_trait]
pub trait BackupStorage: Send + Sync {
    // ... existing methods ...
    
    /// Validate that a file handle references an existing, accessible file
    async fn validate_file_exists(&self, file_handle: &FileHandleRef) -> Result<()>;
}
```

Call this validation in `loaded_chunk_stream()` before processing: [6](#0-5) 

Insert validation after line 353:
```rust
.and_then(|m: TransactionBackup| async move {
    m.verify()?;
    m.verify_file_handles(&storage).await?; // NEW: Pre-flight file check
    Ok(m)
})
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_missing_file_leaves_inconsistent_state() {
    use tempfile::TempDir;
    use std::fs;
    
    // Setup: Create backup directory with manifest and partial files
    let backup_dir = TempDir::new().unwrap();
    let storage = Arc::new(LocalFs::new(backup_dir.path().to_path_buf()));
    
    // Create manifest with 3 chunks
    let manifest = TransactionBackup {
        first_version: 0,
        last_version: 29999,
        chunks: vec![
            TransactionChunk {
                first_version: 0,
                last_version: 9999,
                transactions: "chunk0/transactions".to_string(),
                proof: "chunk0/proof".to_string(),
                format: TransactionChunkFormat::V1,
            },
            TransactionChunk {
                first_version: 10000,
                last_version: 19999,
                transactions: "chunk1/transactions".to_string(),
                proof: "chunk1/proof".to_string(),
                format: TransactionChunkFormat::V1,
            },
            TransactionChunk {
                first_version: 20000,
                last_version: 29999,
                transactions: "chunk2/transactions".to_string(), // THIS FILE MISSING
                proof: "chunk2/proof".to_string(),
                format: TransactionChunkFormat::V1,
            },
        ],
    };
    
    // Manifest verification passes (only checks version ranges)
    assert!(manifest.verify().is_ok());
    
    // Create files for chunk 0 and 1, but NOT chunk 2
    create_chunk_files(&backup_dir, "chunk0", 0, 9999);
    create_chunk_files(&backup_dir, "chunk1", 10000, 19999);
    // chunk2 files intentionally missing
    
    // Setup restore to real DB
    let db_dir = TempDir::new().unwrap();
    let restore_handler = setup_restore_handler(db_dir.path());
    
    let global_opt = GlobalRestoreOptions {
        target_version: Version::MAX,
        trusted_waypoints: Arc::new(HashMap::new()),
        run_mode: Arc::new(RestoreRunMode::Restore { restore_handler: restore_handler.clone() }),
        concurrent_downloads: 1,
        replay_concurrency_level: 1,
    };
    
    // Create controller and attempt restore
    let controller = TransactionRestoreBatchController::new(
        global_opt,
        storage,
        vec!["manifest.json".to_string()],
        None,
        None,
        None,
        VerifyExecutionMode::NoVerify,
        None,
    );
    
    // Restore will fail when accessing missing chunk2 files
    let result = controller.run().await;
    assert!(result.is_err());
    
    // VULNERABILITY: DB now has chunks 0 and 1 committed (versions 0-19999)
    // but chunk 2 is missing, leaving incomplete transaction history
    let synced_version = restore_handler.get_next_expected_transaction_version().unwrap();
    assert_eq!(synced_version, 20000); // Partial restore succeeded
    
    // Validator is now in inconsistent state:
    // - Has transactions 0-19999 committed
    // - Missing transactions 20000-29999
    // - Cannot safely participate in consensus
    // - Requires manual cleanup and restart
}
```

This demonstrates that:
1. Manifest verification passes despite missing files
2. Restore commits transactions from available chunks
3. Restore fails when encountering missing files
4. Database left in inconsistent state with partial data
5. Manual intervention required to recover

## Notes

This vulnerability is specific to the restore/verification workflow and does not affect live consensus operations. However, it represents a significant operational risk as validators regularly use backup/restore for:
- Initial node bootstrapping
- Disaster recovery
- State synchronization
- Testing and validation

The recommended fix adds minimal overhead (file existence checks) while preventing partial restore states. The validation should be performed once upfront rather than discovering missing files mid-restore after partial commits.

### Citations

**File:** storage/backup/backup-cli/src/backup_types/transaction/manifest.rs (L50-88)
```rust
    pub fn verify(&self) -> Result<()> {
        // check number of waypoints
        ensure!(
            self.first_version <= self.last_version,
            "Bad version range: [{}, {}]",
            self.first_version,
            self.last_version,
        );

        // check chunk ranges
        ensure!(!self.chunks.is_empty(), "No chunks.");

        let mut next_version = self.first_version;
        for chunk in &self.chunks {
            ensure!(
                chunk.first_version == next_version,
                "Chunk ranges not continuous. Expected first version: {}, actual: {}.",
                next_version,
                chunk.first_version,
            );
            ensure!(
                chunk.last_version >= chunk.first_version,
                "Chunk range invalid. [{}, {}]",
                chunk.first_version,
                chunk.last_version,
            );
            next_version = chunk.last_version + 1;
        }

        // check last version in chunk matches manifest
        ensure!(
            next_version - 1 == self.last_version, // okay to -1 because chunks is not empty.
            "Last version in chunks: {}, in manifest: {}",
            next_version - 1,
            self.last_version,
        );

        Ok(())
    }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L100-109)
```rust
    async fn load(
        manifest: TransactionChunk,
        storage: &Arc<dyn BackupStorage>,
        epoch_history: Option<&Arc<EpochHistory>>,
    ) -> Result<Self> {
        let mut file = BufReader::new(storage.open_for_read(&manifest.transactions).await?);
        let mut txns = Vec::new();
        let mut persisted_aux_info = Vec::new();
        let mut txn_infos = Vec::new();
        let mut event_vecs = Vec::new();
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L347-353)
```rust
        let manifest_stream = manifest_handle_stream
            .map(move |hdl| {
                let storage = storage.clone();
                async move { storage.load_json_file(&hdl).await.err_notes(&hdl) }
            })
            .buffered_x(con * 3, con)
            .and_then(|m: TransactionBackup| future::ready(m.verify().map(|_| m)));
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L507-517)
```rust
                        tokio::task::spawn_blocking(move || {
                            restore_handler.save_transactions(
                                first_version,
                                &txns_to_save,
                                &persisted_aux_info_to_save,
                                &txn_infos_to_save,
                                &event_vecs_to_save,
                                write_sets_to_save,
                            )
                        })
                        .await??;
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L165-172)
```rust
        // commit the state kv before ledger in case of failure happens
        let last_version = first_version + txns.len() as u64 - 1;
        state_store
            .state_db
            .state_kv_db
            .commit(last_version, None, sharded_kv_schema_batch)?;

        ledger_db.write_schemas(ledger_db_batch)?;
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L98-109)
```rust
    async fn open_for_read(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
        let path = self.dir.join(file_handle);
        let file = OpenOptions::new()
            .read(true)
            .open(&path)
            .await
            .err_notes(&path)?;
        Ok(Box::new(file))
    }
```
