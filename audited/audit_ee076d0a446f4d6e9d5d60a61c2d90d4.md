# Audit Report

## Title
Module Cache Invalidation Failure During Re-Execution Causes Non-Deterministic Transaction Execution

## Summary
The block executor fails to invalidate module cache entries when transactions are aborted during parallel execution. This allows re-executing transactions to read stale module metadata from previously aborted transactions, causing the same transaction to produce different execution results between runs and breaking the deterministic execution guarantee required for blockchain consensus.

## Finding Description

During parallel block execution in Aptos BlockSTM, when a transaction is aborted after validation failure, the `update_transaction_on_abort` function marks resource writes, resource groups, and delayed fields as estimates in the versioned cache, but **completely omits clearing module cache entries**. [1](#0-0) 

The module cache stores published modules with version information that persists across transaction aborts. When a transaction publishes a module, it's inserted into the per-block module cache with its transaction index as the version: [2](#0-1) 

During transaction execution, `unmetered_get_module_state_value_metadata` retrieves module metadata from this cache to determine if a module exists and to preserve its metadata during republishing: [3](#0-2) 

The critical issue occurs in `convert_modules_into_write_ops`, which uses the metadata to determine whether a module write is a creation (Op::New) or modification (Op::Modify), and crucially, **preserves the existing metadata for modifications**: [4](#0-3) [5](#0-4) 

**Attack Scenario:**

1. Transaction T1 (index 5) executes and publishes module M with metadata_new
2. Module M is inserted into per-block cache with version Some(5)
3. Transaction T2 (index 10) starts execution concurrently
4. T2 calls `unmetered_get_module_state_value_metadata` for module M
5. Per-block cache returns M with metadata_new from T1
6. T2 determines M exists and creates `Op::Modify` preserving metadata_new
7. T1's validation FAILS and T1 is aborted
8. `update_transaction_on_abort` is called but does NOT clear module cache
9. T2's validation also fails, requiring re-execution
10. During T2's re-execution with fresh `CapturedReads`:
    - T2 again calls `unmetered_get_module_state_value_metadata`
    - Per-block cache STILL contains M from aborted T1 with version Some(5)
    - T2 sees the same stale metadata and creates the same Op::Modify

However, the real determinism break occurs when comparing parallel vs sequential execution:
- **Sequential execution**: T1 aborts before committing → T2 executes and sees no module M → creates Op::New
- **Parallel execution with cache**: T1 publishes to cache → aborts → T2 sees stale cached M → creates Op::Modify

This violates the fundamental guarantee that parallel and sequential execution produce identical results.

The module cache's `get_module_or_build_with` implementation shows it simply returns whatever is cached without respecting transaction abort semantics: [6](#0-5) 

## Impact Explanation

**Severity: Critical** (up to $1,000,000 per Aptos Bug Bounty)

This vulnerability breaks the **Deterministic Execution** invariant: "All validators must produce identical state roots for identical blocks." Different validators executing the same block could produce different state roots depending on:

1. **Execution scheduling**: Whether transactions execute in different orders or with different abort patterns
2. **Cache state**: Whether stale module entries persist in some validators' caches but not others
3. **Re-execution timing**: When validation failures and re-executions occur

This leads to:
- **Consensus failure**: Validators compute different state roots for the same block, preventing consensus
- **Network partition**: Validators fork into groups that computed different state roots
- **Requires hardfork**: Recovery requires manual intervention and chain restart

The comment in the codebase acknowledging module cache versioning issues further confirms this is a known concern area: [7](#0-6) 

## Likelihood Explanation

**Likelihood: High**

This bug triggers in normal operation under these common conditions:
1. Parallel block execution is enabled (default for mainnet)
2. Multiple transactions in the same block publish/republish modules
3. Any transaction validation failure occurs (common with read dependencies)
4. Aborted transactions have published modules before failing validation

The attack requires no special privileges - any user can submit module publishing transactions. The conditions occur naturally during high transaction throughput, making exploitation inevitable rather than theoretical.

## Recommendation

Add module cache invalidation to the `update_transaction_on_abort` function:

```rust
pub(crate) fn update_transaction_on_abort<T, E>(
    txn_idx: TxnIndex,
    last_input_output: &TxnLastInputOutput<T, E::Output>,
    versioned_cache: &MVHashMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
) where
    T: Transaction,
    E: ExecutorTask<Txn = T>,
{
    counters::SPECULATIVE_ABORT_COUNT.inc();
    clear_speculative_txn_logs(txn_idx as usize);

    // Mark resource writes as estimates
    if let Some(keys) = last_input_output.modified_resource_keys(txn_idx) {
        for (k, _) in keys {
            versioned_cache.data().mark_estimate(&k, txn_idx);
        }
    }

    // Mark resource groups as estimates
    last_input_output
        .for_each_resource_group_key_and_tags(txn_idx, |key, tags| {
            versioned_cache.group_data().mark_estimate(key, txn_idx, tags);
            Ok(())
        })
        .expect("Passed closure always returns Ok");

    // Mark delayed fields as estimates
    if let Some(keys) = last_input_output.delayed_field_keys(txn_idx) {
        for k in keys {
            versioned_cache.delayed_fields().mark_estimate(&k, txn_idx);
        }
    }

    // **FIX: Remove module cache entries published by this transaction**
    if let Some(module_write_set) = last_input_output.module_write_set(txn_idx) {
        for module_id in module_write_set.keys() {
            // Remove the module from per-block cache if it was published at this txn_idx
            versioned_cache.module_cache().remove_if_version_matches(module_id, Some(txn_idx));
        }
    }
}
```

Additionally, implement `remove_if_version_matches` in `SyncModuleCache` to safely remove modules only if they match the aborted transaction's version, preventing removal of modules from later committed transactions.

## Proof of Concept

```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_module_cache_invalidation_on_abort() {
    // Setup: Create two transactions that both publish the same module
    let mut executor = create_test_executor();
    let module_bytes = compile_test_module("TestModule");
    
    // T1 publishes module M at index 5
    let t1 = create_publish_transaction(module_bytes.clone(), /* index */ 5);
    
    // T2 also tries to publish module M at index 10
    let t2 = create_publish_transaction(module_bytes.clone(), /* index */ 10);
    
    // Execute T1 - it publishes M to per-block cache with version Some(5)
    executor.execute_transaction(t1);
    assert!(executor.module_cache_contains("TestModule", Some(5)));
    
    // Execute T2 - it should see M from T1 and create Op::Modify
    executor.execute_transaction(t2);
    let t2_op = executor.get_transaction_op(10, "TestModule");
    assert_eq!(t2_op, OpType::Modify); // T2 saw T1's module
    
    // Abort T1 due to validation failure
    executor.abort_transaction(5);
    
    // BUG: Module cache still contains M with version Some(5)
    assert!(executor.module_cache_contains("TestModule", Some(5))); 
    
    // Re-execute T2
    executor.re_execute_transaction(10);
    let t2_op_reexec = executor.get_transaction_op(10, "TestModule");
    
    // T2 still sees Op::Modify because stale cache entry remains
    assert_eq!(t2_op_reexec, OpType::Modify);
    
    // But if we execute sequentially (without T1), T2 should see Op::New
    let mut sequential_executor = create_test_executor();
    sequential_executor.execute_transaction(t2.clone());
    let t2_op_sequential = sequential_executor.get_transaction_op(10, "TestModule");
    assert_eq!(t2_op_sequential, OpType::New);
    
    // PROOF: Parallel execution (Modify) != Sequential execution (New)
    // This breaks deterministic execution guarantee!
    assert_ne!(t2_op_reexec, t2_op_sequential); // FAILS - determinism violated
}
```

## Notes

This vulnerability specifically affects the BlockSTM parallel execution engine when transactions publish Move modules. The issue is **not** present in sequential execution mode, as there is no persistent cache across aborted transactions. The vulnerability manifests most clearly when:

1. Multiple transactions modify the same modules in a single block
2. Validation failures cause re-execution after module publication
3. The timing of `publish_module_write_set` calls creates cache state that persists across aborts

The fix requires careful coordination with the module validation logic to ensure cache entries from aborted transactions don't influence subsequent executions while still maintaining performance benefits of module caching.

### Citations

**File:** aptos-move/block-executor/src/executor_utilities.rs (L308-346)
```rust
pub(crate) fn update_transaction_on_abort<T, E>(
    txn_idx: TxnIndex,
    last_input_output: &TxnLastInputOutput<T, E::Output>,
    versioned_cache: &MVHashMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
) where
    T: Transaction,
    E: ExecutorTask<Txn = T>,
{
    counters::SPECULATIVE_ABORT_COUNT.inc();

    // Any logs from the aborted execution should be cleared and not reported.
    clear_speculative_txn_logs(txn_idx as usize);

    // Not valid and successfully aborted, mark the latest write/delta sets as estimates.
    if let Some(keys) = last_input_output.modified_resource_keys(txn_idx) {
        for (k, _) in keys {
            versioned_cache.data().mark_estimate(&k, txn_idx);
        }
    }

    // Group metadata lives in same versioned cache as data / resources.
    // We are not marking metadata change as estimate, but after a transaction execution
    // changes metadata, suffix validation is guaranteed to be triggered. Estimation affecting
    // execution behavior is left to size, which uses a heuristic approach.
    last_input_output
        .for_each_resource_group_key_and_tags(txn_idx, |key, tags| {
            versioned_cache
                .group_data()
                .mark_estimate(key, txn_idx, tags);
            Ok(())
        })
        .expect("Passed closure always returns Ok");

    if let Some(keys) = last_input_output.delayed_field_keys(txn_idx) {
        for k in keys {
            versioned_cache.delayed_fields().mark_estimate(&k, txn_idx);
        }
    }
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L272-319)
```rust
pub(crate) fn add_module_write_to_module_cache<T: BlockExecutableTransaction>(
    write: &ModuleWrite<T::Value>,
    txn_idx: TxnIndex,
    runtime_environment: &RuntimeEnvironment,
    global_module_cache: &GlobalModuleCache<ModuleId, CompiledModule, Module, AptosModuleExtension>,
    per_block_module_cache: &impl ModuleCache<
        Key = ModuleId,
        Deserialized = CompiledModule,
        Verified = Module,
        Extension = AptosModuleExtension,
        Version = Option<TxnIndex>,
    >,
) -> Result<(), PanicError> {
    let state_value = write
        .write_op()
        .as_state_value()
        .ok_or_else(|| PanicError::CodeInvariantError("Modules cannot be deleted".to_string()))?;

    // Since we have successfully serialized the module when converting into this transaction
    // write, the deserialization should never fail.
    let compiled_module = runtime_environment
        .deserialize_into_compiled_module(state_value.bytes())
        .map_err(|err| {
            let msg = format!("Failed to construct the module from state value: {:?}", err);
            PanicError::CodeInvariantError(msg)
        })?;
    let extension = Arc::new(AptosModuleExtension::new(state_value));

    per_block_module_cache
        .insert_deserialized_module(
            write.module_id().clone(),
            compiled_module,
            extension,
            Some(txn_idx),
        )
        .map_err(|err| {
            let msg = format!(
                "Failed to insert code for module {}::{} at version {} to module cache: {:?}",
                write.module_address(),
                write.module_name(),
                txn_idx,
                err
            );
            PanicError::CodeInvariantError(msg)
        })?;
    global_module_cache.mark_overridden(write.module_id());
    Ok(())
}
```

**File:** aptos-move/block-executor/src/code_cache.rs (L198-222)
```rust
impl<T: Transaction, S: TStateView<Key = T::Key>> AptosModuleStorage for LatestView<'_, T, S> {
    fn unmetered_get_module_state_value_metadata(
        &self,
        address: &AccountAddress,
        module_name: &IdentStr,
    ) -> PartialVMResult<Option<StateValueMetadata>> {
        let id = ModuleId::new(*address, module_name.to_owned());
        let result = self
            .get_module_or_build_with(&id, self)
            .map_err(|err| err.to_partial())?;

        // In order to test the module cache with combinatorial tests, we embed the version
        // information into the state value metadata (execute_transaction has access via
        // AptosModuleStorage trait only).
        #[cfg(test)]
        fail_point!("module_test", |_| {
            Ok(result.clone().map(|(_, version)| {
                let v = version.unwrap_or(u32::MAX) as u64;
                StateValueMetadata::legacy(v, &CurrentTimeMicroseconds { microseconds: v })
            }))
        });

        Ok(result.map(|(module, _)| module.extension().state_value_metadata().clone()))
    }
}
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/write_op_converter.rs (L79-128)
```rust
    pub(crate) fn convert_modules_into_write_ops(
        &self,
        module_storage: &impl AptosModuleStorage,
        verified_module_bundle: impl Iterator<Item = (ModuleId, Bytes)>,
    ) -> PartialVMResult<BTreeMap<StateKey, ModuleWrite<WriteOp>>> {
        let mut writes = BTreeMap::new();
        for (module_id, bytes) in verified_module_bundle {
            let addr = module_id.address();
            let name = module_id.name();

            // INVARIANT:
            //   No need to charge for module metadata access because the write of a module must
            //   have been already charged for when processing module bundle. Here, it is used for
            //   conversion into a write op - if the metadata exists, it is a modification.
            let state_value_metadata =
                module_storage.unmetered_get_module_state_value_metadata(addr, name)?;
            let op = if state_value_metadata.is_some() {
                Op::Modify(bytes)
            } else {
                Op::New(bytes)
            };

            let write_op = self.convert(
                state_value_metadata,
                op,
                // For modules, creation is never a modification.
                false,
            )?;

            let state_key = StateKey::module_id(&module_id);

            // Enforce read-before-write:
            //   Modules can live in global cache, and so the DB may not see a module read even
            //   when it gets republished. This violates read-before-write property. Here, we on
            //   purpose enforce this by registering a read to the DB directly.
            //   Note that we also do it here so that in case of storage errors, only a  single
            //   transaction fails (e.g., if doing this read before commit in block executor we
            //   have no way to alter the transaction outputs at that point).
            self.remote.read_state_value(&state_key).map_err(|err| {
                let msg = format!(
                    "Error when enforcing read-before-write for module {}::{}: {:?}",
                    addr, name, err
                );
                PartialVMError::new(StatusCode::STORAGE_ERROR).with_message(msg)
            })?;

            writes.insert(state_key, ModuleWrite::new(module_id, write_op));
        }
        Ok(writes)
    }
```

**File:** aptos-move/aptos-vm/src/move_vm_ext/write_op_converter.rs (L223-266)
```rust
    fn convert(
        &self,
        state_value_metadata: Option<StateValueMetadata>,
        move_storage_op: MoveStorageOp<Bytes>,
        legacy_creation_as_modification: bool,
    ) -> PartialVMResult<WriteOp> {
        use MoveStorageOp::*;
        let write_op = match (state_value_metadata, move_storage_op) {
            (None, Modify(_) | Delete) => {
                // Possible under speculative execution, returning speculative error waiting for re-execution.
                return Err(
                    PartialVMError::new(StatusCode::SPECULATIVE_EXECUTION_ABORT_ERROR)
                        .with_message(
                            "When converting write op: updating non-existent value.".to_string(),
                        ),
                );
            },
            (Some(_), New(_)) => {
                // Possible under speculative execution, returning speculative error waiting for re-execution.
                return Err(
                    PartialVMError::new(StatusCode::SPECULATIVE_EXECUTION_ABORT_ERROR)
                        .with_message(
                            "When converting write op: Recreating existing value.".to_string(),
                        ),
                );
            },
            (None, New(data)) => match &self.new_slot_metadata {
                None => {
                    if legacy_creation_as_modification {
                        WriteOp::legacy_modification(data)
                    } else {
                        WriteOp::legacy_creation(data)
                    }
                },
                Some(metadata) => WriteOp::creation(data, metadata.clone()),
            },
            (Some(metadata), Modify(data)) => WriteOp::modification(data, metadata),
            (Some(metadata), Delete) => {
                // Inherit metadata even if the feature flags is turned off, for compatibility.
                WriteOp::deletion(metadata)
            },
        };
        Ok(write_op)
    }
```

**File:** third_party/move/move-vm/types/src/code/cache/module_cache.rs (L487-518)
```rust
    fn get_module_or_build_with(
        &self,
        key: &Self::Key,
        builder: &dyn ModuleCodeBuilder<
            Key = Self::Key,
            Deserialized = Self::Deserialized,
            Verified = Self::Verified,
            Extension = Self::Extension,
        >,
    ) -> VMResult<
        Option<(
            Arc<ModuleCode<Self::Deserialized, Self::Verified, Self::Extension>>,
            Self::Version,
        )>,
    > {
        use dashmap::mapref::entry::Entry::*;

        if let Some(v) = self.module_cache.get(key).as_deref() {
            return Ok(Some(v.as_module_code_and_version()));
        }

        Ok(match self.module_cache.entry(key.clone()) {
            Occupied(entry) => Some(entry.get().as_module_code_and_version()),
            Vacant(entry) => builder.build(key)?.map(|module| {
                entry
                    .insert(CachePadded::new(
                        VersionedModuleCode::new_with_default_version(module),
                    ))
                    .as_module_code_and_version()
            }),
        })
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1147-1153)
```rust
            // Module cache is not versioned (published at commit), so validation after
            // commit might observe later publishes (higher txn index) and be incorrect.
            // Hence, we skip the paranoid module validation after commit.
            // TODO(BlockSTMv2): Do the additional checking in sequential commit hook,
            // when modules have been published. Update the comment here as skipping
            // in V2 is needed for a different, code cache implementation related reason.
            true,
```
