# Audit Report

## Title
Resource Exhaustion via Unvalidated max_response_bytes Parameter in Storage Service Requests

## Summary
The storage service fails to validate the `max_response_bytes` parameter in `GetTransactionDataWithProofRequest`, allowing attackers to set arbitrarily small values (e.g., 1 byte). This forces the server to return only one transaction per request, amplifying request volume by up to 3000x and causing excessive resource consumption through repeated request processing, storage reads, serialization, and network overhead.

## Finding Description
The `get_transaction_data_with_proof()` function in the storage service accepts a user-controlled `max_response_bytes` parameter without validation. [1](#0-0) 

The request moderator validates only whether the data range can be serviced, but performs no checks on the `max_response_bytes` value. [2](#0-1) 

The storage handler directly uses the unvalidated parameter: [3](#0-2) 

The response building logic guarantees at least one item is returned even when `max_response_bytes` is smaller than a single transaction's serialized size. [4](#0-3) 

**Attack Path:**
1. Attacker connects as a storage service peer
2. Sends `GetTransactionDataWithProofRequest` with legitimate version ranges but `max_response_bytes = 1`
3. Request passes validation in `RequestModerator.validate_request()` (only checks data availability)
4. Server processes request, creating storage iterators for up to 3000 transactions
5. Server reads first transaction, calculates serialized size (typically 500-2000 bytes)
6. `ResponseDataProgressTracker` allows first item despite exceeding 1-byte limit
7. Server returns response with exactly 1 transaction
8. Attacker repeats for each transaction needed, amplifying requests 3000x

## Impact Explanation
This vulnerability enables a **High Severity** resource exhaustion attack per Aptos bug bounty criteria ("Validator node slowdowns"):

**Resource Amplification:**
- Normal operation: 1000 transactions in 1 request (with 40MB limit)
- Under attack: 1000 transactions require 1000 requests (with 1-byte limit)
- Each request incurs full overhead: validation, iterator creation, storage reads, serialization, proof generation, network transmission, and LRU cache operations

**Affected Nodes:**
- All nodes running storage service (validators and fullnodes)
- Multiple malicious peers can coordinate to amplify impact
- Attack bypasses application-level protections (request moderator only rejects invalid data ranges)

**Realistic Damage:**
- Validator CPU consumption increases proportionally to request amplification
- Network bandwidth wasted on excessive small responses
- Storage I/O amplification from repeated iterator creation
- LRU cache pollution with tiny chunks
- Legitimate sync requests may experience delays

## Likelihood Explanation
**High Likelihood** - Attack is trivial to execute:
- No special privileges required (any network peer)
- Single parameter manipulation (`max_response_bytes = 1`)
- No cryptographic knowledge needed
- Difficult to distinguish from legitimate but misconfigured clients
- Not detected by unhealthy peer tracking (requests are "valid")

**Attacker Requirements:**
- Network connectivity to storage service
- Knowledge of valid transaction version ranges (publicly available)
- Basic understanding of storage service protocol

**Detection Difficulty:**
- Requests appear valid (proper version ranges, authenticated peer)
- Only suspicious pattern is unusual `max_response_bytes` value
- No existing metrics track this parameter

## Recommendation
Implement minimum validation for `max_response_bytes` in the request moderator:

```rust
// In state-sync/storage-service/server/src/moderator.rs
// Add to validate_request() function before can_service check:

// Define minimum response bytes (e.g., 64KB to ensure reasonable chunking)
const MIN_RESPONSE_BYTES: u64 = 64 * 1024; // 64 KB

pub fn validate_request(
    &self,
    peer_network_id: &PeerNetworkId,
    request: &StorageServiceRequest,
) -> Result<(), Error> {
    // ... existing validation code ...
    
    // Validate max_response_bytes for v2 requests
    if let DataRequest::GetTransactionDataWithProof(req) = &request.data_request {
        if req.max_response_bytes < MIN_RESPONSE_BYTES {
            // Increment invalid request count
            let mut unhealthy_peer_state = self
                .unhealthy_peer_states
                .entry(*peer_network_id)
                .or_insert_with(|| {
                    UnhealthyPeerState::new(
                        self.storage_service_config.max_invalid_requests_per_peer,
                        self.storage_service_config.min_time_to_ignore_peers_secs,
                        self.time_service.clone(),
                    )
                });
            unhealthy_peer_state.increment_invalid_request_count(peer_network_id);
            
            return Err(Error::InvalidRequest(format!(
                "max_response_bytes ({}) below minimum ({})",
                req.max_response_bytes, MIN_RESPONSE_BYTES
            )));
        }
    }
    
    // ... rest of validation ...
}
```

**Alternative/Additional Mitigations:**
1. Add metrics tracking `max_response_bytes` distribution
2. Implement per-peer request rate limiting at application layer
3. Add warning logs for suspiciously small `max_response_bytes` values
4. Document expected `max_response_bytes` ranges in protocol specification

## Proof of Concept

```rust
// Test demonstrating resource amplification
// Add to state-sync/storage-service/server/src/tests/

#[tokio::test]
async fn test_max_response_bytes_resource_exhaustion() {
    use aptos_storage_service_types::requests::DataRequest;
    
    // Setup test environment with 1000 transactions
    let (mut mock_client, service, _) = MockClient::new(None, None);
    utils::update_storage_server_summary(&mut mock_client, 1000, 1000);
    
    // Normal request: should return many transactions in one request
    let normal_request = DataRequest::get_transaction_data_with_proof(
        1000, // proof_version
        0,    // start_version  
        999,  // end_version (1000 transactions)
        false,
        20 * 1024 * 1024, // 20MB - reasonable size
    );
    let response = service.get_response_for_request(normal_request).await.unwrap();
    let normal_count = response.get_transaction_list_with_proof().unwrap().transactions.len();
    assert!(normal_count > 100, "Normal request should return many transactions");
    
    // Attack request: same range but with 1 byte limit
    let attack_request = DataRequest::get_transaction_data_with_proof(
        1000,
        0,
        999,
        false,
        1, // 1 byte - malicious value
    );
    let response = service.get_response_for_request(attack_request).await.unwrap();
    let attack_count = response.get_transaction_list_with_proof().unwrap().transactions.len();
    assert_eq!(attack_count, 1, "Attack request should return exactly 1 transaction");
    
    // Demonstrate amplification
    let amplification_factor = 1000 / attack_count;
    println!("Amplification factor: {}x", amplification_factor);
    assert!(amplification_factor > 100, "Attack causes excessive request amplification");
}
```

**Notes:**
- This vulnerability breaks invariant #9: "All operations must respect gas, storage, and computational limits"
- The lack of validation allows bypassing the efficient chunking mechanism designed to limit resource usage
- While HAProxy provides network-level rate limiting, application-level validation is essential for protocol correctness
- The similar parameters `max_num_output_reductions` have documented limits, but `max_response_bytes` has none

### Citations

**File:** state-sync/storage-service/types/src/requests.rs (L425-431)
```rust
pub struct GetTransactionDataWithProofRequest {
    pub transaction_data_request_type: TransactionDataRequestType, // The type of transaction data to request
    pub proof_version: u64,      // The version the proof should be relative to
    pub start_version: u64,      // The starting version of the data
    pub end_version: u64,        // The ending version of the data (inclusive)
    pub max_response_bytes: u64, // The max number of bytes to return in the response
}
```

**File:** state-sync/storage-service/server/src/moderator.rs (L134-196)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** state-sync/storage-service/server/src/storage.rs (L1140-1153)
```rust
    fn get_transaction_data_with_proof(
        &self,
        transaction_data_with_proof_request: &GetTransactionDataWithProofRequest,
    ) -> aptos_storage_service_types::Result<TransactionDataWithProofResponse, Error> {
        // Extract the data versions from the request
        let proof_version = transaction_data_with_proof_request.proof_version;
        let start_version = transaction_data_with_proof_request.start_version;
        let end_version = transaction_data_with_proof_request.end_version;

        // Calculate the max response size to use
        let max_response_bytes = min(
            transaction_data_with_proof_request.max_response_bytes,
            self.config.max_network_chunk_bytes_v2,
        );
```

**File:** state-sync/storage-service/server/src/storage.rs (L1399-1412)
```rust
    pub fn data_items_fits_in_response(
        &self,
        always_allow_first_item: bool,
        serialized_data_size: u64,
    ) -> bool {
        if always_allow_first_item && self.num_items_fetched == 0 {
            true // We always include at least one item
        } else {
            let new_serialized_data_size = self
                .serialized_data_size
                .saturating_add(serialized_data_size);
            new_serialized_data_size < self.max_response_size
        }
    }
```
