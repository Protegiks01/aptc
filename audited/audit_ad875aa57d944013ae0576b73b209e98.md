# Audit Report

## Title
Race Condition in VM Validator Cache Invalidation Leads to Consensus Divergence During Epoch Reconfigurations

## Summary
The `reset_state_view()` method in `vm-validator/src/vm_validator.rs` performs partial cache invalidation, updating only the state view while leaving the environment configuration (containing feature flags, gas parameters, and deserializer configs) stale. This creates a race condition window during epoch reconfigurations where validators operate with inconsistent state, leading to different transaction validation outcomes and consensus divergence.

## Finding Description

The vulnerability exists in the `notify_commit()` method which handles state updates after block commits. [1](#0-0) 

When the state view version increases linearly (line 92), the code calls `reset_state_view()` instead of `reset_all()`. The `reset_state_view()` implementation only updates the state view pointer: [2](#0-1) 

This leaves the `environment` field unchanged, which contains critical configuration: [3](#0-2) 

The environment includes feature flags, gas parameters, and VM configuration that are fetched from on-chain state during initialization. When feature flags change via governance proposals (a normal occurrence in Aptos), the following race condition occurs:

**Thread 1 (Commit Handler - spawned separately):** [4](#0-3) [5](#0-4) 

**Thread 2 (Reconfig Handler - spawned via bounded executor):** [6](#0-5) [7](#0-6) 

During the window between Thread 1 updating the state view and Thread 2 updating the environment, validators have:
- **New state view**: Points to post-reconfiguration state with updated on-chain configs
- **Old environment**: Contains pre-reconfiguration feature flags and deserializer configs

When validating transactions during this window, the AptosVM is created using the stale environment: [8](#0-7) 

Module deserialization uses the stale deserializer config from the environment: [9](#0-8) 

The deserializer config is created from feature flags: [10](#0-9) 

**Attack Scenario:**

1. Governance proposal updates `MAX_BINARY_FORMAT_VERSION` from 6 to 7 at epoch boundary
2. Block N+1 contains both the epoch change and a new module compiled with format version 7
3. Validator A receives commit notification, calls `reset_state_view()`, state view updated but environment still has max version 6
4. Validator A attempts to validate transaction using the new module
5. Deserialization fails or interprets bytecode incorrectly due to version mismatch
6. Validator B's reconfig event arrives immediately, calls `restart()` â†’ `reset_all()`, environment updated to max version 7
7. Validator B successfully validates the same transaction
8. **Result**: Validators disagree on transaction validity, breaking consensus safety

## Impact Explanation

This is a **Critical Severity** vulnerability per Aptos bug bounty criteria:

- **Consensus/Safety Violation**: Different validators produce different validation results for identical transactions, violating the deterministic execution invariant
- **Network Partition**: Can cause chain split requiring manual intervention or hardfork to resolve
- **Breaks Multiple Invariants**:
  - Invariant #1 (Deterministic Execution): Validators produce different outcomes
  - Invariant #2 (Consensus Safety): Can lead to chain split under < 1/3 Byzantine nodes

The severity is amplified because:
- Feature flag updates happen regularly through governance
- The race window exists on every epoch transition
- All validators are affected simultaneously
- Recovery requires coordinated manual intervention

## Likelihood Explanation

**Likelihood: HIGH**

The vulnerability triggers automatically under normal operations:
- Epoch reconfigurations happen regularly (every few hours on mainnet)
- Governance proposals update feature flags frequently for protocol upgrades
- The two notification channels (`mempool_listener` and `mempool_reconfig_events`) are processed independently with no ordering guarantees
- The race window duration depends on async task scheduling, making it non-deterministic
- Higher network load increases likelihood of hitting the race condition

The vulnerability does not require:
- Malicious actors or special privileges
- Specific timing attacks
- Coordination between validators
- Unusual network conditions

## Recommendation

Replace `reset_state_view()` with `reset_all()` in the linear version progression case to ensure environment consistency:

```rust
fn notify_commit(&mut self) {
    let db_state_view = self.db_state_view();

    // On commit, we need to update the state view so that we can see the latest resources.
    let base_view_id = self.state.state_view_id();
    let new_view_id = db_state_view.id();
    match (base_view_id, new_view_id) {
        (
            StateViewId::TransactionValidation {
                base_version: old_version,
            },
            StateViewId::TransactionValidation {
                base_version: new_version,
            },
        ) => {
            // Always do full reset to ensure environment stays in sync
            if old_version <= new_version {
                self.state.reset_all(db_state_view.into());  // CHANGED: was reset_state_view
            }
        },
        // if the version is incompatible, we flush the cache
        _ => self.state.reset_all(db_state_view.into()),
    }
}
```

**Alternative approach** (if performance is critical): Add environment versioning to detect staleness:

1. Add environment hash/version to `CachedModuleView`
2. On `reset_state_view()`, check if on-chain configs changed
3. If configs changed, call `reset_all()` instead
4. Otherwise, allow partial update for pure state-only commits

## Proof of Concept

```rust
// Rust reproduction steps (integration test)

#[tokio::test]
async fn test_race_condition_consensus_divergence() {
    // 1. Setup: Create two validator nodes with identical initial state
    let validator_a = setup_validator_node();
    let validator_b = setup_validator_node();
    
    // 2. Submit governance proposal to update MAX_BINARY_FORMAT_VERSION
    let proposal = create_feature_flag_proposal(
        FeatureFlag::BINARY_FORMAT_VERSION, 
        7  // upgrade from 6 to 7
    );
    execute_governance_proposal(proposal);
    
    // 3. Deploy module using format version 7
    let module_v7 = compile_module_with_format_version(7);
    let deploy_txn = create_module_publish_txn(module_v7);
    
    // 4. Trigger epoch change (block containing both reconfig and module)
    let epoch_block = create_block_with_txns(vec![
        epoch_change_txn(),
        deploy_txn.clone(),
    ]);
    commit_block(epoch_block);
    
    // 5. Validator A: Process commit notification immediately (hits race window)
    validator_a.handle_commit_notification_sync();  // calls reset_state_view()
    
    // 6. Validator A: Try to validate transaction using new module
    let use_module_txn = create_txn_calling_module(module_v7.id());
    let result_a = validator_a.validate_transaction(use_module_txn.clone());
    
    // 7. Validator B: Process both commit AND reconfig (no race)
    validator_b.handle_commit_notification_sync();
    validator_b.handle_reconfig_sync();  // calls restart() -> reset_all()
    
    // 8. Validator B: Validate same transaction
    let result_b = validator_b.validate_transaction(use_module_txn);
    
    // 9. Assert: Validators disagree (consensus divergence)
    assert_ne!(
        result_a.status(), 
        result_b.status(),
        "Validators should disagree due to stale environment on A"
    );
    
    // Expected: Validator A rejects (deserialization error with old config)
    // Expected: Validator B accepts (correct config)
}
```

**Notes**

The vulnerability is particularly insidious because:

1. **Module cache version checks are insufficient**: While `get_module_or_build_with` checks module versions, it still uses the stale environment's deserializer config when fetching new modules from the updated state view.

2. **Silent failures**: If deserialization succeeds with wrong config, validators may silently diverge without obvious errors.

3. **Affects all feature-gated behavior**: Beyond deserialization, the stale environment affects all feature flag checks during validation, gas metering, and VM configuration.

4. **Production occurrence**: This likely manifests as intermittent "mysterious" validation disagreements during epoch transitions that resolve themselves after reconfig completes.

### Citations

**File:** vm-validator/src/vm_validator.rs (L76-99)
```rust
    fn notify_commit(&mut self) {
        let db_state_view = self.db_state_view();

        // On commit, we need to update the state view so that we can see the latest resources.
        let base_view_id = self.state.state_view_id();
        let new_view_id = db_state_view.id();
        match (base_view_id, new_view_id) {
            (
                StateViewId::TransactionValidation {
                    base_version: old_version,
                },
                StateViewId::TransactionValidation {
                    base_version: new_version,
                },
            ) => {
                // if the state view forms a linear history, just update the state view
                if old_version <= new_version {
                    self.state.reset_state_view(db_state_view.into());
                }
            },
            // if the version is incompatible, we flush the cache
            _ => self.state.reset_all(db_state_view.into()),
        }
    }
```

**File:** vm-validator/src/vm_validator.rs (L155-164)
```rust
        let result = std::panic::catch_unwind(move || {
            let vm_validator_locked = vm_validator.lock().unwrap();

            use aptos_vm::VMValidator;
            let vm = AptosVM::new(&vm_validator_locked.state.environment);
            vm.validate_transaction(
                txn,
                &vm_validator_locked.state.state_view,
                &vm_validator_locked.state,
            )
```

**File:** aptos-move/aptos-resource-viewer/src/module_view.rs (L121-125)
```rust
    /// Resets the state view snapshot to the new one. Does not invalidate the module cache, nor
    /// the VM.
    pub fn reset_state_view(&mut self, state_view: S) {
        self.state_view = state_view;
    }
```

**File:** aptos-move/aptos-resource-viewer/src/module_view.rs (L140-159)
```rust
    fn try_override_bytes_and_deserialized_into_compiled_module_with_ext(
        &self,
        mut state_value: StateValue,
        address: &AccountAddress,
        name: &IdentStr,
    ) -> VMResult<(CompiledModule, Arc<AptosModuleExtension>)> {
        // TODO: remove this once framework on mainnet is using the new option module
        if let Some(bytes) = self
            .runtime_environment()
            .get_module_bytes_override(address, name)
        {
            state_value.set_bytes(bytes);
        }
        let compiled_module = self
            .environment
            .runtime_environment()
            .deserialize_into_compiled_module(state_value.bytes())?;
        let extension = Arc::new(AptosModuleExtension::new(state_value));
        Ok((compiled_module, extension))
    }
```

**File:** aptos-move/aptos-vm-environment/src/environment.rs (L167-209)
```rust
    /// Specifies the chain, i.e., testnet, mainnet, etc.
    chain_id: ChainId,

    /// Set of features enabled in this environment.
    features: Features,
    /// Set of timed features enabled in this environment.
    timed_features: TimedFeatures,

    /// The prepared verification key for keyless accounts. Optional because it might not be set
    /// on-chain or might fail to parse.
    keyless_pvk: Option<PreparedVerifyingKey<Bn254>>,
    /// Some keyless configurations which are not frequently updated.
    keyless_configuration: Option<Configuration>,

    /// Gas feature version used in this environment.
    gas_feature_version: u64,
    /// Gas parameters used in this environment. Error is stored if gas parameters were not found
    /// on-chain.
    gas_params: Result<AptosGasParameters, String>,
    /// Storage gas parameters used in this environment. Error is stored if gas parameters were not
    /// found on-chain.
    storage_gas_params: Result<StorageGasParameters, String>,

    /// The runtime environment, containing global struct type and name caches, and VM configs.
    runtime_environment: RuntimeEnvironment,

    /// True if we need to inject create signer native for government proposal simulation.
    /// Deprecated, and will be removed in the future.
    #[deprecated]
    inject_create_signer_for_gov_sim: bool,

    /// Hash of configs used in this environment. Used to be able to compare environments.
    hash: [u8; 32],
    /// Bytes of serialized verifier config. Used to detect any changes in verification configs.
    /// We stored bytes instead of hash because config is expected to be smaller than the crypto
    /// hash itself.
    verifier_bytes: Vec<u8>,

    /// If true, runtime checks such as paranoid may not be performed during speculative execution
    /// of transactions, but instead once at post-commit time based on the collected execution
    /// trace. This is a node config and will never change for the lifetime of the environment.
    async_runtime_checks_enabled: bool,
}
```

**File:** mempool/src/shared_mempool/coordinator.rs (L152-162)
```rust
    tokio::spawn(async move {
        while let Some(commit_notification) = mempool_listener.next().await {
            handle_commit_notification(
                &mempool,
                &mempool_validator,
                &use_case_history,
                commit_notification,
                &num_committed_txns_received_since_peers_updated,
            );
        }
    });
```

**File:** mempool/src/shared_mempool/coordinator.rs (L229-265)
```rust
fn handle_commit_notification<TransactionValidator>(
    mempool: &Arc<Mutex<CoreMempool>>,
    mempool_validator: &Arc<RwLock<TransactionValidator>>,
    use_case_history: &Arc<Mutex<UseCaseHistory>>,
    msg: MempoolCommitNotification,
    num_committed_txns_received_since_peers_updated: &Arc<AtomicU64>,
) where
    TransactionValidator: TransactionValidation,
{
    debug!(
        block_timestamp_usecs = msg.block_timestamp_usecs,
        num_committed_txns = msg.transactions.len(),
        LogSchema::event_log(LogEntry::StateSyncCommit, LogEvent::Received),
    );

    // Process and time committed user transactions.
    let start_time = Instant::now();
    counters::mempool_service_transactions(
        counters::COMMIT_STATE_SYNC_LABEL,
        msg.transactions.len(),
    );
    num_committed_txns_received_since_peers_updated
        .fetch_add(msg.transactions.len() as u64, Ordering::Relaxed);
    process_committed_transactions(
        mempool,
        use_case_history,
        msg.transactions,
        msg.block_timestamp_usecs,
    );
    mempool_validator.write().notify_commit();
    let latency = start_time.elapsed();
    counters::mempool_service_latency(
        counters::COMMIT_STATE_SYNC_LABEL,
        counters::REQUEST_SUCCESS_LABEL,
        latency,
    );
}
```

**File:** mempool/src/shared_mempool/coordinator.rs (L268-291)
```rust
async fn handle_mempool_reconfig_event<NetworkClient, TransactionValidator, ConfigProvider>(
    smp: &mut SharedMempool<NetworkClient, TransactionValidator>,
    bounded_executor: &BoundedExecutor,
    config_update: OnChainConfigPayload<ConfigProvider>,
) where
    NetworkClient: NetworkClientInterface<MempoolSyncMsg> + 'static,
    TransactionValidator: TransactionValidation + 'static,
    ConfigProvider: OnChainConfigProvider,
{
    info!(LogSchema::event_log(
        LogEntry::ReconfigUpdate,
        LogEvent::Received
    ));
    let _timer =
        counters::task_spawn_latency_timer(counters::RECONFIG_EVENT_LABEL, counters::SPAWN_LABEL);

    bounded_executor
        .spawn(tasks::process_config_update(
            config_update,
            smp.validator.clone(),
            smp.broadcast_within_validator_network.clone(),
        ))
        .await;
}
```

**File:** mempool/src/shared_mempool/tasks.rs (L762-794)
```rust
pub(crate) async fn process_config_update<V, P>(
    config_update: OnChainConfigPayload<P>,
    validator: Arc<RwLock<V>>,
    broadcast_within_validator_network: Arc<RwLock<bool>>,
) where
    V: TransactionValidation,
    P: OnChainConfigProvider,
{
    info!(LogSchema::event_log(
        LogEntry::ReconfigUpdate,
        LogEvent::Process
    ));

    if let Err(e) = validator.write().restart() {
        counters::VM_RECONFIG_UPDATE_FAIL_COUNT.inc();
        error!(LogSchema::event_log(LogEntry::ReconfigUpdate, LogEvent::VMUpdateFail).error(&e));
    }

    let consensus_config: anyhow::Result<OnChainConsensusConfig> = config_update.get();
    match consensus_config {
        Ok(consensus_config) => {
            *broadcast_within_validator_network.write() =
                !consensus_config.quorum_store_enabled() && !consensus_config.is_dag_enabled()
        },
        Err(e) => {
            error!(
                "Failed to read on-chain consensus config, keeping value broadcast_within_validator_network={}: {}",
                *broadcast_within_validator_network.read(),
                e
            );
        },
    }
}
```

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L137-142)
```rust
pub fn aptos_prod_deserializer_config(features: &Features) -> DeserializerConfig {
    DeserializerConfig::new(
        features.get_max_binary_format_version(),
        features.get_max_identifier_size(),
    )
}
```
