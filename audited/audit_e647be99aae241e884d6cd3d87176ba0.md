# Audit Report

## Title
Race Condition in State Sync Stream Initialization Causes Version-Epoch Mismatch and Liveness Degradation

## Summary
The `get_highest_synced_version_and_epoch()` function performs two non-atomic reads from different storage components during the consensus two-phase commit window, allowing the `highest_synced_version` and `highest_synced_epoch` to originate from inconsistent storage states. This violates the critical invariant that the known epoch must contain the known version + 1, causing stream initialization failures, verification errors, and temporary node unavailability.

## Finding Description

The vulnerability exists in the state sync driver's continuous syncer component. When initializing a new data stream, the system reads the highest synced version and epoch from storage to determine where to resume synchronization. [1](#0-0) 

These two reads are not atomic and query different underlying storage components:

1. **`fetch_pre_committed_version`** reads from the state store's current state: [2](#0-1) 

2. **`fetch_latest_epoch_state`** reads from the ledger metadata database: [3](#0-2) 

The Aptos consensus pipeline uses a two-phase commit protocol where these storage components are updated sequentially:

**Phase 1 - Pre-commit**: Updates the state store's buffered state: [4](#0-3) [5](#0-4) 

**Phase 2 - Commit**: Updates the ledger metadata database: [6](#0-5) 

**The Race Window**: Between pre_commit_ledger completion and commit_ledger completion, concurrent reads can observe:
- **New version** from the state store (already updated by pre_commit)
- **Old epoch** from the ledger metadata DB (not yet updated by commit_ledger)

This violates the documented streaming client invariant: [7](#0-6) 

When the stream engine initializes with mismatched parameters, it stores incorrect epoch tracking state: [8](#0-7) 

The speculative stream state is also initialized with the old epoch state but new version: [9](#0-8) 

When transaction data arrives, the system attempts to verify ledger info signatures using the mismatched epoch state: [10](#0-9) [11](#0-10) 

Since the validator set in the old epoch state doesn't match the validators for the new epoch's transactions, signature verification fails, causing the stream to reset and retry.

## Impact Explanation

This vulnerability constitutes **High Severity** according to the Aptos bug bounty criteria:

1. **Validator node slowdowns**: The race condition causes repeated stream initialization failures, verification errors, and stream resets. During periods of frequent epoch transitions or high commit rates, this significantly degrades synchronization performance and can cause temporary node unavailability for state sync operations.

2. **Significant protocol violations**: The invariant documented in the streaming client interface is violated - the system initializes streams where `known_epoch` does NOT contain `known_version + 1`, breaking the fundamental contract between the state sync driver and data streaming service.

While this is primarily a liveness issue (the system fails safe through verification rejection), the performance impact on validator nodes and full nodes during synchronization, combined with the clear violation of documented protocol invariants, qualifies this as High Severity rather than Medium.

The issue does NOT rise to Critical Severity because:
- No consensus safety violations occur (verification correctly rejects invalid data)
- No funds are at risk
- The system recovers automatically through stream resets
- It's a temporary rather than permanent liveness failure

## Likelihood Explanation

**Likelihood: Medium**

The race condition occurs during every consensus commit when the two-phase commit protocol executes. The race window is small (microseconds to milliseconds between pre_commit and commit_ledger completion), but the frequency is high:

1. **Frequency**: Every block commit creates a race window (potentially thousands per hour)
2. **Window Size**: Small but non-zero duration between phase 1 and phase 2 completion
3. **Concurrent Access**: The continuous syncer or other state sync components may read during this window
4. **Amplification**: More likely during epoch transitions when version and epoch values change simultaneously

The probability increases under:
- High transaction throughput
- Frequent epoch changes
- Multi-core systems with concurrent commit and sync operations
- Storage system latencies that widen the race window

## Recommendation

**Solution 1: Atomic Snapshot Read (Preferred)**

Modify the storage interface to provide an atomic snapshot read operation that guarantees both version and epoch come from the same consistent state:

```rust
// In storage-interface/src/lib.rs
pub trait DbReader {
    /// Returns the highest synced version and epoch atomically
    fn get_highest_synced_version_and_epoch(&self) -> Result<(Version, Epoch)>;
}

// In aptosdb/src/db/aptosdb_reader.rs
fn get_highest_synced_version_and_epoch(&self) -> Result<(Version, Epoch)> {
    // Take a consistent snapshot by reading both from the same source
    let current_state = self.state_store.current_state_locked();
    let version = current_state.version();
    
    // Get epoch from the same consistent state
    let ledger_info = self.ledger_db.metadata_db().get_latest_ledger_info()?;
    let epoch = match ledger_info.ledger_info().next_epoch_state() {
        Some(epoch_state) => epoch_state.epoch,
        None => self.ledger_db.metadata_db().get_epoch_state(
            ledger_info.ledger_info().epoch()
        )?.epoch,
    };
    
    Ok((version?, epoch))
}
```

**Solution 2: Wait for Commit Completion**

Ensure commit_ledger completes before allowing concurrent reads by strengthening synchronization in the pipeline or adding a post-commit barrier.

**Solution 3: Use Committed Version Only**

Modify the continuous syncer to use only committed data (from ledger metadata DB) rather than pre-committed data from state store, accepting slightly older but consistent snapshots.

## Proof of Concept

```rust
// Test demonstrating the race condition
// File: state-sync/state-sync-driver/src/tests/continuous_syncer_race.rs

#[tokio::test]
async fn test_version_epoch_race_condition() {
    use std::sync::{Arc, Barrier};
    use std::thread;
    
    let storage = create_test_storage();
    let executor = create_test_executor();
    let continuous_syncer = create_test_continuous_syncer(storage.clone());
    
    // Barrier to synchronize threads
    let barrier = Arc::new(Barrier::new(2));
    let barrier_clone = barrier.clone();
    
    // Thread 1: Simulate consensus commit (two-phase)
    let storage_clone = storage.clone();
    let commit_handle = thread::spawn(move || {
        // Phase 1: pre_commit (updates state store)
        executor.pre_commit_ledger(create_test_chunk_with_epoch_change()).unwrap();
        
        // Wait here to create race window
        barrier_clone.wait();
        std::thread::sleep(std::time::Duration::from_millis(10));
        
        // Phase 2: commit_ledger (updates metadata DB)
        executor.commit_ledger(version, Some(&ledger_info), None).unwrap();
    });
    
    // Thread 2: Read version and epoch during race window
    let read_handle = thread::spawn(move || {
        barrier.wait();
        
        // This read happens between pre_commit and commit_ledger
        let (version, epoch) = continuous_syncer
            .get_highest_synced_version_and_epoch()
            .unwrap();
        
        // Verify the race condition: version is ahead of epoch
        let epoch_ending_version = get_epoch_ending_version(epoch);
        assert!(version > epoch_ending_version, 
            "Race condition detected: version {} is in next epoch but epoch {} is old",
            version, epoch);
        
        (version, epoch)
    });
    
    commit_handle.join().unwrap();
    let (version, epoch) = read_handle.join().unwrap();
    
    // Attempt to initialize stream with mismatched version/epoch
    let stream_result = continuous_syncer.streaming_client
        .continuously_stream_transactions(version, epoch, false, None)
        .await;
    
    // Stream should eventually fail verification due to epoch mismatch
    assert!(stream_verification_fails_with_mismatched_epoch(stream_result));
}
```

## Notes

This vulnerability is a race condition inherent in the system's architecture where storage updates happen in multiple phases across different storage components. The issue manifests during normal operation without requiring malicious input. The fix requires either architectural changes to ensure atomic reads or synchronization improvements in the commit protocol. The impact is measurable but not catastrophic - nodes experience degraded synchronization performance and temporary unavailability rather than data corruption or consensus violations.

### Citations

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L99-180)
```rust
    /// Initializes an active data stream so that we can begin to process notifications
    async fn initialize_active_data_stream(
        &mut self,
        consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
    ) -> Result<(), Error> {
        // Reset the chunk executor to flush any invalid state currently held in-memory
        self.storage_synchronizer.reset_chunk_executor()?;

        // Fetch the highest synced version and epoch (in storage)
        let (highest_synced_version, highest_synced_epoch) =
            self.get_highest_synced_version_and_epoch()?;

        // Fetch the highest epoch state (in storage)
        let highest_epoch_state = utils::fetch_latest_epoch_state(self.storage.clone())?;

        // Fetch the consensus sync request target (if there is one)
        let sync_request_target = consensus_sync_request
            .lock()
            .as_ref()
            .and_then(|sync_request| sync_request.get_sync_target());

        // Initialize a new active data stream
        let active_data_stream = match self.get_continuous_syncing_mode() {
            ContinuousSyncingMode::ApplyTransactionOutputs => {
                self.streaming_client
                    .continuously_stream_transaction_outputs(
                        highest_synced_version,
                        highest_synced_epoch,
                        sync_request_target,
                    )
                    .await?
            },
            ContinuousSyncingMode::ExecuteTransactions => {
                self.streaming_client
                    .continuously_stream_transactions(
                        highest_synced_version,
                        highest_synced_epoch,
                        false,
                        sync_request_target,
                    )
                    .await?
            },
            ContinuousSyncingMode::ExecuteTransactionsOrApplyOutputs => {
                if self.output_fallback_handler.in_fallback_mode() {
                    metrics::set_gauge(
                        &metrics::DRIVER_FALLBACK_MODE,
                        ExecutingComponent::ContinuousSyncer.get_label(),
                        1,
                    );
                    self.streaming_client
                        .continuously_stream_transaction_outputs(
                            highest_synced_version,
                            highest_synced_epoch,
                            sync_request_target,
                        )
                        .await?
                } else {
                    metrics::set_gauge(
                        &metrics::DRIVER_FALLBACK_MODE,
                        ExecutingComponent::ContinuousSyncer.get_label(),
                        0,
                    );
                    self.streaming_client
                        .continuously_stream_transactions_or_outputs(
                            highest_synced_version,
                            highest_synced_epoch,
                            false,
                            sync_request_target,
                        )
                        .await?
                }
            },
        };
        self.speculative_stream_state = Some(SpeculativeStreamState::new(
            highest_epoch_state,
            None,
            highest_synced_version,
        ));
        self.active_data_stream = Some(active_data_stream);

        Ok(())
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L267-272)
```rust
    fn get_highest_synced_version_and_epoch(&self) -> Result<(Version, Epoch), Error> {
        let highest_synced_version = utils::fetch_pre_committed_version(self.storage.clone())?;
        let highest_synced_epoch = utils::fetch_latest_epoch_state(self.storage.clone())?.epoch;

        Ok((highest_synced_version, highest_synced_epoch))
    }
```

**File:** state-sync/state-sync-driver/src/continuous_syncer.rs (L423-467)
```rust
    /// Verifies the given ledger info to be used as a transaction or transaction
    /// output chunk proof. If verification fails, the active stream is terminated.
    async fn verify_proof_ledger_info(
        &mut self,
        consensus_sync_request: Arc<Mutex<Option<ConsensusSyncRequest>>>,
        notification_id: NotificationId,
        ledger_info_with_signatures: &LedgerInfoWithSignatures,
    ) -> Result<(), Error> {
        // If we're syncing to a specific target, verify the ledger info isn't too high
        let sync_request_target = consensus_sync_request
            .lock()
            .as_ref()
            .and_then(|sync_request| sync_request.get_sync_target());
        if let Some(sync_request_target) = sync_request_target {
            let sync_request_version = sync_request_target.ledger_info().version();
            let proof_version = ledger_info_with_signatures.ledger_info().version();
            if sync_request_version < proof_version {
                self.reset_active_stream(Some(NotificationAndFeedback::new(
                    notification_id,
                    NotificationFeedback::PayloadProofFailed,
                )))
                .await?;
                return Err(Error::VerificationError(format!(
                    "Proof version is higher than the sync target. Proof version: {:?}, sync version: {:?}.",
                    proof_version, sync_request_version
                )));
            }
        }

        // Verify the ledger info state and signatures
        if let Err(error) = self
            .get_speculative_stream_state()?
            .verify_ledger_info_with_signatures(ledger_info_with_signatures)
        {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::PayloadProofFailed,
            )))
            .await?;
            Err(error)
        } else {
            Ok(())
        }
    }

```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L137-141)
```rust
    fn get_pre_committed_version(&self) -> Result<Option<Version>> {
        gauged_api("get_pre_committed_version", || {
            Ok(self.state_store.current_state_locked().version())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L696-707)
```rust
    fn get_latest_epoch_state(&self) -> Result<EpochState> {
        gauged_api("get_latest_epoch_state", || {
            let latest_ledger_info = self.ledger_db.metadata_db().get_latest_ledger_info()?;
            match latest_ledger_info.ledger_info().next_epoch_state() {
                Some(epoch_state) => Ok(epoch_state.clone()),
                None => self
                    .ledger_db
                    .metadata_db()
                    .get_epoch_state(latest_ledger_info.ledger_info().epoch()),
            }
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L44-76)
```rust
    fn pre_commit_ledger(&self, chunk: ChunkToCommit, sync_commit: bool) -> Result<()> {
        gauged_api("pre_commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .pre_commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["pre_commit_ledger"]);

            chunk
                .state_summary
                .latest()
                .global_state_summary
                .log_generation("db_save");

            self.pre_commit_validation(&chunk)?;
            let _new_root_hash =
                self.calculate_and_commit_ledger_and_state_kv(&chunk, self.skip_index_and_usage)?;

            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["save_transactions__others"]);

            self.state_store.buffered_state().lock().update(
                chunk.result_ledger_state_with_summary(),
                chunk.estimated_total_state_updates(),
                sync_commit || chunk.is_reconfig,
            )?;

            Ok(())
        })
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L78-112)
```rust
    fn commit_ledger(
        &self,
        version: Version,
        ledger_info_with_sigs: Option<&LedgerInfoWithSignatures>,
        chunk_opt: Option<ChunkToCommit>,
    ) -> Result<()> {
        gauged_api("commit_ledger", || {
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
            // Consensus and state sync must hand over to each other after all pending execution and
            // committing complete.
            let _lock = self
                .commit_lock
                .try_lock()
                .expect("Concurrent committing detected.");
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["commit_ledger"]);

            let old_committed_ver = self.get_and_check_commit_range(version)?;

            let mut ledger_batch = SchemaBatch::new();
            // Write down LedgerInfo if provided.
            if let Some(li) = ledger_info_with_sigs {
                self.check_and_put_ledger_info(version, li, &mut ledger_batch)?;
            }
            // Write down commit progress
            ledger_batch.put::<DbMetadataSchema>(
                &DbMetadataKey::OverallCommitProgress,
                &DbMetadataValue::Version(version),
            )?;
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;

            // Notify the pruners, invoke the indexer, and update in-memory ledger info.
            self.post_commit(old_committed_ver, version, ledger_info_with_sigs, chunk_opt)
        })
    }
```

**File:** storage/aptosdb/src/state_store/buffered_state.rs (L156-175)
```rust
    pub fn update(
        &mut self,
        new_state: LedgerStateWithSummary,
        estimated_new_items: usize,
        sync_commit: bool,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["buffered_state___update"]);

        let old_state = self.current_state_locked().clone();
        assert!(new_state.is_descendant_of(&old_state));

        self.estimated_items += estimated_new_items;
        let version = new_state.last_checkpoint().version();

        let last_checkpoint = new_state.last_checkpoint().clone();
        // Commit state only if there is a new checkpoint, eases testing and make estimated
        // buffer size a tad more realistic.
        let checkpoint_to_commit_opt =
            (old_state.next_version() < last_checkpoint.next_version()).then_some(last_checkpoint);
        *self.current_state_locked() = new_state;
```

**File:** state-sync/data-streaming-service/src/streaming_client.rs (L86-92)
```rust
    /// Continuously streams transaction outputs with proofs as the blockchain
    /// grows. The stream starts at `known_version + 1` (inclusive) and
    /// `known_epoch`, where the `known_epoch` is expected to be the epoch
    /// that contains `known_version + 1`, i.e., any epoch change at
    /// `known_version` must be noted by the client.
    /// Transaction output proof versions are tied to ledger infos within the
    /// same epoch, otherwise epoch ending ledger infos will signify epoch changes.
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L424-480)
```rust
impl ContinuousTransactionStreamEngine {
    fn new(
        data_streaming_config: DataStreamingServiceConfig,
        stream_request: &StreamRequest,
    ) -> Result<Self, Error> {
        // Extract the target version, next version, and next epoch
        let (target_version, next_version, next_epoch) = match stream_request {
            StreamRequest::ContinuouslyStreamTransactions(request) => {
                let target_version = Self::get_target_version(&request.target);
                let (next_version, next_epoch) = Self::calculate_next_version_and_epoch(
                    request.known_version,
                    request.known_epoch,
                )?;
                (target_version, next_version, next_epoch)
            },
            StreamRequest::ContinuouslyStreamTransactionOutputs(request) => {
                let target_version = Self::get_target_version(&request.target);
                let (next_version, next_epoch) = Self::calculate_next_version_and_epoch(
                    request.known_version,
                    request.known_epoch,
                )?;
                (target_version, next_version, next_epoch)
            },
            StreamRequest::ContinuouslyStreamTransactionsOrOutputs(request) => {
                let target_version = Self::get_target_version(&request.target);
                let (next_version, next_epoch) = Self::calculate_next_version_and_epoch(
                    request.known_version,
                    request.known_epoch,
                )?;
                (target_version, next_version, next_epoch)
            },
            request => invalid_stream_request!(request),
        };

        // Verify that the target version is >= the next version
        if let Some(target_version) = target_version {
            if target_version < next_version {
                return Err(Error::UnexpectedErrorEncountered(format!(
                    "Invalid stream request found! Target version ({}) is < next version ({})! No data can be fetched!",
                    target_version, next_version
                )));
            }
        }

        // Create the continuous transaction stream engine
        Ok(ContinuousTransactionStreamEngine {
            data_streaming_config,
            request: stream_request.clone(),
            current_target_ledger_info: None,
            end_of_epoch_requested: false,
            optimistic_fetch_requested: false,
            active_subscription_stream: None,
            next_stream_version_and_epoch: (next_version, next_epoch),
            next_request_version_and_epoch: (next_version, next_epoch),
            stream_is_complete: false,
        })
    }
```

**File:** state-sync/state-sync-driver/src/utils.rs (L100-111)
```rust
    /// Verifies the given ledger info with signatures against the current epoch state
    pub fn verify_ledger_info_with_signatures(
        &mut self,
        ledger_info_with_signatures: &LedgerInfoWithSignatures,
    ) -> Result<(), Error> {
        self.epoch_state
            .verify(ledger_info_with_signatures)
            .map_err(|error| {
                Error::VerificationError(format!("Ledger info failed verification: {:?}", error))
            })
    }
}
```
