# Audit Report

## Title
Storage Service Error Handling Allows Unpunished Reconnaissance via Race Condition Exploitation

## Summary
The storage service's error handling does not apply rate limiting to `StorageErrorEncountered` errors, which are triggered when database operations fail. While these errors are intended for legitimate server-side failures, malicious peers can exploit narrow race condition windows during pruning operations to trigger these errors repeatedly without penalty, enabling reconnaissance of storage state and prune window timing.

## Finding Description

The storage service implements a two-stage request processing pipeline: validation followed by storage access. The vulnerability exists in the gap between these stages:

**Stage 1: Request Validation** [1](#0-0) 

The `RequestModerator` validates requests against a cached `StorageServerSummary` that advertises available data ranges (e.g., transactions 1000-2000000). Requests within these ranges pass validation.

**Stage 2: Storage Access** [2](#0-1) 

When storage access fails, the error is caught, metrics are incremented, and it's converted to `StorageServiceError::InternalError` for the client. Critically, line 152-172 shows that `StorageErrorEncountered` errors are NOT treated as invalid requests.

**The Rate Limiting Gap** [3](#0-2) 

Rate limiting only applies when `can_service()` returns false (line 159). Storage errors that occur AFTER validation bypass this mechanism entirely.

**Attack Execution**

The storage summary is refreshed periodically: [4](#0-3) 

With a default 100ms refresh interval, there exists a race window where:
1. Summary advertises transactions 1000-2000000 at time T
2. Pruning advances `min_readable_version` to 1200 between T and T+100ms
3. Peer requests transactions 1000-1100 at T+50ms
4. Validation passes (request is within advertised range)
5. Storage access fails at T+60ms when pruning has advanced [5](#0-4) 

The `error_if_ledger_pruned` check returns an error that becomes `StorageErrorEncountered`: [6](#0-5) 

**Information Leakage**

By systematically probing versions at the lower boundary of advertised ranges, an attacker can:
- Map exact prune window boundaries (within version precision)
- Determine pruning schedules and timing
- Understand storage capacity and retention policies
- Identify which data types are pruned more aggressively

## Impact Explanation

This qualifies as **Medium severity** per Aptos bug bounty criteria:
- **State inconsistencies requiring intervention**: Repeated exploitation could force operators to analyze anomalous metrics and adjust rate limiting at a different layer
- **Information disclosure**: Reveals internal storage configuration that could inform more sophisticated attacks
- **Resource exhaustion**: Each failed storage access consumes database query resources, error handling, logging, and metrics collection without peer penalization

While this doesn't directly cause fund loss or consensus violations, the lack of rate limiting for a class of errors that can be triggered through timing manipulation represents a security gap in the peer management system.

## Likelihood Explanation

**Likelihood: Low to Medium**

The exploit requires:
- Access to the storage service as a public network peer (easily achievable)
- Timing coordination to hit the 100ms race window (difficult but possible)
- Many attempts to achieve statistically significant results (feasible given no rate limiting)

The narrow race window makes individual probes unlikely to succeed, but the absence of rate limiting means an attacker can send thousands of requests. Over time, statistical analysis of error patterns would reveal storage boundaries with high confidence.

## Recommendation

Implement rate limiting for `StorageErrorEncountered` errors to prevent reconnaissance through systematic error triggering:

```rust
// In handler.rs, modify process_request to track storage errors per peer
match self.validate_and_handle_request(peer_network_id, &request) {
    Err(error) => {
        // Track ALL errors, including storage errors, for rate limiting
        if matches!(error, Error::StorageErrorEncountered(_)) {
            // Increment a separate counter for storage errors
            // If threshold exceeded, treat as suspicious behavior
            self.request_moderator.record_storage_error(peer_network_id, &error);
        }
        
        // Existing error handling...
        increment_counter(...);
        // ...
    }
}
```

Additionally, in `RequestModerator`:
- Add a separate tracking mechanism for storage errors per peer
- Implement a higher threshold than invalid requests (e.g., 1000 storage errors vs 500 invalid requests)
- Apply the same ignore/exponential backoff mechanism when threshold is exceeded

This preserves tolerance for legitimate server-side errors while preventing systematic exploitation.

## Proof of Concept

```rust
// Conceptual PoC - would require coordination with actual pruning operations
// This demonstrates the attack pattern, though success depends on timing

use aptos_config::network_id::{NetworkId, PeerNetworkId};
use aptos_storage_service_types::requests::{DataRequest, StorageServiceRequest, TransactionsWithProofRequest};
use aptos_types::PeerId;

#[tokio::test]
async fn test_storage_error_reconnaissance() {
    // Setup: Create storage service with active pruning
    let (storage_service, storage_summary) = setup_storage_with_pruning().await;
    
    // Step 1: Query storage summary to learn advertised range
    let summary = storage_service.get_storage_server_summary().await;
    let tx_range = summary.data_summary.transactions.unwrap();
    let boundary_version = tx_range.lowest; // e.g., 1000
    
    // Step 2: Send many requests targeting versions near the prune boundary
    let attacker_peer = PeerNetworkId::new(NetworkId::Public, PeerId::random());
    let mut storage_errors = 0;
    let mut invalid_requests = 0;
    
    for attempt in 0..10000 {
        let request = StorageServiceRequest {
            data_request: DataRequest::GetTransactionsWithProof(
                TransactionsWithProofRequest {
                    start_version: boundary_version + (attempt % 100),
                    end_version: boundary_version + (attempt % 100) + 10,
                    proof_version: boundary_version + 50,
                    include_events: false,
                }
            ),
            use_compression: false,
        };
        
        match storage_service.process_request(attacker_peer, request).await {
            Err(StorageServiceError::InternalError(_)) => storage_errors += 1,
            Err(StorageServiceError::InvalidRequest(_)) => invalid_requests += 1,
            _ => {}
        }
    }
    
    // Demonstrate: Storage errors occur without peer being rate-limited
    assert!(storage_errors > 0, "Should trigger some storage errors via race conditions");
    assert!(invalid_requests < 500, "Should not exceed rate limit threshold");
    assert!(!is_peer_ignored(storage_service, attacker_peer), "Peer should NOT be ignored despite errors");
    
    // Analysis: Error patterns reveal prune window timing
    // (In practice, attacker would analyze error timing to map storage state)
}
```

**Notes**

While the vulnerability is technically valid, its practical exploitability is limited by:
1. **Narrow race window**: 100ms default refresh interval plus commit-triggered updates
2. **Low success rate**: Individual probes have low probability of hitting race conditions  
3. **Mitigation exists**: Operators can detect anomalous error patterns in metrics

However, the complete absence of rate limiting for this error class represents a gap in the defense-in-depth strategy, particularly given that systematic exploitation over extended periods could reveal meaningful intelligence about node configuration.

### Citations

**File:** state-sync/storage-service/server/src/moderator.rs (L134-196)
```rust
    pub fn validate_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: &StorageServiceRequest,
    ) -> Result<(), Error> {
        // Validate the request and time the operation
        let validate_request = || {
            // If the peer is being ignored, return an error
            if let Some(peer_state) = self.unhealthy_peer_states.get(peer_network_id) {
                if peer_state.is_ignored() {
                    return Err(Error::TooManyInvalidRequests(format!(
                        "Peer is temporarily ignored. Unable to handle request: {:?}",
                        request
                    )));
                }
            }

            // Get the latest storage server summary
            let storage_server_summary = self.cached_storage_server_summary.load();

            // Verify the request is serviceable using the current storage server summary
            if !storage_server_summary.can_service(
                &self.aptos_data_client_config,
                self.time_service.clone(),
                request,
            ) {
                // Increment the invalid request count for the peer
                let mut unhealthy_peer_state = self
                    .unhealthy_peer_states
                    .entry(*peer_network_id)
                    .or_insert_with(|| {
                        // Create a new unhealthy peer state (this is the first invalid request)
                        let max_invalid_requests =
                            self.storage_service_config.max_invalid_requests_per_peer;
                        let min_time_to_ignore_peers_secs =
                            self.storage_service_config.min_time_to_ignore_peers_secs;
                        let time_service = self.time_service.clone();

                        UnhealthyPeerState::new(
                            max_invalid_requests,
                            min_time_to_ignore_peers_secs,
                            time_service,
                        )
                    });
                unhealthy_peer_state.increment_invalid_request_count(peer_network_id);

                // Return the validation error
                return Err(Error::InvalidRequest(format!(
                    "The given request cannot be satisfied. Request: {:?}, storage summary: {:?}",
                    request, storage_server_summary
                )));
            }

            Ok(()) // The request is valid
        };
        utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_VALIDATION_LATENCY,
            Some((peer_network_id, request)),
            None,
            validate_request,
            None,
        )
    }
```

**File:** state-sync/storage-service/server/src/handler.rs (L142-203)
```rust
    pub(crate) fn process_request(
        &self,
        peer_network_id: &PeerNetworkId,
        request: StorageServiceRequest,
        optimistic_fetch_related: bool,
    ) -> aptos_storage_service_types::Result<StorageServiceResponse> {
        // Process the request and time the operation
        let process_request = || {
            // Process the request and handle any errors
            match self.validate_and_handle_request(peer_network_id, &request) {
                Err(error) => {
                    // Update the error counter
                    increment_counter(
                        &metrics::STORAGE_ERRORS_ENCOUNTERED,
                        peer_network_id.network_id(),
                        error.get_label().into(),
                    );

                    // Periodically log the failure
                    sample!(
                            SampleRate::Duration(Duration::from_secs(ERROR_LOG_FREQUENCY_SECS)),
                            warn!(LogSchema::new(LogEntry::StorageServiceError)
                                .error(&error)
                                .peer_network_id(peer_network_id)
                                .request(&request)
                                .optimistic_fetch_related(optimistic_fetch_related)
                        );
                    );

                    // Return the error
                    Err(error)
                },
                Ok(response) => {
                    // Update the successful response counter
                    increment_counter(
                        &metrics::STORAGE_RESPONSES_SENT,
                        peer_network_id.network_id(),
                        response.get_label(),
                    );

                    // Return the response
                    Ok(response)
                },
            }
        };
        let process_result = utils::execute_and_time_duration(
            &metrics::STORAGE_REQUEST_PROCESSING_LATENCY,
            Some((peer_network_id, &request)),
            None,
            process_request,
            None,
        );

        // Transform the request error into a storage service error (for the client)
        process_result.map_err(|error| match error {
            Error::InvalidRequest(error) => StorageServiceError::InvalidRequest(error),
            Error::TooManyInvalidRequests(error) => {
                StorageServiceError::TooManyInvalidRequests(error)
            },
            error => StorageServiceError::InternalError(error.to_string()),
        })
    }
```

**File:** state-sync/storage-service/server/src/lib.rs (L183-217)
```rust
            let duration = Duration::from_millis(config.storage_summary_refresh_interval_ms);
            let ticker = time_service.interval(duration);
            futures::pin_mut!(ticker);

            // Continuously refresh the cache
            loop {
                futures::select! {
                    _ = ticker.select_next_some() => {
                        // Refresh the cache periodically
                        refresh_cached_storage_summary(
                            cached_storage_server_summary.clone(),
                            storage.clone(),
                            config,
                            cache_update_notifiers.clone(),
                        )
                    },
                    notification = storage_service_listener.select_next_some() => {
                        trace!(LogSchema::new(LogEntry::ReceivedCommitNotification)
                            .message(&format!(
                                "Received commit notification for highest synced version: {:?}.",
                                notification.highest_synced_version
                            ))
                        );

                        // Refresh the cache because of a commit notification
                        refresh_cached_storage_summary(
                            cached_storage_server_summary.clone(),
                            storage.clone(),
                            config,
                            cache_update_notifiers.clone(),
                        )
                    },
                }
            }
        });
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L261-271)
```rust
    pub(super) fn error_if_ledger_pruned(&self, data_type: &str, version: Version) -> Result<()> {
        let min_readable_version = self.ledger_pruner.get_min_readable_version();
        ensure!(
            version >= min_readable_version,
            "{} at version {} is pruned, min available version is {}.",
            data_type,
            version,
            min_readable_version
        );
        Ok(())
    }
```

**File:** state-sync/storage-service/server/src/error.rs (L43-47)
```rust
impl From<aptos_storage_interface::AptosDbError> for Error {
    fn from(error: aptos_storage_interface::AptosDbError) -> Self {
        Error::StorageErrorEncountered(error.to_string())
    }
}
```
