# Audit Report

## Title
Unauthenticated gRPC Channel Communication in Remote Executor Infrastructure Enables Byzantine Validator Attacks

## Summary
The remote executor infrastructure uses plaintext HTTP gRPC channels without TLS encryption or authentication mechanisms. This allows Byzantine validators with network access to hijack communication channels between the coordinator and executor shards, enabling injection of malicious execution commands and interception of blockchain state data.

## Finding Description

The remote executor system, designed for distributed block execution across multiple shards, communicates via gRPC channels that lack both transport-layer security and authentication. 

**Architecture Overview:**
The sharded execution system consists of a coordinator node (main validator) and multiple executor shard processes that execute partitioned transactions in parallel. Communication occurs through `NetworkController` using gRPC channels. [1](#0-0) 

**Critical Vulnerability - Plaintext HTTP Channels:**

The gRPC client creates channels using plaintext HTTP without TLS: [2](#0-1) 

**No Authentication:**

The server accepts any incoming gRPC request without verifying the sender's identity: [3](#0-2) 

The `remote_addr` is obtained from the request but never validated against a trusted peer set. Any client that can reach the network endpoint can send messages.

**Production Integration:**

The remote executor is integrated into the main execution workflow: [4](#0-3) 

When remote addresses are configured via `set_remote_addresses()`, the system uses `REMOTE_SHARDED_BLOCK_EXECUTOR` instead of local execution.

**Attack Vectors:**

1. **Malicious Execution Command Injection:**
   A Byzantine validator operator can connect to executor shard endpoints and send forged `ExecuteBlockCommand` messages: [5](#0-4) 

2. **State Exfiltration:**
   Attackers can send `RemoteKVRequest` messages to extract blockchain state: [6](#0-5) 

3. **Result Manipulation:**
   Byzantine shards can return forged execution results: [7](#0-6) 

**Invariant Violations:**

This breaks two critical invariants:
- **Deterministic Execution**: Malicious results cause validators to produce different state roots for identical blocks
- **Consensus Safety**: Divergent state roots lead to consensus violations and potential chain splits

**Contrast with Secure Validator Network:**

The main validator network properly implements Noise protocol authentication with trusted peer validation, while the remote executor has no such protections: [8](#0-7) 

## Impact Explanation

**Critical Severity** - This vulnerability enables:

1. **Consensus Safety Violations**: Byzantine actors can cause different validators to commit different state roots by injecting malicious execution results, breaking the fundamental safety guarantee that honest validators agree on blockchain state.

2. **State Divergence**: If validators execute different transaction outputs, they will produce different Merkle roots, causing irreconcilable forks requiring a hard fork to resolve.

3. **Information Disclosure**: All execution data flows in plaintext, exposing sensitive transaction details and blockchain state to network-level attackers.

4. **Complete Trust Boundary Bypass**: The system provides no defense against man-in-the-middle attacks, replay attacks, or impersonation attacks.

This meets the **Critical Severity** criteria per Aptos bug bounty: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Current Likelihood: Low** - The remote executor is not currently deployed on mainnet validators based on configuration analysis.

**Conditional Likelihood: High** - IF validators deploy this system for performance optimization:
- Attack requires network access to executor shard endpoints (internal network)
- Requires Byzantine validator operator or compromised infrastructure
- No authentication means exploitation requires only basic network access once inside
- Attack complexity is low (standard gRPC client tools)

The vulnerability exists in production-ready code integrated into the main execution path, creating risk if future deployments enable this feature without proper security hardening.

## Recommendation

**Immediate Actions:**

1. **Implement TLS with Mutual Authentication:**

Add TLS configuration similar to the indexer-grpc services: [9](#0-8) 

2. **Add Authentication Interceptors:**

Use tonic interceptors to validate peer identity: [10](#0-9) 

3. **Implement Trusted Peer Validation:**

Integrate the Noise protocol authentication used by the main validator network, or implement equivalent peer validation against a trusted set.

4. **Add Documentation:**

Clearly document that this system requires deployment on isolated networks with firewall protection until authentication is implemented.

**Code Fix Outline:**

```rust
// In GRPCNetworkMessageServiceClientWrapper::get_channel()
// Replace plaintext HTTP with HTTPS + mTLS:

async fn get_channel(remote_addr: String, tls_config: ClientTlsConfig) 
    -> NetworkMessageServiceClient<Channel> {
    let endpoint = tonic::transport::Endpoint::new(
        format!("https://{}", remote_addr)
    )?
    .tls_config(tls_config)?;
    
    let conn = endpoint.connect_lazy();
    NetworkMessageServiceClient::new(conn)
        .with_interceptor(AuthInterceptor::new(trusted_peers))
        .max_decoding_message_size(MAX_MESSAGE_SIZE)
}

// Add authentication interceptor
struct AuthInterceptor {
    trusted_peers: Arc<HashSet<PeerId>>,
}

impl Interceptor for AuthInterceptor {
    fn call(&mut self, request: Request<()>) -> Result<Request<()>, Status> {
        // Validate peer certificate against trusted set
        // Verify request signatures
        // Check anti-replay timestamps
    }
}
```

## Proof of Concept

```rust
// PoC: Byzantine validator hijacking remote executor channel

use aptos_protos::remote_executor::v1::{
    network_message_service_client::NetworkMessageServiceClient,
    NetworkMessage,
};
use tonic::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Byzantine validator connects to executor shard endpoint
    // No authentication required - plaintext HTTP
    let mut client = NetworkMessageServiceClient::connect(
        "http://executor-shard-1.internal:52201" // Hypothetical shard address
    ).await?;
    
    // Craft malicious ExecuteBlockCommand with altered transactions
    let malicious_command = create_malicious_execution_command();
    let serialized = bcs::to_bytes(&malicious_command)?;
    
    // Inject malicious request - no authentication check
    let request = Request::new(NetworkMessage {
        message: serialized,
        message_type: "execute_command_0".to_string(),
    });
    
    // Server accepts and executes without verifying sender identity
    let response = client.simple_msg_exchange(request).await?;
    
    println!("Malicious command injected successfully");
    println!("Executor shard will produce forged results");
    println!("Consensus safety violated - different state roots");
    
    Ok(())
}

fn create_malicious_execution_command() -> RemoteExecutionRequest {
    // Create ExecuteBlockCommand with:
    // - Altered transaction outputs
    // - Modified state changes
    // - Forged execution results
    // These will cause state divergence when coordinator commits
    todo!()
}
```

**Testing Steps:**
1. Deploy remote executor infrastructure with sharded execution enabled
2. Run Byzantine client from separate process with network access
3. Inject malicious `ExecuteBlockCommand` to any executor shard
4. Observe coordinator commits incorrect state based on forged results
5. Verify different validators produce different state roots â†’ consensus violation

**Notes**

This vulnerability exists in production-ready code but is not currently exploited because:
1. Remote sharded execution is not enabled on mainnet validators (no remote addresses configured)
2. The system is primarily used for benchmarking in isolated environments
3. Production validators use the main network layer with Noise protocol authentication

However, the vulnerability represents a critical security gap if this infrastructure is deployed without proper hardening. The contrast between the secure main validator network (with mutual authentication) and the insecure remote executor network (no authentication) suggests this may be an oversight during development of performance optimization features.

The package name `aptos-secure-net` is misleading as it provides no actual security mechanisms, creating risk of misuse by operators assuming built-in protection.

### Citations

**File:** aptos-move/aptos-vm/src/sharded_block_executor/mod.rs (L68-76)
```rust
    /// Execute a block of transactions in parallel by splitting the block into num_remote_executors partitions and
    /// dispatching each partition to a remote executor shard.
    pub fn execute_block(
        &self,
        state_view: Arc<S>,
        transactions: PartitionedTransactions,
        concurrency_level_per_shard: usize,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>, VMStatus> {
```

**File:** secure/net/src/grpc_network_service/mod.rs (L91-115)
```rust
#[tonic::async_trait]
impl NetworkMessageService for GRPCNetworkMessageServiceServerWrapper {
    async fn simple_msg_exchange(
        &self,
        request: Request<NetworkMessage>,
    ) -> Result<Response<Empty>, Status> {
        let _timer = NETWORK_HANDLER_TIMER
            .with_label_values(&[&self.self_addr.to_string(), "inbound_msgs"])
            .start_timer();
        let remote_addr = request.remote_addr();
        let network_message = request.into_inner();
        let msg = Message::new(network_message.message);
        let message_type = MessageType::new(network_message.message_type);

        if let Some(handler) = self.inbound_handlers.lock().unwrap().get(&message_type) {
            // Send the message to the registered handler
            handler.send(msg).unwrap();
        } else {
            error!(
                "No handler registered for sender: {:?} and msg type {:?}",
                remote_addr, message_type
            );
        }
        Ok(Response::new(Empty {}))
    }
```

**File:** secure/net/src/grpc_network_service/mod.rs (L124-138)
```rust
    pub fn new(rt: &Runtime, remote_addr: SocketAddr) -> Self {
        Self {
            remote_addr: remote_addr.to_string(),
            remote_channel: rt
                .block_on(async { Self::get_channel(format!("http://{}", remote_addr)).await }),
        }
    }

    async fn get_channel(remote_addr: String) -> NetworkMessageServiceClient<Channel> {
        info!("Trying to connect to remote server at {:?}", remote_addr);
        let conn = tonic::transport::Endpoint::new(remote_addr)
            .unwrap()
            .connect_lazy();
        NetworkMessageServiceClient::new(conn).max_decoding_message_size(MAX_MESSAGE_SIZE)
    }
```

**File:** execution/executor/src/workflow/do_get_execution_output.rs (L256-276)
```rust
    fn execute_block_sharded<V: VMBlockExecutor>(
        partitioned_txns: PartitionedTransactions,
        state_view: Arc<CachedStateView>,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> Result<Vec<TransactionOutput>> {
        if !get_remote_addresses().is_empty() {
            Ok(V::execute_block_sharded(
                &REMOTE_SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        } else {
            Ok(V::execute_block_sharded(
                &SHARDED_BLOCK_EXECUTOR.lock(),
                partitioned_txns,
                state_view,
                onchain_config,
            )?)
        }
    }
```

**File:** execution/executor-service/src/lib.rs (L32-40)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct RemoteExecutionResult {
    pub inner: Result<Vec<Vec<TransactionOutput>>, VMStatus>,
}

impl RemoteExecutionResult {
    pub fn new(inner: Result<Vec<Vec<TransactionOutput>>, VMStatus>) -> Self {
        Self { inner }
    }
```

**File:** execution/executor-service/src/lib.rs (L43-53)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub enum RemoteExecutionRequest {
    ExecuteBlock(ExecuteBlockCommand),
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct ExecuteBlockCommand {
    pub(crate) sub_blocks: SubBlocksForShard<AnalyzedTransaction>,
    pub(crate) concurrency_level: usize,
    pub(crate) onchain_config: BlockExecutorConfigFromOnchain,
}
```

**File:** execution/executor-service/src/remote_state_view_service.rs (L74-122)
```rust
    pub fn handle_message(
        message: Message,
        state_view: Arc<RwLock<Option<Arc<S>>>>,
        kv_tx: Arc<Vec<Sender<Message>>>,
    ) {
        // we don't know the shard id until we deserialize the message, so lets default it to 0
        let _timer = REMOTE_EXECUTOR_TIMER
            .with_label_values(&["0", "kv_requests"])
            .start_timer();
        let bcs_deser_timer = REMOTE_EXECUTOR_TIMER
            .with_label_values(&["0", "kv_req_deser"])
            .start_timer();
        let req: RemoteKVRequest = bcs::from_bytes(&message.data).unwrap();
        drop(bcs_deser_timer);

        let (shard_id, state_keys) = req.into();
        trace!(
            "remote state view service - received request for shard {} with {} keys",
            shard_id,
            state_keys.len()
        );
        let resp = state_keys
            .into_iter()
            .map(|state_key| {
                let state_value = state_view
                    .read()
                    .unwrap()
                    .as_ref()
                    .unwrap()
                    .get_state_value(&state_key)
                    .unwrap();
                (state_key, state_value)
            })
            .collect_vec();
        let len = resp.len();
        let resp = RemoteKVResponse::new(resp);
        let bcs_ser_timer = REMOTE_EXECUTOR_TIMER
            .with_label_values(&["0", "kv_resp_ser"])
            .start_timer();
        let resp = bcs::to_bytes(&resp).unwrap();
        drop(bcs_ser_timer);
        trace!(
            "remote state view service - sending response for shard {} with {} keys",
            shard_id,
            len
        );
        let message = Message::new(resp);
        kv_tx[shard_id].send(message).unwrap();
    }
```

**File:** network/framework/src/noise/handshake.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! The handshake module implements the handshake part of the protocol.
//! This module also implements additional anti-DoS mitigation,
//! by including a timestamp in each handshake initialization message.
//! Refer to the module's documentation for more information.
//! A successful handshake returns a [`NoiseStream`] which is defined in the
//! [stream] module.
//!
//! [stream]: crate::noise::stream

use crate::{
    application::storage::PeersAndMetadata,
    logging::NetworkSchema,
    noise::{error::NoiseHandshakeError, stream::NoiseStream},
};
use aptos_config::{
    config::{Peer, PeerRole},
    network_id::{NetworkContext, NetworkId},
};
use aptos_crypto::{noise, x25519};
use aptos_infallible::{duration_since_epoch, RwLock};
use aptos_logger::{error, trace};
use aptos_short_hex_str::{AsShortHexStr, ShortHexStr};
use aptos_types::PeerId;
use futures::io::{AsyncRead, AsyncReadExt, AsyncWrite, AsyncWriteExt};
use std::{collections::HashMap, convert::TryFrom as _, fmt::Debug, sync::Arc};

/// In a mutually authenticated network, a client message is accompanied with a timestamp.
/// This is in order to prevent replay attacks, where the attacker does not know the client's static key,
/// but can still replay a handshake message in order to force a peer into performing a few Diffie-Hellman key exchange operations.
///
/// Thus, to prevent replay attacks a responder will always check if the timestamp is strictly increasing,
/// effectively considering it as a stateful counter.
///
/// If the client timestamp has been seen before, or is not strictly increasing,
/// we can abort the handshake early and avoid heavy Diffie-Hellman computations.
/// If the client timestamp is valid, we store it.
#[derive(Default)]
pub struct AntiReplayTimestamps(HashMap<x25519::PublicKey, u64>);

impl AntiReplayTimestamps {
    /// The timestamp is sent as a payload, so that it is encrypted.
    /// Note that a millisecond value is a 16-byte value in rust,
    /// but as we use it to store a duration since UNIX_EPOCH we will never use more than 8 bytes.
    pub const TIMESTAMP_SIZE: usize = 8;

    /// obtain the current timestamp
    pub fn now() -> [u8; Self::TIMESTAMP_SIZE] {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

use crate::service::RawDataServerWrapper;
use anyhow::{bail, Result};
use aptos_indexer_grpc_server_framework::RunnableConfig;
use aptos_indexer_grpc_utils::{
    compression_util::StorageFormat, config::IndexerGrpcFileStoreConfig,
    in_memory_cache::InMemoryCacheConfig, types::RedisUrl,
};
use aptos_protos::{
    indexer::v1::FILE_DESCRIPTOR_SET as INDEXER_V1_FILE_DESCRIPTOR_SET,
    transaction::v1::FILE_DESCRIPTOR_SET as TRANSACTION_V1_TESTING_FILE_DESCRIPTOR_SET,
    util::timestamp::FILE_DESCRIPTOR_SET as UTIL_TIMESTAMP_FILE_DESCRIPTOR_SET,
};
use aptos_transaction_filter::BooleanTransactionFilter;
use serde::{Deserialize, Serialize};
use std::{net::SocketAddr, sync::Arc};
use tonic::{codec::CompressionEncoding, transport::Server};

pub const SERVER_NAME: &str = "idxdatasvc";

// Default max response channel size.
const DEFAULT_MAX_RESPONSE_CHANNEL_SIZE: usize = 3;

// HTTP2 ping interval and timeout.
// This can help server to garbage collect dead connections.
// tonic server: https://docs.rs/tonic/latest/tonic/transport/server/struct.Server.html#method.http2_keepalive_interval
const HTTP2_PING_INTERVAL_DURATION: std::time::Duration = std::time::Duration::from_secs(60);
const HTTP2_PING_TIMEOUT_DURATION: std::time::Duration = std::time::Duration::from_secs(10);

#[derive(Clone, Debug, Deserialize, Serialize)]
#[serde(deny_unknown_fields)]
pub struct TlsConfig {
    /// The address for the TLS GRPC server to listen on.
    pub data_service_grpc_listen_address: SocketAddr,
    pub cert_path: String,
    pub key_path: String,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
#[serde(deny_unknown_fields)]
pub struct NonTlsConfig {
    /// The address for the TLS GRPC server to listen on.
    pub data_service_grpc_listen_address: SocketAddr,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
#[serde(deny_unknown_fields)]
pub struct IndexerGrpcDataServiceConfig {
```

**File:** protos/rust/src/pb/aptos.remote_executor.v1.tonic.rs (L41-59)
```rust
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> NetworkMessageServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
            >>::Error: Into<StdError> + Send + Sync,
        {
            NetworkMessageServiceClient::new(InterceptedService::new(inner, interceptor))
        }
```
