# Audit Report

## Title
Peer Monitoring Service Fails to Disconnect Misbehaving Peers Despite Detecting Excessive Failures

## Summary
The peer monitoring service detects when peers exceed the configured failure threshold (`max_latency_ping_failures`, default: 3) but fails to take corrective action by disconnecting them. This allows misbehaving or unresponsive peers to remain connected indefinitely, consuming network resources and connection slots that should be available for legitimate peers.

## Finding Description

The `StateValueInterface` trait defines methods that return void (`()`), preventing error propagation up the call chain. More critically, the `LatencyInfoState` implementation detects excessive ping failures but only logs a warning without disconnecting the peer. [1](#0-0) 

The `handle_monitoring_service_response_error()` and `update_peer_state_metrics()` methods in this interface return void, so internal errors cannot be propagated. [2](#0-1) 

When a peer exceeds the failure threshold, the code explicitly contains a TODO comment stating disconnection should occur, but this is not implemented. The peer remains connected despite repeated failures.

The configuration defines a clear threshold for when action should be taken: [3](#0-2) 

In contrast, the network's `HealthChecker` component implements similar functionality correctly by calling `disconnect_peer()` when failures exceed the threshold: [4](#0-3) 

The `NetworkClientInterface` provides the necessary `disconnect_from_peer()` method that could be used: [5](#0-4) 

However, the peer monitoring service never invokes this capability.

**Attack Scenario:**
1. Attacker establishes connections from multiple malicious nodes to target validators/fullnodes
2. Malicious nodes ignore or respond incorrectly to latency ping requests
3. The monitoring service detects failures and increments the failure counter
4. After 3+ consecutive failures, a warning is logged but no disconnection occurs
5. Malicious peers remain connected indefinitely, consuming peer slots
6. If enough malicious peers connect, legitimate peers may be unable to establish connections
7. Network connectivity and performance degrades

## Impact Explanation

**High Severity** - This vulnerability falls under "Validator node slowdowns" and "Significant protocol violations" per the Aptos bug bounty criteria:

- **Resource Exhaustion**: Misbehaving peers consume network bandwidth, memory, and CPU cycles for monitoring requests that consistently fail
- **Peer Slot Exhaustion**: Most nodes have limited peer connection slots. Malicious peers occupying these slots prevent legitimate peers from connecting
- **Network Degradation**: Validators unable to connect to sufficient honest peers may experience consensus issues or reduced block propagation efficiency
- **Coordinated Attack Surface**: Multiple coordinated misbehaving peers could systematically degrade network availability

## Likelihood Explanation

**High Likelihood** - This vulnerability is trivially exploitable:

- **No Authentication Required**: Any entity can run a node and connect to the network
- **Passive Attack**: The attacker simply needs to not respond to pings or respond incorrectly
- **No Special Resources**: Does not require validator status, tokens, or significant computational power
- **Difficult to Mitigate**: Operators have no automated way to detect and remove these peers without manual intervention
- **Configuration Confirms Intent**: The `max_latency_ping_failures` configuration parameter explicitly indicates disconnection was intended

## Recommendation

Implement peer disconnection when the failure threshold is exceeded, similar to how the `HealthChecker` handles this scenario. The fix requires:

1. Add a `disconnect_peer()` method to `PeerMonitoringServiceClient` that wraps the network interface's `disconnect_from_peer()` call
2. Modify `LatencyInfoState::handle_request_failure()` to accept additional parameters (peer network ID and disconnect callback)
3. Invoke disconnection when `num_consecutive_failures >= max_latency_ping_failures`
4. Update `StateValueInterface` to potentially return `Result<(), Error>` instead of void to allow proper error propagation

**Code Fix Example** (for `latency_info.rs`):

```rust
fn handle_request_failure(&self, peer_network_id: &PeerNetworkId, disconnect_fn: impl Fn(PeerNetworkId) -> Result<(), Error>) {
    self.request_tracker.write().record_response_failure();
    
    let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
    if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
        warn!(LogSchema::new(LogEntry::LatencyPing)
            .event(LogEvent::TooManyPingFailures)
            .peer(peer_network_id)
            .message("Too many ping failures occurred for the peer! Disconnecting..."));
        
        if let Err(err) = disconnect_fn(*peer_network_id) {
            error!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::UnexpectedErrorEncountered)
                .peer(peer_network_id)
                .error(&err)
                .message("Failed to disconnect misbehaving peer"));
        }
    }
}
```

## Proof of Concept

The following Rust test demonstrates the vulnerability:

```rust
#[tokio::test]
async fn test_misbehaving_peer_not_disconnected() {
    // Setup: Create monitoring service with max_latency_ping_failures = 3
    let mut config = NodeConfig::default();
    config.peer_monitoring_service.latency_monitoring.max_latency_ping_failures = 3;
    
    let time_service = TimeService::mock();
    let mut latency_state = LatencyInfoState::new(
        config.peer_monitoring_service.latency_monitoring,
        time_service
    );
    
    let peer_network_id = PeerNetworkId::random();
    
    // Simulate 5 consecutive ping failures
    for _ in 0..5 {
        latency_state.handle_monitoring_service_response_error(
            &peer_network_id,
            Error::NetworkError("Timeout".to_string())
        );
    }
    
    // EXPECTED: Peer should be disconnected after 3 failures
    // ACTUAL: Peer remains connected (no disconnect call is made)
    // This test demonstrates the vulnerability
    
    // Verify failure counter increased but no disconnection occurred
    let failures = latency_state.request_tracker.read().get_num_consecutive_failures();
    assert_eq!(failures, 5); // Failures tracked
    
    // BUG: There is no mechanism to verify peer was disconnected
    // because the disconnect never happens!
}
```

The test shows that failure tracking works correctly, but the critical disconnection action is never taken, allowing the misbehaving peer to remain connected indefinitely.

### Citations

**File:** peer-monitoring-service/client/src/peer_states/key_value.rs (L66-97)
```rust
/// The interface offered by all peer state value types
#[enum_dispatch]
pub trait StateValueInterface {
    /// Creates the monitoring service request
    fn create_monitoring_service_request(&mut self) -> PeerMonitoringServiceRequest;

    /// Returns the request timeout (ms)
    fn get_request_timeout_ms(&self) -> u64;

    /// Returns the request tracker
    fn get_request_tracker(&self) -> Arc<RwLock<RequestTracker>>;

    /// Handles the monitoring service response
    fn handle_monitoring_service_response(
        &mut self,
        peer_network_id: &PeerNetworkId,
        peer_metadata: PeerMetadata,
        monitoring_service_request: PeerMonitoringServiceRequest,
        monitoring_service_response: PeerMonitoringServiceResponse,
        response_time_secs: f64,
    );

    /// Handles a monitoring service error
    fn handle_monitoring_service_response_error(
        &mut self,
        peer_network_id: &PeerNetworkId,
        error: Error,
    );

    /// Updates the peer state metrics for the given peer
    fn update_peer_state_metrics(&self, peer_network_id: &PeerNetworkId);
}
```

**File:** peer-monitoring-service/client/src/peer_states/latency_info.rs (L59-72)
```rust
    /// Handles a ping failure for the specified peer
    fn handle_request_failure(&self, peer_network_id: &PeerNetworkId) {
        // Update the number of ping failures for the request tracker
        self.request_tracker.write().record_response_failure();

        // TODO: If the number of ping failures is too high, disconnect from the node
        let num_consecutive_failures = self.request_tracker.read().get_num_consecutive_failures();
        if num_consecutive_failures >= self.latency_monitoring_config.max_latency_ping_failures {
            warn!(LogSchema::new(LogEntry::LatencyPing)
                .event(LogEvent::TooManyPingFailures)
                .peer(peer_network_id)
                .message("Too many ping failures occurred for the peer!"));
        }
    }
```

**File:** config/src/config/peer_monitoring_config.rs (L40-56)
```rust
pub struct LatencyMonitoringConfig {
    pub latency_ping_interval_ms: u64, // The interval (ms) between latency pings for each peer
    pub latency_ping_timeout_ms: u64,  // The timeout (ms) for each latency ping
    pub max_latency_ping_failures: u64, // Max ping failures before the peer connection fails
    pub max_num_latency_pings_to_retain: usize, // The max latency pings to retain per peer
}

impl Default for LatencyMonitoringConfig {
    fn default() -> Self {
        Self {
            latency_ping_interval_ms: 30_000, // 30 seconds
            latency_ping_timeout_ms: 20_000,  // 20 seconds
            max_latency_ping_failures: 3,
            max_num_latency_pings_to_retain: 10,
        }
    }
}
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L356-393)
```rust
                // If the ping failures are now more than
                // `self.ping_failures_tolerated`, we disconnect from the node.
                // The HealthChecker only performs the disconnect. It relies on
                // ConnectivityManager or the remote peer to re-establish the connection.
                let failures = self
                    .network_interface
                    .get_peer_failures(peer_id)
                    .unwrap_or(0);
                if failures > self.ping_failures_tolerated {
                    info!(
                        NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                        "{} Disconnecting from peer: {}",
                        self.network_context,
                        peer_id.short_str()
                    );
                    let peer_network_id =
                        PeerNetworkId::new(self.network_context.network_id(), peer_id);
                    if let Err(err) = timeout(
                        Duration::from_millis(50),
                        self.network_interface.disconnect_peer(
                            peer_network_id,
                            DisconnectReason::NetworkHealthCheckFailure,
                        ),
                    )
                    .await
                    {
                        warn!(
                            NetworkSchema::new(&self.network_context)
                                .remote_peer(&peer_id),
                            error = ?err,
                            "{} Failed to disconnect from peer: {} with error: {:?}",
                            self.network_context,
                            peer_id.short_str(),
                            err
                        );
                    }
                }
            },
```

**File:** network/framework/src/application/interface.rs (L42-46)
```rust
    async fn disconnect_from_peer(
        &self,
        _peer: PeerNetworkId,
        _disconnect_reason: DisconnectReason,
    ) -> Result<(), Error>;
```
