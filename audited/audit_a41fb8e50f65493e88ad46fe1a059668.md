# Audit Report

## Title
Type Conversion Invalidates Cryptographic Signatures Leading to Consensus Split

## Summary
The conversion from `ProofOfStoreMsg<BatchInfo>` to `ProofOfStoreMsg<BatchInfoExt>` preserves the multi-signature but changes the underlying data structure being signed. This causes the signature to become cryptographically invalid for the converted type, breaking the fundamental invariant that digital signatures must be independently verifiable. The system masks this invalidity through caching, creating a critical dependency where consensus safety relies on cache state rather than cryptographic validity. [1](#0-0) 

## Finding Description

The vulnerability exists in the proof message conversion flow where `ProofOfStore<BatchInfo>` is converted to `ProofOfStore<BatchInfoExt>` while preserving the original signature.

**Root Cause:**

Both `BatchInfo` and `BatchInfoExt` derive `BCSCryptoHash`, meaning they are hashed based on their BCS (Binary Canonical Serialization) representation. [2](#0-1) [3](#0-2) 

For `BatchInfo` (a struct), BCS serializes it directly as its fields. For `BatchInfoExt::V1 { info }` (an enum variant), BCS serializes it as a u32 discriminator (0 for V1) followed by the fields. This produces **different hash values**, meaning a signature valid for `BatchInfo` is **cryptographically invalid** for `BatchInfoExt::V1 { info }`.

**The Conversion Flow:**

1. When `ProofOfStoreMsg<BatchInfo>` is received, it's verified against the `BatchInfo` type (signature valid): [4](#0-3) 

2. The conversion at line 219 changes the data type but preserves the signature: [5](#0-4) 

3. During verification, the system relies on caching to mask the invalidity: [6](#0-5) 

When `ProofOfStore<BatchInfo>` is verified, the signature is cached under the `BatchInfoExt::V1 { info }` key (line 636). Later, when `ProofOfStore<BatchInfoExt>` is verified, the cache returns a hit (line 637-640), avoiding re-verification against the incompatible type.

**Attack Scenario:**

The vulnerability manifests when cache coherency is broken:

1. **Cache Eviction**: The `ProofCache` is created with bounded size (e.g., 1024 entries). Under high load, entries are evicted using LRU policy. When a node's cache evicts a proof entry, subsequent verification of converted proofs will fail. [7](#0-6) 

2. **Node Restart**: Cache is in-memory only. When a validator restarts, all cached signatures are lost. If it receives a proposal containing converted proofs, verification fails.

3. **Late-Joining Validators**: New validators joining the network won't have cached entries for previously verified proofs. They will reject valid proposals, causing consensus divergence.

**Exploitation Path:**

```
Step 1: All validators receive and verify ProofOfStoreMsg<BatchInfo>
        → Signatures cached under BatchInfoExt::V1 { info } keys

Step 2: Node A's cache becomes full and evicts some entries (LRU)
        OR Node A restarts (cache cleared)
        OR Node A is a new validator joining the network

Step 3: Node B creates a proposal including ProofOfStore<BatchInfoExt>
        (pulled from local proof queue after conversion)

Step 4: Node A receives the proposal and attempts verification
        → Cache miss occurs
        → verify_multi_signatures called with BatchInfoExt::V1 { info }
        → Signature verification FAILS (signature was for BatchInfo)
        
Step 5: Node A rejects the proposal
        Node B and others (with cache hits) accept the proposal
        → CONSENSUS SPLIT
``` [8](#0-7) 

The `verify_with_cache` method attempts to verify proofs, but if the cache doesn't contain an entry matching the `BatchInfoExt` type, it will call the actual signature verification which will fail due to the hash mismatch.

## Impact Explanation

**Severity: CRITICAL** (up to $1,000,000 per Aptos Bug Bounty)

This vulnerability causes **Consensus Safety Violations**, which is a Critical severity issue. Specifically:

1. **Consensus Split**: Different validators accept/reject the same block based on their cache state, violating the fundamental BFT safety property that honest validators agree on block validity.

2. **Network Partition**: Validators with expired cache entries cannot verify converted proofs and permanently diverge from the main chain, requiring manual intervention or hardfork.

3. **Liveness Failure**: If enough validators lose cache entries (through restarts, evictions, or late joins), quorum cannot be reached for block proposals containing converted proofs, halting the network.

4. **Cryptographic Invariant Violation**: The system breaks the fundamental security assumption that digital signatures are independently verifiable. Signature validity becomes dependent on ephemeral cache state rather than cryptographic properties.

This meets the Critical severity criteria: "Consensus/Safety violations" and "Non-recoverable network partition (requires hardfork)".

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability will manifest in production environments due to:

1. **Cache Capacity Limits**: The proof cache has bounded size (1024 entries in testing). In a high-throughput blockchain processing thousands of batches per epoch, cache eviction is inevitable.

2. **Validator Restarts**: Validators regularly restart for upgrades, configuration changes, or crash recovery. Each restart clears the in-memory cache.

3. **Network Growth**: New validators continuously join the network. These nodes lack cached proof entries and will immediately encounter verification failures.

4. **Normal Operation**: No attacker action is required. The vulnerability triggers during routine consensus operations when validators create proposals using converted proofs from their local queues.

The combination of bounded cache size, non-persistent storage, and type conversion in the critical path makes this vulnerability highly likely to occur in production.

## Recommendation

**Fix: Verify signatures against the original type before conversion**

The conversion should only occur AFTER signature verification succeeds, and the signature should be re-created for the new type structure OR the conversion should be removed entirely to maintain type consistency.

**Option 1: Re-sign after conversion**
```rust
impl From<ProofOfStore<BatchInfo>> for ProofOfStore<BatchInfoExt> {
    fn from(proof: ProofOfStore<BatchInfo>) -> Self {
        let (info, sig) = proof.unpack();
        let info_ext: BatchInfoExt = info.into();
        // Signature is now invalid for info_ext
        // Must either:
        // 1. Keep the original BatchInfo alongside BatchInfoExt
        // 2. Store both signatures
        // 3. Don't convert at all
        Self {
            info: info_ext,
            multi_signature: sig, // This is the bug!
        }
    }
}
```

**Option 2: Maintain type consistency (Recommended)**
```rust
// Remove the conversion entirely. Keep proofs in their original
// BatchInfo type throughout the system. Only convert for
// compatibility when necessary at serialization boundaries.

// In round_manager.rs, don't convert:
UnverifiedEvent::ProofOfStoreMsg(p) => {
    if !self_message {
        p.verify(max_num_batches, validator, proof_cache)?;
    }
    // Remove conversion - keep as BatchInfo
    VerifiedEvent::ProofOfStoreMsg(p) // No .into()
}
```

**Option 3: Store original hash with converted type**
```rust
pub struct ProofOfStore<T> {
    info: T,
    multi_signature: AggregateSignature,
    original_hash: HashValue, // Add this field
}

// Verify against original_hash instead of rehashing info
```

The recommended approach is Option 2: maintain type consistency throughout the system to avoid cryptographic invalidation.

## Proof of Concept

```rust
// Rust reproduction demonstrating the vulnerability

use aptos_crypto::{bls12381, hash::CryptoHash};
use aptos_consensus_types::proof_of_store::{BatchInfo, BatchInfoExt, ProofOfStore};
use aptos_types::aggregate_signature::AggregateSignature;

#[test]
fn test_signature_invalidity_after_conversion() {
    // Step 1: Create a BatchInfo
    let batch_info = BatchInfo::new(
        PeerId::random(),
        BatchId::new(1),
        1, // epoch
        1000, // expiration
        HashValue::random(),
        100, // num_txns
        10000, // num_bytes
        0, // gas_bucket_start
    );
    
    // Step 2: Compute hashes
    let batch_info_hash = batch_info.hash();
    
    let batch_info_ext: BatchInfoExt = batch_info.clone().into();
    let batch_info_ext_hash = batch_info_ext.hash();
    
    // Step 3: Verify hashes are DIFFERENT
    assert_ne!(
        batch_info_hash, 
        batch_info_ext_hash,
        "Hashes should be different due to enum discriminator"
    );
    
    // Step 4: Create a signature for BatchInfo
    let signer = ValidatorSigner::random([0u8; 32]);
    let signature = signer.sign(&batch_info).unwrap();
    
    // Step 5: Verify signature is valid for BatchInfo
    let verifier = ValidatorVerifier::new(vec![signer.public_key()]);
    assert!(verifier.verify_signature(&batch_info, &signature).is_ok());
    
    // Step 6: Convert to ProofOfStore<BatchInfoExt> (preserving signature)
    let proof_batch_info = ProofOfStore::new(
        batch_info.clone(),
        AggregateSignature::new(signature.clone())
    );
    let proof_batch_info_ext: ProofOfStore<BatchInfoExt> = proof_batch_info.into();
    
    // Step 7: Try to verify signature against BatchInfoExt
    // WITHOUT cache (simulating cache miss)
    let result = verifier.verify_signature(
        &proof_batch_info_ext.info(), 
        proof_batch_info_ext.signature()
    );
    
    // Step 8: Verification FAILS
    assert!(
        result.is_err(),
        "Signature should be invalid for BatchInfoExt because hash is different"
    );
    
    println!("✗ Vulnerability confirmed: Signature becomes invalid after conversion");
    println!("  BatchInfo hash:    {:?}", batch_info_hash);
    println!("  BatchInfoExt hash: {:?}", batch_info_ext_hash);
}
```

**Notes**

The vulnerability fundamentally stems from type conversion that changes cryptographic hash values while preserving signatures. The system's reliance on caching to mask this invalidity creates a false sense of security—signatures appear valid due to cache hits, but are cryptographically invalid if verified independently.

This breaks the **Cryptographic Correctness** invariant (invariant #10) and the **Consensus Safety** invariant (invariant #2). Any system where cryptographic validity depends on cache state rather than mathematical properties is fundamentally insecure.

The issue is particularly insidious because it may not manifest immediately in testing (where caches rarely overflow and nodes rarely restart), but will cause catastrophic failures in production under realistic conditions.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L46-58)
```rust
#[derive(
    Clone, Debug, Deserialize, Serialize, CryptoHasher, BCSCryptoHash, PartialEq, Eq, Hash,
)]
pub struct BatchInfo {
    author: PeerId,
    batch_id: BatchId,
    epoch: u64,
    expiration: u64,
    digest: HashValue,
    num_txns: u64,
    num_bytes: u64,
    gas_bucket_start: u64,
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L192-203)
```rust
#[derive(
    Clone, Debug, Deserialize, Serialize, CryptoHasher, BCSCryptoHash, PartialEq, Eq, Hash,
)]
pub enum BatchInfoExt {
    V1 {
        info: BatchInfo,
    },
    V2 {
        info: BatchInfo,
        extra: ExtraBatchInfo,
    },
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L604-614)
```rust
impl From<ProofOfStoreMsg<BatchInfo>> for ProofOfStoreMsg<BatchInfoExt> {
    fn from(proof_msg: ProofOfStoreMsg<BatchInfo>) -> Self {
        Self {
            proofs: proof_msg
                .proofs
                .into_iter()
                .map(|proof| proof.into())
                .collect(),
        }
    }
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L635-652)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
        let batch_info_ext: BatchInfoExt = self.info.clone().into();
        if let Some(signature) = cache.get(&batch_info_ext) {
            if signature == self.multi_signature {
                return Ok(());
            }
        }
        let result = validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!(
                "Failed to verify ProofOfStore for batch: {:?}",
                self.info
            ));
        if result.is_ok() {
            cache.insert(batch_info_ext, self.multi_signature.clone());
        }
        result
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L702-710)
```rust
impl From<ProofOfStore<BatchInfo>> for ProofOfStore<BatchInfoExt> {
    fn from(proof: ProofOfStore<BatchInfo>) -> Self {
        let (info, sig) = proof.unpack();
        Self {
            info: info.into(),
            multi_signature: sig,
        }
    }
}
```

**File:** consensus/src/round_manager.rs (L212-220)
```rust
            UnverifiedEvent::ProofOfStoreMsg(p) => {
                if !self_message {
                    p.verify(max_num_batches, validator, proof_cache)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["proof_of_store"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::ProofOfStoreMsg(Box::new((*p).into()))
            },
```

**File:** consensus/consensus-types/src/opt_proposal_msg.rs (L213-216)
```rust
        let proof_cache = ProofCache::new(1024);
        assert!(msg
            .verify(signer.author(), &validators, &proof_cache, false)
            .is_ok());
```

**File:** consensus/consensus-types/src/common.rs (L517-539)
```rust
    fn verify_with_cache<T>(
        proofs: &[ProofOfStore<T>],
        validator: &ValidatorVerifier,
        proof_cache: &ProofCache,
    ) -> anyhow::Result<()>
    where
        T: TBatchInfo + Send + Sync + 'static,
        BatchInfoExt: From<T>,
    {
        let unverified: Vec<_> = proofs
            .iter()
            .filter(|proof| {
                proof_cache
                    .get(&BatchInfoExt::from(proof.info().clone()))
                    .is_none_or(|cached_proof| cached_proof != *proof.multi_signature())
            })
            .collect();
        unverified
            .par_iter()
            .with_min_len(2)
            .try_for_each(|proof| proof.verify(validator, proof_cache))?;
        Ok(())
    }
```
