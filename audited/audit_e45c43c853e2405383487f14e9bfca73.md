# Audit Report

## Title
Unhandled Panic Propagation in Token Indexer Causes Complete Indexer Process Crash

## Summary
Multiple functions in the token indexer use `.unwrap()` on `Result` types without proper error handling in their callers, allowing panics to cascade and crash the entire indexer process when processing malformed on-chain token events or resources.

## Finding Description

The indexer's token processing pipeline contains multiple critical `.unwrap()` calls that can panic when encountering malformed data. These panics propagate through the task execution layer and terminate the entire indexer process.

**Vulnerable Call Sites:** [1](#0-0) [2](#0-1) [3](#0-2) [4](#0-3) 

**Usage in Token Processor:**

These vulnerable functions are called extensively throughout the token processing pipeline: [5](#0-4) [6](#0-5) [7](#0-6) 

**Panic Propagation Path:**

When a panic occurs in these functions, it propagates through the async task execution: [8](#0-7) 

The runtime spawns multiple processor tasks and waits for them to complete. If any task panics due to an unwrap failure, the entire indexer process crashes at line 218.

**Attack Scenario:**

1. Attacker creates an on-chain token transaction with a correctly-typed event (e.g., `0x4::collection::BurnEvent` or `0x1::object::TransferEvent`) but malformed event data
2. The event type matches the expected pattern in `V2TokenEvent::from_event()`
3. `serde_json::from_value()` fails to deserialize the malformed data, returning an `Err`
4. The `.unwrap()` call at line 358 or 382 panics
5. Panic propagates up through `parse_v2_token()` → `process_transactions()` → tokio task
6. Task join fails in runtime, triggering process-wide panic
7. Entire indexer terminates

**Why This Breaks Security Guarantees:**

The indexer lacks defensive error handling, violating the principle of graceful degradation. A single malformed transaction causes complete service unavailability rather than being skipped or logged.

## Impact Explanation

This vulnerability achieves **High Severity** per the Aptos bug bounty program criteria:

- **API crashes**: The indexer provides critical API services for blockchain explorers, wallets, and dApps. Complete indexer unavailability breaks all dependent services
- **Persistent failure**: If the malformed transaction is permanently on-chain at a specific version, the indexer will crash repeatedly when attempting to process that version, requiring code changes to fix
- **No graceful recovery**: Unlike transient errors, panics provide no opportunity for retry logic or error logging

The impact is classified as High rather than Critical because:
- The indexer does not participate in consensus or transaction execution
- Validator nodes continue operating normally
- No funds are at risk
- The core blockchain functionality remains intact

However, ecosystem-wide indexer unavailability represents significant operational disruption.

## Likelihood Explanation

**Likelihood: High**

This vulnerability is highly likely to be exploited because:

1. **Low attacker requirements**: Any user can submit transactions with token events. No special privileges, validator access, or significant resources required
2. **Multiple attack surfaces**: At least 8 different unwrap sites across event and resource processing
3. **Natural occurrence**: Even non-malicious bugs in Move contracts could trigger this through accidentally malformed event emissions
4. **Discoverable**: Attackers can test locally by examining which event types trigger unwrap paths
5. **Persistent impact**: Once triggered, the indexer cannot progress past the problematic version without code changes

The only barrier is that the attacker must craft event data that:
- Has a valid type string matching expected patterns
- Contains JSON that fails deserialization into the expected struct

This is trivial to achieve with basic understanding of JSON serialization.

## Recommendation

Replace all `.unwrap()` calls with proper error handling that logs the error and continues processing:

**For event processing functions:**

```rust
impl BurnEvent {
    pub fn from_event(event: &Event, txn_version: i64) -> anyhow::Result<Option<Self>> {
        let event_type = event.typ.to_string();
        match V2TokenEvent::from_event(event_type.as_str(), &event.data, txn_version) {
            Ok(Some(V2TokenEvent::BurnEvent(inner))) => Ok(Some(inner)),
            Ok(_) => Ok(None),
            Err(e) => {
                aptos_logger::warn!(
                    "Failed to parse BurnEvent at version {}: {:?}",
                    txn_version,
                    e
                );
                Ok(None) // Skip malformed events rather than crashing
            }
        }
    }
}
```

**For resource processing functions:** [9](#0-8) 

Replace with:

```rust
let resource = MoveResource::from_write_resource(
    write_resource,
    0,
    txn_version,
    0,
);

match resource.data.as_ref() {
    Some(data) => match V2TokenResource::from_resource(&type_str, data, txn_version) {
        Ok(V2TokenResource::AptosCollection(inner)) => Ok(Some(inner)),
        Ok(_) => Ok(None),
        Err(e) => {
            aptos_logger::warn!(
                "Failed to parse AptosCollection at version {}: {:?}",
                txn_version,
                e
            );
            Ok(None)
        }
    },
    None => Ok(None),
}
```

**For JSON serialization:** [10](#0-9) 

Replace line 104 with:

```rust
let serialized_data = serde_json::to_value(&write_resource.data.data)
    .context("Failed to serialize write_resource data")?;

if let V2TokenResource::ObjectCore(inner) = V2TokenResource::from_resource(
    &type_str,
    &serialized_data,
    txn_version,
)? {
    // ... rest of code
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_api_types::{Event, MoveType};
    use serde_json::json;

    #[test]
    #[should_panic(expected = "Failed to parse")]
    fn test_malformed_burn_event_causes_panic() {
        // Create an event with correct type but malformed data
        let malformed_event = Event {
            guid: aptos_api_types::EventGuid {
                creation_number: aptos_api_types::U64::from(0),
                account_address: aptos_api_types::Address::from_hex_literal("0x1").unwrap(),
            },
            sequence_number: aptos_api_types::U64::from(0),
            typ: MoveType::Struct(aptos_api_types::MoveStructTag {
                address: aptos_api_types::Address::from_hex_literal("0x4").unwrap(),
                module: aptos_api_types::IdentStr::from_str("collection").unwrap(),
                name: aptos_api_types::IdentStr::from_str("BurnEvent").unwrap(),
                generic_type_params: vec![],
            }),
            // Malformed data: missing required "index" field or wrong type
            data: json!({
                "token": "0xabc",
                // "index" field missing or malformed
                "index": "not_a_number"  
            }),
        };

        // This will panic because unwrap() is called on the error result
        let result = BurnEvent::from_event(&malformed_event, 12345);
        // The test should panic before reaching this line
    }
}
```

**Notes:**

The indexer is a critical infrastructure component that, while not participating in consensus, provides essential API services for the Aptos ecosystem. The lack of defensive error handling creates an availability vulnerability that can be triggered by any user submitting malformed token transactions, making this a High severity issue per the bug bounty criteria.

### Citations

**File:** crates/indexer/src/models/token_models/v2_token_utils.rs (L89-114)
```rust
    pub fn from_write_resource(
        write_resource: &WriteResource,
        txn_version: i64,
    ) -> anyhow::Result<Option<Self>> {
        let type_str = format!(
            "{}::{}::{}",
            write_resource.data.typ.address,
            write_resource.data.typ.module,
            write_resource.data.typ.name
        );
        if !V2TokenResource::is_resource_supported(type_str.as_str()) {
            return Ok(None);
        }
        if let V2TokenResource::ObjectCore(inner) = V2TokenResource::from_resource(
            &type_str,
            &serde_json::to_value(&write_resource.data.data).unwrap(),
            txn_version,
        )? {
            Ok(Some(Self {
                object_core: inner,
                state_key_hash: standardize_address(write_resource.state_key_hash.as_str()),
            }))
        } else {
            Ok(None)
        }
    }
```

**File:** crates/indexer/src/models/token_models/v2_token_utils.rs (L165-179)
```rust
        let resource = MoveResource::from_write_resource(
            write_resource,
            0, // Placeholder, this isn't used anyway
            txn_version,
            0, // Placeholder, this isn't used anyway
        );

        if let V2TokenResource::AptosCollection(inner) =
            V2TokenResource::from_resource(&type_str, resource.data.as_ref().unwrap(), txn_version)?
        {
            Ok(Some(inner))
        } else {
            Ok(None)
        }
    }
```

**File:** crates/indexer/src/models/token_models/v2_token_utils.rs (L358-358)
```rust
            V2TokenEvent::from_event(event_type.as_str(), &event.data, txn_version).unwrap()
```

**File:** crates/indexer/src/models/token_models/v2_token_utils.rs (L382-382)
```rust
            V2TokenEvent::from_event(event_type.as_str(), &event.data, txn_version).unwrap()
```

**File:** crates/indexer/src/processors/token_processor.rs (L1096-1096)
```rust
                        ObjectWithMetadata::from_write_resource(wr, txn_version).unwrap()
```

**File:** crates/indexer/src/processors/token_processor.rs (L1169-1169)
```rust
                if let Some(burn_event) = BurnEvent::from_event(event, txn_version).unwrap() {
```

**File:** crates/indexer/src/processors/token_processor.rs (L1172-1172)
```rust
                if let Some(transfer_event) = TransferEvent::from_event(event, txn_version).unwrap()
```

**File:** crates/indexer/src/runtime.rs (L213-218)
```rust
            let task = tokio::spawn(async move { other_tailer.process_next_batch().await });
            tasks.push(task);
        }
        let batches = match futures::future::try_join_all(tasks).await {
            Ok(res) => res,
            Err(err) => panic!("Error processing transaction batches: {:?}", err),
```
