# Audit Report

## Title
Memory Exhaustion via Unbounded Batch Accumulation with Far-Future Expiration Timestamps

## Summary
The `receive_batches()` function in `proof_manager.rs` accepts batches with arbitrary expiration timestamps without validation. Unlike `SignedBatchInfo` messages which enforce expiration limits, `BatchMsg` verification lacks expiration timestamp bounds checking. This allows batches with far-future expirations to accumulate indefinitely in memory, bypassing cleanup mechanisms and potentially causing memory exhaustion.

## Finding Description

The vulnerability stems from an asymmetry in expiration timestamp validation between two message types:

**SignedBatchInfo Messages** (properly validated): [1](#0-0) 

This validation ensures expiration timestamps cannot exceed `current_time + max_batch_expiry_gap_usecs` (default 60 seconds).

**BatchMsg Messages** (missing validation): [2](#0-1) 

The `BatchMsg::verify()` method checks author validity, batch counts, and structural integrity, but does **not** validate expiration timestamps against reasonable bounds.

**Attack Flow:**

1. A malicious validator crafts a `BatchMsg` containing batches with expiration timestamps set to far-future values (e.g., year 3000, or `u64::MAX`)
2. The message passes network deserialization and enters `UnverifiedEvent::verify()`: [3](#0-2) 

Note that `max_batch_expiry_gap_usecs` is **not** passed to `BatchMsg::verify()`, unlike `SignedBatchInfo::verify()`.

3. The batch passes through `BatchCoordinator::handle_batches_msg()` which only validates transaction/byte limits: [4](#0-3) 

4. Batches are sent to `ProofManager` and inserted without expiration validation: [5](#0-4) 

5. The `insert_batches()` function stores them in memory structures without checking expiration bounds: [6](#0-5) 

6. Cleanup mechanisms only remove batches where `expiration <= current_timestamp`: [7](#0-6) 

Batches with far-future expirations are never cleaned up until that timestamp is reached, causing indefinite accumulation in `items`, `author_to_batches`, and `expirations` data structures.

**Invariant Violated:** Resource Limits - "All operations must respect gas, storage, and computational limits" (Invariant #9). The system fails to bound memory consumption from incoming batch messages.

## Impact Explanation

**Severity: Medium**

This qualifies as Medium severity per Aptos bug bounty criteria:
- **Memory exhaustion** leading to validator node performance degradation
- **State inconsistencies** as nodes may crash or behave unpredictably under memory pressure
- Not Critical because it requires validator access and doesn't directly cause fund loss or permanent network failure

**Concrete Impact:**
- Each `BatchMsg` can contain up to 20 batches (default `receiver_max_num_batches`) [8](#0-7) 

- Each batch can contain up to 100 transactions (default `receiver_max_batch_txns`) [9](#0-8) 

- Multiple data structures store batch data: `HashMap<BatchKey, QueueItem>`, `HashMap<PeerId, BTreeMap<BatchSortKey, BatchInfoExt>>`, `TimeExpirations<BatchSortKey>`, and `HashMap<TxnSummaryWithExpiration, u64>`

- A single malicious validator can send hundreds of such messages, each accumulating permanently in memory
- Memory pressure can cause OOM crashes, severe performance degradation, or consensus liveness issues

## Likelihood Explanation

**Likelihood: Medium-High** (given attacker has validator access)

**Attacker Requirements:**
- Must be a validator in the current epoch (validated at line 448-453 of `types.rs`)
- Must be able to send `BatchMsg` over the consensus network
- No collusion with other validators required

**Feasibility:**
- Single malicious validator can exploit this repeatedly
- No rate limiting on batch expiration timestamps
- Default configuration makes this immediately exploitable
- Attack is simple: just set `expiration` field to a large value when constructing batches

**Note on Validator Access:** While this requires validator privileges, Byzantine validators are explicitly part of the BFT threat model (up to 1/3 Byzantine validators tolerated). However, per the strict validation checklist requirement of "no validator insider access required", this finding may be considered out of scope despite being a genuine vulnerability within the Byzantine fault tolerance assumptions.

## Recommendation

Add expiration timestamp validation to `BatchMsg::verify()` method, mirroring the validation in `SignedBatchInfo::verify()`: [2](#0-1) 

**Proposed Fix:**
```rust
pub fn verify(
    &self,
    peer_id: PeerId,
    max_num_batches: usize,
    max_batch_expiry_gap_usecs: u64,  // Add this parameter
    verifier: &ValidatorVerifier,
) -> anyhow::Result<()> {
    ensure!(!self.batches.is_empty(), "Empty message");
    ensure!(
        self.batches.len() <= max_num_batches,
        "Too many batches: {} > {}",
        self.batches.len(),
        max_num_batches
    );
    
    let current_time = aptos_infallible::duration_since_epoch().as_micros() as u64;
    
    let epoch_authors = verifier.address_to_validator_index();
    for batch in self.batches.iter() {
        ensure!(
            epoch_authors.contains_key(&batch.author()),
            "Invalid author {} for batch {} in current epoch",
            batch.author(),
            batch.digest()
        );
        ensure!(
            batch.author() == peer_id,
            "Batch author doesn't match sender"
        );
        
        // Add expiration validation
        ensure!(
            batch.expiration() <= current_time + max_batch_expiry_gap_usecs,
            "Batch expiration too far in future: {} > {}",
            batch.expiration(),
            current_time + max_batch_expiry_gap_usecs
        );
        
        batch.verify()?
    }
    Ok(())
}
```

Update the call site in `round_manager.rs`: [3](#0-2) 

Change to pass `max_batch_expiry_gap_usecs` parameter.

## Proof of Concept

```rust
// This PoC demonstrates batch insertion with far-future expiration
// File: consensus/src/quorum_store/tests/proof_manager_expiration_test.rs

#[tokio::test]
async fn test_far_future_batch_accumulation() {
    use crate::quorum_store::{
        proof_manager::ProofManager,
        batch_store::BatchStore,
        types::Batch,
    };
    use aptos_consensus_types::proof_of_store::{BatchInfo, BatchInfoExt};
    use aptos_types::{transaction::SignedTransaction, PeerId};
    use std::sync::Arc;
    
    // Setup
    let peer_id = PeerId::random();
    let batch_store = Arc::new(BatchStore::new(...));
    
    let mut proof_manager = ProofManager::new(
        peer_id,
        100_000,  // back_pressure_total_txn_limit
        1000,     // back_pressure_total_proof_limit
        batch_store,
        true,     // allow_batches_without_pos_in_proposal
        false,    // enable_payload_v2
        60_000_000, // batch_expiry_gap_when_init_usecs (60 seconds)
    );
    
    // Create batch with expiration in year 3000
    let far_future_expiration = 32503680000000000u64; // ~year 3000 in microseconds
    let current_time = aptos_infallible::duration_since_epoch().as_micros() as u64;
    
    assert!(far_future_expiration > current_time + 60_000_000);
    
    let batch_info = BatchInfoExt::new_v1(
        peer_id,
        0u64.into(),  // batch_id
        1,            // epoch
        far_future_expiration,
        HashValue::random(),
        50,           // num_txns
        1024,         // num_bytes
        0,            // gas_bucket_start
    );
    
    let txn_summaries = vec![/* transaction summaries */];
    
    // Insert batch - this should succeed without validation
    proof_manager.receive_batches(vec![(batch_info.clone(), txn_summaries)]);
    
    // Verify batch persists in memory
    let (remaining_txns, remaining_proofs) = proof_manager.batch_proof_queue.remaining_txns_and_proofs();
    assert!(remaining_txns > 0, "Batch should remain in queue");
    
    // Simulate time passing - batch remains indefinitely
    // Even after updating block timestamp to current + 60 seconds,
    // the far-future batch is not cleaned up
    proof_manager.handle_commit_notification(current_time + 60_000_000, vec![]);
    
    let (remaining_txns_after, _) = proof_manager.batch_proof_queue.remaining_txns_and_proofs();
    assert_eq!(remaining_txns, remaining_txns_after, "Far-future batch should not be cleaned up");
    
    // Attacker can repeat this hundreds of times, exhausting memory
}
```

**Compilation Note:** This PoC requires proper test infrastructure setup with batch store initialization and transaction summary construction, but demonstrates the core vulnerability logic.

## Notes

**Critical Distinction:** This vulnerability exists within the legitimate Byzantine fault tolerance threat model where up to 1/3 of validators may be malicious. However, it requires validator-level access to exploit, which may place it outside the scope of the validation checklist requirement for "no validator insider access required." 

The asymmetry between `SignedBatchInfo` and `BatchMsg` validation suggests this is an oversight rather than intentional design, as the same expiration validation mechanism exists for one message type but is missing from the other.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L469-478)
```rust
        if self.expiration()
            > aptos_infallible::duration_since_epoch().as_micros() as u64
                + max_batch_expiry_gap_usecs
        {
            bail!(
                "Batch expiration too far in future: {} > {}",
                self.expiration(),
                aptos_infallible::duration_since_epoch().as_micros() as u64
                    + max_batch_expiry_gap_usecs
            );
```

**File:** consensus/src/quorum_store/types.rs (L433-461)
```rust
    pub fn verify(
        &self,
        peer_id: PeerId,
        max_num_batches: usize,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        ensure!(!self.batches.is_empty(), "Empty message");
        ensure!(
            self.batches.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.batches.len(),
            max_num_batches
        );
        let epoch_authors = verifier.address_to_validator_index();
        for batch in self.batches.iter() {
            ensure!(
                epoch_authors.contains_key(&batch.author()),
                "Invalid author {} for batch {} in current epoch",
                batch.author(),
                batch.digest()
            );
            ensure!(
                batch.author() == peer_id,
                "Batch author doesn't match sender"
            );
            batch.verify()?
        }
        Ok(())
    }
```

**File:** consensus/src/round_manager.rs (L166-173)
```rust
            UnverifiedEvent::BatchMsg(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(Box::new((*b).into()))
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L137-171)
```rust
    fn ensure_max_limits(&self, batches: &[Batch<BatchInfoExt>]) -> anyhow::Result<()> {
        let mut total_txns = 0;
        let mut total_bytes = 0;
        for batch in batches.iter() {
            ensure!(
                batch.num_txns() <= self.max_batch_txns,
                "Exceeds batch txn limit {} > {}",
                batch.num_txns(),
                self.max_batch_txns,
            );
            ensure!(
                batch.num_bytes() <= self.max_batch_bytes,
                "Exceeds batch bytes limit {} > {}",
                batch.num_bytes(),
                self.max_batch_bytes,
            );

            total_txns += batch.num_txns();
            total_bytes += batch.num_bytes();
        }
        ensure!(
            total_txns <= self.max_total_txns,
            "Exceeds total txn limit {} > {}",
            total_txns,
            self.max_total_txns,
        );
        ensure!(
            total_bytes <= self.max_total_bytes,
            "Exceeds total bytes limit: {} > {}",
            total_bytes,
            self.max_total_bytes,
        );

        Ok(())
    }
```

**File:** consensus/src/quorum_store/proof_manager.rs (L80-86)
```rust
    pub(crate) fn receive_batches(
        &mut self,
        batch_summaries: Vec<(BatchInfoExt, Vec<TxnSummaryWithExpiration>)>,
    ) {
        self.batch_proof_queue.insert_batches(batch_summaries);
        self.update_remaining_txns_and_proofs();
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L258-320)
```rust
    pub fn insert_batches(
        &mut self,
        batches_with_txn_summaries: Vec<(BatchInfoExt, Vec<TxnSummaryWithExpiration>)>,
    ) {
        let start = Instant::now();

        for (batch_info, txn_summaries) in batches_with_txn_summaries.into_iter() {
            let batch_sort_key = BatchSortKey::from_info(&batch_info);
            let batch_key = BatchKey::from_info(&batch_info);

            // If the batch is either committed or the txn summary already exists, skip
            // inserting this batch.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.is_committed() || item.txn_summaries.is_some())
            {
                continue;
            }

            self.author_to_batches
                .entry(batch_info.author())
                .or_default()
                .insert(batch_sort_key.clone(), batch_info.clone());
            self.expirations
                .add_item(batch_sort_key, batch_info.expiration());

            // We only count txn summaries first time it is added to the queue
            // and only if the proof already exists.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.proof.is_some())
            {
                for txn_summary in &txn_summaries {
                    *self
                        .txn_summary_num_occurrences
                        .entry(*txn_summary)
                        .or_insert(0) += 1;
                }
            }

            match self.items.entry(batch_key) {
                Entry::Occupied(mut entry) => {
                    entry.get_mut().txn_summaries = Some(txn_summaries);
                },
                Entry::Vacant(entry) => {
                    entry.insert(QueueItem {
                        info: batch_info,
                        proof: None,
                        proof_insertion_time: None,
                        txn_summaries: Some(txn_summaries),
                    });
                },
            }
        }

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
        counters::PROOF_QUEUE_ADD_BATCH_SUMMARIES_DURATION.observe_duration(start.elapsed());
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L324-339)
```rust
    fn gc_expired_batch_summaries_without_proofs(&mut self) {
        let timestamp = aptos_infallible::duration_since_epoch().as_micros() as u64;
        self.items.retain(|_, item| {
            if item.is_committed() || item.proof.is_some() || item.info.expiration() > timestamp {
                true
            } else {
                self.author_to_batches
                    .get_mut(&item.info.author())
                    .map(|queue| queue.remove(&BatchSortKey::from_info(&item.info)));
                counters::GARBAGE_COLLECTED_IN_PROOF_QUEUE_COUNTER
                    .with_label_values(&["expired_batch_without_proof"])
                    .inc();
                false
            }
        });
    }
```

**File:** config/src/config/quorum_store_config.rs (L120-120)
```rust
            receiver_max_batch_txns: 100,
```

**File:** config/src/config/quorum_store_config.rs (L122-122)
```rust
            receiver_max_num_batches: 20,
```
