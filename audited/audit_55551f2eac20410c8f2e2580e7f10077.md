# Audit Report

## Title
Non-Atomic Pruning Coordination Leads to Storage Inconsistency and Node Startup Failure

## Summary
The `LedgerPruner` executes `LedgerMetadataPruner` first, commits its progress to the database, then executes sub-pruners in parallel. If `LedgerMetadataPruner` succeeds but any sub-pruner fails, the system leaves the database in an inconsistent state. On node restart, the failed sub-pruner attempts to catch up, and if it fails again, the node cannot start due to panic in initialization code.

## Finding Description

The pruning system violates the **State Consistency** and **atomicity** invariants due to lack of transaction coordination across multiple database writes.

**Normal Execution Flow:** [1](#0-0) 

The `LedgerMetadataPruner.prune()` method is called first, which atomically commits both data deletion and progress update to the database: [2](#0-1) 

Then sub-pruners execute in parallel: [3](#0-2) 

**The Vulnerability:**

If `LedgerMetadataPruner` succeeds (committing `LedgerPrunerProgress = target_version` to the database) but any sub-pruner fails, the early return at line 84 prevents execution of line 87, leaving in-memory progress at the old value but database progress at the new value.

**Database State After Partial Failure:**
- `LedgerPrunerProgress` in DB: **target_version** (committed by LedgerMetadataPruner)
- `VersionDataSchema` entries: **deleted** for versions in range
- Successful sub-pruner data (e.g., events): **deleted**, progress markers updated
- Failed sub-pruner data (e.g., transactions): **not deleted**, progress markers at old value
- In-memory `self.progress`: **old value** (line 87 never executed)

**Node Restart Scenario:**

On restart, the parent `LedgerPruner` initializes using metadata progress from the database: [4](#0-3) 

Each sub-pruner attempts to catch up during initialization. For example, `TransactionPruner`: [5](#0-4) 

If the sub-pruner's catch-up fails (line 101), the initialization fails and propagates up. The parent initialization uses `.expect()`: [6](#0-5) 

**Result:** The node **panics and cannot start**.

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty program criteria:

1. **Validator Node Unavailability**: If a sub-pruner consistently fails (due to corruption, disk errors, or bugs), the affected node cannot restart, causing validator downtime and network degradation.

2. **Storage Inconsistency**: The database enters an inconsistent state where metadata claims data is pruned up to version X, but actual data stores have mixed pruning states. This violates the **State Consistency** invariant that "state transitions must be atomic."

3. **Significant Protocol Violation**: The pruning operation is not atomic across all storage components, breaking the fundamental expectation that either all data is pruned or none is pruned for a given version range.

If multiple nodes experience similar failures (e.g., due to a common bug in a sub-pruner or widespread disk issues), this could escalate to a network-wide availability problem, potentially qualifying as **Critical Severity** ("Total loss of liveness/network availability").

## Likelihood Explanation

**Likelihood: Medium to High**

Triggering conditions are realistic and can occur in production:

1. **Disk I/O Errors**: Storage hardware failures, out-of-space conditions, or I/O timeouts can cause database write failures in sub-pruners.

2. **Database Corruption**: Any corruption in a sub-pruner's database column family will cause repeated failures during catch-up on every restart.

3. **Bugs in Pruner Logic**: Implementation bugs in any of the 7 sub-pruners (EventStorePruner, TransactionPruner, etc.) that cause intermittent or persistent failures.

4. **Resource Exhaustion**: Memory exhaustion or thread pool saturation during parallel sub-pruner execution could cause failures.

Once the inconsistency occurs, it is **persistent** until manual intervention, as the node cannot restart to self-heal.

## Recommendation

Implement atomic pruning across all components using one of these approaches:

**Option 1: Two-Phase Commit Protocol**
```rust
fn prune(&self, max_versions: usize) -> Result<Version> {
    let mut progress = self.progress();
    let target_version = self.target_version();

    while progress < target_version {
        let current_batch_target_version = 
            min(progress + max_versions as Version, target_version);

        // Phase 1: Prepare all batches
        let metadata_batch = self.ledger_metadata_pruner
            .prepare_batch(progress, current_batch_target_version)?;
        
        let sub_batches: Vec<_> = THREAD_MANAGER.get_background_pool().install(|| {
            self.sub_pruners.par_iter()
                .map(|p| p.prepare_batch(progress, current_batch_target_version))
                .collect::<Result<_>>()
        })?;

        // Phase 2: Commit all batches atomically or rollback all
        // If any commit fails, rollback all previously committed batches
        match self.atomic_commit(metadata_batch, sub_batches) {
            Ok(_) => {
                progress = current_batch_target_version;
                self.record_progress(progress);
            }
            Err(e) => {
                // Rollback logic
                return Err(e);
            }
        }
    }
    Ok(target_version)
}
```

**Option 2: Only Update Metadata Progress After All Sub-Pruners Succeed**

Move the metadata progress update to occur AFTER all sub-pruners succeed:

```rust
fn prune(&self, max_versions: usize) -> Result<Version> {
    // ... existing code ...
    
    while progress < target_version {
        let current_batch_target_version = 
            min(progress + max_versions as Version, target_version);

        // Delete metadata data but DON'T update progress yet
        self.ledger_metadata_pruner
            .prune_data_only(progress, current_batch_target_version)?;

        // Execute sub-pruners
        THREAD_MANAGER.get_background_pool().install(|| {
            self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                sub_pruner.prune(progress, current_batch_target_version)
                    .map_err(|err| anyhow!("{} failed: {err}", sub_pruner.name()))
            })
        })?;

        // Only NOW update metadata progress
        self.ledger_metadata_pruner
            .update_progress_only(current_batch_target_version)?;
        
        progress = current_batch_target_version;
        self.record_progress(progress);
    }
    Ok(target_version)
}
```

**Option 3: Add Recovery Mechanism with Retry Limits**

Allow graceful degradation with retry limits and error logging instead of panicking:

```rust
// In LedgerPruner::new()
for sub_pruner in &sub_pruners {
    match sub_pruner.catch_up_with_retry(progress, metadata_progress, MAX_RETRIES) {
        Ok(_) => continue,
        Err(e) => {
            error!("Sub-pruner {} failed to catch up after {} retries: {}. 
                    Leaving inconsistent state - manual intervention required.",
                   sub_pruner.name(), MAX_RETRIES, e);
            // Don't panic - allow node to start in degraded mode
            // or attempt automatic recovery
        }
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use std::sync::atomic::{AtomicBool, Ordering};
    
    // Create a mock sub-pruner that fails on demand
    struct FailingSubPruner {
        should_fail: Arc<AtomicBool>,
    }
    
    impl DBSubPruner for FailingSubPruner {
        fn name(&self) -> &str { "FailingSubPruner" }
        
        fn prune(&self, _current: Version, _target: Version) -> Result<()> {
            if self.should_fail.load(Ordering::SeqCst) {
                Err(anyhow!("Simulated pruner failure"))
            } else {
                Ok(())
            }
        }
    }
    
    #[test]
    fn test_inconsistent_state_on_partial_failure() {
        // Setup: Create LedgerPruner with failing sub-pruner
        let should_fail = Arc::new(AtomicBool::new(false));
        let failing_pruner = Box::new(FailingSubPruner { 
            should_fail: Arc::clone(&should_fail) 
        });
        
        let mut pruner = create_test_ledger_pruner(failing_pruner);
        pruner.set_target_version(200);
        
        // Step 1: Make sub-pruner fail during pruning
        should_fail.store(true, Ordering::SeqCst);
        
        let result = pruner.prune(100);
        assert!(result.is_err()); // Pruning fails
        
        // Step 2: Check database state
        let metadata_progress = pruner.ledger_metadata_pruner.progress().unwrap();
        assert_eq!(metadata_progress, 200); // Metadata progress IS updated
        
        let in_memory_progress = pruner.progress();
        assert_eq!(in_memory_progress, 0); // In-memory progress NOT updated
        
        // Step 3: Simulate restart
        drop(pruner);
        
        // Node attempts to reinitialize
        let result = LedgerPruner::new(ledger_db, None);
        
        // Assertion: Initialization fails with panic or error
        assert!(result.is_err() || std::panic::catch_unwind(|| {
            LedgerPruner::new(ledger_db, None).expect("Should panic here")
        }).is_err());
    }
}
```

## Notes

This vulnerability is a **design flaw** in the pruning coordination logic. The system assumes that database writes across different pruners are atomic, but they are not. Each pruner commits its batch independently, creating a window for partial failures that leave the system in an inconsistent state.

The issue affects all 8 storage components in the pruning system (1 metadata pruner + 7 sub-pruners), making it a fundamental reliability problem that impacts production nodes under operational stress conditions.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L75-76)
```rust
            self.ledger_metadata_pruner
                .prune(progress, current_batch_target_version)?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L78-84)
```rust
            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L172-174)
```rust
        let pruner = LedgerPruner {
            target_version: AtomicVersion::new(metadata_progress),
            progress: AtomicVersion::new(metadata_progress),
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_metadata_pruner.rs (L47-56)
```rust
        let mut batch = SchemaBatch::new();
        for version in current_progress..target_version {
            batch.delete::<VersionDataSchema>(&version)?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::LedgerPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        self.ledger_metadata_db.write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L84-101)
```rust
        let progress = get_or_initialize_subpruner_progress(
            ledger_db.transaction_db_raw(),
            &DbMetadataKey::TransactionPrunerProgress,
            metadata_progress,
        )?;

        let myself = TransactionPruner {
            transaction_store,
            ledger_db,
            internal_indexer_db,
        };

        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up TransactionPruner."
        );
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L146-149)
```rust
        let pruner = Arc::new(
            LedgerPruner::new(ledger_db, internal_indexer_db)
                .expect("Failed to create ledger pruner."),
        );
```
