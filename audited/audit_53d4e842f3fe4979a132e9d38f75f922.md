# Audit Report

## Title
Array Index Out-of-Bounds Panic in Shamir Secret Sharing Reconstruction Causes Validator Node Crash

## Summary
The `lagrange_for_subset()` function in the Shamir secret sharing implementation performs direct array indexing without bounds validation. When player indices greater than or equal to the domain size are provided, the function panics due to out-of-bounds array access, causing an immediate crash of the validator node attempting secret reconstruction during DKG operations.

## Finding Description

The Aptos DKG (Distributed Key Generation) system uses Shamir secret sharing for threshold cryptography. Two critical implementations contain identical out-of-bounds vulnerabilities:

**Vulnerability 1: Arkworks Implementation** [1](#0-0) 

The `lagrange_for_subset()` function computes Lagrange coefficients for polynomial interpolation. At the critical line, it directly indexes into `derivative_evals` without validation: [2](#0-1) 

The `derivative_evals` array has length equal to `domain.size()` (the next power of 2 ≥ n). If any index in the input `indices` slice is ≥ `domain.size()`, this causes an immediate panic.

**Vulnerability 2: BLSTRS Implementation** [3](#0-2) 

The `accumulator_poly_helper()` function directly indexes into the `omegas` array without bounds checking. If any player ID is ≥ `omegas.len()` (which equals the domain size), this panics.

Additionally, line 180 in the same file has another unchecked array access: [4](#0-3) 

**Root Cause: Missing Input Validation**

The `Player` struct allows arbitrary ID values through its public field: [5](#0-4) 

The TODO comment acknowledges this design flaw. When DKG operations call `decrypt_secret_share_from_transcript()`, player indices are converted without validation: [6](#0-5) 

This leads to the weighted configuration's `get_share_index()` method, which also lacks bounds checking: [7](#0-6) 

Accessing `self.weights[i]` at line 200 panics if `i >= self.weights.len()`.

## Impact Explanation

**Severity: High**

This vulnerability causes validator node crashes during DKG secret share decryption and reconstruction operations. The impact includes:

1. **Validator Node Availability Loss**: Any validator attempting to decrypt shares or participate in reconstruction with invalid player indices will experience an unrecoverable panic, terminating the process.

2. **DKG Protocol Disruption**: If triggered during epoch transitions when validators must decrypt their DKG shares to participate in randomness generation, this could prevent validators from coming online in the new epoch.

3. **Consensus Liveness Impact**: While not directly breaking consensus safety, widespread crashes during DKG operations could impact network liveness if sufficient validators are affected.

This meets the **High Severity** criteria per the Aptos bug bounty program: "Validator node slowdowns/crashes" and "Significant protocol violations."

## Likelihood Explanation

**Likelihood: Medium-to-Low in Current Production**

Currently, production code paths derive player indices from legitimate validator set lookups: [8](#0-7) 

However, the vulnerability can be triggered by:

1. **Configuration Mismatches**: If DKG public parameters are deserialized with a domain size smaller than expected, legitimate validator indices could exceed bounds.

2. **Epoch Transition Edge Cases**: Race conditions or state inconsistencies during epoch changes where validator set size changes.

3. **Future Code Changes**: Any new code path that processes shares from external sources without validation would immediately expose this vulnerability.

4. **Weighted Config Bugs**: The unchecked array access in `get_share_index()` can panic even with indices < n if the weights array is improperly sized.

The lack of defensive programming means this is a time bomb waiting for triggering conditions.

## Recommendation

Add comprehensive bounds validation at all entry points:

**1. Validate player_idx in decrypt_secret_share_from_transcript:**

```rust
fn decrypt_secret_share_from_transcript(
    pub_params: &Self::PublicParams,
    trx: &Self::Transcript,
    player_idx: u64,
    dk: &Self::NewValidatorDecryptKey,
) -> anyhow::Result<(Self::DealtSecretShare, Self::DealtPubKeyShare)> {
    let n = pub_params.pvss_config.wconfig.get_total_num_players();
    ensure!(
        (player_idx as usize) < n,
        "Invalid player_idx {}: must be < {}",
        player_idx,
        n
    );
    
    let (sk, pk) = trx.main.decrypt_own_share(
        &pub_params.pvss_config.wconfig,
        &Player { id: player_idx as usize },
        dk,
        &pub_params.pvss_config.pp,
    );
    // ... rest of function
}
```

**2. Add bounds check in lagrange_for_subset:**

```rust
pub fn lagrange_for_subset(&self, indices: &[usize]) -> Vec<F> {
    assert!(
        indices.len() >= self.t,
        "subset size {} is smaller than threshold t={}",
        indices.len(),
        self.t
    );
    
    // NEW: Validate all indices are within domain bounds
    let domain_size = self.domain.size();
    for &idx in indices {
        assert!(
            idx < domain_size,
            "Invalid index {}: must be < domain size {}",
            idx,
            domain_size
        );
    }
    
    let xs_vec: Vec<F> = indices.iter().map(|i| self.domain.element(*i)).collect();
    // ... rest of function
}
```

**3. Add bounds check in get_share_index:**

```rust
pub fn get_share_index(&self, i: usize, j: usize) -> Option<usize> {
    if i >= self.weights.len() {
        return None;
    }
    if j < self.weights[i] {
        Some(self.starting_index[i] + j)
    } else {
        None
    }
}
```

**4. Make Player.id field private and enforce validation in constructor (breaking change).**

## Proof of Concept

```rust
#[test]
#[should_panic(expected = "index out of bounds")]
fn test_lagrange_out_of_bounds_panic() {
    use ark_bn254::Fr;
    use crate::arkworks::shamir::ShamirThresholdConfig;
    
    let n = 5;
    let t = 3;
    let config = ShamirThresholdConfig::<Fr>::new(t, n);
    
    // Domain size is next_power_of_two(5) = 8
    // Valid indices are [0, 7]
    // Passing index 8 should panic
    let invalid_indices = vec![0, 1, 8]; // 8 >= domain_size
    
    // This will panic with "index out of bounds"
    let _coeffs = config.lagrange_for_subset(&invalid_indices);
}

#[test]
#[should_panic(expected = "index out of bounds")]
fn test_weighted_config_out_of_bounds_panic() {
    use crate::weighted_config::WeightedConfig;
    use ark_bn254::Fr;
    
    let weights = vec![1, 2, 3];
    let t = 3;
    let config = WeightedConfig::<Fr>::new(t, weights).unwrap();
    
    // Attempting to get share index for player 100 (>= weights.len())
    // will panic in self.weights[i] access
    let invalid_player_id = 100;
    let _idx = config.get_share_index(invalid_player_id, 0);
}
```

## Notes

While current production code paths use validated player indices from legitimate validator set lookups, the absence of defensive bounds checking violates secure coding principles and creates fragility. The vulnerability is real and can cause validator crashes under configuration errors, epoch transition anomalies, or future code changes that introduce external inputs. The fix is straightforward and should be implemented to harden the DKG subsystem against edge cases and future regressions.

### Citations

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L253-290)
```rust
    pub fn lagrange_for_subset(&self, indices: &[usize]) -> Vec<F> {
        // Step 0: check that subset is large enough
        assert!(
            indices.len() >= self.t,
            "subset size {} is smaller than threshold t={}",
            indices.len(),
            self.t
        );

        let xs_vec: Vec<F> = indices.iter().map(|i| self.domain.element(*i)).collect();

        // Step 1: compute poly w/ roots at all x in xs, compute eval at 0
        let vanishing_poly = vanishing_poly::from_roots(&xs_vec);
        let vanishing_poly_at_0 = vanishing_poly.coeffs[0]; // vanishing_poly(0) = const term

        // Step 2 (numerators): for each x in xs, divide poly eval from step 1 by (-x) using batch inversion
        let mut neg_xs: Vec<F> = xs_vec.iter().map(|&x| -x).collect();
        batch_inversion(&mut neg_xs);
        let numerators: Vec<F> = neg_xs
            .iter()
            .map(|&inv_neg_x| vanishing_poly_at_0 * inv_neg_x)
            .collect();

        // Step 3a (denominators): Compute derivative of poly from step 1, and its evaluations
        let derivative = vanishing_poly.differentiate();
        let derivative_evals = derivative.evaluate_over_domain(self.domain).evals; // TODO: with a filter perhaps we don't have to store all evals, but then batch inversion becomes a bit more tedious

        // Step 3b: Only keep the relevant evaluations, then perform a batch inversion
        let mut denominators: Vec<F> = indices.iter().map(|i| derivative_evals[*i]).collect();
        batch_inversion(&mut denominators);

        // Step 4: compute Lagrange coefficients
        numerators
            .into_iter()
            .zip(denominators)
            .map(|(numerator, denom_inv)| numerator * denom_inv)
            .collect()
    }
```

**File:** crates/aptos-crypto/src/blstrs/lagrange.rs (L177-181)
```rust
    let mut denominators = Vec::with_capacity(T.len());
    for i in 0..T.len() {
        debug_assert_ne!(Z[T[i]], Scalar::ZERO);
        denominators.push(Z[T[i]]);
    }
```

**File:** crates/aptos-crypto/src/blstrs/lagrange.rs (L195-202)
```rust
fn accumulator_poly_helper(dom: &BatchEvaluationDomain, T: &[usize]) -> Vec<Scalar> {
    let omegas = dom.get_all_roots_of_unity();

    // Build the subset of $\omega_i$'s for all $i\in T$.
    let mut set = Vec::with_capacity(T.len());
    for &s in T {
        set.push(omegas[s]);
    }
```

**File:** crates/aptos-crypto/src/player.rs (L21-28)
```rust
pub struct Player {
    /// A number from 0 to n-1.
    pub id: usize,
}

/// The point of Player is to provide type-safety: ensure nobody creates out-of-range player IDs.
/// So there is no `new()` method; only the SecretSharingConfig trait is allowed to create them.
// TODO: AFAIK the only way to really enforce this is to put both traits inside the same module (or use unsafe Rust)
```

**File:** types/src/dkg/real_dkg/mod.rs (L422-435)
```rust
    fn decrypt_secret_share_from_transcript(
        pub_params: &Self::PublicParams,
        trx: &Self::Transcript,
        player_idx: u64,
        dk: &Self::NewValidatorDecryptKey,
    ) -> anyhow::Result<(Self::DealtSecretShare, Self::DealtPubKeyShare)> {
        let (sk, pk) = trx.main.decrypt_own_share(
            &pub_params.pvss_config.wconfig,
            &Player {
                id: player_idx as usize,
            },
            dk,
            &pub_params.pvss_config.pp,
        );
```

**File:** crates/aptos-crypto/src/weighted_config.rs (L199-205)
```rust
    pub fn get_share_index(&self, i: usize, j: usize) -> Option<usize> {
        if j < self.weights[i] {
            Some(self.starting_index[i] + j)
        } else {
            None
        }
    }
```

**File:** consensus/src/epoch_manager.rs (L1047-1052)
```rust
        let my_index = new_epoch_state
            .verifier
            .address_to_validator_index()
            .get(&self.author)
            .copied()
            .ok_or_else(|| NoRandomnessReason::NotInValidatorSet)?;
```
