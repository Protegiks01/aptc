# Audit Report

## Title
Consensus Liveness Failure via Unvalidated ExecutionBackpressureConfig Causing Validator Panic

## Summary
The `ExecutionBackpressureConfig` nested struct in `ConsensusConfig` can be deserialized with invalid values (specifically `min_blocks_to_activate: 0` with `Percentile` metric) that pass the `sanitize()` validation but cause validator nodes to panic during proposal generation, breaking consensus liveness.

## Finding Description

The `ConsensusConfig::sanitize()` function validates top-level consensus configuration parameters but completely omits validation of the nested `ExecutionBackpressureConfig` struct and its deeply nested `ExecutionBackpressureLookbackConfig` fields. [1](#0-0) 

The sanitize function validates `SafetyRulesConfig`, `QuorumStoreConfig`, and block limit relationships, but never validates `ExecutionBackpressureConfig` which is defined as: [2](#0-1) 

This config contains `ExecutionBackpressureLookbackConfig` with a critical `min_blocks_to_activate` field: [3](#0-2) 

When a validator is configured with `min_blocks_to_activate: 0` and uses the default `Percentile(0.5)` metric, the following execution path triggers a panic during proposal generation:

1. During proposal generation, `calculate_max_block_sizes()` is called: [4](#0-3) 

2. This calls `get_execution_block_size_backoff()` which checks if enough blocks meet the criteria: [5](#0-4) 

3. With `min_blocks_to_activate: 0`, the condition `sizes.len() >= 0` is always true, even when `sizes` is empty

4. The code then calls `compute_lookback_metric()` with an empty vector: [6](#0-5) 

5. For the `Percentile` variant with an empty `blocks` slice:
   - `blocks.len()` is 0
   - `blocks.len() - 1` underflows to `usize::MAX`
   - `(percentile * 0.0)` evaluates to 0
   - `0.min(usize::MAX)` evaluates to 0  
   - `blocks.get(0)` on an empty slice returns `None`
   - `.expect()` panics with message "guaranteed to be within vector size"

The `Mean` case has a safety check for empty vectors, but the `Percentile` case does not.

This vulnerability triggers when:
- The validator is elected as proposer for a round
- No recent blocks meet the execution time threshold (common at epoch start, low traffic periods, or when `min_block_time_ms_to_activate` is misconfigured to be very high)
- The validator has `min_blocks_to_activate: 0` configured

The same vulnerability exists in the gas limit backoff path: [7](#0-6) 

## Impact Explanation

**Severity: High** (Validator node crashes causing liveness degradation)

This vulnerability breaks the **consensus liveness** invariant. When a validator with this misconfiguration is elected as proposer:

1. The validator process panics and crashes during `generate_proposal_inner()`
2. The round fails as no proposal is generated
3. Other validators timeout and proceed to the next round
4. Network liveness is degraded (increased latency, failed rounds)

If multiple validators deploy this misconfiguration:
- Multiple consecutive failed rounds
- Significant liveness degradation
- Potential for extended network stalls if enough validators affected

This fits the Aptos Bug Bounty **High Severity** criteria:
- "Validator node slowdowns" - Crashed validators cannot participate
- "Significant protocol violations" - Proposers failing to generate proposals violates consensus protocol expectations

While not causing permanent network failure (other validators can continue), this represents a critical configuration validation bypass that should be prevented by the `sanitize()` function.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability can be triggered through:

1. **Accidental Misconfiguration**: A validator operator editing YAML config could set `min_blocks_to_activate: 0` thinking it means "always enable" rather than understanding it means "enable even with zero qualifying blocks"

2. **Malicious Insider**: A validator operator could intentionally configure this to sabotage their own validator during certain rounds

3. **Configuration File Compromise**: If an attacker gains write access to a validator's config files, they could inject this misconfiguration

The vulnerability is particularly insidious because:
- The configuration passes serde deserialization without error
- The configuration passes `sanitize()` without error  
- The validator starts and runs normally
- The crash only occurs when the validator is elected proposer AND no recent blocks meet filtering criteria
- This creates intermittent failures that are hard to debug

The likelihood increases in scenarios with:
- Network reconfigurations or epoch transitions
- Low transaction throughput periods
- Multiple validators deployed from similar configuration templates

## Recommendation

Add comprehensive validation of `ExecutionBackpressureConfig` nested fields in the `sanitize()` function:

```rust
impl ConfigSanitizer for ConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // ... existing validation ...

        // Validate ExecutionBackpressureConfig
        if let Some(exec_backpressure) = &node_config.consensus.execution_backpressure {
            if let Some(txn_limit) = &exec_backpressure.txn_limit {
                Self::sanitize_lookback_config(
                    &sanitizer_name,
                    &txn_limit.lookback_config,
                    "txn_limit"
                )?;
            }
            if let Some(gas_limit) = &exec_backpressure.gas_limit {
                Self::sanitize_lookback_config(
                    &sanitizer_name,
                    &gas_limit.lookback_config,
                    "gas_limit"
                )?;
            }
        }

        Ok(())
    }
}

impl ConsensusConfig {
    fn sanitize_lookback_config(
        sanitizer_name: &str,
        config: &ExecutionBackpressureLookbackConfig,
        context: &str,
    ) -> Result<(), Error> {
        // min_blocks_to_activate must be > 0 to prevent empty vector panic
        if config.min_blocks_to_activate == 0 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_owned(),
                format!(
                    "{}: min_blocks_to_activate must be > 0, got {}",
                    context, config.min_blocks_to_activate
                ),
            ));
        }

        // min_blocks_to_activate should not exceed num_blocks_to_look_at
        if config.min_blocks_to_activate > config.num_blocks_to_look_at {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_owned(),
                format!(
                    "{}: min_blocks_to_activate ({}) cannot exceed num_blocks_to_look_at ({})",
                    context, config.min_blocks_to_activate, config.num_blocks_to_look_at
                ),
            ));
        }

        // Validate percentile is in valid range [0.0, 1.0]
        if let ExecutionBackpressureMetric::Percentile(p) = config.metric {
            if !p.is_finite() || p < 0.0 || p > 1.0 {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name.to_owned(),
                    format!(
                        "{}: percentile must be in range [0.0, 1.0], got {}",
                        context, p
                    ),
                ));
            }
        }

        // Validate target_block_time_ms is reasonable
        if config.target_block_time_ms == 0 {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name.to_owned(),
                format!("{}: target_block_time_ms must be > 0", context),
            ));
        }

        Ok(())
    }
}
```

Additionally, add a defensive check in `compute_lookback_metric()`:

```rust
fn compute_lookback_metric(&self, blocks: &[u64], metric: &ExecutionBackpressureMetric) -> u64 {
    match metric {
        ExecutionBackpressureMetric::Mean => {
            if blocks.is_empty() {
                return 0;
            }
            (blocks.iter().sum::<u64>() as f64 / blocks.len() as f64) as u64
        },
        ExecutionBackpressureMetric::Percentile(percentile) => {
            // Add empty check for defensive programming
            if blocks.is_empty() {
                return 0;
            }
            *blocks
                .get(((percentile * blocks.len() as f64) as usize).min(blocks.len() - 1))
                .expect("guaranteed to be within vector size")
        },
    }
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_types::chain_id::ChainId;

    #[test]
    #[should_panic(expected = "min_blocks_to_activate must be > 0")]
    fn test_invalid_execution_backpressure_min_blocks_zero() {
        // Create a node config with invalid execution backpressure config
        let node_config = NodeConfig {
            consensus: ConsensusConfig {
                execution_backpressure: Some(ExecutionBackpressureConfig {
                    txn_limit: Some(ExecutionBackpressureTxnLimitConfig {
                        lookback_config: ExecutionBackpressureLookbackConfig {
                            num_blocks_to_look_at: 18,
                            min_block_time_ms_to_activate: 50,
                            min_blocks_to_activate: 0, // INVALID: triggers panic
                            metric: ExecutionBackpressureMetric::Percentile(0.5),
                            target_block_time_ms: 90,
                        },
                        min_calibrated_txns_per_block: 30,
                    }),
                    gas_limit: None,
                }),
                ..Default::default()
            },
            ..Default::default()
        };

        // This should fail sanitization but currently passes
        ConsensusConfig::sanitize(&node_config, NodeType::Validator, Some(ChainId::testnet()))
            .expect("Should fail but doesn't due to missing validation");
        
        // This configuration will panic during proposal generation when:
        // 1. Validator is elected proposer
        // 2. No recent blocks meet execution time threshold
        // 3. compute_lookback_metric called with empty vector
    }

    #[test]
    fn test_compute_lookback_metric_empty_vector_panic() {
        let config = PipelineBackpressureConfig::new_no_backoff();
        
        // This panics with Percentile metric and empty vector
        let result = config.compute_lookback_metric(
            &[], // Empty vector
            &ExecutionBackpressureMetric::Percentile(0.5)
        );
        
        // Should return 0 for empty vector but currently panics
        assert_eq!(result, 0);
    }
}
```

To reproduce the validator crash:
1. Deploy a validator with config containing:
```yaml
consensus:
  execution_backpressure:
    txn_limit:
      lookback_config:
        min_blocks_to_activate: 0
        metric:
          Percentile: 0.5
```
2. Wait for validator to be elected proposer during a period with no recent high-execution-time blocks
3. Validator panics in `proposal_generator.rs` line 186 during `generate_proposal_inner()`

## Notes

This vulnerability demonstrates a systematic validation bypass in the configuration sanitization layer. The `ExecutionBackpressureConfig` struct and its nested components contain multiple fields that require semantic validation beyond what serde provides, but the `sanitize()` function completely ignores them.

Other potentially problematic fields that lack validation:
- `percentile` values outside [0.0, 1.0] range
- `target_block_time_ms: 0` (causes division issues)
- `block_execution_overhead_ms > target_block_time_ms` (always saturates to 0)
- `num_blocks_to_look_at: 0` (defeats purpose of lookback)

The fix should validate all semantically meaningful constraints on configuration values, not just structural validity that serde provides.

### Citations

**File:** config/src/config/consensus_config.rs (L120-138)
```rust
pub struct ExecutionBackpressureLookbackConfig {
    /// Look at execution time for this many last blocks
    pub num_blocks_to_look_at: usize,

    /// Only blocks above this threshold are treated as potentially needed recalibration
    /// This is needed as small blocks have overheads that are irrelevant to the transactions
    /// being executed.
    pub min_block_time_ms_to_activate: usize,

    /// Backpressure has a second check, where it only activates if
    /// at least `min_blocks_to_activate` are above `min_block_time_ms_to_activate`
    pub min_blocks_to_activate: usize,

    /// Out of blocks in the window, the metric to use for calibration.
    /// i.e. Percentile(0.5) means take a median of last `num_blocks_to_look_at` blocks.
    pub metric: ExecutionBackpressureMetric,
    /// Recalibrating max block size, to target blocks taking this long.
    pub target_block_time_ms: usize,
}
```

**File:** config/src/config/consensus_config.rs (L190-194)
```rust
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
pub struct ExecutionBackpressureConfig {
    pub txn_limit: Option<ExecutionBackpressureTxnLimitConfig>,
    pub gas_limit: Option<ExecutionBackpressureGasLimitConfig>,
}
```

**File:** config/src/config/consensus_config.rs (L503-532)
```rust
impl ConfigSanitizer for ConsensusConfig {
    fn sanitize(
        node_config: &NodeConfig,
        node_type: NodeType,
        chain_id: Option<ChainId>,
    ) -> Result<(), Error> {
        let sanitizer_name = Self::get_sanitizer_name();

        // Verify that the safety rules and quorum store configs are valid
        SafetyRulesConfig::sanitize(node_config, node_type, chain_id)?;
        QuorumStoreConfig::sanitize(node_config, node_type, chain_id)?;

        // Verify that the consensus-only feature is not enabled in mainnet
        if let Some(chain_id) = chain_id {
            if chain_id.is_mainnet() && is_consensus_only_perf_test_enabled() {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "consensus-only-perf-test should not be enabled in mainnet!".to_string(),
                ));
            }
        }

        // Sender block limits must be <= receiver block limits
        Self::sanitize_send_recv_block_limits(&sanitizer_name, &node_config.consensus)?;

        // Quorum store batches must be <= consensus blocks
        Self::sanitize_batch_block_limits(&sanitizer_name, &node_config.consensus)?;

        Ok(())
    }
```

**File:** consensus/src/liveness/proposal_generator.rs (L176-188)
```rust
    fn compute_lookback_metric(&self, blocks: &[u64], metric: &ExecutionBackpressureMetric) -> u64 {
        match metric {
            ExecutionBackpressureMetric::Mean => {
                if blocks.is_empty() {
                    return 0;
                }
                (blocks.iter().sum::<u64>() as f64 / blocks.len() as f64) as u64
            },
            ExecutionBackpressureMetric::Percentile(percentile) => *blocks
                .get(((percentile * blocks.len() as f64) as usize).min(blocks.len() - 1))
                .expect("guaranteed to be within vector size"),
        }
    }
```

**File:** consensus/src/liveness/proposal_generator.rs (L230-233)
```rust
            if sizes.len() >= lookback_config.min_blocks_to_activate {
                let calibrated_block_size = self
                    .compute_lookback_metric(&sizes, &lookback_config.metric)
                    .max(min_calibrated_txns_per_block);
```

**File:** consensus/src/liveness/proposal_generator.rs (L299-302)
```rust
            if gas_limit_estimates.len() >= lookback_config.min_blocks_to_activate {
                let calibrated_gas_limit = self
                    .compute_lookback_metric(&gas_limit_estimates, &lookback_config.metric)
                    .max(min_calibrated_block_gas_limit);
```

**File:** consensus/src/liveness/proposal_generator.rs (L787-795)
```rust
            let (txn_limit, gas_limit) = self
                .pipeline_backpressure_config
                .get_execution_block_txn_and_gas_limit_backoff(
                    &self
                        .block_store
                        .get_recent_block_execution_times(num_blocks_to_look_at),
                    self.max_block_txns_after_filtering,
                    self.max_block_gas_limit,
                );
```
