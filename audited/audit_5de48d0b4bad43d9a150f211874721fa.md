# Audit Report

## Title
Time-of-Check to Time-of-Use (TOCTOU) Race Condition in Consensus Sync Target Validation Causes Validator Synchronization Failures

## Summary
A race condition exists in the state sync driver's `check_sync_request_progress()` function where multiple non-atomic reads of the ledger info can observe inconsistent states due to concurrent commits from the storage synchronizer. This causes legitimate consensus sync requests to fail with `SyncedBeyondTarget` errors even though the sync target was successfully reached.

## Finding Description

The vulnerability exists in the consensus sync target validation flow within the state sync driver. The `check_sync_request_progress()` function performs multiple separate calls to `fetch_latest_synced_ledger_info()` without atomicity guarantees: [1](#0-0) 

The function determines if the sync request is satisfied using the first read. It then waits for pending storage data to drain: [2](#0-1) 

During this wait period, the storage synchronizer—which runs in separate concurrent tasks—can commit additional transactions, advancing the ledger version beyond the original target. The function then fetches the ledger info again before notifying consensus: [3](#0-2) 

The `handle_satisfied_sync_request()` function checks if we've overshot the target and returns an error: [4](#0-3) 

The root cause is that `fetch_latest_synced_ledger_info()` reads from a lock-free `ArcSwap` cache: [5](#0-4) 

This cache is updated by the storage commit pipeline without coordination: [6](#0-5) 

The logic is contradictory: `sync_request_satisfied()` uses `>=` to determine satisfaction: [7](#0-6) 

But `handle_satisfied_sync_request()` treats `>` as an error condition, even though reaching a version beyond the target still means the target was successfully reached.

The error is defined as: [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos Bug Bounty criteria:

**Validator Node Slowdowns (High)**: The race condition causes legitimate sync operations to fail intermittently during validator catch-up scenarios. When validators attempt to synchronize to consensus targets, they may receive `SyncedBeyondTarget` errors despite successfully reaching the target version. This forces validators to retry sync operations, causing significant delays in synchronization and consensus participation.

The error propagates to consensus through the sync notification response mechanism: [9](#0-8) 

The execution client shows incomplete error handling with a TODO comment: [10](#0-9) 

## Likelihood Explanation

This vulnerability has **HIGH** likelihood of occurrence:

1. **Common Trigger Condition**: The race window occurs whenever the storage synchronizer commits transactions between the satisfaction check (line 541-546) and the final notification (line 595-598). This is normal operation for an actively syncing node.

2. **Explicit Yielding**: The wait loop at line 563 explicitly calls `yield_now().await`, encouraging concurrent task execution and making the race condition more likely.

3. **No Synchronization**: There are no locks, barriers, or coordination mechanisms between `check_sync_request_progress()` and the storage commit pipeline to prevent concurrent updates.

4. **Continuous Syncing**: The continuous syncer actively fetches and commits new data in parallel with consensus sync requests, making concurrent commits highly likely during catch-up scenarios.

## Recommendation

**Option 1 (Preferred)**: Remove the overly strict check in `handle_satisfied_sync_request()`. If the sync request was satisfied (version >= target), it should be considered successful regardless of whether we synced beyond the target:

```rust
// In handle_satisfied_sync_request, change line 346-356:
// Instead of returning error when latest_synced_version > sync_target_version,
// accept it as success since the target was reached
```

**Option 2**: Capture the ledger info atomically at the beginning of `check_sync_request_progress()` and use the same snapshot throughout the function, preventing TOCTOU issues.

**Option 3**: Add a tolerance window to accept versions slightly beyond the target as successful completions.

## Proof of Concept

The vulnerability can be triggered during normal validator synchronization operations when:
1. A validator requests `sync_to_target(version=X)`
2. State sync reaches version X (satisfying the request)
3. Between the satisfaction check and final notification, the storage synchronizer commits additional transactions advancing to version X+N
4. The final check sees version X+N and incorrectly returns `SyncedBeyondTarget` error

This race condition occurs naturally during active synchronization scenarios, particularly when validators are catching up to the network while blocks continue being produced and committed.

## Notes

The defensive check in `state_computer.rs` (lines 187-193) shows that consensus already anticipates scenarios where it might have advanced beyond a sync target, treating it as acceptable. The state sync driver's strict rejection of this condition creates an inconsistency between the two components' expectations.

### Citations

**File:** state-sync/state-sync-driver/src/driver.rs (L541-546)
```rust
                let latest_synced_ledger_info =
                    utils::fetch_latest_synced_ledger_info(self.storage.clone())?;
                if !consensus_sync_request
                    .sync_request_satisfied(&latest_synced_ledger_info, self.time_service.clone())
                {
                    return Ok(()); // The sync request hasn't been satisfied yet
```

**File:** state-sync/state-sync-driver/src/driver.rs (L556-564)
```rust
        while self.storage_synchronizer.pending_storage_data() {
            sample!(
                SampleRate::Duration(Duration::from_secs(PENDING_DATA_LOG_FREQ_SECS)),
                info!("Waiting for the storage synchronizer to handle pending data!")
            );

            // Yield to avoid starving the storage synchronizer threads.
            yield_now().await;
        }
```

**File:** state-sync/state-sync-driver/src/driver.rs (L595-598)
```rust
        let latest_synced_ledger_info =
            utils::fetch_latest_synced_ledger_info(self.storage.clone())?;
        self.consensus_notification_handler
            .handle_satisfied_sync_request(latest_synced_ledger_info)
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L204-206)
```rust
                // Check if we've satisfied the target
                latest_synced_version >= sync_target_version
            },
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L346-355)
```rust
                if latest_synced_version > sync_target_version {
                    let error = Err(Error::SyncedBeyondTarget(
                        latest_synced_version,
                        sync_target_version,
                    ));
                    self.respond_to_sync_target_notification(
                        sync_target_notification,
                        error.clone(),
                    )?;
                    return error;
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L94-98)
```rust
    pub(crate) fn get_latest_ledger_info_option(&self) -> Option<LedgerInfoWithSignatures> {
        let ledger_info_ptr = self.latest_ledger_info.load();
        let ledger_info: &Option<_> = ledger_info_ptr.deref();
        ledger_info.clone()
    }
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L180-182)
```rust
    pub(crate) fn set_latest_ledger_info(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) {
        self.latest_ledger_info
            .store(Arc::new(Some(ledger_info_with_sigs)));
```

**File:** state-sync/state-sync-driver/src/error.rs (L45-46)
```rust
    #[error("Synced beyond the target version. Committed version: {0}, target version: {1}")]
    SyncedBeyondTarget(Version, Version),
```

**File:** consensus/src/state_computer.rs (L216-232)
```rust
        let result = monitor!(
            "sync_to_target",
            self.state_sync_notifier.sync_to_target(target).await
        );

        // Update the latest logical time
        *latest_logical_time = target_logical_time;

        // Similarly, after state synchronization, we have to reset the cache of
        // the BlockExecutor to guarantee the latest committed state is up to date.
        self.executor.reset()?;

        // Return the result
        result.map_err(|error| {
            let anyhow_error: anyhow::Error = error.into();
            anyhow_error.into()
        })
```

**File:** consensus/src/pipeline/execution_client.rs (L669-671)
```rust
        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
```
