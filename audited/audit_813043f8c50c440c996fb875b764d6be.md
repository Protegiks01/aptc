# Audit Report

## Title
TOCTOU Race Condition in Block Executor Allows Stalled Transactions to Execute

## Summary
A Time-Of-Check-To-Time-Of-Use (TOCTOU) race condition exists in `pending_scheduling_and_not_stalled()` where the function releases its lock before returning, allowing the transaction's stall status to change between the check and the caller's subsequent action. This enables stalled transactions to be inserted into the execution queue and execute, defeating the stall mechanism designed to prevent cascading aborts and optimize parallel execution. [1](#0-0) 

## Finding Description

The `pending_scheduling_and_not_stalled()` function acquires a lock, checks both the scheduling status and stall state, then releases the lock and returns the result. The primary caller in `try_increase_executed_once_max_idx()` uses this result to decide whether to insert the transaction into the execution queue. [2](#0-1) 

**The Race Window:**

Between when `pending_scheduling_and_not_stalled()` releases its lock (after checking `num_stalls == 0`) and when the caller inserts the transaction into the execution queue, another thread can call `add_stall()`: [3](#0-2) 

The `add_stall()` function increments `num_stalls` atomically, acquires the status lock, and removes the transaction from the execution queue if it's in `PendingScheduling` state.

**Attack Scenario:**

1. Thread A calls `pending_scheduling_and_not_stalled(idx)` → returns `true` (status is PendingScheduling, num_stalls = 0)
2. Thread B calls `add_stall(idx)` → increments num_stalls to 1, removes idx from execution queue
3. Thread A continues and inserts idx into execution queue (using stale information)
4. Later, a worker pops idx from the queue and calls `start_executing(idx)`
5. `start_executing()` only checks if status is `PendingScheduling` (not whether it's stalled), so it succeeds [4](#0-3) 

The transaction now executes despite being stalled, violating the stall mechanism's invariant that stalled transactions should not be in the execution queue.

## Impact Explanation

This vulnerability qualifies as **Medium severity** under the Aptos bug bounty criteria for the following reasons:

1. **Validator Node Slowdowns**: The stall mechanism is explicitly designed to "constrain optimistic concurrency by limiting cascading aborts" and "avoid scheduling transactions for re-execution until stalls are removed". When stalled transactions execute, they trigger the exact cascading aborts the mechanism was meant to prevent, wasting CPU cycles and slowing down block execution. [5](#0-4) 

2. **Resource Waste**: Stalled transactions that shouldn't be executing consume computational resources that could be used for productive work, reducing overall validator throughput.

3. **Optimization Failure**: While the stall mechanism is described as "best-effort", this race condition makes it significantly less effective, undermining a key performance optimization in the BlockSTMv2 parallel execution engine.

This does **not** reach Critical or High severity because:
- It does not break consensus safety or deterministic execution
- It does not cause fund loss or theft
- It does not create permanent liveness failures
- Transactions will eventually execute correctly after re-execution

## Likelihood Explanation

This race condition has a **high likelihood** of occurring in production:

1. **Natural Concurrency**: The race window exists during normal operation whenever transactions are being scheduled and dependencies are being tracked concurrently by multiple worker threads.

2. **Frequent Operations**: Both `try_increase_executed_once_max_idx()` (called after every 0-th incarnation execution) and `add_stall()` (called during abort propagation) are frequently executed operations.

3. **No Special Conditions Required**: The race requires only normal concurrent execution - no adversarial behavior or special timing is needed.

4. **Wide Race Window**: The window between releasing the lock in `pending_scheduling_and_not_stalled()` and acquiring the execution queue lock in the caller provides sufficient opportunity for the race to occur.

## Recommendation

**Fix: Extend the lock scope to make the check-and-insert operation atomic.**

Modify `try_increase_executed_once_max_idx()` to hold the status lock while inserting into the execution queue, or add a new atomic method that checks and inserts under a single lock acquisition:

```rust
// Option 1: New atomic method in ExecutionStatuses
pub(crate) fn check_and_schedule_if_ready(&self, txn_idx: TxnIndex) -> bool {
    let status = &self.statuses[txn_idx as usize];
    let guard = status.status_with_incarnation.lock();
    
    if guard.pending_scheduling().is_some() && !status.is_stalled() {
        // Insert while holding the lock to prevent TOCTOU
        self.execution_queue_manager.execution_queue.lock().insert(txn_idx);
        return true;
    }
    false
}

// In scheduler_v2.rs, replace lines 1316-1318:
if self.txn_statuses.check_and_schedule_if_ready(idx) {
    // Transaction was successfully scheduled
}
```

**Alternative Fix**: Add a stall check in `start_executing()` to catch any stalled transactions that slip through:

```rust
fn to_executing(
    &self,
    txn_idx: TxnIndex,
    status_guard: &mut StatusWithIncarnation,
) -> Result<Option<Incarnation>, PanicError> {
    let status = &self.statuses[txn_idx as usize];
    
    // Check if stalled before starting execution
    if status.is_stalled() {
        return Ok(None);
    }
    
    let ret = status_guard.start_executing();
    if ret.is_some() {
        status.swap_dependency_status_any(
            &[DependencyStatus::ShouldDefer],
            DependencyStatus::WaitForExecution,
            "start_executing",
        )?;
    }
    Ok(ret)
}
```

## Proof of Concept

```rust
#[test]
fn test_toctou_stalled_transaction_execution() {
    use std::sync::{Arc, Barrier};
    use rayon::scope;
    
    let num_txns = 10;
    let statuses = Arc::new(ExecutionStatuses::new(num_txns));
    let barrier = Arc::new(Barrier::new(2));
    
    let txn_idx = 5;
    
    // Setup: Transaction 5 is in PendingScheduling state, incarnation 1, not stalled
    {
        let status = statuses.get_status_mut(txn_idx);
        *status.status_with_incarnation.lock() = 
            StatusWithIncarnation::new_for_test(SchedulingStatus::PendingScheduling, 1);
        status.next_incarnation_to_abort.store(1, Ordering::Relaxed);
    }
    
    let statuses_clone = statuses.clone();
    let barrier_clone = barrier.clone();
    
    // Thread 1: Simulates try_increase_executed_once_max_idx calling 
    // pending_scheduling_and_not_stalled and then inserting
    let handle1 = std::thread::spawn(move || {
        // Check if should schedule (releases lock)
        let should_schedule = statuses_clone.pending_scheduling_and_not_stalled(txn_idx);
        
        // Wait for thread 2 to add stall
        barrier_clone.wait();
        
        if should_schedule {
            // Insert into queue using stale information
            statuses_clone.get_execution_queue_manager()
                .execution_queue.lock().insert(txn_idx);
        }
        should_schedule
    });
    
    // Thread 2: Adds a stall while thread 1 is between check and insert
    let handle2 = std::thread::spawn(move || {
        barrier.wait();
        
        // Add stall - this should remove from queue, but thread 1 will re-add
        let result = statuses.add_stall(txn_idx);
        result
    });
    
    let should_schedule = handle1.join().unwrap();
    let stall_added = handle2.join().unwrap();
    
    // Verify the race occurred
    assert!(should_schedule); // Thread 1 saw not-stalled
    assert_ok_eq!(stall_added, true); // Thread 2 successfully added stall
    
    // BUG: Transaction is now in queue despite being stalled
    let status = statuses.get_status(txn_idx);
    assert!(status.is_stalled()); // Transaction IS stalled
    
    let in_queue = statuses.get_execution_queue_manager()
        .execution_queue.lock().contains(&txn_idx);
    assert!(in_queue); // But it's STILL in the execution queue (TOCTOU bug)
    
    // Demonstrate it can be executed
    let popped = statuses.get_execution_queue_manager().pop_next();
    assert_some_eq!(popped, txn_idx);
    
    // start_executing succeeds even though transaction is stalled
    let incarnation = statuses.start_executing(txn_idx);
    assert_some!(incarnation.unwrap()); // BUG: Stalled transaction started execution!
}
```

## Notes

The TODO comment at line 1315 of `scheduler_v2.rs` suggests the authors were aware of potential lock management issues: "TODO(BlockSTMv2): Audit / should we keep ever_executed lock instead of re-acquiring." This indicates recognition that re-acquiring locks can be problematic, but the TOCTOU vulnerability in `pending_scheduling_and_not_stalled()` appears to have been overlooked. [6](#0-5) 

While the stall mechanism is documented as "best-effort", the explicit removal and re-addition logic in `add_stall()` and `remove_stall()` demonstrates that preventing stalled transactions from executing is an intended invariant, not merely a performance hint.

### Citations

**File:** aptos-move/block-executor/src/scheduler_status.rs (L99-111)
```rust
Key aspects of the stall mechanism:

1. Purpose:
   - Records that a transaction has dependencies that are more likely to cause re-execution
   - Can be used to:
     a) Avoid scheduling transactions for re-execution until stalls are removed
     b) Guide handling when another transaction observes a dependency during execution
   - Helps constrain optimistic concurrency by limiting cascading aborts

2. Behavior:
   - Best-effort approach that allows flexibility in concurrency scenarios, but such that
     high-priority transactions may still be re-executed even in stalled state

```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L363-405)
```rust
    pub(crate) fn add_stall(&self, txn_idx: TxnIndex) -> Result<bool, PanicError> {
        let status = &self.statuses[txn_idx as usize];
        if status.num_stalls.fetch_add(1, Ordering::SeqCst) == 0 {
            // Acquire write lock for (non-monitor) shortcut modifications.
            let status_guard = status.status_with_incarnation.lock();

            let dependency_status =
                DependencyStatus::from_u8(status.dependency_shortcut.load(Ordering::Relaxed))?;

            match (status_guard.pending_scheduling(), dependency_status) {
                (Some(0), DependencyStatus::ShouldDefer) => {
                    // Adding a stall requires being recorded in aborted dependencies in scheduler_v2,
                    // which in turn only happens in the scheduler after a successful abort (that must
                    // increment the incarnation of the status).
                    return Err(code_invariant_error("0-th incarnation in add_stall"));
                },
                (Some(_), DependencyStatus::ShouldDefer) => {
                    self.execution_queue_manager.remove_from_schedule(txn_idx);
                    // Shortcut not affected.
                },
                (Some(_), DependencyStatus::IsSafe | DependencyStatus::WaitForExecution) => {
                    return Err(code_invariant_error(
                        "Inconsistent status and dependency shortcut in add_stall",
                    ));
                },
                (None, DependencyStatus::IsSafe) => {
                    // May not update IsSafe dependency status at an incorrect time in the future
                    // (i.e. ABA), as observing num_stalls = 0 under status is required to set
                    // IsSafe status, but impossible until the corresponding remove_stall (that
                    // starts only after add_stall finishes).
                    status
                        .dependency_shortcut
                        .store(DependencyStatus::ShouldDefer as u8, Ordering::Relaxed);
                },
                (None, DependencyStatus::WaitForExecution | DependencyStatus::ShouldDefer) => {
                    // Executing or aborted: shortcut not affected.
                },
            }

            return Ok(true);
        }
        Ok(false)
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L508-516)
```rust
    pub(crate) fn start_executing(
        &self,
        txn_idx: TxnIndex,
    ) -> Result<Option<Incarnation>, PanicError> {
        let status_guard = &mut *self.statuses[txn_idx as usize]
            .status_with_incarnation
            .lock();
        self.to_executing(txn_idx, status_guard)
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L744-748)
```rust
    pub(crate) fn pending_scheduling_and_not_stalled(&self, txn_idx: TxnIndex) -> bool {
        let status = &self.statuses[txn_idx as usize];
        let guard = status.status_with_incarnation.lock();
        guard.pending_scheduling().is_some() && !status.is_stalled()
    }
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1315-1315)
```rust
                // TODO(BlockSTMv2): Audit / should we keep ever_executed lock instead of re-acquiring.
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1316-1318)
```rust
                if self.txn_statuses.pending_scheduling_and_not_stalled(idx) {
                    execution_queue_manager.execution_queue.lock().insert(idx);
                }
```
