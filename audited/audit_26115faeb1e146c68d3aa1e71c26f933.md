# Audit Report

## Title
Incomplete Subscription Termination Causes Resource Exhaustion During Fallback Recovery

## Summary
The `terminate_all_subscriptions()` function in `enter_fallback_mode()` does not synchronously drop pending messages from old subscriptions in the channel queue. Each queued message (up to 1000 by default) from terminated subscriptions triggers redundant unsubscribe requests and processing overhead, potentially causing resource exhaustion and delayed recovery during critical fallback operations.

## Finding Description

When the consensus observer enters fallback mode, the code comment at line 238 states the intent is "to ensure we don't process any more messages" from old subscriptions. However, the implementation has a critical gap: [1](#0-0) 

The `terminate_all_subscriptions()` call only removes peers from the active subscriptions map synchronously: [2](#0-1) 

Messages already queued in the network channel (up to 1000 messages by default) remain in the queue and are processed in subsequent event loop iterations. The message queue is created with this capacity: [3](#0-2) 

When each queued message is processed, the verification check fails and calls `unsubscribe_from_peer()` again: [4](#0-3) 

This spawns a new async task for EACH queued message: [5](#0-4) 

**Attack Scenario:**
1. Malicious peer (or slow legitimate peer) that observer subscribes to sends burst of 1000 messages to fill the channel queue
2. Observer detects synchronization issue and calls `enter_fallback_mode()`
3. Subscriptions are terminated but 1000 messages remain queued
4. Each message triggers: verification failure, spawning of unsubscribe async task, metrics updates, logging
5. 1000 redundant async tasks are spawned, each attempting to send RPC with 5-second timeout
6. This delays processing of critical state sync notifications and wastes system resources

## Impact Explanation

This qualifies as **Medium severity** per Aptos bug bounty criteria due to:

1. **State inconsistencies requiring intervention**: If the message queue is repeatedly filled during fallback attempts, the observer may fail to recover properly, requiring manual intervention to restore consensus observation functionality

2. **Resource exhaustion**: Spawning up to 1000 concurrent async tasks, each with network timeouts, memory allocation for task state, and logging overhead creates unnecessary resource pressure during an already critical recovery phase

3. **Liveness degradation**: The event loop prioritizes network messages over state sync notifications. Processing 1000 queued rejection messages delays critical state sync completion notifications, extending the fallback recovery window beyond the configured 10-minute duration

4. **Exploitability**: A malicious subscribed peer can deliberately flood the message queue before the observer enters fallback mode, amplifying the resource exhaustion

While this doesn't directly cause fund loss or consensus safety violations, it can cause temporary unavailability of consensus observer functionality and delayed recovery, requiring intervention.

## Likelihood Explanation

**Likelihood: Medium**

- Consensus observers routinely enter fallback mode when subscriptions become unhealthy or progress stalls (configured checks every 5 seconds)
- The default channel size of 1000 messages can realistically be filled by a fast peer or during network bursts
- Any subscribed peer (malicious or experiencing issues) can contribute messages to the queue
- The redundant unsubscribe task spawning happens automatically for every queued message from terminated subscriptions
- No special privileges required - just subscription to a peer that fills the queue

## Recommendation

**Short-term fix**: Clear the message channel when entering fallback mode, or add a flag to skip processing messages from terminated subscriptions without spawning additional tasks.

**Recommended implementation:**

1. Track a "fallback_mode" flag to skip verification and task spawning for messages during fallback
2. Alternatively, drain and discard queued messages from the channel when `terminate_all_subscriptions()` is called
3. Add a check in `verify_message_for_subscription()` to avoid spawning unsubscribe tasks if peer was already removed

Example fix for `verify_message_for_subscription()`:

```rust
pub fn verify_message_for_subscription(
    &mut self,
    message_sender: PeerNetworkId,
) -> Result<(), Error> {
    // Check if the message is from an active subscription
    if let Some(active_subscription) = self
        .active_observer_subscriptions
        .lock()
        .get_mut(&message_sender)
    {
        active_subscription.update_last_message_receive_time();
        return Ok(());
    }

    // Return error without spawning redundant unsubscribe tasks
    // (peer was already unsubscribed during termination)
    Err(Error::InvalidMessageError(format!(
        "Received message from unexpected peer: {}!",
        message_sender
    )))
}
```

## Proof of Concept

```rust
#[tokio::test]
async fn test_fallback_mode_queued_message_processing() {
    // Setup consensus observer with mocked components
    let network_id = NetworkId::Public;
    let (peers_and_metadata, consensus_observer_client) = 
        create_consensus_observer_client(&[network_id]);
    
    let consensus_observer_config = ConsensusObserverConfig::default();
    let db_reader = create_mock_db_reader();
    
    // Create observer and subscription manager
    let mut observer = create_consensus_observer(...);
    
    // Create subscription to a peer
    let peer = create_peer_and_connection(network_id, peers_and_metadata.clone(), 1, None, true);
    create_observer_subscription(&mut observer.subscription_manager, peer, ...);
    
    // Fill message queue with 1000 messages from the peer
    for i in 0..1000 {
        let message = create_test_ordered_block_message(i);
        message_sender.push((), ConsensusObserverNetworkMessage::new(peer, message));
    }
    
    // Verify queue is full
    assert_eq!(message_receiver.len(), 1000);
    
    // Enter fallback mode
    observer.enter_fallback_mode().await;
    
    // Verify subscription was terminated
    assert!(observer.subscription_manager.get_active_subscription_peers().is_empty());
    
    // Process first queued message
    if let Some(message) = message_receiver.next().await {
        observer.process_network_message(message).await;
    }
    
    // Verify that an async task was spawned to send unsubscribe
    // (this would normally be checked via metrics or task monitoring)
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // Demonstrate that all 1000 messages would trigger the same behavior
    // Each spawning a redundant unsubscribe task
    assert_eq!(metrics::get_counter(&metrics::OBSERVER_REJECTED_MESSAGES), 1);
}
```

## Notes

The discrepancy between the code comment ("to ensure we don't process any more messages") and actual behavior (messages are still processed and rejected) indicates this is likely an unintended design gap rather than a deliberate choice. The inefficiency of spawning redundant async tasks for each queued message compounds the resource impact during critical recovery phases.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L236-246)
```rust
    /// Enters fallback mode for consensus observer by invoking state sync
    async fn enter_fallback_mode(&mut self) {
        // Terminate all active subscriptions (to ensure we don't process any more messages)
        self.subscription_manager.terminate_all_subscriptions();

        // Clear all the pending block state
        self.clear_pending_block_state().await;

        // Start syncing for the fallback
        self.state_sync_manager.sync_for_fallback();
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L263-268)
```rust
    /// Terminates all active subscriptions
    pub fn terminate_all_subscriptions(&mut self) {
        for peer_network_id in self.get_active_subscription_peers() {
            self.unsubscribe_from_peer(peer_network_id);
        }
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L307-359)
```rust
    /// Unsubscribes from the given peer by sending an unsubscribe request
    fn unsubscribe_from_peer(&mut self, peer_network_id: PeerNetworkId) {
        // Remove the peer from the active subscriptions
        self.active_observer_subscriptions
            .lock()
            .remove(&peer_network_id);

        // Send an unsubscribe request to the peer and process the response.
        // Note: we execute this asynchronously, as we don't need to wait for the response.
        let consensus_observer_client = self.consensus_observer_client.clone();
        let consensus_observer_config = self.consensus_observer_config;
        tokio::spawn(async move {
            // Send the unsubscribe request to the peer
            let unsubscribe_request = ConsensusObserverRequest::Unsubscribe;
            let response = consensus_observer_client
                .send_rpc_request_to_peer(
                    &peer_network_id,
                    unsubscribe_request,
                    consensus_observer_config.network_request_timeout_ms,
                )
                .await;

            // Process the response
            match response {
                Ok(ConsensusObserverResponse::UnsubscribeAck) => {
                    info!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Successfully unsubscribed from peer: {}!",
                            peer_network_id
                        ))
                    );
                },
                Ok(response) => {
                    // We received an invalid response
                    warn!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Got unexpected response type: {:?}",
                            response.get_label()
                        ))
                    );
                },
                Err(error) => {
                    // We encountered an error while sending the request
                    warn!(
                        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                            "Failed to send unsubscribe request to peer: {}! Error: {:?}",
                            peer_network_id, error
                        ))
                    );
                },
            }
        });
    }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L378-384)
```rust
        // Otherwise, the message is not from an active subscription.
        // Send another unsubscribe request, and return an error.
        self.unsubscribe_from_peer(message_sender);
        Err(Error::InvalidMessageError(format!(
            "Received message from unexpected peer, and not an active subscription: {}!",
            message_sender
        )))
```

**File:** config/src/config/consensus_observer_config.rs (L68-68)
```rust
            max_network_channel_size: 1000,
```
