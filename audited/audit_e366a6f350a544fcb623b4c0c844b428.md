# Audit Report

## Title
Epoch Ending Stream Engine Missing Continuity Validation Enabling Bandwidth Waste DoS

## Summary
The `EpochEndingStreamEngine::transform_client_response_into_notification()` function does not validate that epoch ending ledger infos in responses form a continuous sequence, allowing malicious peers to send gapped responses that cause premature stream completion, stream resets, and wasted node resources.

## Finding Description

The vulnerability exists in the epoch ending ledger info stream processing logic. When the stream engine receives a response from a network peer, it fails to validate epoch continuity within the response payload. [1](#0-0) 

The code extracts only the **last** epoch from the response vector and uses it to update stream state without verifying that all intermediate epochs from `next_stream_epoch` to `last_received_epoch` are present. This allows an attacker to construct responses like `[epoch 1, epoch 2, epoch 100]` (skipping epochs 3-99), which will pass stream engine validation.

The attack flow:
1. Node requests epochs 1-100 from a malicious peer
2. Malicious peer responds with epochs 1-10, 99, 100 (skipping 11-98)
3. Stream engine validates `start_epoch == next_stream_epoch` (1 == 1) ✓
4. Stream engine extracts `last_received_epoch = 100` from the last ledger info
5. Stream engine sets `next_stream_epoch = 101` and marks `stream_is_complete = true`
6. Notification with gapped data is sent to bootstrapper [2](#0-1) 

The bootstrapper will cryptographically validate each epoch sequentially and fail when it encounters the gap (epoch 99 cannot be verified against epoch 10's validator set): [3](#0-2) 

This causes the stream to be reset with `PayloadProofFailed` feedback: [4](#0-3) 

## Impact Explanation

This qualifies as **High Severity** per Aptos bug bounty criteria ("Validator node slowdowns") because:

1. **Bandwidth Waste**: Nodes download incomplete epoch data that will be rejected, wasting network resources
2. **CPU Waste**: Cryptographic verification is performed on data that will ultimately fail, consuming validator CPU cycles
3. **Synchronization Delays**: Each gapped response requires a full stream reset and recreation cycle, significantly delaying node synchronization
4. **DoS Vector**: A persistent malicious peer (or multiple colluding peers) can repeatedly send gapped responses, forcing victim nodes into an inefficient loop of downloading → validating → failing → resetting
5. **Liveness Impact**: During bootstrap, nodes must complete epoch synchronization before participating in consensus; prolonged exploitation could delay validator onboarding

The storage layer provides defense-in-depth by enforcing epoch continuity at commit time: [5](#0-4) 

However, this downstream validation occurs **after** wasted resources have already been consumed, making the attack effective despite not corrupting committed state.

## Likelihood Explanation

**Likelihood: High**

Attack requirements:
- Attacker controls or impersonates a network peer (trivial on permissionless P2P networks)
- No validator keys, stake, or special privileges required
- Simple response manipulation (remove middle epochs from legitimate response)
- No race conditions or timing dependencies

The attack is trivially automatable and can target:
- Bootstrapping validators (highest impact)
- State-syncing full nodes
- Any node fetching historical epoch ending ledger infos

## Recommendation

Add epoch continuity validation before accepting the response and updating stream state:

```rust
// In transform_client_response_into_notification(), after line 1612:

// Verify that we received at least one ledger info
if ledger_infos.is_empty() {
    return Err(Error::AptosDataClientResponseIsInvalid(format!(
        "Received an empty epoch ending ledger info response! Request: {:?}",
        client_request
    )));
}

// NEW: Verify epoch continuity in the response
let mut expected_epoch = request.start_epoch;
for ledger_info_with_sigs in ledger_infos.iter() {
    let epoch = ledger_info_with_sigs.ledger_info().epoch();
    if epoch != expected_epoch {
        return Err(Error::AptosDataClientResponseIsInvalid(format!(
            "Epoch gap detected in response! Expected epoch: {}, got: {}. Request: {:?}",
            expected_epoch, epoch, client_request
        )));
    }
    expected_epoch = expected_epoch.checked_add(1).ok_or_else(|| {
        Error::IntegerOverflow("Expected epoch has overflown!".into())
    })?;
}

// Return the last epoch
ledger_infos
    .last()
    .map(|ledger_info| ledger_info.ledger_info().epoch())
    .unwrap_or(request.start_epoch)
```

This ensures the stream engine rejects gapped responses immediately without wasting downstream validation resources.

## Proof of Concept

```rust
#[test]
fn test_epoch_gap_attack() {
    use crate::stream_engine::EpochEndingStreamEngine;
    use aptos_data_client::interface::ResponsePayload;
    use aptos_types::ledger_info::LedgerInfoWithSignatures;
    
    // Setup: Stream expecting epochs 1-100
    let mut engine = EpochEndingStreamEngine {
        request: GetAllEpochEndingLedgerInfosRequest { start_epoch: 1 },
        end_epoch: 100,
        next_stream_epoch: 1,
        next_request_epoch: 1,
        stream_is_complete: false,
    };
    
    // Attack: Malicious peer sends epochs 1, 2, 100 (skipping 3-99)
    let gapped_ledger_infos = vec![
        create_epoch_ending_ledger_info(1),
        create_epoch_ending_ledger_info(2),
        create_epoch_ending_ledger_info(100),  // Gap!
    ];
    
    let client_request = DataClientRequest::EpochEndingLedgerInfos(
        EpochEndingLedgerInfosRequest {
            start_epoch: 1,
            end_epoch: 100,
        }
    );
    
    let response = ResponsePayload::EpochEndingLedgerInfos(gapped_ledger_infos);
    
    // Process response - currently succeeds, should fail
    let result = engine.transform_client_response_into_notification(
        &client_request,
        response,
        Arc::new(U64IdGenerator::new()),
    );
    
    // BUG: This succeeds when it should fail
    assert!(result.is_ok());
    
    // BUG: Stream marked complete despite missing epochs 3-99
    assert_eq!(engine.next_stream_epoch, 101);
    assert!(engine.stream_is_complete);
    
    // Downstream bootstrapper will fail validation and reset stream,
    // wasting all the resources spent downloading and processing this response
}
```

**Notes**

While downstream cryptographic validation prevents corrupted state from being committed to the database, this validation occurs **after** significant resources have been wasted. The stream engine's lack of basic sanity checks (epoch continuity) allows malicious peers to force victim nodes into inefficient retry loops, constituting a validator slowdown attack vector per the High severity criteria. The fix is straightforward: validate response structure before accepting it and updating internal stream state.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L1603-1633)
```rust
                // Identify the last received epoch and bound it appropriately
                let last_received_epoch = match &client_response_payload {
                    ResponsePayload::EpochEndingLedgerInfos(ledger_infos) => {
                        // Verify that we received at least one ledger info
                        if ledger_infos.is_empty() {
                            return Err(Error::AptosDataClientResponseIsInvalid(format!(
                                "Received an empty epoch ending ledger info response! Request: {:?}",
                                client_request
                            )));
                        }

                        // Return the last epoch
                        ledger_infos
                            .last()
                            .map(|ledger_info| ledger_info.ledger_info().epoch())
                            .unwrap_or(request.start_epoch)
                    },
                    _ => invalid_response_type!(client_response_payload),
                };
                let last_received_epoch =
                    bound_by_range(last_received_epoch, request.start_epoch, request.end_epoch);

                // Update the local stream notification tracker
                self.next_stream_epoch = last_received_epoch.checked_add(1).ok_or_else(|| {
                    Error::IntegerOverflow("Next stream epoch has overflown!".into())
                })?;

                // Check if the stream is complete
                if last_received_epoch >= self.end_epoch {
                    self.stream_is_complete = true;
                }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1094-1106)
```rust
        for epoch_ending_ledger_info in epoch_ending_ledger_infos {
            if let Err(error) = self.verified_epoch_states.update_verified_epoch_states(
                &epoch_ending_ledger_info,
                &self.driver_configuration.waypoint,
            ) {
                self.reset_active_stream(Some(NotificationAndFeedback::new(
                    notification_id,
                    NotificationFeedback::PayloadProofFailed,
                )))
                .await?;
                return Err(error);
            }
        }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L1539-1556)
```rust
    pub async fn reset_active_stream(
        &mut self,
        notification_and_feedback: Option<NotificationAndFeedback>,
    ) -> Result<(), Error> {
        if let Some(active_data_stream) = &self.active_data_stream {
            let data_stream_id = active_data_stream.data_stream_id;
            utils::terminate_stream_with_feedback(
                &mut self.streaming_client,
                data_stream_id,
                notification_and_feedback,
            )
            .await?;
        }

        self.active_data_stream = None;
        self.speculative_stream_state = None;
        Ok(())
    }
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L571-582)
```rust
        // Verify epoch continuity.
        let current_epoch = self
            .ledger_db
            .metadata_db()
            .get_latest_ledger_info_option()
            .map_or(0, |li| li.ledger_info().next_block_epoch());
        ensure!(
            ledger_info_with_sig.ledger_info().epoch() == current_epoch,
            "Gap in epoch history. Trying to put in LedgerInfo in epoch: {}, current epoch: {}",
            ledger_info_with_sig.ledger_info().epoch(),
            current_epoch,
        );
```
