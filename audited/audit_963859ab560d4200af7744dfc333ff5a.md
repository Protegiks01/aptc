# Audit Report

## Title
Indexer gRPC Transaction Filter Size Check Bypass via Late Validation Timing

## Summary
The `max_filter_size_bytes` protection in `parse_transaction_filter()` is ineffective at preventing memory exhaustion attacks because it validates the filter size AFTER the gRPC layer has already deserialized the entire protobuf message and allocated memory. An attacker can send transaction filters up to 256 MB that consume server memory before being rejected by the 10 KB application-level limit.

## Finding Description

The indexer-grpc data service implements a two-tier size limit system:

1. **gRPC layer limit**: 256 MB via `max_decoding_message_size` [1](#0-0) [2](#0-1) 

2. **Application layer limit**: 10 KB via `DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES` [3](#0-2) 

The vulnerability occurs because the application-level validation happens too late in the request processing pipeline:

**Attack Flow:**
1. Attacker crafts a `GetTransactionsRequest` with a deeply nested `BooleanTransactionFilter` in the `transaction_filter` field
2. The encoded protobuf size is 100 MB (larger than the 10 KB limit but under the 256 MB gRPC limit)
3. The tonic/prost gRPC framework **fully deserializes** the message, allocating ~100 MB of memory for the nested filter structure
4. Service handler receives the deserialized request and calls `parse_transaction_filter()` [4](#0-3) 
5. The function calls `BooleanTransactionFilter::new_from_proto()` which checks `proto_filter.encoded_len()` against the 10 KB limit [5](#0-4) [6](#0-5) 
6. The check fails and returns an error
7. **But the memory was already allocated in step 3**

The size check operates on an already-deserialized message, making it ineffective at preventing the resource exhaustion it was designed to prevent. By sending multiple concurrent requests with large filters, an attacker can exhaust server memory and cause out-of-memory crashes.

The protobuf structure allows arbitrary nesting depth via recursive `LogicalAnd`, `LogicalOr`, and `LogicalNot` fields: [7](#0-6) 

This recursive structure can be exploited to create deeply nested messages that consume significant memory when deserialized.

## Impact Explanation

This vulnerability enables **resource exhaustion attacks** against the indexer-grpc data service, qualifying as **High Severity** per Aptos bug bounty criteria for "API crashes". 

An attacker can:
- Send crafted requests with filters between 10 KB and 256 MB
- Each request allocates memory during gRPC deserialization before being rejected
- Concurrent requests can exhaust available memory
- Cause service crashes via out-of-memory conditions
- Degrade service availability for legitimate users

While the indexer-grpc is not part of core consensus infrastructure, it provides critical data access APIs. Service disruption impacts ecosystem participants relying on indexer data.

This is distinct from network-level DoS (which is out of scope) - this is an **application logic vulnerability** where validation timing allows resource allocation before limits are enforced, similar to decompression bomb vulnerabilities.

## Likelihood Explanation

**Likelihood: High**

- No authentication bypass required - any API user can send malicious requests
- Attack is trivial to execute - craft a protobuf with nested filter structures
- No special privileges needed
- Attack can be automated and scaled
- The 256 MB / 10 KB gap provides 25,000x amplification factor
- Default configuration is vulnerable out-of-the-box

## Recommendation

**Fix the timing issue by enforcing size limits at the gRPC layer BEFORE deserialization occurs:**

```rust
// In ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs
// Change line 31 from:
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);

// To align with the application-level filter limit plus reasonable overhead:
pub(crate) const MAX_MESSAGE_SIZE: usize = 50 * 1024; // 50 KB
```

Or implement a separate gRPC message size limit specifically for requests containing transaction filters:

```rust
let wrapper_service =
    aptos_protos::indexer::v1::data_service_server::DataServiceServer::from_arc(wrapper)
        .send_compressed(CompressionEncoding::Zstd)
        .accept_compressed(CompressionEncoding::Gzip)
        .max_decoding_message_size(50 * 1024) // Stricter limit for filter-containing requests
        .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

The gRPC-level limit must be enforced BEFORE deserialization to prevent memory allocation of oversized messages.

## Proof of Concept

```rust
// PoC demonstrating the vulnerability
use aptos_protos::indexer::v1::{
    BooleanTransactionFilter, LogicalAndFilters, ApiFilter, TransactionRootFilter,
    boolean_transaction_filter::Filter,
};
use prost::Message;

fn create_nested_filter(depth: usize) -> BooleanTransactionFilter {
    if depth == 0 {
        // Base case: simple filter
        BooleanTransactionFilter {
            filter: Some(Filter::ApiFilter(ApiFilter {
                filter: Some(aptos_protos::indexer::v1::api_filter::Filter::TransactionRootFilter(
                    TransactionRootFilter {
                        success: Some(true),
                        transaction_type: None,
                    },
                )),
            })),
        }
    } else {
        // Recursive case: nest more filters
        let nested = create_nested_filter(depth - 1);
        BooleanTransactionFilter {
            filter: Some(Filter::LogicalAnd(LogicalAndFilters {
                filters: vec![nested.clone(), nested.clone(), nested],
            })),
        }
    }
}

fn main() {
    // Create a deeply nested filter
    // At depth 12, this creates 3^12 = 531,441 leaf nodes
    let filter = create_nested_filter(12);
    
    // Measure encoded size
    let encoded_size = filter.encoded_len();
    println!("Encoded size: {} bytes", encoded_size);
    
    // This will be several MB but < 256 MB (gRPC limit)
    // Yet it exceeds the 10 KB application limit
    // When sent via gRPC, it will:
    // 1. Pass gRPC max_decoding_message_size check (< 256 MB)
    // 2. Get fully deserialized (allocating memory)
    // 3. Fail application-level check (> 10 KB)
    // 4. But memory already allocated in step 2
    
    assert!(encoded_size > 10_000, "Exceeds app limit");
    assert!(encoded_size < 256 * 1024 * 1024, "Under gRPC limit");
    
    // Send multiple concurrent requests to exhaust memory
}
```

**Notes:**

This vulnerability exists because protobuf deserialization happens at the gRPC framework layer before application code can inspect message sizes. The `max_filter_size_bytes` check is a post-deserialization validation that cannot prevent memory allocation during deserialization. The large disparity between gRPC-level (256 MB) and application-level (10 KB) limits creates a significant attack surface for memory exhaustion.

### Citations

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L31-31)
```rust
pub(crate) const MAX_MESSAGE_SIZE: usize = 256 * (1 << 20);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/config.rs (L240-241)
```rust
                .max_decoding_message_size(MAX_MESSAGE_SIZE)
                .max_encoding_message_size(MAX_MESSAGE_SIZE);
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/constants.rs (L21-21)
```rust
pub const DEFAULT_MAX_TRANSACTION_FILTER_SIZE_BYTES: usize = 10_000;
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L98-115)
```rust
                let filter = if let Some(proto_filter) = request.transaction_filter {
                    match filter_utils::parse_transaction_filter(
                        proto_filter,
                        self.max_transaction_filter_size_bytes,
                    ) {
                        Ok(filter) => Some(filter),
                        Err(err) => {
                            info!("Client error: {err:?}.");
                            let _ = response_sender.blocking_send(Err(err));
                            COUNTER
                                .with_label_values(&["live_data_service_invalid_filter"])
                                .inc();
                            continue;
                        },
                    }
                } else {
                    None
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-utils/src/filter_utils.rs (L9-15)
```rust
pub fn parse_transaction_filter(
    proto_filter: aptos_protos::indexer::v1::BooleanTransactionFilter,
    max_filter_size_bytes: usize,
) -> Result<BooleanTransactionFilter, Status> {
    BooleanTransactionFilter::new_from_proto(proto_filter, Some(max_filter_size_bytes))
        .map_err(|e| Status::invalid_argument(format!("Invalid transaction_filter: {e:?}.")))
}
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/boolean_transaction_filter.rs (L98-107)
```rust
        if let Some(max_filter_size) = max_filter_size {
            ensure!(
                proto_filter.encoded_len() <= max_filter_size,
                format!(
                    "Filter is too complicated. Max size: {} bytes, Actual size: {} bytes",
                    max_filter_size,
                    proto_filter.encoded_len()
                )
            );
        }
```

**File:** protos/proto/aptos/indexer/v1/filter.proto (L58-65)
```text
message BooleanTransactionFilter {
  oneof filter {
      APIFilter api_filter = 1;
      LogicalAndFilters logical_and = 2;
      LogicalOrFilters logical_or = 3;
      BooleanTransactionFilter logical_not = 4;
  }
}
```
