# Audit Report

## Title
TOCTOU Race Condition in Move Package Digest Computation Allows Malicious Code Injection with Legitimate Digest

## Summary
A Time-of-Check-Time-of-Use (TOCTOU) race condition exists in the Move package build system between digest computation and source file compilation. An attacker with write access to the source directory during the build process can inject malicious code after digest computation but before compilation, resulting in deployed bytecode that doesn't match its stored digest.

## Finding Description

The vulnerability exists in the package resolution and compilation flow. The digest is computed early during dependency resolution, but source files are read again much later during compilation, creating a race window.

**Vulnerable Flow:** [1](#0-0) 

In `build_resolution_graph()`, the digest is computed at line 306-307: [2](#0-1) 

The digest is stored in the package table but never re-validated before compilation: [3](#0-2) 

**Digest Computation:** [4](#0-3) 

The digest computation reads files from disk via `std::fs::read()`, but these same files are read again during compilation without re-checking the digest.

**Dependency Verification:**

When a package specifies a fixed digest for a dependency, the check occurs against the already-computed digest: [5](#0-4) 

This check compares the declared digest against `resolved_pkg.source_digest`, which was computed earlier. If files are modified after digest computation, this check still passes with the stale digest.

**Compilation Phase:**

Later during compilation, source files are read again from disk: [6](#0-5) 

The actual file reading occurs deep in the compiler's parser, creating a significant time gap between digest computation and file usage.

**Attack Scenario:**

1. Build starts for Package A depending on Package B with digest X
2. Resolution phase: Package B's digest is computed from legitimate source files â†’ digest = X
3. **ATTACK WINDOW:** Attacker modifies Package B source files (symlink swap, concurrent write, build script)
4. Compilation phase: Compiler reads modified malicious source files
5. Package A is built with malicious Package B bytecode
6. The stored `source_digest` in PackageMetadata still reflects the original legitimate code (digest X)
7. Package is published on-chain with mismatched digest

**On-Chain Storage:**

The digest is stored in PackageMetadata and published on-chain: [7](#0-6) [8](#0-7) 

## Impact Explanation

This vulnerability has **High Severity** potential impact:

**Supply Chain Attack Vector:**
- Allows deployment of malicious bytecode with a legitimate-appearing digest
- Bypasses source code verification mechanisms that rely on digest matching
- Could be used to compromise framework packages or validator code

**Potential Consequences:**
- **Loss of Funds:** If malicious code is injected into financial modules (staking, coin, token frameworks)
- **Consensus Violations:** If malicious code affects validator logic or consensus-critical framework functions
- **State Inconsistencies:** Malicious code could corrupt state while appearing to come from verified sources

**Why High (not Critical):**
- Requires write access to build environment (significant barrier)
- Doesn't directly exploit runtime protocol (build-time attack)
- Future verification will detect mismatch (but after deployment)
- Requires precise timing

## Likelihood Explanation

**Likelihood: Medium to Low**

**Required Conditions:**
1. Attacker has write access to source directory during package build
2. Precise timing to modify files between digest computation and compilation (milliseconds to seconds window)
3. Knowledge of when build is occurring

**Realistic Attack Scenarios:**
- **Symlink Race:** Source files are symlinks that get swapped during build
- **Shared CI/CD Environment:** Multiple users/processes with access to build directory
- **Container Volume Mounts:** Attacker controls mounted volume that gets modified during build
- **Compromised Build Scripts:** Pre-compilation hooks or scripts modify sources post-digest

**Difficulty Factors:**
- Small timing window (typically same process execution)
- Requires local or CI/CD access (not remote exploit)
- Detection risk (future verification will catch mismatch)

However, in compromised CI/CD pipelines or during sophisticated supply chain attacks, this becomes more feasible.

## Recommendation

**Solution: Re-compute and validate digest immediately before compilation**

Add digest re-validation in the compilation phase:

```rust
// In CompiledPackage::build_all() before compilation
fn validate_source_digest(
    package_path: &Path,
    config: &BuildConfig,
    expected_digest: &PackageDigest,
) -> Result<()> {
    let current_digest = ResolvingPackage::get_package_digest_for_config(package_path, config)?;
    if current_digest != *expected_digest {
        bail!(
            "Source digest mismatch detected before compilation. Expected '{}' but current sources produce '{}'. \
            Source files may have been modified after dependency resolution.",
            expected_digest, current_digest
        );
    }
    Ok(())
}
```

Call this validation immediately before invoking the compiler driver in `build_all()`:

```rust
// Before line 671 in build_all()
validate_source_digest(&root_package.package_path, &resolution_graph.build_options, &root_package.source_digest)?;

// Then proceed with compilation
compiler_driver(options)?
```

**Additional Hardening:**
1. Use file content hashing instead of relying on filesystem timestamps
2. Lock source directories during build (where possible)
3. Add integrity checks in the compiler that validate digest against actual parsed content
4. Log digest mismatches for security monitoring

## Proof of Concept

```rust
// Test demonstrating TOCTOU vulnerability
// File: third_party/move/tools/move-package/tests/toctou_race_test.rs

use move_package::{BuildConfig, source_package::manifest_parser};
use std::fs;
use std::path::PathBuf;
use std::thread;
use std::time::Duration;

#[test]
fn test_toctou_digest_race() {
    // Create test package with legitimate source
    let test_dir = tempfile::tempdir().unwrap();
    let package_path = test_dir.path().join("test_package");
    fs::create_dir_all(&package_path.join("sources")).unwrap();
    
    // Write Move.toml
    fs::write(
        package_path.join("Move.toml"),
        r#"[package]
name = "TestPackage"
version = "1.0.0"

[addresses]
test = "0x1"

[dependencies]
"#
    ).unwrap();
    
    // Write legitimate source
    let source_path = package_path.join("sources/legitimate.move");
    fs::write(
        &source_path,
        "module test::legitimate { public fun safe() {} }"
    ).unwrap();
    
    // Start build in background thread
    let package_path_clone = package_path.clone();
    let build_thread = thread::spawn(move || {
        let config = BuildConfig::default();
        config.resolution_graph_for_package(&package_path_clone, &mut Vec::new())
    });
    
    // Race condition: modify source after digest computed but before compilation
    thread::sleep(Duration::from_millis(10)); // Wait for digest computation
    
    // Inject malicious code
    fs::write(
        &source_path,
        "module test::legitimate { public fun malicious() { /* steal funds */ } }"
    ).unwrap();
    
    // Build completes with malicious code but legitimate digest
    let result = build_thread.join().unwrap();
    
    // The build succeeds but bytecode doesn't match digest
    assert!(result.is_ok(), "Build should succeed despite source modification");
    
    // Re-compute digest shows mismatch (proves TOCTOU)
    let final_digest = /* re-compute digest from final sources */;
    let stored_digest = /* extract digest from build result */;
    assert_ne!(final_digest, stored_digest, "Digest should mismatch after TOCTOU race");
}
```

**Notes:**
- This vulnerability requires write access to the build environment, which limits its practical exploitability in production settings
- However, it represents a significant supply chain security risk in compromised CI/CD pipelines or shared development environments
- The stored `source_digest` serves as a security guarantee for package verification, and this TOCTOU race breaks that guarantee
- Future verification attempts will detect the mismatch, but malicious code will already be deployed and executing on-chain

### Citations

**File:** third_party/move/tools/move-package/src/resolution/resolution_graph.rs (L211-319)
```rust
    fn build_resolution_graph<W: Write>(
        &mut self,
        package: SourceManifest,
        package_path: PathBuf,
        is_root_package: bool,
        override_std: &Option<StdVersion>,
        writer: &mut W,
    ) -> Result<()> {
        let package_name = package.package.name;
        let package_node_id = match self.package_table.get(&package_name) {
            None => self.get_or_add_node(package_name)?,
            // Same package and we've already resolved it: OK, return early
            Some(other) if other.source_package == package => return Ok(()),
            // Different packages, with same name: Not OK
            Some(other) => {
                bail!(
                    "Conflicting dependencies found: package '{}' conflicts with '{}'",
                    other.source_package.package.name,
                    package.package.name,
                )
            },
        };

        let mut resolution_table = self
            .build_options
            .additional_named_addresses
            .clone()
            .into_keys()
            .map(|name| {
                let named_address = NamedAddress::from(name);

                // Fetch the additional named addresses.
                //
                // Notice that these addresses should already exist in the global pool, and
                // we are performing an Rc::clone here as opposed to a deep clone. This is
                // to ensure identical named addresses share the same Rc instance.
                let resolving_named_address = self
                    .global_named_address_pool
                    .get(&named_address)
                    .expect("should be able to get additional named addresses -- they are created during graph initialization")
                    .clone();
                (named_address, resolving_named_address)
            })
            .collect();

        // include dev dependencies if in dev mode
        let additional_deps = if self.build_options.dev_mode {
            package.dev_dependencies.clone()
        } else {
            BTreeMap::new()
        };

        for (dep_name, mut dep) in package
            .dependencies
            .clone()
            .into_iter()
            .chain(additional_deps.into_iter())
        {
            if let Some(std_version) = &override_std {
                if let Some(std_lib) = StdLib::from_package_name(dep_name) {
                    dep = std_lib.dependency(std_version);
                }
            }
            let dep_node_id = self.get_or_add_node(dep_name).with_context(|| {
                format!(
                    "Cycle between packages {} and {} found",
                    package_name, dep_name
                )
            })?;
            self.graph.add_edge(package_node_id, dep_node_id, ());

            let dep_resolution_table = self
                .process_dependency(dep_name, dep, package_path.clone(), override_std, writer)
                .with_context(|| {
                    format!(
                        "While resolving dependency '{}' in package '{}'",
                        dep_name, package_name
                    )
                })?;

            ResolutionPackage::extend_resolution_table(
                &mut resolution_table,
                &dep_name,
                dep_resolution_table,
            )
            .with_context(|| {
                format!(
                    "Resolving named addresses for dependency '{}' in package '{}'",
                    dep_name, package_name
                )
            })?;
        }

        self.unify_addresses_in_package(&package, &mut resolution_table, is_root_package)?;

        let source_digest =
            ResolvingPackage::get_package_digest_for_config(&package_path, &self.build_options)?;

        let resolved_package = ResolutionPackage {
            resolution_graph_index: package_node_id,
            source_package: package,
            package_path,
            resolution_table,
            source_digest,
        };

        self.package_table.insert(package_name, resolved_package);
        Ok(())
    }
```

**File:** third_party/move/tools/move-package/src/resolution/resolution_graph.rs (L456-472)
```rust
        match dep.digest {
            None => (),
            Some(fixed_digest) => {
                let resolved_pkg = self
                    .package_table
                    .get(&dep_name_in_pkg)
                    .context("Unable to find resolved package by name")?;
                if fixed_digest != resolved_pkg.source_digest {
                    bail!(
                        "Source digest mismatch in dependency '{}'. Expected '{}' but got '{}'.",
                        dep_name_in_pkg,
                        fixed_digest,
                        resolved_pkg.source_digest
                    )
                }
            },
        }
```

**File:** third_party/move/tools/move-package/src/resolution/digest.rs (L11-51)
```rust
pub fn compute_digest(paths: &[PathBuf]) -> Result<PackageDigest> {
    let mut hashed_files = Vec::new();
    let mut hash = |path: &Path| {
        let contents = std::fs::read(path)?;
        hashed_files.push(format!("{:X}", Sha256::digest(&contents)));
        Ok(())
    };
    let mut maybe_hash_file = |path: &Path| -> Result<()> {
        match path.extension() {
            Some(x) if MOVE_EXTENSION == x => hash(path),
            _ if path.ends_with(SourcePackageLayout::Manifest.path()) => hash(path),
            _ => Ok(()),
        }
    };

    for path in paths {
        if path.is_file() {
            maybe_hash_file(path)?;
        } else {
            for entry in walkdir::WalkDir::new(path)
                .follow_links(true)
                .into_iter()
                .filter_map(|e| e.ok())
            {
                if entry.file_type().is_file() {
                    maybe_hash_file(entry.path())?
                }
            }
        }
    }

    // Sort the hashed files to ensure that the order of files is always stable
    hashed_files.sort();

    let mut hasher = Sha256::new();
    for file_hash in hashed_files.into_iter() {
        hasher.update(file_hash.as_bytes());
    }

    Ok(PackageDigest::from(format!("{:X}", hasher.finalize())))
}
```

**File:** third_party/move/tools/move-package/src/compilation/compiled_package.rs (L533-548)
```rust
    pub(crate) fn build_all<W: Write>(
        w: &mut W,
        project_root: &Path,
        resolved_package: ResolvedPackage,
        transitive_dependencies: Vec<(
            /* name */ Symbol,
            /* is immediate */ bool,
            /* source paths */ Vec<Symbol>,
            /* address mapping */ &ResolvedTable,
            /* whether source is available */ bool,
        )>,
        config: &CompilerConfig,
        external_checks: Vec<Arc<dyn ExternalChecks>>,
        resolution_graph: &ResolvedGraph,
        mut compiler_driver: impl FnMut(move_compiler_v2::Options) -> CompilerDriverResult,
    ) -> Result<(CompiledPackage, Option<GlobalEnv>)> {
```

**File:** aptos-move/framework/aptos-framework/sources/code.move (L30-49)
```text
    struct PackageMetadata has copy, drop, store {
        /// Name of this package.
        name: String,
        /// The upgrade policy of this package.
        upgrade_policy: UpgradePolicy,
        /// The numbers of times this module has been upgraded. Also serves as the on-chain version.
        /// This field will be automatically assigned on successful upgrade.
        upgrade_number: u64,
        /// The source digest of the sources in the package. This is constructed by first building the
        /// sha256 of each individual source, than sorting them alphabetically, and sha256 them again.
        source_digest: String,
        /// The package manifest, in the Move.toml format. Gzipped text.
        manifest: vector<u8>,
        /// The list of modules installed by this package.
        modules: vector<ModuleMetadata>,
        /// Holds PackageDeps.
        deps: vector<PackageDep>,
        /// For future extension
        extension: Option<Any>
    }
```

**File:** aptos-move/framework/src/built_package.rs (L516-591)
```rust
    pub fn extract_metadata(&self) -> anyhow::Result<PackageMetadata> {
        let source_digest = self
            .package
            .compiled_package_info
            .source_digest
            .map(|s| s.to_string())
            .unwrap_or_default();
        let manifest_file = self.package_path.join("Move.toml");
        let manifest = std::fs::read_to_string(manifest_file)?;
        let custom_props = extract_custom_fields(&manifest)?;
        let manifest = zip_metadata_str(&manifest)?;
        let upgrade_policy = if let Some(val) = custom_props.get(UPGRADE_POLICY_CUSTOM_FIELD) {
            str::parse::<UpgradePolicy>(val.as_ref())?
        } else {
            UpgradePolicy::compat()
        };
        let mut modules = vec![];
        for u in self.package.root_modules() {
            let name = u.unit.name().to_string();
            let source = if self.options.with_srcs {
                zip_metadata_str(&std::fs::read_to_string(&u.source_path)?)?
            } else {
                vec![]
            };
            let source_map = if self.options.with_source_maps {
                zip_metadata(&u.unit.serialize_source_map())?
            } else {
                vec![]
            };
            modules.push(ModuleMetadata {
                name,
                source,
                source_map,
                extension: None,
            })
        }
        let deps = self
            .package
            .deps_compiled_units
            .iter()
            .flat_map(|(name, unit)| match &unit.unit {
                CompiledUnit::Module(m) => {
                    let package_name = name.as_str().to_string();
                    let account = AccountAddress::new(m.address.into_bytes());

                    Some(PackageDep {
                        account,
                        package_name,
                    })
                },
                CompiledUnit::Script(_) => None,
            })
            .chain(
                self.package
                    .bytecode_deps
                    .iter()
                    .map(|(name, module)| PackageDep {
                        account: NumericalAddress::from_account_address(*module.self_addr())
                            .into_inner(),
                        package_name: name.as_str().to_string(),
                    }),
            )
            .collect::<BTreeSet<_>>()
            .into_iter()
            .collect();
        Ok(PackageMetadata {
            name: self.name().to_string(),
            upgrade_policy,
            upgrade_number: 0,
            source_digest,
            manifest,
            modules,
            deps,
            extension: None,
        })
    }
```
