# Audit Report

## Title
Race Condition in Transaction Re-scheduling Causes Permanent Execution Queue Removal (Liveness Failure)

## Summary
A memory ordering race condition between `try_increase_executed_once_max_idx` and `remove_stall` can cause high-priority transactions with incarnation 1 to be permanently removed from the execution queue, resulting in incomplete block execution and consensus liveness failure.

## Finding Description

The BlockSTMv2 scheduler tracks transaction execution progress using `executed_once_max_idx`, a watermark indicating the highest contiguous index where all transactions have executed at least once. When a transaction completes its first execution (incarnation 0) and needs re-execution (incarnation 1), special scheduling logic defers this re-execution until `executed_once_max_idx >= txn_idx` to ensure all prior transactions have produced speculative writes. [1](#0-0) 

When a stalled transaction becomes unstalled via `remove_stall`, it attempts to re-add itself to the execution queue. For incarnation 1 transactions, this calls `add_to_schedule(true, txn_idx)`, which only adds the transaction if `executed_once_max_idx >= txn_idx`. [2](#0-1) 

However, a critical race condition exists in `try_increase_executed_once_max_idx`. This function updates `executed_once_max_idx` using `Ordering::Relaxed` AFTER releasing the transaction status lock: [3](#0-2) 

The race occurs as follows:

1. Thread A executes `try_increase_executed_once_max_idx(N-1)` where `executed_once_max_idx = N-1`
2. Thread A checks `ever_executed(N)` under lock, returns true, releases lock  
3. Thread B (concurrent) calls `remove_stall(N)` for transaction N (incarnation 1)
4. Thread B acquires status lock, checks conditions, releases lock
5. Thread B calls `add_to_schedule(true, N)` which loads `executed_once_max_idx` 
6. Due to `Relaxed` ordering and no synchronization, Thread B may still observe old value `N-1`
7. Check `N-1 >= N` fails, transaction N is NOT added to queue
8. Thread A (meanwhile) stores `executed_once_max_idx = N+1` 
9. Transaction N is now stuck: PendingScheduling, incarnation 1, not stalled, NOT in queue
10. Since `executed_once_max_idx` has already advanced past N, `try_increase_executed_once_max_idx` will never re-check transaction N

The code comment claims this race is prevented by lock synchronization, but this is incorrect because: [4](#0-3) 

- The status lock is released BEFORE `executed_once_max_idx` is stored
- `Relaxed` memory ordering provides no happens-before guarantees between threads
- No lock is held during the store (Thread A) or load (Thread B) of `executed_once_max_idx`

This breaks the **liveness invariant**: the scheduler must eventually execute all transactions to completion.

## Impact Explanation

**Severity: High** (potentially $50,000 bounty range)

This vulnerability causes **total loss of liveness** for the affected block:
- Stuck transactions will never execute, preventing block completion
- Block cannot be committed since transactions are pending
- Validators cannot make progress on subsequent blocks
- Requires halting block execution and manual intervention or restart

While not as severe as permanent network partition (Critical), it significantly impacts availability and could require coordinated validator action to recover. The impact qualifies as **High** per the bounty program criteria for "Significant protocol violations" and validator operational disruptions.

The issue affects deterministic execution (Invariant #1) since different validators may experience the race condition differently, potentially leading to divergent execution states if some validators' transactions get stuck while others' do not.

## Likelihood Explanation

**Likelihood: Medium to High**

This race condition will occur naturally during high-throughput execution:
- BlockSTMv2 is designed for parallel execution with multiple worker threads
- Stall/unstall operations happen frequently during transaction re-execution
- The watermark `executed_once_max_idx` advances continuously as transactions complete
- No special attacker capabilities required—normal transaction processing suffices
- Higher probability with more worker threads and transaction dependencies

The race window is narrow but realistic given:
- Relaxed memory ordering allows significant reordering
- Modern CPU architectures can delay visibility of stores across cores  
- High contention on scheduler data structures increases timing variability

An attacker could increase likelihood by:
- Submitting transactions with complex dependencies to trigger more aborts/stalls
- Creating dependency chains that maximize stall propagation
- No privileged access required—any transaction sender can do this

## Recommendation

**Fix: Use stronger memory ordering for `executed_once_max_idx` synchronization**

Change the memory ordering from `Relaxed` to `Release` for stores and `Acquire` for loads to establish proper happens-before relationships:

```rust
// In try_increase_executed_once_max_idx:
execution_queue_manager
    .executed_once_max_idx
    .store(idx + 1, Ordering::Release);  // Changed from Relaxed

// In add_to_schedule:
if !is_first_reexecution || self.executed_once_max_idx.load(Ordering::Acquire) >= txn_idx {  // Changed from Relaxed
    self.execution_queue.lock().insert(txn_idx);
}
```

This ensures that when Thread B loads `executed_once_max_idx` with `Acquire`, it will observe all stores with `Release` ordering that happened-before, including the updated watermark value from Thread A.

**Alternative fix: Hold status lock during watermark update**

Alternatively, keep the status lock held across the watermark update to provide proper synchronization, though this may impact performance.

## Proof of Concept

The following Rust pseudo-test demonstrates the race condition (actual implementation requires BlockSTM test harness):

```rust
#[test]
fn test_race_condition_permanent_queue_removal() {
    let scheduler = SchedulerV2::new(100, 8);
    
    // Setup: Transaction 50 completes incarnation 0, 
    // executed_once_max_idx = 49
    for i in 0..50 {
        execute_and_finish(scheduler, i, 0);
    }
    
    // Transaction 50 gets aborted, becomes incarnation 1, gets stalled
    let txn_idx = 50;
    assert_ok!(scheduler.start_executing(txn_idx));
    assert_ok!(scheduler.finish_execution(AbortManager::new(txn_idx, 0, &scheduler)));
    assert_ok_eq!(scheduler.txn_statuses.add_stall(txn_idx), true);
    
    // Spawn two threads to trigger race
    let handle1 = thread::spawn(move || {
        // Thread A: advances watermark
        scheduler.try_increase_executed_once_max_idx(49);
    });
    
    let handle2 = thread::spawn(move || {
        // Thread B: removes stall
        // May observe old executed_once_max_idx value due to Relaxed ordering
        scheduler.txn_statuses.remove_stall(txn_idx);
    });
    
    handle1.join();
    handle2.join();
    
    // Verify bug: transaction is in PendingScheduling but not in queue
    assert!(scheduler.txn_statuses.pending_scheduling_and_not_stalled(txn_idx));
    assert!(!scheduler.execution_queue_contains(txn_idx));  
    
    // executed_once_max_idx has advanced past txn_idx
    assert!(scheduler.executed_once_max_idx() > txn_idx);
    
    // Transaction is permanently stuck - will never execute
    // Block execution will hang waiting for this transaction
}
```

**Notes:**
- Requires concurrent execution test infrastructure
- Race is timing-dependent; may need multiple iterations to reproduce
- Actual exploitation occurs naturally during high-throughput block execution
- No special attacker privileges required beyond transaction submission rights

### Citations

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L405-414)
```rust
    pub(crate) fn add_to_schedule(&self, is_first_reexecution: bool, txn_idx: TxnIndex) {
        // In BlockSTMv2 algorithm, first re-execution gets a special scheduling treatment.
        // it is deferred until all previous transactions are executed at least once,
        // which is to ensure that all those transactions have produced their speculative
        // writes and the information can be used for intelligent scheduling. Note that
        // for the same reason, incarnation 0 (first execution) is never terminated early.
        if !is_first_reexecution || self.executed_once_max_idx.load(Ordering::Relaxed) >= txn_idx {
            self.execution_queue.lock().insert(txn_idx);
        }
    }
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1297-1302)
```rust
            while idx < self.num_txns && self.txn_statuses.ever_executed(idx) {
                // A successful check of ever_executed holds idx-th status lock and follows an
                // increment of executed_once_max_idx to idx in the prior loop iteration.
                execution_queue_manager
                    .executed_once_max_idx
                    .store(idx + 1, Ordering::Relaxed);
```

**File:** aptos-move/block-executor/src/scheduler_v2.rs (L1304-1313)
```rust
                // Note: for first re-execution, [ExecutionQueueManager::add_to_schedule] adds
                // an index to the execution queue only once executed_once_max_idx >= idx.
                // We need to ensure that re-execution is not missed due to a concurrency
                // race where after the index is added to the execution queue below, it gets
                // removed by [ExecutionStatuses::add_stall] but not re-added due to the
                // aforementioned check after [ExecutionStatuses::remove_stall]. This holds
                // because stall can only remove idx from the execution queue while holding
                // the idx-th status lock, which would have to be after ever_executed, and
                // the corresponding remove_stall would hence acquire the same lock even later,
                // and hence be guaranteed to observe executed_once_max_idx >= idx.
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L437-444)
```rust
            if let Some(incarnation) = status_guard.pending_scheduling() {
                if incarnation == 0 {
                    // Invariant due to scheduler logic: for a successful remove_stall there
                    // must have been an add_stall for incarnation 0, which is impossible.
                    return Err(code_invariant_error("0-th incarnation in remove_stall"));
                }
                self.execution_queue_manager
                    .add_to_schedule(incarnation == 1, txn_idx);
```
