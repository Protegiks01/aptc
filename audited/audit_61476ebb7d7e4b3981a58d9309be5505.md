# Audit Report

## Title
Batch Retrieval Service Crash Due to Protocol Version Mismatch Between V1 and V2 Batches

## Summary
The batch retrieval service in the quorum store consensus component crashes when a validator with `enable_batch_v2=true` stores V2 batches and another validator requests them. The responder unconditionally attempts to downgrade V2 batches to V1 format, causing a panic that terminates the batch serving task. This creates a denial-of-service condition where affected validators cannot serve batch requests, degrading consensus liveness.

## Finding Description

The vulnerability exists in the batch request/response protocol within the quorum store consensus system. The protocol supports two batch formats: V1 (`Batch<BatchInfo>`) and V2 (`Batch<BatchInfoExt>`), where V2 includes additional metadata for extensibility. [1](#0-0) 

Validators can be configured to create V2 batches through the `enable_batch_v2` configuration flag. [2](#0-1)  When enabled, the batch generator creates V2 batches with additional metadata: [3](#0-2) 

The `BatchRequest` structure used to request batches from peers contains no protocol version field to indicate which batch format the requester supports. [4](#0-3) 

When a validator requests a batch, the responder's batch serving task retrieves the batch from local storage, which returns `PersistedValue<BatchInfoExt>` that can contain either V1 or V2 batches. [5](#0-4) 

The critical flaw occurs in the batch serving task, which unconditionally attempts to convert any retrieved batch to V1 format: [6](#0-5) 

The conversion from `Batch<BatchInfoExt>` to `Batch<BatchInfo>` fails for V2 batches because the implementation explicitly rejects non-V1 batches: [7](#0-6) 

When the `try_into()` fails on a V2 batch, the `.expect()` panics the entire batch serving task, permanently disabling batch retrieval on that validator until restart.

On the requester side, while the `BatchResponse` enum includes a `BatchV2` variant, [8](#0-7)  the `request_batch()` function does not properly handle it. When receiving a `BatchV2` response, it only logs an error and continues retrying: [9](#0-8) 

**Attack Scenario:**
1. Validator A configures `enable_batch_v2=true` and creates/stores V2 batches
2. Validator B needs a batch that was created by Validator A (e.g., for consensus execution)
3. Validator B sends a `BatchRequest` to Validator A for the V2 batch
4. Validator A's batch serving task retrieves the V2 batch from storage
5. The task attempts to convert V2 to V1, which fails with "Batch must be V1 type"
6. The `.expect()` panics, crashing the entire batch serving task on Validator A
7. All subsequent batch requests to Validator A fail (no task listening on the channel)
8. Other validators cannot retrieve batches from Validator A, impacting consensus

## Impact Explanation

This vulnerability qualifies as **Medium severity** under the Aptos bug bounty criteria for the following reasons:

**State Inconsistencies Requiring Intervention:** When the batch serving task crashes on multiple validators during a rollout of the V2 feature, the network experiences degraded batch retrieval capabilities. Validators cannot fetch batches from affected peers, potentially preventing block execution and requiring manual intervention (node restarts) to restore functionality.

**Validator Node Slowdowns:** Affected validators must request batches from alternative peers (if available), increasing latency and retry attempts. The requester's retry logic will exhaust all attempts before timing out, causing delays in consensus progression. [10](#0-9) 

**Significant Protocol Violations:** The protocol assumes batch retrieval services remain available. A crash in this critical consensus component violates the availability guarantees expected in a Byzantine fault-tolerant system. During network upgrades when V2 is being rolled out, this can create systemic availability issues.

The impact is contained to Medium rather than High because:
- The issue doesn't directly cause consensus safety violations (no double-spend or chain split)
- Affected validators can be recovered through restart
- The vulnerability requires specific configuration (`enable_batch_v2=true`) to manifest
- Redundant batch sources may provide fallback retrieval paths

## Likelihood Explanation

**Likelihood: Medium to High during protocol upgrades**

The vulnerability will **definitely occur** under the following realistic conditions:

1. **Configuration-Dependent:** The default configuration sets `enable_batch_v2=false`, [11](#0-10)  but validators can override this. During testing or gradual rollout of V2 features, some validators will enable this flag.

2. **No Version Negotiation:** The `BatchRequest` protocol provides no mechanism for version negotiation, meaning V1-only and V2-capable validators cannot communicate their capabilities. Any heterogeneous deployment will trigger the bug.

3. **Inevitable During Upgrades:** When the Aptos network upgrades to enable V2 batches network-wide, there will be a transition period where:
   - Early adopters enable `enable_batch_v2=true`
   - These validators create and store V2 batches
   - Any other validator requesting these batches triggers the panic

4. **Persistent Until Restart:** Once triggered, the batch serving task remains crashed until manual intervention, affecting all validators attempting to retrieve batches from the affected node.

The vulnerability is **easy to trigger** (no special permissions or complex exploit chain needed) and has **deterministic exploitation** (always panics on V2 batches). The only barrier is the configuration flag, which is explicitly designed to be enabled during network evolution.

## Recommendation

Implement proper protocol version negotiation and graceful handling of version mismatches:

### 1. Add Version Field to BatchRequest
Extend `BatchRequest` to include a protocol version field indicating the highest version the requester supports:

```rust
#[derive(Clone, Debug, Deserialize, Serialize, PartialEq, Eq)]
pub struct BatchRequest {
    epoch: u64,
    source: PeerId,
    digest: HashValue,
    max_supported_version: u8,  // Add this field
}
```

### 2. Fix Responder to Check Version Compatibility
Modify the batch serving task to respect the requester's version:

```rust
let response = if let Ok(value) = batch_store.get_batch_from_local(&rpc_request.req.digest()) {
    let batch: Batch<BatchInfoExt> = value.try_into().unwrap();
    
    // Check if requester supports V2
    let max_version = rpc_request.req.max_supported_version();
    if batch.batch_info().is_v2() && max_version >= 2 {
        // Send V2 response
        BatchResponse::BatchV2(batch)
    } else if batch.batch_info().is_v2() && max_version < 2 {
        // Requester doesn't support V2, send NotFound instead of panicking
        match aptos_db_clone.get_latest_ledger_info() {
            Ok(ledger_info) => BatchResponse::NotFound(ledger_info),
            Err(e) => {
                error!(epoch = epoch, error = ?e, "Failed to get ledger info");
                continue;
            }
        }
    } else {
        // V1 batch, safe to downgrade
        let batch: Batch<BatchInfo> = batch.try_into()
            .expect("V1 batch must be convertible");
        BatchResponse::Batch(batch)
    }
} else {
    // ... existing NotFound logic ...
};
```

### 3. Fix Requester to Properly Handle BatchV2
Update the `request_batch()` function to extract transactions from V2 responses:

```rust
Ok(BatchResponse::BatchV2(batch)) => {
    counters::RECEIVED_BATCH_V2_RESPONSE_COUNT.inc();
    // Verify digest matches
    if batch.verify_with_digest(digest).is_ok() {
        let payload = batch.into_transactions();
        return Ok(payload);
    } else {
        error!("BatchV2 response verification failed");
    }
}
```

### 4. Implement Graceful Fallback
For production deployments, implement a configuration-based fallback:
- V2-capable nodes should advertise their capabilities during handshake
- Batch requests should include fallback logic to request from V1-compatible peers
- Add metrics to track version mismatch incidents for monitoring

## Proof of Concept

```rust
#[cfg(test)]
mod test {
    use super::*;
    use aptos_consensus_types::proof_of_store::{BatchInfo, BatchInfoExt, BatchKind};
    use aptos_types::quorum_store::BatchId;
    use aptos_crypto::HashValue;
    
    #[test]
    #[should_panic(expected = "Batch must be V1 type")]
    fn test_v2_batch_conversion_panic() {
        // Create a V2 batch
        let batch_id = BatchId::new_for_test(1);
        let txns = vec![];
        let epoch = 1;
        let expiration = 1000;
        let author = PeerId::random();
        let gas_bucket_start = 0;
        let batch_kind = BatchKind::Normal;
        
        let batch_v2 = Batch::new_v2(
            batch_id,
            txns,
            epoch,
            expiration,
            author,
            gas_bucket_start,
            batch_kind,
        );
        
        // This simulates what the responder does
        let batch_ext: Batch<BatchInfoExt> = batch_v2;
        
        // This will panic because V2 cannot be converted to V1
        let _batch_v1: Batch<BatchInfo> = batch_ext
            .try_into()
            .expect("Batch retrieval requests must be for V1 batch");
    }
    
    #[test]
    fn test_batch_requester_ignores_v2_response() {
        // Setup test environment with mock network
        // ... (setup code) ...
        
        // Simulate receiving a BatchV2 response
        let response = BatchResponse::BatchV2(/* V2 batch */);
        
        // The current code path will:
        // 1. Match on BatchResponse::BatchV2
        // 2. Log error "Batch V2 response is not supported"
        // 3. Continue the loop without extracting transactions
        // 4. Eventually timeout and return ExecutorError::CouldNotGetData
        
        // This demonstrates the requester cannot retrieve V2 batches
        // even when they are validly available
    }
}
```

**To reproduce the vulnerability in a live environment:**

1. Configure one validator with `enable_batch_v2: true` in quorum_store_config
2. Let that validator create and store V2 batches during normal operation
3. Trigger a batch request from another validator for a V2 batch (e.g., by including it in a block proposal)
4. Observe the batch serving task panic with "Batch must be V1 type" in the responder's logs
5. Verify subsequent batch requests to that validator fail with timeout errors
6. Confirm the issue persists until the validator is restarted

**Notes**

The vulnerability stems from incomplete implementation of the V2 batch protocol. While the data structures support V2 batches and the configuration enables their creation, the request/response protocol lacks version negotiation and proper handling logic. This creates a dangerous situation during network upgrades where mixed-version deployments will systematically crash batch retrieval services across the network.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L192-203)
```rust
#[derive(
    Clone, Debug, Deserialize, Serialize, CryptoHasher, BCSCryptoHash, PartialEq, Eq, Hash,
)]
pub enum BatchInfoExt {
    V1 {
        info: BatchInfo,
    },
    V2 {
        info: BatchInfo,
        extra: ExtraBatchInfo,
    },
}
```

**File:** config/src/config/quorum_store_config.rs (L102-102)
```rust
    pub enable_batch_v2: bool,
```

**File:** config/src/config/quorum_store_config.rs (L144-144)
```rust
            enable_batch_v2: false,
```

**File:** consensus/src/quorum_store/batch_generator.rs (L190-201)
```rust
        if self.config.enable_batch_v2 {
            // TODO(ibalajiarun): Specify accurate batch kind
            let batch_kind = BatchKind::Normal;
            Batch::new_v2(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
                batch_kind,
            )
```

**File:** consensus/src/quorum_store/types.rs (L336-343)
```rust
impl TryFrom<Batch<BatchInfoExt>> for Batch<BatchInfo> {
    type Error = anyhow::Error;

    fn try_from(batch: Batch<BatchInfoExt>) -> Result<Self, Self::Error> {
        ensure!(
            matches!(batch.batch_info(), &BatchInfoExt::V1 { .. }),
            "Batch must be V1 type"
        );
```

**File:** consensus/src/quorum_store/types.rs (L355-360)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, PartialEq, Eq)]
pub struct BatchRequest {
    epoch: u64,
    source: PeerId,
    digest: HashValue,
}
```

**File:** consensus/src/quorum_store/types.rs (L416-421)
```rust
#[derive(Clone, Debug, Deserialize, Serialize)]
pub enum BatchResponse {
    Batch(Batch<BatchInfo>),
    NotFound(LedgerInfoWithSignatures),
    BatchV2(Batch<BatchInfoExt>),
}
```

**File:** consensus/src/quorum_store/batch_store.rs (L571-574)
```rust
    pub(crate) fn get_batch_from_local(
        &self,
        digest: &HashValue,
    ) -> ExecutorResult<PersistedValue<BatchInfoExt>> {
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L408-415)
```rust
                let response = if let Ok(value) =
                    batch_store.get_batch_from_local(&rpc_request.req.digest())
                {
                    let batch: Batch<BatchInfoExt> = value.try_into().unwrap();
                    let batch: Batch<BatchInfo> = batch
                        .try_into()
                        .expect("Batch retieval requests must be for V1 batch");
                    BatchResponse::Batch(batch)
```

**File:** consensus/src/quorum_store/batch_requester.rs (L117-179)
```rust
        monitor!("batch_request", {
            let mut interval = time::interval(retry_interval);
            let mut futures = FuturesUnordered::new();
            let request = BatchRequest::new(my_peer_id, epoch, digest);
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // send batch request to a set of peers of size request_num_peers
                        if let Some(request_peers) = request_state.next_request_peers(request_num_peers) {
                            for peer in request_peers {
                                futures.push(network_sender.request_batch(request.clone(), peer, rpc_timeout));
                            }
                        } else if futures.is_empty() {
                            // end the loop when the futures are drained
                            break;
                        }
                    },
                    Some(response) = futures.next() => {
                        match response {
                            Ok(BatchResponse::Batch(batch)) => {
                                counters::RECEIVED_BATCH_RESPONSE_COUNT.inc();
                                let payload = batch.into_transactions();
                                return Ok(payload);
                            }
                            // Short-circuit if the chain has moved beyond expiration
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
                            }
                            Ok(BatchResponse::BatchV2(_)) => {
                                error!("Batch V2 response is not supported");
                            }
                            Err(e) => {
                                counters::RECEIVED_BATCH_RESPONSE_ERROR_COUNT.inc();
                                debug!("QS: batch request error, digest:{}, error:{:?}", digest, e);
                            }
                        }
                    },
                    result = &mut subscriber_rx => {
                        match result {
                            Ok(persisted_value) => {
                                counters::RECEIVED_BATCH_FROM_SUBSCRIPTION_COUNT.inc();
                                let (_, maybe_payload) = persisted_value.unpack();
                                return Ok(maybe_payload.expect("persisted value must exist"));
                            }
                            Err(err) => {
                                debug!("channel closed: {}", err);
                            }
                        };
                    },
                }
            }
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
        })
```
