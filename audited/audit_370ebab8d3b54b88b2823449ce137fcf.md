# Audit Report

## Title
BoundedExecutor Permit Exhaustion Enables Consensus and Mempool DoS via Network Message Flooding

## Summary
The `BoundedExecutor` implementation uses blocking `.spawn()` calls in network message processing loops, allowing adversarial peers to exhaust permits and block legitimate message processing. This causes consensus liveness failures (CRITICAL) and mempool transaction processing DoS (HIGH). [1](#0-0) 

## Finding Description

The `BoundedExecutor` uses a semaphore-based permit system to limit concurrent task execution. The `.spawn()` method blocks until a permit is available by calling `acquire_permit().await`. [2](#0-1) 

**Critical Vulnerability Pattern:**

Network message processing components use `.spawn(...).await` in their main event loops, creating a head-of-line blocking vulnerability:

**1. Consensus RandManager** (Capacity: 16 permits by default): [3](#0-2) 

**2. Consensus SecretShareManager** (Capacity: 16 permits): [4](#0-3) 

**3. Mempool Transaction Processing** (Capacity: 4 permits by default): [5](#0-4) 

**4. Peer Monitoring Service** (Capacity: 1000 permits): [6](#0-5) 

**Attack Scenario:**

1. Adversarial peer connects to validator node
2. Sends N messages where N equals or exceeds the bounded executor capacity (4 for mempool, 16 for consensus)
3. Each message passes initial validation and acquires a permit via `.spawn(...).await`
4. Attacker crafts messages that are valid but slow to verify (e.g., complex cryptographic verification)
5. Once all permits are exhausted, the event loop blocks at `.spawn(...).await`
6. Legitimate messages from honest peers cannot be processed while waiting for permits
7. For consensus: causes liveness failure and round timeouts
8. For mempool: prevents transaction propagation

**Invariants Broken:**
- Consensus liveness: Validators cannot process consensus messages
- Network availability: Legitimate peers cannot communicate
- Transaction propagation: Mempool cannot sync transactions

## Impact Explanation

**Consensus Components (CRITICAL):**
Per Aptos bug bounty, this qualifies as "Total loss of liveness/network availability" (CRITICAL, up to $1,000,000). An attacker can:
- Freeze consensus message processing on targeted validators by exhausting the 16-permit capacity
- Cause round timeouts and prevent block progression
- If multiple validators are targeted simultaneously, halt the entire network
- Requires no validator access, only network peer status [7](#0-6) 

**Mempool (HIGH):**
Qualifies as "Validator node slowdowns" (HIGH, up to $50,000):
- Exhausts the 4-permit capacity easily
- Prevents transaction broadcast and synchronization
- Legitimate transactions cannot propagate to consensus
- Mempool becomes effectively unusable [8](#0-7) 

**Peer Monitoring Service (MEDIUM):**
While capacity is higher (1000 permits), still vulnerable to sustained flooding attacks. [9](#0-8) 

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements:**
- Network connectivity to validator (available to any peer)
- Ability to send valid but slow-to-process messages
- No special privileges or validator access required

**Exploitation Complexity: LOW**
- Simple message flooding attack
- No need to exploit cryptographic weaknesses
- Does not require understanding of complex consensus logic
- Can be automated easily

**Detection Difficulty:**
- Messages appear legitimate initially
- May be confused with network congestion
- No obvious attack signature

**Why This Is Likely:**
- Very low capacity limits (4 for mempool, 16 for consensus)
- No per-peer quotas or rate limiting before permit acquisition
- Blocking design ensures even small floods are effective

## Recommendation

**Solution 1: Use Non-Blocking `try_spawn()` (Preferred)**

Replace `.spawn(...).await` with `.try_spawn()` in message processing loops. Drop or queue messages when at capacity instead of blocking:

```rust
// In RandManager verification_task
while let Some(rand_gen_msg) = incoming_rpc_request.next().await {
    let tx = verified_msg_tx.clone();
    let epoch_state_clone = epoch_state.clone();
    // ... other clones ...
    
    match bounded_executor.try_spawn(async move {
        // verification logic
    }) {
        Ok(_) => { /* spawned successfully */ },
        Err(_) => {
            // Log and drop message, or implement backpressure
            warn!("Dropped message due to executor at capacity");
            counters::DROPPED_MESSAGES.inc();
        }
    }
}
``` [10](#0-9) 

**Solution 2: Per-Peer Permit Quotas**

Implement per-peer quotas to prevent a single peer from exhausting all permits:

```rust
struct PerPeerQuota {
    peer_permits: HashMap<PeerId, Arc<Semaphore>>,
    max_per_peer: usize,
}

// Allow each peer to use at most 25% of total capacity
let per_peer_limit = capacity / 4;
```

**Solution 3: Increase Capacity**

Increase default capacity significantly, though this only mitigates, not fixes:
- Consensus: Increase from 16 to 256+
- Mempool: Increase from 4 to 64+

**Solution 4: Timeout on Permit Acquisition**

Implement timeout-based permit acquisition to prevent indefinite blocking:

```rust
match timeout(Duration::from_millis(100), bounded_executor.spawn(task)).await {
    Ok(handle) => { /* processed */ },
    Err(_) => { /* timeout, drop or queue */ }
}
```

## Proof of Concept

```rust
// Test demonstrating the blocking behavior
#[tokio::test]
async fn test_bounded_executor_dos() {
    use aptos_bounded_executor::BoundedExecutor;
    use tokio::sync::oneshot;
    use std::time::Duration;
    
    // Create executor with small capacity (like mempool's 4)
    let rt = tokio::runtime::Runtime::new().unwrap();
    let executor = BoundedExecutor::new(4, rt.handle().clone());
    
    // Spawn 4 long-running tasks to exhaust all permits
    let mut blockers = vec![];
    for _ in 0..4 {
        let (tx, rx) = oneshot::channel::<()>();
        blockers.push(tx);
        
        // These tasks will hold permits indefinitely
        let _ = executor.spawn(async move {
            let _ = rx.await;
        }).await;
    }
    
    // Now try to spawn a legitimate task
    let start = tokio::time::Instant::now();
    
    // This will block indefinitely waiting for a permit
    let spawn_future = executor.spawn(async {
        println!("Legitimate task executed");
    });
    
    // Verify that the spawn call is stuck waiting
    let result = tokio::time::timeout(
        Duration::from_millis(100),
        spawn_future
    ).await;
    
    // Assertion: The spawn call should timeout because all permits are held
    assert!(result.is_err(), "Spawn should block when permits exhausted");
    
    let elapsed = start.elapsed();
    println!("Blocked for {:?} - DoS successful", elapsed);
    
    // Cleanup: Release one permit to unblock
    blockers.pop().unwrap().send(()).unwrap();
}
```

**Real-World Attack Simulation:**

```rust
// Simulating malicious peer flooding consensus RandManager
// Attacker sends 16+ slow-to-verify rand gen messages
// Each message passes initial deserialization but takes time to verify
// Legitimate consensus messages are blocked from processing

// In attacker code:
for i in 0..16 {
    // Send valid but complex RandMessage that requires expensive verification
    network_client.send_rand_message(
        create_slow_verify_message(target_validator, round, complexity_factor)
    ).await;
}

// Meanwhile, honest validators trying to send messages get blocked
// because the target validator's bounded executor is at capacity
// Result: Consensus progress halts on the target validator
```

## Notes

**Distinction from Network-Level DoS:**

This is an **application-level resource exhaustion vulnerability**, not a network-level DoS. The attack exploits a logic flaw in how the bounded executor is integrated with message processing, not network bandwidth or packet flooding. This falls under "Total loss of liveness/network availability" (CRITICAL) and "Validator node slowdowns" (HIGH) per the bug bounty program.

**Additional Affected Components:**

The same pattern may exist in other consensus components that use `BoundedExecutor`. A comprehensive audit should examine all usages of `.spawn(...).await` in network message handlers.

### Citations

**File:** crates/bounded-executor/src/executor.rs (L33-35)
```rust
    async fn acquire_permit(&self) -> OwnedSemaphorePermit {
        self.semaphore.clone().acquire_owned().await.unwrap()
    }
```

**File:** crates/bounded-executor/src/executor.rs (L41-52)
```rust
    /// Spawn a [`Future`] on the `BoundedExecutor`. This function is async and
    /// will block if the executor is at capacity until one of the other spawned
    /// futures completes. This function returns a [`JoinHandle`] that the caller
    /// can `.await` on for the results of the [`Future`].
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor.spawn(future_with_permit(future, permit))
    }
```

**File:** crates/bounded-executor/src/executor.rs (L59-68)
```rust
    pub fn try_spawn<F>(&self, future: F) -> Result<JoinHandle<F::Output>, F>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        match self.try_acquire_permit() {
            Some(permit) => Ok(self.executor.spawn(future_with_permit(future, permit))),
            None => Err(future),
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L229-261)
```rust
        while let Some(rand_gen_msg) = incoming_rpc_request.next().await {
            let tx = verified_msg_tx.clone();
            let epoch_state_clone = epoch_state.clone();
            let config_clone = rand_config.clone();
            let fast_config_clone = fast_rand_config.clone();
            bounded_executor
                .spawn(async move {
                    match bcs::from_bytes::<RandMessage<S, D>>(rand_gen_msg.req.data()) {
                        Ok(msg) => {
                            if msg
                                .verify(
                                    &epoch_state_clone,
                                    &config_clone,
                                    &fast_config_clone,
                                    rand_gen_msg.sender,
                                )
                                .is_ok()
                            {
                                let _ = tx.unbounded_send(RpcRequest {
                                    req: msg,
                                    protocol: rand_gen_msg.protocol,
                                    response_sender: rand_gen_msg.response_sender,
                                });
                            }
                        },
                        Err(e) => {
                            warn!("Invalid rand gen message: {}", e);
                        },
                    }
                })
                .await;
        }
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L212-234)
```rust
        while let Some(dec_msg) = incoming_rpc_request.next().await {
            let tx = verified_msg_tx.clone();
            let epoch_state_clone = epoch_state.clone();
            let config_clone = config.clone();
            bounded_executor
                .spawn(async move {
                    match bcs::from_bytes::<SecretShareMessage>(dec_msg.req.data()) {
                        Ok(msg) => {
                            if msg.verify(&epoch_state_clone, &config_clone).is_ok() {
                                let _ = tx.unbounded_send(SecretShareRpc {
                                    msg,
                                    protocol: dec_msg.protocol,
                                    response_sender: dec_msg.response_sender,
                                });
                            }
                        },
                        Err(e) => {
                            warn!("Invalid dec message: {}", e);
                        },
                    }
                })
                .await;
        }
```

**File:** mempool/src/shared_mempool/coordinator.rs (L332-341)
```rust
    bounded_executor
        .spawn(tasks::process_transaction_broadcast(
            smp_clone,
            transactions,
            message_id,
            timeline_state,
            peer,
            task_start_timer,
        ))
        .await;
```

**File:** peer-monitoring-service/server/src/lib.rs (L86-122)
```rust
        while let Some(network_request) = self.network_requests.next().await {
            // Log the request
            let peer_network_id = network_request.peer_network_id;
            let peer_monitoring_service_request = network_request.peer_monitoring_service_request;
            let response_sender = network_request.response_sender;
            trace!(LogSchema::new(LogEntry::ReceivedPeerMonitoringRequest)
                .request(&peer_monitoring_service_request)
                .message(&format!(
                    "Received peer monitoring request. Peer: {:?}",
                    peer_network_id,
                )));

            // All handler methods are currently CPU-bound so we want
            // to spawn on the blocking thread pool.
            let base_config = self.base_config.clone();
            let peers_and_metadata = self.peers_and_metadata.clone();
            let start_time = self.start_time;
            let storage = self.storage.clone();
            let time_service = self.time_service.clone();
            self.bounded_executor
                .spawn_blocking(move || {
                    let response = Handler::new(
                        base_config,
                        peers_and_metadata,
                        start_time,
                        storage,
                        time_service,
                    )
                    .call(
                        peer_network_id.network_id(),
                        peer_monitoring_service_request,
                    );
                    log_monitoring_service_response(&response);
                    response_sender.send(response);
                })
                .await;
        }
```

**File:** config/src/config/consensus_config.rs (L379-379)
```rust
            num_bounded_executor_tasks: 16,
```

**File:** config/src/config/mempool_config.rs (L116-116)
```rust
            shared_mempool_max_concurrent_inbound_syncs: 4,
```

**File:** config/src/config/peer_monitoring_config.rs (L26-26)
```rust
            max_concurrent_requests: 1000,
```
