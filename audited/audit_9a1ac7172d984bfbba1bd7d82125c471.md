# Audit Report

## Title
Indexer gRPC Service Denial of Service via batch_size=0 Exploitation

## Summary
The indexer gRPC services fail to validate that the optional `batch_size` field in `GetTransactionsRequest` is non-zero. When an attacker sends `batch_size: Some(0)` (explicitly set to zero), the HistoricalDataService panics due to `.chunks(0)` invocation, and the LiveDataService enters an infinite loop. This exploits the protobuf3 optional field semantics where `None` (absent field) defaults safely to 1000/10000, but `Some(0)` (explicit zero) bypasses validation.

## Finding Description
The protobuf definition for `GetTransactionsRequest` declares `batch_size` as `optional uint64` with comments stating "If not present, default to 1000". [1](#0-0) 

The Rust implementation uses `Option<u64>` for this field, correctly preserving the distinction between `None` (field absent) and `Some(0)` (field explicitly set to zero). [2](#0-1) 

**HistoricalDataService Vulnerability:**

The service extracts `batch_size` without validating it's non-zero: [3](#0-2) 

This value is then used in `.chunks()` which panics when given zero: [4](#0-3) 

**LiveDataService Vulnerability:**

The same pattern exists in LiveDataService: [5](#0-4) 

The zero value is passed to `get_data()` which uses it as a loop termination condition: [6](#0-5) 

When `max_num_transactions_per_batch = 0`, the condition `result.len() < 0` is false immediately (since empty vec has length 0, and 0 < 0 = false). The loop never executes, returning `(vec![], 0, starting_version - 1)`. [7](#0-6) 

This causes `next_version` to be set back to `starting_version`, creating an infinite loop of empty responses that exhausts server resources.

## Impact Explanation
This is **High Severity** per the Aptos bug bounty criteria:

1. **API crashes** - The HistoricalDataService experiences panic when processing requests with `batch_size: 0`, potentially crashing the service thread and disrupting indexer operations.

2. **Validator node slowdowns** - The LiveDataService enters an infinite loop, consuming CPU cycles and network bandwidth sending empty responses, degrading performance for legitimate users and potentially affecting validator operations that depend on indexer services.

3. **Resource Exhaustion** - An attacker can spawn multiple concurrent requests with `batch_size: 0` to amplify the denial of service, exhausting memory and network resources.

The vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits."

## Likelihood Explanation
**Likelihood: HIGH**

- **Attack Complexity: Trivial** - Any client can send a gRPC request with `batch_size: 0`
- **Attacker Requirements: None** - No authentication, special permissions, or insider access required
- **Detectability: Low** - The malicious request looks nearly identical to legitimate requests
- **Amplification: Easy** - Attacker can send multiple concurrent requests to maximize impact

The vulnerability is trivially exploitable by any network peer with access to the indexer gRPC endpoints.

## Recommendation
Add validation to reject `batch_size` values of zero before using them:

```rust
// In HistoricalDataService::run()
let max_num_transactions_per_batch = if let Some(batch_size) = request.batch_size {
    if batch_size == 0 {
        let err = Err(Status::invalid_argument("batch_size must be greater than 0."));
        info!("Client error: {err:?}.");
        let _ = response_sender.blocking_send(err);
        COUNTER
            .with_label_values(&["historical_data_service_invalid_request"])
            .inc();
        continue;
    }
    batch_size as usize
} else {
    DEFAULT_MAX_NUM_TRANSACTIONS_PER_BATCH
};

// Apply similar validation in LiveDataService::run()
```

Additionally, add validation for the upper bound to prevent resource exhaustion from excessively large batch sizes, as mentioned in the protobuf comments: "If larger than 1000, request will be rejected."

## Proof of Concept

```rust
// Rust gRPC client PoC
use aptos_protos::indexer::v1::{GetTransactionsRequest, data_service_client::DataServiceClient};

#[tokio::test]
async fn test_batch_size_zero_dos() {
    let mut client = DataServiceClient::connect("http://indexer-service:50051")
        .await
        .unwrap();
    
    // Attack payload: explicitly set batch_size to 0
    let malicious_request = GetTransactionsRequest {
        starting_version: Some(1),
        transactions_count: Some(100),
        batch_size: Some(0),  // Exploits None vs Some(0) ambiguity
        transaction_filter: None,
    };
    
    // This will cause HistoricalDataService to panic
    // and LiveDataService to infinite loop
    let response = client.get_transactions(malicious_request).await;
    
    // Expected: Service crashes or hangs
    // Actual: Should return invalid_argument error after fix
}
```

**Reproduction Steps:**
1. Deploy indexer gRPC services (HistoricalDataService or LiveDataService)
2. Send `GetTransactionsRequest` with `batch_size: 0` via gRPC client
3. Observe: HistoricalDataService panics with "chunk size must be non-zero", LiveDataService hangs sending empty responses indefinitely
4. Monitor resource consumption showing CPU/network saturation

### Citations

**File:** protos/proto/aptos/indexer/v1/raw_data.proto (L27-29)
```text
  // Optional; number of transactions in each `TransactionsResponse` for current stream.
  // If not present, default to 1000. If larger than 1000, request will be rejected.
  optional uint64 batch_size = 3;
```

**File:** protos/rust/src/pb/aptos.indexer.v1.rs (L129-132)
```rust
    /// Optional; number of transactions in each `TransactionsResponse` for current stream.
    /// If not present, default to 1000. If larger than 1000, request will be rejected.
    #[prost(uint64, optional, tag="3")]
    pub batch_size: ::core::option::Option<u64>,
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L102-106)
```rust
                let max_num_transactions_per_batch = if let Some(batch_size) = request.batch_size {
                    batch_size as usize
                } else {
                    DEFAULT_MAX_NUM_TRANSACTIONS_PER_BATCH
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/historical_data_service.rs (L204-206)
```rust
                    let mut responses: Vec<_> = transactions
                        .chunks(max_num_transactions_per_batch)
                        .map(|chunk| {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/mod.rs (L117-121)
```rust
                let max_num_transactions_per_batch = if let Some(batch_size) = request.batch_size {
                    batch_size as usize
                } else {
                    10000
                };
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L84-87)
```rust
            while version < ending_version
                && total_bytes < max_bytes_per_batch
                && result.len() < max_num_transactions_per_batch
            {
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service-v2/src/live_data_service/in_memory_cache.rs (L99-100)
```rust
            trace!("Data was sent from cache, last version: {}.", version - 1);
            return Some((result, total_bytes, version - 1));
```
