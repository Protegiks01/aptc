# Audit Report

## Title
Epoch Gap in Database Causes Permanent Backup Failure After Truncation

## Summary
The `EpochEndingLedgerInfoIter` enforces strict consecutive epoch ordering but database truncation operations can delete epoch ending ledger infos, creating gaps. Once gaps exist, all backup attempts spanning the gap fail with "Epochs are not consecutive" error, permanently breaking disaster recovery capability.

## Finding Description

The vulnerability exists in the interaction between database truncation and backup iteration logic:

**Component 1: Strict Epoch Consecutiveness Check**

The `EpochEndingLedgerInfoIter` in [1](#0-0)  enforces that epochs must be strictly consecutive. When iterating through epochs, if the database returns epoch N+1 but the iterator expects epoch N, it immediately errors out rather than gracefully skipping the gap.

**Component 2: Epoch Deletion During Truncation**

The `delete_per_epoch_data` function in [2](#0-1)  deletes epoch ending ledger infos from both `LedgerInfoSchema` and `EpochByVersionSchema` when truncating the database to a target version. This removes all epochs at or after the truncation point.

**Component 3: Automatic Truncation on Startup**

The `sync_commit_progress` function in [3](#0-2)  automatically truncates the ledger database on node startup when commit progress inconsistencies are detected (e.g., after a crash during commit).

**Exploitation Scenario:**

1. Node is running with epochs 0-100 committed
2. Node crashes during commit at version V90 (within epoch 90)
3. On restart, `sync_commit_progress` detects inconsistency and calls `truncate_ledger_db(overall_commit_progress=V90)`
4. `delete_per_epoch_data` removes epoch ending ledger infos for epochs 91-100
5. Node continues operating and creates new epoch ending ledger infos for epochs 91, 92, 93...
6. Operator attempts backup from epoch 0 to current epoch via [4](#0-3) 
7. Iterator processes epochs 0-90 successfully, then hits the gap where old epochs 91-100 were deleted
8. Iterator fails with "Epochs are not consecutive. expecting: 91, got: 91" (the new epoch 91 with different version)
9. **Backup fails completely and cannot be completed**

The backup system called via [5](#0-4)  relies on this iterator, and the restore process in [6](#0-5)  also expects consecutive epochs, making any backup with gaps unrestorable.

**Broken Invariant:** State Consistency - backups must be complete and restorable for disaster recovery. The system cannot maintain backup integrity when epoch gaps exist.

## Impact Explanation

**HIGH Severity** per Aptos Bug Bounty criteria:

1. **Significant Protocol Violation**: Breaks the fundamental guarantee that backups can be created and restored, which is critical infrastructure for blockchain disaster recovery

2. **Validator Node Impact**: Once epoch gaps exist, validators cannot create valid backups spanning historical data, limiting their ability to recover from catastrophic failures

3. **Network Availability**: In disaster scenarios requiring restoration from backup (data corruption, security incident requiring rollback), the inability to restore from backups could cause extended network downtime or require emergency hardfork

4. **No Workaround**: Once epoch gaps exist in the database, there is no way to recreate the deleted epoch ending ledger infos, permanently breaking backup capability for that range

This falls under "Significant protocol violations" for HIGH severity ($50,000 category) as it fundamentally breaks the backup/restore system which is essential infrastructure.

## Likelihood Explanation

**HIGH Likelihood:**

1. **Common Trigger**: Node crashes during commit operations are not uncommon in production environments (hardware failures, OOM kills, power outages)

2. **Automatic Execution**: The vulnerability triggers automatically via `sync_commit_progress` on node startup after any commit inconsistency - no manual intervention needed

3. **Permanent Effect**: Once epochs are deleted, the gap persists forever and affects all future backup attempts

4. **Production Relevance**: Backup operations are regularly performed in production for disaster recovery, so operators will discover this issue quickly

The combination of common trigger events, automatic execution, and permanent impact makes this a high-likelihood issue that will affect production systems.

## Recommendation

**Solution 1: Make Iterator Skip Missing Epochs (Preferred)**

Modify `EpochEndingLedgerInfoIter::next_impl()` to skip missing epochs gracefully instead of failing:

```rust
fn next_impl(&mut self) -> Result<Option<LedgerInfoWithSignatures>> {
    if self.next_epoch >= self.end_epoch {
        return Ok(None);
    }

    while let Some((epoch, li)) = self.inner.next().transpose()? {
        if !li.ledger_info().ends_epoch() {
            continue;
        }
        
        if epoch < self.next_epoch {
            // Skip epochs that are before our current position
            continue;
        }
        
        if epoch > self.next_epoch {
            // Gap detected - log warning and skip to found epoch
            warn!(
                "Epoch gap detected: expecting {}, found {}. Skipping gap.",
                self.next_epoch, epoch
            );
        }
        
        self.next_epoch = epoch + 1;
        return Ok(Some(li));
    }
    
    Ok(None)
}
```

**Solution 2: Preserve Epoch Ending Ledger Infos During Truncation**

Modify `delete_per_epoch_data` to not delete epoch ending ledger infos even when truncating, as they are needed for backup continuity.

**Solution 3: Add Gap Detection and Warning**

At minimum, detect epoch gaps during backup initialization and fail fast with clear error message about unrecoverable backup state.

**Recommended Approach:** Solution 1 is preferred as it provides resilience. Epoch ending ledger infos are primarily for verification and backup - having gaps in the sequence doesn't compromise chain integrity since the actual state tree and transactions are intact.

## Proof of Concept

```rust
#[cfg(test)]
mod test_epoch_gap_backup_failure {
    use super::*;
    use aptos_temppath::TempPath;
    use aptos_types::ledger_info::LedgerInfoWithSignatures;
    
    #[test]
    fn test_epoch_gap_causes_backup_failure() {
        // Setup: Create DB with epochs 0-100
        let tmp_dir = TempPath::new();
        let db = AptosDB::new_for_test(&tmp_dir);
        
        // Commit blocks through epochs 0-100
        for epoch in 0..=100 {
            let (txns, li_with_sigs) = create_epoch_ending_block(epoch);
            db.save_transactions_for_test(&txns, epoch * 1000, Some(&li_with_sigs), true)
                .unwrap();
        }
        
        // Verify backup works initially
        let backup_handler = db.get_backup_handler();
        let mut iter = backup_handler
            .get_epoch_ending_ledger_info_iter(0, 101)
            .unwrap();
        let mut count = 0;
        while let Some(result) = iter.next() {
            result.unwrap(); // Should succeed
            count += 1;
        }
        assert_eq!(count, 101);
        
        // Simulate truncation: manually delete epochs 91-100
        let ledger_db = db.ledger_db_arc();
        let mut batch = SchemaBatch::new();
        for epoch in 91..=100 {
            batch.delete::<LedgerInfoSchema>(&epoch).unwrap();
        }
        ledger_db.metadata_db().write_schemas(batch).unwrap();
        
        // Node continues and creates new epoch 91 (different version)
        let (txns, new_li_91) = create_epoch_ending_block(91);
        db.save_transactions_for_test(&txns, 101_000, Some(&new_li_91), true)
            .unwrap();
        
        // Attempt backup spanning the gap - THIS WILL FAIL
        let backup_handler = db.get_backup_handler();
        let mut iter = backup_handler
            .get_epoch_ending_ledger_info_iter(0, 92)
            .unwrap();
        
        let mut count = 0;
        let mut error_found = false;
        while let Some(result) = iter.next() {
            match result {
                Ok(_) => count += 1,
                Err(e) => {
                    // Expected error: "Epochs are not consecutive"
                    assert!(e.to_string().contains("not consecutive"));
                    error_found = true;
                    break;
                }
            }
        }
        
        // Backup failed due to epoch gap
        assert!(error_found, "Expected epoch gap error but backup succeeded");
        assert!(count < 92, "Backup should have failed before completing all epochs");
    }
}
```

**Notes:**

This vulnerability breaks the critical invariant that blockchain backups must be complete and restorable. The strict epoch consecutiveness check in the iterator, combined with automatic truncation that deletes epochs, creates a permanent unrecoverable state where backups cannot be created. This affects disaster recovery capabilities and falls under HIGH severity "significant protocol violations" category. The issue occurs through normal operations (crashes during commit) with high likelihood and has no workaround once epoch gaps exist.

### Citations

**File:** storage/aptosdb/src/utils/iterators.rs (L219-224)
```rust
                    ensure!(
                        epoch == self.next_epoch,
                        "Epochs are not consecutive. expecting: {}, got: {}",
                        self.next_epoch,
                        epoch,
                    );
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L413-425)
```rust
    let mut iter = ledger_db.iter::<EpochByVersionSchema>()?;
    iter.seek(&start_version)?;

    for item in iter {
        let (version, epoch) = item?;
        info!(
            version = version,
            epoch = epoch,
            "Truncate epoch ending data."
        );
        batch.delete::<EpochByVersionSchema>(&version)?;
        batch.delete::<LedgerInfoSchema>(&epoch)?;
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L448-449)
```rust
            truncate_ledger_db(ledger_db.clone(), overall_commit_progress)
                .expect("Failed to truncate ledger db.");
```

**File:** storage/backup/backup-service/src/handlers/mod.rs (L95-96)
```rust
                bh.get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
                    .try_for_each(|record_res| sender.send_size_prefixed_bcs_bytes(record_res?))
```

**File:** storage/aptosdb/src/backup/backup_handler.rs (L207-221)
```rust
    pub fn get_epoch_ending_ledger_info_iter(
        &self,
        start_epoch: u64,
        end_epoch: u64,
    ) -> Result<impl Iterator<Item = Result<LedgerInfoWithSignatures>> + '_> {
        Ok(self
            .ledger_db
            .metadata_db()
            .get_epoch_ending_ledger_info_iter(start_epoch, end_epoch)?
            .enumerate()
            .map(move |(idx, li)| {
                BACKUP_EPOCH_ENDING_EPOCH.set((start_epoch + idx as u64) as i64);
                li
            }))
    }
```

**File:** storage/backup/backup-cli/src/backup_types/epoch_ending/restore.rs (L113-118)
```rust
                ensure!(
                    li.ledger_info().epoch() == next_epoch,
                    "LedgerInfo epoch not expected. Expected: {}, actual: {}.",
                    li.ledger_info().epoch(),
                    next_epoch,
                );
```
