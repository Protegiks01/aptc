# Audit Report

## Title
Event Translation Race Condition Allows Hiding V2 Events from Indexer Queries

## Summary
The `translate_event_v2_to_v1()` function uses `latest_state_checkpoint_view()` to query on-chain state during event translation, creating a race condition where V2 events can be silently excluded from the indexer database if required resources are deleted after event emission but before indexing. This allows events to exist on-chain but remain invisible to indexer queries, violating event visibility guarantees and creating non-deterministic indexer behavior.

## Finding Description

The event translation system in the Aptos indexer exhibits a critical timing vulnerability. When translating V2 events to V1 format for indexing, the system queries blockchain state using the **latest** state checkpoint rather than the state at the time the event was emitted. [1](#0-0) 

The translation delegates to `DBIndexer::translate_event_v2_to_v1()`: [2](#0-1) 

When translation fails (e.g., "resource not found"), the function returns `Ok(None)` rather than propagating an error. This is then handled in `process_a_batch()`: [3](#0-2) 

The critical issue is that all translators query state using `latest_state_checkpoint_view()`: [4](#0-3) [5](#0-4) 

**Attack Scenarios:**

1. **Within-Transaction Resource Deletion**: A transaction emits a `TokenMutation` event then burns the token in the same transaction. When the indexer processes this event, it queries the latest state where the `Token` resource no longer exists, causing translation to fail: [6](#0-5) 

2. **Cross-Transaction Race**: Transaction V1 emits an event at version 100. Transaction V2 at version 150 deletes the required resource. When the indexer processes version 100 but the main DB is at version 200+, the resource lookup fails.

3. **Unregistered Event Types**: Custom V2 events without registered translators are silently skipped with no error.

**Result**: Events that return `None` from translation are **not indexed** into `EventByKeySchema`, `EventByVersionSchema`, or `TranslatedV1EventSchema`. They exist on-chain in the transaction history but become invisible to all indexer-based queries.

## Impact Explanation

This is a **Medium Severity** vulnerability per Aptos bug bounty criteria because it causes **state inconsistencies requiring intervention**:

- **Event Visibility Violation**: Events that should be queryable become invisible, breaking the guarantee that all on-chain events are accessible through the indexer API.

- **Non-Deterministic Behavior**: Two nodes processing the same blockchain history can have different indexer databases depending on when they processed each batch relative to resource deletions. This violates the **Deterministic Execution** invariant.

- **Audit Trail Compromise**: Critical events (token mutations, burns, transfers) can be hidden, compromising audit trails for compliance and security monitoring.

- **API Inconsistency**: The Full Node API will show incomplete event histories, potentially causing dApp failures or incorrect application state.

While this does not directly cause loss of funds or consensus violations, it represents a significant protocol violation affecting multiple nodes and requiring manual intervention to ensure consistent indexer state across the network.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability occurs under common operational conditions:

1. **Token Lifecycle Operations**: The pattern of mutating then burning tokens is standard behavior in NFT marketplaces and game mechanics. The code even acknowledges this case with the comment "The token may have been burned" in the translator.

2. **Indexer Lag**: Indexers routinely lag behind the main blockchain, especially during high load or node restart scenarios, increasing the window for race conditions.

3. **No Attacker Sophistication Required**: Any user performing normal token operations can trigger this. No special privileges, timing coordination, or deep protocol knowledge is needed.

4. **Persistent Effect**: Once an event is skipped from indexing, it remains invisible until manual database reconstruction, making this a persistent rather than transient issue.

The vulnerability is triggered automatically by legitimate user behavior and becomes more frequent as blockchain activity increases.

## Recommendation

**Fix the State View Timing Issue:**

Modify `EventV2TranslationEngine` to accept a version parameter and query state at the correct version rather than using `latest_state_checkpoint_view()`. The translation should occur using the state **immediately before** the transaction that emitted the event.

```rust
// In event_v2_translator.rs
pub fn get_state_value_bytes_for_resource_at_version(
    &self,
    address: &AccountAddress,
    struct_tag: &StructTag,
    version: Version,
) -> Result<Option<Bytes>> {
    // Query state at version-1 (before the transaction)
    let state_view = self
        .main_db_reader
        .state_view_at_version(Some(version.saturating_sub(1)))
        .expect("Failed to get state view");
    let state_key = StateKey::resource(address, struct_tag)?;
    let maybe_state_value = state_view.get_state_value(&state_key)?;
    Ok(maybe_state_value.map(|state_value| state_value.bytes().clone()))
}
```

**Modify the Indexer Flow:**

Pass the transaction version to the translation engine:

```rust
// In db_indexer.rs process_a_batch
if let ContractEvent::V2(v2) = event {
    if let Some(translated_v1_event) = 
        self.translate_event_v2_to_v1_at_version(v2, version)
            .map_err(|e| anyhow::anyhow!("..."))?
    {
        // ... index the event
    }
}
```

**Add Error Handling:**

For critical event types where translation should never fail, propagate errors rather than returning `None` silently to ensure data integrity violations are caught.

## Proof of Concept

```rust
// Test case demonstrating the vulnerability
#[test]
fn test_event_translation_race_condition() {
    // Setup: Create indexer and main DB
    let (indexer, main_db) = setup_test_environment();
    
    // Step 1: Submit transaction at V=100 that:
    // - Emits TokenMutation event
    // - Burns the token (deletes Token resource)
    let txn = create_token_mutation_and_burn_transaction();
    main_db.commit_transaction(100, txn);
    
    // Step 2: Advance main DB to V=200
    for v in 101..=200 {
        main_db.commit_transaction(v, create_dummy_transaction());
    }
    
    // Step 3: Indexer processes V=100
    // Translation will query latest state (V=200) where Token is gone
    indexer.process_a_batch(100, 101);
    
    // Step 4: Verify event is NOT indexed
    let events = indexer.get_events_by_version(100);
    
    // BUG: TokenMutation event exists on-chain but is NOT in indexer
    assert!(events.is_empty(), "Event was incorrectly indexed");
    
    // The event exists in main DB but is invisible to queries
    let on_chain_events = main_db.get_events(100);
    assert!(!on_chain_events.is_empty(), "Event exists on-chain");
    
    // This proves events can be hidden from the indexer
}
```

**Move Test Case:**

```move
#[test(creator = @0x123)]
fun test_hidden_mutation_event(creator: &signer) {
    // Create and mint a token
    let token = create_test_token(creator);
    
    // Mutate the token (emits TokenMutation event)
    set_description(creator, token, string::utf8(b"New description"));
    
    // Immediately burn the token (deletes Token resource)
    burn(creator, token);
    
    // Event was emitted on-chain
    // But if indexer processes this after the burn,
    // the TokenMutation event will not be indexed
    // because Token resource is gone when translator runs
}
```

## Notes

This vulnerability specifically affects the internal indexer's V2-to-V1 event translation system. The events remain in the blockchain's permanent transaction history, but become inaccessible through the indexer API, which is the primary interface used by dApps, explorers, and analytical tools. The race condition is exacerbated by the asynchronous nature of indexer processing and the fact that resource deletions (burns, transfers) are common in token operations.

### Citations

**File:** storage/indexer/src/indexer_reader.rs (L185-197)
```rust
    fn translate_event_v2_to_v1(
        &self,
        v2: &ContractEventV2,
    ) -> anyhow::Result<Option<ContractEventV1>> {
        if let Some(db_indexer_reader) = &self.db_indexer_reader {
            if db_indexer_reader.indexer_db.event_v2_translation_enabled() {
                return Ok(db_indexer_reader.translate_event_v2_to_v1(v2)?);
            } else {
                anyhow::bail!("Event translation is not enabled")
            }
        }
        anyhow::bail!("DB indexer reader is not available")
    }
```

**File:** storage/indexer/src/db_indexer.rs (L448-484)
```rust
                    if self.indexer_db.event_v2_translation_enabled() {
                        if let ContractEvent::V2(v2) = event {
                            if let Some(translated_v1_event) =
                                self.translate_event_v2_to_v1(v2).map_err(|e| {
                                    anyhow::anyhow!(
                                        "Failed to translate event: {:?}. Error: {}",
                                        v2,
                                        e
                                    )
                                })?
                            {
                                let key = *translated_v1_event.key();
                                let sequence_number = translated_v1_event.sequence_number();
                                self.event_v2_translation_engine
                                    .cache_sequence_number(&key, sequence_number);
                                event_keys.insert(key);
                                batch
                                    .put::<EventByKeySchema>(
                                        &(key, sequence_number),
                                        &(version, idx as u64),
                                    )
                                    .expect("Failed to put events by key to a batch");
                                batch
                                    .put::<EventByVersionSchema>(
                                        &(key, version, sequence_number),
                                        &(idx as u64),
                                    )
                                    .expect("Failed to put events by version to a batch");
                                batch
                                    .put::<TranslatedV1EventSchema>(
                                        &(version, idx as u64),
                                        &translated_v1_event,
                                    )
                                    .expect("Failed to put translated v1 events to a batch");
                            }
                        }
                    }
```

**File:** storage/indexer/src/db_indexer.rs (L552-584)
```rust
    pub fn translate_event_v2_to_v1(
        &self,
        v2: &ContractEventV2,
    ) -> Result<Option<ContractEventV1>> {
        let _timer = TIMER.timer_with(&["translate_event_v2_to_v1"]);
        if let Some(translator) = self
            .event_v2_translation_engine
            .translators
            .get(v2.type_tag())
        {
            let result = translator.translate_event_v2_to_v1(v2, &self.event_v2_translation_engine);
            match result {
                Ok(v1) => Ok(Some(v1)),
                Err(e) => {
                    // If the token object collection uses ConcurrentSupply, skip the translation and ignore the error.
                    // This is expected, as the event handle won't be found in either FixedSupply or UnlimitedSupply.
                    let is_ignored_error = (v2.type_tag() == &*MINT_TYPE
                        || v2.type_tag() == &*BURN_TYPE)
                        && e.to_string().contains("resource not found");
                    if !is_ignored_error {
                        warn!(
                            "Failed to translate event: {:?}. Error: {}",
                            v2,
                            e.to_string()
                        );
                    }
                    Ok(None)
                },
            }
        } else {
            Ok(None)
        }
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L202-214)
```rust
    pub fn get_state_value_bytes_for_resource(
        &self,
        address: &AccountAddress,
        struct_tag: &StructTag,
    ) -> Result<Option<Bytes>> {
        let state_view = self
            .main_db_reader
            .latest_state_checkpoint_view()
            .expect("Failed to get state view");
        let state_key = StateKey::resource(address, struct_tag)?;
        let maybe_state_value = state_view.get_state_value(&state_key)?;
        Ok(maybe_state_value.map(|state_value| state_value.bytes().clone()))
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L216-235)
```rust
    pub fn get_state_value_bytes_for_object_group_resource(
        &self,
        address: &AccountAddress,
        struct_tag: &StructTag,
    ) -> Result<Option<Bytes>> {
        let state_view = self
            .main_db_reader
            .latest_state_checkpoint_view()
            .expect("Failed to get state view");
        static OBJECT_GROUP_TAG: Lazy<StructTag> = Lazy::new(ObjectGroupResource::struct_tag);
        let state_key = StateKey::resource_group(address, &OBJECT_GROUP_TAG);
        let maybe_state_value = state_view.get_state_value(&state_key)?;
        let state_value = maybe_state_value
            .ok_or_else(|| anyhow::format_err!("ObjectGroup resource not found"))?;
        let object_group_resource: ObjectGroupResource = bcs::from_bytes(state_value.bytes())?;
        Ok(object_group_resource
            .group
            .get(struct_tag)
            .map(|bytes| Bytes::copy_from_slice(bytes)))
    }
```

**File:** storage/indexer/src/event_v2_translator.rs (L430-456)
```rust
struct TokenMutationTranslator;
impl EventV2Translator for TokenMutationTranslator {
    fn translate_event_v2_to_v1(
        &self,
        v2: &ContractEventV2,
        engine: &EventV2TranslationEngine,
    ) -> Result<ContractEventV1> {
        let token_mutation = TokenMutation::try_from_bytes(v2.event_data())?;
        let struct_tag_str = "0x4::token::Token".to_string();
        let struct_tag = StructTag::from_str(&struct_tag_str)?;
        let (key, sequence_number) = if let Some(state_value_bytes) = engine
            .get_state_value_bytes_for_object_group_resource(
                token_mutation.token_address(),
                &struct_tag,
            )? {
            let token_resource: TokenResource = bcs::from_bytes(&state_value_bytes)?;
            let key = *token_resource.mutation_events().key();
            let sequence_number =
                engine.get_next_sequence_number(&key, token_resource.mutation_events().count())?;
            (key, sequence_number)
        } else {
            // If the token resource is not found, we skip the event translation to avoid panic
            // because the creation number cannot be decided. The token may have been burned.
            return Err(AptosDbError::from(anyhow::format_err!(
                "Token resource not found"
            )));
        };
```
