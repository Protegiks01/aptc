# Audit Report

## Title
Non-Deterministic ExecutorError Handling Causes Consensus Liveness Failure and Validator State Divergence

## Summary
The consensus pipeline's execution error handling is non-deterministic across validators, violating the fundamental "Deterministic Execution" invariant. When different validators encounter different `ExecutorError` variants for the same block (particularly timeout-based `CouldNotGetData` errors), some validators drop the block and halt progress while others successfully execute and advance, leading to consensus liveness failures and potential state divergence.

## Finding Description

The vulnerability exists in the execution wait phase error handling within the consensus buffer manager. When an `ExecutorError` occurs during block execution, the error is logged and the block is silently dropped without any state advancement: [1](#0-0) 

The critical issue is that `ExecutorError` variants can be triggered non-deterministically across validators. The most problematic variant is `CouldNotGetData`, which occurs due to:

1. **Network timeouts** when fetching quorum store batches: [2](#0-1) 

2. **Batch expiration** based on local ledger info timestamps: [3](#0-2) 

3. **Database retrieval failures** when batches are not in local cache: [4](#0-3) 

These error sources are inherently non-deterministic because they depend on:
- Network latency and packet delivery timing (varies per validator)
- Local database and cache state (varies per validator)
- Timestamp-based expiration checks (timing-dependent)

The error handling categorizes all errors uniformly but does not retry or propagate them to consensus: [5](#0-4) 

When a validator encounters an `ExecutorError`, the execution root is not advanced, leaving the block stuck in "Ordered" state. The validator cannot proceed to sign or commit this block. Meanwhile, other validators who successfully retrieved the batch data will execute, sign, and commit the same block, creating state divergence.

**Attack Scenario:**

Under normal network conditions without malicious intent:
1. Block N arrives at all validators via consensus ordering
2. Validator A experiences network delays → batch request times out → `CouldNotGetData` error → drops block N
3. Validators B, C, D successfully retrieve batches → execute block N → advance to signing phase
4. Validators B, C, D reach quorum and commit block N
5. Validator A remains stuck at block N-1, unable to participate in subsequent rounds

With intentional network manipulation:
1. An attacker with network-level access (e.g., controlling routing paths to certain validators)
2. Selectively delays batch delivery to a minority of validators
3. Causes those validators to timeout and drop blocks
4. Forces repeated state sync operations, degrading network performance
5. In extreme cases, delays to >1/3 of validators prevents quorum, causing total liveness failure

## Impact Explanation

**Critical Severity** - This vulnerability can cause:

1. **Total loss of liveness**: If >1/3 of validators encounter non-deterministic timeout errors for the same block, consensus cannot reach quorum (2f+1 votes), halting the entire network. This maps to the Critical severity category: "Total loss of liveness/network availability".

2. **Persistent validator divergence**: Validators that encounter errors become permanently stuck and fall behind the network, requiring manual state synchronization intervention. This approaches "Non-recoverable network partition" territory.

3. **Consensus instability**: Even with <1/3 affected validators, the network experiences degraded reliability as validators randomly drop out and need recovery, violating the "Deterministic Execution" invariant.

The severity is Critical (up to $1,000,000) because:
- It can halt the entire network without requiring Byzantine behavior
- It breaks fundamental consensus guarantees under normal operational variance
- Recovery may require coordinated intervention across validators
- The issue affects core consensus safety and liveness properties

## Likelihood Explanation

**High Likelihood** - This issue will occur naturally during normal network operations:

1. **Network variance is inevitable**: Different validators experience different network conditions, latency, and packet delivery timing. Batch request timeouts (line 178 of batch_requester.rs) will naturally occur more frequently on validators with slower connections.

2. **Cache state divergence**: Validators maintain independent local caches. Database retrieval failures (line 557 of batch_store.rs) will occur when some validators have not yet persisted certain batches while others have.

3. **Timestamp-based races**: Expiration checks depend on local ledger timestamps, which can vary slightly across validators during normal synchronization delays.

4. **No recovery mechanism**: The code has no automatic retry logic for `ExecutorError`. The `advance_execution_root()` function returns an ignored value: [6](#0-5) 

The return value indicating retry is needed is discarded: [7](#0-6) 

This means stuck validators remain stuck indefinitely without manual intervention.

## Recommendation

**Immediate Fix**: Implement deterministic error handling with guaranteed eventual consistency:

1. **Add automatic retry mechanism** with exponential backoff for transient errors like `CouldNotGetData`:

```rust
// In buffer_manager.rs process_execution_response
let executed_blocks = match inner {
    Ok(result) => result,
    Err(e) => {
        log_executor_error_occurred(
            e.clone(),
            &counters::BUFFER_MANAGER_RECEIVED_EXECUTOR_ERROR_COUNT,
            block_id,
        );
        
        // Classify error as transient or permanent
        match e {
            ExecutorError::CouldNotGetData | 
            ExecutorError::DataNotFound(_) => {
                // Transient errors - schedule retry with backoff
                let retry_count = self.get_retry_count(block_id);
                if retry_count < MAX_RETRIES {
                    self.schedule_execution_retry(block_id, retry_count);
                    return;
                } else {
                    // After max retries, trigger state sync
                    self.trigger_state_sync_for_block(block_id);
                    return;
                }
            },
            ExecutorError::BlockNotFound(_) => {
                // Missing dependency - wait for parent
                warn!("Parent block not found, waiting for sync");
                return;
            },
            _ => {
                // Permanent execution errors - these indicate real problems
                // All validators should deterministically hit these
                error!("Permanent execution error: {:?}", e);
                return;
            }
        }
    },
};
```

2. **Synchronize batch availability** before execution phase:

```rust
// In execution_schedule_phase.rs, ensure all validators wait for batch availability
async fn ensure_batches_available(&self, block: &Block) -> ExecutorResult<()> {
    for digest in block.required_batch_digests() {
        // Wait with timeout, but coordinate across validators
        // Use consensus round timeout rather than individual validator timeout
        self.batch_store.await_batch_with_consensus_timeout(digest).await?;
    }
    Ok(())
}
```

3. **Add consensus-level error propagation**: Errors that indicate real execution problems (not just timeouts) should be propagated to consensus to trigger view change, ensuring all validators handle the error uniformly.

4. **Implement batch pre-fetching**: Proactively fetch batches when ordered blocks arrive, before execution phase, to minimize timeout scenarios.

## Proof of Concept

```rust
// Rust test demonstrating non-deterministic error handling
// File: consensus/src/pipeline/buffer_manager_test.rs

#[tokio::test]
async fn test_executor_error_causes_state_divergence() {
    // Setup 4 validators
    let mut validators = vec![];
    for i in 0..4 {
        validators.push(setup_validator(i));
    }
    
    // Create a block that requires batch data
    let block = create_test_block_with_batch_dependency();
    
    // Simulate network conditions:
    // - Validator 0: Normal network, receives batch
    // - Validator 1: Normal network, receives batch  
    // - Validator 2: Slow network, timeout on batch request
    // - Validator 3: Normal network, receives batch
    
    // Inject batch for validators 0, 1, 3
    for i in [0, 1, 3] {
        validators[i].batch_store.insert_batch(TEST_BATCH_DIGEST, test_batch_data());
    }
    
    // Validator 2 will timeout - simulate by NOT inserting batch
    // (In real scenario, network delay causes timeout before batch arrives)
    
    // Send ordered block to all validators
    for validator in &mut validators {
        validator.process_ordered_block(block.clone()).await;
    }
    
    // Wait for execution phase
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // Verify divergence:
    // Validators 0, 1, 3 should have executed the block
    assert_eq!(validators[0].execution_root, Some(block.id()));
    assert_eq!(validators[1].execution_root, Some(block.id()));
    assert_eq!(validators[3].execution_root, Some(block.id()));
    
    // Validator 2 should be stuck at previous block due to CouldNotGetData error
    assert_ne!(validators[2].execution_root, Some(block.id()));
    
    // Check that validator 2 logged the error
    assert!(validators[2].received_executor_error_count("CouldNotGetData") > 0);
    
    // Validators 0, 1, 3 can reach quorum and commit
    // Validator 2 is stuck and cannot participate
    // This demonstrates state divergence and consensus instability
    
    println!("State divergence confirmed: 3 validators advanced, 1 validator stuck");
}
```

**Notes:**

This vulnerability is particularly concerning because:
1. It requires NO malicious action - normal network variance triggers it
2. The `discard_failed_blocks` configuration defaults to `false`, meaning errors propagate: [8](#0-7) 

3. The error conversion to `InternalError` with string formatting can also introduce non-determinism: [9](#0-8) 

The fundamental issue is that consensus requires ALL honest validators to agree on block validity, but the current implementation allows validators to independently decide to drop blocks based on local conditions (timeouts, cache misses) that vary across nodes.

### Citations

**File:** consensus/src/pipeline/buffer_manager.rs (L429-451)
```rust
    fn advance_execution_root(&mut self) -> Option<HashValue> {
        let cursor = self.execution_root;
        self.execution_root = self
            .buffer
            .find_elem_from(cursor.or_else(|| *self.buffer.head_cursor()), |item| {
                item.is_ordered()
            });
        if self.execution_root.is_some() && cursor == self.execution_root {
            // Schedule retry.
            self.execution_root
        } else {
            sample!(
                SampleRate::Frequency(2),
                info!(
                    "Advance execution root from {:?} to {:?}",
                    cursor, self.execution_root
                )
            );
            // Otherwise do nothing, because the execution wait phase is driven by the response of
            // the execution schedule phase, which is in turn fed as soon as the ordered blocks
            // come in.
            None
        }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L617-626)
```rust
        let executed_blocks = match inner {
            Ok(result) => result,
            Err(e) => {
                log_executor_error_occurred(
                    e,
                    &counters::BUFFER_MANAGER_RECEIVED_EXECUTOR_ERROR_COUNT,
                    block_id,
                );
                return;
            },
```

**File:** consensus/src/pipeline/buffer_manager.rs (L954-960)
```rust
                Some(response) = self.execution_wait_phase_rx.next() => {
                    monitor!("buffer_manager_process_execution_wait_response", {
                    self.process_execution_response(response).await;
                    self.advance_execution_root();
                    if self.signing_root.is_none() {
                        self.advance_signing_root().await;
                    }});
```

**File:** consensus/src/quorum_store/batch_requester.rs (L144-150)
```rust
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** consensus/src/quorum_store/batch_store.rs (L555-557)
```rust
                Ok(None) | Err(_) => {
                    warn!("Could not get batch from db");
                    Err(ExecutorError::CouldNotGetData)
```

**File:** consensus/src/counters.rs (L1184-1212)
```rust
pub fn log_executor_error_occurred(
    e: ExecutorError,
    counter: &Lazy<IntCounterVec>,
    block_id: HashValue,
) {
    match e {
        ExecutorError::CouldNotGetData => {
            counter.with_label_values(&["CouldNotGetData"]).inc();
            warn!(
                block_id = block_id,
                "Execution error - CouldNotGetData {}", block_id
            );
        },
        ExecutorError::BlockNotFound(block_id) => {
            counter.with_label_values(&["BlockNotFound"]).inc();
            warn!(
                block_id = block_id,
                "Execution error BlockNotFound {}", block_id
            );
        },
        e => {
            counter.with_label_values(&["UnexpectedError"]).inc();
            warn!(
                block_id = block_id,
                "Execution error {:?} for {}", e, block_id
            );
        },
    }
}
```

**File:** config/src/config/execution_config.rs (L88-88)
```rust
            discard_failed_blocks: false,
```

**File:** execution/executor-types/src/error.rs (L45-51)
```rust
impl From<anyhow::Error> for ExecutorError {
    fn from(error: anyhow::Error) -> Self {
        Self::InternalError {
            error: format!("{}", error),
        }
    }
}
```
