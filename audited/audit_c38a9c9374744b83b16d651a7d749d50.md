# Audit Report

## Title
Semantic Inversion in Transaction Filter Documentation Leads to Misconfiguration and Sensitive Data Leakage

## Summary
The `Filterable` trait documentation states filters should "allow" items that aren't explicitly prevented, creating a default-allow semantic. However, the `strip_transactions` function inverts this logic—transactions matching the filter are stripped (sensitive data removed), not allowed through. This semantic confusion can cause operators to configure filters with reversed logic, resulting in sensitive transactions leaking unredacted while intended-safe transactions get stripped.

## Finding Description

The vulnerability exists in a semantic mismatch between the trait documentation and its security-critical usage: [1](#0-0) 

This documentation establishes the expectation that `matches()` returning `true` means "allow this item through" (default-allow philosophy). This is reinforced by the trait's `filter_vec()` implementation: [2](#0-1) 

However, the security-critical `strip_transactions` function inverts this semantic: [3](#0-2) 

The configuration field that operators must set: [4](#0-3) 

**Attack Scenario:**

1. Operator needs to strip transactions from problematic module `0xBAD::exploit::drain` (too large, contains sensitive data)
2. Reads trait documentation: "allow items that aren't explicitly prevented"
3. Consults README which shows `filter_vec()` keeping matching items
4. Thinks: "I'll create a filter for transactions I want to ALLOW through unmodified"
5. Creates filter: `UserTransactionFilter` matching trusted addresses (e.g., `NOT 0xBAD`)
6. **Actual result**: All trusted transactions get stripped, `0xBAD` transactions leak through with full payload/signatures/events
7. Sensitive data that should be redacted is now exposed to all downstream consumers

## Impact Explanation

**Severity: Medium** per Aptos Bug Bounty criteria for "State inconsistencies requiring intervention" and potential "Limited funds loss or manipulation."

While this doesn't directly compromise consensus, it creates multiple security issues:

1. **Information Disclosure**: Transaction payloads, signatures, events, and state changes that should be stripped are exposed to unauthorized parties
2. **Operational Security Failure**: The stripping mechanism exists for emergency situations (per configuration comments) - its failure could expose sensitive operational data
3. **Downstream System Compromise**: Services consuming the indexer data may make security decisions based on the expectation that certain data is stripped

The impact is amplified because:
- The configuration is rarely changed (emergency use only), meaning misconfiguration may go undetected
- The filter supports complex boolean logic (AND/OR/NOT), increasing misconfiguration surface
- No runtime validation warns operators their filter logic is inverted

## Likelihood Explanation

**Likelihood: Medium-High**

This is highly likely to occur because:

1. **Documentation Conflict**: The trait clearly states one semantic ("allow"), the usage requires the opposite
2. **README Reinforcement**: The README example uses `filter_vec()` which implements the "allow" semantic
3. **Intuitive Naming**: Variable name `txns_to_strip_filter` suggests "filter FOR transactions to strip", but developers reading trait docs think it means "filter transactions, then strip"
4. **Complex Boolean Logic**: Operators must reason about AND/OR/NOT combinations - easy to invert mentally when semantic is already confused
5. **Emergency Deployment**: Per config comments, this is used in emergencies when operators are under pressure and more prone to errors

Test evidence shows developers already struggle with this - note the confused comment: [5](#0-4) 

The comment says "`is_allowed`" but the code strips - evidence of existing confusion.

## Recommendation

**Immediate Fix:**

1. **Rename the method** in the `Filterable` trait to be explicit about its semantic:
   - Change `matches()` to `should_include()` or `is_included_by_filter()`
   - Update documentation to explicitly state: "Returns true if this item should be included in the result set"

2. **Update strip_transactions** to use inverted logic with clear naming:
   ```rust
   fn strip_transactions(
       transactions: Vec<Transaction>,
       txns_to_keep_filter: &BooleanTransactionFilter, // Renamed!
   ) -> (Vec<Transaction>, usize) {
       transactions.into_iter().map(|mut txn| {
           // Strip if NOT matched by keep filter
           if !txns_to_keep_filter.matches(&txn) {
               // strip logic
           }
           txn
       }).collect()
   }
   ```

3. **Add explicit validation** in the configuration that warns about common mistakes:
   ```rust
   // In config validation
   if txns_to_strip_filter.is_or_with_multiple_branches() {
       warn!("⚠️  Complex OR filter detected. Remember: matching txns are STRIPPED, not kept!");
   }
   ```

4. **Update all documentation** to consistently use "strip" terminology and provide clear examples

**Long-term Fix:**

Create two separate filter types with explicit semantics:
- `InclusionFilter` (matches = include)  
- `ExclusionFilter` (matches = exclude)

This eliminates ambiguity at the type level.

## Proof of Concept

```rust
#[test]
fn test_semantic_confusion_vulnerability() {
    use aptos_transaction_filter::{BooleanTransactionFilter, UserTransactionFilterBuilder};
    
    // Operator INTENDS to strip txns from 0xBAD
    // But confuses the semantic and creates filter for "good" addresses
    let good_address = "0xGOOD".to_string();
    
    // Operator thinks: "I want to ALLOW good transactions through unmodified"
    let filter = BooleanTransactionFilter::from(
        UserTransactionFilterBuilder::default()
            .sender(good_address) // Matching "good" address
            .build()
            .unwrap()
    );
    
    let good_txn = create_txn_from_sender("0xGOOD");
    let bad_txn = create_txn_from_sender("0xBAD");
    
    let (results, stripped_count) = strip_transactions(
        vec![good_txn.clone(), bad_txn.clone()],
        &filter
    );
    
    // VULNERABILITY: Good transaction is stripped!
    assert_eq!(stripped_count, 1);
    assert!(results[0].payload.is_none()); // Good txn stripped
    assert!(results[1].payload.is_some()); // Bad txn NOT stripped - LEAKED!
    
    // Expected behavior (if operator understood correctly):
    // Bad txn should be stripped, good txn should pass through
}
```

**Notes:**

This vulnerability demonstrates a critical failure in defensive design: security-critical APIs must have semantics that match developer intuition and documentation. The current design creates a "semantic trap" where doing the intuitive thing produces the opposite security outcome. This is particularly dangerous in emergency scenarios where the feature is intended to be used.

### Citations

**File:** ecosystem/indexer-grpc/transaction-filter/src/traits.rs (L41-46)
```rust
    /// Whether the item is allowed by this filter
    /// This is the core method that should be implemented by any filter
    /// This is the method that should be called by any parent filter to determine if an item is allowed
    /// *If a filter doesn't explicitly prevent an item, then it should be allowed*
    /// This forces the logic of `if !child_filter.matches(item) { return false; }` for any parent filter
    fn matches(&self, item: &T) -> bool;
```

**File:** ecosystem/indexer-grpc/transaction-filter/src/traits.rs (L69-75)
```rust
    #[inline]
    fn filter_vec(&self, items: Vec<T>) -> Vec<T> {
        items
            .into_iter()
            .filter(|item| self.matches(item))
            .collect()
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/service.rs (L919-954)
```rust
/// This function strips transactions that match the given filter. Stripping means we
/// remove the payload, signature, events, and writesets. Note, the filter can be
/// composed of many conditions, see `BooleanTransactionFilter` for more.
///
/// This returns the mutated txns and the number of txns that were stripped.
fn strip_transactions(
    transactions: Vec<Transaction>,
    txns_to_strip_filter: &BooleanTransactionFilter,
) -> (Vec<Transaction>, usize) {
    let mut stripped_count = 0;

    let stripped_transactions: Vec<Transaction> = transactions
        .into_iter()
        .map(|mut txn| {
            // Note: `is_allowed` means the txn matches the filter, in which case
            // we strip it.
            if txns_to_strip_filter.matches(&txn) {
                stripped_count += 1;
                if let Some(info) = txn.info.as_mut() {
                    info.changes = vec![];
                }
                if let Some(TxnData::User(user_transaction)) = txn.txn_data.as_mut() {
                    user_transaction.events = vec![];
                    if let Some(utr) = user_transaction.request.as_mut() {
                        // Wipe the payload and signature.
                        utr.payload = None;
                        utr.signature = None;
                    }
                }
            }
            txn
        })
        .collect();

    (stripped_transactions, stripped_count)
}
```

**File:** ecosystem/indexer-grpc/indexer-grpc-data-service/src/config.rs (L73-84)
```rust
    /// Any transaction that matches this filter will be stripped. This means we remove
    /// the payload, signature, events, and writesets from it before sending it
    /// downstream. This should only be used in an emergency situation, e.g. when txns
    /// related to a certain module are too large and are causing issues for the data
    /// service. Learn more here:
    ///
    /// https://www.notion.so/aptoslabs/Runbook-c006a37259394ac2ba904d6b54d180fa?pvs=4#171c210964ec42a89574fc80154f9e85
    ///
    /// Generally you will want to start with this with an OR, and then list out
    /// separate filters that describe each type of txn we want to strip.
    #[serde(default = "IndexerGrpcDataServiceConfig::default_txns_to_strip_filter")]
    pub txns_to_strip_filter: BooleanTransactionFilter,
```
