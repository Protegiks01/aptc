# Audit Report

## Title
Memory Exhaustion via Unbounded Schnorr Proof Batch in DKG Transcript Verification

## Summary
A malicious validator can craft DKG transcripts containing an excessive number of Schnorr proofs-of-knowledge (PoKs), causing other validators to allocate large amounts of memory (~25-30 MB per transcript) during verification. The `pok_batch_verify()` function allocates vectors proportional to the number of proofs without bounds checking, enabling potential memory exhaustion attacks.

## Finding Description
The DKG (Distributed Key Generation) protocol allows validators to create and aggregate transcripts containing Schnorr PoKs. When verifying these transcripts, the system calls `pok_batch_verify()` which allocates memory proportional to the number of proofs. [1](#0-0) 

The vulnerability manifests through this attack path:

1. **Transcript Creation**: A validator creates multiple DKG transcripts locally by dealing multiple times, each containing one Signature of Knowledge (SoK) with a Schnorr PoK.

2. **Local Aggregation**: The validator aggregates these transcripts together locally. The aggregation logic unconditionally adds all SoKs from aggregated transcripts: [2](#0-1) 

3. **Transcript Distribution**: The attacker sends this aggregated transcript (containing many SoKs) to other validators during the DKG protocol.

4. **Verification Trigger**: When peer validators receive the transcript, they verify it before aggregation: [3](#0-2) 

5. **Memory Allocation**: The verification flows through:
   - `verify_transcript()` → `trx.main.verify()` [4](#0-3) 
   
   - → `batch_verify_soks()` [5](#0-4) 
   
   - → `pok_batch_verify()` which allocates vectors proportional to the number of SoKs: [6](#0-5) 

**Key Issue**: The `ensures_single_dealer` check only validates that all SoKs come from the same dealer, not that there's a limited number of SoKs: [7](#0-6) 

**Bounds Analysis**: Network message size limits cap transcripts at ~61.75 MiB: [8](#0-7) 

This allows approximately 60,000-100,000 SoKs per transcript, causing:
- `exps` vector: ~120,001 × 32 bytes ≈ 3.7 MB
- `bases` vector: ~120,001 × 192 bytes ≈ 22 MB  
- `gammas` vector: ~60,000 × 32 bytes ≈ 1.8 MB
- **Total: ~27.5 MB per verification**

## Impact Explanation
**Severity: Medium**

This vulnerability causes validator node resource exhaustion through:
- **Memory exhaustion**: ~30 MB allocated per malicious transcript
- **CPU exhaustion**: Cryptographic verification of 60k-100k proofs causes significant delays
- **Cascading failures**: Multiple concurrent malicious transcripts from different validators compound the effect

However, impact is limited because:
- Single transcript causes moderate (not catastrophic) memory usage
- Requires memory pressure or concurrent attacks to cause node crashes
- Does not directly compromise consensus safety or fund security
- Affected nodes can recover by rejecting future transcripts from the malicious validator

This aligns with **Medium Severity** per Aptos bug bounty: "Validator node slowdowns" and "State inconsistencies requiring intervention."

## Likelihood Explanation
**Likelihood: Medium-Low**

Required conditions:
- Attacker must control a validator node (privileged position)
- Attacker must remain undetected while sending oversized transcripts
- Multiple validators must process the transcript concurrently for severe impact
- Network conditions must allow ~60 MiB messages to propagate

The attack is straightforward to execute but requires validator privileges, limiting the potential attacker pool to malicious or compromised validators within the active set.

## Recommendation
Add explicit bounds checking on the number of SoKs before verification:

```rust
// In types/src/dkg/real_dkg/mod.rs, modify verify_transcript_extra():
const MAX_SOKS_PER_TRANSCRIPT: usize = 100; // Allow reasonable aggregation

fn verify_transcript_extra(
    trx: &Self::Transcript,
    verifier: &ValidatorVerifier,
    checks_voting_power: bool,
    ensures_single_dealer: Option<AccountAddress>,
) -> anyhow::Result<()> {
    let all_validator_addrs = verifier.get_ordered_account_addresses();
    let main_trx_dealers = trx.main.get_dealers();
    
    // NEW CHECK: Limit number of SoKs
    ensure!(
        main_trx_dealers.len() <= MAX_SOKS_PER_TRANSCRIPT,
        "transcript contains too many SoKs: {} > {}",
        main_trx_dealers.len(),
        MAX_SOKS_PER_TRANSCRIPT
    );
    
    // ... existing checks
}
```

Alternatively, implement streaming verification or pagination for large batches to bound memory usage per operation.

## Proof of Concept
```rust
// Rust test demonstrating the vulnerability
#[test]
fn test_memory_exhaustion_via_sok_batch() {
    use aptos_types::dkg::{DKGTrait, RealDKG};
    use rand::thread_rng;
    
    let mut rng = thread_rng();
    let pub_params = setup_test_params();
    let sk = PrivateKey::generate(&mut rng);
    let pk = sk.public_key();
    
    // Attacker creates many transcripts and aggregates them
    let mut aggregated = RealDKG::generate_transcript(
        &mut rng, &pub_params, &InputSecret::generate(&mut rng), 
        0, &sk, &pk
    );
    
    // Aggregate 50,000 times (within network size limits)
    for _ in 0..50_000 {
        let new_trx = RealDKG::generate_transcript(
            &mut rng, &pub_params, &InputSecret::generate(&mut rng),
            0, &sk, &pk
        );
        RealDKG::aggregate_transcripts(&pub_params, &mut aggregated, new_trx);
    }
    
    // This transcript now has 50,001 SoKs from the same dealer
    assert_eq!(aggregated.main.get_dealers().len(), 50_001);
    
    // Verification triggers large memory allocation in pok_batch_verify()
    // Memory usage: ~25 MB
    let start_mem = get_current_memory_usage();
    RealDKG::verify_transcript(&pub_params, &aggregated).unwrap();
    let end_mem = get_current_memory_usage();
    
    println!("Memory allocated during verification: {} MB", 
             (end_mem - start_mem) / (1024 * 1024));
    assert!((end_mem - start_mem) > 20 * 1024 * 1024); // > 20 MB
}
```

## Notes
This vulnerability breaks the **Resource Limits** invariant: "All operations must respect gas, storage, and computational limits." While gas limits don't apply to DKG verification, computational and memory resources should still be bounded to prevent DoS attacks against validator infrastructure.

The attack requires validator privileges, placing it at the boundary of the trust model. However, Byzantine fault tolerance typically assumes some validators may act maliciously within protocol rules, making resource exhaustion via protocol-compliant but oversized messages a valid concern.

### Citations

**File:** crates/aptos-dkg/src/pvss/schnorr.rs (L69-109)
```rust
pub fn pok_batch_verify<'a, Gr>(
    poks: &Vec<(Gr, PoK<Gr>)>,
    g: &Gr,
    gamma: &Scalar,
) -> anyhow::Result<()>
where
    Gr: Serialize + Group + Mul<&'a Scalar> + HasMultiExp,
{
    let n = poks.len();
    let mut exps = Vec::with_capacity(2 * n + 1);
    let mut bases = Vec::with_capacity(2 * n + 1);

    // Compute \gamma_i = \gamma^i, for all i \in [0, n]
    let mut gammas = Vec::with_capacity(n);
    gammas.push(Scalar::ONE);
    for _ in 0..(n - 1) {
        gammas.push(gammas.last().unwrap().mul(gamma));
    }

    let mut last_exp = Scalar::ZERO;
    for i in 0..n {
        let (pk, (R, s)) = poks[i];

        bases.push(R);
        exps.push(gammas[i]);

        bases.push(pk);
        exps.push(schnorr_hash(Challenge::<Gr> { R, pk, g: *g }) * gammas[i]);

        last_exp += s * gammas[i];
    }

    bases.push(*g);
    exps.push(last_exp.neg());

    if Gr::multi_exp_iter(bases.iter(), exps.iter()) != Gr::identity() {
        bail!("Schnorr PoK batch verification failed");
    }

    Ok(())
}
```

**File:** crates/aptos-dkg/src/pvss/das/unweighted_protocol.rs (L256-263)
```rust
        batch_verify_soks::<G2Projective, A>(
            self.soks.as_slice(),
            &g_2,
            &self.V[sc.n],
            spks,
            auxs,
            &extra[0],
        )?;
```

**File:** crates/aptos-dkg/src/pvss/das/unweighted_protocol.rs (L336-338)
```rust
        for sok in &other.soks {
            self.soks.push(sok.clone());
        }
```

**File:** dkg/src/transcript_aggregation/mod.rs (L96-101)
```rust
        S::verify_transcript_extra(&transcript, &self.epoch_state.verifier, false, Some(sender))
            .context("extra verification failed")?;

        S::verify_transcript(&self.dkg_pub_params, &transcript).map_err(|e| {
            anyhow!("[DKG] adding peer transcript failed with trx verification failure: {e}")
        })?;
```

**File:** types/src/dkg/real_dkg/mod.rs (L312-316)
```rust
        if ensures_single_dealer.is_some() {
            let expected_dealer_set: HashSet<AccountAddress> =
                ensures_single_dealer.into_iter().collect();
            ensure!(expected_dealer_set == dealer_set);
        }
```

**File:** types/src/dkg/real_dkg/mod.rs (L368-374)
```rust
        trx.main.verify(
            &params.pvss_config.wconfig,
            &params.pvss_config.pp,
            &spks,
            &all_eks,
            &aux,
        )?;
```

**File:** config/src/config/network_config.rs (L47-50)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```
