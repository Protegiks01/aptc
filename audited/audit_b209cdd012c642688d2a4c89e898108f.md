# Audit Report

## Title
Insufficient Protection Against InMemoryStorage in Production Causing Validator Key Loss and Network Disruption

## Summary
Validators using testnet, devnet, or premainnet, or mainnet validators with missing genesis files, can accidentally deploy with `InMemoryStorage` for consensus key storage. Upon node restart, all consensus keys and safety data are permanently lost, causing immediate validator downtime and requiring on-chain key rotation to recover. Multiple simultaneous failures could threaten network liveness.

## Finding Description

The Aptos codebase implements a config sanitizer to prevent validators from using `InMemoryStorage` in production environments. However, this protection has critical gaps:

**Protection Implementation:**
The sanitizer check exists in SafetyRulesConfig [1](#0-0)  and only validates:
- When `chain_id.is_mainnet()` returns true
- When `node_type.is_validator()` returns true  
- When `chain_id` is `Some` (not `None`)

**Bypass Vectors:**

1. **Testnet/Devnet Unprotected**: The check uses `chain_id.is_mainnet()` [2](#0-1) , meaning testnet (chain_id=2), devnet (chain_id=3), and premainnet (chain_id=5) validators have NO protection against InMemoryStorage.

2. **Missing Genesis Detection**: Chain ID extraction from genesis can fail [3](#0-2) . When it fails, the code continues with `chain_id = None`, completely bypassing the sanitizer check.

3. **Dangerous Default**: The default SafetyRulesConfig uses InMemoryStorage [4](#0-3) , making accidental misconfigurations likely.

**InMemoryStorage Implementation:**
InMemoryStorage is a simple HashMap with no persistence [5](#0-4) . Documentation explicitly warns it "should not be used in production."

**Data Loss on Restart:**
When a validator restarts with InMemoryStorage, they lose:

1. **Consensus Private Key** - Stored under CONSENSUS_KEY [6](#0-5) 

2. **SafetyData** - Including epoch, last_voted_round, highest_timeout_round [7](#0-6) 

3. **Waypoint** - Required for epoch validation

**Recovery Process:**
When the validator tries to initialize after restart, `guarded_initialize` attempts to load the consensus key [8](#0-7) . This fails with `Error::ValidatorKeyNotFound` because InMemoryStorage has lost the key.

The validator operator must:
1. Generate new consensus key pair
2. Submit `rotate_consensus_key` transaction on-chain [9](#0-8) 
3. Wait for next epoch boundary for rotation to take effect
4. Restart validator with new key

During this period (potentially hours), the validator cannot participate in consensus.

## Impact Explanation

**High Severity** - Validator node slowdowns and significant protocol violations per Aptos bug bounty criteria.

**Immediate Impact:**
- Validator immediately offline upon restart
- Cannot sign votes or participate in consensus
- Potential reward loss and performance penalties
- Recovery requires on-chain transaction and epoch boundary crossing (hours of downtime)

**Systemic Risk:**
- **Testnet/Devnet Production Use**: Organizations using testnet/devnet for staging, load testing, or pre-production validation are completely unprotected. A coordinated node restart (e.g., during cluster maintenance or Kubernetes pod recycling) could cause multiple validators to fail simultaneously.

- **Network Liveness Threat**: If >1/3 of validators restart with InMemoryStorage simultaneously, the network cannot form quorums and consensus halts entirely. This is realistic during:
  - Coordinated software upgrades
  - Infrastructure maintenance windows  
  - Cloud provider outages causing mass restarts
  - Container orchestration platform rolling all pods

- **Mainnet Genesis Failure**: If genesis file is corrupted, deleted, or inaccessible (storage failures, misconfigurations), mainnet validators bypass the sanitizer check entirely.

## Likelihood Explanation

**Likelihood: Medium-High**

**Factors Increasing Likelihood:**

1. **Unsafe Default**: SafetyRulesConfig defaults to InMemoryStorage, not a safe production backend [10](#0-9) 

2. **Testnet/Devnet Common in Production Pipelines**: Many organizations run testnet/devnet validators for:
   - Pre-production testing
   - Load testing and benchmarking
   - Staging environments
   - Development cluster validation
   
   These environments often use production-like configurations but receive less scrutiny.

3. **Configuration Copying**: Developers might copy example configs and forget to change the backend from default to a persistent storage type.

4. **Genesis File Fragility**: The genesis file requirement creates a single point of failure. File corruption, storage issues, or path misconfigurations can cause chain_id detection to fail silently [11](#0-10) .

5. **Silent Failure Mode**: When chain_id extraction fails, it only prints to stdout and continues [12](#0-11) . This doesn't trigger alerts or prevent startup.

## Recommendation

**Immediate Fixes:**

1. **Extend Sanitizer to All Production Chains:**
```rust
// In SafetyRulesConfig::sanitize()
if let Some(chain_id) = chain_id {
    // Protect ALL production chains, not just mainnet
    if (chain_id.is_mainnet() || chain_id.is_testnet() || is_production_chain(chain_id))
        && node_type.is_validator()
        && safety_rules_config.backend.is_in_memory()
    {
        return Err(Error::ConfigSanitizerFailed(
            sanitizer_name,
            format!(
                "InMemoryStorage backend is not allowed for {} validators! Use OnDiskStorage or Vault.",
                chain_id
            ),
        ));
    }
}
```

2. **Fail Fast on Missing Chain ID:**
```rust
// In extract_node_type_and_chain_id()
match get_chain_id(node_config) {
    Ok(chain_id) => (node_type, Some(chain_id)),
    Err(error) => {
        if node_type.is_validator() {
            // For validators, chain_id detection failure is fatal
            panic!(
                "Validator nodes MUST have valid genesis file for chain ID detection. Error: {:?}",
                error
            );
        }
        eprintln!("Warning: Failed to extract chain ID: {:?}", error);
        (node_type, None)
    }
}
```

3. **Change Unsafe Default:**
```rust
impl Default for SafetyRulesConfig {
    fn default() -> Self {
        Self {
            backend: SecureBackend::OnDiskStorage(OnDiskStorageConfig::default()),
            // ... rest unchanged
        }
    }
}
```

4. **Add Startup Warning:**
```rust
// In NodeConfig::sanitize()
if node_config.consensus.safety_rules.backend.is_in_memory() {
    eprintln!(
        "⚠️  WARNING: InMemoryStorage detected! All consensus keys will be LOST on restart. \
         This should ONLY be used for testing."
    );
}
```

## Proof of Concept

**Scenario: Testnet Validator Loses Keys on Restart**

```yaml
# testnet-validator.yaml (vulnerable configuration)
base:
  role: "validator"
  data_dir: "/opt/aptos/data"

consensus:
  safety_rules:
    backend:
      type: "in_memory_storage"  # VULNERABLE: No persistence
    service:
      type: "local"

execution:
  genesis_file_location: "/opt/aptos/genesis/genesis.blob"
```

**Attack/Failure Steps:**

1. Validator operator deploys testnet validator with above config
2. Validator joins network, participates in consensus normally
3. Consensus keys and SafetyData accumulate in memory:
   - CONSENSUS_KEY: Private key for signing votes
   - SafetyData: epoch=50, last_voted_round=10000, etc.
   
4. Node restarts due to:
   - Software upgrade
   - Infrastructure maintenance  
   - Pod eviction in Kubernetes
   - Manual restart
   
5. Upon restart:
   - InMemoryStorage HashMap is empty
   - All data permanently lost
   
6. Validator tries to initialize for current epoch (50):
   - Calls `guarded_initialize()` with epoch 50 proof
   - Attempts `consensus_sk_by_pk(expected_key)` at line 326
   - Fails with `Error::ValidatorKeyNotFound`
   - Validator cannot participate in consensus

7. Recovery requires:
   - Generate new key pair
   - Submit `stake::rotate_consensus_key()` transaction
   - Wait for epoch boundary (potentially hours)
   - Restart with new key

**Validation:**

The config sanitizer will NOT catch this because:
- Chain ID = 2 (testnet)
- `chain_id.is_mainnet()` returns false
- Check at lines 87-89 is skipped
- Validator starts successfully with InMemoryStorage

**Impact if Multiple Validators Affected:**
- 5 validators restart → 5 validators offline
- If total validator set is 10, only 5 remain active
- With >1/3 offline, network liveness threatened
- Consensus may stall until validators recover (hours/days)

---

**Notes:**

This vulnerability represents a significant operational risk for testnet/devnet validators and a potential catastrophic failure mode for mainnet if genesis detection fails. The fix is straightforward: extend the sanitizer to cover all production chains and make chain ID detection mandatory for validators.

### Citations

**File:** config/src/config/safety_rules_config.rs (L36-49)
```rust
impl Default for SafetyRulesConfig {
    fn default() -> Self {
        Self {
            backend: SecureBackend::InMemoryStorage,
            logger: LoggerConfig::default(),
            service: SafetyRulesService::Local,
            test: None,
            // Default value of 30 seconds for a timeout
            network_timeout_ms: 30_000,
            enable_cached_safety_data: true,
            initial_safety_rules_config: InitialSafetyRulesConfig::None,
        }
    }
}
```

**File:** config/src/config/safety_rules_config.rs (L85-96)
```rust
        if let Some(chain_id) = chain_id {
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }
```

**File:** types/src/chain_id.rs (L84-87)
```rust
    /// Returns true iff the chain ID matches mainnet
    pub fn is_mainnet(&self) -> bool {
        self.matches_named_chain(NamedChain::MAINNET)
    }
```

**File:** config/src/config/node_config_loader.rs (L117-123)
```rust
    match get_chain_id(node_config) {
        Ok(chain_id) => (node_type, Some(chain_id)),
        Err(error) => {
            println!("Failed to extract the chain ID from the genesis transaction: {:?}! Continuing with None.", error);
            (node_type, None)
        },
    }
```

**File:** secure/storage/src/in_memory.rs (L9-34)
```rust
/// InMemoryStorage represents a key value store that is purely in memory and intended for single
/// threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission checks and simply
/// is a proof of concept to unblock building of applications without more complex data stores.
/// Internally, it retains all data, which means that it must make copies of all key material which
/// violates the code base. It violates it because the anticipation is that data stores would
/// securely handle key material. This should not be used in production.
#[derive(Default)]
pub struct InMemoryStorage {
    data: HashMap<String, Vec<u8>>,
    time_service: TimeService,
}

impl InMemoryStorage {
    pub fn new() -> Self {
        Self::new_with_time_service(TimeService::real())
    }
}

impl InMemoryStorage {
    pub fn new_with_time_service(time_service: TimeService) -> Self {
        Self {
            data: HashMap::new(),
            time_service,
        }
    }
}
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L98-104)
```rust
    pub fn default_consensus_sk(
        &self,
    ) -> Result<bls12381::PrivateKey, aptos_secure_storage::Error> {
        self.internal_store
            .get::<bls12381::PrivateKey>(CONSENSUS_KEY)
            .map(|v| v.value)
    }
```

**File:** consensus/consensus-types/src/safety_data.rs (L8-21)
```rust
/// Data structure for safety rules to ensure consensus safety.
#[derive(Debug, Deserialize, Eq, PartialEq, Serialize, Clone, Default)]
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** consensus/safety-rules/src/safety_rules.rs (L326-337)
```rust
                    match self.persistent_storage.consensus_sk_by_pk(expected_key) {
                        Ok(consensus_key) => {
                            self.validator_signer =
                                Some(ValidatorSigner::new(author, Arc::new(consensus_key)));
                            Ok(())
                        },
                        Err(Error::SecureStorageMissingDataError(error)) => {
                            Err(Error::ValidatorKeyNotFound(error))
                        },
                        Err(error) => Err(error),
                    }
                }
```

**File:** aptos-move/framework/aptos-framework/sources/stake.move (L909-952)
```text
    /// Rotate the consensus key of the validator, it'll take effect in next epoch.
    public entry fun rotate_consensus_key(
        operator: &signer,
        pool_address: address,
        new_consensus_pubkey: vector<u8>,
        proof_of_possession: vector<u8>,
    ) acquires StakePool, ValidatorConfig {
        check_stake_permission(operator);
        assert_reconfig_not_in_progress();
        assert_stake_pool_exists(pool_address);

        let stake_pool = borrow_global_mut<StakePool>(pool_address);
        assert!(signer::address_of(operator) == stake_pool.operator_address, error::unauthenticated(ENOT_OPERATOR));

        assert!(exists<ValidatorConfig>(pool_address), error::not_found(EVALIDATOR_CONFIG));
        let validator_info = borrow_global_mut<ValidatorConfig>(pool_address);
        let old_consensus_pubkey = validator_info.consensus_pubkey;
        // Checks the public key has a valid proof-of-possession to prevent rogue-key attacks.
        let pubkey_from_pop = &bls12381::public_key_from_bytes_with_pop(
            new_consensus_pubkey,
            &proof_of_possession_from_bytes(proof_of_possession)
        );
        assert!(option::is_some(pubkey_from_pop), error::invalid_argument(EINVALID_PUBLIC_KEY));
        validator_info.consensus_pubkey = new_consensus_pubkey;

        if (std::features::module_event_migration_enabled()) {
            event::emit(
                RotateConsensusKey {
                    pool_address,
                    old_consensus_pubkey,
                    new_consensus_pubkey,
                },
            );
        } else {
            event::emit_event(
                &mut stake_pool.rotate_consensus_key_events,
                RotateConsensusKeyEvent {
                    pool_address,
                    old_consensus_pubkey,
                    new_consensus_pubkey,
                },
            );
        };
    }
```
