# Audit Report

## Title
Malicious DKG Dealer Can Bypass Share Encryption via Identity Element Injection

## Summary
The Aptos DKG chunked ElGamal implementation fails to validate that randomness commitments (`Rs`) are non-identity elements, allowing a Byzantine dealer to create transcripts with zero randomness that expose secret shares publicly. This breaks the confidentiality guarantee of PVSS (Publicly Verifiable Secret Sharing).

## Finding Description

The Aptos DKG uses chunked ElGamal encryption to protect secret shares during distribution. The encryption scheme is defined as: [1](#0-0) 

Where ciphertext chunks are computed as `C_i,j = G_1 * z_i,j + ek_i * r_j` and randomness commitments as `R_j = H_1 * r_j`.

**The Core Vulnerability:**

The MSM terms computation shows that Rs are generated by multiplying randomness scalars with the public parameter H: [2](#0-1) 

If a malicious dealer sets all `r_j = 0`, then `R_j = 0 * H = identity` (the group identity element). This is mathematically valid but breaks the encryption scheme's security.

The decryption process computes `C_ij - dk * R_j` to recover plaintexts: [3](#0-2) 

When `R_j = identity`, the decryption becomes `C_ij - dk * identity = C_ij`, exposing the plaintext chunks `z_ij * G` publicly. Anyone with a Baby-Step Giant-Step (BSGS) table can then compute the discrete logarithm to recover `z_ij`.

**Missing Validation:**

The transcript verification performs multiple checks: [4](#0-3) 

This verification includes:
- Sigma protocol verification (lines 172-190)
- Range proof verification (lines 192-200)  
- SCRAPE low-degree test (lines 206-216)
- Multi-pairing correctness check (lines 240-283)

**However, none of these checks validate that `Rs ≠ identity`.** The sigma protocol accepts `identity = 0 * H` as a valid homomorphism output, and the range proof only validates the secret share chunks, not the randomness values.

**Production Impact:**

The DKG is actively used for on-chain randomness generation, with validators decrypting shares during epoch transitions: [5](#0-4) 

This vulnerability allows a Byzantine dealer to violate the fundamental PVSS confidentiality property: secret shares should only be decryptable by intended recipients, but with identity Rs, anyone can recover them.

## Impact Explanation

**High Severity** - This constitutes a significant protocol violation that breaks cryptographic correctness guarantees.

While the DKG has threshold resilience (a single dealer's compromised shares don't break the final key), this vulnerability:

1. **Breaks PVSS Confidentiality**: The core security property that shares are only decryptable by intended recipients is violated
2. **Enables Coordinated Attacks**: If multiple colluding Byzantine dealers (within the 1/3 tolerance) use this technique, they could leak enough shares to threaten the reconstruction threshold
3. **Affects Production Security**: The DKG is used for validator randomness generation, impacting consensus integrity
4. **No Detection Mechanism**: The verification code deterministically accepts these malformed transcripts

This fits the **High Severity** category as a significant protocol violation affecting production cryptographic operations, though it requires multiple colluding validators to fully compromise the DKG output.

## Likelihood Explanation

**Medium to High Likelihood** - The attack is technically straightforward for a Byzantine validator:

1. **Accessible to Threat Actors**: Any validator can act as a DKG dealer
2. **Simple Exploit**: Setting `r_j = 0` is trivial once the scheme is understood
3. **Deterministic Acceptance**: The verification code will always accept such transcripts
4. **Byzantine Model**: DKG protocols explicitly model Byzantine validators as adversaries, making this threat realistic

The main constraint is that meaningful impact requires coordination among multiple Byzantine validators, but the threshold tolerance (< 1/3 stake) makes this feasible for sophisticated attackers.

## Recommendation

Add explicit validation in the transcript verification to reject identity elements in Rs:

```rust
// In weighted_transcript.rs verify() function, after line 152:
for R_vec in &self.subtrs.Rs {
    for R in R_vec {
        if R.is_identity() {
            bail!("Invalid transcript: randomness commitment R cannot be identity element");
        }
    }
}
```

This check should be added early in the verification flow, before the expensive cryptographic operations, to fail fast on malformed transcripts.

Additionally, consider adding similar validation in the DAS protocol verification: [6](#0-5) 

## Proof of Concept

```rust
#[test]
fn test_identity_randomness_bypass() {
    use aptos_dkg::pvss::chunky::{chunked_elgamal, weighted_transcript};
    use ark_bls12_381::Bls12_381;
    
    // Setup: Create a DKG configuration
    let sc = /* secret sharing config */;
    let pp = /* public parameters */;
    let eks = /* encryption keys */;
    
    // Malicious dealer creates transcript with all r_j = 0
    let zero_randomness = vec![vec![Scalar::ZERO; num_chunks]; max_weight];
    
    // Generate malicious transcript with zero randomness
    // This will create Rs = [identity, identity, ...]
    let malicious_transcript = create_transcript_with_randomness(
        &sc, &pp, &eks, &secret, zero_randomness
    );
    
    // Verify the transcript - THIS SHOULD FAIL BUT DOESN'T
    assert!(malicious_transcript.verify(&sc, &pp, &spks, &eks, &sid).is_ok());
    
    // Demonstrate that shares are now publicly decryptable
    // Anyone can compute C_ij - 0 = z_ij * G and recover z_ij via BSGS
    let recovered_shares = publicly_recover_shares(&malicious_transcript);
    assert_eq!(recovered_shares, original_shares);
}
```

The PoC demonstrates that:
1. A transcript with zero randomness passes verification
2. The resulting shares are publicly decryptable
3. The confidentiality property of PVSS is violated

## Notes

This vulnerability represents a **protocol-level correctness issue** where the implementation fails to enforce a critical security invariant. While the DKG's threshold properties provide some resilience against single dealer attacks, the ability to bypass share encryption fundamentally violates the PVSS design and could enable sophisticated attacks through dealer collusion.

The fix requires minimal code changes but is essential for maintaining the cryptographic guarantees of the DKG protocol.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L27-42)
```rust
/// Formally, given:
/// - `G_1, H_1` ∈ G₁ (group generators)
/// - `ek_i` ∈ G₁ (encryption keys)
/// - `z_i,j` ∈ Scalar<E> (from plaintext scalars `z_i`, each chunked into a vector z_i,j)
/// - `r_j` ∈ Scalar<E> (randomness for `j` in a vector of chunks z_i,j)
///
/// The homomorphism maps input `[z_i,j]` and randomness `[r_j]` to
/// the following codomain elements:
///
/// ```text
/// C_i,j = G_1 * z_i,j + ek_i * r_j
/// R_j  = H_1 * r_j
/// ```
///
/// The `C_i,j` represent "chunked" homomorphic encryptions of the plaintexts,
/// and `R_j` carry the corresponding randomness contributions.
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L241-254)
```rust
        // R_j = r_j * H_1
        let Rs = input
            .plaintext_randomness
            .iter()
            .map(|inner_vec| {
                inner_vec
                    .iter()
                    .map(|&r_j| MsmInput {
                        bases: vec![self.pp.H],
                        scalars: vec![r_j.0],
                    })
                    .collect()
            })
            .collect();
```

**File:** crates/aptos-dkg/src/pvss/chunky/chunked_elgamal.rs (L317-350)
```rust
pub fn decrypt_chunked_scalars<C: CurveGroup>(
    Cs_rows: &[Vec<C>],
    Rs_rows: &[Vec<C>],
    dk: &C::ScalarField,
    pp: &PublicParameters<C>,
    table: &HashMap<Vec<u8>, u32>,
    radix_exponent: u8,
) -> Vec<C::ScalarField> {
    let mut decrypted_scalars = Vec::with_capacity(Cs_rows.len());

    for (row, Rs_row) in Cs_rows.iter().zip(Rs_rows.iter()) {
        // Compute C - d_k * R for each chunk
        let exp_chunks: Vec<C> = row
            .iter()
            .zip(Rs_row.iter())
            .map(|(C_ij, &R_j)| C_ij.sub(R_j * *dk))
            .collect();

        // Recover plaintext chunks
        let chunk_values: Vec<_> =
            bsgs::dlog_vec(pp.G.into_group(), &exp_chunks, &table, 1 << radix_exponent)
                .expect("dlog_vec failed")
                .into_iter()
                .map(|x| C::ScalarField::from(x))
                .collect();

        // Convert chunks back to scalar
        let recovered = chunks::le_chunks_to_scalar(radix_exponent, &chunk_values);

        decrypted_scalars.push(recovered);
    }

    decrypted_scalars
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L125-286)
```rust
    fn verify<A: Serialize + Clone>(
        &self,
        sc: &Self::SecretSharingConfig,
        pp: &Self::PublicParameters,
        spks: &[Self::SigningPubKey],
        eks: &[Self::EncryptPubKey],
        sid: &A,
    ) -> anyhow::Result<()> {
        if eks.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} encryption keys, but got {}",
                sc.get_total_num_players(),
                eks.len()
            );
        }
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }

        // Initialize the **identical** PVSS SoK context
        let sok_cntxt = (
            &spks[self.dealer.id],
            sid.clone(),
            self.dealer.id,
            DST.to_vec(),
        ); // As above, this is a bit hacky... though we have access to `self` now

        {
            // Verify the PoK
            let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
            let lagr_g1: &[E::G1Affine] = match &pp.pk_range_proof.ck_S.msm_basis {
                SrsBasis::Lagrange { lagr: lagr_g1 } => lagr_g1,
                SrsBasis::PowersOfTau { .. } => {
                    bail!("Expected a Lagrange basis, received powers of tau basis instead")
                },
            };
            let hom = hkzg_chunked_elgamal::WeightedHomomorphism::<E>::new(
                lagr_g1,
                pp.pk_range_proof.ck_S.xi_1,
                &pp.pp_elgamal,
                &eks_inner,
            );
            if let Err(err) = hom.verify(
                &TupleCodomainShape(
                    self.sharing_proof.range_proof_commitment.clone(),
                    chunked_elgamal::WeightedCodomainShape {
                        chunks: self.subtrs.Cs.clone(),
                        randomness: self.subtrs.Rs.clone(),
                    },
                ),
                &self.sharing_proof.SoK,
                &sok_cntxt,
            ) {
                bail!("PoK verification failed: {:?}", err);
            }

            // Verify the range proof
            if let Err(err) = self.sharing_proof.range_proof.verify(
                &pp.pk_range_proof.vk,
                sc.get_total_weight() * num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize,
                pp.ell as usize,
                &self.sharing_proof.range_proof_commitment,
            ) {
                bail!("Range proof batch verification failed: {:?}", err);
            }
        }

        let mut rng = rand::thread_rng(); // TODO: make `rng` a parameter of fn verify()?

        // Do the SCRAPE LDT
        let ldt = LowDegreeTest::random(
            &mut rng,
            sc.get_threshold_weight(),
            sc.get_total_weight() + 1,
            true,
            &sc.get_threshold_config().domain,
        ); // includes_zero is true here means it includes a commitment to f(0), which is in V[n]
        let mut Vs_flat: Vec<_> = self.subtrs.Vs.iter().flatten().cloned().collect();
        Vs_flat.push(self.subtrs.V0);
        // could add an assert_eq here with sc.get_total_weight()
        ldt.low_degree_test_group(&Vs_flat)?;

        // let eks_inner: Vec<_> = eks.iter().map(|ek| ek.ek).collect();
        // let hom = hkzg_chunked_elgamal::WeightedHomomorphism::new(
        //     &pp.pk_range_proof.ck_S.lagr_g1,
        //     pp.pk_range_proof.ck_S.xi_1,
        //     &pp.pp_elgamal,
        //     &eks_inner,
        // );
        // let (sigma_bases, sigma_scalars, beta_powers) = hom.verify_msm_terms(
        //         &TupleCodomainShape(
        //             self.sharing_proof.range_proof_commitment.clone(),
        //             chunked_elgamal::WeightedCodomainShape {
        //                 chunks: self.subtrs.Cs.clone(),
        //                 randomness: self.subtrs.Rs.clone(),
        //             },
        //         ),
        //         &self.sharing_proof.SoK,
        //         &sok_cntxt,
        //     );
        // let ldt_msm_terms = ldt.ldt_msm_input(&Vs_flat)?;
        // use aptos_crypto::arkworks::msm::verify_msm_terms_with_start;
        // verify_msm_terms_with_start(ldt_msm_terms, sigma_bases, sigma_scalars, beta_powers);

        // Now compute the final MSM // TODO: merge this multi_exp with the PoK verification, as in YOLO YOSO? // TODO2: and use the iterate stuff you developed? it's being forgotten here
        let mut base_vec = Vec::new();
        let mut exp_vec = Vec::new();

        let beta = sample_field_element(&mut rng);
        let powers_of_beta = utils::powers(beta, sc.get_total_weight() + 1);

        let Cs_flat: Vec<_> = self.subtrs.Cs.iter().flatten().cloned().collect();
        assert_eq!(
            Cs_flat.len(),
            sc.get_total_weight(),
            "Number of ciphertexts does not equal number of weights"
        ); // TODO what if zero weight?
           // could add an assert_eq here with sc.get_total_weight()

        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
        }

        let weighted_Cs = E::G1::msm(&E::G1::normalize_batch(&base_vec), &exp_vec)
            .expect("Failed to compute MSM of Cs in chunky");

        let weighted_Vs = E::G2::msm(
            &E::G2::normalize_batch(&Vs_flat[..sc.get_total_weight()]), // Don't use the last entry of `Vs_flat`
            &powers_of_beta[..sc.get_total_weight()],
        )
        .expect("Failed to compute MSM of Vs in chunky");

        let res = E::multi_pairing(
            [
                weighted_Cs.into_affine(),
                *pp.get_encryption_public_params().message_base(),
            ],
            [pp.get_commitment_base(), (-weighted_Vs).into_affine()],
        ); // Making things affine here rather than converting the two bases to group elements, since that's probably what they would be converted to anyway: https://github.com/arkworks-rs/algebra/blob/c1f4f5665504154a9de2345f464b0b3da72c28ec/ec/src/models/bls12/g1.rs#L14

        if PairingOutput::<E>::ZERO != res {
            return Err(anyhow::anyhow!("Expected zero during multi-pairing check"));
        }

        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L1066-1072)
```rust
        let (sk, pk) = DefaultDKG::decrypt_secret_share_from_transcript(
            &dkg_pub_params,
            &transcript,
            my_index as u64,
            &dkg_decrypt_key,
        )
        .map_err(NoRandomnessReason::SecretShareDecryptionFailed)?;
```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L280-309)
```rust
    fn verify<A: Serialize + Clone>(
        &self,
        sc: &<Self as traits::Transcript>::SecretSharingConfig,
        pp: &Self::PublicParameters,
        spks: &[Self::SigningPubKey],
        eks: &[Self::EncryptPubKey],
        auxs: &[A],
    ) -> anyhow::Result<()> {
        self.check_sizes(sc)?;
        let n = sc.get_total_num_players();
        if eks.len() != n {
            bail!("Expected {} encryption keys, but got {}", n, eks.len());
        }
        let W = sc.get_total_weight();

        // Deriving challenges by flipping coins: less complex to implement & less likely to get wrong. Creates bad RNG risks but we deem that acceptable.
        let mut rng = rand::thread_rng();
        let extra = random_scalars(2 + W * 3, &mut rng);

        let sok_vrfy_challenge = &extra[W * 3 + 1];
        let g_2 = pp.get_commitment_base();
        let g_1 = pp.get_encryption_public_params().pubkey_base();
        batch_verify_soks::<G1Projective, A>(
            self.soks.as_slice(),
            g_1,
            &self.V[W],
            spks,
            auxs,
            sok_vrfy_challenge,
        )?;
```
