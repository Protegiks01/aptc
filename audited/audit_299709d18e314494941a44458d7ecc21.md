# Audit Report

## Title
Faucet Bypasser OR-Logic Enables Complete Rate Limit Bypass and Fund Drainage via Credential Compromise

## Summary
The Aptos faucet's bypasser system uses OR-logic where ANY bypasser returning true causes ALL rate limiting checkers and storage writes to be skipped. If an attacker obtains a single bypass token (e.g., from CI logs, GitHub Actions, or misconfiguration), they can completely bypass rate limiting and drain the faucet with unlimited requests at elevated funding amounts.

## Finding Description
The faucet implements a bypasser mechanism in `preprocess_request()` that short-circuits ALL security checks if any single bypasser approves a request. [1](#0-0) 

When a bypasser returns true, the system:
1. **Skips ALL checker validations** - Rate limiters never execute their `check()` method [2](#0-1) 
2. **Skips ALL storage writes** - The `complete()` method that updates rate limit counters is never called [3](#0-2) 
3. **Allows elevated funding amounts** - Can request up to `maximum_amount_with_bypass` instead of the normal limit [4](#0-3) 

The `AuthTokenBypasser` validates tokens by simple string comparison against an allowlist, without cryptographic verification or expiration checks. [5](#0-4) 

**Attack Scenario:**
An attacker obtains a bypass token through:
- Leaked CI/CD logs or configuration files
- Exposed GitHub Actions secrets
- Misconfigured access controls
- Social engineering

They then send unlimited requests with `Authorization: Bearer <leaked_token>` (without `X_IS_JWT_HEADER` header), completely bypassing rate limiting.

## Impact Explanation
This qualifies as **Critical Severity** under "Loss of Funds":
- **Complete faucet drainage** - Attacker can make unlimited requests with no rate limiting
- **Elevated per-request amounts** - Can request `maximum_amount_with_bypass` which is explicitly higher than normal limits (test shows 1000 vs 100 OCTA) [6](#0-5) 
- **No revocation mechanism** - Leaked tokens remain valid until service restart
- **Service denial** - Legitimate users cannot access faucet after drainage
- **Financial loss** - All faucet funds can be stolen

The rate limiting storage systems (Redis or in-memory) are completely bypassed, so no usage tracking occurs. [7](#0-6) 

## Likelihood Explanation  
**HIGH** - Bypass tokens have multiple exposure vectors:
- CI/CD systems often log or expose authentication tokens
- GitHub Actions and similar platforms have history of secret leakage
- Configuration files may be accidentally committed to repositories
- Developers may share tokens for debugging without proper rotation
- No cryptographic verification makes tokens simple strings that can't be validated for authenticity

The vulnerability requires only:
1. One leaked bypass token (operational failure, not rare)
2. Basic HTTP request capability (trivial)
3. No special privileges or blockchain knowledge

## Recommendation

**Immediate Mitigations:**
1. Implement token expiration and rotation mechanisms
2. Add cryptographic signature verification for bypass tokens (e.g., JWT with RS256)
3. Implement emergency token revocation via hot-reload configuration
4. Add anomaly detection for bypass token usage patterns
5. Enforce stricter `maximum_amount_with_bypass` limits

**Long-term Fixes:**
Restructure bypasser logic to still perform rate limiting checks even when bypassing other validations:

```rust
// In preprocess_request()
let bypass = self.check_bypassers(&checker_data).await?;

// Always run rate limiting checks, even for bypassed requests
let mut rejection_reasons = Vec::new();
for checker in &self.checkers {
    // Only skip non-rate-limit checkers when bypassed
    if bypass && !checker.is_rate_limiter() {
        continue;
    }
    rejection_reasons.extend(checker.check(checker_data.clone(), dry_run).await?);
    if !rejection_reasons.is_empty() && self.return_rejections_early {
        break;
    }
}

// Always call complete() to update storage
// Remove the `if !bypass` condition at line 332
```

Add token lifecycle management with cryptographic verification:
```rust
pub struct VerifiedBypassToken {
    token: String,
    issued_at: u64,
    expires_at: u64,
    signature: Vec<u8>,
}

impl AuthTokenBypasser {
    fn verify_token(&self, token: &str) -> Result<bool> {
        // Verify JWT signature or HMAC
        // Check expiration
        // Validate against revocation list
    }
}
```

## Proof of Concept

The existing test demonstrates the vulnerability: [8](#0-7) 

**Exploitation Steps:**
```bash
# 1. Obtain leaked bypass token from CI logs
LEAKED_TOKEN="test_token"  # Example from test configs

# 2. Drain faucet with unlimited requests
for i in {1..1000}; do
  curl -X POST http://faucet-api/fund \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $LEAKED_TOKEN" \
    -d "{\"address\": \"0x$(openssl rand -hex 32)\", \"amount\": 1000}"
done

# 3. All requests succeed with no rate limiting
# 4. Each request gets maximum_amount_with_bypass (1000 instead of 100)
# 5. No storage updates mean unlimited requests possible
# 6. Faucet completely drained
```

**Notes**

This vulnerability exists in the production faucet code within aptos-core. While the faucet is a testnet/devnet utility and not part of core consensus, it represents real financial loss and service disruption. The bypasser mechanism is intentionally designed for CI/testing but lacks sufficient protection against credential compromise. The OR-logic combined with absent token lifecycle management creates a critical attack surface where a single leaked credential compromises the entire rate limiting system.

### Citations

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L244-259)
```rust
        // See if this request meets the criteria to bypass checkers / storage.
        for bypasser in &self.bypassers {
            if bypasser
                .request_can_bypass(checker_data.clone())
                .await
                .map_err(|e| {
                    AptosTapError::new_with_error_code(e, AptosTapErrorCode::BypasserError)
                })?
            {
                info!(
                    "Allowing request from {} to bypass checks / storage",
                    source_ip
                );
                return Ok((checker_data, true, permit));
            }
        }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L261-278)
```rust
        // Ensure request passes checkers.
        let mut rejection_reasons = Vec::new();
        for checker in &self.checkers {
            rejection_reasons.extend(checker.check(checker_data.clone(), dry_run).await.map_err(
                |e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError),
            )?);
            if !rejection_reasons.is_empty() && self.return_rejections_early {
                break;
            }
        }

        if !rejection_reasons.is_empty() {
            return Err(AptosTapError::new(
                format!("Request rejected by {} checkers", rejection_reasons.len()),
                AptosTapErrorCode::Rejected,
            )
            .rejection_reasons(rejection_reasons));
        }
```

**File:** crates/aptos-faucet/core/src/endpoints/fund.rs (L332-347)
```rust
        if !bypass {
            let response_is_500 = match &fund_result {
                Ok(_) => false,
                Err(e) => e.error_code.status().is_server_error(),
            };
            let complete_data = CompleteData {
                checker_data,
                txn_hashes: txn_hashes.clone(),
                response_is_500,
            };
            for checker in &self.checkers {
                checker.complete(complete_data.clone()).await.map_err(|e| {
                    AptosTapError::new_with_error_code(e, AptosTapErrorCode::CheckerError)
                })?;
            }
        }
```

**File:** crates/aptos-faucet/core/src/funder/common.rs (L176-185)
```rust
    pub fn get_maximum_amount(
        &self,
        // True if a Bypasser let the request bypass the Checkers.
        did_bypass_checkers: bool,
    ) -> Option<u64> {
        match (self.maximum_amount_with_bypass, did_bypass_checkers) {
            (Some(max), true) => Some(max),
            _ => self.maximum_amount,
        }
    }
```

**File:** crates/aptos-faucet/core/src/bypasser/auth_token.rs (L32-49)
```rust
    async fn request_can_bypass(&self, data: CheckerData) -> Result<bool> {
        // Don't check if the request has X_IS_JWT_HEADER set.
        if data.headers.contains_key(X_IS_JWT_HEADER) {
            return Ok(false);
        }

        let auth_token = match data
            .headers
            .get(AUTHORIZATION)
            .and_then(|v| v.to_str().ok())
            .and_then(|v| v.split_whitespace().nth(1))
        {
            Some(auth_token) => auth_token,
            None => return Ok(false),
        };

        Ok(self.manager.contains(auth_token))
    }
```

**File:** crates/aptos-faucet/core/src/server/run.rs (L937-1000)
```rust
    async fn test_maximum_amount_with_bypass() -> Result<()> {
        make_auth_tokens_file(&["test_token"])?;

        // Assert that a localnet is alive.
        let aptos_node_api_client = aptos_sdk::rest_client::Client::new(
            reqwest::Url::from_str("http://127.0.0.1:8080").unwrap(),
        );
        aptos_node_api_client
            .get_index_bcs()
            .await
            .context("Localnet API couldn't be reached at port 8080, have you started one?")?;

        init();
        let (port, _handle) = {
            // Ensure this server and that for test_mint_funder_*
            // don't start up simultaneously, since they're using the same mint key.
            let _guard = MUTEX.get().unwrap().lock().await;
            let config_content =
                include_str!("../../../configs/testing_mint_funder_local_wait_for_txns.yaml");
            start_server(config_content).await?
        };

        // Make a request for more than maximum_amount. This should be accepted as is
        // because we're including an auth token that lets us bypass the checkers,
        // meaning we're instead bound by maximum_amount_with_bypass.
        let fund_request = get_fund_request(Some(1000));
        unwrap_reqwest_result(
            reqwest::Client::new()
                .post(get_fund_endpoint(port))
                .body(fund_request.to_json_string())
                .header(CONTENT_TYPE, "application/json")
                .header(AUTHORIZATION, "Bearer test_token")
                .send()
                .await,
        )
        .await?;

        // Confirm that the account was given the full 1000 OCTA as requested.
        let response = aptos_node_api_client
            .view_apt_account_balance(
                AccountAddress::from_str(&fund_request.address.unwrap()).unwrap(),
            )
            .await?;

        assert_eq!(response.into_inner(), 1000);

        // This time, don't include the auth token. We request more than maximum_amount,
        // but later we'll see that the faucet will only give us maximum_amount, not
        // the amount we requested.
        let fund_request = get_fund_request(Some(1000));
        reqwest::Client::new()
            .post(get_fund_endpoint(port))
            .body(fund_request.to_json_string())
            .header(CONTENT_TYPE, "application/json")
            .send()
            .await?;

        // Confirm that the account was only given 100 OCTA (maximum_amount), not 1000.
        let response = aptos_node_api_client
            .view_apt_account_balance(
                AccountAddress::from_str(&fund_request.address.unwrap()).unwrap(),
            )
            .await?;

```

**File:** crates/aptos-faucet/core/src/checkers/redis_ratelimit.rs (L226-304)
```rust
    async fn check(
        &self,
        data: CheckerData,
        dry_run: bool,
    ) -> Result<Vec<RejectionReason>, AptosTapError> {
        let mut conn = self
            .get_redis_connection()
            .await
            .map_err(|e| AptosTapError::new_with_error_code(e, AptosTapErrorCode::StorageError))?;

        // Generate a key corresponding to this identifier and the current day.
        let key_prefix = self.ratelimit_key_provider.ratelimit_key_prefix();
        let key_value = self
            .ratelimit_key_provider
            .ratelimit_key_value(&data)
            .await?;
        let (key, seconds_until_next_day) =
            self.get_key_and_secs_until_next_day(key_prefix, &key_value);

        // Get the value for the key, indicating how many non-500 requests we have
        // serviced for it today.
        let limit_value: Option<i64> = conn.get(&key).await.map_err(|e| {
            AptosTapError::new_with_error_code(
                format!("Failed to get value for redis key {}: {}", key, e),
                AptosTapErrorCode::StorageError,
            )
        })?;

        // If the limit value is greater than what we allow per day, signal that we
        // should reject this request.
        if let Some(rejection_reason) = self.check_limit_value(limit_value, seconds_until_next_day)
        {
            return Ok(vec![rejection_reason]);
        }

        // Atomically increment the counter for the given key, creating it and setting
        // the expiration time if it doesn't already exist.
        if !dry_run {
            let incremented_limit_value = match limit_value {
                Some(_) => conn.incr(&key, 1).await.map_err(|e| {
                    AptosTapError::new_with_error_code(
                        format!("Failed to increment redis key {}: {}", key, e),
                        AptosTapErrorCode::StorageError,
                    )
                })?,
                // If the limit value doesn't exist, create it and set the
                // expiration time.
                None => {
                    let (incremented_limit_value,): (i64,) = redis::pipe()
                        .atomic()
                        .incr(&key, 1)
                        // Expire at the end of the day roughly.
                        .expire(&key, seconds_until_next_day as usize)
                        // Only set the expiration if one isn't already set.
                        // Only works with Redis 7 sadly.
                        // .arg("NX")
                        .ignore()
                        .query_async(&mut *conn)
                        .await
                        .map_err(|e| {
                            AptosTapError::new_with_error_code(
                                format!("Failed to increment value for redis key {}: {}", key, e),
                                AptosTapErrorCode::StorageError,
                            )
                        })?;
                    incremented_limit_value
                },
            };

            // Check limit again, to ensure there wasn't a get / set race.
            if let Some(rejection_reason) =
                self.check_limit_value(Some(incremented_limit_value), seconds_until_next_day)
            {
                return Ok(vec![rejection_reason]);
            }
        }

        Ok(vec![])
    }
```
