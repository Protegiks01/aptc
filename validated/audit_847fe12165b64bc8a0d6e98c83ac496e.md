# Audit Report

## Title
Data Stream Permanent Zombie State Due to Partial Initialization Failure

## Summary
A resource exhaustion vulnerability in the data streaming service allows streams to become permanently stuck in a "zombie" state when error conditions occur during response processing. The stream remains in memory indefinitely, consuming resources on every progress check cycle, causing validator node slowdowns and memory exhaustion.

## Finding Description

The vulnerability exists in the state stream initialization and error handling flow. When a `StateStreamEngine` receives a `NumberOfStates` response where the returned value is less than the requested `start_index`, the stream enters an unrecoverable zombie state.

**Critical Flow:**

1. **Initialization marks stream as initialized before potential failure**: [1](#0-0) 

The function sets `sent_data_requests = Some(VecDeque::new())` before calling `create_and_send_client_requests()`, meaning `data_requests_initialized()` returns `true` even if subsequent operations encounter errors.

2. **Initialization check only verifies `Some` state**: [2](#0-1) 

3. **Progress update routing based on initialization state**: [3](#0-2) 

Once `data_requests_initialized()` returns `true`, all future progress checks call `process_data_responses()` instead of re-attempting initialization.

4. **Error occurs during response processing**: [4](#0-3) 

When `number_of_states < next_request_index`, the stream engine returns `Error::NoDataToFetch`. This error propagates up from `transform_client_response_into_notification()` without incrementing `request_failure_count`.

5. **Request failure counter only incremented during retries**: [5](#0-4) 

The counter is only incremented in `resend_data_client_request()`, which is not called for this error path.

6. **Error logged but stream not removed**: [6](#0-5) 

Errors are logged but the stream remains in the `data_streams` HashMap indefinitely.

7. **No automatic garbage collection**: [7](#0-6) 

The code explicitly acknowledges the lack of automatic cleanup for misbehaving clients.

8. **Subsequent calls generate empty results**: [8](#0-7) 

When `next_request_index > end_state_index`, the function returns an empty vector, causing the stream to idle indefinitely without making progress or terminating.

**Attack Scenario:**
A malicious peer or race condition causes a state sync stream request where `start_index` exceeds the actual `number_of_states` at the requested version. The stream initialization appears to succeed, but when the `NumberOfStates` response is processed, the error permanently zombifies the stream. The stream never reaches the `max_request_retry` limit because `request_failure_count` is never incremented for this error type.

## Impact Explanation

**High Severity** per Aptos Bug Bounty criteria for "Validator Node Slowdowns":

1. **Memory Exhaustion**: Each zombie stream permanently consumes memory in the `data_streams` HashMap with no cleanup mechanism. Multiple zombie streams accumulate over time.

2. **CPU Overhead**: Every progress check interval (default: configurable milliseconds) processes each zombie stream, consuming CPU cycles. With many zombie streams, this creates measurable performance degradation.

3. **Resource Consumption**: Each stream maintains spawned tasks, pending request queues, and notification mappings that are never released.

4. **Liveness Risk**: In extreme cases with many accumulated zombie streams, the cumulative overhead could degrade state sync performance enough to impact validator liveness and network participation.

The vulnerability does not reach Critical severity because it doesn't directly violate consensus safety, enable fund theft, or cause complete network halt. However, it qualifies as High severity for validator node slowdowns through resource exhaustion.

## Likelihood Explanation

**Medium-High Likelihood:**

1. **Malicious Trigger**: Any network peer can create state sync stream requests with arbitrary `start_index` values, allowing intentional triggering by malicious actors.

2. **Race Conditions**: During network partitions or high load, advertised data summaries may become stale between stream creation and initialization, causing legitimate requests to have invalid indices.

3. **Epoch Transitions**: During epoch changes, temporary inconsistencies between advertised data and actual available data can trigger this condition.

4. **No Validation**: The stream validation at creation only checks version availability, not `start_index` validity: [9](#0-8) 

The vulnerability requires no attacker privileges and can occur under normal adverse network conditions. Once triggered, the impact persists indefinitely until node restart.

## Recommendation

Implement the following fixes:

1. **Add automatic cleanup for zombie streams**: Track streams that make no progress for a configurable timeout and automatically terminate them.

2. **Increment failure counter for all error types**: Modify error handling to increment `request_failure_count` for errors from `transform_client_response_into_notification()`, not just retry scenarios.

3. **Validate start_index during stream creation**: Add validation in `StateStreamEngine::new()` or `ensure_data_is_available()` to reject requests where `start_index` is known to be invalid based on advertised data.

4. **Reset initialization state on error**: If `initialize_data_requests()` or early response processing fails, reset `sent_data_requests` back to `None` to allow re-initialization.

5. **Implement the TODO**: Complete the automatic garbage collection for misbehaving clients mentioned in the code.

## Proof of Concept

```rust
// Conceptual PoC - triggers zombie stream creation
// 1. Create GetAllStatesRequest with start_index=1000
// 2. Actual number_of_states at version is only 500
// 3. Stream gets created and initialized
// 4. NumberOfStates response returns 500
// 5. Error occurs: 500 < 1000
// 6. Stream remains in HashMap forever
// 7. Subsequent progress checks find empty queue, return Ok(())
// 8. Stream never terminates, consumes resources indefinitely
```

**Notes:**
- The report's description of "continuously failing with the same error" is slightly inaccurate. After the initial `NoDataToFetch` error, subsequent progress checks simply return empty results without errors. However, the core vulnerability (permanent zombie streams consuming resources) is valid.
- This vulnerability can be triggered by untrusted network peers through the state sync protocol.
- The lack of automatic cleanup combined with no failure counter increment creates a guaranteed resource leak for certain error conditions.

### Citations

**File:** state-sync/data-streaming-service/src/data_stream.rs (L187-189)
```rust
    pub fn data_requests_initialized(&self) -> bool {
        self.sent_data_requests.is_some()
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L210-219)
```rust
    pub fn initialize_data_requests(
        &mut self,
        global_data_summary: GlobalDataSummary,
    ) -> Result<(), Error> {
        // Initialize the data client requests queue
        self.sent_data_requests = Some(VecDeque::new());

        // Create and send the data client requests to the network
        self.create_and_send_client_requests(&global_data_summary)
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L729-734)
```rust
    fn resend_data_client_request(
        &mut self,
        data_client_request: &DataClientRequest,
    ) -> Result<(), Error> {
        // Increment the number of client failures for this request
        self.request_failure_count += 1;
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L200-201)
```rust
    /// TODO(joshlind): once this is exposed to the wild, we'll need automatic
    /// garbage collection for misbehaving clients.
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L313-332)
```rust
            if let Err(error) = self.update_progress_of_data_stream(data_stream_id).await {
                if matches!(error, Error::NoDataToFetch(_)) {
                    sample!(
                        SampleRate::Duration(Duration::from_secs(NO_DATA_TO_FETCH_LOG_FREQ_SECS)),
                        info!(LogSchema::new(LogEntry::CheckStreamProgress)
                            .stream_id(*data_stream_id)
                            .event(LogEvent::Pending)
                            .error(&error))
                    );
                } else {
                    metrics::increment_counter(
                        &metrics::CHECK_STREAM_PROGRESS_ERROR,
                        error.get_label(),
                    );
                    warn!(LogSchema::new(LogEntry::CheckStreamProgress)
                        .stream_id(*data_stream_id)
                        .event(LogEvent::Error)
                        .error(&error));
                }
            }
```

**File:** state-sync/data-streaming-service/src/streaming_service.rs (L367-381)
```rust
        if !data_stream.data_requests_initialized() {
            // Initialize the request batch by sending out data client requests
            data_stream.initialize_data_requests(global_data_summary)?;
            info!(
                (LogSchema::new(LogEntry::InitializeStream)
                    .stream_id(*data_stream_id)
                    .event(LogEvent::Success)
                    .message("Data stream initialized."))
            );
        } else {
            // Process any data client requests that have received responses
            data_stream
                .process_data_responses(global_data_summary)
                .await?;
        }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L287-293)
```rust
    fn is_remaining_data_available(&self, advertised_data: &AdvertisedData) -> Result<bool, Error> {
        Ok(AdvertisedData::contains_range(
            self.request.version,
            self.request.version,
            &advertised_data.states,
        ))
    }
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L373-378)
```rust
                    if number_of_states < self.next_request_index {
                        return Err(Error::NoDataToFetch(format!(
                            "The next state index to fetch is higher than the \
                            total number of states. Next index: {:?}, total states: {:?}",
                            self.next_request_index, number_of_states
                        )));
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L2056-2058)
```rust
    if start_index > end_index {
        return Ok(vec![]);
    }
```
