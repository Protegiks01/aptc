# Audit Report

## Title
Non-Atomic Cross-Schema Pruning Causes State Inconsistency in Transaction Indexing

## Summary
The transaction pruning logic performs deletions from two separate database schemas (`OrderedTransactionByAccountSchema` in indexer_db and `TransactionSummariesByAccountSchema` in transaction_db) using two separate, non-atomic commits. A system failure between these commits leaves the schemas in an inconsistent state, violating the State Consistency invariant.

## Finding Description

The vulnerability exists in the pruning operation for transaction indices when internal indexer database is enabled with transaction indexing.

When storage sharding is enabled and the internal indexer has transaction indexing enabled, the pruning process performs two separate, non-atomic database write operations: [1](#0-0) 

The pruning flow executes as follows:

1. **Line 53**: Calls `prune_transaction_summaries_by_account()` which adds `TransactionSummariesByAccountSchema` deletions to the main batch for transaction_db
2. **Lines 58-67**: If internal indexer has transaction indexing enabled, creates a **separate** `index_batch` and commits it to indexer_db **first** (line 67)
3. **Line 73**: Commits the main batch to transaction_db **second**

These are two separate RocksDB write operations to two different physical database instances with no transaction coordinator or two-phase commit protocol.

The configuration enforces that internal indexer requires storage sharding: [2](#0-1) 

When storage sharding is enabled, `skip_index_and_usage` is set to true: [3](#0-2) 

This causes `OrderedTransactionByAccountSchema` to be written only to the indexer_db: [4](#0-3) 

While `TransactionSummariesByAccountSchema` remains in transaction_db: [5](#0-4) 

The schemas are also defined in different database column families: [6](#0-5) [7](#0-6) 

**Attack Scenario:**
1. Pruner initiates pruning of transactions
2. Line 67 executes successfully - `OrderedTransactionByAccountSchema` entries are deleted from indexer_db  
3. System crashes (OOM, SIGKILL, power failure, panic) before line 73 executes
4. Upon restart, `TransactionSummariesByAccountSchema` entries remain in transaction_db

**Result:**
Queries via `get_account_ordered_transaction_version` return "not found" for pruned transactions: [8](#0-7) 

But queries via `get_account_transaction_summaries_iter` still return transaction summaries that should have been pruned: [9](#0-8) 

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This qualifies as "State inconsistencies requiring manual intervention" because:

1. **Data Integrity Violation**: Transaction indices become inconsistent - some indices claim transactions are pruned while others claim they still exist
2. **API Inconsistency**: Different query APIs return contradictory results about data availability
3. **Validator Divergence Risk**: If different validators experience crashes at different times during pruning, they may end up with different views of which transaction summaries are available
4. **Operational Impact**: Requires manual database intervention to resolve the inconsistency
5. **Non-Deterministic Failure**: The specific transactions affected depend on crash timing, making debugging difficult

While this does not directly cause consensus safety violations or fund loss, it compromises the State Consistency invariant and could lead to validators having divergent storage states.

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability is **deterministic** when the triggering conditions occur:

- **Trigger Conditions**: 
  - Internal indexer database must be enabled with transaction indexing (common in production)
  - Storage sharding must be enabled (`enable_storage_sharding` config)
  - System must crash/fail between the two commits during pruning

- **Frequency**: Pruning runs periodically based on configuration. Each pruning cycle creates multiple opportunities for this race condition

- **Real-World Scenarios**:
  - Validator node crashes (hardware failure, OOM, panic)
  - Forceful process termination (SIGKILL)
  - Power failures
  - Disk I/O errors during the second commit

- **No Special Privileges Required**: This happens automatically during normal pruning operations; no attacker action needed

## Recommendation

Implement a two-phase commit protocol or use a single atomic batch operation that commits deletions to both schemas together. Alternative solutions:

1. **Single Database Approach**: Store both schemas in the same database when internal indexer is enabled, allowing atomic deletion
2. **Write-Ahead Log**: Implement a WAL that records the intended pruning operation before executing, with recovery logic to complete interrupted operations on restart
3. **Progress Synchronization**: Before pruning, check that both databases have matching progress markers and implement reconciliation logic on startup to detect and fix inconsistencies

## Proof of Concept

The vulnerability can be demonstrated by:

1. Configure a node with `enable_storage_sharding: true` and `indexer_db_config.enable_transaction: true`
2. Allow the node to accumulate transactions and trigger pruning
3. During the pruning operation, simulate a crash between the two database commits (e.g., using a debugger breakpoint or SIGKILL)
4. Restart the node and query both APIs for the same transaction that was being pruned
5. Observe that `get_account_ordered_transaction_version` returns "not found" while `get_account_transaction_summaries_iter` still returns the transaction summary

## Notes

This vulnerability affects production deployments where the internal indexer with transaction indexing is enabled alongside storage sharding. The lack of atomicity guarantees across separate database instances is a fundamental architectural issue that requires careful design consideration. The validation logic in `db_debugger/validation.rs` can detect this inconsistency but is not run automatically on startup, leaving the system vulnerable to silent state divergence.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs (L37-74)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let candidate_transactions =
            self.get_pruning_candidate_transactions(current_progress, target_version)?;
        self.ledger_db
            .transaction_db()
            .prune_transaction_by_hash_indices(
                candidate_transactions.iter().map(|(_, txn)| txn.hash()),
                &mut batch,
            )?;
        self.ledger_db.transaction_db().prune_transactions(
            current_progress,
            target_version,
            &mut batch,
        )?;
        self.transaction_store
            .prune_transaction_summaries_by_account(&candidate_transactions, &mut batch)?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::TransactionPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
        if let Some(indexer_db) = self.internal_indexer_db.as_ref() {
            if indexer_db.transaction_enabled() {
                let mut index_batch = SchemaBatch::new();
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut index_batch)?;
                index_batch.put::<InternalIndexerMetadataSchema>(
                    &IndexerMetadataKey::TransactionPrunerProgress,
                    &IndexerMetadataValue::Version(target_version),
                )?;
                indexer_db.get_inner_db_ref().write_schemas(index_batch)?;
            } else {
                self.transaction_store
                    .prune_transaction_by_account(&candidate_transactions, &mut batch)?;
            }
        }
        self.ledger_db.transaction_db().write_schemas(batch)
    }
```

**File:** config/src/config/internal_indexer_db_config.rs (L92-98)
```rust
        if !node_config.storage.rocksdb_configs.enable_storage_sharding
            && config.is_internal_indexer_db_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Don't turn on internal indexer db if DB sharding is off".into(),
            ));
```

**File:** storage/aptosdb/src/db/aptosdb_internal.rs (L148-160)
```rust
        let mut myself = Self::new_with_dbs(
            ledger_db,
            hot_state_merkle_db,
            state_merkle_db,
            state_kv_db,
            pruner_config,
            buffered_state_target_items,
            readonly,
            empty_buffered_state_for_restore,
            rocksdb_configs.enable_storage_sharding,
            internal_indexer_db,
            hot_state_config,
        );
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L137-146)
```rust
        if !skip_index {
            if let Some(txn) = transaction.try_as_signed_user_txn() {
                if let ReplayProtector::SequenceNumber(seq_num) = txn.replay_protector() {
                    batch.put::<OrderedTransactionByAccountSchema>(
                        &(txn.sender(), seq_num),
                        &version,
                    )?;
                }
            }
        }
```

**File:** storage/aptosdb/src/ledger_db/transaction_db.rs (L157-160)
```rust
            batch.put::<TransactionSummariesByAccountSchema>(
                &(signed_txn.sender(), version),
                &txn_summary,
            )?;
```

**File:** storage/aptosdb/src/db_options.rs (L78-87)
```rust
pub(super) fn transaction_db_column_families() -> Vec<ColumnFamilyName> {
    vec![
        /* empty cf */ DEFAULT_COLUMN_FAMILY_NAME,
        DB_METADATA_CF_NAME,
        TRANSACTION_CF_NAME,
        ORDERED_TRANSACTION_BY_ACCOUNT_CF_NAME,
        TRANSACTION_SUMMARIES_BY_ACCOUNT_CF_NAME,
        TRANSACTION_BY_HASH_CF_NAME,
    ]
}
```

**File:** storage/indexer_schemas/src/schema/mod.rs (L40-51)
```rust
pub fn internal_indexer_column_families() -> Vec<ColumnFamilyName> {
    vec![
        /* empty cf */ DEFAULT_COLUMN_FAMILY_NAME,
        INTERNAL_INDEXER_METADATA_CF_NAME,
        EVENT_BY_KEY_CF_NAME,
        EVENT_BY_VERSION_CF_NAME,
        ORDERED_TRANSACTION_BY_ACCOUNT_CF_NAME,
        STATE_KEYS_CF_NAME,
        TRANSLATED_V1_EVENT_CF_NAME,
        EVENT_SEQUENCE_NUMBER_CF_NAME,
    ]
}
```

**File:** storage/aptosdb/src/transaction_store/mod.rs (L36-52)
```rust
    pub fn get_account_ordered_transaction_version(
        &self,
        address: AccountAddress,
        sequence_number: u64,
        ledger_version: Version,
    ) -> Result<Option<Version>> {
        if let Some(version) =
            self.ledger_db
                .transaction_db_raw()
                .get::<OrderedTransactionByAccountSchema>(&(address, sequence_number))?
        {
            if version <= ledger_version {
                return Ok(Some(version));
            }
        }
        Ok(None)
    }
```

**File:** storage/aptosdb/src/transaction_store/mod.rs (L83-140)
```rust
    pub fn get_account_transaction_summaries_iter(
        &self,
        address: AccountAddress,
        start_version: Option<u64>,
        end_version: Option<u64>,
        limit: u64,
        ledger_version: Version,
    ) -> Result<AccountTransactionSummariesIter<'_>> {
        // Question[Orderless]: When start version is specified, we are current scanning forward from start version.
        // When start version is not specified we are scanning backward, so as to return the most recent transactions.
        // This doesn't seem to be a good design. Should we instead let the API take scan direction as input?
        if start_version.is_some() {
            let mut iter = self
                .ledger_db
                .transaction_db_raw()
                .iter::<TransactionSummariesByAccountSchema>()?;
            iter.seek(&(address, start_version.unwrap()))?;
            Ok(AccountTransactionSummariesIter::new(
                iter,
                address,
                start_version,
                end_version,
                limit,
                ScanDirection::Forward,
                ledger_version,
            ))
        } else if end_version.is_some() {
            let mut iter = self
                .ledger_db
                .transaction_db_raw()
                .rev_iter::<TransactionSummariesByAccountSchema>()?;
            iter.seek_for_prev(&(address, end_version.unwrap()))?;
            Ok(AccountTransactionSummariesIter::new(
                iter,
                address,
                start_version,
                end_version,
                limit,
                ScanDirection::Backward,
                ledger_version,
            ))
        } else {
            let mut iter = self
                .ledger_db
                .transaction_db_raw()
                .rev_iter::<TransactionSummariesByAccountSchema>()?;
            iter.seek_for_prev(&(address, u64::MAX))?;
            Ok(AccountTransactionSummariesIter::new(
                iter,
                address,
                start_version,
                Some(u64::MAX),
                limit,
                ScanDirection::Backward,
                ledger_version,
            ))
        }
    }
```
