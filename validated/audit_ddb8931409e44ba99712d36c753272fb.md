# Audit Report

## Title
Critical Consensus Message Loss via Premature Broadcast Abort in DAG Driver

## Summary
The DAG consensus implementation contains a critical vulnerability where reliable broadcast tasks are prematurely aborted when evicted from a bounded queue, causing certified nodes to be lost without proper delivery to all validators. This creates unrecoverable consensus liveness failures when the specific historical certificate signers become unavailable, violating the fundamental guarantee that consensus should progress with any 2f+1 available validators.

## Finding Description

The vulnerability exists in the interaction between the DAG driver's bounded broadcast handle queue and the reliable broadcast mechanism's design.

The `rb_handles` field stores broadcast abort handles in a `BoundedVecDeque` with capacity set to `window_size_config`: [1](#0-0) 

The default window size is 10 rounds from `DagConsensusConfigV1`: [2](#0-1) 

The bounded queue is initialized with this capacity: [3](#0-2) 

When broadcasting a new node, if the queue is full, `push_back()` evicts the oldest handle: [4](#0-3) 

The evicted `DropGuard` triggers abort when dropped: [5](#0-4) 

**The Critical Design Flaw**: The broadcast mechanism waits for responses from ALL validators, not just quorum. The `SignatureBuilder` returns `Some(())` only when all validators have responded: [6](#0-5) 

Similarly, `CertificateAckState` waits for all validators: [7](#0-6) 

The reliable broadcast loop continues until aggregating status returns `Some(aggregated)`: [8](#0-7) 

**The Recovery Mechanism Failure**: When validators encounter a missing node as a parent dependency, they attempt to fetch it. However, fetch is limited to validators who signed the certificate: [9](#0-8) 

**Critical Observation**: When validators receive a `Node` during the first broadcast, they only send back a `Vote` - they do NOT store the full Node: [10](#0-9) 

The `CertifiedNode` is only stored when received during the second broadcast phase: [11](#0-10) 

**The Vulnerability**: Certificate signers are validators who voted (first broadcast), but they may not have the certified node stored if the second broadcast was aborted. When other validators need to fetch this node, they query the signers, but if those specific signers either:
1. Never received the certified node due to the abort, OR
2. Are currently unreachable (crashed, partitioned)

Then the fetch fails and consensus blocks indefinitely.

The exponential backoff configuration confirms broadcasts can take up to 3 seconds with retries: [12](#0-11) 

State sync uses the same fetch mechanism with the same limitation: [13](#0-12) 

Developer TODO comments indicate awareness of potential issues with the bounded queue: [14](#0-13) 

**Attack Scenario**:
1. Validator V broadcasts a node at round R
2. All validators vote, 2f+1 signatures create certificate
3. V broadcasts CertifiedNode but only some validators receive it before rounds progress
4. Rounds R+1 through R+10 complete quickly (sub-second round times)
5. At round R+11, new broadcast evicts round R's handle
6. Round R's broadcast task is aborted before all validators acknowledge
7. V crashes or becomes partitioned
8. Other validators missing the certified node cannot fetch it because the specific 2f+1 signers who voted are either unavailable or never received the certified node themselves

## Impact Explanation

This vulnerability meets **Critical Severity** under "Total Loss of Liveness/Network Availability" per the Aptos bug bounty program:

- **Consensus Liveness Failure**: Validators missing certified nodes cannot add any nodes depending on them as parents, halting DAG progression for those validators.

- **Network-Wide Impact**: If multiple validators are affected by different missing nodes, the network cannot achieve quorum for new rounds, causing total network liveness loss.

- **Cascading Failures**: Missing nodes from round R block all dependent nodes in rounds R+1, R+2, etc., creating cascades that prevent forward progress.

- **Fundamental Violation**: This violates the core consensus liveness guarantee that the system should make progress when 2f+1 validators are available. The vulnerability requires specific historical validators (the certificate signers) to be available, not just any currently available 2f+1 validators. This creates a permanent dependency on past validator availability rather than current validator availability.

- **Limited Recovery**: Recovery requires manual intervention if the author and enough certificate signers remain unavailable. Unlike normal network partitions that heal when 2f+1 validators reconnect, this requires the specific historical signers to return.

## Likelihood Explanation

This vulnerability has **Medium to High** likelihood:

**Contributing Factors**:
- Broadcasts taking longer than 10 rounds is feasible: with exponential backoff reaching 3 seconds and sub-second round times in optimal conditions, 10 rounds can complete in 5-10 seconds while broadcasts are still retrying
- Network latency spikes are common in production environments
- Validator restarts or temporary partitions occur regularly during normal operations  
- No attacker required - this happens naturally during normal network variance

**Realistic Scenario**: A validator with temporarily poor connectivity collects signatures and creates a certificate, but before the certified node broadcast completes to all validators, network conditions improve and rounds progress quickly, evicting the slow broadcast. The validator then crashes or remains partitioned, making the certified node unrecoverable if the other signers also didn't receive it or become unavailable.

## Recommendation

Implement one or more of the following fixes:

1. **Decouple broadcast completion from bounded queue**: Don't abort broadcasts when evicted from the queue. Instead, let them complete in the background and only abort them when they're truly stale (e.g., round is pruned from DAG window).

2. **Expand fetch responders**: When fetching a CertifiedNode, query ALL validators, not just certificate signers. Any validator who has the node can provide it.

3. **Author-centric storage**: Ensure the author explicitly stores their own CertifiedNode in the DAG store immediately after creating it, without relying on the self-RPC completing.

4. **Increase window size**: Increase the default window size from 10 to a larger value (e.g., 50) to reduce the likelihood of premature eviction during normal operation.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Setting up a DAG consensus network with 5 validators
2. Injecting network delay for validator V1 (the broadcaster)
3. Having V1 broadcast a node at round R
4. Allowing votes to complete and certificate to be created
5. Injecting additional delay in the certified node broadcast
6. Progressing rounds R+1 through R+11 quickly on other validators
7. Observing the abort handle being evicted and broadcast task aborted
8. Simulating V1 crash
9. Attempting to have another validator (V2) add a node depending on R as parent
10. Observing fetch failure when querying certificate signers who don't have the node or are unreachable
11. Observing consensus halt for V2 and subsequent validators

This demonstrates the critical liveness failure where specific historical validator availability (certificate signers) is required rather than current validator availability.

### Citations

**File:** consensus/src/dag/dag_driver.rs (L57-57)
```rust
    rb_handles: Mutex<BoundedVecDeque<(DropGuard, u64)>>,
```

**File:** consensus/src/dag/dag_driver.rs (L103-103)
```rust
            rb_handles: Mutex::new(BoundedVecDeque::new(window_size_config as usize)),
```

**File:** consensus/src/dag/dag_driver.rs (L371-372)
```rust
        // TODO: a bounded vec queue can hold more than window rounds, but we want to limit
        // by number of rounds.
```

**File:** consensus/src/dag/dag_driver.rs (L394-412)
```rust
    async fn process(&self, certified_node: Self::Request) -> anyhow::Result<Self::Response> {
        let epoch = certified_node.metadata().epoch();
        debug!(LogSchema::new(LogEvent::ReceiveCertifiedNode)
            .remote_peer(*certified_node.author())
            .round(certified_node.round()));
        if self.dag.read().exists(certified_node.metadata()) {
            return Ok(CertifiedAck::new(epoch));
        }

        observe_node(certified_node.timestamp(), NodeStage::CertifiedNodeReceived);
        NUM_TXNS_PER_NODE.observe(certified_node.payload().len() as f64);
        NODE_PAYLOAD_SIZE.observe(certified_node.payload().size() as f64);

        let node_metadata = certified_node.metadata().clone();
        self.add_node(certified_node)
            .map(|_| self.order_rule.lock().process_new_node(&node_metadata))?;

        Ok(CertifiedAck::new(epoch))
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L594-594)
```rust
            dag_ordering_causal_history_window: 10,
```

**File:** crates/aptos-collections/src/bounded_vec_deque.rs (L28-38)
```rust
    pub fn push_back(&mut self, item: T) -> Option<T> {
        let oldest = if self.is_full() {
            self.inner.pop_front()
        } else {
            None
        };

        self.inner.push_back(item);
        assert!(self.inner.len() <= self.capacity);
        oldest
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L186-188)
```rust
                            Ok(may_be_aggragated) => {
                                if let Some(aggregated) = may_be_aggragated {
                                    return Ok(aggregated);
```

**File:** crates/reliable-broadcast/src/lib.rs (L232-236)
```rust
impl Drop for DropGuard {
    fn drop(&mut self) {
        self.abort_handle.abort();
    }
}
```

**File:** consensus/src/dag/types.rs (L600-604)
```rust
        if partial_signatures.signatures().len() == self.epoch_state.verifier.len() {
            Ok(Some(()))
        } else {
            Ok(None)
        }
```

**File:** consensus/src/dag/types.rs (L656-660)
```rust
        if received.len() == self.num_validators {
            Ok(Some(()))
        } else {
            Ok(None)
        }
```

**File:** consensus/src/dag/dag_fetcher.rs (L108-110)
```rust
            LocalFetchRequest::CertifiedNode(node, _) => {
                node.signatures().get_signers_addresses(validators)
            },
```

**File:** consensus/src/dag/rb_handler.rs (L249-264)
```rust
        let signature = node.sign_vote(&self.signer)?;
        let vote = Vote::new(node.metadata().clone(), signature);
        self.storage.save_vote(&node.id(), &vote)?;
        self.votes_by_round_peer
            .lock()
            .get_mut(&node.round())
            .expect("must exist")
            .insert(*node.author(), vote.clone());

        self.dag.write().update_votes(&node, false);
        self.order_rule.process_new_node(node.metadata());

        debug!(LogSchema::new(LogEvent::Vote)
            .remote_peer(*node.author())
            .round(node.round()));
        Ok(vote)
```

**File:** config/src/config/dag_consensus_config.rs (L115-118)
```rust
            // A backoff policy that starts at 100ms and doubles each iteration up to 3secs.
            backoff_policy_base_ms: 2,
            backoff_policy_factor: 50,
            backoff_policy_max_delay_ms: 3000,
```

**File:** consensus/src/dag/dag_state_sync.rs (L229-232)
```rust
        let responders = node
            .certificate()
            .signatures()
            .get_signers_addresses(&self.epoch_state.verifier.get_ordered_account_addresses());
```
