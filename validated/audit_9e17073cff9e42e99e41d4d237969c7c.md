# Audit Report

## Title
Tokio Async Thread Pool Exhaustion via Unprotected Rayon Operations in Signature Verification

## Summary
The signature verification phase in the consensus block preparation pipeline uses `rayon::ThreadPool::install()` directly from a tokio async task without proper isolation via `spawn_blocking`. Under high consensus load with many concurrent blocks, this blocks tokio async worker threads while waiting for rayon parallel work to complete, potentially exhausting the async thread pool and causing validator node slowdowns or consensus stalls.

## Finding Description

The consensus pipeline processes blocks through multiple stages, with the `prepare()` stage responsible for signature verification. While transaction deduplication is correctly isolated within `tokio::task::spawn_blocking` [1](#0-0) , the signature verification that immediately follows is NOT properly isolated.

The `prepare()` async function calls `SIG_VERIFY_POOL.install()` directly from an async context [2](#0-1) . The `rayon::ThreadPool::install()` method is a **blocking operation** that blocks the calling thread until all rayon parallel work completes.

Since `prepare()` is spawned as an async task on the tokio runtime via `spawn_shared_fut` which uses `tokio::spawn` [3](#0-2)  and [4](#0-3) , the `install()` call blocks a tokio async worker thread.

The consensus runtime uses the default number of worker threads (number of CPU cores) [5](#0-4)  with [6](#0-5) .

**Execution Path Under High Load:**
1. Network experiences high transaction volume or validator catch-up after downtime
2. Consensus processes many blocks concurrently (e.g., 32+ blocks on a 32-core machine)
3. Each block's `prepare()` task runs signature verification via `SIG_VERIFY_POOL.install()`
4. Each `install()` call blocks a tokio async worker thread for the duration of signature verification
5. With 32+ concurrent blocks, all tokio async worker threads become blocked
6. New consensus tasks cannot be scheduled on the async pool
7. Consensus pipeline stalls, preventing block execution and state updates
8. Validator falls behind or stops participating in consensus

This violates proper async/blocking operation isolation and can cause consensus **liveness** degradation.

## Impact Explanation

This qualifies as **High Severity** ($50,000) under the Aptos bug bounty criteria for "Validator node slowdowns" - significant performance degradation affecting consensus.

Under normal load with sequential block processing, the issue may not manifest. However, during:
- **Catch-up sync**: Validators processing backlog of blocks
- **High transaction throughput**: Rapid block production
- **Network partitions**: Multiple forks being processed simultaneously

The async thread pool exhaustion can cause:
- **Consensus participation degradation**: Validator unable to vote/propose in time
- **Chain quality reduction**: Fewer active validators
- **Cascading failures**: If multiple validators experience slowdowns simultaneously

The tokio runtime has a maximum of 64 blocking threads [7](#0-6) , while `dedup()` operations correctly use this pool. However, signature verification bypasses this protection by blocking async threads directly.

## Likelihood Explanation

**Likelihood: Medium-High**

This issue will manifest under realistic conditions:
- **Testnet/Devnet**: Likely during stress testing or catch-up scenarios
- **Mainnet**: Possible during epoch transitions, validator restarts, or network instability
- **No attacker required**: Natural network conditions trigger the issue
- **Deterministic**: Will occur when concurrent block count exceeds async worker thread count

The `SIG_VERIFY_POOL` has 16 threads [8](#0-7) , meaning signature verification for 16+ concurrent blocks will consume 16+ async worker threads. On a typical 32-core validator, this represents 50% async pool exhaustion.

The pipeline stages are spawned directly with `tokio::spawn` without going through the `BoundedExecutor`, meaning there's no semaphore limiting concurrent block preparation tasks.

## Recommendation

Wrap the signature verification in `tokio::task::spawn_blocking` to properly isolate the blocking rayon operation from the async runtime, similar to how the `execute` phase is handled [9](#0-8) .

The fix would involve modifying the `prepare()` function to move the signature verification into a spawn_blocking context.

## Proof of Concept

While a full executable PoC would require setting up a consensus testnet environment, the vulnerability can be demonstrated by:

1. Configure a validator node with limited CPU cores (e.g., 8 cores)
2. Simulate catch-up scenario where validator processes 16+ blocks concurrently
3. Monitor tokio worker thread pool saturation via metrics
4. Observe consensus voting delays and proposal timeouts
5. Verify that all async worker threads are blocked in `rayon::ThreadPool::install()` calls

The issue is deterministic and will occur when the number of concurrent blocks in the `prepare()` stage exceeds the number of tokio async worker threads.

### Citations

**File:** consensus/src/block_preparer.rs (L90-115)
```rust
        let result = tokio::task::spawn_blocking(move || {
            let filtered_txns = filter_block_transactions(
                txn_filter_config,
                block_id,
                block_author,
                block_epoch,
                block_timestamp_usecs,
                txns,
            );
            let deduped_txns = txn_deduper.dedup(filtered_txns);
            let mut shuffled_txns = {
                let _timer = TXN_SHUFFLE_SECONDS.start_timer();

                txn_shuffler.shuffle(deduped_txns)
            };

            if let Some(max_txns_from_block_to_execute) = max_txns_from_block_to_execute {
                shuffled_txns.truncate(max_txns_from_block_to_execute as usize);
            }
            TXNS_IN_BLOCK
                .with_label_values(&["after_filter"])
                .observe(shuffled_txns.len() as f64);
            MAX_TXNS_FROM_BLOCK_TO_EXECUTE.observe(shuffled_txns.len() as f64);
            shuffled_txns
        })
        .await
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L65-73)
```rust
static SIG_VERIFY_POOL: Lazy<Arc<rayon::ThreadPool>> = Lazy::new(|| {
    Arc::new(
        rayon::ThreadPoolBuilder::new()
            .num_threads(16)
            .thread_name(|index| format!("signature-checker-{}", index))
            .build()
            .expect("Failed to create signature verification thread pool"),
    )
});
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L144-151)
```rust
fn spawn_shared_fut<
    T: Send + Clone + 'static,
    F: Future<Output = TaskResult<T>> + Send + 'static,
>(
    f: F,
    abort_handles: Option<&mut Vec<AbortHandle>>,
) -> TaskFuture<T> {
    let join_handle = tokio::spawn(f);
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L472-475)
```rust
        let prepare_fut = spawn_shared_fut(
            Self::prepare(decryption_fut, self.block_preparer.clone(), block.clone()),
            Some(&mut abort_handles),
        );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L670-677)
```rust
        let sig_verified_txns: Vec<SignatureVerifiedTransaction> = SIG_VERIFY_POOL.install(|| {
            let num_txns = input_txns.len();
            input_txns
                .into_par_iter()
                .with_min_len(optimal_min_len(num_txns, 32))
                .map(|t| Transaction::UserTransaction(t).into())
                .collect::<Vec<_>>()
        });
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L857-868)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(start.elapsed())
```

**File:** consensus/src/consensus_provider.rs (L56-56)
```rust
    let runtime = aptos_runtimes::spawn_named_runtime("consensus".into(), None);
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** crates/aptos-runtimes/src/lib.rs (L52-54)
```rust
    if let Some(num_worker_threads) = num_worker_threads {
        builder.worker_threads(num_worker_threads);
    }
```
