# Audit Report

## Title
Certified Timestamp Divergence Causes Premature Batch Expiration and Block Execution Failures

## Summary
Network partitions and sync lag cause validators to have divergent `certified_timestamp` values. When a validator with a lower certified_timestamp requests a batch, validators with higher certified_timestamps incorrectly signal that the batch has globally expired, causing the requester to enter an infinite retry loop and fail to execute blocks even when the batch is valid for the block's timestamp.

## Finding Description

The vulnerability exists in the batch request-response flow between validators in the Quorum Store system, causing validators with lower certified timestamps to become stuck when executing valid blocks.

**Core Issue:**

When a validator doesn't have a batch locally and requests it from peers, the responding validator returns `BatchResponse::NotFound(ledger_info)` containing their current ledger info from the database. [1](#0-0) 

The requester checks if the responder's ledger_info timestamp exceeds the batch expiration, and if so, immediately short-circuits and returns an error. [2](#0-1) 

**Why This Is Wrong:**

The batch expiration should be evaluated relative to the **block's timestamp** being processed, not the responder's current certified_timestamp. The payload manager correctly checks `block_timestamp <= batch_info.expiration()` before requesting batches, [3](#0-2)  but this context is lost when the batch request is made.

The `request_batch` function signature only accepts the batch expiration, not the block timestamp. [4](#0-3) 

The batch retrieval call passes only the batch expiration without block context. [5](#0-4) 

**Attack Scenario:**

1. Network partition or sync lag occurs (natural network condition)
2. Validator A has `certified_timestamp = 150` (ahead due to better connectivity)
3. Validator B has `certified_timestamp = 50` (behind due to temporary disconnection)
4. Batch exists with `expiration = 100`
5. Validator A deletes the batch via `clear_expired_payload` because `150 > 100`. [6](#0-5) 
6. Validator B receives block proposal with `timestamp = 90` referencing this batch
7. Validator B correctly checks: `90 ≤ 100` (valid) and attempts to fetch the batch
8. Validator B requests batch from Validator A
9. Validator A responds: `NotFound(ledger_info)` where `ledger_info.timestamp = 150`
10. Validator B checks: `150 > 100` (TRUE) → returns `ExecutorError::CouldNotGetData`
11. The error propagates up to the block preparation layer, which enters an infinite retry loop. [7](#0-6) 
12. Validator B becomes stuck retrying every 100ms, unable to execute the block

The certified_timestamp is updated atomically when blocks are committed. [8](#0-7) 

This triggers batch expiration through `update_certified_timestamp`. [9](#0-8) 

The batch store also rejects batches that are expired relative to the current certified_timestamp when saving. [10](#0-9) 

The test suite confirms this short-circuit behavior is intentional for the "globally expired" case. [11](#0-10)  However, it fails to account for scenarios where the batch is still valid for the block being executed despite being expired relative to some validators' local state.

## Impact Explanation

**High Severity** per Aptos bug bounty criteria:

1. **Validator Node Slowdowns (High)**: Validators with lower certified_timestamps cannot execute blocks, becoming stuck in an infinite retry loop. This directly matches the "Validator Node Slowdowns" category in the Aptos bug bounty program, which is classified as High severity.

2. **Consensus Liveness Impact**: If enough validators are behind during network partition or high latency, consensus cannot proceed efficiently as multiple validators cannot execute the proposed blocks, leading to temporary liveness degradation.

3. **Protocol Violation**: Breaks the invariant that all honest validators should be able to execute the same valid blocks deterministically. Different validators succeed or fail at executing identical blocks based solely on their certified_timestamp divergence, not on the block's inherent validity.

4. **Non-Deterministic Execution**: Whether a validator can execute a block depends on which peers it queries and their sync state, violating deterministic execution guarantees.

This does not constitute Critical severity because:
- No direct fund loss or theft
- No permanent network partition (validators eventually catch up)
- No state corruption (execution fails cleanly rather than producing wrong state)
- Temporary rather than permanent liveness impact

## Likelihood Explanation

**High Likelihood:**

- Network partitions and sync lag occur naturally in distributed systems, especially in geographically distributed validator sets
- Validators routinely operate at different sync states during normal operation, particularly after:
  - Brief network disconnections
  - High network latency periods
  - Validator restarts
  - Temporary infrastructure issues
- No malicious behavior or attacker required - happens through natural network conditions
- The vulnerability triggers whenever:
  - A block references a batch that some validators have already deleted due to higher certified_timestamp
  - The requesting validator queries a validator with higher certified_timestamp
  - This is a common occurrence during network latency spikes, partition recovery, or normal validator operations

## Recommendation

Modify the batch request mechanism to include the block timestamp context:

1. **Update `request_batch` signature** to accept the block timestamp being executed, not just the batch expiration
2. **Pass block timestamp** from the payload manager through to the batch requester
3. **Modify expiration check** in batch_requester.rs to compare against block timestamp instead of responder's certified_timestamp:
   - Current: `ledger_info.timestamp_usecs() > expiration`
   - Proposed: `block_timestamp > expiration` (check locally before requesting)
   - For `NotFound` responses: Only short-circuit if the ledger_info proves the batch could not have existed at the block's timestamp (e.g., ledger_info epoch > block epoch)

4. **Alternative approach**: Include block timestamp in `BatchRequest` message so responders can make informed decisions about whether to return NotFound based on the execution context

## Proof of Concept

While no explicit executable PoC is provided, the vulnerability is clearly demonstrated through the code analysis showing:

1. The exact execution path from block execution through batch request to the expiration check
2. Test cases confirming the short-circuit behavior when ledger_info timestamp > batch expiration
3. The infinite retry loop in the pipeline builder when batch retrieval fails
4. Clear scenario showing how natural network conditions (sync lag) trigger the issue

The vulnerability can be reproduced by:
1. Creating a network partition between validators
2. Allowing some validators to progress ahead (higher certified_timestamp)
3. Proposing a block with a batch that has been deleted by ahead validators but is still valid for the block timestamp
4. Observing behind validators enter infinite retry loop attempting to execute the block

## Notes

This is a protocol-level design flaw in the batch expiration validation logic, not a network DoS attack. The issue arises from confusing "local expiration state" (based on a validator's current certified_timestamp) with "global validity for a specific block" (based on the block's timestamp). The fix requires threading block timestamp context through the batch request flow to enable correct validity assessment.

### Citations

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L417-418)
```rust
                    match aptos_db_clone.get_latest_ledger_info() {
                        Ok(ledger_info) => BatchResponse::NotFound(ledger_info),
```

**File:** consensus/src/quorum_store/batch_requester.rs (L101-107)
```rust
    pub(crate) async fn request_batch(
        &self,
        digest: HashValue,
        expiration: u64,
        responders: Arc<Mutex<BTreeSet<PeerId>>>,
        mut subscriber_rx: oneshot::Receiver<PersistedValue<BatchInfoExt>>,
    ) -> ExecutorResult<Vec<SignedTransaction>> {
```

**File:** consensus/src/quorum_store/batch_requester.rs (L142-151)
```rust
                            Ok(BatchResponse::NotFound(ledger_info)) => {
                                counters::RECEIVED_BATCH_NOT_FOUND_COUNT.inc();
                                if ledger_info.commit_info().epoch() == epoch
                                    && ledger_info.commit_info().timestamp_usecs() > expiration
                                    && ledger_info.verify_signatures(&validator_verifier).is_ok()
                                {
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
                                }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L102-103)
```rust
            if block_timestamp <= batch_info.expiration() {
                futures.push(batch_reader.get_batch(batch_info, responders.clone()));
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L168-170)
```rust
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>) {
        self.batch_reader
            .update_certified_timestamp(block_timestamp);
```

**File:** consensus/src/quorum_store/batch_store.rs (L419-438)
```rust
    pub(crate) fn save(&self, value: &PersistedValue<BatchInfoExt>) -> anyhow::Result<bool> {
        let last_certified_time = self.last_certified_time();
        if value.expiration() > last_certified_time {
            fail_point!("quorum_store::save", |_| {
                // Skip caching and storing value to the db
                Ok(false)
            });
            counters::GAP_BETWEEN_BATCH_EXPIRATION_AND_CURRENT_TIME_WHEN_SAVE.observe(
                Duration::from_micros(value.expiration() - last_certified_time).as_secs_f64(),
            );

            return self.insert_to_cache(value);
        }
        counters::NUM_BATCH_EXPIRED_WHEN_SAVE.inc();
        bail!(
            "Incorrect expiration {} in epoch {}, last committed timestamp {}",
            value.expiration(),
            self.epoch(),
            last_certified_time,
        );
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-471)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
        let mut ret = Vec::new();
        for h in expired_digests {
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
            // No longer holding the lock on db_cache entry.
            if let Some(value) = removed_value {
                self.free_quota(value);
                ret.push(h);
            }
        }
        ret
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-539)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L696-702)
```rust
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```

**File:** consensus/src/quorum_store/tests/batch_requester_test.rs (L234-277)
```rust
#[tokio::test]
async fn test_batch_request_not_exists_expired() {
    let retry_interval_ms = 1_000;
    let expiration = 10_000;

    // Batch has expired according to the ledger info that will be returned
    let (ledger_info_with_signatures, validator_verifier) =
        create_ledger_info_with_timestamp(expiration + 1);

    let batch = Batch::new(
        BatchId::new_for_test(1),
        vec![],
        1,
        expiration,
        AccountAddress::random(),
        0,
    );
    let batch_response = BatchResponse::NotFound(ledger_info_with_signatures);
    let batch_requester = BatchRequester::new(
        1,
        AccountAddress::random(),
        1,
        2,
        retry_interval_ms,
        1_000,
        MockBatchRequester::new(batch_response),
        validator_verifier.into(),
    );

    let request_start = Instant::now();
    let (_, subscriber_rx) = oneshot::channel();
    let result = batch_requester
        .request_batch(
            *batch.digest(),
            batch.expiration(),
            Arc::new(Mutex::new(btreeset![AccountAddress::random()])),
            subscriber_rx,
        )
        .await;
    let request_duration = request_start.elapsed();
    assert_err!(result);
    // No retry because of short-circuiting of expired batch
    assert!(request_duration < Duration::from_millis(retry_interval_ms as u64));
}
```
