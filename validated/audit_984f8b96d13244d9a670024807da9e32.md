# Audit Report

## Title
Timeout Vote Flooding Enables Validator Resource Exhaustion Through Missing Pre-Verification Duplicate Detection

## Summary
Byzantine validators can flood duplicate timeout vote messages (both `VoteMsg` with timeouts and `RoundTimeoutMsg`) to cause resource exhaustion on honest validators. The consensus layer performs expensive BLS signature verification **before** checking for duplicate messages from the same author, allowing a single Byzantine validator to consume disproportionate CPU resources without contributing additional signatures to consensus.

## Finding Description

The Aptos consensus protocol has two timeout message paths that both suffer from the same architectural flaw: signature verification occurs before duplicate message detection.

**Path 1: VoteMsg with Timeout**

When a timeout vote is broadcast via `broadcast_timeout_vote()`, the processing flow is:
1. Message arrives and is converted to `UnverifiedEvent::VoteMsg` [1](#0-0) 
2. Signature verification occurs in `UnverifiedEvent::verify()` which calls `VoteMsg::verify()` [2](#0-1) 
3. This performs expensive cryptographic verification via `self.vote().verify(validator)` [3](#0-2) 
4. Only after verification, duplicate detection occurs in `insert_vote()` by checking the `author_to_vote` HashMap [4](#0-3) 

**Path 2: RoundTimeoutMsg**

When broadcast via `broadcast_round_timeout()`, the processing flow is:
1. Message converted to `UnverifiedEvent::RoundTimeoutMsg` [5](#0-4) 
2. Signature verification in `UnverifiedEvent::verify()` calls `RoundTimeoutMsg::verify()` [6](#0-5) 
3. This verifies the BLS signature via `self.round_timeout.verify(validator)` [7](#0-6) 
4. Messages are processed in `insert_round_timeout()` with NO explicit duplicate checking [8](#0-7) 
5. Only implicit deduplication via `or_insert()` in signature aggregation occurs AFTER all processing [9](#0-8) 

**Attack Mechanism:**

A Byzantine validator can exploit this by repeatedly sending timeout messages for the same round. The consensus message channel has a bounded capacity of 10 messages [10](#0-9) , but this only provides backpressure, not deduplication. The attacker can continuously send messages, each forcing expensive BLS signature verification before the duplicate is eventually discarded via `or_insert()`.

The verification occurs in spawned async tasks within a bounded executor [11](#0-10) , consuming CPU resources for each duplicate message.

## Impact Explanation

This vulnerability enables **HIGH Severity** impact per Aptos bug bounty criteria: "Validator Node Slowdowns"

**Quantified Impact:**
- **CPU Exhaustion**: BLS signature verification is the most expensive consensus operation. Forcing redundant verifications on 99 duplicate messages wastes significant computational resources
- **Consensus Delay**: Legitimate consensus messages are delayed while validators process duplicate timeout messages, reducing overall network throughput
- **Targeted Attacks**: Byzantine validators can selectively slow down specific honest validators by flooding them with duplicate messages
- **Channel Saturation**: With only 10-message capacity, an attacker can saturate the consensus message channel, creating backpressure on legitimate messages

**Important Note**: This vulnerability does NOT force unauthorized round changes because Timeout Certificate formation still requires 2f+1 unique validator signatures. The `or_insert()` pattern ensures only one signature per validator is counted [12](#0-11) . The attack vector is resource exhaustion, not consensus manipulation.

## Likelihood Explanation

**Likelihood: HIGH**

- **Low Attack Complexity**: A Byzantine validator simply needs to repeatedly call `broadcast_timeout_vote()` or `broadcast_round_timeout()` with messages for the same round
- **Within Threat Model**: Requires only a single Byzantine validator within the < 1/3 threshold allowed by BFT assumptions
- **No Special Preconditions**: Attack works during normal network operation without requiring specific timing, epoch state, or coordination
- **Valid Signatures**: The Byzantine validator signs their own messages, so signature verification succeeds, making detection difficult
- **Continuous Attack**: The FIFO channel processes messages sequentially, so the attacker can maintain continuous pressure by sending new messages as old ones are processed

## Recommendation

Implement duplicate detection **before** signature verification:

1. **Early Deduplication Cache**: Maintain a per-round cache of `(author, message_type)` pairs before verification. Check this cache in `UnverifiedEvent::verify()` before calling cryptographic verification functions.

2. **Rate Limiting per Author**: Add per-validator rate limiting for timeout messages within a single round to prevent flooding.

3. **Explicit Duplicate Check in `insert_round_timeout()`**: Add an explicit check similar to `insert_vote()` that returns `DuplicateVote` if the author has already sent a timeout message for the current round:

```rust
// In insert_round_timeout()
if self.maybe_2chain_timeout_votes
    .as_ref()
    .map_or(false, |votes| votes.partial_2chain_tc.signers().any(|s| s == &round_timeout.author()))
{
    return VoteReceptionResult::DuplicateVote;
}
```

4. **Verification Order**: Consider verifying message well-formedness (epoch, round checks) before expensive cryptographic operations.

## Proof of Concept

While a complete PoC requires a Byzantine validator node setup, the attack flow is straightforward:

```rust
// Pseudocode for Byzantine validator attack
let timeout_msg = create_round_timeout_msg(epoch, round, my_signature);

// Send 100 duplicate messages
for _ in 0..100 {
    network.broadcast_round_timeout(timeout_msg.clone()).await;
}

// Each message forces:
// 1. BLS signature verification (expensive)
// 2. Processing through insert_round_timeout()
// 3. Only the first signature retained via or_insert()
// Result: 99 wasted verifications
```

The vulnerability can be observed by monitoring `VERIFY_MSG` counter metrics with label "timeout" - a Byzantine validator flooding duplicates will cause disproportionate verification activity compared to unique signatures collected.

## Notes

This is a **protocol-level resource exhaustion vulnerability**, not a network DoS attack (which is explicitly out of scope). The attack exploits the consensus message processing logic order, using validly signed messages that the Byzantine validator is authorized to create. The distinction is critical: this is a consensus protocol bug, not a network layer attack.

### Citations

**File:** consensus/src/epoch_manager.rs (L1562-1562)
```rust
        let maybe_unverified_event = self.check_epoch(peer_id, consensus_msg).await?;
```

**File:** consensus/src/epoch_manager.rs (L1587-1622)
```rust
            self.bounded_executor
                .spawn(async move {
                    match monitor!(
                        "verify_message",
                        unverified_event.clone().verify(
                            peer_id,
                            &epoch_state.verifier,
                            &proof_cache,
                            quorum_store_enabled,
                            peer_id == my_peer_id,
                            max_num_batches,
                            max_batch_expiry_gap_usecs,
                        )
                    ) {
                        Ok(verified_event) => {
                            Self::forward_event(
                                quorum_store_msg_tx,
                                round_manager_tx,
                                buffered_proposal_tx,
                                peer_id,
                                verified_event,
                                payload_manager,
                                pending_blocks,
                            );
                        },
                        Err(e) => {
                            error!(
                                SecurityEvent::ConsensusInvalidMessage,
                                remote_peer = peer_id,
                                error = ?e,
                                unverified_event = unverified_event
                            );
                        },
                    }
                })
                .await;
```

**File:** consensus/src/round_manager.rs (L93-93)
```rust
    RoundTimeoutMsg(Box<RoundTimeoutMsg>),
```

**File:** consensus/src/round_manager.rs (L138-145)
```rust
            UnverifiedEvent::VoteMsg(v) => {
                if !self_message {
                    v.verify(peer_id, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["vote"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::VoteMsg(v)
```

**File:** consensus/src/round_manager.rs (L147-154)
```rust
            UnverifiedEvent::RoundTimeoutMsg(v) => {
                if !self_message {
                    v.verify(validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["timeout"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::RoundTimeoutMsg(v)
```

**File:** consensus/consensus-types/src/vote_msg.rs (L56-81)
```rust
    pub fn verify(&self, sender: Author, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        ensure!(
            self.vote().author() == sender,
            "Vote author {:?} is different from the sender {:?}",
            self.vote().author(),
            sender,
        );
        ensure!(
            self.vote().epoch() == self.sync_info.epoch(),
            "VoteMsg has different epoch"
        );
        ensure!(
            self.vote().vote_data().proposed().round() > self.sync_info.highest_round(),
            "Vote Round should be higher than SyncInfo"
        );
        if let Some((timeout, _)) = self.vote().two_chain_timeout() {
            ensure!(
                timeout.hqc_round() <= self.sync_info.highest_certified_round(),
                "2-chain Timeout hqc should be less or equal than the sync info hqc"
            );
        }
        // We're not verifying SyncInfo here yet: we are going to verify it only in case we need
        // it. This way we avoid verifying O(n) SyncInfo messages while aggregating the votes
        // (O(n^2) signature verifications).
        self.vote().verify(validator)
    }
```

**File:** consensus/src/pending_votes.rs (L190-271)
```rust
    pub fn insert_round_timeout(
        &mut self,
        round_timeout: &RoundTimeout,
        validator_verifier: &ValidatorVerifier,
    ) -> VoteReceptionResult {
        //
        // Let's check if we can create a TC
        //

        let timeout = round_timeout.two_chain_timeout();
        let signature = round_timeout.signature();

        let validator_voting_power = validator_verifier
            .get_voting_power(&round_timeout.author())
            .unwrap_or(0);
        if validator_voting_power == 0 {
            warn!(
                "Received vote with no voting power, from {}",
                round_timeout.author()
            );
        }
        let cur_epoch = round_timeout.epoch();
        let cur_round = round_timeout.round();

        counters::CONSENSUS_CURRENT_ROUND_TIMEOUT_VOTED_POWER
            .with_label_values(&[&round_timeout.author().to_string()])
            .set(validator_voting_power as f64);
        counters::CONSENSUS_LAST_TIMEOUT_VOTE_EPOCH
            .with_label_values(&[&round_timeout.author().to_string()])
            .set(cur_epoch as i64);
        counters::CONSENSUS_LAST_TIMEOUT_VOTE_ROUND
            .with_label_values(&[&round_timeout.author().to_string()])
            .set(cur_round as i64);

        let two_chain_votes = self
            .maybe_2chain_timeout_votes
            .get_or_insert_with(|| TwoChainTimeoutVotes::new(timeout.clone()));
        two_chain_votes.add(
            round_timeout.author(),
            timeout.clone(),
            signature.clone(),
            round_timeout.reason().clone(),
        );

        let partial_tc = two_chain_votes.partial_2chain_tc_mut();
        let tc_voting_power =
            match validator_verifier.check_voting_power(partial_tc.signers(), true) {
                Ok(_) => {
                    return match partial_tc.aggregate_signatures(validator_verifier) {
                        Ok(tc_with_sig) => {
                            VoteReceptionResult::New2ChainTimeoutCertificate(Arc::new(tc_with_sig))
                        },
                        Err(e) => VoteReceptionResult::ErrorAggregatingTimeoutCertificate(e),
                    };
                },
                Err(VerifyError::TooLittleVotingPower { voting_power, .. }) => voting_power,
                Err(error) => {
                    error!(
                        "MUST_FIX: 2-chain timeout vote received could not be added: {}, vote: {}",
                        error, timeout
                    );
                    return VoteReceptionResult::ErrorAddingVote(error);
                },
            };

        // Echo timeout if receive f+1 timeout message.
        if !self.echo_timeout {
            let f_plus_one = validator_verifier.total_voting_power()
                - validator_verifier.quorum_voting_power()
                + 1;
            if tc_voting_power >= f_plus_one {
                self.echo_timeout = true;
                return VoteReceptionResult::EchoTimeout(tc_voting_power);
            }
        }

        //
        // No TC could be formed, return the TC's voting power
        //

        VoteReceptionResult::VoteAdded(tc_voting_power)
    }
```

**File:** consensus/src/pending_votes.rs (L287-296)
```rust
        if let Some((previously_seen_vote, previous_li_digest)) =
            self.author_to_vote.get(&vote.author())
        {
            // is it the same vote?
            if &li_digest == previous_li_digest {
                // we've already seen an equivalent vote before
                let new_timeout_vote = vote.is_timeout() && !previously_seen_vote.is_timeout();
                if !new_timeout_vote {
                    // it's not a new timeout vote
                    return VoteReceptionResult::DuplicateVote;
```

**File:** consensus/consensus-types/src/round_timeout.rs (L153-171)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        ensure!(
            self.round_timeout.epoch() == self.sync_info.epoch(),
            "RoundTimeoutV2Msg has different epoch"
        );
        ensure!(
            self.round_timeout.round() > self.sync_info.highest_round(),
            "Timeout Round should be higher than SyncInfo"
        );
        ensure!(
            self.round_timeout.two_chain_timeout().hqc_round()
                <= self.sync_info.highest_certified_round(),
            "2-chain Timeout hqc should be less or equal than the sync info hqc"
        );
        // We're not verifying SyncInfo here yet: we are going to verify it only in case we need
        // it. This way we avoid verifying O(n) SyncInfo messages while aggregating the votes
        // (O(n^2) signature verifications).
        self.round_timeout.verify(validator)
    }
```

**File:** consensus/consensus-types/src/timeout_2chain.rs (L320-329)
```rust
    pub fn add_signature(
        &mut self,
        validator: AccountAddress,
        round: Round,
        signature: bls12381::Signature,
    ) {
        self.signatures
            .entry(validator)
            .or_insert((round, signature));
    }
```

**File:** consensus/src/network.rs (L757-760)
```rust
        let (consensus_messages_tx, consensus_messages) = aptos_channel::new(
            QueueStyle::FIFO,
            10,
            Some(&counters::CONSENSUS_CHANNEL_MSGS),
```
