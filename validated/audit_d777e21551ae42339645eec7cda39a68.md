# Audit Report

## Title
Race Condition in Randomness Share Aggregation Causes Validator Crash via unreachable!() Panic

## Summary
A race condition exists in the consensus randomness generation subsystem where `RandItem::get_all_shares_authors()` can be called on a `PendingMetadata` state item, triggering an `unreachable!()` panic that crashes validator nodes. This occurs when a reset operation clears round state while an asynchronous share aggregation task is pending, followed by arrival of new shares that recreate the item in the wrong state.

## Finding Description

The vulnerability exists in the interaction between three components in the randomness generation pipeline.

The `get_all_shares_authors()` function assumes it will only be called when a `RandItem` is in `PendingDecision` or `Decided` state, not `PendingMetadata`. When called on `PendingMetadata`, it triggers `unreachable!()` which causes a panic. [1](#0-0) 

The function is called from an asynchronous task spawned in `RandManager`. [2](#0-1) 

This task sleeps for 300ms before querying share authors. [3](#0-2)  During this window, a race condition can occur:

**Race Condition Sequence:**

1. **T0: Metadata Addition** - When a block is processed, `process_incoming_metadata` adds randomness metadata to the store [4](#0-3) , which transitions the `RandItem` from `PendingMetadata` to `PendingDecision` state [5](#0-4)  and spawns the aggregation task.

2. **T0+100ms: Reset Triggered** - A reset operation (due to state sync or epoch transition) is processed [6](#0-5) , which clears the round state. [7](#0-6) 

3. **T0+200ms: Share Arrives** - A randomness share arrives from a peer validator for the reset round. The `add_share` function creates a new `RandItem` in `PendingMetadata` state if the entry doesn't exist. [8](#0-7) 

4. **T0+300ms: Task Executes** - The spawned task wakes up and calls `get_all_shares_authors()` on line 275. The `RandItem` is now in `PendingMetadata` state (from step 3), triggering the `unreachable!()` panic.

**Why the Race is Possible:**

The validation in `add_share` allows shares for a wide range of rounds. [9](#0-8)  Shares can be accepted for rounds up to `highest_known_round + 200`. [10](#0-9)  After a reset updates `highest_known_round`, incoming shares for reset rounds can still pass validation and recreate the item in the wrong state.

The spawned task is wrapped in `Abortable` [11](#0-10) , but the abort only takes effect at the next `.await` point. Between line 274 (sleep completes) and line 290 (next await), the task executes synchronously and cannot be interrupted, creating a window where the panic can occur.

## Impact Explanation

**Severity: HIGH** (Validator node crashes)

This vulnerability causes validator nodes to panic and crash, directly impacting network availability and liveness:

1. **Validator Downtime**: The panic causes the validator process to crash, requiring a restart. During this time, the validator cannot participate in consensus.

2. **Consensus Liveness Impact**: If multiple validators experience this race condition simultaneously (likely during network healing after partitions), it could temporarily reduce the number of active validators below the threshold needed for consensus progress.

3. **Repeatability**: The crash can occur repeatedly if the timing conditions persist, especially during state sync operations where resets are frequent.

This meets the **High Severity** criteria per the Aptos bug bounty program:
- "Validator node slowdowns" (crashes are worse than slowdowns)
- "API crashes" 
- "Significant protocol violations" (availability violation)

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

This vulnerability can trigger naturally during normal operations without requiring any malicious action:

**Triggering Conditions:**
1. A validator processes blocks and spawns share aggregation tasks
2. The validator experiences a reset (common during state sync or catching up after downtime)
3. Other validators continue broadcasting shares for rounds being reset
4. Network timing aligns such that shares arrive during the 300ms window after reset

**Common Scenarios:**
- **State Synchronization**: When a validator falls behind and syncs to a target round [12](#0-11) 
- **Network Partitions**: When a validator reconnects after a partition, it receives delayed shares while also processing resets
- **High Network Latency**: Increased likelihood when network delays cause shares to arrive out of order

**No Attacker Required**: This is a pure race condition bug that occurs during legitimate consensus operations. An attacker could potentially increase likelihood by strategically timing share broadcasts, but this is not necessary for exploitation.

## Recommendation

The issue can be fixed by ensuring that `get_all_shares_authors()` handles the `PendingMetadata` state gracefully instead of using `unreachable!()`. Options include:

1. Return `None` for `PendingMetadata` state, indicating shares aren't yet ready
2. Check the item state before calling `get_all_shares_authors()` in the task
3. Store the round's abort handle and check if it was aborted before proceeding
4. Validate that the item is in the expected state before querying share authors

## Proof of Concept

A proof of concept would involve:
1. Setting up a validator node with randomness generation enabled
2. Processing blocks to spawn share aggregation tasks
3. Triggering a reset operation via state sync
4. Simulating delayed share arrivals during the 300ms window
5. Observing the `unreachable!()` panic when the task queries a recreated `PendingMetadata` item

The race condition can be reproduced by instrumenting the code with delays or using tools like `tokio-console` to observe task scheduling during state sync operations.

## Notes

This vulnerability demonstrates a classic race condition between asynchronous task execution and state management. The use of `unreachable!()` as an assertion that should "never happen" became exploitable due to the timing window created by the 300ms sleep and the state reset mechanism. The fix requires either more defensive programming (handling all enum variants) or stronger invariants (preventing the problematic state transitions entirely).

### Citations

**File:** consensus/src/rand/rand_gen/rand_store.rs (L180-193)
```rust
    fn add_metadata(&mut self, rand_config: &RandConfig, rand_metadata: FullRandMetadata) {
        let item = std::mem::replace(self, Self::new(Author::ONE, PathType::Slow));
        let new_item = match item {
            RandItem::PendingMetadata(mut share_aggregator) => {
                share_aggregator.retain(rand_config, &rand_metadata);
                Self::PendingDecision {
                    metadata: rand_metadata,
                    share_aggregator,
                }
            },
            item @ (RandItem::PendingDecision { .. } | RandItem::Decided { .. }) => item,
        };
        let _ = std::mem::replace(self, new_item);
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L195-205)
```rust
    fn get_all_shares_authors(&self) -> Option<HashSet<Author>> {
        match self {
            RandItem::PendingDecision {
                share_aggregator, ..
            } => Some(share_aggregator.shares.keys().cloned().collect()),
            RandItem::Decided { .. } => None,
            RandItem::PendingMetadata(_) => {
                unreachable!("Should only be called after block is added")
            },
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-312)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
        let rand_metadata = share.metadata().clone();

        let (rand_config, rand_item) = if path == PathType::Fast {
            match (self.fast_rand_config.as_ref(), self.fast_rand_map.as_mut()) {
                (Some(fast_rand_config), Some(fast_rand_map)) => (
                    fast_rand_config,
                    fast_rand_map
                        .entry(rand_metadata.round)
                        .or_insert_with(|| RandItem::new(self.author, path)),
                ),
                _ => anyhow::bail!("Fast path not enabled"),
            }
        } else {
            (
                &self.rand_config,
                self.rand_map
                    .entry(rand_metadata.round)
                    .or_insert_with(|| RandItem::new(self.author, PathType::Slow)),
            )
        };

        rand_item.add_share(share, rand_config)?;
        rand_item.try_aggregate(rand_config, self.decision_tx.clone());
        Ok(rand_item.has_decision())
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L145-169)
```rust
    fn process_incoming_metadata(&self, metadata: FullRandMetadata) -> DropGuard {
        let self_share = S::generate(&self.config, metadata.metadata.clone());
        info!(LogSchema::new(LogEvent::BroadcastRandShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(metadata.round()));
        let mut rand_store = self.rand_store.lock();
        rand_store.update_highest_known_round(metadata.round());
        rand_store
            .add_share(self_share.clone(), PathType::Slow)
            .expect("Add self share should succeed");

        if let Some(fast_config) = &self.fast_config {
            let self_fast_share =
                FastShare::new(S::generate(fast_config, metadata.metadata.clone()));
            rand_store
                .add_share(self_fast_share.rand_share(), PathType::Fast)
                .expect("Add self share for fast path should succeed");
        }

        rand_store.add_rand_metadata(metadata.clone());
        self.network_sender
            .broadcast_without_self(RandMessage::<S, D>::Share(self_share).into_network_message());
        self.spawn_aggregate_shares_task(metadata.metadata)
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L184-194)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.rand_store.lock().reset(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L263-303)
```rust
    fn spawn_aggregate_shares_task(&self, metadata: RandMetadata) -> DropGuard {
        let rb = self.reliable_broadcast.clone();
        let aggregate_state = Arc::new(ShareAggregateState::new(
            self.rand_store.clone(),
            metadata.clone(),
            self.config.clone(),
        ));
        let epoch_state = self.epoch_state.clone();
        let round = metadata.round;
        let rand_store = self.rand_store.clone();
        let task = async move {
            tokio::time::sleep(Duration::from_millis(300)).await;
            let maybe_existing_shares = rand_store.lock().get_all_shares_authors(round);
            if let Some(existing_shares) = maybe_existing_shares {
                let epoch = epoch_state.epoch;
                let request = RequestShare::new(metadata.clone());
                let targets = epoch_state
                    .verifier
                    .get_ordered_account_addresses_iter()
                    .filter(|author| !existing_shares.contains(author))
                    .collect::<Vec<_>>();
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Start broadcasting share request for {}",
                    targets.len(),
                );
                rb.multicast(request, aggregate_state, targets)
                    .await
                    .expect("Broadcast cannot fail");
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Finish broadcasting share request",
                );
            }
        };
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(task, abort_registration));
        DropGuard::new(abort_handle)
    }
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```
