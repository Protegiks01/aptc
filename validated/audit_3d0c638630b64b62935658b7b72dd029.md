# Audit Report

## Title
Database Version Mismatch in Batch Deletion Causes Resource Exhaustion in Quorum Store

## Summary
The quorum store database uses separate column families for V1 and V2 batch schemas. Critical deletion operations fail to properly track batch versions, causing V2 batches to accumulate indefinitely in the database when `enable_batch_v2` is enabled, leading to disk space exhaustion and validator node failure.

## Finding Description

The quorum store database maintains two separate column families for batch storage: `BATCH_CF_NAME` ("batch") for V1 batches and `BATCH_V2_CF_NAME` ("batch_v2") for V2 batches. [1](#0-0) 

Two critical deletion code paths contain version mismatch bugs that prevent V2 batch cleanup:

**Bug #1 - Epoch Transition Cleanup:**

The `gc_previous_epoch_batches_from_db_v2` function reads V2 batches from the "batch_v2" column family using `get_all_batches_v2()` [2](#0-1)  but incorrectly calls `delete_batches()` (V1 deletion method) instead of `delete_batches_v2()` [3](#0-2) . This causes expired V2 batches from previous epochs to never be deleted from the database.

For comparison, the correctly implemented V2 cleanup function `populate_cache_and_gc_expired_batches_v2` properly pairs `get_all_batches_v2()` with `delete_batches_v2()` [4](#0-3) .

**Bug #2 - Normal Operation Cleanup:**

The `update_certified_timestamp` function calls `clear_expired_payload()` to identify expired batches, then calls only `delete_batches()` for database cleanup [5](#0-4) , which only deletes from the V1 column family. V2 batches are never deleted.

The `clear_expired_payload` function returns only `Vec<HashValue>` digests without version information [6](#0-5) , making it impossible to determine which deletion method should be called.

The root cause is the lack of version tracking in the deletion pipeline. When validators have `enable_batch_v2` enabled [7](#0-6) , V2 batches are created and stored in the "batch_v2" column family. However, the two deletion methods (`delete_batches()` and `delete_batches_v2()`) operate on separate column families [8](#0-7) , and the buggy deletion paths only call the V1 method.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty program criteria for "State inconsistencies requiring intervention."

**Direct Impact:**
- Database bloat: V2 batches accumulate indefinitely without cleanup
- Disk space exhaustion: Validators eventually run out of storage  
- Performance degradation: Growing database slows read/write operations
- Node crashes: Validators may fail when disk space is exhausted

**Operational Impact:**
- Requires manual intervention (database cleanup or node restart with fixed code)
- Affects all validators with `enable_batch_v2` enabled
- Can escalate to **High Severity** if it causes validator node slowdowns or availability issues

While this doesn't directly cause consensus violations or loss of funds, the resource exhaustion can lead to validator liveness failures, potentially affecting network stability if many validators are impacted simultaneously.

## Likelihood Explanation

**Likelihood: HIGH (for affected validators)**

This bug will manifest automatically on every validator running with `enable_batch_v2` enabled. No attacker action is required.

**Occurrence Frequency:**
- Epoch transition cleanup bug triggers at every epoch boundary (typically every few hours)
- Normal operation cleanup bug triggers continuously as batches expire
- Accumulation rate depends on transaction volume and batch creation rate

**Affected Systems:**
- Any validator with `enable_batch_v2 = true` in quorum store configuration
- The default configuration has this set to `false` [9](#0-8) , but validators using V2 batches are immediately affected

**Time to Impact:**
- Days to weeks depending on transaction volume
- Higher transaction rates accelerate disk space consumption

## Recommendation

**Fix for Bug #1:**
In `gc_previous_epoch_batches_from_db_v2`, change line 241 to call the correct V2 deletion method:
```rust
db.delete_batches_v2(expired_keys)  // Changed from delete_batches
    .expect("Deletion of expired keys should not fail");
```

**Fix for Bug #2:**
Modify the deletion pipeline to track batch versions:

1. Update `clear_expired_payload()` to return version information along with digests
2. Modify `update_certified_timestamp()` to call both deletion methods or track which batches are V2
3. Consider adding a version field to the cache entries or using separate caches for V1/V2

**Alternative Approach:**
Store a version flag with each digest in the expirations queue, or query the cache to determine batch version before deletion.

## Proof of Concept

This is a logic bug in the deletion paths that can be verified by code inspection. A runtime test would require:

1. Enable `enable_batch_v2 = true` in configuration
2. Run validator through an epoch transition
3. Create V2 batches during operation
4. Verify that V2 batches accumulate in the "batch_v2" column family without deletion
5. Monitor disk space growth over time

The bug is evident from the code mismatch between read and delete operations in the two identified paths.

### Citations

**File:** consensus/src/quorum_store/schema.rs (L14-16)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";
```

**File:** consensus/src/quorum_store/batch_store.rs (L213-214)
```rust
        let db_content = db
            .get_all_batches_v2()
```

**File:** consensus/src/quorum_store/batch_store.rs (L241-242)
```rust
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
```

**File:** consensus/src/quorum_store/batch_store.rs (L332-334)
```rust
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-471)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
        let mut ret = Vec::new();
        for h in expired_digests {
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
            // No longer holding the lock on db_cache entry.
            if let Some(value) = removed_value {
                self.free_quota(value);
                ret.push(h);
            }
        }
        ret
```

**File:** consensus/src/quorum_store/batch_store.rs (L535-537)
```rust
        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
```

**File:** config/src/config/quorum_store_config.rs (L102-102)
```rust
    pub enable_batch_v2: bool,
```

**File:** config/src/config/quorum_store_config.rs (L144-144)
```rust
            enable_batch_v2: false,
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L93-131)
```rust
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }

    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>> {
        let mut iter = self.db.iter::<BatchSchema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfo>>>>()
    }

    fn save_batch(&self, batch: PersistedValue<BatchInfo>) -> Result<(), DbError> {
        trace!(
            "QS: db persists digest {} expiration {:?}",
            batch.digest(),
            batch.expiration()
        );
        self.put::<BatchSchema>(batch.digest(), &batch)
    }

    fn get_batch(&self, digest: &HashValue) -> Result<Option<PersistedValue<BatchInfo>>, DbError> {
        Ok(self.db.get::<BatchSchema>(digest)?)
    }

    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```
