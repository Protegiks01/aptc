Based on my comprehensive analysis of the Aptos Core codebase, I have validated this security claim and found it to be **VALID**. The vulnerability exists as described.

# Audit Report

## Title
DKG Transcript Deserialization CPU Exhaustion DoS

## Summary
The DKG transcript deserialization process lacks size validation before performing expensive BLS12-381 elliptic curve point validation, allowing a malicious validator to cause CPU exhaustion on all other validators during proposal validation.

## Finding Description

The vulnerability exists in the DKG transcript verification flow where deserialization occurs without pre-validation of vector sizes. When a validator proposes a block containing a `DKGTranscript`, all other validators must verify it during proposal processing.

**Critical Code Path:**

1. During proposal validation, `vtxn.verify()` is called synchronously in the consensus layer. [1](#0-0) 

2. This triggers `DKGTranscript::verify()` which immediately deserializes the transcript_bytes without any size pre-validation. [2](#0-1) 

3. The underlying `Transcript` structure contains multiple vectors of BLS12-381 elliptic curve points (R, R_hat, V, V_hat, C). [3](#0-2) 

4. The `try_from()` implementation performs BCS deserialization which includes expensive point validation by calling `GroupEncoding::from_bytes` for each point, as explicitly noted in the code comment. [4](#0-3) 

5. Size validation via `check_sizes()` only occurs AFTER complete deserialization during the `verify()` call. [5](#0-4) 

6. The 2MB validator transaction size limit is enforced but only AFTER the expensive `vtxn.verify()` operation completes. [6](#0-5) [7](#0-6) 

**Attack Mechanism:**

A malicious validator can craft a `DKGTranscript` containing the maximum number of BLS12-381 points within the 2MB limit. Based on gas costs, G2 point validation takes approximately 37 microseconds, and G1 point validation takes approximately 18.5 microseconds. With 2MB allowing ~21,845 G2Projective points (96 bytes compressed) or ~42,666 G1Projective points (48 bytes compressed), this results in substantial CPU time wasted on all validators before the malformed transcript is rejected.

## Impact Explanation

**Severity: Medium** per Aptos Bug Bounty categories.

This vulnerability causes temporary validator node slowdowns through CPU resource exhaustion:
- Synchronous blocking operation during proposal validation
- All validators in the network affected simultaneously when processing the malicious proposal
- Estimated processing time of 0.8-4 seconds per validator depending on hardware and exact payload
- Could potentially cause validators to miss consensus deadlines during the affected round
- Repeatable attack vector during each round when the malicious validator is selected as proposer

This qualifies as MEDIUM (not HIGH) severity because:
- Does not cause permanent validator unavailability or crashes
- Does not violate consensus safety guarantees (Byzantine fault tolerance remains intact)
- System automatically recovers after rejecting the malicious proposal
- Impact is temporally limited to the malicious validator's proposer rounds
- The malicious validator can be identified (proposals are signed) and potentially removed through governance

## Likelihood Explanation

**Likelihood: Medium**

The attack requires:
- Attacker must be an active validator with stake (untrusted role under <1/3 Byzantine assumption)
- Attack only executable when the malicious validator is selected as block proposer
- Attack is repeatable during each of their proposer rounds

Mitigating factors:
- Malicious validator is identifiable through proposal signatures
- Potential for slashing or governance-based removal
- 2MB size limit bounds the maximum impact per attack instance
- Economic disincentive from potential validator removal

## Recommendation

Implement size validation before deserialization to prevent expensive cryptographic operations on oversized payloads:

```rust
// In types/src/dkg/mod.rs, modify verify() method:
pub(crate) fn verify(&self, verifier: &ValidatorVerifier) -> Result<()> {
    // Add early size check before deserialization
    ensure!(
        self.transcript_bytes.len() <= MAX_REASONABLE_TRANSCRIPT_SIZE,
        "Transcript bytes exceed maximum reasonable size"
    );
    
    let transcripts: Transcripts = bcs::from_bytes(&self.transcript_bytes)
        .context("Transcripts deserialization failed")?;
    RealDKG::verify_transcript_extra(&transcripts, verifier, true, None)
}
```

Where `MAX_REASONABLE_TRANSCRIPT_SIZE` is calculated based on the maximum expected validator set size and reasonable DKG parameters, well below the 2MB limit.

Alternatively, implement streaming validation or early-exit checks during deserialization to bound CPU time.

## Proof of Concept

The vulnerability can be demonstrated by creating a malicious validator that proposes blocks with oversized DKGTranscripts:

```rust
// Conceptual PoC - requires full test harness
#[test]
fn test_dkg_transcript_dos() {
    // 1. Create a DKGTranscript with maximum-sized vectors within 2MB limit
    // 2. Wrap in ValidatorTransaction::DKGResult
    // 3. Propose block containing the malicious transcript
    // 4. Measure CPU time spent by other validators during verify()
    // 5. Verify proposal is rejected but significant CPU time was consumed
    
    // Expected: Multiple seconds of CPU time wasted before rejection
    // Actual protection: Only post-deserialization size checks exist
}
```

A full PoC would require setting up a test validator network and instrumenting the verification path with timing measurements to demonstrate the CPU exhaustion.

### Citations

**File:** consensus/src/round_manager.rs (L1134-1135)
```rust
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
```

**File:** consensus/src/round_manager.rs (L1172-1177)
```rust
        ensure!(
            validator_txns_total_bytes <= vtxn_bytes_limit,
            "process_proposal failed with per-block vtxn bytes limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_total_bytes(),
            validator_txns_total_bytes
        );
```

**File:** types/src/dkg/mod.rs (L83-87)
```rust
    pub(crate) fn verify(&self, verifier: &ValidatorVerifier) -> Result<()> {
        let transcripts: Transcripts = bcs::from_bytes(&self.transcript_bytes)
            .context("Transcripts deserialization failed")?;
        RealDKG::verify_transcript_extra(&transcripts, verifier, true, None)
    }
```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L48-72)
```rust
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, BCSCryptoHash, CryptoHasher)]
#[allow(non_snake_case)]
pub struct Transcript {
    /// Proofs-of-knowledge (PoKs) for the dealt secret committed in $c = g_2^{p(0)}$.
    /// Since the transcript could have been aggregated from other transcripts with their own
    /// committed secrets in $c_i = g_2^{p_i(0)}$, this is a vector of PoKs for all these $c_i$'s
    /// such that $\prod_i c_i = c$.
    ///
    /// Also contains BLS signatures from each player $i$ on that player's contribution $c_i$, the
    /// player ID $i$ and auxiliary information `aux[i]` provided during dealing.
    soks: Vec<SoK<G1Projective>>,
    /// Commitment to encryption randomness $g_1^{r_j} \in G_1, \forall j \in [W]$
    R: Vec<G1Projective>,
    /// Same as $R$ except uses $g_2$.
    R_hat: Vec<G2Projective>,
    /// First $W$ elements are commitments to the evaluations of $p(X)$: $g_1^{p(\omega^i)}$,
    /// where $i \in [W]$. Last element is $g_1^{p(0)}$ (i.e., the dealt public key).
    V: Vec<G1Projective>,
    /// Same as $V$ except uses $g_2$.
    V_hat: Vec<G2Projective>,
    /// ElGamal encryption of the $j$th share of player $i$:
    /// i.e., $C[s_i+j-1] = h_1^{p(\omega^{s_i + j - 1})} ek_i^{r_j}, \forall i \in [n], j \in [w_i]$.
    /// We sometimes denote $C[s_i+j-1]$ by C_{i, j}.
    C: Vec<G1Projective>,
}
```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L82-90)
```rust
impl TryFrom<&[u8]> for Transcript {
    type Error = CryptoMaterialError;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        // NOTE: The `serde` implementation in `blstrs` already performs the necessary point validation
        // by ultimately calling `GroupEncoding::from_bytes`.
        bcs::from_bytes::<Transcript>(bytes).map_err(|_| CryptoMaterialError::DeserializationError)
    }
}
```

**File:** crates/aptos-dkg/src/pvss/das/weighted_protocol.rs (L415-455)
```rust
    fn check_sizes(&self, sc: &WeightedConfigBlstrs) -> anyhow::Result<()> {
        let W = sc.get_total_weight();

        if self.V.len() != W + 1 {
            bail!(
                "Expected {} G_2 (polynomial) commitment elements, but got {}",
                W + 1,
                self.V.len()
            );
        }

        if self.V_hat.len() != W + 1 {
            bail!(
                "Expected {} G_2 (polynomial) commitment elements, but got {}",
                W + 1,
                self.V_hat.len()
            );
        }

        if self.R.len() != W {
            bail!(
                "Expected {} G_1 commitment(s) to ElGamal randomness, but got {}",
                W,
                self.R.len()
            );
        }

        if self.R_hat.len() != W {
            bail!(
                "Expected {} G_2 commitment(s) to ElGamal randomness, but got {}",
                W,
                self.R_hat.len()
            );
        }

        if self.C.len() != W {
            bail!("Expected C of length {}, but got {}", W, self.C.len());
        }

        Ok(())
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L126-126)
```rust
const VTXN_CONFIG_PER_BLOCK_LIMIT_TOTAL_BYTES_DEFAULT: u64 = 2097152; //2MB
```
