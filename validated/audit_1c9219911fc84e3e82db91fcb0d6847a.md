# Audit Report

## Title
Race Condition Between BlockExecutor State Sync and Consensus Operations Causes Validator Panics

## Summary
The `BlockExecutor` contains a Time-Of-Check-Time-Of-Use (TOCTOU) race condition where the `finish()` method (called during state synchronization) can set the internal `inner` field to `None` between the `maybe_initialize()` check and subsequent field access in concurrent consensus operations. This causes validator processes to panic with "BlockExecutor is not reset" and crash, requiring manual restart.

## Finding Description

The `BlockExecutor` struct manages its state using an `inner` field of type `RwLock<Option<BlockExecutorInner<V>>>`. [1](#0-0) 

During state synchronization, the `ExecutionProxy` calls `finish()` to release memory before syncing, as documented in the code comments. [2](#0-1) [3](#0-2) 

The `finish()` method sets `inner` to `None` by acquiring a write lock: [4](#0-3) 

Multiple BlockExecutor methods follow a vulnerable pattern where they call `maybe_initialize()` and then immediately access `inner`:

**`committed_block_id()`**: [5](#0-4) 

**`execute_and_update_state()`**: [6](#0-5) 

**`state_view()`**: [7](#0-6) 

**`pre_commit_block()`**: [8](#0-7) 

**`commit_ledger()`**: [9](#0-8) 

The `maybe_initialize()` method checks if `inner` is `None` and calls `reset()` if needed, but critically releases the read lock between the check and return: [10](#0-9) 

**The Race Condition Execution:**

Thread A (consensus pipeline via `spawn_blocking`):
- Calls a BlockExecutor method like `committed_block_id()`
- Executes `maybe_initialize()` successfully - acquires read lock, checks that `inner` is `Some(...)`, releases lock
- Returns from `maybe_initialize()`

Thread B (state sync):
- ExecutionProxy's sync methods acquire the write_mutex and call `finish()`
- Acquires write lock on `inner` and sets it to `None`
- Releases write lock

Thread A (continued):
- Acquires read lock at `self.inner.read()`
- Calls `.as_ref()` which returns `None` because Thread B nullified it
- Calls `.expect("BlockExecutor is not reset")` â†’ **PANIC**
- The panic handler terminates the validator process

The consensus pipeline uses `spawn_blocking` to execute these methods: [11](#0-10) [12](#0-11) [13](#0-12) [14](#0-13) 

**Lack of Synchronization:**

The `execution_lock` mutex only protects the execution phase itself, acquired inside `execute_and_update_state()`, not the initialization check: [15](#0-14) 

The `write_mutex` in ExecutionProxy only serializes state sync operations (held during `sync_for_duration` and `sync_to_target`), but consensus pipeline operations directly call the executor without acquiring this mutex: [16](#0-15) [17](#0-16) 

When a panic occurs, the crash handler terminates the validator process: [18](#0-17) [19](#0-18) 

## Impact Explanation

**HIGH Severity** per Aptos bug bounty program criteria:

1. **Validator Node Crashes**: The panic causes immediate validator process termination (exit code 12), directly matching the "API crashes" criterion for HIGH severity impacts in the Aptos bug bounty program.

2. **Network Liveness Risk**: When multiple validators synchronize simultaneously (common after network partitions or during catch-up periods), multiple validators can crash concurrently, potentially affecting consensus liveness if sufficient validators are impacted.

3. **Consensus Participation Loss**: Crashed validators cannot participate in block voting or proposal, temporarily reducing network capacity until manual operator intervention restarts them.

4. **Natural Trigger**: This occurs during normal validator operations without requiring any malicious activity - any time a validator needs to state sync while the consensus pipeline is actively processing blocks through `spawn_blocking` tasks.

The race window is narrow but real, and the consequence is severe: complete validator process termination requiring manual operator intervention to restart.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

The vulnerability triggers when three conditions align:
1. A validator falls behind and initiates state sync (frequent occurrence)
2. Consensus pipeline is concurrently processing blocks (continuous during normal operation)
3. The timing window between `maybe_initialize()` completion and `inner` access is hit

**Factors increasing likelihood:**
- State synchronization is a routine operation for validators catching up after downtime or network issues
- The consensus pipeline runs continuously through `spawn_blocking` tasks that cannot be cancelled mid-execution
- Multiple BlockExecutor methods share this vulnerable pattern (`committed_block_id`, `execute_and_update_state`, `state_view`, `pre_commit_block`, `commit_ledger`), creating multiple attack surfaces
- No synchronization mechanism prevents concurrent execution of state sync and consensus operations
- The `execution_lock` only protects the execution phase, not other operations

The vulnerability requires no attacker involvement and occurs naturally during normal validator operations, making it particularly concerning for network reliability.

## Recommendation

Implement atomic initialization checking by holding the lock across both the check and usage. One approach:

```rust
fn committed_block_id(&self) -> HashValue {
    let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "committed_block_id"]);
    
    self.maybe_initialize().expect("Failed to initialize.");
    
    // Hold the lock across the entire operation
    let inner_guard = self.inner.read();
    inner_guard
        .as_ref()
        .expect("BlockExecutor is not reset")
        .committed_block_id()
}
```

Alternatively, use a single atomic operation that checks and accesses in one critical section, or implement proper synchronization between state sync and consensus operations using a shared mutex that both paths acquire.

## Proof of Concept

To reproduce this race condition:

1. Set up a validator node that is slightly behind the network
2. Trigger state sync while the consensus pipeline is actively processing blocks
3. The race window between `maybe_initialize()` and `inner` access in methods like `committed_block_id()` can be hit
4. When hit, the validator will panic with "BlockExecutor is not reset" and crash with exit code 12

A stress test could be created that repeatedly triggers state sync while continuously calling BlockExecutor methods from `spawn_blocking` tasks to increase the likelihood of hitting the race window.

## Notes

This is a classic TOCTOU (Time-Of-Check-Time-Of-Use) race condition in concurrent code. The vulnerability exists because the read lock acquired in `maybe_initialize()` is released before the subsequent access to `inner`, creating a window where another thread can modify the state. The fact that `spawn_blocking` tasks cannot be cancelled makes this race more likely to occur during state sync operations, as consensus tasks continue running even when state sync begins.

### Citations

**File:** execution/executor/src/block_executor/mod.rs (L49-53)
```rust
pub struct BlockExecutor<V> {
    pub db: DbReaderWriter,
    inner: RwLock<Option<BlockExecutorInner<V>>>,
    execution_lock: Mutex<()>,
}
```

**File:** execution/executor/src/block_executor/mod.rs (L67-72)
```rust
    fn maybe_initialize(&self) -> Result<()> {
        if self.inner.read().is_none() {
            self.reset()?;
        }
        Ok(())
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L79-88)
```rust
    fn committed_block_id(&self) -> HashValue {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "committed_block_id"]);

        self.maybe_initialize().expect("Failed to initialize.");
        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .committed_block_id()
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L97-113)
```rust
    fn execute_and_update_state(
        &self,
        block: ExecutableBlock,
        parent_block_id: HashValue,
        onchain_config: BlockExecutorConfigFromOnchain,
    ) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "execute_and_state_checkpoint"]);

        self.maybe_initialize()?;
        // guarantee only one block being executed at a time
        let _guard = self.execution_lock.lock();
        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .execute_and_update_state(block, parent_block_id, onchain_config)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L131-139)
```rust
    fn pre_commit_block(&self, block_id: HashValue) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "pre_commit_block"]);

        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .pre_commit_block(block_id)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L141-149)
```rust
    fn commit_ledger(&self, ledger_info_with_sigs: LedgerInfoWithSignatures) -> ExecutorResult<()> {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "commit_ledger"]);

        self.inner
            .read()
            .as_ref()
            .expect("BlockExecutor is not reset")
            .commit_ledger(ledger_info_with_sigs)
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L151-155)
```rust
    fn finish(&self) {
        let _guard = CONCURRENCY_GAUGE.concurrency_with(&["block", "finish"]);

        *self.inner.write() = None;
    }
```

**File:** execution/executor/src/block_executor/mod.rs (L157-160)
```rust
    fn state_view(&self, block_id: HashValue) -> ExecutorResult<CachedStateView> {
        self.maybe_initialize()?;
        self.inner.read().as_ref().unwrap().state_view(block_id)
    }
```

**File:** consensus/src/state_computer.rs (L136-137)
```rust
        // Grab the logical time lock
        let mut latest_logical_time = self.write_mutex.lock().await;
```

**File:** consensus/src/state_computer.rs (L139-141)
```rust
        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by the BlockExecutor to prevent a memory leak.
        self.executor.finish();
```

**File:** consensus/src/state_computer.rs (L178-179)
```rust
        // Grab the logical time lock and calculate the target logical time
        let mut latest_logical_time = self.write_mutex.lock().await;
```

**File:** consensus/src/state_computer.rs (L183-185)
```rust
        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by BlockExecutor to prevent a memory leak.
        self.executor.finish();
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L857-868)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(start.elapsed())
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L887-893)
```rust
        let result = tokio::task::spawn_blocking(move || {
            executor
                .ledger_update(block_clone.id(), block_clone.parent_id())
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1067-1073)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .pre_commit_block(block.id())
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1098-1104)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .commit_ledger(ledger_info_with_sigs_clone)
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```

**File:** crates/crash-handler/src/lib.rs (L56-57)
```rust
    // Kill the process
    process::exit(12);
```

**File:** aptos-node/src/lib.rs (L233-234)
```rust
    // Setup panic handler
    aptos_crash_handler::setup_panic_handler();
```
