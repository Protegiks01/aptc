# Audit Report

## Title
Batch Retrieval Task Panic on V2 Batches Causes Validator DoS and Consensus Disruption

## Summary
The batch serving task in the Aptos consensus layer unconditionally converts all retrieved batches to V1 format using `.expect()`, causing a panic when V2 batches are requested. This creates a validator task crash and consensus disruption vulnerability when validators enable the `enable_batch_v2` configuration flag.

## Finding Description

The quorum store's batch serving mechanism has a critical version mismatch vulnerability. The `enable_batch_v2` configuration flag controls whether validators create V1 or V2 format batches. [1](#0-0)  The flag defaults to `false`. [2](#0-1) 

When `enable_batch_v2` is enabled, the batch generator creates V2 batches using `Batch::new_v2()` which wraps batch information in the `BatchInfoExt::V2` variant. [3](#0-2) 

These V2 batches are stored in a separate database column family using `save_batch_v2()`. [4](#0-3)  When retrieved via `get_batch_from_local()`, the method returns `PersistedValue<BatchInfoExt>` which can contain either V1 or V2 batches. [5](#0-4) 

However, the batch serving task assumes all batches are V1 and unconditionally converts them with `.expect()`. [6](#0-5) 

The `TryFrom<Batch<BatchInfoExt>>` to `Batch<BatchInfo>` implementation explicitly checks that batches must be V1 type and returns an error for V2 batches. [7](#0-6) 

**Attack Scenario:**
1. Validator A enables `enable_batch_v2 = true` in their configuration
2. Validator A creates and stores V2 batches locally
3. Validator B sends a `BatchRequest` to Validator A (the request contains no version field) [8](#0-7) 
4. Validator A's batch_serve task retrieves the V2 batch from local storage
5. The task attempts to convert `Batch<BatchInfoExt>` â†’ `Batch<BatchInfo>`
6. The `TryFrom` implementation returns error "Batch must be V1 type"
7. The `.expect()` panics, terminating the batch_serve task permanently
8. Validator A can no longer serve ANY batch requests
9. Other validators cannot retrieve batches needed for consensus from Validator A

This breaks consensus availability by preventing batch dissemination, a critical component of the Aptos quorum store protocol.

## Impact Explanation

**Severity: HIGH** (up to $50,000 per Aptos Bug Bounty criteria)

This vulnerability meets the HIGH severity category #8: "Validator node slowdowns/crashes" from the Aptos Bug Bounty program:

1. **Task Termination**: The batch_serve task spawned at [9](#0-8)  terminates permanently on panic. Unlike recoverable errors, the `.expect()` panic crashes the async task without recovery mechanism.

2. **Consensus Protocol Violation**: The batch retrieval protocol is essential for consensus operation. Validators must be able to retrieve batches from peers to execute blocks and verify proposals. When the batch_serve task crashes, the validator becomes unable to serve batch requests, degrading network consensus capability.

3. **Cascading Impact**: If multiple validators enable V2 simultaneously, the network experiences distributed batch serving failures, potentially causing:
   - Increased latency in block execution
   - Validators unable to obtain required batches
   - Degraded consensus liveness

**Not CRITICAL because:**
- The full validator process does not crash (only the task)
- No consensus safety violation occurs (no double-spending or state corruption)
- Recoverable by restarting the validator or disabling the flag
- Does not cause permanent network partition or fund loss

## Likelihood Explanation

**Likelihood: MEDIUM**

**Factors increasing likelihood:**
- Simple trigger: Single configuration flag change
- No special permissions required beyond validator operator access
- No version negotiation exists in the `BatchRequest` protocol
- Any validator operator can independently enable the feature

**Factors decreasing likelihood:**
- Default configuration is `false`, requiring explicit opt-in [2](#0-1) 
- Feature appears experimental: V2 payloads are explicitly rejected at the block verification level [10](#0-9) 
- Incomplete V2 migration indicated by TODO comments in the codebase
- Validators likely coordinate major configuration changes through governance

The vulnerability can realistically occur if validators prematurely enable the experimental feature without coordination.

## Recommendation

Implement version-aware batch serving with proper error handling:

1. **Add version negotiation to BatchRequest**: Include a `version` field in the `BatchRequest` struct to indicate expected batch format
2. **Support both V1 and V2 responses**: Modify the batch_serve task to handle both batch types without panic
3. **Use BatchResponse enum variants**: Leverage the existing `BatchResponse::BatchV2` variant for serving V2 batches
4. **Graceful error handling**: Replace `.expect()` with proper error handling that returns `BatchResponse::NotFound` instead of panicking

The recommended fix in the batch_serve task would check the batch version and use the appropriate response type, or implement backward-compatible conversion only when safe.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Creating a test validator configuration with `enable_batch_v2: true`
2. Generating V2 batches through the batch generator
3. Simulating a batch request from another validator
4. Observing the panic in the batch_serve task when attempting to convert V2 to V1

The panic occurs at the exact location cited in the batch serving task, causing immediate task termination and loss of batch serving capability.

### Citations

**File:** config/src/config/quorum_store_config.rs (L102-102)
```rust
    pub enable_batch_v2: bool,
```

**File:** config/src/config/quorum_store_config.rs (L144-144)
```rust
            enable_batch_v2: false,
```

**File:** consensus/src/quorum_store/batch_generator.rs (L190-211)
```rust
        if self.config.enable_batch_v2 {
            // TODO(ibalajiarun): Specify accurate batch kind
            let batch_kind = BatchKind::Normal;
            Batch::new_v2(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
                batch_kind,
            )
        } else {
            Batch::new_v1(
                batch_id,
                txns,
                self.epoch,
                expiry_time,
                self.my_peer_id,
                bucket_start,
            )
        }
```

**File:** consensus/src/quorum_store/batch_store.rs (L508-513)
```rust
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L571-585)
```rust
    pub(crate) fn get_batch_from_local(
        &self,
        digest: &HashValue,
    ) -> ExecutorResult<PersistedValue<BatchInfoExt>> {
        if let Some(value) = self.db_cache.get(digest) {
            if value.payload_storage_mode() == StorageMode::PersistedOnly {
                self.get_batch_from_db(digest, value.batch_info().is_v2())
            } else {
                // Available in memory.
                Ok(value.clone())
            }
        } else {
            Err(ExecutorError::CouldNotGetData)
        }
    }
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L404-438)
```rust
        spawn_named!("batch_serve", async move {
            info!(epoch = epoch, "Batch retrieval task starts");
            while let Some(rpc_request) = batch_retrieval_rx.next().await {
                counters::RECEIVED_BATCH_REQUEST_COUNT.inc();
                let response = if let Ok(value) =
                    batch_store.get_batch_from_local(&rpc_request.req.digest())
                {
                    let batch: Batch<BatchInfoExt> = value.try_into().unwrap();
                    let batch: Batch<BatchInfo> = batch
                        .try_into()
                        .expect("Batch retieval requests must be for V1 batch");
                    BatchResponse::Batch(batch)
                } else {
                    match aptos_db_clone.get_latest_ledger_info() {
                        Ok(ledger_info) => BatchResponse::NotFound(ledger_info),
                        Err(e) => {
                            let e = anyhow::Error::from(e);
                            error!(epoch = epoch, error = ?e, kind = error_kind(&e));
                            continue;
                        },
                    }
                };

                let msg = ConsensusMsg::BatchResponseV2(Box::new(response));
                let bytes = rpc_request.protocol.to_bytes(&msg).unwrap();
                if let Err(e) = rpc_request
                    .response_sender
                    .send(Ok(bytes.into()))
                    .map_err(|_| anyhow::anyhow!("Failed to send block retrieval response"))
                {
                    warn!(epoch = epoch, error = ?e, kind = error_kind(&e));
                }
            }
            info!(epoch = epoch, "Batch retrieval task stops");
        });
```

**File:** consensus/src/quorum_store/types.rs (L340-342)
```rust
        ensure!(
            matches!(batch.batch_info(), &BatchInfoExt::V1 { .. }),
            "Batch must be V1 type"
```

**File:** consensus/src/quorum_store/types.rs (L356-361)
```rust
pub struct BatchRequest {
    epoch: u64,
    source: PeerId,
    digest: HashValue,
}

```

**File:** consensus/consensus-types/src/common.rs (L610-611)
```rust
                if true {
                    bail!("OptQuorumStorePayload::V2 cannot be accepted yet");
```
