# Audit Report

## Title
Unbounded Memory Growth in SecretShareManager Block Queue Due to Missing Reset During Sync Operations

## Summary
The `SecretShareManager`'s `block_queue` experiences unbounded memory growth because the `reset()` method called during sync operations fails to clear the SecretShareManager queue, unlike the RandManager and BufferManager which are properly reset. This causes blocks with incomplete secret shares to accumulate indefinitely within an epoch, leading to validator node memory exhaustion.

## Finding Description

The `SecretShareManager` maintains a `block_queue` to store blocks awaiting secret share aggregation. [1](#0-0) 

This queue uses an unbounded `BTreeMap` data structure with no size constraints. [2](#0-1) 

Blocks are added to the queue when they arrive from consensus and remain pending until sufficient secret shares meet the threshold. [3](#0-2) 

The coordinator blocks downstream progress until both RandManager AND SecretShareManager signal blocks as ready, creating a bottleneck if secret shares don't arrive. [4](#0-3) 

**The Critical Bug:** During sync operations (`sync_for_duration` and `sync_to_target`), the `reset()` method is called but only resets RandManager and BufferManager, completely omitting the SecretShareManager. [5](#0-4) 

The reset method extracts only `reset_tx_to_rand_manager` and `reset_tx_to_buffer_manager` from the handle. [6](#0-5) 

In contrast, the `end_epoch()` method properly extracts and sends reset requests to all three managers including SecretShareManager. [7](#0-6) 

The SecretShareManager's `process_reset()` method is functional and clears the block_queue when called. [8](#0-7) 

However, this reset is only invoked during epoch transitions, not during sync operations, causing blocks to accumulate across multiple sync operations within an epoch.

The share requester uses `ReliableBroadcast` which retries indefinitely using exponential backoff. [9](#0-8) 

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria under "Validator Node Slowdowns":

1. **Unbounded Memory Growth**: Blocks accumulate in both the SecretShareManager's `block_queue` and the coordinator's `inflight_block_tracker` whenever secret shares fail to arrive, with no upper bound.

2. **Performance Degradation**: As memory consumption grows, validators experience slowdowns affecting their ability to participate in consensus, potentially causing missed votes and reduced network throughput.

3. **Potential Node Crashes**: If memory exhaustion reaches system limits, validator processes may crash due to OOM, temporarily removing them from the active validator set.

4. **Persistence Across Sync**: Unlike RandManager and BufferManager which are cleared during sync operations, the SecretShareManager queue persists, causing memory pressure to compound across multiple sync events within an epoch.

5. **Consensus Pipeline Blocking**: The coordinator requires both managers to signal ready before forwarding blocks, meaning accumulated blocks also block the coordinator's inflight tracker from being cleared.

The vulnerability breaks resource limit invariants by allowing unbounded queue growth over epoch durations that can last minutes to hours.

## Likelihood Explanation

This vulnerability has **HIGH likelihood** of occurring:

**Triggering Conditions:**
- Byzantine validators (< 1/3 of stake) can selectively withhold secret shares for specific blocks
- Natural network partitions or latency issues prevent share delivery
- No special permissions required beyond normal validator participation
- The bug is deterministic - every sync operation omits SecretShareManager reset

**Attack Feasibility:**
- Requires only f Byzantine validators where f < n/3 (within standard BFT assumptions)
- No coordination with other attack vectors needed
- Memory accumulates linearly with block production rate
- Effect compounds across multiple sync operations within an epoch
- Epochs typically last 2+ hours, providing extended accumulation windows

**Natural Occurrence:**
- Transient network issues between geographically distributed validators
- Temporary node failures or network partitions
- High network latency preventing timely share delivery

The missing reset during sync operations is particularly severe because sync operations are common during normal network operation (state synchronization, catching up after brief downtime), yet the bug causes memory to persist and grow across these events.

## Recommendation

Modify the `reset()` method in `ExecutionProxyClient` to include the SecretShareManager reset:

```rust
async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
    let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager, reset_tx_to_secret_share_manager) = {
        let handle = self.handle.read();
        (
            handle.reset_tx_to_rand_manager.clone(),
            handle.reset_tx_to_buffer_manager.clone(),
            handle.reset_tx_to_secret_share_manager.clone(), // ADD THIS LINE
        )
    };

    if let Some(mut reset_tx) = reset_tx_to_rand_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::RandResetDropped)?;
        ack_rx.await.map_err(|_| Error::RandResetDropped)?;
    }

    // ADD THIS BLOCK
    if let Some(mut reset_tx) = reset_tx_to_secret_share_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::SecretShareResetDropped)?;
        ack_rx.await.map_err(|_| Error::SecretShareResetDropped)?;
    }

    if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
        let (tx, rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::ResetDropped)?;
        rx.await.map_err(|_| Error::ResetDropped)?;
    }

    Ok(())
}
```

Additionally, consider implementing:
1. A maximum queue size limit with eviction policy for stale blocks
2. Timeout mechanism to remove blocks that haven't received shares within a threshold duration
3. Metrics and alerts for queue size monitoring beyond the existing `DEC_QUEUE_SIZE` metric

## Proof of Concept

The vulnerability can be demonstrated by:

1. Configuring a validator set with SecretShareManager enabled
2. Having 1-2 Byzantine validators (< 1/3) withhold secret shares for blocks
3. Triggering sync operations via `sync_to_target()` or `sync_for_duration()`
4. Observing that the SecretShareManager's block_queue is never cleared during sync
5. Monitoring memory growth over time as blocks accumulate

The code evidence clearly shows the omission in the reset method compared to end_epoch, making this a deterministic bug that occurs on every sync operation when secret shares are incomplete.

## Notes

This is a **logic vulnerability** in the reset coordination code, not a network DoS attack. The bug exists regardless of whether Byzantine validators or network issues trigger it - the missing reset during sync operations is the core issue. The vulnerability is within the standard BFT threat model (< 1/3 Byzantine validators) and affects production consensus code.

### Citations

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L62-62)
```rust
    block_queue: BlockQueue,
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L112-130)
```rust
    async fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
        let rounds: Vec<u64> = blocks.ordered_blocks.iter().map(|b| b.round()).collect();
        info!(rounds = rounds, "Processing incoming blocks.");

        let mut share_requester_handles = Vec::new();
        let mut pending_secret_key_rounds = HashSet::new();
        for block in blocks.ordered_blocks.iter() {
            let handle = self.process_incoming_block(block).await;
            share_requester_handles.push(handle);
            pending_secret_key_rounds.insert(block.round());
        }

        let queue_item = QueueItem::new(
            blocks,
            Some(share_requester_handles),
            pending_secret_key_rounds,
        );
        self.block_queue.push_back(queue_item);
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L172-184)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.secret_share_store
            .lock()
            .update_highest_known_round(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/secret_sharing/block_queue.rs (L89-91)
```rust
pub struct BlockQueue {
    queue: BTreeMap<Round, QueueItem>,
}
```

**File:** consensus/src/pipeline/execution_client.rs (L357-360)
```rust
                if o.get().1 && o.get().2 {
                    let (_, (ordered_blocks, _, _)) = o.remove_entry();
                    let _ = ready_block_tx.send(ordered_blocks).await;
                }
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L712-745)
```rust
        let (
            reset_tx_to_rand_manager,
            reset_tx_to_buffer_manager,
            reset_tx_to_secret_share_manager,
        ) = {
            let mut handle = self.handle.write();
            handle.reset()
        };

        if let Some(mut tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel();
            tx.send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::Stop,
            })
            .await
            .expect("[EpochManager] Fail to drop rand manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop rand manager");
        }

        if let Some(mut tx) = reset_tx_to_secret_share_manager {
            let (ack_tx, ack_rx) = oneshot::channel();
            tx.send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::Stop,
            })
            .await
            .expect("[EpochManager] Fail to drop secret share manager");
            ack_rx
                .await
                .expect("[EpochManager] Fail to drop secret share manager");
        }
```

**File:** crates/reliable-broadcast/src/lib.rs (L191-200)
```rust
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
```
