# Audit Report

## Title
DAG Consensus Pipeline Latency Tracking Memory Leak Causes Total Liveness Failure After 30 Seconds

## Summary
The DAG consensus implementation contains a critical bug where the `block_ordered_ts` tracking map is never cleaned up, causing all validators to permanently stop voting after 30 seconds of operation within an epoch, resulting in complete consensus halt.

## Finding Description

The `OrderedNotifierAdapter` in DAG consensus maintains a `block_ordered_ts` map (BTreeMap<Round, Instant>) that tracks when blocks are ordered for pipeline latency measurement. [1](#0-0) 

This map is used by `pipeline_pending_latency()` to calculate the elapsed time since the oldest ordered block by retrieving the first entry and returning its elapsed time. [2](#0-1) 

When nodes are ordered via `send_ordered_nodes()`, entries are inserted into this map with the current timestamp. [3](#0-2) 

However, the cleanup callback that should remove committed blocks from this map is commented out with a TODO note, preventing any entries from ever being removed during the epoch. The current `OrderedBlocks` struct doesn't even have a callback field to support this cleanup mechanism. [4](#0-3) [5](#0-4) 

The `PipelineLatencyBasedBackpressure` implementation compares this growing latency against `voter_pipeline_latency_limit` (default 30,000ms). [6](#0-5) [7](#0-6) 

When the limit is exceeded, the `stop_voting()` method returns true, causing validators to refuse voting on new blocks. [8](#0-7) [9](#0-8) 

DAG consensus is enabled via on-chain configuration through `is_dag_enabled()` check in the consensus configuration. [10](#0-9) [11](#0-10) 

**Security Guarantee Broken**: This violates the Consensus Liveness invariant. After 30 seconds from the first block ordered in an epoch, ALL validators will hit the latency limit and stop voting, causing complete consensus halt until the next epoch boundary. Since the map is never cleaned up and only grows, the oldest timestamp continuously ages, eventually exceeding the 30-second threshold.

## Impact Explanation

**Critical Severity** - This meets the "Total loss of liveness/network availability" category from the Aptos Bug Bounty program. Within 30 seconds of epoch start, the entire DAG consensus network would stop producing blocks.

While epochs reset the state by creating a new `OrderedNotifierAdapter` instance with an empty `block_ordered_ts` map at each epoch boundary, this creates a pattern of 30-second windows of liveness followed by consensus halt for the remaining duration of each epoch. [12](#0-11) 

With default 2-hour epochs (7200 seconds), this results in approximately 7170 seconds of halt per epoch, or 99.6% downtime. [13](#0-12) 

## Likelihood Explanation

**Certain (for DAG-enabled networks)** - This bug triggers automatically on all DAG consensus validators once DAG is enabled. No attacker action is required. The moment the first block is ordered in an epoch, the 30-second countdown begins for all validators simultaneously.

**Important Note**: DAG consensus is not enabled by default (JolteonV2 is the default), but can be enabled via on-chain governance configuration. Once enabled, this vulnerability manifests immediately. [14](#0-13) 

## Recommendation

Uncomment and properly integrate the cleanup callback mechanism. The callback should be invoked when blocks are committed and should remove all entries from `block_ordered_ts` where the round is less than or equal to the committed round:

```rust
block_ordered_ts
    .write()
    .retain(|&round, _| round > commit_decision.commit_info().round());
```

The `OrderedBlocks` struct needs to be extended to support callbacks, and the pipeline_builder must be updated to invoke these callbacks upon block commitment.

## Proof of Concept

1. Enable DAG consensus on a test network via on-chain configuration update
2. Start validators and wait for first epoch to begin
3. Observe normal block production for first 30 seconds
4. After 30 seconds, `pipeline_pending_latency()` exceeds 30,000ms
5. All validators stop voting (verified via `stop_voting()` returning true)
6. No new blocks are produced until next epoch boundary
7. Pattern repeats each epoch: 30s liveness, then ~7170s halt

## Notes

This vulnerability only affects networks where DAG consensus has been explicitly enabled via on-chain governance. While not enabled by default, DAG is a supported production feature in the Aptos Core codebase that can be activated on mainnet, making this a valid critical security issue for any network operator considering or using DAG consensus.

### Citations

**File:** consensus/src/dag/adapter.rs (L101-101)
```rust
    block_ordered_ts: Arc<RwLock<BTreeMap<Round, Instant>>>,
```

**File:** consensus/src/dag/adapter.rs (L125-134)
```rust
    pub(super) fn pipeline_pending_latency(&self) -> Duration {
        match self.block_ordered_ts.read().first_key_value() {
            Some((round, timestamp)) => {
                let latency = timestamp.elapsed();
                info!(round = round, latency = latency, "pipeline pending latency");
                latency
            },
            None => Duration::ZERO,
        }
    }
```

**File:** consensus/src/dag/adapter.rs (L203-205)
```rust
        self.block_ordered_ts
            .write()
            .insert(block_info.round(), Instant::now());
```

**File:** consensus/src/dag/adapter.rs (L215-228)
```rust
            // TODO: this needs to be properly integrated with pipeline_builder
            // callback: Box::new(
            //     move |committed_blocks: &[Arc<PipelinedBlock>],
            //           commit_decision: LedgerInfoWithSignatures| {
            //         block_created_ts
            //             .write()
            //             .retain(|&round, _| round > commit_decision.commit_info().round());
            //         dag.commit_callback(commit_decision.commit_info().round());
            //         ledger_info_provider
            //             .write()
            //             .notify_commit_proof(commit_decision);
            //         update_counters_for_committed_blocks(committed_blocks);
            //     },
            // ),
```

**File:** consensus/src/pipeline/buffer_manager.rs (L80-83)
```rust
pub struct OrderedBlocks {
    pub ordered_blocks: Vec<Arc<PipelinedBlock>>,
    pub ordered_proof: LedgerInfoWithSignatures,
}
```

**File:** config/src/config/dag_consensus_config.rs (L141-154)
```rust
pub struct DagHealthConfig {
    pub chain_backoff_config: Vec<ChainHealthBackoffValues>,
    pub voter_pipeline_latency_limit_ms: u64,
    pub pipeline_backpressure_config: Vec<PipelineBackpressureValues>,
}

impl Default for DagHealthConfig {
    fn default() -> Self {
        Self {
            chain_backoff_config: Vec::new(),
            voter_pipeline_latency_limit_ms: 30_000,
            pipeline_backpressure_config: Vec::new(),
        }
    }
```

**File:** consensus/src/dag/health/pipeline_health.rs (L39-56)
```rust
pub struct PipelineLatencyBasedBackpressure {
    voter_pipeline_latency_limit: Duration,
    pipeline_config: PipelineBackpressureConfig,
    adapter: Arc<OrderedNotifierAdapter>,
}

impl PipelineLatencyBasedBackpressure {
    pub(in crate::dag) fn new(
        voter_pipeline_latency_limit: Duration,
        pipeline_config: PipelineBackpressureConfig,
        adapter: Arc<OrderedNotifierAdapter>,
    ) -> Arc<Self> {
        Arc::new(Self {
            voter_pipeline_latency_limit,
            pipeline_config,
            adapter,
        })
    }
```

**File:** consensus/src/dag/health/pipeline_health.rs (L77-80)
```rust
    fn stop_voting(&self) -> bool {
        let latency = self.adapter.pipeline_pending_latency();
        latency > self.voter_pipeline_latency_limit
    }
```

**File:** consensus/src/dag/rb_handler.rs (L219-222)
```rust
        ensure!(
            !self.health_backoff.stop_voting(),
            NodeBroadcastHandleError::VoteRefused
        );
```

**File:** types/src/on_chain_config/consensus_config.rs (L30-36)
```rust
    pub fn default_for_genesis() -> Self {
        Self::JolteonV2 {
            main: ConsensusConfigV1::default(),
            quorum_store_enabled: true,
            order_vote_enabled: true,
        }
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L77-83)
```rust
    pub fn is_dag_enabled(&self) -> bool {
        match self {
            ConsensusAlgorithmConfig::Jolteon { .. }
            | ConsensusAlgorithmConfig::JolteonV2 { .. } => false,
            ConsensusAlgorithmConfig::DAG(_) => true,
        }
    }
```

**File:** types/src/on_chain_config/consensus_config.rs (L288-296)
```rust
    pub fn is_dag_enabled(&self) -> bool {
        match self {
            OnChainConsensusConfig::V1(_) => false,
            OnChainConsensusConfig::V2(_) => false,
            OnChainConsensusConfig::V3 { alg, .. }
            | OnChainConsensusConfig::V4 { alg, .. }
            | OnChainConsensusConfig::V5 { alg, .. } => alg.is_dag_enabled(),
        }
    }
```

**File:** consensus/src/dag/bootstrap.rs (L533-540)
```rust
        let ordered_notifier = Arc::new(OrderedNotifierAdapter::new(
            self.ordered_nodes_tx.clone(),
            dag.clone(),
            self.epoch_state.clone(),
            parent_block_info,
            ledger_info_provider.clone(),
            self.allow_batches_without_pos_in_proposal,
        ));
```

**File:** aptos-move/vm-genesis/src/lib.rs (L537-537)
```rust
    let num_epochs_in_a_year = NUM_SECONDS_PER_YEAR / genesis_config.epoch_duration_secs;
```
