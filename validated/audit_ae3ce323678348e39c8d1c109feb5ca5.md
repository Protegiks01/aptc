# Audit Report

## Title
Race Condition in Batch Store Expiration Causes Validator Panic and Consensus Disruption

## Summary
A race condition exists in the Batch Store's expiration tracking mechanism where non-atomic operations between `db_cache` and `expirations` data structures can lead to stale expiration entries. When a validator processes these stale entries, it triggers an `unreachable!()` panic, causing immediate validator crash and consensus disruption.

## Finding Description

The vulnerability exists in the `insert_to_cache()` method of the Batch Store, which performs two operations that are not atomic:

**First operation**: The method acquires a DashMap lock to insert or replace an entry in `db_cache`. [1](#0-0) 

**Second operation**: After releasing the lock at line 409, the method adds the expiration time to the `expirations` tracking structure. [2](#0-1) 

The developer's comment at line 411 assumes this doesn't need to be atomic, but this assumption is violated when the same digest is concurrently inserted with different expiration times.

**The Race Condition:**

1. Thread A inserts digest D with expiration 100 into `db_cache`, then releases the lock but gets preempted before adding to `expirations`
2. Thread B finds the existing entry with expiration 100, replaces it with expiration 200 (since 100 < 200) [3](#0-2) , and adds (D, 200) to `expirations` [4](#0-3) 
3. Thread C calls `clear_expired_payload(250)`, finds D expired [5](#0-4) , and removes it from `db_cache` [6](#0-5) 
4. Thread A resumes and adds stale entry (D, 100) to `expirations`
5. Thread D later calls `clear_expired_payload()`, finds the stale (D, 100) entry, attempts to look up D in `db_cache`, finds it Vacant, and triggers the panic [7](#0-6) 

**Root Cause**: The `TimeExpirations` structure uses a `BinaryHeap` that allows duplicate entries for the same digest with different expiration times [8](#0-7) , with no mechanism to remove stale entries when replacements occur.

**Production Scenario**: This can occur naturally when the same batch content (identified by digest) is proposed at different times with different expiration timestamps, which is possible during network retries, re-proposals, or when multiple validators independently create batches with the same content.

## Impact Explanation

**Severity: CRITICAL**

This vulnerability meets the CRITICAL severity criteria for "Total loss of liveness/network availability" under the Aptos bug bounty program because:

1. **Immediate validator crash**: When the `unreachable!()` macro is triggered [7](#0-6) , the validator panics and crashes immediately, ceasing all consensus participation
2. **Non-recoverable without manual intervention**: The validator must be manually restarted, and without a fix, the race condition can recur
3. **Consensus disruption**: Under high load conditions where this race is more likely, multiple validators could crash simultaneously, severely degrading or halting consensus progress
4. **Liveness violation**: Crashed validators cannot vote, propose blocks, or participate in consensus, directly impacting the network's ability to make progress

This directly violates the consensus liveness guarantees that are fundamental to blockchain operation.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This race condition has a realistic probability of occurring in production:

1. **Natural occurrence**: The same digest with different expirations can legitimately occur during normal operations (network retries, batch re-proposals, epoch transitions)
2. **Race window exists**: There is a clear, unprotected window between lines 409 and 414 [9](#0-8)  where thread interleaving can occur
3. **High load amplification**: Under heavy transaction volume, CPU contention, or GC pauses, the race window becomes more exploitable
4. **No synchronization**: There are no memory barriers or atomic operations protecting this critical section
5. **Test gap**: The existing concurrent test uses different digests for each experiment [10](#0-9)  and doesn't cover this specific interleaving pattern where the same digest is inserted with different expirations concurrently

## Recommendation

The issue can be fixed by making the operations atomic. One approach:

1. Hold the `expirations` lock while updating `db_cache` to ensure atomicity between both data structures
2. Add a mechanism to remove stale expiration entries when a digest is replaced with a higher expiration
3. Replace the `unreachable!()` with graceful handling that logs the inconsistency and continues, preventing validator crashes

The critical fix is to ensure that when a digest is replaced in `db_cache`, any existing entries for that digest in `expirations` are either removed or the new expiration is added atomically with the cache update.

## Proof of Concept

A proof of concept would require:
1. Creating multiple threads that concurrently call `insert_to_cache()` with the same digest but different expiration times
2. Introducing controlled delays after line 409 to widen the race window
3. Having another thread call `clear_expired_payload()` at strategic times
4. Demonstrating that the `unreachable!()` panic is triggered

The test at [11](#0-10)  provides a foundation but uses different digests, so it would need to be modified to use the same digest with different expirations to trigger this race condition.

## Notes

This is a valid concurrency bug in production consensus code that can cause validator crashes and consensus disruption. The vulnerability is confirmed by direct code inspection showing the non-atomic operations and the panic condition that gets triggered when the invariant is violated.

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L366-415)
```rust
        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
```

**File:** consensus/src/quorum_store/batch_store.rs (L443-448)
```rust
    pub(crate) fn clear_expired_payload(&self, certified_time: u64) -> Vec<HashValue> {
        // To help slow nodes catch up via execution without going to state sync we keep the blocks for 60 extra seconds
        // after the expiration time. This will help remote peers fetch batches that just expired but are within their
        // execution window.
        let expiration_time = certified_time.saturating_sub(self.expiration_buffer_usecs);
        let expired_digests = self.expirations.lock().expire(expiration_time);
```

**File:** consensus/src/quorum_store/batch_store.rs (L451-464)
```rust
            let removed_value = match self.db_cache.entry(h) {
                Occupied(entry) => {
                    // We need to check up-to-date expiration again because receiving the same
                    // digest with a higher expiration would update the persisted value and
                    // effectively extend the expiration.
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
                        Some(entry.remove())
                    } else {
                        None
                    }
                },
                Vacant(_) => unreachable!("Expired entry not in cache"),
            };
```

**File:** consensus/src/quorum_store/utils.rs (L60-73)
```rust
pub(crate) struct TimeExpirations<I: Ord> {
    expiries: BinaryHeap<(Reverse<u64>, I)>,
}

impl<I: Ord + Hash> TimeExpirations<I> {
    pub(crate) fn new() -> Self {
        Self {
            expiries: BinaryHeap::new(),
        }
    }

    pub(crate) fn add_item(&mut self, item: I, expiry_time: u64) {
        self.expiries.push((Reverse(expiry_time), item));
    }
```

**File:** consensus/src/quorum_store/tests/batch_store_test.rs (L91-184)
```rust
#[tokio::test(flavor = "multi_thread")]
async fn test_extend_expiration_vs_save() {
    let num_experiments = 2000;
    let batch_store = batch_store_for_test(2001);

    let batch_store_clone1 = batch_store.clone();
    let batch_store_clone2 = batch_store.clone();

    let digests: Vec<HashValue> = (0..num_experiments).map(|_| HashValue::random()).collect();
    let later_exp_values: Vec<PersistedValue<BatchInfoExt>> = (0..num_experiments)
        .map(|i| {
            // Pre-insert some of them.
            if i % 2 == 0 {
                assert_ok!(batch_store.save(&request_for_test(
                    &digests[i],
                    i as u64 + 30,
                    1,
                    None
                )));
            }

            request_for_test(&digests[i], i as u64 + 40, 1, None)
        })
        .collect();

    // Marshal threads to start at the same time.
    let start_flag = Arc::new(AtomicUsize::new(0));
    let start_clone1 = start_flag.clone();
    let start_clone2 = start_flag.clone();

    let save_error = Arc::new(AtomicBool::new(false));
    let save_error_clone1 = save_error.clone();
    let save_error_clone2 = save_error.clone();

    // Thread that extends expiration by saving.
    spawn_blocking(move || {
        for (i, later_exp_value) in later_exp_values.into_iter().enumerate() {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone1.load(Ordering::Acquire);
                if flag_val == 3 * i + 1 || flag_val == 3 * i + 2 {
                    break;
                }
            }

            if batch_store_clone1.save(&later_exp_value).is_err() {
                // Save in a separate flag and break so test doesn't hang.
                save_error_clone1.store(true, Ordering::Release);
                break;
            }
            start_clone1.fetch_add(1, Ordering::Relaxed);
        }
    });

    // Thread that expires.
    spawn_blocking(move || {
        for i in 0..num_experiments {
            // Wait until both threads are ready for next experiment.
            loop {
                let flag_val = start_clone2.load(Ordering::Acquire);
                if flag_val == 3 * i + 1
                    || flag_val == 3 * i + 2
                    || save_error_clone2.load(Ordering::Acquire)
                {
                    break;
                }
            }

            batch_store_clone2.update_certified_timestamp(i as u64 + 30);
            start_clone2.fetch_add(1, Ordering::Relaxed);
        }
    });

    for (i, &digest) in digests.iter().enumerate().take(num_experiments) {
        // Set the conditions for experiment (both threads waiting).
        while start_flag.load(Ordering::Acquire) % 3 != 0 {
            assert!(!save_error.load(Ordering::Acquire));
        }

        if i % 2 == 1 {
            assert_ok!(batch_store.save(&request_for_test(&digest, i as u64 + 30, 1, None)));
        }

        // Unleash the threads.
        start_flag.fetch_add(1, Ordering::Relaxed);
    }
    // Finish the experiment
    while start_flag.load(Ordering::Acquire) % 3 != 0 {}

    // Expire everything, call for higher times as well.
    for i in 35..50 {
        batch_store.update_certified_timestamp((i + num_experiments) as u64);
    }
}
```
