# Audit Report

## Title
Missing Peer Penalty on Compression Mismatch Allows Malicious Peers to Gain Reputation While Sending Invalid Data

## Summary
The Aptos state synchronization system fails to penalize peers that send compression-mismatched responses. Malicious peers actually gain reputation score (+1.0) for successful network delivery despite the client detecting and rejecting invalid compressed/uncompressed data. This breaks the peer reputation security invariant and enables persistent state sync slowdowns for validators and full nodes.

## Finding Description

The Aptos data client implements a peer scoring mechanism where peers start at 50.0 and gain +1.0 per successful response (up to 100.0 max). When peers send invalid data, `notify_bad_response()` should be called to apply penalties (0.95x for NotUseful errors, 0.8x for Malicious errors). Peers scoring at or below 25.0 are ignored when `ignore_low_score_peers` is enabled (the default configuration). [1](#0-0) [2](#0-1) [3](#0-2) 

The vulnerability occurs in `send_request_to_peer_and_decode` where compression validation happens. After extracting the `ResponseContext` containing the peer's `ResponseCallback`, the code checks for compression mismatches but returns errors directly without calling `notify_bad_response()`: [4](#0-3) 

The context is dropped when the error is returned, losing all peer identification. In contrast, when type conversion errors occur later in the same function, the code correctly notifies the callback before returning: [5](#0-4) 

**Critical Aggravating Factor**: The peer reputation is increased on successful network response delivery BEFORE compression validation occurs. In `send_request_to_peer`, the peer score is increased immediately after the network layer succeeds: [6](#0-5) 

This means malicious peers sending compression-mismatched data GAIN +1.0 reputation score without penalty, making them progressively more likely to be selected. [7](#0-6) 

When errors propagate to the streaming service, they lose all peer context. The error handler receives errors without peer identification and simply retries: [8](#0-7) [9](#0-8) 

**Attack Path:**
1. Malicious peer registers as storage service peer
2. Receives request with `use_compression = true/false`
3. Intentionally sends response with opposite compression setting
4. Network layer succeeds → peer gains +1.0 score
5. Compression validation detects mismatch but doesn't penalize
6. Error returned, request retried to another peer
7. Malicious peer's score increased from 50.0 → 51.0
8. Attack repeats, peer score continues growing
9. Over time, malicious peer becomes MORE likely to be selected over honest peers

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria for "Validator node slowdowns" (up to $50,000).

**Concrete Impact:**
- Malicious peers exploit the reputation system to gain trust while sending invalid data
- Validator nodes attempting to sync from malicious peers experience persistent slowdowns
- CPU and network resources wasted on retries with increasingly trusted malicious peers
- State sync degradation can cause validators to fall behind consensus rounds
- With multiple colluding malicious peers, state sync becomes severely degraded
- Unlike normal bad peers that eventually get banned (score drops to ≤25.0), these peers become MORE trusted over time (score increases toward 100.0)
- The attack is persistent and worsens with each iteration

The vulnerability breaks the fundamental **peer reputation security invariant**: malicious behavior should decrease reputation, not increase it.

## Likelihood Explanation

**Likelihood: High**

- **Ease of Exploitation**: Trivial - malicious storage service peer simply ignores the `use_compression` flag in requests
- **Attacker Requirements**: Any network peer can register as a storage service peer
- **Prerequisites**: None - works during normal network operation
- **Detection Difficulty**: Hard to detect - appears as normal retry errors in logs while peer score silently increases
- **Automation**: Fully automatable attack requiring no human intervention
- **Cost**: Negligible - no economic or computational cost beyond running a network peer
- **Scalability**: Attack effectiveness increases over time as malicious peer's reputation grows from 50.0 toward 100.0

## Recommendation

Add `notify_bad_response()` call before returning compression mismatch errors in `send_request_to_peer_and_decode`:

```rust
// Ensure the response obeys the compression requirements
let (context, storage_response) = storage_response.into_parts();
if request.use_compression && !storage_response.is_compressed() {
    context.response_callback.notify_bad_response(ResponseError::InvalidData);
    return Err(Error::InvalidResponse(format!(
        "Requested compressed data, but the response was uncompressed! Response: {:?}",
        storage_response.get_label()
    )));
} else if !request.use_compression && storage_response.is_compressed() {
    context.response_callback.notify_bad_response(ResponseError::InvalidData);
    return Err(Error::InvalidResponse(format!(
        "Requested uncompressed data, but the response was compressed! Response: {:?}",
        storage_response.get_label()
    )));
}
```

This ensures compression mismatches are treated as `NotUseful` errors (0.95x multiplier), preventing reputation gain and eventually banning persistent malicious peers.

## Proof of Concept

The existing test `compression_mismatch_disabled` demonstrates the vulnerability: [10](#0-9) 

This test verifies that compression mismatches return errors, but it does NOT verify that peer scores are penalized. A malicious peer sending compressed responses when compression is disabled will have its score INCREASED rather than DECREASED, despite the client correctly detecting and rejecting the invalid response.

To demonstrate the reputation gain, add peer score assertions to the test showing the malicious peer's score increases from 50.0 to 51.0 after each failed compression-mismatched request.

## Notes

This vulnerability is distinct from network DoS attacks (which are out of scope). It exploits a logic flaw in the peer reputation system where the scoring mechanism is applied before data validation completes. The impact is on state sync reliability and validator performance, not pure network flooding.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L32-43)
```rust
/// Scores for peer rankings based on preferences and behavior.
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L163-165)
```rust
    fn update_score_success(&mut self) {
        self.score = f64::min(self.score + SUCCESSFUL_RESPONSE_DELTA, MAX_SCORE);
    }
```

**File:** config/src/config/state_sync_config.rs (L421-421)
```rust
    pub ignore_low_score_peers: bool,
```

**File:** config/src/config/state_sync_config.rs (L466-466)
```rust
            ignore_low_score_peers: true,
```

**File:** state-sync/aptos-data-client/src/client.rs (L736-748)
```rust
        // Ensure the response obeys the compression requirements
        let (context, storage_response) = storage_response.into_parts();
        if request.use_compression && !storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested compressed data, but the response was uncompressed! Response: {:?}",
                storage_response.get_label()
            )));
        } else if !request.use_compression && storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested uncompressed data, but the response was compressed! Response: {:?}",
                storage_response.get_label()
            )));
        }
```

**File:** state-sync/aptos-data-client/src/client.rs (L756-760)
```rust
                Err(err) => {
                    context
                        .response_callback
                        .notify_bad_response(ResponseError::InvalidPayloadDataType);
                    Err(err.into())
```

**File:** state-sync/aptos-data-client/src/client.rs (L799-828)
```rust
            Ok(response) => {
                trace!(
                    (LogSchema::new(LogEntry::StorageServiceResponse)
                        .event(LogEvent::ResponseSuccess)
                        .request_type(&request.get_label())
                        .request_id(id)
                        .peer(&peer))
                );

                // Update the received response metrics
                self.update_received_response_metrics(peer, &request);

                // For now, record all responses that at least pass the data
                // client layer successfully. An alternative might also have the
                // consumer notify both success and failure via the callback.
                // On the one hand, scoring dynamics are simpler when each request
                // is successful or failed but not both; on the other hand, this
                // feels simpler for the consumer.
                self.peer_states.update_score_success(peer);

                // Package up all of the context needed to fully report an error
                // with this RPC.
                let response_callback = AptosNetResponseCallback {
                    data_client: self.clone(),
                    id,
                    peer,
                    request,
                };
                let context = ResponseContext::new(id, Box::new(response_callback));
                Ok(Response::new(context, response))
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L523-538)
```rust
                Err(error) => {
                    // Handle the error depending on the request type
                    if client_request.is_new_data_request() {
                        // The request was for new data. We should notify the
                        // stream engine and clear the requests queue.
                        self.notify_new_data_request_error(client_request, error)?;
                    } else {
                        // Decrease the prefetching limit on an error
                        self.dynamic_prefetching_state
                            .decrease_max_concurrent_requests();

                        // Handle the error and simply retry
                        self.handle_data_client_error(client_request, &error)?;
                    }
                    break; // We're now head of line blocked on the failed request
                },
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L711-725)
```rust
    fn handle_data_client_error(
        &mut self,
        data_client_request: &DataClientRequest,
        data_client_error: &aptos_data_client::error::Error,
    ) -> Result<(), Error> {
        // Log the error
        warn!(LogSchema::new(LogEntry::ReceivedDataResponse)
            .stream_id(self.data_stream_id)
            .event(LogEvent::Error)
            .error(&data_client_error.clone().into())
            .message("Encountered a data client error!"));

        // TODO(joshlind): can we identify the best way to react to the error?
        self.resend_data_client_request(data_client_request)
    }
```

**File:** state-sync/aptos-data-client/src/tests/compression.rs (L21-98)
```rust
async fn compression_mismatch_disabled() {
    // Create a base config for a validator
    let base_config = utils::create_validator_base_config();

    // Create a data client config that disables compression
    let data_client_config = AptosDataClientConfig {
        use_compression: false,
        ..Default::default()
    };

    // Ensure the properties hold for all peer priorities
    for peer_priority in PeerPriority::get_all_ordered_priorities() {
        // Create the mock network, mock time, client and poller
        let (mut mock_network, mut mock_time, client, poller) =
            MockNetwork::new(Some(base_config.clone()), Some(data_client_config), None);

        // Start the poller
        tokio::spawn(poller::start_poller(poller));

        // Add a connected peer
        let (_, network_id) = utils::add_peer_to_network(peer_priority, &mut mock_network);

        // Advance time so the poller sends a data summary request
        utils::advance_polling_timer(&mut mock_time, &data_client_config).await;

        // Receive their request and respond
        let highest_synced_version = 100;
        let network_request = utils::get_network_request(&mut mock_network, network_id).await;
        let data_response = DataResponse::StorageServerSummary(utils::create_storage_summary(
            highest_synced_version,
        ));
        network_request.response_sender.send(Ok(
            StorageServiceResponse::new(data_response, false).unwrap()
        ));

        // Wait for the poller to process the response
        let transaction_range = CompleteDataRange::new(0, highest_synced_version).unwrap();
        utils::wait_for_transaction_advertisement(
            &client,
            &mut mock_time,
            &data_client_config,
            transaction_range,
        )
        .await;

        // Handle the client's transactions request using compression
        tokio::spawn(async move {
            loop {
                // Verify the received network request
                let network_request =
                    utils::get_network_request(&mut mock_network, network_id).await;
                assert!(!network_request.storage_service_request.use_compression);

                // Fulfill the request if it is for transactions
                if matches!(
                    network_request.storage_service_request.data_request,
                    DataRequest::GetTransactionsWithProof(TransactionsWithProofRequest {
                        start_version: 50,
                        end_version: 100,
                        proof_version: 100,
                        include_events: false,
                    })
                ) {
                    // Compress the response
                    utils::handle_transactions_request(network_request, true);
                }
            }
        });

        // The client should receive a compressed response and return an error
        let request_timeout = data_client_config.response_timeout_ms;
        let response = client
            .get_transactions_with_proof(100, 50, 100, false, request_timeout)
            .await
            .unwrap_err();
        assert_matches!(response, Error::DataIsUnavailable(_));
    }
}
```
