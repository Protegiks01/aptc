# Audit Report

## Title
Panic in Encrypted Transaction Decryption Pipeline Allows Byzantine Validator to Crash All Honest Nodes

## Summary
The encrypted transaction decryption pipeline in the consensus layer contains unchecked `.expect()` calls that panic when processing `EncryptedPayload` transactions not in the `Encrypted` state. A Byzantine block proposer can craft a malicious block containing encrypted transactions in the `Decrypted` or `FailedDecryption` state, causing all honest validators to panic and crash when processing the block, resulting in total network liveness failure.

## Finding Description
The vulnerability exists in the consensus decryption pipeline where encrypted transactions are processed. When a block containing encrypted transactions reaches the decryption stage, the code assumes all encrypted payloads are in the `Encrypted` state and uses `.expect()` to unwrap the results of state transition methods without validation.

The critical panic points are in the decryption pipeline: [1](#0-0) [2](#0-1) 

These methods require the payload to be in the `Encrypted` state and will return an error otherwise: [3](#0-2) [4](#0-3) 

Both methods return `bail!("Payload is not in Encrypted state")` if the payload is in `Decrypted` or `FailedDecryption` state, causing the `.expect()` to panic.

**Attack Path:**

1. Byzantine validator becomes block proposer for a round
2. Validator crafts a malicious block containing one or more encrypted transactions with `EncryptedPayload` in the `Decrypted` or `FailedDecryption` state (achievable since all enum variants are serializable)
3. Validator proposes the block to the network
4. Honest validators receive and deserialize the block
5. Block passes structural validation in `verify_well_formed()`: [5](#0-4) 

This method validates block structure, rounds, timestamps, and failed authors, but does not check encrypted payload internal states.

6. Block passes consensus validation in `process_proposal()`: [6](#0-5) 

This method validates proposer, transaction limits, and denied transactions, but does not validate encrypted payload states.

7. Block enters the execution pipeline where `decrypt_encrypted_txns` is invoked: [7](#0-6) 

8. When processing the malicious encrypted transaction, all validators panic at the `.expect()` calls, crashing simultaneously

While the API validates submitted transactions are in `Encrypted` state: [8](#0-7) 

This validation only applies to transactions submitted through the API. A Byzantine block proposer can bypass this by directly crafting blocks with transactions in invalid states, as there is no corresponding validation at the consensus level before the decryption pipeline.

## Impact Explanation
**Critical Severity** - This vulnerability enables a single Byzantine validator (when elected as block proposer) to cause total network liveness failure by crashing all honest validators simultaneously with a single malicious block. 

This meets the Critical severity criteria per the Aptos bug bounty program: **"Total Loss of Liveness/Network Availability - Network halts due to protocol bug; All validators unable to progress."**

The attack violates AptosBFT's liveness guarantee under < 1/3 Byzantine validators. While the system tolerates Byzantine behavior mathematically, this specific vulnerability allows a single Byzantine validator to halt the entire network through a deterministic panic, requiring emergency intervention or coordinated validator restarts to recover. This is fundamentally different from normal Byzantine behavior that the protocol is designed to tolerate.

## Likelihood Explanation
**High Likelihood** - The attack requires:

1. **Attacker controls a validator node** - This is the definition of a Byzantine validator, which Aptos must tolerate up to 1/3 of stake. This is within the threat model.

2. **Validator is elected as block proposer** - This is probabilistic based on stake, but will eventually occur through normal rotation.

3. **Attacker crafts a malicious block** - This is trivial as the attacker controls their node software and can serialize any valid BCS data structure, including `EncryptedPayload` variants in any state.

No sophisticated cryptographic attacks, race conditions, or complex state manipulations are required. The vulnerability is deterministic: any block containing an encrypted payload in the wrong state will cause all validators processing it to panic. The attack is guaranteed to succeed once the malicious validator is elected as proposer.

## Recommendation
Add validation in the consensus block validation pipeline to verify that all `EncryptedPayload` transactions are in the `Encrypted` state before processing:

**Option 1**: Add validation in `Block::verify_well_formed()` to check encrypted payload states.

**Option 2**: Add validation in `RoundManager::process_proposal()` before inserting the block into the block store.

**Option 3**: Replace `.expect()` calls with proper error handling in the decryption pipeline that returns errors instead of panicking, allowing validators to reject invalid blocks gracefully.

Example fix for Option 3:
```rust
// In decrypt_encrypted_txns at line 136-137
p.into_decrypted(eval_proof, executable, nonce)
    .map_err(|e| anyhow!("Invalid encrypted payload state: {}", e))?
    
// At line 142-143  
p.into_failed_decryption(eval_proof)
    .map_err(|e| anyhow!("Invalid encrypted payload state: {}", e))?
```

The recommended approach is Option 2 (validation in `process_proposal`) combined with Option 3 (defensive error handling), providing defense in depth.

## Proof of Concept
A Byzantine validator can create a malicious block as follows:

```rust
// Byzantine validator crafts a transaction with EncryptedPayload in wrong state
let mut malicious_payload = EncryptedPayload::Encrypted {
    ciphertext: /* valid ciphertext */,
    extra_config: /* valid config */,
    payload_hash: /* valid hash */,
};

// Force transition to Decrypted state without proper decryption
// (This would be done by directly constructing the Decrypted variant)
let malicious_payload = EncryptedPayload::Decrypted {
    ciphertext: /* same ciphertext */,
    extra_config: /* same config */,
    payload_hash: /* same hash */,
    eval_proof: /* fake proof */,
    executable: /* arbitrary executable */,
    decryption_nonce: 0,
};

// Include this in a transaction and propose block
// When other validators process this block, they will panic at:
// consensus/src/pipeline/decryption_pipeline_builder.rs:136-137
```

When honest validators receive and process this block, they will all panic simultaneously at the `.expect()` calls in the decryption pipeline, causing complete network liveness failure.

## Notes
This vulnerability represents a critical gap between API-level validation and consensus-level validation. While the API correctly validates that submitted encrypted transactions are in the `Encrypted` state, there is no corresponding validation when blocks are received through consensus. This asymmetry allows Byzantine validators to bypass the intended invariant that all encrypted payloads entering the decryption pipeline must be in the `Encrypted` state, leading to deterministic panics across all honest validators.

### Citations

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L136-137)
```rust
                            p.into_decrypted(eval_proof, executable, nonce)
                                .expect("must happen")
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L142-143)
```rust
                        .as_encrypted_payload_mut()
                        .map(|p| p.into_failed_decryption(eval_proof).expect("must happen"))
```

**File:** types/src/transaction/encrypted_payload.rs (L107-114)
```rust
        let Self::Encrypted {
            ciphertext,
            extra_config,
            payload_hash,
        } = self
        else {
            bail!("Payload is not in Encrypted state");
        };
```

**File:** types/src/transaction/encrypted_payload.rs (L127-135)
```rust
    pub fn into_failed_decryption(&mut self, eval_proof: EvalProof) -> anyhow::Result<()> {
        let Self::Encrypted {
            ciphertext,
            extra_config,
            payload_hash,
        } = self
        else {
            bail!("Payload is not in Encrypted state");
        };
```

**File:** consensus/consensus-types/src/block.rs (L469-551)
```rust
    pub fn verify_well_formed(&self) -> anyhow::Result<()> {
        ensure!(
            !self.is_genesis_block(),
            "We must not accept genesis from others"
        );
        let parent = self.quorum_cert().certified_block();
        ensure!(
            parent.round() < self.round(),
            "Block must have a greater round than parent's block"
        );
        ensure!(
            parent.epoch() == self.epoch(),
            "block's parent should be in the same epoch"
        );
        if parent.has_reconfiguration() {
            ensure!(
                self.payload().is_none_or(|p| p.is_empty()),
                "Reconfiguration suffix should not carry payload"
            );
        }

        if let Some(payload) = self.payload() {
            payload.verify_epoch(self.epoch())?;
        }

        if let Some(failed_authors) = self.block_data().failed_authors() {
            // when validating for being well formed,
            // allow for missing failed authors,
            // for whatever reason (from different max configuration, etc),
            // but don't allow anything that shouldn't be there.
            //
            // we validate the full correctness of this field in round_manager.process_proposal()
            let succ_round = self.round() + u64::from(self.is_nil_block());
            let skipped_rounds = succ_round.checked_sub(parent.round() + 1);
            ensure!(
                skipped_rounds.is_some(),
                "Block round is smaller than block's parent round"
            );
            ensure!(
                failed_authors.len() <= skipped_rounds.unwrap() as usize,
                "Block has more failed authors than missed rounds"
            );
            let mut bound = parent.round();
            for (round, _) in failed_authors {
                ensure!(
                    bound < *round && *round < succ_round,
                    "Incorrect round in failed authors"
                );
                bound = *round;
            }
        }

        if self.is_nil_block() || parent.has_reconfiguration() {
            ensure!(
                self.timestamp_usecs() == parent.timestamp_usecs(),
                "Nil/reconfig suffix block must have same timestamp as parent"
            );
        } else {
            ensure!(
                self.timestamp_usecs() > parent.timestamp_usecs(),
                "Blocks must have strictly increasing timestamps"
            );

            let current_ts = duration_since_epoch();

            // we can say that too far is 5 minutes in the future
            const TIMEBOUND: u64 = 300_000_000;
            ensure!(
                self.timestamp_usecs() <= (current_ts.as_micros() as u64).saturating_add(TIMEBOUND),
                "Blocks must not be too far in the future"
            );
        }
        ensure!(
            !self.quorum_cert().ends_epoch(),
            "Block cannot be proposed in an epoch that has ended"
        );
        debug_checked_verify_eq!(
            self.id(),
            self.block_data.hash(),
            "Block id mismatch the hash"
        );
        Ok(())
    }
```

**File:** consensus/src/round_manager.rs (L1111-1286)
```rust
    async fn process_proposal(&mut self, proposal: Block) -> anyhow::Result<()> {
        let author = proposal
            .author()
            .expect("Proposal should be verified having an author");

        if !self.vtxn_config.enabled()
            && matches!(
                proposal.block_data().block_type(),
                BlockType::ProposalExt(_)
            )
        {
            counters::UNEXPECTED_PROPOSAL_EXT_COUNT.inc();
            bail!("ProposalExt unexpected while the vtxn feature is disabled.");
        }

        if let Some(vtxns) = proposal.validator_txns() {
            for vtxn in vtxns {
                let vtxn_type_name = vtxn.type_name();
                ensure!(
                    is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                    "unexpected validator txn: {:?}",
                    vtxn_type_name
                );
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
            }
        }

        let (num_validator_txns, validator_txns_total_bytes): (usize, usize) =
            proposal.validator_txns().map_or((0, 0), |txns| {
                txns.iter().fold((0, 0), |(count_acc, size_acc), txn| {
                    (count_acc + 1, size_acc + txn.size_in_bytes())
                })
            });

        let num_validator_txns = num_validator_txns as u64;
        let validator_txns_total_bytes = validator_txns_total_bytes as u64;
        let vtxn_count_limit = self.vtxn_config.per_block_limit_txn_count();
        let vtxn_bytes_limit = self.vtxn_config.per_block_limit_total_bytes();
        let author_hex = author.to_hex();
        PROPOSED_VTXN_COUNT
            .with_label_values(&[&author_hex])
            .inc_by(num_validator_txns);
        PROPOSED_VTXN_BYTES
            .with_label_values(&[&author_hex])
            .inc_by(validator_txns_total_bytes);
        info!(
            vtxn_count_limit = vtxn_count_limit,
            vtxn_count_proposed = num_validator_txns,
            vtxn_bytes_limit = vtxn_bytes_limit,
            vtxn_bytes_proposed = validator_txns_total_bytes,
            proposer = author_hex,
            "Summarizing proposed validator txns."
        );

        ensure!(
            num_validator_txns <= vtxn_count_limit,
            "process_proposal failed with per-block vtxn count limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_txn_count(),
            num_validator_txns
        );
        ensure!(
            validator_txns_total_bytes <= vtxn_bytes_limit,
            "process_proposal failed with per-block vtxn bytes limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_total_bytes(),
            validator_txns_total_bytes
        );
        let payload_len = proposal.payload().map_or(0, |payload| payload.len());
        let payload_size = proposal.payload().map_or(0, |payload| payload.size());
        ensure!(
            num_validator_txns + payload_len as u64 <= self.local_config.max_receiving_block_txns,
            "Payload len {} exceeds the limit {}",
            payload_len,
            self.local_config.max_receiving_block_txns,
        );

        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );

        ensure!(
            self.proposer_election.is_valid_proposal(&proposal),
            "[RoundManager] Proposer {} for block {} is not a valid proposer for this round or created duplicate proposal",
            author,
            proposal,
        );

        // If the proposal contains any inline transactions that need to be denied
        // (e.g., due to filtering) drop the message and do not vote for the block.
        if let Err(error) = self
            .block_store
            .check_denied_inline_transactions(&proposal, &self.block_txn_filter_config)
        {
            counters::REJECTED_PROPOSAL_DENY_TXN_COUNT.inc();
            bail!(
                "[RoundManager] Proposal for block {} contains denied inline transactions: {}. Dropping proposal!",
                proposal.id(),
                error
            );
        }

        if !proposal.is_opt_block() {
            // Validate that failed_authors list is correctly specified in the block.
            let expected_failed_authors = self.proposal_generator.compute_failed_authors(
                proposal.round(),
                proposal.quorum_cert().certified_block().round(),
                false,
                self.proposer_election.clone(),
            );
            ensure!(
                proposal.block_data().failed_authors().is_some_and(|failed_authors| *failed_authors == expected_failed_authors),
                "[RoundManager] Proposal for block {} has invalid failed_authors list {:?}, expected {:?}",
                proposal.round(),
                proposal.block_data().failed_authors(),
                expected_failed_authors,
            );
        }

        let block_time_since_epoch = Duration::from_micros(proposal.timestamp_usecs());

        ensure!(
            block_time_since_epoch < self.round_state.current_round_deadline(),
            "[RoundManager] Waiting until proposal block timestamp usecs {:?} \
            would exceed the round duration {:?}, hence will not vote for this round",
            block_time_since_epoch,
            self.round_state.current_round_deadline(),
        );

        observe_block(proposal.timestamp_usecs(), BlockStage::SYNCED);
        if proposal.is_opt_block() {
            observe_block(proposal.timestamp_usecs(), BlockStage::SYNCED_OPT_BLOCK);
        }

        // Since processing proposal is delayed due to backpressure or payload availability, we add
        // the block to the block store so that we don't need to fetch it from remote once we
        // are out of the backpressure. Please note that delayed processing of proposal is not
        // guaranteed to add the block to the block store if we don't get out of the backpressure
        // before the timeout, so this is needed to ensure that the proposed block is added to
        // the block store irrespective. Also, it is possible that delayed processing of proposal
        // tries to add the same block again, which is okay as `insert_block` call
        // is idempotent.
        self.block_store
            .insert_block(proposal.clone())
            .await
            .context("[RoundManager] Failed to insert the block into BlockStore")?;

        let block_store = self.block_store.clone();
        if block_store.check_payload(&proposal).is_err() {
            debug!("Payload not available locally for block: {}", proposal.id());
            counters::CONSENSUS_PROPOSAL_PAYLOAD_AVAILABILITY
                .with_label_values(&["missing"])
                .inc();
            let start_time = Instant::now();
            let deadline = self.round_state.current_round_deadline();
            let future = async move {
                (
                    block_store.wait_for_payload(&proposal, deadline).await,
                    proposal,
                    start_time,
                )
            }
            .boxed();
            self.futures.push(future);
            return Ok(());
        }

        counters::CONSENSUS_PROPOSAL_PAYLOAD_AVAILABILITY
            .with_label_values(&["available"])
            .inc();

        self.check_backpressure_and_process_proposal(proposal).await
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L461-471)
```rust
        let decryption_fut = spawn_shared_fut(
            Self::decrypt_encrypted_txns(
                materialize_fut,
                block.clone(),
                self.signer.author(),
                self.secret_share_config.clone(),
                derived_self_key_share_tx,
                secret_shared_key_rx,
            ),
            Some(&mut abort_handles),
        );
```

**File:** api/src/transactions.rs (L1332-1338)
```rust
                if !payload.is_encrypted() {
                    return Err(SubmitTransactionError::bad_request_with_code(
                        "Encrypted transaction must be in encrypted state",
                        AptosErrorCode::InvalidInput,
                        ledger_info,
                    ));
                }
```
