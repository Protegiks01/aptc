# Audit Report

## Title
Unvalidated Chunk Count Causes Index Out-of-Bounds Panic in DKG Transcript Verification

## Summary
The PVSS transcript verification code does not validate that chunked ElGamal ciphertexts contain the expected number of chunks before accessing a fixed-size array, allowing a single malicious validator to crash all honest validator nodes during Distributed Key Generation (DKG) transcript verification, causing total network liveness failure.

## Finding Description

The DKG protocol uses chunked ElGamal encryption where field elements are split into chunks. The verification code computes a Multi-Scalar Multiplication (MSM) that indexes into the precomputed `powers_of_radix` array without validating chunk counts. [1](#0-0) 

The `powers_of_radix` array has exactly `num_chunks_per_scalar(ell)` elements, computed during public parameter initialization: [2](#0-1) [3](#0-2) 

The only validation performed checks the outer dimension of `Cs` (number of players), not the inner dimensions (chunk counts per ciphertext): [4](#0-3) [5](#0-4) 

**Attack Propagation Path:**

1. Malicious validator constructs a `Subtranscript` with `Cs[i][j]` containing more than `num_chunks_per_scalar(ell)` chunks
2. The transcript is serialized via BCS and wrapped in a `ValidatorTransaction::DKGResult`: [6](#0-5) 

3. Validators process the transaction through the VM: [7](#0-6) 

4. VM deserializes and calls DKG verification: [8](#0-7) 

5. Which flows to the weighted transcript verification: [9](#0-8) 

6. The verification loop iterates `j in 0..Cs_flat[i].len()` and accesses `pp.powers_of_radix[j]` without bounds checking. When `j >= pp.powers_of_radix.len()`, Rust panics with "index out of bounds," terminating the validator process.

The sigma protocol and range proof verifications do not catch this structural issue because they verify cryptographic properties, not dimensional constraints.

## Impact Explanation

This vulnerability achieves **Critical Severity** under the Aptos Bug Bounty program criteria for **Total Loss of Liveness/Network Availability**.

A single malicious validator can crash all honest validator nodes by submitting a DKG transcript with oversized chunk vectors. Since DKG transcripts are processed as validator transactions during consensus, all validators attempting to verify the malformed transcript will panic simultaneously, halting the network.

The attack causes:
- Immediate validator process termination via Rust panic
- Network-wide consensus halt (all validators crash on the same malformed transaction)
- Manual intervention required to restore service
- Potential persistent crash loop if the malicious transaction remains in consensus proposals

This does NOT require:
- Validator majority control (< 1/3 Byzantine assumption holds)
- Cryptographic breaks
- Network-level attacks

It exploits a simple bounds-checking failure in critical consensus infrastructure, meeting the criteria for "Total loss of liveness/network availability" where "All validators unable to progress."

## Likelihood Explanation

**Likelihood: High**

**Attacker Requirements:**
- Participation as a validator (standard Byzantine threat model allows < 1/3 malicious validators)
- Knowledge of `num_chunks_per_scalar(ell)` (publicly available from protocol parameters)
- Ability to construct and serialize a malformed `Subtranscript` structure (trivial - just create oversized chunk vectors)

**Attack Complexity: Low**
- No cryptographic operations required
- No timing dependencies
- Single malicious transcript submission sufficient
- Deterministic crash behavior (100% reliable)
- BCS serialization accepts arbitrary vector dimensions without protocol-specific validation

**Detection Difficulty:**
- Crash manifests as generic Rust panic
- No clear attribution without forensic analysis
- May be misdiagnosed as implementation bug rather than attack

**Operational Context:**
- DKG verification is part of validator transaction processing during epoch transitions
- Cannot be bypassed without protocol changes
- Affects all validators simultaneously when processing the same malformed transcript

## Recommendation

Add explicit validation that each ciphertext chunk vector has exactly the expected number of chunks before the MSM computation:

```rust
// Before line 255 in weighted_transcript.rs
let expected_chunks = num_chunks_per_scalar::<E::ScalarField>(pp.ell) as usize;
for i in 0..Cs_flat.len() {
    if Cs_flat[i].len() != expected_chunks {
        bail!(
            "Expected {} chunks per ciphertext, but got {} for ciphertext {}",
            expected_chunks,
            Cs_flat[i].len(),
            i
        );
    }
}
```

Alternatively, use safe array access with `.get()` and proper error handling instead of direct indexing.

## Proof of Concept

```rust
#[test]
fn test_oversized_chunks_panic() {
    use aptos_dkg::pvss::chunky::weighted_transcript::Transcript;
    use aptos_dkg::pvss::chunky::public_parameters::PublicParameters;
    
    // Setup normal parameters
    let mut rng = rand::thread_rng();
    let pp = PublicParameters::default();
    let sc = /* create secret sharing config */;
    
    // Generate a valid transcript
    let mut trx = Transcript::generate(&sc, &pp, &mut rng);
    
    // Maliciously modify to add extra chunks
    let expected_chunks = num_chunks_per_scalar(pp.ell) as usize;
    trx.subtrs.Cs[0][0].push(/* extra chunk point */);
    
    // Serialize via BCS (will succeed - no validation)
    let bytes = bcs::to_bytes(&trx).unwrap();
    let malicious_trx: Transcript = bcs::from_bytes(&bytes).unwrap();
    
    // Verify will panic with index out of bounds
    // This would crash all validators processing this transcript
    let result = std::panic::catch_unwind(|| {
        malicious_trx.verify(&sc, &pp, &spks, &eks, &aux)
    });
    
    assert!(result.is_err()); // Panics instead of returning error
}
```

## Notes

This vulnerability demonstrates a critical failure in input validation for consensus-critical data structures. The BCS deserialization layer validates structural integrity (proper encoding, sufficient bytes) but cannot enforce protocol-specific semantic constraints like expected chunk counts. This responsibility falls on the application layer, which failed to implement the necessary checks before performing array indexing operations that assume fixed-size dimensions based on protocol parameters.

### Citations

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L140-153)
```rust
        if self.subtrs.Cs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of chunked ciphertexts, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Cs.len()
            );
        }
        if self.subtrs.Vs.len() != sc.get_total_num_players() {
            bail!(
                "Expected {} arrays of commitment elements, but got {}",
                sc.get_total_num_players(),
                self.subtrs.Vs.len()
            );
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L247-252)
```rust
        let Cs_flat: Vec<_> = self.subtrs.Cs.iter().flatten().cloned().collect();
        assert_eq!(
            Cs_flat.len(),
            sc.get_total_weight(),
            "Number of ciphertexts does not equal number of weights"
        ); // TODO what if zero weight?
```

**File:** crates/aptos-dkg/src/pvss/chunky/weighted_transcript.rs (L255-262)
```rust
        for i in 0..Cs_flat.len() {
            for j in 0..Cs_flat[i].len() {
                let base = Cs_flat[i][j];
                let exp = pp.powers_of_radix[j] * powers_of_beta[i];
                base_vec.push(base);
                exp_vec.push(exp);
            }
        }
```

**File:** crates/aptos-dkg/src/pvss/chunky/public_parameters.rs (L35-40)
```rust
fn compute_powers_of_radix<E: Pairing>(ell: u8) -> Vec<E::ScalarField> {
    utils::powers(
        E::ScalarField::from(1u64 << ell),
        num_chunks_per_scalar::<E::ScalarField>(ell) as usize,
    )
}
```

**File:** crates/aptos-dkg/src/pvss/chunky/public_parameters.rs (L95-95)
```rust
            powers_of_radix: compute_powers_of_radix::<E>(serialized.ell),
```

**File:** types/src/validator_txn.rs (L15-18)
```rust
pub enum ValidatorTransaction {
    DKGResult(DKGTranscript),
    ObservedJWKUpdate(jwks::QuorumCertifiedUpdate),
}
```

**File:** aptos-move/aptos-vm/src/validator_txns/mod.rs (L24-27)
```rust
        match txn {
            ValidatorTransaction::DKGResult(dkg_node) => {
                self.process_dkg_result(resolver, module_storage, log_context, session_id, dkg_node)
            },
```

**File:** aptos-move/aptos-vm/src/validator_txns/dkg.rs (L106-112)
```rust
        let transcript = bcs::from_bytes::<<DefaultDKG as DKGTrait>::Transcript>(
            dkg_node.transcript_bytes.as_slice(),
        )
        .map_err(|_| Expected(TranscriptDeserializationFailed))?;

        DefaultDKG::verify_transcript(&pub_params, &transcript)
            .map_err(|_| Expected(TranscriptVerificationFailed))?;
```

**File:** types/src/dkg/real_dkg/mod.rs (L368-374)
```rust
        trx.main.verify(
            &params.pvss_config.wconfig,
            &params.pvss_config.pp,
            &spks,
            &all_eks,
            &aux,
        )?;
```
