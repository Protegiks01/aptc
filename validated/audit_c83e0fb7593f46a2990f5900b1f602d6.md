# Audit Report

## Title
Race Condition in Layout Cache Invalidation During Module Publishing Causes Non-Deterministic Execution and Consensus Failure

## Summary
A critical race condition exists in the layout cache management during parallel block execution. When a transaction publishes an upgraded module, the new module becomes visible to concurrent transactions before the layout cache is flushed, allowing concurrent transactions to load the new module but deserialize structs using stale cached layouts from the old module, leading to type confusion and consensus divergence across validators.

## Finding Description

The vulnerability occurs in the interaction between module publishing and layout caching during parallel block execution.

**Architecture Background:**

The global module cache maintains two separate data structures with different versioning semantics:
- Module cache with "overridden" flags for version tracking [1](#0-0) 
- Layout cache keyed only by struct identifier without version information [2](#0-1) 

**The Vulnerability:**

When a transaction publishes a module upgrade, the commit sequence exposes a race window [3](#0-2) :

1. Line 564: New module added to per-block cache via `add_module_write_to_module_cache`, marking the old version as overridden [4](#0-3) 
2. **RACE WINDOW**: New module is visible to all concurrent transactions
3. Line 574: Layout cache flushed

During this window, concurrent workers can execute transactions [5](#0-4) . The `commit_hooks_try_lock()` is a non-blocking try-lock, allowing other workers to proceed with execution tasks while one worker processes commits.

A concurrent transaction T2 can:
- Load the NEW module from per-block cache (since the old version is marked overridden) [6](#0-5) 
- Request the struct layout via `get_struct_layout` which queries the global cache using only StructKey [7](#0-6) 
- Receive the OLD cached layout because StructKey contains no version component

Even though cached layouts trigger module re-reads for gas charging, these re-reads load the NEW module but still return the OLD layout [8](#0-7) . The comment explicitly states module re-reading is for "gas charging" and "transaction invalidation", but the cached layout itself is not validated against the new module version.

The mismatched layout is then used for deserialization during execution [9](#0-8) , causing type confusion when field counts or types differ between module versions.

## Impact Explanation

**Critical Severity: Consensus/Safety Violation**

This vulnerability breaks the fundamental deterministic execution invariant required for blockchain consensus. When different validators execute the same block:

- Validator A: T2 executes before T1 flushes cache → uses old layout → produces state_root_A
- Validator B: T2 executes after T1 flushes cache → recomputes new layout → produces state_root_B
- state_root_A ≠ state_root_B

Both validators read the same NEW module (recorded in their read sets, so validation passes), but use different layouts for deserialization. This produces different execution results and different state roots for identical blocks, causing consensus failure.

This meets the Aptos bug bounty **Critical Severity** criteria for "Consensus/Safety Violations" where different validators commit different state roots, resulting in network partition that requires a hard fork to resolve. Transaction execution becomes non-deterministic across the network, compromising fund safety and chain integrity.

## Likelihood Explanation

**Medium-High Likelihood:**

1. **Common Trigger**: Module upgrades are standard governance operations on Aptos
2. **Natural Occurrence**: Parallel execution with 8+ worker threads creates frequent overlapping windows
3. **No Special Timing**: Race manifests probabilistically during normal operation - no precise coordination needed
4. **Broad Attack Surface**: Any module upgrade changing struct layouts (adding/removing/reordering fields) triggers the vulnerability
5. **Silent Failure**: No errors thrown - validators silently diverge on state roots
6. **No Special Permissions**: Any account authorized for module publishing can trigger this

The race window exists for the duration between adding modules to cache and flushing layouts - a window during which multiple worker threads are actively executing speculative transactions. With typical parallel execution configurations, transaction T2 has a high probability of executing during T1's commit window.

## Recommendation

Implement atomic module publishing with layout cache invalidation. Options include:

1. **Immediate Option**: Move `flush_layout_cache()` call before `add_module_write_to_module_cache` loop, or hold an exclusive lock during the entire publish operation to prevent concurrent execution.

2. **Long-term Fix**: Add version information to StructKey or implement a generation counter for layout cache entries that is checked during cache reads. When a layout is retrieved, verify it was computed from the currently visible module version.

3. **Alternative**: Make layout cache reads track dependencies similar to module reads, ensuring transactions are invalidated when layouts become stale.

## Proof of Concept

While a full executable PoC would require complex parallel execution setup, the vulnerability can be demonstrated through code analysis:

```rust
// T1 worker thread:
publish_module_write_set() {
    for write in module_write_set {
        add_module_write_to_module_cache(write, ...); // Line 564 - NEW module visible
    }
    // <-- RACE WINDOW HERE
    if published {
        global_module_cache.flush_layout_cache(); // Line 574 - cache flushed
    }
}

// T2 worker thread (concurrent):
execute_transaction() {
    module = get_module_or_build_with(...); // Gets NEW module
    layout = get_struct_layout(&struct_key); // Gets OLD cached layout
    deserialize_with_layout(bytes, layout); // Type confusion!
}
```

The race is timing-dependent but highly probable in production with multiple validators executing the same block at slightly different speeds.

## Notes

This vulnerability demonstrates a subtle interaction between module versioning and layout caching in the parallel execution engine. The module cache properly tracks versions with "overridden" flags, but the layout cache lacks equivalent version tracking, creating a consistency gap exploitable during the module publishing window.

### Citations

**File:** aptos-move/block-executor/src/code_cache_global.rs (L89-97)
```rust
pub struct GlobalModuleCache<K, D, V, E> {
    /// Module cache containing the verified code.
    module_cache: HashMap<K, Entry<D, V, E>>,
    /// Sum of serialized sizes (in bytes) of all cached modules.
    size: usize,
    /// Cached layouts of structs or enums. This cache stores roots only and is invalidated when
    /// modules are published.
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L272-318)
```rust
pub(crate) fn add_module_write_to_module_cache<T: BlockExecutableTransaction>(
    write: &ModuleWrite<T::Value>,
    txn_idx: TxnIndex,
    runtime_environment: &RuntimeEnvironment,
    global_module_cache: &GlobalModuleCache<ModuleId, CompiledModule, Module, AptosModuleExtension>,
    per_block_module_cache: &impl ModuleCache<
        Key = ModuleId,
        Deserialized = CompiledModule,
        Verified = Module,
        Extension = AptosModuleExtension,
        Version = Option<TxnIndex>,
    >,
) -> Result<(), PanicError> {
    let state_value = write
        .write_op()
        .as_state_value()
        .ok_or_else(|| PanicError::CodeInvariantError("Modules cannot be deleted".to_string()))?;

    // Since we have successfully serialized the module when converting into this transaction
    // write, the deserialization should never fail.
    let compiled_module = runtime_environment
        .deserialize_into_compiled_module(state_value.bytes())
        .map_err(|err| {
            let msg = format!("Failed to construct the module from state value: {:?}", err);
            PanicError::CodeInvariantError(msg)
        })?;
    let extension = Arc::new(AptosModuleExtension::new(state_value));

    per_block_module_cache
        .insert_deserialized_module(
            write.module_id().clone(),
            compiled_module,
            extension,
            Some(txn_idx),
        )
        .map_err(|err| {
            let msg = format!(
                "Failed to insert code for module {}::{} at version {} to module cache: {:?}",
                write.module_address(),
                write.module_name(),
                txn_idx,
                err
            );
            PanicError::CodeInvariantError(msg)
        })?;
    global_module_cache.mark_overridden(write.module_id());
    Ok(())
```

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L79-83)
```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
}
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L559-577)
```rust
        for write in output_before_guard.module_write_set().values() {
            published = true;
            if scheduler.is_v2() {
                module_ids_for_v2.insert(write.module_id().clone());
            }
            add_module_write_to_module_cache::<T>(
                write,
                txn_idx,
                runtime_environment,
                global_module_cache,
                versioned_cache.module_cache(),
            )?;
        }
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
        Ok(published)
```

**File:** aptos-move/block-executor/src/executor.rs (L1454-1474)
```rust
        loop {
            while scheduler.commit_hooks_try_lock() {
                // Perform sequential commit hooks.
                while let Some((txn_idx, incarnation)) = scheduler.start_commit()? {
                    self.prepare_and_queue_commit_ready_txn(
                        txn_idx,
                        incarnation,
                        num_txns,
                        executor,
                        block,
                        num_workers as usize,
                        runtime_environment,
                        scheduler_wrapper,
                        shared_sync_params,
                    )?;
                }

                scheduler.commit_hooks_unlock();
            }

            match scheduler.next_task(worker_id)? {
```

**File:** aptos-move/block-executor/src/code_cache.rs (L148-174)
```rust
        match &self.latest_view {
            ViewState::Sync(state) => {
                // Check the transaction-level cache with already read modules first.
                if let CacheRead::Hit(read) = state.captured_reads.borrow().get_module_read(key) {
                    return Ok(read);
                }

                // Otherwise, it is a miss. Check global cache.
                if let Some(module) = self.global_module_cache.get(key) {
                    state
                        .captured_reads
                        .borrow_mut()
                        .capture_global_cache_read(key.clone(), module.clone());
                    return Ok(Some((module, Self::Version::default())));
                }

                // If not global cache, check per-block cache.
                let _timer = GLOBAL_MODULE_CACHE_MISS_SECONDS.start_timer();
                let read = state
                    .versioned_map
                    .module_cache()
                    .get_module_or_build_with(key, builder)?;
                state
                    .captured_reads
                    .borrow_mut()
                    .capture_per_block_cache_read(key.clone(), read.clone());
                Ok(read)
```

**File:** aptos-move/block-executor/src/code_cache.rs (L254-257)
```rust
impl<T: Transaction, S: TStateView<Key = T::Key>> LayoutCache for LatestView<'_, T, S> {
    fn get_struct_layout(&self, key: &StructKey) -> Option<LayoutCacheEntry> {
        self.global_module_cache.get_struct_layout_entry(key)
    }
```

**File:** third_party/move/move-vm/runtime/src/storage/loader/lazy.rs (L203-221)
```rust
    fn load_layout_from_cache(
        &self,
        gas_meter: &mut impl DependencyGasMeter,
        traversal_context: &mut TraversalContext,
        key: &StructKey,
    ) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
        let entry = self.module_storage.get_struct_layout(key)?;
        let (layout, modules) = entry.unpack();
        for module_id in modules.iter() {
            // Re-read all modules for this layout, so that transaction gets invalidated
            // on module publish. Also, we re-read them in exactly the same way as they
            // were traversed during layout construction, so gas charging should be exactly
            // the same as on the cache miss.
            if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
                return Some(Err(err));
            }
        }
        Some(Ok(layout))
    }
```

**File:** third_party/move/move-vm/runtime/src/data_cache.rs (L273-300)
```rust
        let layout_with_delayed_fields = layout_converter.type_to_type_layout_with_delayed_fields(
            gas_meter,
            traversal_context,
            ty,
            false,
        )?;

        let (data, bytes_loaded) = {
            let module = metadata_loader.load_module_for_metadata(
                gas_meter,
                traversal_context,
                &struct_tag.module_id(),
            )?;

            // If we need to process delayed fields, we pass type layout to remote storage. Remote
            // storage, in turn ensures that all delayed field values are pre-processed.
            resource_resolver.get_resource_bytes_with_metadata_and_layout(
                addr,
                &struct_tag,
                &module.metadata,
                layout_with_delayed_fields.layout_when_contains_delayed_fields(),
            )?
        };

        let function_value_extension = FunctionValueExtensionAdapter { module_storage };
        let (layout, contains_delayed_fields) = layout_with_delayed_fields.unpack();
        let value = match data {
            Some(blob) => {
```
