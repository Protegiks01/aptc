# Audit Report

## Title
V2 Batch Garbage Collection Failure Due to Wrong Delete Method Call Causes Unbounded Storage Growth

## Summary
The `gc_previous_epoch_batches_from_db_v2()` function contains a critical logic bug where it reads V2 batches from the "batch_v2" column family but incorrectly calls the V1 deletion method that targets the "batch" column family. This causes V2 batches from old epochs to never be cleaned up, resulting in unbounded storage growth that can exhaust disk space and cause validator node failures.

## Finding Description

The quorum store maintains two separate column families for batch storage: "batch" (V1) and "batch_v2" (V2), as defined in the schema constants. [1](#0-0) 

The `delete_batches()` function operates exclusively on the V1 "batch" column family using `BatchSchema`, which explicitly targets the "batch" column family: [2](#0-1) [3](#0-2) 

In contrast, `delete_batches_v2()` correctly operates on the V2 "batch_v2" column family using `BatchV2Schema`: [4](#0-3) [5](#0-4) 

**The critical bug exists in `gc_previous_epoch_batches_from_db_v2()`**. This function reads V2 batches from the "batch_v2" column family using `get_all_batches_v2()` at line 214, but then incorrectly calls `delete_batches()` instead of `delete_batches_v2()` at line 241: [6](#0-5) 

The consequence is that the function attempts to delete V2 batch digests from the V1 "batch" column family where they don't exist. Since RocksDB delete operations are idempotent, deleting a non-existent key is a silent no-op. The V2 batches remain in the "batch_v2" column family indefinitely.

To confirm this is a bug and not intended behavior, the parallel V1 function `gc_previous_epoch_batches_from_db_v1()` correctly reads V1 batches and deletes them using `delete_batches()`: [7](#0-6) 

Additionally, the related function `populate_cache_and_gc_expired_batches_v2()` correctly uses `delete_batches_v2()` for V2 batches: [8](#0-7) 

The garbage collection function is invoked at every epoch transition when `is_new_epoch` is true: [9](#0-8) 

V2 batches are actively created and persisted to the database when the `is_v2()` check returns true: [10](#0-9) 

The `BatchInfoExt` enum supports both V1 and V2 variants with the `is_v2()` method distinguishing between them: [11](#0-10) [12](#0-11) 

**Root Cause**: This is a copy-paste error where `gc_previous_epoch_batches_from_db_v2()` was created from the V1 version but line 241 wasn't updated to call the correct V2 deletion method.

**Attack Path:**
1. V2 batches are created during normal transaction processing
2. At each epoch transition, `gc_previous_epoch_batches_from_db_v2()` attempts to clean old batches
3. The function reads V2 batches but calls the V1 deletion method
4. V2 batches are never deleted from the "batch_v2" column family
5. Over many epochs, V2 batches accumulate indefinitely
6. Disk space is gradually exhausted, causing validator nodes to crash or become unable to sync
7. An attacker can accelerate this by maintaining high transaction volume

**Broken Invariant**: The code violates the **State Consistency** invariant - the database state becomes inconsistent with the intended cleanup logic, with old batches persisting when they should be purged.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty criteria:

1. **State Inconsistencies Requiring Manual Intervention**: Old V2 batches accumulate indefinitely in the database, creating a divergence between intended state (clean database after GC) and actual state (growing collection of stale batches). Manual intervention is required to clean the database, fitting the Medium severity category definition.

2. **Resource Exhaustion Leading to Availability Issues**: Over time, the accumulated batches will:
   - Consume increasing disk space until exhaustion
   - Degrade database performance due to larger data sets
   - Cause validator nodes to crash when disk space runs out
   - Prevent nodes from syncing if disk space is insufficient

3. **Exploitable by Unprivileged Attackers**: Any user can submit transactions to create batches, and by maintaining high transaction volume, can accelerate the accumulation of stale V2 batches. No special permissions or stake is required.

This is NOT a network DoS attack (which is out of scope). This is a **logic bug** causing a **storage leak** similar to memory leaks or file handle leaks. The issue is gradual resource exhaustion from incorrect garbage collection, not network flooding.

While this doesn't directly cause consensus safety violations or immediate fund loss, it creates a path to validator node unavailability through resource exhaustion, meeting the criteria for Medium severity per Aptos bug bounty guidelines.

## Likelihood Explanation

This issue has **HIGH likelihood** of occurrence:

1. **Guaranteed Trigger**: The bug triggers automatically at every epoch transition when V2 batches exist in the database
2. **Active Feature**: V2 batches are actively created when the V2 batch functionality is enabled
3. **Cumulative Effect**: The impact compounds over time - each epoch adds more undeletable batches
4. **No Self-Healing**: There is no automatic mechanism to clean up the accumulated batches
5. **Attacker Acceleration**: An attacker can trivially increase the rate of batch creation by sending more transactions

The time to disk exhaustion depends on:
- Transaction volume (higher volume = faster accumulation)
- Disk capacity (smaller disks fill faster)
- Epoch duration (more frequent epochs = more GC attempts that fail)
- V2 batch size and frequency

## Recommendation

**Fix**: Change line 241 in `gc_previous_epoch_batches_from_db_v2()` to call the correct V2 deletion method:

```rust
// Change from:
db.delete_batches(expired_keys)
    .expect("Deletion of expired keys should not fail");

// To:
db.delete_batches_v2(expired_keys)
    .expect("Deletion of expired keys should not fail");
```

This single-line change ensures that V2 batches are deleted from the correct "batch_v2" column family, matching the pattern used in:
- The V1 function `gc_previous_epoch_batches_from_db_v1()` 
- The related function `populate_cache_and_gc_expired_batches_v2()`

**Additional Recommendations**:
1. Add unit tests that verify V2 batches are actually deleted after garbage collection
2. Consider adding monitoring/metrics to track the size of the "batch_v2" column family
3. Review the codebase for similar copy-paste errors between V1 and V2 variants

## Proof of Concept

While a complete integration test would require a full validator setup with epoch transitions, the bug is evident from static code analysis. A test case should:

1. Create V2 batches from a previous epoch
2. Persist them to the database using `save_batch_v2()`
3. Call `gc_previous_epoch_batches_from_db_v2()` with a higher epoch number
4. Verify that the V2 batches are actually deleted from the "batch_v2" column family
5. The test will fail on the current code because `delete_batches()` targets the wrong column family

The bug is reproducible on any validator node where V2 batches are enabled and epoch transitions occur.

## Notes

This is a confirmed logic bug with clear code evidence. The vulnerability is automatically triggered at epoch transitions and has real security impact through resource exhaustion. The fix is straightforward - a single line change to call the correct deletion method.

### Citations

**File:** consensus/src/quorum_store/schema.rs (L14-16)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";
```

**File:** consensus/src/quorum_store/schema.rs (L19-26)
```rust
pub(crate) struct BatchSchema;

impl Schema for BatchSchema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfo>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_CF_NAME;
}
```

**File:** consensus/src/quorum_store/schema.rs (L49-56)
```rust
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L93-101)
```rust
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L123-131)
```rust
    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L156-160)
```rust
        if is_new_epoch {
            tokio::task::spawn_blocking(move || {
                Self::gc_previous_epoch_batches_from_db_v1(db_clone.clone(), epoch);
                Self::gc_previous_epoch_batches_from_db_v2(db_clone, epoch);
            });
```

**File:** consensus/src/quorum_store/batch_store.rs (L181-210)
```rust
    fn gc_previous_epoch_batches_from_db_v1(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db.get_all_batches().expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L212-243)
```rust
    fn gc_previous_epoch_batches_from_db_v2(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L500-513)
```rust
                if needs_db {
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L195-203)
```rust
pub enum BatchInfoExt {
    V1 {
        info: BatchInfo,
    },
    V2 {
        info: BatchInfo,
        extra: ExtraBatchInfo,
    },
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L263-265)
```rust
    pub fn is_v2(&self) -> bool {
        matches!(self, Self::V2 { .. })
    }
```
