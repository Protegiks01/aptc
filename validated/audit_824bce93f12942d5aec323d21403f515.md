# Audit Report

## Title
Non-Atomic Batch Writes in Event Pruner Cause API Failures and False Corruption Errors

## Summary
The EventStorePruner performs two separate database write operations to different RocksDB instances without transaction isolation, creating a race condition window where concurrent API queries can observe partial pruning state, resulting in false "DB corruption" errors and API service disruption.

## Finding Description

The vulnerability exists in the EventStorePruner's `prune()` method, which executes two non-atomic batch writes when the internal indexer database is enabled. [1](#0-0) 

These operations write to two separate RocksDB instances:

1. **First write**: Writes to the internal indexer database, deleting event index entries from `EventByKeySchema` and `EventByVersionSchema`. [2](#0-1)  The `prune_event_indices` method populates the indexer_batch with deletion operations. [3](#0-2) 

2. **Second write**: Writes to the event database, deleting actual event data from `EventSchema`. [4](#0-3) 

**Critical Configuration Requirement**: The internal indexer REQUIRES database sharding to be enabled, as enforced by the config sanitizer. [5](#0-4) 

**API Routing**: When database sharding is enabled, the API routes event queries to the indexer reader instead of the main database. [6](#0-5) 

**Race Condition Window**: Between the two write operations, there exists a critical race condition window where event indices have been deleted from the indexer DB but event data still exists in the event DB. During this window, API queries read from the indexer database and encounter missing index entries. The `lookup_events_by_key` method has a sequence discontinuity check that throws an error when it detects gaps in sequence numbers. [7](#0-6) 

**Attack Path**:
1. EventStorePruner begins pruning events containing sequence numbers 50-54
2. First write executes: Index entries for seq 50-54 are deleted from indexer DB and committed
3. **RACE WINDOW**: Before second write executes
4. User calls `/accounts/:address/events/:creation_number?start=48&limit=10`
5. API invokes `get_events_by_event_key` which routes to indexer reader
6. IndexerDB's `lookup_events_by_key` seeks indices for seq 48, 49 (found), then seq 50 (missing - deleted)
7. Iterator jumps to seq 55 (next available after pruned range)
8. Sequence discontinuity detected: expected 50, found 55
9. Error returned: "DB corruption: Sequence number not continuous."

**No Protection Mechanism**: Unlike other ledger read operations that check `error_if_ledger_pruned` before accessing data [8](#0-7) , the indexer's `get_events_by_event_key` method does NOT perform this check. [9](#0-8)  It only calls `ensure_cover_ledger_version` which checks if the indexer has caught up, not if data has been pruned. [10](#0-9) 

**Parallel Execution**: The pruner system executes sub-pruners in parallel without synchronization with readers. [11](#0-10) 

## Impact Explanation

**Severity: High** - This qualifies as "API crashes" under the High severity category (up to $50,000 per the Aptos bug bounty program).

**Impact:**
- **Service Disruption**: Public event query APIs return 500 Internal Server Error during pruning operations due to the `bail!` macro throwing unrecoverable errors
- **False Corruption Alerts**: Error messages incorrectly indicate "DB corruption: Sequence number not continuous." when the database is functioning normally - this is simply a race condition, not actual corruption
- **Application Failures**: Client applications dependent on event queries will crash or enter error states when receiving these errors
- **Operational Confusion**: Node operators may perform unnecessary database recovery procedures based on false corruption errors, wasting resources and potentially causing additional downtime
- **Availability Impact**: During active pruning (which occurs regularly based on configured prune windows), event querying becomes unreliable

The vulnerability affects all nodes with:
1. Pruning enabled (standard for production nodes to manage disk space)
2. Internal indexer enabled (required for API nodes serving event queries with DB sharding)
3. DB sharding enabled (enforced requirement for internal indexer)

## Likelihood Explanation

**Likelihood: High**

This vulnerability occurs naturally during normal operations:

1. **Frequent Trigger**: Pruning runs automatically based on the configured prune window, which for production nodes is typically continuous or daily to manage disk usage
2. **Wide Race Window**: The window between the two database writes depends on RocksDB write latency, which can be milliseconds to seconds under load - sufficient time for multiple API requests to land in the window
3. **No Special Access Required**: Any external user calling the public `/accounts/:address/events/:creation_number` API endpoint can observe the error
4. **High Traffic Scenarios**: Production API nodes serving many concurrent requests have high probability of queries landing in the race window during each pruning cycle
5. **No Synchronization**: There are no locks, reader-writer coordination, or transaction isolation mechanisms protecting readers from observing partial state during the two-phase write

The pruner manager tracks minimum readable versions but the event query path does not consult this value before reading, unlike other ledger operations.

## Recommendation

**Option 1: Add pruning protection check**
Add `error_if_ledger_pruned` check in the indexer's `get_events_by_event_key` method before calling `lookup_events_by_key`, similar to how other database read operations handle pruned data.

**Option 2: Atomic write operation**
Combine both database writes into a single atomic operation or use a two-phase commit protocol to ensure readers never observe partial pruning state.

**Option 3: Reader-writer synchronization**
Implement proper synchronization between the pruner and readers using read-write locks or version-based coordination to prevent readers from accessing data during pruning operations.

## Proof of Concept

To reproduce this vulnerability:

1. Set up an Aptos node with:
   - DB sharding enabled (`enable_storage_sharding: true`)
   - Internal indexer enabled with events (`enable_event: true`)
   - Pruning enabled with a reasonable prune window

2. Generate events by executing transactions that emit events

3. Run a script that continuously queries events via the API:
   ```
   GET /accounts/{address}/events/{creation_number}?start={seq}&limit=10
   ```

4. Trigger pruning or wait for automatic pruning to occur

5. Observe 500 Internal Server Error responses with message "DB corruption: Sequence number not continuous." during the race window between the two database writes

The error will occur intermittently when API queries land in the race window between the indexer DB write and the event DB write.

## Notes

This vulnerability is a race condition in the storage layer that causes API service disruption. While it doesn't lead to fund loss or consensus violations, it qualifies as HIGH severity under the Aptos bug bounty program's "API crashes" category. The false "DB corruption" error messages are particularly problematic as they may trigger unnecessary recovery procedures by node operators.

### Citations

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L43-81)
```rust
    fn prune(&self, current_progress: Version, target_version: Version) -> Result<()> {
        let mut batch = SchemaBatch::new();
        let mut indexer_batch = None;

        let indices_batch = if let Some(indexer_db) = self.indexer_db() {
            if indexer_db.event_enabled() {
                indexer_batch = Some(SchemaBatch::new());
            }
            indexer_batch.as_mut()
        } else {
            Some(&mut batch)
        };
        let num_events_per_version = self.ledger_db.event_db().prune_event_indices(
            current_progress,
            target_version,
            indices_batch,
        )?;
        self.ledger_db.event_db().prune_events(
            num_events_per_version,
            current_progress,
            target_version,
            &mut batch,
        )?;
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        if let Some(mut indexer_batch) = indexer_batch {
            indexer_batch.put::<InternalIndexerMetadataSchema>(
                &IndexerMetadataKey::EventPrunerProgress,
                &IndexerMetadataValue::Version(target_version),
            )?;
            self.expect_indexer_db()
                .get_inner_db_ref()
                .write_schemas(indexer_batch)?;
        }
        self.ledger_db.event_db().write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L192-222)
```rust
    pub(crate) fn prune_event_indices(
        &self,
        start: Version,
        end: Version,
        mut indices_batch: Option<&mut SchemaBatch>,
    ) -> Result<Vec<usize>> {
        let mut ret = Vec::new();

        let mut current_version = start;

        for events in self.get_events_by_version_iter(start, (end - start) as usize)? {
            let events = events?;
            ret.push(events.len());

            if let Some(ref mut batch) = indices_batch {
                for event in events {
                    if let ContractEvent::V1(v1) = event {
                        batch.delete::<EventByKeySchema>(&(*v1.key(), v1.sequence_number()))?;
                        batch.delete::<EventByVersionSchema>(&(
                            *v1.key(),
                            current_version,
                            v1.sequence_number(),
                        ))?;
                    }
                }
            }
            current_version += 1;
        }

        Ok(ret)
    }
```

**File:** config/src/config/internal_indexer_db_config.rs (L92-98)
```rust
        if !node_config.storage.rocksdb_configs.enable_storage_sharding
            && config.is_internal_indexer_db_enabled()
        {
            return Err(Error::ConfigSanitizerFailed(
                sanitizer_name,
                "Don't turn on internal indexer db if DB sharding is off".into(),
            ));
```

**File:** storage/indexer/src/indexer_reader.rs (L92-114)
```rust
    fn get_events_by_event_key(
        &self,
        event_key: &EventKey,
        start_seq_num: u64,
        order: Order,
        limit: u64,
        ledger_version: Version,
    ) -> anyhow::Result<Vec<EventWithVersion>> {
        if let Some(db_indexer_reader) = &self.db_indexer_reader {
            if db_indexer_reader.indexer_db.event_enabled() {
                return Ok(db_indexer_reader.get_events_by_event_key(
                    event_key,
                    start_seq_num,
                    order,
                    limit,
                    ledger_version,
                )?);
            } else {
                anyhow::bail!("Internal event index is not enabled")
            }
        }
        anyhow::bail!("DB indexer reader is not available")
    }
```

**File:** storage/indexer/src/db_indexer.rs (L163-172)
```rust
    pub fn ensure_cover_ledger_version(&self, ledger_version: Version) -> Result<()> {
        let indexer_latest_version = self.get_persisted_version()?;
        if let Some(indexer_latest_version) = indexer_latest_version {
            if indexer_latest_version >= ledger_version {
                return Ok(());
            }
        }

        bail!("ledger version too new")
    }
```

**File:** storage/indexer/src/db_indexer.rs (L232-238)
```rust
            if seq != cur_seq {
                let msg = if cur_seq == start_seq_num {
                    "First requested event is probably pruned."
                } else {
                    "DB corruption: Sequence number not continuous."
                };
                bail!("{} expected: {}, actual: {}", msg, cur_seq, seq);
```

**File:** storage/indexer/src/db_indexer.rs (L644-676)
```rust
    pub fn get_events_by_event_key(
        &self,
        event_key: &EventKey,
        start_seq_num: u64,
        order: Order,
        limit: u64,
        ledger_version: Version,
    ) -> Result<Vec<EventWithVersion>> {
        self.indexer_db
            .ensure_cover_ledger_version(ledger_version)?;
        error_if_too_many_requested(limit, MAX_REQUEST_LIMIT)?;
        let get_latest = order == Order::Descending && start_seq_num == u64::MAX;

        let cursor = if get_latest {
            // Caller wants the latest, figure out the latest seq_num.
            // In the case of no events on that path, use 0 and expect empty result below.
            self.indexer_db
                .get_latest_sequence_number(ledger_version, event_key)?
                .unwrap_or(0)
        } else {
            start_seq_num
        };

        // Convert requested range and order to a range in ascending order.
        let (first_seq, real_limit) = get_first_seq_num_and_limit(order, cursor, limit)?;

        // Query the index.
        let mut event_indices = self.indexer_db.lookup_events_by_key(
            event_key,
            first_seq,
            real_limit,
            ledger_version,
        )?;
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L280-280)
```rust
            self.error_if_ledger_pruned("Transaction", start_version)?;
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L78-84)
```rust
            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```
