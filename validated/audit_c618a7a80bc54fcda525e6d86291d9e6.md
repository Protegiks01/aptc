# Audit Report

## Title
Epoch Boundary Validation Bypass in Optimistic Fetch Requests via Inconsistent known_epoch and known_version

## Summary
The optimistic fetch validation logic in the storage service only validates that a client's `known_version` is not beyond the end of their claimed `known_epoch`, but fails to verify that `known_version` actually falls within the claimed `known_epoch`. This allows an attacker to claim a newer epoch than their version is actually in, bypassing proper epoch boundary handling and potentially causing state sync failures or invalid proofs.

## Finding Description
The vulnerable validation logic is located in the `identify_ready_and_invalid_optimistic_fetches` function. When a client is in an older epoch than the server, the code fetches the epoch ending ledger info for the client's claimed `highest_known_epoch` and performs validation. [1](#0-0) 

The validation at line 533 only checks whether the epoch ending version is less than or equal to the known version (`epoch_ending_ledger_info.ledger_info().version() <= highest_known_version`). This catches cases where a client claims to have synced past the end of their epoch, but does NOT validate that the client's version is actually within the epoch they claim to be in.

**Attack Scenario:**
1. Attacker's actual state: version 500, epoch N (where epoch N ends at version 1000)
2. Current server state: version 2500, epoch N+2 (where epoch N+1 ends at version 2000)  
3. Attacker sends: `NewTransactionsWithProofRequest { known_version: 500, known_epoch: N+1 }` [2](#0-1) 

The server processes this by:
- Fetching epoch ending ledger info for epoch N+1 (ends at version 2000)
- Validating: `2000 <= 500`? NO â†’ Marked as READY (passes validation)
- Setting target to epoch ending ledger info for epoch N+1 (version 2000)

The server then creates a storage request for transactions starting from version 501, potentially spanning both epoch N and epoch N+1, but with the target ledger info from epoch N+1. [3](#0-2) 

By claiming epoch N+1 when actually at a version in epoch N, the attacker bypasses proper epoch boundary protection. The correct validation should verify both:
1. `known_version > epoch_(N)_ending_version` (lower bound)
2. `known_version <= epoch_(N+1)_ending_version` (upper bound)

The current implementation only checks #2.

## Impact Explanation
This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria due to significant protocol violations:

1. **Epoch Boundary Bypass**: Epoch transitions are critical security boundaries in Aptos. The validator set changes at epoch boundaries, and proper validation ensures clients can verify state transitions across epochs using epoch change proofs.

2. **Invalid Proof Construction**: The server constructs transaction proofs against an incorrect epoch's ledger info, potentially creating proofs that clients cannot properly verify or that reference the wrong validator set.

3. **State Sync Integrity**: This breaks the state sync protocol's assumptions about epoch handling, which could lead to nodes falling out of sync or accepting invalid state.

4. **Protocol Violation**: State consistency invariants are violated when transactions from epoch N are paired with proofs from epoch N+1, potentially affecting the verifiability of state transitions.

## Likelihood Explanation
**Likelihood: High**

1. **No Privileged Access Required**: Any network peer can send optimistic fetch requests through the storage service network interface.

2. **Simple Exploit**: The attack requires only crafting a request with `known_epoch` set to a value higher than the epoch containing `known_version`.

3. **Direct Attack Vector**: The vulnerable code path is directly reachable through the network API without any rate limiting specific to invalid epoch claims.

4. **Realistic Preconditions**: The attack works during normal network operation without requiring special blockchain states or timing.

## Recommendation
Modify the validation logic to check both the lower and upper bounds of the epoch range:

```rust
// Fetch the epoch ending ledger info for the PREVIOUS epoch
let previous_epoch = highest_known_epoch.checked_sub(1);
if let Some(prev_epoch) = previous_epoch {
    let previous_epoch_ending = get_epoch_ending_ledger_info(..., prev_epoch, ...)?;
    
    // Validate that known_version is actually within the claimed epoch
    if previous_epoch_ending.ledger_info().version() >= highest_known_version {
        // Known version is not past the previous epoch - invalid claim
        peers_with_invalid_optimistic_fetches.lock().push(peer_network_id);
        continue;
    }
}

// Then check upper bound (existing check)
if epoch_ending_ledger_info.ledger_info().version() <= highest_known_version {
    peers_with_invalid_optimistic_fetches.lock().push(peer_network_id);
}
```

## Proof of Concept
A PoC would involve:
1. Creating a mock storage service with multiple epochs
2. Sending a `NewTransactionsWithProofRequest` with `known_version` in epoch N but `known_epoch` set to N+1
3. Verifying the request is marked as READY instead of INVALID
4. Observing that the server returns data with incorrect epoch context

The test infrastructure in `state-sync/storage-service/server/src/tests/optimistic_fetch.rs` demonstrates the testing pattern, but lacks coverage for this specific validation gap. [4](#0-3) 

## Notes
The existing test at line 141-142 validates the opposite case (known_version beyond epoch end), but there's no test coverage for the case where known_version is before the claimed epoch begins. This gap in test coverage mirrors the gap in the validation logic, suggesting this vulnerability was not considered during implementation.

### Citations

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L61-142)
```rust
    pub fn get_storage_request_for_missing_data(
        &self,
        config: StorageServiceConfig,
        target_ledger_info: &LedgerInfoWithSignatures,
    ) -> aptos_storage_service_types::Result<StorageServiceRequest, Error> {
        // Verify that the target version is higher than the highest known version
        let known_version = self.highest_known_version();
        let target_version = target_ledger_info.ledger_info().version();
        if target_version <= known_version {
            return Err(Error::InvalidRequest(format!(
                "Target version: {:?} is not higher than known version: {:?}!",
                target_version, known_version
            )));
        }

        // Calculate the number of versions to fetch
        let mut num_versions_to_fetch =
            target_version.checked_sub(known_version).ok_or_else(|| {
                Error::UnexpectedErrorEncountered(
                    "Number of versions to fetch has overflown!".into(),
                )
            })?;

        // Bound the number of versions to fetch by the maximum chunk size
        num_versions_to_fetch = min(
            num_versions_to_fetch,
            self.max_chunk_size_for_request(config),
        );

        // Calculate the start and end versions
        let start_version = known_version.checked_add(1).ok_or_else(|| {
            Error::UnexpectedErrorEncountered("Start version has overflown!".into())
        })?;
        let end_version = known_version
            .checked_add(num_versions_to_fetch)
            .ok_or_else(|| {
                Error::UnexpectedErrorEncountered("End version has overflown!".into())
            })?;

        // Create the storage request
        let data_request = match &self.request.data_request {
            DataRequest::GetNewTransactionOutputsWithProof(_) => {
                DataRequest::GetTransactionOutputsWithProof(TransactionOutputsWithProofRequest {
                    proof_version: target_version,
                    start_version,
                    end_version,
                })
            },
            DataRequest::GetNewTransactionsWithProof(request) => {
                DataRequest::GetTransactionsWithProof(TransactionsWithProofRequest {
                    proof_version: target_version,
                    start_version,
                    end_version,
                    include_events: request.include_events,
                })
            },
            DataRequest::GetNewTransactionsOrOutputsWithProof(request) => {
                DataRequest::GetTransactionsOrOutputsWithProof(
                    TransactionsOrOutputsWithProofRequest {
                        proof_version: target_version,
                        start_version,
                        end_version,
                        include_events: request.include_events,
                        max_num_output_reductions: request.max_num_output_reductions,
                    },
                )
            },
            DataRequest::GetNewTransactionDataWithProof(request) => {
                DataRequest::GetTransactionDataWithProof(GetTransactionDataWithProofRequest {
                    transaction_data_request_type: request.transaction_data_request_type,
                    proof_version: target_version,
                    start_version,
                    end_version,
                    max_response_bytes: request.max_response_bytes,
                })
            },
            request => unreachable!("Unexpected optimistic fetch request: {:?}", request),
        };
        let storage_request =
            StorageServiceRequest::new(data_request, self.request.use_compression);
        Ok(storage_request)
    }
```

**File:** state-sync/storage-service/server/src/optimistic_fetch.rs (L500-546)
```rust
        let active_task = runtime.spawn_blocking(move || {
            // Check if we have synced beyond the highest known version
            if highest_known_version < highest_synced_version {
                if highest_known_epoch < highest_synced_epoch {
                    // Fetch the epoch ending ledger info from storage (the
                    // peer needs to sync to their epoch ending ledger info).
                    let epoch_ending_ledger_info = match utils::get_epoch_ending_ledger_info(
                        cached_storage_server_summary.clone(),
                        optimistic_fetches.clone(),
                        subscriptions.clone(),
                        highest_known_epoch,
                        lru_response_cache.clone(),
                        request_moderator.clone(),
                        &peer_network_id,
                        storage.clone(),
                        time_service.clone(),
                    ) {
                        Ok(epoch_ending_ledger_info) => epoch_ending_ledger_info,
                        Err(error) => {
                            // Log the failure to fetch the epoch ending ledger info
                            error!(LogSchema::new(LogEntry::OptimisticFetchRefresh)
                                .error(&error)
                                .message(&format!(
                                    "Failed to get the epoch ending ledger info for epoch: {:?} !",
                                    highest_known_epoch
                                )));

                            return;
                        },
                    };

                    // Check that we haven't been sent an invalid optimistic fetch request
                    // (i.e., a request that does not respect an epoch boundary).
                    if epoch_ending_ledger_info.ledger_info().version() <= highest_known_version {
                        peers_with_invalid_optimistic_fetches
                            .lock()
                            .push(peer_network_id);
                    } else {
                        peers_with_ready_optimistic_fetches
                            .lock()
                            .push((peer_network_id, epoch_ending_ledger_info));
                    }
                } else {
                    peers_with_ready_optimistic_fetches
                        .lock()
                        .push((peer_network_id, highest_synced_ledger_info.clone()));
                };
```

**File:** state-sync/storage-service/types/src/requests.rs (L335-339)
```rust
pub struct NewTransactionsWithProofRequest {
    pub known_version: u64,   // The highest known transaction version
    pub known_epoch: u64,     // The highest known epoch
    pub include_events: bool, // Whether or not to include events in the response
}
```

**File:** state-sync/storage-service/server/src/tests/optimistic_fetch.rs (L34-164)
```rust
#[tokio::test]
async fn test_peers_with_ready_optimistic_fetches() {
    // Test both v1 and v2 data requests
    for use_request_v2 in [false, true] {
        // Create a mock time service
        let time_service = TimeService::mock();

        // Create two peers and optimistic fetch requests
        let peer_network_1 = PeerNetworkId::random();
        let peer_network_2 = PeerNetworkId::random();
        let optimistic_fetch_1 =
            create_optimistic_fetch_request(time_service.clone(), Some(1), Some(1), use_request_v2);
        let optimistic_fetch_2 = create_optimistic_fetch_request(
            time_service.clone(),
            Some(10),
            Some(1),
            use_request_v2,
        );

        // Insert the optimistic fetches into the pending map
        let optimistic_fetches = Arc::new(DashMap::new());
        optimistic_fetches.insert(peer_network_1, optimistic_fetch_1);
        optimistic_fetches.insert(peer_network_2, optimistic_fetch_2);

        // Create epoch ending test data
        let epoch_ending_ledger_info = utils::create_epoch_ending_ledger_info(1, 5);
        let epoch_change_proof = EpochChangeProof {
            ledger_info_with_sigs: vec![epoch_ending_ledger_info],
            more: false,
        };

        // Create the mock db reader
        let mut db_reader = mock::create_mock_db_reader();
        utils::expect_get_epoch_ending_ledger_infos(
            &mut db_reader,
            1,
            2,
            epoch_change_proof,
            false,
        );

        // Create the storage reader
        let storage_service_config = utils::create_storage_config(use_request_v2, false);
        let storage_reader = StorageReader::new(
            storage_service_config,
            Arc::new(db_reader),
            time_service.clone(),
        );

        // Create test data with an empty storage server summary
        let cached_storage_server_summary =
            Arc::new(ArcSwap::from(Arc::new(StorageServerSummary::default())));
        let lru_response_cache = Cache::new(0);
        let request_moderator = Arc::new(RequestModerator::new(
            AptosDataClientConfig::default(),
            cached_storage_server_summary.clone(),
            mock::create_peers_and_metadata(vec![]),
            storage_service_config,
            time_service.clone(),
        ));
        let subscriptions = Arc::new(DashMap::new());

        // Verify that there are no peers with ready optimistic fetches
        let peers_with_ready_optimistic_fetches =
            optimistic_fetch::get_peers_with_ready_optimistic_fetches(
                Handle::current(),
                storage_service_config,
                cached_storage_server_summary.clone(),
                optimistic_fetches.clone(),
                lru_response_cache.clone(),
                request_moderator.clone(),
                storage_reader.clone(),
                subscriptions.clone(),
                time_service.clone(),
            )
            .await
            .unwrap();
        assert!(peers_with_ready_optimistic_fetches.is_empty());

        // Update the storage server summary so that there is new data for optimistic fetch 1
        let synced_ledger_info =
            utils::update_storage_summary_cache(cached_storage_server_summary.clone(), 2, 1);

        // Verify that optimistic fetch 1 is ready
        let peers_with_ready_optimistic_fetches =
            optimistic_fetch::get_peers_with_ready_optimistic_fetches(
                Handle::current(),
                storage_service_config,
                cached_storage_server_summary.clone(),
                optimistic_fetches.clone(),
                lru_response_cache.clone(),
                request_moderator.clone(),
                storage_reader.clone(),
                subscriptions.clone(),
                time_service.clone(),
            )
            .await
            .unwrap();
        assert_eq!(peers_with_ready_optimistic_fetches, vec![(
            peer_network_1,
            synced_ledger_info
        )]);

        // Manually remove optimistic fetch 1 from the map
        optimistic_fetches.remove(&peer_network_1);

        // Update the storage server summary so that there is new data for optimistic fetch 2,
        // but the optimistic fetch is invalid because it doesn't respect an epoch boundary.
        let _ = utils::update_storage_summary_cache(cached_storage_server_summary.clone(), 100, 2);

        // Verify that optimistic fetch 2 is not returned because it was invalid
        let peers_with_ready_optimistic_fetches =
            optimistic_fetch::get_peers_with_ready_optimistic_fetches(
                Handle::current(),
                storage_service_config,
                cached_storage_server_summary,
                optimistic_fetches,
                lru_response_cache,
                request_moderator,
                storage_reader,
                subscriptions,
                time_service,
            )
            .await
            .unwrap();
        assert_eq!(peers_with_ready_optimistic_fetches, vec![]);

        // Verify that optimistic fetches no longer contains peer 2
        assert!(peers_with_ready_optimistic_fetches.is_empty());
    }
}
```
