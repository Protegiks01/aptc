# Audit Report

## Title
Consensus Node Crash via Duplicate BatchKey with Different gas_bucket_start Values in BatchProofQueue

## Summary
A Byzantine validator can crash honest validators by broadcasting batches and proofs with the same `(author, batch_id)` but different `gas_bucket_start` values. This exploits a mismatch between `BatchKey` (2-tuple) and `BatchSortKey` (3-tuple) indexing, creating multiple expiration entries that map to a single storage entry, causing a deterministic panic during expiration processing.

## Finding Description

The `BatchProofQueue` maintains three data structures with inconsistent key schemes. The `items` HashMap uses `BatchKey` as the key, while `author_to_batches` and `expirations` use `BatchSortKey`: [1](#0-0) 

The core issue is that `BatchKey` uses only `(author, batch_id)` while `BatchSortKey` includes `gas_bucket_start`: [2](#0-1) [3](#0-2) 

**Attack Execution:**

1. Byzantine validator broadcasts a batch summary with `(author=V, batch_id=1, gas_bucket_start=100, expiration=T)`. This creates entries using `BatchSortKey(V,1,100)` in `author_to_batches` and `expirations`, and using `BatchKey(V,1)` in `items`: [4](#0-3) 

2. The same validator broadcasts a proof with `(author=V, batch_id=1, gas_bucket_start=200, expiration=T)`. The duplicate check only validates if a proof exists or batch is committed, NOT if `gas_bucket_start` matches: [5](#0-4) 

This creates a second entry with `BatchSortKey(V,1,200)` in `author_to_batches` and `expirations`, but updates the same `BatchKey(V,1)` entry in `items`.

3. When expiration occurs, both `BatchSortKey` entries are returned from the `expirations` data structure: [6](#0-5) 

The first iteration successfully processes and removes `items[(V,1)]`. The second iteration attempts to access the same entry and panics with "Entry for unexpired batch must exist": [7](#0-6) 

Even if the expect were removed, the subsequent assertion would still panic: [8](#0-7) 

## Impact Explanation

**Severity: HIGH to CRITICAL**

This qualifies as **High Severity** under Aptos Bug Bounty criteria ("Validator node slowdowns" - validator crashes). It escalates to **Critical** if causing "Total loss of liveness/network availability":

1. **Deterministic Crash**: Once malicious data enters the queue, the panic is guaranteed at expiration time - not a race condition. The panic message "Entry for unexpired batch must exist" will terminate the validator process.

2. **Network-Wide Impact**: If the Byzantine validator broadcasts to all validators, they will all crash simultaneously at the same block timestamp when expiration processing occurs, causing complete network halt until manual intervention and node restarts.

3. **No Recovery Mechanism**: The panic is unrecoverable within the process and requires node restarts. The corrupted queue state may persist across restarts if the malicious batches haven't expired yet.

4. **Low Detection**: No logging or metrics would identify this before the crash occurs. The crash happens during normal expiration processing without warning.

## Likelihood Explanation

**Likelihood: HIGH**

The attack is highly feasible:

1. **Attacker Requirements**: Any Byzantine validator (< 1/3 threshold, within threat model) can execute this attack. They control their own batch ID generation and private key for signing.

2. **Execution Simplicity**: 
   - Create two `BatchInfo` objects with same `(author, batch_id)` but different `gas_bucket_start`
   - Sign both with validator's private key (signatures are valid since they cover the entire BatchInfo)
   - Broadcast both via normal consensus network channels
   - Wait for expiration (no timing precision required)

3. **No Validation**: The code has no checks preventing this scenario. The duplicate checks only verify if txn_summaries already exist or if the batch is committed: [9](#0-8) 

4. **Cryptographic Validity**: The Byzantine validator signs each BatchInfo object with their private key, and each signature is cryptographically valid for its respective BatchInfo: [10](#0-9) 

## Recommendation

Add validation to ensure `gas_bucket_start` consistency when inserting batches or proofs with the same `(author, batch_id)`. In `insert_proof`:

```rust
if let Some(existing_item) = self.items.get(&batch_key) {
    if existing_item.info.gas_bucket_start() != proof.gas_bucket_start() {
        counters::inc_rejected_pos_count(counters::POS_INCONSISTENT_GAS_BUCKET_LABEL);
        return;
    }
    if existing_item.proof.is_some() || existing_item.is_committed() {
        counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
        return;
    }
}
```

Similarly, add gas_bucket_start consistency checks in `insert_batches`. Alternatively, include `gas_bucket_start` in `BatchKey` to make the key schemes consistent, though this would require more extensive refactoring.

## Proof of Concept

```rust
#[tokio::test]
async fn test_duplicate_batch_id_different_gas_bucket_crash() {
    let my_peer_id = PeerId::random();
    let batch_store = batch_store_for_test(5 * 1024 * 1024);
    let mut proof_queue = BatchProofQueue::new(my_peer_id, batch_store, 1);
    
    let author = PeerId::random();
    let now_in_usecs = aptos_infallible::duration_since_epoch().as_micros() as u64;
    let expiration = now_in_usecs + 10000;
    
    // Create two batches with same (author, batch_id) but different gas_bucket_start
    let batch_info_1 = BatchInfo::new(
        author,
        BatchId::new_for_test(1),
        0,
        expiration,
        HashValue::random(),
        1,
        1,
        100, // gas_bucket_start = 100
    );
    
    let batch_info_2 = BatchInfo::new(
        author,
        BatchId::new_for_test(1), // SAME batch_id
        0,
        expiration,
        HashValue::random(),
        1,
        1,
        200, // DIFFERENT gas_bucket_start = 200
    );
    
    // Insert both as batch summaries
    proof_queue.insert_batches(vec![(batch_info_1.into(), vec![])]);
    proof_queue.insert_batches(vec![(batch_info_2.into(), vec![])]);
    
    // Trigger expiration - this will panic with "Entry for unexpired batch must exist"
    proof_queue.handle_updated_block_timestamp(expiration);
}
```

This test demonstrates the vulnerability. When `handle_updated_block_timestamp` is called, the expiration handler will find two `BatchSortKey` entries but only one `BatchKey` entry, causing a panic.

## Notes

The vulnerability stems from a fundamental data structure design inconsistency where different parts of the system use different notions of batch uniqueness. The `BatchKey` considers batches unique by `(author, batch_id)` only, while `BatchSortKey` requires all three fields `(author, batch_id, gas_bucket_start)` for uniqueness. This creates an exploitable mismatch where multiple index entries can point to the same storage entry, causing crashes during cleanup operations.

### Citations

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L56-76)
```rust
pub struct BatchProofQueue {
    my_peer_id: PeerId,
    // Queue per peer to ensure fairness between peers and priority within peer
    author_to_batches: HashMap<PeerId, BTreeMap<BatchSortKey, BatchInfoExt>>,
    // Map of Batch key to QueueItem containing Batch data and proofs
    items: HashMap<BatchKey, QueueItem>,
    // Number of unexpired and uncommitted proofs in which the txn_summary = (sender, replay protector, hash, expiration)
    // has been included. We only count those batches that are in both author_to_batches and items along with proofs.
    txn_summary_num_occurrences: HashMap<TxnSummaryWithExpiration, u64>,
    // Expiration index
    expirations: TimeExpirations<BatchSortKey>,
    batch_store: Arc<BatchStore>,

    latest_block_timestamp: u64,
    remaining_txns_with_duplicates: u64,
    remaining_proofs: u64,
    remaining_local_txns: u64,
    remaining_local_proofs: u64,

    batch_expiry_gap_when_init_usecs: u64,
}
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L175-256)
```rust
    pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
        if proof.expiration() <= self.latest_block_timestamp {
            counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
            return;
        }
        let batch_key = BatchKey::from_info(proof.info());
        if self
            .items
            .get(&batch_key)
            .is_some_and(|item| item.proof.is_some() || item.is_committed())
        {
            counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
            return;
        }

        let author = proof.author();
        let bucket = proof.gas_bucket_start();
        let num_txns = proof.num_txns();
        let expiration = proof.expiration();

        let batch_sort_key = BatchSortKey::from_info(proof.info());
        let batches_for_author = self.author_to_batches.entry(author).or_default();
        batches_for_author.insert(batch_sort_key.clone(), proof.info().clone());

        // Check if a batch with a higher batch Id (reverse sorted) exists
        if let Some((prev_batch_key, _)) = batches_for_author
            .range((Bound::Unbounded, Bound::Excluded(batch_sort_key.clone())))
            .next_back()
        {
            if prev_batch_key.gas_bucket_start() == batch_sort_key.gas_bucket_start() {
                counters::PROOF_MANAGER_OUT_OF_ORDER_PROOF_INSERTION
                    .with_label_values(&[author.short_str().as_str()])
                    .inc();
            }
        }

        self.expirations.add_item(batch_sort_key, expiration);

        // If we are here, then proof is added for the first time. Otherwise, we will
        // return early. We only count when proof is added for the first time and txn
        // summary exists.
        if let Some(txn_summaries) = self
            .items
            .get(&batch_key)
            .and_then(|item| item.txn_summaries.as_ref())
        {
            for txn_summary in txn_summaries {
                *self
                    .txn_summary_num_occurrences
                    .entry(*txn_summary)
                    .or_insert(0) += 1;
            }
        }

        match self.items.entry(batch_key) {
            Entry::Occupied(mut entry) => {
                let item = entry.get_mut();
                item.proof = Some(proof);
                item.proof_insertion_time = Some(Instant::now());
            },
            Entry::Vacant(entry) => {
                entry.insert(QueueItem {
                    info: proof.info().clone(),
                    proof: Some(proof),
                    proof_insertion_time: Some(Instant::now()),
                    txn_summaries: None,
                });
            },
        }

        if author == self.my_peer_id {
            counters::inc_local_pos_count(bucket);
        } else {
            counters::inc_remote_pos_count(bucket);
        }
        self.inc_remaining_proofs(&author, num_txns);

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L258-320)
```rust
    pub fn insert_batches(
        &mut self,
        batches_with_txn_summaries: Vec<(BatchInfoExt, Vec<TxnSummaryWithExpiration>)>,
    ) {
        let start = Instant::now();

        for (batch_info, txn_summaries) in batches_with_txn_summaries.into_iter() {
            let batch_sort_key = BatchSortKey::from_info(&batch_info);
            let batch_key = BatchKey::from_info(&batch_info);

            // If the batch is either committed or the txn summary already exists, skip
            // inserting this batch.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.is_committed() || item.txn_summaries.is_some())
            {
                continue;
            }

            self.author_to_batches
                .entry(batch_info.author())
                .or_default()
                .insert(batch_sort_key.clone(), batch_info.clone());
            self.expirations
                .add_item(batch_sort_key, batch_info.expiration());

            // We only count txn summaries first time it is added to the queue
            // and only if the proof already exists.
            if self
                .items
                .get(&batch_key)
                .is_some_and(|item| item.proof.is_some())
            {
                for txn_summary in &txn_summaries {
                    *self
                        .txn_summary_num_occurrences
                        .entry(*txn_summary)
                        .or_insert(0) += 1;
                }
            }

            match self.items.entry(batch_key) {
                Entry::Occupied(mut entry) => {
                    entry.get_mut().txn_summaries = Some(txn_summaries);
                },
                Entry::Vacant(entry) => {
                    entry.insert(QueueItem {
                        info: batch_info,
                        proof: None,
                        proof_insertion_time: None,
                        txn_summaries: Some(txn_summaries),
                    });
                },
            }
        }

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
        counters::PROOF_QUEUE_ADD_BATCH_SUMMARIES_DURATION.observe_duration(start.elapsed());
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L729-731)
```rust
        let expired = self.expirations.expire(block_timestamp);
        let mut num_expired_but_not_committed = 0;
        for key in &expired {
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L734-737)
```rust
                    let item = self
                        .items
                        .get(&key.batch_key)
                        .expect("Entry for unexpired batch must exist");
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L760-760)
```rust
                    claims::assert_some!(self.items.remove(&key.batch_key));
```

**File:** consensus/src/quorum_store/utils.rs (L150-163)
```rust
#[derive(PartialEq, Eq, Hash, Clone, Debug)]
pub struct BatchKey {
    author: PeerId,
    batch_id: BatchId,
}

impl BatchKey {
    pub fn from_info(info: &BatchInfoExt) -> Self {
        Self {
            author: info.author(),
            batch_id: info.batch_id(),
        }
    }
}
```

**File:** consensus/src/quorum_store/utils.rs (L165-186)
```rust
#[derive(PartialEq, Eq, Clone, Hash, Debug)]
pub struct BatchSortKey {
    pub(crate) batch_key: BatchKey,
    gas_bucket_start: u64,
}

impl BatchSortKey {
    pub fn from_info(info: &BatchInfoExt) -> Self {
        Self {
            batch_key: BatchKey::from_info(info),
            gas_bucket_start: info.gas_bucket_start(),
        }
    }

    pub fn author(&self) -> PeerId {
        self.batch_key.author
    }

    pub fn gas_bucket_start(&self) -> u64 {
        self.gas_bucket_start
    }
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L425-436)
```rust
    pub fn new(
        batch_info: T,
        validator_signer: &ValidatorSigner,
    ) -> Result<Self, CryptoMaterialError> {
        let signature = validator_signer.sign(&batch_info)?;

        Ok(Self {
            info: batch_info,
            signer: validator_signer.author(),
            signature: SignatureWithStatus::from(signature),
        })
    }
```
