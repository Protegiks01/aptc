# Audit Report

## Title
Database Restore Tool Bypasses Cryptographic and Execution Verification, Enabling State Corruption via Unauthenticated Backups

## Summary
The `db-tool restore oneoff transaction` command simultaneously bypasses **two critical security layers**: (1) cryptographic signature verification of ledger info by hardcoding `epoch_history = None`, and (2) Move VM execution verification by hardcoding `VerifyExecutionMode::NoVerify`. This dual bypass allows completely unauthenticated backup data—including arbitrary write sets that were never validated by the blockchain consensus—to be applied directly to node state, enabling state corruption, consensus violations, and loss of funds.

## Finding Description

**The vulnerability involves TWO hardcoded security bypasses working in combination:**

### Bypass 1: Cryptographic Signature Verification Disabled

The oneoff transaction restore explicitly passes `None` for `epoch_history`: [1](#0-0) 

When `epoch_history` is `None`, the critical signature verification step is skipped during backup loading: [2](#0-1) 

Without this verification, the `LedgerInfoWithSignatures` from the backup is **never validated against validator signatures**. The subsequent verification at line 167 only checks internal Merkle proof consistency—it does NOT verify that validators actually signed this ledger state. [3](#0-2) 

### Bypass 2: Execution Verification Disabled

The oneoff transaction restore also hardcodes `NoVerify` mode: [4](#0-3) 

During transaction replay, the executor checks whether to verify execution: [5](#0-4) 

The `should_verify()` method returns `false` for `NoVerify` mode: [6](#0-5) 

This skips the `verify_execution()` call that would normally re-execute transactions through the Move VM and validate outputs. Instead, write sets are applied directly: [7](#0-6) 

### Combined Attack Vector

With both protections disabled, an attacker who can influence backup data (compromised S3 storage, MITM attack, malicious backup provider) can:

1. Create fake `LedgerInfoWithSignatures` with invalid or missing validator signatures
2. Craft arbitrary write sets violating Move resource safety (double-spending, destroying non-droppable resources, arbitrary balance manipulation)
3. Build internally consistent Merkle proofs linking these to the fake ledger info
4. Package this into a backup file

When a node operator runs `db-tool restore oneoff transaction` with this corrupted backup:
- Signature verification is skipped (no validator authentication)
- Execution verification is skipped (no Move VM validation)
- Malicious write sets are applied directly to the database

### Contrast with BootstrapDB Path

The production restore path (`db-tool restore bootstrap-db`) correctly creates `epoch_history` for signature verification: [8](#0-7) 

This path maintains cryptographic integrity even though it also uses `NoVerify` for execution. The oneoff transaction restore is uniquely vulnerable by disabling **both** security layers.

## Impact Explanation

**Severity: CRITICAL**

This vulnerability meets multiple CRITICAL impact criteria per Aptos bug bounty:

1. **Loss of Funds (Critical)**: Arbitrary write sets can mint tokens, manipulate account balances, double-spend resources, or transfer assets without authorization.

2. **Consensus/Safety Violations (Critical)**: Different nodes restoring from different compromised backups will compute different state roots for identical transaction sequences, causing immediate consensus divergence and potential chain splits.

3. **Permanent State Corruption (Critical)**: Once malicious state is committed to the database, it becomes the node's canonical view of the blockchain. Recovery requires detecting the corruption (difficult without re-executing all transactions), manual intervention, and potentially a network-wide hard fork if multiple nodes are affected.

4. **Permanent Freezing of Funds (Critical)**: Resource safety violations can create impossible-to-recover state (e.g., destroying a resource holding locked funds without proper cleanup, violating Move's linear type guarantees).

The impact is **network-wide** because:
- Any validator operator performing disaster recovery with compromised backups will corrupt their node's state
- If that validator participates in consensus with corrupted state, it will vote for invalid state roots
- Multiple corrupted nodes could cause consensus failures requiring hardfork resolution

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

**Prerequisites:**
- Operator access to run `db-tool` (standard for validator operators—not a privilege escalation)
- Ability to influence backup data sources

**Realistic Attack Scenarios:**

1. **Cloud Storage Compromise**: Operators commonly store backups in S3/GCS. Compromised credentials allow attackers to replace legitimate backups with malicious ones.

2. **Supply Chain Attack**: Operators downloading "official" snapshots from third-party providers or community mirrors could receive corrupted data.

3. **MITM During Backup Download**: Attackers intercepting backup downloads can serve malicious data.

4. **Disaster Recovery Window**: During network incidents requiring urgent restoration, operators may not verify backup integrity before using them.

5. **Automated Restore Processes**: Infrastructure automation that automatically restores from backups amplifies the attack surface.

**Factors Increasing Likelihood:**

- The vulnerability is **silently present**—no warnings that signature verification is being skipped
- No CLI option to enable verification—the insecure behavior is hardcoded
- Tool is **designed for production use** during critical recovery scenarios
- Operators have no visibility into what validation is (or isn't) occurring
- The tool appears superficially similar to the secure BootstrapDB path, creating false confidence

## Recommendation

**Immediate Fix:**

Replace the hardcoded `None` with proper `epoch_history` creation:

```rust
Oneoff::Transaction {
    storage,
    opt,
    global,
} => {
    // Create epoch_history for signature verification
    let metadata_view = metadata::cache::sync_and_load(
        &global.metadata_cache_opt,
        Arc::clone(&storage),
        global.concurrent_downloads,
    ).await?;
    
    let epoch_ending_backups = metadata_view.select_epoch_ending_backups(global.target_version)?;
    let epoch_handles = epoch_ending_backups
        .iter()
        .filter(|e| e.first_version <= global.target_version)
        .map(|backup| backup.manifest.clone())
        .collect();
    
    let epoch_history = Some(Arc::new(
        EpochHistoryRestoreController::new(
            epoch_handles,
            global.clone(),
            storage.clone(),
        )
        .run()
        .await?,
    ));

    TransactionRestoreController::new(
        opt,
        global.try_into()?,
        storage.init_storage().await?,
        epoch_history, // Now properly validates signatures
        VerifyExecutionMode::NoVerify, // Can remain NoVerify if signatures are checked
    )
    .run()
    .await?;
},
```

**Additional Hardening:**

1. Add a CLI flag `--verify-execution` to enable `VerifyExecutionMode::verify_all()` for maximum safety
2. Log warnings when signature verification is skipped (though it should never be skipped in production)
3. Document that oneoff restore should only be used with trusted, pre-verified backups
4. Consider making signature verification mandatory with no option to disable

## Proof of Concept

A complete PoC would require:
1. Creating a fake backup with arbitrary write sets
2. Generating self-consistent Merkle proofs
3. Running `db-tool restore oneoff transaction` against it
4. Observing the corrupted state being applied without validation

The core vulnerability is demonstrated by the code citations above showing that both `epoch_history = None` (disabling signature verification) and `VerifyExecutionMode::NoVerify` (disabling execution verification) are hardcoded in the oneoff transaction restore path.

---

**Notes:**

This vulnerability is more severe than initially reported because it bypasses **both** cryptographic signature verification **and** execution verification. The signature verification bypass is the more critical flaw—it means the backup data was never authenticated by validator consensus. Even with execution verification disabled, proper signature verification would ensure the data represents a legitimate blockchain state that validators actually committed to.

### Citations

**File:** storage/db-tool/src/restore.rs (L106-106)
```rust
                            None, /* epoch_history */
```

**File:** storage/db-tool/src/restore.rs (L107-107)
```rust
                            VerifyExecutionMode::NoVerify,
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L152-154)
```rust
        if let Some(epoch_history) = epoch_history {
            epoch_history.verify_ledger_info(&ledger_info)?;
        }
```

**File:** storage/backup/backup-cli/src/backup_types/transaction/restore.rs (L167-167)
```rust
        txn_list_with_proof.verify(ledger_info.ledger_info(), Some(manifest.first_version))?;
```

**File:** execution/executor/src/chunk_executor/mod.rs (L562-575)
```rust
            let next_begin = if verify_execution_mode.should_verify() {
                self.verify_execution(
                    transactions,
                    persisted_aux_info,
                    transaction_infos,
                    write_sets,
                    event_vecs,
                    batch_begin,
                    batch_end,
                    verify_execution_mode,
                )?
            } else {
                batch_end
            };
```

**File:** execution/executor/src/chunk_executor/mod.rs (L656-700)
```rust
    fn remove_and_apply(
        &self,
        transactions: &mut Vec<Transaction>,
        persisted_aux_info: &mut Vec<PersistedAuxiliaryInfo>,
        transaction_infos: &mut Vec<TransactionInfo>,
        write_sets: &mut Vec<WriteSet>,
        event_vecs: &mut Vec<Vec<ContractEvent>>,
        begin_version: Version,
        end_version: Version,
    ) -> Result<()> {
        let num_txns = (end_version - begin_version) as usize;
        let txn_infos: Vec<_> = transaction_infos.drain(..num_txns).collect();
        let (transactions, persisted_aux_info, transaction_outputs) = multizip((
            transactions.drain(..num_txns),
            persisted_aux_info.drain(..num_txns),
            txn_infos.iter(),
            write_sets.drain(..num_txns),
            event_vecs.drain(..num_txns),
        ))
        .map(|(txn, persisted_aux_info, txn_info, write_set, events)| {
            (
                txn,
                persisted_aux_info,
                TransactionOutput::new(
                    write_set,
                    events,
                    txn_info.gas_used(),
                    TransactionStatus::Keep(txn_info.status().clone()),
                    TransactionAuxiliaryData::default(), // No auxiliary data if transaction is not executed through VM
                ),
            )
        })
        .multiunzip();

        let chunk = ChunkToApply {
            transactions,
            transaction_outputs,
            persisted_aux_info,
            first_version: begin_version,
        };
        let chunk_verifier = Arc::new(ReplayChunkVerifier {
            transaction_infos: txn_infos,
        });
        self.enqueue_chunk(chunk, chunk_verifier, "replay")?;

```

**File:** execution/executor-types/src/lib.rs (L240-242)
```rust
    pub fn should_verify(&self) -> bool {
        !matches!(self, Self::NoVerify)
    }
```

**File:** storage/backup/backup-cli/src/coordinators/restore.rs (L219-231)
```rust
        let epoch_history = if !self.skip_epoch_endings {
            Some(Arc::new(
                EpochHistoryRestoreController::new(
                    epoch_handles,
                    self.global_opt.clone(),
                    self.storage.clone(),
                )
                .run()
                .await?,
            ))
        } else {
            None
        };
```
