# Audit Report

## Title
Unbounded Memory Exhaustion via Byzantine Validator JWK Consensus Request Flooding in Per-Key Mode

## Summary
Byzantine validators can exhaust validator node memory by flooding the JWK consensus system with arbitrary (issuer, kid) pairs through `KeyLevelObservationRequest` messages. The vulnerability stems from unconditional HashMap entry creation without validation, combined with broken cleanup logic that indefinitely retains malicious entries.

## Finding Description

The JWK consensus system in per-key mode maintains a `states_by_key: HashMap<(Issuer, KID), ConsensusState<ObservedKeyLevelUpdate>>` to track consensus state for each key pair. [1](#0-0) 

When a `KeyLevelObservationRequest` arrives, `process_peer_request()` unconditionally creates a HashMap entry using `entry().or_default()` without validating that the issuer is in the on-chain `SupportedOIDCProviders` list: [2](#0-1) 

Both `Issuer` and `KID` are type aliases for `Vec<u8>` with no inherent length restrictions: [3](#0-2) 

Although the function returns early for `NotStarted` states without sending a response, the HashMap entry persists in memory: [4](#0-3) 

The cleanup logic in `reset_with_on_chain_state()` contains a critical bug. It uses `unwrap_or_default()` which returns 0 for non-existent issuers, causing the retention condition `0 == 0` to evaluate to `true`, thereby keeping malicious entries indefinitely: [5](#0-4) 

While epoch validation occurs at the `EpochManager` level, it only filters mismatched epochs and does not prevent attacks within the current epoch: [6](#0-5) 

The network layer enforces a limit of 100 concurrent inbound RPCs per peer, but this does not prevent sequential batches of requests from accumulating unbounded HashMap entries: [7](#0-6) 

**Attack Execution Path:**
1. Byzantine validator (≤1/3 of validator set) crafts `KeyLevelObservationRequest` with arbitrary (issuer, kid) pairs
2. Request passes epoch validation if sent with correct epoch number
3. `process_peer_request()` creates HashMap entry with `ConsensusState::NotStarted`
4. Function returns early, leaving entry in memory
5. Attacker repeats with unique pairs in sequential batches of 100
6. Cleanup logic fails to remove entries for non-existent issuers due to `0 == 0` comparison
7. HashMap grows unboundedly until memory exhaustion occurs

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program's impact categories:

- **Validator Node Slowdowns (High)**: Memory exhaustion causes performance degradation affecting consensus participation and block processing speed
- **Resource Exhaustion**: Violates the requirement that all operations respect resource limits, as arbitrary external input can consume unbounded memory
- **Potential DoS**: In severe cases with large issuer/kid payloads or multiple attacking validators, memory pressure could crash validator nodes

The impact aligns with the bounty program's High severity category: "Validator node slowdowns" through DoS via resource exhaustion, which can degrade network performance if multiple validators are simultaneously targeted.

## Likelihood Explanation

**High Likelihood:**

The attack requires only a Byzantine validator (≤1/3 of validator set) sending RPC messages with random byte sequences, which is:
- **Trivially executable**: No special timing, state conditions, or complex coordination required
- **Within standard threat model**: Byzantine validators are part of the BFT adversary model
- **Unmitigated**: No validation checks issuer against `SupportedOIDCProviders`, no per-key memory limits exist
- **Persistent**: Cleanup logic bug ensures malicious entries survive indefinitely across epoch transitions and on-chain state updates

The network layer's 100 concurrent RPC limit provides minimal protection as attackers can send unlimited sequential batches over time.

## Recommendation

**Fix 1: Add Issuer Validation**
```rust
pub fn process_peer_request(&mut self, rpc_req: IncomingRpcRequest) -> Result<()> {
    let IncomingRpcRequest { msg, mut response_sender, .. } = rpc_req;
    match msg {
        JWKConsensusMsg::KeyLevelObservationRequest(request) => {
            let ObservedKeyLevelUpdateRequest { issuer, kid, .. } = request;
            
            // Validate issuer exists in on-chain state
            if !self.onchain_jwks.contains_key(&issuer) {
                return Ok(()); // Silently reject unknown issuers
            }
            
            let consensus_state = self.states_by_key.entry((issuer.clone(), kid.clone())).or_default();
            // ... rest of function
        }
    }
}
```

**Fix 2: Correct Cleanup Logic**
```rust
pub fn reset_with_on_chain_state(&mut self, on_chain_state: AllProvidersJWKs) -> Result<()> {
    let new_onchain_jwks = on_chain_state.indexed()?;
    
    // Retain only entries for issuers that exist in new on-chain state with unchanged version
    self.states_by_key.retain(|(issuer, _), _| {
        if let Some(new_jwks) = new_onchain_jwks.get(issuer) {
            if let Some(old_jwks) = self.onchain_jwks.get(issuer) {
                new_jwks.version == old_jwks.version
            } else {
                false // Issuer newly added, discard old consensus
            }
        } else {
            false // Issuer not in new on-chain state, discard
        }
    });
    
    self.onchain_jwks = new_onchain_jwks;
    Ok(())
}
```

**Fix 3: Add Per-Issuer Entry Limits**
```rust
const MAX_KEYS_PER_ISSUER: usize = 100;

// In process_peer_request, before creating entry:
let keys_for_issuer = self.states_by_key.keys()
    .filter(|(iss, _)| iss == &issuer)
    .count();
if keys_for_issuer >= MAX_KEYS_PER_ISSUER {
    return Ok(());
}
```

## Proof of Concept

```rust
#[test]
fn test_memory_exhaustion_attack() {
    let mut manager = KeyLevelConsensusManager::new(/* ... */);
    
    // Simulate Byzantine validator flooding with arbitrary (issuer, kid) pairs
    for i in 0..10000 {
        let malicious_issuer = format!("malicious_issuer_{}", i).into_bytes();
        let malicious_kid = format!("kid_{}", i).into_bytes();
        
        let request = IncomingRpcRequest {
            msg: JWKConsensusMsg::KeyLevelObservationRequest(
                ObservedKeyLevelUpdateRequest {
                    epoch: manager.epoch_state.epoch,
                    issuer: malicious_issuer.clone(),
                    kid: malicious_kid.clone(),
                }
            ),
            response_sender: /* mock sender */,
            sender: /* attacker address */,
        };
        
        // Process request - creates HashMap entry
        manager.process_peer_request(request).unwrap();
        
        // Verify entry exists
        assert!(manager.states_by_key.contains_key(&(malicious_issuer, malicious_kid)));
    }
    
    // Simulate on-chain state update - should cleanup malicious entries but doesn't
    manager.reset_with_on_chain_state(AllProvidersJWKs::empty()).unwrap();
    
    // BUG: Malicious entries still present after cleanup
    assert_eq!(manager.states_by_key.len(), 10000);
}
```

## Notes

This is a protocol-level resource exhaustion vulnerability, distinct from network DoS attacks. The root cause lies in application logic flaws (missing validation and broken cleanup), not network flooding. The bug violates the security invariant that external untrusted input should not cause unbounded resource consumption. The fixes address both prevention (input validation) and defense-in-depth (correct cleanup logic and rate limiting).

### Citations

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L59-59)
```rust
    states_by_key: HashMap<(Issuer, KID), ConsensusState<ObservedKeyLevelUpdate>>,
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L244-254)
```rust
        self.states_by_key.retain(|(issuer, _), _| {
            new_onchain_jwks
                .get(issuer)
                .map(|jwks| jwks.version)
                .unwrap_or_default()
                == self
                    .onchain_jwks
                    .get(issuer)
                    .map(|jwks| jwks.version)
                    .unwrap_or_default()
        });
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L274-277)
```rust
                let consensus_state = self
                    .states_by_key
                    .entry((issuer.clone(), kid.clone()))
                    .or_default();
```

**File:** crates/aptos-jwk-consensus/src/jwk_manager_per_key.rs (L279-285)
```rust
                    ConsensusState::NotStarted => {
                        debug!(
                            issuer = String::from_utf8(issuer.clone()).ok(),
                            kid = String::from_utf8(kid.clone()).ok(),
                            "key-level jwk consensus not started"
                        );
                        return Ok(());
```

**File:** types/src/jwks/mod.rs (L36-38)
```rust
pub type Issuer = Vec<u8>;
/// Type for JWK Key ID.
pub type KID = Vec<u8>;
```

**File:** crates/aptos-jwk-consensus/src/epoch_manager.rs (L99-104)
```rust
        if Some(rpc_request.msg.epoch()) == self.epoch_state.as_ref().map(|s| s.epoch) {
            if let Some(tx) = &self.jwk_rpc_msg_tx {
                let _ = tx.push(peer_id, (peer_id, rpc_request));
            }
        }
        Ok(())
```

**File:** network/framework/src/constants.rs (L15-15)
```rust
pub const MAX_CONCURRENT_INBOUND_RPCS: u32 = 100;
```
