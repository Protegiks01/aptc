# Audit Report

## Title
Missing Execution Retry Mechanism Causes Permanent Consensus Pipeline Stall on ExecutorError

## Summary
The consensus pipeline's buffer manager lacks a retry mechanism for execution phase failures. When any block fails execution with an ExecutorError, the pipeline permanently stalls because no retry is scheduled, causing complete loss of consensus liveness on affected nodes.

## Finding Description

The Aptos consensus pipeline processes blocks through multiple phases coordinated by the BufferManager: execution scheduling → execution wait → signing → persisting. When a block fails during the execution phase with an ExecutorError, a critical vulnerability allows the entire pipeline to permanently stall.

**Execution Error Handling Without State Advancement:**

When execution fails, the buffer manager logs the error and returns immediately without advancing the block state. [1](#0-0)  The block remains in "Ordered" state, and the `execution_root` cursor continues pointing to this failed block.

**Stall Detection Returns Retry Signal:**

The `advance_execution_root()` function searches for the next "Ordered" block starting from the current execution_root cursor. When the cursor doesn't move (because the block at execution_root is still "Ordered" after failure), the function returns `Some(block_id)` to signal that a retry is needed. [2](#0-1) 

**Retry Signal Ignored at All Call Sites:**

However, at all three call sites where `advance_execution_root()` is invoked, the return value indicating retry is needed is completely ignored:
- Call site 1: [3](#0-2) 
- Call site 2: [4](#0-3) 
- Call site 3: [5](#0-4) 

**No Retry Mechanism Exists:**

The execution schedule request is only sent once when blocks are first ordered. [6](#0-5)  This is the only location in the entire codebase where execution requests are sent to the execution pipeline.

Critically, the execution phase has no equivalent retry mechanism. In contrast, the signing phase implements proper retry logic using `spawn_retry_request` when the signing_root cursor doesn't advance. [7](#0-6) 

**Triggerable ExecutorError Types:**

Multiple ExecutorError types can cause this stall:
- `ExecutorError::BlockNotFound`: When speculative execution state is unavailable [8](#0-7) 
- `ExecutorError::CouldNotGetData`: When batch data cannot be retrieved [9](#0-8) 
- `ExecutorError::InternalError`: For various internal failures [10](#0-9) 

These errors occur in production scenarios such as batch data unavailability [11](#0-10) , parent block not found during speculative execution [12](#0-11) , or pipeline abortion [13](#0-12) .

**Execution Flow Leading to Stall:**
1. Ordered blocks arrive and execution request is sent once
2. Execution fails with ExecutorError (BlockNotFound, CouldNotGetData, InternalError, etc.)
3. `process_execution_response` logs error and returns without processing block
4. Block stays in "Ordered" state, execution_root remains unchanged
5. `advance_execution_root()` detects stall, returns `Some(block_id)` 
6. Return value is discarded at all three call sites, no retry scheduled
7. Pipeline permanently stalled - no new blocks can execute until manual reset

## Impact Explanation

This vulnerability qualifies as **HIGH severity** per Aptos bug bounty criteria under "Validator Node Slowdowns (High)" that escalates to complete validator node freeze.

**Affected Systems**: All validator nodes running consensus with decoupled execution pipeline  
**Severity**: Complete loss of liveness for individual nodes  
**Recovery**: Requires node restart and state reset  
**Scope**: Single ExecutorError causes permanent pipeline stall

Once triggered, the affected validator node cannot:
- Process any new consensus blocks
- Participate in voting or block proposals
- Maintain chain synchronization with the network
- Recover without manual intervention (restart)

While this affects individual nodes rather than network-wide consensus (assuming < 1/3 of nodes affected), it represents a critical availability vulnerability. An attacker could use this to conduct targeted DoS attacks against specific validators, degrading network performance and potentially forcing validators offline to lose rewards and reputation.

The impact exceeds typical "slowdowns" because it causes complete pipeline freeze, not just performance degradation. The validator becomes entirely non-functional for consensus participation.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

ExecutorErrors occur naturally in distributed systems due to:
- Network partitions causing temporary data unavailability
- Transient resource exhaustion in execution components  
- Race conditions during state synchronization or epoch transitions
- Database read failures or cache misses

An attacker can deliberately trigger these conditions without special privileges:
1. **CouldNotGetData**: Cause batch data to be unavailable through timing attacks or resource exhaustion
2. **BlockNotFound**: Exploit race conditions in speculative execution state management
3. **InternalError**: Trigger edge cases in executor state that cause internal failures

The vulnerability is exploitable without:
- Validator private keys or stake ownership
- Special network position or Byzantine validator collusion
- Compromising trusted roles

Once any ExecutorError occurs (naturally or maliciously), the permanent stall is deterministic and guaranteed due to the missing retry mechanism. The error handling is consistent across all ExecutorError types [14](#0-13) , making the vulnerability reliably triggerable.

## Recommendation

Implement a retry mechanism for the execution phase similar to the existing signing phase retry logic:

1. **Capture the retry signal**: Check the return value of `advance_execution_root()` at all call sites
2. **Schedule retry requests**: When `Some(block_id)` is returned, use `spawn_retry_request` to schedule execution retry after a delay
3. **Add exponential backoff**: Implement retry limits and exponential backoff to handle persistent failures
4. **Add monitoring**: Track execution retry attempts and failures for observability

The fix should mirror the signing phase retry pattern shown in `advance_signing_root()` where cursor non-advancement triggers automatic retry scheduling.

## Proof of Concept

A complete PoC would require:
1. Setting up a validator node with decoupled execution enabled
2. Triggering an ExecutorError (e.g., by causing batch data unavailability)
3. Observing that the execution_root cursor becomes stuck
4. Verifying that no new blocks are processed despite arriving at the buffer manager
5. Confirming that only manual restart recovers the pipeline

The code path for the vulnerability is clearly documented in the consensus pipeline implementation, making reproduction straightforward for validators experiencing transient ExecutorErrors in production environments.

## Notes

This vulnerability demonstrates a clear asymmetry in error handling between the execution and signing phases of the consensus pipeline. While the signing phase properly handles transient failures with retry logic, the execution phase lacks any recovery mechanism, converting temporary errors into permanent availability loss. This represents a significant reliability issue for validator operators and poses risks for network stability if multiple validators are affected simultaneously.

### Citations

**File:** consensus/src/pipeline/buffer_manager.rs (L397-410)
```rust
        let request = self.create_new_request(ExecutionRequest {
            ordered_blocks: ordered_blocks.clone(),
        });
        if let Some(consensus_publisher) = &self.consensus_publisher {
            let message = ConsensusObserverMessage::new_ordered_block_message(
                ordered_blocks.clone(),
                ordered_proof.clone(),
            );
            consensus_publisher.publish_message(message);
        }
        self.execution_schedule_phase_tx
            .send(request)
            .await
            .expect("Failed to send execution schedule request");
```

**File:** consensus/src/pipeline/buffer_manager.rs (L429-451)
```rust
    fn advance_execution_root(&mut self) -> Option<HashValue> {
        let cursor = self.execution_root;
        self.execution_root = self
            .buffer
            .find_elem_from(cursor.or_else(|| *self.buffer.head_cursor()), |item| {
                item.is_ordered()
            });
        if self.execution_root.is_some() && cursor == self.execution_root {
            // Schedule retry.
            self.execution_root
        } else {
            sample!(
                SampleRate::Frequency(2),
                info!(
                    "Advance execution root from {:?} to {:?}",
                    cursor, self.execution_root
                )
            );
            // Otherwise do nothing, because the execution wait phase is driven by the response of
            // the execution schedule phase, which is in turn fed as soon as the ordered blocks
            // come in.
            None
        }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L478-486)
```rust
            if cursor == self.signing_root {
                let sender = self.signing_phase_tx.clone();
                Self::spawn_retry_request(sender, request, Duration::from_millis(100));
            } else {
                self.signing_phase_tx
                    .send(request)
                    .await
                    .expect("Failed to send signing request");
            }
```

**File:** consensus/src/pipeline/buffer_manager.rs (L617-626)
```rust
        let executed_blocks = match inner {
            Ok(result) => result,
            Err(e) => {
                log_executor_error_occurred(
                    e,
                    &counters::BUFFER_MANAGER_RECEIVED_EXECUTOR_ERROR_COUNT,
                    block_id,
                );
                return;
            },
```

**File:** consensus/src/pipeline/buffer_manager.rs (L943-943)
```rust
                        self.advance_execution_root();
```

**File:** consensus/src/pipeline/buffer_manager.rs (L957-957)
```rust
                    self.advance_execution_root();
```

**File:** consensus/src/pipeline/buffer_manager.rs (L979-979)
```rust
                            self.advance_execution_root();
```

**File:** execution/executor-types/src/error.rs (L14-15)
```rust
    #[error("Cannot find speculation result for block id {0}")]
    BlockNotFound(HashValue),
```

**File:** execution/executor-types/src/error.rs (L32-33)
```rust
    #[error("Internal error: {:?}", error)]
    InternalError { error: String },
```

**File:** execution/executor-types/src/error.rs (L41-42)
```rust
    #[error("request timeout")]
    CouldNotGetData,
```

**File:** consensus/src/quorum_store/batch_store.rs (L556-557)
```rust
                    warn!("Could not get batch from db");
                    Err(ExecutorError::CouldNotGetData)
```

**File:** execution/executor/src/block_executor/mod.rs (L208-209)
```rust
            .expect("Must exist.")
            .ok_or(ExecutorError::BlockNotFound(parent_block_id))?;
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L551-553)
```rust
            .ok_or(ExecutorError::InternalError {
                error: "Pipeline aborted".to_string(),
            })?
```

**File:** consensus/src/counters.rs (L1184-1210)
```rust
pub fn log_executor_error_occurred(
    e: ExecutorError,
    counter: &Lazy<IntCounterVec>,
    block_id: HashValue,
) {
    match e {
        ExecutorError::CouldNotGetData => {
            counter.with_label_values(&["CouldNotGetData"]).inc();
            warn!(
                block_id = block_id,
                "Execution error - CouldNotGetData {}", block_id
            );
        },
        ExecutorError::BlockNotFound(block_id) => {
            counter.with_label_values(&["BlockNotFound"]).inc();
            warn!(
                block_id = block_id,
                "Execution error BlockNotFound {}", block_id
            );
        },
        e => {
            counter.with_label_values(&["UnexpectedError"]).inc();
            warn!(
                block_id = block_id,
                "Execution error {:?} for {}", e, block_id
            );
        },
```
