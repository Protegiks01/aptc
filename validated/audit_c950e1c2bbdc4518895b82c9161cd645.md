# Audit Report

## Title
OptQS Parameter Attack: Malicious Leader Can Censor Validators Through Misplaced Blame in Availability Checking

## Summary
A malicious block proposer can exploit the OptQuorumStore (OptQS) batch availability checking mechanism to systematically censor specific validators by including their batches when those batches are not widely replicated, causing other validators to incorrectly blame the batch authors rather than the proposer, resulting in those validators being excluded from future OptQS proposals through the failure tracker mechanism.

## Finding Description

The OptQuorumStore feature allows proposers to include batches without proof-of-store quorum signatures (`opt_batches`) for improved throughput. The system contains an architectural flaw in how batch availability is checked and how blame is assigned for unavailable batches.

**Attack Flow:**

1. **Batch Inclusion with Exclusion Filter**: The proposer pulls opt_batches from their local proof queue with an `exclude_authors` parameter that filters out specific validator authors. [1](#0-0) 

2. **Lack of Availability Guarantee**: OptQS batches require only author validation via `verify_opt_batches()`, which checks if the batch author is a valid validator but does NOT verify quorum availability or proof-of-store signatures. [2](#0-1) 

3. **Misplaced Blame Mechanism**: When validators check payload availability for OptQuorumStore payloads, if a batch doesn't exist locally via `batch_reader.exists()`, the system records the **batch author's** validator index in the `missing_authors` BitVec, not the proposer who chose to include the unavailable batch. [3](#0-2) 

4. **Blame Propagation in Timeouts**: When a round times out, `compute_timeout_reason()` checks payload availability and creates a `RoundTimeoutReason::PayloadUnavailable { missing_authors }` that gets included in the timeout vote. [4](#0-3) 

5. **Aggregation Across Validators**: The `aggregated_timeout_reason()` method collects missing_authors from multiple validators and computes which authors were reported missing by at least f+1 validators by voting power. [5](#0-4) 

6. **Persistent Censorship via Failure Tracker**: The `ExponentialWindowFailureTracker` extracts `missing_authors` from past `PayloadUnavailable` timeouts and adds them to the `exclude_authors` HashSet for future OptQS proposals. [6](#0-5)  This `exclude_authors` set is then passed to `pull_batches()`, creating a censorship feedback loop. [7](#0-6) 

7. **Timeout Reason Recording**: The aggregated timeout reason is pushed to the proposal status tracker, feeding the failure tracker mechanism. [8](#0-7) 

**The Core Vulnerability:**

The architectural flaw is that the **proposer** has control over which batches to include (and can strategically include batches that are not widely available), but the **batch authors** receive the blame when those batches are unavailable to other validators. This misalignment of responsibility and accountability enables a censorship attack.

A malicious proposer can:
- Include opt_batches that haven't fully propagated through the network
- Include batches from targeted validators when network conditions delay propagation  
- Cause honest validators to report the batch authors as having unavailable batches
- Trigger the exponential window failure tracker to exclude those validators from future proposals

The failure tracker doubles its exclusion window on each failure (up to max_window of 100), meaning the exclusion can persist for extended periods. [9](#0-8) 

## Impact Explanation

**Severity Assessment: Medium**

This vulnerability represents a **protocol fairness violation** rather than a safety violation:

**Why NOT Critical:**
- Does not enable fund theft or unlimited minting
- Does not cause consensus safety violations (chain splits, double-spending)
- Does not permanently halt the network
- Does not freeze funds or enable remote code execution

**Why Medium:**
- **Consensus Fairness Violation**: The OptQS mechanism is designed to include batches from all validators fairly, but this attack enables selective censorship
- **Liveness Degradation**: Excluding multiple validators reduces effective transaction throughput as fewer batches are included in blocks
- **Persistent Effect**: The exponential window failure tracker can maintain exclusion for many rounds (up to 100 consecutive rounds at maximum window)
- **Difficult to Detect**: The attack appears as legitimate availability issues rather than malicious behavior, making it hard to identify and attribute

Per Aptos bug bounty categories, this aligns with **"Limited Protocol Violations"** (Medium severity) that impact consensus fairness and liveness without breaking safety guarantees.

## Likelihood Explanation

**Likelihood: Medium**

**Factors Enabling Exploitation:**
1. **Regular Opportunity**: Any validator becomes proposer in rotation, providing regular attack windows
2. **No Special Privileges**: Attacker only needs to be a validator; no >1/3 Byzantine requirement
3. **Logic-Based Exploit**: No cryptographic barriers or complex preconditions
4. **Detection Difficulty**: Misplaced blame makes the attack appear as victim's availability problems

**Limiting Factors:**
1. **Batch Age Requirement**: OptQS batches must meet minimum age requirements, reducing the window where batches are truly unavailable
2. **Network Propagation**: Under normal network conditions, batches propagate quickly enough that timeouts may not occur before fetch completes
3. **Prefetch Mechanism**: Validators attempt to prefetch payload data when proposals are received
4. **Recovery Mechanism**: The failure tracker resets to window=2 after consecutive successes, providing some recovery path

**Exploitation Complexity:**
The attack requires timing coordination where:
- The proposer includes batches at a moment when they're not widely available
- The round timeout occurs before validators can fetch the missing batches
- This is achievable but not guaranteed in every attempt

## Recommendation

Fix the blame assignment logic to attribute unavailable batches to the proposer who chose to include them, rather than the batch authors:

1. **Track Proposer Responsibility**: When a `PayloadUnavailable` timeout occurs, record the proposer's address alongside (or instead of) the batch authors' addresses.

2. **Proposer-Based Exclusion**: Modify the failure tracker to exclude proposers who repeatedly include unavailable batches from using OptQS, rather than excluding the batch authors.

3. **Availability Proof Requirement**: Consider requiring proposers to prove batch availability (e.g., witness signatures from f+1 validators) before including opt_batches, similar to the proof-of-store mechanism.

4. **Audit Trail**: Add logging and metrics to track which proposers include batches that later become unavailable, enabling detection of potential censorship attempts.

## Proof of Concept

The vulnerability is demonstrated through code analysis showing the architectural flaw in blame assignment. A practical PoC would require:

1. Setting up a test network with multiple validators
2. Having a malicious proposer include opt_batches from target validators at strategic times
3. Observing the timeout behavior and blame assignment in `missing_authors` BitVec
4. Verifying that the failure tracker excludes the batch authors rather than the proposer
5. Confirming that excluded validators' batches are no longer included in subsequent OptQS proposals

The code evidence provided above demonstrates that this attack flow is architecturally possible given the current blame assignment implementation.

## Notes

This vulnerability represents a **design flaw** in the OptQuorumStore blame assignment mechanism rather than an implementation bug. The system correctly implements the specified behavior, but that behavior creates a fairness violation where proposers can shift blame for unavailable batches onto innocent batch authors. While practical exploitation requires specific timing conditions, the architectural misalignment of responsibility and accountability creates a censorship vector that violates the fairness guarantees of the consensus protocol.

### Citations

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L596-600)
```rust
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
        {
```

**File:** consensus/consensus-types/src/common.rs (L558-572)
```rust
    pub fn verify_opt_batches<T: TBatchInfo>(
        verifier: &ValidatorVerifier,
        opt_batches: &OptBatches<T>,
    ) -> anyhow::Result<()> {
        let authors = verifier.address_to_validator_index();
        for batch in &opt_batches.batch_summary {
            ensure!(
                authors.contains_key(&batch.author()),
                "Invalid author {} for batch {}",
                batch.author(),
                batch.digest()
            );
        }
        Ok(())
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-425)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
            },
```

**File:** consensus/src/round_manager.rs (L469-470)
```rust
        self.proposal_status_tracker
            .push(new_round_event.reason.clone());
```

**File:** consensus/src/round_manager.rs (L968-983)
```rust
    fn compute_timeout_reason(&self, round: Round) -> RoundTimeoutReason {
        if self.round_state().vote_sent().is_some() {
            return RoundTimeoutReason::NoQC;
        }

        match self.block_store.get_block_for_round(round) {
            None => RoundTimeoutReason::ProposalNotReceived,
            Some(block) => {
                if let Err(missing_authors) = self.block_store.check_payload(block.block()) {
                    RoundTimeoutReason::PayloadUnavailable { missing_authors }
                } else {
                    RoundTimeoutReason::Unknown
                }
            },
        }
    }
```

**File:** consensus/src/pending_votes.rs (L93-153)
```rust
    fn aggregated_timeout_reason(&self, verifier: &ValidatorVerifier) -> RoundTimeoutReason {
        let mut reason_voting_power: HashMap<RoundTimeoutReason, u128> = HashMap::new();
        let mut missing_batch_authors: HashMap<usize, u128> = HashMap::new();
        // let ordered_authors = verifier.get_ordered_account_addresses();
        for (author, reason) in &self.timeout_reason {
            // To aggregate the reason, we only care about the variant type itself and
            // exclude any data within the variants.
            let reason_key = match reason {
                reason @ RoundTimeoutReason::Unknown
                | reason @ RoundTimeoutReason::ProposalNotReceived
                | reason @ RoundTimeoutReason::NoQC => reason.clone(),
                RoundTimeoutReason::PayloadUnavailable { missing_authors } => {
                    for missing_idx in missing_authors.iter_ones() {
                        *missing_batch_authors.entry(missing_idx).or_default() +=
                            verifier.get_voting_power(author).unwrap_or_default() as u128;
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        // Since we care only about the variant type, we replace the bitvec
                        // with a placeholder.
                        missing_authors: BitVec::with_num_bits(verifier.len() as u16),
                    }
                },
            };
            *reason_voting_power.entry(reason_key).or_default() +=
                verifier.get_voting_power(author).unwrap_or_default() as u128;
        }
        // The aggregated timeout reason is the reason with the most voting power received from
        // at least f+1 peers by voting power. If such voting power does not exist, then the
        // reason is unknown.

        reason_voting_power
            .into_iter()
            .max_by_key(|(_, voting_power)| *voting_power)
            .filter(|(_, voting_power)| {
                verifier
                    .check_aggregated_voting_power(*voting_power, false)
                    .is_ok()
            })
            .map(|(reason, _)| {
                // If the aggregated reason is due to unavailable payload, we will compute the
                // aggregated missing authors bitvec counting batch authors that have been reported
                // missing by minority peers.
                if matches!(reason, RoundTimeoutReason::PayloadUnavailable { .. }) {
                    let mut aggregated_bitvec = BitVec::with_num_bits(verifier.len() as u16);
                    for (author_idx, voting_power) in missing_batch_authors {
                        if verifier
                            .check_aggregated_voting_power(voting_power, false)
                            .is_ok()
                        {
                            aggregated_bitvec.set(author_idx as u16);
                        }
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        missing_authors: aggregated_bitvec,
                    }
                } else {
                    reason
                }
            })
            .unwrap_or(RoundTimeoutReason::Unknown)
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L65-78)
```rust
    fn compute_failure_window(&mut self) {
        self.last_consecutive_success_count = self.last_consecutive_statuses_matching(|reason| {
            !matches!(
                reason,
                NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable { .. })
            )
        });
        if self.last_consecutive_success_count == 0 {
            self.window *= 2;
            self.window = self.window.min(self.max_window);
        } else if self.last_consecutive_success_count == self.past_round_statuses.len() {
            self.window = 2;
        }
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L145-160)
```rust
        let exclude_authors = tracker.get_exclude_authors();
        if !exclude_authors.is_empty() {
            let exclude_authors_str: Vec<_> =
                exclude_authors.iter().map(|a| a.short_str()).collect();
            for author in &exclude_authors_str {
                counters::OPTQS_EXCLUDE_AUTHORS_COUNT
                    .with_label_values(&[author.as_str()])
                    .inc();
            }
            warn!("OptQS exclude authors: {:?}", exclude_authors_str);
        }
        Some(OptQSPayloadPullParams {
            exclude_authors,
            minimum_batch_age_usecs: self.minimum_batch_age_usecs,
        })
    }
```
