# Audit Report

## Title
Byzantine Proposer Can Falsely Exclude Honest Validators from OptQS Through Unauthenticated Batch Attribution

## Summary
A Byzantine validator acting as proposer can craft OptQuorumStore payloads with fake batch entries attributed to honest validators, causing all receiving validators to incorrectly report those honest validators as having missing payloads. This triggers automatic exclusion from OptQS, systematically degrading network efficiency and violating fairness guarantees.

## Finding Description

The vulnerability exists in the OptQuorumStore (OptQS) payload verification and timeout handling mechanism. The attack exploits the lack of cryptographic authentication on `BatchInfo` entries in `opt_batches`.

**Attack Flow:**

1. **Malicious Payload Creation**: When a Byzantine validator becomes proposer, they create an `OptQuorumStorePayload` with fake `BatchInfo` entries. The `BatchInfo` structure contains only metadata fields (author, batch_id, epoch, expiration, digest, num_txns, num_bytes, gas_bucket_start) without any signature field [1](#0-0) , allowing arbitrary attribution to any validator.

2. **Weak Verification**: The payload passes validation because `verify_opt_batches()` only checks if the author is in the validator set [2](#0-1) , with no signature verification to prove the claimed author actually created the batch.

3. **False Missing Detection**: When honest validators receive the block, `check_payload_availability()` verifies batch availability by checking if the digest exists locally [3](#0-2) . Since the fake batches with fabricated digests don't exist in any honest validator's batch reader, validators mark the falsely-attributed author as missing in the `missing_authors` BitVec.

4. **Timeout Propagation**: When validators timeout due to unavailable payload, they create `RoundTimeoutReason::PayloadUnavailable` with the manipulated `missing_authors` BitVec [4](#0-3) .

5. **Byzantine Aggregation**: The `aggregated_timeout_reason()` function aggregates timeout reasons from multiple validators [5](#0-4) . When computing aggregated missing authors, it checks if each author index has been reported missing by f+1 voting power (lines 137-143), and if so, marks that author in the aggregated BitVec. Since all honest validators see the same fake batch, they all report the same falsely-attributed author as missing, easily exceeding the f+1 threshold.

6. **Exclusion from OptQS**: The `get_exclude_authors()` function reads the aggregated `missing_authors` BitVec from PayloadUnavailable timeout reasons within a sliding window and adds those validators to the exclusion set [6](#0-5) .

7. **Network Degradation**: When pulling batches for OptQS, the excluded authors are filtered out [7](#0-6) , preventing their legitimate batches from being included in future OptQS payloads.

**Root Cause**: Unlike `ProofOfStore` which has cryptographic signatures via the `multi_signature` field and verification through `verify_multi_signatures()` [8](#0-7) , the `BatchInfo` structure in `opt_batches` has no signature field, allowing arbitrary batch attribution without proof of authorship.

## Impact Explanation

**Severity: High**

This vulnerability causes significant protocol violations through:

1. **Network Efficiency Degradation**: Byzantine proposers can systematically exclude honest validators from OptQS, forcing the network to fall back to less efficient payload mechanisms (regular quorum store with ProofOfStore requirements).

2. **Unfair Validator Treatment**: Honest validators are penalized and excluded for malicious actions they didn't commit, violating protocol fairness guarantees. There is no mechanism for falsely-accused validators to prove their innocence.

3. **Sustained Performance Impact**: The exclusion persists across the configured window size (tracked in the exponential failure tracker), allowing sustained degradation of network efficiency when Byzantine validators rotate as proposers.

4. **Byzantine Amplification**: A single Byzantine proposer can manipulate the entire validator set's behavior through false accusations, exceeding the expected impact of f Byzantine validators within the tolerance threshold.

While this doesn't directly cause fund loss or consensus safety violations, it qualifies as HIGH severity under "Validator Node Slowdowns" - causing significant performance degradation affecting consensus operations by forcing the network away from its optimized payload mechanism.

## Likelihood Explanation

**Likelihood: High**

- **Attack Complexity**: Low - A Byzantine proposer only needs to construct a malicious Block with fake BatchInfo entries (arbitrary author and digest values) and sign it with their legitimate proposer key when selected as leader.

- **Detection Difficulty**: High - The attack appears as legitimate payload unavailability to observers. The falsely-accused validators cannot distinguish between genuine unavailability and false accusations.

- **Frequency**: Occurs every time a Byzantine validator is selected as proposer through normal rotation (approximately 1/n probability per round where n is the validator set size).

- **Prerequisites**: Only requires being selected as proposer through normal consensus rotation. No special network conditions or coordinator attacks needed.

- **Persistence**: Exclusion persists across the configured exponential window size, allowing sustained impact until the window resets after consecutive successful rounds.

With f Byzantine validators in the system, this attack can be executed repeatedly to maintain continuous degradation of network efficiency.

## Recommendation

Add cryptographic authentication to `BatchInfo` entries, similar to `ProofOfStore`:

1. **Add signature field to BatchInfo**: Modify the `BatchInfo` struct to include a signature field proving the claimed author actually created the batch.

2. **Verify signatures in verify_opt_batches()**: Extend the validation logic to verify that each BatchInfo signature is valid for the claimed author, not just checking if the author is in the validator set.

3. **Alternative approach**: Require all opt_batches to have lightweight cryptographic proofs (e.g., signed batch digests) that can be quickly verified without full ProofOfStore overhead, maintaining the performance benefits of OptQS while preventing false attribution.

The fix should maintain the performance optimization goals of OptQS while ensuring batch authorship authenticity.

## Proof of Concept

A complete PoC would require setting up a test network with Byzantine validators. The attack flow:

```rust
// Conceptual PoC - Byzantine proposer creates fake BatchInfo
let fake_batch = BatchInfo::new(
    honest_validator_address,  // Falsely attribute to honest validator
    BatchId::new(attacker_nonce),
    current_epoch,
    expiration,
    HashValue::random(),  // Fake digest that doesn't exist anywhere
    100,  // fake num_txns
    10000,  // fake num_bytes
    0,  // gas_bucket_start
);

let malicious_payload = OptQuorumStorePayload::new(
    vec![],  // inline_batches
    vec![fake_batch],  // opt_batches with fake attribution
    vec![],  // proofs
    PayloadExecutionLimit::None,
);

// Create and sign malicious block as legitimate proposer
let malicious_block = Block::new_proposal(
    malicious_payload,
    byzantine_proposer,  // We're the legitimate proposer this round
    vec![],  // failed_authors
    round,
    timestamp,
    quorum_cert,
);
// Broadcast to network - honest validators will mark honest_validator_address as missing
```

## Notes

This vulnerability represents a fundamental design flaw in OptQuorumStore's trust model. The optimization of including batches without full ProofOfStore certification creates an attack vector where proposers can falsely attribute batches. The lack of any cryptographic binding between BatchInfo entries and their claimed authors enables this manipulation. While OptQS aims for efficiency, it should not sacrifice the ability to verify batch authorship, which is a critical component of fair validator participation.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L46-58)
```rust
#[derive(
    Clone, Debug, Deserialize, Serialize, CryptoHasher, BCSCryptoHash, PartialEq, Eq, Hash,
)]
pub struct BatchInfo {
    author: PeerId,
    batch_id: BatchId,
    epoch: u64,
    expiration: u64,
    digest: HashValue,
    num_txns: u64,
    num_bytes: u64,
    gas_bucket_start: u64,
}
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L618-652)
```rust
#[derive(Deserialize, Serialize, Clone, Debug, PartialEq, Eq)]
pub struct ProofOfStore<T> {
    info: T,
    multi_signature: AggregateSignature,
}

impl<T> ProofOfStore<T>
where
    T: TBatchInfo + Send + Sync + 'static,
{
    pub fn new(info: T, multi_signature: AggregateSignature) -> Self {
        Self {
            info,
            multi_signature,
        }
    }

    pub fn verify(&self, validator: &ValidatorVerifier, cache: &ProofCache) -> anyhow::Result<()> {
        let batch_info_ext: BatchInfoExt = self.info.clone().into();
        if let Some(signature) = cache.get(&batch_info_ext) {
            if signature == self.multi_signature {
                return Ok(());
            }
        }
        let result = validator
            .verify_multi_signatures(&self.info, &self.multi_signature)
            .context(format!(
                "Failed to verify ProofOfStore for batch: {:?}",
                self.info
            ));
        if result.is_ok() {
            cache.insert(batch_info_ext, self.multi_signature.clone());
        }
        result
    }
```

**File:** consensus/consensus-types/src/common.rs (L558-572)
```rust
    pub fn verify_opt_batches<T: TBatchInfo>(
        verifier: &ValidatorVerifier,
        opt_batches: &OptBatches<T>,
    ) -> anyhow::Result<()> {
        let authors = verifier.address_to_validator_index();
        for batch in &opt_batches.batch_summary {
            ensure!(
                authors.contains_key(&batch.author()),
                "Invalid author {} for batch {}",
                batch.author(),
                batch.digest()
            );
        }
        Ok(())
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/consensus-types/src/round_timeout.rs (L16-22)
```rust
#[derive(Deserialize, Serialize, Clone, PartialEq, Eq, Hash, Debug)]
pub enum RoundTimeoutReason {
    Unknown,
    ProposalNotReceived,
    PayloadUnavailable { missing_authors: BitVec },
    NoQC,
}
```

**File:** consensus/src/pending_votes.rs (L93-153)
```rust
    fn aggregated_timeout_reason(&self, verifier: &ValidatorVerifier) -> RoundTimeoutReason {
        let mut reason_voting_power: HashMap<RoundTimeoutReason, u128> = HashMap::new();
        let mut missing_batch_authors: HashMap<usize, u128> = HashMap::new();
        // let ordered_authors = verifier.get_ordered_account_addresses();
        for (author, reason) in &self.timeout_reason {
            // To aggregate the reason, we only care about the variant type itself and
            // exclude any data within the variants.
            let reason_key = match reason {
                reason @ RoundTimeoutReason::Unknown
                | reason @ RoundTimeoutReason::ProposalNotReceived
                | reason @ RoundTimeoutReason::NoQC => reason.clone(),
                RoundTimeoutReason::PayloadUnavailable { missing_authors } => {
                    for missing_idx in missing_authors.iter_ones() {
                        *missing_batch_authors.entry(missing_idx).or_default() +=
                            verifier.get_voting_power(author).unwrap_or_default() as u128;
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        // Since we care only about the variant type, we replace the bitvec
                        // with a placeholder.
                        missing_authors: BitVec::with_num_bits(verifier.len() as u16),
                    }
                },
            };
            *reason_voting_power.entry(reason_key).or_default() +=
                verifier.get_voting_power(author).unwrap_or_default() as u128;
        }
        // The aggregated timeout reason is the reason with the most voting power received from
        // at least f+1 peers by voting power. If such voting power does not exist, then the
        // reason is unknown.

        reason_voting_power
            .into_iter()
            .max_by_key(|(_, voting_power)| *voting_power)
            .filter(|(_, voting_power)| {
                verifier
                    .check_aggregated_voting_power(*voting_power, false)
                    .is_ok()
            })
            .map(|(reason, _)| {
                // If the aggregated reason is due to unavailable payload, we will compute the
                // aggregated missing authors bitvec counting batch authors that have been reported
                // missing by minority peers.
                if matches!(reason, RoundTimeoutReason::PayloadUnavailable { .. }) {
                    let mut aggregated_bitvec = BitVec::with_num_bits(verifier.len() as u16);
                    for (author_idx, voting_power) in missing_batch_authors {
                        if verifier
                            .check_aggregated_voting_power(voting_power, false)
                            .is_ok()
                        {
                            aggregated_bitvec.set(author_idx as u16);
                        }
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        missing_authors: aggregated_bitvec,
                    }
                } else {
                    reason
                }
            })
            .unwrap_or(RoundTimeoutReason::Unknown)
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L596-600)
```rust
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
        {
```
