# Audit Report

## Title
Out-of-Bounds Panic in Network Layer Subscriber Removal Causes Validator Network Crashes and Lock Poisoning

## Summary
The `broadcast()` function in `network/framework/src/application/storage.rs` contains a critical logic bug where removing multiple closed subscribers causes an out-of-bounds panic due to improper use of `swap_remove()` with stale indices. This panic occurs while holding critical locks, causing lock poisoning that renders the validator's network layer completely inoperable and requires node restart.

## Finding Description

The vulnerability exists in the subscriber cleanup logic of the `broadcast()` function. [1](#0-0) 

The code iterates through the subscriber list to identify closed channels, collecting their indices into the `to_del` vector. It then attempts to remove these subscribers by iterating through `to_del` and calling `swap_remove()` on each index.

**The Critical Flaw:** `swap_remove()` modifies the vector by swapping the last element into the removed position and shrinking the length. This invalidates all subsequent indices in the `to_del` vector that were collected before any removals occurred.

**Concrete Exploit Scenario:**
- Subscriber vector: [Sub0, Sub1, Sub2, Sub3, Sub4] (length 5)
- Closed channels at indices: 1, 3, 4
- `to_del = [1, 3, 4]`
- First `swap_remove(1)`: Vector becomes [Sub0, Sub4, Sub2, Sub3] (length 4)
- Second `swap_remove(3)`: Vector becomes [Sub0, Sub4, Sub2] (length 3)
- Third `swap_remove(4)`: **PANIC** - index 4 exceeds bounds of length 3 vector

**Lock Poisoning Chain:**

The `broadcast()` function is called from `remove_peer_metadata()` while holding the `peers_and_metadata` write lock. [2](#0-1) 

When the panic occurs:
1. The `subscribers` Mutex is held [3](#0-2) 
2. The `peers_and_metadata` RwLock is held in write mode [4](#0-3) 
3. Both locks become poisoned during panic unwinding
4. The critical cache update never executes [5](#0-4) 

The `aptos_infallible` lock implementations panic on any poisoned lock access: [6](#0-5)  and [7](#0-6) 

This causes cascading failures because all subsequent network operations (peer insertions, removals, connection state updates, metadata queries) will panic with "Cannot currently handle a poisoned lock" when attempting to acquire either lock.

**Secondary Impact - Cache Inconsistency:**

The cache update at line 259 never executes, leaving the peer removed from the main map but still present in the cached data. This affects components like the consensus publisher that rely on the cached peer metadata for determining connected peers. [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **HIGH Severity** under the Aptos bug bounty category of **"API Crashes affecting network participation"**.

**Primary Impact:**
- **Network Layer Crash**: Out-of-bounds panic terminates the network operation
- **Complete Lock Poisoning**: Both `peers_and_metadata` RwLock and `subscribers` Mutex become permanently poisoned
- **Total Network Dysfunction**: All network operations requiring these locks panic on access, making peer management, connection handling, and metadata queries impossible
- **Loss of Network Participation**: The validator cannot send or receive network messages, effectively removing it from consensus participation
- **Mandatory Manual Recovery**: Node restart is the only recovery path from poisoned lock state

**Secondary Impact:**
- **Cache Inconsistency**: Stale peer data served to network clients
- **Partial Event Notification**: Incomplete subscriber notification creates inconsistent network topology views
- **Consensus Publisher Inefficiency**: Continues sending to disconnected peers that appear connected in stale cache

While the validator process doesn't terminate, the complete inability to perform network operations functionally equivalent to a node crash from a consensus participation perspective.

## Likelihood Explanation

**Medium Likelihood** - This bug can be triggered through normal production network operations without malicious intent:

1. **Natural Subscriber Closure**: Network components (health checker, consensus observer, connectivity manager) create subscriptions that close during component restarts, crashes, or resource cleanup operations

2. **Multi-Component Architecture**: Production validators run multiple network-dependent components that each subscribe to connection events, making 3+ simultaneous subscribers realistic

3. **Common Trigger**: Peer disconnections occur frequently due to normal network churn, validator restarts, and network instability

4. **Timing Window**: The bug triggers when 3+ closed subscriber channels exist AND a peer subsequently disconnects, calling `remove_peer_metadata()` â†’ `broadcast()`

5. **No Protection**: No validation exists to prevent stale index usage - the code directly iterates through collected indices without bounds checking

While requiring specific timing (3+ closed channels before peer disconnection), this scenario is realistic in long-running production validators experiencing component restarts or high network churn.

## Recommendation

**Fix the index invalidation issue by iterating in reverse order:**

```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    let mut to_del = vec![];
    for i in 0..listeners.len() {
        let dest = listeners.get_mut(i).unwrap();
        if let Err(err) = dest.try_send(event.clone()) {
            match err {
                TrySendError::Full(_) => { /* log and continue */ },
                TrySendError::Closed(_) => {
                    to_del.push(i);
                },
            }
        }
    }
    // Iterate in REVERSE order to maintain index validity
    for evict in to_del.into_iter().rev() {
        listeners.swap_remove(evict);
    }
}
```

**Alternative using retain():**

```rust
fn broadcast(&self, event: ConnectionNotification) {
    let mut listeners = self.subscribers.lock();
    
    // Send to all subscribers and mark closed ones
    let mut closed_indices = vec![];
    for (i, dest) in listeners.iter_mut().enumerate() {
        if let Err(err) = dest.try_send(event.clone()) {
            match err {
                TrySendError::Full(_) => { /* log */ },
                TrySendError::Closed(_) => closed_indices.push(i),
            }
        }
    }
    
    // Remove closed subscribers using retain
    let closed_set: std::collections::HashSet<_> = closed_indices.into_iter().collect();
    let mut index = 0;
    listeners.retain(|_| {
        let keep = !closed_set.contains(&index);
        index += 1;
        keep
    });
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio::sync::mpsc;
    
    #[tokio::test]
    async fn test_broadcast_multiple_closed_subscribers_panic() {
        let peers_and_metadata = PeersAndMetadata::new(&[NetworkId::Validator]);
        
        // Create 5 subscribers
        let mut receivers = vec![];
        for _ in 0..5 {
            receivers.push(peers_and_metadata.subscribe());
        }
        
        // Drop receivers at indices 1, 3, 4 to close their channels
        drop(receivers.remove(4));
        drop(receivers.remove(3));
        drop(receivers.remove(1));
        
        // Insert a test peer
        let peer_id = PeerId::random();
        let connection_metadata = ConnectionMetadata::mock(peer_id);
        let peer_network_id = PeerNetworkId::new(NetworkId::Validator, peer_id);
        
        peers_and_metadata
            .insert_connection_metadata(peer_network_id, connection_metadata.clone())
            .unwrap();
        
        // Trigger the bug: removing the peer will call broadcast() with 3 closed channels
        // This will panic with out-of-bounds error
        let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
            peers_and_metadata
                .remove_peer_metadata(peer_network_id, connection_metadata.connection_id)
                .unwrap();
        }));
        
        // Verify panic occurred
        assert!(result.is_err(), "Expected panic due to out-of-bounds access");
        
        // Verify locks are now poisoned
        let lock_result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
            peers_and_metadata.get_all_peers()
        }));
        
        assert!(lock_result.is_err(), "Expected panic due to poisoned lock");
    }
}
```

## Notes

This is a legitimate logic vulnerability in production code that can cause complete network layer failure through lock poisoning. The bug is triggered through normal network operations without requiring malicious actors. The impact severity aligns with HIGH classification under "API Crashes affecting network participation" as the validator loses all network functionality and requires restart.

### Citations

**File:** network/framework/src/application/storage.rs (L219-262)
```rust
    pub fn remove_peer_metadata(
        &self,
        peer_network_id: PeerNetworkId,
        connection_id: ConnectionId,
    ) -> Result<PeerMetadata, Error> {
        // Grab the write lock for the peer metadata
        let mut peers_and_metadata = self.peers_and_metadata.write();

        // Fetch the peer metadata for the given network
        let peer_metadata_for_network =
            get_peer_metadata_for_network(&peer_network_id, &mut peers_and_metadata)?;

        // Remove the peer metadata for the peer
        let peer_metadata = if let Entry::Occupied(entry) =
            peer_metadata_for_network.entry(peer_network_id.peer_id())
        {
            // Don't remove the peer if the connection doesn't match!
            // For now, remove the peer entirely, we could in the future
            // have multiple connections for a peer
            let active_connection_id = entry.get().connection_metadata.connection_id;
            if active_connection_id == connection_id {
                let peer_metadata = entry.remove();
                let event = ConnectionNotification::LostPeer(
                    peer_metadata.connection_metadata.clone(),
                    peer_network_id.network_id(),
                );
                self.broadcast(event);
                peer_metadata
            } else {
                return Err(Error::UnexpectedError(format!(
                    "The peer connection id did not match! Given: {:?}, found: {:?}.",
                    connection_id, active_connection_id
                )));
            }
        } else {
            // Unable to find the peer metadata for the given peer
            return Err(missing_peer_metadata_error(&peer_network_id));
        };

        // Update the cached peers and metadata
        self.set_cached_peers_and_metadata(peers_and_metadata.clone());

        Ok(peer_metadata)
    }
```

**File:** network/framework/src/application/storage.rs (L371-395)
```rust
    fn broadcast(&self, event: ConnectionNotification) {
        let mut listeners = self.subscribers.lock();
        let mut to_del = vec![];
        for i in 0..listeners.len() {
            let dest = listeners.get_mut(i).unwrap();
            if let Err(err) = dest.try_send(event.clone()) {
                match err {
                    TrySendError::Full(_) => {
                        // Tried to send to an app, but the app isn't handling its messages fast enough.
                        // Drop message. Maybe increment a metrics counter?
                        sample!(
                            SampleRate::Duration(Duration::from_secs(1)),
                            warn!("PeersAndMetadata.broadcast() failed, some app is slow"),
                        );
                    },
                    TrySendError::Closed(_) => {
                        to_del.push(i);
                    },
                }
            }
        }
        for evict in to_del.into_iter() {
            listeners.swap_remove(evict);
        }
    }
```

**File:** crates/aptos-infallible/src/rwlock.rs (L19-30)
```rust
    pub fn read(&self) -> RwLockReadGuard<'_, T> {
        self.0
            .read()
            .expect("Cannot currently handle a poisoned lock")
    }

    /// lock the rwlock in write mode
    pub fn write(&self) -> RwLockWriteGuard<'_, T> {
        self.0
            .write()
            .expect("Cannot currently handle a poisoned lock")
    }
```

**File:** crates/aptos-infallible/src/mutex.rs (L19-23)
```rust
    pub fn lock(&self) -> MutexGuard<'_, T> {
        self.0
            .lock()
            .expect("Cannot currently handle a poisoned lock")
    }
```

**File:** consensus/src/consensus_observer/publisher/consensus_publisher.rs (L103-118)
```rust
        // Get the connected peers and metadata
        let peers_and_metadata = self.consensus_observer_client.get_peers_and_metadata();
        let connected_peers_and_metadata =
            match peers_and_metadata.get_connected_peers_and_metadata() {
                Ok(connected_peers_and_metadata) => connected_peers_and_metadata,
                Err(error) => {
                    // We failed to get the connected peers and metadata
                    warn!(LogSchema::new(LogEntry::ConsensusPublisher)
                        .event(LogEvent::UnexpectedError)
                        .message(&format!(
                            "Failed to get connected peers and metadata! Error: {:?}",
                            error
                        )));
                    return;
                },
            };
```
