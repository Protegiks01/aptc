# Audit Report

## Title
OptQS Exclusion Bomb: Malicious Proposer Can Disable Optimistic Quorum Store via Fake Batch Inclusion

## Summary
A Byzantine validator acting as proposer can create an `OptQuorumStorePayload` containing fabricated batch references for all validators, triggering a cascading exclusion mechanism that disables OptQS's optimistic batch feature for multiple rounds, significantly degrading consensus throughput network-wide.

## Finding Description

The vulnerability exists in the interaction between payload verification, availability checking, and failure tracking in OptQS. The attack exploits weak validation in the optimistic batch verification path.

**Attack Flow:**

**Step 1 - Weak Validation**: The `verify_opt_batches` function only validates that batch authors are legitimate validators, without verifying batch existence or digest authenticity. [1](#0-0) 

The validation only checks `authors.contains_key(&batch.author())` but never verifies the digest corresponds to an actual batch.

**Step 2 - Fake Batch Creation**: A malicious proposer constructs an `OptQuorumStorePayload::V1` with `opt_batches` containing fabricated `BatchInfo` entries for all validators with non-existent digests. The payload passes verification since author checks succeed. [2](#0-1) 

**Step 3 - Availability Check Failure**: When honest validators receive the block, they execute `check_payload_availability` which calls `batch_reader.exists()` for each opt_batch. Since digests are fake, all batches are reported missing, causing all validator indices to be set in the `missing_authors` BitVec. [3](#0-2) 

**Step 4 - Timeout Generation**: The missing payload causes validators to generate a timeout with the missing_authors BitVec populated. [4](#0-3) 

**Step 5 - Timeout Aggregation**: When f+1 validators report `PayloadUnavailable`, the aggregation logic counts voting power per missing author index and includes any author reported missing by f+1 voting power in the aggregated result. [5](#0-4) 

The critical code at lines 137-143 sets bits for any author_idx with sufficient voting power reporting them missing.

**Step 6 - Exclusion Bomb**: The `ExponentialWindowFailureTracker` receives the aggregated timeout reason and `get_exclude_authors()` iterates through the failure window, adding ALL validators from the `missing_authors` BitVec to the exclusion set. [6](#0-5) 

**Step 7 - OptQS Disabled**: When pulling optimistic batches, `pull_batches` filters by `.filter(|(author, _)| !exclude_authors.contains(author))`. With all validators excluded, no optimistic batches are pulled. [7](#0-6) 

**Step 8 - Prolonged Impact**: The failure window uses exponential backoff, starting at 2 and doubling on each `PayloadUnavailable` failure up to `max_window` (default 100). The exclusion persists until the window is satisfied with consecutive successes. [8](#0-7) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty category "Validator node slowdowns":

1. **Performance Degradation**: OptQS's primary optimization (speculative batch inclusion without full proofs) is completely disabled network-wide. Consensus throughput degrades to only using authenticated proofs and inline batches, significantly reducing transaction processing capacity.

2. **Network-Wide Impact**: All validators experience performance degradation during exclusion periods, not just the attacker.

3. **Prolonged Effect**: The exclusion persists for `window` consecutive successful rounds. Starting at 2 rounds and doubling on each attack, reaching up to 100 rounds of degraded performance. On a 1-second block time, this means up to 100 seconds of reduced throughput per attack.

4. **Repeatable Attack**: Any Byzantine validator can execute this attack whenever they become proposer. In round-robin or randomized leader selection, this occurs regularly, allowing repeated degradation attacks.

5. **No Safety Violation**: Consensus safety guarantees are maintained (no double-spending, no chain splits). However, the liveness/performance degradation is significant and exploitable.

## Likelihood Explanation

**Likelihood: High**

1. **Attack Requirements**: Only requires being a validator (< 1/3 Byzantine assumption) and becoming proposer for a single round. No collusion or coordination needed.

2. **Technical Complexity**: Extremely low. Attacker simply includes fake `BatchInfo` entries in the `opt_batches` field with arbitrary digests. No complex timing or state manipulation required.

3. **Detection Difficulty**: The attack appears as legitimate payload unavailability. Network operators cannot easily distinguish between malicious fake batches and actual network/storage issues causing batch unavailability.

4. **Execution Frequency**: In rotating leader protocols, any validator statistically becomes proposer regularly. A Byzantine validator can execute this attack every time they're selected.

5. **Economic Incentives**: Could be used by competing validators to degrade network performance, or as griefing/DoS against the protocol with minimal cost.

## Recommendation

**Fix 1: Strengthen opt_batches Validation**

Add digest verification to `verify_opt_batches`:

```rust
pub fn verify_opt_batches<T: TBatchInfo>(
    verifier: &ValidatorVerifier,
    opt_batches: &OptBatches<T>,
    batch_reader: &dyn BatchReader, // Add batch reader
) -> anyhow::Result<()> {
    let authors = verifier.address_to_validator_index();
    for batch in &opt_batches.batch_summary {
        ensure!(
            authors.contains_key(&batch.author()),
            "Invalid author {} for batch {}",
            batch.author(),
            batch.digest()
        );
        // Add existence check
        ensure!(
            batch_reader.exists(batch.digest()).is_some(),
            "Batch {} from {} does not exist",
            batch.digest(),
            batch.author()
        );
    }
    Ok(())
}
```

**Fix 2: Rate-limit Exclusion Updates**

Modify `ExponentialWindowFailureTracker` to only exclude authors reported missing by a larger threshold (e.g., 2f+1 instead of f+1), or implement per-author exclusion tracking to avoid excluding all validators simultaneously.

**Fix 3: Add Proposer Reputation Tracking**

Track which proposers frequently cause `PayloadUnavailable` timeouts and apply additional scrutiny or temporary exclusion to suspicious proposers.

## Proof of Concept

The attack can be demonstrated by:

1. Creating an `OptQuorumStorePayload::V1` with fabricated `BatchInfo` entries in `opt_batches`
2. Submitting as a block proposal when the Byzantine validator is proposer
3. Observing honest validators timeout with `PayloadUnavailable` containing all validator indices
4. Verifying the `ExponentialWindowFailureTracker` excludes all validators
5. Confirming subsequent proposals have empty `opt_batches` due to universal exclusion

The vulnerability is exploitable in the current codebase as the validation path lacks batch existence checks for optimistic batches.

## Notes

This is a protocol-level performance degradation vulnerability, not a network DoS attack. The attack exploits legitimate consensus mechanisms (timeout aggregation, failure tracking) by providing malformed but syntactically valid payloads. The vulnerability demonstrates a gap between the optimistic batch verification (weak) and regular batch verification (strong with proofs).

### Citations

**File:** consensus/consensus-types/src/common.rs (L558-572)
```rust
    pub fn verify_opt_batches<T: TBatchInfo>(
        verifier: &ValidatorVerifier,
        opt_batches: &OptBatches<T>,
    ) -> anyhow::Result<()> {
        let authors = verifier.address_to_validator_index();
        for batch in &opt_batches.batch_summary {
            ensure!(
                authors.contains_key(&batch.author()),
                "Invalid author {} for batch {}",
                batch.author(),
                batch.digest()
            );
        }
        Ok(())
    }
```

**File:** consensus/consensus-types/src/common.rs (L598-607)
```rust
            (true, Payload::OptQuorumStore(OptQuorumStorePayload::V1(p))) => {
                let proof_with_data = p.proof_with_data();
                Self::verify_with_cache(&proof_with_data.batch_summary, verifier, proof_cache)?;
                Self::verify_inline_batches(
                    p.inline_batches()
                        .iter()
                        .map(|batch| (batch.info(), batch.transactions())),
                )?;
                Self::verify_opt_batches(verifier, p.opt_batches())?;
                Ok(())
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/src/round_manager.rs (L973-982)
```rust
        match self.block_store.get_block_for_round(round) {
            None => RoundTimeoutReason::ProposalNotReceived,
            Some(block) => {
                if let Err(missing_authors) = self.block_store.check_payload(block.block()) {
                    RoundTimeoutReason::PayloadUnavailable { missing_authors }
                } else {
                    RoundTimeoutReason::Unknown
                }
            },
        }
```

**File:** consensus/src/pending_votes.rs (L93-153)
```rust
    fn aggregated_timeout_reason(&self, verifier: &ValidatorVerifier) -> RoundTimeoutReason {
        let mut reason_voting_power: HashMap<RoundTimeoutReason, u128> = HashMap::new();
        let mut missing_batch_authors: HashMap<usize, u128> = HashMap::new();
        // let ordered_authors = verifier.get_ordered_account_addresses();
        for (author, reason) in &self.timeout_reason {
            // To aggregate the reason, we only care about the variant type itself and
            // exclude any data within the variants.
            let reason_key = match reason {
                reason @ RoundTimeoutReason::Unknown
                | reason @ RoundTimeoutReason::ProposalNotReceived
                | reason @ RoundTimeoutReason::NoQC => reason.clone(),
                RoundTimeoutReason::PayloadUnavailable { missing_authors } => {
                    for missing_idx in missing_authors.iter_ones() {
                        *missing_batch_authors.entry(missing_idx).or_default() +=
                            verifier.get_voting_power(author).unwrap_or_default() as u128;
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        // Since we care only about the variant type, we replace the bitvec
                        // with a placeholder.
                        missing_authors: BitVec::with_num_bits(verifier.len() as u16),
                    }
                },
            };
            *reason_voting_power.entry(reason_key).or_default() +=
                verifier.get_voting_power(author).unwrap_or_default() as u128;
        }
        // The aggregated timeout reason is the reason with the most voting power received from
        // at least f+1 peers by voting power. If such voting power does not exist, then the
        // reason is unknown.

        reason_voting_power
            .into_iter()
            .max_by_key(|(_, voting_power)| *voting_power)
            .filter(|(_, voting_power)| {
                verifier
                    .check_aggregated_voting_power(*voting_power, false)
                    .is_ok()
            })
            .map(|(reason, _)| {
                // If the aggregated reason is due to unavailable payload, we will compute the
                // aggregated missing authors bitvec counting batch authors that have been reported
                // missing by minority peers.
                if matches!(reason, RoundTimeoutReason::PayloadUnavailable { .. }) {
                    let mut aggregated_bitvec = BitVec::with_num_bits(verifier.len() as u16);
                    for (author_idx, voting_power) in missing_batch_authors {
                        if verifier
                            .check_aggregated_voting_power(voting_power, false)
                            .is_ok()
                        {
                            aggregated_bitvec.set(author_idx as u16);
                        }
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        missing_authors: aggregated_bitvec,
                    }
                } else {
                    reason
                }
            })
            .unwrap_or(RoundTimeoutReason::Unknown)
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L65-78)
```rust
    fn compute_failure_window(&mut self) {
        self.last_consecutive_success_count = self.last_consecutive_statuses_matching(|reason| {
            !matches!(
                reason,
                NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable { .. })
            )
        });
        if self.last_consecutive_success_count == 0 {
            self.window *= 2;
            self.window = self.window.min(self.max_window);
        } else if self.last_consecutive_success_count == self.past_round_statuses.len() {
            self.window = 2;
        }
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L595-599)
```rust
        let mut iters = vec![];
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
```
