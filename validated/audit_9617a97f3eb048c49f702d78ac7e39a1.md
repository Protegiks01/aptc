# Audit Report

## Title
Mixed-Epoch SyncInfo Generation During BlockStore Rebuild Causes Consensus Liveness Failure

## Summary
The `sync_info()` function returns a `SyncInfo` containing certificates from different epochs when `rebuild()` is called during epoch transitions. The old epoch's timeout certificate is rolled over without epoch validation, violating the invariant that all certificates in a `SyncInfo` must be from the same epoch, causing other nodes to reject messages and breaking consensus liveness.

## Finding Description

The vulnerability exists in the consensus layer's state synchronization mechanism. When a node syncs to a new epoch, it incorrectly rolls over the previous epoch's timeout certificate into the new epoch's `BlockTree` without epoch validation.

**Root Cause 1 - Timeout Certificate Rollover Without Epoch Check:** [1](#0-0) 

The `rebuild()` method retrieves the old timeout certificate from the in-memory BlockTree and passes it to the new tree without checking if it matches the new epoch. This bypasses the storage-level epoch filtering that only occurs during initial startup.

**Root Cause 2 - Missing Epoch Validation in BlockTree Constructor:** [2](#0-1) 

The `BlockTree::new()` constructor validates that the window root and ordered certificate are from the same epoch (line 113), but does NOT validate the `highest_2chain_timeout_cert` epoch when it's stored at line 145.

**Root Cause 3 - Unvalidated SyncInfo Construction:** [3](#0-2) 

The `sync_info()` method constructs a `SyncInfo` without calling `verify()`, allowing mixed-epoch certificates to be packaged together.

**Why Old Timeout Certificate Persists:** [4](#0-3) 

The `insert_2chain_timeout_certificate()` method only replaces the timeout certificate if the new one has a higher round. Since rounds restart at each epoch [5](#0-4) , an old epoch's timeout certificate at round 100 will have a higher round than a new epoch's timeout certificate at round 5, causing the old certificate to persist.

**Attack Propagation:**

1. Node operates in epoch N with timeout certificate at round R
2. Epoch N ends
3. Node receives epoch N+1 blocks via sync protocol, triggering `add_certs()` [6](#0-5) 
4. `sync_to_highest_quorum_cert()` calls `rebuild()` [7](#0-6) 
5. New BlockTree created with epoch N+1 blocks but epoch N timeout certificate
6. `sync_info()` returns mixed-epoch SyncInfo
7. Node broadcasts this in consensus messages

**Verification Failure at Recipients:** [8](#0-7) 

When other nodes receive the mixed-epoch `SyncInfo`, the verification at line 149 fails with "Multi epoch in SyncInfo - TC and HQC" error, causing the message to be rejected.

**Why Storage Filtering Doesn't Protect:** [9](#0-8) 

While epoch filtering exists for timeout certificates loaded from storage during startup, `rebuild()` retrieves the timeout certificate from in-memory BlockTree data, completely bypassing this protection.

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria:

1. **Consensus Liveness Violation**: If the affected node is a proposer, its proposals are rejected by all validators, blocking consensus progress for that round. This constitutes a significant protocol violation.

2. **Validator Operational Issues**: The affected validator cannot participate effectively in consensus, with all its messages systematically rejected until manual intervention (restart) or a new timeout certificate with higher round is created in the current epoch.

3. **Cascading Failures**: Multiple nodes experiencing this simultaneously during epoch transitions can cause network-wide sync failures, potentially approaching Critical severity if enough validators are affected.

4. **Persistent Issue**: The rolled-over timeout certificate persists across multiple rounds until explicit replacement, not self-correcting.

This meets the Aptos bug bounty **High Severity** category for "Validator Node Slowdowns" and "Significant protocol violations."

## Likelihood Explanation

**Likelihood: Medium to High**

This vulnerability triggers automatically during normal network operations:

**Triggering Conditions:**
1. **Epoch Transitions**: Occur regularly in Aptos (typically daily or governance-triggered)
2. **State Sync During Transition**: Node catching up via sync when epoch changes
3. **Pre-existing Timeout Certificate**: Node has timeout certificate from old epoch

**No Attacker Required**: This is a protocol-level bug manifesting during normal operations. Common scenarios include:
- Validators restarting during epoch transitions
- Nodes experiencing temporary network issues during epoch changes
- Fast state sync operations spanning epoch boundaries

**Frequency**: Given regular epoch transitions and common validator restart/sync patterns, affected nodes likely encounter this multiple times per year in production environments.

## Recommendation

Add epoch validation in `BlockTree::new()` constructor to ensure the timeout certificate matches the epoch of other certificates:

```rust
pub(super) fn new(
    commit_root_id: HashValue,
    window_root: PipelinedBlock,
    root_quorum_cert: QuorumCert,
    root_ordered_cert: WrappedLedgerInfo,
    root_commit_cert: WrappedLedgerInfo,
    max_pruned_blocks_in_mem: usize,
    highest_2chain_timeout_cert: Option<Arc<TwoChainTimeoutCertificate>>,
) -> Self {
    assert_eq!(window_root.epoch(), root_ordered_cert.commit_info().epoch());
    assert!(window_root.round() <= root_ordered_cert.commit_info().round());
    
    // ADD THIS VALIDATION:
    let epoch = root_ordered_cert.commit_info().epoch();
    if let Some(tc) = &highest_2chain_timeout_cert {
        assert_eq!(tc.epoch(), epoch, 
            "Timeout certificate epoch {} doesn't match tree epoch {}", 
            tc.epoch(), epoch);
    }
    
    // ... rest of constructor
}
```

Alternatively, filter out mismatched timeout certificates in `rebuild()` before passing to `build()`.

## Proof of Concept

While a full end-to-end PoC requires a multi-node testnet with epoch transitions, the vulnerability can be demonstrated through the code paths:

1. Set up node in epoch N with timeout certificate TC_N at round 100
2. Trigger epoch transition to epoch N+1
3. Call `rebuild()` with epoch N+1 root and blocks
4. Observe that `highest_2chain_timeout_cert()` returns epoch N certificate
5. Call `sync_info()` and observe mixed-epoch SyncInfo
6. Call `verify()` on the SyncInfo and observe "Multi epoch in SyncInfo - TC and HQC" error

The vulnerability is evident from the code structure where no epoch validation exists in the critical path from `rebuild()` through `BlockTree::new()` to `sync_info()`.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L370-379)
```rust
        // Rollover the previous highest TC from the old tree to the new one.
        let prev_2chain_htc = self
            .highest_2chain_timeout_cert()
            .map(|tc| tc.as_ref().clone());
        let _ = Self::build(
            root,
            root_metadata,
            blocks,
            quorum_certs,
            prev_2chain_htc,
```

**File:** consensus/src/block_storage/block_store.rs (L560-575)
```rust
    pub fn insert_2chain_timeout_certificate(
        &self,
        tc: Arc<TwoChainTimeoutCertificate>,
    ) -> anyhow::Result<()> {
        let cur_tc_round = self
            .highest_2chain_timeout_cert()
            .map_or(0, |tc| tc.round());
        if tc.round() <= cur_tc_round {
            return Ok(());
        }
        self.storage
            .save_highest_2chain_timeout_cert(tc.as_ref())
            .context("Timeout certificate insert failed when persisting to DB")?;
        self.inner.write().replace_2chain_timeout_cert(tc);
        Ok(())
    }
```

**File:** consensus/src/block_storage/block_store.rs (L680-688)
```rust
    fn sync_info(&self) -> SyncInfo {
        SyncInfo::new_decoupled(
            self.highest_quorum_cert().as_ref().clone(),
            self.highest_ordered_cert().as_ref().clone(),
            self.highest_commit_cert().as_ref().clone(),
            self.highest_2chain_timeout_cert()
                .map(|tc| tc.as_ref().clone()),
        )
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L113-145)
```rust
        assert_eq!(window_root.epoch(), root_ordered_cert.commit_info().epoch());
        assert!(window_root.round() <= root_ordered_cert.commit_info().round());
        let window_root_id = window_root.id();

        // Build the tree from the window root block which is <= the commit root block.
        let mut id_to_block = HashMap::new();
        let mut round_to_ids = BTreeMap::new();
        round_to_ids.insert(window_root.round(), window_root_id);
        id_to_block.insert(window_root_id, LinkableBlock::new(window_root));
        counters::NUM_BLOCKS_IN_TREE.set(1);

        let root_quorum_cert = Arc::new(root_quorum_cert);
        let mut id_to_quorum_cert = HashMap::new();
        id_to_quorum_cert.insert(
            root_quorum_cert.certified_block().id(),
            Arc::clone(&root_quorum_cert),
        );

        let pruned_block_ids = VecDeque::with_capacity(max_pruned_blocks_in_mem);

        BlockTree {
            id_to_block,
            ordered_root_id: commit_root_id,
            commit_root_id, // initially we set commit_root_id = root_id
            window_root_id,
            highest_certified_block_id: commit_root_id,
            highest_quorum_cert: Arc::clone(&root_quorum_cert),
            highest_ordered_cert: Arc::new(root_ordered_cert),
            highest_commit_cert: Arc::new(root_commit_cert),
            id_to_quorum_cert,
            pruned_block_ids,
            max_pruned_blocks_in_mem,
            highest_2chain_timeout_cert,
```

**File:** consensus/consensus-types/src/block_data.rs (L292-300)
```rust
    pub fn new_genesis(timestamp_usecs: u64, quorum_cert: QuorumCert) -> Self {
        assume!(quorum_cert.certified_block().epoch() < u64::MAX); // unlikely to be false in this universe
        Self {
            epoch: quorum_cert.certified_block().epoch() + 1,
            round: 0,
            timestamp_usecs,
            quorum_cert,
            block_type: BlockType::Genesis,
        }
```

**File:** consensus/src/block_storage/sync_manager.rs (L116-172)
```rust
    pub async fn add_certs(
        &self,
        sync_info: &SyncInfo,
        mut retriever: BlockRetriever,
    ) -> anyhow::Result<()> {
        // When the local ordered round is very old than the received sync_info, this function will
        // (1) resets the block store with highest commit cert = sync_info.highest_quorum_cert()
        // (2) insert all the blocks between (inclusive) highest_commit_cert.commit_info().id() to
        // highest_quorum_cert.certified_block().id() into the block store and storage
        // (3) insert the quorum cert for all the above blocks into the block store and storage
        // (4) executes all the blocks that are ordered while inserting the above quorum certs
        self.sync_to_highest_quorum_cert(
            sync_info.highest_quorum_cert().clone(),
            sync_info.highest_commit_cert().clone(),
            &mut retriever,
        )
        .await?;

        self.sync_to_highest_commit_cert(
            sync_info.highest_commit_cert().ledger_info(),
            retriever.network.clone(),
        )
        .await;

        // The insert_ordered_cert(order_cert) function call expects that order_cert.commit_info().id() block
        // is already stored in block_store. So, we first call insert_quorum_cert(highest_quorum_cert).
        // This call will ensure that the highest ceritified block along with all its ancestors are inserted
        // into the block store.
        self.insert_quorum_cert(sync_info.highest_quorum_cert(), &mut retriever)
            .await?;

        // Even though we inserted the highest_quorum_cert (and its ancestors) in the above step,
        // we still need to insert ordered cert explicitly. This will send the highest ordered block
        // to execution.
        if self.order_vote_enabled {
            self.insert_ordered_cert(&sync_info.highest_ordered_cert())
                .await?;
        } else {
            // When order votes are disabled, the highest_ordered_cert().certified_block().id() need not be
            // one of the ancestors of highest_quorum_cert.certified_block().id() due to forks. So, we call
            // insert_quorum_cert instead of insert_ordered_cert as in the above case. This will ensure that
            // highest_ordered_cert().certified_block().id() is inserted the block store.
            self.insert_quorum_cert(
                &self
                    .highest_ordered_cert()
                    .as_ref()
                    .clone()
                    .into_quorum_cert(self.order_vote_enabled)?,
                &mut retriever,
            )
            .await?;
        }

        if let Some(tc) = sync_info.highest_2chain_timeout_cert() {
            self.insert_2chain_timeout_certificate(Arc::new(tc.clone()))?;
        }
        Ok(())
```

**File:** consensus/src/block_storage/sync_manager.rs (L313-313)
```rust
        self.rebuild(root, root_metadata, blocks, quorum_certs)
```

**File:** consensus/consensus-types/src/sync_info.rs (L138-150)
```rust
    pub fn verify(&self, validator: &ValidatorVerifier) -> anyhow::Result<()> {
        let epoch = self.highest_quorum_cert.certified_block().epoch();
        ensure!(
            epoch == self.highest_ordered_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HQC"
        );
        ensure!(
            epoch == self.highest_commit_cert().commit_info().epoch(),
            "Multi epoch in SyncInfo - HOC and HCC"
        );
        if let Some(tc) = &self.highest_2chain_timeout_cert {
            ensure!(epoch == tc.epoch(), "Multi epoch in SyncInfo - TC and HQC");
        }
```

**File:** consensus/src/persistent_liveness_storage.rs (L414-417)
```rust
            highest_2chain_timeout_certificate: match highest_2chain_timeout_cert {
                Some(tc) if tc.epoch() == epoch => Some(tc),
                _ => None,
            },
```
