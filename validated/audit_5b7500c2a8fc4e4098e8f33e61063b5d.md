# Audit Report

## Title
Lack of Durable Persistence in Safety Data Storage Enables Consensus Equivocation After Crash

## Summary
The OnDiskStorage implementation used for consensus safety data persistence lacks fsync/sync_all calls, allowing OS write caches to contain uncommitted safety data. After a crash, validators can equivocate by signing conflicting votes for the same round, violating AptosBFT consensus safety guarantees.

## Finding Description

The vulnerability exists in the consensus safety data persistence flow. When a validator signs a vote, the SafetyRules module immediately persists the updated safety data to prevent equivocation. However, the OnDiskStorage backend implementation has a critical durability flaw.

**The Vulnerable Flow:**

1. Validator constructs and signs a vote, which updates `safety_data.last_vote` [1](#0-0) 

2. The updated SafetyData is persisted via `set_safety_data()` [2](#0-1) 

3. This eventually calls `OnDiskStorage::write()` which creates a temp file, writes the data, and atomically renames it [3](#0-2) 

4. **Critical flaw**: No `fsync()` or `sync_all()` is called before returning, allowing the OS to report success while data remains in write cache

5. The safety rules check prevents re-voting by returning the previous vote if `last_vote` exists for a round [4](#0-3) 

**Exploitation After Crash:**

If power loss or OS crash occurs after step 3 but before the write cache flushes, on restart:
- The validator loads old safety data (missing the vote for round R)
- Receives a different proposal for round R with block B2
- The check at lines 70-74 passes (no `last_vote` for round R)
- Signs and broadcasts a second, conflicting vote for round R
- **This is equivocation**, violating consensus safety

**Why OnDiskStorage Is Exploitable:**

Despite documentation warning that OnDiskStorage "should not be used in production" [5](#0-4)  and README.md explicitly stating "on-disk should not be used in production environments as it provides no security guarantees" [6](#0-5) , the config sanitizer only blocks InMemoryStorage on mainnet, NOT OnDiskStorage [7](#0-6) 

Furthermore, official production deployment configurations explicitly use `on_disk_storage` backend [8](#0-7) [9](#0-8) 

The PersistentSafetyStorage documentation explicitly states: "Any set function is expected to sync to the remote system before returning" [10](#0-9) , but OnDiskStorage violates this contract.

## Impact Explanation

This is a **Critical** severity vulnerability meeting the Aptos bug bounty's highest category (Consensus/Safety Violations):

- **Consensus Safety Violation**: Enables equivocation with < 1/3 Byzantine validators (in fact, 0 Byzantine validators required), violating AptosBFT's core safety guarantee that the SafetyData structure is designed to enforce [11](#0-10) 

- **Chain Splits**: Multiple conflicting votes can lead to network partition requiring hardfork resolution

- **Double-Spending Risk**: Safety violations enable double-spending attacks

- **No Byzantine Threshold Required**: A single validator crash (accidental or induced) is sufficient to trigger equivocation

This directly violates the consensus safety properties that AptosBFT is designed to guarantee, making it a fundamental protocol-level vulnerability.

## Likelihood Explanation

**High Likelihood:**

1. **Trigger Mechanism**: Any power loss, OS crash, or hardware failure at validators using OnDiskStorage

2. **No Privileged Access**: Requires no special permissions or validator compromise - natural system crashes are sufficient

3. **Configuration Gap**: The config sanitizer explicitly allows OnDiskStorage on mainnet while only blocking InMemoryStorage, despite both being documented as test-only implementations [12](#0-11) 

4. **Real Deployments**: Official repository deployment configuration files use `on_disk_storage` backend, suggesting validators may be running with this vulnerable configuration

5. **Natural Occurrence**: Power outages and system crashes are common operational realities in production environments

The three-way contradiction between documentation (warns against production use), code enforcement (config sanitizer allows it), and deployment configs (actively use it) creates real risk.

## Recommendation

**Immediate Fix Options:**

1. **Add fsync to OnDiskStorage**: Modify `OnDiskStorage::write()` to call `file.sync_all()?` after `file.write_all(&contents)?` and before the `fs::rename()` to ensure durable persistence.

2. **Block OnDiskStorage in Config Sanitizer**: Extend the config sanitizer check to also reject OnDiskStorage on mainnet validators, similar to how InMemoryStorage is blocked.

3. **Update Deployment Configs**: Change official deployment configurations to use VaultStorage (the recommended production backend [13](#0-12) ) instead of OnDiskStorage.

**Recommended Implementation (Option 1 - Add fsync):**

In `secure/storage/src/on_disk.rs`, modify the `write()` method to:
```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    let mut file = File::create(self.temp_path.path())?;
    file.write_all(&contents)?;
    file.sync_all()?;  // Add this line to ensure durability
    fs::rename(&self.temp_path, &self.file_path)?;
    Ok(())
}
```

## Proof of Concept

A complete PoC would require:
1. Configuring a validator with OnDiskStorage backend
2. Having the validator sign a vote for round R
3. Triggering a system crash (e.g., SIGKILL) after the write() call but before OS flushes cache
4. Restarting the validator
5. Observing that the validator can sign a conflicting vote for round R

The vulnerability is demonstrated by the fact that the write path lacks durability guarantees required by the documented interface contract, combined with the config sanitizer allowing this vulnerable configuration on mainnet and official deployment configs actively using it.

## Notes

This vulnerability exists due to a three-way mismatch:
- **Documentation** clearly states OnDiskStorage should not be used in production
- **Config sanitizer** explicitly allows OnDiskStorage on mainnet (only blocks InMemoryStorage)
- **Deployment configs** in the repository actively use on_disk_storage

This creates real risk because validators following official deployment examples would be vulnerable to equivocation after crash. The issue could be resolved by either (1) making OnDiskStorage production-safe with fsync, (2) blocking it in the config sanitizer like InMemoryStorage, or (3) updating all deployment configs to use VaultStorage.

### Citations

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L70-74)
```rust
        if let Some(vote) = safety_data.last_vote.clone() {
            if vote.vote_data().proposed().round() == proposed_block.round() {
                return Ok(vote);
            }
        }
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L89-91)
```rust
        let vote = Vote::new_with_signature(vote_data, author, ledger_info, signature);

        safety_data.last_vote = Some(vote.clone());
```

**File:** consensus/safety-rules/src/safety_rules_2chain.rs (L92-92)
```rust
        self.persistent_storage.set_safety_data(safety_data)?;
```

**File:** secure/storage/src/on_disk.rs (L16-22)
```rust
/// OnDiskStorage represents a key value store that is persisted to the local filesystem and is
/// intended for single threads (or must be wrapped by a Arc<RwLock<>>). This provides no permission
/// checks and simply offers a proof of concept to unblock building of applications without more
/// complex data stores. Internally, it reads and writes all data to a file, which means that it
/// must make copies of all key material which violates the code base. It violates it because
/// the anticipation is that data stores would securely handle key material. This should not be used
/// in production.
```

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** secure/storage/README.md (L31-33)
```markdown
- `Vault`: The Vault secure storage implementation uses the Vault Storage Engine (an engine
offered by HashiCorp: https://www.vaultproject.io/). The Vault secure storage implementation
is the one primarily used in production environments by nodes in the blockchain.
```

**File:** secure/storage/README.md (L37-42)
```markdown
- `OnDisk`: Similar to InMemory, the OnDisk secure storage implementation provides another
useful testing implementation: an on-disk storage engine, where the storage backend is
implemented using a single file written to local disk. In a similar fashion to the in-memory
storage, on-disk should not be used in production environments as it provides no security
guarantees (e.g., encryption before writing to disk). Moreover, OnDisk storage does not
currently support concurrent data accesses.
```

**File:** config/src/config/safety_rules_config.rs (L86-96)
```rust
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }
```

**File:** docker/compose/aptos-node/validator.yaml (L11-13)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** terraform/helm/aptos-node/files/configs/validator-base.yaml (L14-16)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L18-18)
```rust
/// Any set function is expected to sync to the remote system before returning.
```

**File:** consensus/consensus-types/src/safety_data.rs (L8-21)
```rust
/// Data structure for safety rules to ensure consensus safety.
#[derive(Debug, Deserialize, Eq, PartialEq, Serialize, Clone, Default)]
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```
