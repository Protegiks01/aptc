# Audit Report

## Title
Dynamic Prefetching Freeze Timer Manipulation Enables Persistent State Sync Performance Degradation

## Summary
A malicious network peer can exploit the dynamic prefetching freeze mechanism in Aptos state sync to force synchronization operations to run at minimum concurrency (3 requests instead of up to 30) indefinitely, while maintaining an excellent peer reputation score (100.0) that prevents exclusion. This is achieved by providing mostly successful responses but timing occasional failures to continuously reset the 30-second freeze timer.

## Finding Description

The vulnerability exists in the interaction between the dynamic prefetching system and peer reputation scoring in the state sync data streaming service.

**Dynamic Prefetching Mechanism:**

The prefetching system adjusts concurrent request limits based on network performance. On success, it increases the limit [1](#0-0) . On timeout/failure, it decreases the limit and activates a freeze timer [2](#0-1) .

**Critical Flaw - Timer Reset:**

Every failure unconditionally resets the freeze timer to the current time [3](#0-2) , regardless of when the previous failure occurred. This allows an attacker to maintain a permanent freeze by causing failures more frequently than the 30-second freeze duration [4](#0-3) .

**Freeze Mechanism:**

During the freeze period, the check prevents any increases to the prefetch limit [5](#0-4) . The freeze is determined by comparing elapsed time since the last timeout [6](#0-5) .

**Peer Reputation Bypass:**

The peer scoring system adds 1.0 per successful response [7](#0-6)  and multiplies by 0.95 per failure [8](#0-7) . With a 25:1 success-to-failure ratio, the peer score converges to the maximum value of 100.0 [9](#0-8) , far above the 25.0 exclusion threshold [10](#0-9) .

**Attack Execution:**

1. Malicious peer provides 25 successful responses
2. Causes 1 timeout/failure 
3. Repeats cycle every ~26 seconds (less than 30-second freeze duration)

**Why This Works:**

- The freeze timer is global to the data stream, not per-peer
- Timeouts from data client errors call `decrease_max_concurrent_requests()` [11](#0-10) , resetting the freeze timer
- Network timeouts are classified as `ErrorType::NotUseful` [12](#0-11) , applying only the 0.95 multiplier
- Each failure decreases the limit by 2 [13](#0-12) , eventually reaching minimum of 3 [14](#0-13) 
- Even with multi-fetch enabled selecting multiple peers, one malicious peer's timeout keeps the global freeze active

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty category "Validator node slowdowns" [15](#0-14) . 

**Concrete Impact:**
- State synchronization operates at 10% normal capacity (3 vs 30 maximum concurrent requests)
- New validators attempting to join the network experience 10x slower synchronization
- Existing validators that fall behind (e.g., after downtime) take 10x longer to catch up to the blockchain tip
- Network's ability to onboard new validators is severely degraded

While this does not completely halt operations (minimum concurrency is 3, not 0), it significantly impairs the network's ability to maintain decentralization and operational resilience. The performance degradation is persistent and requires no ongoing effort from the attacker once the pattern is established.

## Likelihood Explanation

**Likelihood: Medium to High**

**Attacker Capabilities Required:**
- Operate network peer nodes (achievable by any party - no special access required)
- Control response timing to selectively timeout requests
- No validator privileges or stake requirements

**Feasibility:**
- Attack pattern is straightforward: 25 successes, 1 timeout, repeat every 26 seconds
- Timing requirements are not strict - any failure frequency less than 30 seconds maintains the freeze
- The default configuration enables dynamic prefetching [16](#0-15) , making the attack universally applicable
- Peer scoring configuration enables ignoring low-score peers by default [17](#0-16) , but the attack maintains maximum scores

**Practical Limitations:**
- Requires malicious peer to be selected by the peer selection algorithm
- If sufficient honest peers exist, they may provide faster responses
- However, the global freeze timer means even one malicious peer among many honest peers can maintain the freeze

## Recommendation

**Fix 1: Track Per-Peer Freeze State**
Instead of a global freeze timer, maintain freeze state per peer. Only block increases for the specific peer that experienced the timeout, not the entire stream.

**Fix 2: Implement Freeze Timer Accumulation**
Instead of resetting the timer on each failure, accumulate freeze penalties. Require a sustained period of success to clear the freeze, preventing rapid cycling between frozen and unfrozen states.

**Fix 3: Adaptive Peer Selection**
When the prefetch limit is at minimum for an extended period, deprioritize peers with recent timeouts in the selection algorithm, even if their overall score remains high.

**Recommended Implementation (Fix 1):**
Modify `DynamicPrefetchingState` to track per-peer freeze state and only block increases when the specific responding peer is frozen. This requires coordination with the data stream to associate responses with specific peers.

## Proof of Concept

The vulnerability can be demonstrated through the following test scenario:

1. Configure a malicious peer that responds successfully 25 times, then times out once
2. Monitor the `max_dynamic_concurrent_requests` value in `DynamicPrefetchingState`
3. Observe that after the initial ramp-up, the value decreases to 3 and remains there
4. Verify the malicious peer's score remains at 100.0 throughout
5. Confirm the freeze timer is continuously reset by checking `last_timeout_instant`

Expected behavior: The prefetch limit should recover after 30 seconds of no timeouts.
Actual behavior: The prefetch limit remains at minimum indefinitely due to continuous freeze timer resets.

**Notes**

This vulnerability demonstrates a design flaw where a global mechanism (freeze timer) can be indefinitely exploited by any single participant (malicious peer), even in the presence of many honest participants. The peer reputation system, while functioning as designed, does not protect against this attack pattern because it focuses on aggregate success rates rather than the timing of failures. The attack is particularly effective because it exploits the defensive mechanism (freeze timer) intended to prevent aggressive prefetching near network saturation points.

### Citations

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L61-77)
```rust
    fn is_prefetching_value_frozen(&self) -> bool {
        match self.last_timeout_instant {
            Some(last_failure_time) => {
                // Get the time since the last failure and max freeze duration
                let time_since_last_failure =
                    self.time_service.now().duration_since(last_failure_time);
                let max_freeze_duration = Duration::from_secs(
                    self.get_dynamic_prefetching_config()
                        .timeout_freeze_duration_secs,
                );

                // Check if the time since the last failure is less than the freeze duration
                time_since_last_failure < max_freeze_duration
            },
            None => false, // No failures have occurred
        }
    }
```

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L109-126)
```rust
    pub fn increase_max_concurrent_requests(&mut self) {
        // If dynamic prefetching is disabled, or the value is currently frozen, do nothing
        if !self.is_dynamic_prefetching_enabled() || self.is_prefetching_value_frozen() {
            return;
        }

        // Otherwise, get and increase the current max
        let dynamic_prefetching_config = self.get_dynamic_prefetching_config();
        let amount_to_increase = dynamic_prefetching_config.prefetching_value_increase;
        let max_dynamic_concurrent_requests = self
            .max_dynamic_concurrent_requests
            .saturating_add(amount_to_increase);

        // Bound the value by the configured maximum
        let max_prefetching_value = dynamic_prefetching_config.max_prefetching_value;
        self.max_dynamic_concurrent_requests =
            min(max_dynamic_concurrent_requests, max_prefetching_value);
    }
```

**File:** state-sync/data-streaming-service/src/dynamic_prefetching.rs (L130-150)
```rust
    pub fn decrease_max_concurrent_requests(&mut self) {
        // If dynamic prefetching is disabled, do nothing
        if !self.is_dynamic_prefetching_enabled() {
            return;
        }

        // Update the last failure time
        self.last_timeout_instant = Some(self.time_service.now());

        // Otherwise, get and decrease the current max
        let dynamic_prefetching_config = self.get_dynamic_prefetching_config();
        let amount_to_decrease = dynamic_prefetching_config.prefetching_value_decrease;
        let max_dynamic_concurrent_requests = self
            .max_dynamic_concurrent_requests
            .saturating_sub(amount_to_decrease);

        // Bound the value by the configured minimum
        let min_prefetching_value = dynamic_prefetching_config.min_prefetching_value;
        self.max_dynamic_concurrent_requests =
            max(max_dynamic_concurrent_requests, min_prefetching_value);
    }
```

**File:** config/src/config/state_sync_config.rs (L315-315)
```rust
            enable_dynamic_prefetching: true,
```

**File:** config/src/config/state_sync_config.rs (L318-318)
```rust
            max_prefetching_value: 30,
```

**File:** config/src/config/state_sync_config.rs (L319-319)
```rust
            min_prefetching_value: 3,
```

**File:** config/src/config/state_sync_config.rs (L321-321)
```rust
            prefetching_value_decrease: 2,
```

**File:** config/src/config/state_sync_config.rs (L322-322)
```rust
            timeout_freeze_duration_secs: 30,
```

**File:** config/src/config/state_sync_config.rs (L466-466)
```rust
            ignore_low_score_peers: true,
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L33-34)
```rust
const MAX_SCORE: f64 = 100.0;
const MIN_SCORE: f64 = 0.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L152-160)
```rust
    fn is_ignored(&self) -> bool {
        // Only ignore peers if the config allows it
        if !self.data_client_config.ignore_low_score_peers {
            return false;
        }

        // Otherwise, ignore peers with a low score
        self.score <= IGNORE_PEER_THRESHOLD
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L163-165)
```rust
    fn update_score_success(&mut self) {
        self.score = f64::min(self.score + SUCCESSFUL_RESPONSE_DELTA, MAX_SCORE);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L168-174)
```rust
    fn update_score_error(&mut self, error: ErrorType) {
        let multiplier = match error {
            ErrorType::NotUseful => NOT_USEFUL_MULTIPLIER,
            ErrorType::Malicious => MALICIOUS_MULTIPLIER,
        };
        self.score = f64::max(self.score * multiplier, MIN_SCORE);
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L531-532)
```rust
                        self.dynamic_prefetching_state
                            .decrease_max_concurrent_requests();
```

**File:** state-sync/aptos-data-client/src/client.rs (L865-865)
```rust
                self.notify_bad_response(id, peer, &request, ErrorType::NotUseful);
```
