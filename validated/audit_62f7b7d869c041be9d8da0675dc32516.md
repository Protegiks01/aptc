# Audit Report

## Title
Resource Exhaustion via Unvalidated Transaction Signatures in Remote Batch Processing

## Summary
The Quorum Store batch coordinator accepts and stores batches from remote validators without validating transaction signatures, allowing Byzantine validators to consume storage quota, network bandwidth, and processing resources on honest nodes with cryptographically invalid transactions that are only rejected during the execution pipeline's prepare phase.

## Finding Description

The vulnerability exists in the Quorum Store's deferred signature validation architecture. When remote batches arrive from validators, they undergo metadata verification but bypass transaction signature validation, consuming resources before eventual rejection.

**Batch Reception Flow:**

Network messages are converted from `UnverifiedEvent` to `VerifiedEvent` through the verification process. [1](#0-0) 

The `BatchMsg::verify()` method validates batch metadata including author validity, peer matching, and batch counts, but explicitly does not verify individual transaction signatures. [2](#0-1) 

Each batch's `verify()` method checks payload hash consistency, transaction counts, byte counts, and gas prices, but again does not validate transaction signatures. [3](#0-2) 

**Resource Consumption Before Validation:**

The `BatchCoordinator::handle_batches_msg()` receives verified batches, performs size limit checks and optional transaction filtering, then immediately sends batches to the batch generator and initiates persistence. [4](#0-3) 

During persistence, batches are stored via `BatchStore::insert_to_cache()`, which consumes per-peer quota through `QuotaManager::update_quota()` before any signature verification occurs. [5](#0-4) 

The `QuotaManager::update_quota()` method decrements memory, database, and batch quotas, failing only when quotas are exhausted—not when signatures are invalid. [6](#0-5) 

**Deferred Signature Verification:**

Transaction signatures are only verified during the pipeline's prepare phase using parallel signature verification. [7](#0-6) 

The signature verification happens through the `From<Transaction>` trait implementation for `SignatureVerifiedTransaction`, which calls `verify_signature()` and marks invalid transactions accordingly. [8](#0-7) 

**Attack Scenario:** A Byzantine validator (within the <1/3 BFT tolerance) crafts batches containing transactions with invalid signatures (random bytes). These batches pass all metadata verification checks, consume storage quota on honest validators, and are only rejected during the prepare phase after resources have been consumed.

## Impact Explanation

**Severity: HIGH** per Aptos Bug Bounty criteria for "Validator node slowdowns."

The vulnerability enables resource exhaustion attacks against validator infrastructure:

1. **Storage Quota Depletion**: Each validator maintains per-peer quotas with configurable limits. [9](#0-8)  A Byzantine validator can fill these quotas with invalid batches, preventing legitimate batches from being stored and disrupting consensus operations.

2. **Network Bandwidth Waste**: Invalid batches consume network resources during gossip across the validator network before eventual rejection.

3. **Consensus Processing Overhead**: Blocks containing invalid batches waste consensus round time during preparation and validation cycles.

4. **Database Write Amplification**: When memory quota is exceeded, batches trigger persistence to the database layer, causing unnecessary write operations for invalid data.

**Scope**: Affects all honest validators receiving batches from Byzantine peers. With N validators, a single Byzantine validator can amplify resource consumption (N-1) times across the network.

## Likelihood Explanation

**Likelihood: HIGH**

**Requirements:**
- Byzantine validator behavior within BFT tolerance (< 1/3 validators)
- No cryptographic cost (invalid signatures are trivial to generate)
- No special network conditions or timing requirements

**Ease of Exploitation:**
- Attack is trivial: generate transactions with random signature bytes
- No complex timing or race conditions required
- Persistent effect: batches remain stored until expiration
- Network amplification: one malicious batch affects multiple honest nodes
- Detection only occurs during prepare phase, after resource consumption

**Within Threat Model**: The Aptos BFT consensus model explicitly assumes up to 1/3 Byzantine validators. This attack operates within that threshold and exploits the deferred validation design pattern in the Quorum Store architecture.

## Recommendation

Implement early signature verification before resource allocation. Options include:

1. **Eager Signature Verification**: Add signature verification in `BatchMsg::verify()` before batches are forwarded to the batch coordinator.

2. **Sample-Based Validation**: Verify a random sample of transaction signatures during batch reception to detect malicious batches early while maintaining performance.

3. **Quota Penalization**: Track signature verification failures and exponentially reduce quotas for peers sending invalid batches.

4. **Separate Invalid Batch Tracking**: Maintain separate counters for signature-invalid batches to prevent them from consuming legitimate batch quotas.

The fix should balance security (early validation) with performance (parallel verification benefits) while preventing resource exhaustion from Byzantine actors.

## Proof of Concept

A Byzantine validator can exploit this by:

1. Creating a batch with transactions containing invalid signatures (random bytes)
2. Broadcasting the batch to honest validators
3. Honest validators accept and store the batch (consuming quota)
4. Batch persists in storage until signature verification in prepare phase
5. Quota consumption prevents legitimate batches from the same peer

The vulnerability is demonstrated by the code flow: network message → `UnverifiedEvent::verify()` (metadata only) → `BatchCoordinator::handle_batches_msg()` → `BatchStore::insert_to_cache()` → `QuotaManager::update_quota()` (resource consumption) → later prepare phase signature verification (rejection after damage done).

## Notes

The deferred signature validation design appears intentional for performance optimization (parallel verification in `SIG_VERIFY_POOL`), but creates a resource exhaustion vulnerability. The issue is not a network DoS attack but rather a protocol-level design flaw that allows Byzantine validators to weaponize the deferred validation pattern against honest nodes within the BFT threat model.

### Citations

**File:** consensus/src/round_manager.rs (L166-183)
```rust
            UnverifiedEvent::BatchMsg(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(Box::new((*b).into()))
            },
            UnverifiedEvent::BatchMsgV2(b) => {
                if !self_message {
                    b.verify(peer_id, max_num_batches, validator)?;
                    counters::VERIFY_MSG
                        .with_label_values(&["batch_v2"])
                        .observe(start_time.elapsed().as_secs_f64());
                }
                VerifiedEvent::BatchMsg(b)
            },
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```

**File:** consensus/src/quorum_store/types.rs (L433-461)
```rust
    pub fn verify(
        &self,
        peer_id: PeerId,
        max_num_batches: usize,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        ensure!(!self.batches.is_empty(), "Empty message");
        ensure!(
            self.batches.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.batches.len(),
            max_num_batches
        );
        let epoch_authors = verifier.address_to_validator_index();
        for batch in self.batches.iter() {
            ensure!(
                epoch_authors.contains_key(&batch.author()),
                "Invalid author {} for batch {} in current epoch",
                batch.author(),
                batch.digest()
            );
            ensure!(
                batch.author() == peer_id,
                "Batch author doesn't match sender"
            );
            batch.verify()?
        }
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L173-245)
```rust
    pub(crate) async fn handle_batches_msg(
        &mut self,
        author: PeerId,
        batches: Vec<Batch<BatchInfoExt>>,
    ) {
        if let Err(e) = self.ensure_max_limits(&batches) {
            error!("Batch from {}: {}", author, e);
            counters::RECEIVED_BATCH_MAX_LIMIT_FAILED.inc();
            return;
        }

        let Some(batch) = batches.first() else {
            error!("Empty batch received from {}", author.short_str().as_str());
            return;
        };

        // Filter the transactions in the batches. If any transaction is rejected,
        // the message will be dropped, and all batches will be rejected.
        if self.transaction_filter_config.is_enabled() {
            let transaction_filter = &self.transaction_filter_config.batch_transaction_filter();
            for batch in batches.iter() {
                for transaction in batch.txns() {
                    if !transaction_filter.allows_transaction(
                        batch.batch_info().batch_id(),
                        batch.author(),
                        batch.digest(),
                        transaction,
                    ) {
                        error!(
                            "Transaction {}, in batch {}, from {}, was rejected by the filter. Dropping {} batches!",
                            transaction.committed_hash(),
                            batch.batch_info().batch_id(),
                            author.short_str().as_str(),
                            batches.len()
                        );
                        counters::RECEIVED_BATCH_REJECTED_BY_FILTER.inc();
                        return;
                    }
                }
            }
        }

        let approx_created_ts_usecs = batch
            .info()
            .expiration()
            .saturating_sub(self.batch_expiry_gap_when_init_usecs);

        if approx_created_ts_usecs > 0 {
            observe_batch(
                approx_created_ts_usecs,
                batch.author(),
                BatchStage::RECEIVED,
            );
        }

        let mut persist_requests = vec![];
        for batch in batches.into_iter() {
            // TODO: maybe don't message batch generator if the persist is unsuccessful?
            if let Err(e) = self
                .sender_to_batch_generator
                .send(BatchGeneratorCommand::RemoteBatch(batch.clone()))
                .await
            {
                warn!("Failed to send batch to batch generator: {}", e);
            }
            persist_requests.push(batch.into());
        }
        counters::RECEIVED_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        if author != self.my_peer_id {
            counters::RECEIVED_REMOTE_BATCH_COUNT.inc_by(persist_requests.len() as u64);
        }
        self.persist_and_send_digests(persist_requests, approx_created_ts_usecs);
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L41-62)
```rust
pub(crate) struct QuotaManager {
    memory_balance: usize,
    db_balance: usize,
    batch_balance: usize,
    // Recording the provided quotas for asserts.
    memory_quota: usize,
    db_quota: usize,
    batch_quota: usize,
}

impl QuotaManager {
    pub(crate) fn new(db_quota: usize, memory_quota: usize, batch_quota: usize) -> Self {
        assert!(db_quota >= memory_quota);
        Self {
            memory_balance: memory_quota,
            db_balance: db_quota,
            batch_balance: batch_quota,
            memory_quota,
            db_quota,
            batch_quota,
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L64-84)
```rust
    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L650-681)
```rust
    async fn prepare(
        decryption_fut: TaskFuture<DecryptionResult>,
        preparer: Arc<BlockPreparer>,
        block: Arc<Block>,
    ) -> TaskResult<PrepareResult> {
        let mut tracker = Tracker::start_waiting("prepare", &block);
        let (input_txns, max_txns_from_block_to_execute, block_gas_limit) = decryption_fut.await?;

        tracker.start_working();

        let (input_txns, block_gas_limit) = preparer
            .prepare_block(
                &block,
                input_txns,
                max_txns_from_block_to_execute,
                block_gas_limit,
            )
            .await;

        let sig_verification_start = Instant::now();
        let sig_verified_txns: Vec<SignatureVerifiedTransaction> = SIG_VERIFY_POOL.install(|| {
            let num_txns = input_txns.len();
            input_txns
                .into_par_iter()
                .with_min_len(optimal_min_len(num_txns, 32))
                .map(|t| Transaction::UserTransaction(t).into())
                .collect::<Vec<_>>()
        });
        counters::PREPARE_BLOCK_SIG_VERIFICATION_TIME
            .observe_duration(sig_verification_start.elapsed());
        Ok((Arc::new(sig_verified_txns), block_gas_limit))
    }
```

**File:** types/src/transaction/signature_verified_transaction.rs (L129-139)
```rust
impl From<Transaction> for SignatureVerifiedTransaction {
    fn from(txn: Transaction) -> Self {
        match txn {
            Transaction::UserTransaction(txn) => match txn.verify_signature() {
                Ok(_) => SignatureVerifiedTransaction::Valid(Transaction::UserTransaction(txn)),
                Err(_) => SignatureVerifiedTransaction::Invalid(Transaction::UserTransaction(txn)),
            },
            _ => SignatureVerifiedTransaction::Valid(txn),
        }
    }
}
```
