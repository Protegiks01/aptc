# Audit Report

## Title
DropHelper Blocking Behavior Causes Validator Timeouts During Consensus Block Pruning

## Summary
The `DropHelper` implementation uses a bounded async drop queue with a capacity of 32 concurrent drops. When blocks are pruned or execution results are replaced during consensus operations, dropping `LedgerUpdateOutput` instances can block synchronously if the queue is full, causing validator timeouts and missed consensus rounds.

## Finding Description

The vulnerability arises from the interaction between the async drop system and consensus execution paths:

**Technical Chain:**

1. `LedgerUpdateOutput` wraps its data in `Arc<DropHelper<Inner>>` [1](#0-0) 

2. When `DropHelper` is dropped, it schedules asynchronous cleanup via `DEFAULT_DROPPER.schedule_drop()` [2](#0-1) 

3. `DEFAULT_DROPPER` has a maximum capacity of 32 concurrent drops [3](#0-2) 

4. When capacity is exceeded, `schedule_drop` calls `inc()` which **blocks synchronously** on a condition variable until capacity becomes available [4](#0-3) 

5. During consensus, `StateComputeResult` (which contains `LedgerUpdateOutput`) is stored in blocks [5](#0-4) 

6. When `PipelinedBlock::set_compute_result()` is called, it **synchronously replaces** the old `StateComputeResult`, triggering immediate drop [6](#0-5) 

7. This happens in the execution pipeline during block processing [7](#0-6) 

**Attack Scenario:**

During state sync catch-up, chain reorganization, or sustained high-throughput periods:
- Consensus rapidly produces and executes blocks
- Each execution replaces the previous `StateComputeResult`, dropping the old one
- Block pruning can remove up to 100 blocks when `max_pruned_blocks_in_mem` is exceeded [8](#0-7) [9](#0-8) 
- If 33+ `LedgerUpdateOutput` instances need dropping before the 8 async dropper threads process them, the 33rd drop blocks
- This blocking occurs on the consensus execution thread, causing validators to miss round deadlines
- Multiple validators experiencing this simultaneously degrades consensus liveness

The `Inner` struct contains `Vec<TransactionInfo>` and `Vec<HashValue>` which can be large for blocks with many transactions (up to 5000), making individual drops slower and increasing queue saturation probability [10](#0-9) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty criteria: "Validator node slowdowns". 

The blocking behavior occurs on the consensus execution pipeline, which is critical for validator performance. When the drop queue saturates (33+ pending drops), subsequent drops block synchronously on the calling thread. Since `set_compute_result` is called during block execution and pruning operations happen during normal consensus flow, this blocking directly impacts:

- **Validator Performance**: Blocked threads cannot process subsequent consensus messages or execute blocks
- **Round Timeouts**: With default `round_initial_timeout_ms` of 1000ms, sustained blocking can cause validators to miss round deadlines
- **Consensus Liveness**: Multiple validators experiencing simultaneous blocking reduces network throughput and can degrade consensus progress

While this doesn't cause consensus safety violations or fund loss, it directly impacts the validator's ability to participate in consensus, which is a recognized High Severity impact category in the bug bounty program.

## Likelihood Explanation

**Likelihood: Medium-to-High**

This issue occurs naturally during normal blockchain operations:

1. **State Sync**: Validators catching up process many blocks rapidly, each triggering execution result drops
2. **Chain Reorganizations**: Alternative chains are pruned after finality, dropping multiple block execution results
3. **High Throughput Periods**: Fast block production with large transaction batches creates sustained drop pressure
4. **Memory Pressure**: Automatic garbage collection when `max_pruned_blocks_in_mem` (default 100) is exceeded triggers batch block removal

The configuration makes this feasible:
- Only 32 concurrent drop slots available
- 8 worker threads to process drops
- Blocks can contain up to 5000 transactions, making `Inner` drops potentially slow
- Default pruning threshold of 100 blocks means large batch removals are possible

The developers explicitly documented this blocking behavior as a known tradeoff, but may not have considered the impact on consensus-critical paths [11](#0-10) 

## Recommendation

**Immediate Mitigation:**
1. Increase `DEFAULT_DROPPER` capacity from 32 to 128 or higher to reduce blocking probability
2. Increase drop worker thread count from 8 to 16 to process drops faster
3. Add monitoring/alerting for drop queue saturation

**Long-term Fix:**
1. Avoid dropping large objects synchronously on consensus-critical paths
2. Consider using non-blocking drop scheduling with fallback to sync drop only when absolutely necessary
3. Implement backpressure mechanisms to slow block execution when drop queue is saturated
4. Profile actual drop durations for large `LedgerUpdateOutput` objects and optimize if needed

## Proof of Concept

The blocking behavior is inherent in the design and can be reproduced by:

1. Configuring a validator to process blocks with large transaction counts (approaching 5000 per block)
2. Triggering state sync or sustained high-throughput block production
3. Monitoring the `enqueue_drop` timer metric to observe blocking duration when queue saturates
4. Observing validator round timeout increases during these periods

The existing test demonstrates the blocking behavior [12](#0-11)  - with capacity 8, the 9th drop blocks until the first completes. Scaling this to 32 capacity with consensus execution rates validates the vulnerability.

## Notes

This is a **design-level vulnerability** where a performance optimization (async dropping) introduces blocking on consensus-critical paths. The developers documented the blocking behavior but the interaction with consensus execution timings creates a validator performance degradation vector. While individual occurrences may be brief, sustained saturation during critical operations (state sync, reorg, high load) can meaningfully impact validator participation and consensus liveness.

### Citations

**File:** execution/executor-types/src/ledger_update_output.rs (L17-21)
```rust
#[derive(Clone, Debug, Default, Deref)]
pub struct LedgerUpdateOutput {
    #[deref]
    inner: Arc<DropHelper<Inner>>,
}
```

**File:** execution/executor-types/src/ledger_update_output.rs (L70-75)
```rust
pub struct Inner {
    pub transaction_infos: Vec<TransactionInfo>,
    pub transaction_info_hashes: Vec<HashValue>,
    pub transaction_accumulator: Arc<InMemoryTransactionAccumulator>,
    pub parent_accumulator: Arc<InMemoryTransactionAccumulator>,
}
```

**File:** crates/aptos-drop-helper/src/lib.rs (L19-20)
```rust
pub static DEFAULT_DROPPER: Lazy<AsyncConcurrentDropper> =
    Lazy::new(|| AsyncConcurrentDropper::new("default", 32, 8));
```

**File:** crates/aptos-drop-helper/src/lib.rs (L51-55)
```rust
impl<T: Send + 'static> Drop for DropHelper<T> {
    fn drop(&mut self) {
        DEFAULT_DROPPER.schedule_drop(self.inner.take());
    }
}
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L18-21)
```rust
/// Be aware that there is a bounded number of concurrent drops, as a result:
///   1. when it's "out of capacity", `schedule_drop` will block until a slot to be available.
///   2. if the `Drop` implementation tries to lock things, there can be a potential deadlock due
///      to another thing being waiting for a slot to be available.
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L112-119)
```rust
    fn inc(&self) {
        let mut num_tasks = self.lock.lock();
        while *num_tasks >= self.max_tasks {
            num_tasks = self.cvar.wait(num_tasks).expect("lock poisoned.");
        }
        *num_tasks += 1;
        GAUGE.set_with(&[self.name, "num_tasks"], *num_tasks as i64);
    }
```

**File:** crates/aptos-drop-helper/src/async_concurrent_dropper.rs (L173-186)
```rust
    #[test]
    fn test_concurrency_limit_hit() {
        let s = AsyncConcurrentDropper::new("test", 8, 4);
        let now = std::time::Instant::now();
        for _ in 0..8 {
            s.schedule_drop(SlowDropper);
        }
        assert!(now.elapsed() < Duration::from_millis(200));
        s.schedule_drop(SlowDropper);
        assert!(now.elapsed() > Duration::from_millis(200));
        assert!(now.elapsed() < Duration::from_millis(400));
        s.schedule_drop(SlowDropper);
        assert!(now.elapsed() < Duration::from_millis(400));
    }
```

**File:** execution/executor-types/src/state_compute_result.rs (L30-34)
```rust
pub struct StateComputeResult {
    pub execution_output: ExecutionOutput,
    pub state_checkpoint_output: StateCheckpointOutput,
    pub ledger_update_output: LedgerUpdateOutput,
}
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L307-307)
```rust
        *self.state_compute_result.lock() = state_compute_result;
```

**File:** consensus/src/pipeline/execution_schedule_phase.rs (L70-74)
```rust
        let fut = async move {
            for b in ordered_blocks.iter_mut() {
                let (compute_result, execution_time) = b.wait_for_compute_result().await?;
                b.set_compute_result(compute_result, execution_time);
            }
```

**File:** consensus/src/block_storage/block_tree.rs (L496-510)
```rust
    pub(super) fn process_pruned_blocks(&mut self, mut newly_pruned_blocks: VecDeque<HashValue>) {
        counters::NUM_BLOCKS_IN_TREE.sub(newly_pruned_blocks.len() as i64);
        // The newly pruned blocks are pushed back to the deque pruned_block_ids.
        // In case the overall number of the elements is greater than the predefined threshold,
        // the oldest elements (in the front of the deque) are removed from the tree.
        self.pruned_block_ids.append(&mut newly_pruned_blocks);
        if self.pruned_block_ids.len() > self.max_pruned_blocks_in_mem {
            let num_blocks_to_remove = self.pruned_block_ids.len() - self.max_pruned_blocks_in_mem;
            for _ in 0..num_blocks_to_remove {
                if let Some(id) = self.pruned_block_ids.pop_front() {
                    self.remove_block(id);
                }
            }
        }
    }
```

**File:** config/src/config/consensus_config.rs (L232-232)
```rust
            max_pruned_blocks_in_mem: 100,
```
