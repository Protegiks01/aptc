# Audit Report

## Title
Memory Exhaustion Vulnerability in aptos_channel Due to Unbounded Message Sizes Leading to Validator OOM Crashes

## Summary
The consensus message handling pipeline queues messages in `aptos_channel` before size validation, allowing malicious validators to exhaust memory on honest validators by sending oversized consensus messages up to the network limit, potentially causing OOM crashes and consensus liveness failures.

## Finding Description

The vulnerability exists in the consensus message handling pipeline where size validation occurs **after** messages are queued rather than before.

**Root Cause:** The `aptos_channel` generic type has no trait bounds constraining message sizes, where the `SharedState` struct accepts any type `M` without size constraints [1](#0-0) , and messages are stored directly in a `VecDeque` within a `HashMap` [2](#0-1) .

**Attack Flow:**

1. The network layer allows messages up to 64MB [3](#0-2) , with the actual application-usable size being approximately 61.87 MB after accounting for overhead [4](#0-3) .

2. When consensus messages arrive from the network, they are immediately pushed to the `aptos_channel` queue without any size validation. The `push_msg` function directly calls `tx.push()` without performing size checks [5](#0-4) , and consensus messages including `ProposalMsg` are routed to the consensus channel [6](#0-5) .

3. Messages are queued per `(AccountAddress, Discriminant<ConsensusMsg>)` key with max capacities of 10 for consensus messages [7](#0-6)  and 50 for quorum store messages [8](#0-7) .

4. Size validation only occurs later when processing the proposal in `RoundManager::process_proposal()`, after the message has been dequeued from the channel [9](#0-8) .

5. The consensus config sets `max_receiving_block_bytes` to 6MB [10](#0-9) .

**Exploitation Scenario:**

A malicious validator can craft `ProposalMsg` containing blocks with transaction payloads exceeding the 6MB consensus limit (up to the network's ~62MB limit). These messages pass network-layer deserialization using the `CompressedBcs` encoding with `RECURSION_LIMIT` [11](#0-10)  and are queued in memory before consensus validation rejects them.

The `PerKeyQueue::push` method will queue messages up to the capacity limit per key [12](#0-11) , with messages being dropped only when the per-key queue is full.

**Memory Calculation:**
- Single malicious validator, consensus messages: 10 messages × ~62MB = ~620MB per message type
- Single malicious validator, quorum store messages: 50 messages × ~62MB = ~3.1GB per message type  
- Multiple malicious validators (10): 10 × 3.1GB = 31GB just for quorum store messages
- With multiple message types (ProposalMsg, OptProposalMsg, etc.), memory consumption multiplies accordingly

This breaks the **Resource Limits** security invariant that all operations must respect memory constraints.

## Impact Explanation

This is a **High Severity** vulnerability per Aptos bug bounty criteria category 8: "Validator Node Slowdowns (High) - DoS through resource exhaustion":

- **Validator node slowdowns**: Memory pressure causes significant performance degradation affecting consensus
- **Potential validator crashes**: OOM conditions can crash validator processes  
- **Consensus liveness impact**: If multiple validators crash or slow down simultaneously, consensus may stall

The impact qualifies as High rather than Critical because:
- It requires compromised validators within the Byzantine threat model (<1/3 malicious validators)
- It doesn't directly cause fund loss or permanent state corruption
- Recovery is possible by restarting affected validators
- It affects availability rather than safety properties

However, in a large validator set with multiple compromised validators coordinating an attack, the impact could be severe enough to temporarily halt network progress.

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is likely because:
- AptosBFT is designed to tolerate up to 1/3 Byzantine validators, so malicious validators are explicitly within the threat model
- No special privileges beyond being a validator are required
- The attack is straightforward: craft and send oversized consensus messages
- Detection may be delayed since messages appear structurally valid until processing
- No cryptographic or complex technical barriers exist

Mitigating factors:
- Requires control of one or more validator nodes (higher barrier than arbitrary network peer)
- Network bandwidth limitations may slow the attack rate
- Monitoring systems might detect unusual memory consumption patterns

## Recommendation

Implement size validation **before** queuing messages in the consensus network layer:

1. Add a size check in the `push_msg` function or before it to validate message sizes against `max_receiving_block_bytes` before pushing to the channel
2. Reject oversized messages immediately at the network layer with appropriate logging
3. Consider adding trait bounds to `aptos_channel` to enforce maximum message sizes at compile time
4. Implement rate limiting per validator to prevent rapid queue filling

The fix should validate the serialized message size against the consensus limit before calling `tx.push()` in the network message handling pipeline.

## Proof of Concept

A malicious validator can trigger this vulnerability by:

1. Crafting a `ProposalMsg` with a `Block` containing transactions totaling 30MB (between the 6MB consensus limit and ~62MB network limit)
2. Sending this message repeatedly to fill up the channel queue (10 messages for consensus channel)
3. The victim validator will queue all 10 messages (10 × 30MB = 300MB) before any size validation occurs
4. With multiple message types and multiple malicious validators, memory consumption scales to multiple gigabytes
5. The victim validator experiences memory pressure, potentially leading to OOM crashes

The vulnerability can be reproduced by instrumenting a test validator to send oversized `ProposalMsg` and monitoring memory consumption on receiving validators.

## Notes

The actual memory impact is more severe than initially calculated in the report, as the network layer accepts messages up to approximately 62MB (after overhead), not just 6MB. The vulnerability is within scope as it exploits consensus-layer message handling logic, not the network layer itself, and requires malicious validator behavior within the Byzantine threat model.

### Citations

**File:** crates/channel/src/aptos_channel.rs (L29-29)
```rust
struct SharedState<K: Eq + Hash + Clone, M> {
```

**File:** crates/channel/src/message_queues.rs (L51-51)
```rust
    per_key_queue: HashMap<K, VecDeque<T>>,
```

**File:** crates/channel/src/message_queues.rs (L112-152)
```rust
    pub(crate) fn push(&mut self, key: K, message: T) -> Option<T> {
        if let Some(c) = self.counters.as_ref() {
            c.with_label_values(&["enqueued"]).inc();
        }

        let key_message_queue = self
            .per_key_queue
            .entry(key.clone())
            // Only allocate a small initial queue for a new key. Previously, we
            // allocated a queue with all `max_queue_size_per_key` entries;
            // however, this breaks down when we have lots of transient peers.
            // For example, many of our queues have a max capacity of 1024. To
            // handle a single rpc from a transient peer, we would end up
            // allocating ~ 96 b * 1024 ~ 64 Kib per queue.
            .or_insert_with(|| VecDeque::with_capacity(1));

        // Add the key to our round-robin queue if it's not already there
        if key_message_queue.is_empty() {
            self.round_robin_queue.push_back(key);
        }

        // Push the message to the actual key message queue
        if key_message_queue.len() >= self.max_queue_size.get() {
            if let Some(c) = self.counters.as_ref() {
                c.with_label_values(&["dropped"]).inc();
            }
            match self.queue_style {
                // Drop the newest message for FIFO
                QueueStyle::FIFO => Some(message),
                // Drop the oldest message for LIFO
                QueueStyle::LIFO | QueueStyle::KLAST => {
                    let oldest = key_message_queue.pop_front();
                    key_message_queue.push_back(message);
                    oldest
                },
            }
        } else {
            key_message_queue.push_back(message);
            None
        }
    }
```

**File:** config/src/config/network_config.rs (L45-48)
```rust
pub const MAX_MESSAGE_METADATA_SIZE: usize = 128 * 1024; /* 128 KiB: a buffer for metadata that might be added to messages by networking */
pub const MESSAGE_PADDING_SIZE: usize = 2 * 1024 * 1024; /* 2 MiB: a safety buffer to allow messages to get larger during serialization */
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
```

**File:** config/src/config/network_config.rs (L50-50)
```rust
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** consensus/src/network.rs (L757-761)
```rust
        let (consensus_messages_tx, consensus_messages) = aptos_channel::new(
            QueueStyle::FIFO,
            10,
            Some(&counters::CONSENSUS_CHANNEL_MSGS),
        );
```

**File:** consensus/src/network.rs (L762-767)
```rust
        let (quorum_store_messages_tx, quorum_store_messages) = aptos_channel::new(
            QueueStyle::FIFO,
            // TODO: tune this value based on quorum store messages with backpressure
            50,
            Some(&counters::QUORUM_STORE_CHANNEL_MSGS),
        );
```

**File:** consensus/src/network.rs (L799-813)
```rust
    fn push_msg(
        peer_id: AccountAddress,
        msg: ConsensusMsg,
        tx: &aptos_channel::Sender<
            (AccountAddress, Discriminant<ConsensusMsg>),
            (AccountAddress, ConsensusMsg),
        >,
    ) {
        if let Err(e) = tx.push((peer_id, discriminant(&msg)), (peer_id, msg)) {
            warn!(
                remote_peer = peer_id,
                error = ?e, "Error pushing consensus msg",
            );
        }
    }
```

**File:** consensus/src/network.rs (L863-900)
```rust
                        consensus_msg @ (ConsensusMsg::ProposalMsg(_)
                        | ConsensusMsg::OptProposalMsg(_)
                        | ConsensusMsg::VoteMsg(_)
                        | ConsensusMsg::RoundTimeoutMsg(_)
                        | ConsensusMsg::OrderVoteMsg(_)
                        | ConsensusMsg::SyncInfo(_)
                        | ConsensusMsg::EpochRetrievalRequest(_)
                        | ConsensusMsg::EpochChangeProof(_)) => {
                            if let ConsensusMsg::ProposalMsg(proposal) = &consensus_msg {
                                observe_block(
                                    proposal.proposal().timestamp_usecs(),
                                    BlockStage::NETWORK_RECEIVED,
                                );
                                info!(
                                    LogSchema::new(LogEvent::NetworkReceiveProposal)
                                        .remote_peer(peer_id),
                                    block_round = proposal.proposal().round(),
                                    block_hash = proposal.proposal().id(),
                                );
                            }
                            if let ConsensusMsg::OptProposalMsg(proposal) = &consensus_msg {
                                observe_block(
                                    proposal.timestamp_usecs(),
                                    BlockStage::NETWORK_RECEIVED,
                                );
                                observe_block(
                                    proposal.timestamp_usecs(),
                                    BlockStage::NETWORK_RECEIVED_OPT_PROPOSAL,
                                );
                                info!(
                                    LogSchema::new(LogEvent::NetworkReceiveOptProposal)
                                        .remote_peer(peer_id),
                                    block_author = proposal.proposer(),
                                    block_epoch = proposal.epoch(),
                                    block_round = proposal.round(),
                                );
                            }
                            Self::push_msg(peer_id, consensus_msg, &self.consensus_messages_tx);
```

**File:** consensus/src/round_manager.rs (L1187-1193)
```rust
        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );
```

**File:** config/src/config/consensus_config.rs (L231-231)
```rust
            max_receiving_block_bytes: 6 * 1024 * 1024, // 6MB
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L159-161)
```rust
            ProtocolId::ConsensusDirectSendCompressed | ProtocolId::ConsensusRpcCompressed => {
                Encoding::CompressedBcs(RECURSION_LIMIT)
            },
```
