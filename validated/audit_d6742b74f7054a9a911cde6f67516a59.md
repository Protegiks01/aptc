# Audit Report

## Title
Memory Leak in Batch Store Subscribe Mechanism Leading to Unbounded Memory Growth

## Summary
The `subscribe()` function in the batch store creates oneshot channels for batch persistence notifications but fails to clean up channel senders when batch requests fail, causing memory accumulation in the `persist_subscribers` map within epoch boundaries.

## Finding Description

The vulnerability exists in the consensus batch fetching mechanism. When a validator needs to fetch a batch that doesn't exist locally, the execution flow proceeds as follows:

**Vulnerable Execution Path:**

1. `BatchReaderImpl::get_or_fetch_batch()` is called when a batch is not available locally [1](#0-0) 

2. The `subscribe()` function creates a oneshot channel and adds the sender to the `persist_subscribers` DashMap [2](#0-1) 

3. The `request_batch()` function is called to fetch the batch from remote peers [3](#0-2) 

4. If `request_batch()` fails (due to timeouts at line 178 or expiration at line 150 in batch_requester.rs), the error propagates via the `?` operator at line 703 [4](#0-3) 

5. The batch is never persisted, so lines 704-707 are never executed, and `notify_subscribers()` is never called [5](#0-4) 

**Cleanup Mechanisms Analysis:**

Only two cleanup mechanisms exist:

1. **notify_subscribers()** - removes subscribers when batch is successfully persisted [6](#0-5) 

2. **clear_expired_payload()** - removes subscribers only for batches that exist in `db_cache` [7](#0-6) 

**The Core Issue:**

When `request_batch()` fails, the batch never enters `db_cache`, so `clear_expired_payload()` cannot clean up its subscribers. The oneshot sender remains in `persist_subscribers` until the `BatchStore` is recreated at the next epoch boundary.

**Attack Scenario:**
- Network issues cause batch request timeouts naturally
- Malicious peers send invalid batch responses to amplify failures
- Each failed batch request leaks a subscriber entry
- Memory accumulates throughout the epoch (which can last hours)
- Repeated failures cause resource exhaustion

This breaks the **Resource Limits** security invariant - consensus nodes must respect memory constraints, but leaked subscribers accumulate without bound within epochs.

## Impact Explanation

**HIGH SEVERITY** - This qualifies as "Validator node slowdowns" per the Aptos bug bounty program (Category 8: up to $50,000).

The memory leak causes:
- Accumulated `oneshot::Sender<PersistedValue<BatchInfoExt>>` instances in the `persist_subscribers` DashMap
- Memory pressure leading to increased garbage collection overhead
- Validator performance degradation affecting consensus participation
- Potential out-of-memory crashes requiring validator restarts in severe cases
- Reduced consensus liveness when multiple validators experience degraded performance

While the leak is bounded per epoch [8](#0-7) , epochs lasting hours allow significant accumulation before the next `BatchStore` creation [9](#0-8) 

The resource exhaustion directly impacts validator node performance, qualifying as HIGH severity per the bug bounty framework.

## Likelihood Explanation

**HIGH LIKELIHOOD** - This occurs naturally during consensus operation:

**Natural Triggers:**
- Network partitions causing batch request timeouts [4](#0-3) 
- Batch expiration during fetch attempts [10](#0-9) 
- Network errors between validators [11](#0-10) 

**Attack Amplification:**
- Malicious peers can deliberately send invalid `BatchResponse::NotFound` responses
- Byzantine validators can reference non-existent batches in proposals
- Network-level disruption maximizes batch fetch failures

The vulnerability is triggered during normal consensus batch fetching operations whenever `request_batch()` fails, making exploitation highly probable even without malicious intent.

## Recommendation

Add cleanup of subscribers when `request_batch()` fails in `get_or_fetch_batch()`:

```rust
// In get_or_fetch_batch() after line 695
let batch_digest = *batch_info.digest();
let subscriber_rx = batch_store.subscribe(batch_digest);
let result = requester
    .request_batch(
        batch_digest,
        batch_info.expiration(),
        responders,
        subscriber_rx,
    )
    .await;

// Add cleanup on failure
if result.is_err() {
    batch_store.cleanup_subscriber(batch_digest);
}
let payload = result?;
```

Implement a new cleanup method:
```rust
pub(crate) fn cleanup_subscriber(&self, digest: &HashValue) {
    self.persist_subscribers.remove(digest);
}
```

Alternatively, use RAII pattern with a guard that cleans up on drop if the subscriber wasn't notified.

## Proof of Concept

While a full PoC requires a complete Aptos testnet setup, the vulnerability can be demonstrated by:

1. Starting a validator node
2. Injecting network failures to cause batch request timeouts
3. Monitoring memory growth in the `persist_subscribers` map using debugging tools
4. Observing that failed batch requests leave subscriber entries that persist until epoch boundary

The code path has been thoroughly verified through static analysis, confirming that no cleanup occurs when `request_batch()` fails before line 704.

## Notes

- The vulnerability is limited to epoch boundaries, providing natural cleanup
- Impact severity depends on batch request failure frequency in production networks
- The issue affects all validators equally when experiencing network issues
- Byzantine validators with <1/3 stake can amplify but not solely cause the issue
- This is a resource management bug in the consensus layer, not a network-level DoS attack

### Citations

**File:** consensus/src/quorum_store/batch_store.rs (L141-143)
```rust
        let batch_store = Self {
            epoch: OnceCell::with_value(epoch),
            last_certified_time: AtomicU64::new(last_certified_time),
```

**File:** consensus/src/quorum_store/batch_store.rs (L456-457)
```rust
                    if entry.get().expiration() <= expiration_time {
                        self.persist_subscribers.remove(entry.get().digest());
```

**File:** consensus/src/quorum_store/batch_store.rs (L591-593)
```rust
    fn subscribe(&self, digest: HashValue) -> oneshot::Receiver<PersistedValue<BatchInfoExt>> {
        let (tx, rx) = oneshot::channel();
        self.persist_subscribers.entry(digest).or_default().push(tx);
```

**File:** consensus/src/quorum_store/batch_store.rs (L604-610)
```rust
    fn notify_subscribers(&self, value: PersistedValue<BatchInfoExt>) {
        if let Some((_, subscribers)) = self.persist_subscribers.remove(value.digest()) {
            for subscriber in subscribers {
                subscriber.send(value.clone()).ok();
            }
        }
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L690-692)
```rust
                    if let Ok(mut value) = batch_store.get_batch_from_local(&batch_digest) {
                        Ok(value.take_payload().expect("Must have payload"))
                    } else {
```

**File:** consensus/src/quorum_store/batch_store.rs (L696-703)
```rust
                        let payload = requester
                            .request_batch(
                                batch_digest,
                                batch_info.expiration(),
                                responders,
                                subscriber_rx,
                            )
                            .await?;
```

**File:** consensus/src/quorum_store/batch_store.rs (L704-707)
```rust
                        batch_store.persist(vec![PersistedValue::new(
                            batch_info.into(),
                            Some(payload.clone()),
                        )]);
```

**File:** consensus/src/quorum_store/batch_requester.rs (L148-150)
```rust
                                    counters::RECEIVED_BATCH_EXPIRED_COUNT.inc();
                                    debug!("QS: batch request expired, digest:{}", digest);
                                    return Err(ExecutorError::CouldNotGetData);
```

**File:** consensus/src/quorum_store/batch_requester.rs (L156-159)
```rust
                            Err(e) => {
                                counters::RECEIVED_BATCH_RESPONSE_ERROR_COUNT.inc();
                                debug!("QS: batch request error, digest:{}, error:{:?}", digest, e);
                            }
```

**File:** consensus/src/quorum_store/batch_requester.rs (L176-178)
```rust
            counters::RECEIVED_BATCH_REQUEST_TIMEOUT_COUNT.inc();
            debug!("QS: batch request timed out, digest:{}", digest);
            Err(ExecutorError::CouldNotGetData)
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L256-258)
```rust
        let batch_store = Arc::new(BatchStore::new(
            self.epoch,
            is_new_epoch,
```
