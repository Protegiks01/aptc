# Audit Report

## Title
Hot State Shard Desynchronization Causing Validator Crash via set_commited() Bypass

## Summary
The `Committer::commit()` function panics when processing states after `HotState::set_commited()` is called via `hack_reset()`. The desynchronization between `committed` and `base.shards` causes an assertion failure that crashes validator nodes during restore operations.

## Finding Description

The `Committer` maintains two critical data structures: `base.shards` (DashMap storing hot state entries) and `committed` (Arc<Mutex<State>> tracking committed state). [1](#0-0) 

The vulnerability occurs because `set_commited()` bypasses normal commit flow by only updating the `committed` field without synchronizing `base.shards`. [2](#0-1) 

This function is called via `PersistedState::hack_reset()` with a documented but unenforced precondition. [3](#0-2) 

When `commit()` subsequently processes a new State, it calculates a delta between `to_commit` and `self.committed`. [4](#0-3) 

The delta only contains entries where `StateSlot` changed. Since `StateSlot` includes LRU chain pointers in its `lru_info` field and derives `PartialEq`, only entries with modified pointers appear in the delta. [5](#0-4) 

The delta is created using `view_layers_after` which only shows changes between states. [6](#0-5) 

After updating the shard with delta entries only, `commit()` sets `heads` and `tails` from the full state, then performs a length check. [7](#0-6) 

**Attack Scenario:**
1. System initialized with empty HotState
2. `hack_reset()` called with State S1 containing hot entries A→B→C
   - `committed` = S1, `base.shards` remains empty
3. New commit with State S2: D→A→B→C
   - Delta contains only D (new) and A (prev pointer changed)
   - B and C unchanged (same prev/next pointers), not in delta
4. `commit()` inserts only D and A into shard
5. `assert_eq!(self.base.shards[shard_id].len(), to_commit.num_hot_items(shard_id))` fails
   - Left: 2 (D, A), Right: 4 (D, A, B, C)
   - **PANIC in both debug and release builds**

## Impact Explanation

**Severity: HIGH**

This causes validator node crashes during critical restore operations. The panic occurs at a regular `assert_eq!` (not debug_assert), affecting **both debug and release builds**. [8](#0-7) 

Since the Committer runs in a dedicated thread processing hot state updates, the panic causes validator unavailability. The validator cannot commit new state, disrupting consensus participation.

This meets **HIGH Severity** criteria per Aptos Bug Bounty: "Validator node slowdowns" and "API crashes" - a validator crash during state commit operations is a significant availability issue.

## Likelihood Explanation

**Likelihood: MEDIUM**

The vulnerability is triggered when `StateStore::set_state_ignoring_summary()` is invoked during restore operations. [9](#0-8) 

This function is called during backup/restore operations in `restore_utils.rs` where `calculate_state_and_put_updates()` can return a LedgerState with hot entries. [10](#0-9) 

The function is also used in `BufferedState::new_at_snapshot()` during state initialization. [11](#0-10) 

The precondition "no on the fly commit is in the queue" is documented but not enforced. After `hack_reset()` completes, subsequent commits trigger the desynchronization.

Node operators performing recovery operations or state synchronization can trigger this sequence, causing validator crashes.

## Recommendation

Add validation in `hack_reset()` to ensure no pending commits, or synchronize `base.shards` when calling `set_commited()`:

```rust
pub(crate) fn set_commited(&self, state: State) {
    // Option 1: Fail if committer has pending work
    assert!(self.commit_tx.try_send(state.clone()).is_err(), 
            "Cannot set_commited while commits are pending");
    
    // Option 2: Enqueue commit instead of direct update
    self.enqueue_commit(state);
}
```

Alternatively, enforce the precondition in `hack_reset()` with runtime checks.

## Proof of Concept

The vulnerability can be demonstrated by:
1. Initializing a HotState with empty shards
2. Calling `set_commited()` with a State containing hot entries
3. Enqueuing a new commit that modifies only some LRU pointers
4. Observing the assertion failure at line 264-267

The exact PoC would require simulating the restore flow, but the core issue is evident from the code structure where delta-based updates are applied after `hack_reset()` bypasses shard synchronization.

## Notes

The original report incorrectly identified the panic location as line 288 in `validate_lru()` via debug_assert. The actual panic occurs earlier at line 264-267 in a regular `assert_eq!` that executes in both debug and release builds, making the impact more severe than initially reported.

### Citations

**File:** storage/aptosdb/src/state_store/hot_state.rs (L127-129)
```rust
    pub(crate) fn set_commited(&self, state: State) {
        *self.committed.lock() = state
    }
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L160-170)
```rust
pub struct Committer {
    base: Arc<HotStateBase>,
    committed: Arc<Mutex<State>>,
    rx: Receiver<State>,
    total_key_bytes: usize,
    total_value_bytes: usize,
    /// Points to the newest entry. `None` if empty.
    heads: [Option<StateKey>; NUM_STATE_SHARDS],
    /// Points to the oldest entry. `None` if empty.
    tails: [Option<StateKey>; NUM_STATE_SHARDS],
}
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L235-242)
```rust
    fn commit(&mut self, to_commit: &State) {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["hot_state_commit"]);

        let mut n_insert = 0;
        let mut n_update = 0;
        let mut n_evict = 0;

        let delta = to_commit.make_delta(&self.committed.lock());
```

**File:** storage/aptosdb/src/state_store/hot_state.rs (L262-267)
```rust
            self.heads[shard_id] = to_commit.latest_hot_key(shard_id);
            self.tails[shard_id] = to_commit.oldest_hot_key(shard_id);
            assert_eq!(
                self.base.shards[shard_id].len(),
                to_commit.num_hot_items(shard_id)
            );
```

**File:** storage/aptosdb/src/state_store/persisted_state.rs (L64-69)
```rust
    // n.b. Can only be used when no on the fly commit is in the queue.
    pub fn hack_reset(&self, state_with_summary: StateWithSummary) {
        let (state, summary) = state_with_summary.into_inner();
        *self.summary.lock() = summary;
        self.hot_state.set_commited(state);
    }
```

**File:** types/src/state_store/state_slot.rs (L23-40)
```rust
#[derive(Clone, Debug, Eq, PartialEq)]
pub enum StateSlot {
    ColdVacant,
    HotVacant {
        hot_since_version: Version,
        lru_info: LRUEntry<StateKey>,
    },
    ColdOccupied {
        value_version: Version,
        value: StateValue,
    },
    HotOccupied {
        value_version: Version,
        value: StateValue,
        hot_since_version: Version,
        lru_info: LRUEntry<StateKey>,
    },
}
```

**File:** storage/storage-interface/src/state_store/state_delta.rs (L26-39)
```rust
impl StateDelta {
    pub fn new(base: State, current: State) -> Self {
        assert!(current.is_descendant_of(&base));

        let shards = Arc::new(std::array::from_fn(|shard_id| {
            current.shards()[shard_id].view_layers_after(&base.shards()[shard_id])
        }));

        Self {
            base,
            current,
            shards,
        }
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1208-1239)
```rust
    pub fn set_state_ignoring_summary(&self, ledger_state: LedgerState) {
        let hot_smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let smt = SparseMerkleTree::new(*CORRUPTION_SENTINEL);
        let last_checkpoint_summary = StateSummary::new_at_version(
            ledger_state.last_checkpoint().version(),
            hot_smt.clone(),
            smt.clone(),
            HotStateConfig::default(),
        );
        let summary = StateSummary::new_at_version(
            ledger_state.version(),
            hot_smt,
            smt,
            HotStateConfig::default(),
        );

        let last_checkpoint = StateWithSummary::new(
            ledger_state.last_checkpoint().clone(),
            last_checkpoint_summary.clone(),
        );
        let latest = StateWithSummary::new(ledger_state.latest().clone(), summary);
        let current = LedgerStateWithSummary::from_latest_and_last_checkpoint(
            latest,
            last_checkpoint.clone(),
        );

        self.persisted_state.hack_reset(last_checkpoint.clone());
        *self.current_state_locked() = current;
        self.buffered_state
            .lock()
            .force_last_snapshot(last_checkpoint);
    }
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L269-277)
```rust
    if kv_replay && first_version > 0 && state_store.get_usage(Some(first_version - 1)).is_ok() {
        let (ledger_state, _hot_state_updates) = state_store.calculate_state_and_put_updates(
            &StateUpdateRefs::index_write_sets(first_version, write_sets, write_sets.len(), vec![]),
            &mut ledger_db_batch.ledger_metadata_db_batches, // used for storing the storage usage
            state_kv_batches,
        )?;
        // n.b. ideally this is set after the batches are committed
        state_store.set_state_ignoring_summary(ledger_state);
    }
```

**File:** storage/aptosdb/src/state_store/buffered_state.rs (L55-68)
```rust
    pub(crate) fn new_at_snapshot(
        state_db: &Arc<StateDb>,
        last_snapshot: StateWithSummary,
        target_items: usize,
        out_current_state: Arc<Mutex<LedgerStateWithSummary>>,
        out_persisted_state: PersistedState,
    ) -> Self {
        let (state_commit_sender, state_commit_receiver) =
            mpsc::sync_channel(ASYNC_COMMIT_CHANNEL_BUFFER_SIZE as usize);
        let arc_state_db = Arc::clone(state_db);
        *out_current_state.lock() =
            LedgerStateWithSummary::new_at_checkpoint(last_snapshot.clone());
        out_persisted_state.hack_reset(last_snapshot.clone());

```
