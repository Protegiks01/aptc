# Audit Report

## Title
Silent Message Dropping in DKG Channel Causes Network Liveness Failure During Epoch Transitions

## Summary
The DKG (Distributed Key Generation) system silently drops RPC messages when its channel reaches capacity (100 messages per peer), causing RPC failures that prevent transcript collection. When randomness is enabled, incomplete DKG blocks epoch transitions, potentially halting the blockchain until manual governance intervention via `force_end_epoch()` is executed.

## Finding Description

The DKG EpochManager creates a FIFO channel with 100-message capacity per peer to forward RPC requests to the DKGManager: [1](#0-0) 

When RPC requests arrive, the result of `push()` is explicitly discarded, providing no error notification to the sender: [2](#0-1) 

The underlying FIFO implementation drops the newest message when at capacity: [3](#0-2) 

The `push()` method returns `Ok(())` even when messages are dropped, only returning errors if the receiver is closed: [4](#0-3) 

When messages are dropped, the contained `IncomingRpcRequest` with its `response_sender` is destroyed without sending a response. This causes the RPC caller's oneshot channel to close and triggers timeout errors. The ReliableBroadcast layer retries indefinitely with exponential backoff: [5](#0-4) 

The backoff policy defaults to a maximum delay of 3000ms: [6](#0-5) 

**Critical Liveness Impact**: When randomness is enabled, the `reconfigure()` function calls `try_start()` instead of immediately finishing the epoch transition: [7](#0-6) 

The `try_start()` function checks for incomplete DKG sessions and returns early if one exists for the current epoch, preventing new epoch transitions: [8](#0-7) 

If DKG cannot complete due to channel saturation preventing transcript collection, the incomplete session blocks all future epoch transitions. The blockchain remains stuck until governance manually invokes `force_end_epoch()` to clear the incomplete DKG session: [9](#0-8) [10](#0-9) 

The test suite demonstrates DKG stall scenarios requiring `force_end_epoch()` for recovery: [11](#0-10) 

## Impact Explanation

**CRITICAL Severity** per Aptos bug bounty criteria - **Total Loss of Liveness/Network Availability**:

When randomness is enabled (the default configuration for mainnet), incomplete DKG prevents epoch transitions. If channel saturation prevents DKG transcript collection across sufficient validators (>f validators unable to respond due to saturated channels where f = 1/3 for Byzantine fault tolerance), DKG cannot complete, and the blockchain cannot progress to new epochs. This effectively halts the network until manual governance intervention.

The vulnerability also causes **Validator Node Slowdowns** through retry mechanisms with delays up to 3000ms, degrading performance during critical DKG operations.

Unlike typical DoS attacks (which are out of scope), this is a protocol design flaw where legitimate high-load operations trigger a liveness failure without requiring malicious actors.

## Likelihood Explanation

**Medium-High Likelihood** during normal operations:

1. **Epoch transitions create synchronized load**: All validators simultaneously execute DKG, creating NÂ² message exchanges between validators
2. **100-message capacity may be insufficient**: Large validator sets (100+ validators) can generate hundreds of concurrent RPC requests during DKG transcript exchange
3. **No backpressure mechanism**: Senders have no indication that receivers are overloaded, continuing to send messages that get silently dropped
4. **No monitoring**: The DKG module lacks dropped message metrics. For comparison, consensus channels track dropped messages: [12](#0-11) 

Meanwhile, the DKG channel is created without metrics: [1](#0-0) 

The test suite explicitly includes recovery scenarios for DKG stalls, confirming this is a recognized failure mode.

## Recommendation

1. **Add metrics tracking**: Pass a counter to the DKG channel creation to track enqueued, dequeued, and dropped messages, similar to consensus channels
2. **Increase channel capacity**: Consider dynamic sizing based on validator set size or increase to a higher fixed capacity (e.g., 1000)
3. **Implement backpressure**: Return errors from `push()` when messages are dropped so callers can implement flow control
4. **Add monitoring and alerting**: Create dashboards to detect channel saturation before it causes DKG failures
5. **Consider priority queuing**: Use KLAST instead of FIFO to drop oldest messages rather than newest critical messages

## Proof of Concept

The existing test demonstrates the failure scenario and recovery mechanism: [13](#0-12) 

This test shows that when DKG stalls (line 52-55), the network halts (line 57-62), and requires `force_end_epoch()` (line 121) to recover. While the test uses sync_only mode to simulate the stall, the same outcome occurs when channel saturation prevents DKG transcript collection.

## Notes

The vulnerability represents a design flaw in the DKG channel implementation where:
- Messages are silently dropped without error propagation
- No backpressure mechanism exists to prevent overload
- No metrics exist to detect the problem before it causes network halt
- Recovery requires manual governance intervention via `force_end_epoch()`

This is distinct from network DoS attacks as it's triggered by legitimate protocol operations during epoch transitions, not by malicious external actors.

### Citations

**File:** dkg/src/epoch_manager.rs (L102-102)
```rust
                let _ = tx.push(peer_id, (peer_id, dkg_request));
```

**File:** dkg/src/epoch_manager.rs (L227-230)
```rust
            let (dkg_rpc_msg_tx, dkg_rpc_msg_rx) = aptos_channel::new::<
                AccountAddress,
                (AccountAddress, IncomingRpcRequest),
            >(QueueStyle::FIFO, 100, None);
```

**File:** crates/channel/src/message_queues.rs (L138-140)
```rust
            match self.queue_style {
                // Drop the newest message for FIFO
                QueueStyle::FIFO => Some(message),
```

**File:** crates/channel/src/aptos_channel.rs (L85-112)
```rust
    pub fn push(&self, key: K, message: M) -> Result<()> {
        self.push_with_feedback(key, message, None)
    }

    /// Same as `push`, but this function also accepts a oneshot::Sender over which the sender can
    /// be notified when the message eventually gets delivered or dropped.
    pub fn push_with_feedback(
        &self,
        key: K,
        message: M,
        status_ch: Option<oneshot::Sender<ElementStatus<M>>>,
    ) -> Result<()> {
        let mut shared_state = self.shared_state.lock();
        ensure!(!shared_state.receiver_dropped, "Channel is closed");
        debug_assert!(shared_state.num_senders > 0);

        let dropped = shared_state.internal_queue.push(key, (message, status_ch));
        // If this or an existing message had to be dropped because of the queue being full, we
        // notify the corresponding status channel if it was registered.
        if let Some((dropped_val, Some(dropped_status_ch))) = dropped {
            // Ignore errors.
            let _err = dropped_status_ch.send(ElementStatus::Dropped(dropped_val));
        }
        if let Some(w) = shared_state.waker.take() {
            w.wake();
        }
        Ok(())
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L191-200)
```rust
                            Err(e) => {
                                log_rpc_failure(e, receiver);

                                let backoff_strategy = backoff_policies
                                    .get_mut(&receiver)
                                    .expect("should be present");
                                let duration = backoff_strategy.next().expect("should produce value");
                                rpc_futures
                                    .push(send_message(receiver, Some(duration)));
                            },
```

**File:** config/src/config/dag_consensus_config.rs (L115-118)
```rust
            // A backoff policy that starts at 100ms and doubles each iteration up to 3secs.
            backoff_policy_base_ms: 2,
            backoff_policy_factor: 50,
            backoff_policy_max_delay_ms: 3000,
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L687-688)
```text
        if (consensus_config::validator_txn_enabled() && randomness_config::enabled()) {
            reconfiguration_with_dkg::try_start();
```

**File:** aptos-move/framework/aptos-framework/sources/aptos_governance.move (L700-703)
```text
    public entry fun force_end_epoch(aptos_framework: &signer) {
        system_addresses::assert_aptos_framework(aptos_framework);
        reconfiguration_with_dkg::finish(aptos_framework);
    }
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration_with_dkg.move (L24-30)
```text
    public(friend) fun try_start() {
        let incomplete_dkg_session = dkg::incomplete_session();
        if (option::is_some(&incomplete_dkg_session)) {
            let session = option::borrow(&incomplete_dkg_session);
            if (dkg::session_dealer_epoch(session) == reconfiguration::current_epoch()) {
                return
            }
```

**File:** aptos-move/framework/aptos-framework/sources/reconfiguration_with_dkg.move (L46-48)
```text
    public(friend) fun finish(framework: &signer) {
        system_addresses::assert_aptos_framework(framework);
        dkg::try_clear_incomplete_session(framework);
```

**File:** testsuite/smoke-test/src/randomness/randomness_stall_recovery.rs (L19-165)
```rust
/// Chain recovery using a local config from randomness stall should work.
/// See `randomness_config_seqnum.move` for more details.
#[tokio::test]
async fn randomness_stall_recovery() {
    let epoch_duration_secs = 20;

    let (mut swarm, mut cli, _faucet) = SwarmBuilder::new_local(4)
        .with_num_fullnodes(0) //TODO: revert back to 1 after invalid version bug is fixed
        .with_aptos()
        .with_init_config(Arc::new(|_, conf, _| {
            conf.api.failpoints_enabled = true;
        }))
        .with_init_genesis_config(Arc::new(move |conf| {
            conf.epoch_duration_secs = epoch_duration_secs;

            // Ensure randomness is enabled.
            conf.consensus_config.enable_validator_txns();
            conf.randomness_config_override = Some(OnChainRandomnessConfig::default_enabled());
        }))
        .build_with_cli(0)
        .await;

    let root_addr = swarm.chain_info().root_account().address();
    let root_idx = cli.add_account_with_address_to_cli(swarm.root_key(), root_addr);

    let rest_client = swarm.validators().next().unwrap().rest_client();

    info!("Wait for epoch 2.");
    swarm
        .wait_for_all_nodes_to_catchup_to_epoch(2, Duration::from_secs(epoch_duration_secs * 2))
        .await
        .expect("Epoch 2 taking too long to arrive!");

    info!("Halting the chain by putting every validator into sync_only mode.");
    for validator in swarm.validators_mut() {
        enable_sync_only_mode(4, validator).await;
    }

    info!("Chain should have halted.");
    let liveness_check_result = swarm
        .liveness_check(Instant::now().add(Duration::from_secs(20)))
        .await;
    info!("liveness_check_result={:?}", liveness_check_result);
    assert!(liveness_check_result.is_err());

    info!("Hot-fixing all validators.");
    for (idx, validator) in swarm.validators_mut().enumerate() {
        info!("Stopping validator {}.", idx);
        validator.stop();
        let config_path = validator.config_path();
        let mut validator_override_config =
            OverrideNodeConfig::load_config(config_path.clone()).unwrap();
        validator_override_config
            .override_config_mut()
            .randomness_override_seq_num = 1;
        validator_override_config
            .override_config_mut()
            .consensus
            .sync_only = false;
        info!("Updating validator {} config.", idx);
        validator_override_config.save_config(config_path).unwrap();
        info!("Restarting validator {}.", idx);
        validator.start().unwrap();
        info!("Let validator {} bake for 5 secs.", idx);
        tokio::time::sleep(Duration::from_secs(5)).await;
    }

    info!("Hot-fixing the VFNs.");
    for (idx, vfn) in swarm.fullnodes_mut().enumerate() {
        info!("Stopping VFN {}.", idx);
        vfn.stop();
        let config_path = vfn.config_path();
        let mut vfn_override_config = OverrideNodeConfig::load_config(config_path.clone()).unwrap();
        vfn_override_config
            .override_config_mut()
            .randomness_override_seq_num = 1;
        info!("Updating VFN {} config.", idx);
        vfn_override_config.save_config(config_path).unwrap();
        info!("Restarting VFN {}.", idx);
        vfn.start().unwrap();
        info!("Let VFN {} bake for 5 secs.", idx);
        tokio::time::sleep(Duration::from_secs(5)).await;
    }

    let liveness_check_result = swarm
        .liveness_check(Instant::now().add(Duration::from_secs(30)))
        .await;
    assert!(liveness_check_result.is_ok());

    info!("There should be no randomness at the moment.");
    let block_randomness_seed = get_on_chain_resource::<PerBlockRandomness>(&rest_client).await;
    assert!(block_randomness_seed.seed.is_none());

    info!("Bump on-chain conig seqnum to re-enable randomness.");
    let script = r#"
script {
    use aptos_framework::aptos_governance;
    use aptos_framework::randomness_config_seqnum;

    fun main(core_resources: &signer) {
        let framework_signer = aptos_governance::get_signer_testnet_only(core_resources, @0x1);
        randomness_config_seqnum::set_for_next_epoch(&framework_signer, 2);
        aptos_governance::force_end_epoch(&framework_signer); // reconfigure() won't work at the moment.
    }
}
    "#;
    let gas_options = GasOptions {
        gas_unit_price: Some(1),
        max_gas: Some(2000000),
        expiration_secs: 60,
    };
    let txn_summary = cli
        .run_script_with_gas_options(root_idx, script, Some(gas_options))
        .await
        .expect("Txn execution error.");
    debug!("txn_summary={:?}", txn_summary);

    tokio::time::sleep(Duration::from_secs(10)).await;

    let epoch = rest_client
        .get_ledger_information()
        .await
        .unwrap()
        .into_inner()
        .epoch;
    info!(
        "Current epoch is {}. Wait until epoch {}, and randomness should be back.",
        epoch,
        epoch + 1
    );

    swarm
        .wait_for_all_nodes_to_catchup_to_epoch(
            epoch + 1,
            Duration::from_secs(epoch_duration_secs * 2),
        )
        .await
        .unwrap_or_else(|_| panic!("Epoch {} taking too long to arrive!", epoch + 1));

    let PerBlockRandomness {
        epoch: actual_epoch,
        ..
    } = get_on_chain_resource::<PerBlockRandomness>(&rest_client).await;
    // seed is not necessarily generated because of the rand check optimization.
    // but epoch and round should be updated.
    assert_eq!(epoch + 1, actual_epoch);
}
```

**File:** consensus/src/network.rs (L757-760)
```rust
        let (consensus_messages_tx, consensus_messages) = aptos_channel::new(
            QueueStyle::FIFO,
            10,
            Some(&counters::CONSENSUS_CHANNEL_MSGS),
```
