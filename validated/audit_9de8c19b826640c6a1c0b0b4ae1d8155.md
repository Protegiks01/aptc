# Audit Report

## Title
Critical Consensus Race Condition: OrderVote Creation Uses Inconsistent State Compute Results Across Validators

## Summary
A critical race condition exists in the consensus protocol where validators create `OrderVote` messages with different `BlockInfo` data depending on whether block execution has completed when they broadcast their order vote. This design flaw violates the protocol's intended use of ordered-only state and prevents vote aggregation, causing consensus liveness failures.

## Finding Description

The vulnerability occurs because the order vote creation mechanism reads the **current** execution state without normalization, unlike regular votes which force all validators to use dummy state through the `decoupled_execution` flag.

**Vulnerable Flow:**

Blocks are created with dummy execution state via `PipelinedBlock::new_ordered()` which calls `StateComputeResult::new_dummy()`. [1](#0-0) 

This dummy state uses `ACCUMULATOR_PLACEHOLDER_HASH` as the root hash. [2](#0-1) 

Execution happens asynchronously and updates the block's state via `set_compute_result()`. [3](#0-2) 

When a QC forms, `broadcast_order_vote()` is immediately called without waiting for execution completion. [4](#0-3) 

The order vote creation calls `order_vote_proposal()` which uses `self.block_info()` to read the **current** execution state. [5](#0-4) 

The `block_info()` method reads the current compute result's root hash and version without normalization. [6](#0-5) 

**Critical Design Inconsistency:**

Regular votes use `decoupled_execution = true` (hardcoded) to force ALL validators to vote with dummy state. [7](#0-6) 

This ensures all validators generate identical `VoteData` through `vote_data_ordering_only()` which uses `ACCUMULATOR_PLACEHOLDER_HASH`. [8](#0-7) 

However, order votes have NO such normalization mechanism and read whatever execution state is currently available.

**Race Condition Impact:**

Order votes are aggregated by `LedgerInfo` hash in `PendingOrderVotes`. [9](#0-8) 

Since different validators may have different execution states at order vote creation time (fast executors: actual state, slow executors: dummy state), they produce different `BlockInfo` → different `LedgerInfo` → different hashes → separate HashMap entries, preventing aggregation.

**System Expects Ordered-Only State:**

The validation logic in `guarded_sign_commit_vote()` explicitly checks that order vote ledger info uses ordered-only (dummy) state. [10](#0-9) 

This confirms the system's design intent: order votes should use dummy execution state. However, the implementation doesn't enforce this consistently across validators.

## Impact Explanation

**Critical Severity - Consensus Liveness Failure**

This meets the **Total Loss of Liveness/Network Availability (Critical)** category from the Aptos bug bounty program:

1. **Vote Aggregation Failure**: If validator voting power splits between those with dummy state (slow execution) and actual state (fast execution), neither group reaches the 2f+1 quorum threshold required to form an order certificate.

2. **Consensus Deadlock**: Without an order certificate, the consensus protocol cannot progress, permanently blocking the network until manual intervention or validator restarts synchronize execution states.

3. **Protocol Non-Determinism**: The outcome depends on network timing and execution speed rather than deterministic protocol rules, violating consensus safety guarantees.

4. **Design Violation**: The system's validation code expects ordered-only state, but the implementation doesn't enforce it, creating a logic vulnerability that violates protocol invariants.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

The vulnerability can trigger during normal operation:

1. **No Attack Required**: The race condition is inherent in the pipelined consensus design where order votes are created immediately after QC formation without synchronization with execution.

2. **Timing-Dependent**: The race window exists between QC formation and execution completion. Fast execution reduces the window, but variable network latency and transaction complexity can widen it.

3. **Natural Occurrence**: Any block where execution takes longer than QC formation time on some validators but not others will trigger inconsistent state reads.

4. **Mitigating Factors**: In practice, execution is typically fast (< QC formation time), which may explain why this hasn't manifested as a widespread issue. However, complex transactions or system load can increase execution time.

## Recommendation

Make `order_vote_proposal()` use ordered-only `BlockInfo` (with dummy execution state) like regular votes do:

```rust
pub fn order_vote_proposal(&self, quorum_cert: Arc<QuorumCert>) -> OrderVoteProposal {
    let compute_result = self.compute_result();
    let block_info = self.block().gen_block_info(
        *ACCUMULATOR_PLACEHOLDER_HASH,  // Use dummy state
        0,  // Version 0 for ordered-only
        compute_result.epoch_state().clone(),
    );
    OrderVoteProposal::new(self.block.clone(), block_info, quorum_cert)
}
```

This ensures all validators create order votes with identical `BlockInfo` regardless of execution timing, matching the design pattern already used by regular votes and expected by the validation logic.

## Proof of Concept

The logic vulnerability is demonstrated through code analysis showing the inconsistency between regular vote and order vote creation mechanisms. A runtime PoC would require:

1. Deploy a transaction-heavy workload to increase execution time
2. Monitor validators with varying network latency
3. Observe order votes with different `executed_state_id` values for the same block
4. Demonstrate failed vote aggregation due to hash mismatches

The vulnerability is valid as a logic flaw even without runtime reproduction, as it violates the protocol's design invariants.

## Notes

The system already has all the necessary infrastructure for ordered-only state (`is_ordered_only()`, `match_ordered_only()`, `create_merged_with_executed_state()`), and regular votes successfully use this pattern. The order vote implementation simply fails to follow the same pattern, creating an architectural inconsistency that can cause consensus failures under specific timing conditions.

### Citations

**File:** consensus/consensus-types/src/pipelined_block.rs (L277-330)
```rust
    pub fn set_compute_result(
        &self,
        state_compute_result: StateComputeResult,
        execution_time: Duration,
    ) {
        let mut to_commit = 0;
        let mut to_retry = 0;
        for txn in state_compute_result.compute_status_for_input_txns() {
            match txn {
                TransactionStatus::Keep(_) => to_commit += 1,
                TransactionStatus::Retry => to_retry += 1,
                _ => {},
            }
        }

        let execution_summary = ExecutionSummary {
            payload_len: self
                .block
                .payload()
                .map_or(0, |payload| payload.len_for_execution()),
            to_commit,
            to_retry,
            execution_time,
            root_hash: state_compute_result.root_hash(),
            gas_used: state_compute_result
                .execution_output
                .block_end_info
                .as_ref()
                .map(|info| info.block_effective_gas_units()),
        };
        *self.state_compute_result.lock() = state_compute_result;

        // We might be retrying execution, so it might have already been set.
        // Because we use this for statistics, it's ok that we drop the newer value.
        if let Some(previous) = self.execution_summary.get() {
            if previous.root_hash == execution_summary.root_hash
                || previous.root_hash == *ACCUMULATOR_PLACEHOLDER_HASH
            {
                warn!(
                    "Skipping re-inserting execution result, from {:?} to {:?}",
                    previous, execution_summary
                );
            } else {
                error!(
                    "Re-inserting execution result with different root hash: from {:?} to {:?}",
                    previous, execution_summary
                );
            }
        } else {
            self.execution_summary
                .set(execution_summary)
                .expect("inserting into empty execution summary");
        }
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L394-398)
```rust
    pub fn new_ordered(block: Block, window: OrderedBlockWindow) -> Self {
        let input_transactions = Vec::new();
        let state_compute_result = StateComputeResult::new_dummy();
        Self::new(block, input_transactions, state_compute_result).with_block_window(window)
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L452-459)
```rust
    pub fn block_info(&self) -> BlockInfo {
        let compute_result = self.compute_result();
        self.block().gen_block_info(
            compute_result.root_hash(),
            compute_result.last_version_or_0(),
            compute_result.epoch_state().clone(),
        )
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L461-469)
```rust
    pub fn vote_proposal(&self) -> VoteProposal {
        let compute_result = self.compute_result();
        VoteProposal::new(
            compute_result.extension_proof(),
            self.block.clone(),
            compute_result.epoch_state().clone(),
            true,
        )
    }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L471-473)
```rust
    pub fn order_vote_proposal(&self, quorum_cert: Arc<QuorumCert>) -> OrderVoteProposal {
        OrderVoteProposal::new(self.block.clone(), self.block_info(), quorum_cert)
    }
```

**File:** execution/executor-types/src/state_compute_result.rs (L74-76)
```rust
    pub fn new_dummy() -> Self {
        Self::new_dummy_with_root_hash(*ACCUMULATOR_PLACEHOLDER_HASH)
    }
```

**File:** consensus/src/round_manager.rs (L1807-1807)
```rust
                    if let Err(e) = self.broadcast_order_vote(vote, qc.clone()).await {
```

**File:** consensus/consensus-types/src/vote_proposal.rs (L59-69)
```rust
    /// This function returns the vote data with a dummy executed_state_id and version
    fn vote_data_ordering_only(&self) -> VoteData {
        VoteData::new(
            self.block().gen_block_info(
                *ACCUMULATOR_PLACEHOLDER_HASH,
                0,
                self.next_epoch_state().cloned(),
            ),
            self.block().quorum_cert().certified_block().clone(),
        )
    }
```

**File:** consensus/src/pending_order_votes.rs (L68-81)
```rust
        let li_digest = order_vote.ledger_info().hash();

        // obtain the ledger info with signatures associated to the order vote's ledger info
        let (quorum_cert, status) = self.li_digest_to_votes.entry(li_digest).or_insert_with(|| {
            // if the ledger info with signatures doesn't exist yet, create it
            (
                verified_quorum_cert.expect(
                    "Quorum Cert is expected when creating a new entry in pending order votes",
                ),
                OrderVoteStatus::NotEnoughVotes(SignatureAggregator::new(
                    order_vote.ledger_info().clone(),
                )),
            )
        });
```

**File:** consensus/safety-rules/src/safety_rules.rs (L381-393)
```rust
        if !old_ledger_info.commit_info().is_ordered_only()
            // When doing fast forward sync, we pull the latest blocks and quorum certs from peers
            // and store them in storage. We then compute the root ordered cert and root commit cert
            // from storage and start the consensus from there. But given that we are not storing the
            // ordered cert obtained from order votes in storage, instead of obtaining the root ordered cert
            // from storage, we set root ordered cert to commit certificate.
            // This means, the root ordered cert will not have a dummy executed_state_id in this case.
            // To handle this, we do not raise error if the old_ledger_info.commit_info() matches with
            // new_ledger_info.commit_info().
            && old_ledger_info.commit_info() != new_ledger_info.commit_info()
        {
            return Err(Error::InvalidOrderedLedgerInfo(old_ledger_info.to_string()));
        }
```
