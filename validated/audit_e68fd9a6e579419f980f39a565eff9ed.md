# Audit Report

## Title
State Snapshot Finalization Fails to Write StateKvCommitProgress Leading to Panic on Restart

## Summary
The `finalize_state_snapshot()` function in the storage layer creates state KV database batches but fails to commit them, leaving `StateKvCommitProgress` unwritten. When the node restarts, `sync_commit_progress()` expects this progress marker to exist and panics with "State K/V commit progress cannot be None", preventing node recovery.

## Finding Description

The vulnerability exists in the state snapshot finalization code path where state KV batches are created but never committed to disk, violating database atomicity guarantees.

When `finalize_state_snapshot()` executes, it creates both ledger and state KV batches: [1](#0-0) 

These batches are passed to `save_transactions()` with the `existing_batch` parameter set to `Some`: [2](#0-1) 

However, when `save_transactions()` receives `Some(existing_batch)`, it only populates the batches without committing them: [3](#0-2) 

The function then writes `OverallCommitProgress` and `LedgerCommitProgress` to the ledger batch, and only commits the ledger database batch: [4](#0-3) 

The state KV batches (`sharded_kv_batch` and `state_kv_metadata_batch`) are never committed. `StateKvCommitProgress` is only written when `state_kv_db.commit()` is called, which invokes `write_progress()`: [5](#0-4) 

In contrast, normal transaction processing correctly commits state KV batches by calling `state_kv_db.commit()`: [6](#0-5) 

On node restart, `StateStore::new()` calls `sync_commit_progress()` to reconcile database state: [7](#0-6) 

The `sync_commit_progress()` function reads `OverallCommitProgress` and expects `StateKvCommitProgress` to exist when it does: [8](#0-7) 

Since `StateKvCommitProgress` was never written during snapshot finalization, but `OverallCommitProgress` was, the node panics at line 434 with "State K/V commit progress cannot be None.", preventing restart.

This is triggered during normal state synchronization operations when a node completes snapshot restoration: [9](#0-8) 

## Impact Explanation

**HIGH Severity** - This vulnerability causes validator node crashes, aligning with the "API Crashes" category from the Aptos bug bounty program (up to $50,000):

1. **Validator Node Crashes**: Any validator performing state sync via snapshot restoration will crash on restart with an unrecoverable panic, unable to rejoin the network
2. **Loss of Network Liveness**: Affected validators cannot participate in consensus, reducing the active validator set and potentially impacting network performance
3. **State Database Inconsistency**: The database contains `OverallCommitProgress` but missing `StateKvCommitProgress`, violating atomicity assumptions and preventing automatic recovery
4. **Manual Intervention Required**: Recovery requires database-level manual intervention or complete resync from genesis, causing operational disruption

The impact directly affects validator availability and network operational integrity, meeting the HIGH severity criteria for operational vulnerabilities.

## Likelihood Explanation

**HIGH Likelihood** - This bug triggers deterministically during normal node operations:

1. State snapshot restoration is the standard "fast sync" mechanism for nodes catching up to the network
2. Any node performing snapshot-based state sync will deterministically trigger this bug
3. The bug occurs automatically on the next restart after snapshot finalization—no attacker action required
4. This is a pure logic bug in the commit flow, not a race condition or timing issue
5. The vulnerability affects production code paths used in mainnet operations

The combination of high likelihood and high impact makes this a critical operational vulnerability affecting validator availability.

## Recommendation

Fix the `finalize_state_snapshot()` function to commit the state KV batches after committing the ledger batch:

```rust
// After line 223 in aptosdb_writer.rs, add:
self.state_kv_db.commit(
    version,
    Some(state_kv_metadata_batch),
    sharded_kv_batch
)?;
```

Alternatively, refactor `save_transactions()` to accept a commit flag and handle both batch population and commitment in a single atomic operation to prevent similar issues in the future.

## Proof of Concept

To reproduce this vulnerability:

1. Start a fresh Aptos node and initiate state sync using snapshot restoration mode
2. Wait for the state snapshot to complete (when `finalize_state_snapshot()` is called)
3. Verify that `OverallCommitProgress` exists in the ledger metadata database but `StateKvCommitProgress` does not exist in the state KV metadata database
4. Restart the node
5. Observe the panic at `StateStore::new()` → `sync_commit_progress()` with message: "State K/V commit progress cannot be None."

The node will be unable to restart without manual database intervention or full resync.

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L164-165)
```rust
            let mut sharded_kv_batch = self.state_kv_db.new_sharded_native_batches();
            let mut state_kv_metadata_batch = SchemaBatch::new();
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L183-198)
```rust
            restore_utils::save_transactions(
                self.state_store.clone(),
                self.ledger_db.clone(),
                version,
                &transactions,
                &persisted_aux_info,
                &transaction_infos,
                &events,
                wsets,
                Some((
                    &mut ledger_db_batch,
                    &mut sharded_kv_batch,
                    &mut state_kv_metadata_batch,
                )),
                false,
            )?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L207-223)
```rust
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::LedgerCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;
            ledger_db_batch
                .ledger_metadata_db_batches
                .put::<DbMetadataSchema>(
                    &DbMetadataKey::OverallCommitProgress,
                    &DbMetadataValue::Version(version),
                )?;

            // Apply the change set writes to the database (atomically) and update in-memory state
            //
            // state kv and SMT should use shared way of committing.
            self.ledger_db.write_schemas(ledger_db_batch)?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L376-380)
```rust
            s.spawn(|_| {
                self.state_kv_db
                    .commit(chunk.expect_last_version(), None, sharded_state_kv_batches)
                    .unwrap();
            });
```

**File:** storage/aptosdb/src/backup/restore_utils.rs (L131-144)
```rust
    if let Some((ledger_db_batch, state_kv_batches, _state_kv_metadata_batch)) = existing_batch {
        save_transactions_impl(
            state_store,
            ledger_db,
            first_version,
            txns,
            persisted_aux_info,
            txn_infos,
            events,
            write_sets.as_ref(),
            ledger_db_batch,
            state_kv_batches,
            kv_replay,
        )?;
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-215)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }

    pub(crate) fn write_progress(&self, version: Version) -> Result<()> {
        self.state_kv_metadata_db.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvCommitProgress,
            &DbMetadataValue::Version(version),
        )
    }
```

**File:** storage/aptosdb/src/state_store/mod.rs (L353-359)
```rust
        if !hack_for_tests && !empty_buffered_state_for_restore {
            Self::sync_commit_progress(
                Arc::clone(&ledger_db),
                Arc::clone(&state_kv_db),
                Arc::clone(&state_merkle_db),
                /*crash_if_difference_is_too_large=*/ true,
            );
```

**File:** storage/aptosdb/src/state_store/mod.rs (L417-436)
```rust
        if let Some(overall_commit_progress) = ledger_metadata_db
            .get_synced_version()
            .expect("DB read failed.")
        {
            info!(
                overall_commit_progress = overall_commit_progress,
                "Start syncing databases..."
            );
            let ledger_commit_progress = ledger_metadata_db
                .get_ledger_commit_progress()
                .expect("Failed to read ledger commit progress.");
            assert_ge!(ledger_commit_progress, overall_commit_progress);

            let state_kv_commit_progress = state_kv_db
                .metadata_db()
                .get::<DbMetadataSchema>(&DbMetadataKey::StateKvCommitProgress)
                .expect("Failed to read state K/V commit progress.")
                .expect("State K/V commit progress cannot be None.")
                .expect_version();
            assert_ge!(state_kv_commit_progress, overall_commit_progress);
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1129-1136)
```rust
    storage
        .writer
        .finalize_state_snapshot(
            version,
            target_output_with_proof.clone(),
            epoch_change_proofs,
        )
        .map_err(|error| format!("Failed to finalize the state snapshot! Error: {:?}", error))?;
```
