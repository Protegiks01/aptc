# Audit Report

## Title
Epoch Transition Race Condition Causes Node Crash on Restart Due to Unfiltered Batch Loading

## Summary
A logic bug in the quorum store batch cleanup process allows old-epoch batches to be loaded into memory without epoch validation during same-epoch restarts, potentially causing quota exhaustion and node panic that prevents automatic restart.

## Finding Description

The vulnerability stems from inconsistent epoch filtering logic between two code paths during `BatchStore` initialization.

**The Problem Chain:**

1. **Database Returns All Epochs:** The `get_all_batches()` function retrieves all batches from the database without any epoch filtering. [1](#0-0) 

2. **Asynchronous Epoch Cleanup:** During epoch transitions when `is_new_epoch = true`, old batch cleanup via `gc_previous_epoch_batches_from_db_v1()` is spawned asynchronously in a background task and NOT awaited. [2](#0-1) 

3. **Epoch Detection:** The `is_new_epoch` flag is determined by checking if the latest ledger info ends an epoch. [3](#0-2) 

4. **Epoch Filtering Present in Cleanup Path:** When `is_new_epoch = true`, the `gc_previous_epoch_batches_from_db_v1()` function correctly filters batches by epoch (`if epoch < current_epoch`). [4](#0-3) 

5. **Epoch Filtering MISSING in Recovery Path:** When `is_new_epoch = false` (same-epoch restart), the `populate_cache_and_gc_expired_batches_v1()` function only filters by expiration time (`if expiration < gc_timestamp`) and does NOT check the epoch. [5](#0-4) 

6. **Panic on Quota Exhaustion:** When inserting batches via `insert_to_cache()`, quota limits are enforced. If exceeded, the `QuotaManager::update_quota()` returns an error with `bail!()`. [6](#0-5) 

The recovery path then panics with `.expect("Storage limit exceeded upon BatchReader construction")` if quotas are exceeded. [7](#0-6) 

**Attack Scenario:**

1. Epoch N-1 â†’ N transition occurs at a validator node
2. `gc_previous_epoch_batches_from_db_v1()` spawns asynchronously to delete old batches but is not awaited
3. Node crashes BEFORE the async cleanup task completes
4. Old epoch N-1 batches remain in the database
5. On restart, `latest_ledger_info.ends_epoch()` returns `false` (mid-epoch N), so `is_new_epoch = false`
6. `populate_cache_and_gc_expired_batches_v1()` is called instead of `gc_previous_epoch_batches_from_db_v1()`
7. ALL batches from database (including old epoch N-1 batches) are loaded via `get_all_batches()`
8. Batches from epoch N-1 that are not yet expired by time (within 60-second expiration window) are inserted into cache
9. Each batch consumes quota via `insert_to_cache()` 
10. If total size exceeds configured quotas, the node panics during `BatchStore::new()` construction
11. Node enters crash loop and cannot restart without manual database cleanup

## Impact Explanation

**Severity: Medium** (up to $10,000 per Aptos Bug Bounty)

This vulnerability causes **temporary liveness issues requiring manual intervention**, which aligns with the Medium severity "Limited Protocol Violations" category.

**Impact:**
- **Liveness Failure**: Affected nodes cannot restart automatically, requiring manual database cleanup
- **State Inconsistencies**: Nodes stuck in crash loop while network progresses
- **Validator Downtime**: Validators cannot participate in consensus until manually recovered

The default quotas are memory_quota: 120MB, db_quota: 300MB, batch_quota: 300K. [8](#0-7) 

The 60-second expiration buffer provides a window where old-epoch batches can be loaded. [9](#0-8) 

While this doesn't directly cause consensus safety violations (other validators continue operating normally), it represents a logic bug that breaks resource management invariants and can cause individual node unavailability.

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability requires specific timing:
1. Node crash during or shortly after epoch transition
2. Background cleanup task not completed before crash  
3. Restart occurs within same epoch
4. Sufficient old-epoch batches remain unexpired in database (within 60-second window)
5. Combined batches exceed quota limits

Epoch transitions are frequent (typically every few hours in Aptos), and node crashes during these periods can occur in production. The asynchronous nature of cleanup creates a realistic race window. Byzantine validators could also deliberately create many large batches near epoch boundaries to maximize the likelihood of quota exhaustion on restart.

## Recommendation

Add epoch filtering to `populate_cache_and_gc_expired_batches_v1()` (and v2 variant) similar to how `gc_previous_epoch_batches_from_db_v1()` filters batches:

```rust
fn populate_cache_and_gc_expired_batches_v1(
    db: Arc<dyn QuorumStoreStorage>,
    current_epoch: u64,
    last_certified_time: u64,
    expiration_buffer_usecs: u64,
    batch_store: &BatchStore,
) {
    let db_content = db.get_all_batches().expect("failed to read v1 data from db");
    let mut expired_keys = Vec::new();
    let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
    
    for (digest, value) in db_content {
        let expiration = value.expiration();
        let epoch = value.epoch(); // Add epoch check
        
        // Filter by BOTH expiration AND epoch
        if expiration < gc_timestamp || epoch < current_epoch {
            expired_keys.push(digest);
        } else {
            batch_store
                .insert_to_cache(&value.into())
                .expect("Storage limit exceeded upon BatchReader construction");
        }
    }
    
    tokio::task::spawn_blocking(move || {
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    });
}
```

This ensures old-epoch batches are never loaded into the cache during same-epoch restarts, preventing quota exhaustion from stale data.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Setting up a validator node with moderate batch creation
2. Triggering an epoch transition 
3. Crashing the node immediately after epoch transition (before async cleanup completes)
4. Verifying old-epoch batches remain in database
5. Restarting the node within the same epoch
6. Observing the node panic with "Storage limit exceeded upon BatchReader construction" if combined batches exceed quotas

The core issue is the logical inconsistency: `gc_previous_epoch_batches_from_db_v1()` filters by epoch while `populate_cache_and_gc_expired_batches_v1()` does not, creating a code path where old-epoch batches can be loaded incorrectly.

---

**Notes:**
This is a genuine logic bug in the epoch transition handling code. The missing epoch filter in the recovery path creates an inconsistency with the cleanup path, allowing stale data to be loaded under specific timing conditions. While the natural occurrence may be rare, the bug represents a violation of resource management invariants that should be fixed.

### Citations

**File:** consensus/src/quorum_store/quorum_store_db.rs (L103-108)
```rust
    fn get_all_batches(&self) -> Result<HashMap<HashValue, PersistedValue<BatchInfo>>> {
        let mut iter = self.db.iter::<BatchSchema>()?;
        iter.seek_to_first();
        iter.map(|res| res.map_err(Into::into))
            .collect::<Result<HashMap<HashValue, PersistedValue<BatchInfo>>>>()
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L64-83)
```rust
    pub(crate) fn update_quota(&mut self, num_bytes: usize) -> anyhow::Result<StorageMode> {
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!("Batch quota exceeded ");
        }

        if self.db_balance >= num_bytes {
            self.batch_balance -= 1;
            self.db_balance -= num_bytes;

            if self.memory_balance >= num_bytes {
                self.memory_balance -= num_bytes;
                Ok(StorageMode::MemoryAndPersisted)
            } else {
                Ok(StorageMode::PersistedOnly)
            }
        } else {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!("Storage quota exceeded ");
        }
```

**File:** consensus/src/quorum_store/batch_store.rs (L156-160)
```rust
        if is_new_epoch {
            tokio::task::spawn_blocking(move || {
                Self::gc_previous_epoch_batches_from_db_v1(db_clone.clone(), epoch);
                Self::gc_previous_epoch_batches_from_db_v2(db_clone, epoch);
            });
```

**File:** consensus/src/quorum_store/batch_store.rs (L181-210)
```rust
    fn gc_previous_epoch_batches_from_db_v1(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db.get_all_batches().expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L245-290)
```rust
    fn populate_cache_and_gc_expired_batches_v1(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();

            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value.into())
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L239-244)
```rust
        let latest_ledger_info_with_sigs = self
            .aptos_db
            .get_latest_ledger_info()
            .expect("could not get latest ledger info");
        let last_committed_timestamp = latest_ledger_info_with_sigs.commit_info().timestamp_usecs();
        let is_new_epoch = latest_ledger_info_with_sigs.ledger_info().ends_epoch();
```

**File:** consensus/src/quorum_store/quorum_store_builder.rs (L265-265)
```rust
            Duration::from_secs(60).as_micros() as u64,
```

**File:** config/src/config/quorum_store_config.rs (L133-135)
```rust
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
```
