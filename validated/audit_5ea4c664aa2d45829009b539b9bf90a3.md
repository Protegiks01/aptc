# Audit Report

## Title
State Restore Atomicity Violation: KV and Merkle Tree Divergence via Parallel Execution Failure

## Summary
The state snapshot restoration process executes KV store writes and Merkle tree updates in parallel without atomicity guarantees. When proof verification fails, the KV data is already permanently committed while the Merkle tree writes are aborted, leaving the database in an inconsistent state. The vulnerability is exacerbated by in-memory state corruption in `JellyfishMerkleRestore` that causes subsequent chunks to skip the failed range, making the corruption permanent.

## Finding Description

The vulnerability exists in the parallel execution pattern where KV and tree operations execute without transactional coordination. The `IO_POOL.join(kv_fn, tree_fn)` executes two database operations in parallel without atomicity guarantees. [1](#0-0) 

The `kv_fn` calls `write_kv_batch()` which commits directly to RocksDB: [2](#0-1) 

This commit is permanent and durable via `state_kv_db.commit()`: [3](#0-2) 

The commit writes to RocksDB with synchronous durability guarantees: [4](#0-3) 

Meanwhile, `tree_fn` processes the chunk and critically updates `self.previous_leaf` in memory for each key BEFORE verifying the proof: [5](#0-4) 

The tree nodes are only written to storage AFTER successful verification: [6](#0-5) 

**Critical Flaw**: If verification fails at line 391, the function returns an error BUT `previous_leaf` has already been updated to the last key in the chunk (line 381) even though no tree nodes were written to storage.

State sync reuses the same `StateSnapshotRestore` instance across chunks: [7](#0-6) [8](#0-7) 

When the next chunk arrives, `JellyfishMerkleRestore` skips keys based on the corrupted `previous_leaf`: [9](#0-8) 

The error handling does not recreate the receiver instance - it merely sends an error notification and continues: [10](#0-9) 

**Exploitation Scenario**:
1. Malicious peer sends chunk [D, E, F] with valid KV data but invalid proof (wrong sibling hashes)
2. Both operations execute in parallel
3. `kv_fn` succeeds: writes D-F to KV database, commits permanently to RocksDB
4. `tree_fn` fails: updates `previous_leaf` to F in memory, then `verify(proof)?` fails, no tree nodes written
5. Error propagates but KV commit is irreversible
6. Next chunk [G, H, I] from honest peer arrives
7. Tree restoration skips D-F based on corrupted `previous_leaf` (believes they're already processed)
8. **Result**: KV has D-F and G-I, but Merkle tree only has G-I - permanent state corruption

## Impact Explanation

**Severity: Critical**

This vulnerability causes permanent state corruption where the KV store and Jellyfish Merkle tree become permanently desynchronized:

1. **Permanent State Corruption**: Affected keys exist in KV storage but have no corresponding Merkle tree nodes, making it impossible to generate valid Merkle proofs for those keys. This breaks a fundamental invariant of the state storage system.

2. **Consensus Divergence Risk**: If multiple nodes are attacked at different key ranges during state sync, they will have different corrupted states. When these nodes compute state root hashes, they will produce different results, potentially causing consensus failures and chain splits.

3. **Unrecoverable Without Manual Intervention**: Recovery requires complete database reset and resync from genesis, or manual database surgery to identify and remove orphaned KV entries. This meets the Critical severity criterion of "Non-recoverable network partition" and "Permanent state corruption" per Aptos Bug Bounty guidelines.

4. **Affects Network Availability**: Nodes with corrupted state cannot participate in consensus correctly, reducing network capacity and potentially leading to liveness issues if enough nodes are affected.

## Likelihood Explanation

**Likelihood: High**

The attack requires only:
- **Ability to act as a state sync peer**: No privileges required - any network participant can serve state sync data
- **Crafting chunks with invalid Merkle proofs**: Trivial to execute - simply provide wrong sibling hashes or mismatched root hash in the proof
- **No cryptographic breaks or validator compromise needed**: The attack exploits a logic flaw in transactional coordination

The vulnerability is triggered during:
- Regular state sync operations for new/syncing nodes
- State snapshot restoration during recovery
- Fast sync modes where nodes bootstrap from snapshots

State sync is a continuous network operation executed by any node joining or recovering, making this attack surface constantly available. The parallel execution runs by default in `StateSnapshotRestoreMode::Default`.

## Recommendation

Implement atomic transaction coordination between KV and tree operations:

**Option 1 - Sequential Execution with Rollback**:
Modify `add_chunk` to execute tree verification BEFORE KV commit, and only commit KV if tree verification succeeds.

**Option 2 - Two-Phase Commit**:
Implement a two-phase commit protocol where both KV and tree operations prepare their writes, verify the proof, and only commit both atomically if verification succeeds.

**Option 3 - Checkpoint/Rollback on previous_leaf**:
Save a checkpoint of `previous_leaf` before processing each chunk. If verification fails, restore `previous_leaf` to the checkpoint value before returning the error.

**Immediate Mitigation**:
Add error recovery logic in `storage_synchronizer.rs` to recreate the `state_snapshot_receiver` instance when `add_chunk` fails, ensuring corrupted in-memory state doesn't persist across chunks.

## Proof of Concept

While a full PoC would require setting up a malicious state sync peer, the vulnerability can be demonstrated by examining the code flow:

1. State sync receives chunk from peer via network
2. `spawn_state_snapshot_receiver` calls `state_snapshot_receiver.add_chunk(states_with_proof.raw_values, states_with_proof.proof)`
3. `StateSnapshotRestore::add_chunk` executes `IO_POOL.join(kv_fn, tree_fn)` in parallel
4. `kv_fn` commits to RocksDB immediately and irreversibly
5. `tree_fn` updates `previous_leaf` in memory, then calls `verify(proof)?`
6. If proof is invalid, verification fails and returns error
7. KV is committed but tree is not, and `previous_leaf` is corrupted
8. Same receiver instance processes next chunk, skipping corrupted range
9. Result: KV-tree divergence is permanent

The code paths documented in the citations above confirm this execution flow without requiring a runtime PoC.

### Citations

**File:** storage/aptosdb/src/state_restore/mod.rs (L122-126)
```rust
        self.db.write_kv_batch(
            self.version,
            &kv_batch,
            StateSnapshotProgress::new(last_key_hash, usage),
        )
```

**File:** storage/aptosdb/src/state_restore/mod.rs (L249-254)
```rust
            StateSnapshotRestoreMode::Default => {
                // We run kv_fn with TreeOnly to restore the usage of DB
                let (r1, r2) = IO_POOL.join(kv_fn, tree_fn);
                r1?;
                r2?;
            },
```

**File:** storage/aptosdb/src/state_store/mod.rs (L1277-1279)
```rust
        self.state_kv_db
            .commit(version, Some(batch), sharded_schema_batch)
    }
```

**File:** storage/aptosdb/src/state_kv_db.rs (L177-208)
```rust
    pub(crate) fn commit(
        &self,
        version: Version,
        state_kv_metadata_batch: Option<SchemaBatch>,
        sharded_state_kv_batches: ShardedStateKvSchemaBatch,
    ) -> Result<()> {
        let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit"]);
        {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_shards"]);
            THREAD_MANAGER.get_io_pool().scope(|s| {
                let mut batches = sharded_state_kv_batches.into_iter();
                for shard_id in 0..NUM_STATE_SHARDS {
                    let state_kv_batch = batches
                        .next()
                        .expect("Not sufficient number of sharded state kv batches");
                    s.spawn(move |_| {
                        // TODO(grao): Consider propagating the error instead of panic, if necessary.
                        self.commit_single_shard(version, shard_id, state_kv_batch)
                            .unwrap_or_else(|err| {
                                panic!("Failed to commit shard {shard_id}: {err}.")
                            });
                    });
                }
            });
        }
        if let Some(batch) = state_kv_metadata_batch {
            let _timer = OTHER_TIMERS_SECONDS.timer_with(&["state_kv_db__commit_metadata"]);
            self.state_kv_metadata_db.write_schemas(batch)?;
        }

        self.write_progress(version)
    }
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L349-368)
```rust
        if let Some(prev_leaf) = &self.previous_leaf {
            let skip_until = chunk
                .iter()
                .find_position(|(key, _hash)| key.hash() > *prev_leaf.account_key());
            chunk = match skip_until {
                None => {
                    info!("Skipping entire chunk.");
                    return Ok(());
                },
                Some((0, _)) => chunk,
                Some((num_to_skip, next_leaf)) => {
                    info!(
                        num_to_skip = num_to_skip,
                        next_leaf = next_leaf,
                        "Skipping leaves."
                    );
                    chunk.split_off(num_to_skip)
                },
            }
        };
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L373-391)
```rust
        for (key, value_hash) in chunk {
            let hashed_key = key.hash();
            if let Some(ref prev_leaf) = self.previous_leaf {
                ensure!(
                    &hashed_key > prev_leaf.account_key(),
                    "State keys must come in increasing order.",
                )
            }
            self.previous_leaf.replace(LeafNode::new(
                hashed_key,
                value_hash,
                (key.clone(), self.version),
            ));
            self.add_one(key, value_hash);
            self.num_keys_received += 1;
        }

        // Verify what we have added so far is all correct.
        self.verify(proof)?;
```

**File:** storage/jellyfish-merkle/src/restore/mod.rs (L394-410)
```rust
        if self.async_commit {
            self.wait_for_async_commit()?;
            let (tx, rx) = channel();
            self.async_commit_result = Some(rx);

            let mut frozen_nodes = HashMap::new();
            std::mem::swap(&mut frozen_nodes, &mut self.frozen_nodes);
            let store = self.store.clone();

            IO_POOL.spawn(move || {
                let res = store.write_node_batch(&frozen_nodes);
                tx.send(res).unwrap();
            });
        } else {
            self.store.write_node_batch(&self.frozen_nodes)?;
            self.frozen_nodes.clear();
        }
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L857-863)
```rust
        let mut state_snapshot_receiver = storage
            .writer
            .get_state_snapshot_receiver(version, expected_root_hash)
            .expect("Failed to initialize the state snapshot receiver!");

        // Handle state value chunks
        while let Some(storage_data_chunk) = state_snapshot_listener.next().await {
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L878-881)
```rust
                    let result = state_snapshot_receiver.add_chunk(
                        states_with_proof.raw_values,
                        states_with_proof.proof.clone(),
                    );
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L956-965)
```rust
                        Err(error) => {
                            let error =
                                format!("Failed to commit state value chunk! Error: {:?}", error);
                            send_storage_synchronizer_error(
                                error_notification_sender.clone(),
                                notification_id,
                                error,
                            )
                            .await;
                        },
```
