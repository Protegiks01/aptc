# Audit Report

## Title
Pre-Partition Read-Write Dependency Tracking Failure Causes State Inconsistency in Parallel Execution

## Summary
The `ConnectedComponentPartitioner` in the block partitioner only considers write sets during union-find grouping, completely ignoring read sets. This allows transactions with read-after-write (RAW) dependencies to be assigned to different shards and execute in parallel without proper synchronization, causing readers to access stale state from the base view instead of waiting for writer commits. This violates the sequential execution equivalence guarantee of the sharded block executor.

## Finding Description

The block partitioner's `ConnectedComponentPartitioner` uses a union-find algorithm to group conflicting transactions, but it only considers write sets during the grouping phase. [1](#0-0) 

Read sets are completely ignored, meaning:
1. Transaction T0 writes to key A (sender S0)
2. Transaction T1 reads from key A (sender S1, where S0 â‰  S1)
3. S1 is NOT unioned with key A in the union-find structure
4. T0 and T1 end up in different partition groups

During `remove_cross_shard_dependencies`, the `has_write_in_range` function only checks for pending writes, not reads. [2](#0-1) 

The `key_owned_by_another_shard` check can fail to detect conflicts when the anchor shard equals the current shard, resulting in an empty range check. [3](#0-2) 

When building cross-shard dependencies, only the last writer before the current transaction's position is tracked. [4](#0-3)  If T1 is in shard 0 and T0 is in shard 1 (both in round 0), T1 won't see T0 as a dependency because `ShardedTxnIndexV2` ordering places T0 after T1.

The `CrossShardStateView` only tracks keys from `required_edges`. [5](#0-4)  Keys without required edges are read from the base view. [6](#0-5) 

**Result**: T1 reads stale state from base_view while T0 writes in parallel, producing results inconsistent with sequential execution order.

## Impact Explanation

This vulnerability violates the **deterministic execution invariant**: parallel execution must produce identical results to sequential execution. While the partitioning itself is deterministic (all validators produce the same partition), the **execution produces incorrect results** that differ from sequential execution semantics.

**Severity: HIGH**

This qualifies as a **State Inconsistency** issue that could enable:

1. **Bypass of Safety Checks**: Smart contracts that read state to enforce safety conditions (balance checks, collateral verification, authorization checks) may execute with stale state, potentially allowing unauthorized actions.

2. **Incorrect State Transitions**: The final committed state contains side effects from transactions that executed with incorrect input values, leading to state corruption.

3. **Exploitation of Dependent Transactions**: Attackers can craft transaction sequences where a reader transaction executes with stale state, bypassing intended sequential dependencies.

While this doesn't cause direct consensus splits (all validators using the same configuration produce identical incorrect results), it breaks the fundamental correctness guarantee of the sharded block executor and creates exploitable state inconsistencies.

## Likelihood Explanation

**Likelihood: HIGH**

This occurs when:
1. Block contains transactions from different senders with RAW dependencies
2. `ConnectedComponentPartitioner` is used (default pre-partitioner)
3. Anchor shard assignment and pre-partition ordering create the blind spot condition

Common patterns affected:
- Transfer followed by balance-dependent logic
- State updates followed by conditional operations
- Any cross-account interactions with read dependencies

**Attacker Requirements**:
- Submit two transactions from different accounts in same block
- First transaction writes to a state location
- Second transaction reads from that location
- No special privileges required

The conditions are routine in blockchain operations, making this a high-likelihood issue.

## Recommendation

Modify `ConnectedComponentPartitioner` to union both read and write sets during dependency grouping:

```rust
for txn_idx in 0..state.num_txns() {
    let sender_idx = state.sender_idx(txn_idx);
    let write_set = state.write_sets[txn_idx].read().unwrap();
    let read_set = state.read_sets[txn_idx].read().unwrap();
    
    // Union both reads and writes
    for &key_idx in write_set.iter().chain(read_set.iter()) {
        let key_idx_in_uf = num_senders + key_idx;
        uf.union(key_idx_in_uf, sender_idx);
    }
}
```

Additionally, modify `has_write_in_range` to check for both pending reads and writes when detecting cross-shard conflicts, or implement a more comprehensive dependency detection mechanism that properly handles RAW dependencies.

## Proof of Concept

The vulnerability is demonstrated by the existing code structure where:
1. Pre-partition ignores read sets (verified in code)
2. Conflict detection only checks writes (verified in code)
3. Dependency building only tracks writers (verified in code)
4. CrossShardStateView only tracks required_edges keys (verified in code)

A concrete PoC would require constructing two transactions with RAW dependency, submitting them to a block, and observing the incorrect parallel execution. The test suite's `verify_partitioner_output` would not catch this because it only validates that existing dependencies are correct, not that all necessary dependencies are created.

**Notes**

This vulnerability represents a fundamental flaw in how the `ConnectedComponentPartitioner` analyzes transaction dependencies. The union-find algorithm correctly groups write-write (WAW) and write-read-write (WAR) conflicts by tracking writes, but completely misses read-after-write (RAW) dependencies because readers don't cause unions. This creates a blind spot where RAW-dependent transactions can be incorrectly parallelized.

The issue is compounded by multiple layers of the system (conflict detection, dependency building, state view) all assuming that proper grouping happened in pre-partition. When pre-partition fails to group RAW-dependent transactions, all subsequent phases fail to catch the error, resulting in incorrect parallel execution.

While this doesn't cause consensus divergence (the partitioning is deterministic), it breaks the correctness guarantee that parallel execution equals sequential execution, which is a critical property of the sharded block executor architecture.

### Citations

**File:** execution/block-partitioner/src/pre_partition/connected_component/mod.rs (L49-56)
```rust
        for txn_idx in 0..state.num_txns() {
            let sender_idx = state.sender_idx(txn_idx);
            let write_set = state.write_sets[txn_idx].read().unwrap();
            for &key_idx in write_set.iter() {
                let key_idx_in_uf = num_senders + key_idx;
                uf.union(key_idx_in_uf, sender_idx);
            }
        }
```

**File:** execution/block-partitioner/src/v2/conflicting_txn_tracker.rs (L70-84)
```rust
    pub fn has_write_in_range(
        &self,
        start_txn_id: PrePartitionedTxnIdx,
        end_txn_id: PrePartitionedTxnIdx,
    ) -> bool {
        if start_txn_id <= end_txn_id {
            self.pending_writes
                .range(start_txn_id..end_txn_id)
                .next()
                .is_some()
        } else {
            self.pending_writes.range(start_txn_id..).next().is_some()
                || self.pending_writes.range(..end_txn_id).next().is_some()
        }
    }
```

**File:** execution/block-partitioner/src/v2/state.rs (L211-217)
```rust
    pub(crate) fn key_owned_by_another_shard(&self, shard_id: ShardId, key: StorageKeyIdx) -> bool {
        let tracker_ref = self.trackers.get(&key).unwrap();
        let tracker = tracker_ref.read().unwrap();
        let range_start = self.start_txn_idxs_by_shard[tracker.anchor_shard_id];
        let range_end = self.start_txn_idxs_by_shard[shard_id];
        tracker.has_write_in_range(range_start, range_end)
    }
```

**File:** execution/block-partitioner/src/v2/state.rs (L304-321)
```rust
        for &key_idx in write_set.iter().chain(read_set.iter()) {
            let tracker_ref = self.trackers.get(&key_idx).unwrap();
            let tracker = tracker_ref.read().unwrap();
            if let Some(txn_idx) = tracker
                .finalized_writes
                .range(..ShardedTxnIndexV2::new(round_id, shard_id, 0))
                .last()
            {
                let src_txn_idx = ShardedTxnIndex {
                    txn_index: *self.final_idxs_by_pre_partitioned[txn_idx.pre_partitioned_txn_idx]
                        .read()
                        .unwrap(),
                    shard_id: txn_idx.shard_id(),
                    round_id: txn_idx.round_id(),
                };
                deps.add_required_edge(src_txn_idx, tracker.storage_location.clone());
            }
        }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L58-71)
```rust
    pub fn create_cross_shard_state_view(
        base_view: &'a S,
        transactions: &[TransactionWithDependencies<AnalyzedTransaction>],
    ) -> CrossShardStateView<'a, S> {
        let mut cross_shard_state_key = HashSet::new();
        for txn in transactions {
            for (_, storage_locations) in txn.cross_shard_dependencies.required_edges_iter() {
                for storage_location in storage_locations {
                    cross_shard_state_key.insert(storage_location.clone().into_state_key());
                }
            }
        }
        CrossShardStateView::new(cross_shard_state_key, base_view)
    }
```

**File:** aptos-move/aptos-vm/src/sharded_block_executor/cross_shard_state_view.rs (L77-82)
```rust
    fn get_state_value(&self, state_key: &StateKey) -> Result<Option<StateValue>, StateViewError> {
        if let Some(value) = self.cross_shard_data.get(state_key) {
            return Ok(value.get_value());
        }
        self.base_view.get_state_value(state_key)
    }
```
