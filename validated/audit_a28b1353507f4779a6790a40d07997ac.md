# Audit Report

## Title
OptQS Parameter Attack: Malicious Leader Can Censor Validators Through Misplaced Blame in Availability Checking

## Summary
A malicious block proposer can exploit the OptQuorumStore (OptQS) batch availability checking mechanism to systematically censor specific validators by including their batches when those batches are not widely replicated, causing other validators to incorrectly blame the batch authors rather than the proposer, resulting in those validators being excluded from future OptQS proposals through the failure tracker mechanism.

## Finding Description

The OptQuorumStore feature allows proposers to include batches without proof-of-store quorum signatures (`opt_batches`) for improved throughput. The system contains an architectural flaw in how batch availability is checked and how blame is assigned for unavailable batches.

**Attack Flow Validation:**

1. **Batch Inclusion with Exclusion Filter**: The proposer pulls opt_batches from their local proof queue using `pull_batches()` with an `exclude_authors` parameter. [1](#0-0)  The internal implementation filters authors using `!exclude_authors.contains(author)`. [2](#0-1) 

2. **Lack of Availability Guarantee**: OptQS batches require only author validation via `verify_opt_batches()`, which checks if the batch author is a valid validator but does NOT verify quorum availability or proof-of-store. [3](#0-2) 

3. **Misplaced Blame Mechanism**: When validators check payload availability for OptQuorumStore payloads, if a batch doesn't exist locally via `batch_reader.exists()`, the system records the **batch author's** validator index in the `missing_authors` BitVec, not the proposer who chose to include the unavailable batch. [4](#0-3) 

4. **Blame Propagation in Timeouts**: When a round times out, `compute_timeout_reason()` checks payload availability and creates a `RoundTimeoutReason::PayloadUnavailable { missing_authors }` that gets included in the timeout vote. [5](#0-4) [6](#0-5) 

5. **Aggregation Across Validators**: The `aggregated_timeout_reason()` method collects missing_authors from multiple validators and computes which authors were reported missing by at least f+1 validators. [7](#0-6) 

6. **Persistent Censorship via Failure Tracker**: The `ExponentialWindowFailureTracker` extracts `missing_authors` from past `PayloadUnavailable` timeouts and adds them to the `exclude_authors` HashSet for future OptQS proposals. [8](#0-7)  This `exclude_authors` set is then passed to `pull_batches()`, creating a censorship feedback loop. [9](#0-8) 

**The Core Vulnerability:**

The architectural flaw is that the **proposer** has control over which batches to include (and can strategically include batches that are not widely available), but the **batch authors** receive the blame when those batches are unavailable to other validators. This misalignment of responsibility and accountability enables a censorship attack.

A malicious proposer can:
- Include fresh opt_batches that haven't propagated through the network
- Include batches from targeted validators when network conditions delay propagation
- Cause honest validators to report the batch authors as having unavailable batches
- Trigger the exponential window failure tracker to exclude those validators from future proposals

The failure tracker doubles its exclusion window on each failure (up to max_window of 100), meaning the exclusion can persist for extended periods. [10](#0-9) 

## Impact Explanation

**Severity Assessment: Medium to High**

This vulnerability represents a **protocol fairness violation** rather than a safety violation:

**Why NOT Critical:**
- Does not enable fund theft or unlimited minting
- Does not cause consensus safety violations (chain splits, double-spending)
- Does not permanently halt the network
- Does not freeze funds or enable remote code execution

**Why Medium/High:**
- **Consensus Fairness Violation**: The OptQS mechanism is designed to include batches from all validators fairly, but this attack enables selective censorship
- **Liveness Degradation**: Excluding multiple validators reduces effective transaction throughput as fewer batches are included in blocks
- **Persistent Effect**: The exponential window failure tracker can maintain exclusion for many rounds (up to 100 consecutive rounds at maximum window)
- **Difficult to Detect**: The attack appears as legitimate availability issues rather than malicious behavior, making it hard to identify and attribute

**Not a Network DoS:** This is explicitly NOT a network DoS attack (which are out of scope). The network continues to produce blocks and process transactions. Rather, this is a protocol-level censorship mechanism that violates validator fairness guarantees.

Per Aptos bug bounty categories, this aligns with **"Significant protocol violations"** that impact consensus fairness and liveness without breaking safety guarantees.

## Likelihood Explanation

**Likelihood: Medium**

**Factors Enabling Exploitation:**
1. **Regular Opportunity**: Any validator becomes proposer in rotation, providing regular attack windows
2. **No Special Privileges**: Attacker only needs to be a validator; no >1/3 Byzantine requirement
3. **Logic-Based Exploit**: No cryptographic barriers or complex preconditions
4. **Detection Difficulty**: Misplaced blame makes the attack appear as victim's availability problems

**Limiting Factors:**
1. **Batch Age Requirement**: `opt_qs_minimum_batch_age_usecs` (default 50ms) requires batches to be somewhat aged, though this only reduces (not eliminates) the attack surface
2. **Network Propagation**: Under normal network conditions, batches propagate quickly enough that timeouts may not occur before fetch completes
3. **Prefetch Mechanism**: Validators attempt to prefetch payload data when proposals are received
4. **Recovery Mechanism**: The failure tracker resets to window=2 after consecutive successes, providing some recovery path

**Exploitation Complexity:**
The attack requires timing coordination where:
- The proposer includes batches at a moment when they're not widely available
- The round timeout occurs before validators can fetch the missing batches
- This is achievable but not guaranteed in every attempt

## Recommendation

**Solution: Correct Blame Attribution**

The fundamental fix is to change the blame attribution from batch authors to block proposers when opt_batches are unavailable:

1. **Track Proposer Accountability**: When `check_payload_availability()` detects missing opt_batches, return both `missing_authors` (batch authors) AND the block proposer's identity.

2. **Modify Failure Tracker Logic**: Update `ExponentialWindowFailureTracker` to exclude the **proposer** who included unavailable batches, not the batch authors. This ensures validators who create batches are not penalized for a proposer's decision to include them prematurely.

3. **Proposer Reputation System**: Implement a proposer reputation mechanism that tracks which proposers consistently include unavailable opt_batches, and use this for exclusion decisions rather than penalizing batch authors.

4. **Stronger Availability Requirements**: Consider requiring opt_batches to have some form of availability proof (e.g., signatures from k validators confirming they have the batch) before inclusion is permitted.

5. **Monitoring and Alerts**: Add metrics and alerts specifically for opt_batch availability patterns that could indicate censorship attacks.

## Proof of Concept

The vulnerability can be demonstrated through the following scenario:

1. Validator M is selected as proposer for round N
2. M observes fresh batches from Validator V in their local proof queue
3. M creates a proposal including V's fresh batches in `opt_batches` before they've propagated widely
4. Other validators receive the proposal and check availability
5. Validators timeout because V's batches haven't arrived yet
6. Validators report `PayloadUnavailable` with V's index in `missing_authors`
7. The failure tracker adds V to `exclude_authors` for future rounds
8. Subsequent proposals exclude V's batches, effectively censoring V

The code path validation confirms each step:
- Batch inclusion: `proof_manager.rs:135-148`
- Availability checking: `quorum_store_payload_manager.rs:409-424`
- Timeout reporting: `round_manager.rs:968-983, 1023-1030`
- Failure tracking: `proposal_status_tracker.rs:80-98, 145-160`

## Notes

This vulnerability represents a real architectural flaw in the OptQuorumStore blame assignment logic. While the impact is limited to consensus fairness rather than safety, it enables systematic censorship of validators through a feedback loop mechanism. The attack exploits the design decision to blame batch authors for unavailability when the proposer controls batch inclusion decisions.

The vulnerability is particularly concerning because:
1. It's difficult to distinguish from legitimate network issues
2. It creates a persistent censorship mechanism through the failure tracker
3. It requires only a single malicious validator acting as proposer
4. Recovery depends on consecutive successes, which the attacker can disrupt during their proposer slots

### Citations

**File:** consensus/src/quorum_store/proof_manager.rs (L135-148)
```rust
                    self.batch_proof_queue.pull_batches(
                        &excluded_batches
                            .iter()
                            .cloned()
                            .chain(proof_block.iter().map(|proof| proof.info().clone()))
                            .collect(),
                        &params.exclude_authors,
                        max_opt_batch_txns_size,
                        max_opt_batch_txns_after_filtering,
                        request.soft_max_txns_after_filtering,
                        request.return_non_full,
                        request.block_timestamp,
                        Some(params.minimum_batch_age_usecs),
                    );
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L596-599)
```rust
        for (_, batches) in self
            .author_to_batches
            .iter()
            .filter(|(author, _)| !exclude_authors.contains(author))
```

**File:** consensus/consensus-types/src/common.rs (L558-572)
```rust
    pub fn verify_opt_batches<T: TBatchInfo>(
        verifier: &ValidatorVerifier,
        opt_batches: &OptBatches<T>,
    ) -> anyhow::Result<()> {
        let authors = verifier.address_to_validator_index();
        for batch in &opt_batches.batch_summary {
            ensure!(
                authors.contains_key(&batch.author()),
                "Invalid author {} for batch {}",
                batch.author(),
                batch.digest()
            );
        }
        Ok(())
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L409-424)
```rust
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                let mut missing_authors = BitVec::with_num_bits(self.ordered_authors.len() as u16);
                for batch in p.opt_batches().deref() {
                    if self.batch_reader.exists(batch.digest()).is_none() {
                        let index = *self
                            .address_to_validator_index
                            .get(&batch.author())
                            .expect("Payload author should have been verified");
                        missing_authors.set(index as u16);
                    }
                }
                if missing_authors.all_zeros() {
                    Ok(())
                } else {
                    Err(missing_authors)
                }
```

**File:** consensus/src/round_manager.rs (L968-983)
```rust
    fn compute_timeout_reason(&self, round: Round) -> RoundTimeoutReason {
        if self.round_state().vote_sent().is_some() {
            return RoundTimeoutReason::NoQC;
        }

        match self.block_store.get_block_for_round(round) {
            None => RoundTimeoutReason::ProposalNotReceived,
            Some(block) => {
                if let Err(missing_authors) = self.block_store.check_payload(block.block()) {
                    RoundTimeoutReason::PayloadUnavailable { missing_authors }
                } else {
                    RoundTimeoutReason::Unknown
                }
            },
        }
    }
```

**File:** consensus/src/round_manager.rs (L1023-1030)
```rust
                let timeout_reason = self.compute_timeout_reason(round);

                RoundTimeout::new(
                    timeout,
                    self.proposal_generator.author(),
                    timeout_reason,
                    signature,
                )
```

**File:** consensus/src/pending_votes.rs (L93-153)
```rust
    fn aggregated_timeout_reason(&self, verifier: &ValidatorVerifier) -> RoundTimeoutReason {
        let mut reason_voting_power: HashMap<RoundTimeoutReason, u128> = HashMap::new();
        let mut missing_batch_authors: HashMap<usize, u128> = HashMap::new();
        // let ordered_authors = verifier.get_ordered_account_addresses();
        for (author, reason) in &self.timeout_reason {
            // To aggregate the reason, we only care about the variant type itself and
            // exclude any data within the variants.
            let reason_key = match reason {
                reason @ RoundTimeoutReason::Unknown
                | reason @ RoundTimeoutReason::ProposalNotReceived
                | reason @ RoundTimeoutReason::NoQC => reason.clone(),
                RoundTimeoutReason::PayloadUnavailable { missing_authors } => {
                    for missing_idx in missing_authors.iter_ones() {
                        *missing_batch_authors.entry(missing_idx).or_default() +=
                            verifier.get_voting_power(author).unwrap_or_default() as u128;
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        // Since we care only about the variant type, we replace the bitvec
                        // with a placeholder.
                        missing_authors: BitVec::with_num_bits(verifier.len() as u16),
                    }
                },
            };
            *reason_voting_power.entry(reason_key).or_default() +=
                verifier.get_voting_power(author).unwrap_or_default() as u128;
        }
        // The aggregated timeout reason is the reason with the most voting power received from
        // at least f+1 peers by voting power. If such voting power does not exist, then the
        // reason is unknown.

        reason_voting_power
            .into_iter()
            .max_by_key(|(_, voting_power)| *voting_power)
            .filter(|(_, voting_power)| {
                verifier
                    .check_aggregated_voting_power(*voting_power, false)
                    .is_ok()
            })
            .map(|(reason, _)| {
                // If the aggregated reason is due to unavailable payload, we will compute the
                // aggregated missing authors bitvec counting batch authors that have been reported
                // missing by minority peers.
                if matches!(reason, RoundTimeoutReason::PayloadUnavailable { .. }) {
                    let mut aggregated_bitvec = BitVec::with_num_bits(verifier.len() as u16);
                    for (author_idx, voting_power) in missing_batch_authors {
                        if verifier
                            .check_aggregated_voting_power(voting_power, false)
                            .is_ok()
                        {
                            aggregated_bitvec.set(author_idx as u16);
                        }
                    }
                    RoundTimeoutReason::PayloadUnavailable {
                        missing_authors: aggregated_bitvec,
                    }
                } else {
                    reason
                }
            })
            .unwrap_or(RoundTimeoutReason::Unknown)
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L65-78)
```rust
    fn compute_failure_window(&mut self) {
        self.last_consecutive_success_count = self.last_consecutive_statuses_matching(|reason| {
            !matches!(
                reason,
                NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable { .. })
            )
        });
        if self.last_consecutive_success_count == 0 {
            self.window *= 2;
            self.window = self.window.min(self.max_window);
        } else if self.last_consecutive_success_count == self.past_round_statuses.len() {
            self.window = 2;
        }
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L80-98)
```rust
    fn get_exclude_authors(&self) -> HashSet<Author> {
        let mut exclude_authors = HashSet::new();

        let limit = self.window;
        for round_reason in self.past_round_statuses.iter().rev().take(limit) {
            if let NewRoundReason::Timeout(RoundTimeoutReason::PayloadUnavailable {
                missing_authors,
            }) = round_reason
            {
                for author_idx in missing_authors.iter_ones() {
                    if let Some(author) = self.ordered_authors.get(author_idx) {
                        exclude_authors.insert(*author);
                    }
                }
            }
        }

        exclude_authors
    }
```

**File:** consensus/src/liveness/proposal_status_tracker.rs (L145-160)
```rust
        let exclude_authors = tracker.get_exclude_authors();
        if !exclude_authors.is_empty() {
            let exclude_authors_str: Vec<_> =
                exclude_authors.iter().map(|a| a.short_str()).collect();
            for author in &exclude_authors_str {
                counters::OPTQS_EXCLUDE_AUTHORS_COUNT
                    .with_label_values(&[author.as_str()])
                    .inc();
            }
            warn!("OptQS exclude authors: {:?}", exclude_authors_str);
        }
        Some(OptQSPayloadPullParams {
            exclude_authors,
            minimum_batch_age_usecs: self.minimum_batch_age_usecs,
        })
    }
```
